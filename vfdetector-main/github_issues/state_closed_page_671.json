[{"number": 33470, "title": "TFLite-micro: unable to build bluepill tests", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Debian 9\r\n- TensorFlow version: current master (17c4db8)\r\n- GCC version: gcc (Debian 9.2.1-8) 9.2.1 20190909\r\n\r\n**Describe the problem**\r\n\r\nTrying to follow the instructions from [TFLite Micro README](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/micro/README.md#building-for-the-blue-pill-stm32f103-using-make) fails, being unable to build the code properly.\r\n\r\nI traced down the problem to e98d181 - the commit before this one passes properly.\r\n\r\nThe fail log is below, but the first line is important, namely the `cannot find entry symbol _main`.\r\nFurther lines are because Renode is unable to run it properly.\r\n\r\n```\r\n...\r\n.../tensorflow/tensorflow/lite/experimental/micro/tools/make/downloads/gcc_embedded/bin/../lib/gcc/arm-none-eabi/7.3.1/../../../../arm-none-eabi/bin/ld: warning: cannot find entry symbol _main; defaulting to 0000000008000000\r\ntensorflow/lite/experimental/micro/testing/test_bluepill_binary.sh tensorflow/lite/experimental/micro/tools/make/gen/bluepill_cortex-m3/bin/micro_features_fft_test '~~~ALL TESTS PASSED~~~'\r\nSending build context to Docker daemon  37.38kB\r\nStep 1/2 : FROM antmicro/renode:latest\r\n ---> d8aae99c4341\r\nStep 2/2 : LABEL maintainer=\"Pete Warden <petewarden@google.com>\"\r\n ---> Using cache\r\n ---> 659756518d3d\r\nSuccessfully built 659756518d3d\r\nSuccessfully tagged renode_bluepill:latest\r\nLOGS:\r\nPreparing suites\r\nStarting suites\r\nRunning /workspace/tensorflow/lite/experimental/micro/testing/bluepill.robot\r\n==============================================================================\r\nbluepill                                                                      \r\n==============================================================================\r\nShould Run Bluepill Test :: Runs a Bluepill test and waits for a s... | FAIL |\r\nTargetInvocationException: Exception has been thrown by the target of an invocation.\r\nInvalidOperationException: Time for operation to finish has exceeded 00:00:30.000000. Events so far:\r\n[14:42:22.501]   ------------------------------------------------------------------------------------\r\n[14:42:52.633]   >>> 'WaitUntilLine': timeout occurred\r\n[14:42:52.634]   >>> Characters waiting in buffer: \r\n\r\n[14:42:52.635]   ------------------------------------------------------------------------------------\r\n------------------------------------------------------------------------------\r\nbluepill                                                              | FAIL |\r\n1 critical test, 0 passed, 1 failed\r\n1 test total, 0 passed, 1 failed\r\n==============================================================================\r\nOutput:  /home/developer/bluepill.xml\r\nCleaning up suites\r\nAggregating all robot results\r\nOutput:  /home/developer/robot_output.xml\r\nLog:     /home/developer/log.html\r\nReport:  /home/developer/report.html\r\nSome tests failed :( See logs for details!\r\ntensorflow/lite/experimental/micro/tools/make/gen/bluepill_cortex-m3/bin/micro_features_fft_test: FAIL - '~~~ALL TESTS PASSED~~~' not found in logs.\r\nmake: *** [tensorflow/lite/experimental/micro/examples/micro_speech/Makefile.inc:314: test_micro_features_fft_test] Error 1\r\n```\r\n\r\nThe said symbol is provided by stm32_bare_lib which is downloaded correctly. The problem is that it is **not compiled** at all. I believe that `MICROLITE_CC_SRCS` in [bluepill_makefile.inc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/micro/tools/make/targets/bluepill_makefile.inc) is evaluated before the lib is actually downloaded.\r\n\r\nThis is easy to verify: just add the following in `bluepill_makefile.inc:54`\r\n```\r\n$(error MICROLITE_CC_SRCS is $(MICROLITE_CC_SRCS))\r\n```\r\nIt will stop the build process before downloading the lib (and will print out the variable **not** containing the relevant source files).\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n1. Clone the repo\r\n2. Run `make -f tensorflow/lite/experimental/micro/tools/make/Makefile TARGET=bluepill test`\r\n3. Fail with the above.\r\n\r\nCC @petewarden \r\n\r\n**Note**\r\nI assume there are two actual problems: one is that the compilation is not correct, the other is that it does not prevent the test from running, but let's it work on a \"crippled\" output binary.", "comments": ["The tests all build now, with the caveat that the binary size is more than what the bluepill hardware can support. A subset of the tests can be run in the renode emulator (e.g. kernel_add_test) while others fail.\r\n\r\nThe remaining work to be done to get everything going again for the Bluepill platform is being tracked internally so I am closing this issue for now.\r\n\r\nPlease let us know if there is something specific that you are unable to do at this time."]}, {"number": 33469, "title": "Simultaneous fetching of collective_ops and global_step triggers \"Skipping rendezvous re-initialization\"", "body": "**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution: Linux CentOS 7.6.1810\r\n- Mobile device if the issue happens on mobile device: No\r\n- TensorFlow installed from: Binary\r\n- TensorFlow version: v1.13.1-0-g6612da8951\r\n- Python version: 3.6.8\r\n- Bazel version: None\r\n- GCC/Compiler version: None\r\n- CUDA/cuDNN version: None\r\n- GPU model and memory: None\r\n\r\n**Describe the current behavior**\r\n\r\n`collective_ops.all_reduce` and `global_step` can be fetched successfully when the operations are carried out _separately_ by a session. Nevertheless, the calling will trigger an info or occasionally fail when the two tensors are fetched _simultaneously_ in a session run.\r\n\r\nregularly raise info:\r\n```console\r\n2019-10-17 17:33:58.119365: I tensorflow/core/distributed_runtime/base_rendezvous_mgr.cc:159] Skipping rendezvous re-initialization.\r\n```\r\noccasionally raise failure:\r\n```console\r\n2019-10-17 17:35:07.980957: I tensorflow/core/distributed_runtime/base_rendezvous_mgr.cc:159] Skipping rendezvous re-initialization.\r\n2019-10-17 17:35:07.982111: W tensorflow/core/common_runtime/base_collective_executor.cc:203] BaseCollectiveExecutor::StartAbort Aborted: Cleanup 34190423657599268\r\n         [[{{node _send_worker0/CollectiveReduce_0}}]]\r\ntask 1: sync_op and global_step [0.5, 0]\r\nINFO:tensorflow:An error was raised. This may be due to a preemption in a connected worker or parameter server. The current session will be closed and a new session will be created. This error may also occur due to a gRPC failure caused by high memory or network bandwidth usage in the parameter servers. If this error occurs repeatedly, try increasing the number of parameter servers assigned to the job. Error: Cleanup 34190423657599268\r\n         [[{{node _send_worker0/CollectiveReduce_0}}]]\r\n```\r\nFull logs are attached below.\r\n\r\n**Describe the expected behavior**\r\n\r\nValue is fetched without warnings.\r\n\r\n**Code to reproduce the issue**\r\n```python\r\n\"\"\"Illustrate AllReduce\"\"\"\r\n\r\nimport os\r\nimport multiprocessing as mp\r\nimport time\r\nimport tensorflow as tf\r\nfrom tensorflow.python.ops import collective_ops\r\n\r\nMP_METHOD = 'fork'\r\nNUM_PROCESSES = 2\r\nCHIEF_INDEX = 0\r\nJOB = 'worker'\r\nDELAY = 0.01\r\n\r\ndef process_fn(hosts, task_index):\r\n    \"\"\"allreduce process\"\"\"\r\n    tf.logging.set_verbosity(tf.logging.INFO)\r\n\r\n    cluster_spec = tf.train.ClusterSpec({JOB: hosts})\r\n    workers = list()\r\n    for task, _ in enumerate(hosts):\r\n        workers.append(tf.DeviceSpec(\r\n            job=JOB, replica=0, task=task, device_type='cpu', device_index=0))\r\n\r\n    collective_group_leader, _, _ = \\\r\n        workers[0].to_string().partition('/device')\r\n    config = tf.ConfigProto()\r\n    config.experimental.collective_group_leader = collective_group_leader\r\n    server = tf.train.Server(cluster_spec, config=config,\r\n                             job_name='worker', task_index=task_index)\r\n    with tf.Graph().as_default():\r\n        creator_fn = tf.train.ChiefSessionCreator\r\n        if task_index != CHIEF_INDEX:\r\n            creator_fn = tf.train.WorkerSessionCreator\r\n        session_creator = creator_fn(master=server.target, config=config)\r\n\r\n        with tf.device(workers[task_index]), \\\r\n                tf.variable_scope('worker{}'.format(task_index)):\r\n            token = tf.constant(task_index, dtype=tf.float32)\r\n            sync_op = collective_ops.all_reduce(\r\n                token, NUM_PROCESSES, 0, 0, 'Add', 'Div')\r\n\r\n        with tf.device(workers[0]), tf.variable_scope('worker0'):\r\n            global_step = tf.train.get_or_create_global_step()\r\n\r\n        with tf.train.MonitoredSession(\r\n                session_creator=session_creator, hooks=[]) \\\r\n                as mon_sess:\r\n            time.sleep((task_index + 1) * DELAY)\r\n            ret = mon_sess.run(sync_op)  # successful\r\n            print('task {}: sync_op {}.'.format(task_index, ret))\r\n\r\n            ret = mon_sess.run(global_step)  # successful\r\n            print('task {}: global_step {}'.format(task_index, ret))\r\n\r\n            ret = mon_sess.run([sync_op, global_step])  # failed\r\n            print('task {}: sync_op and global_step {}'.format(task_index, ret))\r\n\r\n            mon_sess.run(sync_op)\r\n            print('task {}: finalized.'.format(task_index))\r\n            time.sleep(DELAY)\r\n\r\ndef start_process():\r\n    \"\"\"start process\"\"\"\r\n\r\n    port = 60000\r\n    host_fmt = 'localhost:{}'\r\n    hosts = list()\r\n    for process_index in range(NUM_PROCESSES):\r\n        hosts.append(host_fmt.format(port + process_index))\r\n    mp_ctx = mp.get_context(MP_METHOD)\r\n    processes = list()\r\n    for process_index in range(NUM_PROCESSES):\r\n        process = mp_ctx.Process(target=process_fn,\r\n                                 args=(hosts, process_index,))\r\n        processes.append(process)\r\n        process.start()\r\n        time.sleep(DELAY)\r\n    for process in processes:\r\n        process.join()\r\n\r\nif __name__ == '__main__':\r\n    start_process()\r\n```\r\n\r\n**Other info / logs**\r\n\r\nFull log with regular info of `Skipping rendezvous re-initialization`, processes exit successfully:\r\n```console\r\ntf-1.13) [huwh1@huwh1-centos worksync]$ python ./tf_distribute_re-initialization.py\r\n2019-10-17 17:33:57.919229: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-10-17 17:33:57.931531: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-10-17 17:33:57.935766: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3408000000 Hz\r\n2019-10-17 17:33:57.936208: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x378c150 executing computations on platform Host. Devices:\r\n2019-10-17 17:33:57.936241: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\r\n2019-10-17 17:33:57.938117: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:252] Initialize GrpcChannelCache for job worker -> {0 -> localhost:60000, 1 -> localhost:60001}\r\n2019-10-17 17:33:57.939150: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:391] Started server with target: grpc://localhost:60000\r\n2019-10-17 17:33:57.949331: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3408000000 Hz\r\n2019-10-17 17:33:57.949702: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x378c2a0 executing computations on platform Host. Devices:\r\n2019-10-17 17:33:57.949723: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\r\n2019-10-17 17:33:57.951578: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:252] Initialize GrpcChannelCache for job worker -> {0 -> localhost:60000, 1 -> localhost:60001}\r\n2019-10-17 17:33:57.952724: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:391] Started server with target: grpc://localhost:60001\r\nWARNING:tensorflow:From /home/huwh1/virtualenv/tf-1.13/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nColocations handled automatically by placer.\r\nWARNING:tensorflow:From /home/huwh1/virtualenv/tf-1.13/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nColocations handled automatically by placer.\r\nINFO:tensorflow:Graph was finalized.\r\n2019-10-17 17:33:58.053372: I tensorflow/core/distributed_runtime/master_session.cc:1192] Start master session 96a54c0a4de96215 with config: experimental { collective_group_leader: \"/job:worker/replica:0/task:0\" }\r\nINFO:tensorflow:Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\nINFO:tensorflow:Graph was finalized.\r\n2019-10-17 17:33:58.072731: I tensorflow/core/distributed_runtime/master_session.cc:1192] Start master session 543a2da8fd7ecd53 with config: experimental { collective_group_leader: \"/job:worker/replica:0/task:0\" }\r\nINFO:tensorflow:Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\ntask 1: sync_op 0.5.\r\ntask 0: sync_op 0.5.\r\ntask 0: global_step 0\r\ntask 1: global_step 0\r\n2019-10-17 17:33:58.119365: I tensorflow/core/distributed_runtime/base_rendezvous_mgr.cc:159] Skipping rendezvous re-initialization.\r\ntask 1: sync_op and global_step [0.5, 0]\r\ntask 0: sync_op and global_step [0.5, 0]\r\ntask 1: finalized.\r\ntask 0: finalized.\r\n```\r\nFull log with occasionally warning `BaseCollectiveExecutor::StartAbort Aborted`, processes hang:\r\n```console\r\n(tf-1.13) [huwh1@huwh1-centos worksync]$ python ./tf_distribute_re-initialization.py\r\n2019-10-17 17:35:07.780731: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-10-17 17:35:07.793013: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-10-17 17:35:07.795259: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3408000000 Hz\r\n2019-10-17 17:35:07.795603: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x30ea150 executing computations on platform Host. Devices:\r\n2019-10-17 17:35:07.795627: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\r\n2019-10-17 17:35:07.797198: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:252] Initialize GrpcChannelCache for job worker -> {0 -> localhost:60000, 1 -> localhost:60001}\r\n2019-10-17 17:35:07.798176: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:391] Started server with target: grpc://localhost:60000\r\n2019-10-17 17:35:07.810391: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3408000000 Hz\r\n2019-10-17 17:35:07.810780: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x30ea2a0 executing computations on platform Host. Devices:\r\n2019-10-17 17:35:07.810805: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\r\n2019-10-17 17:35:07.812369: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:252] Initialize GrpcChannelCache for job worker -> {0 -> localhost:60000, 1 -> localhost:60001}\r\n2019-10-17 17:35:07.813640: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:391] Started server with target: grpc://localhost:60001\r\nWARNING:tensorflow:From /home/huwh1/virtualenv/tf-1.13/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nColocations handled automatically by placer.\r\nWARNING:tensorflow:From /home/huwh1/virtualenv/tf-1.13/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nColocations handled automatically by placer.\r\nINFO:tensorflow:Graph was finalized.\r\n2019-10-17 17:35:07.902323: I tensorflow/core/distributed_runtime/master_session.cc:1192] Start master session b8c8018638e2809a with config: experimental { collective_group_leader: \"/job:worker/replica:0/task:0\" }\r\nINFO:tensorflow:Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\nINFO:tensorflow:Graph was finalized.\r\n2019-10-17 17:35:07.921347: I tensorflow/core/distributed_runtime/master_session.cc:1192] Start master session 41eee7eda589977d with config: experimental { collective_group_leader: \"/job:worker/replica:0/task:0\" }\r\nINFO:tensorflow:Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\ntask 1: sync_op 0.5.\r\ntask 0: sync_op 0.5.\r\ntask 0: global_step 0\r\ntask 1: global_step 0\r\n2019-10-17 17:35:07.980957: I tensorflow/core/distributed_runtime/base_rendezvous_mgr.cc:159] Skipping rendezvous re-initialization.\r\n2019-10-17 17:35:07.982111: W tensorflow/core/common_runtime/base_collective_executor.cc:203] BaseCollectiveExecutor::StartAbort Aborted: Cleanup 34190423657599268\r\n         [[{{node _send_worker0/CollectiveReduce_0}}]]\r\ntask 1: sync_op and global_step [0.5, 0]\r\nINFO:tensorflow:An error was raised. This may be due to a preemption in a connected worker or parameter server. The current session will be closed and a new session will be created. This error may also occur due to a gRPC failure caused by high memory or network bandwidth usage in the parameter servers. If this error occurs repeatedly, try increasing the number of parameter servers assigned to the job. Error: Cleanup 34190423657599268\r\n         [[{{node _send_worker0/CollectiveReduce_0}}]]\r\nINFO:tensorflow:Graph was finalized.\r\n2019-10-17 17:35:07.986279: I tensorflow/core/distributed_runtime/master_session.cc:1192] Start master session 82ea6dbd6778bbf4 with config: experimental { collective_group_leader: \"/job:worker/replica:0/task:0\" }\r\nINFO:tensorflow:Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\n```\r\nA related issue can be found #33321.", "comments": ["I hope this issue is clear enough to be supported. :slightly_smiling_face: @ravikyram ", "I believe the \"skipping rendezvous re-initialization\" message was benign and has been fixed in bcb615c42a6215037ed7f1c81316bc0960e76269.  Can you try to rerun your program with a nightly build to confirm?", "cc @haoyuz @qqfish ", "It works perfectly. Thanks very much! :+1:\r\nMaybe we should migrate to the compat.v1 module in tf-2.0.", "@whhu \r\nPlease, let me know if we can close this issue since it looks to be fixed. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33469\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33469\">No</a>\n"]}, {"number": 33468, "title": "Current thread 0x00004514 (most recent call first):", "body": "(tensorflow1) C:\\Users\\\u042e\u0440\u0438\u0439\\Desktop\\models-master\\research\\object_detection>python generate_tfrecord.py --csv_input=images\\train_labels.csv --image_dir=images\\train --output_path=train.record\r\n2019-10-17 20:28:23.110602: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll\r\nC:\\Python 3.7\\anaconda\\envs\\tensorflow1\\lib\\site-packages\\h5py\\__init__.py:75: UserWarning: h5py is running against HDF5 1.10.5 when it was built against 1.10.4, this may cause problems\r\n  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\r\nWARNING:tensorflow:From generate_tfrecord.py:116: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\r\n\r\nWARNING:tensorflow:From generate_tfrecord.py:102: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\r\n\r\nW1017 20:28:25.492974 17684 module_wrapper.py:137] From generate_tfrecord.py:102: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\r\n\r\nWARNING:tensorflow:From generate_tfrecord.py:61: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\r\n\r\nW1017 20:28:25.515945 17684 module_wrapper.py:137] From generate_tfrecord.py:61: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\r\n\r\nWindows fatal exception: access violation\r\n\r\nCurrent thread 0x00004514 (most recent call first):\r\n  File \"C:\\Python 3.7\\anaconda\\envs\\tensorflow1\\lib\\site-packages\\tensorflow_core\\python\\lib\\io\\file_io.py\", line 84 in _preread_check\r\n  File \"C:\\Python 3.7\\anaconda\\envs\\tensorflow1\\lib\\site-packages\\tensorflow_core\\python\\lib\\io\\file_io.py\", line 122 in read\r\n  File \"generate_tfrecord.py\", line 62 in create_tf_example\r\n  File \"generate_tfrecord.py\", line 107 in main\r\n  File \"C:\\Python 3.7\\anaconda\\envs\\tensorflow1\\lib\\site-packages\\absl\\app.py\", line 250 in _run_main\r\n  File \"C:\\Python 3.7\\anaconda\\envs\\tensorflow1\\lib\\site-packages\\absl\\app.py\", line 299 in run\r\n  File \"C:\\Python 3.7\\anaconda\\envs\\tensorflow1\\lib\\site-packages\\tensorflow_core\\python\\platform\\app.py\", line 40 in run\r\n  File \"generate_tfrecord.py\", line 116 in <module>\r\n\r\n\r\n**********************************\r\nTensorflow gives such an error, how can I fix it ???", "comments": ["Please provide the information asked in the template\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\n\r\n\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "> Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n\r\nmany people have the same problem\uff0cwhy not go fix it.", "@cnzjhdx, Please provide the information asked in Template or open new issue with all the details asked in Template to analyze the issue. Thanks!", "how to deal with the probelm\uff1fthx"]}, {"number": 33467, "title": "tf.range is not equivalent to np.arange", "body": "`tensorflow-gpu==1.12.3`\r\n\r\n[The docs](https://www.tensorflow.org/versions/r1.12/api_docs/python/tf/range#numpy_compatibility) state about `tf.range`:\r\n\r\n> Equivalent to np.arange\r\n\r\nBut:\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\ntf.enable_eager_execution()\r\n\r\ndef main():\r\n\r\n    s = tf.constant(np.random.rand(20))\r\n    rate = 2.5\r\n    s1 = np.arange(0, tf.shape(s)[0], rate)\r\n    s2 = tf.range(0, tf.shape(s)[0], rate).numpy()\r\n\r\n    print(s1)\r\n    print(s2)\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n```\r\n\r\nOutputs:\r\n\r\n```\r\n[ 0.   2.5  5.   7.5 10.  12.5 15.  17.5 20.  22.5]\r\n[ 0.   2.5  5.   7.5 10.  12.5 15.  17.5]\r\n```", "comments": ["@stefan-falk I tried with TF 2.0.0 and the values seem to match. Can you update the TF (1.12.3 is a little outdated) to latest 2.0.0?", "@stefan-falk ,\r\nHi, you can also try 1.15rc3 version. It works fine.Please find the [gist](https://colab.sandbox.google.com/gist/oanush/66deef65fdd8a30da4f811bee810220c/33467.ipynb) of colab.Thanks!", "@stefan-falk ,\r\nHi, any update on the issue ?Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "@oanush Sorry for responding so late. Unfortunately, I am stuck with 1.12.3 - I am sure it works with later versions but the example above was run with 1.12.3 - Looking forward for 1.12.4 \ud83d\ude03 "]}, {"number": 33466, "title": "Combine adjacent concatenate operations", "body": "In the algebraic simplifier: look for adjacent concatenate operations\r\nand fuse them if they are compatible.", "comments": ["@akuegel Will this undo the compile time optimization we have for concatenates?", "> @akuegel Will this undo the compile time optimization we have for concatenates?\r\n\r\nYes, you're right: I hadn't tested the CPU backend: it does create an infinite loop there.\r\nLet's drop that PR then."]}, {"number": 33465, "title": "Padded_batch with pre- or post-padding option", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 1.12.2\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nI have a dataset of variable-length sequences to feed an LSTM network and I want to try and compare pre- and post-padding in the batches, but current padded_batch function only pads at the sequences end.\r\n\r\n**Who will benefit with this feature?**\r\nI heard that pre-padding may be better for LSTM than post-padding, because post-padding may 'wash' the cell states before final decision making. Is it true?\r\n\r\n**Any Other info.**\r\n", "comments": ["@shahriar49 This already exists in the later versions of tensorflow \r\n\r\n`tf.keras.preprocessing.sequence.pad_sequences(\r\n    sequences,\r\n    maxlen=None,\r\n    dtype='int32',\r\n    padding='pre',\r\n    truncating='pre',\r\n    value=0.0\r\n)`\r\n\r\nYou can use `padding = 'pre' or 'post'` based on your use case.\r\n", "@gowthamkpr \r\nI knew it but I don't know how to apply this function to dataset batch processor. The padded_batch function in tensorflow does both padding and batching, and it will find the required paddding size per batch dynamically. How can I implement this myself? My code right now is like this, and I am reading multiple TFRecord files and interleave them to make my mixed dataset:\r\n\r\n```\r\nfeaturesDict = {'data': tf.FixedLenFeature([], dtype=tf.string),\r\n                'rows': tf.FixedLenFeature([], dtype=tf.int64),\r\n                'label': tf.FixedLenFeature([], dtype=tf.int64)\r\n               }\r\n\r\ndef parse_tfrecord(example):\r\n    features = tf.parse_single_example(example, featuresDict)\r\n    label = tf.one_hot(features['label'],N)\r\n    rows = features['rows']\r\n    data = tf.decode_raw(features['data'], tf.int64)\r\n    data = tf.reshape(data, (rows,num_features)\r\n    return data, label\r\n\r\ndef read_datasets(pattern, numFiles, numEpochs=None, batchSize=None):\r\n    files = tf.data.Dataset.list_files(pattern)\r\n\r\n    def _parse(x):\r\n        x = tf.data.TFRecordDataset(x, compression_type='GZIP')\r\n        return x\r\n\r\n    dataset = files.interleave(_parse, cycle_length=numFiles, block_length=1).map(parse_tfrecord)\r\n    padded_shapes = (tf.TensorShape([None, num_features]), tf.TensorShape([N,])))\r\n    dataset = dataset.padded_batch(batchSize, padded_shapes)\r\n    dataset = dataset.prefetch(buffer_size=batchSize)\r\n    dataset = dataset.repeat(numEpochs)\r\n    return dataset\r\n\r\n```", "@gowthamkpr\r\nCould you please help me with this issue?", "@shahriar49 Please post this question in [stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow) as this platform is only for bug/performance, docs or build/installation issues. Thanks!", "@gowthamkpr \r\nI tried it but nobody give me an answer on stackoverflow. Can you help me with it?", "@gowthamkpr\r\nI tried it but nobody give me an answer on stackoverflow. Can you help me with it?", "Hi @shahriar49 ,\r\n\r\nI have answered your question on [stackoverflow ](https://stackoverflow.com/questions/58525480/padded-batch-with-pre-or-post-padding-option/59212858#59212858), please check it."]}, {"number": 33462, "title": "A question on ctc implementation", "body": "I have a question on ctc implementation here:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/util/ctc/ctc_loss_calculator.h#L500\r\nwhy the gradient is set to y instead of zero when no valid path is found? ", "comments": ["This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. We might answer these support type questions on stackoverflow. GitHub is mainly for addressing bugs in installation and performance. Thanks!\r\n\r\n"]}, {"number": 33461, "title": "Minor readability improvement", "body": "", "comments": ["The `Ubuntu CC` and `import/copybara` checks are taking forever to complete. Is there a way to fix this ?"]}, {"number": 33460, "title": "update docstring of TopKCategoricalAccuracy", "body": "It's a simple edit that replaces capital `K` with `k`, which is more consistent with the parameter names of the metrics classes.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F33460) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot rescan", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F33460) for more info**.\n\n<!-- ok -->", "We will not be encouraging one liner grammatical changes as this is expensive process, thank you for your interest.\r\nCC @mihaimaruseac ", "@rthadur Thank you for your consideration and your time. Although I understand your point, I still do believe that small incremental changes in the documentation might improve developer experience.", "Every PR takes around 16 CPU/GPU hours of CI. As such, we cannot just run every PR through the CI infrastructure.\r\n\r\nIf you want to make documentation changes, please pick an entire file and clean it up from end to end, not just a letter here and there.", "Thank you, @mihaimaruseac, for the explanation. I was put off by the tone of the initial copy-and-paste comment, but of course computational cost should be keept in mind. I would recommend updating the \"Contributing guideline\" to make the point clear for future contributors."]}, {"number": 33459, "title": "resnet50 imagenet weights are differents in tf.keras vs keras", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): win10, pycharm (same issue from colab)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pycharm\r\n- TensorFlow version (use command below): 2.0 and keras 2.3.0 (same issue with tf 1.15 and keras 2.2.5 in google colab)\r\n- Python version: 3.7\r\n\r\n\r\n**Describe the current behavior**\r\nThe weights of the kernel in layers 13 & 14 are different in tf.keras and keras: the weights of the layer 13 in tf.keras are the ones of the layers 14 in keras and the weights of the layer 14 in tf.keras are the ones of the layer 13 in keras:\r\nwith tf.keras:\r\nlayer 13: conv2_block1_0_conv\r\n[[[[ 0.00460704  0.0613995   0.04595907 ... -0.12616335 -0.00781816\r\n     0.03271283]\r\n   ...\r\n   [-0.00736084  0.00832207 -0.00591875 ... -0.16227128  0.00581011\r\n     0.01718325]]]]\r\nlayer 14: conv2_block1_3_conv\r\n[[[[ 0.00412396 -0.01779881 -0.01002417 ... -0.0397268  -0.01897338\r\n    -0.00012411]\r\n   ...\r\n   [ 0.01601992  0.00197976 -0.01605847 ...  0.06464136  0.0353195\r\n     0.02405972]]]]\r\n\r\n\r\nwith keras:\r\nlayer 13: res2a_branch2c\r\n[[[[ 0.00412396 -0.01779881 -0.01002417 ... -0.0397268  -0.01897338\r\n    -0.00012411]\r\n   ...\r\n   [ 0.01601992  0.00197976 -0.01605847 ...  0.06464136  0.0353195\r\n     0.02405972]]]]\r\nlayer 14: res2a_branch1\r\n[[[[ 0.00460704  0.0613995   0.04595907 ... -0.12616335 -0.00781816\r\n     0.03271283]\r\n   ...\r\n   [-0.00736084  0.00832207 -0.00591875 ... -0.16227128  0.00581011\r\n     0.01718325]]]]\r\n\r\nthis is with include_top=True but include_top=False gives the same thing\r\n\r\n**Describe the expected behavior**\r\nI would expect the same weights, not sure which weights are the right ones\r\n\r\n**Code to reproduce the issue**\r\nfrom tensorflow.python.keras.applications import ResNet50\r\n#from keras.applications import ResNet50\r\nimage_size = 224\r\nmodel = ResNet50(input_shape=(image_size, image_size, 3), include_top=True, weights='imagenet')\r\nprint(model.layers[13].name)\r\nweights = model.layers[13].get_weights()[0]\r\nprint(weights)\r\nprint(model.layers[14].name)\r\nweights = model.layers[14].get_weights()[0]\r\nprint(weights)\r\n\r\n**Other info / logs**\r\nThe difference is coming from the different path used to load the h5 file:\r\nin tf.keras:\r\n'https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5'\r\nin keras: \r\n'https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels.h5'\r\n", "comments": ["I could reproduce the issue with Tf 2.0.0 keras 2.3.0 and TF 1.15.0 keras 2.2.5. Please take a look at the gist of tf.keras [here](https://colab.sandbox.google.com/gist/gadagashwini/903f26e451e5b6d40ac5f99991716a25/untitled206.ipynb) and keras with tensorflow backend [here](https://colab.sandbox.google.com/gist/gadagashwini/99de5876f3f6ff5937bb29c6ab1185e7/untitled207.ipynb). Thanks!", "@gadagashwini This does not answer anything. The issue still remains. Or is it that they are downloading two versions of resnet (v1 and v2) ?", "Adding Francois for this. When did we update the weights last time?", "Any updates on this please?", "It seems that several blocks are affected. For example, in the `conv5_` block the weights of the following layers are switched:\r\n- `conv5_block1_3_bn` and `conv5_block1_0_bn`\r\n- `conv5_block1_3_conv` and `conv5_block1_0_conv`.\r\n\r\nThis affects quite significantly the accuracy of transfer learning (on at least semantic segmentation in my case).", "I guess #35336 is a similar issue.\r\n\r\nIn my testing code which loading weights from tf.keras, the accuracy for pre-trained weights are under 70%.", "@CNOCycle Nice. I guess we now have enough evidence that the pre-trained weights are broken.", "I think tf.keras.application is exporting the latest implementation of resnet50, while keras.application is exporting the old version of implementation. They are structured differently (eg the layer may appear in different order), but functionality wise, they are the same.\r\n\r\nI think the root cause is for keras.application not exporting the latest version is in https://github.com/keras-team/keras-applications/blob/master/keras_applications/__init__.py. Basically both resnet50.py and resnet.py will export Resnet50, and the former one is exported by contains the legacy implementation.", "Checked with @fchollet offline for this issue. I think the keras-team/keras-application was exporting the old model. The PR should fix the issue, but since the keras-application is not going to make any new release, I would suggest you to use the version in tf.keras.application, which should be latest and correct.\r\n\r\nBtw, the keras-team/keras-application is still correct, it is just structured differently compare to the latest implementation. You can still use it for transfer learning.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33459\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33459\">No</a>\n", "Not sure I fully understood the root cause, but I'm happy there's some progress on this.\r\n\r\nThe difference between tf.keras and keras does not seem to be an issue as they used two different implementations. But is it sure that the weights of tf.keras' ResNet50 are good? As @CNOCycle pointed out in #35336, the best accuracy he/she could get on ImageNet validation set is 45.7% for ResNet50, which is far from the [reported](https://keras.io/applications/) 74.9%.\r\n\r\n@CNOCycle Would it be possible for you to try applying the above PR and performing your experiment again?", "I do the test again in docker image: `tensorflow/tensorflow:2.1.0-gpu-py3`\r\n\r\nand comment out the line as @qlzh727 suggestion\r\n\r\n`/usr/local/lib/python3.6/dist-packages/keras_applications/__init__.py\" 65L`\r\n```diff\r\n-from . import resnet50\r\n+#from . import resnet50\r\n```\r\n\r\nThe following is the output of testing code which is shown in #35336\r\n```\r\nDownloading data from https://github.com/keras-team/keras-applications/releases/download/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\r\n102973440/102967424 [==============================] - 204s 2us/step\r\n2020-03-02 12:37:29.774845: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n2020-03-02 12:37:30.223375: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n500/500 [==============================] - 143s 287ms/step - loss: 2.6850 - accuracy: 0.4601\r\n[Testing][pixel vales are from (0,255)][model:ResNet50] - loss: 2.685 - accuracy: 0.460\r\nDownloading data from https://github.com/keras-team/keras-applications/releases/download/densenet/densenet121_weights_tf_dim_ordering_tf_kernels.h5\r\n33193984/33188688 [==============================] - 107s 3us/step\r\n500/500 [==============================] - 80s 159ms/step - loss: 39.1680 - accuracy: 0.0056\r\n[Testing][pixel vales are from (0,255)][model:DenseNet121] - loss: 39.168 - accuracy: 0.006\r\nDownloading data from https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/download/v1.1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\r\n14540800/14536120 [==============================] - 39s 3us/step\r\n500/500 [==============================] - 41s 81ms/step - loss: 9.9651 - accuracy: 0.0026\r\n[Testing][pixel vales are from (0,255)][model:MobileNetV2] - loss: 9.965 - accuracy: 0.003\r\n500/500 [==============================] - 76s 151ms/step - loss: 8.5355 - accuracy: 0.0010\r\n[Testing][pixel vales are from (0,1)][model:ResNet50] - loss: 8.535 - accuracy: 0.001\r\n500/500 [==============================] - 71s 142ms/step - loss: 1.7376 - accuracy: 0.6029\r\n[Testing][pixel vales are from (0,1)][model:DenseNet121] - loss: 1.738 - accuracy: 0.603\r\n500/500 [==============================] - 45s 91ms/step - loss: 2.2516 - accuracy: 0.5285\r\n[Testing][pixel vales are from (0,1)][model:MobileNetV2] - loss: 2.252 - accuracy: 0.528\r\n500/500 [==============================] - 76s 152ms/step - loss: 8.4942 - accuracy: 0.0010\r\n[Testing][pixel vales are normalized from (-1,1)][model:ResNet50] - loss: 8.494 - accuracy: 0.001\r\n500/500 [==============================] - 71s 142ms/step - loss: 1.9044 - accuracy: 0.5703\r\n[Testing][pixel vales are normalized from (-1,1)][model:DenseNet121] - loss: 1.904 - accuracy: 0.570\r\n500/500 [==============================] - 46s 93ms/step - loss: 2.4290 - accuracy: 0.4992\r\n[Testing][pixel vales are normalized from (-1,1)][model:MobileNetV2] - loss: 2.429 - accuracy: 0.499\r\n```\r\n\r\nHowever, I still get similar results. I hope that someone would check correctness of my code.", "@CNOCycle, note that the downloading url is from https://github.com/keras-team/keras-applications/releases, which should be same as the one in tf.keras.application. This somehow indicating that your transfer learning model might not be constructed correctly.\r\n\r\nThe easiest way to verify whether the original resnet model is correct is to run some eval with the eval data, which I am quite sure we did before we release the model.", "> @CNOCycle, note that the downloading url is from https://github.com/keras-team/keras-applications/releases, which should be same as the one in tf.keras.application. This somehow indicating that your transfer learning model might not be constructed correctly.\r\n\r\nRight. I have just tried again with `tf-nightly`, and indeed, the URLs have changed:\r\n\r\n> Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\r\n\r\nOne can check this in my [Colab notebook](https://colab.research.google.com/drive/13zpJSsJ0GmXluiVNAF4DLSqW3Ao84G5Z).\r\n\r\n@CNOCycle Could you please try again with `tf-nightly`? Thanks a lot.", "I checked the weight from `storage.googleapis.com` and `keras-applications/releases`. Both files' hash are same.\r\n\r\n```\r\n2cb95161c43110f7111970584f804107  /root/.keras/models/resnet50_weights_tf_dim_ordering_tf_kernels.h5\r\n```\r\n\r\nWhat I do is not transfer learning. I'm trying to reproduce to accuracy which publish in many papers. \r\n\r\nFrom my experience, my implement of training ImageNet from scratch by TF and pytorch. For pytorch version, its top-1 accuracy is about 74%. For TF version, its top-1 accuracy is about 68%.  For TF version with pre-trained weights, its top-1 accuracy is under 50%", "Hmm, that's bad news... \r\n\r\n> The easiest way to verify whether the original resnet model is correct is to run some eval with the eval data, which I am quite sure we did before we release the model.\r\n\r\nThis is exactly what @CNOCycle did. @qlzh727 Would you mind sharing your eval code so that we can check the weights again on our side?\r\n", "Hmm... I think this issue is rather critical... Imagine getting 2-3% lower accuracy than PyTorch just because of bad conversion of pretrained models? That'd be a pity...", "Hello everyone,\r\nI have just tried to use pre-trained ResNet50 with tf.keras.applications.ResNet50(**args). The thing is happening for me is that after downloading weights, nothing else happens!! even after a couple of hours it does not go any further!! Any idea? what may be the casue of this? Any solution?\r\n\r\nMany thanks for your help in advance.\r\n\r\nI use as follow:\r\n\r\nENCODER_BASE =  tf.keras.applications.ResNet50(include_top=False,input_shape=(None,None,3), weights='imagenet')", "@nick-nikzad At least show us your code to see what you would expect to see after loading the model.", "@netw0rkf10w  Thanks for the reply. I just expect using the output of some blocks as below: \r\n    \r\n    ENCODER_BASE=tf.keras.applications.ResNet50(include_top=False,input_shape=(None,None,3), weights='imagenet')\r\n    for layer in ENCODER_BASE.layers:\r\n        layer.traiable = True\r\n        \r\n    f0 = ENCODER_BASE.get_layer(\"conv1_relu\").output  #43358  \r\n\r\n    f1 = ENCODER_BASE.get_layer(\"conv2_block2_out\").output  \r\n    f2 = ENCODER_BASE.get_layer(\"conv3_block4_out\").output \r\n    f3 = ENCODER_BASE.get_layer(\"conv4_block6_out\").output  \r\n    f4 = ENCODER_BASE.get_layer(\"conv5_block3_out\").output ", "@nick-nikzad Can you reproduce that using Colab?", "https://stackoverflow.com/questions/67365237/imagenet-pretrained-resnet50-backbones-are-different-between-pytorch-and-tensorf\r\n\r\nAnd given my ongoing experiments, transfer learning doesn't work as well in TensorFlow :o "]}, {"number": 33458, "title": "Change default epsilons and add warning in the doc. Epsilon as large \u2026", "body": "\u2026as 1e-3 leads to silent failures.\r\n\r\nRedo of #33432\r\n\r\nI think I was branched off rc2 before.", "comments": ["I don't think that we can change the default, since it would be a breaking change and also result in different behavior compared to keras-team/keras, tf.layers, and TF 1.x. However I am fine with updating the docstring to point out the effect of an epsilon which is too high.", "Updating the docs to warn all future humans of the dangers sounds reasonable.", "We have decided to decline this PR on the basis that it is not relevant to enough people to justify adding it to the docstring."]}, {"number": 33457, "title": "Change default epsilons and add warning in the doc. Epsilon as large \u2026", "body": "\u2026as 1e-3 leads to silent failures.\r\n\r\nRedo of https://github.com/tensorflow/tensorflow/pull/33432\r\n\r\nI think I was branched off rc2 before.", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F33457) for more info**.\n\n<!-- need_author_cla -->", "@googlebot I fixed it."]}, {"number": 33456, "title": "happen error\uff1aERROR: Config value opt is not defined in any .rc file", "body": "# Environment\r\nUbuntu 16.05\r\ntensorflow r1.14\r\nbazel 0.24.1\r\n\r\n# Problem\r\nI transform the model using the following command, [documentation](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tensorflowlite.md)\r\n```\r\nbazel run --config=opt tensorflow/lite/toco:toco -- \\\r\n--input_file=$OUTPUT_DIR/tflite_graph.pb \\\r\n--output_file=$OUTPUT_DIR/detect.tflite \\\r\n--input_shapes=1,300,300,3 \\\r\n--input_arrays=normalized_input_image_tensor \\\r\n--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'  \\\r\n--inference_type=FLOAT \\\r\n--allow_custom_ops\r\n```\r\n\r\nerror logs:\r\n```\r\ntest@test:~/tensorflow$ bazel run --config=opt tensorflow/lite/toco:toco -- \\\r\n> --input_file=/home/test/lite/model/tflite_graph.pb \\\r\n> --output_file=/home/test/lite/model/ssd_mobilenet_v2.tflite \\\r\n> --input_shapes=1,300,300,3 \\\r\n> --input_arrays=normalized_input_image_tensor \\\r\n> --output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'  \\\r\n> --inference_type=FLOAT \\\r\n> --allow_custom_ops\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=258\r\nINFO: Reading rc options for 'run' from /home/test/tensorflow/.bazelrc:\r\n  Inherited 'build' options: --apple_platform_type=macos --define framework_shared_object=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --strategy=Genrule=standalone -c opt --define=grpc_no_ares=true --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include\r\nERROR: Config value opt is not defined in any .rc file\r\n```\r\n\r\nHow do I transform the model to tensorflow lite.\r\n\r\n", "comments": ["@yeyupiaoling Please take a look at the similar [issues](https://github.com/tensorflow/tensorflow/issues/23613) and let me know if it helps.!", "Ok, thank you"]}, {"number": 33455, "title": "Can't create Tensor from java buffer", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution: Linux Ubuntu 18.04\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: 1.13.1 (maybe 1.14 and 2.0)\r\n\r\n**Describe the current behavior**\r\nwhen you create a `java.nio.buffer` and fill it with data you can't use it to create `Tensor` with shape\r\n\r\n**Describe the expected behavior**\r\nWe should be able to create a Tensor with buffer\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```scala\r\nimport java.nio.FloatBuffer\r\nimport org.tensorflow.Tensor\r\nval buf: FloatBuffer = FloatBuffer.allocate(4)\r\nbuf.put(1f)\r\nbuf.put(2f)\r\nbuf.put(3f)\r\nbuf.put(4f)\r\nval t = Tensor.create(Array(1L,4L), buf)\r\n```\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n```\r\njava.lang.IllegalArgumentException: buffer with 0 elements is not compatible with a Tensor with shape [1, 4]\r\n  at org.tensorflow.Tensor.incompatibleBuffer(Tensor.java:583)\r\n  at org.tensorflow.Tensor.allocateForBuffer(Tensor.java:308)\r\n  at org.tensorflow.Tensor.create(Tensor.java:186)\r\n```\r\n\r\nsource of Tensor\r\n```java\r\npublic static Tensor<Float> create(long[] shape, FloatBuffer data) {\r\n    Tensor<Float> t = allocateForBuffer(DataType.FLOAT, shape, data.remaining());\r\n    t.buffer().asFloatBuffer().put(data);\r\n    return t;\r\n  }\r\n\r\nprivate static <T> Tensor<T> allocateForBuffer(DataType dataType, long[] shape, int nBuffered) {\r\n    final int nflattened = numElements(shape);\r\n    int nbytes = 0;\r\n    if (dataType != DataType.STRING) {\r\n      if (nBuffered != nflattened) {\r\n        throw incompatibleBuffer(nBuffered, shape);\r\n      }\r\n      nbytes = nflattened * elemByteSize(dataType);\r\n    } else {\r\n      // DT_STRING tensor encoded in a ByteBuffer.\r\n      nbytes = nBuffered;\r\n    }\r\n    Tensor<T> t = new Tensor<T>(dataType);\r\n    t.shapeCopy = Arrays.copyOf(shape, shape.length);\r\n    t.nativeHandle = allocate(t.dtype.c(), t.shapeCopy, nbytes);\r\n    return t;\r\n  }\r\n```\r\n", "comments": []}, {"number": 33454, "title": "[1.15]Discrepancy between documentation & behaviour in tf.keras.Model.Save", "body": "## URL(s) with the issue:\r\n\r\nIn the 1.15 changelog:\r\n\r\nhttps://github.com/tensorflow/tensorflow/releases/tag/v1.15.0\r\n> tf.keras.model.save_model and model.save now defaults to saving a TensorFlow SavedModel.\r\n\r\n\r\nIn the 1.15 docstring:\r\nhttps://www.tensorflow.org/versions/r1.15/api_docs/python/tf/keras/Model#save\r\n> filepath: String, path to SavedModel or H5 file to save the model. overwrite: Whether to silently \r\noverwrite any existing file at the target location, or provide the user with a manual prompt. include_optimizer: If True, save optimizer's state together. save_format: Either 'tf' or 'h5', indicating whether to save the model to Tensorflow SavedModel or HDF5. The default is currently 'h5', but will switch to 'tf' in TensorFlow 2.0. The 'tf' option is currently disabled (use tf.keras.experimental.export_saved_model instead).\r\n\r\n## Description of issue (what needs changing):\r\n\r\n- The changelogs states that tf.keras.Model are saved using tf format by default\r\n- The docstring states that the default save format in tf1.x is hdf5 and that tf is disabled\r\n- \"tf\" save format is NOT disabled but can be passed as parameters\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.15/tensorflow/python/keras/saving/save.py#L92\r\nWe can still save using tf format using tf.keras.Model.save(). HOWEVER you cannot load tf model\r\n\r\n## Usage example\r\n\r\nThis is not a critical issue but this can be confusing to users reading the changelog and reading the docstring, and seeing that tf behaviour is enabled by default.\r\n\r\nThis will lead users to:\r\n- Being confused between behaviours...\r\n- Thinking they need to update their codebases to switch to 1.15\r\n- Seeing that tf format doesn't work in tf1.15\r\n\r\nSaving works but not reloading, which confirms the fact that tf save format doesn't work\r\n\r\n```python\r\ni = tf.keras.layers.Input(shape=(10,))\r\nx = tf.keras.layers.Dense(2)(i)\r\no = tf.keras.layers.Activation(\"softmax\")(x)\r\nm = tf.keras.Model(inputs=i, outputs=o)\r\nm.save('test_model_tf', save_format=\"tf\")\r\nm2 = tf.keras.models.load_model(\"test_model_tf\")\r\nm2.summary()\r\n```\r\n\r\n```text\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-48-d0af62cb113d> in <module>\r\n----> 1 m2.summary()\r\n\r\n~/opt/miniconda3/envs/py36-tf1.15/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py in summary(self, line_length, positions, print_fn)\r\n   1459                               line_length=line_length,\r\n   1460                               positions=positions,\r\n-> 1461                               print_fn=print_fn)\r\n   1462 \r\n   1463   def _validate_graph_inputs_and_outputs(self):\r\n\r\n~/opt/miniconda3/envs/py36-tf1.15/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/layer_utils.py in print_summary(model, line_length, positions, print_fn)\r\n    224   for i in range(len(layers)):\r\n    225     if sequential_like:\r\n--> 226       print_layer_summary(layers[i])\r\n    227     else:\r\n    228       print_layer_summary_with_connections(layers[i])\r\n\r\n~/opt/miniconda3/envs/py36-tf1.15/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/layer_utils.py in print_layer_summary(layer)\r\n    182     name = layer.name\r\n    183     cls_name = layer.__class__.__name__\r\n--> 184     fields = [name + ' (' + cls_name + ')', output_shape, layer.count_params()]\r\n    185     print_row(fields, positions)\r\n    186 \r\n\r\n~/opt/miniconda3/envs/py36-tf1.15/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py in count_params(self)\r\n   1632                          ', but the layer isn\\'t built. '\r\n   1633                          'You can build it manually via: `' + self.name +\r\n-> 1634                          '.build(batch_input_shape)`.')\r\n   1635     return int(sum(np.prod(w.shape.as_list()) for w in self.weights))\r\n   1636 \r\n\r\nValueError: You tried to call `count_params` on input_1, but the layer isn't built. You can build it manually via: `input_1.build(batch_input_shape)`.\r\n\r\n```\r\nThis works,\r\n\r\n```python\r\ni = tf.keras.layers.Input(shape=(10,))\r\nx = tf.keras.layers.Dense(2)(i)\r\no = tf.keras.layers.Activation(\"softmax\")(x)\r\nm = tf.keras.Model(inputs=i, outputs=o)\r\nm.save('test_model_hdf5.hdf5`)\r\nm2 = tf.keras.models.load_model(\"test_model_hdf5.hdf5\")\r\nm2.summary()\r\n```\r\n```txt\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\ninput_4 (InputLayer)         [(None, 10)]              0         \r\n_________________________________________________________________\r\ndense_3 (Dense)              (None, 2)                 22        \r\n_________________________________________________________________\r\nactivation_3 (Activation)    (None, 2)                 0         \r\n=================================================================\r\nTotal params: 22\r\nTrainable params: 22\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\n```", "comments": ["@fchouteau \r\ncan you add `m2.summary()` for the model you saved in `.hdf5 format `and see if it is loading.I am seeing it is not loading in the both cases. Please, confirm.Thanks!", "I updated both code snippets,\r\n\r\n\r\nBuiliding with tf save format gives out\r\n\r\n`ValueError: You tried to call `count_params` on input_1, but the layer isn't built. You can build it manually via: `input_1.build(batch_input_shape)`.`\r\n(And calling model.build(input_shape) does not solve the issue)\r\n\r\nHowever the hdf5 saving format works as expected\r\n\r\n", "I have tried on colab with TF version 1.15.0-rc3 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/daca9a1f94832b974f102164b76d0b1b/untitled292.ipynb). Thanks!", "@fchouteau Thanks for finding this. The issue happens only when you provide `save_format` as input as in `m.save('test_model_tf', save_format=\"tf\")`. If you replace that line with `m.save('test_model_tf.tf')`, then there is no error. Please check the gist [here](https://colab.sandbox.google.com/gist/jvishnuvardhan/eb5684e8c405b47a41686e951fd99823/untitled584.ipynb).\r\n\r\nThe following is working fine.\r\n```\r\ni = tf.keras.layers.Input(shape=(10,))\r\nx = tf.keras.layers.Dense(2)(i)\r\no = tf.keras.layers.Activation(\"softmax\")(x)\r\nm = tf.keras.Model(inputs=i, outputs=o)\r\nm.save('test_model_tf.tf')\r\nm2 = tf.keras.models.load_model(\"test_model_tf.tf\")\r\nm2.summary()\r\n```\r\n", "Hello ! \r\n\r\nThis issue concerns the discrepancy between the changelog for tf 1.15 release and the actual behaviour,\r\n\r\nI fully understand that not providing save format defaults to hdf5 (legacy keras) and works. \r\n\r\nI also understand that, as stated in the [model_save docstring](https://github.com/tensorflow/tensorflow/blob/r1.15/tensorflow/python/keras/engine/network.py#L1151), the tf format does not work. \r\n\r\nUsing \".tf\" without save format defaults to [hdf5 independently of the file extension](https://github.com/tensorflow/tensorflow/blob/590d6eef7e91a6a7392c8ffffb7b58f2e0c8bc6b/tensorflow/python/keras/saving/save.py#L92) - which by the way doesn't allow subclassed models... is this disabled in tf 1.15 ?.\r\n\r\nMy point was: there is a discrepancy between the 1.15 changelog (stating that we should not use legacy hdf5 format) and the actual behaviour in 1.15 (where tf format is disabled and does not work if we enable it). There should also be warnings that enforces the disabling of the tf save format (which worked in previous versions such as 1.13 and 1.14 IIRC)\r\n\r\nBest regards,\r\n\r\n", "Thanks for reporting this, the loading bug (\"layers is not built\") should be fixed in the most recent version of TensorFlow. \r\n\r\nAnd yes the release notes were inaccurate... the default format didn't actually change to \"tf\" until TF 2. I'll try to make sure the saving release notes are more accurate in the future."]}, {"number": 33453, "title": "tf.print operations inside tf.function do not print in order", "body": "**System information**\r\nTensorflow-gpu 2.0.0 installed via `pip install tensorflow-gpu` in a Colaboratory notebook.\r\n\r\n**Describe the current and expected behavior**\r\nIn https://www.tensorflow.org/guide/function#side_effects one can read that `tf.print` operations inside `tf.function` will execute in order. This seem, indeed , to be the case. However, while operations are executed in order, the printed statements are not always shown in the expected order.\r\n\r\nThe code\r\n```\r\nv = tf.Variable(5)\r\n\r\n@tf.function\r\ndef find_next_odd():\r\n  tf.print('1:',v)\r\n  v.assign(v + 1)\r\n  tf.print('2:', v)\r\n  if v % 2 == 0:\r\n    v.assign(v + 1)\r\n    tf.print('3:', v)\r\n\r\nfind_next_odd()\r\n```\r\nprints\r\n```\r\n1: 5\r\n3: 7\r\n2: 6\r\n```\r\n\r\nNote, however, that if a (dummy) conditional statement is inserted before the second `tf.print`, the output is the expected one.\r\n\r\nThe code\r\n```\r\nv = tf.Variable(5)\r\n\r\n@tf.function\r\ndef find_next_odd():\r\n  tf.print('1:',v)\r\n  v.assign(v + 1)\r\n  if v==v: #dummy condition\r\n    tf.print('2:', v)\r\n  if v % 2 == 0:\r\n    v.assign(v + 1)\r\n    tf.print('3:', v)\r\n\r\nfind_next_odd()\r\n```\r\nprints\r\n```\r\n1: 5\r\n2: 6\r\n3: 7\r\n```\r\n", "comments": ["@humcasma ,\r\nCan you please try using latest` tf-nightly-gpu-2.1.0.dev20191017`, issue seemed to be fixed. Kindly find the [gist](https://colab.sandbox.google.com/gist/oanush/e3f25288b0b53912adc5ca36131f6c72/33453.ipynb) of colab.Thanks!\r\n\r\n", "@oanush Unfortunately I am not able to confirm whether it has been fixed or not. When using the nightly version of tensorflow I get an exception when running `v = tf.Variable(5)`:\r\n\r\n>  AttributeError: 'google.protobuf.pyext._message.RepeatedCompositeCo' object has no attribute 'append'", "@humcasma ,\r\nIt worked fine for me, try with `pip install tf-nightly-gpu`. Please share the gist of colab your trying to execute.", "@oanush You can access the gist [here](https://colab.research.google.com/gist/humcasma/cecc9b33645c774409a576d0c4b496b2/33453.ipynb)", "@humcasma ,\r\nHi, tried running the same gist no error was faced. \r\nFor the error being faced can you check the [link](https://stackoverflow.com/questions/58343293/attributeerror-google-protobuf-pyext-message-repeatedcompositeco-object-has)?", "It works now as expected. Thanks!"]}, {"number": 33452, "title": "gpu-jupyter Dockerfile not compatible with docker-compose?", "body": "I am taking the official TF image `tensorflow/tensorflow:1.15.0rc2-gpu-py3-jupyter` and trying to get it to work in a `docker-compose.yml` file.\r\n\r\nI have the following `docker-compose.yml` file:\r\n\r\n```\r\nversion: '3'\r\n\r\nservices:\r\n  tf:\r\n    image: tensorflow/tensorflow:1.15.0rc2-gpu-py3-jupyter\r\n\r\n    # mount host system volume to save updates from container\r\n    volumes:\r\n      - jupyter:/tf/notebooks\r\n    \r\n    ports:\r\n      - '8888:8888'\r\n   \r\n    # build:\r\n    #   context: .\r\n    #   dockerfile: Dockerfile\r\n\r\n\r\nvolumes:\r\n  jupyter:\r\n\r\n```\r\n\r\nwhere `jupyter` is the directory of notebooks. \r\n\r\nThe result of `docker-compose build & docker-compose up` is:\r\n\r\n```\r\nERROR: for 186e1443ba94_docker-tf-jn_tf_1  Cannot start service tf: OCI runtime create failed: container_linux.go:346: starting container process caused \"exec: \\\"jupyter notebook --notebook-dir=/tf/notebooks --ip 0.0.0.0 --no-browser --allow-root\\\": stat jupyter notebook --notebook-dir=/tf/notebooks --ip 0.0.0.0 --no-browser --allow-root: no such file or directory\": unknown\r\n\r\nERROR: for tf  Cannot start service tf: OCI runtime create failed: container_linux.go:346: starting container process caused \"exec: \\\"jupyter notebook --notebook-dir=/tf/notebooks --ip 0.0.0.0 --no-browser --allow-root\\\": stat jupyter notebook --notebook-dir=/tf/notebooks --ip 0.0.0.0 --no-browser --allow-root: no such file or directory\": unknown\r\n```\r\n\r\n", "comments": ["I can't replicate this. The following runs fine on my machine, running Docker 18.09.03 and docker-compose 1.21.0.\r\n\r\n```\r\nmkdir /tmp/dc\r\ncd /tmp/dc\r\ncat > docker-compose.yml <<EOF\r\nversion: '3'\r\n\r\nservices:\r\n  tf:\r\n    image: tensorflow/tensorflow:1.15.0rc2-gpu-py3-jupyter\r\n    volumes:\r\n      - jupyter:/tf/notebooks\r\n    ports:\r\n      - '8888:8888'\r\nvolumes:\r\n  jupyter:\r\nEOF\r\ndocker-compose up\r\n```\r\n\r\nIf you are still encountering the issue, please provide your Docker and docker-compose versions as well as your system version.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "@angerson no idea what it was, I am now using `FROM tensorflow/tensorflow:2.0.0-gpu-py3-jupyter` with no issues", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33452\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33452\">No</a>\n"]}, {"number": 33451, "title": "[Intel MKL] Add FP32 fusion of MatMul and Relu.", "body": "This the 2nd part of Enable FP32 FusedMatMul(MatMul with BiasAdd) for MKL-DNN backend(https://github.com/tensorflow/tensorflow/pull/31782). It will fuse Relu/Relu6/Elu with FusedMatMul and rewrite it to MklFusedMatMul.\r\n\r\n\r\nModified:\r\n- tensorflow/core/graph/mkl_layout_pass.cc\r\n- tensorflow/core/kernels/mkl_fused_ops_test.cc\r\n- tensorflow/core/kernels/mkl_matmul_op_fused.cc\r\n- tensorflow/core/kernels/mkl_matmul_ops_common.h\r\n\r\nSigned-off-by: Lu Teng teng.lu@intel.com", "comments": ["The previous PR(#31782) will fuse MatMul and BiasAdd into FusedMatMul, and rewrite it to MklFusedMatMul, but it will prevent 2 situations:\r\n- Attribute transpose_a is false.\r\n- FusedMatMul must has only one post op(default is BiasAdd, but it will be fused with BiasAdd and Relu if possible). \r\n\r\nThe 2nd rule will impact performance of some models like NCF because FusedMatMul wasn't rewritten to MklFusedMatMul and went into Eigen path. This PR will optimize it to MKL-DNN and remove the 2nd limitation by fusing it with Relu/Relu6/Elu.", "@penpornk please let us know if we can do anything for the PR to merge. We are thinking to have this PR merged before TF 2.1 cutoff.", "Hi @penpornk ,thanks for your suggestion, we've found an internal issue related to Elu in MKL back-end:\r\nWe used `SetRandom()` in UT to test the fusion ops, but it only generate positive value so that `Elu` become the same as `Relu`, then we weren't aware the typo error in UT. Besides, I found that we set wrong `alpha` for `Elu` and got wrong result after I corrected UT. `Alpha` in `Elu` should be `1` but not `0`: https://github.com/intel/mkl-dnn/blob/master/src/common/math_utils.hpp#L189\r\n\r\nNow  I have fixed it with this PR, please take a look at the new changes, thanks!", "I made a new change after an internal discussion - separate the Conv correction part from this PR and will fix it in another PR. It will make bug fix and feature implementation more clear. "]}, {"number": 33450, "title": "What is the Const node in batch_normalization?", "body": "use **tensorflow.layer.batch_normalization** then define the batch_normalization/Const node,\r\n<br>\r\n## what is this const node and how act this node in batch normal operation?", "comments": ["This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!"]}, {"number": 33449, "title": "WARNING:tensorflow:Entity <function layers at 0x7fdeb05e6d08> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: If not matching a CFG node, must be a block statement: <gast.gast.ImportFrom object at 0x7fde56634b38>", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): centos7\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below): 1.15.0\r\n- Python version: 3.7.4\r\n- Bazel version (if compiling from source): 1.0.0\r\n- GCC/Compiler version (if compiling from source):4.8.5 \r\n- CUDA/cuDNN version: 10.0/7.60\r\n- GPU model and memory: 2080ti/11GB\r\n\r\n**Describe the current behavior**\r\ntensor2tensor 1.14.1 \r\nt2t-trainer \r\n\r\nPROBLEM=translate_ende_wmt32k\r\nMODEL=transformer\r\nHPARAMS=transformer_base_single_gpu\r\nt2t-trainer \\\r\n  --data_dir=$DATA_DIR \\\r\n  --problem=$PROBLEM \\\r\n  --model=$MODEL \\\r\n  --hparams_set=$HPARAMS \\\r\n  --output_dir=$TRAIN_DIR\r\n\r\n**Other info / logs / WARNING logs**\r\n\r\nWARNING:tensorflow:Entity <function layers at 0x7fe5fa758d08> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: If not matching a CFG node, must be a block statement: <gast.gast.ImportFrom object at 0x7fe60c8ffc50>\r\nW1017 12:48:28.307721 140626233849664 ag_logging.py:146] Entity <function layers at 0x7fe5fa758d08> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: If not matching a CFG node, must be a block statement: <gast.gast.ImportFrom object at 0x7fe60c8ffc50>\r\nWARNING:tensorflow:From /opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensor2tensor/layers/common_layers.py:3077: The name tf.layers.Dense is deprecated. Please use tf.compat.v1.layers.Dense instead.\r\n\r\n\r\nWARNING:tensorflow:From /opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensor2tensor/utils/bleu_hook.py:151: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\ntf.py_func is deprecated in TF V2. Instead, there are two\r\n    options available in V2.\r\n    - tf.py_function takes a python function which manipulates tf eager\r\n    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\r\n    an ndarray (just call tensor.numpy()) but having access to eager tensors\r\n    means `tf.py_function`s can use accelerators such as GPUs as well as\r\n    being differentiable using a gradient tape.\r\n    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\r\n    (it is not differentiable, and manipulates numpy arrays). It drops the\r\n    stateful argument making all functions stateful.\r\n\r\nW1017 12:52:31.947059 140626233849664 deprecation.py:323] From /opt/anaconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensor2tensor/utils/bleu_hook.py:151: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\ntf.py_func is deprecated in TF V2. Instead, there are two\r\n    options available in V2.\r\n    - tf.py_function takes a python function which manipulates tf eager\r\n    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\r\n    an ndarray (just call tensor.numpy()) but having access to eager tensors\r\n    means `tf.py_function`s can use accelerators such as GPUs as well as\r\n    being differentiable using a gradient tape.\r\n    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\r\n    (it is not differentiable, and manipulates numpy arrays). It drops the\r\n    stateful argument making all functions stateful.\r\n\r\n\r\n\r\n\r\n\r\n", "comments": ["@cfwin \r\nCan you please elaborate about the issue & the context.Will it be possible to provide simple stand alone code to reproduce the issue in our environment, then it will be easy for localizing the issue faster.Thanks!", "I have got the more or less same issue while running the BERT model using TF hub. \r\n\r\n`WARNING: Entity <bound method BertLayer.call of <__main__.BertLayer object at 0x000001F3B880B0B8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BertLayer.call of <__main__.BertLayer object at 0x000001F3B880B0B8>>: AttributeError: module 'gast' has no attribute 'Num'`\r\n\r\nand then I got the error as follows \r\n\r\n```FailedPreconditionError                   Traceback (most recent call last)\r\n in \r\n      9     validation_data=([test_input_ids, test_input_masks, test_segment_ids], test_labels),\r\n     10     epochs=1,\r\n---> 11     batch_size=64\r\n     12 )\r\n\r\n~\\envs\\tf_1_14\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    778           validation_steps=validation_steps,\r\n    779           validation_freq=validation_freq,\r\n--> 780           steps_name='steps_per_epoch')\r\n    781 \r\n    782   def evaluate(self,\r\n\r\n~\\envs\\tf_1_14\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py in model_iteration(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\r\n    361 \r\n    362         # Get outputs.\r\n--> 363         batch_outs = f(ins_batch)\r\n    364         if not isinstance(batch_outs, list):\r\n    365           batch_outs = [batch_outs]\r\n\r\n~\\envs\\tf_1_14\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py in __call__(self, inputs)\r\n   3290 \r\n   3291     fetched = self._callable_fn(*array_vals,\r\n-> 3292                                 run_metadata=self.run_metadata)\r\n   3293     self._call_fetch_callbacks(fetched[-len(self._fetches):])\r\n   3294     output_structure = nest.pack_sequence_as(\r\n\r\n~\\envs\\tf_1_14\\lib\\site-packages\\tensorflow\\python\\client\\session.py in __call__(self, *args, **kwargs)\r\n   1456         ret = tf_session.TF_SessionRunCallable(self._session._session,\r\n   1457                                                self._handle, args,\r\n-> 1458                                                run_metadata_ptr)\r\n   1459         if run_metadata:\r\n   1460           proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\nFailedPreconditionError: 2 root error(s) found.\r\n  (0) Failed precondition: Error while reading resource variable bert_layer_module/bert/encoder/layer_5/intermediate/dense/bias from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/bert_layer_module/bert/encoder/layer_5/intermediate/dense/bias/class tensorflow::Var does not exist.\r\n\t [[{{node bert_layer/bert_layer_module_apply_tokens/bert/encoder/layer_5/intermediate/dense/BiasAdd/ReadVariableOp}}]]\r\n\t [[loss/mul/_491]]\r\n  (1) Failed precondition: Error while reading resource variable bert_layer_module/bert/encoder/layer_5/intermediate/dense/bias from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/bert_layer_module/bert/encoder/layer_5/intermediate/dense/bias/class tensorflow::Var does not exist.\r\n\t [[{{node bert_layer/bert_layer_module_apply_tokens/bert/encoder/layer_5/intermediate/dense/BiasAdd/ReadVariableOp}}]]\r\n0 successful operations.\r\n0 derived errors ignored.\r\n```\r\n\r\nI have,\r\nTF = 1.14\r\nOS = Windows 10\r\nGPU = 2060rtx\r\n\r\nI have observed other errors like out of memory in GPU while the actual data and models are so small that they can easily fit in the memory. I think this is bug in TF 1.14 which is not handling the memory properly in 20 series GPUs.", "I run my code again and I got this error now \r\n\r\n```ResourceExhaustedError                    Traceback (most recent call last)\r\n in \r\n      9     validation_data=([test_input_ids, test_input_masks, test_segment_ids], test_labels),\r\n     10     epochs=1,\r\n---> 11     batch_size=64\r\n     12 )\r\n\r\n~\\envs\\tf_1_14\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    778           validation_steps=validation_steps,\r\n    779           validation_freq=validation_freq,\r\n--> 780           steps_name='steps_per_epoch')\r\n    781 \r\n    782   def evaluate(self,\r\n\r\n~\\envs\\tf_1_14\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py in model_iteration(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\r\n    361 \r\n    362         # Get outputs.\r\n--> 363         batch_outs = f(ins_batch)\r\n    364         if not isinstance(batch_outs, list):\r\n    365           batch_outs = [batch_outs]\r\n\r\n~\\envs\\tf_1_14\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py in __call__(self, inputs)\r\n   3290 \r\n   3291     fetched = self._callable_fn(*array_vals,\r\n-> 3292                                 run_metadata=self.run_metadata)\r\n   3293     self._call_fetch_callbacks(fetched[-len(self._fetches):])\r\n   3294     output_structure = nest.pack_sequence_as(\r\n\r\n~\\envs\\tf_1_14\\lib\\site-packages\\tensorflow\\python\\client\\session.py in __call__(self, *args, **kwargs)\r\n   1456         ret = tf_session.TF_SessionRunCallable(self._session._session,\r\n   1457                                                self._handle, args,\r\n-> 1458                                                run_metadata_ptr)\r\n   1459         if run_metadata:\r\n   1460           proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\nResourceExhaustedError: 2 root error(s) found.\r\n  (0) Resource exhausted: OOM when allocating tensor with shape[64,12,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n\t [[{{node bert_layer/bert_layer_module_apply_tokens/bert/encoder/layer_11/attention/self/MatMul}}]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\t [[loss/mul/_1199]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n  (1) Resource exhausted: OOM when allocating tensor with shape[64,12,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n\t [[{{node bert_layer/bert_layer_module_apply_tokens/bert/encoder/layer_11/attention/self/MatMul}}]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n0 successful operations.\r\n0 derived errors ignored.\r\n```", "@cfwin \r\nany updates please.\r\n@urvishp80 \r\nWhat is the version of gast on your system?.\r\nCan you please try by downgrading the gast by using `pip install gast==0.2.2` and let us know if the issue still persists. Thanks!", "@cfwin \r\n@urvishp80 \r\nany update please.Thanks!", "For me, the warning happens in tensorflow==1.14.0 and gast==0.3.2, but doesn't show in tensorflow==1.13.2 and gast==0.3.2. "]}, {"number": 33448, "title": "Update word2vec_basic.py", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F33448) for more info**.\n\n<!-- need_sender_cla -->", "@weidadeyaqhhya Could you please sign cla ? Thank you.", "> @googlebot I signed it!\r\n\r\n@googlebot I signed it!", "We will not be encouraging one liner grammatical changes as this is expensive process, thank you for your interest.\r\nCC @mihaimaruseac @chanshah"]}, {"number": 33447, "title": "Could not satisfy explicit device specification '' because the node placed on device Device assignments active during op was colocated with a group of nodes that required incompatible device", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- I didn't write custom code\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): pip install tensorflow-gpu==1.14.0\r\n- Python version: 3.6.9\r\n- CUDA/cuDNN version: 8.0, cuDNN 6.0\r\n- GPU model and memory: 2 x 1080 TI\r\n**Describe the current behavior**\r\nI try to train a simple convolutional neural network defined by tf.keras.layers.Conv2D with random normal initialization, the network should be trained on GPU:\r\n\r\nI use the following code to initialize the code:\r\n\r\nconfig = tf.compat.v1.ConfigProto()\r\nconfig.log_device_placement=False\r\nsess = tf.compat.v1.InteractiveSession(config=config)\r\nwith tf.device('/gpu:0'):\r\n     setup the network and train\r\n**Describe the expected behavior**\r\nIt should train without bugs\r\n\r\nI tried to use config.allow_soft_placement=True and it didn't throw out the bug anymore but the network can only be trained on cpu instead of GPU. Please help to figure out this issue as I've seen multiple issue reported in many places but the problem is never solved with a clean solution.\r\n\r\n**Other info / logs**\r\nCould not satisfy explicit device specification '' because the node placed on device Device assignments active during op was colocated with a group of nodes that required incompatible device", "comments": ["@DontGiveUpEasily, Please provide the complete code with neural network to reproduce the reported issue. Thanks! ", "@DontGiveUpEasily, Any update on standalone code!.", "@DontGiveUpEasily, Please refer this [link](https://www.tensorflow.org/guide/gpu#manual_device_placement) for manual device placement. The doc describes, TensorFlow runtime will choose one based on the operation and available devices and automatically copy tensors between devices if required. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "To anyone with the same issue, creating the generator in a CPU device context fixes the problem:\r\n```\r\nwith tf.device('/CPU:0'):\r\n    _rng = tf.random.Generator.from_seed(123, alg='philox')\r\n```"]}, {"number": 33446, "title": "GraphKeys.BIASES variables present in losses.get_regularization_losses()", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes.\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.14 GPU\r\n- Python version: 3.6\r\n- CUDA/cuDNN version: 10.2\r\n- GPU model and memory: 1060 ti\r\n\r\n**Describe the current behavior**\r\n\r\nAll variables, including biases are added to regularization losses (not only weights) within a tf.variable_scope with a regularizer.\r\n\r\n**Describe the expected behavior**\r\n\r\nI find this behavior very strange. As far as I know only weights should be added to the l1/l2 losses list. Even if some of the losses resolve to zero later (doesn't seem the case). I asume this is by design, however this has caused me tons of confusion in the past and forces me to manually pass the regularizer everywhere. Please point me in the right direction if I'm missing something here, because I find this quite odd.\r\n\r\n**Code to reproduce the issue**\r\n\r\n\r\n```\r\nimport tensorflow.compat.v1 as tf\r\nimport tensorflow.contrib.layers as tf_c_l\r\n\r\nwith tf.Session() as sess:\r\n    t0 = tf.placeholder(dtype=tf.float32, shape=(20, 10,))\r\n\r\n    reg = tf_c_l.l1_l2_regularizer()\r\n    with tf.variable_scope('test', regularizer=reg):\r\n        v2 = tf.get_variable('test', shape=(20, 10), collections=[tf.GraphKeys.BIASES])\r\n        layer = tf_c_l.fully_connected(t0, num_outputs=10)\r\n\r\n    print('Bias Variables:')\r\n    for i in tf.get_collection(tf.GraphKeys.BIASES):\r\n        print('{} {}'.format(i.shape.as_list(), i.name))\r\n\r\n    print()\r\n\r\n    print('Regularization losses:')\r\n    for i in tf.losses.get_regularization_losses():\r\n        print('{} {}'.format(i.shape.as_list(), i.name))\r\n```\r\n\r\n\r\n**Other info / logs**\r\n\r\n```\r\nBias Variables:\r\n[20, 10] test/test:0\r\n\r\nRegularization losses:\r\n[] test/test/Regularizer/l1_l2_regularizer:0\r\n[] test/fully_connected/weights/Regularizer/l1_l2_regularizer:0\r\n[] test/fully_connected/biases/Regularizer/l1_l2_regularizer:0\r\n```\r\n", "comments": ["I have tried on colab with TF version 1.14, 1.15.0-rc3 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/f1d2d75f051cfde366dcfd0bbb3e5719/untitled286.ipynb). Thanks!", "@pisiiki Is this still an issue for you? Can you please try latest versions and let us know whether the error persists or not. Thanks!\r\n\r\nPlease feel free to close if this was already resolved for you. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 33445, "title": "Delete temporary variables from memory, but maintain them on graph for back propagation. ", "body": "\r\n\r\n**System information**\r\n- TensorFlow version: 1.15\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nI'm wondering if there is any feature that allows deleting a temporary variable from memory but still keep it on the graph. For example, I'm writing a custom layer:\r\n```bash\r\nfrom tensorflow.keras import layers\r\n\r\n\r\nclass custom_layer(layers.Layer):\r\n\r\n  def __init__(self, units=32, input_dim=32):\r\n    super(custom_layer, self).__init__()\r\n    self.units = units\r\n    self.input_dim = input_dim\r\n    w_init = tf.random_normal_initializer()\r\n    self.w = tf.Variable(initial_value=w_init(shape=(self.input_dim, self.units),\r\n                                              dtype='float32'),\r\n                         trainable=True)\r\n    b_init = tf.zeros_initializer()\r\n    self.b = tf.Variable(initial_value=b_init(shape=(self.units,),\r\n                                              dtype='float32'),\r\n                         trainable=True)\r\n\r\n  def call(self, inputs1, inputs2):\r\n    batch_size = tf.shape(inputs1)[0]\r\n    G = tf.matrix_diag(tf.matmul(inputs1, self.w) + self.b)\r\n    map = tf.matrix_inverse(tf.eye(self.units, batch_shape=[batch_size]) + tf.matmul(G, tf.transpose(G, perm = [0,2,1])))\r\n    res = tf.matmul(inputs2, map)\r\n    \r\n    return res\r\n\r\n```    \r\n\r\nThe tensor ```G``` and ```map``` will take large memory space here, so I want to delete these variables to free the memory they took but still keep them on graph. When going through back propagation, if any of these variable is needed, it still can be recomputed according to the forward graph. I know this will definitely cost longer computation time but I'm willing to trade time for space. Just curious whether there is any feature like this.\r\n Or any suggestion about trade time for space will be appreciated.\r\n\r\n**Who will benefit with this feature?**\r\nPeople who doing research on representation learning, meta learning.\r\n\r\n", "comments": ["The API that you're looking for is `tf.custom_gradient`, and the technique is called gradient checkpointing. There's no need to use tf.Variables to manage when values are collected; the standard Tensor lifetime analysis will do that. (Since the gradients will mostly be using rematerialized values rather than the original Tensors from the forward pass.)"]}, {"number": 33444, "title": "[Intel MKL] fix ut check_numerics_callback_test", "body": "", "comments": ["@penpornk Thanks for you review, I have update my code based on your comments, please help to check , thanks. "]}, {"number": 33443, "title": "Fixes Issue #26197", "body": "Updated link to better documentation.\r\n\r\nHappy Hacktoberfest :)\r\n\r\nhttps://hacktoberfest.digitalocean.com/\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/26197", "comments": ["Can this be merged in?\r\n", "@drakegens  Could you please address Ubuntu Sanity errors? Thanks!", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "Yes. Sorry i've been on vacation. I will look into resolving the Sanity errors\r\n", "Is this good to be merged?"]}, {"number": 33442, "title": "Unable to run train.py / model_main.py", "body": "**System information**\r\n- Windows 10\r\n- TensorFlow installed via pip - I've tried 1.5, 1.8, 1.9, and 2.0 - all yield different error messages\r\n- Python 3.7.4 installed, 3.5 in virtual environment\r\n- Using conda too\r\n- CUDA/cuDNN: N/A\r\n- GPU model and memory: N/A, CPU only\r\n\r\nConsistently getting error message when trying to execute train.py or model_main.py.  The latter always returns \"no module named pycocotools.\"\r\n\r\nThe train.py error depends on the version of Tensorflow I try, but it's always \"module tensorflow has no attribute '[something]'\"  For example, 'contrib,' or 'experimental'.\r\n\r\nI'm using this command: `python` model_main.py --logtostderr --train_dir=training/ `--pipeline_config_path=training/faster_rcnn_inception_v2_pets.config`\r\n\r\nI also tried porting the train.py to v2, with no change.\r\n\r\nFull traceback: \r\n`Traceback (most recent call last):\r\n  File \"train.py\", line 49, in <module>\r\n    from object_detection.builders import dataset_builder\r\n  File \"C:\\tensorflow1\\models\\research\\object_detection\\builders\\dataset_builder.py\", line 27, in <module>\r\n    from object_detection.data_decoders import tf_example_decoder\r\n  File \"C:\\tensorflow1\\models\\research\\object_detection\\data_decoders\\tf_example_decoder.py\", line 32, in <module>\r\n    slim_example_decoder = tf.contrib.slim.tfexample_decoder\r\nAttributeError: module 'tensorflow' has no attribute `'contrib'``\r\n\r\n\r\n\r\nHUGE thanks for looking at this - I'm not a professional programmer, just a hobbyist trying to get better.  I appreciate the help in solving it, and I'm very open to education to help me understand the 'why' behind these problems!", "comments": ["@RockOrSomething ,\r\nHello, `AttributeError: module 'tensorflow' has no attribute 'contrib'` is faced because `contrib` is removed from latest TF-2.0 version, you need find alternatives for that using [this](https://github.com/tensorflow/addons) link. Hence you need to modify code according to TF1.X and TF2.X versions.\r\nCan you please provide the `train.py `and `model_main.py `files or gist of colab which you are trying to execute so that we can replicate the issue?Thanks!", "Sure, here they are.  \r\n[training scripts.zip](https://github.com/tensorflow/tensorflow/files/3741168/training.scripts.zip)\r\n\r\nOriginals can be found here:\r\n[https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10](https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10)\r\n\r\nI'll have a look at that link and try to find an alternative.  \r\n", "@RockOrSomething ,\r\ndid you get chance to check the link and modify the code? \r\nAlso as this question is not a bug or feature request better asked on [StackOverflow](http://stackoverflow.com/questions/tagged//tensorflow) . There is also a larger community that reads questions there.\r\n", "Running basically the same `model_main.py` command I get:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"model_main.py\", line 26, in <module>\r\n    from object_detection import model_lib\r\n  File \"C:\\tensorflow1\\models\\research\\object_detection\\model_lib.py\", line 27, in <module>\r\n    from object_detection import eval_util\r\n  File \"C:\\tensorflow1\\models\\research\\object_detection\\eval_util.py\", line 40, in <module>\r\n    slim = tf.contrib.slim\r\nAttributeError: module 'tensorflow' has no attribute 'contrib'\r\n```\r\n\r\nEDIT:\r\n\r\nI get the above error after passing the pycocotools error by [manually building it with custom flags](https://github.com/cocodataset/cocoapi/issues/51#issuecomment-379872704). Essentially, you `pip download pycocotools`, bastardize setup.py, then `python setup.py build` and `python setup.py install`.", "@RockOrSomething ,\r\nAny update on the issue ?Thanks!", "@oanush, I'm closing this one out for the moment.  I have to take a leave of absence due for the rest of the year, and after that I'm going to try this entire process again on a fresh image, new hardware.  If the issue persists, I'll run it to ground on StackExchange and report back here!", "is there any workaround ?", "Hi there, also trying to figure out how to resolve the same issue. I would highly appreciate If someone can recommend an addon which allows an updated TF2 code to be run smoothly without \"contrib\" ", "Has anyone been able to find a workaround? ", "Project is on pause for me - catching up in other areas until the new year.\n\nOn Sat, Dec 7, 2019 at 12:50 AM Nandini Bansal <notifications@github.com>\nwrote:\n\n> Has anyone been able to find a workaround?\n>\n> \u2014\n> You are receiving this because you modified the open/close state.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/33442?email_source=notifications&email_token=AIHGT2DTIYUBINHQN3JZ5MLQXNBU3A5CNFSM4JBSNCA2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEGF7SVA#issuecomment-562821460>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AIHGT2HHPESKFN7FVUQIRP3QXNBU3ANCNFSM4JBSNCAQ>\n> .\n>\n", "I'm still troubleshooting this.", "any clues what to do with slim package on tf2 ?\r\n", "also facing the same issue. \r\n```\r\n    slim = tf.contrib.slim\r\nAttributeError: module 'tensorflow' has no attribute 'contrib'\r\n```", "Hello @oanush , Could you please help me with the issue in my train.py model ? I have tried a hell lot of stuffs and still blooming around for a solution. \r\nPlease help me if you can. I'll be obliged. (AttributeError: module 'tensorflow' has no attribute 'contrib'). \r\nHere is my code:\r\n[train.zip](https://github.com/tensorflow/tensorflow/files/4076931/train.zip)\r\n\r\n", "> Hello @oanush , Could you please help me with the issue in my train.py model ? I have tried a hell lot of stuffs and still blooming around for a solution.\r\n> Please help me if you can. I'll be obliged. (AttributeError: module 'tensorflow' has no attribute 'contrib').\r\n> Here is my code:\r\n> [train.zip](https://github.com/tensorflow/tensorflow/files/4076931/train.zip)\r\n\r\n@tanmay1994 ,\r\nFrom the error log I see that you are using code which is 1.x compatible and not 2.x. You must be using 2.x tensorflow version to run the code, `contrib` is depreciated in tf-2.x version. Please refer this[ add-on link ](https://github.com/tensorflow/addons)and modify the code for 2.x.", "Can confirm i'm getting the same problem with train.py"]}, {"number": 33441, "title": "Fix the memory leak described in Issue #33178", "body": "Documented in [THIS](https://github.com/tensorflow/tensorflow/issues/33178) thread.\r\nBased on the documentation of get() and generic_utils.object_list_uid, this has no functional effect, except to remove an unnecessary map that was growing with every input.\r\n\r\nTested using the example program in [THIS](https://github.com/tensorflow/tensorflow/issues/33178#issuecomment-541971922) post.  That could be turned into a unit-test, but the actual amount of memory before it fails is dependent on GPU, and I'm not sure what guidelines or methods there are to mitigate that.", "comments": ["@Tetragramm Can you please resolve conflicts? Thanks!", "Ok, that should do it.", "Also adding Francois, since this caching field was added a long times ago.", "@qlzh727 Any update on this PR, please. Thanks!", "It should be ready to be tested.", "@Tetragramm Can you please address Ubuntu Sanity errors? Thanks!", "They should be fixed, but I guess you have to kick off the checks?  They didn't run, anyway.", "The status says an error happened.  I don't see any details.  Is there anything I need to do?  Rebase the change again?", "@Tetragramm It is waiting for a import internally. We will let you know if anything is required from you. Thank you."]}, {"number": 33440, "title": "Fix a minor style issue in nn_ops and math_ops", "body": "", "comments": ["@autoih Could you please address Ubuntu Sanity errors? Thanks!", "Thanks @gbaned.  Since I cannot find the log message, can you help me trigger it again?", "@autoih Can you please check it now. Thanks!"]}, {"number": 33439, "title": "Cannot import tensorflow after installing via pip3", "body": "**System information**\r\n- OS Platform and Distribution: Linux Ubuntu 19.04\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: 2.0.0\r\n- Python version: 3.7.3\r\n- Installed using: pip\r\n\r\n\r\n**Describe the problem**\r\n\r\nInstalled `tensorflow` via `pip3` using `pip3 install tensorflow --user`. Any python script using `import tensorflow` or `import tensorflow as tf` fails.\r\n\r\n\r\n**Any other info / logs**\r\n```none\r\nTraceback (most recent call last):\r\n  File \"/home/[redacted]/Documents/VSC Projects/POSNN/main.py\", line 5, in <module>\r\n    import tensorflow as tf\r\nImportError: No module named tensorflow\r\n```", "comments": ["Can I see your `pip3 list` ? Thanks! Also there might me many cases why you are noticing this error. Please take a look at this issue as well and check every possibility.", "I have checked as many issues as possible (I used to use python a lot in the past but have fallen away from it in recent years). I don\u2019t think my recent transition from Windows 10 to Ubuntu helped either. I will reply with my `pip list` tommorow morning when I get my laptop back (I left it at school in my locker) around 8:45 EST.", "Here is the output from `pip3 list` on my machine (sorry if its a bit long):\r\n```none\r\nPackage                  Version    \r\n------------------------ -----------\r\nabsl-py                  0.8.1      \r\nappdirs                  1.4.3      \r\napturl                   0.5.2      \r\nasn1crypto               0.24.0     \r\nastor                    0.8.0      \r\nastroid                  2.3.1      \r\nattrs                    19.3.0     \r\nblinker                  1.4        \r\nBrlapi                   0.6.7      \r\ncertifi                  2018.8.24  \r\nchardet                  3.0.4      \r\ncommand-not-found        0.3        \r\ncryptography             2.3        \r\ncupshelpers              1.0        \r\ndefer                    1.0.6      \r\ndill                     0.3.1.1    \r\ndistro                   1.3.0      \r\ndistro-info              0.21ubuntu2\r\nentrypoints              0.3        \r\nfuture                   0.18.0     \r\ngast                     0.2.2      \r\ngoogle-pasta             0.1.7      \r\ngoogleapis-common-protos 1.6.0      \r\ngrpcio                   1.24.1     \r\nh5py                     2.10.0     \r\nhttplib2                 0.11.3     \r\nidna                     2.6        \r\nisort                    4.3.21     \r\nKeras-Applications       1.0.8      \r\nKeras-Preprocessing      1.1.0      \r\nkeyring                  17.1.1     \r\nkeyrings.alt             3.1.1      \r\nlanguage-selector        0.1        \r\nlaunchpadlib             1.10.6     \r\nlazr.restfulclient       0.14.2     \r\nlazr.uri                 1.0.3      \r\nlazy-object-proxy        1.4.2      \r\nlouis                    3.8.0      \r\nmacaroonbakery           1.2.1      \r\nMako                     1.0.7      \r\nMarkdown                 3.1.1      \r\nMarkupSafe               1.1.0      \r\nmccabe                   0.6.1      \r\nmenulibre                2.2.0      \r\nmeson                    0.49.0     \r\nnetifaces                0.10.4     \r\nnumpy                    1.17.2     \r\noauthlib                 2.1.0      \r\nolefile                  0.46       \r\nopt-einsum               3.1.0      \r\npbr                      5.4.3      \r\npexpect                  4.6.0      \r\nPillow                   5.4.1      \r\npip                      19.3       \r\npromise                  2.2.1      \r\nprotobuf                 3.10.0     \r\npsutil                   5.5.1      \r\npycairo                  1.16.2     \r\npycrypto                 2.6.1      \r\npycups                   1.9.73     \r\nPyGObject                3.32.0     \r\npygubu                   0.9.8.2    \r\nPyJWT                    1.7.0      \r\npylint                   2.4.2      \r\npymacaroons              0.13.0     \r\nPyNaCl                   1.3.0      \r\npyRFC3339                1.1        \r\npython-apt               1.8.4      \r\npython-dateutil          2.7.3      \r\npython-debian            0.1.34     \r\npytz                     2018.9     \r\npyxdg                    0.25       \r\nPyYAML                   3.13       \r\nreportlab                3.5.18     \r\nrequests                 2.21.0     \r\nrequests-unixsocket      0.1.5      \r\nSecretStorage            2.3.1      \r\nsetuptools               41.4.0     \r\nsimplejson               3.16.0     \r\nsix                      1.12.0     \r\nsystem-service           0.3        \r\nsystemd-python           234        \r\ntensorboard              2.0.0      \r\ntensorflow               2.0.0      \r\ntensorflow-datasets      1.2.0      \r\ntensorflow-estimator     2.0.0      \r\ntensorflow-hub           0.6.0      \r\ntensorflow-metadata      0.15.0     \r\ntermcolor                1.1.0      \r\ntestresources            2.0.1      \r\ntqdm                     4.36.1     \r\ntyped-ast                1.4.0      \r\nubuntu-advantage-tools   19.2       \r\nubuntu-drivers-common    0.0.0      \r\nufw                      0.36       \r\nunattended-upgrades      0.1        \r\nurllib3                  1.24.1     \r\nusb-creator              0.3.3      \r\nvirtualenv               16.7.6     \r\nwadllib                  1.3.3      \r\nWerkzeug                 0.16.0     \r\nwheel                    0.33.6     \r\nwrapt                    1.11.2     \r\nxkit                     0.0.0      \r\n```", "So, if I understand, `python script.py` where `script.py` has `import tensorflow as tf` is failing with missing tensorflow.\r\n\r\nIn this case, can you also post the output of `python -m pip list`?", "Here is the output of `python3 -m pip list`:\r\n```none\r\nPackage                  Version    \r\n------------------------ -----------\r\nabsl-py                  0.8.1      \r\nappdirs                  1.4.3      \r\napturl                   0.5.2      \r\nasn1crypto               0.24.0     \r\nastor                    0.8.0      \r\nastroid                  2.3.1      \r\nattrs                    19.3.0     \r\nblinker                  1.4        \r\nBrlapi                   0.6.7      \r\ncertifi                  2018.8.24  \r\nchardet                  3.0.4      \r\ncommand-not-found        0.3        \r\ncryptography             2.3        \r\ncupshelpers              1.0        \r\ndefer                    1.0.6      \r\ndill                     0.3.1.1    \r\ndistro                   1.3.0      \r\ndistro-info              0.21ubuntu2\r\nentrypoints              0.3        \r\nfuture                   0.18.0     \r\ngast                     0.2.2      \r\ngoogle-pasta             0.1.7      \r\ngoogleapis-common-protos 1.6.0      \r\ngrpcio                   1.24.1     \r\nh5py                     2.10.0     \r\nhttplib2                 0.11.3     \r\nidna                     2.6        \r\nisort                    4.3.21     \r\nKeras-Applications       1.0.8      \r\nKeras-Preprocessing      1.1.0      \r\nkeyring                  17.1.1     \r\nkeyrings.alt             3.1.1      \r\nlanguage-selector        0.1        \r\nlaunchpadlib             1.10.6     \r\nlazr.restfulclient       0.14.2     \r\nlazr.uri                 1.0.3      \r\nlazy-object-proxy        1.4.2      \r\nlouis                    3.8.0      \r\nmacaroonbakery           1.2.1      \r\nMako                     1.0.7      \r\nMarkdown                 3.1.1      \r\nMarkupSafe               1.1.0      \r\nmccabe                   0.6.1      \r\nmenulibre                2.2.0      \r\nmeson                    0.49.0     \r\nnetifaces                0.10.4     \r\nnumpy                    1.17.2     \r\noauthlib                 2.1.0      \r\nolefile                  0.46       \r\nopt-einsum               3.1.0      \r\npbr                      5.4.3      \r\npexpect                  4.6.0      \r\nPillow                   5.4.1      \r\npip                      19.3       \r\npromise                  2.2.1      \r\nprotobuf                 3.10.0     \r\npsutil                   5.5.1      \r\npycairo                  1.16.2     \r\npycrypto                 2.6.1      \r\npycups                   1.9.73     \r\nPyGObject                3.32.0     \r\npygubu                   0.9.8.2    \r\nPyJWT                    1.7.0      \r\npylint                   2.4.2      \r\npymacaroons              0.13.0     \r\nPyNaCl                   1.3.0      \r\npyRFC3339                1.1        \r\npython-apt               1.8.4      \r\npython-dateutil          2.7.3      \r\npython-debian            0.1.34     \r\npytz                     2018.9     \r\npyxdg                    0.25       \r\nPyYAML                   3.13       \r\nreportlab                3.5.18     \r\nrequests                 2.21.0     \r\nrequests-unixsocket      0.1.5      \r\nSecretStorage            2.3.1      \r\nsetuptools               41.4.0     \r\nsimplejson               3.16.0     \r\nsix                      1.12.0     \r\nsystem-service           0.3        \r\nsystemd-python           234        \r\ntensorboard              2.0.0      \r\ntensorflow               2.0.0      \r\ntensorflow-datasets      1.2.0      \r\ntensorflow-estimator     2.0.0      \r\ntensorflow-hub           0.6.0      \r\ntensorflow-metadata      0.15.0     \r\ntermcolor                1.1.0      \r\ntestresources            2.0.1      \r\ntqdm                     4.36.1     \r\ntyped-ast                1.4.0      \r\nubuntu-advantage-tools   19.2       \r\nubuntu-drivers-common    0.0.0      \r\nufw                      0.36       \r\nunattended-upgrades      0.1        \r\nurllib3                  1.24.1     \r\nusb-creator              0.3.3      \r\nvirtualenv               16.7.6     \r\nwadllib                  1.3.3      \r\nWerkzeug                 0.16.0     \r\nwheel                    0.33.6     \r\nwrapt                    1.11.2     \r\nxkit                     0.0.0 \r\n```", "And you're running the script as `python3 script.py`?", "I just realized I made a rookie mistake. It seems to work when running via the terminal (which I never tried for some reason). I believe it's a problem with VS code, or with my configuration.\r\n\r\n*Update:* It was an issue with the default VS code configuration. I have changed the `python.pythonPath` in VS Code's settings from `python` (the default value) to `python3` and it seems to have fixed the issue. Lesson learned, check your paths.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33439\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33439\">No</a>\n"]}]