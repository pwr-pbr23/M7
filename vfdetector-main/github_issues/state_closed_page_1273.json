[{"number": 14944, "title": "[BUG]embedding_lookup can't convert out of index into zeros vector when embedding matrix is placed on CPU ", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: windows 10\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.4.0\r\n- **Python version**: 3.5.2\r\n- **Bazel version (if compiling from source)**: \r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:  8.0 / 6\r\n- **GPU model and memory**: nvidia geforce gtx 1080 ti\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\n\r\nembedding_lookup can't convert out of index into zeros vector when embedding matrix is placed on CPU.\r\n\r\nwhen the matrix is placed on GPU, embedding_lookup method automatically convert out_of_index components into zeros vector, but it doesn't work when the matrix is placed on CPU\r\n\r\n\r\n### Source code / logs\r\n\r\nimport tensorflow as tf\r\n\r\ninputs = tf.placeholder(tf.int32, [None, None])\r\nwith tf.device('/cpu'):  ### when tf.device('/gpu') it's okay\r\n    embedding_matrix = tf.get_variable('embedding_matrix', [5, 2],\r\n                                            dtype=tf.float32,\r\n                                            initializer=tf.contrib.layers.xavier_initializer())\r\n    embedded = tf.nn.embedding_lookup(embedding_matrix, inputs)\r\n\r\n\r\n\r\ninputs_test = [[1],[2],[10]\r\n\r\n\r\n]\r\n\r\nsess = tf.Session()\r\nsess.run(tf.global_variables_initializer())\r\nres = sess.run(embedded,feed_dict = {inputs:inputs_test})\r\nprint(res)\r\n", "comments": []}, {"number": 14943, "title": "Update docker images and documentation to not use nvidia-docker by default.", "body": "`nvidia-docker` is not used anymore by the [nvidia-docker](https://github.com/NVIDIA/nvidia-docker) project.  Rather `nvidia-docker2` should be used:\r\n\r\n```\r\n$ docker run --runtime=nvidia --rm nvidia/cuda nvidia-smi\r\n```", "comments": ["@caisq, could you please look into updating our examples?", "dupe of #14714", "Nagging Assignee @caisq: It has been 298 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "This issue has been fixed."]}, {"number": 14942, "title": "tensorflow 1.4 is 8 times slower than tensorflow 1.3 when read data", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**: python wheel\r\n- **TensorFlow version (use command below)**: 1.4 and 1.3\r\n- **Python version**: 3.6.1\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: None\r\n- **GPU model and memory**: None\r\n- **Exact command to reproduce**:\r\n\r\nwhen I run tensorflow1.4 script using estimator, the script is 8 times slower than tensorflow 1.3\r\n\r\n### Source code / logs\r\n`main` script\r\n```python\r\n#!/usr/bin/env python\r\n__author__ = 'zj'\r\n\r\nimport argparse\r\nimport os\r\nimport sys\r\nimport numpy as np\r\nimport time\r\ntry:\r\n    import better_exceptions\r\nexcept ImportError:\r\n    pass\r\nimport tensorflow as tf\r\nfrom src.model_ori import crnn_fn\r\nfrom src.data_handler import data_loader\r\nfrom src.config import Params, Alphabet\r\nfrom src.input_utils import input_fn\r\n\r\n\r\ndef main(unused_argv):\r\n    models_path = FLAGS.input_model_dir\r\n    if not os.path.exists(models_path):\r\n        assert FileNotFoundError\r\n\r\n    models_list = [os.path.join(models_path, x[:-5]) for x in os.listdir(models_path) if x.endswith('.meta')]\r\n\r\n    if not os.path.exists(FLAGS.output_model_dir):\r\n        os.makedirs(FLAGS.output_model_dir)\r\n\r\n    parameters = Params(eval_batch_size=128,\r\n                        input_shape=(32, 304),\r\n                        digits_only=False,\r\n                        alphabet=Alphabet.CHINESECHAR_LETTERS_DIGITS_EXTENDED,\r\n                        alphabet_decoding='same',\r\n                        image_channels=1,\r\n                        csv_delimiter=' ',\r\n                        csv_files_eval=FLAGS.csv_files_eval,\r\n                        output_model_dir=FLAGS.output_model_dir,\r\n                        gpu=FLAGS.gpu\r\n                        )\r\n\r\n    model_params = {\r\n        'Params': parameters,\r\n    }\r\n\r\n    os.environ['CUDA_VISIBLE_DEVICES'] = parameters.gpu\r\n    config_sess = tf.ConfigProto()\r\n    config_sess.gpu_options.per_process_gpu_memory_fraction = 0.6\r\n\r\n    # Config estimator\r\n    est_config = tf.estimator.RunConfig()\r\n    est_config = est_config.replace(session_config=config_sess,\r\n                                    save_summary_steps=100,\r\n                                    model_dir=parameters.output_model_dir)\r\n\r\n    estimator = tf.estimator.Estimator(model_fn=crnn_fn,\r\n                                       params=model_params,\r\n                                       config=est_config,\r\n                                       model_dir=parameters.output_model_dir,\r\n                                       )\r\n    try:\r\n        with open(FLAGS.output_file, encoding='utf-8', mode='w') as save_file:\r\n            for model in models_list:\r\n                start = time.time()\r\n                \r\n                eval_results = estimator.evaluate(input_fn=data_loader(csv_filename=parameters.csv_files_eval,\r\n                                                                       params=parameters,\r\n                                                                       batch_size=parameters.eval_batch_size,\r\n                                                                       num_epochs=1),\r\n                                                  steps=3,\r\n                                                  checkpoint_path=model)\r\n                print('time:',time.time() - start)\r\n                print('model: %s Evaluation results: %s' % (model, str(eval_results)))\r\n                save_file.write(model + ' ' + str(eval_results) + '\\n')\r\n\r\n    except KeyboardInterrupt:\r\n        print('Interrupted')\r\n\r\n\r\nif __name__ == '__main__':\r\n    parser = argparse.ArgumentParser()\r\n    parser.add_argument('-fe', '--csv_files_eval', required=False, type=str, help='CSV filename for evaluation',\r\n                        nargs='*', default=['E:/val1.csv'])\r\n    parser.add_argument('-o', '--output_model_dir', required=False, type=str,\r\n                        help='Directory for output', default='models_vgg_100K_no_eval')\r\n    parser.add_argument('-m', '--input_model_dir', required=False, type=str,\r\n                        help='Directory for output', default='model_test')\r\n    parser.add_argument('-g', '--gpu', type=str, help=\"GPU 0,1 or '' \", default='0')\r\n    parser.add_argument('-of', '--output_file', required=False, type=str, default='123.txt', help=\"the log output file\")\r\n\r\n    tf.logging.set_verbosity(tf.logging.DEBUG)\r\n    FLAGS, unparsed = parser.parse_known_args()\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n\r\n```\r\n\r\n`data_loader` script\r\n```python\r\n#!/usr/bin/env python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom .config import Params, CONST\r\nfrom typing import Tuple\r\n\r\n\r\ndef data_loader(csv_filename: str, params: Params, batch_size: int = 128, data_augmentation: bool = False,\r\n                num_epochs: int = None, image_summaries: bool = False):\r\n    def input_fn():\r\n        # Choose case one csv file or list of csv files\r\n        if not isinstance(csv_filename, list):\r\n            filename_queue = tf.train.string_input_producer([csv_filename], num_epochs=num_epochs,\r\n                                                            name='filename_queue')\r\n        elif isinstance(csv_filename, list):\r\n            filename_queue = tf.train.string_input_producer(csv_filename, num_epochs=num_epochs, name='filename_queue')\r\n\r\n        # Skip lines that have already been processed\r\n        reader = tf.TextLineReader(name='CSV_Reader', skip_header_lines=0)\r\n        key, value = reader.read(filename_queue, name='file_reading_op')\r\n\r\n        default_line = [['None'], ['None']]\r\n        path, label = tf.decode_csv(value, record_defaults=default_line, field_delim=params.csv_delimiter,\r\n                                    name='csv_reading_op')\r\n\r\n        image, img_width = image_reading(path, resized_size=params.input_shape, params=params,\r\n                                         data_augmentation=data_augmentation, padding=True)\r\n\r\n        to_batch = {'images': image, 'images_widths': img_width, 'filenames': path, 'labels': label}\r\n        prepared_batch = tf.train.shuffle_batch(to_batch,\r\n                                                batch_size=batch_size,\r\n                                                min_after_dequeue=500,\r\n                                                num_threads=15, capacity=4000,\r\n                                                allow_smaller_final_batch=False,\r\n                                                name='prepared_batch_queue')\r\n\r\n        if image_summaries:\r\n            tf.summary.image('input/image', prepared_batch.get('images'), max_outputs=1)\r\n        tf.summary.text('input/labels', prepared_batch.get('labels')[:10])\r\n        tf.summary.text('input/widths', tf.as_string(prepared_batch.get('images_widths')))\r\n\r\n        return prepared_batch, prepared_batch.get('labels')\r\n\r\n    return input_fn\r\n\r\n\r\ndef image_reading(path: str, params: Params, resized_size: Tuple[int, int] = None, data_augmentation: bool = False,\r\n                  padding: bool = False) -> Tuple[tf.Tensor, tf.Tensor]:\r\n    # Read image\r\n    image_content = tf.read_file(path, name='image_reader')\r\n    image = tf.cond(tf.equal(tf.string_split([path], '.').values[1], tf.constant('jpg', dtype=tf.string)),\r\n                    true_fn=lambda: tf.image.decode_jpeg(image_content, channels=params.image_channels,\r\n                                                         try_recover_truncated=True),  # TODO channels = 3 ?\r\n                    false_fn=lambda: tf.image.decode_png(image_content, channels=params.image_channels),\r\n                    name='image_decoding')\r\n\r\n    # Data augmentation\r\n    if data_augmentation:\r\n        image = augment_data(image)\r\n\r\n    # Padding\r\n    if padding:\r\n        with tf.name_scope('padding'):\r\n            image, img_width = padding_inputs_width(image, resized_size, increment=CONST.DIMENSION_REDUCTION_W_POOLING)\r\n    # Resize\r\n    else:\r\n        image = tf.image.resize_images(image, size=resized_size)\r\n        img_width = tf.shape(image)[1]\r\n\r\n    with tf.control_dependencies([tf.assert_equal(image.shape[:2], resized_size)]):\r\n        return image, img_width\r\n\r\n\r\ndef random_rotation(img: tf.Tensor, max_rotation: float = 0.1, crop: bool = True) -> tf.Tensor:  # from SeguinBe\r\n    with tf.name_scope('RandomRotation'):\r\n        rotation = tf.random_uniform([], -max_rotation, max_rotation)\r\n        rotated_image = tf.contrib.image.rotate(img, rotation, interpolation='BILINEAR')\r\n        if crop:\r\n            rotation = tf.abs(rotation)\r\n            original_shape = tf.shape(rotated_image)[:2]\r\n            h, w = original_shape[0], original_shape[1]\r\n            # see https://stackoverflow.com/questions/16702966/rotate-image-and-crop-out-black-borders for formulae\r\n            old_l, old_s = tf.cond(h > w, lambda: [h, w], lambda: [w, h])\r\n            old_l, old_s = tf.cast(old_l, tf.float32), tf.cast(old_s, tf.float32)\r\n            new_l = (old_l * tf.cos(rotation) - old_s * tf.sin(rotation)) / tf.cos(2 * rotation)\r\n            new_s = (old_s - tf.sin(rotation) * new_l) / tf.cos(rotation)\r\n            new_h, new_w = tf.cond(h > w, lambda: [new_l, new_s], lambda: [new_s, new_l])\r\n            new_h, new_w = tf.cast(new_h, tf.int32), tf.cast(new_w, tf.int32)\r\n            bb_begin = tf.cast(tf.ceil((h - new_h) / 2), tf.int32), tf.cast(tf.ceil((w - new_w) / 2), tf.int32)\r\n            rotated_image_crop = rotated_image[bb_begin[0]:h - bb_begin[0], bb_begin[1]:w - bb_begin[1], :]\r\n\r\n            # If crop removes the entire image, keep the original image\r\n            rotated_image = tf.cond(tf.equal(tf.size(rotated_image_crop), 0),\r\n                                    true_fn=lambda: img,\r\n                                    false_fn=lambda: rotated_image_crop)\r\n\r\n        return rotated_image\r\n\r\n\r\ndef random_padding(image: tf.Tensor, max_pad_w: int = 5, max_pad_h: int = 10) -> tf.Tensor:\r\n    w_pad = list(np.random.randint(0, max_pad_w, size=[2]))\r\n    h_pad = list(np.random.randint(0, max_pad_h, size=[2]))\r\n    paddings = [h_pad, w_pad, [0, 0]]\r\n\r\n    return tf.pad(image, paddings, mode='REFLECT', name='random_padding')\r\n\r\n\r\ndef augment_data(image: tf.Tensor) -> tf.Tensor:\r\n    with tf.name_scope('DataAugmentation'):\r\n        # Random padding\r\n        image = random_padding(image)\r\n\r\n        image = tf.image.random_brightness(image, max_delta=0.1)\r\n        image = tf.image.random_contrast(image, 0.5, 1.5)\r\n        image = random_rotation(image, 0.05, crop=True)\r\n\r\n        if image.shape[-1] >= 3:\r\n            image = tf.image.random_hue(image, 0.2)\r\n            image = tf.image.random_saturation(image, 0.5, 1.5)\r\n\r\n        return image\r\n\r\n\r\ndef padding_inputs_width(image: tf.Tensor, target_shape: Tuple[int, int], increment: int) -> Tuple[\r\n    tf.Tensor, tf.Tensor]:\r\n    target_ratio = target_shape[1] / target_shape[0]\r\n    # Compute ratio to keep the same ratio in new image and get the size of padding\r\n    # necessary to have the final desired shape\r\n    shape = tf.shape(image)\r\n    # \u8ba1\u7b97\u5bbd\u9ad8\u6bd4\r\n    ratio = tf.divide(shape[1], shape[0], name='ratio')\r\n\r\n    new_h = target_shape[0]\r\n    new_w = tf.cast(tf.round((ratio * new_h) / increment) * increment, tf.int32)\r\n    f1 = lambda: (new_w, ratio)\r\n    f2 = lambda: (new_h, tf.constant(1.0, dtype=tf.float64))\r\n    new_w, ratio = tf.case({tf.greater(new_w, 0): f1,\r\n                            tf.less_equal(new_w, 0): f2},\r\n                           default=f1, exclusive=True)\r\n    target_w = target_shape[1]\r\n\r\n    # Definitions for cases\r\n    def pad_fn():\r\n        with tf.name_scope('mirror_padding'):\r\n            pad = tf.subtract(target_w, new_w)\r\n\r\n            img_resized = tf.image.resize_images(image, [new_h, new_w])\r\n\r\n            # Padding to have the desired width\r\n            paddings = [[0, 0], [0, pad], [0, 0]]\r\n            pad_image = tf.pad(img_resized, paddings, mode='SYMMETRIC', name=None)\r\n\r\n            # Set manually the shape\r\n            pad_image.set_shape([target_shape[0], target_shape[1], img_resized.get_shape()[2]])\r\n\r\n            return pad_image, (new_h, new_w)\r\n\r\n    def replicate_fn():\r\n        with tf.name_scope('replication_padding'):\r\n            img_resized = tf.image.resize_images(image, [new_h, new_w])\r\n\r\n            # If one symmetry is not enough to have a full width\r\n            # Count number of replications needed\r\n            n_replication = tf.cast(tf.ceil(target_shape[1] / new_w), tf.int32)\r\n            img_replicated = tf.tile(img_resized, tf.stack([1, n_replication, 1]))\r\n            pad_image = tf.image.crop_to_bounding_box(image=img_replicated, offset_height=0, offset_width=0,\r\n                                                      target_height=target_shape[0], target_width=target_shape[1])\r\n\r\n            # Set manually the shape\r\n            pad_image.set_shape([target_shape[0], target_shape[1], img_resized.get_shape()[2]])\r\n\r\n            return pad_image, (new_h, new_w)\r\n\r\n    def simple_resize():\r\n        with tf.name_scope('simple_resize'):\r\n            img_resized = tf.image.resize_images(image, target_shape)\r\n\r\n            img_resized.set_shape([target_shape[0], target_shape[1], img_resized.get_shape()[2]])\r\n\r\n            return img_resized, target_shape\r\n\r\n    # 3 cases\r\n    pad_image, (new_h, new_w) = tf.case(\r\n        {  # case 1 : new_w >= target_w\r\n            tf.logical_and(tf.greater_equal(ratio, target_ratio),\r\n                           tf.greater_equal(new_w, target_w)): simple_resize,\r\n            # case 2 : new_w >= target_w/2 & new_w < target_w & ratio < target_ratio\r\n            tf.logical_and(tf.less(ratio, target_ratio),\r\n                           tf.logical_and(tf.greater_equal(new_w, tf.cast(tf.divide(target_w, 2), tf.int32)),\r\n                                          tf.less(new_w, target_w))): pad_fn,\r\n            # case 3 : new_w < target_w/2 & new_w < target_w & ratio < target_ratio\r\n            tf.logical_and(tf.less(ratio, target_ratio),\r\n                           tf.logical_and(tf.less(new_w, target_w),\r\n                                          tf.less(new_w, tf.cast(tf.divide(target_w, 2), tf.int32)))): replicate_fn\r\n        },\r\n        default=simple_resize, exclusive=True)\r\n\r\n    return pad_image, new_w  # new_w = image width used for computing sequence lengths\r\n\r\n\r\ndef preprocess_image_for_prediction(fixed_height: int = 32, min_width: int = 8):\r\n    \"\"\"\r\n    Input function to use when exporting the model for making predictions (see estimator.export_savedmodel)\r\n    :param fixed_height: height of the input image after resizing\r\n    :param min_width: minimum width of image after resizing\r\n    :return:\r\n    \"\"\"\r\n\r\n    def serving_input_fn():\r\n        # define placeholder for input image\r\n        image = tf.placeholder(dtype=tf.float32, shape=[None, None, 1])\r\n\r\n        shape = tf.shape(image)\r\n        # Assert shape is h x w x c with c = 1\r\n\r\n        ratio = tf.divide(shape[1], shape[0])\r\n        increment = CONST.DIMENSION_REDUCTION_W_POOLING\r\n        new_width = tf.cast(tf.round((ratio * fixed_height) / increment) * increment, tf.int32)\r\n\r\n        resized_image = tf.cond(new_width < tf.constant(min_width, dtype=tf.int32),\r\n                                true_fn=lambda: tf.image.resize_images(image, size=(fixed_height, min_width)),\r\n                                false_fn=lambda: tf.image.resize_images(image, size=(fixed_height, new_width))\r\n                                )\r\n\r\n        # Features to serve\r\n        features = {'images': resized_image[None],  # cast to 1 x h x w x c\r\n                    'images_widths': new_width[None]  # cast to tensor\r\n                    }\r\n\r\n        # Inputs received\r\n        receiver_inputs = {'images': image}\r\n\r\n        return tf.estimator.export.ServingInputReceiver(features, receiver_inputs)\r\n\r\n    return serving_input_fn\r\n```\r\n\r\nlog\r\ntensorflow1.4\r\n```sh\r\nINFO:tensorflow:Using config: {'_model_dir': 'models_vgg_100K_no_eval', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': gpu_options {\r\n  per_process_gpu_memory_fraction: 0.6\r\n}\r\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000002BAAA7A6780>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\r\nINFO:tensorflow:Starting evaluation at 2017-11-28-12:21:42\r\nINFO:tensorflow:Restoring parameters from model_test\\model.ckpt-54692\r\n2017-11-28 20:22:04.720980: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows\\PY\\36\\tensorflow\\core\\kernels\\logging_ops.cc:79] * Loss : [0.236689657]\r\nINFO:tensorflow:Evaluation [1/3]\r\n2017-11-28 20:28:32.360331: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows\\PY\\36\\tensorflow\\core\\kernels\\logging_ops.cc:79] * Loss : [0.238805175]\r\nINFO:tensorflow:Evaluation [2/3]\r\n2017-11-28 20:35:41.020994: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows\\PY\\36\\tensorflow\\core\\kernels\\logging_ops.cc:79] * Loss : [0.237995088]\r\nINFO:tensorflow:Evaluation [3/3]\r\nINFO:tensorflow:Finished evaluation at 2017-11-28-12:43:21\r\nINFO:tensorflow:Saving dict for global step 54692: eval/CER = 0.0108218, eval/accuracy = 0.929688, global_step = 54692, loss = 0.23783\r\ntime:1306.1133954524994\r\nmodel: model_test\\model.ckpt-54692 Evaluation results: {'eval/CER': 0.01082176, 'eval/accuracy': 0.9296875, 'loss': 0.23782997, 'global_step': 54692}\r\n```\r\n\r\ntensorflow 1.3\r\n```sh\r\nINFO:tensorflow:Using config: {'_model_dir': 'models_vgg_100K_no_eval', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': gpu_options {\r\n  per_process_gpu_memory_fraction: 0.6\r\n}\r\n, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100}\r\nINFO:tensorflow:Starting evaluation at 2017-11-28-12:49:50\r\nINFO:tensorflow:Restoring parameters from model_test\\model.ckpt-54692\r\n2017-11-28 20:50:12.841210: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows\\PY\\36\\tensorflow\\core\\kernels\\logging_ops.cc:79] * Loss : [0.17519826]\r\nINFO:tensorflow:Evaluation [1/3]\r\n2017-11-28 20:51:03.366275: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows\\PY\\36\\tensorflow\\core\\kernels\\logging_ops.cc:79] * Loss : [0.2987892]\r\nINFO:tensorflow:Evaluation [2/3]\r\n2017-11-28 20:51:49.843030: I C:\\tf_jenkins\\home\\workspace\\rel-win\\M\\windows\\PY\\36\\tensorflow\\core\\kernels\\logging_ops.cc:79] * Loss : [0.20660429]\r\nINFO:tensorflow:Evaluation [3/3]\r\nINFO:tensorflow:Finished evaluation at 2017-11-28-12:52:19\r\nINFO:tensorflow:Saving dict for global step 54692: eval/CER = 0.01188, eval/accuracy = 0.924479, global_step = 54692, loss = 0.226864\r\ntime:157.26274514198303\r\nmodel: model_test\\model.ckpt-54692 Evaluation results: {'eval/CER': 0.011879961, 'eval/accuracy': 0.92447919, 'loss': 0.22686392, 'global_step': 54692}\r\n```", "comments": ["@ispirmustafa, any ideas what might be causing this?", "I'm not aware of any related change within estimator. ", "May be something related to data loader part? @WenmuZhou do you mind to test time difference of input_fn between 1.3 and 1.4? ", "here is the time of input_fn between 1.3 and 1.4\r\nthe script is \r\n```python\r\n# -*- coding: utf-8 -*-\r\n# @Time    : 2017/11/29 8:43\r\n# @Author  : zhoujun\r\nfrom src.data_handler import data_loader, input_fn\r\nfrom src.config import Params, Alphabet\r\nimport tensorflow as tf\r\nimport time\r\n\r\nif __name__ == '__main__':\r\n    parameters = Params(eval_batch_size=128,\r\n                        input_shape=(32, 304),\r\n                        digits_only=False,\r\n                        alphabet=Alphabet.CHINESECHAR_LETTERS_DIGITS_EXTENDED,\r\n                        alphabet_decoding='same',\r\n                        image_channels=1,\r\n                        csv_delimiter=' ',\r\n                        )\r\n\r\n    featureBatch, labelBatch = input_fn(csv_filename='E:/val1.csv', params=parameters,\r\n                                        batch_size=parameters.eval_batch_size,\r\n                                        num_epochs=1)\r\n\r\n    global_init = tf.global_variables_initializer()\r\n    loacl_init = tf.local_variables_initializer()\r\n    with tf.Session() as sess:\r\n        sess.run(global_init)\r\n        sess.run(loacl_init)\r\n        coord = tf.train.Coordinator()\r\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\r\n\r\n        start = time.time()\r\n        example, label = sess.run([featureBatch, labelBatch])\r\n        print('time: ',time.time()-start)\r\n        print(len(label))\r\n        coord.request_stop()\r\n        coord.join(threads)\r\n```\r\n`input_fn` is extracted from `data_loader` function\r\n```python\r\ndef input_fn(csv_filename: str, params: Params, batch_size: int = 128, data_augmentation: bool = False,\r\n                num_epochs: int = None):\r\n    # Choose case one csv file or list of csv files\r\n    if not isinstance(csv_filename, list):\r\n        filename_queue = tf.train.string_input_producer([csv_filename], num_epochs=num_epochs,\r\n                                                        name='filename_queue')\r\n    elif isinstance(csv_filename, list):\r\n        filename_queue = tf.train.string_input_producer(csv_filename, num_epochs=num_epochs, name='filename_queue')\r\n\r\n    # Skip lines that have already been processed\r\n    reader = tf.TextLineReader(name='CSV_Reader', skip_header_lines=0)\r\n    key, value = reader.read(filename_queue, name='file_reading_op')\r\n\r\n    default_line = [['None'], ['None']]\r\n    path, label = tf.decode_csv(value, record_defaults=default_line, field_delim=params.csv_delimiter,\r\n                                name='csv_reading_op')\r\n\r\n    image, img_width = image_reading(path, resized_size=params.input_shape, params=params,\r\n                                     data_augmentation=data_augmentation, padding=True)\r\n\r\n    to_batch = {'images': image, 'images_widths': img_width, 'filenames': path, 'labels': label}\r\n    prepared_batch = tf.train.shuffle_batch(to_batch,\r\n                                            batch_size=batch_size,\r\n                                            min_after_dequeue=500,\r\n                                            num_threads=15, capacity=4000,\r\n                                            allow_smaller_final_batch=False,\r\n                                            name='prepared_batch_queue')\r\n    return prepared_batch, prepared_batch.get('labels')\r\n```\r\ntf 1.3 log\r\n```sh\r\ntime:  0.4531559944152832\r\n128\r\n```\r\ntf 1.4 log\r\n```sh\r\ntime:  0.5000338554382324\r\n128\r\n```", "There seems to be a tiny difference in the accuracies, are the runs exactly the same? \r\nThe config for 1.4 seems to include a clusterspec, are you running the 1.4 run locally as well?\r\n\r\nAlso are either or both of them using a GPU?\r\n", "both of them ara run using 1080TI\uff0cand everything is the same except for the tensorflow version", "the tf1.4 log of input_fn is error and I have fixed it ", "@WenmuZhou thanks for helping us to investigate this issue.\r\nTo understand the issue better could you please give us following information:\r\nprint est_config.cluster_spec\r\nprint os.environ['TF_CONFIG']", "Another useful information can be get by using ProfilerHook as follows:\r\n```\r\nfrom tensorflow.contrib.hooks.python.training import profiler_hook\r\nimport os\r\nos.mkdir('/tmp/estimator_debug')\r\nestimator.evaluate(input_fn=test_input_fn, hooks=[profiler_hook.ProfilerHook(save_steps=1, output_dir='/tmp/estimator_debug')])\r\n```\r\n\r\nYou can check the output by using catapult as follows:\r\n```\r\ngit clone https://github.com/catapult-project/catapult\r\ncatapult/tracing/bin/trace2html /tmp/estimator_debug/FILENAME.json --output=/tmp/estimator_debug/FILENAME.html\r\n```\r\n\r\nCould you please let us know the differences between 1.3 and 1.4 in profiler output?", "the `est_config.cluster_spec` is None and there are a error when run \r\n```python\r\nprint os.environ['TF_CONFIG']\r\n```\r\n\r\nlog is\r\n```sh\r\n1.3.0\r\nTraceback (most recent call last):\r\n  File \"Z:/zhoujun/tf-crnn/test_model.py\", line 110, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"Z:/zhoujun/tf-crnn/test_model.py\", line 57, in main\r\n    print('os.environ[\\'TF_CONFIG\\']',os.environ['TF_CONFIG'])\r\n  File \"C:\\Anaconda3\\lib\\os.py\", line 669, in __getitem__\r\n    raise KeyError(key) from None\r\nKeyError: 'TF_CONFIG'\r\nest_config.cluster_spec None\r\n```\r\nand when I import profile_hook, there are a error\r\n```sh\r\n>>> from tensorflow.contrib.hooks.python.training import profiler_hook\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\contrib\\hooks\\__init__.py\", line 25, in <module>\r\n    from tensorflow.contrib.hooks.python.training import *\r\nModuleNotFoundError: No module named 'tensorflow.contrib.hooks.python'\r\n```", "I've seen a similar issue:\r\n\r\nMy code snippet to test on tf1.3:\r\n\r\n```\r\ndef parser(record, split_name, imagenet_mean):\r\n    assert (split_name == 'train' or split_name == 'train_dev')\r\n    keys_to_features = {\r\n        'image/encoded': tf.FixedLenFeature((), tf.string, default_value=''),\r\n        'image/format': tf.FixedLenFeature((), tf.string, default_value='jpeg'),\r\n        'image/class/class_id': tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64)),\r\n        'image/product_id': tf.FixedLenFeature([], tf.int64, default_value=tf.zeros([], dtype=tf.int64)),\r\n    }\r\n    parsed = tf.parse_single_example(record, keys_to_features)\r\n    image = tf.image.decode_jpeg(parsed['image/encoded'])\r\n    image.set_shape([180, 180, 3])\r\n    image = tf.cast(image, tf.float32)\r\n    image = tf.subtract(image, imagenet_mean)\r\n    image = tf.expand_dims(image, axis=0)\r\n    image = tf.image.resize_bicubic(image, [224, 224])\r\n    image = tf.squeeze(image)\r\n    if split_name == 'train':\r\n        image = tf.image.random_flip_left_right(image)\r\n    label = parsed['image/class/class_id']\r\n    product_id = parsed['image/product_id']\r\n    return image, label, product_id\r\n\r\n\r\ndef get_dataset(file_patterns, split_name):\r\n    assert (split_name == 'train' or split_name == 'train_dev')\r\n    imagenet_mean = tf.constant([_R_MEAN, _G_MEAN, _B_MEAN])\r\n    d = tf.contrib.data.Dataset.list_files(file_patterns)\r\n    # We choose NUM_SHARDS as buffer_size to ensure that in each epoch we are seeing all the shard TFRecord files\r\n    # with no duplicate or missing ones.\r\n    d = d.shuffle(buffer_size=NUM_SHARDS)\r\n    # cycle_length is set as NUM_SHARDS so in each cycle we will be able to see images from different shards.\r\n    d = d.interleave(lambda x: tf.contrib.data.TFRecordDataset(filenames=x), cycle_length=NUM_SHARDS, block_length=1)\r\n    d = d.map(lambda x: parser(x, split_name, imagenet_mean), num_threads=8192, output_buffer_size=BATCH_SIZE * 20)\r\n    d = d.batch(BATCH_SIZE)\r\n    return d\r\n\r\n\r\ndef main():\r\n    config = tf.ConfigProto()\r\n    config.gpu_options.visible_device_list = '0'\r\n    with tf.Graph().as_default() as g:\r\n        with tf.device('/cpu:0'):\r\n            train_set = get_dataset(TRAIN_ON_RAM, 'train')\r\n            train_iter = train_set.make_one_shot_iterator()\r\n            images, labels, product_ids = train_iter.get_next()\r\n    with tf.Session(graph=g, config=config) as sess:\r\n        for _ in tqdm(range(1000)):\r\n            sess.run(images)\r\n```\r\n\r\nFor tf1.4, I simply changed `tf.contrib.data` to `tf.data`, `num_threads` into `num_parallel_calls` and `output_buffer_size` to `prefetch`. Then I've seen a very significant performance drop:\r\n\r\nOn TF 1.3 I get:\r\n\r\n```\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [03:14<00:00,  5.14it/s]\r\n```\r\n\r\nOn TF 1.4 I get:\r\n\r\n```\r\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [05:28<00:00,  3.05it/s]\r\n```", "I did another test (using a trained models to predict the image) and also proved that tensorflow1.4 was slower than 1.3 #15057", "@mrry and @jsimsa may have better ideas about the differences in tf.data performance.", "It\u2019s not clear what caused the change in performance but `num_threads=8192` (or `num_parallel_calls=8192`) is very unlikely to be optimal, because of the potential for contention from so many parallel work items. Try setting this to a much smaller value (e.g. the number of CPU cores in your test machine) to see if this speeds things up.", "Thanks @mrry. That code was a `tf.data` benchmark script I was using when trying to tune the best parameter setting for input. Initially I was using something like 64 which is the number of cores, but I've increased the number of threads all the way from 64, 128, 256 to 8192 and the performance kept improving so that's why I was using 8192 in that script. I can change it back to smaller values and show more results.", "Thank you @WenmuZhou for adding a test with Predict. That test doesn't use Dataset or Estimator. @aselle who can help us here?", "@WenmuZhou for your `tf.data` experiment:\r\n\r\n1) Did you do the 64, 128, ..., 8192 scaling using TF 1.3 or TF 1.4? If TF 1.3, could you verify that you see a similar effect for TF 1.4?\r\n\r\n2) Could you also add timing information to the `parser` method to see how much time is spent in this method in TF 1.3 and TF 1.4? I am not aware of any `tf.data` changes between TF 1.3 and TF 1.4 to the transformations you are using that should result in a performance drop, so I am trying to see if perhaps the slowdown is due to a change in the image parsing logic.", "@WenmuZhou re:ProfilerHook, it is available as `tf.train.ProfilerHook` in TF1.4. But for 1.3 sorry to here it's not working. Could you please run it only on 1.4? It may give us some info.", "@jsimsa - I think that's actually my experiment but I'm happy to add more data. :)", "@ispirmustafa  for tf 1.4 the ouput of \r\n```python\r\nprint(est_config.cluster_spec)\r\n```\r\nis \r\n```sh\r\n<tensorflow.python.training.server_lib.ClusterSpec object at 0x00000226E91666A0>\r\n```\r\nbut, the output of tf 1.3 is None\r\n\r\nand my python verison is python3 ,can not run \r\n```python\r\ncatapult/tracing/bin/trace2html /tmp/estimator_debug/FILENAME.json --output=/tmp/estimator_debug/FILENAME.html\r\n```", "@WenmuZhou please do print(est_config.cluster_spec.as_dict()) to get the content.\r\n\r\nre: catapult, did you clone it? I mean following: `git clone https://github.com/catapult-project/catapult`\r\n", "@ispirmustafa the output is a None dict\r\n```sh\r\n{}\r\n```\r\nI have clone the catapult", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activityand the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "the code I used is in this https://github.com/solivr/tf-crnn", "Thanks @WenmuZhou \r\n\r\n@ispirmustafa could you please look to reproduce this, and then pull in whoever else is needed.\r\n", "Thanks @WenmuZhou\r\nCould you also point us an example data set in format expected by your program?\r\n", "I have a similar issue with v1.4.x. However, it goes away with v1.5rc0. ", "@songgc v1.5rc0 is slower than 1.3 in my test", "Hi @WenmuZhou ,\r\nIt would be great to have an example data set in format expected by your program and creates this issue. Would you mind to point us to it?", "I have update the code to generate dataset\r\n[hlp.zip](https://github.com/tensorflow/tensorflow/files/1648413/hlp.zip)\r\n", "A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.", "Hi @WenmuZhou \r\nWe've created two environment with GPUS one with TF1.3 and one with TF1.4.\r\nWe've run your data generation script (BTW, there is a small mismatch with between the generated data and what your model expects).\r\nWe've run your model with following command as describe on your github:\r\n'python train.py -g 1 -ft ../data/10.csv -fe ../data/10.csv -o ./export_model_dir'.\r\n\r\nAt the end we couldn't reproduce the issue. Could you please provide us a single script which we can run and which reproduces the slowness. \r\n", "@ispirmustafa I have update a latest [code](https://github.com/WenmuZhou/Segmentation-Free_OCR), the python version I used is python3.5.2, and I have test once and reproduce the issue.\r\nthe environment is\r\n \r\n* python 3.5.2\r\n* tensorflow 1.3 or 1.4\r\n\r\nSome Chinese comments cause the code to no longer run under python2 and if you need to test in python2 you need to comment out these Chinese comments\r\n", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "I tried to reproduce your issue with the code you provided but I cannot see any slowdown switching from 1.3 to 1.4. \r\nThe scripts you provided are very complex, many different issues inside and outside TensorFlow could contribute to a slowdown. \r\nCan you provide a small repro script that isolates the issue and which we can use for debugging?\r\nI will close this issue as not reproducible, but please reopen this with some more specific information. "]}, {"number": 14941, "title": "Update datasets.md", "body": "Specifically, I changed Iterator into tf.data.Iterator for people who read programming guide of Tensorflow \r\n\r\n", "comments": ["Can one of the admins verify this patch?"]}, {"number": 14940, "title": "The keys in end_points of slim are not unified for different layers.", "body": "Look at the code:\r\n\r\n```python\r\n  with tf.name_scope('xx'):\r\n    end_points_collection = 'dd'\r\n    with slim.arg_scope([slim.conv2d, slim.fully_connected, slim.max_pool2d],\r\n                      outputs_collections=end_points_collection):\r\n      y = slim.conv2d(np.zeros([1,20,20,3],dtype=np.float32), 10, [2, 2])\r\n      x = slim.max_pool2d(np.zeros([1,20,20,3],dtype=np.float32), [2, 2])\r\n      end_points = slim.utils.convert_collection_to_dict(end_points_collection)\r\n  print(end_points)\r\n```\r\n\r\nIt output\r\n```\r\nOrderedDict([('Conv', <tf.Tensor 'xx/Conv/Relu:0' shape=(1, 20, 20, 10) dtype=fl\r\noat32>), ('xx/MaxPool2D', <tf.Tensor 'xx/MaxPool2D/MaxPool:0' shape=(1, 10, 10,\r\n3) dtype=float32>)])\r\n```\r\n\r\nFor `max_pool2d` layer, the key has prefix `xx`, but for `conv2d` layer, it don't have prefix `xx`. Because in `conv2d` it uses `variable_scope` but in `max_pool2d` it uses `name_scope`. So the behavior looks inconsistent, and may cause the code make mistake. Do we need to unify the behavior ?\r\n\r\n\r\nFor example, if we use multi-gpu to train the network, and we have many clones of network, which name_scope's prefix  are `clone_1`,  `clone_2` and so on. If we want to use the key of `end_points` to get the output of layer on different gpu. We should deal with `max_pool2d` and `conv2d`  differently.", "comments": ["@sguada, could you please comment on this?", "If you replace the name_scope with a variable_scope do both align? \r\nIn general when creating layers and variables one should use variable_scopes instead of name_scope.", "But in some case, we just need `ops` should have different name rather than `variable`, we want the shared variables on different gpu, so we can't use `variable_scope`.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied."]}, {"number": 14939, "title": "Add complex dtypes support for `tf.squared_difference`", "body": "This fix tries to address the issue raised in #14932 where complex dtypes are not supported for `tf.squared_difference`, which is different from the doc string in `math_ops.cc` (see `BINARY_FEWER`).\r\n\r\nThis fix adds the `complex64` and `complex128` support in kernel, and adds additional test cases.\r\n\r\nThis fix fixes #14932.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["@benoitsteiner WDYT?", "Does this actually work as it should? The tests all have zeroes for the imaginary part so it's hard to tell.", "@carlthome The PR has been updated with additional test cases to cover imag != 0 case.", "@benoitsteiner : Does this look good to merge?", "Nagging @benoitsteiner again.", "@rmlarsen Could you take a look?", "Thanks @rmlarsen for the review. I updated the PR to capture the complex support for squared difference. Please take a look at the change and see if it fits.", "Nagging Assignees @rmlarsen, @wt-huang: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@rmlarsen The PR has been updated with `conj(x-y)*(x-y)` used now. Please take a look and see if there are any issues.", "@rmlarsen  Could you please review and approve this PR."]}, {"number": 14938, "title": "Merge pull request #1 from tensorflow/master", "body": "just merge", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->"]}, {"number": 14937, "title": "_dynamic_rnn_loop flat_output_size prevents arbitrary-shaped output tensors", "body": "I want a custom RNN cell to output multiple tensors, each with a different shape. I can handle the logic internally, but I'm running into the issue that `_dynamic_rnn_loop` automatically constructs initial outputs using `flat_output_size = nest.flatten(cell.output_size)`. This is problematic because the flattening prevents me from specifying arbitrary-shapes for my output tensors.\r\n\r\nFor concreteness, I'd like to output three tensors with shapes (batch size, a), (batch size, b), (batch size, c, d, e). However, both\r\n\r\n    @property\r\n    def output_size(self):\r\n        return (a, b, (c, d, e))\r\n\r\nand \r\n\r\n    @property\r\n    def output_size(self):\r\n        return (a, b, c, d, e)\r\n\r\nfail to create a third tensor with shape (batch size, 210, 160, 3). In the first case, `zero_output` is a tuple of (batch size, a), (batch_size, b), ((batch size, c), (batch size, d), and (batch size, e)). In the second case, the `zero_output` is a tuple of (batch size, a), (batch_size, b), (batch size, c), (batch size, d), and (batch size, e).\r\n\r\nI feel that RNN cell outputs should be permitted to be arbitrary shapes. I don't know if this is a desired feature or a bug.\r\n\r\nLinux Ubuntu 16.04\r\nTensorFlow versions: ('v1.3.0-rc1-5211-gab0fcac', '1.5.0-dev20171127')", "comments": ["I could flatten the third tensor into (batch size, c * d * e) and then reexpand it back to (batch size, c, d, e) later, but I feel like I should be able to make this work without having to do that.", "I guess that doesn't solve my problem, since later on, `final_outputs = array_ops.stack(final_outputs, axis=0)` in `rnn.py` fails because the tensors can't be stacked.", "@ebrevdo what is the proper way of having a RNN cell output multiple tensors?", "Using TensorShapes in the output_size property solves the first issue i.e.\r\n\r\n    def output_size(self):\r\n        return tf.TensorShape([a]), tf.TensorShape([b]), tf.TensorShape([c, d, e])\r\n\r\nAlso, I think the second issue is caused by TensorFlow eager. Specifically, the problem arises from array_ops.stack, which is only called if eager.in_graph_mode() is false. From rnn.py:\r\n\r\n```\r\n  final_outputs = nest.pack_sequence_as(\r\n      structure=cell.output_size, flat_sequence=final_outputs)\r\n  if not in_graph_mode:\r\n    final_outputs = array_ops.stack(final_outputs, axis=0)\r\n```", "Yes, the problem is definitely with TensorFlow eager. Removing `tfe.enable_eager_execution()` removes the problem. However, now I can't use eager and I'm back to struggling to debug :(", "@RylanSchaeffer Can you boil your problem down into a minimum reproducible program?  Otherwise it's hard to know what problem you're facing.  E.g. without your last two comments, it wasn't clear that Eager mode was involved at all.", "The problem is in eager mode; and is here:\r\nhttps://github.com/tensorflow/tensorflow/blob/0aa09c2de25ddb321405656ae33031773690bd5e/tensorflow/python/ops/rnn.py#L829\r\nI think that line should be something like:\r\n\r\nfinal_outputs = nest.map_structure(lambda out: array_ops.stack(out,\r\naxis=0), final_outputs)\r\n\r\nOn Tue, Nov 28, 2017 at 6:24 PM, Todd Wang <notifications@github.com> wrote:\r\n\r\n> @RylanSchaeffer <https://github.com/rylanschaeffer> Can you boil your\r\n> problem down into a minimum reproducible program? Otherwise it's hard to\r\n> know what problem you're facing. E.g. without your last two comments, it\r\n> wasn't clear that Eager mode was involved at all.\r\n>\r\n> \u2014\r\n> You are receiving this because you were mentioned.\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/tensorflow/tensorflow/issues/14937#issuecomment-347731846>,\r\n> or mute the thread\r\n> <https://github.com/notifications/unsubscribe-auth/ABtimwe9gVGPAGWwMnBTsXEjGTYuhu8xks5s7MBugaJpZM4QtL5U>\r\n> .\r\n>\r\n", "@tatatodd, help me interpret Eugene's comment. I can't access the link he shared. Should I still put together a minimal reproducible program?", "Also, sorry for the lack of clear explanation. I wasn't aware of the interaction between eager and the RNN code when I originally posted. It was only when I dug in to try to pinpoint the issue that I realized that eager was involved.", "Sorry, I meant line 829 of file tensorflow/python/ops/rnn.py at master.\n\nOn Wed, Nov 29, 2017 at 1:20 AM, Rylan Schaeffer <notifications@github.com>\nwrote:\n\n> Also, sorry for the lack of clear explanation. I wasn't aware of the\n> interaction between eager and the RNN code when I originally posted. It was\n> only when I dug in to try to pinpoint the issue that I realized that eager\n> was involved.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/14937#issuecomment-347799823>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtimxaT6dkwelYvHrQ4HD7al21IHDQoks5s7SHhgaJpZM4QtL5U>\n> .\n>\n", "@RylanSchaeffer I've edited Eugene's comment to provide the correct link.  I guess one thing you can do is to try changing the code as he's described, to see if that helps with your immediate problem.\r\n\r\nIf not, a minimal reproducible program will still be useful for us to track down what other issues there might be.\r\n\r\n@alextp @josh11b since this seems to be a problem with Eager mode, can one of you take a look at the problem, and Eugene's suggested fix?  Thanks!", "I don't think I have enough context to understand whether this fixes the issue. Can I get an example to reproduce this problem?\r\n\r\nI think @akshayka originally wrote this.", "@alextp , I can throw an example together tomorrow if you are willing to wait.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "This issue somehow slipped past me; @RylanSchaeffer, a minimal example that reproduces the problem would indeed be helpful", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Re-reading this, looks like what you want is:\r\n\r\n```python\r\nreturn (tf.TensorShape([a]), tf.TensorShape([b]), tf.TensorShape([c, d, e]))\r\n```", "A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "I *think* that my suggested `output_size` solves your problem.  Feel free to reopen if it doesn't."]}, {"number": 14936, "title": "tensorflow lite: Some operations cannot be supported when convert to tflite format", "body": "## System information\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n   No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n   Ubuntu 14.04\r\n- TensorFlow installed from (source or binary):\r\n   source\r\n- TensorFlow version (use command below):\r\n  1.3.0\r\n- Python version:\r\n  2.7\r\n- Bazel version (if compiling from source):\r\n  0.7.0\r\n- GCC/Compiler version (if compiling from source):\r\n  gcc (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4\r\n- CUDA/cuDNN version:\r\n  cuda8.0/cudnn6.0\r\n\r\n# Issue:\r\nWhen I convert pb file trained from tensorflow to tflite format, some operations cannot be supported, such as:\r\n**Sign\r\nTranspose\r\nUnpack\r\nPack\r\nFill\r\nRandomUniform\r\nSelect\r\nReverseSequence\r\nZerosLike\r\nArgMax**\r\nand some operations cannot support INT64\uff0c such as Cast \u3001Gather\r\nHope this issure could be solved as soon?\r\n", "comments": ["See the supported op list:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/tf_ops_compatibility.md\r\n\r\nDid you make sure to remove training related operations. Could you provide more details about your model? Did you train from a standard model script?", "@aselle \r\nWe trained a rnn model using encoder-decoder framework to implement the named entity recognition and generated the pb file from model.ckpt which produced in training steps.\r\n\r\nThe main code is as follows:\r\n```\r\nself.chars = tf.placeholder(tf.int32, [None, self.seq_len], name='chars')\r\nself.chars_emb = tf.nn.embedding_lookup(self.char_emb, self.chars)\r\nself.chars_emb = tf.transpose(self.chars_emb, [1, 0, 2])\r\nself.chars_emb = tf.unstack(self.chars_emb, num=self.seq_len,\r\n                                        name='chars_emb')\r\nself.sequence_length = tf.reduce_sum(tf.sign(self.chars), axis=1)\r\nself.encoder_outputs, self.encoder_state_fw, self.encoder_state_bw = rnn.static_bidirectional_rnn(\r\n                self.encoder_cell_f,\r\n                self.encoder_cell_b,\r\n                self.chars_emb,\r\n                dtype=tf.float32,\r\n                sequence_length=self.sequence_length\r\n            )\r\nself.decoder_logits= self.decoder_unroll(self.encoder_outputs,\r\n                                                                                self.encoder_state, self.feas_emb,\r\n                                                                                self.num_cls)\r\nself.logits = tf.transpose(self.decoder_logits, [1, 0, 2])\r\nself.loss = tf.nn.softmax_cross_entropy_with_logits(logits=self.logits, labels=self.labels, name='loss')\r\n\r\n```\r\nSo hereby\uff0cshould I rewrite the realted function as what i've mentioned above in tf-lite to make my model work? If so, that will be a huge tuffing work. And is there any suggestions, cause we want to transfer our trained model to mobile devices. Thanks in advance .\r\n", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @andrehentz: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @andrehentz: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @andrehentz: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Many of these ops are now supported. Please try again with the latest version to get an updated list.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?"]}, {"number": 14935, "title": "How to scale the weights at runtime in tensorflow?", "body": "I have asked this questione in the stackoverflow.\r\nhttps://stackoverflow.com/questions/47527384/how-to-scale-the-weights-at-runtime-in-tensorflow\r\n\r\nThanks for your help! ", "comments": ["Since this is not a bug or feature request, you should follow-up on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow). There is also a larger community that reads questions there. Thanks!"]}, {"number": 14933, "title": "Support \"causal\" padding in tf.keras.layers.Conv1D by adding support to tf.layers.convolutional.Conv1D", "body": "TensorFlow version:1.4.0\r\n\r\n\r\nIn the API docs, tf.keras.layers.Conv1D supports \"causal\". However, if I use \"causal\" as the argument of 'padding', there will be an error like this: The 'padding' argument must be one of\" valid \",\" same \". Received : causal.\r\n\r\nI check the source code, the Conv1D uses the methods in tensorflow.python.layers.convolutional, but the default implementations of tensorflow do not support  \"causal\" as the padding.\r\n\r\n(p.s., fchollet/keras uses the conv1d method in tensorflow_backend.py)\r\n\r\n", "comments": ["Thanks for filing the issue @szpssky!  I've dug through the code and agree with you; either the documentation is wrong (and should be fixed), or we need to add support for \"causal\" padding\r\n\r\n@fchollet can you comment on this?", "I think support for causal padding should be added to the parent layer in `tf.layers`. Then it will also be supported in the Keras layer that subclasses it. Please open a PR, if your time allows.", "@fchollet The implementation of causal padding seems designed for NWC format only, does it make sense for NCW?\r\n\r\nhttps://github.com/fchollet/keras/blob/b00ec66ba948077b61e25cf7dc004857c432b01a/keras/backend/tensorflow_backend.py#L3140", "@facaiy I've never seen this use case (it's used for timeseries only, which are in NTC format), but in theory it could be made more general.", "Thanks for explanation, @fchollet . #15000 is created to fix the issue, might you take a look?", "hi @facaiy\r\nI use your convolutional.py file to replace the original file, I found error\uff1a\r\n\r\n`   File \"/Users/szp/Documents/github/check_tf/causal.py\", line 63, in build_model\r\n    model = tf.keras.models.Model(input_, net)\r\n  File \"/Users/szp/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/topology.py\", line 670, in __init__\r\n    super(Network, self).__init__(inputs, outputs, name=name)\r\n  File \"/Users/szp/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 1554, in __init__\r\n    '(thus holding past layer metadata). Found: ' + str(x))\r\nValueError: Output tensors to a Model must be the output of a TensorFlow `Layer` (thus holding past layer metadata). Found: Tensor(\"conv1d_8/Relu:0\", shape=(?, ?, 1), dtype=float32)`\r\n\r\nDoes this modify still have some problem?\r\n", "@szpssky I only write test case for `tf.layers.Conv1D`, however it should work well for keras as well. I think that replacing file might not be a good idea, because the file might be quite different between 1.4 and master branch (Note that the exception stack complains metadata)\r\n\r\nCould you replace only the modification to original 1.4 python file? If failed, please tell me. Thank you very much.", "@facaiy You are right, there are some difference between 1.4 and master branch. As you said I just replaced the modified part, It seems that the operation can only be \"SAME\" and \"VALID\":\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/python/framework/op_def_library.py#L688\r\n`ValueError: Attr 'padding' of 'Conv2D' Op passed string 'CAUSAL' not in: \"SAME\", \"VALID\".`\r\n\r\nCurrently, I haven't found a place to specify \"SAME\" and \"VALID\" in source code.", "Yes, hacking `__call__()` method might make mess because `tf.kears` and `tf.layers` share a complicate multiple inheritance. Thanks for feedback, @szpssky . I'll look out other solution to fix the problem.", "Hi, @szpssky. I reopened a PR with another solution. And both tests passed for keras and core. Perhaps you are interested on it.", "@facaiy \r\nIt seems that this problem still exists:\r\n\r\n`  File \"/Users/szp/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/keras/_impl/keras/engine/topology.py\", line 252, in __call__\r\n    output = super(Layer, self).__call__(inputs, **kwargs)\r\n  File \"/Users/szp/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 575, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"/Users/szp/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/layers/convolutional.py\", line 167, in call\r\n    outputs = self._convolution_op(inputs, self.kernel)\r\n  File \"/Users/szp/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 835, in __call__\r\n    return self.conv_op(inp, filter)\r\n  File \"/Users/szp/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 499, in __call__\r\n    return self.call(inp, filter)\r\n  File \"/Users/szp/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 187, in __call__\r\n    name=self.name)\r\n  File \"/Users/szp/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 177, in _conv1d\r\n    data_format=data_format, name=name)\r\n  File \"/Users/szp/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 2204, in conv1d\r\n    data_format=data_format)\r\n  File \"/Users/szp/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 631, in conv2d\r\n    data_format=data_format, name=name)\r\n  File \"/Users/szp/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 691, in _apply_op_helper\r\n    attr_def.allowed_values.list.s))))\r\nValueError: Attr 'padding' of 'Conv2D' Op passed string 'CAUSAL' not in: \"SAME\", \"VALID\".`\r\n\r\nIt should be a variable declaring that only \"SAME\" and \"VALID\" are used.\r\n\r\nIs the master branch correct? let me try test it on master branch.\r\n", "Yes, at least for Linux CPU, both tests below passed on master branch for python 2.7 and python 3.6.\r\n\r\n```bash\r\nHEAD is now at 04a029d... TST: more test for invalid argument\r\nINFO: Found 1 test target...\r\nTarget //tensorflow/python:layers_convolutional_test up-to-date:\r\n  bazel-bin/tensorflow/python/layers_convolutional_test\r\nINFO: Elapsed time: 303.626s, Critical Path: 78.83s\r\n//tensorflow/python:layers_convolutional_test                            PASSED in 3.5s\r\nExecuted 1 out of 1 test: 1 test passes.\r\n\r\nHEAD is now at 04a029d... TST: more test for invalid argument\r\nINFO: Found 1 test target...\r\nTarget //tensorflow/python/keras:convolutional_test up-to-date:\r\n  bazel-bin/tensorflow/python/keras/convolutional_test\r\nINFO: Elapsed time: 23.051s, Critical Path: 22.28s\r\n//tensorflow/python/keras:convolutional_test                             PASSED in 20.1s\r\nExecuted 1 out of 1 test: 1 test passes.\r\n```", "Hi, @szpssky . I leave some comments on PR for you, and could you recheck your patch? It seems that `causal` leaks into its parent class, which is unexpected for me. Moreover, could you paste your environment information and test code? Thanks.", "@facaiy \r\nI tested your PR on master branch, it looks work well. However, if input shape is (None,None,1) such as the first layer is LSTM, it will have an error:\r\n`  File \"/Users/szp/anaconda3/envs/tf-latest/lib/python3.6/site-packages/tensorflow/python/layers/convolutional.py\", line 358, in shape_fn\r\n    input_list[1] += left_pad\r\nTypeError: unsupported operand type(s) for +=: 'NoneType' and 'int'`\r\n\r\nBut it doesn't seem to be your problem.  fchollet/keras LSTM layer output is a exact shape, such as (None, 30, 1), but the `tf.keras.layers.LSTM` output shape becomes (None, None, 1). \r\nA simple test code:\r\nhttps://gist.github.com/szpssky/3a54239a0044363abb53ef5c69a80056\r\n", "Good question! Yes, I forget unknown dimension. I'll fix the problem later. Thanks very much. ", "By the way, if the two LSTM behaves differently, which might indicate a bug. I suggest to report the inconsistency: -) ", "OK. Looking forward to the new version of your PR, Thanks : ) "]}, {"number": 14932, "title": "tf.squared_difference does not work with complex dtypes", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, the provided minimal example\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary (tensorflow-gpu)\r\n- **TensorFlow version (use command below)**: 1.4.0\r\n- **Python version**: 3.6\r\n- **CUDA/cuDNN version**: 8/6\r\n- **GPU model and memory**: GeForce GTX 980 4GB\r\n\r\n### Describe the problem\r\n\r\n`tf.squared_difference` does not work with complex dtypes `tf.complex64` and `tf.complex128` although the documentation says so: https://www.tensorflow.org/api_docs/python/tf/squared_difference.\r\n\r\n### Source code / logs\r\n\r\nMinimal (not) working example:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nfor dtype in [tf.complex128, tf.complex64]:\r\n    try:\r\n        print(f'*************** {dtype} ***************')\r\n        x = tf.constant(1, dtype=dtype)\r\n        y = tf.constant(2, dtype=dtype)\r\n        result = tf.squared_difference(x, y)\r\n\r\n        with tf.Session() as sess:\r\n            sess.run(result)\r\n    except Exception as e:\r\n        print(e)\r\n```\r\n\r\nThe error output:\r\n\r\n```\r\n*************** <dtype: 'complex128'> ***************\r\n2017-11-28 10:33:08.695995: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX\r\n2017-11-28 10:33:08.836822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Found device 0 with properties: \r\nname: GeForce GTX 980 major: 5 minor: 2 memoryClockRate(GHz): 1.2785\r\npciBusID: 0000:04:00.0\r\ntotalMemory: 3.94GiB freeMemory: 3.86GiB\r\n2017-11-28 10:33:08.836855: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:04:00.0, compute capability: 5.2)\r\nNo OpKernel was registered to support Op 'SquaredDifference' with these attrs.  Registered devices: [CPU,GPU], Registered kernels:\r\n  device='GPU'; T in [DT_INT32]\r\n  device='GPU'; T in [DT_INT64]\r\n  device='GPU'; T in [DT_DOUBLE]\r\n  device='GPU'; T in [DT_HALF]\r\n  device='GPU'; T in [DT_FLOAT]\r\n  device='CPU'; T in [DT_INT64]\r\n  device='CPU'; T in [DT_INT32]\r\n  device='CPU'; T in [DT_DOUBLE]\r\n  device='CPU'; T in [DT_HALF]\r\n  device='CPU'; T in [DT_FLOAT]\r\n\r\n         [[Node: SquaredDifference = SquaredDifference[T=DT_COMPLEX128](Const, Const_1)]]\r\n\r\nCaused by op 'SquaredDifference', defined at:\r\n  File \"/home/neumann/.conda/envs/project_dc/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/home/neumann/.conda/envs/project_dc/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/net/home/neumann/workspace/python/tensorflow/tf_speech/tf_speech/complex_squared_difference_example.py\", line 9, in <module>\r\n    res = tf.squared_difference(x, y)\r\n  File \"/home/neumann/.conda/envs/project_dc/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 4601, in squared_difference\r\n    \"SquaredDifference\", x=x, y=y, name=name)\r\n  File \"/home/neumann/.conda/envs/project_dc/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/neumann/.conda/envs/project_dc/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\r\n    op_def=op_def)\r\n  File \"/home/neumann/.conda/envs/project_dc/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'SquaredDifference' with these attrs.  Registered devices: [CPU,GPU], Registered kernels:\r\n  device='GPU'; T in [DT_INT32]\r\n  device='GPU'; T in [DT_INT64]\r\n  device='GPU'; T in [DT_DOUBLE]\r\n  device='GPU'; T in [DT_HALF]\r\n  device='GPU'; T in [DT_FLOAT]\r\n  device='CPU'; T in [DT_INT64]\r\n  device='CPU'; T in [DT_INT32]\r\n  device='CPU'; T in [DT_DOUBLE]\r\n  device='CPU'; T in [DT_HALF]\r\n  device='CPU'; T in [DT_FLOAT]\r\n\r\n         [[Node: SquaredDifference = SquaredDifference[T=DT_COMPLEX128](Const, Const_1)]]\r\n\r\n*************** <dtype: 'complex64'> ***************\r\n2017-11-28 10:33:08.858858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1120] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:04:00.0, compute capability: 5.2)\r\nNo OpKernel was registered to support Op 'SquaredDifference' with these attrs.  Registered devices: [CPU,GPU], Registered kernels:\r\n  device='GPU'; T in [DT_INT32]\r\n  device='GPU'; T in [DT_INT64]\r\n  device='GPU'; T in [DT_DOUBLE]\r\n  device='GPU'; T in [DT_HALF]\r\n  device='GPU'; T in [DT_FLOAT]\r\n  device='CPU'; T in [DT_INT64]\r\n  device='CPU'; T in [DT_INT32]\r\n  device='CPU'; T in [DT_DOUBLE]\r\n  device='CPU'; T in [DT_HALF]\r\n  device='CPU'; T in [DT_FLOAT]\r\n\r\n         [[Node: SquaredDifference_1 = SquaredDifference[T=DT_COMPLEX64](Const_2, Const_3)]]\r\n\r\nCaused by op 'SquaredDifference_1', defined at:\r\n  File \"/home/neumann/.conda/envs/project_dc/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/home/neumann/.conda/envs/project_dc/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/net/home/neumann/workspace/python/tensorflow/tf_speech/tf_speech/complex_squared_difference_example.py\", line 9, in <module>\r\n    res = tf.squared_difference(x, y)\r\n  File \"/home/neumann/.conda/envs/project_dc/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 4601, in squared_difference\r\n    \"SquaredDifference\", x=x, y=y, name=name)\r\n  File \"/home/neumann/.conda/envs/project_dc/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/neumann/.conda/envs/project_dc/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\r\n    op_def=op_def)\r\n  File \"/home/neumann/.conda/envs/project_dc/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'SquaredDifference' with these attrs.  Registered devices: [CPU,GPU], Registered kernels:\r\n  device='GPU'; T in [DT_INT32]\r\n  device='GPU'; T in [DT_INT64]\r\n  device='GPU'; T in [DT_DOUBLE]\r\n  device='GPU'; T in [DT_HALF]\r\n  device='GPU'; T in [DT_FLOAT]\r\n  device='CPU'; T in [DT_INT64]\r\n  device='CPU'; T in [DT_INT32]\r\n  device='CPU'; T in [DT_DOUBLE]\r\n  device='CPU'; T in [DT_HALF]\r\n  device='CPU'; T in [DT_FLOAT]\r\n\r\n         [[Node: SquaredDifference_1 = SquaredDifference[T=DT_COMPLEX64](Const_2, Const_3)]]\r\n```", "comments": ["Added a PR #14939 for the fix."]}, {"number": 14931, "title": "Missing gradient for tf.argmax", "body": "LookupError: No gradient defined for operation 'Argmax' (op type: Argmax)", "comments": ["Please resubmit and pay attention to the issue template (https://github.com/tensorflow/tensorflow/issues/new) . Please provide all the information it asks. Thank you.", "Afaik it is impossible to define a gradient for argmax.", "Ah sorry, brain freeze.  Actually, we could create a practical implementation of gradient for argmax, but it just wouldn't be very useful for learning.\r\n\r\nFor details see:\r\nYaroslav's comment here: #2177\r\nhttps://www.reddit.com/r/MachineLearning/comments/4e2get/argmax_differentiable/"]}, {"number": 14930, "title": "softmax_cross_entropy: Improve docstring", "body": "Improve docstring of `softmax_cross_entropy`.", "comments": ["Can one of the admins verify this patch?"]}, {"number": 14929, "title": "Number of bytes mismatch when reading tflite schema", "body": "I train a model outside and convert it into.lite format and import it to the iOS project\uff0cbut I  encounter a problem below:why?\r\nLoaded model resolved reporter tensorflow/contrib/lite/interpreter.cc:481 required_bytes != bytes (4 != 16)Tensor 88 is invalidly specified in schema.\r\nFailed to construct interpreter\r\n\r\n", "comments": ["Could you possibly provide more information about your model (source code) and tflite converted model binary file?", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "I got the same error.\r\nMy model is defined by \r\n```python\r\ndef make_model(input, scope, output_count, reuse=None):\r\n    net = input\r\n    batch_norm_params = {\r\n        # Decay for the moving averages.\r\n        'decay': 0.995,\r\n        # epsilon to prevent 0s in variance.\r\n        'epsilon': 0.001,\r\n        # calculate moving average or using exist one\r\n        'is_training': False,\r\n        'variables_collections': [ tf.GraphKeys.TRAINABLE_VARIABLES ],\r\n        'updates_collections': None,\r\n    }\r\n    with tf.variable_scope(scope, [input], reuse=reuse) as sc:\r\n        with slim.arg_scope([slim.conv2d, slim.fully_connected],\r\n                            activation_fn=tf.nn.relu,\r\n                            weights_initializer=tf.truncated_normal_initializer(0.0, 0.01),\r\n                            weights_regularizer=slim.l2_regularizer(0.00005),\r\n                            biases_initializer=tf.constant_initializer(),\r\n                            normalizer_fn=slim.batch_norm,\r\n                            normalizer_params=batch_norm_params):\r\n            with slim.arg_scope([slim.batch_norm], **batch_norm_params):\r\n                net = slim.conv2d(net, 32, 3, padding='VALID', scope='conv1')\r\n                net = slim.max_pool2d(net, 3, 2, scope='pool1')\r\n                net = slim.conv2d(net, 64, 3, padding='VALID', scope='conv2')\r\n                net = slim.max_pool2d(net, 3, 2, scope='pool2')\r\n                net = slim.conv2d(net, 64, 3, padding='VALID', scope='conv3')\r\n                net = slim.max_pool2d(net, 2, 2, scope='pool3')\r\n                net = slim.conv2d(net, 128, 2, padding='VALID', scope='conv4')\r\n                net = slim.flatten(net)\r\n                net = slim.fully_connected(net, 256, scope='fc1')\r\n                label = slim.fully_connected(net, output_count, activation_fn=None, scope='fc_label')\r\n                offset = slim.fully_connected(net, 2, activation_fn=None, scope='fc_offset')\r\n    return label, offset\r\n```\r\nand input has shape [1,48,48,3], output_count is 3.\r\nI got error \"tensorflow/contrib/lite/interpreter.cc:481 required_bytes != bytes (4 != 8)Tensor 28 is invalidly specified in schema.\\ntensorflow/contrib/lite/interpreter.cc:481 required_bytes != bytes (4 != 8)Tensor 38 is invalidly specified in schema.\\n\", when in tflite::InterpreterBuilder function.", "@dhc1256436519 Did you resolve this issue?", "Nagging Assigneee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @aselle: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 44 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Is this still a problem for you?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 31 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 14928, "title": "Variable size multi-label candidate sampling.", "body": "A fix that adresses the following issue https://github.com/tensorflow/tensorflow/issues/12968.\r\nMakes candidate sampling ops accept a `tensor` instead of an `int` per batch as a `num_true` parameter. Interface change (switching the `.attr` to `.input`). I left out one check in `ComputeAccidentalHits` - `.SetShapeFn()`, and would be open to any suggestion on how to fix that.\r\n", "comments": ["Can one of the admins verify this patch?", "Sorry this fell through the cracks.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Sorry, I'm traveling rn. I'll get back to it as soon as possible.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @drpngx: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @drpngx: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Reviewer @drpngx: It has been 14 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "So, the problem is that we need binary compatibility of existing graphs. So what you would need is,\r\n* Create a V2 op that has the new signature\r\n* Check it in, wait for 2 weeks\r\n* Change the python wrapper to call the new v2 op\r\n\r\nCould you change the PR to create a new op? Thanks.", "@drpngx Yes, I'll try to address this.\r\nAlso, do you have any idea about how to prevent `Segmentation fault (core dumped)` - I've added some comments on Feb 10th.", "Sorry I missed that. Feel free to ping me more aggressively if this slips. I am guessing that you need `.HostMemory()` otherwise the variable might just go in GPU.", "In the last comment I show how I add `.HostMemory()` to no avail. Is this a correct use?", "I see. Can you see if the problem persists with `int64`? Maybe the first thing to try would be to run with `--config=asan` to see if there are obvious bugs.", "Thanks, I don't remember if I tried, I'll update the op and get back to you.", "Nagging Reviewer @drpngx: It has been 14 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "Nagging Reviewer @drpngx: It has been 29 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "Does turning num_true into a scalar tensor make sense at at?\r\n\r\nThe only advantage I can see for having num_true at all, is to allow shape calculation before the graph is executed.\r\n\r\nBut with that advantage gone, the value for num_true might just be taken as the second dimension of the shape of the \"labels\" tensor. Maybe it would make sense to simply do that if the value \"-1\" is passed in as num_true value?", "Nagging Reviewer @drpngx: It has been 15 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "Nagging Reviewer @drpngx: It has been 15 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "It has been 44 days that this pull-request has stalled. Please create a new pull-request with the requested changes.", "@MtDersvan , @drpngx is there a working example for this change?"]}, {"number": 14927, "title": "Fix a typo in comment", "body": "its cached -> it's cached", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please.", "Jenkins, test this please."]}, {"number": 14926, "title": "Branch 176737730", "body": "", "comments": []}, {"number": 14925, "title": "Adapt identity initializer API to other initializers.", "body": "**This API extension is completely backwards compatible and supports consistency.**\r\n\r\nAll initializer classes (such as `ZerosInitializer`) have the same API and can either be accessed via the initializer namespace, from Keras initializers or directly from the tensorflow import:\r\n```python\r\n>>> tf.initializers.zeros\r\n<class 'tensorflow.python.ops.init_ops.Zeros'>\r\n>>> tf.keras.initializers.Zeros\r\n<class 'tensorflow.python.ops.init_ops.Zeros'>\r\n>>> tf.zeros_initializer\r\n<class 'tensorflow.python.ops.init_ops.Zeros'>\r\n```\r\n\r\nThe `IdentityInitializer` class, which was added in d5f1790530db0ee430d223497a59cfc26ab5f4d8, had been missing the last of those options. This is why the following way of access was added to its API:\r\n```python\r\n>>> tf.identity_initializer\r\n<class 'tensorflow.python.ops.init_ops.Identity'>\r\n```\r\n", "comments": ["Can one of the admins verify this patch?", "The initializers namespace is preferred, and we are trying to avoid adding new symbols to the top-level tf module.\r\n\r\nEventually (probably with 2.0), tf.*initializer will be deprecated in favor of tf.initializers.*. \r\n\r\nThe inconsistency is ugly, but if you switch to using tf.initializers, you don't ever have to see it."]}, {"number": 14923, "title": "_LayerRNNCell __call__() method incompatible with tuple of tensors", "body": "I'm trying to build a custom LSTM cell that should accept a tuple of tensors in the call method. However, as part of the `dynamic_rnn` loop, `_LayerRNNCell`'s `__call__()` method requires that `inputs` be a `2-D` tensor with shape `[batch_size, input_size]`, which is incompatible with a tuple of tensors. Is there a way around this, or can the `__call__()1 method be expanded to be more flexible?\r\n\r\nThe error that I receive:\r\n`ValueError: Layer action_conditioned_lstm_cell_1 expects 1 inputs, but it received 2 input tensors.`\r\n\r\nLinux Ubuntu 16.04\r\nTensorFlow versions: ('v1.3.0-rc1-5211-gab0fcac', '1.5.0-dev20171127')", "comments": ["I just realised that the problem arises because my custom LSTM inherits from `BasicLSTMCell`, which requires that `Inputs must be 2-dimensional.` The above error thus arises because `self.input_spec` is set during initialisation and an error check on dimensionality is performed, so even though my custom `call` method handles the tuple of tensors, execution never reaches that code because it fails the dimensionality check. How do I get around this?", "It seems like changing `call()` to `__call__()` allows me to bypass this problem. What is the difference?", "@ebrevdo might have some thoughts on this.", "Don't subclass `BasicLSTMCell`.  You can copy/paste the bits you need for your class."]}, {"number": 14922, "title": "Branch 176732156", "body": "", "comments": ["@tensorflow-jenkins retest this please\r\n", "The jenkins failure is a flake as the same test passed on the Ubuntu Python 3 build"]}, {"number": 14921, "title": "Possible sparse gradients bug in 1.4", "body": "\r\n### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Slackware 14.2\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.4.0-rc1-11-g130a514 1.4.0\r\n- **Python version**: 3.6\r\n\r\n### Problem\r\nI get the following warning when I run my code:\r\n```\r\n/usr/lib64/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:96: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\r\n  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\r\n```\r\nWhen I was using the exact same code with TF 1.3, I did not get the warning. I was wondering if this is a possible bug in 1.4 or simply the warning got added in the update?\r\n\r\nI located the problem to this part of my code:\r\n\r\n```\r\nact_t_ph = tf.placeholder(tf.int32, [None])\r\n# ...\r\nwith tf.variable_scope(\"action_value\"):\r\n    x = tf.layers.dense(x, 512, activation=tf.nn.relu)\r\n    x = tf.layers.dense(x, 6, activation=None)\r\nz_net_locs = x\r\naction_mask = tf.one_hot(act_t_ph, 6, on_value=True, off_value=False, dtype=tf.bool)\r\nz_locations = tf.boolean_mask(z_net_locs, action_mask)\r\n# ...\r\n```\r\nLater, gradients are computed with respect to the variables in the dense layers and these gradients are backpropagated through  `z_locations`. \r\n\r\nI also tried changing my code to:\r\n\r\n```\r\nself.act_t_ph = tf.placeholder(tf.int32, [None])\r\n# ...\r\nwith tf.variable_scope(\"action_value\"):\r\n    x = tf.layers.dense(x, 512, activation=tf.nn.relu)\r\n    x = tf.layers.dense(x, 6, activation=None)\r\nz_net_locs = x\r\nbsize = tf.shape(self.act_t_ph)[0]\r\nb_ind = tf.range(0, bsize, 1, tf.int32)\r\nind   = tf.concat([act_t_ph, b_ind], axis=-1)\r\nz_locations = tf.gather_nd(z_net_locs, ind)\r\n# ...\r\n```\r\nand I no longer get the warning in TF 1.4. As far as I can tell, one of the operations in the original code cannot handle sparse gradients. \r\n", "comments": ["Looks like that warning has existed for over a year:\r\nhttps://github.com/tensorflow/tensorflow/blame/master/tensorflow/python/ops/gradients_impl.py#L96\r\n\r\nBut note that it's only a warning.  Is there actually anything wrong, other than the warning being generated?", "The code runs fine, but it is hard to tell if there is difference in speed, compared to TF 1.3.\r\n\r\nI know that the warning has been there for a long time, but could it be that the implementation of some of the operators that I use changed between the two versions and causes the implicit conversion and hence the warning? In any case, it is very strange that I was not getting the warning in 1.3 if nothing changed.\r\n", "@nikonikolov it's defnitely possible that something has changed, but again, note that it's just a warning.\r\n\r\nI'm closing this out.  If you feel there's a concrete bug here, feel free to ping this issue (or open a new one), with a minimum reproducible example that demonstrates the issue, and I'll re-open."]}, {"number": 14920, "title": "Fix issue in tf.nn.softmax where negative dims could only be -1", "body": "This fix tries to address the issue raised in #14916 where negative dims could only be -1 in tf.nn.softmax.\r\n\r\nThe issue was that dims=-1 was handled as a case of \"last dim\" with `is_last_dim = (dim is -1) or (dim == shape.ndims - 1)`, but the generic negative dims were never processed.\r\n\r\nThis fix adds `dim += shape.ndims` for generic negative dims, and add additional test cases.\r\n\r\nThis fix fixes #14916.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>\r\n", "comments": ["@facaiy WDYT?", "@facaiy In the example shown in #14916,\r\n```\r\nxx = tf.constant(1, shape=[10, 28, 28, 3], dtype=tf.float32)\r\n```\r\nso `shape.ndims = 4` (not `3`). In that case, `-4 + 4 = 0` will pass and `-5 + 4 = -1` will fail.\r\n\r\nI think the edge case has been covered:\r\n```python\r\nPython 2.7.12 (default, Nov 20 2017, 18:23:56) \r\n[GCC 5.4.0 20160609] on linux2\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> xx = tf.constant(1, shape=[10, 28, 28, 3], dtype=tf.float32)\r\n>>> tf.nn.softmax(xx, dim=-1)\r\nWARNING:tensorflow:From <stdin>:1: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\ndim is deprecated, use axis instead\r\n<tf.Tensor 'Reshape_1:0' shape=(10, 28, 28, 3) dtype=float32>\r\n>>> tf.nn.softmax(xx, dim=-2)\r\n<tf.Tensor 'transpose_1:0' shape=(10, 28, 28, 3) dtype=float32>\r\n>>> tf.nn.softmax(xx, dim=-3)\r\n<tf.Tensor 'transpose_3:0' shape=(10, 28, 28, 3) dtype=float32>\r\n>>> tf.nn.softmax(xx, dim=-4)\r\n<tf.Tensor 'transpose_5:0' shape=(10, 28, 28, 3) dtype=float32>\r\n>>> tf.nn.softmax(xx, dim=-5)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/deprecation.py\", line 316, in new_func\r\n    return func(*args, **kwargs)\r\n```", "@yongtang Sounds good. Thanks for the clarification!", "@aselle WDYT?", "Nagging Reviewer @aselle, @yuefengz: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 14 days with no activity and the `awaiting review` label has been applied.", "@drpngx @facaiy @aselle @yuefengz Any chance to take a look at the PR again? I think the issue raised in review have all been addressed.", "@drpngx @wt-huang I think the change is clear and straightforward. Could you help us to merge it?", "> @drpngx @wt-huang I think the change is clear and straightforward. Could you help us to merge it?\r\n\r\n@facaiy   -  Let me help you to get this merged as wt-huang is OOO. Do you want me to bypass the kokoro failures ?(If they are unrelated to this PR)", "@harshini-gadige Thanks. The failures are unrelated. I find that `feedback/copybara` checker is missing, do you know why? If all tests pass in the Google internal repository, then we can merge the PR safely.", "@alextp The PR has been updated, please take a look and let me know if there are any issues."]}, {"number": 14919, "title": "Branch 176791620", "body": "", "comments": ["@tensorflow-jenkins retest this please\r\n"]}, {"number": 14918, "title": "This build requires an Android SDK. Please add the android_sdk_repository rule to your WORKSPACE", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04 LTS\r\n- **TensorFlow installed from (source or binary)**:  Source\r\n- **TensorFlow version (use command below)**:  Master from November 17 (11eefcd21f9f3d92740cb85d9576198507eeb118)\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: 0.7.0\r\n- **GCC/Compiler version (if compiling from source)**: gcc version 5.4.0 20160609\r\n- **CUDA/cuDNN version**: N/A (not trying to build Tensorflow GPU)\r\n- **GPU model and memory**: \r\n- **Exact command to reproduce**:  `sudo tensorflow/tools/ci_build/ci_build.sh CPU bazel test //tensorflow/...`\r\n\r\n### Describe the problem\r\nI am trying to run unit tests following the instructions here: https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md#running-unit-tests\r\n\r\nI have installed Docker and am running: \r\n`sudo tensorflow/tools/ci_build/ci_build.sh CPU bazel test //tensorflow/...`\r\n\r\nI receive the following error:\r\n```\r\nERROR: /home/jovarty/git/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/external/bazel_tools/tools/android/BUILD:230:1: Executing genrule @bazel_tools//tools/android:no_android_sdk_repository_error failed (Exit 1): bash failed: error executing command\r\n  (cd /home/jovarty/git/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH='' \\\r\n    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin \\\r\n  /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; echo     This build requires an Android SDK. Please add the android_sdk_repository     rule to your WORKSPACE. ;     exit 1 ').\r\n```\r\n\r\nAfter this error I see that no tests were run: `Executed 0 out of 1666 tests: 1666 were skipped.`\r\n\r\n\r\nIs the Android SDK required when running unit tests? Is this something that should be included in the Dockerfile? (I'm not very familiar with Docker)", "comments": ["@angersson, I thought we had disabled these tests. Could you take a look please.", "If you disabled them after November 17 (11eefcd) then I may just need to merge master into my branch. I'll give this a shot later tonight.", "I've replicated this on a fresh pull from master:\r\n\r\n```shell\r\ngit clone http://github.com/tensorflow/tensorflow /tmp/tf\r\ncd /tmp/tf\r\ngit pull\r\ntensorflow/tools/ci_build/ci_build.sh CPU bazel test //tensorflow/...\r\n```\r\n\r\n...but it's not replicating with:\r\n\r\n```shell\r\ndocker run -it gcr.io/tensorflow/tensorflow:latest-devel bash\r\n> cd /tensorflow/\r\n> git pull\r\n> bazel test //tensorflow/...\r\n```\r\n\r\nStill investigating -- might be a difference in Bazel versions?", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "I tried to replicate this again (on the same command as earlier) and the tests still fail, but this time due to a different error:\r\n\r\n```\r\nERROR: /workspace/tensorflow/contrib/lite/models/smartreply/demo/app/src/main/BUILD:50:1: C++ compilation of rule '//tensorflow/co\r\nntrib/lite/models/smartreply/demo/app/src/main:smartreply_jni_lib' failed (Exit 1).\r\ntensorflow/contrib/lite/models/smartreply/demo/app/src/main/smartreply_jni.cc:16:17: fatal error: jni.h: No such file or directory\r\n #include <jni.h>\r\n                 ^\r\n```\r\n\r\nThese ci_build scripts aren't used much internally, so I'm not sure what's going on with them.", "Nagging Assigneee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.", "@gunan are the [\"please run these tests\" instructions](https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md#running-unit-tests) still relevant? Maybe we should get rid of them.", "We should still describe a way for contributors to test tensorflow locally.\r\nI agree that those instructions may be stale, and we may need to rewrite them.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Agreed. I wonder what the best way to do so is -- probably to make Kokoro's testing scripts use Docker under the hood, so that everyone can run those tests locally.\r\n\r\nUntil then, I'm not sure maintaining the ci_build stuff is worth the opportunity cost. Is it just as effective to make a PR with no reviewers, since the tests will run then anyway? Local TDD *should* be possible without ci_build, right?", "Nagging Assignee @angersson: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @angersson: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I can no longer replicate this particular error. Please comment if it comes up again."]}, {"number": 14917, "title": "Branch 177033313", "body": "", "comments": []}, {"number": 14916, "title": "tf.nn.softmax(input, dim=-1, name=None), argument `dim` cannot take negative index other than -1?", "body": "I expect that in the function `tf.nn.softmax(input, dim=-1, name=None)`, the argument `dim` can take dim either positive or negative. However, it seems the only negative index can be taken is -1?\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\ntf.__version__\r\n> '1.4.0'\r\n\r\nxx = tf.constant(1, shape=[10, 28, 28, 3], dtype=tf.float32)\r\n\r\ntf.nn.softmax(xx, dim=-1)\r\n> <tf.Tensor 'Reshape_1:0' shape=(10, 28, 28, 3) dtype=float32>\r\n\r\ntf.nn.softmax(xx, dim=3)\r\n> <tf.Tensor 'Reshape_3:0' shape=(10, 28, 28, 3) dtype=float32>\r\n\r\ntf.nn.softmax(xx, dim=-2)\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-8-c0dec6c1fa17> in <module>()\r\n----> 1 tf.nn.softmax(xx, dim=-2)\r\n\r\n/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.pyc in softmax(logits, dim, name)\r\n   1665       dimension of `logits`.\r\n   1666   \"\"\"\r\n-> 1667   return _softmax(logits, gen_nn_ops._softmax, dim, name)\r\n   1668 \r\n   1669 \r\n\r\n/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.pyc in _softmax(logits, compute_op, dim, name)\r\n   1624   # Swap logits' dimension of dim and its last dimension.\r\n   1625   input_rank = array_ops.rank(logits)\r\n-> 1626   logits = _swap_axis(logits, dim, math_ops.subtract(input_rank, 1))\r\n   1627   shape_after_swap = array_ops.shape(logits)\r\n   1628 \r\n\r\n/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/ops/nn_ops.pyc in _swap_axis(logits, dim_index, last_index, name)\r\n   1596     return array_ops.transpose(logits,\r\n   1597                                array_ops.concat([\r\n-> 1598                                    math_ops.range(dim_index), [last_index],\r\n   1599                                    math_ops.range(dim_index + 1, last_index),\r\n   1600                                    [dim_index]\r\n\r\n/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/ops/math_ops.pyc in range(start, limit, delta, dtype, name)\r\n   1232       delta = cast(delta, inferred_dtype)\r\n   1233 \r\n-> 1234     return gen_math_ops._range(start, limit, delta, name=name)\r\n   1235 \r\n   1236 \r\n\r\n/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/ops/gen_math_ops.pyc in _range(start, limit, delta, name)\r\n   3257   if _ctx.in_graph_mode():\r\n   3258     _, _, _op = _op_def_lib._apply_op_helper(\r\n-> 3259         \"Range\", start=start, limit=limit, delta=delta, name=name)\r\n   3260     _result = _op.outputs[:]\r\n   3261     _inputs_flat = _op.inputs\r\n\r\n/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc in _apply_op_helper(self, op_type_name, name, **keywords)\r\n    785         op = g.create_op(op_type_name, inputs, output_types, name=scope,\r\n    786                          input_types=input_types, attrs=attr_protos,\r\n--> 787                          op_def=op_def)\r\n    788       return output_structure, op_def.is_stateful, op\r\n    789 \r\n\r\n/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc in create_op(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\r\n   2956         op_def=op_def)\r\n   2957     if compute_shapes:\r\n-> 2958       set_shapes_for_outputs(ret)\r\n   2959     self._add_op(ret)\r\n   2960     self._record_op_seen_by_control_dependencies(ret)\r\n\r\n/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc in set_shapes_for_outputs(op)\r\n   2207       shape_func = _call_cpp_shape_fn_and_require_op\r\n   2208 \r\n-> 2209   shapes = shape_func(op)\r\n   2210   if shapes is None:\r\n   2211     raise RuntimeError(\r\n\r\n/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/framework/ops.pyc in call_with_requiring(op)\r\n   2157 \r\n   2158   def call_with_requiring(op):\r\n-> 2159     return call_cpp_shape_fn(op, require_shape_fn=True)\r\n   2160 \r\n   2161   _call_cpp_shape_fn_and_require_op = call_with_requiring\r\n\r\n/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc in call_cpp_shape_fn(op, require_shape_fn)\r\n    625     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\r\n    626                                   input_tensors_as_shapes_needed,\r\n--> 627                                   require_shape_fn)\r\n    628     if not isinstance(res, dict):\r\n    629       # Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\r\n\r\n/home/jetadmin/anaconda2/envs/ygtf/lib/python2.7/site-packages/tensorflow/python/framework/common_shapes.pyc in _call_cpp_shape_fn_impl(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\r\n    689       missing_shape_fn = True\r\n    690     else:\r\n--> 691       raise ValueError(err.message)\r\n    692 \r\n    693   if missing_shape_fn:\r\n\r\nValueError: Requires start <= limit when delta > 0: 0/-2 for 'range' (op: 'Range') with input shapes: [], [], [] and with computed input tensors: input[0] = <0>, input[1] = <-2>, input[2] = <1>.\r\n```", "comments": ["Added a PR #14920 for the fix.", "@yongtang, thanks for looking into fixing this."]}, {"number": 14915, "title": "Very different CPU usage/allocation behavior when using slightly different CPUs", "body": "I am running the same exact model on two largely similar systems, let's call them system A and B. However, TF's behavior is very different. On system A, CPU utilization is around 60% (on a 12-core system), while on system B CPU utilization is only around 8%. Moreover, on system A the same model runs about 10x slower than system B, even though it's using far fewer CPU resources.\r\n\r\nThe systems are similar in that they're both running:\r\n\r\nUbuntu 14.04\r\nTensorFlow 1.4.0 (compiled from source)\r\nPython 2.7\r\ngcc 4.8.4\r\n\r\nWhat's different:\r\n\r\nSystem A:\r\nBazel 0.6.0\r\n2x E5-2643 v3\r\n\r\nSystem B:\r\nBazel 0.7.0\r\n2x E5-2643 v4\r\n\r\nWhy would they behave so differently?", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "You can close this if you want, but I'm reporting this as a bug, not a request for help. Same model with 10X performance decrease and 8X CPU utilization increase on nearly identical CPUs is not exactly expected behavior.", "@alquraishi I guess the issue is that this bug is not actionable. Performance optimization is tricky, and there are many ways of ending up with slow performance. Without more details it's not clear if this is a fixable bug in TensorFlow, an unfixable bug in TensorFlow (or at least hard to fix), some kind of interaction between TensorFlow and underlying system, some inefficient implementation of the network where the inefficiency only comes out on some hardware implementation, etc", "@alquraishi I don't deny that the behavior you're experiencing is unexpected.\r\n\r\nThe reason I'm suggesting you turn to StackOverflow for help is exactly what @yaroslavvb mentioned - without more information or a means for us to reproduce the issue, it's not clear what the issue is, and whether it is a bug in TensorFlow or not.  As a matter of policy, that sort of support is handled on StackOverflow.  Note we regularly monitor StackOverflow issues, just like we do for github issues.\r\n\r\nIf you do discover a more concrete problem, definitely do file an issue here."]}, {"number": 14914, "title": "\"and\", \"or\", etc, should be overloaded if possible", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: OS X 10.13.1\r\n- **TensorFlow installed from (source or binary)**: Binary (anaconda)\r\n- **TensorFlow version (use command below)**: 1.1.0\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**:  N/A\r\n- **GPU model and memory**: Intel HD Graphics 630 1536 MB (not used)\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\nIt would make code much cleaner if more of Python's binary boolean operations were overloaded for \r\nTF. I understand this can't be done for \"==\" because of hashmap key problems but \"and\", \"or\", \"^\", \"not\", really as many operations as possible, would be great.\r\n\r\n\r\n### Source code / logs\r\n\r\nCurrently:\r\n```\r\ndef cube_isect(x_m,x_M,y_m,y_M):\r\n  return tf.logical_or(tf.logical_and(x_m >= y_m, x_m <= y_M), \r\n                                  tf.logical_and(y_m >= x_m, y_m <= x_M))\r\n```\r\nProposed:\r\n```\r\ndef cube_isect(x_m,x_M,y_m,y_M):\r\n  return (x_m >= y_m and x_m <= y_M) or (y_m >= x_m and y_m <= x_M)\r\n```\r\n", "comments": ["Not sure how I can assign or mark as a feature request but looping in @alextp ", "Looking at the details of python we're not allowed to override and and or since python has weird short-circuiting control flow based on those operators. What we can do is turn a tensor into a boolean if eager execution is enabled in which case and, or, not, etc all work as intended. We can override the bitwise operators to be elementwise but I think that is less attractive.", "i would vote for overriding the bitwise operators to be elementwise because thats what python already does with \"^\" since it has no xor. You can write \"True ^ False\" etc", "Also, you can think of an array of booleans as being an array of bits, so I don't see why overriding bitwise is a problem?", "Numpy treats bitwise operators as elementwise operators on boolean arrays so I think we should too. Reopening.", "Yeah as does regular python, for not just xor:\r\n\r\n```\r\n>>> True & True\r\nTrue\r\n>>> import numpy as np\r\n>>> np.bool\r\n<type 'bool'>\r\n>>> a=np.asarray([True,False,False,True],dtype=np.bool)\r\n>>> b=np.asarray([False,False,True,True],dtype=np.bool)\r\n>>> a ^ b\r\narray([ True, False,  True, False], dtype=bool)\r\n>>> a & b\r\narray([False, False, False,  True], dtype=bool)\r\n>>> a | b\r\narray([ True, False,  True,  True], dtype=bool)\r\n>>> \r\n```\r\n\r\nThis is actually better than overriding \"and\" and \"or\" because these TF operators never shortcircuit AFAIK. This would be really nice to have in regular mode, not just immediate.", "I think bitwise operators have been supported, \r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/3d1452c6a4a37c9f5d6f1da77d335cc43f9b7fc8/tensorflow/python/ops/math_ops.py#L1167-L1169\r\n\r\n```python\r\nIn [11]: a = tf.constant([False, True])\r\nIn [12]: b = tf.constant([True, True])\r\n\r\nIn [13]: a & b\r\nOut[13]: <tf.Tensor 'and:0' shape=(2,) dtype=bool>\r\n\r\nIn [14]: a | b\r\nOut[14]: <tf.Tensor 'or:0' shape=(2,) dtype=bool>\r\n\r\nIn [15]: a ^ b\r\nOut[15]: <tf.Tensor 'xor:0' shape=(2,) dtype=bool>\r\n```"]}, {"number": 14913, "title": "[BUG] argparse (Argument Parser) is not working in nightly build", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: pip install tf-nightly-gpu\r\n- **TensorFlow version (use command below)**: v1.3.0-rc1-5211-gab0fcac 1.5.0-dev20171125\r\n- **Python version**: 3.5.3\r\n- **Bazel version (if compiling from source)**:n/a\r\n- **GCC/Compiler version (if compiling from source)**:n/a\r\n- **CUDA/cuDNN version**:9.0/7.0\r\n- **GPU model and memory**:Titan Xp (12Gb)\r\n- **Exact command to reproduce**: python test.py --myarg buzz\r\n\r\n### Describe the problem\r\nNightly build is not handing correctly arguments passed to the script. The arguments are parsed correctly in the official 1.4 version.\r\n\r\n```\r\n(nightly) daniyar@sleepy-prism:~/tmp/argsparse$ python test.py --myarg buzz\r\nbuzz\r\nFATAL Flags parsing error: Unknown command line flag 'myarg'\r\nPass --helpshort or --helpfull to see help on flags.\r\n```\r\n\r\n### Source code\r\n```\r\nimport numpy as np\r\nimport argparse\r\nimport tensorflow as tf\r\n\r\nparser = argparse.ArgumentParser(description='argsparse test for tensorflow nightly build')\r\nparser.add_argument('--myarg', type=str, help='fizz or buzz', default='fizz')\r\nargs = parser.parse_args()\r\n\r\ndef main(argv):\r\n    print(args.myarg)\r\n\r\nif __name__ == '__main__':\r\n    main([]) # test before tf.app.run()\r\n    tf.app.run()\r\n```", "comments": ["2652704b576adc16b4d735f651cea1024e88b72e changed the behavior of `tf.app.run()` to look at `sys.argv` and attempt to parse the flags using `absl.flags`.\r\n\r\nAs a workaround, you can pass an empty list of args to `tf.app.run()`:\r\n\r\n```python\r\nif __name__ == '__main__':\r\n  tf.app.run(argv=[])\r\n```\r\n\r\n@martinwicke @yilei This seems like it might be a breaking change for existing users of `argparse`. Should we find a way to make this optional before it gets into a release?", "Yeah, that is a problem. @yilei, we do need to maintain backwards compatibility for the behavior of `tf.app.*`. Maybe we need to extend the wrapper to be ugly. \r\n\r\nWe should also deprecate `tf.app` and `tf.flags` altogether. They are included for historical reasons, TF has no business containing those modules.", "Looks like `tf.app.run` needs to continue ignoring unknown flags (i.e. unfix #11195)\r\n\r\nHowever, does the example code work before the change? `tf.app.run` will call `main` with positional arguments, but here the `main` function has no arguments and it's called manually.\r\n\r\nDid you mean the following?\r\n\r\n    def main(argv):\r\n      parser = argparse.ArgumentParser(description='argsparse test for tensorflow nightly build')\r\n      parser.add_argument('--myarg', type=str, help='fizz or buzz', default='fizz')\r\n      args = parser.parse_args()\r\n\r\n    if __name__ == '__main__':\r\n      tf.app.run()\r\n\r\nI'm asking since I'm wondering if the positional arguments passed to `main` by `tf.app.run` is important or not. If it's not important, we can simply swallow the `absl.flags` parsing exception in `tf.app.run` and pass `sys.argv[:1]` to `main`. Otherwise we need to add an extra API to `absl.flags`.", "@yilei yes, the example code works with tensorflow 1.4.\r\n\r\nI call `main` manually just to show that the arguments are parsed by python. I wouldn't call it in a usual usecase. I don't think I would want any arguments from `tf.app.run`.\r\n\r\n\r\n@mrry Unfortunately the work-around doesn't work:\r\n```\r\n(nightly) daniyar@sleepy-prism:~/tmp/argsparse$ python test.py --myarg buzz\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 13, in <module>\r\n    tf.app.run(argv=[])\r\n  File \"/home/daniyar/anaconda2/envs/tensorsource/lib/python3.5/site-packages/tensorflow/python/platform/app.py\", line 119, in run\r\n    argv = flags.FLAGS(_sys.argv if argv is None else argv)\r\n  File \"/home/daniyar/anaconda2/envs/tensorsource/lib/python3.5/site-packages/absl/flags/_flagvalues.py\", line 634, in __call__\r\n    'argv cannot be an empty list, and must contain the program name as '\r\nValueError: argv cannot be an empty list, and must contain the program name as the first element.\r\n```\r\n\r\nThis, however, works:\r\n```\r\nif __name__ == '__main__':\r\n    import sys\r\n    tf.app.run(argv=sys.argv[1:])\r\n```\r\nand this doesn't:\r\n```\r\nif __name__ == '__main__':\r\n    import sys\r\n    tf.app.run(argv=sys.argv)\r\n```", "The correct workaround should be `tf.app.run(argv=sys.argv[:1])`, not `tf.app.run(argv=sys.argv[1:])`", "@yilei you are right, but surprisingly it works in both cases.", "Hmm I think it worked in your example since `sys.argv[1:]` is `['--myarg', 'buzz']`, `--myargv` is treated as the program name, and it only tries to parse `['buzz']`, which only contains positional arguments.", "@dantkz I tried your example in 1.4, but I got this:\r\n\r\n```\r\n$ python test.py --myarg buzz\r\nbuzz\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 17, in <module>\r\n    tf.app.run()\r\n  File \"/tmp/tf/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 48, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\nTypeError: main() takes no arguments (1 given)\r\n```", "@yilei Oops, my tensorflow 1.4 example had `def main(argv):`, sorry. :(\r\n\r\nThe bug is still there with `def main(argv):`.", "Sorry for the bug in the workaround. Perhaps the following would work to ensure that the executable name is preserved?\r\n\r\n```python\r\nif __name__ == '__main__':\r\n  tf.app.run(argv=sys.argv[:1])\r\n```", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "I believe this has been fixed with https://github.com/tensorflow/tensorflow/commit/f38f92eb369b9cbb12b2c8bd0006d7fa1c64c5c0"]}]