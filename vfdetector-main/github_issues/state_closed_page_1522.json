[{"number": 7266, "title": "undefined reference to `google::protobuf::internal::fixed_address_empty_string'", "body": "![error_2_4](https://cloud.githubusercontent.com/assets/14129554/22622882/bd9c80a0-eb15-11e6-9ee1-3269efd7e0bd.png)\r\n\r\nHello,\r\nI am tring to do install core of tensorflow on Raspberry PI 3, on Ubuntu 16.04 LTS using python 3.5.2, exactly following the instruction on https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile, but got error messages at last step \"make -f tensorflow/contrib/makefile/Makefile HOST_OS=PI TARGET=PI OPTFLAGS=\"-Os\" CXX=g++-4.8\". \r\n\r\nNote that I tried the method shared on  https://github.com/samjabrahams/tensorflow-on-raspberry-pi, but there are also error occured. \r\n\r\nI am wondering is it due to some update of tensorflow? Looking forward to your reply. Thank you!", "comments": ["cc @samjabrahams who made TF work on PI", "Thanks @yaroslavb - I haven't seen the \"undefined reference to ...protobuf...\" error before. Generally, the error code 1 messages I've seen were due to an out of memory error, though that doesn't seem likely to be the case here. Currently at a super bowl party, but I'll try to take a closer look soon.", "This appears to be a duplicate of #5684. @fangyan93 - it may be good to move the discussion over there.\r\n\r\nAs an aside, you mentioned that you experienced a bug following the instructions on my repo. If you have the time, would you mind opening up an issue over there with a few details so I can investigate that problem separately?", "Closing as a duplicate per @samjabrahams's comment."]}, {"number": 7265, "title": "Errata in mnist.py", "body": "Part of the images and labels were not selected from the shuffled array.", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "@Lezcano: can you sign the cla so that we can merge your fix ? Thanks.", "I think I've accepted it.\r\n\r\nDo I have to do anything else?", "CLAs look good, thanks!\n\n<!-- ok -->", "Jenkins, test this please.", "@Lezcano: thanks, our bot has found a CLA for you. I'll merge the changes as soon as testing is complete."]}, {"number": 7264, "title": "To avoid failures in windows, do not always fetch contrib/nccl.", "body": "", "comments": ["http://ci.tensorflow.org/job/tf-pr-win-bzl/8/console\r\n\r\nIt looks like this only fixes one problem. Onto the next one.", "Looks like there was an issue in win3 (build machine).\r\nNext build returned much better:\r\nhttp://ci.tensorflow.org/job/tf-pr-win-bzl/9/\r\n\r\nNow building with the gradients test disabled:\r\nhttp://ci.tensorflow.org/job/tf-pr-win-bzl/10/"]}, {"number": 7263, "title": "Added missing return doc for export results in train_and_evaluate", "body": "", "comments": []}, {"number": 7262, "title": "Android example app - Embed app icon in README file", "body": "Since we have the asset in this repo, it's nice to show it inline. :-)\r\n\r\nHere's what it looks like when viewing [the updated README file in my fork]:(https://github.com/daj/tensorflow/blob/master/tensorflow/examples/android/README.md)):\r\n![screen shot 2017-02-04 at 5 08 51 pm](https://cloud.githubusercontent.com/assets/739125/22621904/a7769a90-eafc-11e6-9bc0-9bdb0f0038fb.png)\r\n\r\nThis SO answer told be how I could embed the image while limiting its size on the page:\r\nhttp://stackoverflow.com/a/26138535/112705", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.\r\n"]}, {"number": 7261, "title": "\"No Android SDK found\" error when building Android demo app", "body": "I'm only following [the README instructions](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/README.md) to build the Android demo app.\r\n\r\nI believe I have configured my ./WORKSPACE file correctly.  This seems to be a different error to the obvious one you get if you haven't update the WORKSPACE file...\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\nhttp://stackoverflow.com/q/41478820/112705\r\n[No matching open or closed Issues in this Git project](https://github.com/tensorflow/tensorflow/issues?utf8=%E2%9C%93&q=is%3Aissue%20%22No%20Android%20SDK%20found%22%20is%3Aclosed%20\r\n) (I tried various Android build searches too and they seemed to be different problems):\r\n\r\n### Environment info\r\nOperating System: Mac OS X 10.10.5\r\n\r\nInstalled version of CUDA and cuDNN: None\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n```\r\n19d932f4cb49182c111d646267ac6c0bbc4f2f00\r\n```\r\nI cloned (with submodules) today, so this is the current master code.\r\n\r\n2. The output of `bazel version`\r\n```\r\nBuild label: 0.4.4-homebrew\r\nBuild target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Thu Feb 2 01:06:38 2017 (1485997598)\r\nBuild timestamp: 1485997598\r\nBuild timestamp as int: 1485997598\r\n```\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\nHere's the error:\r\n\r\n> Daniels-MacBook-Air:tensorflow Dan$ bazel build //tensorflow/examples/android:tensorflow_demo\r\n> ...\r\n> <snip>\r\n> ...\r\n> ERROR: /private/var/tmp/_bazel_Dan/e9cc2fe61f735d74f6a33af534dffc47/external/bazel_tools/src/tools/android/java/com/google/devtools/build/android/incrementaldeployment/BUILD:3:1: in android_library rule @bazel_tools//src/tools/android/java/com/google/devtools/build/android/incrementaldeployment:incremental_stub_application: **No Android SDK found. Use the --android_sdk command line option to specify one.**\r\n\r\nHere's the relevant section of my WORKSPACE file (Bazel 0.4.4 seems to require Android build tools 24.0.3 or newer, which is why I updated that too):\r\n```\r\nandroid_sdk_repository(\r\n    name = \"androidsdk\",\r\n    api_level = 23,\r\n    build_tools_version = \"24.0.3\",\r\n    # Replace with path to Android SDK on your system\r\n    path = \"/Developer/Android/sdk/\",\r\n)\r\n\r\nandroid_ndk_repository(\r\n    name=\"androidndk\",\r\n    path=\"/Developer/Android/android-ndk-r12b\",\r\n    api_level=21)\r\n```\r\n### What other attempted solutions have you tried?\r\n\r\nI tried the path both with and without the trailing slash.  \r\n\r\nI investigated how to pass the `--android_sdk` option to bazel based on [this Bazel documentation](https://bazel.build/versions/master/docs/command-line-reference.html):\r\n```\r\n--android_sdk=<a build target label> default: \"@bazel_tools//tools/android:sdk\"\r\nSpecifies Android SDK/platform that is used to build Android applications.\r\n```\r\nI couldn't figure out how to pass in that setting (plus I suspect it is supposed to come from the WORKSPACE file anyway).  Here's what I tried:\r\n```\r\nDaniels-MacBook-Air:tensorflow Dan$ bazel build --android_sdk=/Developer/Android/sdk //tensorflow/examples/android:tensorflow_demo\r\nWhile parsing option --android_sdk=/Developer/Android/sdk: invalid label: /Developer/Android/sdk\r\n\r\nDaniels-MacBook-Air:tensorflow Dan$ bazel build //tensorflow/examples/android:tensorflow_demo --android_sdk=/Developer/Android/sdk\r\nWhile parsing option --android_sdk=/Developer/Android/sdk: invalid label: /Developer/Android/sdk\r\n```\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n\r\nFull logs are here:\r\n```\r\nDaniels-MacBook-Air:tensorflow Dan$ bazel build //tensorflow/examples/android:tensorflow_demo\r\nWARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.build/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.\r\nWARNING: /Users/Dan/Code/tensorflow/tensorflow/core/BUILD:826:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:avgpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there.\r\nWARNING: /Users/Dan/Code/tensorflow/tensorflow/core/BUILD:826:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:bounds_check.h' directly. You should either move the file to this package or depend on an appropriate rule there.\r\nWARNING: /Users/Dan/Code/tensorflow/tensorflow/core/BUILD:826:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:cwise_ops.h' directly. You should either move the file to this package or depend on an appropriate rule there.\r\nWARNING: /Users/Dan/Code/tensorflow/tensorflow/core/BUILD:826:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:cwise_ops_common.h' directly. You should either move the file to this package or depend on an appropriate rule there.\r\nWARNING: /Users/Dan/Code/tensorflow/tensorflow/core/BUILD:826:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:cwise_ops_gradients.h' directly. You should either move the file to this package or depend on an appropriate rule there.\r\nWARNING: /Users/Dan/Code/tensorflow/tensorflow/core/BUILD:826:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_activations.h' directly. You should either move the file to this package or depend on an appropriate rule there.\r\nWARNING: /Users/Dan/Code/tensorflow/tensorflow/core/BUILD:826:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_attention.h' directly. You should either move the file to this package or depend on an appropriate rule there.\r\nWARNING: /Users/Dan/Code/tensorflow/tensorflow/core/BUILD:826:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_backward_cuboid_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there.\r\nWARNING: /Users/Dan/Code/tensorflow/tensorflow/core/BUILD:826:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_backward_spatial_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there.\r\nWARNING: /Users/Dan/Code/tensorflow/tensorflow/core/BUILD:826:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_cuboid_convolution.h' directly. You should either move the file to this package or depend on an appropriate rule there.\r\nWARNING: /Users/Dan/Code/tensorflow/tensorflow/core/BUILD:826:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_patch_3d.h' directly. You should either move the file to this package or depend on an appropriate rule there.\r\nWARNING: /Users/Dan/Code/tensorflow/tensorflow/core/BUILD:826:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_pooling.h' directly. You should either move the file to this package or depend on an appropriate rule there.\r\nWARNING: /Users/Dan/Code/tensorflow/tensorflow/core/BUILD:826:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_softmax.h' directly. You should either move the file to this package or depend on an appropriate rule there.\r\nWARNING: /Users/Dan/Code/tensorflow/tensorflow/core/BUILD:826:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:eigen_spatial_convolutions.h' directly. You should either move the file to this package or depend on an appropriate rule there.\r\nWARNING: /Users/Dan/Code/tensorflow/tensorflow/core/BUILD:826:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:fifo_queue.h' directly. You should either move the file to this package or depend on an appropriate rule there.\r\nWARNING: /Users/Dan/Code/tensorflow/tensorflow/core/BUILD:826:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:maxpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there.\r\nWARNING: /Users/Dan/Code/tensorflow/tensorflow/core/BUILD:826:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:ops_util.cc' directly. You should either move the file to this package or depend on an appropriate rule there.\r\nWARNING: /Users/Dan/Code/tensorflow/tensorflow/core/BUILD:826:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:ops_util.h' directly. You should either move the file to this package or depend on an appropriate rule there.\r\nWARNING: /Users/Dan/Code/tensorflow/tensorflow/core/BUILD:826:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:padding_fifo_queue.h' directly. You should either move the file to this package or depend on an appropriate rule there.\r\nWARNING: /Users/Dan/Code/tensorflow/tensorflow/core/BUILD:826:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:pooling_ops_common.cc' directly. You should either move the file to this package or depend on an appropriate rule there.\r\nWARNING: /Users/Dan/Code/tensorflow/tensorflow/core/BUILD:826:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:pooling_ops_common.h' directly. You should either move the file to this package or depend on an appropriate rule there.\r\nWARNING: /Users/Dan/Code/tensorflow/tensorflow/core/BUILD:826:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:queue_base.h' directly. You should either move the file to this package or depend on an appropriate rule there.\r\nWARNING: /Users/Dan/Code/tensorflow/tensorflow/core/BUILD:826:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:queue_op.h' directly. You should either move the file to this package or depend on an appropriate rule there.\r\nWARNING: /Users/Dan/Code/tensorflow/tensorflow/core/BUILD:826:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:typed_queue.h' directly. You should either move the file to this package or depend on an appropriate rule there.\r\nWARNING: /Users/Dan/Code/tensorflow/tensorflow/core/BUILD:826:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_entry.h' directly. You should either move the file to this package or depend on an appropriate rule there.\r\nWARNING: /Users/Dan/Code/tensorflow/tensorflow/core/BUILD:826:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_scorer.h' directly. You should either move the file to this package or depend on an appropriate rule there.\r\nWARNING: /Users/Dan/Code/tensorflow/tensorflow/core/BUILD:826:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_beam_search.h' directly. You should either move the file to this package or depend on an appropriate rule there.\r\nWARNING: /Users/Dan/Code/tensorflow/tensorflow/core/BUILD:826:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_decoder.h' directly. You should either move the file to this package or depend on an appropriate rule there.\r\nWARNING: /Users/Dan/Code/tensorflow/tensorflow/core/BUILD:826:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/ctc:ctc_loss_util.h' directly. You should either move the file to this package or depend on an appropriate rule there.\r\nWARNING: /Users/Dan/Code/tensorflow/tensorflow/core/BUILD:826:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:naming.cc' directly. You should either move the file to this package or depend on an appropriate rule there.\r\nWARNING: /Users/Dan/Code/tensorflow/tensorflow/core/BUILD:826:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:naming.h' directly. You should either move the file to this package or depend on an appropriate rule there.\r\nWARNING: /Users/Dan/Code/tensorflow/tensorflow/core/BUILD:826:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:tensor_bundle.cc' directly. You should either move the file to this package or depend on an appropriate rule there.\r\nWARNING: /Users/Dan/Code/tensorflow/tensorflow/core/BUILD:826:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/util/tensor_bundle:tensor_bundle.h' directly. You should either move the file to this package or depend on an appropriate rule there.\r\nERROR: /private/var/tmp/_bazel_Dan/e9cc2fe61f735d74f6a33af534dffc47/external/bazel_tools/src/tools/android/java/com/google/devtools/build/android/incrementaldeployment/BUILD:3:1: in android_library rule @bazel_tools//src/tools/android/java/com/google/devtools/build/android/incrementaldeployment:incremental_stub_application: No Android SDK found. Use the --android_sdk command line option to specify one.\r\nERROR: Analysis of target '//tensorflow/examples/android:tensorflow_demo' failed; build aborted.\r\nINFO: Elapsed time: 7.929s\r\n```\r\n", "comments": ["@petewarden Are you still the right person for Android issues?", "@daj When you run `/Developer/Android/sdk/tools/android` do you see the specified build tools and  API installed?", "D'oh, it looks like I was missing the specific API level that I had specified in the WORKSPACE file.  My bad.\r\n![screen shot 2017-02-06 at 8 44 56 pm](https://cloud.githubusercontent.com/assets/739125/22674827/279d0e66-ecb0-11e6-97a1-5df9de45140b.png)\r\n\r\nIn hindsight the error message is pretty good, though it would be awesome if it said which specific SDK version was missing, e.g. `Android SDK version 23 not found`.  In my case I had almost all the other SDK versions installed, just not the one I had configured in the WORKSPACE file.\r\n\r\nI did have the right build tools version installed (showing screenshot here in case it helps future people who find this GitHub issue):\r\n![screen shot 2017-02-06 at 8 55 46 pm](https://cloud.githubusercontent.com/assets/739125/22674842/46c7209c-ecb0-11e6-8749-62cb33351942.png)\r\n\r\nIf there's a way I can improve the error message, let me know and I'll PR it (though if that requires a Bazel change then that might be beyond me!).", "@daj Great, glad you found it! Yeah, a more informative error message doesn't sound like a bad idea -- you could create an issue/send them a PR over at https://github.com/bazelbuild/bazel"]}, {"number": 7260, "title": "load_op_library don't see Ops", "body": "### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\nhttp://stackoverflow.com/questions/42019818/tensorflow-load-op-library-load-incorrectly?noredirect=1#comment71258436_42019818\r\n### Environment info\r\nOperating System: Linux Gentoo\r\n\r\nInstalled version of CUDA and cuDNN: \r\n-rw-r--r-- 1 root root 558632 Dec 28 08:08 /opt/cuda/lib64/libcudadevrt.a\r\nlrwxrwxrwx 1 root root     16 Dec 28 08:08 /opt/cuda/lib64/libcudart.so -> libcudart.so.8.0\r\nlrwxrwxrwx 1 root root     19 Dec 28 08:08 /opt/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\r\n-rwxr-xr-x 1 root root 415432 Sep 15 00:05 /opt/cuda/lib64/libcudart.so.8.0.44\r\n-rw-r--r-- 1 root root 774168 Dec 28 08:08 /opt/cuda/lib64/libcudart_static.a\r\n\r\nIf installed from binary pip package, provide:\r\nv 0.12.0\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n_actv_module = tf.load_op_library('<path>/actv.so')\r\nprint(_actv_module.OP_LIST)\r\n\r\nWhen act.so situated in some directories I see the list of Ops in it (as it should be).\r\nWhen I copy it to another directories list of Ops is empty. I can't find any reason why some directories are different from other. In both cases path is correct -- load_op_library is able to find file.\r\n\r\n### What other attempted solutions have you tried?\r\nI tried to copy source files to \"problem\" directories and compile it there (according to Adding new Op manual, compile with GPU support) -- with same results.\r\nMore strange -- I made a copy of all source files with another names, compiled it in \"normal\" directory, and load_op_library can't find Ops in it!\r\n\r\n### Logs or other output that would be helpful\r\nAttached: sources -- actv.cc, actv_kernel.cu.cc\r\nNormal libs -- actv.so, actv_kernel.cu.o\r\n\"Corrupted\" libs (in which load_op_library can't see any ops) -- actv_corrupted.so, actv_kernel_corrupted.cu.o\r\n[Archive.zip](https://github.com/tensorflow/tensorflow/files/752539/Archive.zip)\r\n\r\n\r\n\r\n\r\n\r\n", "comments": ["Presumably your `actv.so` file is linked against some other files in directory dependent way.  Try running `ldd actv.so` in both places and see if they're different.", "ldd returns equal list of links:\r\n        linux-vdso.so.1 (0x00007ffcaad4c000)\r\n\tlibstdc++.so.6 => /usr/lib/gcc/x86_64-pc-linux-gnu/4.9.4/libstdc++.so.6 (0x00007f9cf9533000)\r\n\tlibm.so.6 => /lib64/libm.so.6 (0x00007f9cf9234000)\r\n\tlibgcc_s.so.1 => /usr/lib/gcc/x86_64-pc-linux-gnu/4.9.4/libgcc_s.so.1 (0x00007f9cf901d000)\r\n\tlibc.so.6 => /lib64/libc.so.6 (0x00007f9cf8c81000)\r\n\t/lib64/ld-linux-x86-64.so.2 (0x000055d7b28ec000)\r\nThe only changes are in (0x000.....) (addresses?)\r\nInclude sections in source code:\r\nactv.cc:\r\n  #include \"tensorflow/core/framework/op.h\"\r\n  #include \"tensorflow/core/framework/shape_inference.h\"\r\n  #include \"tensorflow/core/framework/op_kernel.h\"\r\nactv_kernel.cu.cc:\r\n  #include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"", "@keveman Is it expected that the op library doesn't link against TensorFlow?", "Can anyone help?", "Automatically closing due to lack of recent activity. Since this issue is old at this point, please reopen the issue if it still occurs when tried with the latest version of Tensorflow. Thank you."]}, {"number": 7259, "title": "Configure script optimization flags don't work", "body": "The default optimization switches that are set when running the configure script do not change the compiler settings.  The values are put into the bazel.rc file.  They don't get into the gcc command line.  For example if I run ./configure with all of the default answers the optimization should be \"-march=native\".  I have tested this on multiple Ubuntu 16.04 systems with don't have CUDA.\r\n\r\nIf I then build the pip package with 'bazel build --c opt -s  ...' one example compile is this:\r\n\r\n> /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/local-opt/bin/external/farmhash_archive/_objs/farmhash/external/farmhash_archive/src/farmhash.pic.d '-frandom-seed=bazel-out/local-opt/bin/external/farmhash_archive/_objs/farmhash/external/farmhash_archive/src/farmhash.pic.o' -fPIC -iquote external/farmhash_archive -iquote bazel-out/local-opt/genfiles/external/farmhash_archive -iquote external/bazel_tools -iquote bazel-out/local-opt/genfiles/external/bazel_tools -isystem external/farmhash_archive/src -isystem bazel-out/local-opt/genfiles/external/farmhash_archive/src -isystem external/bazel_tools/tools/cpp/gcc3 -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -c external/farmhash_archive/src/farmhash.cc -o bazel-out/local-opt/bin/external/farmhash_archive/_objs/farmhash/external/farmhash_archive/src/farmhash.pic.o)\r\n\r\nIf I explicitly set the compile options with 'bazel build --c opt --copts=-march=native -s  ...' I get the correct results:\r\n\r\n> /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections **'-march=native'** '-std=c++0x' -MD -MF bazel-out/local-opt/bin/external/farmhash_archive/_objs/farmhash/external/farmhash_archive/src/farmhash.pic.d '-frandom-seed=bazel-out/local-opt/bin/external/farmhash_archive/_objs/farmhash/external/farmhash_archive/src/farmhash.pic.o' -fPIC -iquote external/farmhash_archive -iquote bazel-out/local-opt/genfiles/external/farmhash_archive -iquote external/bazel_tools -iquote bazel-out/local-opt/genfiles/external/bazel_tools -isystem external/farmhash_archive/src -isystem bazel-out/local-opt/genfiles/external/farmhash_archive/src -isystem external/bazel_tools/tools/cpp/gcc3 -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -c external/farmhash_archive/src/farmhash.cc -o bazel-out/local-opt/bin/external/farmhash_archive/_objs/farmhash/external/farmhash_archive/src/farmhash.pic.o)\r\n\r\nThe performance is slower for the first example.  Somehow the optimizations in bazel.rc are not getting through to the compiler command line.", "comments": ["You have to build with --config=opt rather than -c opt", "Thanks.  I didn't understand the explanation printed by the configure script.  It would help to have this explained in the manual.", "Would you like to send a pr to fix it?\n\nOn Feb 4, 2017 9:47 AM, \"Tom Baker\" <notifications@github.com> wrote:\n\n> Thanks. I didn't understand the explanation printed by the configure\n> script. It would help to have this explained in the manual.\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/7259#issuecomment-277462389>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AABaHGsoGNNuEZe8j13SYbhSZTw2a491ks5rZLmjgaJpZM4L3MlA>\n> .\n>\n", "BTW, here's the recipe I use for making pull requests\r\nhttps://gist.github.com/yaroslavvb/bdb0a92f2a516ebbe2d386c48f5e2c45", "We have updated our documentation, and configure script at head.\r\nBut I am happy to accept another change to either our docs or the explanation printed by configure script.", "@tbaker2 Are you happy with the change?  We'd be happy to accept clarifying PRs.", "I don't see where the changes are.  The only commit from @gunan that I see is about cuDNN library handling.  I would like to contribute more information about optimization.  It would help to have some feedback from the TensorFlow maintainers about what the default should be.  For example, why is '--config=opt' not recommended when building with the '-c opt' flag?  ", "`config=opt` was added in https://github.com/tensorflow/tensorflow/commit/c4e3d4a74e86fce3a09badd20952f067ff340f32 and documented in https://github.com/tensorflow/tensorflow/pull/7211\r\n\r\n-c opt means \"compilation mode=opt\"\r\n\r\nIf you do `--config=opt` and `-c opt`, you are adding `-c opt` option twice because it's one of the options added when you do `--config=opt`", "I see it now.  I was looking on the tensorflow.org site.  Everything looks good.", "It's on master version of \"Get Started/Os Setup\" -- https://www.tensorflow.org/versions/master/get_started/os_setup#optimizing_cpu_performance , which means it'll eventually be on tensorflow.org default version. Closing issue since it seems resolved"]}, {"number": 7258, "title": "Building a .dll on Windows", "body": "I have built libtensorflow.so with Bazel and used it successfully with the C Api in Ubuntu, however I was wondering if it is possible at all to use Bazel to build a .dll extension to use for Windows? As I want to integrate TensorFlow into an existing project. \r\n\r\nThanks in advance", "comments": ["/cc @asimshankar \r\nAt the moment, we have not tested building a dll in windows.", "might not be obvious: on top of building a such a dll, another thing is needed - the code in the dll would want to call say the c api that is in tensorflow.dll. On windows such public api's would need to be declared with dllexport so a new dll can link against tensorflow.dll and resolve references to the public api (for example the c api). Loading such a dll via tf.load_library() should kind of work on windows.", "Could someone provide a definitive statement about the status of linking to a TensorFlow library on Windows from a third-party application?  Some questions in particular:\r\n\r\n1. Is it possible to build a TensorFlow DLL on Windows?  If so, how?\r\n2. Is it possible to build a TensorFlow static library on Windows?  If so, how?\r\n3. If 1 or 2 is not possible what needs to change to make it possible?\r\n", "for 2:\r\nyes, there is an example here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cmake/tf_tutorials.cmake\r\nIts using mostly object files instead of a library because of the way tensorflow registers ops. \r\nThere is a static library generated here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cmake/tf_python.cmake#L692\r\nbut you'd need to link with /WHOLEARCHIVE to have op register correctly. pywrap_tensorflow_internal_static.lib includes the things python needs and for a standalone app you might need to add a few more things like tf_protos_cc, protobuf_STATIC_LIBRARIES ...\r\n\r\nfor 1:\r\nIn theory yes. This https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cmake/tf_python.cmake#L750 nearly does this but there are a few issues with it if you want to link this way. \r\nI think @vit-stepanovs was working on a tensorflow.dll that works out of the box.", "Thanks @guschmue!  That's very helpful.\r\n\r\nAnd do I have to build from source to get these?  They don't come as part of the binary distribution?", "[Look here for compiled libtensorflow.dll for Windows](https://github.com/tensorflow/tensorflow/issues/18)", "@luketg8 There are a few issues with using the DLL from the Python Windows package:\r\n\r\n1. It was implicitly linked with Python DLLs, so it expects Python DLLs to be present on the machine where you use it.\r\n2. It does not include some of the TF symbols that non-python programs might find useful, e.g. C++ API objects like Scope, Ops etc.\r\n\r\nAs @guschmue mentioned, I am currently working on CMake changes to build a stand-alone DLL with TensorFlow that addresses the two issues. I can already successfully build such DLL, but quite a few C++ tests fail when linked with it, which I am trying to address right now.\r\n", "Can anyone explain *why* the DLL and static library are not built by default?", "FYI, my PR #9124 adds support for building the DLL that does not depend on Python.", "@vit-stepanovs Am I right in thinking that in order to build this one needs to issue \r\n\r\n    MSBuild /p:Configuration=Release tensorflow.sln\r\n\r\n?", "@guschmue, I could build 2 with VS2015 & cmake (no bazel), but **no session factories are registered at runtime**. I could build & run tf_label_image_example, but when I used the same includes & links in my own soft, it crashes with \r\n`\\tensorflow\\tensorflow\\core\\common_runtime\\session.cc:58] Not found: No session factory registered for the given session options: {target: \"\" config: } Registered factories are {}.` \r\n\r\nCurrently the /WHOLEARCHIVE option make VS crashes with \"fatal error LNK1000: Internal error during CImplib::EmitThunk\". I could avoid it by specifying a library as in\r\n`/WHOLEARCHIVE:tf_core_direct_session`\r\nBut it does not work either (maybe it is not the right library?).\r\nAs tf_label_image_example does not use /WHOLEARCHIVE at all, I am wondering if it is the right option to use?\r\n\r\nI understand that factories are registered through global variables as in \r\n` static DirectSessionRegistrar registrar;` \r\n\r\nIs there another way to force such registration? \r\nOr does anyone understand why these symbols are discarded?\r\nWith VS it is not possible to control the order of globals' instantiation, but it should not be the case here!", "The problem with with registration is that nothing in the file is referenced from outside the file so the linker drops it. The regular build does with by giving the linker the object files and not the library.  /WHOLEARCHIVE is suppose to do the same but I did not expect it to crash - maybe check that you are using the 64bit version of link.exe ('where link.exe' should tell).\r\nUsing the object files as in the example:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cmake/tf_tutorials.cmake\r\nis the better way because you have more control over what goes into your exe.", "@tomjaguarpaw, the actual option name is tensorflow_BUILD_SHARED_LIB, not BUILD_SHARED_LIB. If you use that, cmake generates a project tensorflow.vcxproj (not tensorflow.sln!) which you can use to build the DLL.", "@vit-stepanovs Thank you.  `cmake` did not complain when I used `-DBUILD_SHARED_LIB` so I assumed that was the correct option.  Perhaps it's a different option provided by default by `cmake`.", "@vit-stepanovs Thanks for the PR. What's the size of the resulting DLL? Assuming it's on the larger side, are there any plans to allow it to be smaller? For example there's [this discussion](http://stackoverflow.com/questions/41400873/how-to-reduce-tensorflow-size-for-android) about how we can reduce tensorflow's .so size on Android.", "@mikejohnstn When I built the DLL it was 44MB.", "Anybody hosting the built DLL?", "We're now building the C library ([`c_api.h`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/c/c_api.h) and `tensorflow.dll`) for Windows. This won't contain the C++ API, but should be sufficient for other language bindings like C#.\r\n\r\nThis will be part of release 1.2 onwards, but in case anyone wants to give it a spin in the meantime, try the nightly build artifacts at:\r\nhttp://ci.tensorflow.org/view/Nightly/job/nightly-libtensorflow-windows/lastSuccessfulBuild/artifact/lib_package/libtensorflow-cpu-windows-x86_64.zip\r\n", "@asimshankar Great! I have just tested it using [TensorFlowSharp](/migueldeicaza/TensorFlowSharp) with no issue.", "OK so after all this, is there any documentation on how one would train a network in python, then consume it (as in run the trained model to classify something) from C++?  From what I understand, I would save the graph to file, then add tensorflow.dll as a dependency in my application and load the graph using the c_api.h ? Is that right? ", "@gemmell: I would also like to do this in the near future.  This is the \"best\" reference I have found so far: http://stackoverflow.com/questions/41070330/is-it-possible-to-use-tensorflow-c-api-on-windows/41071296#41071296\r\n\r\nIt would be useful to have a more detailed and precise one.", "What about GPU support?", "Automatically closing due to lack of recent activity. Since this issue is old at this point, please reopen the issue if it still occurs when tried with the latest version of Tensorflow. Thank you.", "I made [a script to build Tensorflow C++ API using Bazel on Windows](https://github.com/guikarist/tensorflow-windows-build-script). It made it easier to build Tensorflow on Windows (which also supports building pip packages or C API). But I believe there will be better solutions and I hope everyone with same trouble could join me!\r\n\r\nIf you need `.dll` files, you should only rename `bazel-bin\\tensorflow\\libtensorflow_cc.so` to `tensorflow_cc.dll`. **and** `bazel-bin\\tensorflow\\liblibtensorflow_cc.so.ifso` to `tensorflow_cc.lib`.", "@guikarist Thanks for your effort! Unfortunately, none of my unresolved symbol errors disappeared. I updated the `BUILD` file as well as the `tf_exported_symbols_msvc.lds`.\r\n\r\nAny idea what could be wrong?\r\n\r\nHere the part from the `BUILD` file, would be nice if you could have a quick look:\r\n\r\n```\r\ntf_cc_shared_object(\r\n    name = \"libtensorflow_cc.so\",\r\n    linkopts = select({\r\n        \"//tensorflow:darwin\": [\r\n            \"-Wl,-exported_symbols_list\",  # This line must be directly followed by the exported_symbols.lds file\r\n            \"$(location //tensorflow:tf_exported_symbols.lds)\",\r\n        ],\r\n        \"//tensorflow:windows\": [\r\n\t\t\t\"-def:\" +  # This line must be directly followed by the exported_symbols_msvc.lds file\r\n\t\t\t\"$(location //tensorflow:tf_exported_symbols_msvc.lds)\",\r\n\t\t],\r\n        \"//conditions:default\": [\r\n            \"-z defs\",\r\n            \"-Wl,--version-script\",  #  This line must be directly followed by the version_script.lds file\r\n            \"$(location //tensorflow:tf_version_script.lds)\",\r\n        ],\r\n    }),\r\n    visibility = [\"//visibility:public\"],\r\n    deps = [\r\n        \"//tensorflow:tf_exported_symbols.lds\",\r\n\t\t\"//tensorflow:tf_exported_symbols_msvc.lds\",\r\n        \"//tensorflow:tf_version_script.lds\",\r\n        \"//tensorflow/c:c_api\",\r\n        \"//tensorflow/c/eager:c_api\",\r\n        \"//tensorflow/cc:cc_ops\",\r\n        \"//tensorflow/cc:client_session\",\r\n        \"//tensorflow/cc:scope\",\r\n        \"//tensorflow/cc/profiler\",\r\n        \"//tensorflow/core:tensorflow\",\r\n    ] + if_ngraph([\"@ngraph_tf//:ngraph_tf\"]),\r\n)\r\n\r\nexports_files(\r\n    [\r\n        \"tf_version_script.lds\",\r\n        \"tf_exported_symbols.lds\",\r\n\t\t\"tf_exported_symbols_msvc.lds\",\r\n    ],\r\n)\r\n```", "@mnboos Have you added your unresolved symbols into `patches\\tf_exported_symbols_msvc.lds`?", "Yes. Some of the errors even were symbols, that already were existent in this file. It looks like somehow this file is being ignored. On the other hand, after every change of this file and starting the build of tensorflow, it will link the libtensorflow_cc.so.\r\n\r\nI also had a look at the exported symbols of the `libtensorflow_cc.so` and they seem to be exported correctly, at least according to `dumpbin /exports libtensorflow_cc.so`.", "@mnboos Maybe we'd better dicuss it in [an issue of my repo](https://github.com/guikarist/tensorflow-windows-build-script/issues/2).", "> I made [a script to build Tensorflow C++ API using Bazel on Windows](https://github.com/guikarist/tensorflow-windows-build-script). It made it easier to build Tensorflow on Windows (which also supports building pip packages or C API). But I believe there will be better solutions and I hope everyone with same trouble could join me!\r\n> \r\n> If you need `.dll` files, you should only rename `bazel-bin\\tensorflow\\libtensorflow_cc.so` to `tensorflow_cc.dll`. **and** `bazel-bin\\tensorflow\\liblibtensorflow_cc.so.ifso` to `tensorflow_cc.lib`.\r\n@guikarist \r\nThanks a lot."]}, {"number": 7257, "title": "Feature request: Please provide AVX2/FMA capable builds", "body": "I would go out on a limb and guess that the vast majority of Tensorflow users on Linux at least use fairly modern CPUs. It would therefore be beneficial for them to have the prebuilt TF binaries support AVX2/FMA. These two ISA extensions, and especially FMA, tend to speed up GEMM-like math pretty significantly.\r\n\r\nIt'd be great if TF team provided prebuilt Linux release *.whl that supports AVX2/FMA, perhaps as an alternative, non-default wheel. These should be compatible with Haswell and above. Haswell came out in 2013, lots of people have it by now.\r\n\r\nTo be clear, this is not a hugely pressing issue, `*.whl` can be easily rebuilt from source. It'd just make things faster and easier for people with modern CPUs.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\nN/A\r\n\r\n### Environment info\r\nOperating System:\r\nLinux Ubuntu 16.04\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`): NONE\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed: `https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.0.0rc0-cp35-cp35m-linux_x86_64.whl`\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`: `1.0.0-rc0`\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\nCode:\r\n```\r\nimport tensorflow as tf\r\nsess = tf.InteractiveSession()\r\n```\r\n\r\nOutput:\r\n```\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\nW tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n```\r\n\r\n### What other attempted solutions have you tried?\r\n\r\nCompiled from source.\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n", "comments": ["As a performance datapoint, this matrix multiplication benchmark goes 0.31 Tops/sec -> 1.05 Tops/sec when enabling avx2/fma on our Intel Xeon 3 @ 2.4 Ghz servers: https://github.com/yaroslavvb/stuff/blob/master/matmul_bench.py\r\n\r\nOn the other hand, there may be technical issues with infrastructure that make it hard to setup such a build. @caisq for comment", "+@gunan\r\n\r\nI believe our tooling and CI machines have the capacity to run bazel build with `--copt=-mavx2` and `--copt=-mfma`. Gunhan, what do you think of expanding the nightly and release matrices to support those build options? My sense is that we are already a little constrained in terms of the machine resource and manpower to fix breakages.", "This was discussed before, and the decision was to make the released binaries work for everyone.\r\nWhile it is very easy for users to upgrade personal computers, many cloud providers or thousands of machines take longer to upgrade. With 0.12, we tried to enable avx and sse4.1, but we had to roll it back because it is not as common for AMD CPUs to have sse 4.1 as intel CPUs.\r\n\r\nSo, we decided this to be our policy about SIMD instruction sets going forward:\r\n1 - Our released binaries will be as portable as possible, working out of the box on most of the machines.\r\n2 - For people who need the best TF performance, we recommend building from sources. We will make sure things build well, and building from sources is as easy as possible, but rather than supporting a a new binary package for 10s of CPU architectures out in the wild, we decided the best would be to let users build binaries as needed.", "Since Intel is getting involved, perhaps they would be willing to maintain an Intel-optimized build of TensorFlow? cc @mahmoud-abuzaina in case he has some connections", "IIRC only Microsoft uses AMD CPUs in the cloud and those are on their way\nout. The proposal is not to make this the new default whl. The proposal is\nto pre-build binaries for Haswell and above as a second wheel set. Just\nbuild them with the same settings you build the regular whls but say -mavx2\nand -mfma and throw them into the cloud bucket. That's what users will do\nwhen building their own from source. Why not save them the aggravation and\nhalf an hour of their time? It adds up.\n\nOn Mon, Feb 6, 2017 at 10:25 AM, gunan <notifications@github.com> wrote:\n\n> This was discussed before, and the decision was to make the released\n> binaries work for everyone.\n> While it is very easy for users to upgrade personal computers, many cloud\n> providers or thousands of machines take longer to upgrade. With 0.12, we\n> tried to enable avx and sse4.1, but we had to roll it back because it is\n> not as common for AMD CPUs to have sse 4.1 as intel CPUs.\n>\n> So, we decided this to be our policy about SIMD instruction sets going\n> forward:\n> 1 - Our released binaries will be as portable as possible, working out of\n> the box on most of the machines.\n> 2 - For people who need the best TF performance, we recommend building\n> from sources. We will make sure things build well, and building from\n> sources is as easy as possible, but rather than supporting a a new binary\n> package for 10s of CPU architectures out in the wild, we decided the best\n> would be to let users build binaries as needed.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/7257#issuecomment-277768292>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AX6E09Lzc-Di7h10CqOSdku6bGR6LUFqks5rZ2WPgaJpZM4L3Fgv>\n> .\n>\n", "@dmitry-xnor I guess the issue here is limited resources at Google. Releasing an official wheel with a new configuration means you have to support it and fix issues that arise. I have seen some subtle alignment issues caused by enabling avx2, so troubleshooting such things can take time. And if you don't fix them, people get mad at Google, since the release is \"official\". Also, this sets a precedent for supporting a \"highly optimized\" binary + \"lowest common denominator\" binary, and the standard of \"highly optimized binary\" can shift over time. I do agree that it would be nice to have an Intel-specific build that's highly optimized.\r\n\r\nI'm currently getting around this lack it by launching \"build --config=opt --config=cuda\" builds weekly and dropping resulting wheel in a shared folder for other users in our company.", "@dmitry-xnor now to think of it, I could probably drop such binaries into a public shared folder as well, as I'm going through my build process. I'm building with `--config=opt --config=cuda` with CUDA 8.0 on `Intel(R) Xeon(R) CPU E5-2630 v3 @ 2.40GHz` from Cirrascale which seems like a common configuration. The downside is that I don't have time to setup cloud storage/ research uploading, but if someone gave me an easy recipe to follow, I could do that.", "Do you build as yourself interactively or is this an automated build? If you build as yourself, the solution is easily scriptable. Create a GCS bucket for binaries once, then just upload stuff there for every release and make it public like so, using gsutil:\r\n\r\n`gsutil cp $TENSORFLOW_WHL gs://<bucket name>/`\r\n`gsutil acl set public-read gs://<bucket name>/$TENSORFLOW_WHL`\r\n\r\nAnd publish the resulting download URL somewhere. Note also that you should not rename the WHL or else pip3 will barf.", "thanks, I'll give it a shot on the next build", "Sounds great, thanks! Looking forward to prebuilt WHLs! It just doesn't make sense to use the CPU at 1/3rd the speed. \ud83d\udc4d ", "I have just launched a new website for this purpose: [TensorFlow Community Wheels](https://github.com/yaroslavvb/tensorflow-community-wheels). Fully integrated with github.", "Hey guys,\r\nneed to dig some deeper into this thread, but to expedite things some thoughts here in advance:\r\n\r\n1) Am I mistaken? As far as I saw / understood on my machine there is not even optimization for SSE1? How about cutting off CPUs of a certain age / SSE for the default distribution?! (Naturally I'd appreciate a community effort for a finer-grained optimization offering!!)\r\n\r\n2) Do you have any insight how XLA / JIT / AOT announced last Wednesday (2017-02-15) comes to the rescue?\r\n\r\nTIA\r\nG.", "Yaroslav has created a repo with links to unofficial builds. TF proper is\nunderstandably concerned about the support burden such backward\nincompatible change would create (i.e. you fire up TF on an old AMD machine\nand it gives you \"invalid instruction\"). I think Yaroslav's soluion is a\ngood middle ground, with the possible benefit of e.g. Ryzen specific builds\nalso appearing in the coming months.\n\nOn Mon, Feb 20, 2017 at 12:58 PM, gue22 <notifications@github.com> wrote:\n\n> Hey guys,\n> need to dig some deeper into this thread, but to expedite things some\n> thoughts here in advance:\n>\n>    1.\n>\n>    Am I mistaken? As far as I saw / understood on my machine there is not\n>    even optimization for SSE1? How about cutting off CPUs of a certain age /\n>    SSE for the default distribution?! (Naturally I'd appreciate a community\n>    effort for a finer-grained optimization offering!!)\n>    2.\n>\n>    Do you have any insight how XLA / JIT / AOT announced last Wednesday\n>    (2017-02-15) comes to the rescue?\n>\n> TIA\n> G.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/7257#issuecomment-281179574>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AX6E0990riGntEb9EEWHJ7x3VZhgalZ1ks5ref54gaJpZM4L3Fgv>\n> .\n>\n", "Any suggestion for users of the TF docker images? These image have TF pre-installed.", "If you are using docker, you should be able to download devel docker images\nand install from sources that are already on docker images.\n\nOn Feb 28, 2017 4:22 PM, \"Alex Rothberg\" <notifications@github.com> wrote:\n\nAny suggestion for users of the TF docker images? These image have TF\npre-installed.\n\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub\n<https://github.com/tensorflow/tensorflow/issues/7257#issuecomment-283204412>,\nor mute the thread\n<https://github.com/notifications/unsubscribe-auth/AHlCOb0Y7ZlLY0dUP5k_PrCUSJUoiQEXks5rhLoxgaJpZM4L3Fgv>\n.\n", "I am using the GPU devel docker images, but right now I am just \"using them\" without rebuilding / reinstalling.\r\n\r\nIt is worth considering how far back in SSE instructions is reasonable to handle when dealing with a machine that needs to have CUDA compute >= 3.0 (for the gpu images or gpu wheels).", "SSE was causing problems for people running on AMD CPU -- https://github.com/tensorflow/tensorflow/issues/6809", "after upgrading to 1.0 I found the OSX prebuilt version lacked SSE, FMA and AVX support. after searching around for a while there's no alternative except to build it myself. Well then, i'll build it myself.", "@yaroslavvb created this repository to link to community supported wheel files.\r\nhttps://github.com/yaroslavvb/tensorflow-community-wheels\r\n\r\nWe encourage our community creating and maintaining specialized builds, but we will be creating wheel files that are installable in most platforms. Therefore, I will close this issue.", "For example, the glibc library is designed to work anywhere, and has mechanisms to detect the availability of advanced instruction sets and use the proper functions to take advantage of them when they're available, and fall back if they're not. It's not necessary to support a separate binary for every possible processor capability.\r\n\r\nIntel Performance Primitives: https://software.intel.com/en-us/articles/intel-integrated-performance-primitives-intel-ipp-is-there-any-function-to-detect-processor-type\r\n\r\nLinux Function Multi-Versioning (FMV):\r\nhttps://clearlinux.org/features/function-multiversioning-fmv", "Here's a LWN article on the FMV capabilities provided for C++ in GCC 4.8 and up, and for C in GCC 6:\r\n\r\nhttps://lwn.net/Articles/691932/", "I built these for OS X, with FMA and friends.\r\nhttps://github.com/ctmakro/tensorflow_custom_python_wheel_build", "> @gunan For user needing best performance ... build from sources ...\r\n\r\n> We will make sure things build well, and building from sources is as easy as possible\r\n\r\nThat would be acceptable, if there was an _easy_ way of building Tensorflow on Windows. Apparently, there isn't: [People try](https://stackoverflow.com/questions/42603407/how-to-compile-tensor-flow-with-sse-and-and-avx-instructions-on-windows/42755665#42755665) but the [official documentation](https://www.tensorflow.org/install/install_sources) on that clearly states that Windows is currently not supported. So it would be very valuable, if there were optimized builds available or you could follow up on @mvpel's suggestion on detecting cpu and enabling optimizations dynamically. Meanwhile, I will try to follow the instructions from [here](https://github.com/tensorflow/tensorflow/tree/r1.1/tensorflow/contrib/cmake)", "FYI: Following up on my last comment, I built the GPU-Version of Tensorflow with CPU-Optimizations (AVX) enabled and I couldn't see much performance improvements on my side, so I will stick to the pre-build GPU-version that can be installed using `pip install tensorflow-gpu==1.1.0`", "@apacha From my experiments I found CPU-optimized GPU TF doesn't boost the performance significantly, but it can make the CPU cooler. My processor's temperature often goes up to 80C during training, while the optimized TF usually keeps the temp. below 70C.", "@xinyazhang - that can have performance implications, albeit slight, since CPUs will throttle their frequency if they are pushed into the upper limits of their temperature range for too long.\r\n\r\n@apacha - There's not much point to vector instructions in a GPU-enabled TF runs, since the work that would be done by those instructions in the CPU is done in the GPU much more quickly, and so the fact that there's little performance improvement with AVX on a GPU-based run is to be expected.\r\n\r\nThe basic idea is that there's far more machines out there with AVX, AVX2, SSE, etc. than there are with GPUs, and they're much cheaper to rent in the cloud (an AWS c4.large with AVX2 is 10 cents per hour, while the smallest GPU instance p2.xlarge is 90 cents an hour), so wringing out every last bit of CPU performance potential for non-GPU runs can be of benefit provided that a TF job on c4.large doesn't take 9 times longer than on p4.xlarge.", "@mvpel \"There's not much point to vector instructions in a GPU-enabled TF runs\"\r\n\r\nCPU is very much a bottleneck with today's faster GPUs on certain models. Typically for e.g. computer vision problems you need to do a bunch of data decoding and augmentation, much of which can't be done on the GPU. This is actually a major problem we had with TF for multi-GPU training. Things were so bad (even _with_ AVX2 and FMA enabled) that we switched to using PyTorch _just_ for data augmentation in our TF pipelines. For what we do, it was an easy 40% throughput gain right off the bat, and code was quite a bit simpler too.\r\n\r\nThe point is: GPUs are specialized devices, and while they are powerful, they are not really usable for everything. Things are pretty bad even now for high throughput tasks, and I imagine they'll get much worse when we TPUs and NVIDIA V100 GPUs become available.", "For anyone looking for optimized builds, we maintain a bunch of these at TinyMind that you can find at https://github.com/mind/wheels.\r\n\r\nThere are both CPU and GPU builds for all versions post TF1.1. Enjoy :)", "@gunan Why the TF team cannot official maintain some alternative builds like suggested in  the previous comment? ", "@bhack it's a business level decision (what's the best use of Google engineer time?). Providing custom hardware builds is possible by people outside of Google, but there are many Tensorflowy things that can only be done by Googlers.\r\n\r\nPS: whole \"bake AVX2 into binary\" is not that great for open-source ecosystem -- TensorFlow would be better off with dynamic dispatch system like what's used by PyTorch, MKL. ", "I don't think that there is so much effort required other than hardware resources cause I think that AVX2 code paths are still tested in the matrix. When code is tested, and so builded, i think that it is quite automatic to publish it. But never mind, Intel is already [maintaining optimized builds](https://anaconda.org/intel/tensorflow) with a sort of delay over the official upstream releases.", "I don't how that Intel build works -- does it/conda automatically figure out which instruction sets your machine has and get the proper version? Or it just automatically pushes XeonV4 optimized build?\r\n\r\nThis wasn't an issue with MKL because MKL has dynamic dispatch, but TF has to have advanced instructions statically baked in there", "The only available info are at https://software.intel.com/en-us/articles/tensorflow-optimizations-on-modern-intel-architecture", "At any rate, feel free to use [the wheels I posted above](https://github.com/mind/wheels) @bhack - we rely on these ourselves so we will keep maintaining them. :)", "How can make the tensrflow installed on my machine to compile SSE, AVX, FMA instructions?", "If you use ubuntu 16.04, check out the link I posted above (https://github.com/mind/wheels) - there you can find the version you want as well as how to install it.", "I have tensorflow wheels for a few different configurations at https://github.com/lakshayg/tensorflow-build"]}, {"number": 7256, "title": "couldn't find \"libtensorflow_demo.so\"", "body": "Hi All: \r\n  I'm a newbie on trying out tensorflow in Android,\r\nby following the guildline to build the libtensorflow_demo.so,  I new a folder \"libs\" to put this so file in folder \"tensorflow/examples/android/libs\"\r\n\r\n    sourceSets {\r\n        main {\r\n            manifest.srcFile 'AndroidManifest.xml'\r\n            java.srcDirs = ['src', '../../contrib/android/java']\r\n            resources.srcDirs = ['src']\r\n            aidl.srcDirs = ['src']\r\n            renderscript.srcDirs = ['src']\r\n            res.srcDirs = ['res']\r\n            assets.srcDirs = ['assets']\r\n            jniLibs.srcDirs = ['libs']\r\n        }\r\n\r\nhowever when app's running, it still can not find this lib.\r\nany idea for resolving is appreciated\r\n\r\n### Environment info\r\nOperating System: Mac (CPU)\r\n\r\nProcess: org.tensorflow.demo, PID: 2401\r\n                                                                   java.lang.UnsatisfiedLinkError: com.android.tools.fd.runtime.IncrementalClassLoader$DelegateClassLoader[DexPathList[[dex file \"/data/data/org.tensorflow.demo/files/instant-run/dex/slice-slice_9-classes.dex\", dex file \"/data/data/org.tensorflow.demo/files/instant-run/dex/slice-slice_8-classes.dex\", dex file \"/data/data/org.tensorflow.demo/files/instant-run/dex/slice-slice_7-classes.dex\", dex file \"/data/data/org.tensorflow.demo/files/instant-run/dex/slice-slice_6-classes.dex\", dex file \"/data/data/org.tensorflow.demo/files/instant-run/dex/slice-slice_5-classes.dex\", dex file \"/data/data/org.tensorflow.demo/files/instant-run/dex/slice-slice_4-classes.dex\", dex file \"/data/data/org.tensorflow.demo/files/instant-run/dex/slice-slice_3-classes.dex\", dex file \"/data/data/org.tensorflow.demo/files/instant-run/dex/slice-slice_2-classes.dex\", dex file \"/data/data/org.tensorflow.demo/files/instant-run/dex/slice-slice_1-classes.dex\", dex file \"/data/data/org.tensorflow.demo/files/instant-run/dex/slice-slice_0-classes.dex\"],nativeLibraryDirectories=[/data/app/org.tensorflow.demo-1/lib/x86_64, /system/lib64, /vendor/lib64]]] couldn't find \"libtensorflow_demo.so\"\r\n                                                                       at java.lang.Runtime.loadLibrary0(Runtime.java:984)\r\n                                                                       at java.lang.System.loadLibrary(System.java:1530)\r\n", "comments": ["Are you following the instructions outlined in https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android ?\r\n\r\nThat suggests the use of `bazel build` to build the demo, and has some instructions for using Android Studio as well. Are you following those?\r\n\r\nIf you're using a custom setup, then perhaps you want to add some more detail on your setup and post your question on stackoverflow?", "Yes,  I use Android Studio 2.2.3 to import tensorflow project,\r\nand follow the instructions listed in this page,\r\nand also use command line below to build the apk\r\nbazel build -c opt //tensorflow/examples/android:tensorflow_demo\r\n\r\nthen run this project, the error \"couldn't find libtensorflow_demo.so\" appears...\r\nafter refering to some suggestions, I new a folder \"libs\" and put so file in, but the problem is still there..\r\n\r\nthanks", "So the `bazel build -c opt //tensorflow/examples/android:tensorflow_demo` succeeds?\r\nCan you manually install the `.apk` using\r\n\r\n`adb install -r <path_to_apk_printed_by_bazel_build>`\r\n?\r\n\r\nDoes that work?", "Hi:\r\n I think the \"bazel build\" is successful for it didn't come out build error and finally shown build result as below\r\n\r\nINFO: Found 1 target...\r\nTarget //tensorflow/examples/android:tensorflow_demo up-to-date:\r\n  bazel-bin/tensorflow/examples/android/tensorflow_demo_deploy.jar\r\n  bazel-bin/tensorflow/examples/android/tensorflow_demo_unsigned.apk\r\n  bazel-bin/tensorflow/examples/android/tensorflow_demo.apk\r\nINFO: Elapsed time: 25.941s, Critical Path: 8.17s\r\n\r\nHOWEVER, it did fail in adb install this apk, with error below\r\nFailed to install bazel-bin/tensorflow/examples/android/tensorflow_demo.apk: Failure [INSTALL_FAILED_NO_MATCHING_ABIS: Failed to extract native libraries, res=-113]\r\n", "That seems like the native library is being [built for a different architecture](http://stackoverflow.com/questions/24572052/install-failed-no-matching-abis-when-install-apk).\r\n\r\nDid you setup the `WORKSPACE` file with the appropriate SDK/NDK.\r\nAlso, you might want to try with:\r\n\r\n`bazel build -c opt --config=android_arm //tensorflow/examples/android:tensorflow_demo`\r\n(notice the `--config=android_arm`)", "Hi:\r\n Yes, the SDK/NDK path is already configured, and if the \"bazel\" command line has \"x86\" build config ?\r\n\r\nbecause I'm using x86 Android emulator...(run faster the arm version ^_^)\r\n\r\nPS: when I use ARM ver emulator, the so lib can be found", "The CPU type that gets built for in Android Studio/Gradle builds is defined here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/build.gradle#L10\r\n\r\nThe default is armeabi-v7a, so if you're running in an x86 emulator you'll need to change that accordingly.", "Thanks, but I can not figure out which cpu type to specify, will it look like below \r\nbazel build -c opt --config=x86 //tensorflow/examples/android:tensorflow_demo\r\n\r\nI tried but seems still not build \"x86\" version lib ", "What's the log output when you try that? There are no .so files placed under bazel-bin?", "I use the command below\r\n1. bazel clean\r\n2. bazel build -c opt --config=x86 //tensorflow/examples/android:tensorflow_demo\r\n3. sudo find / ./ -name libtensorflow_demo.so\r\n\r\nthe search result is below, where I didn't notice the \"x86\" version is generated ?!\r\nand not found any so file under bazel-bin.\r\n\r\n/private/var/tmp/_bazel_ycw/a122119f088e17a4855898206da17645/execroot/tensorflow/bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-opt/bin/_solib_armeabi-v7a/_U_S_Stensorflow_Sexamples_Sandroid_Ctensorflow_Unative_Ulibs___Utensorflow_Sexamples_Sandroid/libtensorflow_demo.so\r\n/private/var/tmp/_bazel_ycw/a122119f088e17a4855898206da17645/execroot/tensorflow/bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-opt/bin/tensorflow/examples/android/_objs/libtensorflow_demo.so\r\n/private/var/tmp/_bazel_ycw/a122119f088e17a4855898206da17645/execroot/tensorflow/bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-opt/bin/tensorflow/examples/android/libtensorflow_demo.so\r\n/private/var/tmp/_bazel_ycw/a122119f088e17a4855898206da17645/execroot/tensorflow/bazel-out/local-opt/bin/tensorflow/examples/android/_dx/tensorflow_demo/native_symlinks/armeabi-v7a/libtensorflow_demo.so\r\n/Users/ycw/tensorflow/tensorflow/examples/android/gradleBuild/intermediates/jniLibs/debug/libtensorflow_demo.so\r\n.//tensorflow/examples/android/gradleBuild/intermediates/jniLibs/debug/libtensorflow_demo.so", "Oh, you actually need to use the --cpu flag, not config.\r\n\r\nbuild.gradle already uses that, though -- are you sure that doesn't work when you modify the CPU type?", "HI:\r\nIn bazel command line, no matter I set the --cpu to ios_x86_64 or darwin,\r\nafter tensorflow_demo.apk built and unzip it to check, the so file is always located in \"armeabi-v7a\"\r\n\r\nlib/armeabi-v7a/libtensorflow_demo.so \r\n\r\nis it normal ?", "You don't want to build for iOS if you're targeting Android. The cpu value is x86, but you also need to pass the crosstool flags described in the instructions at https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/android\r\n\r\nAnd to clarify, have you tried modifying build.gradle to set the cpu to x86, and then building from *within* Android Studio yet?", "Hi:\r\n I modify the cpu type as \"x86_64\" of gradle file below, and run \"Build APK\" in \"Build\" menu.\r\n\r\nit appears error below..\r\nError:(63) Error: This fragment should provide a default constructor (a public constructor with no arguments) (org.tensorflow.demo.CameraConnectionFragment) [ValidFragment]\r\n\r\nthe SDK ver is 25", "Seems that newer SDK levels require a default constructor: http://stackoverflow.com/questions/29762949/error-this-fragment-should-provide-a-default-constructor-a-public-constructor\r\n\r\nYou can try adding a default constructor (or just lower your target API level)l. Feel free to send a PR with the fix if this addresses the issue for you, thanks.", "Hi:\r\n  I add \"checkReleaseBuilds false\" below to resolve the \"default constructor\" issue,\r\n    lintOptions {\r\n        abortOnError false\r\n        checkReleaseBuilds false\r\n    }\r\n\r\n  and finally the \"libtensorflow_demo.so\" can be loaded in x86 emulator.\r\n\r\n However once launch the demo app, the error occurs ,\r\nand I'm not sure if it's because the x86 issue or not ?!\r\n\r\n02-05 22:48:47.447 4814-4814/? I/art: Not late-enabling -Xcheck:jni (already on)\r\n02-05 22:48:47.447 4814-4814/? W/art: Unexpected CPU variant for X86 using defaults: x86_64\r\n02-05 22:48:47.547 4814-4814/org.tensorflow.demo D/tensorflow: CameraActivity: onCreate org.tensorflow.demo.ClassifierActivity@321f567\r\n02-05 22:48:47.577 4814-4814/org.tensorflow.demo D/tensorflow: CameraActivity: onStart org.tensorflow.demo.ClassifierActivity@321f567\r\n02-05 22:48:47.578 4814-4814/org.tensorflow.demo D/tensorflow: CameraActivity: onResume org.tensorflow.demo.ClassifierActivity@321f567\r\n02-05 22:48:47.835 4814-4836/org.tensorflow.demo I/OpenGLRenderer: Initialized EGL, version 1.4\r\n02-05 22:48:47.835 4814-4836/org.tensorflow.demo D/OpenGLRenderer: Swap behavior 1\r\n02-05 22:48:47.936 4814-4836/org.tensorflow.demo E/EGL_emulation: tid 4836: eglSurfaceAttrib(1174): error 0x3009 (EGL_BAD_MATCH)\r\n02-05 22:48:47.936 4814-4836/org.tensorflow.demo W/OpenGLRenderer: Failed to set EGL_SWAP_BEHAVIOR on surface 0x75969760d940, error=EGL_BAD_MATCH\r\n02-05 22:48:47.943 4814-4814/org.tensorflow.demo I/CameraManagerGlobal: Connecting to camera service\r\n02-05 22:48:47.973 4814-4814/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Adding size: 640x480\r\n02-05 22:48:47.973 4814-4814/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 352x288\r\n02-05 22:48:47.973 4814-4814/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 320x240\r\n02-05 22:48:47.973 4814-4814/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Chosen size: 640x480\r\n02-05 22:48:48.009 4814-4814/org.tensorflow.demo I/TensorFlowImageClassifier: Reading labels from: imagenet_comp_graph_label_strings.txt\r\n02-05 22:48:48.012 4814-4814/org.tensorflow.demo D/AndroidRuntime: Shutting down VM\r\n02-05 22:48:48.016 4814-4814/org.tensorflow.demo E/AndroidRuntime: FATAL EXCEPTION: main\r\n                                                                   Process: org.tensorflow.demo, PID: 4814\r\n                                                                   java.lang.RuntimeException: Error initializing TensorFlow!\r\n                                                                       at org.tensorflow.demo.ClassifierActivity.onPreviewSizeChosen(ClassifierActivity.java:135)\r\n                                                                       at org.tensorflow.demo.CameraActivity$1.onPreviewSizeChosen(CameraActivity.java:158)\r\n                                                                       at org.tensorflow.demo.CameraConnectionFragment.setUpCameraOutputs(CameraConnectionFragment.java:394)\r\n                                                                       at org.tensorflow.demo.CameraConnectionFragment.openCamera(CameraConnectionFragment.java:411)\r\n                                                                       at org.tensorflow.demo.CameraConnectionFragment.access$000(CameraConnectionFragment.java:63)\r\n                                                                       at org.tensorflow.demo.CameraConnectionFragment$1.onSurfaceTextureAvailable(CameraConnectionFragment.java:94)", "(Followed)\r\nwhen set cpu = armeabi-v7a and using \"arm\" version emulator,\r\nthe below error also occur..\r\n\r\n02-05 23:13:02.691 4190-4190/org.tensorflow.demo I/art: Not late-enabling -Xcheck:jni (already on)\r\n02-05 23:13:02.695 4190-4190/org.tensorflow.demo W/art: Unknown instruction set features for ARM CPU variant (generic) using conservative defaults\r\n02-05 23:13:06.459 4190-4190/org.tensorflow.demo D/tensorflow: CameraActivity: onCreate org.tensorflow.demo.StylizeActivity@5bb014e\r\n02-05 23:13:06.552 4190-4198/org.tensorflow.demo W/art: Suspending all threads took: 10.696ms\r\n02-05 23:13:07.005 4190-4190/org.tensorflow.demo D/tensorflow: CameraActivity: onStart org.tensorflow.demo.StylizeActivity@5bb014e\r\n02-05 23:13:07.048 4190-4190/org.tensorflow.demo D/tensorflow: CameraActivity: onResume org.tensorflow.demo.StylizeActivity@5bb014e\r\n02-05 23:13:07.432 4190-4224/org.tensorflow.demo I/OpenGLRenderer: Initialized EGL, version 1.4\r\n02-05 23:13:07.433 4190-4224/org.tensorflow.demo D/OpenGLRenderer: Swap behavior 1\r\n02-05 23:13:07.513 4190-4224/org.tensorflow.demo E/EGL_emulation: tid 4224: eglSurfaceAttrib(1146): error 0x3009 (EGL_BAD_MATCH)\r\n02-05 23:13:07.513 4190-4224/org.tensorflow.demo W/OpenGLRenderer: Failed to set EGL_SWAP_BEHAVIOR on surface 0xa21ec4c0, error=EGL_BAD_MATCH\r\n02-05 23:13:07.569 4190-4190/org.tensorflow.demo I/CameraManagerGlobal: Connecting to camera service\r\n02-05 23:13:07.778 4190-4190/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 640x480\r\n02-05 23:13:07.778 4190-4190/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 352x288\r\n02-05 23:13:07.779 4190-4190/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 320x240\r\n02-05 23:13:07.779 4190-4190/org.tensorflow.demo I/tensorflow: CameraConnectionFragment: Not adding size: 176x144\r\n02-05 23:13:07.779 4190-4190/org.tensorflow.demo E/tensorflow: CameraConnectionFragment: Couldn't find any suitable preview size\r\n02-05 23:13:07.793 4190-4190/org.tensorflow.demo I/native: tensorflow_inference_jni.cc:97 Native TF methods loaded.\r\n02-05 23:13:07.793 4190-4190/org.tensorflow.demo I/TensorFlowInferenceInterface: Native methods already loaded.\r\n02-05 23:13:07.794 4190-4190/org.tensorflow.demo I/native: tensorflow_inference_jni.cc:85 Creating new session variables for 33d6c42f66af20bb\r\n02-05 23:13:07.795 4190-4190/org.tensorflow.demo I/native: tensorflow_inference_jni.cc:113 Loading Tensorflow.\r\n02-05 23:13:07.822 4190-4190/org.tensorflow.demo I/native: tensorflow_inference_jni.cc:120 Session created.\r\n02-05 23:13:07.822 4190-4190/org.tensorflow.demo I/native: tensorflow_inference_jni.cc:126 Acquired AssetManager.\r\n02-05 23:13:07.823 4190-4190/org.tensorflow.demo I/native: tensorflow_inference_jni.cc:128 Reading file to proto: file:///android_asset/stylize_quantized.pb\r\n02-05 23:13:07.824 4190-4190/org.tensorflow.demo A/native: jni_utils.cc:98 'asset' Must be non NULL\r\n02-05 23:13:07.826 4190-4190/org.tensorflow.demo A/libc: Fatal signal 6 (SIGABRT), code -6 in tid 4190 (tensorflow.demo)\r\n                                                         \r\n                                                         [ 02-05 23:13:07.859  3898: 3898 W/         ]\r\n                                                         debuggerd: handling request: pid=4190 uid=10079 gid=10079 tid=4190\r\n", "The null asset error indicates that the model is not being found in the assets/ dir.\r\n\r\nThis is currently missing from the directions (needs to be added), but if you're not building with Bazel you'll need to download and extract the contents of https://storage.googleapis.com/download.tensorflow.org/models/stylize_v1.zip into the assets/ dir.", "Hi:\r\n finally I use the command to obtain the model, and run it successfully in emulator,\r\nmuch appreciated for your guild.\r\n\r\n$ curl -L https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip -o /tmp/inception5h.zip\r\n$ curl -L https://storage.googleapis.com/download.tensorflow.org/models/mobile_multibox_v1.zip -o /tmp/mobile_multibox_v1.zip\r\n\r\n$ unzip /tmp/inception5h.zip -d tensorflow/examples/android/assets/\r\n$ unzip /tmp/mobile_multibox_v1.zip -d tensorflow/examples/android/assets/"]}, {"number": 7255, "title": "Multi-GPU training drastically slow after recent commit", "body": "I recently upgraded to the latest master, in order to fix the issues caused by this bug: https://github.com/tensorflow/tensorflow/issues/7038\r\nThough the above fix does resolve the issue of same batch being pulled from the GPU, now my model training has become drastically slow (> 4x), and most time is being spent in dequeues. A timeline snapshot is here:\r\n\r\n![screenshot from 2017-02-03 18-43-55](https://cloud.githubusercontent.com/assets/1893429/22612749/be748f0c-ea40-11e6-9efb-989b9466301a.png)\r\n\r\nAny ideas as to what might be going wrong?\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\nhttps://github.com/tensorflow/tensorflow/issues/7038\r\n\r\n### Environment info\r\nOperating System: CentOS 6.5\r\n\r\nInstalled version of CUDA and cuDNN: 8.0.27 and 5.1\r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\n1. The commit hash (`git rev-parse HEAD`): 084b37a00f3cf2cc89d433528ca63ec1d3b5b313\r\n2. The output of `bazel version`\r\n```\r\nBuild label: 0.4.3- (@non-git)\r\nBuild target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Fri Dec 23 16:35:28 2016 (1482510928)\r\nBuild timestamp: 1482510928\r\nBuild timestamp as int: 1482510928\r\n```\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\nMy code is based on the tensorflow/models/slim interface", "comments": ["It seems crux of the fix in that issue is to set `stateful` property to true, any chance you can change it to read ` op_def->set_is_stateful(false);` and see if this fixes things?\r\n\r\nhttps://github.com/tensorflow/tensorflow/commit/06e3aa655506773e49ce9a855f81ba3eae2a6b88#diff-333845d139890198962551b3a1c2a33b", "PS, spending time in dequeues can mean that you have queue starvation, so it's really the `.run` call which enqueues to your queue that is slow. So you should make sure your `queue.size()` is always above batch size, and if not, profile your enqueue `.run` call. Here's an example of similar issue https://github.com/tensorflow/tensorflow/issues/6845", "I changed the line in `tensorflow/core/framework/op_def_builder.cc`, L379 (true->false). Now I'm getting a segmentation fault with my code, right after it prints `INFO:tensorflow:Starting Queues.` (I'm using models/slim based script). Maybe there has been some other change in the last few days that conflicts with this...?", "I downgraded my tensorflow installation to 0.12.1 release (4d924e796368163eff11a8151e8505715345f58d)\r\nAfter the required API changes, my code seemed to run at a similar speed as I'm seeing with the latest head. So it might be possible that last few weeks I've been running it with the optimization bug with made it 4x faster (by copying the same batch onto all 4 GPUs), and the slowdown I'm seeing now is actually the expected speed given the amount of I/O I'm doing.\r\n\r\nI'll debug some more on this, but thanks for the pointers and quick response, @yaroslavvb ", "FYI, on my side it runs faster with the bug as well, because it reused the same data 4 times.", "![picard12](https://cloud.githubusercontent.com/assets/23068/22631578/c203add0-ebc4-11e6-8a97-8658e8964870.png)\r\n", "The meme probably explains the situation here :p Closing the issue."]}, {"number": 7254, "title": "Fixing Issue 7214 about tf_update.py", "body": "- first commit of tf_update2.py implemented by using RedBaron method\r\n- fixed issue of #7214\r\n- fixed issue of mixed code\r\n- added support of tf.reverse and tf.image.resize_image", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "@machrisaa can you sign the CLA?", "Hi @rmlarsen , I have signed it just now.", "@machrisaa you have to type \"I signed it!\" exactly, as there is a bot for checking CLA.", "I signed it!", "Another problem with CLA.\r\nLooks like your commit email is is not recognized by github. Maybe you need to change the email of the commit to your email you use in github?", "Thanks @gunan. I created `tf_upgrade2.py` because it used completely different approach to implement the upgrading script. I have been communication with @aselle in [7214](https://github.com/tensorflow/tensorflow/issues/7214) to see if he would accept this approach or not. Also, this method has not fully completed the functions in `tf_update.py` (upgrading a folder tree and creating log file)", "This is currently a demo implementation. See the issue #7214 for discussion."]}, {"number": 7253, "title": "tf.reshape() of a tensor with an unknown dimension (None) does not seem to work", "body": "\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\nhttps://github.com/fchollet/keras/issues/4302\r\n\r\n### Environment info\r\nOperating System: Mac (CPU)\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n0.12.1\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n`input = tf.placeholder(dtype=tf.float32, shape=(None, 2, 3))\r\ninput_flattened = tf.reshape(input, shape=[input.get_shape()[0].value, -1])\r\n\r\nwith tf.Session() as sess:\r\n    init = tf.global_variables_initializer()\r\n    sess.run(init)\r\n    input_val, input_flattened_val = \\\r\n        sess.run([input, input_flattened], feed_dict={input: np.random.random(24).reshape(4, 2, 3)})\r\n    print input_val\r\n    print input_flattened_val`\r\n\r\nTypeErrorTraceback (most recent call last)<ipython-input-36-99d32472c9da> in <module>()\r\n      1 input = tf.placeholder(dtype=tf.float32, shape=(None, 2, 3))\r\n----> 2 input_flattened = tf.reshape(input, shape=[input.get_shape()[0].value, -1])\r\n      3 \r\n      4 with tf.Session() as sess:\r\n      5     init = tf.global_variables_initializer()\r\n/Users/adeoras/tensorflow/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.pyc in reshape(tensor, shape, name)\r\n   2446   \"\"\"\r\n   2447   result = _op_def_lib.apply_op(\"Reshape\", tensor=tensor, shape=shape,\r\n-> 2448                                 name=name)\r\n   2449   return result\r\n   2450 \r\n/Users/adeoras/tensorflow/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.pyc in apply_op(self, op_type_name, name, **keywords)\r\n    491           except TypeError as err:\r\n    492             if dtype is None:\r\n--> 493               raise err\r\n    494             else:\r\n    495               raise TypeError(\r\nTypeError: Expected binary or unicode string, got None\r\n\r\n### What other attempted solutions have you tried?\r\nNone\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n\r\n\r\n", "comments": ["`tf.reshape` takes a tensor of ints as the shape argument.  You are passing None, so it doesn't work.  Maybe you want to replace `x.get_shape()[0]` with `tf.shape(x)[0]`?", "Does that mean doing reshaping with variable batch size is not possible then? Often I have input of shape [None, other_dims] and if I want to reshape the \"other_dims\" into a different shape I cannot do it?", "`tf.shape(x)[0]` gives a scalar tensor with the variable batch size.  Try passing it to reshape.", "using `tf.shape(x)` worked for me! Thanks.", "It is also possible to use `tf.stack` to convert a list into a tensor\r\n", "- I have successfully used tf.shape()[0] to flat a  tensor with  none dim  as a vector, thanks\r\n```python\r\ntensor_vector = tf.reshape(tensor=some_tensor, shape=(-1, tf.shape(some_tensor)[1]*tf.shape(some_tensor)[2])\r\n```\r\n- however , I want to connect a full connected layer behind the  `tensor_vector`, so I have to define the weight matrix's shape, then the contradiction is occurred ,because when I\u3000using the `wshape = (tf.shape(some_tensor)[1] *tf.shape(some_tensor)[\uff12] , 1000)` to define the weight matrix , the error is that the dim of the weight matrix must be an integer not a tensor,  however ,the dim I have to use tf.shape(some_tensor) to get which is a tensor ,so ,how can I\u3000solve it ?   ", "Group normalization in keras with tf backend need to handle the reshape consists of None dimension.", "> `tf.reshape` takes a tensor of ints as the shape argument. You are passing None, so it doesn't work. Maybe you want to replace `x.get_shape()[0]` with `tf.shape(x)[0]`?\r\n\r\nThanks a lot. tf.shape() works for me", "```\r\ndef generator(x):\r\n  weights['gen_inp'] = tf.Variable(xavier_init([100, 256]))\r\n  bias['gen_inp'] = tf.Variable(xavier_init([256]))\r\n\r\n  inp = tf.nn.relu(tf.add(tf.matmul(x, weights['gen_inp']), bias['gen_inp']))\r\n  print(inp.shape,)\r\n  \r\n  inp = tf.reshape(inp, shape=tf.TensorShape([tf.shape(inp)[0], 16, 16, 1]))\r\n\r\n  conv_1 = tf.nn.relu(gen_new_conv_layer(x, num_input_channels = 1, filter_size = 4,\\\r\n                                     num_filters = 1024, name='gen_conv_1', weights_dict = weights, bias_dict = bias))\r\n  \r\n  conv_2 = tf.nn.relu(gen_new_conv_layer(conv_1, num_input_channels = 1024, filter_size = 8,\\\r\n                                     num_filters = 512, name='gen_conv_2', weights_dict = weights, bias_dict = bias))\r\n  \r\n  conv_3 = tf.nn.relu(gen_new_conv_layer(conv_2, num_input_channels = 512, filter_size = 16,\\\r\n                                     num_filters = 256, name='gen_conv_3', weights_dict = weights, bias_dict = bias))\r\n  \r\n  conv_4 = tf.nn.relu(gen_new_conv_layer(conv_3, num_input_channels = 256, filter_size = 32,\\\r\n                                     num_filters = 128, name='gen_conv_4', weights_dict = weights, bias_dict = bias))\r\n  \r\n  gen_output = tf.nn.tanh(gen_new_conv_layer(conv_4, num_input_channels = 128, filter_size = 64,\\\r\n                                         num_filters = 3, name='gen_conv_5', weights_dict = weights, bias_dict = bias))\r\n\r\n  return gen_output\r\n\r\nz_input = tf.placeholder(tf.float32, [None, z_noise_dim], name='NoiseInput')\r\nx_input = tf.placeholder(tf.float32, [None, img_wid, img_hei, input_channels], name='RealInput')\r\n\r\nwith tf.name_scope('Generator') as scope:\r\n  output_gen = generator(z_input)\r\n```\r\n\r\nis giving error as,\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-27-27084685abe1> in <module>()\r\n     48 \r\n     49 with tf.name_scope('Generator') as scope:\r\n---> 50   output_gen = generator(z_input)\r\n\r\n4 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/tensor_shape.py in __init__(self, value)\r\n    191       raise TypeError(\"Cannot convert %s to Dimension\" % value)\r\n    192     else:\r\n--> 193       self._value = int(value)\r\n    194       if (not isinstance(value, compat.bytes_or_text_types) and\r\n    195           self._value != value):\r\n\r\nTypeError: int() argument must be a string, a bytes-like object or a number, not 'Tensor'\r\n```"]}, {"number": 7252, "title": "Prevent Python unit test files from going into PIP package", "body": "See also experimental PIP build at (Jenkins login required to view):\r\nhttp://ci.tensorflow.org/job/experimental-cais-linux-python35-pip/6/console", "comments": ["It is possible due to recent issues pip tests are disabled in presubmits. Could you setup an experimental build and run any pip tests, @caisq ?", "@gunan, I (kind of) did that already. See the original PR comment. But that particular build timed out at 90 minutes. I increased the timeout to 120 minutes and kicked off another one:\r\n\r\nhttp://ci.tensorflow.org/view/Experimental/job/experimental-cais-linux-python35-pip/7/console", "To quantify the reduction in the PIP wheel file size (in bytes, for Python 3.5):\r\nBefore: 43691027\r\nAfter: 43507664\r\nAbout 180 kB (0.5% reduction).\r\n\r\nNot as much as one would expect :)  But it gets rid of 175 unnecessary files and about 2.5 MB disk space when installed.", "Change mostly looks good.\r\nWould this lead to any changes in public API?", "I am not a fan of how this is done -- can we instead put this exception into the build_pip_package rule? Otherwise we have another point at which to control what goes into the pip package -- we already have too many.", "I'll close this for now. There is a related issue of unnecessary include header files in the pip package. I'll reopen the PR again when I have a more elegant fix for both issues."]}, {"number": 7251, "title": "Native GPU version of `tf.dynamic_stitch`", "body": "### Environment info\r\nOperating System: Windows 10\r\n\r\nInstalled version of CUDA and cuDNN: 8.0, 5105\r\ntensorflow release 0.12.1\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n``` python\r\nimport tensorflow as tf\r\nfrom tensorflow.python.client.timeline import Timeline\r\n\r\nwith tf.device(\"/gpu:0\"):\r\n    x = tf.ones(100)\r\n    idxs = tf.range(100)\r\n\r\n    for _ in range(10):\r\n        y = tf.identity(x)\r\n        x = tf.dynamic_stitch([idxs, idxs], [x, y])\r\n        # x = tf.gather(y, idxs)\r\n\r\nwith tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:\r\n    metadata = tf.RunMetadata()\r\n    sess.run(x, options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),\r\n             run_metadata=metadata)\r\n\r\ntimeline = Timeline(metadata.step_stats)\r\nwith open(\"profile.json\", \"w\") as f:\r\n    f.write(timeline.generate_chrome_trace_format())\r\n```\r\n\r\nThe `log_device_placement` output shows that everything is assigned to the GPU, as expected.  However, inspecting the trace output shows that data is being copied on and off the GPU for each call to `dynamic_stitch`.  This is something specific to the `dynamic_stitch` implementation, because using `tf.gather` (a similar indexed read operation, and functionally equivalent in this case), doesn't show this behaviour.\r\n\r\nIs this intended behaviour for `dynamic_stitch` (i.e., the copying to and from the GPU is necessary)?  Or is this a bug?  If it isn't a bug, is there some equivalent solution that doesn't require the data to be copied back and forth?", "comments": ["This is probably due to the following `HostMemory` annotations in definition of DynamicStitch in [dynamic_stitch_op.cc](https://github.com/tensorflow/tensorflow/blob/27711108b5fce2e1692f9440631a183b3808fa01/tensorflow/core/kernels/dynamic_stitch_op.cc#L184)\r\n\r\n```\r\n#define REGISTER_DYNAMIC_STITCH_GPU(type)                \\\r\n  REGISTER_KERNEL_BUILDER(Name(\"DynamicStitch\")          \\\r\n                              .Device(DEVICE_GPU)        \\\r\n                              .TypeConstraint<type>(\"T\") \\\r\n                              .HostMemory(\"indices\")     \\\r\n                              .HostMemory(\"data\")        \\\r\n                              .HostMemory(\"merged\"),     \\\r\n                          DynamicStitchOp<type>)\r\n```\r\n\r\nNow if you look at [data_flow_ops.cc](https://github.com/tensorflow/tensorflow/blob/b00fc538638f87ac45be9105057b9865f0f9418b/tensorflow/core/ops/data_flow_ops.cc#L112), you see this\r\n\r\n```\r\nREGISTER_OP(\"DynamicStitch\")\r\n    .Input(\"indices: N * int32\")\r\n    .Input(\"data: N * T\")\r\n    .Output(\"merged: T\")\r\n    .Attr(\"N : int >= 1\")\r\n```\r\n\r\nThis means that GPU implementation of DynamicStitch keeps all of its inputs and outputs in main memory. It may seem useless to have this kind of implementation, but it reduces overhead in some cases - it could make sense to place the op on `/gpu:0` logical device to avoid having to cross the logical device boundary, even though an op the op would actually use CPU hardware resources to compute things.", "Running with a bit more instrumentation, see [dynamic_stitch_gpu.py](https://github.com/yaroslavvb/stuff/blob/master/dynamic_stitch_gpu.py) . There are two kinds of transfers going on. The inputs are transferred from GPU to host memory, the op runs, and then outputs are transferred from host memory to GPU memory. \r\n\r\nIf you run with `output_partition_graphs=True` and look at `partition_graphs` in generated metadata [pbtxt](https://github.com/yaroslavvb/stuff/blob/master/dynamic_stitch_gpu_profile.pbtxt) you see there are ops like this\r\n\r\n```\r\n  node {\r\n    name: \"x/_0\"\r\n    op: \"_Send\"\r\n    input: \"x\"\r\n    device: \"/job:localhost/replica:0/task:0/gpu:0\"\r\n    attr {\r\n      key: \"T\"\r\n      value {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n\r\n```\r\n\r\nThis is the input `x` which is on GPU, and is transferred onto CPU because that input has `HostMemory` attribute, hence needs to be copied.\r\n\r\nLater you have ops like this\r\n\r\n```\r\n  node {\r\n    name: \"stitch-0/_4\"\r\n    op: \"_HostSend\"\r\n    input: \"stitch-0\"\r\n    device: \"/job:localhost/replica:0/task:0/gpu:0\"\r\n```\r\n\r\nwhich indicates that output was placed into Host memory, and needs to be transferred to GPU memory. To summarize, it seems like `dynamic_stitch` is not optimized for GPU, and may be faster to run it pinned  to CPU.", "A natively GPU version of `dynamic_stitch` looks doable to me (not fundamentally harder than scatter or gather), so I'll mark this contributions welcome.\r\n\r\nI'm happy to provide tips if someone wants to take this on.", "One gotcha to avoid is to make sure GPU outputs are real-valued, since integer tensors on GPU don't seem to be supported ([register_types.h](https://github.com/tensorflow/tensorflow/blob/a304537954a865752ad1b18461e6bd67b36082db/tensorflow/core/framework/register_types.h))\r\n\r\n```\r\n// Call \"m\" on all types supported on GPU.\r\n#define TF_CALL_GPU_NUMBER_TYPES(m) \\\r\n  TF_CALL_half(m) TF_CALL_float(m) TF_CALL_double(m)\r\n\r\n#define TF_CALL_GPU_NUMBER_TYPES_NO_HALF(m) TF_CALL_float(m) TF_CALL_double(m)\r\n\r\n```", "I have written a pretty simple Cuda kernel for this op, please see pull request #7764", "@MycChiu did you ever open a new PR for this?", "@girving @skye The [#8260 PR](https://github.com/tensorflow/tensorflow/pull/8260) stalled for a few months, and I also need the GPU version of dynamic_stitch op recently. So may i take over it? Thanks.", "@nolanliou Probably, pending @skye's thoughts, but if so it's probably worth describing the algorithm you plan to use.  The previous approach had some fundamental issues.", "@girving\r\nwe have to check the collision before sending data to GPU given the  the collision requirements.  \r\nSo I wanna divide into two cases:\r\n\r\n1. No collision: easy to use threadIdx/blockIdx to index. (most time).\r\n2. Collison: compute all the output's indies at CPU to resolve the collision, then send to GPU.\r\n\r\nWelcome any tips.", "@nolanliou It would be better to do it all in one pass, both to avoid the separate collision checking phase and to avoid CPU work in the collision case.  One option is to have a separate buffer storing the source index of an output index.  Atomically writing an entry in the separate buffer at the same time as the main buffer can avoid collisions.  Not sure if the separate buffer can be avoided.", "This message was created automatically by mail delivery software.\n\nA message that you sent could not be delivered to one or more of its\nrecipients. This is a temporary error. The following address(es) deferred:\n\n  mazecreator@gmail.com\n    Domain mazecreator.com has exceeded the max emails per hour (27/25 (108%)) allowed.  Message will be reattempted later\n\n------- This is a copy of the message, including all the headers. ------\nReceived: from o8.sgmail.github.com ([167.89.101.199]:55459)\n\tby server2.lowesthostingrates.com with esmtps (TLSv1.2:ECDHE-RSA-AES128-GCM-SHA256:128)\n\t(Exim 4.89)\n\t(envelope-from <bounces+848413-e6d9-mazecreator=mazecreator.com@sgmail.github.com>)\n\tid 1dcDaF-0004jv-BH\n\tfor mazecreator@mazecreator.com; Mon, 31 Jul 2017 11:30:49 -0500\nDKIM-Signature: v=1; a=rsa-sha1; c=relaxed/relaxed; d=github.com; \n\th=from:reply-to:to:cc:in-reply-to:references:subject:mime-version:content-type:content-transfer-encoding:list-id:list-archive:list-post:list-unsubscribe; \n\ts=s20150108; bh=nx71yJs08keP5T07fL7PA0zJ5Sk=; b=EWCBHGn0d7W2HWBf\n\tc31a0Zv8qb4xspIsMQJJX0Ygav/e8OSs9mBlJQAdUPOCa/rPEPAH6hiteaC02key\n\t8srV34R1lhfmYLYRRNp0hw+i4H/9RQbV4+LfgnBUmnbc5lXkz3tM1w+80TLv7UJ2\n\tY7keWQbgc/4OwbfMjTCXQ7cPO1E=\nReceived: by filter1090p1mdw1.sendgrid.net with SMTP id filter1090p1mdw1-31658-597F5D93-1E\n        2017-07-31 16:40:51.938204643 +0000 UTC\nReceived: from github-smtp2b-ext-cp1-prd.iad.github.net (github-smtp2b-ext-cp1-prd.iad.github.net [192.30.253.17])\n\tby ismtpd0003p1iad1.sendgrid.net (SG) with ESMTP id ej7d3jnRSfiR-na-eSX06A\n\tfor <mazecreator@mazecreator.com>; Mon, 31 Jul 2017 16:40:51.885 +0000 (UTC)\nDate: Mon, 31 Jul 2017 16:40:52 +0000 (UTC)\nFrom: Geoffrey Irving <notifications@github.com>\nReply-To: tensorflow/tensorflow <reply@reply.github.com>\nTo: tensorflow/tensorflow <tensorflow@noreply.github.com>\nCc: Subscribed <subscribed@noreply.github.com>\nMessage-ID: <tensorflow/tensorflow/issues/7251/319126665@github.com>\nIn-Reply-To: <tensorflow/tensorflow/issues/7251@github.com>\nReferences: <tensorflow/tensorflow/issues/7251@github.com>\nSubject: Re: [tensorflow/tensorflow] Native GPU version of `tf.dynamic_stitch`\n (#7251)\nMime-Version: 1.0\nContent-Type: multipart/alternative;\n boundary=\"--==_mimepart_597f5d93c36ab_27253f8d0fb59c2c364450\";\n charset=UTF-8\nContent-Transfer-Encoding: 7bit\nPrecedence: list\nX-GitHub-Sender: girving\nX-GitHub-Recipient: Mazecreator\nX-GitHub-Reason: subscribed\nList-ID: tensorflow/tensorflow <tensorflow.tensorflow.github.com>\nList-Archive: https://github.com/tensorflow/tensorflow\nList-Post: <mailto:reply@reply.github.com>\nList-Unsubscribe: <mailto:unsub+0118f3a0d0f555d24b289287f58f3650cf2dacfcbcd77ae092cf0000000115971f9392a169ce0c3c4c09@reply.github.com>,\n <https://github.com/notifications/unsubscribe/ARjzoKPYlSfOTycEiwL0VaTM6KRaRBL3ks5sTgOTgaJpZM4L22Cc>\nX-Auto-Response-Suppress: All\nX-GitHub-Recipient-Address: mazecreator@mazecreator.com\nX-SG-EID: BJ4qYjf5a3yL0lCrdDNghY4YYR+k1a+cluU6wEX1JqwOXPbdUKmyhRm47T5qUt/NDnaAPnCAqApKQk\n lCFCUusMnkTUaO8V2Q2akzYhYU3BvTU1jLWgrazEAbStj3XO0vJXp/8+jGYXijr+BWlBHzd+UyBCiP\n zw3fqzev/O/UT1HosblJk+khV8Hefjzlr9ICE2zHXawfEsWdbU7/HtDnXGtYb5IesMVrm3r7l5DrPf\n 0bj3EinW8zXeKfPOrZuynx\nX-Spam-Status: No, score=\nX-Spam-Score:\nX-Spam-Bar:\nX-Ham-Report:\nX-Spam-Flag: NO\n\n----==_mimepart_597f5d93c36ab_27253f8d0fb59c2c364450\nContent-Type: text/plain;\n charset=UTF-8\nContent-Transfer-Encoding: 7bit\n\n@nolanliou It would be better to do it all in one pass, both to avoid the separate collision checking phase and to avoid CPU work in the collision case.  One option is to have a separate buffer storing the source index of an output index.  Atomically writing an entry in the separate buffer at the same time as the main buffer can avoid collisions.  Not sure if the separate buffer can be avoided.\n\n-- \nYou are receiving this because you are subscribed to this thread.\nReply to this email directly or view it on GitHub:\nhttps://github.com/tensorflow/tensorflow/issues/7251#issuecomment-319126665\n----==_mimepart_597f5d93c36ab_27253f8d0fb59c2c364450\nContent-Type: text/html;\n charset=UTF-8\nContent-Transfer-Encoding: quoted-printable\n\n<p><a href=3D\"https://github.com/nolanliou\" class=3D\"user-mention\">@nolanli=\nou</a> It would be better to do it all in one pass, both to avoid the separ=\nate collision checking phase and to avoid CPU work in the collision case.  =\nOne option is to have a separate buffer storing the source index of an outp=\nut index.  Atomically writing an entry in the separate buffer at the same t=\nime as the main buffer can avoid collisions.  Not sure if the separate buff=\ner can be avoided.</p>\n\n<p style=3D\"font-size:small;-webkit-text-size-adjust:none;color:#666;\">&mda=\nsh;<br />You are receiving this because you are subscribed to this thread.<=\nbr />Reply to this email directly, <a href=3D\"https://github.com/tensorflow=\n/tensorflow/issues/7251#issuecomment-319126665\">view it on GitHub</a>, or <=\na href=3D\"https://github.com/notifications/unsubscribe-auth/ARjzoNomEooi4MK=\nxyeFsDrNYCfW_PA2lks5sTgOTgaJpZM4L22Cc\">mute the thread</a>.<img alt=3D\"\" he=\night=3D\"1\" src=3D\"https://github.com/notifications/beacon/ARjzoKE5D3UUNMrXu=\nCWAVKwcef6jh5fXks5sTgOTgaJpZM4L22Cc.gif\" width=3D\"1\" /></p>\n<div itemscope itemtype=3D\"http://schema.org/EmailMessage\">\n<div itemprop=3D\"action\" itemscope itemtype=3D\"http://schema.org/ViewAction=\n\">\n  <link itemprop=3D\"url\" href=3D\"https://github.com/tensorflow/tensorflow/i=\nssues/7251#issuecomment-319126665\"></link>\n  <meta itemprop=3D\"name\" content=3D\"View Issue\"></meta>\n</div>\n<meta itemprop=3D\"description\" content=3D\"View this Issue on GitHub\"></meta>\n</div>\n\n<script type=3D\"application/json\" data-scope=3D\"inboxmarkup\">{\"api_version\"=\n:\"1.0\",\"publisher\":{\"api_key\":\"05dde50f1d1a384dd78767c55493e4bb\",\"name\":\"Gi=\ntHub\"},\"entity\":{\"external_key\":\"github/tensorflow/tensorflow\",\"title\":\"ten=\nsorflow/tensorflow\",\"subtitle\":\"GitHub repository\",\"main_image_url\":\"https:=\n//cloud.githubusercontent.com/assets/143418/17495839/a5054eac-5d88-11e6-95f=\nc-7290892c7bb5.png\",\"avatar_image_url\":\"https://cloud.githubusercontent.com=\n/assets/143418/15842166/7c72db34-2c0b-11e6-9aed-b52498112777.png\",\"action\":=\n{\"name\":\"Open in GitHub\",\"url\":\"https://github.com/tensorflow/tensorflow\"}}=\n,\"updates\":{\"snippets\":[{\"icon\":\"PERSON\",\"message\":\"@girving in #7251: @nol=\nanliou It would be better to do it all in one pass, both to avoid the separ=\nate collision checking phase and to avoid CPU work in the collision case.  =\nOne option is to have a separate buffer storing the source index of an outp=\nut index.  Atomically writing an entry in the separate buffer at the same t=\nime as the main buffer can avoid collisions.  Not sure if the separate buff=\ner can be avoided.\"}],\"action\":{\"name\":\"View Issue\",\"url\":\"https://github.c=\nom/tensorflow/tensorflow/issues/7251#issuecomment-319126665\"}}}</script>=\n\n----==_mimepart_597f5d93c36ab_27253f8d0fb59c2c364450--\n", "@girving Yeah, it could avoid the collision checking, I have implemented the code and post a [PR](https://github.com/tensorflow/tensorflow/pull/11940), please review it if you have time.", "@nolanliou I'll let someone else review it, since I am no longer at Google and am focused on other things at the moment.", "@girving thanks and good luck.", "I think this issue has been fixed by PR #11940. Probably could be closed?", "It's ok."]}, {"number": 7250, "title": "(WIP) Remove all Python unit test files from PIP package", "body": "", "comments": []}, {"number": 7249, "title": "ValueError: Only call `sigmoid_cross_entropy_with_logits` with named arguments (labels=..., logits=..., ...)", "body": "**OS:** \r\nmacOS 10.12, CUDA 8.0 / cudnn 5, GeForce GTX 780\r\n\r\nTensorflow version:\r\n0.12.head, build from source with CUDA 8 support. Is working!\r\n\r\n---\r\n\r\n**Problem:**\r\nTrying to run the code of this project (written for tensorflow 0.10 \u2013 and i have 0.12):\r\nhttps://github.com/david-gpu/srez\r\n\r\nAnd am getting the following error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"srez_main.py\", line 190, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/platform/app.py\", line 44, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"srez_main.py\", line 187, in main\r\n    _train()\r\n  File \"srez_main.py\", line 168, in _train\r\n    gene_loss = srez_model.create_generator_loss(disc_fake_output, gene_output, train_features)\r\n  File \"/Users/david/github/image-manipulation/srez/srez_model.py\", line 452, in create_generator_loss\r\n    cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(disc_output, tf.ones_like(disc_output))\r\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/ops/nn_impl.py\", line 147, in sigmoid_cross_entropy_with_logits\r\n    _sentinel, labels, logits)\r\n  File \"/usr/local/lib/python3.5/site-packages/tensorflow/python/ops/nn_ops.py\", line 1535, in _ensure_xent_args\r\n    \"named arguments (labels=..., logits=..., ...)\" % name)\r\nValueError: Only call `sigmoid_cross_entropy_with_logits` with named arguments (labels=..., logits=..., ...)\r\n```\r\n\r\nThe file which generates the **\"ValueError: Only call `sigmoid_cross_entropy_with_logits` with named arguments (labels=..., logits=..., ...)\"** error contains this code:\r\n\r\n```python\r\ndef create_generator_loss(disc_output, gene_output, features):\r\n    # I.e. did we fool the discriminator?\r\n    cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(disc_output, tf.ones_like(disc_output))\r\n    gene_ce_loss  = tf.reduce_mean(cross_entropy, name='gene_ce_loss')\r\n\r\n    # I.e. does the result look like the feature?\r\n    K = int(gene_output.get_shape()[1])//int(features.get_shape()[1])\r\n    assert K == 2 or K == 4 or K == 8    \r\n    downscaled = _downscale(gene_output, K)\r\n    \r\n    gene_l1_loss  = tf.reduce_mean(tf.abs(downscaled - features), name='gene_l1_loss')\r\n\r\n    gene_loss     = tf.add((1.0 - FLAGS.gene_l1_factor) * gene_ce_loss,\r\n                           FLAGS.gene_l1_factor * gene_l1_loss, name='gene_loss')\r\n    \r\n    return gene_loss\r\n\r\ndef create_discriminator_loss(disc_real_output, disc_fake_output):\r\n    # I.e. did we correctly identify the input as real or not?\r\n    cross_entropy_real = tf.nn.sigmoid_cross_entropy_with_logits(disc_real_output, tf.ones_like(disc_real_output))\r\n    disc_real_loss     = tf.reduce_mean(cross_entropy_real, name='disc_real_loss')\r\n    \r\n    cross_entropy_fake = tf.nn.sigmoid_cross_entropy_with_logits(disc_fake_output, tf.zeros_like(disc_fake_output))\r\n    disc_fake_loss     = tf.reduce_mean(cross_entropy_fake, name='disc_fake_loss')\r\n\r\n    return disc_real_loss, disc_fake_loss\r\n```\r\n\r\nThe project was written for tensorflow 0.10 and i already had to change a deprecated function name.\r\n\r\nWhat do i need to change in \r\n```python\r\ntf.nn.sigmoid_cross_entropy_with_logits(disc_output, tf.ones_like(disc_output))\r\n```\r\nto get rid of the error?\r\n\r\nThanks!", "comments": ["try to run your code through @aselle 's upgrade script and see if it fixes things -- https://github.com/tensorflow/tensorflow/blob/cb17d1b0e2b581b5da1d9597b7929ba764749d38/tensorflow/tools/compatibility/BUILD", "Thanks for the script! I switched back to tf version 0.11 and got rid of the errors. Will try the script on the 0.10 files and then update again to 0.12 and rerun the project.", "I encountered the same error in TF 1.0 and the code I used is DCGAN downloaded from the internet. Do you have any idea how to solve it? Thanks!", "@pengjingg  see @yaroslavvb's answer\r\n", "I solved it in a easier way:\r\n[https://github.com/tensorflow/tensorflow/issues/7814](https://github.com/tensorflow/tensorflow/issues/7814)\r\nbut thanks anyway @aselle ", "https://github.com/tensorflow/tensorflow/issues/7814\r\n\r\nyou guys can see the solution here, it works for me.", "https://github.com/tensorflow/tensorflow/issues/7814\r\n\r\nyou guys can see the solution here, it works for me.", "I solved in a way mentioned here: [#7814](https://github.com/tensorflow/tensorflow/issues/7814)."]}, {"number": 7248, "title": "R0.12", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "@ivansuknovic can you sign the CLA?"]}, {"number": 7247, "title": "Branch 146479561", "body": "Push internal changes.", "comments": []}, {"number": 7246, "title": "Pool Allocator Problem", "body": "I was running LSTM having 2 layers and 64 nodes in each layer running in batch mode with small data size. I am unable to figure out the problem. I am getting warning like \r\n\r\n tensorflow/core/common_runtime/gpu/pool_allocator.cc:257] Raising pool_size_limit_ from 100 to 110\r\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 1323 get requests, put_count=2336 evicted_count=1000 eviction_rate=0.428082 and unsatisfied allocation rate=0\r\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 6326 get requests, put_count=5369 evicted_count=2000 eviction_rate=0.372509 and unsatisfied allocation rate=0.470123\r\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:257] Raising pool_size_limit_ from 193 to 212\r\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 1415 get requests, put_count=2440 evicted_count=1000 eviction_rate=0.409836 and unsatisfied allocation rate=0\r\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 1590 get requests, put_count=3623 evicted_count=2000 eviction_rate=0.552029 and unsatisfied allocation rate=0\r\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:245] PoolAllocator: After 1137 get requests, put_count=2186 evicted_count=1000 eviction_rate=0.457457 and unsatisfied allocation rate=0\r\n\r\nBecause of which code runs very slow.\r\n\r\n**Machine 1**\r\nConfiguration as follows:\r\nEnvironment Information (we've tried several different permutations):\r\nOS: CentOS 7.2\r\nCUDA: 8.0.44 and 7.5.17\r\nCUDNN: 5.1 and 5.0\r\nTensorflow: 0.11.0rc0, 0.11.0, 0.12.1, 1.0.0rc0\r\nNvidia drivers: 352.39, 367.48\r\nGPU:Tesla k80\r\nservers with 2 K80 cards each (2 GPUs per card, for a total of 4 GPUs per machine).\r\n\r\nIf I run the same code on different machine the code runs fine without any warning:\r\n**Machine 2**\r\nOS:Ubuntu 16.04.1 LTS\r\nCUDA: 8.0\r\nCUDNN: 5.0\r\nTensorflow:0.12.1\r\nNvidia drivers: 367.48\r\nGPU:GeForce GTX TITAN.\r\n", "comments": ["It's not clear that those messages indeed indicate the problem, cc @zheng-xq  just in case. Note that each K80 card consists of two gk110 GPUs, and most things in TF don't automatically parallelize over multiple GPUs.\r\n\r\nIn terms of SGEMM FLOPS, gk110 peaks at about 3 TFLOPS whereas GTX Pascal TitanX is about 11 TFLOPS, which means there are situations where your Dual K80 setup is expected to run 4x slower than your single TitanX.", "Hi @zheng-xq and @yaroslavvb,\r\nI am also having the same problem. I am running a 2 layer bidirectional LSTM with 128 nodes in each layer, as well as some fully connected layers after. I am training in batch mode as well (16 inputs/batch) and EVERY batch I see this in the console:\r\n\r\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 2243 get requests, put_count=4572 evicted_count=2000 eviction_rate=0.437445 and unsatisfied allocation rate=0\r\n2017-05-25 15:46:06.663221: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 12011 get requests, put_count=24340 evicted_count=12000 eviction_rate=0.493016 and unsatisfied allocation rate=0\r\n2017-05-25 15:46:06.901503: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 21738 get requests, put_count=44067 evicted_count=22000 eviction_rate=0.49924 and unsatisfied allocation rate=0\r\n2017-05-25 15:46:07.138803: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 31460 get requests, put_count=63789 evicted_count=32000 eviction_rate=0.501654 and unsatisfied allocation rate=0\r\n2017-05-25 15:46:07.377981: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 41184 get requests, put_count=83513 evicted_count=42000 eviction_rate=0.502916 and unsatisfied allocation rate=0\r\n2017-05-25 15:46:07.617605: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 50905 get requests, put_count=103234 evicted_count=52000 eviction_rate=0.50371 and unsatisfied allocation rate=0\r\n2017-05-25 15:46:07.857844: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 60626 get requests, put_count=122955 evicted_count=62000 eviction_rate=0.50425 and unsatisfied allocation rate=0\r\n2017-05-25 15:46:08.094322: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 70348 get requests, put_count=142677 evicted_count=72000 eviction_rate=0.504636 and unsatisfied allocation rate=0\r\n2017-05-25 15:46:08.331157: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 80122 get requests, put_count=162451 evicted_count=82000 eviction_rate=0.504768 and unsatisfied allocation rate=0\r\n2017-05-25 15:46:08.565842: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 89849 get requests, put_count=182178 evicted_count=92000 eviction_rate=0.505001 and unsatisfied allocation rate=0\r\n2017-05-25 15:46:08.770882: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 99570 get requests, put_count=201899 evicted_count=102000 eviction_rate=0.505203 and unsatisfied allocation rate=0\r\n2017-05-25 15:46:09.042809: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 107869 get requests, put_count=220198 evicted_count=112000 eviction_rate=0.508633 and unsatisfied allocation rate=0\r\n2017-05-25 15:46:09.277130: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 117596 get requests, put_count=239925 evicted_count=122000 eviction_rate=0.508492 and unsatisfied allocation rate=0\r\n2017-05-25 15:46:09.500336: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 127318 get requests, put_count=259647 evicted_count=132000 eviction_rate=0.508383 and unsatisfied allocation rate=0\r\n2017-05-25 15:46:09.732960: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 137042 get requests, put_count=279371 evicted_count=142000 eviction_rate=0.508285 and unsatisfied allocation rate=0\r\n2017-05-25 15:46:09.965206: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 146763 get requests, put_count=299092 evicted_count=152000 eviction_rate=0.508205 and unsatisfied allocation rate=0\r\n2017-05-25 15:46:10.199228: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 156484 get requests, put_count=318813 evicted_count=162000 eviction_rate=0.508135 and unsatisfied allocation rate=0\r\n2017-05-25 15:46:10.430862: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 166206 get requests, put_count=338535 evicted_count=172000 eviction_rate=0.508072 and unsatisfied allocation rate=0\r\n2017-05-25 15:46:10.661903: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 175980 get requests, put_count=358309 evicted_count=182000 eviction_rate=0.507941 and unsatisfied allocation rate=0\r\n2017-05-25 15:46:10.892090: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 185707 get requests, put_count=378036 evicted_count=192000 eviction_rate=0.507888 and unsatisfied allocation rate=0\r\n2017-05-25 15:46:11.122478: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 195428 get requests, put_count=397757 evicted_count=202000 eviction_rate=0.507848 and unsatisfied allocation rate=0\r\n2017-05-25 15:46:11.354941: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 205154 get requests, put_count=417483 evicted_count=212000 eviction_rate=0.507805 and unsatisfied allocation rate=0\r\n\r\nBecause of this the code runs very slow. I'm running on:\r\nOS:Ubuntu 16.04.1 LTS\r\nCUDA: 8.0\r\nCUDNN: 5.1\r\nTensorflow: 1.1\r\nNvidia drivers: 375.51\r\nGPU: Tesla K80\r\n\r\nAs an additional note: the GPU is only being utilized about 60% during training. There doesn't seem to be a bottleneck on CPU because we have 4 cores and they are 70% idle. \r\n\r\nThank you SO much for your help. \r\n\r\nBest,\r\nDylan", "I also have the problem. I want to train a multi_task network and the main network I used is the inception v2 but I reduced the number of inception blocks. I wrote the code by myself.\r\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 2422 get requests, put_count=2413 evicted_count=1000 eviction_rate=0.414422 and unsatisfied allocation rate=0.457886\r\nI tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 100 to 110\r\n", "I also met the same issue with tensorflow 1.1. I used the Resnet-50 with 3 FC layers to deal with a multi-task learning problem. Here is part of my console log:\r\n\r\n`018-01-19 11:08:02.458231: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 100 to 110\r\nINFO:tensorflow:Saving checkpoints for 1 into /tmp/hopenet_model/model.ckpt.\r\n2018-01-19 11:08:29.193806: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:247] PoolAllocator: After 2333 get requests, put_count=2478 evicted_count=1000 eviction_rate=0.403551 and unsatisfied allocation rate=0.376339\r\n2018-01-19 11:08:29.193831: I tensorflow/core/common_runtime/gpu/pool_allocator.cc:259] Raising pool_size_limit_ from 256 to 281`", "All the logs you are seeing are just `INFO` logs. They are just informational.\r\nYou can tell if by the `I` right after the timestamp."]}, {"number": 7245, "title": "OutOfRangeError on FIFOQueues of different experiments", "body": "Hi,\r\n\r\nI am running some experiments with Tensorflow on a 4-GPU machine using CIFAR10 with the FIFOQueue implementation for input data pipeline. \r\n\r\nI want to simultaneously run one different instance of my experiment on each of the four GPUs,\r\nbut because the data processing queues are always places on the CPU I get an OutOfRange error and\r\ncannot run more than one instance per machine.\r\n\r\nIs there a way to overcome this? (other than placing the data processing on GPUs)\r\n\r\nThanks", "comments": ["Hi, could you please ask this on stackoverflow? We are trying to keep this list for tensorflow bugs/feature requests", "Okay"]}, {"number": 7244, "title": "Saver unable to restore from checkpoint file although it had successfully restored previously.", "body": "I am currently seeing a very strange behavior from using tf.train.Saver. Basically I had previously successfully run my code and restored all the variables from the TensorFlow-slim inception-resnet-v2 model and even obtained my losses and predictions. However, after I added some scopes to exclude in `variables_to_restore = slim.get_variables_to_restore(exclude = [...])` , which I successfully run,  when I returned back to using no excluded scope, my code actually fails. It gave me the following error:\r\n\r\n`NotFoundError (see above for traceback): Tensor name \"InceptionResnetV2/Repeat_1/block17_13/Branch_1/Conv2d_0c_7x1/BatchNorm/beta/Adam\" not found in checkpoint files ./inception_resnet_v2_2016_08_30.ckpt`\r\n\r\nHere is the code I run.\r\n```\r\nwith slim.arg_scope(inception_resnet_v2.inception_resnet_v2_arg_scope()):\r\n\tlogits, end_points = inception_resnet_v2.inception_resnet_v2(image_batch, is_training = False)\r\n\tpredictions = end_points['Predictions']\r\n\r\n#....then the typical building of operations till you get the train_op\r\n\r\nvariables_to_restore = slim.get_variables_to_restore()\r\nsaver = tf.train.Saver(variables_to_restore) #This is the line where the errors appear\r\ndef restore_fn(sess):\r\n\treturn saver.restore(sess, checkpoint_file)\r\nsv = tf.train.Supervisor(logdir = log_dir, summary_op = None, init_fn = restore_fn)\r\n```\r\n\r\nI have even replaced my checkpoint file again and this error persists. Why does this happen?\r\n\r\nI strongly suspect it might have been because the original graph has been edited again as I did not encapsulate most of the definitions within a specified graph like `with tf.Graph.as_default() as g:`, but at the start of my code I have always done `tf.reset_default_graph()`.", "comments": ["If you think it's a bug in TensorFlow you can use [inspect_checkpoint](https://github.com/tensorflow/tensorflow/blob/ec7929b878926c39255254e9aea992f0bc65aa68/tensorflow/python/tools/BUILD#L54) tool to isolate it further. IE, check what names are saved in checkpoint, and then what names are getting restored (`print tf.get_default_graph().as_graph_def()` will let you obtain you names of variables in current graph)", "@yaroslavvb After inspecting the checkpoint, I have found 908 variables to restore, but using `slim.get_variables_to_restore()` I got around 1.5k variables. Turns out it was because I defined the variables to restore after I created my train_op, which caused many more variables that weren't defined in the checkpoint file to be tried to restore. After I defined the variables to restore **immediately after** my model inference, the problem is now solved. Thank you for your help! "]}, {"number": 7243, "title": "std::system_error after tensor flow install", "body": "### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\nFound no threads matching the exact output of the problem, and troubleshooting with the tensor flow website was unsuccessful.\r\n\r\n### Environment info\r\nOperating System:\r\n\r\nCentOS Linux release 7.2.1511 (Core)\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\nN/A, we're using only CPUs for the moment. The tensor flow documentation suggests this is only an optional requirement?\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\n\r\nexport TF_BINARY_URL=https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.12.0rc0-cp27-none-linux_x86_64.whl\r\n\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n\r\n0.11.0\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n2. The output of `bazel version`\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\n```\r\nimport tensorflow as tf\r\nhello = tf.constant('Hello, TensorFlow!')\r\nsess = tf.Session()\r\n```\r\n\r\nI get:\r\n\r\n```\r\nterminate called after throwing an instance of 'std::system_error'\r\nwhat():  Resource temporarily unavailable\r\nAborted\r\n```\r\n\r\nI've looked around for the common troubleshooting with no success. Any ideas where to start?\r\n\r\n### What other attempted solutions have you tried?\r\n\r\nNone.\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n\r\nSee above.\r\n\r\nAny useful ideas of where to start debugging would be useful. ", "comments": ["Our pip packages are built on Ubuntu machines. We currently have official support for Ubuntu but not for centOS.\r\n\r\nYou might want to try building from sources using either cmake or bazel for running on centOS.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 7242, "title": "How to use Tensorflow in my android project?", "body": "I am working on a project, where I change the View with a button (working with Fragments). I am changing between a FirstFragment and a CamFragment. Now I want to use Tensorflow (it works on my phone) instead of CamFragment.\r\n\r\nWhen I \"import new Module\", I get Errors only. Do you have any Tips or solutions how I can do that?\r\n\r\nThank You\r\n", "comments": ["Thanks for you interest in TensorFlow, but for general TF usage and Android development questions we recommend that you ask on StackOverflow (I believe I responded to your question there; can't find it now though)."]}, {"number": 7241, "title": "Don't use __has_builtin with version of apple clang that doesn't supp\u2026", "body": "This is a small fix to allow the clang compiler in OS/X El Capitan \"Apple LLVM version 7.3.0 (clang-703.0.31)\"  to compile the CRC acceleration code.\r\n\r\nIt is a fix for issue: https://github.com/tensorflow/tensorflow/issues/7223\r\n\r\n\r\n", "comments": ["Can one of the admins verify this patch?", "ok - maybe this isn't the correct fix.  doesn't work on apple clang 8.0.0 either.  there is obviously some sort of library that is meant to be linked in (clang compiler-rt or something)", "@DavidNorman do you want to close this one out while you investigate, or are you going to re-use this PR?", "no - i'm done now.  as far as I can tell, the problem exists on all apple compilers.  the fix assumes that the problem will have gone away by the next major compiler release.\r\n", "@rmlarson hi. I definitely want to have this patch pulled as is. Thanks. ", "@tensorflow-jenkins test this please", "@tensorflow-jenkins test this please", "@tensorflow-jenkins test this please"]}, {"number": 7240, "title": "Add graph parameter to tf.import_graph_def()", "body": "Allows user to indicate a specific `Graph` to place `GraphDef` Operations. This keeps users from needing to use a `with g.as_default()` statement in their code. The documentation for `import_graph_def()` has also been improved to inform users that the default graph is used.. by default. For tests, I've simply done an altered version of the basic test thus far- let me know what further testing you'd like to see.\r\n\r\nThis should maintain backwards compatibility.", "comments": ["Can one of the admins verify this patch?", "Ok, we looked at this -- since we don't take graph arguments on most functions, and since this is the same behavior as \r\n\r\n```\r\nwith g.as_default():\r\n  tf.import_graph_def(...)\r\n```\r\n\r\nWe probably don't want to add the extra argument here.", "@martinwicke what are your thoughts on tweaking the documentation to indicate that the imported Ops get placed into the default graph? Something like making the first line read \"Imports the TensorFlow graph in `graph_def` into the _current default_ Python `Graph`\".", "I think that would be a good idea.\n", "Submitted the documentation change as a PR in #7325"]}, {"number": 7239, "title": "Cherrypicks for test fixes into the release", "body": "* Fix by Josh Levenberg for cmake build.\r\n\r\n* Cmake fix, take 2.", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that they're okay with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->"]}, {"number": 7238, "title": "fix cmake/windows gpu build", "body": "https://github.com/tensorflow/tensorflow/commit/191658d54f90ac03c15b339326129cd52d1f56a3 switched from dynamically loading the cuda dso's to linking them.\r\nAdd the required libraries to cmake to fix the gpu build.\r\n", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please", "Thanks for the fix @guschmue !"]}, {"number": 7237, "title": "Fix cudnn filename in configure script.", "body": "", "comments": ["@gunan looks like agent died again for the mac build. Want to just kick off that one?", "@tensorflow-jenkins test this please", "Sorry for the delay, either way, I will investigate why agents are going offline this much today."]}]