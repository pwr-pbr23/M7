[{"number": 33500, "title": "In eager mode, how to achieve weight attenuation during training, and how to customize a layer learning rate\uff1f", "body": "My environment:\r\nTensorflow1.14-gpu\r\nHello, I have set up a CNN model in eager mode. Now, I want to set a weight decay, which I did on the old version:\r\n`       \r\nreg_losses = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\r\n\r\nprint(\"Regularization losses:\")\r\n\r\nopt_loss = loss + args.weight_decay*sum(reg_losses) \r\n `\r\nBut in eager mode, this method is not very suitable. Is there any new way to provide it? I did not find a tutorial.\r\n\r\nIn addition, I want to customize the learning rate of some layers. For example, the feature extraction part of the network (such as mobilenetv3) only needs to use a small learning rate, while other parts need a large learning rate. How to achieve this?\r\n\r\nI hope someone can help me, thank you very much.", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n Thanks!\r\n"]}, {"number": 33499, "title": "Resolve isuue #32776 undeclared inclusion", "body": "I was using patch , and faced this issue #32776 , I Found an solution here in this Pull request #33106 by  , which is make sense but because of some CLA issue , I want this issue to be close ASAP , So raising this PR.", "comments": ["\"We are closing this PR as it has been copied from somebody else. This behavior is unethical and runs contrary to our TensorFlow Code of Conduct. Please do not do this. If you continue to plagiarize work, we will ban you from the project.\"\r\n"]}, {"number": 33498, "title": "TFLite slower than Keras on RPi 4", "body": "When doing inference on a Raspberry Pi 4 with Keras and Tensorflow installed using `pip`, the inference time is slower using TFLite. \r\n\r\nThe initial Keras model is about 20 mb - after converting it to TFLite it is about 2.4 mb. During inference the Keras model processes a sample in about 50 ms and TFLite does it in about 80 ms. \r\n\r\nInitially the pip-installed version of Tensorflow caused errors with TFLite, so I installed TFLite-runtime using this information: https://www.tensorflow.org/lite/guide/python\r\n\r\n\r\n\r\nDuring inference in TFLite I use the following snippet:\r\n```python\r\ninterpreter = tflite.Interpreter(model_path=CHECKPOINT)\r\ninterpreter.allocate_tensors()\r\n\r\ninput_index = interpreter.get_input_details()[0][\"index\"]\r\noutput_index = interpreter.get_output_details()[0][\"index\"]\r\n\r\nfor im in images:\r\n\tt = time.time()\r\n\t\r\n\tinp = np.expand_dims(np.expand_dims(im,-1),0)\r\n\r\n\tinterpreter.set_tensor(input_index, inp)\r\n\tinterpreter.invoke()\r\n\t\r\n\tpredictions = interpreter.get_tensor(output_index)\r\n\r\n\tprint(\"Time: {}\".format(time.time()-t),end=\"\\r\")\r\n```\r\n\r\nDoes anybody have any experience with TFLite on Raspberry Pi? Am I missing something in order accelerate inference further? It seems wrong that inference should be faster in Keras with 10x model size.", "comments": ["@JesperChristensen89 do you still having the issue with recent (2.1) TFLite package?", "@terryheo I actually think I found out that Keras automatically use all cores where as TFlite only use 1. ", "1. From TF2.3, you can control the number of threads.\r\nhttps://www.tensorflow.org/versions/r2.3/api_docs/python/tf/lite/Interpreter\r\n\r\n2. To get a speed up, you need to quantize your model to integer\r\nhttps://www.tensorflow.org/lite/performance/model_optimization\r\n\r\nThanks.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33498\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33498\">No</a>\n", "we tried with tf2.2, it was still slower than using h5 model. Will try 2.3 soon."]}, {"number": 33497, "title": "Handle indexed slice empty shapes in IndexedSlices gradients correctly.", "body": "Potential fix for https://github.com/tensorflow/tensorflow/issues/31962\r\n\r\nI ran into this after updating to the 2.0 final release. I am training a LSTM network using .fit() passing in Numpy arrays as input.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F33497) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F33497) for more info**.\n\n<!-- ok -->", "This is really small minor fix which fixes TF2.0 usage with numpy datasets. I am happy to get into this more, but it would be really good if the next patch release had this fix.", "I will get the unittests done this weekend.", "This fixes #31962 for me. Thanks! Hope this gets upstreamed."]}, {"number": 33496, "title": "//tensorflow/python/kernel_tests:decode_raw_op_test fails with Assertion error", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu 19.04 s390x\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 2.7.16\r\n- Bazel version (if compiling from source): 0.26.1\r\n- GCC/Compiler version (if compiling from source): gcc (Ubuntu 8.3.0-6ubuntu1) 8.3.0\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\n**Describe the current behavior**\r\nThe above test fails with the output array mismatch in [testToComplex64](https://github.com/tensorflow/tensorflow/blob/v2.0.0/tensorflow/python/kernel_tests/decode_raw_op_test.py#L105) and [testToComplex128](https://github.com/tensorflow/tensorflow/blob/v2.0.0/tensorflow/python/kernel_tests/decode_raw_op_test.py#L118).\r\n\r\nThe cause of failure seems to be in the byte swapping code to solve endianness problem [here](https://github.com/tensorflow/tensorflow/blob/v2.0.0/tensorflow/core/kernels/decode_raw_op.cc#L88). The code doesn't seem to work as intentioned for **complex data**.\r\n\r\n\r\n**Describe the expected behavior**\r\nThe test should pass on s390x.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nbazel test //tensorflow/python/kernel_tests:decode_raw_op_test\r\n```\r\n\r\n**Other info / logs**\r\n```\r\nAssertionError:\r\nArrays are not equal\r\n\r\nnot equal where = (array([0, 0]), array([1, 2]))\r\nnot equal lhs = [[ 2.-2.j -3.+3.j]]\r\nnot equal rhs = [-2.+2.j  3.-3.j]\r\nMismatch: 0%\r\nMax absolute difference: 8.48528137\r\nMax relative difference: 2.\r\n x: matrix([[ 1.+1.j,  2.-2.j, -3.+3.j, -4.-4.j]])\r\n y: array([[ 1.+1.j, -2.+2.j,  3.-3.j, -4.-4.j]])\r\n\r\n======================================================================\r\nFAIL: testToComplex64 (__main__.DecodeRawOpTest)\r\ntestToComplex64 (__main__.DecodeRawOpTest)\r\n----------------------------------------------------------------------\r\nAssertionError:\r\nArrays are not equal\r\n\r\nnot equal where = (array([0, 0]), array([1, 2]))\r\nnot equal lhs = [[ 2.-2.j -3.+3.j]]\r\nnot equal rhs = [-2.+2.j  3.-3.j]\r\nMismatch: 0%\r\nMax absolute difference: 8.485281\r\nMax relative difference: 2.\r\n x: matrix([[ 1.+1.j,  2.-2.j, -3.+3.j, -4.-4.j]], dtype=complex64)\r\n y: array([[ 1.+1.j, -2.+2.j,  3.-3.j, -4.-4.j]], dtype=complex64)\r\n\r\n----------------------------------------------------------------------\r\n```\r\n", "comments": ["Further Analysis shows that the real and imaginary components in the output are getting swapped with each other causing the array mismatch on Big Endian.\r\n@jiefangxuanyan I could see [PR](https://github.com/tensorflow/tensorflow/pull/9876) for fixing endianness problem in the `decode_raw_op` functionality. However, the tests for complex data types have been recently added and need more changes for incorporating this particular case.\r\nCould you please have a look?", "@abhay1722,\r\nIn the process of reproducing the error, I have cloned the Branch corresponding to TF Version 2.0 and ran the command, \r\n\r\n`bazel test //usr/local/google/home/mothukuru/tensorflow- 2.0/tensorflow/python/kernel_tests:decode_raw_op_test` but it resulted in the below error, \r\n\r\n```\r\nERROR: The 'test' command is only supported from within a workspace (below a directory having a WORKSPACE file).\r\nSee documentation at https://docs.bazel.build/versions/master/build-ref.html#workspace\r\nINFO: Writing tracer profile to '/usr/local/google/home/mothukuru/.cache/bazel/_bazel_mothukuru/d41d8cd98f00b204e9800998ecf8427e/command.profile.gz'\r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\n```\r\n\r\nCan you please help us reproduce the error. Thanks!", "> @abhay1722,\r\n> In the process of reproducing the error, I have cloned the Branch corresponding to TF Version 2.0 and ran the command,\r\n> \r\n> `bazel test //usr/local/google/home/mothukuru/tensorflow- 2.0/tensorflow/python/kernel_tests:decode_raw_op_test` but it resulted in the below error,\r\n> \r\n> ```\r\n> ERROR: The 'test' command is only supported from within a workspace (below a directory having a WORKSPACE file).\r\n> See documentation at https://docs.bazel.build/versions/master/build-ref.html#workspace\r\n> INFO: Writing tracer profile to '/usr/local/google/home/mothukuru/.cache/bazel/_bazel_mothukuru/d41d8cd98f00b204e9800998ecf8427e/command.profile.gz'\r\n> WARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\n> ```\r\n> \r\n> Can you please help us reproduce the error. Thanks!\r\n\r\n@rmothukuru I suggest that you run the test from the location where you have cloned the Tensorflow repo.\r\nFor instance, If I clone the [repo](https://github.com/tensorflow/tensorflow.git) in the `/home/test` folder, then I must do the following:-\r\n```\r\ncd /home/test/tensorflow/\r\nbazel test //tensorflow/python/kernel_tests:decode_raw_op_test\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33496\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33496\">No</a>\n"]}, {"number": 33495, "title": "Simple Audio Recognition validation seems error", "body": "my tf version is 1.14.0. I download the code from the newest git for the example Simple Audio Recognition, and run the train.py, but after running several steps, the validation  acc seems not change at all, alse the confusion matrix, all the predict result is the first class. but the training acc is normal, after 8000 steps, about 80%.\r\n![image](https://user-images.githubusercontent.com/31615877/67067057-7f5acb80-f1a7-11e9-852a-ca218bebd8a3.png)\r\n![image](https://user-images.githubusercontent.com/31615877/67067081-939ec880-f1a7-11e9-85d2-f027f4a8749d.png)\r\n", "comments": ["@ArtemisZGL, Please provide the information asked in template.\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.", "i change to tf2.0 and everything is ok"]}, {"number": 33494, "title": "CTC tensorflow lite conversion problem", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 19.04\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version (or github SHA if from source): 2.0\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n```\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: . Here is a list of operators for which you will need custom implementations: CTC_BEAM_SEARCH_DECODER.```\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\nimport tensorflow as tf\r\nclass BasicModel(tf.Module):\r\n  def __init__(self):\r\n    self.const = None\r\n  @tf.function(input_signature=[tf.TensorSpec(shape=[None,500,28], dtype=tf.float32),tf.TensorSpec(shape=[None,], dtype=tf.int32)])\r\n  def decoder(self, logits,seq_len):\r\n    decoded, log_prob = tf.nn.ctc_beam_search_decoder(logits, seq_len)\r\n    return decoded\r\n# Create the tf.Module object.\r\nroot = BasicModel()\r\n# Get the concrete function.\r\nconcrete_func = root.decoder.get_concrete_function()\r\nconverter = tf.lite.TFLiteConverter.from_concrete_functions([concrete_func])\r\nconverter.allow_custom_ops = False\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,tf.lite.OpsSet.SELECT_TF_OPS]\r\ntflite_model =converter.convert()\r\n\r\nopen(\"ctc_greedy_decoder.tflite\",'wb').write(tflite_model)\r\n\r\n**Any other info / logs**\r\n\r\nBut according to this link https://github.com/tensorflow/tensorflow/tree/r2.0/tensorflow/lite/experimental/kernels ctc_beam_search_decoder is registered as tflite op.\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Hi,\r\n\r\nCould you change this line:\r\nconverter.allow_custom_ops = False\r\n\r\nto\r\nconverter.allow_custom_ops = True\r\n\r\n\r\nI run your script in TF 2 and can successfully do the conversion.", "But if I do converter.allow_custom_ops=True I can convert it to tflite but I am not able to use it.\r\nHere is the error :\r\nTraceback (most recent call last):\r\n  File \"tflite.py\", line 34, in <module>\r\n    inference_from_tflite(pbfile_path)\r\n  File \"tflite.py\", line 24, in inference_from_tflite\r\n    interpreter.allocate_tensors()\r\n  File \"/home/mihup/anaconda3/lib/python3.7/site-packages/tensorflow_core/lite/python/interpreter.py\", line 244, in allocate_tensors\r\n    return self._interpreter.AllocateTensors()\r\n  File \"/home/mihup/anaconda3/lib/python3.7/site-packages/tensorflow_core/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py\", line 106, in AllocateTensors\r\n    return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)\r\nRuntimeError: Encountered unresolved custom op: CTC_BEAM_SEARCH_DECODER.Node number 0 (CTC_BEAM_SEARCH_DECODER) failed to prepare.\r\n\r\nCode used for inference:\r\ninterpreter = tf.lite.Interpreter(model_path=tflite_model)\r\ninterpreter.allocate_tensors()\r\ninput_details = interpreter.get_input_details()\r\noutput_details = interpreter.get_output_details()\r\ninterpreter.invoke()\r\nprint(input_details,output_details)\r\n", "This seems like the default op resolver couldn't find the op kernel for CTC_BEAM_SEARCH_DECODER.\r\n\r\nI guess you need to implement something like this:\r\ntflite::ops::builtin::BuiltinOpResolver builtins;\r\nbuiltins.AddCustom(\"CTCBeamSearchDecoder\", Register_CTC_BEAM_SEARCH_DECODER());\r\n\r\nThe corresponding python interpreter to use with custom op is:\r\nhttps://github.com/tensorflow/tensorflow/blob/0dec1a6a8a5d7a40378ab418ceab20cd6d4adb4b/tensorflow/lite/python/interpreter.py#L499\r\n\r\nPlease See link:https://www.tensorflow.org/lite/guide/ops_custom#defining_the_kernel_in_the_tensorflow_lite_runtime", "The corresponding python interpreter   \"class InterpreterWithCustomOps(Interpreter): \"  to use with custom op is not present in the stable releases like  1.14,1.15,2.0 .\r\nPython interpreter \"class InterpreterWithCustomOps(Interpreter): \" is only available in the master branch.\r\nHow can I use it as I cannot use master branch with pip install", "@haozha111 @gadagashwini  please look into it.", "@haozha111 any update on this?", "Hi!\r\n\r\nInterpreterWithCustomOps seems not the correct recommendation here, since it's currently not exposed as the public API. Looping in @jdduke to take a look. Hi Jared, do you know the recommended interpreter API to use when the model contains customs ops such as ctc beam search decoder? AFAIK the model can convert but it encounters a kernel registration issue during runtime.", "@tulasiram58827 just to be clear, do you want Python support primarily for testing? Or you plan on deploying your model in a Python environment? You can use `InterpreterWithCustomOps` if you build from source. How else did you want to plug in your custom ops into that function? Would you be linking it into the TF runtime?", "@jdduke I planned for deploying my model in cpp enviornment. I want to converty my ctc model to tflite and use it in tflite runtime. I can easily convert my model to tflite by specifying this while conversion(converter.allow_custom_ops = True) but in runtime i am facing difficulties that this op is not registered. Please check this log.\r\nHere is the error :\r\nTraceback (most recent call last):\r\nFile \"tflite.py\", line 34, in\r\ninference_from_tflite(pbfile_path)\r\nFile \"tflite.py\", line 24, in inference_from_tflite\r\ninterpreter.allocate_tensors()\r\nFile \"/home/mihup/anaconda3/lib/python3.7/site-packages/tensorflow_core/lite/python/interpreter.py\", line 244, in allocate_tensors\r\nreturn self._interpreter.AllocateTensors()\r\nFile \"/home/mihup/anaconda3/lib/python3.7/site-packages/tensorflow_core/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py\", line 106, in AllocateTensors\r\nreturn _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)\r\nRuntimeError: Encountered unresolved custom op: CTC_BEAM_SEARCH_DECODER.Node number 0 (CTC_BEAM_SEARCH_DECODER) failed to prepare.", "@jdduke Any update?", "I see, you would need to link in the CTC_BEAM_SEARCH_DECODER custom op manually. So you'd have to update the [builtin deps](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/BUILD#L625) to include [this dependency](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/kernels/BUILD#L39), then manually register that kernel [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/register.cc#L315) via:\r\n\r\n```\r\nAddCustom(\"CTC_BEAM_SEARCH_DECODER\",\r\n            tflite::ops::experimental::Register_CTC_BEAM_SEARCH_DECODER());\r\n```", "Thanks @jdduke for the pointers. But with this modifications we need to compile tensorflow from source. Is it possible to add this op in next tensorflow release or atleast in TF Nightly because CTC is something widely used in Speech Recognition engines and also OCR engines. Recently i am working to make on device OCR possible in this [Repository](https://github.com/tulasiram58827/ocr_tflite) But at the end we need a CTC Decoder to do post processing. It would be very great if TFLite team can add support to CTC op.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33494\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33494\">No</a>\n", "@tulasiram58827 can you confirm that, by building from source with that op included as a custom op, your model runs successfully? If so, we can look into adding it as a builtin operator. Thanks. It would also help if you can attach the model that is created if you allow custom ops. Thanks.", "@jdduke I tried building from source including custom op but it seems like `ctc_beam_search_decoder.cc` file is missing. Please find the error here.\r\n\r\n> ERROR: missing input file 'tensorflow/lite/kernels/ctc_beam_search_decoder.cc', owner: '//tensorflow/lite/kernels:ctc_beam_search_decoder.cc'\r\n", "The kernel is actually defined here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/kernels/BUILD#L39. So you would need to add\r\n\r\n```\r\n//tensorflow/lite/experimental/kernels:ctc_beam_search_decoder_op\r\n```\r\n\r\nto the builtin deps [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/BUILD#L653), then add a line that registers it with the builtin op registry [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/register.cc#L318).\r\n\r\nThat should make it available for any target you build from source.", "Thanks @jdduke .Previous error was resolved. New error popped out.\r\n> ERROR: /home/ram/Projects/tensorflow/tensorflow/lite/kernels/BUILD:781:1: C++ compilation of rule '//tensorflow/lite/kernels:builtin_ops' failed (Exit 1)\r\ntensorflow/lite/kernels/register.cc: In constructor 'tflite::ops::builtin::BuiltinOpResolver::BuiltinOpResolver()':\r\ntensorflow/lite/kernels/register.cc:322:26: error: 'tflite::ops::experimental' has not been declared\r\n             tflite::ops::experimental::Register_CTC_BEAM_SEARCH_DECODER());\r\n", "You need to forward declare it first, e.g., https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/register.cc#L27,  but in the right experimental namespace.", "Hi @jdduke With the new version of TensorFlow 2.4 my conversion of CTC Decoder is successful by enabling TFLite Ops \r\n```\r\nconverter.target_spec.supported_ops = [\r\n          tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\r\n          tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\r\n      ]\r\n```\r\n\r\nMy issue is solved. You can check this [OCR Notebook](https://github.com/tulasiram58827/ocr_tflite/blob/main/colabs/KERAS_OCR_TFLITE.ipynb) where I successfully used and converted CTC Decoder to TFLite.", "Great!"]}, {"number": 33493, "title": "Add custom_object argument for keras model", "body": "Fix load_keras_model() cannot load custom classes and functions.", "comments": ["I don't think we can accept this PR; 1.13 has already been released, and we're only doing patch releases for it. Contrib is no longer packaged in newer releases.\r\n\r\nPlease try the new SavedModel format support in tf.keras.Model.save."]}, {"number": 33492, "title": "add INT8 quantization support for the OP RESIZE_NEAREST_NEIGHBOR", "body": "This commit is to address the issue where UpSample2D was not supported during the tflite conversion with INT8 quantization. \r\n\r\nThe bug was due to the missing `RESIZE_NEAREST_NEIGHBOR` property in `operator_property.cc`.\r\n\r\nThis addresses the issue https://github.com/tensorflow/tensorflow/issues/33438 .", "comments": []}, {"number": 33491, "title": "[TF2.0.0]ValueError: The two structures don't have the same nested structure.", "body": "I can run my code in tensorflow==2.0.0b1, but when I update tensorflow to 2.0.0; I got an error;\r\nThis is my code:\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow import feature_column\r\n\r\nprint('tf version:', tf.__version__)\r\n\r\nfeature_description = {\r\n    'h_k_u_watchanch_his': tf.io.VarLenFeature(tf.string),\r\n    'a_gender': tf.io.FixedLenFeature(shape=(1,), dtype=tf.int64),\r\n    'l_label': tf.io.FixedLenFeature([], tf.int64)\r\n}\r\nfeature_columns = []\r\nthal = feature_column.categorical_column_with_hash_bucket(\r\n    'h_k_u_watchanch_his', hash_bucket_size=100\r\n)\r\nthal_one_hot = feature_column.embedding_column(thal, dimension=10, combiner='mean')\r\nfeature_columns.append(thal_one_hot)\r\n\r\ndataSet = tf.data.TFRecordDataset(\r\n    \"/Users/lyx/projects/recommend/embedding/tmp/PUSH.TFRecords/dt=20191012/hour=10/part-r-00000\")\r\n\r\n\r\ndef _parse_function(serilized_example):\r\n    feature = tf.io.parse_single_example(\r\n        serilized_example,\r\n        feature_description\r\n    )\r\n    label = feature.get('l_label')\r\n    return feature, label\r\n\r\n\r\nparsed_dataset = dataSet.map(_parse_function)\r\n\r\ninput1 = tf.keras.Input(shape=(), name='h_k_u_watchanch_his', sparse=True, dtype=tf.string)\r\ninput2 = tf.keras.Input(shape=(), name='a_gender', dtype=tf.int64)\r\n\r\ninput_layers = {'h_k_u_watchanch_his': input1, 'a_gender': input2}\r\nfeature_layer = tf.keras.layers.DenseFeatures(feature_columns, name='DenseFeatures')(input_layers)\r\noutputs = tf.keras.layers.Dense(1, activation='sigmoid')(feature_layer)\r\nmodel = tf.keras.Model(inputs=[input1, input2], outputs=outputs)\r\n\r\nmodel.compile(\r\n    optimizer='adam',\r\n    loss='binary_crossentropy',\r\n    metrics=['accuracy']\r\n)\r\n\r\nmodel.fit(\r\n    x=parsed_dataset,\r\n    validation_data=parsed_dataset,\r\n    epochs=5,\r\n)\r\n\r\nloss, accuracy = model.evaluate(parsed_dataset)\r\nprint(\"Accuracy\", accuracy)\r\n```\r\n\r\nError output:\r\n```\r\ntf version: 2.0.0\r\n2019-10-18 09:59:10.095365: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-10-18 09:59:10.118556: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbcd9c21e00 executing computations on platform Host. Devices:\r\n2019-10-18 09:59:10.118572: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\", line 318, in assert_same_structure\r\n    expand_composites)\r\nValueError: The two structures don't have the same nested structure.\r\n\r\nFirst structure: type=TensorSpec str=TensorSpec(shape=(1,), dtype=tf.int64, name=None)\r\n\r\nSecond structure: type=SparseTensor str=SparseTensor(indices=Tensor(\"h_k_u_watchanch_his/indices:0\", shape=(None, 1), dtype=int64), values=Tensor(\"h_k_u_watchanch_his/values:0\", shape=(None,), dtype=string), dense_shape=Tensor(\"h_k_u_watchanch_his/shape:0\", shape=(1,), dtype=int64))\r\n\r\nMore specifically: Substructure \"type=SparseTensor str=SparseTensor(indices=Tensor(\"h_k_u_watchanch_his/indices:0\", shape=(None, 1), dtype=int64), values=Tensor(\"h_k_u_watchanch_his/values:0\", shape=(None,), dtype=string), dense_shape=Tensor(\"h_k_u_watchanch_his/shape:0\", shape=(1,), dtype=int64))\" is a sequence, while substructure \"type=TensorSpec str=TensorSpec(shape=(1,), dtype=tf.int64, name=None)\" is not\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/lyx/projects/recommend/embedding/tmp/test.py\", line 52, in <module>\r\n    epochs=5,\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 728, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 224, in fit\r\n    distribution_strategy=strategy)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 547, in _process_training_inputs\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 594, in _process_inputs\r\n    steps=steps)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 2497, in _standardize_user_data\r\n    nest.assert_same_structure(a, b, expand_composites=True)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\", line 325, in assert_same_structure\r\n    % (str(e), str1, str2))\r\nValueError: The two structures don't have the same nested structure.\r\n\r\nFirst structure: type=TensorSpec str=TensorSpec(shape=(1,), dtype=tf.int64, name=None)\r\n\r\nSecond structure: type=SparseTensor str=SparseTensor(indices=Tensor(\"h_k_u_watchanch_his/indices:0\", shape=(None, 1), dtype=int64), values=Tensor(\"h_k_u_watchanch_his/values:0\", shape=(None,), dtype=string), dense_shape=Tensor(\"h_k_u_watchanch_his/shape:0\", shape=(1,), dtype=int64))\r\n\r\nMore specifically: Substructure \"type=SparseTensor str=SparseTensor(indices=Tensor(\"h_k_u_watchanch_his/indices:0\", shape=(None, 1), dtype=int64), values=Tensor(\"h_k_u_watchanch_his/values:0\", shape=(None,), dtype=string), dense_shape=Tensor(\"h_k_u_watchanch_his/shape:0\", shape=(1,), dtype=int64))\" is a sequence, while substructure \"type=TensorSpec str=TensorSpec(shape=(1,), dtype=tf.int64, name=None)\" is not\r\nEntire first structure:\r\n.\r\nEntire second structure:\r\n.\r\n\r\n```\r\n\r\nLooking forward to your reply!", "comments": ["I am able to reproduce the issue with TF 2.0.0.Please see the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/5453b2363c7e9509292d8cb440236841/untitled212.ipynb). Thanks!", "@yxleung, Please provide the `dataSet` file to verify with TF 2.0.0.beta1. Thanks!", "> @yxleung, Please provide the `dataSet` file to verify with TF 2.0.0.beta1. Thanks!\r\n\r\nHow can I upload the  TFRecord dataset?", "@yxleung, Will it be possible to make zip file of dataSet and include it here. Thanks!", "> @yxleung, Will it be possible to make zip file of dataSet and include it here. Thanks!\r\nThis is tfrecord dataset.\r\n[part-r-00000.zip](https://github.com/tensorflow/tensorflow/files/3766190/part-r-00000.zip)\r\n", "It works as expected with Tf 2.0 beta1. Please see the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/3730b5cf52560b399c05d1c236fb1555/untitled.ipynb). Thanks!", "> It works as expected with Tf 2.0 beta1. Please see the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/3730b5cf52560b399c05d1c236fb1555/untitled.ipynb). Thanks!\r\n\r\nyes,I can run my code in tensorflow==2.0.0b1, but when I update tensorflow to 2.0.0; I got an error; Is it tensorflow2.0.0 bug?", "same problem in tf2.1.0, any solution? @omalleyt12 ", "> same problem in tf2.1.0, any solution? @omalleyt12\r\n\r\nSame problem...", "I had a similar problem involving `tf.map_fn` and I solved it by indicating the `dtype`, as advised [here](https://stackoverflow.com/questions/42776980/valueerror-the-two-structures-dont-have-the-same-number-of-elements). I see that `map_fn` is not involved here, but maybe something similar is happening where a `dtype` is not specified where it should be. For `map_fn`, it is actually indicated in the [docs](https://www.tensorflow.org/api_docs/python/tf/map_fn) that you should provide it if the `dtype` of the output is not the same as the input.", "> I had a similar problem involving `tf.map_fn` and I solved it by indicating the `dtype`, as advised [here](https://stackoverflow.com/questions/42776980/valueerror-the-two-structures-dont-have-the-same-number-of-elements). I see that `map_fn` is not involved here, but maybe something similar is happening where a `dtype` is not specified where it should be. For `map_fn`, it is actually indicated in the [docs](https://www.tensorflow.org/api_docs/python/tf/map_fn) that you should provide it if the `dtype` of the output is not the same as the input.\r\n\r\n@yxleung,\r\nIs this still an issue? Could you please check @zaccharieramzi's comment and let us know if it helps. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33491\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33491\">No</a>\n", "> > I had a similar problem involving `tf.map_fn` and I solved it by indicating the `dtype`, as advised [here](https://stackoverflow.com/questions/42776980/valueerror-the-two-structures-dont-have-the-same-number-of-elements). I see that `map_fn` is not involved here, but maybe something similar is happening where a `dtype` is not specified where it should be. For `map_fn`, it is actually indicated in the [docs](https://www.tensorflow.org/api_docs/python/tf/map_fn) that you should provide it if the `dtype` of the output is not the same as the input.\r\n> \r\n> @yxleung,\r\n> Is this still an issue? Could you please check @zaccharieramzi's comment and let us know if it helps. Thanks!\r\n\r\nI get this same error message. when I am trying to load a model with tf.keras.models.load. ", "> I get this same error message. when I am trying to load a model with tf.keras.models.load.\r\n\r\n@Santosh-Gupta,\r\nCould you please submit a new issue from [this link](https://github.com/tensorflow/tensorflow/issues/new/choose) and fill in the template so that we can track the issue there. Thanks!", "> > I get this same error message. when I am trying to load a model with tf.keras.models.load.\r\n> \r\n> @Santosh-Gupta,\r\n> Could you please submit a new issue from [this link](https://github.com/tensorflow/tensorflow/issues/new/choose) and fill in the template so that we can track the issue there. Thanks!\r\n\r\nFrom my search it seems that it just may be due to using a custom model, so I am not 100% sure of if its a bug. \r\n\r\nHere's is a stackoverflow post I made of this, \r\n\r\nhttps://stackoverflow.com/questions/62433195/tensorflow-keras-models-load-model-results-in-valueerror-the-two-structures\r\n\r\nIf this looks like a bug I would be happy to fill out the form. \r\n\r\n\r\n\r\n", "@Santosh-Gupta did you manage to find a solution?", "In tf.2.2.0 it's seems to be solved.", "I just used save_weights instead ", "> I just used save_weights instead\r\n\r\nYou basically solved the issue by just avoiding it. I think this is still an important issue even in TF 2.3.0. I get the error on Transfer Learning with Hugging Face Bert models. I created my model and saved on the end of the training. To deploy with Flask, I simply tried to load the saved model but got:\r\n\r\nValueError: The two structures don't have the same nested structure.\r\n\r\nFirst structure: type=TensorSpec str=TensorSpec(shape=(None, 512), dtype=tf.int32, name='inputs')\r\n\r\nSecond structure: type=dict str={'input_ids': TensorSpec(shape=(None, 5), dtype=tf.int32, name='input_ids')}", "@Subfly did you manage to solve this issue by any chance?", "> > I just used save_weights instead\r\n> \r\n> You basically solved the issue by just avoiding it. I think this is still an important issue even in TF 2.3.0. I get the error on Transfer Learning with Hugging Face Bert models. I created my model and saved on the end of the training. To deploy with Flask, I simply tried to load the saved model but got:\r\n> \r\n> ValueError: The two structures don't have the same nested structure.\r\n> \r\n> First structure: type=TensorSpec str=TensorSpec(shape=(None, 512), dtype=tf.int32, name='inputs')\r\n> \r\n> Second structure: type=dict str={'input_ids': TensorSpec(shape=(None, 5), dtype=tf.int32, name='input_ids')}\r\n\r\nnot really solve your problem, but Flask should not be used to deploy tensorflow :) better user tensorflow-serving.", "Bump. This is still not solved on 2.3.\r\n@gadagashwini ", "@dshahrokhian,\r\nCould you please submit a new issue from [this link](https://github.com/tensorflow/tensorflow/issues/new/choose) and fill in the template, so that we can track the issue there. Thanks!", "@amahendrakar I can confirm that this issue was solved in TF-nightly (2.4). \r\n\r\nThank you for the support!", "> > I just used save_weights instead\r\n> \r\n> You basically solved the issue by just avoiding it. I think this is still an important issue even in TF 2.3.0. I get the error on Transfer Learning with Hugging Face Bert models. I created my model and saved on the end of the training. To deploy with Flask, I simply tried to load the saved model but got:\r\n> \r\n> ValueError: The two structures don't have the same nested structure.\r\n> \r\n> First structure: type=TensorSpec str=TensorSpec(shape=(None, 512), dtype=tf.int32, name='inputs')\r\n> \r\n> Second structure: type=dict str={'input_ids': TensorSpec(shape=(None, 5), dtype=tf.int32, name='input_ids')}\r\n\r\n@Subfly @MattdaVill  \r\n\r\nI solved it with\r\n> change\r\n>`base_output = base_model([ids, mask, token_type_ids])` \r\n>to\r\n>`base_output = base_model.bert([ids, mask, token_type_ids])`\r\n\r\nhere is the issue ablout this problem in huggingface-transformers [https://github.com/huggingface/transformers/issues/3627](https://github.com/huggingface/transformers/issues/3627)\r\n\r\nI think the reason for that works may be that `self.bert=TFBertMainLayer(config, name=\"bert\")`  and `TFBertMainLayer` is inherited from `tf.keras.layers.Layer`"]}, {"number": 33490, "title": "Some of the operators in the model are not supported by the standard TensorFlow Lite runtime!!!", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (or github SHA if from source):\r\n\r\n OS Platform and Distribution: **WIn10**\r\n TensorFlow installed from  **binary**\r\n  TensorFlow version  **TF2.0 '2.1.0-dev20191015'**\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONCATENATION, CONV_2D, FILL, LEAKY_RELU, MEAN, MUL, PACK, RESHAPE, REVERSE_V2, SHAPE, STRIDED_SLICE, TRANSPOSE. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.\r\nTraceback (most recent call last):\r\n  File \"d:\\users\\zhenk\\anaconda3\\envs\\tensorflow2.0\\lib\\runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"d:\\users\\zhenk\\anaconda3\\envs\\tensorflow2.0\\lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"D:\\Users\\zhenk\\Anaconda3\\envs\\tensorflow2.0\\Scripts\\toco_from_protos.exe\\__main__.py\", line 9, in <module>\r\n  File \"d:\\users\\zhenk\\anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\tensorflow_core\\lite\\toco\\python\\toco_from_protos.py\", line 89, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"d:\\users\\zhenk\\anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\tensorflow_core\\python\\platform\\app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"d:\\users\\zhenk\\anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\absl\\app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"d:\\users\\zhenk\\anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\absl\\app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"d:\\users\\zhenk\\anaconda3\\envs\\tensorflow2.0\\lib\\site-packages\\tensorflow_core\\lite\\toco\\python\\toco_from_protos.py\", line 52, in execute\r\n    enable_mlir_converter)\r\nException: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONCATENATION, CONV_2D, FILL, LEAKY_RELU, MEAN, MUL, PACK, RESHAPE, REVERSE_V2, SHAPE, STRIDED_SLICE, TRANSPOSE. Here is a list of operators for which you will need custom implementations: TensorListFromTensor, TensorListReserve, TensorListStack, While.\r\n\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n\r\n**Any other info / logs**\r\n\r\nCan you help me ? If I want to use this model in TensorFlow Lite , what shall I do? \r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["As the error message suggested you will need custom implementations for following operations;\r\n```TensorListFromTensor, TensorListReserve, TensorListStack, While.```\r\n\r\n- To make a custom op you may refer https://www.tensorflow.org/lite/guide/ops_custom\r\n- You can also raise a request to add these features in TF by commenting on this issue thread.\r\n  https://github.com/tensorflow/tensorflow/issues/21526\r\n- You can try converting your model using ```TFLITE_BUILTINS, SELECT_TF_OPS``` flags to reduce custom implementation of ops (only a subset of ops can be implemented by this method while others may still require custom implementation )", "Thank you for your reply! I have found this https://github.com/tensorflow/tensorflow/issues/33416. \r\n\r\nvcarpani says \"so my problem could be solved by adding TensorListFromTensor, TensorListReserve, TensorListStack, While to the whitelist here and use the standard tensorflow implementation.\"", "I finally solved this problem using the following code\r\n\r\n---------------------------------------------------------------------------------------------------------------\r\nconverter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\r\nconverter.allow_custom_ops=True\r\ntflite_model = converter.convert()\r\n--------------------------------------------------------------------------------------------------------------\r\n", "I have solved  this problem.", "> I finally solved this problem using the following code\r\n> \r\n> ## converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\r\n> converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\r\n> converter.allow_custom_ops=True\r\n> tflite_model = converter.convert()\r\n\r\n@hzk7287 \r\nI follow your code, but I still get the same error.\r\n`converter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\r\nconverter.allow_custom_ops=True\r\ntflite_model = converter.convert()`\r\n\r\nError as follows.\r\n\r\n`RuntimeError                              Traceback (most recent call last)\r\n<ipython-input-13-ca8eb7ec6089> in <module>()\r\n      1 # interpreter = tf.lite.Interpreter(model_content=tflite_model)\r\n----> 2 interpreter.allocate_tensors()\r\n      3 # help(tf.lite.Interpreter)\r\n\r\n~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\lite\\python\\interpreter.py in allocate_tensors(self)\r\n    242   def allocate_tensors(self):\r\n    243     self._ensure_safe()\r\n--> 244     return self._interpreter.AllocateTensors()\r\n    245 \r\n    246   def _safe_to_run(self):\r\n\r\n~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow_core\\lite\\python\\interpreter_wrapper\\tensorflow_wrap_interpreter_wrapper.py in AllocateTensors(self)\r\n    104 \r\n    105     def AllocateTensors(self):\r\n--> 106         return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)\r\n    107 \r\n    108     def Invoke(self):\r\n\r\nRuntimeError: Encountered unresolved custom op: TensorListFromTensor.Node number 710 (TensorListFromTensor) failed to prepare.`\r\n\r\nI am trying to convert EfficientDet in https://github.com/xuannianz/EfficientDet, which is based on fizyr/keras-retinanet in https://github.com/fizyr/keras-retinanet. \r\nMy tensorflow is 1.15.0.", "> As the error message suggested you will need custom implementations for following operations;\r\n> `TensorListFromTensor, TensorListReserve, TensorListStack, While.`\r\n> \r\n> * To make a custom op you may refer https://www.tensorflow.org/lite/guide/ops_custom\r\n> * You can also raise a request to add these features in TF by commenting on this issue thread.\r\n>   #21526\r\n> * You can try converting your model using `TFLITE_BUILTINS, SELECT_TF_OPS` flags to reduce custom implementation of ops (only a subset of ops can be implemented by this method while others may still require custom implementation )\r\n\r\n@ymodak Hi, Could you share your custom implementations for following operations;\r\nTensorListFromTensor, TensorListReserve, TensorListStack, While? And how to use them?", "I had a similar error as above using tensorflow 2.2:\r\n\r\n```\r\nerror: failed to legalize operation 'tf.TensorListReserve'\r\n```\r\n\r\nand\r\n\r\n```\r\nerror: requires element_dtype to be 1-bit/8-bit/16-bit/32-bit/64-bit integer or 16-bit/32-bit/64-bit float type during TF Lite transformation pass\r\n```\r\n\r\nI fixed it by using:\r\n\r\n```python\r\nconverter = TFLiteConverter.from_saved_model(model_dir)\r\nconverter.experimental_new_converter = False\r\nconverter.optimizations = [tf.lite.Optimize.OPTIMIZE_FOR_SIZE]\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\r\nconverter.allow_custom_ops=True\r\ntflite_model = converter.convert()\r\n```\r\n\r\nCompared to the fix by @hzk7287 in https://github.com/tensorflow/tensorflow/issues/33490#issuecomment-544847214, this also disables the new experimental converter. "]}, {"number": 33489, "title": "Issue building on OSX 10.13", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OSX 10.13.6 High Sierra\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 1.14.0\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source): 0.25.2\r\n- GCC/Compiler version (if compiling from source): clang\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: NVIDIA GeForce GTX 1080 ti\r\n\r\n**Describe the problem**\r\n\r\nHi,\r\nI am building Tensorflow 1.14.0 on my High Sierra, but I am facing an issue during the build time, I try also the latest 1.15.0 and I have exactly the same trouble, I try to find a solution but so far no luck, any idea or suggestion ?\r\n\r\nIt seems the issue is related to absl but looking and trying to modify the compressed_tuple.h do not seems to change anything.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```\r\nbazel build --config=cuda --config=opt --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" --action_env PATH --action_env LD_LIBRARY_PATH --action_env DYLD_LIBRARY_PATH //tensorflow/tools/pip_package:build_pip_package --verbose_failures --config=nonccl\r\n```\r\n\r\n**Any other info / logs**\r\n\r\n```\r\nexternal/com_google_absl/absl/container/internal/compressed_tuple.h:170:53: error: use 'template' keyword to treat 'Storage' as a dependent template name\r\nreturn (std::move(*this).internal_compressed_tuple::Storage< CompressedTuple, I> ::get());\r\n                                                    ^\r\n                                                    template\r\nexternal/com_google_absl/absl/container/internal/compressed_tuple.h:176:54: error: use 'template' keyword to treat 'Storage' as a dependent template name\r\nreturn (absl::move(*this).internal_compressed_tuple::Storage< CompressedTuple, I> ::get());\r\n                                                     ^\r\n                                                     template\r\n```", "comments": ["I was able to find a work around by patching abseil.\r\n"]}, {"number": 33488, "title": "Update word2vec_basic.py #33448", "body": "Update word2vec_basic.py #33448", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F33488) for more info**.\n\n<!-- need_author_consent -->"]}, {"number": 33487, "title": "Why is TensorFlow 2 much slower than TensorFlow 1?", "body": "It's been cited by many users as the reason for switching to Pytorch, but I've yet to find a justification / explanation for sacrificing the most important practical quality, speed, for eager execution.\r\n\r\nBelow is code benchmarking performance, TF1 vs. TF2 - with TF1 running anywhere from **47% to 276% faster**.\r\n\r\nMy question is: _what is it, at the graph or hardware level, that yields such a significant slowdown?_\r\n\r\n<hr>\r\n\r\nLooking for a detailed answer - am already familiar with broad concepts.  [Relevant SO](https://stackoverflow.com/questions/58441514/why-is-tensorflow-2-much-slower-than-tensorflow-1)\r\n\r\n**Specs**: CUDA 10.0.130, cuDNN 7.4.2, Python 3.7.4, Windows 10, GTX 1070\r\n\r\n<hr>\r\n\r\n**Benchmark results**:\r\n\r\n<img src=\"https://i.stack.imgur.com/ayBCS.png\" width=\"530\">\r\n\r\n<hr>\r\n\r\n**Benchmark code**:\r\n\r\n```python\r\n# use tensorflow.keras... to benchmark tf.keras; used GPU for all above benchmarks\r\nfrom keras.layers import Input, Dense, LSTM, Bidirectional, Conv1D\r\nfrom keras.layers import Flatten, Dropout\r\nfrom keras.models import Model\r\nfrom keras.optimizers import Adam\r\nimport keras.backend as K\r\nimport numpy as np\r\nfrom time import time\r\n\r\nbatch_shape = (32, 400, 16)\r\nX, y = make_data(batch_shape)\r\n\r\nmodel_small = make_small_model(batch_shape)\r\nmodel_small.train_on_batch(X, y)  # skip first iteration which builds graph\r\ntimeit(model_small.train_on_batch, 200, X, y)\r\n\r\nK.clear_session()  # in my testing, kernel was restarted instead\r\n\r\nmodel_medium = make_medium_model(batch_shape)\r\nmodel_medium.train_on_batch(X, y)  # skip first iteration which builds graph\r\ntimeit(model_medium.train_on_batch, 10, X, y)\r\n```\r\n\r\n<hr>\r\n\r\n**Functions used**:\r\n\r\n```python\r\ndef timeit(func, iterations, *args):\r\n    t0 = time()\r\n    for _ in range(iterations):\r\n        func(*args)\r\n    print(\"Time/iter: %.4f sec\" % ((time() - t0) / iterations))\r\n\r\ndef make_small_model(batch_shape):\r\n    ipt   = Input(batch_shape=batch_shape)\r\n    x     = Conv1D(128, 400, strides=4, padding='same')(ipt)\r\n    x     = Flatten()(x)\r\n    x     = Dropout(0.5)(x)\r\n    x     = Dense(64, activation='relu')(x)\r\n    out   = Dense(1,  activation='sigmoid')(x)\r\n    model = Model(ipt, out)\r\n    model.compile(Adam(lr=1e-4), 'binary_crossentropy')\r\n    return model\r\n\r\ndef make_medium_model(batch_shape):\r\n    ipt   = Input(batch_shape=batch_shape)\r\n    x     = Bidirectional(LSTM(512, activation='relu', return_sequences=True))(ipt)\r\n    x     = LSTM(512, activation='relu', return_sequences=True)(x)\r\n    x     = Conv1D(128, 400, strides=4, padding='same')(x)\r\n    x     = Flatten()(x)\r\n    x     = Dense(256, activation='relu')(x)\r\n    x     = Dropout(0.5)(x)\r\n    x     = Dense(128, activation='relu')(x)\r\n    x     = Dense(64,  activation='relu')(x)\r\n    out   = Dense(1,   activation='sigmoid')(x)\r\n    model = Model(ipt, out)\r\n    model.compile(Adam(lr=1e-4), 'binary_crossentropy')\r\n    return model\r\n    \r\ndef make_data(batch_shape):\r\n    return np.random.randn(*batch_shape), np.random.randint(0, 2, (batch_shape[0], 1))\r\n```", "comments": ["I hava similar problem when I use keras bert. tf.function is hard to use too", "Hi,\r\n\r\nThank you for a very interesting performance report. I replicated the small model example and tried to see what happened when enabling or disabling Eager execution and found the following results (note that I am always using `tensorflow.keras`):\r\n\r\nTF 2.0 with Eager on: 0.0361 s/iter\r\nTF 2.0 without Eager: 0.0177 s/iter\r\nTF 1.14 without Eager: 0.0167 s/iter\r\nTF 1.14 with Eager on: 0.0169 s/iter\r\n\r\nIt would therefore appear that disabling Eager is beneficial in 2.0, but not so much in 1.14. I am therefore inclined to believe that the issue at stage is not so much related to Eager itself (since using keras should result in building the Model in graph mode anyway), but to side modifications to the training loop in 2.0; specifically, I am wondering whether this is related to the data handling changes, which if I am not mistaken have everything be reformatted as a `tensorflow.data.Dataset` in 2.0. **Edit**: I ran additional tests pre-wrapping data as a Dataset, it does not solve the issue. The source code clearly indicates that the functions called as a backend to `train_on_batch` are different depending on whether Eager is enabled or not, but I was not able to figure out what makes the eager-enabled v2 function slower than its alternatives.", "I ran some additional tests, investigating runtimes of `tensorflow.keras.Model.fit` rather than that of the `train_on_batch` method. To do so, I slightly altered the code submitted by @OverLordGoldDragon to generate 10 data batches and wrap them with a `tensorflow.data.Dataset` ; I then measured the mean time to run 10 `fit` calls, after having run an initial `train_on_batch` to exclude graph building time from the reported measures.\r\n\r\nIn this setting, it appears that Eager execution speeds things up in both 2.0 and 1.14, and that 2.0 yields lower runtimes for both the small and medium models. Note that for the latter, some optimization on LSTM kernels handling is at work, in addition to the training loop modifications.\r\n\r\n### Results:\r\n\r\nsmall model:\r\n\r\nTF 2.0  with Eager on: 0.1586 sec/fit\r\nTF 2.0  without Eager: 0.3201 sec/fit\r\nTF 1.14 without Eager: 0.3198 sec/fit\r\nTF 1.14 with Eager on: 0.1855 sec/fit\r\n\r\nmedium model:\r\n\r\nTF 2.0  with Eager on: 18.6217 sec/fit\r\nTF 2.0  without Eager: 19.1296 sec/fit\r\nTF 1.14 without Eager: 41.8126 sec/fit\r\nTF 1.14 with Eager on: failed (GPU memory exhausted / tensors initialization issue)\r\n\r\nsetup:\r\n\r\nLinux Mint  19.2, Python 3.6.8, Tensorflow 1.14 or 2.0.0 both with GPU enabled, CUDA 10.0, cuDNN 7.4, NVidia Quadro P1000 (4GB of dedicated RAM)\r\n\r\n### Code:\r\n\r\n```python\r\n\r\nfrom time import time\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Input, Dense, LSTM, Bidirectional, Conv1D\r\nfrom tensorflow.keras.layers import Flatten, Dropout\r\nfrom tensorflow.keras.models import Model\r\nfrom tensorflow.keras.optimizers import Adam\r\n\r\n# to disable Eager in 2.0:  tf.enable_eager_execution()\r\n# to enable Eager in 1.14: tf.compat.v1.disable_eager_execution()\r\n\r\ndef timeit(func, iterations, *args):\r\n    t0 = time()\r\n    for _ in range(iterations):\r\n        func(*args)\r\n    print(\"Time/iter: %.4f sec\" % ((time() - t0) / iterations))\r\n\r\ndef make_small_model(batch_shape):\r\n    ipt   = Input(batch_shape=batch_shape)\r\n    x     = Conv1D(128, 400, strides=4, padding='same')(ipt)\r\n    x     = Flatten()(x)\r\n    x     = Dropout(0.5)(x)\r\n    x     = Dense(64, activation='relu')(x)\r\n    out   = Dense(1,  activation='sigmoid')(x)\r\n    model = Model(ipt, out)\r\n    model.compile(Adam(lr=1e-4), 'binary_crossentropy')\r\n    return model\r\n\r\ndef make_medium_model(batch_shape):\r\n    ipt   = Input(batch_shape=batch_shape)\r\n    x     = Bidirectional(LSTM(512, activation='relu', return_sequences=True))(ipt)\r\n    x     = LSTM(512, activation='relu', return_sequences=True)(x)\r\n    x     = Conv1D(128, 400, strides=4, padding='same')(x)\r\n    x     = Flatten()(x)\r\n    x     = Dense(256, activation='relu')(x)\r\n    x     = Dropout(0.5)(x)\r\n    x     = Dense(128, activation='relu')(x)\r\n    x     = Dense(64,  activation='relu')(x)\r\n    out   = Dense(1,  activation='sigmoid')(x)\r\n    model = Model(ipt, out)\r\n    model.compile(Adam(lr=1e-4), 'binary_crossentropy')\r\n    return model\r\n\r\ndef make_data(batch_shape, n_batches):\r\n    data = np.random.randn(n_batches, *batch_shape),\r\n    trgt = np.random.randint(0, 2, (n_batches, batch_shape[0], 1))\r\n    return tf.data.Dataset.from_tensor_slices((data, trgt))\r\n\r\nbatch_shape = (32, 400, 16)\r\ndata = make_data(batch_shape, n_batches=10)\r\n\r\nmodel = make_medium_model(batch_shape)  # OR change to make_small_model\r\nmodel.train_on_batch(data.take(1))\r\ntimeit(lambda: model.fit(data, steps_per_epoch=10), 10)\r\n```", "@pandrey-fr Excellent testing, thanks for your work - I'll be looking into it. Hopefully there's a workaround to using `fit`, as I use a custom train loop and `train_on_batch` or an iterative `fit` is a must.", "@OverLordGoldDragon \r\nPlease, let us know if any updates on this issue?.Thanks!", "@ravikyram Currently unable to work on the matter, maybe will get to it in a week - but so far, I verified @pandrey-fr  's results on models of interest; disabling eager execution _does_ significantly speed up training, and makes it comparable with TF1's.\r\n\r\nEven if finding all the Eager / Graph combinations that work best for various models, it still wouldn't answer this Issue's question: _why_? What are the graph / hardware-level reasons for such a slowdown with Eager (and sometimes _without_ Eager, as shown by @pandrey-fr )?", "I noticed this issue as well. Just switched to tensorflow 2.0 and noticed a dramatic slowdown. I'm new so maybe I'm missing something around `@tf.function` or something else. I've tried reading the docs and to my understanding v2.0 always runs in \"eager mode\" and the `tf.enable_eager_execution()` listed above threw an error for me. I can't find how to turn it off. Even if I could, based on reading the docs, it seems I'd then have to transform my code back to v1 syntax? Any help would be appreciated - I'd love to have the best of both words - easier code and fast execution. PyTorch has both so until this is fixed I'll be switching back to PyTorch. Training takes a lot of time so fast execution is a top priority.\r\n\r\nRun times for me:\r\nTensorflow 2.0: 67 seconds.\r\nPyTorch: 12 seconds.\r\n\r\nPyTorch is over 5 times faster!!\r\nThat's just for a small, simple model. For one that days a day to train, that would mean with Tensorflow 2.0 it could take days. Huge difference. Big slowdown in iterating; seems to make it practically unusable.\r\n\r\nHere's a cProfile of the slowest calls for the Tensorflow 2.0 run:\r\n```\r\nncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n   498259   12.719    0.000   12.720    0.000 {built-in method _pywrap_tensorflow_internal.TFE_Py_FastPathExecute}\r\n101950/48907    1.990    0.000   36.269    0.001 base_layer.py:703(__call__)\r\n    36212    1.562    0.000    1.562    0.000 {built-in method _pywrap_tensorflow_internal.TFE_Py_Execute}\r\n6042682/6042497    1.415    0.000    2.247    0.000 {built-in method builtins.isinstance}\r\n   186290    1.081    0.000    1.437    0.000 constant_op.py:68(convert_to_eager_tensor)\r\n   243485    0.962    0.000    6.178    0.000 ops.py:1249(internal_convert_to_tensor)\r\n    16128    0.765    0.000    2.080    0.000 {built-in method builtins.print}\r\n   204746    0.761    0.000    3.523    0.000 nest.py:474(map_structure)\r\n   187531    0.732    0.000    1.381    0.000 ops.py:6280(__init__)\r\n1361992/1361978    0.730    0.000    1.030    0.000 {built-in method builtins.hasattr}\r\n    40425    0.618    0.000    5.808    0.000 array_ops.py:669(_slice_helper)\r\n   667713    0.618    0.000    0.637    0.000 {built-in method _pywrap_tensorflow_internal.Flatten}\r\n   101950    0.609    0.000    2.344    0.000 base_layer.py:1942(_set_mask_metadata)\r\n  1253649    0.550    0.000    0.591    0.000 {built-in method builtins.getattr}\r\n   290510    0.549    0.000    0.865    0.000 ops.py:6367(enter_eager_name_scope)\r\n    26638    0.515    0.000    0.702    0.000 {method 'reduce' of 'numpy.ufunc' objects}\r\n   203900    0.507    0.000    0.856    0.000 base_layer.py:1996(_call_arg_was_passed)\r\n   327386    0.488    0.000    0.852    0.000 abc.py:180(__instancecheck__)\r\n   118043    0.462    0.000    1.344    0.000 mlg_connect_four_win.py:53(checkCell)\r\n   832923    0.449    0.000    0.652    0.000 dtypes.py:690(as_dtype)\r\n   204740    0.446    0.000    1.571    0.000 tf_utils.py:322(is_symbolic_tensor)\r\n412717/412253    0.434    0.000    0.546    0.000 base_layer.py:2250(__setattr__)\r\n    28474    0.431    0.000    0.448    0.000 mlg_connect_four_cells.py:166(getValidCells)\r\n   416625    0.424    0.000    0.663    0.000 context.py:1601(executing_eagerly)\r\n   308167    0.413    0.000    1.165    0.000 dtypes.py:144(is_floating)\r\n    69455    0.405    0.000    0.523    0.000 {built-in method numpy.array}\r\n    13440    0.386    0.000   42.441    0.003 ai_a2c_tf.py:140(selectAction)\r\n    48907    0.386    0.000    7.291    0.000 core.py:1041(call)\r\n   287489    0.381    0.000    0.381    0.000 mlg_connect_four_cells.py:254(getCellIndexByCells)\r\n   667713    0.381    0.000    1.288    0.000 nest.py:231(flatten)\r\n    66588    0.374    0.000    4.218    0.000 nn_ops.py:2685(bias_add)\r\n   625730    0.341    0.000    0.341    0.000 _weakrefset.py:70(__contains__)\r\n137599/49170    0.329    0.000    2.669    0.000 base.py:453(_method_wrapper)\r\n     2963    0.327    0.000    0.327    0.000 {built-in method marshal.loads}\r\n   138573    0.316    0.000    1.063    0.000 layer_utils.py:42(filter_empty_layer_containers)\r\n   101950    0.316    0.000    2.965    0.000 base_layer.py:1763(_maybe_cast_inputs)\r\n   101950    0.309    0.000    2.077    0.000 base_layer.py:1982(_collect_input_masks)\r\n137312/48907    0.306    0.000    1.987    0.000 base_layer.py:1137(_clear_losses)\r\n   344833    0.305    0.000    0.713    0.000 numerictypes.py:365(issubdtype)\r\n   211710    0.305    0.000    0.365    0.000 contextlib.py:59(__init__)\r\n```", "@lukemadera try disabling eager execution using tf.compat.v1.disable_eager_execution()", "Thanks @max1mn though that just led to other errors, specifically `.numpy()` fails outside of eager execution. I'm not necessarily surprised, but seems I need to revert my code to v1.x style to get it to work. PyTorch is still easier as it works out of the box. That said, I haven't yet run on a GPU and I'm working on setting that up now, so I'll give tensorflow 2.0 another try then and compare it to PyTorch and tensorflow 1.x and see who wins. Even if 2.0 is better on a GPU though, would be nice to not have these huge slowdowns on a CPU / standard install. This big slowdown still feels like a core issue with 2.0 to me and we need a solution that doesn't require disabling default behavior.", "@lukemadera Partly from [this PR](https://github.com/tensorflow/tensorflow/pull/33318), try replacing all `K.get_value()` and `K.eval()` in your code with below, and try both of `import keras.backend as K` and `import tensorflow.keras.backend as K`:\r\n\r\n\r\n```python\r\ndef K_eval(x):\r\n    try:\r\n        return K.get_value(K.to_dense(x))\r\n    except:\r\n        try:\r\n            eval_fn = K.function([], [x])\r\n            return eval_fn([])[0]\r\n        except:\r\n            return K.eager(K.eval)(x)\r\n```", "Thanks for the prompt reply @OverLordGoldDragon ! I actually do not have any `get_value()` or `eval()` calls in my code. Should I? Here's my code - it's just a simple first version of an A2C model.\r\n\r\n```\r\nimport numpy as np\r\nimport os\r\nimport random\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D\r\nfrom tensorflow.keras import Model\r\n\r\ndef sample(logits):\r\n    noise = tf.random.uniform(tf.shape(logits))\r\n    return tf.argmax(logits - tf.math.log(-tf.math.log(noise)), 1)\r\n\r\nclass ActorCritic(Model):\r\n    def __init__(self, numActions):\r\n        super(ActorCritic, self).__init__()\r\n\r\n        # self.conv1 = Conv2D(32, 3, 1, padding='same', activation='relu')\r\n        # self.conv2 = Conv2D(64, 3, 1, padding='same', activation='relu')\r\n        # self.conv3 = Conv2D(64, 3, 1, padding='same', activation='relu')\r\n        # self.flatten = Flatten()\r\n        # self.d1 = Dense(512, activation='relu')\r\n\r\n        self.conv1 = Conv2D(64, 3, 1, padding='same', activation='relu')\r\n        self.flatten = Flatten()\r\n        self.d1 = Dense(64, activation='relu')\r\n\r\n        self.pi = Dense(numActions, activation=None)\r\n        self.vf = Dense(1, activation=None)\r\n\r\n    def call(self, x):\r\n        x = self.conv1(x)\r\n        # x = self.conv2(x)\r\n        # x = self.conv3(x)\r\n        x = self.flatten(x)\r\n        x = self.d1(x)\r\n        return x\r\n\r\n    def step(self, x):\r\n        x = self(x)\r\n\r\n        value = self.vf(x)\r\n        v = value[:, 0]\r\n        actions = self.pi(x)\r\n        a = sample(actions)\r\n\r\n        return a, v\r\n\r\n    def lastValues(self, x):\r\n        x = self(x)\r\n        value = self.vf(x)\r\n        v = value[:, 0]\r\n        return v\r\n\r\n    def value(self, x):\r\n        x = self(x)\r\n        return self.vf(x)\r\n\r\n    def actionValues(self, x):\r\n        x = self(x)\r\n        return self.pi(x)\r\n\r\n    def both(self, x):\r\n        x = self(x)\r\n        actionValues = self.pi(x)\r\n        values = self.vf(x)\r\n        return actionValues, values\r\n\r\n\r\ndef set_global_seeds(i):\r\n    tf.set_random_seed(i)\r\n    np.random.seed(i)\r\n\r\n\r\ndef cat_entropy(logits):\r\n    a0 = logits - tf.reduce_max(logits, 1, keepdims=True)\r\n    ea0 = tf.exp(a0)\r\n    z0 = tf.reduce_sum(ea0, 1, keepdims=True)\r\n    p0 = ea0 / z0\r\n    return tf.reduce_sum(p0 * (tf.math.log(z0) - a0), 1)\r\n\r\n\r\ndef find_trainable_variables(key):\r\n    with tf.variable_scope(key):\r\n        return tf.trainable_variables()\r\n\r\n\r\ndef discount_with_dones(rewards, dones, gamma):\r\n    discounted = []\r\n    r = 0\r\n    for reward, done in zip(rewards[::-1], dones[::-1]):\r\n        r = reward + gamma * r * (1. - done)  # fixed off by one bug\r\n        discounted.append(r)\r\n    return discounted[::-1]\r\n\r\nclass Agent:\r\n    def __init__(self, numActions,\r\n        ent_coef=0.01, vf_coef=0.5, max_grad_norm=0.5, lr=7e-4, alpha=0.99, epsilon=1e-5,\r\n        gamma=0.95):\r\n\r\n        self.model = ActorCritic(numActions)\r\n        self.entropyFactor = ent_coef\r\n        self.valueLossFactor = vf_coef\r\n        self.maxGradNorm = max_grad_norm\r\n        self.learningRate = lr\r\n        self.decay = alpha\r\n        self.epsilon = epsilon\r\n        self.gamma = gamma\r\n        self.optimizer = tf.keras.optimizers.RMSprop(learning_rate=lr, rho=alpha, epsilon=epsilon)\r\n\r\n    def train(self, states, rewards, actions, values):\r\n        with tf.GradientTape() as tape:\r\n            pisPred, valuesPred = self.model.both(states)\r\n\r\n            advs = rewards - values\r\n            # Get the probabilities of the chosen actions.\r\n            negLogPolicy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=actions, logits=pisPred)\r\n            pgLoss = tf.reduce_mean(advs * negLogPolicy)\r\n            vfLoss = tf.reduce_mean(tf.math.squared_difference(tf.squeeze(valuesPred), rewards) / 2.0)\r\n            entropy = tf.reduce_mean(cat_entropy(pisPred))\r\n            loss = pgLoss - entropy * self.entropyFactor + self.valueLossFactor * vfLoss\r\n\r\n        gradients = tape.gradient(loss, self.model.trainable_variables)\r\n        if self.maxGradNorm is not None:\r\n            gradients, _ = tf.clip_by_global_norm(gradients, self.maxGradNorm)\r\n        self.optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\r\n\r\n        return pgLoss, vfLoss, entropy\r\n\r\n    def save(self, savePath):\r\n        tf.keras.models.save_model(self.model, savePath)\r\n        print ('saved model', savePath)\r\n\r\n    def load(self, loadPath):\r\n        self.model = tf.keras.models.load_model(loadPath)\r\n        print ('loaded model', loadPath)\r\n\r\n    def getValues(self, state):\r\n        # Neural network wants batches so wrap single state in an array to add dimension.\r\n        return self.model.actionValues(np.asarray([state], dtype='float32'))\r\n\r\n    def selectAction(self, state, validActions, randomRatio=-1):\r\n        # Neural network wants batches so wrap single state in an array to add dimension.\r\n        action, value = self.model.step(np.asarray([state], dtype='float32'))\r\n        action = action[0] if len(action) else action\r\n        value = value[0] if len(value) else value\r\n\r\n        if randomRatio >= 0:\r\n            randNum = random.uniform(0, 1)\r\n            if randNum < randomRatio:\r\n                action = np.random.choice(validActions)\r\n\r\n        if validActions is not None and action not in validActions:\r\n            action = np.random.choice(validActions)\r\n\r\n        return action, value\r\n\r\n    def learn(self, states, actions, rewards, dones, values):\r\n\r\n        # Update / discount rewards. TODO - understand this..\r\n        lastValues = self.model.lastValues(states).numpy()\r\n        # discount/bootstrap off value fn\r\n        for n, (rewards1, dones1, value1) in enumerate(zip(rewards, dones, lastValues)):\r\n            rewards1 = rewards1.tolist()\r\n            dones1 = dones1.tolist()\r\n            if dones1[-1] == 0:\r\n                rewards1 = discount_with_dones(rewards1 + [value1], dones1 + [0], self.gamma)[:-1]\r\n            else:\r\n                rewards1 = discount_with_dones(rewards1, dones1, self.gamma)\r\n            rewards[n] = rewards1\r\n\r\n        # Combine envs and steps with flatten.\r\n        # State is already flattened / joined.\r\n        rewards = rewards.flatten()\r\n        actions = actions.flatten()\r\n        values = values.flatten()\r\n\r\n        return self.train(states, rewards, actions, values)\r\n```", "I'm afraid that's beyond the scope of this Issue, and should be asked separately - or on Stack Overflow. To reply briefly, check that your `keras` vs `tf.keras` imports are consistent, and disabling eager in TF2 can be tricky. Lastly, as it's a long code excerpt, it'd help if you edited it out to keep the comments clearer.", "Fair enough on the code scope, though it's already <200 lines and the error logging was fairly opaque so I don't know which code snippets to paste specifically. And I don't have any `keras` imports at all, so those are consistent already I believe.\r\n\r\n`disabling eager in TF2 can be tricky` <-- Yeah, I think that's the core issue. Even more core, that it needs to be disabled in the first place to get tensorflow v1.x performance.\r\nI used the tensorflow 2.0 tutorials to build that fairly simple code and I think we need to get to a state where the tutorials can be followed as is WITH good performance.", "@lukemadera What I meant with \"edit it out\" is, delete your long code excerpt from the comment to keep the thread easier to read and more relevant - thanks\r\n\r\nTo all: I'll resume testing today. Unfortunately TF devs seem to be unable to be bothered with, so I'll try digging in the source & profiling.", "I just saw a Kaggle competition for TensorFlow 2.0 so I'm assuming they'll either see this performance issue there or if not, there's something we're doing wrong..", "@pandrey-fr Question: why do you use `tf.data.Dataset`? Do you expect any performance gains from non-TFRECORDS files (i.e. Numpy)? I rather keep testing minimalistic\r\n\r\n**Update**: I see no performance benefit from using `tf.data.Dataset` on Numpy arrays; they're even.\r\n**Update 2**: `train_on_batch` is 5.3% faster than `fit`, a nontrivial margin for 100 train iterations -- not making any claims, but I'll be doing my testing w/ `train_on_batch`", "@OverLordGoldDragon \r\n\r\n> Question: why do you use tf.data.Dataset?\r\n\r\nIn 2.0, I believe the `fit` method transforms inputs to a `tf.data.Dataset` no matter what (which is a way to simplify some internal dependency functions), hence my initial intuition that part of the issue could come from overhead linked to this transformation. However I arrived at the same conclusion as you: this intuition was wrong, and there is no significant runtime change; it therefore feels logical to keep testing using numpy arrays, to avoid test code complexification.\r\n\r\n> Update 2: train_on_batch is 5.3% faster than fit, a nontrivial margin for 100 train iterations -- not making any claims, but I'll be doing my testing w/ train_on_batch\r\n\r\nThat is certainly interesting. On the one hand, it makes sense that using direct calls to `train_on_batch` would be faster as you avoid some boilerplate code from `fit`. On the other hand, my results would indicate that using `fit` is differently efficient depending on the TF version used; perhaps it simply means that the amount of `fit` overhead has been greatly reduced in 2.0 and with the introduction of Eager execution, which in my testing would mask the fact that the underlying `fit_on_batch` is actually made slower?\r\n\r\n> Unfortunately TF devs seem to be unable to be bothered with, so I'll try digging in the source & profiling.\r\n\r\nThank your for your investment in digging the issue; hopefully a tensorflower will eventually also come to the rescue (in my humble experience it can take some time before getting an answer, but they usually do a great job once they are on it).", "@pandrey-fr Are you familiar w/ memory allocation differences of Eager vs. Graph? [This](https://pastebin.com/njD875J0) throws OOM in TF2, but runs fine in TF1 - and disabling Eager solves it. If you have a graph/hardware-level insight on this, I'd appreciate it.\r\n\r\n**UPDATE**: importing from `keras` instead of `tensorflow.keras` also solves OOM, w/o switching to graph. How strange.", "Sorry for the very late reply. Let me comment on the performance aspect for Keras, between v1 and v2, also eager/graph.\r\n\r\nIn TF2, as we all know, eager mode becomes the default context, and you can disable it by tf.compat.v1.disable_eager_execution(). In eager mode, the runtime need to execute the ops and return the numerical value for every line of python code. The nature of single step execution cause it to be slow, and mainly good for debug only. To overcome the slowness in eager mode, we have @tf.function, which will turn a python function into a graph. When feed numerical value like np array, the body of the tf.function is converted into static graph, being optimized, and return the final value, which is fast and should have similar performance as TF1 graph mode.\r\n\r\nAlso in TF2, Keras made some change to leverage tf.function to build its graph for training, eval and prediction. We call them \"execution function\" for the model. In TF1, the \"execution function\" was a FuncGraph, which shared some common component as TF function, but has a different implementation. We made the decision to make this change since we observe the performance gain when we test some large model before we cut the 2.0 release. During the process of the change, we correctly update the model.fit/eval/predict function, but somehow leave an incorrect implementation for train_on_batch(), test_on_batch() and predict_on_batch(). They are still numerically correct, but the execution function for x_on_batch is a pure python function, rather than a tf.function wrapped python function. This will cause the slowness as you observed above, and the reason is as I stated in paragraph 1.\r\n\r\nYou can find more details about the change history for keras change in https://github.com/tensorflow/tensorflow/commit/b389d0b8f3dc15907c5cea908c4cbbbdb75fc862.\r\n\r\nI am taking the performance part of the issue from here. For now, if you want to do some performance analysis, please try model.fit/eval/predict() until this issue is fixed. The first batch of the first epoch will have some overhead for execution function initialization and function trace, which you should ignore. The following batches and epochs should have the correct performance.\r\n\r\nIn general, we would suggest user stay with the eager runtime, since this is the focus for us currently. More updates will come in future to make the eager runtime faster. \r\n\r\nHope this resolve your question, and thanks again for reporting this issue in details.\r\n", "@qlzh727 Thank you for the detailed response - I understand devs are short on time. \r\n\r\nI have a few follow-ups: much of what you describe is exactly what I noticed while reading the source code / profiler results, but certainly not all, and the new info is useful. It appears the root of the performance discrepancy lies in graph-building and input data processing, and differences can be seen even in TF1-graph vs. TF2-graph execution due to your mentioned API changes - correct?\r\n\r\nI'm running a thorough experimentation for performance comparison, and plan on posting a highly detailed answer - I'd appreciate if you'd be able to review the accuracy of my explanations before I post on StackOverflow. In the meantime, I do have a specific question: for certain data & model size configurations, imports from `keras` can run 5-10x faster than from `tf.keras` -- why the difference? (I may answer this myself by the end, so I'd prioritize the 'review' if I were to choose)", "@OverLordGoldDragon, for TF2, we also convert all the input data into a tf.dataset, by which we can unify our execution function to handle the single type of the inputs. There might be some overhead in the dataset conversion, and I think this is a one-time only overhead, rather than a per-batch cost.\r\n\r\nFor importing performance, I guess importing tf.keras will first import tensorflow low level ops since they have the direct dependency. On the other hand, import keras-team/keras will just load the keras API, and I guess TF backend is not loaded until the execution (I could be wrong).", "[ANSWERED](https://stackoverflow.com/questions/58441514/why-is-tensorflow-2-much-slower-than-tensorflow-1) in detail. I verified the information to best of my ability, but would still appreciate an expert review, @qlzh727 . If anything looks off or could be improved, please let me know.\r\n\r\nIncluded are some rather 'interesting' results, some of which contradict a few of your statements, @qlzh727. \r\n\r\nThat took a while, but was interesting - going to take a break. ", "THANK YOU for that very detailed answer @OverLordGoldDragon ! I've skimmed through it (there's a lot there) and while it's good to know Tensorflow 2.0 CAN be as fast as TF 1, it seems very finicky to get right. Reinforcement learning already is sensitive to hyperparameters and can be difficult to debug, so adding another layer of having to set up the code correctly to get it to train quickly is a huge turn off. I guess this is a question for TF devs - is there a near term future where TF 2.0 can ALWAYS run fast? Until then I don't see a reason not to use PyTorch instead, which seems to have all the benefits without this huge cost / added complexity.", "@OverLordGoldDragon Thank you a lot for your very thorough and detailed testing and analysis!", "The train/eval/predict_on_batch performance issue has been resolve by @robieta in https://github.com/tensorflow/tensorflow/commit/28d07261622a589b7f427756677c2178ccaca7fb. \r\n\r\nSimple DNN benchmark on CPU has a performance gain: 7.27  ->  1.67 ms / step\r\n\r\nClosing this issue for now, and thanks Taylor for the hard work.", "Thank you, @robieta - I'll be benchmarking on GPU to verify improvements.", "@qlzh727 @robieta I'm afraid this commit isn't of much help yet; it either introduced a breaking bug, or requires a full reinstall per master-branch - details below. The question now is: when will the next stable version downloadable via `conda` or `pip` be released? Can this be fixed before then?\r\n\r\n<hr>\r\n\r\nCopying just the commit files, calling `train_on_batch()` yields:\r\n\r\n```python\r\nFile \"<ipython-input-1-dffadba2780b>\", line 167, in test_all\r\n  model.train_on_batch(*data)\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 1034, in train_on_batch\r\n  self._check_call_args('train_on_batch')\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 1326, in _check_call_args\r\n  fullargspec = self._call_full_argspec\r\n\r\nAttributeError: 'Model' object has no attribute '_call_full_argspec'\r\n```\r\n\r\nTo resolve this error, I also copy/paste _base_layer.py_, but this breaks everything - see below. I created a fresh Anaconda virtual environment and reinstalled everything - but latest commits aren't included (and PyPI last release was Sep 30). Repeating the copy steps leads to same error.\r\n\r\n<hr>\r\n\r\n**Full error trace** after pasting _base_layer.py_ or replacing entire Python folder w/ master branch's; the error is spammed infinitely and cannot be stopped unless kernel is restarted. Occurs upon `import tensorflow`\r\n\r\n```python\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 578, in post_execute_hook\r\n  _, pymtime = self._reloader.filename_and_mtime(sys.modules[modname])\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 184, in filename_and_mtime\r\n  if not hasattr(module, '__file__') or module.__file__ is None:\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n  module = self._load()\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n  module = _importlib.import_module(self.__name__)\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n  return _bootstrap._gcd_import(name[level:], package, level)\r\nFile \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\nFile \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\nFile \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\nFile \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nFile \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\nFile \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\nFile \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\nFile \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\nFile \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\nFile \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 45, in <module>\r\n  from . _api.v2 import compat\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\__init__.py\", line 23, in <module>\r\n  from . import v1\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\__init__.py\", line 40, in <module>\r\n  from . import experimental\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow_core\\_api\\v2\\compat\\v1\\experimental\\__init__.py\", line 11, in <module>\r\n  from tensorflow.python.ops.control_flow_v2_toggles import output_all_intermediates\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow_core\\python\\ops\\control_flow_v2_toggles.py\", line 24, in <module>\r\n  from tensorflow.python.ops import control_flow_util_v2\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow_core\\python\\ops\\control_flow_util_v2.py\", line 28, in <module>\r\n  from tensorflow.python.keras.engine import base_layer_utils\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\__init__.py\", line 27, in <module>\r\n  from tensorflow.python.keras import applications\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\applications\\__init__.py\", line 25, in <module>\r\n  from tensorflow.python.keras import engine\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\__init__.py\", line 23, in <module>\r\n  from tensorflow.python.keras.engine.base_layer import Layer\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\", line 57, in <module>\r\n  from tensorflow.python.keras.utils import generic_utils\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\__init__.py\", line 38, in <module>\r\n  from tensorflow.python.keras.utils.multi_gpu_utils import multi_gpu_model\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\multi_gpu_utils.py\", line 22, in <module>\r\n  from tensorflow.python.keras.engine.training import Model\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 42, in <module>\r\n  from tensorflow.python.keras import metrics as metrics_module\r\n\r\nFile \"D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\metrics.py\", line 34, in <module>\r\n  from tensorflow.python.keras.engine.base_layer import Layer\r\n\r\nImportError: cannot import name 'Layer' from 'tensorflow.python.keras.engine.base_layer'\r\n(D:\\Anaconda\\envs\\tf3_env\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py)\r\n```", "@OverLordGoldDragon Yeah, environment management is a never ending battle. It seems like you have a non-clean env or a stale version of TF in your PYTHONPATH. I'm not at all surprised that copy-pasting the contents of training.py didn't do the right thing. It's actually fortunate that it gave an ImportError, because otherwise you would have just wound up with some inscrutable error. (Also, the import error is consistent with paths being messed up.)\r\n\r\nWe don't control the conda package so I don't have any say over the cadence there, but we do release the `tf-nightly` pip package which is the recommended way to try out changes prior to a stable release. We are in the process of putting together 2.1 if you want a stable release. Also be aware that there were some updates to the CUDA version (10.0 -> 10.1) between 2.0 and now, so you may have to update that side to make everything work properly. (Like I said, the joys of env management.)", "@robieta So basically, `tf-nightly` is the current master branch, installable via `!pip`? If so, the concept of \"nightly\" finally makes sense to me: \"all the stuff since last stable release and before next\". \r\n\r\nMy env is fine, but yes, a simple copy can easily break - the problem is in installing w/o a package manager which correctly unpacks (and ignores) the repository files. If nightly is what I described, I'll be testing it soon -- thanks.", "That's a correct understanding of `tf-nightly`", "Looks like this is its own circus to set up without the kernel imploding - think I'll await the stable release. Anyone is still welcome to suggest a workaround [here](https://github.com/tensorflow/tensorflow/issues/34351).", "For anyone coming here with a `conda install tensorflow=2.0` I saw a massive decrease in performance (several hundred percent) compared to the `tf-nightly` build. \r\n\r\nI have a 2019 MBP with 16 cores (no compatible GPU). Training time for each epoch in my pipeline went from 4 hours to 20 minutes (!) when switching between the 2.0 and nightly build. When checking CPU useage with `htop` the difference in CPU load is very visible. \r\n\r\nWrt to the [SO thread](https://stackoverflow.com/questions/58441514/why-is-tensorflow-2-much-slower-than-tensorflow-1), I exclusively use `from tensorflow import keras` and no mixing of `numpy` or `keras` modules in my pipeline.", "@tomonodes Several-hundred % is a red flag; either something's very wrong with the current `tf-nightly`, or something off with your code/configs. If you share a minimal reproducible code for which you can observe such discrepancy, and the code looks fine, I'll mention it on the SO. Also include your environment info (OS, CUDA + cuDNN versions, GPU, CPU, IDE)", "@tomonodes To clarify, you're saying that 2.0 is much slower than tf-nightly? If so, that is expected behavior; there are a number of key performance improvements that were made to TensorFlow after the 2.0 release that are present in HEAD (where tf-nightly is built from) and will be in 2.1. On the other hand, if tf-nightly is slower than 2.0 then that's a problem.", "@robieta Now that I re-read it, OP does clearly state \"decrease compared to `tf-nightly`\", guess I misread that; if so, great work, I'm looking forward to 2.1", "Yup, the nightly build is much, much faster than 2.0. \r\n\r\nI won't bother with performance tests if the behaviour is expected. Just wanted to chip in if anyone - like me- came from a freshly installed 2.0 and saw a massive performance drop from earlier alpha or nightly. Looking forward to 2.1 as well!", "I've read the release notes for rc1 and rc2, and while mention was made of `tf.function`, the promised benefits of improved performance to `on_batch` methods weren't - and the connection may not be apparent to all. Consider stating it explicitly in the final release.", "@robieta @qlzh727 @tomonodes Results in for TF 2.1 `train_on_batch()`; Small-Small through Large-Small: equal to or _much faster_ than the best of TF1 & TF2. Large-Large: ... **47% slower** than TF2 in Graph (2's Eager OOM'd). What's the deal?\r\n\r\nAlso Medium-Large was 2% slower (\"equal\"), but Large-Large Eager didn't OOM. Small-Large also ~equal to TF2. Basically, it seems to have grown worse on processing large batches, in both Eager and Graph.\r\n\r\nI have only tested `train_on_batch()` w/ `tf.keras` on `numpy` inputs so far, will test other configs later - but this is the setup that I mainly use, and Large-Large being so much slower will be quite problematic.\r\n\r\nI used [this answer's](https://stackoverflow.com/questions/58441514/why-is-tensorflow-2-much-slower-than-tensorflow-1#answer-58653636) code (at bottom), with `tf.compat.v1.disable_eager_execution()` and `test_all(fit=False, tf_dataset=False)`. I installed TF 2.1 via `pip`, and built CUDA 10.1 from source along cuDNN 7.6.5, so maybe something's off with my install - feel free to test on your machines.", "New info in: `fit()` is <s>faster, but is still slower than TF2's</s> approx. as fast as `train_on_batch()` after accounting for the \"warmup\". \r\n\r\n<img src=\"https://user-images.githubusercontent.com/16495490/74341828-d709ec00-4dc1-11ea-93cd-7e46c907355e.png\" width=\"450\">\r\n\r\nBefore this image, the average was 4.65 secs - these are the 50 `fit()` calls after restarting the kernel and running again. I noticed in the first one that iterations were as fast as 3 secs. It doesn't seem to be a memory leak as far as Task Manager's reporting of Dedicated memory usage goes, or RAM. Also, here's the plot _after_ the one above: \r\n\r\n<img src=\"https://user-images.githubusercontent.com/16495490/74342094-60212300-4dc2-11ea-8daf-370eedef7ad5.png\" width=\"400\">\r\n\r\nIt averages 6.03 secs, even worse. Now I did notice that GPU % usage (Task Manager) spikes to 100% at each iteration, so maybe this is GPU throttling - but that didn't happen with TF2 no matter how many times I re-ran the Large-Large test. [modified `timeit`](https://pastebin.com/aSctQUSN)\r\n\r\n<hr>\r\n\r\n**Update**: 300 iters, avg. 5.75.\r\n\r\n<img src=\"https://user-images.githubusercontent.com/16495490/74351610-c7de6a80-4dd0-11ea-86b1-60313c7ade6b.png\" width=\"450\">\r\n\r\n```python\r\nfrom tensorflow.python.platform import build_info\r\nprint(build_info.cuda_version_number)   # 10.1\r\nprint(build_info.cudnn_version_number)  # 7\r\nprint(build_info.cudnn_dll_name)        # 'cudnn64_7.dll'\r\nprint(build_info.cudart_dll_name)       # 'cudart64_101.dll'\r\n```", "Just saw a **2.5x slowdown** in Graph execution for a large model relative to both TF1 and TF2.1-Eager - also an _extreme_ reproducibility difference w.r.t. 2.1-Eager. Guess I should open a new issue on this - no reproducible code yet, will post when I'm able.", "A CPU user reported a phenomenon of periodic (and increasing) inference-time spikes in TF2, not seen in TF1: from the [SO](https://stackoverflow.com/questions/60267911/keras-inconsistent-prediction-time):\r\n\r\n![image](https://user-images.githubusercontent.com/16495490/74878243-5aa67880-5380-11ea-980f-4931b30e65fe.png)\r\n\r\nUsing `model(x)` opposed to `.predict()` largely solved the problem - regardless, something to note.", "I have the issue of difference in inference time, when done with model(x) vs model.predict(x). Here the model is a resnet50 model taken from tf.keras.applications. I found that model.predict(x) is approximately 1.5-2 times faster than model(x). \r\nI am using tensorflow-gpu==2.0.0", "[2.2 followup](https://github.com/tensorflow/tensorflow/issues/39665)"]}, {"number": 33486, "title": "Out of date BERT Tutorial Link", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue: https://www.tensorflow.org/guide/distributed_training\r\n## Description of issue (what needs changing): Out of date link to BERT tutorial\r\n### Clear description\r\nThe above URL contains an out of date link:\r\nBERT Tutorial: https://github.com/tensorflow/models/blob/master/official/bert/run_classifier.py \r\nThis is the correct link: https://github.com/tensorflow/models/blob/master/official/nlp/bert/run_classifier.py\r\n\r\nAre you planning to also submit a pull request to fix the issue?  Yes", "comments": ["https://github.com/tensorflow/docs/pull/1113"]}, {"number": 33485, "title": "Improve API documentation for WindowDataset op", "body": "This pull request extends the API documentation for the op `WindowDataset` with some additional information. I added some more detailed information about the window semantics, as well as information about the op returning self-consistent results even if its inputs are in nondeterministic order.", "comments": ["@aaudiber could you please review this? thank you", "Hi @frreiss,\r\n\r\nThanks for improving these docs. Right now the main documentation for `WindowDataset` is in the Python docs: https://github.com/tensorflow/tensorflow/blob/5f47ceeaa050a4cd74c259783d4f9300037a7307/tensorflow/python/data/ops/dataset_ops.py#L1564\r\n\r\nThe Python docs are pretty good since they include descriptive examples.\r\n\r\nIdeally we could make these docs match the Python docs in terms of content. To accomplish this, can you make any necessary updates to the Python docs, then update the `api_def/` docs to match?", "Sorry for the delay in getting back to this PR. I've merged the additional information about window semantics from my original commit into the Python docs and synchronized the `.pbtxt` file's documentation strings match the Python docs.", "@frreiss No worries, thanks for the updates", "@aaudiber Can you please take a look on this PR? Thanks!"]}, {"number": 33484, "title": "Issue with tf.keras.mixed_precision.experimental.LossScaleOptimizer", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.0\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.0, 7.5\r\n- GPU model and memory: Titian RTX 24gb\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nWhen attempting to use tf.keras.mixed_precision.experimental.LossScaleOptimizer it fails to cast a matmul to float16\r\n**Describe the expected behavior**\r\nMatmul should cast to float16\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tensorflow.keras.datasets import mnist\r\n\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\nif gpus:\r\n    try:\r\n        for gpu in gpus:\r\n            tf.config.experimental.set_memory_growth(gpu, True)\r\n        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\r\n        print(len(gpus), \"Physical GPUS,\", len(logical_gpus), \"Logical GPUS\")\r\n    except RuntimeError as e:\r\n        print(e)\r\n\r\ntf.keras.backend.set_floatx('float16')\r\ntf.keras.backend.set_epsilon(1e-4)\r\n\r\nmodel = tf.keras.models.Sequential()\r\nmodel.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\r\nmodel.add(tf.keras.layers.MaxPooling2D((2, 2), padding=\"same\"))\r\nmodel.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding=\"same\"))\r\n\r\nmodel.add(tf.keras.layers.Flatten())\r\nmodel.add(tf.keras.layers.Dense(64, activation='relu'))\r\nmodel.add(tf.keras.layers.Dense(10, activation='softmax'))\r\n\r\nmodel.summary()\r\n\r\n(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\r\n\r\ntrain_images = train_images.reshape((60000, 28, 28, 1))\r\ntrain_images = train_images.astype(np.float16) / 255\r\n\r\ntest_images = test_images.reshape((10000, 28, 28, 1))\r\ntest_images = test_images.astype(np.float16) / 255\r\n\r\ntrain_labels = tf.keras.utils.to_categorical(train_labels, dtype='float16')\r\ntest_labels = tf.keras.utils.to_categorical(test_labels, dtype='float16')\r\n\r\nopt = tf.keras.optimizers.RMSprop()\r\nopt = tf.keras.mixed_precision.experimental.LossScaleOptimizer(opt, \"dynamic\")\r\n\r\nmodel.compile(optimizer=opt,\r\n              loss='categorical_crossentropy',\r\n              metrics=['accuracy'])\r\nmodel.fit(tf.dtypes.cast(train_images, tf.float16), tf.dtypes.cast(train_labels, tf.float16), epochs=50, batch_size=64, steps_per_epoch=200)\r\n\r\ntest_loss, test_acc = model.evaluate(test_images, test_labels)\r\n\r\ntest_acc\r\n\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["I could reproduce the issue with Tf 2.0. Please take a look at the colab [gist](https://colab.sandbox.google.com/gist/gadagashwini/7909678539c398aa1f4b8fafa334807f/untitled208.ipynb). Thanks!", "@mattbernardini The tf.matmul() op does not perform automatic type conversions, so both of its inputs must have the same element type.\r\nTry converting all the inputs to float32 and it should work fine. Please find my github gist [here](https://colab.sandbox.google.com/gist/gowthamkpr/2ab5ef2ed2af387abc2e60016a3936bc/untitled208.ipynb).\r\n\r\nFor more context, you can go through the following [issue](https://stackoverflow.com/questions/36210887/how-to-fix-matmul-op-has-type-float64-that-does-not-match-type-float32-typeerror). Thanks!", "Right, that works for float32, but does not work for float16 which was the original issue.", "@reedwm Can you PTAL? Thanks!", "@gowthamkpr I'm running into the same issue, trying to run float16 training. Not sure why you're casting to float32 in the .fit() method? Thanks!", "I encounter the same problem with float16 training. So far I have figured out that the issue lies in the LossScaleOptimizer, because the issue disappears when you remove it (but then obviously losses are too tiny to be effective). \r\n\r\nTo be more specific, the error is raised when the LossScaleOptimizer calls its `get_scaled_loss()` function which simply multiplies (via python operator *) the loss with the `loss_scale`, which is an instance of `tf.train.experimental.LossScale`. [See the code here.](https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/mixed_precision/experimental/loss_scale_optimizer.py#L149)\r\n\r\n```py\r\ndef get_scaled_loss(self, loss):\r\n    loss_scale = self._loss_scale()\r\n    if callable(loss):\r\n      return lambda: loss() * loss_scale\r\n    else:\r\n      return loss * loss_scale\r\n```\r\n\r\nThe error says that the `y` input of the multiplication is float32 and the `x` input is float16. Since the multiplication in `get_scaled_loss()` is done like this: `loss * loss_scale`, this means that `loss_scale` is a float32. A few lines above we see that `loss_scale = self._loss_scale()`, and `self._loss_scale` is an instance of `tf.train.experimental.LossScale`.\r\n\r\nNow, if we look into the source code of `tf.train.experimental.LossScale` [here](https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/training/experimental/loss_scale.py) we see that the `__call__()` method of e.g. the DynamicLossScale (which is the one @mattbernardini uses) returns `ops.convert_to_tensor(self._current_loss_scale)`. If we then check the initialization of `self._current_loss_scale` we see that it is initialized as float32:\r\n\r\n```python\r\nself._current_loss_scale = self._add_weight(\r\n    name='current_loss_scale',\r\n    dtype=dtypes.float32,\r\n    initial_value=self._initial_loss_scale)\r\n```\r\n\r\nSo this is why the TypeError is thrown when using LossScaleOptimizer in float16 training. I am not exactly sure why LossScales were implemented to only return float32 values. There are also no clear online guides on how to do float16 training in TF 2.0, so it would be nice if someone who knows the details of how Tensorflow implements the optimization process could provide information on proper float16 training, because evidently neither `tf.keras.backend.set_floatx('float16')` nor `    tf.keras.mixed_precision.experimental.set_policy('mixed_float16')` seem to work out-of-the-box.", "@verrannt, good investigation! In TF 2.1, this will be fixed. Alternatively, you can use the nightly builds with `pip install tf-nightly-gpu` which has the fix now. This has been fixed by casting the float32 loss scale to the dtype of the loss.\r\n\r\nFor reference, to do float16 training (typically referred to as mixed precision training), you **always** want to do the following\r\n\r\n```\r\ntf.keras.mixed_precision.experimental.set_policy('mixed_float16')  # Good\r\n```\r\n\r\nYou **do not** want to set floatx to float16 with the following, unless you also set the policy to 'mixed_float16':\r\n\r\n```\r\ntf.keras.backend.set_floatx('float16')  # Bad!\r\n```\r\n\r\nThe reason you want to set the policy instead of floatx is that the policy will keep variables in float32, which is necessary for numeric stability.\r\n\r\nAs for an online guide to do float16 training, I agree we need one and we will have one in the future. For now, [the Policy API documentation](https://www.tensorflow.org/api_docs/python/tf/keras/mixed_precision/experimental/Policy) has a brief guide on how to do mixed precision training", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33484\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33484\">No</a>\n"]}, {"number": 33483, "title": "Fix small typo in v2.0.0 release note", "body": "This fix was attempted in the r2.0 branch with [PR 32979](https://github.com/tensorflow/tensorflow/pull/32979), which is now closed.", "comments": []}, {"number": 33482, "title": "In the pix2pix tutorial, the dimension of upsample within up_stack looks wrong. Only the image size is doubled, not filters!", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n", "comments": ["Although it won't effect anything, but just wanna point it out for the comments are not right. \r\n", "@CindyQi7788 ,\r\nHello, Can you please let us know where exactly in the [pix2pix tutorial](https://www.tensorflow.org/tutorials/generative/pix2pix) issue is being reported by you?", "In the cell of Define a Generator: I think the dimension after 1st\nupsample(512, 4, apply_dropout=True) ,  ### (bs, 2,2, 512), and so on...\notherwise the dimensions do not match with skip layers below.\n\nup_stack = [\nupsample(512, 4, apply_dropout=True), # (bs, 2, 2, 1024) ---> should be\n(bs, 2,2, 512)\nupsample(512, 4, apply_dropout=True), # (bs, 4, 4, 1024) ---> should be\n(bs, 4, 4, 512)\nupsample(512, 4, apply_dropout=True), # (bs, 8, 8, 1024) ---> should be\n(bs, 8, 8, 512)\nupsample(512, 4), # (bs, 16, 16, 1024) ---> should be (bs, 16, 16, 512)\nupsample(256, 4), # (bs, 32, 32, 512) ---> should be (bs, 32, 32, 256)\nupsample(128, 4), # (bs, 64, 64, 256) ---> should be (bs, 64, 64, 128)\nupsample(64, 4), # (bs, 128, 128, 128) ---> should be (bs, 128, 128, 64)\n\nOn Thu, Oct 17, 2019 at 11:46 PM oanush <notifications@github.com> wrote:\n\n> @CindyQi7788 <https://github.com/CindyQi7788> ,\n> Hello, Can you please let us know where exactly in the pix2pix tutorial\n> <https://www.tensorflow.org/tutorials/generative/pix2pix> issue is being\n> reported by you?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/33482?email_source=notifications&email_token=AENN7ATRUJEQW6KIDHQP7ZTQPFLTVA5CNFSM4JB6OTLKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEBS47UI#issuecomment-543543249>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AENN7ATD5LU3UCEXFT5J77LQPFLTVANCNFSM4JB6OTLA>\n> .\n>\n", "Thanks. That notebook lives over here in the tensorflow/docs repo: https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/pix2pix.ipynb\r\nCan you send a pull request, please?", "I think, the up_stack comments are referring to the shapes after the concatenation with the skip connection. ", "yeah, \"after the concatenation with the skip connection\"  makes sense.\n\nThanks\nXin\n\nOn Wed, Oct 23, 2019 at 10:02 AM Yash Katariya <notifications@github.com>\nwrote:\n\n> I think, the up_stack comments are referring to the shapes after the\n> concatenation with the skip connection.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/33482?email_source=notifications&email_token=AENN7ATSEQGLBGJZRFDP77DQQB7R3A5CNFSM4JB6OTLKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOECCD7OA#issuecomment-545537976>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AENN7AUH4NLEMYL2W6YNQLLQQB7R3ANCNFSM4JB6OTLA>\n> .\n>\n", "Closing this issue since its resolved. Thanks!"]}, {"number": 33481, "title": "fixing documentation for tf.batch_to_space", "body": "issue #33354\r\neach step is not separated correctly : https://www.tensorflow.org/api_docs/python/tf/batch_to_space\r\n\r\nreplacing #33351", "comments": ["cc @mihaimaruseac ", "@vishalsubbiah can you please check the build failures ?", "@rthadur can i redo a certain check? the error for Ubuntu Sanity, Android Demo App,  is\r\n```\r\nERROR: /tmpfs/src/github/tensorflow/tensorflow/tools/ci_build/BUILD:3:1:  failed: No usable spawn strategy found for spawn with mnemonic TestRunner.  Your --spawn_strategy, --genrule_strategy or --strategy flags are probably too strict. Visit https://github.com/bazelbuild/bazel/issues/7480 for migration advice\r\n```\r\nThis shouldn't be because of my change"]}, {"number": 33480, "title": "Improve tf.make_ndarray() docstring", "body": "Added a usage example to improve documentation.", "comments": []}, {"number": 33479, "title": "Error in loading a keras model saved by tf 1.15 from tf 1.14", "body": "I saved the keras model by tf 1.15.\r\nwhen loading from  tf 1.14, occurs:\r\n\r\n> ValueError: ('Unrecognized keyword arguments:', dict_keys(['ragged']))\r\n\r\nhow to fix it?", "comments": ["Tensorflow 1.15 contains breaking changes like ragged tensor support, so it does not support backwards compatibility(Tf 1.14). This is the issue. Please try to load it using Tensorflow 1.15 and it should work.", "> Tensorflow 1.15 contains breaking changes like ragged tensor support, so it does not support backwards compatibility(Tf 1.14). This is the issue. Please try to load it using Tensorflow 1.15 and it should work.\r\n\r\nThanks.\r\n\r\nCan I save the model by tf 1.15 to the old format? Or any way else to convert the saved file backwards?", "You can load tf1.15+ model using  tf1.15-2.1. Then save only weights to open in tf1.14\r\n```\r\n\r\n# In tensorflow 1.15-2.1\r\n# Load model\r\nmodel = load_model(\"my_model.h5\")\r\n\r\n# Save weights and architecture\r\nmodel.save_weights(\"weights_only.h5\")\r\n\r\n# Save model config\r\njson_config = model.to_json()\r\nwith open('model_config.json', 'w') as json_file:\r\n    json_file.write(json_config)\r\n\r\n# at this point you can edit json file by \r\n# deleting ragged field, change kernel_initializer, etc...\r\n# _________________________  In tensorflow 1.14   _________________________________\r\n# Reload the model from the 2 files we saved\r\nwith open('model_config.json') as json_file:\r\n    json_config = json_file.read()\r\nnew_model = tf.keras.models.model_from_json(json_config)\r\n\r\n# Load weights\r\nnew_model.load_weights('weights_only.h5')\r\n'''\r\n```", "> You can load tf1.15+ model using tf1.15-2.1. Then save only weights to open in tf1.14\r\n> ___________________________________________________________________\r\n> # In tensorflow 1.15-2.1\r\n> # Load model\r\n> model = load_model(\"my_model.h5\")\r\n> \r\n> # Save weights and architecture\r\n> model.save_weights(\"weights_only.h5\")\r\n> \r\n> # Save model config\r\n> json_config = model.to_json()\r\n> with open('model_config.json', 'w') as json_file:\r\n> json_file.write(json_config)\r\n> ___________________________________________________________________\r\n> # In tensorflow 1.14\r\n> # Reload the model from the 2 files we saved\r\n> with open('model_config.json') as json_file:\r\n> json_config = json_file.read()\r\n> new_model = tf.keras.models.model_from_json(json_config)\r\n> \r\n> # Load weights\r\n> new_model.load_weights('weights_only.h5')\r\n> '''\r\n\r\nThank you. I will try later.", "I wrote a repo to handle this issue. It utilizes docker to load/save models in different tensorflow versions and gets around the ragged keyword. Here it is https://github.com/OlofHarrysson/tensorflow-model-converter", "> I wrote a repo to handle this issue. It utilizes docker to load/save models in different tensorflow versions and gets around the ragged keyword. Here it is https://github.com/OlofHarrysson/tensorflow-model-converter\r\n\r\nIt seems great._", "I tried out the repo from @OlofHarrysson but it wasn't able to load a tf.keras 2.1.0 model for some reason. \r\n\r\nI was able to get past the \"ragged\" error though. In the `model_config.json`, I just ctrl+f for 'rag' and found one match which was this: `\"ragged\": false,`. I deleted that and then was able to load the model configuration and its weights :)"]}, {"number": 33478, "title": "Need a way to get Intermediate Layer Inputs/Activations for tf.keras Models", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using):\r\n2.0\r\n- Are you willing to contribute it (Yes/No):\r\nYes, if there is a consensus on how it should be designed. \r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nIn eager mode, there is no way to access a tf.keras model's layer inputs/outputs during training (as far as I can tell, please correct me if I'm wrong). In TF 1.x (graph mode), this was not a problem, since you could use <s>[`layer.input`](https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/engine/base_layer.py#L1541-L1558) or [`layer.output`](https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/engine/base_layer.py#L1560-L1577)</s> [`layer.inbound_nodes` or `layer.outbound_nodes`](https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/engine/base_layer.py#L1663-L1673) to get these tensors and use those values, but this is no longer possible in eager mode. \r\n\r\nPyTorch solves this issue by allowing users to register hooks on layers, which is essentially a function that is called before/after the forward/backward pass on a layer. [Here](https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.register_forward_hook) is the code for `register_forward_hook` in PyTorch.\r\n\r\nAlternatively, the input/output properties of a layer could store a reference to the tensors used in the most recent forward pass.\r\n\r\n**Will this change the current api? How?**\r\nYes, depending on how this is implemented. If a hooks approach is used, this public method would have to be added to `tf.keras.layers.Layer`. If the input/output property approach is used, these properties would have new behavior in eager mode.\r\n\r\n**Who will benefit with this feature?**\r\nBeing able to access, record, manipulate, or otherwise use layer inputs and outputs for models during training/inference is generally very useful. \r\n\r\nA specific example is the [K-FAC](https://arxiv.org/abs/1503.05671) optimization algorithm, which uses each layer's inputs and pre-activation gradients to approximate the Fisher information matrix. The [current implementation](https://github.com/tensorflow/kfac) does not support eager. PyTorch implementations (e.g. [this one](https://github.com/alecwangcq/KFAC-Pytorch/blob/master/optimizers/kfac.py#L81-L82)) of this algorithm use hooks to do this.\r\n\r\nAnother use case is visualizing intermediate activations of CNNs. [This example](https://towardsdatascience.com/visualizing-intermediate-activation-in-convolutional-neural-networks-with-keras-260b36d60d0) uses layer.outputs in TF 1.x + Keras to grab the right tensors then creating an augmented model. This process would be greatly simplified by allowing access to intermediate activations without augmenting the model. \r\n  \r\n**Any Other info.**\r\n[Here](https://github.com/tensorflow/tensorflow/issues/33129) is a related issue about getting intermediate activations.\r\n\r\n\r\n**EDIT (2019-10-20):** I learned that `layer.inbound_nodes `and `layer.outbound_nodes` used to have this behavior, not `layer.input` and `layer.output`. `layer.input` and `layer.output` track the tensors that are created when [`model.build(input_shape)`](https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/engine/base_layer.py#L365-L379) is called. When you use the model as a callable on your own input (i.e. `predictions = model(inputs)`), new tensors are created (reusing the model's weights/architecture). In TF 1.x, `inputs` would be added to the `inbound_nodes` list and `predictions` would be added to the `outbound_nodes` list during this call. Now, since in eager mode the model is called on a new `EagerTensor` for every training step, it is not reasonable to add that many new tensors to these lists, so the property was deprecated. Since this feature used to exist, I think it's important for a reasonable replacement to exist in TF2 (such as hooks or a layer property tracking the most recent inputs/outputs).", "comments": ["@n2cholas If you are looking for `tf.keras` Models, `model.get_layer(layer_name).outputs` or `model.layer[layer_index].output` will provide the details you are looking. This was already answered in the [link](https://github.com/tensorflow/tensorflow/issues/33129) you provided. \r\n\r\nPlease let us know what you think. Thanks!", "Thanks @jvishnuvardhan for your response. I don't think `model.layer[layer_index].output` gives me the outputs I need.  Here's a minimal example of trying to compute the output gradients from a Dense layer using this property (runs in colab):\r\n\r\n```\r\n%tensorflow_version 2.x\r\nimport tensorflow as tf\r\n\r\n(x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\r\ntrain_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\r\n\r\nmodel = tf.keras.models.Sequential([\r\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\r\n  tf.keras.layers.Dense(128),\r\n  tf.keras.layers.ReLU(),\r\n  tf.keras.layers.Dense(10)\r\n])\r\n\r\nloss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\r\n\r\nimages, labels = next(iter(train_ds))\r\n\r\nwith tf.GradientTape() as tape:\r\n  predictions = model(images)\r\n  loss = loss_object(labels, predictions)\r\n  \r\nprint(tape.gradient(loss, model.layers[1].output))\r\n```\r\n\r\nThis prints `None` instead of the gradient. Manually tracking the outputs at each layer then computing the gradient gives me the output gradient of the Dense layer, which is what I need:\r\n\r\n```\r\noutputs = [images]\r\nwith tf.GradientTape() as tape:\r\n  for layer in model.layers:\r\n    outputs.append(layer(outputs[-1]))\r\n  loss = loss_object(labels, outputs[-1])\r\n  \r\nprint(tape.gradient(loss, outputs[2]))\r\n```\r\n\r\nIn this sequential case, manually doing the forward pass (as I did with the loop) is trivial, but it can become difficult with other architectures, such as ResNets. With hooks, this would not be necessary.\r\n\r\nAm I doing something wrong? Is there a better way for me to track the intermediate activations?", "If you change the model code to not include an `input_shape`, the model is never built and the `input` and `output` properties don't exist, even after the forward pass. Concretely, if you change the model code from my previous example to the following:\r\n```\r\nmodel = tf.keras.models.Sequential([\r\n  tf.keras.layers.Flatten(),\r\n  tf.keras.layers.Dense(128),\r\n  tf.keras.layers.ReLU(),\r\n  tf.keras.layers.Dense(10)\r\n])\r\n```\r\nThe first bit of code in my previous reply will result in `AttributeError: Layer dense has no inbound nodes.`\r\n\r\nThe `input` and `output` properties simply track the tensors created when the model built, not the tensors created during the `predictions = model(images)` call. The tensors I'm interested in are the ones created during that call.\r\n\r\n**EDIT (2019-10-20):** I updated the original feature request with this information (and more).", "@jvishnuvardhan @tanzhenyu Any update on this? I would be happy to implement hooks and submit a PR if hooks seem like the most suitable way to move forward.", "@n2cholas I will happily test your PR :D", "Same problem here, great problem description @n2cholas! \r\nfyi - I tried a function closure as workaround solution (suggested [here](https://github.com/keras-team/keras/issues/13453)) but this throws a TypeError in Tf 2.x...\r\n\r\nTypeError: To be compatible with tf.contrib.eager.defun, Python functions must return zero or more Tensors; in compilation of <function mu_loss_2 at 0x7f2cc7dc4bf8>, found return value of type <class 'function'>, which is not a Tensor.\r\n\r\nLooking forward to solution for this in Tf2.x", "My current application also needs to access the intermediate activations and backward gradients. Since a solution to this has not been implemented yet, does it make sense to just save these tensors as attributes of my class which is inherited from `tf.keras.models.Model`?", "Sorry about the delay, I won't have the bandwidth to work on my implementation until the end of December. I'd be happy to test someone else's implementation if they do it sooner!\r\n\r\n> My current application also needs to access the intermediate activations and backward gradients. Since a solution to this has not been implemented yet, does it make sense to just save these tensors as attributes of my class which is inherited from `tf.keras.models.Model`?\r\n\r\nYes, this is what I've been doing. I subclassed all the layer types I needed, then saved the input/output tensors as attributes during my forward pass.", "Should I create an RFC for this, since it's an API addition? Or just a PR? Also, how should this interact with autograph and model saving? The base_layer.py code is pretty intimidating.  I'd love some guidance from a TensorFlower, if possible.\r\n\r\nHere's a temporary layer wrapper I've been using to get this functionality. This is pretty similar to what I'd do in the `tf.keras.layers.Layer` code (in the `__call__` function): \r\n\r\n```Python\r\n%tensorflow_version 2.x \r\nimport tensorflow as tf\r\nfrom typing import List, Callable, Optional\r\n\r\nclass LayerWithHooks(tf.keras.layers.Layer):\r\n  def __init__(\r\n      self, \r\n      layer: tf.keras.layers.Layer,\r\n      hooks: List[Callable[[tf.Tensor, tf.Tensor], Optional[tf.Tensor]]] = None):\r\n    super().__init__()\r\n    self._layer = layer\r\n    self._hooks = hooks or []\r\n  \r\n  def call(self, input: tf.Tensor) -> tf.Tensor:\r\n    output = self._layer(input)\r\n    for hook in self._hooks:\r\n      hook_result = hook(input, output)\r\n      if hook_result is not None:\r\n        output = hook_result\r\n    return output\r\n  \r\n  def register_hook(\r\n      self, \r\n      hook: Callable[[tf.Tensor, tf.Tensor], Optional[tf.Tensor]]) -> None:\r\n    self._hooks.append(hook)\r\n\r\nmodel = tf.keras.Sequential([\r\n  LayerWithHooks(tf.keras.layers.Dense(50, input_shape=(1,))),\r\n  LayerWithHooks(tf.keras.layers.Dense(1)),\r\n])\r\n```\r\n\r\nIf you have an existing model, the code below seems to work, though I'm always hesitant to use monkey patching:\r\n\r\n```Python\r\nmodel = tf.keras.Sequential([\r\n  tf.keras.layers.Dense(50, input_shape=(1,)),\r\n  tf.keras.layers.Dense(1),\r\n])\r\n\r\ndef get_call_fn(layer: tf.keras.layers.Layer) -> Callable[[tf.Tensor], tf.Tensor]:\r\n  old_call_fn = layer.call\r\n  def call(input: tf.Tensor) -> tf.Tensor:\r\n    output = old_call_fn(input)\r\n    for hook in layer._hooks:\r\n        hook_result = hook(input, output)\r\n        if hook_result is not None:\r\n          output = hook_result\r\n    return output\r\n  return call\r\n\r\nfor layer in model.layers:\r\n  layer._hooks = []\r\n  layer.call = get_call_fn(layer)\r\n  layer.register_hook = lambda hook: layer._hooks.append(hook)\r\n```\r\n\r\nHere's an example of saving inputs/outputs with this:\r\n\r\n```Python\r\nclass InputOutputSaver:\r\n  def __call__(self, input: tf.Tensor, output: tf.Tensor) -> None:\r\n    self.input = input\r\n    self.output = output\r\n\r\nsavers = {}\r\nfor layer in model.layers:\r\n  saver = InputOutputSaver()\r\n  layer.register_hook(saver)\r\n  savers[layer] = saver\r\n\r\ninps = tf.convert_to_tensor([[1.], [2.], [3.],])\r\nprint(model(inps))\r\nprint(savers[model.layers[0]].output)\r\n```\r\n\r\nThis temporary solution workaround was not thoroughly tested, please let me know if you have any suggestions.", "Did you know that model.outputs is a mutable Pyhon list? You can just change it to return all outputs.\r\n```\r\n# assuming model is a keras Sequence and x is a valid input\r\noutput_names = [l.name for l in model.layers]\r\nmodel.outputs = [l.output for l in model.layers]\r\nmodel.build(input_shape=x.shape)\r\noutput_values = model(x)\r\nlayer_name_to_output_value = dict(zip(output_names, output_values))\r\n```\r\n", "Has some improvement been done to solve this issue? Or do we still need to save manually intermediate output as an attribute of the model? It is very impractical to have this problem when using model subclassing in eager mode", "hey guys\r\n\r\nIf i want to get the output of a intermediate layer in my NN, What should i do? which function can give me the output of the specific layer? and can i define a new loss function at that layer? for example for parallel learning : parent classification and subclass classification. ", "Sorry for the delay!\r\nI'm not sure if layer.input and layer.output cannot achieve what you're looking for.\r\nFirst of all, layer.inbound_nodes and layer.outbound_nodes are deprecated in 2.0.\r\nSecond of all, layer.input and layer.output are still symbolic tensors, just as you described, they're created under the first `layer.build(input_shape)`\r\n\r\nSo to make your first use case work, i.e., the activation visualization work, it should be exactly the same code as before, i.e.,:\r\n```python\r\noriginal_model = tf.keras.Model(inputs, outputs)\r\nactivation_outputs = [layer.output for layer in original_model.layers]\r\nactivation_model = tf.keras.Model(inputs, activation_outputs)\r\n```\r\n\r\nTo make your second use case work, i.e., getting the right gradient, remember `input` and `output` are symbolic tensors, what you really need is the gradient of an `EagerTensor` imperatively, so:\r\n```python\r\nseq_1 = tf.keras.models.Sequential([\r\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\r\n  tf.keras.layers.Dense(128),\r\n])\r\nseq_2 = tf.keras.models.Sequential([\r\n  tf.keras.layers.ReLU(),\r\n  tf.keras.layers.Dense(10)\r\n])\r\nloss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\r\nimages, labels = next(iter(train_ds))\r\nwith tf.GradientTape() as tape:\r\n  out = seq_1(images)\r\n  predictions = seq_2(out)\r\n  loss = loss_object(labels, predictions)\r\n  \r\nprint(tape.gradient(loss, out))\r\n```\r\nOr you can create a subclassed model that returns the final output as well as the intermediate output.\r\n\r\nIf this is too much of a hassle, maybe we could consider `layer.eager_input` and `layer.symbolic_input`.", "BTW, you can still call a layer repeatedly and add inputs to the nodes.\r\n```python\r\ninput_1 = tf.keras.Input((5,), name='input_1')\r\ndense = tf.keras.layers.Dense(units=3)\r\noutput_1 = dense(input_1) \r\nprint(dense.inbound_nodes[0].input_tensors)  #<tf.Tensor 'input_1:0' shape=(None, 5) dtype=float32>\r\ninput_2 = tf.keras.Input((5,), name='input_2')\r\noutput_2 = dense(input_2)\r\nprint(dense.inbound_nodes[1].input_tensors)  #<tf.Tensor 'input_2:0' shape=(None, 5) dtype=float32>\r\n```", "Also check this as suggestion:\r\nhttps://github.com/tensorflow/tensorflow/issues/33129#issuecomment-539876444", "Closing it for now. Feel free to re-open if you still have concerns :-)", "How do we the same thing when running non-eager mode, i.e `tf.function`?", "> BTW, you can still call a layer repeatedly and add inputs to the nodes.\r\n> \r\n> ```python\r\n> input_1 = tf.keras.Input((5,), name='input_1')\r\n> dense = tf.keras.layers.Dense(units=3)\r\n> output_1 = dense(input_1) \r\n> print(dense.inbound_nodes[0].input_tensors)  #<tf.Tensor 'input_1:0' shape=(None, 5) dtype=float32>\r\n> input_2 = tf.keras.Input((5,), name='input_2')\r\n> output_2 = dense(input_2)\r\n> print(dense.inbound_nodes[1].input_tensors)  #<tf.Tensor 'input_2:0' shape=(None, 5) dtype=float32>\r\n> ```\r\n@tanzhenyu \r\nI want to get intermediate tensor,not layer's output.for example:\r\n```\r\nmodel = train_model()\r\nfunc = tf.function(model)\r\ntensor_specs1 = tf.TensorSpec.from_tensor(model.input)\r\ncall = func.get_concrete_function(tensor_specs1)\r\ngraph = call.graph\r\noutputs = graph.get_tensor_by_name('model_1/word_encoder_time/word_attention/Softmax:0')\r\npred_model = tf.keras.models.Model(model.input,outputs)\r\nresults = pred_model(tensor_specs1)\r\n\r\n```\r\nbut raise an exception:\r\n```\r\nraise ValueError(\"Tensor %s is not an element of this graph.\" % obj)\r\nValueError: Tensor Tensor(\"model_1/word_encoder_time/model/word_attention/BiasAdd:0\", shape=(?, 10), dtype=float32) is not an element of this graph\r\n```\r\n```\r\noutputs = [model.get_layer(name=output).get_output_at(0) for output in output_layers]\r\npred_model = tf.keras.models.Model(model.input,outputs)\r\n```\r\nIt's working ,but it's not what I want.I want to get attention's score ,not only layer's output \r\n", "@tanzhenyu any updates ?", "Any updates?", "Using monkey patch to break in and hook, that is not a elegant way, but it works\r\n```python\r\ndef proxy_call(input:tf.Tensor, obj:tf.keras.layers.Layer)->tf.Tensor:\r\n    if obj._before_call is not None:\r\n        obj._before_call(obj,input)\r\n    output = obj._old_call(input)\r\n    if obj._after_call is not None:\r\n        hook_result = obj._after_call(obj, input, output)\r\n        if hook_result is not None:\r\n            output = hook_result\r\n    return output\r\n\r\ndef hook_layer_call(layers: List[tf.keras.layers.Layer], \r\n                    before_call: Callable[[tf.keras.layers.Layer, tf.Tensor],None]=None, \r\n                    after_call: Callable[[tf.keras.layers.Layer, tf.Tensor, tf.Tensor],Optional[tf.Tensor]]=None):\r\n    for layer in layers:\r\n        layer._before_call = before_call\r\n        layer._after_call = after_call\r\n        layer._old_call = layer.call\r\n        layer.call = functools.partial(proxy_call, obj=layer)\r\n\r\ndef print_input_output(layer:tf.keras.layers.Layer, input:tf.Tensor, output:tf.Tensor):\r\n    print(input, output)\r\n\r\n# suppose you have a model(such as a tf.keras.Sequential instance)\r\nhook_layer_call(model.layers, after_call=print_input_output)\r\n```\r\n      "]}, {"number": 33477, "title": "Problem with manually updating matrix in a custom layer.", "body": "## System information:\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution: MacOs 10.14.6\r\nTensorFlow installed from: pip\r\nTensorFlow version: 2.0\r\n\r\n## Describe the current behavior and expected behavior\r\nI am really new to Tensorflow, so maybe this is quite obvious, but what I am trying to do is to basically create my own layer, where I introduce an additional matrix that I update manually each call. I started off with a copy of a SimpleRNNCell from recurrent.py and my idea was to simply extend this SimpleRNN (Layer) into what I need. This extensions would not be a lot of effort, since it would only include\r\na) Initialising a matrix when the cell is created (with zeros),\r\nb) Manually updating this matrix in the call() function. (this is done by simple building the output product of the recurrent layers activation and adding it to the to the matrix in question),\r\nc) Adding it onto the normal reservoir activity.\r\n\r\nMy Problem is that when trying to manually updating this matrix, I get presented the following error:\r\n\r\nTypeError: An op outside of the function building code is being passed\r\na \"Graph\" tensor. It is possible to have Graph tensors\r\nleak out of the function building context by including a\r\ntf.init_scope in your function building code.\r\nFor example, the following function will fail:\r\n```\r\n  @tf.function\r\n  def has_init_scope():\r\n    my_constant = tf.constant(1.)\r\n    with tf.init_scope():\r\n      added = my_constant * 2\r\nThe graph tensor has name: add_1\r\n```\r\n\r\n## Code to reproduce the issue\r\n- Initialisation of the matrix:\r\n```\r\nself.A = K.variable(value=tf.zeros((self.units, self.units)),\r\n        dtype='float32', name='fast_weights')\r\n```\r\n- Manual update\r\n```\r\nself.A = self.l * self.A + self.e * K.dot(K.transpose(h), h)\r\n```\r\n, where h is the activation of the hidden, recurrent layer. This is where the error is thrown.\r\n\r\n- Addition to update step:\r\n```\r\nh = self.activation(K.bias_add(K.dot(inputs, self.kernel), self.bias) + K.dot(h, self.recurrent_kernel)) + K.dot(h, self.A)\r\n```\r\nwhere ```K.dot(h, self.A)``` is what I added.\r\n\r\nThank you in advance.", "comments": ["@Devrim-Celik \r\nCan you please help us with the minimal standalone code to reproduce the issue in our environment.It is easy for localizing the issue faster. Thanks!", "Yes, of course:\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow.python.keras.layers.recurrent import RNN, DropoutRNNCellMixin\r\nfrom tensorflow.python.framework import ops\r\nfrom tensorflow.python.framework import tensor_shape\r\nfrom tensorflow.python.keras import activations\r\nfrom tensorflow.python.keras import backend as K\r\nfrom tensorflow.python.keras import constraints\r\nfrom tensorflow.python.keras import initializers\r\nfrom tensorflow.python.keras import regularizers\r\nfrom tensorflow.python.keras.engine.base_layer import Layer\r\nfrom tensorflow.python.keras.engine.input_spec import InputSpec\r\nfrom tensorflow.python.keras.utils import tf_utils\r\nfrom tensorflow.python.ops import array_ops\r\nfrom tensorflow.python.util import nest\r\nfrom tensorflow.python.util.tf_export import keras_export\r\n\r\n\r\n\r\nclass FastWeightRNNCell(DropoutRNNCellMixin, Layer):\r\n  \"\"\"Cell class for FastWeightRNN.\r\n  Arguments:\r\n    units: Positive integer, dimensionality of the output space.\r\n    activation: Activation function to use.\r\n      Default: hyperbolic tangent (`tanh`).\r\n      If you pass `None`, no activation is applied\r\n      (ie. \"linear\" activation: `a(x) = x`).\r\n    use_bias: Boolean, whether the layer uses a bias vector.\r\n    kernel_initializer: Initializer for the `kernel` weights matrix,\r\n      used for the linear transformation of the inputs.\r\n    recurrent_initializer: Initializer for the `recurrent_kernel`\r\n      weights matrix, used for the linear transformation of the recurrent state.\r\n    bias_initializer: Initializer for the bias vector.\r\n    kernel_regularizer: Regularizer function applied to\r\n      the `kernel` weights matrix.\r\n    recurrent_regularizer: Regularizer function applied to\r\n      the `recurrent_kernel` weights matrix.\r\n    bias_regularizer: Regularizer function applied to the bias vector.\r\n    kernel_constraint: Constraint function applied to\r\n      the `kernel` weights matrix.\r\n    recurrent_constraint: Constraint function applied to\r\n      the `recurrent_kernel` weights matrix.\r\n    bias_constraint: Constraint function applied to the bias vector.\r\n\r\n  Call arguments:\r\n    inputs: A 2D tensor.\r\n    states: List of state tensors corresponding to the previous timestep.\r\n    training: Python boolean indicating whether the layer should behave in\r\n      training mode or in inference mode. Only relevant when `dropout` or\r\n      `recurrent_dropout` is used.\r\n  \"\"\"\r\n\r\n  def __init__(self,\r\n               units,\r\n               learning_rate,\r\n               decay_rate,\r\n               S,\r\n               fast_weight=True,\r\n               layer_norm=True,\r\n               activation='tanh',\r\n               use_bias=True,\r\n               kernel_initializer='glorot_uniform',\r\n               recurrent_initializer='orthogonal',\r\n               bias_initializer='zeros',\r\n               kernel_regularizer=None,\r\n               recurrent_regularizer=None,\r\n               bias_regularizer=None,\r\n               kernel_constraint=None,\r\n               recurrent_constraint=None,\r\n               bias_constraint=None,\r\n               **kwargs):\r\n    super(FastWeightRNNCell, self).__init__(**kwargs)\r\n    self.units = units\r\n\r\n    self.l = decay_rate # for lambda\r\n    self.e = learning_rate # for eta\r\n    self.S = S\r\n\r\n    self.layer_norm = layer_norm\r\n    self.fast_weight = fast_weight\r\n\r\n    self.activation = activations.get(activation)\r\n    self.use_bias = use_bias\r\n\r\n    self.kernel_initializer = initializers.get(kernel_initializer)\r\n    self.recurrent_initializer = initializers.get(recurrent_initializer)\r\n    self.bias_initializer = initializers.get(bias_initializer)\r\n\r\n    self.kernel_regularizer = regularizers.get(kernel_regularizer)\r\n    self.recurrent_regularizer = regularizers.get(recurrent_regularizer)\r\n    self.bias_regularizer = regularizers.get(bias_regularizer)\r\n\r\n    self.kernel_constraint = constraints.get(kernel_constraint)\r\n    self.recurrent_constraint = constraints.get(recurrent_constraint)\r\n    self.bias_constraint = constraints.get(bias_constraint)\r\n\r\n    self.state_size = self.units\r\n    self.output_size = self.units\r\n\r\n    print(\"Learning rate {} and decay {}\".format(self.e, self.l))\r\n\r\n  @tf_utils.shape_type_conversion\r\n  def build(self, input_shape):\r\n    self.kernel = self.add_weight(\r\n        shape=(input_shape[-1], self.units),\r\n        name='kernel',\r\n        initializer=self.kernel_initializer,\r\n        regularizer=self.kernel_regularizer,\r\n        constraint=self.kernel_constraint)\r\n    self.recurrent_kernel = self.add_weight(\r\n        shape=(self.units, self.units),\r\n        name='recurrent_kernel',\r\n        initializer=self.recurrent_initializer,\r\n        regularizer=self.recurrent_regularizer,\r\n        constraint=self.recurrent_constraint)\r\n    self.bias = self.add_weight(\r\n          shape=(self.units,),\r\n          name='bias',\r\n          initializer=self.bias_initializer,\r\n          regularizer=self.bias_regularizer,\r\n          constraint=self.bias_constraint)\r\n    self.A = K.constant(0,\r\n          shape=(self.units, self.units),\r\n          name='fast_weight_matrix')\r\n    self.built = True\r\n\r\n  def call(self, inputs, states, training=None):\r\n    prev_output = states[0]\r\n\r\n    h = self.activation(K.bias_add(K.dot(inputs, self.kernel), self.bias) \\\r\n        + K.dot(prev_output, self.recurrent_kernel))\r\n\r\n\r\n    if self.layer_norm:\r\n\r\n        if self.fast_weight:\r\n            # TODO PROBLEM\r\n            self.A = self.l * self.A + self.e * K.dot(K.transpose(h), h)\r\n\r\n            # S times\r\n            for _ in range(self.S):\r\n                h = self.activation(K.bias_add(K.dot(inputs, self.kernel), self.bias) \\\r\n                    + K.dot(h, self.recurrent_kernel)) + K.dot(h, self.A)\r\n\r\n\r\n\r\n    return h, [h]\r\n\r\n  def get_initial_state(self, inputs=None, batch_size=None, dtype=None):\r\n    return _generate_zero_filled_state_for_cell(self, inputs, batch_size, dtype)\r\n\r\n########################\r\n\r\nclass FastWeightRNN(RNN):\r\n  \"\"\"Fully-connected RNN where the output is to be fed back to input.\r\n  Arguments:\r\n    units: Positive integer, dimensionality of the output space.\r\n    activation: Activation function to use.\r\n      Default: hyperbolic tangent (`tanh`).\r\n      If you pass None, no activation is applied\r\n      (ie. \"linear\" activation: `a(x) = x`).\r\n    use_bias: Boolean, whether the layer uses a bias vector.\r\n    kernel_initializer: Initializer for the `kernel` weights matrix,\r\n      used for the linear transformation of the inputs.\r\n    recurrent_initializer: Initializer for the `recurrent_kernel`\r\n      weights matrix,\r\n      used for the linear transformation of the recurrent state.\r\n    bias_initializer: Initializer for the bias vector.\r\n    kernel_regularizer: Regularizer function applied to\r\n      the `kernel` weights matrix.\r\n    recurrent_regularizer: Regularizer function applied to\r\n      the `recurrent_kernel` weights matrix.\r\n    bias_regularizer: Regularizer function applied to the bias vector.\r\n    kernel_constraint: Constraint function applied to\r\n      the `kernel` weights matrix.\r\n    recurrent_constraint: Constraint function applied to\r\n      the `recurrent_kernel` weights matrix.\r\n    bias_constraint: Constraint function applied to the bias vector.\r\n    return_sequences: Boolean. Whether to return the last output\r\n      in the output sequence, or the full sequence.\r\n    return_state: Boolean. Whether to return the last state\r\n      in addition to the output.\r\n    go_backwards: Boolean (default False).\r\n      If True, process the input sequence backwards and return the\r\n      reversed sequence.\r\n    stateful: Boolean (default False). If True, the last state\r\n      for each sample at index i in a batch will be used as initial\r\n      state for the sample of index i in the following batch.\r\n    unroll: Boolean (default False).\r\n      If True, the network will be unrolled,\r\n      else a symbolic loop will be used.\r\n      Unrolling can speed-up a RNN,\r\n      although it tends to be more memory-intensive.\r\n      Unrolling is only suitable for short sequences.\r\n  Call arguments:\r\n    inputs: A 3D tensor.\r\n    mask: Binary tensor of shape `(samples, timesteps)` indicating whether\r\n      a given timestep should be masked.\r\n    training: Python boolean indicating whether the layer should behave in\r\n      training mode or in inference mode. This argument is passed to the cell\r\n      when calling it. This is only relevant if `dropout` or\r\n      `recurrent_dropout` is used.\r\n    initial_state: List of initial state tensors to be passed to the first\r\n      call of the cell.\r\n  \"\"\"\r\n\r\n  def __init__(self,\r\n               units,\r\n               learning_rate,\r\n               decay_rate,\r\n               S,\r\n               fast_weight=True,\r\n               layer_norm=True,\r\n               activation='tanh',\r\n               use_bias=True,\r\n               kernel_initializer='glorot_uniform',\r\n               recurrent_initializer='orthogonal',\r\n               bias_initializer='zeros',\r\n               kernel_regularizer=None,\r\n               recurrent_regularizer=None,\r\n               bias_regularizer=None,\r\n               kernel_constraint=None,\r\n               recurrent_constraint=None,\r\n               bias_constraint=None,\r\n               return_sequences=False,\r\n               return_state=False,\r\n               go_backwards=False,\r\n               stateful=False,\r\n               unroll=False,\r\n               **kwargs):\r\n\r\n    cell = FastWeightRNNCell(\r\n        units,\r\n        learning_rate,\r\n        decay_rate,\r\n        S,\r\n        fast_weight=True,\r\n        layer_norm=True,\r\n        activation=activation,\r\n        use_bias=use_bias,\r\n        kernel_initializer=kernel_initializer,\r\n        recurrent_initializer=recurrent_initializer,\r\n        bias_initializer=bias_initializer,\r\n        kernel_regularizer=kernel_regularizer,\r\n        recurrent_regularizer=recurrent_regularizer,\r\n        bias_regularizer=bias_regularizer,\r\n        kernel_constraint=kernel_constraint,\r\n        recurrent_constraint=recurrent_constraint,\r\n        bias_constraint=bias_constraint,\r\n        dtype=kwargs.get('dtype'))\r\n    super(FastWeightRNN, self).__init__(\r\n        cell,\r\n        return_sequences=return_sequences,\r\n        return_state=return_state,\r\n        go_backwards=go_backwards,\r\n        stateful=stateful,\r\n        unroll=unroll,\r\n        **kwargs)\r\n\r\n    self.input_spec = [InputSpec(ndim=3)]\r\n\r\n  def call(self, inputs, initial_state=None):\r\n    return super(FastWeightRNN, self).call(\r\n        inputs, initial_state=initial_state)\r\n\r\ndef _generate_zero_filled_state_for_cell(cell, inputs, batch_size, dtype):\r\n  if inputs is not None:\r\n    batch_size = array_ops.shape(inputs)[0]\r\n    dtype = inputs.dtype\r\n  return _generate_zero_filled_state(batch_size, cell.state_size, dtype)\r\n\r\n\r\ndef _generate_zero_filled_state(batch_size_tensor, state_size, dtype):\r\n  \"\"\"Generate a zero filled tensor with shape [batch_size, state_size].\"\"\"\r\n  if batch_size_tensor is None or dtype is None:\r\n    raise ValueError(\r\n        'batch_size and dtype cannot be None while constructing initial state: '\r\n        'batch_size={}, dtype={}'.format(batch_size_tensor, dtype))\r\n\r\n  def create_zeros(unnested_state_size):\r\n    flat_dims = tensor_shape.as_shape(unnested_state_size).as_list()\r\n    init_state_size = [batch_size_tensor] + flat_dims\r\n    return array_ops.zeros(init_state_size, dtype=dtype)\r\n\r\n  if nest.is_sequence(state_size):\r\n    return nest.map_structure(create_zeros, state_size)\r\n  else:\r\n    return create_zeros(state_size)\r\n\r\n\r\nif __name__==\"__main__\":\r\n    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data(path='mnist.npz')\r\n\r\n    eta = 0.5 # learning rate for A\r\n    lamb = 0.95 # decay rate\r\n    S = 1\r\n\r\n    # transform int labels to one hot vectors\r\n    y_train = tf.keras.utils.to_categorical(y_train)\r\n    y_test = tf.keras.utils.to_categorical(y_test)\r\n\r\n    # normalize input TODO why?\r\n    x_train = x_train.astype('float32') / 255\r\n    x_test = x_test.astype('float32') / 255\r\n\r\n    # define model\r\n    model = tf.keras.Sequential([\r\n\r\n    FastWeightRNN(units=50, learning_rate = eta, S = S, decay_rate = lamb,\r\n        layer_norm = True, input_shape=(28, 28)),\r\n    layers.Dense(units=10, activation='softmax')])\r\n\r\n    # compile model\r\n    model.compile(optimizer=tf.keras.optimizers.Adam(0.01),\r\n                  loss='categorical_crossentropy',\r\n                  metrics=['accuracy'])\r\n\r\n    # fit model\r\n    model.fit(x_train, y_train, epochs=1, batch_size=32)\r\n\r\n    # evaluate model\r\n    model.evaluate(x_test, y_test, verbose=0)\r\n```\r\nWhere FastWeightRNN and FastWeightCell as modified versions of SimpleRNN and SimpleRNNCell. ", "I solved the issue by initialising my matrix as a ```tf.Variable```:\r\n\r\n```\r\n    self.A = tf.Variable(np.zeros((self.units, self.units)),\r\n          shape=(self.units, self.units),\r\n          name='fast_weight_matrix',\r\n          dtype=\"float32\",\r\n          trainable=False)\r\n```"]}, {"number": 33476, "title": "empirical mean from tf.random.gamma does not match theoretical expectation", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nLinux Ubuntu 16.04.6\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nN/A\r\n- TensorFlow installed from (source or binary):\r\nNot sure, came pre-installed so probably binary\r\n- TensorFlow version (use command below):\r\n1.13.1\r\n- Python version:\r\n3.5.5\r\n- Bazel version (if compiling from source):\r\nN/A\r\n- GCC/Compiler version (if compiling from source):\r\nN/A\r\n- CUDA/cuDNN version:\r\nCUDA: 10.0.130\r\ncuDNN: 7\r\n- GPU model and memory:\r\nTesla K80, total memory = 11441 MiB\r\n\r\n**Describe the current behavior**\r\nIf I sample many values from `tf.random.gamma` with shape=A and beta=B and compute their mean, I get a value which isn't close to A/B.\r\n\r\nIf I use the script below, computing the mean absolute difference between the empirical and theoretical mean, I get ~7.26 (with 500 tries, 50k samples from the gamma distribution each time).\r\n\r\n**Describe the expected behavior**\r\nThe expected value of a Gamma-distributed random variable with shape parameter A and inverse scale parameter B is A/B, so the empirical mean should be close to A/B. \r\n\r\nSo I would expect the output of my script to be close to 0.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nCode to report the mean absolute discrepancy between the empirical and theoretical means:\r\n```\r\ndef check_gamma(n_sample=50000, n_iter=500):\r\n    shape_ph = tf.placeholder(tf.float32)\r\n    beta_ph = tf.placeholder(tf.float32)\r\n    gamma_mean = tf.reduce_mean(tf.random.gamma(shape=[n_sample], alpha=shape_ph, beta=beta_ph))\r\n    mean_difference = np.zeros(shape=n_iter)\r\n    mean_difference_np = np.zeros(shape=n_iter)\r\n    with tf.Session() as sess:\r\n        for i in range(n_iter):\r\n            # sample a shape (non-negative)\r\n            shape_parameter = np.random.uniform(1, 5)\r\n            # sample a scale (non-negative)\r\n            scale_parameter = np.random.uniform(1, 5)\r\n            # the gamma distribution in tensorflow takes the inverse scale parameter\r\n            beta = 1.0/scale_parameter\r\n            # theoretical mean of gamma distribution:\r\n            expected_mean = shape_parameter*scale_parameter\r\n            # sample it!\r\n            sample_mean = sess.run(gamma_mean, feed_dict={shape_ph: shape_parameter, beta_ph: beta})\r\n            mean_difference[i] = np.abs(expected_mean - sample_mean)\r\n            mean_difference_np[i] = np.abs(expected_mean - np.mean(np.random.gamma(size=n_sample, shape=shape_parameter, scale=scale_parameter)))\r\n    print('average absolute difference in empirical and theoretical means, using tensorflow:', np.mean(mean_difference))\r\n    print('...using numpy:', np.mean(mean_difference_np))\r\n    return True\r\n```\r\n\r\nCode to visualise the distribution:\r\n```def visualise_distribution(n_sample=10000, shape_parameter=1, scale_parameter=2):\r\n    with tf.Session() as sess:\r\n        gamma_samples = sess.run(tf.random.gamma(shape=[n_sample], alpha=shape_parameter, beta=1.0/scale_parameter))\r\n    expected_mean = shape_parameter * scale_parameter\r\n    empirical_mean = np.mean(gamma_samples)\r\n    sns.distplot(gamma_samples, kde=False)\r\n    plt.axvline(x=expected_mean, label='theoretical mean', color='black')\r\n    plt.axvline(x=empirical_mean, label='empirical mean')\r\n    plt.legend()\r\n    return True\r\n```\r\n\r\n\r\n**Other info / logs**\r\n\r\nVisualisation of distribution produced by above code, with shape = 1, scale = 2:\r\n![image](https://user-images.githubusercontent.com/4471845/67024197-ea4ec880-f0fb-11e9-809d-8b9f338598cf.png)", "comments": ["@corcra ,\r\nThank you for reporting, can you please provide a standalone code so that we can try reproducing the issue.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "@corcra ,\r\nAny update on the issue ?Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33476\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33476\">No</a>\n"]}, {"number": 33475, "title": "[ROCm] Updating the README.md with ROCm CSB links", "body": "Minor change to the README, adding both TF 1.15 and 2.x releases to the list of ROCm CSB links\r\n\r\nCC:  @sunway513", "comments": ["Seems auto-merge is not happening but the changes are now committed so we can close this. Thank you for the PR."]}, {"number": 33474, "title": "Can't Load tf.keras Saved h5 Model in TF 2.0 CPU Version", "body": "I can't load tf.keras h5 Model in TF 2.0 CPU Version.\r\n* OS: MacOS Catalina 10.15\r\n* Python version: 3.7.4\r\n* Env: virtualenv as described in TF official website\r\n* TF Version: 2.0 Stable **CPU** version installed with `pip install tensorflow`\r\n\r\n![Screen Shot 2019-10-17 at 21 51 06](https://user-images.githubusercontent.com/32727188/67023093-3f083880-f128-11e9-9448-c9c898c0bf62.png)\r\n\r\n\r\nFirst, I trained the model in google colab with **gpu** by installing `!pip install tensorflow-gpu` and saved the model in google colab with **`model.save(main.h5)`** \r\nAnd, I can load the saved h5 model in colab, so I downloaded the saved h5 model from google colab but I **cannot** load the saved h5 model in the local system with \r\n**`model = tf.keras.models.load_model(\"main.h5\")`**\r\n\r\n![Screen Shot 2019-10-17 at 21 10 35](https://user-images.githubusercontent.com/32727188/67022943-023c4180-f128-11e9-8918-2cefa7eda157.png)\r\n\r\n[Colab Notebook Here](https://nbviewer.jupyter.org/github/ydcjeff/cvify/blob/master/main.ipynb)\r\n\r\nThank You", "comments": ["@ydcjeff Can try following this [comment](https://github.com/tensorflow/tensorflow/issues/22480#issuecomment-439099157) and let me know if it helps.!!!\r\n\r\nIf you are not able to figure it out, Can you please share the step by step process that you followed to save your model and load it as the current information is too vague to answer. Thanks!\r\n\r\n\r\n", "@gowthamkpr \r\n### Below is the code I used in **Google Colab** for training with **GPU** with TF 2.0 Stable\r\n```py\r\n!pip install tensorflow-gpu\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport pandas as pd\r\n\r\ndata = pd.read_csv('https://raw.githubusercontent.com/ydcjeff/cvify/master/dataset.csv', header=None)\r\nX = data.sample(frac=1)\r\nX = X.sample(frac=1)\r\nX = X.sample(frac=1)\r\nX = X.sample(frac=1)\r\nX = X.sample(frac=1)\r\n\r\ntrain_len = int(len(X) * 0.8)\r\ntest_len = int(len(X) - train_len)\r\n\r\ntrain_df = X[0:train_len]\r\ntest_df = X[-test_len:]\r\nprint(train_df.shape)\r\nprint(test_df.shape)\r\n\r\n# convert string to lower case \r\ntrain_texts = train_df[1].values \r\ntrain_texts = [s.lower() for s in train_texts]\r\n\r\ntest_texts = test_df[1].values \r\ntest_texts = [s.lower() for s in test_texts]\r\n\r\n#=======================Convert string to index================\r\nfrom tensorflow.keras.preprocessing.text import Tokenizer\r\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\r\n\r\n# Tokenizer\r\ntk = Tokenizer(num_words=None, char_level=True, oov_token='UNK')\r\ntk.fit_on_texts(train_texts)\r\n# If we already have a character list, then replace the tk.word_index\r\n# If not, just skip below part\r\n\r\n#-----------------------Skip part start--------------------------\r\n# construct a new vocabulary \r\nalphabet=\"abcdefghijklmnopqrstuvwxyz0123456789 ,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\"\r\nchar_dict = {}\r\nfor i, char in enumerate(alphabet):\r\n    char_dict[char] = i + 1\r\n    \r\n# Use char_dict to replace the tk.word_index\r\ntk.word_index = char_dict.copy() \r\n# Add 'UNK' to the vocabulary \r\ntk.word_index[tk.oov_token] = max(char_dict.values()) + 1\r\n#-----------------------Skip part end----------------------------\r\n\r\n# Convert string to index \r\ntrain_sequences = tk.texts_to_sequences(train_texts)\r\ntest_texts = tk.texts_to_sequences(test_texts)\r\n\r\n# Padding\r\ntrain_data = pad_sequences(train_sequences, maxlen=1014, padding='post')\r\ntest_data = pad_sequences(test_texts, maxlen=1014, padding='post')\r\n\r\n# Convert to numpy array\r\ntrain_data = np.array(train_data, dtype='float32')\r\ntest_data = np.array(test_data, dtype='float32')\r\n\r\n#=======================Get classes================\r\ntrain_classes = train_df[0].values\r\ntrain_class_list = [x-1 for x in train_classes]\r\n\r\ntest_classes = test_df[0].values\r\ntest_class_list = [x-1 for x in test_classes]\r\n\r\nfrom tensorflow.keras.utils import to_categorical\r\ntrain_classes = to_categorical(train_class_list)\r\ntest_classes = to_categorical(test_class_list)\r\n\r\nprint(tk.word_index)\r\n\r\nvocab_size = len(tk.word_index)\r\n\r\nfrom tensorflow.keras.layers import Input, Embedding, Activation, Flatten, Dense\r\nfrom tensorflow.keras.layers import Conv1D, MaxPooling1D, Dropout\r\nfrom tensorflow.keras.models import Model\r\n\r\n# =====================Char CNN in whole dataset=======================\r\n# parameter\r\ntf.keras.backend.clear_session()\r\n#@tf.function\r\ninput_size = 1014\r\nvocab_size = len(tk.word_index)\r\nembedding_size = 70\r\nconv_layers = [[256, 7, 3],\r\n               [256, 7, 3],\r\n               [256, 3, -1],\r\n               [256, 3, -1],\r\n               [256, 3, -1],\r\n               [256, 3, 3]]\r\n\r\nfully_connected_layers = [1024, 1024]\r\nnum_of_classes = 2\r\ndropout_p = 0.5\r\noptimizer = 'adam'\r\nloss = 'binary_crossentropy'\r\n\r\n# Embedding weights\r\nembedding_weights = []  # (71, 70)\r\nembedding_weights.append(np.zeros(vocab_size))  # (0, 70)\r\n\r\nfor char, i in tk.word_index.items():  # from index 1 to 70\r\n    onehot = np.zeros(vocab_size)\r\n    onehot[i - 1] = 1\r\n    embedding_weights.append(onehot)\r\n\r\nembedding_weights = np.array(embedding_weights)\r\nprint('Load')\r\n\r\n# Embedding layer Initialization\r\nembedding_layer = Embedding(vocab_size + 1,\r\n                            embedding_size,\r\n                            input_length=input_size,\r\n                            weights=[embedding_weights])\r\n\r\n# Model Construction\r\n# Input\r\ninputs = Input(shape=(input_size,), name='input', dtype='int64')  # shape=(?, 1014)\r\n# Embedding\r\nx = embedding_layer(inputs)\r\n# Conv\r\nfor filter_num, filter_size, pooling_size in conv_layers:\r\n    x = Conv1D(filter_num, filter_size)(x)\r\n    x = Activation('relu')(x)\r\n    if pooling_size != -1:\r\n        x = MaxPooling1D(pool_size=pooling_size)(x)  # Final shape=(None, 34, 256)\r\nx = Flatten()(x)  # (None, 8704)\r\n# Fully connected layers\r\nfor dense_size in fully_connected_layers:\r\n    x = Dense(dense_size, activation='relu')(x)  # dense_size == 1024\r\n    x = Dropout(dropout_p)(x)\r\n# Output Layer\r\npredictions = Dense(num_of_classes, activation='sigmoid')(x)\r\n# Build model\r\nmodel = Model(inputs=inputs, outputs=predictions)\r\nmodel.compile(optimizer=optimizer, loss=loss, metrics=['acc'])  # Adam, categorical_crossentropy\r\nmodel.summary()\r\n\r\n# Shuffle\r\nindices = np.arange(train_data.shape[0])\r\nnp.random.shuffle(indices)\r\n\r\nx_train = train_data[indices]\r\ny_train = train_classes[indices]\r\n\r\nx_test = test_data\r\ny_test = test_classes\r\n\r\nclass myCallback(tf.keras.callbacks.Callback):\r\n  def on_epoch_end(self, epoch, logs={}):\r\n    if(logs.get('val_acc')>0.95):\r\n      print(\"\\nReached 95% validation accuracy so cancelling training!\")\r\n      self.model.stop_training = True\r\n\r\ncallbacks = myCallback()\r\n# Training\r\nhist = model.fit(x_train, y_train,\r\n          validation_data=(x_test, y_test),\r\n          epochs=15,\r\n          verbose=1,\r\n          callbacks = [callbacks])\r\n\r\nmodel.save('main.h5') # Here I saved the model in h5 format\r\n\r\n# Here I can load the h5 model in Colab with load_model, (TF 2.0 GPU Stable version)\r\nmodel = tf.keras.models.load_model('main.h5')\r\nmodel.summary() # It showed no error\r\n\r\nprint(tf.__version__) # 2.0.0\r\n```\r\n### And then, I downloaded the saved h5 model from colab into the local system in which I installed TF 2.0 CPU Stable version with `pip install tensorflow`\r\n### Below is my app.py code I used my laptop\r\n```py\r\nfrom flask import Flask, jsonify, request, session\r\nfrom flask_cors import CORS\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport pandas as pd\r\n# from process import pdf2txt\r\n\r\nprint(tf.__version__)\r\napp = Flask(__name__)\r\napp.secret_key = \"super_secret_key\"\r\nCORS(app)\r\n\r\n# Here I can't load the downloaded h5 model in my local system (TF 2.0 CPU Stable version installed)\r\nmodel = tf.keras.models.load_model('main.h5')\r\n\r\ntk = tf.keras.preprocessing.text.Tokenizer(\r\n    num_words=None, char_level=True, oov_token='UNK')\r\nalphabet = \"abcdefghijklmnopqrstuvwxyz0123456789 ,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]{}\"\r\nchar_dict = {}\r\n\r\nfor i, char in enumerate(alphabet):\r\n    char_dict[char] = i + 1\r\n\r\ntk.word_index = char_dict.copy()\r\ntk.word_index[tk.oov_token] = max(char_dict.values()) + 1\r\n\r\n\r\ndef prepare_text(data):\r\n    Y = []\r\n    for x in data.split('\\n'):\r\n        x.split(';')\r\n        Y.append(x)\r\n\r\n    df = pd.DataFrame(Y)\r\n    val_texts = df[0].values\r\n    val_texts = [s.lower() for s in val_texts]\r\n    val_texts = tk.texts_to_sequences(val_texts)\r\n    val_data = tf.keras.preprocessing.sequence.pad_sequences(\r\n        val_texts, maxlen=1014, padding='post')\r\n    val_data = np.array(val_data, dtype='float32')\r\n\r\n    return val_data\r\n\r\n\r\n@app.route('/api/tasks', method=['GET'])\r\ndef get_result():\r\n    result = []\r\n    data_result = session['my_result']\r\n    result.append({'title': data_result['title'], 'tag': data_result['tag']})\r\n    session.clear()\r\n\r\n    return jsonify(result)\r\n\r\n\r\n@app.route('/api/task', method=['POST'])\r\ndef input_predict_text():\r\n    title = request.get_json()['title']\r\n    text = pdf2txt(title)\r\n    x = prepare_text(text)\r\n    out = model.predict(x)\r\n    print(\"The First argument in the lists is the accuracy of being Engineering CV\")\r\n    print(\"The Second argument in the lists is the accuracy of being Finance CV\")\r\n\r\n    return jsonify({'Result': out})\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    app.run(debug=True)\r\n```\r\n### Here is the error message running app.py\r\n```py\r\n2.0.0\r\nTraceback (most recent call last):\r\n  File \"python/app.py\", line 13, in <module>\r\n    model = tf.keras.models.load_model(\"main.h5\")\r\n  File \"/Users/ydc/pyjsenv/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py\", line 149, in load_model\r\n    loader_impl.parse_saved_model(filepath)\r\n  File \"/Users/ydc/pyjsenv/lib/python3.7/site-packages/tensorflow_core/python/saved_model/loader_impl.py\", line 83, in parse_saved_model\r\n    constants.SAVED_MODEL_FILENAME_PB))\r\nOSError: SavedModel file does not exist at: main.h5/{saved_model.pbtxt|saved_model.pb}\r\n```\r\n### I don't save the model in \".pb\" format and I don't have, I saved the model in \".h5\" format\r\nThanks", "@gowthamkpr that linked comment seems irrelevant as that is for a different file format. \r\n\r\nI am also encountering a similar issue, which stems from an older issues that never got resolved that revolve around how device placement seems to be locked on export. \r\n\r\n1. [tf estimators imports are limited to no longer support `contrib` module](https://github.com/tensorflow/tensorflow/issues/23824)\r\n2. [Relative device placement](https://github.com/tensorflow/tensorflow/issues/23834)\r\n3. [No clear_device_placement](https://github.com/tensorflow/tensorflow/issues/23900)\r\n\r\n```\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py in _get_session(op_input_list)\r\n    453       else:\r\n    454         _SESSION.session = session_module.Session(\r\n--> 455             config=get_default_session_config())\r\n    456     session = _SESSION.session\r\n    457   return session\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py in __init__(self, target, graph, config)\r\n   1583           protocol buffer with configuration options for the session.\r\n   1584     \"\"\"\r\n-> 1585     super(Session, self).__init__(target, graph, config=config)\r\n   1586     # NOTE(mrry): Create these on first `__enter__` to avoid a reference cycle.\r\n   1587     self._default_graph_context_manager = None\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py in __init__(self, target, graph, config)\r\n    697     try:\r\n    698       # pylint: disable=protected-access\r\n--> 699       self._session = tf_session.TF_NewSessionRef(self._graph._c_graph, opts) \r\n    700       # pylint: enable=protected-access\r\n    701     finally:\r\n\r\nInvalidArgumentError: device CUDA:0 not supported by XLA service\r\n\twhile setting up XLA_GPU_JIT device number 0\r\n\r\n```\r\n\r\nnotice line 699 where it creates a new session from the previous graph thereby having whatever devices the model was trained on being linked to the model. \r\n\r\n\r\n", "@ydcjeff Can you please provide a **minimum** reproducible code to reproduce this issue. Thanks!", "@gowthamkpr \r\nHere! [Code](https://colab.research.google.com/github/ydcjeff/cvify/blob/master/main.ipynb) to reproduce\r\nand then download the \"main.h5\" model to the local system which has python 3.7.4 and TF 2.0 CPU version installed.\r\nYou can try loading the \"main.h5\" model with `tf.keras.models.load_model()` in your local system with TF 2 CPU version.\r\nIt shows an error on mind. Error msg below\r\n```py\r\nOSError: SavedModel file does not exist at: main.h5/{saved_model.pbtxt|saved_model.pb}\r\n```\r\nThanks!", "@ydcjeff,\r\nSorry for the delayed response. The issue is in the line, `model.save('model', save_format='tf')`.\r\n\r\nAs per this [Save_Format_Doc_String](https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/engine/network.py#L952-L954), `save_format='tf'` is currently disabled.\r\n\r\nWorking code is shown below:\r\n\r\n```\r\nmodel.save('model')\r\nmodel = tf.keras.models.load_model('model')\r\n```\r\n or \r\n\r\n```\r\nmodel.save('test_model_tf.tf')\r\nmodel = tf.keras.models.load_model('test_model_tf.tf')\r\n```\r\nHere is the [Gist](https://colab.sandbox.google.com/gist/rmothukuru/e8ca88a9882994ee9ae3ff08ee108b97/main.ipynb). ", "@ydcjeff,\r\nCan you please let us know if your issue is resolved. Thanks! ", "@rmothukuru Thank you for your answer & sorry for late response!\r\nIt solved."]}, {"number": 33473, "title": "build fails when choosing clang/llvm compiler instead of nvcc compiler", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution Linux Ubuntu 18.04):\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version: r2.0\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?: conda\r\n- Bazel version (if compiling from source): 0.26.1\r\n- GCC/Compiler version (if compiling from source): clang version 6.0.0-1ubuntu2 (tags/RELEASE_600/final)\r\n- CUDA/cuDNN version: CUDA 10.0 /cuDNN 7.6.3.30\r\n- GPU model and memory: nvidia GTX 1080 8GB RAM\r\n\r\n\r\n\r\n**Problem Description**\r\nwhen building using clang/llvm compiler over nvcc, the build fails  with the error message:\r\n\r\nERROR: /usr/local/tensorflow/tensorflow/tools/pip_package/BUILD:35:1: Illegal ambiguous match on configurable attribute \"deps\" in //tensorflow/tools/pip_package:included_headers_gather:\r\n@local_config_cuda//cuda:using_nvcc\r\n@local_config_cuda//cuda:using_clang\r\nMultiple matches are not allowed unless one is unambiguously more specialized.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nstep1:  configuring with these options:\r\nDo you wish to build TensorFlow with XLA JIT support? [Y/n]: y\r\nXLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: n\r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: n\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with TensorRT support? [y/N]: y\r\nTensorRT support will be enabled for TensorFlow.\r\n\r\nFound CUDA 10.0 in:\r\n    /usr/local/cuda/lib64\r\n    /usr/local/cuda/include\r\nFound cuDNN 7 in:\r\n    /usr/lib/x86_64-linux-gnu\r\n    /usr/include\r\nFound TensorRT 6 in:\r\n    /usr/lib/x86_64-linux-gnu\r\n    /usr/include/x86_64-linux-gnu\r\n\r\nPlease specify a list of comma-separated CUDA compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 6.1]: \r\n\r\nDo you want to use clang as CUDA compiler? [y/N]: y\r\nClang will be used as CUDA compiler.\r\n\r\nDo you wish to download a fresh release of clang? (Experimental) [y/N]: n\r\nClang will not be downloaded.\r\n\r\nPlease specify which clang should be used as device and host compiler. [Default is /usr/bin/clang]: \r\n\r\nDo you wish to build TensorFlow with MPI support? [y/N]: y\r\nMPI support will be enabled for TensorFlow.\r\n\r\nPlease specify the MPI toolkit folder. [Default is /usr/local/pgi/linux86-64/19.4/mpi/openmpi-3.1.3]: \r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native -Wno-sign-compare]: \r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n\r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n\t--config=mkl         \t# Build with MKL support.\r\n\t--config=monolithic  \t# Config for mostly static monolithic build.\r\n\t--config=gdr         \t# Build with GDR support.\r\n\t--config=verbs       \t# Build with libverbs support.\r\n\t--config=ngraph      \t# Build with Intel nGraph support.\r\n\t--config=numa        \t# Build with NUMA support.\r\n\t--config=dynamic_kernels\t# (Experimental) Build kernels into separate shared objects.\r\n\t--config=v2          \t# Build TensorFlow 2.x instead of 1.x.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n\t--config=noaws       \t# Disable AWS S3 filesystem support.\r\n\t--config=nogcp       \t# Disable GCP support.\r\n\t--config=nohdfs      \t# Disable HDFS support.\r\n\t--config=noignite    \t# Disable Apache Ignite support.\r\n\t--config=nokafka     \t# Disable Apache Kafka support.\r\n\t--config=nonccl      \t# Disable NVIDIA NCCL support.\r\nConfiguration finished\r\n\r\nstep 2: build with this command:\r\n\r\nbazel build  --config=cuda --linkopt='-lrt'  --verbose_failures -c opt  //tensorflow/tools/pip_package:build_pip_packag\r\n\r\n\r\n\r\n\r\n**Any other info / logs**\r\nnone", "comments": ["@Ghassan, Just to verify, did you follow the instructions mentioned in [this link](https://www.tensorflow.org/install/source). Thanks!", "@Ghassan, Is this still an issue! ", "Please follow the instructions mentioned in this [link](https://www.tensorflow.org/install/source).\r\nClosing the issue due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33473\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33473\">No</a>\n"]}, {"number": 33472, "title": "Allowing to provide pre-built flatbuffers when building tflite C++", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android/Ubuntu\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version: 1.15.0\r\n- Python version: 3.6.8\r\n- Installed using virtualenv? pip? conda?: ip\r\n- Bazel version (if compiling from source): 0.24.1\r\n- GCC/Compiler version (if compiling from source): NDK r17b clang\r\n- CUDA/cuDNN version: -\r\n- GPU model and memory: -\r\n\r\n\r\n**Describe the problem**\r\nCurrently tensorflow build always pulls flatbuffers on its own, resulting in duplication of flatbuffers, if user already has dependency on flatbuffers.\r\nDue to how tensorflow headers work, it leaks dependency to generated schema (and therefore flatbuffers.h) \r\nBut as we used flatbuffers 1.10.0 in our project, we had no compilation errors due to missing header.\r\nSince tf 1.15 schema uses some specific feature of flatbuffers 1.11.0 which results in failed build when including model.h for example\r\n\r\nIdeally it would be great if flatbuffers schema wouldn't be leaked, but I doubt it is feasible.\r\nSo my plan is currently upgrading our own flatbuffers to 1.11.0.\r\n\r\nBut this brings me to a question, if we could somehow tell bazel to use our own flatbuffers instead of pulling its own?\r\n\r\nP.s. I tried to find some options in configuration script, but there seem to be none. So I assume most common use case is always build own copy of flatbuffers as part of build process.\r\n\r\n**Any other info / logs**\r\n\r\nHaving proper instructions to how build and install self-contained C++ tflite would be nice too :)\r\n", "comments": ["Hi @DoumanAsh, out of curiosity, would it help if we had a pure C API (perhaps with lightweight C++ wrappers) which did not have any kind of flatbuffer dependency in its public API?\r\n\r\nAnd for the C/C++ library, are you fine if it's built as a separate shared library? Or are you buliding it as a direct bazel dependency in your project?", "Hey @jdduke actually if flatbuffers wouldn't be leaked, it would be perfect for us.\r\nThe main problem right now is that not only it is leaked in headers, but GPU delegate library has these symbols public, which originally caused some asan issues.\r\nI only noticed flatbuffers in public API because it was using our own headers which wasn't comptabile with 1.15 :(\r\nBut I'm also would be fine with flatbuffers headers leaked, as long as we can provide our own version via some config\r\n\r\nIdeally we'd like static library, but shared library works just fine for us, we do not use bazel and package our dependencies using conan", "@jdduke On side note, as 1.15 is latest release, I assume any changes related to that would be reflected only in 2.x right?", "Hey @DoumanAsh , apologies for the severely delayed response.\r\n\r\nWe have migrated our [C API](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/c) out of experimental, and it does not pull in the flatbuffer headers. At the same time, I'm trying to pull out the flatbuffer header dependency from the C++ API, but that's a bit more involved.\r\n\r\nI should also note that we started exporting the C API symbols from the native libraries, and including the C headers, in our [prebuilt Android libraries](https://bintray.com/google/tensorflow/tensorflow-lite#files/org%2Ftensorflow%2Ftensorflow-lite%2F0.0.0-nightly) in case you'd prefer to use prebuilts. ", "@jdduke Glad to hear this, do you have any idea which 2.x version would get stable C API?\r\n\r\nAs for pre-built libraries, for our purpose we only need C/C++ API so we avoid any JNI enabled binaries (as we use tensorflow lite outside of Android too)", "The next release (2.2) will have the stable C API embedded in the prebuilt Android libraries.\r\n\r\nWe're also exploring hosting prebuilt libraries for non-Android platforms, but it likely won't be until Q2 that we can make that happen. ", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33472\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33472\">No</a>\n"]}, {"number": 33471, "title": "TF 2.0 Keras add_loss() function seems to make trainable weight not in model but added in add_loss() also being updated during training", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nUbuntu 18.04.2 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\npip\r\n- TensorFlow version (use command below):\r\nv2.0.0-rc2-26-g64c3d38 2.0.0\r\nv1.14.0-rc1-22-gaf24dc9 1.14.0\r\n- Python version: \r\n3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\n\r\nIn TF 2.0, if output of another model with trainable weight is included in add_loss() function, all weight from that model will be updated during training.\r\n\r\nI also couldn't find any documentation regarding this change. So I assume it is unintended.\r\n\r\n**Describe the expected behavior**\r\n\r\nIt should be like in TF 1.14. The gradient of additional model in add_loss() should be back propagated because the model to be trained may be used as input for additional model. But additional model should not be updated.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport numpy as np\r\nimport pandas as pd\r\nimport tensorflow as tf\r\nimport tensorflow_probability as tfp\r\nimport sys\r\nimport time\r\n\r\nfrom tensorflow.keras.layers import Dense, Input, Add, Lambda\r\nfrom tensorflow.keras import Model\r\nfrom tensorflow.keras.models import load_model, clone_model\r\nfrom tensorflow.keras import optimizers\r\n\r\nfrom scipy.io import loadmat\r\nfrom scipy.spatial.distance import cdist\r\ntf.compat.v1.disable_eager_execution()\r\n\r\nx = np.random.rand(100).reshape(100, 1).astype(float)\r\ny = np.array(x>0.5).reshape(100, 1).astype(float)\r\n\r\ninput1 = Input(shape=(1, ), name='input1')\r\nd1 = Dense(12, name='d11')(input1)\r\nd1 = Dense(12, name='d12')(d1)\r\nd1 = Dense(1, name='output1')(d1)\r\n\r\ninput2 = Input(shape=(1, ), name='input2')\r\nd2 = Dense(12, name = 'd21')(input2)\r\nd2 = Dense(12, name = 'd22')(d2)\r\nd2 = Dense(1, name = 'output2')(d2)\r\n\r\nlabel = Input(shape = (1, ), name = 'label')\r\n\r\nmodel1 = Model(inputs = [input1, label], outputs = d1)\r\nmodel2 = Model(inputs = input2, outputs = d2)\r\nmodel2_cl = clone_model(model2)\r\nmodel1_cl = clone_model(model1)\r\n\r\npre_result1 = model1.predict({'input1': x, 'label': y})\r\npre_result1_cl = model1_cl.predict({'input1': x, 'label': y})\r\npre_result2 = model2.predict(x)\r\n\r\ndef cust_loss(xi, yi, yp):\r\n    loss = tf.reduce_mean((yi - yp)**2) + tf.reduce_mean((model2(xi) - yi)**2)\r\n    \r\n    return loss\r\n\r\nmodel1.add_loss(cust_loss(input1, label, d1))\r\n#optimizer = optimizers.Adam(lr = 3e-4)\r\noptimizer = tf.compat.v1.train.AdamOptimizer(3e-4)\r\nmodel1.compile(optimizer, loss = None)\r\n\r\nmodel1.fit({'input1': x, 'label': y}, None, epochs=100)\r\npost_result1 = model1.predict({'input1': x, 'label': y})\r\npost_result1_cl = model1_cl.predict({'input1': x, 'label': y})\r\npost_result2 = model2.predict(x)\r\n\r\nprint(sum(pre_result2 != post_result2))\r\n```\r\n\r\n**Other info / logs**\r\nIf you run the code above in TF 1.14, it will show 0 because model2 remains and should remain the same after training of model1.\r\n\r\nBut if you run it in TF 2.0, it will show 100 as model2 is updated as well for some reason during model1 training.\r\n", "comments": ["Yes in TF 1.14 it shows 0 but in TF 1.15rc3 and TF 2.0 its showing 100. I think this is clearly a bug\r\n\r\nHere are my github gists [Tf 1.14](https://colab.sandbox.google.com/gist/gowthamkpr/1fd2d4e745b093af63325bfbd7dbefb7/untitled198.ipynb), [TF 1.15rc3](https://colab.sandbox.google.com/gist/gowthamkpr/edf243d59c16cbe5709754d8d346636e/untitled199.ipynb) and [TF2.0](https://colab.sandbox.google.com/gist/gowthamkpr/0fefab16eefe321e944f7fe528376765/untitled197.ipynb)", "As a followup, it seems add_loss() function incorrectly add any trainable variables in the model linked within custom loss function into the main model being trained. You should be able to see the difference by printing out model1's trainable variable in TF 1.14 and TF 1.15.", "https://github.com/matterport/Mask_RCNN/issues/1889#issuecomment-566217231\r\n\r\nAs mentioned in the post above. The issue can be resolved by converting passed function into a lambda function without input parameters.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33471\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33471\">No</a>\n", "the title of this issue gave me a headache"]}]