[{"number": 51519, "title": "Question about custom convolution layer", "body": "Hi,\r\n\r\n**Question**\r\nIs it possible to make a custom convolution layer by scratch?\r\nCan you tell me how to do it?\r\n\r\n**What I'm thinking**\r\nI am thinking to create a custom convolution layer that works like tf.keras.layers.Conv2D.\r\nI still don't have codes but it will work like FIR filter.\r\nBasic FIR filter could be implemented by Conv2D or Conv1D but the layer I want can't be, because it'll has some process that Conv2D and Conv1D don't have.\r\n \r\nIf I try to implement by tf.keras.layers.Layer, I need to have some for-loops or while-loops. \r\nAnd the loops will make the computation slow and consume a lot of GPU memory.\r\n\r\n\r\n", "comments": ["@ntyoshi ,\r\n\r\nCan you please take a look at this links for information on custome convolution layer.[Link1](https://towardsdatascience.com/custom-neural-networks-in-keras-a-street-fighters-guide-to-build-a-graphcnn-e91f6b05f12e),[Link2](https://medium.com/analytics-vidhya/creating-a-custom-convolutional-neural-network-in-tensor-flow-a9b29ae9fcf9),[Link3](https://keras.io/api/layers/convolution_layers/).It helps.Thanks", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 51518, "title": "Update year in LICENSE", "body": null, "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F51518) for more info**.\n\n<!-- need_sender_cla -->", "@ohld  Can you please sign CLA. Thanks!", "Just signed!"]}, {"number": 51517, "title": "Time Series Documentation Doesn't Display on Chrome", "body": "\r\n\r\n\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/tutorials/structured_data/time_series#the_weather_dataset\r\n\r\n## Description of issue (what needs changing):\r\n\r\nIn Chrome, the weather dataset table only shows a portion of the table.\r\n\r\n\r\n\r\nALSO, I have been struggling to learn from this documentation. It would be MUCH easier to learn if there were at least one complete script (preferably one per section) in a single code block. For example. It would be much easier to understand if I could see a code block that had everything needed to train and test a Single-Step and Multi-Step model\r\n\r\nAlso Also, it would help if all the variable's names were consistent with the diagrams and their purpose was described in text i.e.\r\n [https://www.tensorflow.org/tutorials/structured_data/time_series#multi-step_dense](CONV_WIDTH) is not described and it's purpose can only be guessed at from the diagram.\r\n\r\n### Request visuals, if applicable\r\n<img width=\"951\" alt=\"ZR61xt1sYW\" src=\"https://user-images.githubusercontent.com/52757442/129586646-f7ae0920-2dfd-4f91-8ab8-26db833d1371.png\">\r\n", "comments": ["I see all 5 rows of the dataset as shown in the left image above. I am using chrome Version 92.0.4515.131 (Official Build) (x86_64)\r\nPerhaps you may want to check for browser updates. Also which browser are you using to display the left image above?", "@spencerconnor,\r\n\r\nAs mentioned by @ymodak , even I am able to see all the 5 rows as usual and I am using chrome `Version 92.0.4515.130 (Official Build) (64-bit)`. Attached the image below for your reference. \r\n\r\nYou can take a look at this [ipynb](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/structured_data/time_series.ipynb) which consolidates all the code blocks in one notebook as you requested. Let me know if it helps. Thanks!\r\n\r\n![image](https://user-images.githubusercontent.com/87846724/129667753-1ac8d554-5dbc-4825-b46e-98f8bee129ec.png)\r\n", "So the previous image was Firefox and Chrome respectively. This one is Chrome (Incognito) and Chrome (normal). Extensions are disabled. \r\n<img width=\"960\" alt=\"chrome_4KNNRJ8Lb7\" src=\"https://user-images.githubusercontent.com/52757442/129725410-27f14a04-fb79-4b4c-b7ad-b7c8ab978828.png\">\r\n\r\n\r\n It worked for a moment in a normal Chrome window, but now it's back to the partial view.\r\n\r\n<img width=\"960\" alt=\"kGBqPApc5x\" src=\"https://user-images.githubusercontent.com/52757442/129725064-7e34b999-1524-4207-9f27-66b398857694.png\">\r\n\r\n I noticed that when loading in the incognito window, the table briefly appears in a partial view before expanding immediately to the full size.\r\n\r\nAfter some testing (changing DNS, removing/refreshing cookies, reloading page and window) it looks like it is an issue with the cookies. It seems like it happens when Google Analytics is opted out of or blocked. ", "This is one of two cookies that are different between working and non-working. (Incognito - Normal)\r\n\r\n<img width=\"960\" alt=\"3c8b46SwsX\" src=\"https://user-images.githubusercontent.com/52757442/129729912-ec3b4f42-8316-493e-9e12-9a1b93cb91e7.png\">\r\n", "@spencerconnor,\r\n\r\nThanks for the information that its not an issue from TF end and mostly related to cookies. Also I've added link for ipynb in my previous comment, which consolidated all codes into one as you requested. Please confirm if we are good to close this issue. Thanks!", "Thanks for the help :)"]}, {"number": 51515, "title": "Tensorflow 2.4: where is tf.contrib.layers.fully_connected?", "body": "How can I replace tf.contrib.layers.fully_connected of tensorflow 1.x with a similar function in 2.4?\r\n\r\nGot the following error:\r\n    import tensorflow.contrib.layers as layers\r\nModuleNotFoundError: No module named 'tensorflow.contrib'", "comments": ["@zhr-ar ,\r\n\r\nPlease refer the issues #36878, #35197, #30794, #37720 with similar error log.It helps.\r\n\r\nThanks", "There is no contrib in TF 2.x.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51515\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51515\">No</a>\n"]}, {"number": 51514, "title": "Links lead to 404 on food101 dataset page ", "body": "## Whats Wrong?\r\nThe link of Homepage of Food101 on the Food101 page of the catalog section of tensorflow datasets doesnt work.\r\nLink of the page: https://www.tensorflow.org/datasets/catalog/food101\r\n\r\n\r\n### Description\r\n\r\nThe link given for the Homepage of the Food-101 doesn't work\r\n![image](https://user-images.githubusercontent.com/43718923/129578159-57c489d4-b98b-47bc-930c-c993ee2a9999.png)\r\n\r\nIt leads to a 404 Page not found\r\n![image](https://user-images.githubusercontent.com/43718923/129578246-4b2680d0-d519-4885-8135-edc51133f202.png)\r\n\r\n\r\n\r\n### Correct links\r\n\r\nLink to the correct paper: https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/\r\n\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n", "comments": ["@shashwat9kumar \r\n\r\nThanks for pointing it out and the correct link for food 101 dataset is https://data.vision.ee.ethz.ch/cvl/datasets_extra/food-101/\r\n\r\nI can see that you have already submitted a PR for the same. Thanks! ", "This is fixed with https://github.com/tensorflow/datasets/commit/5d1d3c9ec95f8bf6c7d1a73befbd3e8b4458363d#diff-e36263420b0922ac75692057d52dd1a3bcfe57bafaeed330caffba97c16bdadc Thanks!"]}, {"number": 51513, "title": "Fix endianness issue of internal data views in LiteralUtilTest (F16) on BE machines", "body": "`LiteralUtilTest.F16` in test case `//tensorflow/compiler/xla:literal_test` fails on Big-Endian systems because the internal data views are in Little-Endian format. This PR swaps the data on BE machines to make the data format machine endianness dependent, so that this test case would pass on both LE and BE systems.", "comments": ["@kun-lu20  Can you please address Ubuntu Sanity errors? Thanks!", "Hi @gbaned , I've reformatted `tensorflow/compiler/xla/BUILD` to address `Ubuntu Sanity` issue. Thanks!", "Hi @sanjoy , could you please take a look again? Thank you very much!", "Hi @majnemer , thanks again for your advice! Could you please approve this PR?", "Thanks @majnemer "]}, {"number": 51512, "title": "I want to know Is it supported that the C_API can use the Core ML delegate? ", "body": "\r\n**System information**\r\n- MacOS11.2 Compile the C_API for IOS 12\r\n\r\n\r\n**Describe the problem**\r\nI want to know Is it supported that the C_API can use the Core ML delegate? \r\nWhat I can learn about the Doc is CoreML only compiled as Framework not a static library. Now I have a project used the tf-lite with C API, And.I want to know whether it can use the CoreML delegate with C API . So that I don't need change the export way (just give a dynamic library out) to the caller . \r\n\r\n", "comments": ["Hi @xunbing. Yes, this is supported. Please see the example code at https://www.tensorflow.org/lite/performance/coreml_delegate#c-until-2.3.0.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51512\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51512\">No</a>\n", "> Hi @xunbing. Yes, this is supported. Please see the example code at https://www.tensorflow.org/lite/performance/coreml_delegate#c-until-2.3.0.\r\n\r\n Thank you for your reply\uff01I 've seen this example code. But I cannot find the Interface about CoreMLDelegate in c_api.cc. So I guess is CoreML Delegate cc_libarry not supported for now?  If I want to use the Core ML Delegate  like this code example , Do I have to link the framework build separately with bazel instead of a c static library ? Becuase In my case, I really need a C static library linked to my present final library. Looking forward to your reply\uff01", "So, you mean the compiled CoreML delegate implementation is not included in your TFLite C static library, correct?\r\n\r\nCan you tell me more details about how you are building the TFLite C static library for your project?\r\nI might be able to help with adding the CoreML delegate code into the static library.", "> So, you mean the compiled CoreML delegate implementation is not included in your TFLite C static library, correct?\r\n> \r\n> Can you tell me more details about how you are building the TFLite C static library for your project?\r\n> I might be able to help with adding the CoreML delegate code into the static library.\r\n\r\nFirst I use 'bazel build -c opt --config=ios_fat //tensorflow/lite/ios:TensorFlowLiteC_static_framework' command to get the TensorFlowLiteC, which is Mach-O consist of 4 architectures.\r\n\r\nSecond I use 'lipo TensorFlowLiteC -thin arm64 -output arm64.a' to get the arm64 arch: current at archive.\r\n\r\nAnd then use 'ar -x arm64.a' to get all the .o files.\r\n\r\nAt last use 'ld -r *.o -o libTensorflowLiteC.a' .\r\n\r\nNow I have a project named A.dylib which linked to a APP.  I linked the  libTensorflowLiteC.a to the A.dylib. So in this App I can do some inference work with tf-lite now.  Further I want to use the Core ML to accelerate the inference. But I 've not found a way to compile a static library to link to my current project.\r\n\r\nCan you tell me what should i do\uff1fIt will be a great help for me.", "I see. You'll need to modify the `tensorflow/lite/ios/BUILD` file on your side to make it work.\r\nIn the `TensorFlowLiteC_static_framework` rule in this file, add the followings:\r\n1) Add `\":coreml_delegate.h\"` under `hdrs`.\r\n2) Add `\"//tensorflow/lite/delegates/coreml:coreml_delegate\"` under `deps`.\r\n\r\nThe resulting rule would look like:\r\n\r\n```\r\n# Similar to TensorFlowLiteC_framework but this is a static framework and symbol\r\n# hiding is not applied. Note both have the same bundle name.\r\nios_static_framework(\r\n    name = \"TensorFlowLiteC_static_framework\",\r\n    hdrs = [\r\n        \":builtin_ops.h\",\r\n        \":c_api.h\",\r\n        \":c_api_experimental.h\",\r\n        \":common.h\",\r\n        \":coreml_delegate.h\",\r\n        \":xnnpack_delegate.h\",\r\n        \"//tensorflow/lite/c:c_api_types.h\",\r\n    ],\r\n    bundle_name = \"TensorFlowLiteC\",\r\n    minimum_os_version = TFL_MINIMUM_OS_VERSION,\r\n    deps = [\r\n        \":tensorflow_lite_c\",\r\n        \"//tensorflow/lite/delegates/coreml:coreml_delegate\",\r\n    ],\r\n)\r\n```\r\n\r\nAfter this, run your bazel build again and extract the `.a` file for arm64 platform as you did before.\r\nLet me know if this works for you.", "Thanks!  I modified the ios/BUILD like you said. There is a ERROR: 'missing input file '//tensorflow/lite/delegates/coreml:coreml_delegate.mm'.\r\n\r\nComplete error message is:\r\n\r\n> xunbinggao@DARYLGAO-MB0 tensorflow-master % bazel build --config=ios_fat //tensorflow/lite/ios:TensorFlowLiteC_static_framework --verbose_failures\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=111\r\nINFO: Reading rc options for 'build' from /Users/xunbinggao/darylgao/2.task/tensorflow-master/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /Users/xunbinggao/darylgao/2.task/tensorflow-master/.bazelrc:\r\n  'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true\r\nINFO: Reading rc options for 'build' from /Users/xunbinggao/darylgao/2.task/tensorflow-master/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/usr/local/opt/python@3.9/bin/python3.9 --action_env PYTHON_LIB_PATH=/usr/local/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages --python_path=/usr/local/opt/python@3.9/bin/python3.9\r\nINFO: Found applicable config definition build:short_logs in file /Users/xunbinggao/darylgao/2.task/tensorflow-master/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /Users/xunbinggao/darylgao/2.task/tensorflow-master/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:ios_fat in file /Users/xunbinggao/darylgao/2.task/tensorflow-master/.bazelrc: --config=ios --ios_multi_cpus=armv7,arm64,i386,x86_64\r\nINFO: Found applicable config definition build:ios in file /Users/xunbinggao/darylgao/2.task/tensorflow-master/.bazelrc: --apple_platform_type=ios --apple_bitcode=embedded --copt=-fembed-bitcode --copt=-Wno-c++11-narrowing --noenable_platform_specific_config --copt=-w --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --define=with_xla_support=false\r\nINFO: Build options --cpu and --ios_multi_cpus have changed, discarding analysis cache.\r\nINFO: Analyzed target //tensorflow/lite/ios:TensorFlowLiteC_static_framework (0 packages loaded, 9952 targets configured).\r\nINFO: Found 1 target...\r\nERROR: /Users/xunbinggao/darylgao/2.task/tensorflow-master/tensorflow/lite/delegates/coreml/BUILD:105:13: //tensorflow/lite/delegates/coreml:coreml_delegate_kernel: missing input file '//tensorflow/lite/delegates/coreml:coreml_delegate_kernel.mm'\r\nTarget //tensorflow/lite/ios:TensorFlowLiteC_static_framework failed to build\r\nERROR: /Users/xunbinggao/darylgao/2.task/tensorflow-master/tensorflow/lite/delegates/coreml/BUILD:105:13 1 input file(s) do not exist\r\nINFO: Elapsed time: 1.600s, Critical Path: 0.00s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully\r\n\r\nI noticed there is no cc_library called in the ios/delegates/coreml/BUILD.  Is the reason about this ERROR?\r\nLooking forward your reply. I feel I found some hope!", "Sorry, I had some mistakes in my earlier reply. The dependency should be `\"//tensorflow/lite/delegates/coreml:coreml_delegate\",` with out the `third_party/` portion.\r\n\r\nLooking at your error logs, I guess you've figured this out already though.\r\n\r\nCan you navigate to the `tensorflow/lite/delegates/coreml` directory and see if `coreml_delegate_kernel.mm` file actually exists? I'll try the same build on my side and see if it works.", "FYI, the build was successful on my side, so it ideally should work for you assuming your configuration is correct.", "Yeah. That \"third_party\" caused some confuse indeed. Just like you say, I figured this out.\r\nAfter I checked my directory, I noticed I make a ridiculous mistake. I modify the .mm to .cc because of Ignorance of the relationship between C and OC.\r\n\r\nIt's worked!\r\n\r\nThank you very much! @yyoon  And through this experience, I feel the charm of the community. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51512\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51512\">No</a>\n", "Great to hear that it worked for you!", "Emm... May I ask something more? I'm still a little confused.\r\nNow I've prepared the static library like we talked above.\r\nWhen I compile the whole project, there is some ERROR message like this:\r\n\r\n>[100%] Linking CXX shared library libA.dylib\r\nUndefined symbols for architecture arm64:\r\n  \"_OBJC_CLASS_$_MLFeatureValue\", referenced from:\r\n      objc-class-ref in libTensorFLowLiteC_CoreML.a\r\n  \"_OBJC_CLASS_$_MLModel\", referenced from:\r\n      objc-class-ref in libTensorFLowLiteC_CoreML.a\r\n  \"_OBJC_CLASS_$_MLModelConfiguration\", referenced from:\r\n      objc-class-ref in libTensorFLowLiteC_CoreML.a\r\n  \"_OBJC_CLASS_$_MLMultiArray\", referenced from:\r\n      objc-class-ref in libTensorFLowLiteC_CoreML.a\r\n  \"_OBJC_CLASS_$_MLPredictionOptions\", referenced from:\r\n      objc-class-ref in libTensorFLowLiteC_CoreML.a\r\nld: symbol(s) not found for architecture arm64\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\n\r\nSo I have to doubt whether Using CoreML delegate with C static library is correct. Is the only way that Linking the whole framework in xcode prj ?", "I use 'nm TensorFlowLite | grep MLModelConfiguration', found the front flag is 'U' .\r\nlike this:\r\n> U _OBJC_CLASS_$_MLFeatureValue\r\nU _OBJC_CLASS_$_MLModel\r\nU _OBJC_CLASS_$_MLModelConfiguration\r\nU _OBJC_CLASS_$_MLMultiArray\r\nU _OBJC_CLASS_$_MLPredictionOptions\r\nU _OBJC_CLASS_$_NSArray\r\nU _OBJC_CLASS_$_NSFileManager\r\nU _OBJC_CLASS_$_NSMutableArray\r\nU _OBJC_CLASS_$_NSNumber\r\nU _OBJC_CLASS_$_NSObject\r\nU _OBJC_CLASS_$_NSProcessInfo\r\nU _OBJC_CLASS_$_NSSet\r\nU _OBJC_CLASS_$_NSString\r\nU _OBJC_CLASS_$_NSURL\r\nU _OBJC_METACLASS_$_NSObject\r\n\r\nTo find out the relationship between the two Framework and my compiled static library, I check the CoreMLFramework with bazel with same way. The result is also 'U' undefined.\r\n\r\nAnd finally , I found these symbols belongs to iPhoneOS.sdk's CoreML.framework Headers. \r\n\r\nI'm not sure what should i do to solve these ERRORs.", "Hi @xunbing,\r\n\r\nSounds like you are missing the CoreML.framework in your project setting. In Xcode, try navigating to the project settings -> General -> Frameworks, Libraries, and Embedded Content -> Add `Coreml.framework` under iOS.\r\n\r\n![image](https://user-images.githubusercontent.com/1309817/129812998-b5017455-6b00-417e-864e-9ef9c02a74b7.png)\r\n", "@yyoon thx for your reply!\r\nThis is also what puzzles me. I learned Adding Coreml.framework is necessary by reading the examples code. \r\nBut maybe my situation is special. I want to compile all of symbols to a final C static library and **call the interface in this library.** So I can just use the tf-lite(TfLiteCoreMlDelegateCreate) c_api  in the final static library without adding the Coreml.framework in Xcode prj.\r\n\r\nAfter all, my role is the backend developer. The simpler my product, things will be better.\r\n\r\nCan CoreML Delegate be used like this? Or its interface must be used in a  xcode.prj?", "> **call the interface in this library.**\r\n\r\nCall the interface from what? I assume your static library will be called from an iOS app anyways, and you would have to use an Xcode project for it.\r\n\r\nCoreml.framework is part of the iOS, and I don't think it's possible to statically link it to your own library.", "For example, now I encapsulate the interface in lite/c/c_api.h to my custom interface. So somewhere in my final static library, customer interface will be called to do some inference work. Just output custom result like labels to iOS fore-end.", "I am beginning to understand. What I pursue is that there is only one curtom interface to iOS fore-end to do some ml interface work. Like give me a picture, I give the labels out. So pure C library compiled with tensorflow/lite/c/ can cover this case. But if I  want use the CoreML delegate further, the solution just now is not work anymore. Maybe I should split the custom interface to several parts. Let iOS fore-end call the tf-lite inference interface. I do some preprocess and postprecess work.\r\n\r\nAm I right?", "You can still have a single interface to include coreml delegate feature as well.\r\n\r\nIt's just that users of your static library (app developers) still need to manually add the coreml.framework as a dependency in their Xcode projects for their apps. This part is inevitable, and even if you split your C API, users still need to add the Coreml.framework dependency in their app.", "I get it. The Coreml.framework is a part of iOS. I can not compile it into my final C static library. For Objective-C code, it's supported using the C API. My mistake is that **I want to use the C API about coreml delegate feature in a library compiled with pure C code.** So it appeared errors above:\r\n> U OBJC_CLASS$_MLFeatureValue\r\n\r\nNow I figure it out.\r\n\r\n1. For the pure C code product , by using 'ar -x' to extact all the obj files, there will have not weak symbols like OBJC_CLASS about Objective-C. It can used in C code to do some inference work without CoreML delegate feature. Even not in iOS, it can be cross platform easily.\r\n2. For the xcode prj, If I want use the CoreML delegate in my app. I cant use the C API or Objective-C API by linking the CoreML.framework  in Objective-C code. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51512\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51512\">No</a>\n"]}, {"number": 51511, "title": "stream_executor/platform/logging.h: catch up with core/platform/logging.h", "body": "In [core/platform/logging.h](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/logging.h), TensorFlow used `google/logging.h` while `PLATFORM_GOOGLE*`, `GOOGLE_LOGGING` or `__EMSCRIPTEN__` is defined, but its `stream_executor` only considered two cases (`PLATFORM_GOOGLE` and `PLATFORM_GOOGLE_ANDROID`).\r\nThis PR is aimed to make their behavior same.", "comments": ["@gbaned Hello, when will this PR be reviewed?"]}, {"number": 51510, "title": "How to get a coarse-grained op-level graph in tensorflow", "body": "Hi, tensorflow community,\r\nI want to use tensorflow to get the full computation graph (including forward, backward and parameter update). I tried tf.functions, but the graph I got is too fine-grained, as many ops (Adam for example) are splited into smaller operators (add, mul, div etc.). So is there any methods that I can get a coarse-grained op-level graph? Thanks a lot!\r\n\r\nJiangfei", "comments": ["@JF-D ,\r\nKindly open a tf discussion [forum](https://discuss.tensorflow.org/) issue for this as it is not a bug or feature request, Please post this kind of support questions at Stackoverflow. There is a big community to support and learn from your questions.Thanks!\r\n\r\n\r\n", "Ok. Thanks!"]}, {"number": 51509, "title": "Can't create multiple instances of tf.keras.Model subclasses", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No.\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04.\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No.\r\n- TensorFlow installed from (source or binary): pip install.\r\n- TensorFlow version (use command below): v2.6.0-rc2-32-g919f693420e 2.6.0.\r\n- Python version: 3.9.6.\r\n- Bazel version (if compiling from source): NA.\r\n- GCC/Compiler version (if compiling from source): NA.\r\n- CUDA/cuDNN version: NA.\r\n- GPU model and memory: GTX 2080 Ti.\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nHere is an example of triggering the issue:\r\n```python\r\nimport tensorflow as tf\r\n\r\nclass MyModel(tf.keras.Model):\r\n\r\n  def __init__(self, input_shape):\r\n    super(MyModel, self).__init__()\r\n    self.my_model_input_shape = input_shape\r\n    self.dense1 = tf.keras.layers.Dense(5, activation=tf.nn.relu)\r\n    self.dense2 = tf.keras.layers.Dense(5, activation=tf.nn.softmax)\r\n    input_layer = tf.keras.layers.Input(self.my_model_input_shape)\r\n    output_layer = self.call(input_layer)\r\n    super(MyModel, self).__init__(\r\n      inputs=input_layer,\r\n      outputs=output_layer\r\n    )\r\n\r\n  def call(self, inputs, training=None):\r\n    x = self.dense1(inputs)\r\n    return self.dense2(x) + x\r\n\r\n\r\nmodel_1 = MyModel((10,))\r\nmodel_1.summary()\r\n\r\nmodel_2 = MyModel((20,))\r\nmodel_2.summary()\r\n```\r\nIt fails at the creation of `model_2` with\r\n```\r\nFile \".../lib/python3.9/site-packages/tensorflow/python/training/tracking/base.py\", line 530, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\nTypeError: __init__() missing 2 required positional arguments: 'inputs' and 'outputs'\r\n```\r\n\r\nWithout the the second 2-param `super().__init__` call at the end of `MyModel.__init__`, it is OK to run, but the summary and `model_1.layers` outputs are different: the one with the second `__init__` call contains more and better information, such as the input and last addition layers and a `Connected to` columns:\r\n```\r\nModel: \"my_model_1\"\r\n__________________________________________________________________________________________________\r\nLayer (type)                    Output Shape         Param #     Connected to                     \r\n==================================================================================================\r\ninput_1 (InputLayer)            [(None, 10)]         0                                            \r\n__________________________________________________________________________________________________\r\ndense (Dense)                   (None, 5)            55          input_1[0][0]                    \r\n__________________________________________________________________________________________________\r\ndense_1 (Dense)                 (None, 5)            30          dense[0][0]                      \r\n__________________________________________________________________________________________________\r\ntf.__operators__.add (TFOpLambd (None, 5)            0           dense_1[0][0]                    \r\n                                                                 dense[0][0]                      \r\n==================================================================================================\r\nTotal params: 85\r\nTrainable params: 85\r\nNon-trainable params: 0\r\n```\r\nI would much prefer the one with better information. I learned this from various examples such as https://github.com/matterport/Mask_RCNN/issues/921#issuecomment-432846634.\r\n\r\n**Describe the expected behavior**\r\nCreating multiple instances of subclasses should have no issue and the variables and models should be independent from each other.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): no.\r\n- Briefly describe your candidate solution(if contributing): NA.\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\nSee above.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@fm966mhz,\r\n\r\nThis looks like an issue with Keras, can you kindly post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues),To know more see;[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)", "@sanatmpa1 \r\n\r\nThanks. I asked this question at keras-team/keras too. Please feel free to close this one for now. ", "Thanks for the confirmation @fm966mhz ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51509\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51509\">No</a>\n"]}, {"number": 51507, "title": "[WIP] Fixing Minor Issues", "body": null, "comments": ["@EverLookNeverSee  Can you please address PyLint errors? Thanks!\r\n", "> @EverLookNeverSee Can you please address PyLint errors? Thanks!\r\n\r\nIt is written in tensorflow code style that the indentation size should be multiply four, but pylint says the indentation should be 6 instead of 12 in some lines.", "I am going to ignore fixing the line indentations.", "I decided to close this PR and create a new one without manipulating the line indentations."]}, {"number": 51506, "title": "Apple M1 - How to build 2.6 or Master (Fixed)", "body": "The genius command \"pip install tensorflow\" does not even work in Debian 11, so we have to compile from source. The instructions on the TF homepage do not work for the M1.\r\n\r\nHas anyone compiled TF 2.6+ on the M1 and can share a guideline please ?", "comments": ["This issue better raised on https://github.com/apple/tensorflow_macos/issues\r\nPlease refer a previous [thread ](https://github.com/tensorflow/tensorflow/issues/45631#issuecomment-751412972) which discusses similar issue. Thanks!\r\n", "Current Progress on MacOS 12 Beta 5 &  default Python 3.9.6\r\n\r\n\r\nInstall from Developer site:\r\nXcode Command Line Tools 13.x\r\nXcode Gui 13.x   # reboot\r\n\r\nconda deactivate   #exit Conda environment\r\n\r\npip3 install --upgrade pip\r\n\r\nbrew install bazel\r\nnano .bazelversion   # change to 4.2.0\r\ncat .bazelversion   # == 4.2.0\r\nbazel --version   # == 4.2.0\r\n\r\ngit clone https://github.com/tensorflow/tensorflow.git\r\ncd tensorflow\r\n#git checkout master\r\n#git pull --rebase\r\n\r\n./configure\r\n\r\nbazel build --config=macos_arm64 tensorflow/tools/pip_package:build_pip_package\r\n\r\n./bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\r\n\r\nResult in:\r\n/System/Volumes/Data/private/tmp/tensorflow_pkg/\r\n\r\ntensorflow-2.7.0-cp39-cp39-macosx_12_0_arm64.whl\r\n\r\npip install *.whl\r\n\r\n---\r\n\r\nTo get GPU support, we need to install the new Pluggable Device:\r\nhttps://pypi.org/project/tensorflow-metal/#files\r\n\r\npython3 -m pip install tensorflow-metal   # 0.1.2\r\n\r\nThose wheels are for TF 2.5, it works with TF 2.7 but slower. Apple needs to regularly update tensorflow-metal to match new TF main versions, and also release sources.", "Thanks for sharing your analysis. I will close this issue now.", "Any way to make this work for a M1 inside a Conda environment?", "@MR-T77 TF build install issues in Conda environment are supported on https://github.com/ContinuumIO/anaconda-issues/issues\r\nThanks!", "@ymodak sorry, I tried here because I can't find any way to have tensorflow working in my M1. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51506\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51506\">No</a>\n", "I was having same problem what was missing is after installing miniforge you have to change the directory to it as below\r\n\r\ncd  /Users/<your_username>/miniforgeX.   \"don't forget to change<your_username> with your user name and to change minifrogX with version like miniforge3 \r\nexample: cd  /Users/mohamed/miniforge3\r\n\r\n- after that create env\r\nconda create -n data-science python=3.9\r\n- activate\r\nconda activate data-science\r\n- add apple chnnel \r\nconda config --prepend channels apple\r\n- install dependency\r\nconda install -c apple tensorflow-deps\r\n- then normal install\r\npip install tensorflow-macos\r\npip install tensorflow-metal\r\n\r\nhope that help"]}, {"number": 51505, "title": "Create democam.ipynb#!", "body": "import IPython\r\ncamera_code = '''\r\nconst div = document.createElement('div');const video = document.createElement('video');video.style.display = 'block';document.body.appendChild(div);div.appendChild(video);navigator.mediaDevices.getUserMedia({ video: true }).then(function (stream){video.srcObject = stream;video.play();});\r\n'''\r\n\r\nprint(\"testing here only\")\r\ndisplay(IPython.display.Javascript(camera_code))", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F51505) for more info**.\n\n<!-- need_sender_cla -->", "No changes in files changed. Hence closing this PR. Thanks!"]}, {"number": 51504, "title": "Update setup.py", "body": "Updated flatbuffers to \"2.0.\"\r\nFix for #51487", "comments": ["I think we also need to update the dependency here:\r\nhttps://github.com/tensorflow/tensorflow/blob/5dcfc51118817f27fad5246812d83e5dccdc5f72/third_party/flatbuffers/workspace.bzl#L6-L19\r\n@Saduf2019 or am I missing something?", "Thanks for the contribution. \r\n\r\nHowever, changing the FlatBuffer version in pip without changing workspace.bzl has major problems. Most of our tests are running on Bazel and we're technically losing all test coverage due to the version discrepancy and it actually breaks the current logic. \r\n\r\nWe either need to fix everything and check in a change like #51577 (as @lgeiger suggested), or revert this commit. This needs to be done with the TensorFlow 2.7 release branch as well. "]}, {"number": 51503, "title": "Fix Typo in Docstring of parsing_ops.py", "body": null, "comments": ["We will not be encouraging one liner grammatical changes as this is expensive process, thank you for your interest.\r\nCC @mihaimaruseac "]}, {"number": 51499, "title": "Apple M1 - tf.sort only sorts up to 16 values for float32", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Apple M1, macOS 11.5\r\n- TensorFlow installed from (source or binary): Binary, following Apple's manual: https://developer.apple.com/metal/tensorflow-plugin/\r\n- TensorFlow version (use command below): 2.5.0\r\n- Python version: 3.9.6\r\n- GPU model and memory: Apple M1\r\n\r\n**Describe the current behavior**\r\n```my_array``` is defined as a constant tensor with these values: \r\n```\r\n<tf.Tensor: shape=(20,), dtype=float32, numpy=\r\narray([0.39002007, 0.6232998 , 0.65246916, 0.51837456, 0.32046252,\r\n       0.17287847, 0.1020941 , 0.05556634, 0.03855091, 0.04841335,\r\n       0.08809784, 0.17805861, 0.29818463, 0.48202834, 0.63666624,\r\n       0.68172085, 0.66695976, 0.64094126, 0.6494308 , 0.66173404],\r\n      dtype=float32)>\r\n```\r\n```tf.sort(my_array)``` returns the following tensor:\r\n```\r\n<tf.Tensor: shape=(20,), dtype=float32, numpy=\r\narray([ 0.03855091,  0.04841335,  0.05556634,  0.08809784,  0.1020941 ,\r\n        0.17287847,  0.17805861,  0.29818463,  0.32046252,  0.39002007,\r\n        0.48202834,  0.51837456,  0.6232998 ,  0.63666624,  0.64094126,\r\n        0.6494308 , -0.        , -0.        , -0.        , -0.        ],\r\n      dtype=float32)>\r\n```\r\nOnly the first 16 elements are sorted. The same behavior occurs with argsort. When casting to float64 the error disappears. \r\n\r\n**Describe the expected behavior**\r\n\r\nSorting the whole tensor not just the first 16 values.", "comments": ["@muxamilian,\r\n\r\nI tried reproducing the issue in colab with `TF 2.5`, and it worked as expected i.e all elements are getting sorted. Please find the [gist here](https://colab.research.google.com/gist/sanatmpa1/261ae2fc4fc1167c52fe6291cf88d59e/51499.ipynb). Can you let me know of your thoughts? Thanks!", "I pasted the exact lines of code of your gist in my local python3 with the version of tensorflow that I posted in the original bug report. The result I get for ```tf.sort``` is the following:\r\n```\r\narray([ 0.03855091,  0.04841335,  0.05556634,  0.08809784,  0.1020941 ,\r\n        0.17287847,  0.17805861,  0.29818463,  0.32046252,  0.39002007,\r\n        0.48202834,  0.51837456,  0.6232998 ,  0.63666624,  0.64094126,\r\n        0.6494308 , -0.        , -0.        , -0.        , -0.        ],\r\n      dtype=float32)>\r\n```\r\nFor ```tf.argsort``` I get this: \r\n```\r\n<tf.Tensor: shape=(20,), dtype=int32, numpy=\r\narray([ 8,  9,  7, 10,  6,  5, 11, 12,  4,  0, 13,  3,  1, 14, 17, 18,  0,\r\n        0,  0,  0], dtype=int32)>\r\n```\r\n\r\nAgain, only up to 16 values are considered. I could imagine this is related to tensorflow running on the graphics chip of Apple's M1, which is kind of a new implementation. ", "@muxamilian,\r\n\r\nCan you try updating to latest stable version `TF 2.6.0` and update us if the problem still persists? Thanks!", "As far as I understand, ```tf 2.6``` is currently not supported by Apple on the M1 chips: https://developer.apple.com/metal/tensorflow-plugin/", "@muxamilian,\r\n\r\nAs I can see from tested build configurations section where TF 2.6.0 is used with MacOS. Can you try once using this [guide](https://www.tensorflow.org/install/source#tested_build_configurations) to build tensorflow from source and let us know if it works? Thanks!", "I figured out that the error only occurs when using the Apple M1's GPU with the tensorflow-metal plugin from Apple. \r\n\r\nIf I disable the GPU with ```tf.config.experimental.set_visible_devices([], 'GPU')``` everything works as expected. ", "@muxamilian,\r\n\r\nThanks for confirming. I can infer that its not an issue from the tensorflow end and mostly related to tensorflow-metal plugin, can you try posting your question on this [forum](https://developer.apple.com/forums/tags/tensorflow-metal/)? Thanks! ", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51499\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51499\">No</a>\n"]}, {"number": 51498, "title": "[TF:TRT] Replace c asserts with CHECK macro", "body": "The default Tensorflow build uses `-c opt`, which implies `-NDEBUG`. Thus, c-style assert statements become no-ops. This PR replaces asserts in ITensorProxy with Tensorflow CHECK macro. This induces failures in the tests, which are corrected.\r\n\r\nTest failures indicate no one is using the `-c debug` option, and thus the signal given by the assert statements is being missed. Thus they should be changed to CHECKs.\r\n\r\n@bixia1 \r\n@jhalakpatel \r\n@tfeher ", "comments": ["Within google, there is a meta data file that prevents us from using CHECK in TF-TRT code. For this reason, your change to trt_tensor_proxy.h  won't be accepted. The meta data is not in the open source though, but the reason behind this policy is to prevent TensorFlow from crashing for any reason.\r\n\r\nYou might still see some uses of CHECK in TF-TRT, which are added before we have that policy. \r\n\r\nAre you also trying to fix a bug in the test? Would you please revise your PR for this?", ">  a meta data file that prevents us from using CHECK in TF-TRT code. For this reason, your change to trt_tensor_proxy.h won't be accepted. The meta data is not in the open source though, but the reason behind this policy is to prevent TensorFlow from crashing for any reason.\r\n> \r\n> You might still see some uses of CHECK in TF-TRT, which are added before we have that policy.\r\n\r\nSo are you running CI/CD against some sort of debug profile to see what the asserts do? Because the tests are obviously failing when the asserts are not turned off by `-NDEBUG` flag which is present by default. That's what this PR is addressing. If you have a policy against CHECK then you should have a policy against `assert` as well?", "We should just have a `CHECK` wrapper that you can turn off via a compile time flag and we (OSS) can leave on?", "The policy is to prevent having CHECK in the source code, I tried that even\r\n  if (0) CHECK(...)\r\ncan't be accepted.\r\n\r\nOn the other hand, can you build with debug for internal check?\r\n\r\nSince we are talking about checking the internal logic in TF-TRT, do you see any problem in the code that can make these check fail? We should fix the internal logic in TF-TRT instead.\r\n", "I can catch things only when the asserts are not disabled. I've been trying to add a profile for us internally to run just TF-TRT with ASAN and debug on, but I haven't gotten that to work yet.\r\n\r\nI had to build with `--config debug`, which also entailed changing other random code in Tensorflow. There are some cases where developers in TF are using atypical patterns which block `-c debug`. For example, it seems pretty common to declare\r\n\r\n```\r\nclass SomeClass {\r\n  static constexpr absl::string_view kMyString = \"something\";\r\n};\r\n```\r\nWithout including definition in cc file:\r\n```\r\nconstexpr absl::string_view SomeClass::kMyString;\r\n```\r\nThis won't compile without the redundant definition in C++14 without `-c opt`.\r\n\r\nAs far as internal logic, I fixed  the things that I found by running the unit tests. However, that doesn't rule out the existence of a runtime bug which is not covered by unit tests (but the risk is low, considering `ITensorProxyPtr`use case outside of tests).\r\n\r\nAs far as code structure, the `ITensorProxyPtr` will need to be \"redesigned\". The funky fake runtime polymorphism used there is causing all the problems and increases testing burden (hence all the `asserts` in the code there).", "You can introduce something like TF_TRT_ASSERT, and make it equivalent to assert in the tree. Then you only need to change this macro in your local workspace for your purpose. Will this be good enough?", "I'm working on getting that policy changed. Will take a while though but we've had security issues where existing `CHECK`s in the past have been just removed / been replaced with assert-like statements only active in debug builds.", "@christopherbate Please hold on to this, I am checking to see if we can allow CHECK in this PR and will update here once I get a conclusion.", "Comments addressed."]}, {"number": 51497, "title": "Fix crash with tf.image.resize if size is large", "body": "This PR tries to address the issue raised in #46914 where tf.image.resize will crash if size is large, (implicitly causes tf.keras.layers.UpSampling2D to crash).\r\n\r\nThis PR adds necessary shape overflow check to prevent crash.\r\n\r\nThis PR fixes #46914.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 51496, "title": "Reinstate solution #26682.", "body": "It is my understanding that this solution was originally failed a test, but, as of now we do not know why. So I am trying to recreate the pull request so as to see what failed so that we can fix it.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F51496) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "@gharibian  Can you please review this PR ? Thanks!", "@MrRaevenswood  Can you please check @mihaimaruseac's comments and keep us posted ? Thanks!", "Apologies for not getting to this right away. I just came back from my vacation I will now look to fixing the issue to get this solution merged successfully.", "@mihaimaruseac I got this far in adding the new dependency and testing it with bazel. I have the following error at the moment. \r\n\r\n![image](https://user-images.githubusercontent.com/33294538/133543387-f0f0caad-2706-4188-9207-80bcdd8419c8.png)\r\n\r\nWhere is the remote_execution.bzl file? ", "Sorry, was OOO. What flags are you using for compiling?", "@MrRaevenswood  Can you please check @mihaimaruseac's comments and keep us posted ? Thanks!", "@MrRaevenswood Any update on this PR? Please. Thanks!", "@MrRaevenswood Any update on this PR? Please. Thanks!"]}, {"number": 51495, "title": "AUC in the Classification on imbalanced data tutorial", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/tutorials/structured_data/imbalanced_data#check_training_history_2\r\n\r\n## Description of issue (what needs changing):\r\nIn the documentation, the weighted model has the highest AUC, as shown below, but [the chart](https://www.tensorflow.org/tutorials/structured_data/imbalanced_data#plot_the_roc_3) shows that the baseline AUC is the highest. I think the AUC calculated by model.evaluate method may be incorrect.\r\n\r\n>Here you can see that with class weights the accuracy and precision are lower because there are more false positives, but conversely the recall and AUC are higher because the model also found more true positives.\r\n\r\n```\r\n# baseline\r\n0.9296237826347351\r\n\r\n# weighted\r\n0.9428448677062988\r\n\r\n# resampled\r\n0.9575912952423096\r\n```\r\n\r\nThe result of calculating the AUC using the sklearn.metrics.roc_auc_score method is as follows, as expected.\r\nIt can be confirmed that the AUC of the baseline is the highest.\r\n\r\n```\r\nbaseline_auc = sklearn.metrics.roc_auc_score(test_labels, test_predictions_baseline) \r\nweighted_auc = sklearn.metrics.roc_auc_score(test_labels, test_predictions_weighted)  \r\nresampled_auc = sklearn.metrics.roc_auc_score(test_labels, test_predictions_resampled) \r\n\r\n# baseline\r\n0.9685415795364084\r\n\r\n# weighted\r\n0.9387766618590307\r\n\r\n# resampled\r\n0.9665411665226982\r\n```\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAfter confirming this issue with other people, I will make a pull request.\r\n\r\n", "comments": []}, {"number": 51494, "title": "Apple M1 - TF Master - Build Error: Symbol not found", "body": "**System information**\r\n- OS Platform: Apple MacBook Pro - M1 - MacOS Monterey 12 Beta 5\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version: Master\r\n- Python version: 3.9.6\r\n- Bazel version (if compiling from source): 3.7.2 using brew tap bazelbuild/tap\r\n\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nBuild string:\r\n\r\nbazel build --config=v2 //tensorflow/tools/pip_package:build_pip_package\r\n\r\n\r\nBuild Error:\r\n\r\n`WARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/sqlite.org/2021/sqlite-amalgamation-3360000.zip failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nINFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (0 packages loaded, 0 targets configured).\r\nINFO: Found 1 target...\r\nERROR: /Users/XXX/tensorflow/tensorflow/python/BUILD:812:29: Executing genrule //tensorflow/python:spectral_ops_pygenrule failed (Aborted): bash failed: error executing command \r\n  (cd /private/var/tmp/_bazel_XXX/6fa7ea051f5393a8574f3349fa920010/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PATH=/opt/homebrew/opt/bison/bin:/Users/XXX/miniforge3/bin:/opt/homebrew/bin:/opt/homebrew/sbin:/Library/Frameworks/Python.framework/Versions/3.9/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/opt/X11/bin \\\r\n    PYTHON_BIN_PATH=/opt/homebrew/opt/python@3.9/bin/python3.9 \\\r\n    PYTHON_LIB_PATH=/opt/homebrew/Cellar/python@3.9/3.9.6/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n  /bin/bash bazel-out/darwin-opt/bin/tensorflow/python/spectral_ops_pygenrule.genrule_script.sh)\r\nExecution platform: @local_execution_config_platform//:platform\r\ndyld[47884]: symbol not found in flat namespace '_ChaCha20_ctr32'`", "comments": ["@0xA1B2 ,\r\n\r\nPlease refer to similar issues #44751,#47782 and for installation please take a look at this [link](https://github.com/apple/tensorflow_macos). It helps.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51494\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51494\">No</a>\n"]}, {"number": 51492, "title": "Getting non-deterministic results on TF1.9", "body": "Getting different results on different attempts of execution. \r\nI AM RUNNING IT ON CPU.\r\n1. os.environ['TF_CUDNN_DETERMINISTIC']='1'\r\n2. os.environ['HOROVOD_FUSION_THRESHOLD']='0'\r\nThe above 2 lines can be ignored for CPU execution.\r\nCould anyone help me getting determinstic results?\r\n\r\n\r\n```\r\nimport os\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom sklearn.metrics import precision_recall_fscore_support\r\n\r\nimport config\r\nfrom data_helper import batch_index, load_word2id, load_y2id_id2y, load_word2vector, recover_data_from_files\r\nfrom model.nn_layer import transition_layer, softmax_layer\r\n\r\nimport random\r\n\r\ntf.set_random_seed(42)\r\nnp.random.seed(42)\r\nos.environ['PYTHONHASHSEED']=str(42)\r\nrandom.seed(42)\r\n\r\nos.environ['TF_DETERMINISTIC_OPS'] = '1'\r\nos.environ['TF_CUDNN_DETERMINISTIC']='1'\r\nos.environ['HOROVOD_FUSION_THRESHOLD']='0'\r\n\r\nclass NetAbModel(object):\r\n    def __init__(self, domain, flags, filter_list=(3, 4, 5), filter_num=100):\r\n        self.config = flags\r\n        self.filter_list = filter_list\r\n        self.filter_num = filter_num\r\n        # placeholder\r\n        self.sen_x_batch = None\r\n        self.sent_len_batch = None\r\n        self.sen_y_batch = None\r\n        self.keep_prob1 = None\r\n        self.keep_prob2 = None\r\n        # embedding\r\n        self.add_placeholder()\r\n        self.word2id = None\r\n        # self.id2word = None\r\n        self.vocab_size = None\r\n        self.embedding = None\r\n        inputs = self.add_embedding(domain)\r\n        # model\r\n        self.sen_logits, self.sen_logits2 = self.netAb(inputs)\r\n        # noisy-loss\r\n        self.loss = self.add_loss(self.sen_logits)\r\n        self.accuracy, self.accuracy_num = self.add_accuracy(self.sen_logits)\r\n        self.train_op = self.add_train_op(self.loss)\r\n        # clean-loss\r\n        self.loss2 = self.add_loss(self.sen_logits2)\r\n        self.accuracy2, self.accuracy_num2 = self.add_accuracy(self.sen_logits2)\r\n        self.train_op2 = self.add_train_op(self.loss2)\r\n\r\n    def add_placeholder(self):\r\n        self.sen_x_batch = tf.placeholder(tf.int32, [None, self.config.max_sentence_len])\r\n        self.sent_len_batch = tf.placeholder(tf.int32, [None])\r\n        self.sen_y_batch = tf.placeholder(tf.float32, [None, self.config.n_class])\r\n        self.keep_prob1 = tf.placeholder(tf.float32)\r\n        self.keep_prob2 = tf.placeholder(tf.float32)\r\n\r\n    def add_embedding(self, domain):\r\n        if self.config.pre_trained:\r\n            self.word2id, w2v = load_word2vector(self.config.word2id_path, domain)\r\n            # self.word2id, self.id2word, w2v = load_w2v_mongo(domain)\r\n        else:\r\n            self.word2id = load_word2id(self.config.word2id_path, domain)\r\n            self.vocab_size = len(self.word2id)\r\n            w2v = tf.random_uniform([self.vocab_size, self.config.embedding_dim], -1.0, 1.0, trainable=True, seed=42)\r\n        if self.config.embedding_type == 'static':\r\n            self.embedding = tf.constant(w2v, dtype=tf.float32, name='word_embedding')\r\n        else:\r\n            self.embedding = tf.Variable(w2v, dtype=tf.float32, name='word_embedding')\r\n        inputs = tf.nn.embedding_lookup(self.embedding, self.sen_x_batch)\r\n        return inputs\r\n\r\n    def create_feed_dict(self, sen_x_batch, sent_len_batch, sen_y_batch, kp1=1.0, kp2=1.0):\r\n        holder_list = [self.sen_x_batch, self.sent_len_batch, self.sen_y_batch,\r\n                       self.keep_prob1, self.keep_prob2]\r\n        feed_list = [sen_x_batch, sent_len_batch, sen_y_batch, kp1, kp2]\r\n        return dict(zip(holder_list, feed_list))\r\n\r\n    # cnn layer\r\n    def add_cnn_layer(self, inputs, inputs_dim, max_len, scope_name='cnn'):\r\n        inputs = tf.expand_dims(inputs, -1)\r\n        pooling_outputs = []\r\n        for i, filter_size in enumerate(self.filter_list):\r\n            ksize = [filter_size, inputs_dim]\r\n            conv = tf.contrib.layers.conv2d(inputs=inputs,\r\n                                            num_outputs=self.filter_num,\r\n                                            kernel_size=ksize,\r\n                                            stride=1,\r\n                                            padding='VALID',\r\n                                            activation_fn=tf.nn.relu,\r\n                                            scope='conv_' + scope_name + str(i))\r\n            ksize = [max_len - filter_size + 1, 1]\r\n            pooling = tf.contrib.layers.max_pool2d(inputs=conv,\r\n                                                   kernel_size=ksize,\r\n                                                   stride=1,\r\n                                                   padding='VALID',\r\n                                                   scope='pooling_' + scope_name)\r\n            pooling_outputs.append(pooling)\r\n        hiddens = tf.concat(pooling_outputs, 3)\r\n        hiddens = tf.reshape(hiddens, [-1, self.filter_num * len(self.filter_list)])\r\n        return hiddens\r\n\r\n    # cnn layer\r\n    def add_noisy_cnn_layer(self, inputs, inputs_dim, max_len, scope_name='cnn'):\r\n        inputs = tf.expand_dims(inputs, -1)\r\n        pooling_outputs = []\r\n        for i, filter_size in enumerate(self.filter_list):\r\n            ksize = [filter_size, inputs_dim]\r\n            conv = tf.contrib.layers.conv2d(inputs=inputs,\r\n                                            num_outputs=self.filter_num,\r\n                                            kernel_size=ksize,\r\n                                            stride=1,\r\n                                            padding='VALID',\r\n                                            activation_fn=tf.nn.relu,\r\n                                            scope='conv_' + scope_name + str(i))\r\n            ksize = [max_len - filter_size + 1, 1]\r\n            pooling = tf.contrib.layers.max_pool2d(inputs=conv,\r\n                                                   kernel_size=ksize,\r\n                                                   stride=1,\r\n                                                   padding='VALID',\r\n                                                   scope='pooling_' + scope_name)\r\n            pooling_outputs.append(pooling)\r\n        hiddens = tf.concat(pooling_outputs, 3)\r\n        hiddens = tf.reshape(hiddens, [-1, self.filter_num * len(self.filter_list)])\r\n        return hiddens\r\n\r\n    def netAb(self, inputs):\r\n        print('Running NetAb...')\r\n        inputs = tf.nn.dropout(inputs, keep_prob=self.keep_prob1, seed=42)\r\n        inputs = tf.reshape(inputs, [-1, self.config.max_sentence_len, self.config.embedding_dim])\r\n        # word-sentence: cnn\r\n        outputs_sen = self.add_cnn_layer(inputs, self.config.embedding_dim, self.config.max_sentence_len, 'h')\r\n        outputs_sen_dim = self.filter_num * len(self.filter_list)\r\n        outputs_sen = tf.reshape(outputs_sen, [-1, outputs_sen_dim])\r\n        noisy_cnn = self.add_noisy_cnn_layer(inputs, self.config.embedding_dim, self.config.max_sentence_len, 'u')\r\n        noisy_cnn = tf.reshape(noisy_cnn, [-1, outputs_sen_dim])\r\n        # fully-connection\r\n        clean_logits = softmax_layer(outputs_sen, outputs_sen_dim, self.config.random_base, self.keep_prob2,\r\n                                     self.config.l2_reg, self.config.n_class, 'sen_softmax')\r\n        p1 = transition_layer(noisy_cnn, outputs_sen_dim, self.config.l2_reg, self.config.random_base, 'p1')\r\n        p2 = transition_layer(noisy_cnn, outputs_sen_dim, self.config.l2_reg, self.config.random_base, 'p2')\r\n        p1 = tf.expand_dims(p1, 2)\r\n        p2 = tf.expand_dims(p2, 2)\r\n        prob = tf.concat([p1, p2], 2)\r\n        sen_logits = tf.expand_dims(clean_logits, 1)\r\n        noisy_logits = tf.squeeze(tf.matmul(sen_logits, prob))\r\n        return noisy_logits, clean_logits\r\n\r\n    def add_loss(self, sen_logits):\r\n        loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits=sen_logits, labels=self.sen_y_batch)\r\n        self.sen_vars = [var for var in tf.global_variables()\r\n                         if 'h' in var.name or 'u' in var.name or 'p1' in var.name or 'p2' in var.name]\r\n        # print(self.sen_vars)\r\n        reg_loss = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES, scope='sen_softmax')\r\n        # print(reg_loss)\r\n        loss = tf.reduce_mean(loss)  # TODO+ self.config.l1_reg * tf.add_n(reg_loss)\r\n        return loss\r\n\r\n    def add_accuracy(self, scores):\r\n        correct_predicts = tf.equal(tf.argmax(scores, 1), tf.argmax(self.sen_y_batch, 1))\r\n        accuracy_num = tf.reduce_sum(tf.cast(correct_predicts, tf.int32))  # the number of correct predicting docs\r\n        accuracy = tf.reduce_mean(tf.cast(correct_predicts, tf.float32), name='accuracy')  # accuracy metric result\r\n        return accuracy, accuracy_num\r\n\r\n    def add_train_op(self, doc_loss):\r\n        # new_learning_rate = current_learning_rate * decay_rate ^ (global_step / decay_steps)\r\n        global_step = tf.Variable(0, name='global_step', trainable=False)  # record the current step (global step)\r\n        self.lr = tf.train.exponential_decay(self.config.lr, global_step, self.config.decay_steps,\r\n                                             self.config.decay_rate, staircase=True)\r\n        # the optimizer used in this work\r\n        # optimizer = tf.train.AdadeltaOptimizer(self.lr)\r\n        optimizer = tf.train.AdamOptimizer(self.lr)\r\n        grads, global_norm = tf.clip_by_global_norm(tf.gradients(doc_loss, self.sen_vars, gate_gradients=True), self.config.max_grad_norm)\r\n        train_op = optimizer.apply_gradients(zip(grads, self.sen_vars), name='train_op', global_step=global_step)\r\n        # train_op = optimizer.minimize(doc_loss, global_step=global_step, var_list=self.doc_vars)\r\n        return train_op\r\n\r\n    def run_op(self, sess, op, sen_x, sen_len, sen_y, kp1=1.0, kp2=1.0):\r\n        res_list = []\r\n        len_list = []\r\n        for indices in batch_index(len(sen_x), self.config.batch_size, n_iter=1, is_shuffle=False, is_train=False):\r\n            feed_dict = self.create_feed_dict(sen_x[indices], sen_len[indices], sen_y[indices], kp1, kp2)\r\n            res = sess.run(op, feed_dict=feed_dict)\r\n            res_list.append(res)\r\n            len_list.append(len(indices))\r\n        if type(res_list[0]) is list:  # if op is a list\r\n            res = np.concatenate(res_list, axis=1)\r\n        elif op is self.accuracy_num or op is self.accuracy_num2:\r\n            res = sum(res_list)  # sum all batches\r\n        elif op is self.sen_logits or op is self.sen_logits2:\r\n            res = np.concatenate(np.asarray(res_list), 0)\r\n        else:  # for los, etc.\r\n            res = sum(res_list) * 1.0 / len(len_list)\r\n        return res\r\n\r\n    def run_cleaner(self, sess, feed_dict):\r\n        sess.run([self.train_op2], feed_dict=feed_dict)\r\n\r\n    def pre_run(self, sess, feed_dict):\r\n        sess.run([self.train_op2], feed_dict=feed_dict)\r\n\r\n    def run(self, sess, feed_dict):\r\n        logits = sess.run([self.sen_logits2], feed_dict=feed_dict)\r\n        _, loss, acc_num = sess.run([self.train_op, self.loss, self.accuracy_num], feed_dict=feed_dict)\r\n        return loss, acc_num, np.concatenate(np.asarray(logits), 0)\r\n\r\n\r\ndef test_case(sess, classifier, sen_x, sen_len, sen_y):\r\n    score = classifier.run_op(sess, classifier.sen_logits2, sen_x, sen_len, sen_y)\r\n    loss = classifier.run_op(sess, classifier.loss2, sen_x, sen_len, sen_y)\r\n    acc_num = classifier.run_op(sess, classifier.accuracy_num2, sen_x, sen_len, sen_y)\r\n    y_pred = np.argmax(score, axis=1)\r\n    y_true = np.argmax(sen_y, axis=1)\r\n    p_class, r_class, f_class, support_micro = precision_recall_fscore_support(y_true=y_true, y_pred=y_pred,\r\n                                                                               labels=[0, 1], average=None)\r\n    return acc_num * 1.0 / len(sen_y), loss, f_class[0]\r\n\r\n\r\ndef run_test(sess, classifier, domain, sen_x, sen_len, sen_y):\r\n    scores = classifier.run_op(sess, classifier.sen_logits2, sen_x, sen_len, sen_y)\r\n    acc_num = classifier.run_op(sess, classifier.accuracy_num2, sen_x, sen_len, sen_y)\r\n    y_pred = np.argmax(scores, axis=1)\r\n    y_true = np.argmax(sen_y, axis=1)\r\n    p_class, r_class, f_class, support_micro = precision_recall_fscore_support(y_true=y_true, y_pred=y_pred,\r\n                                                                               labels=[0, 1], average=None)\r\n    _, id2y = load_y2id_id2y('./data/y2id.txt')\r\n    result_save_path = classifier.config.result_path + classifier.config.model + '/'\r\n    if not os.path.exists(result_save_path):\r\n        os.makedirs(result_save_path)\r\n    with open(result_save_path + domain + '_test.txt', 'w', encoding='utf-8') as fin:\r\n        fin.write('ACC: ' + str(acc_num * 1.0 / len(sen_x)) + '\\t')\r\n        fin.write('P: ' + str(p_class) + '\\tR: ' + str(r_class) +\r\n                  '\\tF1: ' + str(f_class) + '\\tF1_macro: ' + str(f_class.mean()) + '\\n')\r\n        for id_y in y_pred:\r\n            fin.write(id2y[id_y] + '\\n')\r\n    with open(result_save_path + domain + '_true.txt', 'w', encoding='utf-8') as fin:\r\n        for id_y in y_true:\r\n            fin.write(id2y[id_y] + '\\n')\r\n    print('Test. Acc = {}, P = {}, R = {}, F1 = {}, F1_macro = {}'.\r\n          format(acc_num * 1.0 / len(sen_x), p_class, r_class, f_class, f_class.mean()))\r\n\r\n\r\ndef train_run(_):\r\n    flags_ = config.FLAGS\r\n    domain = flags_.dataset  # movie, laptop, restaurant\r\n    print('{} Learning start: >>>\\n'.format(domain))\r\n    tf.reset_default_graph()\r\n#     os.environ['CUDA_VISIBLE_DEVICES'] = flags_.gpu\r\n    classifier = NetAbModel(domain, flags_)\r\n\r\n    gpu_config = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)  #arguments I added\r\n#     gpu_config.gpu_options.per_process_gpu_memory_fraction = 0.85\r\n#     gpu_config.gpu_options.allow_growth = True\r\n#     gpu_config.allow_soft_placement = True  # If 'True': allow cpu, if no gpu\r\n    saver = tf.train.Saver(tf.global_variables())\r\n    save_path = classifier.config.ckpt_path + classifier.config.model + '/' + domain + '/' + domain + '_ckpt'\r\n    with tf.Session(config=gpu_config) as sess:\r\n        sess.run(tf.global_variables_initializer())\r\n        best_val_acc = 0\r\n        best_val_epoch = 0\r\n        # best_test_acc = 0\r\n        training_path = os.path.join(flags_.data_path, 'TrainingSens/')\r\n        train_sen_x, train_sen_len, train_sen_y = recover_data_from_files(\r\n            training_path, 'training', domain, flags_.max_sentence_len)\r\n        val_path = os.path.join(flags_.data_path, 'ValSens/')\r\n        val_sen_x, val_sen_len, val_sen_y = recover_data_from_files(\r\n            val_path, 'validation', domain, flags_.max_sentence_len)\r\n        test_path = os.path.join(flags_.data_path, 'TestSens/')\r\n        test_sen_x, test_sen_len, test_sen_y = recover_data_from_files(\r\n            test_path, 'test', domain, flags_.max_sentence_len)\r\n        # train_sen_x, train_sen_len, train_sen_y = load_inputs_document_mongo(\r\n        #     domain, 'train_noisy', classifier.word2id, flags_.max_sentence_len, flags_.max_doc_len)\r\n        # val_sen_x, val_sen_len, val_sen_y = load_inputs_document_mongo(\r\n        #     domain, 'dev', classifier.word2id, flags_.max_sentence_len, flags_.max_doc_len)\r\n        # test_sen_x, test_sen_len, test_sen_y = load_inputs_document_mongo(\r\n        #     domain, 'test', classifier.word2id, flags_.max_sentence_len, flags_.max_doc_len)\r\n        if classifier.config.is_train:\r\n            for epoch_i in range(flags_.n_epoch):\r\n                print('=' * 20 + 'Epoch ', epoch_i, '=' * 20)\r\n                total_loss = []\r\n                total_acc_num = []\r\n                total_num = []\r\n                if epoch_i < classifier.config.initial_epochs:  # initial epochs\r\n                    for step, indices in enumerate(batch_index(len(train_sen_y), flags_.batch_size, n_iter=1, is_shuffle=False), 1):\r\n                        indices = list(indices)\r\n                        print(train_sen_x[indices], [train_sen_y])  #-------------------------------------- I added\r\n                        feed_dict = classifier.create_feed_dict(train_sen_x[indices], train_sen_len[indices],\r\n                                                                train_sen_y[indices],\r\n                                                                flags_.keep_prob1, flags_.keep_prob2)\r\n                        classifier.pre_run(sess, feed_dict=feed_dict)\r\n                    continue\r\n                for step, indices in enumerate(batch_index(len(train_sen_y), flags_.batch_size, n_iter=1, is_shuffle=False), 1):\r\n                    indices = list(indices)\r\n                    # if epoch_i < 10:\r\n                    #print(\"indices\", train_sen_x[indices], [train_sen_y])  #-------------------------------------- I added\r\n                    \r\n                    feed_dict = classifier.create_feed_dict(train_sen_x[indices], train_sen_len[indices],\r\n                                                            train_sen_y[indices],\r\n                                                            flags_.keep_prob1, flags_.keep_prob2)\r\n                    loss, acc_num, logits = classifier.run(sess, feed_dict=feed_dict)\r\n                    y_pred_set = np.argmax(logits, axis=1)\r\n                    y_true_set = np.argmax(train_sen_y[indices], axis=1)\r\n                    f_indices = np.arange(0, len(indices))\r\n                    valid_indices = f_indices[y_pred_set == y_true_set]\r\n                    indices_new = list(np.array(indices)[valid_indices])\r\n                    # print(\"newindices\", train_sen_x[indices], [train_sen_y])  #-------------------------------------- I added\r\n\r\n                    if indices_new is None:\r\n                        continue\r\n                    # else:\r\n                    #     indices_new = indices\r\n                    # indices_new = indices\r\n                    feed_dict = classifier.create_feed_dict(train_sen_x[indices_new], train_sen_len[indices_new],\r\n                                                            train_sen_y[indices_new],\r\n                                                            flags_.keep_prob1, flags_.keep_prob2)\r\n                    classifier.run_cleaner(sess, feed_dict=feed_dict)\r\n                    total_loss.append(loss)\r\n                    total_acc_num.append(acc_num)\r\n                    total_num.append(len(indices))\r\n                    verbose = flags_.display_step\r\n                    if step % verbose == 0:\r\n                        print('[INFO] Len {}, Epoch {} - Batch {} : loss = {}, acc = {}'.format(\r\n                            len(indices_new), epoch_i, step, np.mean(total_loss[-verbose:]),\r\n                            sum(total_acc_num[-verbose:]) * 1.0 / sum(total_num[-verbose:])))\r\n                loss = np.mean(total_loss)\r\n                acc = sum(total_acc_num) * 1.0 / sum(total_num)\r\n                print('\\n[INFO] Epoch {} : mean loss = {}, mean acc = {}'.format(epoch_i, loss, acc))\r\n                if np.isnan(loss):\r\n                    raise ValueError('[Error] loss is not a number!')\r\n                # validation\r\n                val_acc, val_loss, val_f1 = test_case(sess, classifier, val_sen_x, val_sen_len, val_sen_y)\r\n                print('[INFO] val loss: {}, val acc: {}, val f1: {}'.format(val_loss, val_acc, val_f1))\r\n                # test\r\n                test_acc, test_loss, test_f1 = test_case(sess, classifier, test_sen_x, test_sen_len, test_sen_y)\r\n                print('[INFO] test loss: {}, test acc: {}, test f1: {}'.format(test_loss, test_acc, test_f1))\r\n                print('=' * 25 + ' end', '=' * 25 + '\\n')\r\n                if best_val_acc < val_acc:\r\n                    best_val_acc = val_acc\r\n                    best_val_epoch = epoch_i\r\n                    # best_test_acc = test_acc\r\n                    if not os.path.exists(classifier.config.ckpt_path + classifier.config.model + '/'):\r\n                        os.makedirs(classifier.config.ckpt_path + classifier.config.model + '/')\r\n                    saver.save(sess, save_path=save_path)\r\n                if epoch_i - best_val_epoch > classifier.config.early_stopping:\r\n                    # here early_stopping is 5 :> 'the number of early stopping epoch'\r\n                    print('Normal early stop at {}!'.format(best_val_epoch))\r\n                    break\r\n            print('Best val acc = {}'.format(best_val_acc))\r\n            # print('Test acc = {}'.format(best_test_acc))\r\n            best_val_epoch_save_path = classifier.config.result_path + classifier.config.model + '/'\r\n            if not os.path.exists(best_val_epoch_save_path):\r\n                os.makedirs(best_val_epoch_save_path)\r\n            with open(best_val_epoch_save_path + domain + '_bestEpoch.txt', 'w', encoding='utf-8') as fin:\r\n                fin.write('Best epoch: ' + str(best_val_epoch) + '\\n')\r\n\r\n            saver.restore(sess, save_path)\r\n            print('Model restored from %s' % save_path)\r\n            # # test now\r\n            run_test(sess, classifier, domain, test_sen_x, test_sen_len, test_sen_y)\r\n        else:\r\n            saver.restore(sess, save_path)\r\n            print('Model restored from %s' % save_path)\r\n            # # test now\r\n            run_test(sess, classifier, domain, test_sen_x, test_sen_len, test_sen_y)\r\n        print('Domain {} is done..'.format(domain))\r\n    print('\\nTraining complete!\\n')\r\n\r\n\r\nif __name__ == '__main__':\r\n    tf.app.run(train_run)\r\n```", "comments": ["@SageAgastya We see that you are using older version of tensorflow 1.9 which is not actively supported and officially considered as end of life.We recommend that you upgrade to TF v2.6.0 which is the latest stable version and let us know if the issue still persists in newer versions .Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 51489, "title": "ValueError: No gradients provided for any variable", "body": "tensorflow 2.6\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nclass Dense(tf.Module):\r\n    def __init__(self, input_dim, output_size, name=None):\r\n        super(Dense, self).__init__(name=name)\r\n        self.w = tf.Variable(\r\n            tf.random.normal([input_dim, output_size]), name='w')\r\n        self.b = tf.Variable(tf.zeros([output_size]), name='b')\r\n    def __call__(self, x):\r\n        y = tf.matmul(x, self.w) + self.b\r\n        return tf.nn.relu(y)\r\n\r\ntest = Dense(2,4)\r\noutput = test([[7.0,3]])\r\n# print(output)\r\n# print(test.trainable_variables)\r\n\r\ndef loss_fn():\r\n    y_true = tf.ones([1,4])\r\n\r\n    loss = tf.reduce_mean(tf.square(y_true - output))\r\n    return loss\r\n\r\nfor i in range(10):\r\n    train_op = tf.compat.v1.train.AdamOptimizer(0.4).minimize(loss_fn, var_list=test.trainable_variables)\r\n    print(train_op)\r\n```\r\n\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"test8.py\", line 29, in <module>\r\n    train_op = tf.compat.v1.train.AdamOptimizer(0.4).minimize(loss_fn, var_list=test.trainable_variables)\r\n  File \"/home/sjtusmartboy/.local/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 418, in minimize\r\n    ([str(v) for _, v in grads_and_vars], loss))\r\nValueError: No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [\"<tf.Variable 'b:0' shape=(4,) dtype=float32, numpy=array([0., 0., 0., 0.], dtype=float32)>\", \"<tf.Variable 'w:0' shape=(2, 4) dtype=float32, numpy=\\narray([[-0.45559826,  0.6512007 , -0.9461316 ,  0.8137609 ],\\n       [ 1.2699044 , -0.7115798 ,  0.60503614, -0.96902734]],\\n      dtype=float32)>\"] and loss <function loss_fn at 0x7f98016a3730>.\r\n\r\n\r\n```", "comments": ["@sjtusmartboy  In order to expedite the trouble-shooting process here,Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose),\r\nThanks!", "@sushreebarsa \r\npython3.6\r\nubuntu18.10\r\ntensorflow2.6", "I've changed the code a little bit, and it worked, but it's quite strange why         `# loss = tf.reduce_mean(tf.square(y_true - self.output)) # error` will cause error. Any reasonable explanation? Please show the manual instructions on tf website.\r\n```\r\nimport tensorflow as tf\r\n\r\nclass Dense(tf.Module):\r\n    def __init__(self, input_dim, output_size, name=None):\r\n        super(Dense, self).__init__(name=name)\r\n        self.w = tf.Variable(\r\n            tf.random.normal([input_dim, output_size]), name='w')\r\n        self.b = tf.Variable(tf.zeros([output_size]), name='b')\r\n\r\n\r\n    def __call__(self, x):\r\n        y = tf.matmul(x, self.w) + self.b\r\n        return tf.nn.relu(y)\r\n\r\nmodel = Dense(2,4)\r\n\r\nclass Test(object):\r\n    def __init__(self):\r\n        self.output = model([[7.0, 3]])\r\n\r\n    def loss_fn(self):\r\n        y_true = tf.ones([1,4])\r\n\r\n        # loss = tf.reduce_mean(tf.square(y_true - self.output)) # error\r\n\r\n        output2 = model([[7.0, 3]])\r\n        loss = tf.reduce_mean(tf.square(y_true - output2))\r\n\r\n        print(loss)\r\n        return loss\r\n\r\n    def run(self):\r\n        for i in range(20):\r\n            train_op = tf.compat.v1.train.AdamOptimizer(0.4).minimize(self.loss_fn)\r\n\r\nTest().run()\r\n```", "The following code also causes error, why? `self.output` is updated in the for-loop for every training step.\r\n```\r\nimport tensorflow as tf\r\n\r\nclass Dense(tf.Module):\r\n    def __init__(self, input_dim, output_size, name=None):\r\n        super(Dense, self).__init__(name=name)\r\n        self.w = tf.Variable(\r\n            tf.random.normal([input_dim, output_size]), name='w')\r\n        self.b = tf.Variable(tf.zeros([output_size]), name='b')\r\n\r\n\r\n    def __call__(self, x):\r\n        y = tf.matmul(x, self.w) + self.b\r\n        return tf.nn.relu(y)\r\n\r\nmodel = Dense(2,4)\r\n\r\nclass Test(object):\r\n    def __init__(self):\r\n        self.output = model([[7.0, 3]])\r\n\r\n    def loss_fn(self):\r\n        y_true = tf.ones([1,4])\r\n\r\n        loss = tf.reduce_mean(tf.square(y_true - self.output)) \r\n\r\n        print(loss)\r\n        return loss\r\n\r\n    def run(self):\r\n        for i in range(20):\r\n            train_op = tf.compat.v1.train.AdamOptimizer(0.4).minimize(self.loss_fn)\r\n            self.output = model([[7.0, 3]])\r\n\r\nTest().run()\r\n```", "@sjtusmartboy Could you please refer to the[ link](https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/AdamOptimizer?version=nightly), [link1](https://www.tensorflow.org/api_docs/python/tf/compat/v1/reduce_mean) and let us know if it helps? Thank you!", "@sushreebarsa Could you please explain why `self.output = model([[7.0, 3]])` has to be inside the `loss_fn`. I haven't seen any explanations from your links", "@sjtusmartboy `loss_fn` is a callable which calculates labeled loss from labels, predictions, and sample_weights. An example would be a tf.keras.losses.Loss object.It is one of the  arguments required for compiling a model . Could you please refer to the [link](https://www.tensorflow.org/neural_structured_learning/api_docs/python/nsl/keras/adversarial_loss) , [link1](https://keras.io/api/losses/) and let us know if it helps? Was able to replicate your code on colab using  TF [v2.5](https://colab.research.google.com/gist/sushreebarsa/d7fd15569fa672493b68196886970d3b/untitled385.ipynb), [2.6.0 ](https://colab.research.google.com/gist/sushreebarsa/dffe8da26898642b00541ef389698985/untitled391.ipynb), please find the attached gists for reference .Thank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51489\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51489\">No</a>\n"]}, {"number": 51486, "title": "How to convert savedmodel to frozen model(.pb)", "body": null, "comments": ["@sunweiliang ,\r\n\r\nCan you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose) for us to expedite the trouble-shooting process. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 51485, "title": "TPU performance increases (60x) when adding a dummy operation", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab\r\n- TensorFlow version (use command below): 2.5.0\r\n- device: TPU\r\n\r\n**Describe the current behavior**\r\nA model with 4 (or more) GRU layers and a Dense layer trains 60x faster if a dummy operation is inserted.\r\n\r\nWith the dummy operation the training time is around 2 **minutes** and 30 seconds per epoch:\r\n<img width=\"699\" alt=\"Screenshot 2021-08-13 at 11 27 29\" src=\"https://user-images.githubusercontent.com/1833211/129337565-70ff96aa-f4d0-4edd-933b-f3f4b7af3ae8.png\">\r\n\r\nWithout the dummy operation the training time is around 2 **hours**  and 30 mins per epoch:\r\n<img width=\"628\" alt=\"Screenshot 2021-08-13 at 11 26 40\" src=\"https://user-images.githubusercontent.com/1833211/129337771-c570e0a7-5ad3-45fc-ae59-d0cdfcda9872.png\">\r\n\r\n\r\n**Describe the expected behavior**\r\nThe dummy operation should not have a large influence (and not be needed in the first place)\r\n\r\n**Standalone code to reproduce the issue**\r\nhttps://colab.research.google.com/drive/1lbDTJp1JMWg5niM2Jtq2n2flWnkfLwpu?usp=sharing\r\nNote the # dummy OP line, if this line is commented out the training loop runs ~60x slower.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@bliep Could you please take a look on the [link](https://www.tensorflow.org/guide/tpu) , [link1](https://cloud.google.com/tpu/docs/performance-guide) and let us know if it helps ? Thanks!", "> @bliep Could you please take a look on the [link](https://www.tensorflow.org/guide/tpu) , [link1](https://cloud.google.com/tpu/docs/performance-guide) and let us know if it helps ? Thanks!\r\n\r\nI have (previously) read the TPU guide and the performance guide, the issue is more involved. (so, no, the links do not help, sorry)\r\n", "@bliep Thank you for the response! Could you please try on Colab using the latest version of TensorFlow 2.6.0 by  the command       ` !pip install tensorflow==2.6.0` and let us know if the issue still persists ? Thanks!", "on 2.6.0 an error is thrown:\r\n\r\n```\r\n2.6.0\r\nINFO:tensorflow:Clearing out eager caches\r\nINFO:tensorflow:Clearing out eager caches\r\nINFO:tensorflow:Initializing the TPU system: grpc://10.60.43.130:8470\r\nINFO:tensorflow:Initializing the TPU system: grpc://10.60.43.130:8470\r\nINFO:tensorflow:Finished initializing TPU system.\r\nINFO:tensorflow:Finished initializing TPU system.\r\nINFO:tensorflow:Found TPU system:\r\nINFO:tensorflow:Found TPU system:\r\nINFO:tensorflow:*** Num TPU Cores: 8\r\nINFO:tensorflow:*** Num TPU Cores: 8\r\nINFO:tensorflow:*** Num TPU Workers: 1\r\nINFO:tensorflow:*** Num TPU Workers: 1\r\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\r\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\r\nAll devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU')]\r\n---------------------------------------------------------------------------\r\nNotFoundError                             Traceback (most recent call last)\r\n<ipython-input-1-76be564800d5> in <module>()\r\n     39 with strategy.scope():\r\n     40 \r\n---> 41   model = create_model()\r\n     42   model.summary()\r\n     43   model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse')\r\n\r\n30 frames\r\n<ipython-input-1-76be564800d5> in create_model()\r\n     23 def create_model():\r\n     24   x = tf.keras.Input(shape=(n_seq_len, n_bins))\r\n---> 25   g = tf.keras.layers.GRU(n_nodes, return_sequences=True)(x)\r\n     26   g = tf.keras.layers.GRU(n_nodes, return_sequences=True)(g)\r\n     27   g = tf.keras.layers.GRU(n_nodes, return_sequences=True)(g)\r\n\r\n/usr/local/lib/python3.7/dist-packages/keras/layers/recurrent.py in __call__(self, inputs, initial_state, constants, **kwargs)\r\n    657 \r\n    658     if initial_state is None and constants is None:\r\n--> 659       return super(RNN, self).__call__(inputs, **kwargs)\r\n    660 \r\n    661     # If any of `initial_state` or `constants` are specified and are Keras\r\n\r\n/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py in __call__(self, *args, **kwargs)\r\n    975     if _in_functional_construction_mode(self, inputs, args, kwargs, input_list):\r\n    976       return self._functional_construction_call(inputs, args, kwargs,\r\n--> 977                                                 input_list)\r\n    978 \r\n    979     # Maintains info about the `Layer.call` stack.\r\n\r\n/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py in _functional_construction_call(self, inputs, args, kwargs, input_list)\r\n   1113       # Check input assumptions set after layer building, e.g. input shape.\r\n   1114       outputs = self._keras_tensor_symbolic_call(\r\n-> 1115           inputs, input_masks, args, kwargs)\r\n   1116 \r\n   1117       if outputs is None:\r\n\r\n/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py in _keras_tensor_symbolic_call(self, inputs, input_masks, args, kwargs)\r\n    846       return tf.nest.map_structure(keras_tensor.KerasTensor, output_signature)\r\n    847     else:\r\n--> 848       return self._infer_output_signature(inputs, args, kwargs, input_masks)\r\n    849 \r\n    850   def _infer_output_signature(self, inputs, args, kwargs, input_masks):\r\n\r\n/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py in _infer_output_signature(self, inputs, args, kwargs, input_masks)\r\n    884           # overridden).\r\n    885           # TODO(kaftan): do we maybe_build here, or have we already done it?\r\n--> 886           self._maybe_build(inputs)\r\n    887           inputs = self._maybe_cast_inputs(inputs)\r\n    888           outputs = call_fn(inputs, *args, **kwargs)\r\n\r\n/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py in _maybe_build(self, inputs)\r\n   2657         # operations.\r\n   2658         with tf_utils.maybe_init_scope(self):\r\n-> 2659           self.build(input_shapes)  # pylint:disable=not-callable\r\n   2660       # We must set also ensure that the layer is marked as built, and the build\r\n   2661       # shape is stored since user defined build functions may not be calling\r\n\r\n/usr/local/lib/python3.7/dist-packages/keras/layers/recurrent.py in build(self, input_shape)\r\n    575     if isinstance(self.cell, Layer) and not self.cell.built:\r\n    576       with backend.name_scope(self.cell.name):\r\n--> 577         self.cell.build(step_input_shape)\r\n    578         self.cell.built = True\r\n    579 \r\n\r\n/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py in wrapper(instance, input_shape)\r\n    257     if input_shape is not None:\r\n    258       input_shape = convert_shapes(input_shape, to_tuples=True)\r\n--> 259     output_shape = fn(instance, input_shape)\r\n    260     # Return shapes from `fn` as TensorShapes.\r\n    261     if output_shape is not None:\r\n\r\n/usr/local/lib/python3.7/dist-packages/keras/layers/recurrent.py in build(self, input_shape)\r\n   1796         regularizer=self.kernel_regularizer,\r\n   1797         constraint=self.kernel_constraint,\r\n-> 1798         caching_device=default_caching_device)\r\n   1799     self.recurrent_kernel = self.add_weight(\r\n   1800         shape=(self.units, self.units * 3),\r\n\r\n/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py in add_weight(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, **kwargs)\r\n    661         synchronization=synchronization,\r\n    662         aggregation=aggregation,\r\n--> 663         caching_device=caching_device)\r\n    664     if regularizer is not None:\r\n    665       # TODO(fchollet): in the future, this should be handled at the\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py in _add_variable_with_custom_getter(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\r\n    816         dtype=dtype,\r\n    817         initializer=initializer,\r\n--> 818         **kwargs_for_getter)\r\n    819 \r\n    820     # If we set an initializer and the variable processed it, tracking will not\r\n\r\n/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer_utils.py in make_variable(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\r\n    127       synchronization=synchronization,\r\n    128       aggregation=aggregation,\r\n--> 129       shape=variable_shape if variable_shape else None)\r\n    130 \r\n    131 \r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py in __call__(cls, *args, **kwargs)\r\n    264   def __call__(cls, *args, **kwargs):\r\n    265     if cls is VariableV1:\r\n--> 266       return cls._variable_v1_call(*args, **kwargs)\r\n    267     elif cls is Variable:\r\n    268       return cls._variable_v2_call(*args, **kwargs)\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py in _variable_v1_call(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\r\n    225         synchronization=synchronization,\r\n    226         aggregation=aggregation,\r\n--> 227         shape=shape)\r\n    228 \r\n    229   def _variable_v2_call(cls,\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py in getter(**kwargs)\r\n     65 \r\n     66   def getter(**kwargs):\r\n---> 67     return captured_getter(captured_previous, **kwargs)\r\n     68 \r\n     69   return getter\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py in creator_with_resource_vars(next_creator, **kwargs)\r\n   2125         checkpoint_restore_uid = None\r\n   2126 \r\n-> 2127       created = self._create_variable(next_creator, **kwargs)\r\n   2128 \r\n   2129       if checkpoint_restore_uid is not None:\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/tpu_strategy.py in _create_variable(self, next_creator, **kwargs)\r\n   1167         self._container_strategy(), _real_mirrored_creator,\r\n   1168         distribute_utils.TPU_VARIABLE_CLASS_MAPPING,\r\n-> 1169         distribute_utils.TPU_VARIABLE_POLICY_MAPPING, **kwargs)\r\n   1170 \r\n   1171   def _gather_to_implementation(self, value, destinations, axis, options):\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_utils.py in create_mirrored_variable(strategy, real_mirrored_creator, class_mapping, policy_mapping, **kwargs)\r\n    306   # here.\r\n    307   with tape.stop_recording():\r\n--> 308     value_list = real_mirrored_creator(**kwargs)\r\n    309     # MirroredVariable is recreated during saved_model loading, and its\r\n    310     # component variables (value_list) will have None initializer. We\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/tpu_strategy.py in _real_mirrored_creator(**kwargs)\r\n   1146             with maybe_init_scope():\r\n   1147               initial_value = initial_value() if callable(\r\n-> 1148                   initial_value) else initial_value\r\n   1149 \r\n   1150           if i > 0:\r\n\r\n/usr/local/lib/python3.7/dist-packages/keras/initializers/initializers_v2.py in __call__(self, shape, dtype, **kwargs)\r\n    515     else:\r\n    516       limit = math.sqrt(3.0 * scale)\r\n--> 517       return self._random_generator.random_uniform(shape, -limit, limit, dtype)\r\n    518 \r\n    519   def get_config(self):\r\n\r\n/usr/local/lib/python3.7/dist-packages/keras/initializers/initializers_v2.py in random_uniform(self, shape, minval, maxval, dtype)\r\n    971       op = tf.random.uniform\r\n    972     return op(\r\n--> 973         shape=shape, minval=minval, maxval=maxval, dtype=dtype, seed=self.seed)\r\n    974 \r\n    975   def truncated_normal(self, shape, mean, stddev, dtype):\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)\r\n    204     \"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\r\n    205     try:\r\n--> 206       return target(*args, **kwargs)\r\n    207     except (TypeError, ValueError):\r\n    208       # Note: convert_to_eager_tensor currently raises a ValueError, not a\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/random_ops.py in random_uniform(shape, minval, maxval, dtype, seed, name)\r\n    300     maxval_is_one = isinstance(maxval, int) and maxval == 1\r\n    301     if not minval_is_zero or not maxval_is_one or dtype.is_integer:\r\n--> 302       minval = ops.convert_to_tensor(minval, dtype=dtype, name=\"min\")\r\n    303       maxval = ops.convert_to_tensor(maxval, dtype=dtype, name=\"max\")\r\n    304     seed1, seed2 = random_seed.get_seed(seed)\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py in wrapped(*args, **kwargs)\r\n    161         with Trace(trace_name, **trace_kwargs):\r\n    162           return func(*args, **kwargs)\r\n--> 163       return func(*args, **kwargs)\r\n    164 \r\n    165     return wrapped\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\r\n   1564 \r\n   1565     if ret is None:\r\n-> 1566       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n   1567 \r\n   1568     if ret is NotImplemented:\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_conversion_registry.py in _default_conversion_function(***failed resolving arguments***)\r\n     50 def _default_conversion_function(value, dtype, name, as_ref):\r\n     51   del as_ref  # Unused.\r\n---> 52   return constant_op.constant(value, dtype, name=name)\r\n     53 \r\n     54 \r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py in constant(value, dtype, shape, name)\r\n    270   \"\"\"\r\n    271   return _constant_impl(value, dtype, shape, name, verify_shape=False,\r\n--> 272                         allow_broadcast=True)\r\n    273 \r\n    274 \r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)\r\n    281       with trace.Trace(\"tf.constant\"):\r\n    282         return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n--> 283     return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n    284 \r\n    285   g = ops.get_default_graph()\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py in _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n    306 def _constant_eager_impl(ctx, value, dtype, shape, verify_shape):\r\n    307   \"\"\"Creates a constant on the current device.\"\"\"\r\n--> 308   t = convert_to_eager_tensor(value, ctx, dtype)\r\n    309   if shape is None:\r\n    310     return t\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py in convert_to_eager_tensor(value, ctx, dtype)\r\n    104       dtype = dtypes.as_dtype(dtype).as_datatype_enum\r\n    105   ctx.ensure_initialized()\r\n--> 106   return ops.EagerTensor(value, ctx.device_name, dtype)\r\n    107 \r\n    108 \r\n\r\nNotFoundError: '_EagerConst' is neither a type of a primitive operation nor a name of a function registered in binary running on n-c9063562-w-0. Make sure the operation or function is registered in the binary running in this process.```", "@sushreebarsa Using the default Colab TPU environment with TF 2.5, can you reproduce the issue (60x decrease/increase in training speed) with the provided sample code? ", "@sanatmpa1  Was able to reproduce the issue (60x decrease/increase in training speed) using the default Colab TPU environment with TF 2.5 ,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/94852cc44f4a3dd53256f48a38178ed4/tpu-performance-issue.ipynb#scrollTo=P2EL671fL1Sg) for reference .I also tried the code on colab using latest TF v2.6.0 and got the error as mentioned in above [comment](https://github.com/tensorflow/tensorflow/issues/51485#issuecomment-898564779), please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/7415a3ea10359644eab420f41f620f3d/untitled384.ipynb) for your reference .Thank you!", "@jvishnuvardhan The same issue (60x decrease/increase) of training performance also occurs on the (recently introduced) TPU-VM. The following code is used to demonstrate the issue, uncomment the line with dummy OP to get a 60x training speed increase.\r\n\r\n__Create a TPU-VM and connect with SSH__\r\n```\r\ngcloud alpha compute tpus tpu-vm create tpu_vm_test \\\r\n  --zone=europe-west4-a \\\r\n  --accelerator-type=v2-8 \\\r\n  --preemptible \\\r\n  --version=v2-alpha\r\n\r\ngcloud alpha compute tpus tpu-vm ssh tpu_vm_test \\\r\n  --zone europe-west4-a\r\n```\r\n\r\n__On the TPU-VM run the following with python3:__\r\n```\r\nimport os\r\nimport tensorflow as tf\r\n\r\nprint(f'tensorflow version {tf.__version__}')\r\n\r\nn_batch = 1024\r\nn_seq_len = 2048\r\nn_bins = 64\r\nn_nodes = 128\r\n\r\ndef create_dataset():\r\n    ds = tf.data.Dataset.from_tensor_slices([tf.ones((n_batch, n_seq_len, n_bins))])\r\n    def rand_batch(x):\r\n        return tf.random.uniform((1,))*x, tf.random.uniform((1,))*x\r\n    return ds.map(rand_batch).repeat()\r\n\r\ndef create_model():\r\n  x = tf.keras.Input(shape=(n_seq_len, n_bins))\r\n  g = tf.keras.layers.GRU(n_nodes, return_sequences=True)(x)\r\n  g = tf.keras.layers.GRU(n_nodes, return_sequences=True)(g)\r\n  g = tf.keras.layers.GRU(n_nodes, return_sequences=True)(g)\r\n  g = tf.keras.layers.GRU(n_nodes, return_sequences=True)(g)\r\n  # g = 1 * g # dummy OP\r\n  g = tf.keras.layers.Dense(n_bins, activation='sigmoid')(g)\r\n  return tf.keras.Model(inputs=[x], outputs=[g])\r\n\r\ncluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='local')\r\ntf.tpu.experimental.initialize_tpu_system(cluster_resolver)\r\nstrategy = tf.distribute.TPUStrategy(cluster_resolver)\r\nprint(\"All devices: \", tf.config.list_logical_devices('TPU'))\r\n\r\nwith strategy.scope():\r\n\r\n  model = create_model()\r\n  model.summary()\r\n  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse')\r\n  model.fit(\r\n      create_dataset(),\r\n      steps_per_epoch=512,\r\n      epochs=10,\r\n      verbose=1\r\n  )\r\n```\r\n\r\n(note that the TPU-VM uses TF 2.6.0, however the code does not crash like Colab TPU 2.6.0)", "Sorry @jvishnuvardhan , I don't work on TF anymore. Reassigning back to you to re-triage. Sorry!", "This issue seems to be fixed in TF 2.7.0 :)"]}, {"number": 51483, "title": "script exits after starting first epoch", "body": "\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.5.0\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CUDA : 11.2, cuDNN : 8.1.0.77\r\n- GPU model and memory: GEFORCE RTX 3090\r\n\r\n\r\n**Describe the problem**\r\npython code is exiting after starting first epoch with the exit code error \r\n\"Process finished with exit code -1073740791 (0xC0000409)\"\r\nwhen I debugged it is observed that code is exiting when \r\nfunction \r\ntensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n                                        inputs, attrs, num_outputs)\r\nexecuting\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\njust installed all the packages and updated the script for tensorflow 2.5.0 and using pycharm started running the script\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n2021-08-13 14:28:59.820107: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudart64_110.dll\r\n3670\r\nFound 3670 files belonging to 5 classes.\r\nUsing 2936 files for training.\r\n2021-08-13 14:29:02.684243: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library nvcuda.dll\r\n2021-08-13 14:29:02.767638: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \r\npciBusID: 0000:15:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\r\ncoreClock: 1.695GHz coreCount: 82 deviceMemorySize: 24.00GiB deviceMemoryBandwidth: 871.81GiB/s\r\n2021-08-13 14:29:02.768344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \r\npciBusID: 0000:2d:00.0 name: Quadro P2000 computeCapability: 6.1\r\ncoreClock: 1.4805GHz coreCount: 8 deviceMemorySize: 5.00GiB deviceMemoryBandwidth: 130.53GiB/s\r\n2021-08-13 14:29:02.769004: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudart64_110.dll\r\n2021-08-13 14:29:02.815082: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cublas64_11.dll\r\n2021-08-13 14:29:02.815441: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cublasLt64_11.dll\r\n2021-08-13 14:29:02.820867: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cufft64_10.dll\r\n2021-08-13 14:29:02.823516: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library curand64_10.dll\r\n2021-08-13 14:29:02.836259: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cusolver64_11.dll\r\n2021-08-13 14:29:02.840952: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cusparse64_11.dll\r\n2021-08-13 14:29:02.842131: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudnn64_8.dll\r\n2021-08-13 14:29:02.842526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1\r\n2021-08-13 14:29:02.843140: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-08-13 14:29:03.199398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \r\npciBusID: 0000:15:00.0 name: NVIDIA GeForce RTX 3090 computeCapability: 8.6\r\ncoreClock: 1.695GHz coreCount: 82 deviceMemorySize: 24.00GiB deviceMemoryBandwidth: 871.81GiB/s\r\n2021-08-13 14:29:03.200104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \r\npciBusID: 0000:2d:00.0 name: Quadro P2000 computeCapability: 6.1\r\ncoreClock: 1.4805GHz coreCount: 8 deviceMemorySize: 5.00GiB deviceMemoryBandwidth: 130.53GiB/s\r\n2021-08-13 14:29:03.200791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1\r\n2021-08-13 14:29:04.474905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-08-13 14:29:04.475271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 1 \r\n2021-08-13 14:29:04.475507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N N \r\n2021-08-13 14:29:04.475734: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 1:   N N \r\n2021-08-13 14:29:04.476211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 18786 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:15:00.0, compute capability: 8.6)\r\n2021-08-13 14:29:04.478811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 3625 MB memory) -> physical GPU (device: 1, name: Quadro P2000, pci bus id: 0000:2d:00.0, compute capability: 6.1)\r\nFound 3670 files belonging to 5 classes.\r\nUsing 734 files for validation.\r\n['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\r\n2021-08-13 14:29:05.999112: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\r\n(16, 180, 180, 3)\r\n(16,)\r\n0.0 0.9627812\r\nModel: \"sequential\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nrescaling_1 (Rescaling)      (None, 180, 180, 3)       0         \r\n_________________________________________________________________\r\nconv2d (Conv2D)              (None, 180, 180, 16)      448       \r\n_________________________________________________________________\r\nmax_pooling2d (MaxPooling2D) (None, 90, 90, 16)        0         \r\n_________________________________________________________________\r\nconv2d_1 (Conv2D)            (None, 90, 90, 32)        4640      \r\n_________________________________________________________________\r\nmax_pooling2d_1 (MaxPooling2 (None, 45, 45, 32)        0         \r\n_________________________________________________________________\r\nconv2d_2 (Conv2D)            (None, 45, 45, 64)        18496     \r\n_________________________________________________________________\r\nmax_pooling2d_2 (MaxPooling2 (None, 22, 22, 64)        0         \r\n_________________________________________________________________\r\nflatten (Flatten)            (None, 30976)             0         \r\n_________________________________________________________________\r\ndense (Dense)                (None, 128)               3965056   \r\n_________________________________________________________________\r\ndense_1 (Dense)              (None, 5)                 645       \r\n=================================================================\r\nTotal params: 3,989,285\r\nTrainable params: 3,989,285\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\nEpoch 1/10\r\n2021-08-13 14:29:08.463012: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudnn64_8.dll\r\n\r\nProcess finished with exit code -1073740791 (0xC0000409)\r\n", "comments": ["@sujithsudhi,\r\n\r\nPlease share a simple standalone code to expedite the process. Thanks!", "Tried with same code from tensorflow 2.5.0 examples, but got the same\r\n\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\nimport os\r\nimport PIL\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\nfrom tensorflow.keras.models import Sequential\r\nimport pathlib\r\ndataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\r\ndata_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)\r\ndata_dir = pathlib.Path(data_dir)\r\nimage_count = len(list(data_dir.glob('*/*.jpg')))\r\nprint(image_count)\r\nroses = list(data_dir.glob('roses/*'))\r\nPIL.Image.open(str(roses[0]))\r\nPIL.Image.open(str(roses[1]))\r\ntulips = list(data_dir.glob('tulips/*'))\r\nPIL.Image.open(str(tulips[0]))\r\nPIL.Image.open(str(tulips[1]))\r\nbatch_size = 16\r\nimg_height = 180\r\nimg_width = 180\r\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\r\n  data_dir,\r\n  validation_split=0.2,\r\n  subset=\"training\",\r\n  seed=123,\r\n  image_size=(img_height, img_width),\r\n  batch_size=batch_size)\r\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\r\n  data_dir,\r\n  validation_split=0.2,\r\n  subset=\"validation\",\r\n  seed=123,\r\n  image_size=(img_height, img_width),\r\n  batch_size=batch_size)\r\nclass_names = train_ds.class_names\r\nprint(class_names)\r\nimport matplotlib.pyplot as plt\r\n\r\nplt.figure(figsize=(10, 10))\r\n#for images, labels in train_ds.take(1):\r\n#  for i in range(9):\r\n#    ax = plt.subplot(3, 3, i + 1)\r\n#    plt.imshow(images[i].numpy().astype(\"uint8\"))\r\n#    plt.title(class_names[labels[i]])\r\n#    plt.axis(\"off\")\r\nfor image_batch, labels_batch in train_ds:\r\n  print(image_batch.shape)\r\n  print(labels_batch.shape)\r\n  break\r\nAUTOTUNE = tf.data.AUTOTUNE\r\n\r\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\r\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\r\nnormalization_layer = layers.experimental.preprocessing.Rescaling(1./255)\r\nnormalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\r\nimage_batch, labels_batch = next(iter(normalized_ds))\r\nfirst_image = image_batch[0]\r\n# Notice the pixels values are now in `[0,1]`.\r\nprint(np.min(first_image), np.max(first_image))\r\nnum_classes = 5\r\n\r\nmodel = Sequential([\r\n  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\r\n  layers.Conv2D(16, 3, padding='same', activation='relu'),\r\n  layers.MaxPooling2D(),\r\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\r\n  layers.MaxPooling2D(),\r\n  layers.Conv2D(64, 3, padding='same', activation='relu'),\r\n  layers.MaxPooling2D(),\r\n  layers.Flatten(),\r\n  layers.Dense(128, activation='relu'),\r\n  layers.Dense(num_classes)\r\n])\r\nmodel.compile(optimizer='adam',\r\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n              metrics=['accuracy'])\r\nmodel.summary()\r\nepochs=10\r\nhistory = model.fit(\r\n  train_ds,\r\n  validation_data=val_ds,\r\n  epochs=epochs\r\n)\r\nacc = history.history['accuracy']\r\nval_acc = history.history['val_accuracy']\r\n\r\nloss = history.history['loss']\r\nval_loss = history.history['val_loss']\r\n\r\nepochs_range = range(epochs)\r\n\r\nplt.figure(figsize=(8, 8))\r\nplt.subplot(1, 2, 1)\r\nplt.plot(epochs_range, acc, label='Training Accuracy')\r\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\r\nplt.legend(loc='lower right')\r\nplt.title('Training and Validation Accuracy')\r\n\r\nplt.subplot(1, 2, 2)\r\nplt.plot(epochs_range, loss, label='Training Loss')\r\nplt.plot(epochs_range, val_loss, label='Validation Loss')\r\nplt.legend(loc='upper right')\r\nplt.title('Training and Validation Loss')\r\nplt.show()", "@sujithsudhi,\r\n\r\nFormatting in the above code is not clear, and can you share a colab gist for the same? Thanks!", "I just used the script from the TensorFlow examples as a test script\r\n\r\nhttps://www.tensorflow.org/tutorials/images/classification", "@sujithsudhi,\r\n\r\nI am able to run the code fine with colab and take a look at the [gist here](https://colab.research.google.com/gist/sanatmpa1/e41cb7840580a647bcd3cfb3fceb462c/classification.ipynb). Can you try installing the latest stable version of Tensorflow `2.6` and let us know if the issue still persists? Take a look at these links for your reference [link1](https://www.tensorflow.org/install), [link2](https://www.tensorflow.org/install/gpu). Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "@sanatmpa1,\r\n\r\nI have update the Tensorflow to 2.6 but still the same error. when I use Qadro P2000 (with its dependencies) training is fine.\r\nanybody is using GEFORCE RTX 3090.?", "@sujithsudhi,\r\n\r\nCan you please take a look at this similar issue #45285, also you can checkout this #46673, #45170 which discussed about the similar problem. let me know if it helps. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51483\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51483\">No</a>\n"]}, {"number": 51482, "title": "same issue with CUDA=10.0 CUDNN=7.4 Tensorflow=1.14.0", "body": "same issue with CUDA=10.0 CUDNN=7 Tensorflow=1.14.0\r\nstuck at `I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcublas.so.10`\r\n\r\n", "comments": ["@YongyuG We see that the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose) has not been filled, could you please do so as it helps us analyse the issue.We could see that you are using TF v1.14.0 which is out of support window kindly try to upgrade the tensorflow version to latest stable version 2.6.0 and let us know if the issue persists ? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 51481, "title": "[tflite] add same scale constraint for mirror pad", "body": "add `SameOperandsAndResultsScale` to MirrorPad so that when the new MLIR quantizer is used for post-training quantization, all\r\nquantized mirror_pad will have the same quantization scaled for inputs and outputs (as what the old non-MLIR one does).\r\n\r\ncf. the constrain in old [quantizer](https://github.com/tensorflow/tensorflow/blob/r2.6/tensorflow/lite/tools/optimize/operator_property.cc#L1020-L1026)", "comments": ["@teijeong could you review this change?"]}, {"number": 51480, "title": "add int8 support for tf.tile", "body": "add int8 support for tf.tile otherwise there is an error after int8 quantization", "comments": ["@goexle could you provide some contexts to understand why this op is needed?", "Fyi @thaink @teijeong ", "@goexle We are having an internal commit for this as well.\r\n\r\n@abattery our internal cl is in better state since it also add quantization support and increase the op version.", "@thaink thanks for mentioning. Do you know when your internal commit will be pushed to master?", "Not sure about that yet but It is not a complicated one so I hope it will be landed soon.\r\nI'll let you know then.", "@goexle Can you describe a bit about your use-case?\r\nEx: What model are you trying to run and why does it need int8?", "@thaink Yes sure. I want to quantize a model which is using the tf.tile operation. And I want to quantize it to int8.\r\n", "@goexle  Any update on this PR? Please. Thanks!", "@gbaned do you need further explanation about the use case or the model type beyond the mentioned use case?\nThe model is a modified version of TDNN for speech recognition.\nIf you need anything else, please let me know", "> @gbaned do you need further explanation about the use case or the model type beyond the mentioned use case? The model is a modified version of TDNN for speech recognition. If you need anything else, please let me know\r\n\r\n@goexle Thank you for the update.", "@thaink Can you please review this PR ? Thanks!", "int8 support is already added. If you are interested in int16 support too, please take a look at https://github.com/tensorflow/tensorflow/pull/50424/"]}, {"number": 51479, "title": "ValueError: Tensor data is null. Run allocate_tensors() first ", "body": "class ImageEncoder(object):\r\n\r\n    def __init__(self, checkpoint_filename, input_name=\"images\",\r\n                 output_name=\"features\"):\r\n        self.session = tf.Session()\r\n        interpreter = tf.lite.Interpreter(model_path=\"model.tflite\")\r\n        interpreter.allocate_tensors()\r\n        self.input_var = interpreter.get_tensor(0)\r\n        self.output_var = interpreter.get_tensor(130)\r\n\r\n\r\n  File \"\\tools\\generate_detections.py\", line 115, in __init__\r\n    self.output_var = interpreter.get_tensor(130)\r\n  File \"C:\\envs\\yolov4-cpu\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py\", line 810, in get_tensor\r\n    return self._interpreter.GetTensor(tensor_index)\r\n_**ValueError: Tensor data is null. Run allocate_tensors() first**_\r\n", "comments": ["@rajeshdhanda ,\r\n\r\nIn order to expedite the trouble-shooting process, could you please provide complete code and the TensorFlow version you are using.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51479\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51479\">No</a>\n", "can anyone elaborate how the issue was resolved? i am facing the same error while trying to extract weights from tflite model."]}]