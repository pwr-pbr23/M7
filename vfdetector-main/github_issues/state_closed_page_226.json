[{"number": 47796, "title": "my changes => your changes", "body": "For consistency with the rest of the file's content.", "comments": []}, {"number": 47795, "title": "distribution strategy in tensorflow", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1.  It must be a bug, a feature request, or a significant problem with the\r\n    documentation (for small docs fixes please send a PR instead).\r\n2.  The form below must be filled out.\r\n3.  It shouldn't be a TensorBoard issue. Those go\r\n    [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**:\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**:\r\n-   **TensorFlow installed from (source or binary)**:\r\n-   **TensorFlow version (use command below)**:\r\n-   **Python version**:\r\n-   **Bazel version (if compiling from source)**:\r\n-   **GCC/Compiler version (if compiling from source)**:\r\n-   **CUDA/cuDNN version**:\r\n-   **GPU model and memory**:\r\n-   **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["Closing as spam."]}, {"number": 47794, "title": "undefined symbol: _ZN10tensorflow8OpKernel11TraceStringEPNS_15OpKernelContextEb", "body": "This is an issue reported earlier and it remains for the following versions of tensorflow and keras:\r\n\r\nSuccessfully installed tensorflow-2.4.1\r\n\r\nSuccessfully installed keras-2.4.3\r\n\r\nWhen trying to execute previously well-functioning keras/tensorflow-pythoncode output is: \r\n\r\ntensorflow.python.framework.errors_impl.NotFoundError: /usr/local/lib/python3.8/dist-packages/tensorflow/core/kernels/libtfkernel_sobol_op.so: undefined symbol: _ZN10tensorflow8OpKernel11TraceStringEPNS_15OpKernelContextEb\r\n\r\nAre the above versions of tensorflow and keras incompatible? Is a downgrade of tensorflow requried, and if so to which version ?\r\n", "comments": ["@bgcgh,\r\nIn order to expedite the trouble-shooting process, could you please provide the following information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nalong with the compete code and dataset you are using. Thanks!", "Also, please try installing TensorFlow in a new virtual environment and check if it works. Thanks!", "Hello Abhilash,\n\n\nthank you for looking into the issue. It causes a real problem because if a downgrade is necessary that involves a requirement of certain libraries (such as libcublas.so.10, libcusolver.so.10, libcusparse.so.10) from CUDA 10.\n\n\nOS Ubuntu 20.04\n\nTensorflow 2.4.1 installed via pip3\n\nPython 3.8\n\nCUDA 11.1.1/cuDNN8\n\nGPU GeForce GTX 1660 Super, 6 GB DDRAM\n\n\nThe python code has been working well with Tensorflow 2.3.1.\n\n\nBest regards,\n\nbgcgh\n\n\n\n\n\n\n________________________________\nFrom: Abhilash Mahendrakar ***@***.***>\nSent: 15 March 2021 16:59:21\nTo: tensorflow/tensorflow\nCc: Bo Cartling; Mention\nSubject: Re: [tensorflow/tensorflow] undefined symbol: _ZN10tensorflow8OpKernel11TraceStringEPNS_15OpKernelContextEb (#47794)\n\n\nAlso, please try installing TensorFlow in a new virtual environment and check if it works. Thanks!\n\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub<https://github.com/tensorflow/tensorflow/issues/47794#issuecomment-799535316>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ATHCUZLH3TVBMOS7ZMSQQL3TDYVFTANCNFSM4ZEYSY5A>.\n", "> The python code has been working well with Tensorflow 2.3.1.\r\n\r\n@bgcgh,\r\nCould you please provide the code you are running, so that we can reproduce the issue on our end?\r\n\r\nI was able to run a minimal code snippet using TensorFlow v2.4.1 and Keras v2.4.3. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/7c769d007fff52882e3cb7f81adfabea/47794.ipynb#scrollTo=4ONtdNs1cI0K). Thanks!", "Hello Abhilash,\n\n\nthank you very much again for looking into this issue. I hope the most relevant part of my code for a multiclass, multilabel temporal sequence problem is of some assistance to you:\n\n\n\nimport keras\nfrom keras import layers\n\nmodel=keras.models.Sequential()\nmodel.add(layers.LSTM(512,input_shape=(len_seq,span),return_sequences=True))\nmodel.add(layers.LSTM(512))\nmodel.add(layers.Dense(span,activation='sigmoid'))\n\nmodel.summary()\n\noptimizer=keras.optimizers.RMSprop(lr=0.001)\nmodel.compile(loss='binary_crossentropy',optimizer=optimizer,metrics=['acc'])\n\nhistory=model.fit(train_in,train_out,batch_size=32,epochs=10,\n                  validation_data=(valid_in,valid_out))\n\n\nTo be able to continue my work right now, I have had to downgrade to tensorflow 2.3 and install CUDA 10 in parallel with CUDA 11.1 for required libraries.\n\n\nBest regards,\n\nbgcgh\n\n________________________________\nFrom: Abhilash Mahendrakar ***@***.***>\nSent: 23 March 2021 19:59:16\nTo: tensorflow/tensorflow\nCc: Bo Cartling; Mention\nSubject: Re: [tensorflow/tensorflow] undefined symbol: _ZN10tensorflow8OpKernel11TraceStringEPNS_15OpKernelContextEb (#47794)\n\n\nThe python code has been working well with Tensorflow 2.3.1.\n\n@bgcgh<https://github.com/bgcgh>,\nCould you please provide the code you are running, so that we can reproduce the issue on our end?\n\nI was able to run a minimal code snippet using TensorFlow v2.4.1 and Keras v2.4.3. Please find the gist of it here<https://colab.research.google.com/gist/amahendrakar/7c769d007fff52882e3cb7f81adfabea/47794.ipynb#scrollTo=4ONtdNs1cI0K>. Thanks!\n\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub<https://github.com/tensorflow/tensorflow/issues/47794#issuecomment-805153695>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ATHCUZOHZBX4JETWYNNNF2LTFDQIJANCNFSM4ZEYSY5A>.\n", "@bgcgh,\r\nOn running the code, I am facing an error stating `NameError: name 'len_seq' is not defined`. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/7a1db9136cf3f4443b37ec2ec72c6b94/47794.ipynb).\r\n\r\nIn order to reproduce the issue reported here, could you please provide the complete code and the dataset you are using.\r\n\r\nAlso, instead of `import keras` please use `from tensorflow import keras` and check if it helps. \r\n\r\nThanks!", "I provided the complete code defining the model for your investigation of possible model-dependence of the tensorboard problem reported. The program runs well with tensorboard 2.3.1 as I have reported, so there should be no problem with the code or dataset (which I regrettably am unable to distribute). Since I have been forced to downgrade to  tensorboard 2.3.1 as well as to CUDA 11, it is not possible for me to perform the proposed test under the required conditions. Apologies for not being able to meet all your requests.\n\n________________________________\nFrom: Abhilash Mahendrakar ***@***.***>\nSent: 31 March 2021 21:10:43\nTo: tensorflow/tensorflow\nCc: Bo Cartling; Mention\nSubject: Re: [tensorflow/tensorflow] undefined symbol: _ZN10tensorflow8OpKernel11TraceStringEPNS_15OpKernelContextEb (#47794)\n\n\n@bgcgh<https://github.com/bgcgh>,\nOn running the code, I am facing an error stating NameError: name 'len_seq' is not defined. Please find the gist of it here<https://colab.research.google.com/gist/amahendrakar/7a1db9136cf3f4443b37ec2ec72c6b94/47794.ipynb>.\n\nIn order to reproduce the issue reported here, could you please provide the complete code and the dataset you are using.\n\nAlso, instead of import keras please use from tensorflow import keras and check if it helps.\n\nThanks!\n\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub<https://github.com/tensorflow/tensorflow/issues/47794#issuecomment-811358371>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ATHCUZI4YGFHOP4AMKQEII3TGNXTHANCNFSM4ZEYSY5A>.\n", "> so there should be no problem with the code or dataset (which I regrettably am unable to distribute)\r\n\r\nWithout a reproducible code, it would be difficult for us to debug the issue. In this case, you can provide a dummy dataset and code to reproduce the error.\r\n\r\n \r\n> Also, please try installing TensorFlow in a new virtual environment and check if it works. Thanks!\r\n\r\nCould you please confirm if you are facing the same issue in a virtual environment as well? Thanks!", "Since, due to the current problem, I have had to downgrade to tensorflow version 2.3.1 as well as to CUDA 11.1 (and CUDA 10 for certain libraries) it is regrettably not possible to perform the tests you propose. In my current configuration, everything (code and datasets) works fine, which is of course the reason I tentatively ascribed the problem to the 2.4.1 version of tensorflow. There is perhaps a chance that the problem will be gone in the next version of tensorflow.\n\n________________________________\nFrom: Abhilash Mahendrakar ***@***.***>\nSent: 09 April 2021 17:48:31\nTo: tensorflow/tensorflow\nCc: Bo Cartling; Mention\nSubject: Re: [tensorflow/tensorflow] undefined symbol: _ZN10tensorflow8OpKernel11TraceStringEPNS_15OpKernelContextEb (#47794)\n\n\nso there should be no problem with the code or dataset (which I regrettably am unable to distribute)\n\nWithout a reproducible code, it would be difficult for us to debug the issue. In this case, you can provide a dummy dataset and code to reproduce the error.\n\nAlso, please try installing TensorFlow in a new virtual environment and check if it works. Thanks!\n\nCould you please confirm if you are facing the same issue in a virtual environment as well? Thanks!\n\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub<https://github.com/tensorflow/tensorflow/issues/47794#issuecomment-816776173>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ATHCUZIAP4C2VG7FZNP6FALTH4OU7ANCNFSM4ZEYSY5A>.\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "> Since, due to the current problem, I have had to downgrade to tensorflow version 2.3.1 as well as to CUDA 11.1 (and CUDA 10 for certain libraries) it is regrettably not possible to perform the tests you propose.\r\n\r\n@bgcgh,\r\nThank you for the update. Can we close this issue for now?\r\n\r\nPlease let us know if you are facing the same error with the latest version of TensorFlow v2.5.0rc1 as well. Thanks!", "This seems to have been a problem for other people and for quite some time, it is really unfortunate that it still remains unresolved. I apologize that I could not provide more than the model that generates the issue.\n\n\nBest regards,\n\nbgcgh\n\n________________________________\nFrom: Abhilash Mahendrakar ***@***.***>\nSent: 19 April 2021 08:39:47\nTo: tensorflow/tensorflow\nCc: Bo Cartling; Mention\nSubject: Re: [tensorflow/tensorflow] undefined symbol: _ZN10tensorflow8OpKernel11TraceStringEPNS_15OpKernelContextEb (#47794)\n\n\nSince, due to the current problem, I have had to downgrade to tensorflow version 2.3.1 as well as to CUDA 11.1 (and CUDA 10 for certain libraries) it is regrettably not possible to perform the tests you propose.\n\n@bgcgh<https://github.com/bgcgh>,\nThank you for the update. Can we close this issue for now?\n\nPlease let us know if you are facing the same error with the latest version of TensorFlow v2.5.0rc1 as well. Thanks!\n\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub<https://github.com/tensorflow/tensorflow/issues/47794#issuecomment-822212039>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ATHCUZKQERBD7WCO5EQWQKDTJPF3HANCNFSM4ZEYSY5A>.\n", "@bgcgh,\r\nClosing the issue for now. Please feel free to re-open if you can share a reproducible code with us. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47794\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47794\">No</a>\n", "You could just delete `tensorflow/core/kernels/libtfkernel_sobol_op.so` inside the site-package folder. This kernel op is unlikely to be used by a normal DNN. \r\n\r\nI am guessing that a proper fix for the TF team is to figure out what dynamic library `https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/sobol_op.cc` is using, and why the particular cuda/linux distribution combo didn't have it, because from the first glance this code has nothing to do with CUDA and is purely CPU-based.\r\n\r\nRef: https://en.wikipedia.org/wiki/Sobel_operator ", "Thank you very much xuy for kindly sharing your helpful conclusions! I will certainly apply your advice when having upgraded my system back again.\r\n\r\nBest regards,\r\nbgcgh"]}, {"number": 47793, "title": "  programs that use this library are impossible to understand", "body": "My cpu has a frequency of 3GHz, that is, electric current runs through it's circuitry 3 thousand million times per second, in something more than 2 seconds it cycles once for every person in the world, this of course is an ordinary modern computer, the small computers in our pockets have the same power. 25 years ago a computer with a thirtiedth of the power beat the strongest chess player in the world taking no more than a couple of minutes per move. With one second of that 1996 cpu I can find the first thousand prime numbers, I can figure out how much sleep I get on average, I can find out the geometry of an ozone atom.  \r\n\r\nNow why in the world does a program take 10 hours to build? 3 million million cycles to compile a program? And this is just the beggining, tensorflow models will then be trained, so they will continue to squeeze out a cpu like it's a slave until something useful comes out of the other end. We are spending a small eternity to compile a compiler, which then will spend as many small eternities as money can buy to obtain a result, without care for the way it is accomplished.\r\n\r\nCan we still consider this open source? Will someone be able to understand this code, and if they can, will they be able to understand the binaries, and if they manage to do that, will they ever understand the trained models.\r\nThe open source movement tries to understand the software that we build and use, but by turning the assembly line up to 11, this approach is effectively creating logic/code faster than we can analyze it. There's definitely applications for such code and human systems will cope, mainly by treating these programs as a black box and studying the systems they interface with instead, but I just wanted to expose that, altough open source, these machine learning libraries are blueprints to build a machine that generates opaque systems, which is kind of a paradox.", "comments": ["@TZubiri \r\nFirstly, that's a lot of philosophy in one post. \ud83d\ude02 \r\nWhat I think, is that seeing and understanding what's under the hood is  matter of experience. When one has complex systems like this library itself, one cannot expect to see and understand the code at the first glance. But if you give the time and energy, you will find yourself completely understanding the code and logic behind TensorFlow and ML in general. \r\nNot all people have the luxury to do what I just mentioned. They need results and they need them fast. We may be generating \"opaque systems\", as you preferred to put it, without knowing what the weights represent, but we do understand the logic they are created by. I think that's a good start for a field like ML, which has been mainstream for around for two or three decades, as opposed to something like mathematics and physics, which are around for centuries or millenniums.  \r\nFinally, I'd like to say that the libraries that make and run ML are changing the world as we speak. And unfortunately, finding the geometry of ozone doesn't change the world, after all.", "Thanks for the response Aditya. I'm afraid I was too cynical and critical yesterday without devoting enough effort to first understand the system. The truth is that I was simply frustrated by the 10 hour build time, but that problem is also present in the building of several mainstream technologies like android and linux as well, and it's mostly a byproduct of the C toolchain.\r\n\r\nI find myself delving into this library because I have been contracted to build a prototype for a videovigilance startup, and a previous contractor tried to use tensorflow to solve some of the challenges. I'm facing the decision between following the path of the previous contractor, or lowering the expectations and using simpler technology. I apologize if this seems off topic, or not in line with what you expect at a github repo, but I do not expect or demand anything from the maintainers, at best I'm providing insight to maintainers into the preconceptions and the first experiences of a skeptical new developer might have with the library.\r\n\r\nFeel free to ignore everything here.\r\n\r\nThat said,\r\n\r\n@AdityaKane2001 Specific question, you mention that we may not understand the weighs, but that we may understand the logic by which they are created by. I agree that we may understand the code, and I'll try to do so. But regarding the weighs, do you think we have a chance to understand them? Are there any features built into tensorflow for analyzing the models or minimizing their size (thus making them easier to understand?). Something that I would like to do is to draw a correspondence between my own understanding of the subject at hand and that of my model. Taking a specifc case of my videovigilance prototype, can I inspect the model to find out if it's classifying people by skin colour? Adding another case to clarify, if I'm building a chess model, can I inspect the models to figure out whether the model knows what a [fork](https://en.wikipedia.org/wiki/Fork_(chess)) is? If the question depends on the specific models, let me know and I can post a repo with a working example.\r\nThank you Aditya.\r\n\r\nClosing the issue to highlight that no response is really needed, but I appreciate having an open space to post my thoughts about my experience with the tech.", "Actually scratch that, I don't think I'm going to be able to build this thing, let alone build something with it. (#4680)"]}, {"number": 47792, "title": "Retracing happens when using eager execution for custom code", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab default\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary):  Colab default\r\n- TensorFlow version (use command below): 2.4.1\r\n- Python version: Colab default\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: Colab default\r\n- GPU model and memory: Tesla T4\r\n\r\n\r\n**Describe the current behavior**\r\nI use a `get_param()` function to wrap the `tf.Variable()`  function.  It returns the `Variable` on non-first call or creates it otherwise. There is a `network()` function that gets the network output and a `train_network()` function that runs a training step. Following [this example](https://www.tensorflow.org/guide/function#using_with_multiple_keras_optimizers) I created a Keras Adam optimizer for training  a network.\r\n\r\nI found that tracing happens twice for `train_network()` and once for `network()`. I wonder whether it is a bug and whether this will negatively affect the efficiency of the code.\r\n\r\n**Describe the expected behavior**\r\nTracing should happens only once for both `network()`  and `train_network()`\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nw=get_param('w0', np.random.normal(0,1,[10000,10000]))\r\n@tf.function\r\ndef network(): # Define a network \r\n  print('Tracing network')\r\n  w=get_param('w0')\r\n  return tf.reduce_sum(w**2)\r\n\r\nopt = tf.keras.optimizers.Adam(1)\r\n\r\n@tf.function\r\ndef train_network():\r\n print('Tracing train_network')\r\n with tf.GradientTape() as tape:\r\n    loss = network()\r\n    w=get_param('w0')\r\n grad=tape.gradient(loss, [w])\r\n grad_and_var=zip(grad,[w])\r\n opt.apply_gradients(grad_and_var)\r\n return loss\r\n```\r\n```\r\nfor i in range(10):\r\n  t0 = time.time()\r\n  loss = train_network()\r\n  iter_time = time.time() - t0\r\n  print('iter %i:'%i, ' loss=%.2f,' % loss, 'iter_itme=%.4f s' % iter_time) \r\n```\r\n\r\nFor the complete program please refer to [this Colab Notebook](https://colab.research.google.com/drive/1RomHVK3fHPCJw8tSst4DERTBSEm9sf0t?usp=sharing)\r\n", "comments": ["@tsc2017 \r\n[This](https://stackoverflow.com/questions/57675242/how-does-tf-function-works-when-two-functions-call-each-other) may be helpful.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47792\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47792\">No</a>\n"]}, {"number": 47790, "title": "micro: CUMSUM PR3-5", "body": "PR steps 3 through 5 for the CUMSUM operator as per Issue #47290", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "@ddavis-2015 This PR is in draft, any update on this? Please. Thanks!"]}, {"number": 47789, "title": "ImageResizerState's public function contains redundant arguments", "body": "`ImageResizerState::ValidateAndCreateOutput` needs a tensor as the second argument. Actually it is unnecessary. Because `input` can be retrieved through `context->input(0)`. `ImageResizerGradientState` has a similar issue.", "comments": ["I sent a pull request which should fix this issue", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47789\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47789\">No</a>\n"]}, {"number": 47788, "title": "Remove redundant arguments of ImageResizerState's API", "body": "Fix #47789 \r\n\r\nCurrently `ImageResizerState::ValidateAndCreateOutput()` needs a tensor as the second argument. Actually its value can be retrieved through `context->input(0)`. Hence, it is unnecessary to provide the second argument. `ImageResizerGradientState::ValidateAndCreateOutput()` has the similar issue.\r\n\r\nThis code change removes the redundant arguments of the two functions mentioned above.", "comments": ["One test seems to have been impending for a long time. How should I deal with it?", "I notice that one test failed. How should I re-run the test? Just want to rule out the possibility that the failing test is flaky.", "Is there anyone to tell me how I should fix the broken test of MacOS CPU Python3?  I am able to run a test through the command like `bazel test //tensorflow/lite/python:lite_test`. But how should I verify the test for MacOS?", "@rohan100jain Can you please take a look on the above comment from @CyangXu. Thanks!", "@CyangXu I apologize for the delay. I brought in the PR and ran the tests. It should be merged in shortly.", "@hyeygit No worry! Thank you for your reply! By the way, I have a question: if my CL really breaks a MacOS test, how should I reproduce it on my side? Do I have to own a MacOS machine to reproduce the failure?", "@CyangXu MacOS would be necessary; however, even with a mac, it's not easy to replicate the environment the CI test is run in, unfortunately. The best path forward is to remind us in the comments that windows/macos tests are failing and someone from tensorflow team should help test the PR further. "]}, {"number": 47787, "title": "Inference for WeightNormalization", "body": "\r\nWeightNormalization according to\r\n`https://www.tensorflow.org/addons/api_docs/python/tfa/layers/WeightNormalization` \r\ncreates a wrapper around the kernel for normalization. it uses `tf.nn.l2_normalize` for normalization.\r\nThe issue is during inference which you don't need to run `tf.nn.l2_normalize` every time.\r\nIs there any tool or a way to replace the kernel with normalized kernel after training?\r\n", "comments": ["@alexmil2019 \r\nPlease share simple stand alone code to replicate the issue reported or a colab gist.", "```\r\ndef get_model():\r\n  in_shape = (3, 3, 1)\r\n  in_feat = tf.keras.Input(shape=in_shape, name=\"model_input\")\r\n  output = WeightNormalization(tf.keras.layers.Conv2D(filters=4,\r\n                                                    kernel_size=3,\r\n                                                    strides=1,\r\n                                                    padding='VALID',\r\n                                                    data_format='channels_last',\r\n                                                    activation=None,\r\n                                                    kernel_initializer='ones',\r\n                                                      use_bias=True))(in_feat)\r\n\r\n  return tf.keras.Model(inputs=[in_feat], outputs=[output])\r\n\r\n```\r\n\r\nHere is the output of profiler in prediction/inference mode:\r\n```\r\n==================Model Analysis Report======================\r\nIncomplete shape.\r\n\r\nDoc:\r\nscope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\r\nflops: Number of float operations. Note: Please read the implementation for the math behind it.\r\n\r\nProfile:\r\nnode name | # float_ops\r\n_TFProfRoot (--/152 flops)\r\n  model/weight_normalization/l2_normalize (36/116 flops)\r\n    model/weight_normalization/l2_normalize/Square (36/36 flops)\r\n    model/weight_normalization/l2_normalize/Sum (32/32 flops)\r\n    model/weight_normalization/l2_normalize/Rsqrt (8/8 flops)\r\n    model/weight_normalization/l2_normalize/Maximum (4/4 flops)\r\n  model/weight_normalization/mul (36/36 flops)\r\n\r\n======================End of Report==========================\r\n========================================================\r\nTotal Flops : 152\r\n```\r\n\r\nthere is no need to calculate the l2_norm every time. l2_norm should be calculated only during training time. In prediction mode it should be consuming only 36 flops instead of 152.", "@alexmil2019 \r\nI ran the code shared and there is no output, please share a colab gist with the issue reported.", "fixed."]}, {"number": 47786, "title": "InvalidArgumentError:  indices[112,8] = -1 is not in [0, 32)", "body": "Hi!\r\n\r\nIm trying to create an RNN to predict if a stock price will go up or down tomorrow (its just for practice, im not expecting that it works).\r\n\r\nBut i can not run the model. I let you the code and the error message:\r\n\r\nCODE ////////////////////////////////////////////////////////////////////////////////////////////////\r\n`import tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras.preprocessing import sequence\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Dense, Embedding, LSTM\r\nfrom tensorflow.keras.layers import SimpleRNN\r\nfrom tensorflow.keras import initializers\r\n\r\nimport pandas as pd\r\nimport numpy as np\r\nfrom sklearn.model_selection import train_test_split\r\n\r\ninTrain, inTest, outTrain, outTest = train_test_split(pd.read_csv(\"CocaColaImput.csv\"), pd.read_csv(\"CocaColaOutput.csv\"), test_size=0.33, random_state=14)\r\ninTrain=inTrain.reset_index(drop=True)\r\ninTest=inTest.reset_index(drop=True)\r\noutTrain=outTrain.reset_index(drop=True)\r\noutTest=outTest.reset_index(drop=True)\r\n\r\nmodel_rnn = Sequential()\r\nmodel_rnn.add(Embedding(32, 24))\r\nmodel_rnn.add(Dense(5, activation='relu'))\r\nmodel_rnn.add(Dense(1, activation='sigmoid'))\r\n\r\nmodel_rnn.compile(loss='mse', optimizer='adam',metrics=['accuracy'])\r\n\r\nmodel_rnn.fit(inTrain, outTrain, batch_size=128, epochs=15, validation_data=(inTest,outTest))`\r\n\r\nERROR MESSAGE ////////////////////////////////////////////////////////////////////////////////////\r\n**The error message:**\r\n\r\n_\"InvalidArgumentError:  indices[112,8] = -1 is not in [0, 32)\r\n\t [[node sequential_43/embedding_20/embedding_lookup (defined at <ipython-input-208-c4c0034817e8>:1) ]] [Op:__inference_train_function_14324]\r\n\r\nErrors may have originated from an input operation.\r\nInput Source operations connected to node sequential_43/embedding_20/embedding_lookup:\r\n sequential_43/embedding_20/embedding_lookup/14045 (defined at /usr/lib/python3.7/contextlib.py:112)\r\n\r\nFunction call stack:\r\ntrain_function\"_\r\n\r\n/////////////////////////////////////////////////////////////////////////////////////////////////////////\r\n\r\nCocaColaImput.csv has a shape of 14868 rows \u00d7 32 columns; CocaColaOutput.csv has 14868 rows \u00d7 1 columns.\r\nIm working in the google colaboratory platform, using its standard libraries.\r\n\r\n\r\nDo you know what i am doing wrong or how can i fix it?", "comments": ["@JoseConi \r\nI ran the code shared and find missing dependencies, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/a35feed050951e7a7d7ca4d0428340b1/untitled561.ipynb) , if possible share a colab gist with the error reported.\r\n\r\nMeanwhile you may refer to similar issues :[link](https://stackoverflow.com/questions/51223936/tensorflow-invalidargumenterror-indices-while-training-with-keras),[link1](https://github.com/tensorflow/tensorflow/issues/23698).\r\n\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 47785, "title": "tape.batch_jacobian gives different results if changing parallel_iterations", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64\r\n- TensorFlow installed from (source or binary): binary (pip install)\r\n- TensorFlow version (use command below): 2.4.1\r\n- Python version: 3.8.5\r\n- Bazel version (if compiling from source): -\r\n- GCC/Compiler version (if compiling from source): -\r\n- CUDA/cuDNN version: -\r\n- GPU model and memory: -\r\n\r\n**Describe the current behavior**\r\n\r\nUsing [batch_jacobian](https://www.tensorflow.org/api_docs/python/tf/GradientTape#batch_jacobian) with different values for `parallel_iterations` leads to differences in the output and the computational speed above the expected numerical errors.\r\n\r\n**Describe the expected behavior**\r\n\r\nUsing `tape.batch_jacobian` should result in mostly the same outputs independent of `parallel_iterations`.\r\n\r\nIn my custom Code (which I did not provide) I encountered differences in calculation speed from 500 us for `parallel_iterations = 3` up to 238 ms for `parallel_iterations=8` without any pattern that could be related to the `parallel_iterations`.\r\n\r\nI was able to reproduce this behaviour with a simplified version using `tf.einsum` as a function which provides a jacobian.\r\nThe error becomes zero when `parallel_iterations >=16`.\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```py\r\nimport tensorflow as tf\r\ndata = tf.random.normal((32, 16, 16))\r\n\r\ndef func(r):\r\n    return tf.einsum(\"bij, bij -> bi\", r, r)\r\n\r\n@tf.function\r\ndef func_grad(r, p_it = 2):\r\n    with tf.GradientTape() as tape:\r\n        tape.watch(r)\r\n        out = func(r)\r\n    return tape.batch_jacobian(out, r, unconnected_gradients=\"zero\", parallel_iterations=p_it)\r\n\r\ndef func_grad_no_parallel(r, p_it = 2):\r\n    with tf.GradientTape(persistent=True) as tape:\r\n        tape.watch(r)\r\n        out = func(r)\r\n    return tape.batch_jacobian(out, r, experimental_use_pfor=False)\r\n\r\ndef error_analysis(y_true, y_second):\r\n    rmse = tf.sqrt(tf.reduce_mean(tf.square(y_true - y_second)))\r\n    max_err = tf.reduce_max(y_true - y_second)\r\n    print(f\"RMSE: {rmse} \\t MAX: {max_err}\")\r\n\r\ngrad_out = func_grad_no_parallel(data)\r\nfor x in range(2, 24):\r\n    print(f\"Parallel iterations: {x}\")\r\n    jacobian_out = func_grad(data, p_it=x)\r\n    error_analysis(grad_out, jacobian_out)\r\n    %timeit func_grad(data, p_it = x)\r\n    print('-----------------------------------')\r\n```\r\n```\r\nParallel iterations: 8\r\nRMSE: 0.5038933157920837 \t MAX: 7.24960470199585\r\n1000 loops, best of 5: 667 \u00b5s per loop\r\n-----------------------------------\r\nParallel iterations: 9\r\nRMSE: 0.3786795139312744 \t MAX: 7.24960470199585\r\n1000 loops, best of 5: 1.13 ms per loop\r\n-----------------------------------\r\nParallel iterations: 16\r\nRMSE: 0.5038933157920837 \t MAX: 7.24960470199585\r\n1000 loops, best of 5: 645 \u00b5s per loop\r\n-----------------------------------\r\nParallel iterations: 17\r\nRMSE: 0.0 \t MAX: 0.0\r\n1000 loops, best of 5: 1.03 ms per loop\r\n-----------------------------------\r\n```\r\n\r\n\r\n**Other info / logs**\r\n\r\nI was comparing the computation of the jacobian with a persisent GradientTape and looping over the last dimension of my data to get the individual gradients. Without using the `parallel_iterations` the loop over gradients and the jacobian are identical, but computing the jacobian is up to 4x times slower. When using `parallel_iterations` it can get more than twice as fast but comes with large errors/differences to the gradient loop method.\r\n\r\nI added some simplified version of this approach to the end of the gist as well. This is not directly related to the bug but I thought, that using the Jacobian would be more efficient than unstacking and looping over the Tensor.\r\n\r\n```py\r\n\r\nimport tensorflow as tf\r\ndata = tf.random.normal((32, 16, 3))\r\n\r\ndef func(r):\r\n    r_mat = r[:, :, tf.newaxis, :] - r[:, tf.newaxis, :, :]\r\n    return tf.einsum(\"bijk, bijk -> bi\", r_mat, r_mat)\r\n\r\n@tf.function\r\ndef func_grad_no_parallel(r):\r\n    with tf.GradientTape(persistent=True) as tape:\r\n        tape.watch(r)\r\n        out = func(r)\r\n    return tape.batch_jacobian(out, r, experimental_use_pfor=False)\r\n\r\n@tf.function\r\ndef test_grad(r):\r\n    with tf.GradientTape(persistent=True) as tape:\r\n        tape.watch(r)\r\n        out = func(r)\r\n        out = tf.unstack(out, axis=1)\r\n    deriv = []\r\n    for frame in out:\r\n        deriv.append(tape.gradient(frame, r))\r\n    return tf.stack(deriv, axis=1)\r\n\r\ntf.reduce_sum(func_grad_no_parallel(data) - test_grad(data))  # they are equal (without parallel_iterations)\r\n\r\n%timeit func_grad_no_parallel(data)  # for this simplified version is still slower\r\n%timeit test_grad(data)\r\n\r\n```\r\n\r\nYou can find a [GIST here](https://colab.research.google.com/drive/1h42fHAeWvDn5gRlU5BBWqwHmuBkHQHg5?usp=sharing)\r\n", "comments": ["Was able to reproduce the issue with TF v2.3, TF v2.4 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/954bca9237e735e977a8868367be27af/47785.ipynb#scrollTo=Qd1dl5KrcQRb). Thanks!", "Thank you for the report. Looks like a capturing issue, where the gradient of the placeholder in the while_loop isn't recorded properly as being associated with the external tensor being captured. So `tape.gradient` returns None and the wrapper code crashes, or with `unconnected_gradients=\"zero\"` it returns an incorrect result. The cases where the result is correct correspond to vectorized_map not using a while_loop.\r\n\r\nI'll see if I can reproduce it with just a regular while_loop capturing a watched tensor.", "Looks like this is actually because the tape needs `persistent=True`, since vectorized_map calls the function that computes gradients twice. I'll add an explicit error message, but in the meantime I'd use `GradientTape(persistent=True)` in your code for `batch_jacobian(..., parallel_iterations=...)`. Sorry you ran into this.", "Thanks a lot! Adding `persistent=True` solved all the issues I had.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47785\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47785\">No</a>\n"]}, {"number": 47783, "title": "[TFLM] Added optimized softmax kernel (int32 and float) for CEVA-BX1 and CEVA SP500", "body": "Relevant github issue:https://github.com/tensorflow/tensorflow/issues/45607\r\n", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 47782, "title": "M1 arm64 release binaries", "body": "\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 11.2.3 (20D91)\r\n- TensorFlow installed from (source or binary): tf-nighly\r\n- TensorFlow version: \r\n- Python version: 3.9.2\r\n\r\n**Describe the problem**\r\n\r\n`tf-nightly` fails to install on M1 arm64. \r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n```\r\n~: where pip\r\n/opt/homebrew/bin/pip\r\n~: where python\r\n/opt/homebrew/bin/python\r\n~: pip --version\r\npip 21.0.1 from /opt/homebrew/lib/python3.9/site-packages/pip (python 3.9)\r\n~: python --version\r\nPython 3.9.2\r\n~: file /opt/homebrew/bin/python\r\n/opt/homebrew/bin/python: Mach-O 64-bit executable arm64\r\n~: pip install tf-nightly\r\nERROR: Could not find a version that satisfies the requirement tf-nightly\r\nERROR: No matching distribution found for tf-nightly\r\n```", "comments": ["proably trying to build from source will help", "The official pip packages that we build are for x86_64. For ARM, you have to build from source.", "@mihaimaruseac understood. Given strategy is towards native Python on M1 are there plans to provide arm64 binaries? Should this issue be used for tracking if there isn't another one?", "We are not able to provide ARM binaries at the moment. The earliest would be next year after we get all the needed infrastructure and head count.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47782\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47782\">No</a>\n", "Is there any plans to officially release binary distributions for TensorFlow for ARM (Apple M1) on linux?"]}, {"number": 47781, "title": "[TFLM] Added support for optimized quantize kernel, CEVA-BX1 & SP500", "body": "Also added some #ifdefs to the tests since I removed unit8 support from our code.\r\n\r\nThis PR comes instead of #46226 which I closed. \r\n", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 47780, "title": "Inconsistency in tf.keras.models.Model.fit() doc", "body": "### URL(s) with the issue\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/Model#fit\r\n\r\n### Description of the issue (what needs changing):\r\nRelated to the `validation_data` parameter, the doc clearly states the following:\r\n\r\n> Note that validation_data does not support all the data types that are supported in x, eg, dict, generator or keras.utils.Sequence.\r\n\r\nI don't get whether this was just an oversight or it was intended, since this method is working fine even when `validation_data` is a generator. \r\n", "comments": ["The documentation for `model.fit` arguments are now updated with latest [tf-nightly api docs](https://www.tensorflow.org/api_docs/python/tf/keras/Model?version=nightly#fit). Thanks!"]}, {"number": 47779, "title": "TensorFlow Lite object detection example code does not work with custom trained model", "body": "### System information\r\n\r\n-   **OS Platform and Distribution (macOS Big Sur 11.2)**:\r\n-   **Mobile device (iPhone 7)\r\n-   **TensorFlow Lite installed from (https://www.tensorflow.org/lite/examples/object_detection/overview:View iOS example)**:\r\n-   **TensorFlow (1.14.1)\r\n-   **Xcode version(Version 12.4)\r\n-   **Python (Python 3.7.3)\r\n\r\n### Describe the problem\r\nI want to test my custom trained (ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync) model with tensorflow lite, to see if the performance (accuracy and fps) is good enough to be able to start the development of my project for IOS devices or not. But when I execute my .tflite and labelmap.txt files with TensorFlow Lite example code, nothing can be detected.\r\n\r\nHere is my flow:\r\n\r\n1- I trained my images with ssd_mobilenet_\r\n\r\nv1_fpn_shared_box_predictor_640x640_coco14_sync model:\r\nCode:\r\nhttps://github.com/tensorflow/models\r\n(master branch)\r\nCommand:\r\npython3.7 train.py\r\n--logtostderr\r\n--train_dir=/Users/Documents/Temp/tensorflow_last/models/train\r\n--pipeline_config_path=/Users/Documents/Temp/tensorflow_last/models/ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync.config\r\nNote:I can also attach my config file, if it is related\r\n\r\n2-Converted it to .pb file (tflite_graph.pb):\r\npython3.7 models/research/object_detection/object_detection/export_tflite_ssd_graph.py\r\n--pipeline_config_path=/Users/emre/Documents/Temp/tensorflow_last/models/ssd_mobilenet_v1_fpn_shared_box_predictor_640x640_coco14_sync.config\r\n--trained_checkpoint_prefix=/Users/emre/Documents/Temp/tensorflow_last/models/train/model.ckpt-21881\r\n--output_directory=/Users/emre/Documents/Temp/tensorflow_last/models/Lite\r\n\r\n3-Converted it to tflite file:\r\nCode:\r\nhttps://github.com/tensorflow/models\r\n(master branch)\r\nCommand:\r\npython3.7 tflite_convert.py --output_file=test.tflite --graph_def_file=/Users/Documents/Temp/tensorflow_last/models/Lite/tflite_graph.pb --input_arrays=image_tensor --output_arrays='detection_boxes','detection_scores','detection_classes','num_detections' --input_shape=1,800,600,3 --allow_custom_ops\r\n\r\n4-Downloaded following Tensorflow example code from https://www.tensorflow.org/lite/examples/object_detection/overview\r\n(View iOS example)\r\n\r\nThe example works fine with the existing pretrained model(which is in tensorflow_lite/examples/lite/examples/object_detection/ios/ObjectDetection/Model/detect.tflite and labelmap.txt) on Xcode version(Version 12.4) and on Mobile device (iPhone 7)).\r\n\r\n5-Changed original detect.tflite and labelmap.txt files with my own test.tflite(re-named it as detect.tflite) and labelmap.txt. But when I try to execute the same code to detect my own images with my own .tflite and label map.txt files, nothing can be detected and no error messages pop up.\r\n\r\n6-Also tried to execute following pre-trained models with Tensorflow example code, to see if there is a problem with my own custom trained model or not:\r\nhttps://github.com/asus4/tf-lite-unity-sample/tree/master/Assets/StreamingAssets/mediapipe\r\nBut they did not also work properly. Nothing can be detected and no error messages pop up.\r\n\r\nI assume that I miss something to modify in example code, since pre-trained models from github.com can also not detect any objects.\r\n\r\nCan someone please help me if I need anything else to modify to make my model work? \r\n\r\nThanks a lot in advance.\r\n\r\n### Source code / logs\r\n-No Related log file can I observe in Xcode(Nothing special in debugger output or device logs) \r\nNote: I have no experience with Xcode. I hope I do not miss any points. I can provide any logs, if you require.\r\n", "comments": ["@lintian06 could you take a look at this?", "Hi @emre84 ,\r\n\r\nAs the model is changed, please notice that it has different inputs and outputs from our built-in one. Therefore, most likely, you need to change those inputs and outputs in [ModelDataHandler](https://github.com/tensorflow/examples/blob/f2946cb116ac5e06eb3e318dd94144214c95238a/lite/examples/object_detection/ios/ObjectDetection/ModelDataHandler/ModelDataHandler.swift#L46-L63) accordingly.\r\n\r\nSeeing from your conversion script, you may need to change the swift code to adapt to your new model.\r\n```\r\n--input_shape=1,800,600,3 \r\n# Change your input shape to 800x600 in the swift code.\r\n\r\n--output_arrays='detection_boxes','detection_scores','detection_classes','num_detections'\r\n# Please make sure the meanings of output values and orders are aligned with swift code, or otherwise adapt to it. The model may be varied a bit from case to case, which I cannot tell by the name.\r\n\r\n--allow_custom_ops\r\n# I would suggest removing this to see if the conversion still works for your model. FYI, if [custom ops](https://www.tensorflow.org/lite/guide/ops_custom) have to be there, it requires a bit more efforts.\r\n```\r\n\r\nPlease use xcode's console to debug, the app doesn't show errors in the GUI.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47779\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47779\">No</a>\n"]}, {"number": 47778, "title": "python crashes without error performing a tensorflow operation on a new GPU", "body": "EDIT : I don't know if it helps but it looks similar to https://github.com/tensorflow/tensorflow/issues/47770, though on a different hardware\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Pro\r\n- TensorFlow installed from (source or binary): see installation procedure\r\n- TensorFlow version: nightly 2.5\r\n- Python version: 3.8\r\n- Installed using virtualenv? pip? conda?: pip\r\n**Installation procedure :**\r\n1. created a new 3.8 env within anaconda navigator\r\n2. opened the env in terminal and used the two following commands : pip3 install tf-nightly-gpu ; conda install jupyter scikit-learn matplotlib pandas\r\n- CUDA/cuDNN version: cuda_11.2.2_461.33_win10 ; cudnn-11.2-windows-x64-v8.1.1.33 ; DRIVER : 461.72-desktop-win10-64bit-international-dch-whql\r\n- GPU model and memory: NVIDIA RTX 3090\r\n\r\nI apologize in advance if I made an obvious mistake, but I am very bad with computers. I basically know the bare minimum for Deep Learning. Thank you very much for your help !\r\n\r\n**Describe the problem**\r\nPython crashes without displaying errors. This can be reproduced using the following code :\r\nimport tensorflow\r\na = tensorflow.Variable(1.)\r\nb = tensorflow.Variable(2.)\r\nc = tensorflow.multiply(a, b)\r\nThe GPU is correctly detected as far as I can see, and the three first lines work as intended (see full code bellow). The fourth line makes python freeze for a few seconds then python crashes.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nI have recently received a new computer with an RTX 3090 and was trying to test it for the first time for some basic Deep Learning. I followed a few guides (e.g. https://www.reddit.com/r/tensorflow/comments/jsalkw/rtx_3090_and_tensorflow_for_windows_10_step_by/ or https://docs.nvidia.com/deeplearning/cudnn/install-guide/index.html#prerequisites-windows) and installed the following :\r\n- GPU driver (461.72)\r\n- Visual Studio 16.9.1 with C++ desktop development option, including MSVC v142 - VS 2019 C++ build tools ; Kit SDK windows 10 (10.0.19041.0) ; just in time debugger ; profiling C++ tools ; C++ cmake tools for windows ; C++ ATL for BuildTools V142\r\n- CUDA v11.2.2_461.33_win10\r\n- cuDNN cudnn-11.2-windows-x64-v8.1.1.33\r\n- I then copied the file cusolver64_11.dll as indicated by the guide and renamed the copy cusolver64_10.dll\r\n\r\n**Any other info / logs**\r\n\r\nPython 3.8.8 | packaged by conda-forge | (default, Feb 20 2021, 15:50:08) [MSC v.1916 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n2021-03-13 13:54:50.149216: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n>>> a = tf.Variable(1.)\r\n2021-03-13 13:55:12.083695: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll\r\n2021-03-13 13:55:12.111014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1779] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce RTX 3090 computeCapability: 8.6\r\ncoreClock: 1.695GHz coreCount: 82 deviceMemorySize: 24.00GiB deviceMemoryBandwidth: 871.81GiB/s\r\n2021-03-13 13:55:12.111148: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2021-03-13 13:55:12.610340: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2021-03-13 13:55:12.610462: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n2021-03-13 13:55:12.904250: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\r\n2021-03-13 13:55:12.936850: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\r\n2021-03-13 13:55:13.147562: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\r\n2021-03-13 13:55:13.337686: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\r\n2021-03-13 13:55:13.341143: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n2021-03-13 13:55:13.341313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1917] Adding visible gpu devices: 0\r\n2021-03-13 13:55:13.341889: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-03-13 13:55:13.343072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1779] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce RTX 3090 computeCapability: 8.6\r\ncoreClock: 1.695GHz coreCount: 82 deviceMemorySize: 24.00GiB deviceMemoryBandwidth: 871.81GiB/s\r\n2021-03-13 13:55:13.343142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1917] Adding visible gpu devices: 0\r\n2021-03-13 13:55:13.722962: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-03-13 13:55:13.723047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1310]      0\r\n2021-03-13 13:55:13.723426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1323] 0:   N\r\n2021-03-13 13:55:13.724062: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1464] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 21692 MB memory) -> physical GPU (device: 0, name: GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6)\r\n>>> b = tf.Variable(2.)\r\n>>> c = tf.multiply(a,b)\r\n\r\n(tf_nightly_2_5_test2) C:\\Users\\>", "comments": ["@Antzyx \r\nWe see that you are using 1.x version of tensorflow and there is no support for 1.x, please upgrade yo 2.x also verify with the [system requirements](https://github.com/tensorflow/tensorflow/issues/47720#issuecomment-797249831) for the same and let us know.", "I have similar problem(RTX3090, CUDA 11.1, cuDNN 8). When using tf-nightly-gpu==2.5.0.dev20210305 and later versions will cause python to crash. Back to tf-nightly-gpu==2.5.0.dev20210304 version can run normally.", "@dalan2014 \r\nAre you using tf 1.x, can you please create a separate issue using this [link](https://github.com/tensorflow/tensorflow/issues/new/choose).", "Sorry for the typo, I was indeed using 2.5 as well, and not 1.2.5, therefore I believe @dalan2014's comment here is correct. I will edit my post up there.\r\nIt should be noted that installing the last non-nightly version (2.4.x) solved the problem for me.", "@Antzyx\r\nThank you for your update.\r\nGlad the issue is resolved for you, please move this to closed status.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47778\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47778\">No</a>\n"]}, {"number": 47777, "title": "enh: allow stateless numpy function", "body": "\r\n**System information**\r\n- TensorFlow version (you are using): 2.4\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n`tf.numpy_function` is assumed to be stateful. However, many pure Python functions (as the example with `np.*` in the docs) are actually stateless. `numpy_function` calls `py_func_common` that actually has a 'stateful' argument. Can't we just pass this through?\r\n\r\n**Will this change the current api? How?**\r\nAdd an argument `stateful` to `numpy_function`. Defaults to `True`, keeps backwards compatibility\r\n\r\n**Who will benefit with this feature?**\r\n\r\nThis allows optimizations in the graph\r\n\r\n**Any Other info.**\r\nIs there any reason why this is not passed through currently?", "comments": ["cc @allenlavoie @saxenasaurabh \r\nMarking it stateless might cause trouble if the Python function calls into other TF ops, like variable reads or updates. But if the user is made aware of the pitfalls, it might be ok to allow.", "This is then the responsibility of the user I would say, it's a guarantee that the user gives. AFAIK there is currently no way of creating an eager, stateless function from the public API, right? The main motivation is to wrap efficiently np, scipy etc functionality", "Could you provide more detail on what problems you are running into with this? Performance perhaps?\r\n\r\nI am not sure why we removed the `stateful` arg in TF2 (compared to `py_func`). Adding it back sounds reasonable to me but it would be nice to understand the impact.", "I agree, this discrepancy was my motivation for the issue as (to me) the de-facto difference between the two is the `use_gradient_tape` in `py_function` which leads [to a memory leak](https://github.com/tensorflow/tensorflow/issues/35010#issuecomment-798198842) in eager and is meant for TF eager, not pure Python eager (AFAI understand).\r\n\r\nI didn`t run explicitly in performance issues (an artificial example would be easy but also not reality), rather when looking through the code and I didn't understand why it was off. I can't really see a reason for the (potential) loss in performance by not being able to communicate this guarantee.\r\n\r\nIf that seems risky but we don't know why, we can maybe introduce it as an experimental knob? Or directly expose the `py_func_common` publicly?", "I think adding `stateful=True` arg to the API sounds reasonable. Would you like to send a PR? \r\nOne way to test this change might be to create a tf.function with two calls to `tf.numpy_function` and test that there is no control edge between them. Right now there should be, which is a possibly performance concern I believe.", "Sure, gladly doing that!"]}, {"number": 47776, "title": "flow_from_directory doesn't create enough batches", "body": "Hello I have an issue with flow_from_directory to yield enough data.\r\n\r\n\r\n**System information**\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow version (use command below): TF 2.5\r\n- Python version: 3.7\r\n\r\n- CUDA/cuDNN version: CUDA 11.2\r\n- GPU model and memory: GTX 1660 TI\r\n\r\n\r\n**Describe the current behavior**\r\nI wanted to yield data with flow_from_directory method. But it didn't work well.\r\n\r\n**Describe the expected behavior**\r\nI expected to have enough batches for my training.\r\n\r\n**Standalone code to reproduce the issue**\r\n` from tensorflow.keras import layers\r\nfrom tensorflow.keras import models\r\nfrom tensorflow.keras import optimizers\r\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n\r\n\r\nimport matplotlib.pyplot as plt\r\n\r\nimport os\r\n\r\nnew_DS = r'C:\\Users\\lucas\\Projets Code\\ConvNet Dogs And Cats\\cats_and_dogs_small'\r\ntrain_folder = os.path.join(new_DS, 'train')\r\ntest_folder = os.path.join(new_DS, 'test')\r\n\r\n\r\ntrain_datagen = ImageDataGenerator(rescale=1./255, rotation_range=40,width_shift_range=0.2,height_shift_range=0.2, shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\r\nvalidation_folder = os.path.join(new_DS, 'validation')\r\ntest_datagen = ImageDataGenerator(rescale=1./255)\r\n\r\n\r\ntrain_generator = train_datagen.flow_from_directory(train_folder,target_size=(150,150),batch_size=32, class_mode='binary')\r\n\r\nvalidation_generator = test_datagen.flow_from_directory(validation_folder, target_size=(150,150),batch_size=32, class_mode='binary')\r\n\r\n\r\n\r\nmodel = models.Sequential()\r\nmodel.add(layers.Conv2D(32, (3,3), activation='relu',input_shape=(150,150,3)))\r\nmodel.add(layers.MaxPooling2D((2,2)))\r\nmodel.add(layers.Conv2D(64, (3,3), activation='relu'))\r\nmodel.add(layers.MaxPooling2D((2,2)))\r\nmodel.add(layers.Conv2D(128, (3,3), activation='relu'))\r\nmodel.add(layers.MaxPooling2D((2,2)))\r\nmodel.add(layers.Conv2D(128, (3,3), activation='relu'))\r\nmodel.add(layers.MaxPooling2D((2,2)))\r\nmodel.add(layers.Flatten())\r\nmodel.add(layers.Dropout(0.5))\r\nmodel.add(layers.Dense(512, activation='relu')) #provides learning features from all the combinations\r\n                                                #of the features of the previous layer\r\nmodel.add(layers.Dense(1,activation='sigmoid'))\r\n\r\nmodel.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])\r\n\r\n\r\n\r\nhistory = model.fit(train_generator, steps_per_epoch=100, epochs=100, validation_data=validation_generator,validation_steps=50)\r\nmodel.save('cats_and_dogs_2.h5')\r\nacc = history.history['acc']\r\nval_acc = history.history['val_acc']\r\nloss = history.history['loss']\r\nval_loss = history.history['val_loss']\r\n\r\nepochs = range(1,len(acc)+1)\r\n\r\nplt.plot(epochs,acc,'bo', label='Training acc')\r\nplt.plot(epochs, val_acc,'b', label='Validation acc')\r\nplt.title('Training and validation accuracy')\r\nplt.legend()\r\n\r\nplt.figure()\r\n\r\nplt.plot(epochs, loss, 'bo', label='Training loss')\r\nplt.plot(epochs, val_loss, 'b', label='Validation loss')\r\nplt.title('Training and validation loss')\r\nplt.legend()\r\n\r\nplt.show()\r\n `\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\nHere is what I got in my terminal : \r\n\r\n> To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-03-13 06:51:31.781669: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-03-13 06:51:31.792390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1310]\r\n2021-03-13 06:51:32.680059: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\r\nEpoch 1/100\r\n 63/100 [=================>............] - ETA: 22s - loss: 0.7003 - acc: 0.4875WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 10000 batches). You may need to use the repeat() function when building your dataset.\r\nWARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\r\n100/100 [==============================] - 44s 418ms/step - loss: 0.6964 - acc: 0.4993 - val_loss: 0.7465 - val_acc: 0.5000\r\n", "comments": ["@LucasColas \r\nNote that `steps_per_epoch` is the number of batches to consume in one epoch. You can omit it to enable the model to go through the whole dataset once every epoch. If `steps_per_epoch` is mentioned, make sure that you have atleast `batch_size*steps_per_epoch*epochs` number of individual samples in your dataset.\r\n\r\nHope this helps.", "I use `flow_from_directory` so it generates batches of augmented data...", "@LucasColas,\r\nIn order to expedite the trouble-shooting process, could you please provide the dataset you are using and all the files required to run the code. Thanks!", "How can I send the dataset ? It's a very large folder", "> \r\n> \r\n> @LucasColas\r\n> Note that `steps_per_epoch` is the number of batches to consume in one epoch. You can omit it to enable the model to go through the whole dataset once every epoch. If `steps_per_epoch` is mentioned, make sure that you have atleast `batch_size*steps_per_epoch*epochs` number of individual samples in your dataset.\r\n> \r\n> Hope this helps.\r\n\r\nBut `flow_from_directory` yields data indefinitely, right ?", "@LucasColas \r\nYes, it is infinite, but its termination is handled by `model.fit()` and `steps_per_epoch` and `epochs` parameters. It throws an error when the data is iterated once. For more flexibility, I recommend using `tf.data.Dataset`.", "It's not really useful, is it ?", "> How can I send the dataset ? It's a very large folder\r\n\r\n@LucasColas,\r\nIf it's a publicly available dataset you can the link with us or you can also upload the dataset to Google Drive and share the folder with us. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47776\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47776\">No</a>\n"]}, {"number": 47775, "title": "Update of --config=mkl_aarch64 with Compute Library support", "body": "This PR introduces the support of Compute Library for the Arm Architecture (ACL) as part of Bazel build for `mkl_aarch64` build config. The code was developed together with @joeramsay\r\nThe PR is related to\r\n- previously raised [issue #47415](https://github.com/tensorflow/tensorflow/issues/47415) \r\n- PRs #47745 and #47679", "comments": ["@agramesh1 @gzmkl please have a look.", "@alenik01 Can you please resolve conflicts? Thanks!", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F47775) for more info**.\n\n<!-- need_author_cla -->", "@gbaned, GitHub GUI for the conflict resolution fails to pass google-cla bot for some reason. Would force push be the best way to proceed here?", "@alenik01 Please don't force push. \r\n\r\n@google-cla I have verified that the commits are from the same user (@alenik01). Manually setting CLA to yes.", "@alenik01  Can you please check @agramesh1's comments and keep us posted ? Thanks!", "@penpornk, thanks. My main concern is how this PR stacks with recently merged PR [#47745](https://github.com/tensorflow/tensorflow/pull/47745). If the functionality will be broken, then what way would be the best to proceed, open another PR for the fix?", "@alenik01 Since your build is a separate build, I don't think anything will clash (dependency-wise) as long as you keep `--define=tensorflow_mkldnn_contraction_kernel=0` in your build config. The reason I wanted to go with a separate repo was because `mkl_dnn_v1` v2.1 could still be reverted back to v1.6.4 at any time. (It's used by our official build so it goes through a large number of test configurations). So by having a separate repo, you can ensure you are able to use v2.1 regardless of what happens to `mkl_dnn_v1` (because we don't test `--config=mkl_aarch64`, so anything that passes your tests would be fine).\r\n\r\nNow it's quite likely that `mkl_dnn_v1` would be able to keep v2.1. So if you'd like to go back to the same repo, that's fine too. Please let me know. I'll wait if you'd like to make more changes. ", "> If the functionality will be broken, then what way would be the best to proceed, open another PR for the fix?\r\n\r\nForgot to answer this one. Yes. If anything is broken after this PR, you can just send a PR to fix.\r\n\r\nIf your tests will be done by today, I think we can wait. Otherwise, I'd say we should get the PR in first.", "@penpornk, many thanks for the clarification.\r\n\r\n> If your tests will be done by today\r\n\r\nI will check and come back within 1.5 hours. My concern is about ENABLE_MKL macro, which is used by both PRs.", "@alenik01 Sounds good. Thank you very much! :)", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F47775) for more info**.\n\n<!-- need_author_cla -->", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F47775) for more info**.\n\n<!-- need_author_cla -->", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F47775) for more info**.\n\n<!-- need_author_cla -->", "My minor fixes done within GitHub GUI are for some reason failing Google CLA checks despite I am in the corporate CLA group.", "@googlebot I've verified that the other commits are from the same user, editing through Github's GUI. Manually changing CLA to yes.", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F47775) for more info**.\n\n<!-- need_author_cla -->", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F47775) for more info**.\n\n<!-- need_author_cla -->", "@penpornk,\r\n> Please also resolve conflicts.\r\n\r\nI am resolving them right now.", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F47775) for more info**.\n\n<!-- need_author_cla -->", "@penpornk, the feature of TF is that it takes some time to build. Currently I am encountering the following error after the merge:\r\n>create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: dnnl_threadpool_interop_stream_create\r\n\r\nDo you observe it for `--config=mkl` also?", "> @penpornk, the problem with TF is that it takes some time to build. Currently I am encountering the following error after the merge:\r\n> \r\n> > create_tensorflow.python_api_keras_python_api_gen_compat_v2.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: dnnl_threadpool_interop_stream_create\r\n> \r\n> Do you observe it for `--config=mkl` also?\r\n\r\n@alenik01 I didn't see that with the default build. I don't think `--config=mkl` has seen that error, otherwise there CI test should have caught it. @agramesh1 Could you please help confirm? Thank you!\r\n", "@penpornk, this PR is ready to go in its current state, I have checked that with `--config=mkl_aarch64` Compute Library kernels are called and the correct accuracy is reproduced for ResNet50 inference. `mkl_dnn_acl_compatible` can later be combined with `mkl_dnn_v1` if you upgrade oneDNN version to 2.2 (we may probably need a separate PR for it).\r\n\r\n@agramesh1, about `undefined symbol: dnnl_threadpool_interop_stream_create` it was false alarm, sorry for creating a mess.", "@alenik01 Thank you for the update!\r\n\r\nCould you please check the [Android Demo App](https://source.cloud.google.com/results/invocations/f06b044c-b836-4d2c-bee6-0d7d114da615) CI failure? It seems related:\r\n```\r\ntensorflow/core/common_runtime/eager/mkl_eager_op_rewrite.cc:22:10: fatal error: 'tensorflow/core/util/mkl_util.h' file not found\r\n#include \"tensorflow/core/util/mkl_util.h\"\r\n         ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n1 error generated.\r\nTarget //tensorflow/core/common_runtime/eager:execute failed to build\r\n```", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F47775) for more info**.\n\n<!-- need_author_cla -->", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F47775) for more info**.\n\n<!-- need_author_cla -->", "Good morning, @penpornk. This Android CI failure seems to be out of scope of this PR, because according to the logs it is related to `android_arm64` build target, and also the header file `\"tensorflow/core/util/mkl_util.h\"` is in place. To proceed further the interaction with developers, who are responsible for `android_arm64` maintenance, is needed.", "@alenik01 You're right. This break actually comes from #47745. Sorry about that! Fixing that now.", "@alenik01 @agramesh1 I'm going to change `if_mkl` to just\r\n```\r\n    return select({\r\n        \"@org_tensorflow//third_party/mkl:build_with_mkl\": if_true,\r\n        \"//tensorflow:linux_x86_64\": if_true,\r\n        \"//tensorflow:windows\": if_true,\r\n        \"//conditions:default\": if_false,\r\n    })\r\n```\r\nto avoid breaking builds on platforms TF-oneDNN isn't tested on. (It broke `//tensorflow:android_x86_64` and `//tensorflow:android_arm64`.)\r\n\r\n@alenik01 I saw that you removed `\"//tensorflow:arm_any\": if_false,` from the list in this PR. Have you tested with all targets that  `//tensorflow:arm_any` covers? E.g.,\r\n```\r\n        \":arm\",\r\n        \":armeabi\",\r\n        \":armeabi-v7a\",\r\n        \":arm64-v8a\",\r\n        \":linux_aarch64\",\r\n        \":linux_armhf\",\r\n```\r\n\r\n", "> @alenik01 @agramesh1 I'm going to change `if_mkl` to just\r\n> \r\n> ```\r\n>     return select({\r\n>         \"@org_tensorflow//third_party/mkl:build_with_mkl\": if_true,\r\n>         \"//tensorflow:linux_x86_64\": if_true,\r\n>         \"//tensorflow:windows\": if_true,\r\n>         \"//conditions:default\": if_false,\r\n>     })\r\n> ```\r\n> \r\n> to avoid breaking builds on platforms TF-oneDNN isn't tested on. (It broke `//tensorflow:android_x86_64` and `//tensorflow:android_arm64`.)\r\n> \r\n> @alenik01 I saw that you removed `\"//tensorflow:arm_any\": if_false,` from the list in this PR. Have you tested with all targets that `//tensorflow:arm_any` covers? E.g.,\r\n> \r\n> ```\r\n>         \":arm\",\r\n>         \":armeabi\",\r\n>         \":armeabi-v7a\",\r\n>         \":arm64-v8a\",\r\n>         \":linux_aarch64\",\r\n>         \":linux_armhf\",\r\n> ```\r\n\r\n@penpornk Thanks that should work.  I think also adding back  \"//tensorflow:arm_any\": if_false, should also fix the android build issue.", "@penpornk please let me know if you need any help. Thanks!", "> I think also adding back \"//tensorflow:arm_any\": if_false, should also fix the android build issue.\r\n\r\n@agramesh1 `//tensorflow:arm_any` doesn't include `//tensorflow:android_arm64` and `//tensorflow:android_x86_64` which are breaking. `\"//tensorflow:android\": if_false` can fix the issue. But there are simply too many platforms to account for (`chromiumos`, `enscripten`, `linux_mips64`, etc) and there could be more in the future. It's too dangerous to match `//conditions:default` with `if_true`.\r\n\r\nThis PR is setting `\"//tensorflow:arm_any\": if_true`. So I'm just asking to make sure that the `--config=aarch64` build has been tested on all the platforms `//tensorflow:arm_any` covers.\r\n```\r\n        \"//tensorflow:arm\",\r\n        \"//tensorflow:armeabi\",\r\n        \"//tensorflow:armeabi-v7a\",\r\n        \"//tensorflow:arm64-v8a\",\r\n        \"//tensorflow:linux_aarch64\",\r\n        \"//tensorflow:linux_armhf\",\r\n```\r\nIf not, it's probably better to break `//tensorflow:arm_any` down to only those that have been tested.", "@gzmkl Thank you for the offer! The fix is being submitted. It should show up soon.", "The fix is in (https://github.com/tensorflow/tensorflow/commit/37c1f29d1510c715ad1b6a249f32ac162b7fc2ec). \r\n\r\n@alenik01 Could you please help resolve merge conflicts again? Thank you very much!", "@penpornk, `arm_any` leads to the following conflict during the build:\r\n>ERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: /tensorflow/tools/pip_package/BUILD:179:10: Illegal ambiguous match on configurable attribute \"data\" in //tensorflow/tools/pip_package:licenses:\r\n//third_party/mkl:build_with_mkl_aarch64\r\n//tensorflow:arm_any\r\n\r\nthus I removed it. May you please advise on the possible fix of \"Illegal ambiguous match on configurable attribute\"? The only new LICENSE file which this PR adds is in `./third_party/compute_library/`, and I don't see from where this \"ambiguous match\" arises.\r\n\r\n>Have you tested with all targets that //tensorflow:arm_any covers?\r\n\r\nThe tests were performed with `linux_aarch64` and `arm64-v8a`.", "@penpornk, the new fix 37c1f29 actually excludes `arm_any` from if_mkl and mkl_deps.\r\n\r\n>Could you please help resolve merge conflicts again?\r\n\r\nI am now building TF to test.", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F47775) for more info**.\n\n<!-- need_author_cla -->", ">Could you please help resolve merge conflicts again?\r\n\r\nDone.", "Hi @penpornk  sorry for the confusion. This commit https://github.com/tensorflow/tensorflow/commit/37c1f29d1510c715ad1b6a249f32ac162b7fc2ec broke the oneDNN builds due to ambiguous definitions of \r\n//third_party/mkl:build_with_mkl\r\n//tensorflow:linux_x86_64\r\n\r\nWe verified that this change fixes it. Let me know if you can make the change or should we submit a PR. Thanks.\r\n```\r\ndiff --git a/third_party/mkl/build_defs.bzl b/third_party/mkl/build_defs.bzl\r\nindex d913f22a110..7a4f08ed6a3 100644\r\n--- a/third_party/mkl/build_defs.bzl\r\n+++ b/third_party/mkl/build_defs.bzl\r\n@@ -32,7 +32,6 @@ def if_mkl(if_true, if_false = []):\r\n       may need it. It may be deleted in future with refactoring.\r\n     \"\"\"\r\n     return select({\r\n-        \"@org_tensorflow//third_party/mkl:build_with_mkl\": if_true,\r\n         \"//tensorflow:linux_x86_64\": if_true,\r\n         \"//tensorflow:windows\": if_true,\r\n         \"//conditions:default\": if_false,\r\n@@ -101,7 +100,6 @@ def mkl_deps():\r\n       inclusion in the deps attribute of rules.\r\n     \"\"\"\r\n     return select({\r\n-        \"@org_tensorflow//third_party/mkl:build_with_mkl\": [\"@mkl_dnn_v1//:mkl_dnn\"],\r\n         \"@org_tensorflow//third_party/mkl:build_with_mkl_aarch64\": [\"@mkl_dnn_v1//:mkl_dnn_aarch64\"],\r\n         \"//tensorflow:linux_x86_64\": [\"@mkl_dnn_v1//:mkl_dnn\"],\r\n         \"//tensorflow:windows\": [\"@mkl_dnn_v1//:mkl_dnn\"],\r\n```\r\n", "@agramesh1 Thank you for the patch! I'll make the change.\r\n\r\n@googlebot I've verified that all the commits are from the same github user. Manually setting CLA to yes.\r\n\r\n", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F47775) for more info**.\n\n<!-- need_author_cla -->", "The fix is in. https://github.com/tensorflow/tensorflow/commit/5eabb16de7c41a115ccac4192c81a41487b676d0\r\n\r\nNo need to resolve merge conflicts again. I've already pulled this PR in and running tests internally.", "Thanks everyone for sorting this out!"]}, {"number": 47774, "title": "Legacy C++ gradients for PartitionedCall and StatefulPartitionedCall", "body": "This adds legacy C++ (`cc/gradients`) gradients for `PartitionedCall` and `StatefulPartitionedCall`, using `SymbolicGradient` as per https://github.com/tensorflow/tensorflow/pull/46115#issuecomment-797685426.", "comments": ["gradients_functional_grad_test is missing BUILD dependencies for its includes. Please add `//tensorflow/cc:ops`"]}, {"number": 47773, "title": "Update dockerfiles to CUDA 11.2", "body": null, "comments": []}, {"number": 47772, "title": "[determinism] Add segment reduction op exceptions for GPU determinism", "body": "## High-Level Summary\r\n\r\nThis current PR adds and tests the following functionality:\r\n\r\nWhen the environment variable `TF_DETERMINISTIC_OPS` is set to `\"true\"` or `\"1\"`, an attempt to run the following ops on a GPU will throw `tf.errors.UnimplementedError` (with an understandable message) when `data` is a floating-point type, including complex types (if supported).\r\n\r\n`tf.math.segment_prod`\r\n`tf.math.segment_sum`\r\n`tf.math.unsorted_segment_mean`\r\n`tf.math.unsorted_segment_sqrt_n`\r\n`tf.math.unsorted_segment_prod`\r\n`tf.math.unsorted_segment_sum`\r\n\r\n`tf.convert_to_tensor`, when running on a GPU and when `value` is of type `tf.IndexedSlides` will also throw `tf.errors.UnimplementedError` (because it uses `tf.math.unsorted_segment_sum`). This is confirmed by a test included in this PR.\r\n\r\nThe output of `tf.gather`'s backprop is of type `tf.IndexedSlices`. Therefore, when running on a GPU, if the output of `tf.gather`'s backprop is passed to `tf.convert_to_tensor`, such as when updating a word embedding, then that will also cause `tf.errors.UnimplementedError` to be thrown. This is confirmed by a test included in this PR.\r\n\r\nPlease see _RFC: Enhancing determinism in TF_ (being added via tensorflow/community PR [346](https://github.com/tensorflow/community/pull/346)).\r\n\r\n## Additional Notes\r\n\r\n### Sorted Segment Mean\r\n\r\n`tf.math.segment_mean` is currently implemented on the CPU only, operates deterministically, and will not throw `tf.errors.UnimplementedError`. The tests included in the current PR confirm that it does not throw an exception.\r\n\r\n### Unsorted Segment Mean and Square Root\r\n\r\n`tf.math.unsorted_segment_mean` and `tf.math_unsorted_segment_sqrt_n` are both currently implemented on top of `tf.math.unsorted_segment_sum`. Running these two ops on the GPU, with floating-point-based data types, will cause `tf.errors.UnimplementedError` to be thrown as if by `tf.math.unsorted_segment_sum`.\r\n\r\n### Min and Max Segment Reductions\r\n\r\nThe following ops will not throw `tf.errors.UnimplementedError`, even for floating-point-based types, because min and max operations are associative (ignoring potential non-commutativity and non-associativity of math corner cases). That they do not throw exceptions when run on GPU is confirmed by the tests included in this current PR.\r\n\r\n  * `tf.math.segment_max`\r\n  * `tf.math.segment_min`\r\n  * `tf.math.unsorted_segment_max`\r\n  * `tf.math.unsorted_segment_min`\r\n\r\n### Data Types\r\n\r\nWhere GPU implementations of the sorted segment (non-min/max) reduction ops exist, they support the following data types: `tf.float16`, `tf.float32`, and `tf.float64`. The tests confirm that `tf.errors.UnimplementedError` is thrown for all of these, regardless of the integer index data type.\r\n\r\nWhere GPU implementations of the unsorted segment (non-min/max) reduction ops exist, they support the following data types: `tf.float16`, `tf.float32`, `tf.float64`, and `tf.int32` (except `tf.math.unsorted_segment_sqrt_n`, which does not support `tf.int32`).  The tests confirm that `tf.errors.UnimplementedError` is thrown for all ops on all the floating-point types and not for any of the ops with `int32`, regardless of the integer index data type.\r\n\r\nThe GPU implementation of `tf.math_unsorted_segment_sum` (and therefore also `tf.math.unsorted_segment_mean` and `tf.math_unsorted_segment_sqrt_n`) supports `tf.complex64` and `tf.complex128`. The tests confirm that `tf.errors.UnimplementedError` is thrown for these ops and datatypes, regardless of the integer index data type.\r\n\r\n### Graph Mode vs Eager Mode Testing\r\n\r\nAll the tests run in eager mode and some tests run in graph mode as well. I was not able to get all the test to work in graph mode, for reasons that seemed unrelated to the actual intentions of the tests. I didn't want to spend more time on it, and I felt that enough of the exception throwing had been shown to translate, as expected, to graph mode.\r\n\r\n### XLA\r\n\r\nThe tests that run in graph mode would also end up getting run with the XLA auto-jit enabled. This would cause tests to fail where the expected exceptions were not generated by the XLA implementations of the ops. For this reason, in this PR, XLA auto-jit is disabled. I don't know if the XLA implementations of these ops are deterministic, but I imagine that they probably would be. I propose that when we implement deterministic versions of these ops, the determinism tests (that actually check determinism) should also be run on the XLA functionality.\r\n\r\n### Dense Image Warp\r\n\r\n`tfa.image.dense_image_warp`'s backprop to `image` (but not `flow`) is nondeterministic on a GPU because [it uses `tf.gather`](https://github.com/tensorflow/addons/blob/d26e2ed5f68092aed57016a7005ce534b1be3dce/tensorflow_addons/image/dense_image_warp.py#L171). Therefore, after this PR, enabling determinism should cause `tfa.image.dense_image_warp` to throw an exception up from `tf.math.unsorted_segment_sum` if its backprop is run on a GPU. This behavior is not confirmed by the tests included with this current PR.", "comments": ["@sanjoy @reedwm : I'm hoping that this can get into TF 2.5", "@gbaned: please `kokoro:force-run`; I fixed an Ubuntu Sanity error with the most recent commit.", "@sanjoy: I have added a lot of additional information to the [original comment](https://github.com/tensorflow/tensorflow/pull/47772#issue-592163042). My intention is to more thoroughly document this PR both for myself and for anyone else who reviews it in the future. Please take look at it, particularly the sections on graph vs eager mode and XLA.", "Note that non-sparse GPU-deterministic segment reduction ops, both sorted and unsorted, will be added by TF [51392](https://github.com/tensorflow/tensorflow/pull/51392), probably then appearing in release 2.7. The aforementioned PR also adds a (deterministic) GPU implementation of `tf.math.segment_mean` (which hitherto was implemented on CPU only)."]}, {"number": 47771, "title": "tf.keras.layers.Input with ragged=True is not setting uniform outer dimensions", "body": "**System information**\r\n- Have I written custom code: Yes, but this is expected functionality of tf.keras.layers.Input for ragged input\r\n- OS Platform and Distribution: Linux Ubuntu 20 LTS\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: 2.2.0\r\n- Python version: 3.8.5\r\n- Bazel version: N/A\r\n- GCC/Compiler version: N/A\r\n- CUDA/cuDNN version: 11.0\r\n- GPU model and memory: V100 / 32G\r\n\r\n**Describe the current behavior**\r\n```\r\ninput_tiles = tf.keras.layers.Input(shape=(2, None, 128, 128, 3), dtype=tf.float32, ragged=True)\r\ninput_tiles.shape\r\nOut[97]: TensorShape([None, None, None, 128, 128, 3])\r\n```\r\n\r\n**Describe the expected behavior**\r\n```\r\ninput_tiles = tf.keras.layers.Input(shape=(2, None, 128, 128, 3), dtype=tf.float32, ragged=True)\r\ninput_tiles.shape\r\nOut[97]: TensorShape([None, 2, None, 128, 128, 3])\r\n```\r\n\r\nMore specifically, there should be only 1 ragged axis since there was only 1 dim listed as None in the shape param of tf.keras.layers.Input with ragged=True.\r\n\r\n[Tensorflow Documentation](https://www.tensorflow.org/api_docs/python/tf/keras/Input)\r\n\"A boolean specifying whether the placeholder to be created is ragged. Only one of 'ragged' and 'sparse' can be True. In this case, values of 'None' in the 'shape' argument represent ragged dimensions. For more information about RaggedTensors, see this guide.\"\r\n\r\n**Standalone code to reproduce the issue**\r\nSee above.\r\n\r\n", "comments": ["@alexbaras \r\nThis has been fixed in tf 2.4, please refer to the [gist here](https://colab.research.google.com/gist/Saduf2019/9950829dc1dd83a16d3e7161f78fb146/untitled561.ipynb)", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Ok thanks", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47771\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47771\">No</a>\n"]}, {"number": 47770, "title": "TF2.5 quietly fails after 'Created TensorFlow device' step", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10, build 18363\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -\r\n- TensorFlow installed from (source or binary): no\r\n- TensorFlow version (use command below): v1.12.1-52710-g601acc3950f 2.5.0-dev20210312\r\n- Python version: 3.9.2\r\n- Bazel version (if compiling from source): -\r\n- GCC/Compiler version (if compiling from source): -\r\n- CUDA/cuDNN version: 11.0.2 / cuDNN v8.0.1 RC2 (June 26th, 2020), for CUDA 11.0\r\n- GPU model and memory: Quadro T1000 (Notebook version) with 4GB vram\r\n\r\n**Describe the current behavior**\r\nImporting tensorflow works fine, but using tf 2.5 with my GPU results in the program being terminated with no errors thrown.\r\nSample output:\r\n```\r\n2021-03-13 00:00:28.101487: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2021-03-13 00:00:30.597453: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll\r\n2021-03-13 00:00:30.644337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1779] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: Quadro T1000 computeCapability: 7.5\r\ncoreClock: 1.455GHz coreCount: 14 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 104.34GiB/s\r\n2021-03-13 00:00:30.654714: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2021-03-13 00:00:30.662719: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2021-03-13 00:00:30.667912: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n2021-03-13 00:00:30.676216: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\r\n2021-03-13 00:00:30.683153: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\r\n2021-03-13 00:00:30.728592: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\r\n2021-03-13 00:00:30.745117: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\r\n2021-03-13 00:00:30.767488: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n2021-03-13 00:00:30.775182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1917] Adding visible gpu devices: 0\r\n2021-03-13 00:00:30.778549: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-03-13 00:00:30.789455: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1779] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: Quadro T1000 computeCapability: 7.5\r\ncoreClock: 1.455GHz coreCount: 14 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 104.34GiB/s\r\n2021-03-13 00:00:30.795660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1917] Adding visible gpu devices: 0\r\n2021-03-13 00:00:31.250426: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-03-13 00:00:31.254948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1310]      0 \r\n2021-03-13 00:00:31.257903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1323] 0:   N \r\n2021-03-13 00:00:31.262166: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1464] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2171 MB memory) -> physical GPU (device: 0, name: Quadro T1000, pci bus id: 0000:01:00.0, compute capability: 7.5)\r\n```\r\n**Describe the expected behavior**\r\nExceution doesn't stop after the \"Created TensorFlow device\" step\r\n**Standalone code to reproduce the issue**\r\nI'm using [this sample](https://www.tensorflow.org/tutorials/quickstart/beginner) that I copy-paste in a .py file\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\nSee above", "comments": ["@razvanra2,\r\nCould you please share the output of the below code snippet with us\r\n\r\n```\r\nimport tensorflow as tf\r\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\r\n```\r\n\r\nAlso, please check if you are facing the same issue with **Python 3.8** and **TensorFlow 2.4.1** as well?\r\n\r\nThanks!", "@amahendrakar \r\nThe output of that code snippet on my sistem is:\r\n'''\r\nPython 3.9.2 (tags/v3.9.2:1a79785, Feb 19 2021, 13:44:55) [MSC v.1928 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n2021-03-15 15:49:10.691630: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n>>> print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\r\n2021-03-15 15:49:27.701535: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll\r\n2021-03-15 15:49:28.058594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1779] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: Quadro T1000 computeCapability: 7.5\r\ncoreClock: 1.455GHz coreCount: 14 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 104.34GiB/s\r\n2021-03-15 15:49:28.064253: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2021-03-15 15:49:31.530100: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2021-03-15 15:49:31.533143: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n2021-03-15 15:49:33.773959: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\r\n2021-03-15 15:49:34.492267: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\r\n2021-03-15 15:49:41.641929: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusolver64_10.dll\r\n2021-03-15 15:49:43.911648: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\r\n2021-03-15 15:49:43.931078: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n2021-03-15 15:49:43.933881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1917] Adding visible gpu devices: 0\r\nNum GPUs Available:  1\r\n'''\r\n\r\nI can confirm that my system has been working flawlessly previously with python 3.8 and TF 2.2, but if you need me to check with 2.4.1 precisely, please re-confirm.", "I can now confirm I've tried the same code sample with python 3.8.6 and TF 2.4.1. It works flawlessly. ", "> I can now confirm I've tried the same code sample with python 3.8.6 and TF 2.4.1. It works flawlessly.\r\n\r\n@razvanra2,\r\nThank you for the update.\r\n\r\nPlease feel free to close the issue if it is resolved.", "It's not solved. It works in 2.4.1 and not in 2.5. It's a recent regression. ", "@razvanra2,\r\nI was able to run the linked tutorial without any issues on a machine with **Python 3.9**, **CUDA 11.2** and **cuDNN 8.1**. \r\n\r\nPlease check the attached screenshot for reference. \r\n\r\n![Screenshot 2021-03-18 11 45 10 PM](https://user-images.githubusercontent.com/57165142/111676456-30094680-8844-11eb-91a2-abf80ad154b3.png)\r\n\r\nCould you please update CUDA to **v11.2** and cuDNN  to **v8.1**, and let us know if you are still facing the same issue. Thanks!\r\n", "I experimented with TF 2.4.1 on python 3.8.6 vs. TF 2.5 on python 3.9, both with cudnn 11.2 and cuda 11.2.2.\r\nAgain, the example works flawlessly on python 3.8.6 with TF 2.4.1.\r\nOn python 3.9 with TF 2.5 the issue persists. If it helps, I stepped with a debugger through the example and I'm seeing that the crash happens at:\r\n```\r\nmodel = tf.keras.models.Sequential([\r\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\r\n  tf.keras.layers.Dense(128, activation='relu'),\r\n  tf.keras.layers.Dropout(0.2),\r\n  tf.keras.layers.Dense(10)\r\n])\r\n```", "This happens to me as well. TF 2.4.1 with python 3.8 works for me. TF 2.5 crashes/fails at the same part as it does for @razvanra2 ", "Latest tf-nightly is now working for me. @razvanra2 I had the same problem as you so maybe it will work for you now?", "@razvanra2 Can we close this issue if it is not an issue any more? Thanks!", "Thanks for the reply @MopsieX ! @jvishnuvardhan - i tried  tf_nightly-2.6.0.dev20210330 today. Everything looks like it's working again. Closing the issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47770\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47770\">No</a>\n"]}, {"number": 47769, "title": "tensorflow.keras.utils.Sequence does not work with TPU", "body": "Paste the self-contained mwe below into a Google Colab instance. It runs fine if hardware acceleration is CPU or GPU but if it is TPU then the following traceback will be produced:\r\n```\r\n   /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:1540 convert_to_tensor\r\n        ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py:339 _constant_tensor_conversion_function\r\n        return constant(v, dtype=dtype, name=name)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py:265 constant\r\n        allow_broadcast=True)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py:283 _constant_impl\r\n        allow_broadcast=allow_broadcast))\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/tensor_util.py:445 make_tensor_proto\r\n        raise ValueError(\"None values not supported.\")\r\n\r\n    ValueError: None values not supported.\r\n```\r\nI suspect the error has something to do with the `element_spec` attribute which is present on `tensorflow.data.Dataset` objects but not on `tensorflow.keras.utils.Sequence` objects. The logic I have implemented in the `RandomBatches` class is, afaik, not reimplementable using the tensorflow.data API.\r\n```\r\nfrom os import environ\r\nfrom tensorflow.config import *\r\nfrom tensorflow.data import *\r\nfrom tensorflow.distribute import *\r\nfrom tensorflow.distribute.cluster_resolver import *\r\nfrom tensorflow.keras import *\r\nfrom tensorflow.keras.layers import *\r\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\r\nfrom tensorflow.keras.optimizers import *\r\nfrom tensorflow.keras.utils import Sequence\r\nfrom tensorflow.tpu.experimental import *\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ndef select_strategy():\r\n    gpus = list_physical_devices('GPU')\r\n    tpu_addr = environ.get('COLAB_TPU_ADDR')\r\n    if not tpu_addr:\r\n        dev = '/GPU:0' if gpus else '/CPU:0'\r\n        return OneDeviceStrategy(device = dev)\r\n    resolver = TPUClusterResolver('grpc://' + tpu_addr)\r\n    experimental_connect_to_cluster(resolver)\r\n    initialize_tpu_system(resolver)\r\n    tpus = list_logical_devices('TPU')\r\n    return TPUStrategy(resolver)\r\ndef make_dataset(seq, sl, bs):\r\n    def split_input_target(chunk):\r\n        return chunk[:-1], chunk[1:]\r\n    def flatten_window(win):\r\n        return win.batch(sl + 1, drop_remainder = True)\r\n    source = tf.constant(seq, dtype = tf.int32)\r\n    return Dataset.from_tensor_slices(seq) \\\r\n                  .window(sl + 1, sl, drop_remainder = True) \\\r\n                  .flat_map(flatten_window) \\\r\n                  .map(split_input_target) \\\r\n                  .batch(bs, drop_remainder = True)\r\nclass RandomBatches(Sequence):\r\n    def __init__(self, d, sl, bs):\r\n        self.d = d\r\n        self.sl = sl\r\n        self.bs = bs\r\n        self.batches = self.random_batches()\r\n    def __len__(self):\r\n        return len(self.d) // self.sl // self.bs\r\n    def on_epoch_end(self):\r\n        self.batches = self.random_batches()\r\n    def random_batches(self):\r\n        hi = len(self.d) - self.sl - 1\r\n        return np.random.randint(hi, size = (len(self), self.bs))\r\n    def __getitem__(self, i):\r\n        d, bs, sl = self.d, self.bs, self.sl\r\n        batch = self.batches[i]\r\n        return (np.array([d[s:s + sl] for s in batch]),\r\n                np.array([d[s + 1:s + sl + 1] for s in batch]))\r\n\r\nBS, SL = 128, 256\r\nseq = np.random.randint(100, size = 10_000_000)\r\nwith select_strategy().scope():\r\n    inp = Input(shape = (None,), batch_size = BS, dtype = tf.int32)\r\n    embedding = Embedding(input_dim = 100, output_dim = 100)\r\n    lstm = LSTM(512, stateful = False, return_sequences = True)\r\n    time_dist = TimeDistributed(Dense(100))\r\n    out = time_dist(lstm(embedding(inp)))\r\n    model = Model(inputs = [inp], outputs = [out])\r\n    loss = SparseCategoricalCrossentropy(from_logits = True)\r\n    opt = RMSprop(learning_rate = 0.004)\r\n    model.compile(optimizer = opt, loss = loss)\r\n    model.summary()\r\n    model.fit(x = RandomBatches(seq, SL, BS), epochs = 100)\r\n    # model.fit(x = make_dataset(seq, SL, BS), epochs = 100)\r\n```", "comments": ["@bjourne \r\nAccording to `tf.keras.Input` docs\r\n>inp = Input(shape = (None,), batch_size = BS, dtype = tf.int32)\r\n\r\n\r\nraises `ValueError` as mentioned [here](https://www.tensorflow.org/api_docs/python/tf/keras/Input#raises_1).\r\n\r\nAlso, TPUs execute completely in graph mode, so ambiguity in shapes is not tolerated.", "But why does it work when I use the GPU and TPU? \r\n\r\nIf I change the definition of the input layer to `inp = Input(shape = (SL,), batch_size = BS, dtype = tf.int64)` I get the following error:\r\n```\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\", line 659, in <listcomp>\r\n    structure[0], [func(*x) for x in entries],\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\", line 510, in _to_single_numpy_or_python_type\r\n    x = t.numpy()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 1071, in numpy\r\n    maybe_arr = self._numpy()  # pylint: disable=protected-access\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 1039, in _numpy\r\n    six.raise_from(core._status_to_exception(e.code, e.message), None)  # pylint: disable=protected-access\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.UnavailableError: 5 root error(s) found.\r\n  (0) Unavailable: {{function_node __inference_train_function_6281}} failed to connect to all addresses\r\nAdditional GRPC error information from remote target /job:localhost/replica:0/task:0/device:CPU:0:\r\n:{\"created\":\"@1615650981.567818546\",\"description\":\"Failed to pick subchannel\",\"file\":\"third_party/grpc/src/core/ext/filters/client_channel/client_channel.cc\",\"file_line\":4143,\"referenced_errors\":[{\"created\":\"@1615650981.567817207\",\"description\":\"failed to connect to all addresses\",\"file\":\"third_party/grpc/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc\",\"file_line\":398,\"grpc_status\":14}]}\r\n         [[{{node MultiDeviceIteratorGetNextFromShard}}]]\r\n         [[RemoteCall]]\r\n         [[IteratorGetNextAsOptional]]\r\n         [[strided_slice_73/_310]]\r\n  (1) Unavailable: {{function_node __inference_train_function_6281}} failed to connect to all addresses\r\nAdditional GRPC error information from remote target /job:localhost/replica:0/task:0/device:CPU:0:\r\n:{\"created\":\"@1615650981.567818546\",\"description\":\"Failed to pick subchannel\",\"file\":\"third_party/grpc/src/core/ext/filters/client_channel/client_channel.cc\",\"file_line\":4143,\"referenced_errors\":[{\"created\":\"@1615650981.567817207\",\"description\":\"failed to connect to all addresses\",\"file\":\"third_party/grpc/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc\",\"file_line\":398,\"grpc_status\":14}]}\r\n         [[{{node MultiDeviceIteratorGetNextFromShard}}]]\r\n         [[RemoteCall]]\r\n         [[IteratorGetNextAsOptional]]\r\n         [[ConstantFoldingCtrl/cond_6/switch_pred/_56_0/_110]]\r\n  (2) Unavailable: {{function_node __inference_train_function_6281}} failed to connect to all addresses\r\nAdditional GRPC error information from remote target /job:localhost/replica:0/task:0/device:CPU:0:\r\n:{\"created\":\"@1615650981.567818546\",\"description\":\"Failed to pick subchannel\",\"file\":\"third_party/grpc/src/core/ext/filters/client_channel/client_channel.cc\",\"file_line\":4143,\"referenced_errors\":[{\"created\":\"@1615650981.567817207\",\"description\":\"failed to connect to all addresses\",\"file\":\"third_party/grpc/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc\",\"file_line\":398,\"grpc_status\":14}]}\r\n         [[{{node MultiDeviceIteratorGetNextFromShard}}]]\r\n         [[RemoteCall]]\r\n         [[IteratorGetNextAsOptional]]\r\n         [[strided_slice_54/_280]]\r\n  (3) Unavailable: {{function_node __inference_train_function_6281}} failed to connect to all addresses\r\nAdditional GRPC error information from remote target /job:localhost/replica:0/task:0/device:CPU:0:\r\n:{\"created\":\"@1615650981.567818546\",\"description\":\"Failed to pick subchannel\",\"file\":\"third_party/grpc/src/core/ext/filters/client_channel/client_channel.cc\",\"file_line\":4143,\"referenced_errors\":[{\"created\":\"@1615650981.567817207\",\"description\":\"failed to connect to all addresses\",\"file\":\"third_party/grpc/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc\",\"file_line\":398,\"grpc_status\":14}]}\r\n         [[{{node MultiDeviceIteratorGetNextFromShard}}]]\r\n         [[RemoteCall]]\r\n         [[IteratorGetNextAsOptional]]\r\n         [[Cast_1/_60]]\r\n  (4) Unavailable: {{function_node __inference_t ... [truncated]\r\nError in atexit._run_exitfuncs:\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/tpu_strategy.py\", line 738, in async_wait\r\n    context.async_wait()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py\", line 2330, in async_wait\r\n    context().sync_executors()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/context.py\", line 645, in sync_executors\r\n    pywrap_tfe.TFE_ContextSyncExecutors(self._context_handle)\r\ntensorflow.python.framework.errors_impl.UnavailableError: 5 root error(s) found.\r\n  (0) Unavailable: {{function_node __inference_train_function_6281}} failed to connect to all addresses\r\nAdditional GRPC error information from remote target /job:localhost/replica:0/task:0/device:CPU:0:\r\n:{\"created\":\"@1615650981.567818546\",\"description\":\"Failed to pick subchannel\",\"file\":\"third_party/grpc/src/core/ext/filters/client_channel/client_channel.cc\",\"file_line\":4143,\"referenced_errors\":[{\"created\":\"@1615650981.567817207\",\"description\":\"failed to connect to all addresses\",\"file\":\"third_party/grpc/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc\",\"file_line\":398,\"grpc_status\":14}]}\r\n         [[{{node MultiDeviceIteratorGetNextFromShard}}]]\r\n         [[RemoteCall]]\r\n         [[IteratorGetNextAsOptional]]\r\n         [[strided_slice_73/_310]]\r\n  (1) Unavailable: {{function_node __inference_train_function_6281}} failed to connect to all addresses\r\nAdditional GRPC error information from remote target /job:localhost/replica:0/task:0/device:CPU:0:\r\n:{\"created\":\"@1615650981.567818546\",\"description\":\"Failed to pick subchannel\",\"file\":\"third_party/grpc/src/core/ext/filters/client_channel/client_channel.cc\",\"file_line\":4143,\"referenced_errors\":[{\"created\":\"@1615650981.567817207\",\"description\":\"failed to connect to all addresses\",\"file\":\"third_party/grpc/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc\",\"file_line\":398,\"grpc_status\":14}]}\r\n         [[{{node MultiDeviceIteratorGetNextFromShard}}]]\r\n         [[RemoteCall]]\r\n         [[IteratorGetNextAsOptional]]\r\n         [[ConstantFoldingCtrl/cond_6/switch_pred/_56_0/_110]]\r\n  (2) Unavailable: {{function_node __inference_train_function_6281}} failed to connect to all addresses\r\nAdditional GRPC error information from remote target /job:localhost/replica:0/task:0/device:CPU:0:\r\n:{\"created\":\"@1615650981.567818546\",\"description\":\"Failed to pick subchannel\",\"file\":\"third_party/grpc/src/core/ext/filters/client_channel/client_channel.cc\",\"file_line\":4143,\"referenced_errors\":[{\"created\":\"@1615650981.567817207\",\"description\":\"failed to connect to all addresses\",\"file\":\"third_party/grpc/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc\",\"file_line\":398,\"grpc_status\":14}]}\r\n         [[{{node MultiDeviceIteratorGetNextFromShard}}]]\r\n         [[RemoteCall]]\r\n         [[IteratorGetNextAsOptional]]\r\n         [[strided_slice_54/_280]]\r\n  (3) Unavailable: {{function_node __inference_train_function_6281}} failed to connect to all addresses\r\nAdditional GRPC error information from remote target /job:localhost/replica:0/task:0/device:CPU:0:\r\n:{\"created\":\"@1615650981.567818546\",\"description\":\"Failed to pick subchannel\",\"file\":\"third_party/grpc/src/core/ext/filters/client_channel/client_channel.cc\",\"file_line\":4143,\"referenced_errors\":[{\"created\":\"@1615650981.567817207\",\"description\":\"failed to connect to all addresses\",\"file\":\"third_party/grpc/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc\",\"file_line\":398,\"grpc_status\":14}]}\r\n         [[{{node MultiDeviceIteratorGetNextFromShard}}]]\r\n         [[RemoteCall]]\r\n         [[IteratorGetNextAsOptional]]\r\n         [[Cast_1/_60]]\r\n  (4) Unavailable: {{function_node __inference_t ... [truncated]\r\n2021-03-13 15:56:21.787417: W ./tensorflow/core/distributed_runtime/eager/destroy_tensor_handle_node.h:57] Ignoring an error encountered when deleting remote tensors handles: Invalid argument: Unable to find the relevant tensor remote_handle: Op ID: 812, Output num: 0\r\nAdditional GRPC error information from remote target /job:worker/replica:0/task:0:\r\n:{\"created\":\"@1615650981.784021655\",\"description\":\"Error received from peer ipv4:10.38.153.218:8470\",\"file\":\"external/com_github_grpc_grpc/src/core/lib/surface/call.cc\",\"file_line\":1056,\"grpc_message\":\"Unable to find the relevant tensor remote_handle: Op ID: 812, Output num: 0\",\"grpc_status\":3}\r\n```\r\nIf I change it to `inp = Input(tensor = tf.constant([[0] * SL] * (BS // 8), dtype = tf.int32))` I get:\r\n```\r\nFile \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\", line 1105, in fit\r\n    callbacks.on_train_batch_end(end_step, logs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\", line 454, in on_train_batch_end\r\n    self._call_batch_hook(ModeKeys.TRAIN, 'end', batch, logs=logs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\", line 296, in _call_batch_hook\r\n    self._call_batch_end_hook(mode, batch, logs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\", line 316, in _call_batch_end_hook\r\n    self._call_batch_hook_helper(hook_name, batch, logs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\", line 356, in _call_batch_hook_helper\r\n    hook(batch, logs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\", line 1020, in on_train_batch_end\r\n    self._batch_update_progbar(batch, logs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/callbacks.py\", line 1084, in _batch_update_progbar\r\n    logs = tf_utils.to_numpy_or_python_type(logs)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\", line 514, in to_numpy_or_python_type\r\n    return nest.map_structure(_to_single_numpy_or_python_type, tensors)\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\", line 659, in map_structure\r\n    structure[0], [func(*x) for x in entries],\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\", line 659, in <listcomp>\r\n    structure[0], [func(*x) for x in entries],\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/tf_utils.py\", line 510, in _to_single_numpy_or_python_type\r\n    x = t.numpy()\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 1071, in numpy\r\n    maybe_arr = self._numpy()  # pylint: disable=protected-access\r\n  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\", line 1039, in _numpy\r\n    six.raise_from(core._status_to_exception(e.code, e.message), None)  # pylint: disable=protected-access\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.UnavailableError: 8 root error(s) found.\r\n  (0) Unavailable: {{function_node __inference_train_function_6284}} failed to connect to all addresses\r\nAdditional GRPC error information from remote target /job:localhost/replica:0/task:0/device:CPU:0:\r\n:{\"created\":\"@1615651392.431855787\",\"description\":\"Failed to pick subchannel\",\"file\":\"third_party/grpc/src/core/ext/filters/client_channel/client_channel.cc\",\"file_line\":4143,\"referenced_errors\":[{\"created\":\"@1615651392.431853148\",\"description\":\"failed to connect to all addresses\",\"file\":\"third_party/grpc/src/core/ext/filters/client_channel/lb_policy/pick_first/pick_first.cc\",\"file_line\":398,\"grpc_status\":14}]}\r\n         [[{{node MultiDeviceIteratorGetNextFromShard}}]]\r\n         [[RemoteCall]]\r\n         [[IteratorGetNextAsOptional]]\r\n         [[strided_slice_73/_310]]\r\n  (1) Unavailable: {{function_node __inference_train_function_6284}} failed to connect to all addresses\r\n...\r\n```\r\nSo I don't know how I should define my `Input` layer to make it work with my `tensorflow.keras.utils.Sequence` data.", "Can you try replacing\r\n`model = Model(inputs = [inp], outputs = [out]) `\r\nto\r\n`model = Model(inputs = inp, outputs = out)` ?", "Yes. I get the exact same errors.", "I am able to replicate the issue reported on tf 2.3,2.4 and nightly. please find the [gist here](https://colab.research.google.com/gist/Saduf2019/54a02f595891dcdd90bd4ad3a1499af6/untitled563.ipynb).", "Was able to replicate your issue in Tensorflow 2.5, please find the gist [here](https://colab.research.google.com/gist/sachinprasadhs/8047b2c9ad32ff894012afa756ba27ef/47769.ipynb). Thanks!", "I'm able to run the code without any error in Tensorflow 2.8, please find the gist [here](https://colab.research.google.com/gist/sachinprasadhs/36e85c5d5c9972b6271dfe28f4680c9d/47769.ipynb). Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47769\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47769\">No</a>\n"]}, {"number": 47768, "title": "Do not specialize eigen convolution classes for ppc64le arch", "body": "Eigen merged a new ppc64le improvement that specializes the\r\nEigen::internal::gemm_pack_rhs structure. TF also specializes the\r\npacking routine. This patch removes this double specialization for\r\nppc64le, using only the Eigen one.\n\n<!-- Reviewable:start -->\n---\nThis change is\u2002[<img src=\"https://reviewable.io/review_button.svg\" height=\"34\" align=\"absmiddle\" alt=\"Reviewable\"/>](https://reviewable.io/reviews/tensorflow/tensorflow/47768)\n<!-- Reviewable:end -->\n", "comments": ["https://github.com/tensorflow/tensorflow/issues/44626 @Flamefire @ezhulenev @ChipKerchner\r\n", "Is this import/copybara error an important thing?\r\n\r\nEDIT: import/copybara check has passed now (I didn't change anything)"]}, {"number": 47767, "title": "lite: nnapi: Check memory mapping errors after NNMemory()", "body": "There are no error checks in the constructor `NNMemory::NNMemory()`.\r\nWhen creating a shared memory fd, `NNMemory::fd_` could be set to a\r\nnegative value due to errors. Thus, when trying to `mmap` this,\r\n`NNMemory::data_ptr_` will be set to `MAP_FAILED` (and which in turn\r\nwill yield an invalid call to `ANeuralNetworksMemory_createFromFd()`) in\r\nthe constructor.\r\n\r\nIdeally, one should check for errors early. However, since Google's C++\r\nstyle guide prohibits the use of exceptions, we need to check this\r\nexplicitly after the constructor instead. We check `NNMemory::data_ptr_`\r\nfor any errors (since `NNMemory::fd_` is private).", "comments": ["@miaowang14 could you review this PR?"]}, {"number": 47766, "title": "[tf.data] move checkpoint tests to kernel tests part 6", "body": "This PR is a continuation of https://github.com/tensorflow/tensorflow/pull/47693 and moves the checkpoint tests of:\r\n\r\n1. dataset constructor\r\n2. sequence\r\n3. parallel map\r\n4. choose fastest branch dataset\r\n5. choose fastest dataset\r\n6. sample from datasets\r\n serialization tests to kernel tests. Additionally the remaining test targets are moved directly to `experimental/kernel_tests` as per https://github.com/tensorflow/tensorflow/pull/47693#issuecomment-796993326.\r\n\r\nAlso, this PR is a part of the larger cleanup as discussed in point 4 of https://github.com/tensorflow/tensorflow/pull/46761#issuecomment-770059963\r\n\r\ncc: @jsimsa All the serialization tests have been cleaned up!", "comments": ["@jsimsa made the changes. Please take a look.", "@jsimsa seems like the changes were committed without merging the PR. Are those tests passing now?", "I cloned your PR internally because there were internal dependencies that required fixing. This PR can be closed.", "Thanks!"]}, {"number": 47765, "title": "Converting models with mutable resource variable with v2 TFLiteConveter", "body": "### 1. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab\r\n- TensorFlow installation (pip package or built from source):\r\n- TensorFlow library (version, if pip package or github SHA, if built from source): 2.4.1\r\n\r\n### 2. Code\r\n\r\nThis is how the original model is built:\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.applications import MobileNetV2\r\nfrom tensorflow.keras.layers import *\r\n\r\ndef get_student_model():\r\n    base_model = MobileNetV2(weights=None, include_top=False,\r\n                input_shape=(224, 224, 3))\r\n    base_model.trainable = True\r\n    inputs = Input(shape=(224, 224, 3)) \r\n    x = experimental.preprocessing.Rescaling(1./127.5, offset=-1)(inputs)\r\n    y = base_model(x, training=True)\r\n    y = GlobalAveragePooling2D()(y)\r\n    y = Dense(512, activation=\"relu\")(y)\r\n    y = Dropout(0.5)(y)\r\n    outputs = Dense(30, activation='softmax')(y)\r\n    model = tf.keras.Model(inputs, outputs)\r\n    return model\r\n```\r\n\r\nThis is how the TensorFlow Lite model is generated:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(\"mobilenetv2_student_no_true_labels_e_125_t_2\")\r\nconverter.experimental_new_converter = False\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n\r\ntflite_model = converter.convert()\r\nopen(\"student_mobilenetv2.tflite\", 'wb').write(tflite_model)\r\nprint('Model size is %f MBs.' % (len(tflite_model) / 1024 / 1024.0))\r\n```\r\n\r\n### 3. Failure after conversion\r\n\r\nWhen trying to convert with `converter.experimental_new_converter = True` the conversion runs into - \r\n\r\n```\r\nConverterError: <unknown>:0: error: loc(\"Conv_1_bn/moving_mean\"): is not immutable, try running tf-saved-model-optimize-global-tensors to prove tensors are immutable\r\n```\r\n\r\nWith tf-nightly (2.5.0-dev20210312) this issue seems to be persisting as well. \r\n\r\nAs per https://github.com/tensorflow/tensorflow/issues/43833#issuecomment-744087884, I understand with the MLIR converter this is probably still unsupported. \r\n\r\n_What is more surprising are the outputs of the TFLite models converted with the TOCO converter. I have tried with just the float model i.e. when the conversion is done without any optimization flag set. The results remain fixed._ \r\n\r\nHere's the Colab Notebook that reproduces this issue: https://colab.research.google.com/gist/sayakpaul/2326ccd94e3d33e1c1ced7dfd7f09519/inference_tflite.ipynb. \r\n\r\nCc: @MeghnaNatraj @abattery ", "comments": ["I further looked into the issue and it seems to be stemming from this line, in particular `training=True` - \r\n\r\n```\r\ny = base_model(x, training=True)\r\n```\r\n\r\nI instantiated a blank model with the utility function provided above and removed the `training` argument. Doing so allowed me to do the conversion seamlessly. I will try the model again with this change and report back. \r\n\r\nHope this helps someone facing a similar issue. ", "Hi @sayakpaul \r\n\r\nWe are working on the mutable variable support. I will notify this thread once the on-going work is done.\r\n\r\nThank you for filing this feature request!", "@abattery sure. \r\n\r\nBut currently, with the TOCO converter, I am able to run the conversion successfully but that indeed results in spurious outputs. Is this expected or a known behavior? ", "@sayakpaul I am not sure the converted model with TOCO will work correctly for mutable variables.", "I see. So, the best bet, for now, would be to implement a similar architecture and train using the same loop, and then run the conversions. Am I correct?", "Could you try using the following code snippet with the tf-nightly version and linking the `tensorflow/lite/kernels:variable_op_kernels`?\r\n\r\n```\r\nconverter._enable_tflite_resource_variables = True\r\n```\r\n\r\nThe above experimental items are subject to change since it is under development.", "@abattery yes, it works now, thanks. Here's the [Colab](https://colab.research.google.com/gist/sayakpaul/76640f20ac8937ddd15a813342c8899a/scratchpad.ipynb). We need to convert it with the flex ops: \r\n\r\n```python\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(\"mobilenetv2_student_no_true_labels_e_125_t_2\")\r\nconverter._enable_tflite_resource_variables = True\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_spec.supported_ops = [\r\n  tf.lite.OpsSet.TFLITE_BUILTINS, # enable TensorFlow Lite ops.\r\n  tf.lite.OpsSet.SELECT_TF_OPS # enable TensorFlow ops.\r\n]\r\ntflite_model = converter.convert()\r\nopen(\"student_mobilenetv2.tflite\", 'wb').write(tflite_model)\r\nprint('Model size is %f MBs.' % (len(tflite_model) / 1024 / 1024.0))\r\n```", "Mutable variable support is available in the nightly when converting from SavedModel only (Other types are coming soon).\r\nBuiltin ops are available now for VarHandleOp, ReadVariable, AssignVariable in the nightly also\r\n\r\nOnly thing needed is to set this flag during conversion:\r\nconverter.experimental_enable_resource_variables = True\r\n\r\nPlease let us know if you're having any issues.\r\n\r\nThanks"]}]