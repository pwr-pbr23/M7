[{"number": 50495, "title": "Update version numbers for TensorFlow 2.6.0-rc0", "body": "Before merging this PR, please double check that it has correctly updated\n`core/public/version.h`, `tools/pip_package/setup.py`, and\n`tensorflow/tensorflow.bzl`. Also review the execution notes below:\n\n```\nMajor: 2 -> 2\nMinor: 6 -> 6\nPatch: 0 -> 0\n\nWARNING: Below are potentially instances of lingering old version string \n\"2.6.0\" in source directory \"tensorflow/\" that are not updated by this script. \nPlease check them manually!\ntensorflow/python/keras/__init__.py:33:2.6.0\ntensorflow/java/maven/tensorflow-hadoop/pom.xml:17:2.6.0\ntensorflow/workspace2.bzl:1051:2.6.0\ntensorflow/workspace2.bzl:1052:2.6.0\ntensorflow/workspace2.bzl:1055:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:80:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:149:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:155:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:161:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:227:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:334:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:355:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:356:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:357:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:358:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:359:2.6.0\ntensorflow/tools/pip_package/setup.py:53:2.6.0\ntensorflow/tools/pip_package/setup.py:108:2.6.0\ntensorflow/tools/pip_package/setup.py:120:2.6.0\ntensorflow/tools/pip_package/setup.py:122:2.6.0\ntensorflow/tools/pip_package/setup.py:124:2.6.0\ntensorflow/tools/ci_build/release/requirements_common.txt:27:2.6.0\ntensorflow/tools/ci_build/release/requirements_common.txt:28:2.6.0\ntensorflow/tools/ci_build/release/requirements_common.txt:29:2.6.0\ntensorflow/tensorflow.bzl:55:2.6.0\n\nWARNING: Below are potentially instances of lingering old version string \n\"2.6.0\" in source directory \"tensorflow/\" that are not updated by this script. \nPlease check them manually!\ntensorflow/python/keras/__init__.py:33:2.6.0\ntensorflow/java/maven/tensorflow-hadoop/pom.xml:17:2.6.0\ntensorflow/workspace2.bzl:1051:2.6.0\ntensorflow/workspace2.bzl:1052:2.6.0\ntensorflow/workspace2.bzl:1055:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:80:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:149:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:155:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:161:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:227:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:334:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:355:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:356:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:357:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:358:2.6.0\ntensorflow/lite/tools/versioning/runtime_version.cc:359:2.6.0\ntensorflow/tools/pip_package/setup.py:53:2.6.0\ntensorflow/tools/pip_package/setup.py:108:2.6.0\ntensorflow/tools/pip_package/setup.py:120:2.6.0\ntensorflow/tools/pip_package/setup.py:122:2.6.0\ntensorflow/tools/pip_package/setup.py:124:2.6.0\ntensorflow/tools/ci_build/release/requirements_common.txt:27:2.6.0\ntensorflow/tools/ci_build/release/requirements_common.txt:28:2.6.0\ntensorflow/tools/ci_build/release/requirements_common.txt:29:2.6.0\ntensorflow/tensorflow.bzl:55:2.6.0\n```", "comments": []}, {"number": 50494, "title": "Getting error while performing one hot encoding", "body": "MemoryError                               Traceback (most recent call last)\r\n<ipython-input-333-6e9121367701> in <module>\r\n      1 ## categorical processing\r\n      2 \r\n----> 3 df_cat_dum = pd.get_dummies(df_cat)\r\n\r\n~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py in get_dummies(data, prefix, prefix_sep, dummy_na, columns, sparse, drop_first, dtype)\r\n    887         for (col, pre, sep) in zip(data_to_encode.items(), prefix, prefix_sep):\r\n    888             # col is (column_name, column), use just column data here\r\n--> 889             dummy = _get_dummies_1d(\r\n    890                 col[1],\r\n    891                 prefix=pre,\r\n\r\n~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\reshape.py in _get_dummies_1d(data, prefix, prefix_sep, dummy_na, sparse, drop_first, dtype)\r\n   1003 \r\n   1004     else:\r\n-> 1005         dummy_mat = np.eye(number_of_cols, dtype=dtype).take(codes, axis=0)\r\n   1006 \r\n   1007         if not dummy_na:\r\n\r\nMemoryError: Unable to allocate 654. MiB for an array with shape (26187, 26187) and data type uint8", "comments": ["@Nehap-27 \r\n\r\nWe see that the issue template has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced]\r\n\r\nLooking at the error log it is similar to the issues: [#39442](https://github.com/tensorflow/tensorflow/issues/39442), [#384144](https://github.com/tensorflow/tensorflow/issues/38414#issuecomment-642836301)  ,  and also check this [comment](https://stackoverflow.com/questions/57507832/unable-to-allocate-array-with-shape-and-data-type) ,let us know if it helps\r\nThanks", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50494\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50494\">No</a>\n"]}, {"number": 50493, "title": "[ROCm] Adding complex type support for SparseTensorDenseMatMul op (on the ROCm platform)", "body": "/cc @cheshire @chsigg ", "comments": []}, {"number": 50492, "title": "Pipeline sharing between tf.data Dispatcher and Worker", "body": "## Tensorflow Version\r\nTensorflow v2.5.0\r\n\r\n## Description of issue (what needs changing):\r\nHow does the Workers find out about the input pipeline code? Is it serialised over the network from the main Tensorflow process, to the Dispatcher and then to the Worker?\r\n\r\n### Clear description\r\nI'm looking to find out to see if there's any need for encryption between the process.\r\n\r\n### Parameters defined\r\nN/A\r\n\r\n### Returns defined\r\nN/A\r\n\r\n\r\n### Raises listed and defined\r\nN/A\r\n\r\n### Usage example\r\nN/A\r\n\r\n### Request visuals, if applicable\r\nN/A \r\n\r\n### Submit a pull request?\r\nN/A\r\n", "comments": []}, {"number": 50491, "title": "WAR a bazel cache corruption issue.", "body": "Bazel is taking much time to enable the WAR.\r\n@sanjoy suggested to enable it now for us.\r\n\r\nHaving a potential cache corruption is something very bad to have.", "comments": []}, {"number": 50490, "title": "TFLite Quantization Old Spec version?", "body": "### 1. System information\r\n\r\n- OS Ubuntu 16.04:\r\n\r\n----\r\n\r\nHi I have a question:\r\n\r\nI'm intended to use tflite with vx-delegate (provided by VeriSillicon) for A311D SoC. The SoC has chip with INT8 support.\r\nIm able to convert tf to tflite and run my tflite model, no problem here. Both on ARM CPU and INT8 chip.\r\n\r\nThe problem is performance: when I use TF2.4 for conversion and tflite runtime, INT8 performance is subpar, because as I was told, A311D doesn't support \"new\" per channel quantization. And in order to get most out of the chip I need per tensor quantization.\r\n\r\n_So, the question is: how to quantize model in \"old\" per tensor quantization format?_\r\n\r\nthanks! ", "comments": ["the answer is to use this flag - https://github.com/tensorflow/tensorflow/blob/2c4ed56aca5becc6fd51347e694f151f8c46e8fd/tensorflow/lite/python/lite.py#L454", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50490\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50490\">No</a>\n"]}, {"number": 50489, "title": "Adding mhlo Einsum to LinalgGeneric Lowering", "body": "", "comments": ["@joker-eph @sanjoy @sherhut @gbaned\r\n\r\nThis is Hanhan from IREE team. I usually land changes through internal flow, and I'm not familiar with Github flow. The PR looks good to me. Could you take a look and help on landing the change? \r\n\r\nThanks!", "You just need to approve the PR, and the automation adds the \"ready-to-pull\" label and pulls this into a CL.\r\nIn the list of \"builds\"  you'll find a link to the internal CL when it is created.", "> I somehow can not comment on l.436. There is an empty statement, please delete it?\r\n\r\ndone :) \r\n\r\n\r\n", "@joker-eph I think it is ready to restart the integration process, could you approve again? Thanks!", "> @joker-eph I think it is ready to restart the integration process, could you approve again? Thanks!\r\n\r\n@hanhanW Will it not restart if you approve it instead? \ud83d\ude04 \r\n", "I don't have the permission. I probably could, I have to check it and see if I can get it.", "@joker-eph Sorry for bothering you again... Could you help approve it to restart the process again? Thanks!\r\n\r\n(I'm requesting the permission, but not get approved yet)", "(I got the permission and approve it to restart the process.)"]}, {"number": 50488, "title": "LSTM performs worse than CuDNNLSTM", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nWindows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nNA\r\n- TensorFlow installed from (source or binary):\r\nbinary\r\n- TensorFlow version (use command below):\r\nv2.5.0-rc3-213-ga4dfb8d1a71 2.5.0\r\n- Python version:\r\n3.8\r\n- Bazel version (if compiling from source):\r\nNA\r\n- GCC/Compiler version (if compiling from source):\r\nNA\r\n- CUDA/cuDNN version:\r\nCUDA = 11.3\r\ncuDNN = 8201\r\n- GPU model and memory:\r\nNvidia RTX 3070 (24gb)\r\n\r\n**Describe the current behavior**\r\n`tensorflow.python.keras.layers.CuDNNLSTM` is much faster than `tensorflow.python.keras.layers.LSTM`.\r\n\r\n**Describe the expected behavior**\r\nGPU utilisation of deprecated `tensorflow.python.keras.layers.CuDNNLSTM` should be in  `tensorflow.python.keras.layers.LSTM` since TF 2.0\r\n\r\n**Standalone code to reproduce the issue**\r\n```python\r\nfrom tensorflow.python.keras import Sequential\r\nfrom tensorflow.python.keras.callbacks import ModelCheckpoint\r\nfrom tensorflow.python.keras.layers import LSTM, CuDNNLSTM\r\n\r\nX = [\r\n    [[1, 1, 1]],\r\n    [[1, 1, 1]]\r\n]\r\n\r\nY = [\r\n    [1, 1, 1],\r\n    [1, 1, 1]\r\n]\r\n\r\nX = numpy.array(X)\r\nY = numpy.array(Y)\r\n\r\nuse_cud = True\r\n\r\nmodel = Sequential()  # initialize a sequential model\r\nif use_cud:\r\n   model.add(CuDNNLSTM(3, return_sequences=False, input_shape=(1, 3))) \r\nelse:\r\n   model.add(LSTM(3, return_sequences=False, input_shape=(1, 3))) \r\nmodel.compile(loss='mse', optimizer='rmsprop', metrics=['accuracy'])\r\n\r\n\r\nmodel.fit(X, Y, batch_size=1, epochs=100, validation_split=0.5)\r\n```\r\n\r\n**Other info / logs** \r\n\r\nFor the sake of simplicity I kept the model simple, so the difference between duration isn't that big here. But with larger models, the difference is day and night. CuDNNLSTM taking 20 seconds whereas LSTM takes 3 minutes. If needed I might be able to provide a simple model that showcases this. \r\n\r\n### CuDNNLSTM logs\r\n```\r\nPython 3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)] on win32\r\nrunfile('C:/Users/31619/PycharmProjects/nn-drum-midi-synthesis/stackoverflow_2.py', wdir='C:/Users/31619/PycharmProjects/nn-drum-midi-synthesis')\r\n2021-06-28 18:22:10.218773: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudart64_110.dll\r\n2021-06-28 18:22:13.402089: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library nvcuda.dll\r\n2021-06-28 18:22:13.427953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3070 computeCapability: 8.6\r\ncoreClock: 1.725GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s\r\n2021-06-28 18:22:13.428334: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudart64_110.dll\r\n2021-06-28 18:22:13.433853: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cublas64_11.dll\r\n2021-06-28 18:22:13.434053: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cublasLt64_11.dll\r\n2021-06-28 18:22:13.436251: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cufft64_10.dll\r\n2021-06-28 18:22:13.437295: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library curand64_10.dll\r\n2021-06-28 18:22:13.439241: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cusolver64_11.dll\r\n2021-06-28 18:22:13.441256: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cusparse64_11.dll\r\n2021-06-28 18:22:13.442057: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudnn64_8.dll\r\n2021-06-28 18:22:13.442322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\r\n2021-06-28 18:22:13.443064: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-06-28 18:22:13.443999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3070 computeCapability: 8.6\r\ncoreClock: 1.725GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s\r\n2021-06-28 18:22:13.444555: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\r\n2021-06-28 18:22:14.074090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-06-28 18:22:14.074295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \r\n2021-06-28 18:22:14.074411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \r\n2021-06-28 18:22:14.074697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5235 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6)\r\n2021-06-28 18:22:18.643413: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\r\nEpoch 1/100\r\n2021-06-28 18:22:23.781377: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudnn64_8.dll\r\n2021-06-28 18:22:28.853394: I tensorflow/stream_executor/cuda/cuda_dnn.cc:359] Loaded cuDNN version 8201\r\n1/1 [==============================] - 15s 15s/step - loss: 0.9057 - accuracy: 0.0000e+00 - val_loss: 0.8996 - val_accuracy: 0.0000e+00\r\nEpoch 2/100\r\n1/1 [==============================] - 0s 22ms/step - loss: 0.8996 - accuracy: 0.0000e+00 - val_loss: 0.8952 - val_accuracy: 0.0000e+00\r\nEpoch 3/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.8952 - accuracy: 0.0000e+00 - val_loss: 0.8915 - val_accuracy: 0.0000e+00\r\nEpoch 4/100\r\n1/1 [==============================] - 0s 18ms/step - loss: 0.8915 - accuracy: 0.0000e+00 - val_loss: 0.8882 - val_accuracy: 0.0000e+00\r\nEpoch 5/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.8882 - accuracy: 0.0000e+00 - val_loss: 0.8852 - val_accuracy: 0.0000e+00\r\nEpoch 6/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.8852 - accuracy: 0.0000e+00 - val_loss: 0.8823 - val_accuracy: 0.0000e+00\r\nEpoch 7/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.8823 - accuracy: 0.0000e+00 - val_loss: 0.8797 - val_accuracy: 0.0000e+00\r\nEpoch 8/100\r\n1/1 [==============================] - 0s 21ms/step - loss: 0.8797 - accuracy: 0.0000e+00 - val_loss: 0.8771 - val_accuracy: 0.0000e+00\r\nEpoch 9/100\r\n1/1 [==============================] - 0s 24ms/step - loss: 0.8771 - accuracy: 0.0000e+00 - val_loss: 0.8746 - val_accuracy: 0.0000e+00\r\nEpoch 10/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.8746 - accuracy: 0.0000e+00 - val_loss: 0.8722 - val_accuracy: 0.0000e+00\r\nEpoch 11/100\r\n1/1 [==============================] - 0s 20ms/step - loss: 0.8722 - accuracy: 0.0000e+00 - val_loss: 0.8699 - val_accuracy: 0.0000e+00\r\nEpoch 12/100\r\n1/1 [==============================] - 0s 22ms/step - loss: 0.8699 - accuracy: 0.0000e+00 - val_loss: 0.8676 - val_accuracy: 0.0000e+00\r\nEpoch 13/100\r\n1/1 [==============================] - 0s 22ms/step - loss: 0.8676 - accuracy: 0.0000e+00 - val_loss: 0.8654 - val_accuracy: 0.0000e+00\r\nEpoch 14/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.8654 - accuracy: 0.0000e+00 - val_loss: 0.8632 - val_accuracy: 0.0000e+00\r\nEpoch 15/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.8632 - accuracy: 0.0000e+00 - val_loss: 0.8610 - val_accuracy: 0.0000e+00\r\nEpoch 16/100\r\n1/1 [==============================] - 0s 21ms/step - loss: 0.8610 - accuracy: 0.0000e+00 - val_loss: 0.8589 - val_accuracy: 0.0000e+00\r\nEpoch 17/100\r\n1/1 [==============================] - 0s 21ms/step - loss: 0.8589 - accuracy: 0.0000e+00 - val_loss: 0.8568 - val_accuracy: 0.0000e+00\r\nEpoch 18/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.8568 - accuracy: 0.0000e+00 - val_loss: 0.8547 - val_accuracy: 0.0000e+00\r\nEpoch 19/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.8547 - accuracy: 0.0000e+00 - val_loss: 0.8526 - val_accuracy: 0.0000e+00\r\nEpoch 20/100\r\n1/1 [==============================] - 0s 18ms/step - loss: 0.8526 - accuracy: 0.0000e+00 - val_loss: 0.8505 - val_accuracy: 0.0000e+00\r\nEpoch 21/100\r\n1/1 [==============================] - 0s 18ms/step - loss: 0.8505 - accuracy: 0.0000e+00 - val_loss: 0.8485 - val_accuracy: 0.0000e+00\r\nEpoch 22/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.8485 - accuracy: 0.0000e+00 - val_loss: 0.8465 - val_accuracy: 0.0000e+00\r\nEpoch 23/100\r\n1/1 [==============================] - 0s 22ms/step - loss: 0.8465 - accuracy: 0.0000e+00 - val_loss: 0.8444 - val_accuracy: 0.0000e+00\r\nEpoch 24/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.8444 - accuracy: 0.0000e+00 - val_loss: 0.8424 - val_accuracy: 0.0000e+00\r\nEpoch 25/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.8424 - accuracy: 0.0000e+00 - val_loss: 0.8404 - val_accuracy: 0.0000e+00\r\nEpoch 26/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.8404 - accuracy: 0.0000e+00 - val_loss: 0.8384 - val_accuracy: 0.0000e+00\r\nEpoch 27/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.8384 - accuracy: 0.0000e+00 - val_loss: 0.8365 - val_accuracy: 0.0000e+00\r\nEpoch 28/100\r\n1/1 [==============================] - 0s 18ms/step - loss: 0.8365 - accuracy: 0.0000e+00 - val_loss: 0.8345 - val_accuracy: 0.0000e+00\r\nEpoch 29/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.8345 - accuracy: 0.0000e+00 - val_loss: 0.8325 - val_accuracy: 0.0000e+00\r\nEpoch 30/100\r\n1/1 [==============================] - 0s 18ms/step - loss: 0.8325 - accuracy: 0.0000e+00 - val_loss: 0.8306 - val_accuracy: 0.0000e+00\r\nEpoch 31/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.8306 - accuracy: 0.0000e+00 - val_loss: 0.8286 - val_accuracy: 0.0000e+00\r\nEpoch 32/100\r\n1/1 [==============================] - 0s 21ms/step - loss: 0.8286 - accuracy: 0.0000e+00 - val_loss: 0.8267 - val_accuracy: 0.0000e+00\r\nEpoch 33/100\r\n1/1 [==============================] - 0s 20ms/step - loss: 0.8267 - accuracy: 0.0000e+00 - val_loss: 0.8247 - val_accuracy: 0.0000e+00\r\nEpoch 34/100\r\n1/1 [==============================] - 0s 20ms/step - loss: 0.8247 - accuracy: 0.0000e+00 - val_loss: 0.8228 - val_accuracy: 0.0000e+00\r\nEpoch 35/100\r\n1/1 [==============================] - 0s 22ms/step - loss: 0.8228 - accuracy: 0.0000e+00 - val_loss: 0.8209 - val_accuracy: 0.0000e+00\r\nEpoch 36/100\r\n1/1 [==============================] - 0s 21ms/step - loss: 0.8209 - accuracy: 0.0000e+00 - val_loss: 0.8189 - val_accuracy: 0.0000e+00\r\nEpoch 37/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.8189 - accuracy: 0.0000e+00 - val_loss: 0.8170 - val_accuracy: 0.0000e+00\r\nEpoch 38/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.8170 - accuracy: 0.0000e+00 - val_loss: 0.8151 - val_accuracy: 0.0000e+00\r\nEpoch 39/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.8151 - accuracy: 0.0000e+00 - val_loss: 0.8132 - val_accuracy: 0.0000e+00\r\nEpoch 40/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.8132 - accuracy: 0.0000e+00 - val_loss: 0.8113 - val_accuracy: 0.0000e+00\r\nEpoch 41/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.8113 - accuracy: 0.0000e+00 - val_loss: 0.8094 - val_accuracy: 0.0000e+00\r\nEpoch 42/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.8094 - accuracy: 0.0000e+00 - val_loss: 0.8075 - val_accuracy: 0.0000e+00\r\nEpoch 43/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.8075 - accuracy: 0.0000e+00 - val_loss: 0.8056 - val_accuracy: 0.0000e+00\r\nEpoch 44/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.8056 - accuracy: 0.0000e+00 - val_loss: 0.8037 - val_accuracy: 0.0000e+00\r\nEpoch 45/100\r\n1/1 [==============================] - 0s 21ms/step - loss: 0.8037 - accuracy: 0.0000e+00 - val_loss: 0.8018 - val_accuracy: 0.0000e+00\r\nEpoch 46/100\r\n1/1 [==============================] - 0s 20ms/step - loss: 0.8018 - accuracy: 0.0000e+00 - val_loss: 0.7999 - val_accuracy: 0.0000e+00\r\nEpoch 47/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.7999 - accuracy: 0.0000e+00 - val_loss: 0.7980 - val_accuracy: 0.0000e+00\r\nEpoch 48/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.7980 - accuracy: 0.0000e+00 - val_loss: 0.7961 - val_accuracy: 0.0000e+00\r\nEpoch 49/100\r\n1/1 [==============================] - 4s 4s/step - loss: 0.7961 - accuracy: 0.0000e+00 - val_loss: 0.7942 - val_accuracy: 0.0000e+00\r\nEpoch 50/100\r\n1/1 [==============================] - 0s 25ms/step - loss: 0.7942 - accuracy: 0.0000e+00 - val_loss: 0.7924 - val_accuracy: 0.0000e+00\r\nEpoch 51/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.7924 - accuracy: 0.0000e+00 - val_loss: 0.7905 - val_accuracy: 0.0000e+00\r\nEpoch 52/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.7905 - accuracy: 0.0000e+00 - val_loss: 0.7886 - val_accuracy: 0.0000e+00\r\nEpoch 53/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.7886 - accuracy: 0.0000e+00 - val_loss: 0.7868 - val_accuracy: 0.0000e+00\r\nEpoch 54/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.7868 - accuracy: 0.0000e+00 - val_loss: 0.7849 - val_accuracy: 0.0000e+00\r\nEpoch 55/100\r\n1/1 [==============================] - 0s 22ms/step - loss: 0.7849 - accuracy: 0.0000e+00 - val_loss: 0.7830 - val_accuracy: 0.0000e+00\r\nEpoch 56/100\r\n1/1 [==============================] - 0s 17ms/step - loss: 0.7830 - accuracy: 0.0000e+00 - val_loss: 0.7812 - val_accuracy: 0.0000e+00\r\nEpoch 57/100\r\n1/1 [==============================] - 0s 18ms/step - loss: 0.7812 - accuracy: 0.0000e+00 - val_loss: 0.7793 - val_accuracy: 0.0000e+00\r\nEpoch 58/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.7793 - accuracy: 0.0000e+00 - val_loss: 0.7775 - val_accuracy: 0.0000e+00\r\nEpoch 59/100\r\n1/1 [==============================] - 0s 20ms/step - loss: 0.7775 - accuracy: 0.0000e+00 - val_loss: 0.7756 - val_accuracy: 0.0000e+00\r\nEpoch 60/100\r\n1/1 [==============================] - 0s 20ms/step - loss: 0.7756 - accuracy: 0.0000e+00 - val_loss: 0.7738 - val_accuracy: 0.0000e+00\r\nEpoch 61/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.7738 - accuracy: 0.0000e+00 - val_loss: 0.7720 - val_accuracy: 0.0000e+00\r\nEpoch 62/100\r\n1/1 [==============================] - 0s 20ms/step - loss: 0.7720 - accuracy: 0.0000e+00 - val_loss: 0.7701 - val_accuracy: 0.0000e+00\r\nEpoch 63/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.7701 - accuracy: 0.0000e+00 - val_loss: 0.7683 - val_accuracy: 0.0000e+00\r\nEpoch 64/100\r\n1/1 [==============================] - 0s 18ms/step - loss: 0.7683 - accuracy: 0.0000e+00 - val_loss: 0.7665 - val_accuracy: 0.0000e+00\r\nEpoch 65/100\r\n1/1 [==============================] - 0s 28ms/step - loss: 0.7665 - accuracy: 0.0000e+00 - val_loss: 0.7647 - val_accuracy: 0.0000e+00\r\nEpoch 66/100\r\n1/1 [==============================] - 0s 22ms/step - loss: 0.7647 - accuracy: 0.0000e+00 - val_loss: 0.7629 - val_accuracy: 0.0000e+00\r\nEpoch 67/100\r\n1/1 [==============================] - 0s 21ms/step - loss: 0.7629 - accuracy: 0.0000e+00 - val_loss: 0.7610 - val_accuracy: 0.0000e+00\r\nEpoch 68/100\r\n1/1 [==============================] - 0s 17ms/step - loss: 0.7610 - accuracy: 0.0000e+00 - val_loss: 0.7592 - val_accuracy: 0.0000e+00\r\nEpoch 69/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.7592 - accuracy: 0.0000e+00 - val_loss: 0.7574 - val_accuracy: 0.0000e+00\r\nEpoch 70/100\r\n1/1 [==============================] - 0s 20ms/step - loss: 0.7574 - accuracy: 0.0000e+00 - val_loss: 0.7556 - val_accuracy: 0.0000e+00\r\nEpoch 71/100\r\n1/1 [==============================] - 0s 18ms/step - loss: 0.7556 - accuracy: 0.0000e+00 - val_loss: 0.7538 - val_accuracy: 0.0000e+00\r\nEpoch 72/100\r\n1/1 [==============================] - 0s 27ms/step - loss: 0.7538 - accuracy: 0.0000e+00 - val_loss: 0.7520 - val_accuracy: 0.0000e+00\r\nEpoch 73/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.7520 - accuracy: 0.0000e+00 - val_loss: 0.7502 - val_accuracy: 0.0000e+00\r\nEpoch 74/100\r\n1/1 [==============================] - 0s 20ms/step - loss: 0.7502 - accuracy: 0.0000e+00 - val_loss: 0.7485 - val_accuracy: 0.0000e+00\r\nEpoch 75/100\r\n1/1 [==============================] - 0s 17ms/step - loss: 0.7485 - accuracy: 0.0000e+00 - val_loss: 0.7467 - val_accuracy: 0.0000e+00\r\nEpoch 76/100\r\n1/1 [==============================] - 0s 18ms/step - loss: 0.7467 - accuracy: 0.0000e+00 - val_loss: 0.7449 - val_accuracy: 0.0000e+00\r\nEpoch 77/100\r\n1/1 [==============================] - 0s 18ms/step - loss: 0.7449 - accuracy: 0.0000e+00 - val_loss: 0.7431 - val_accuracy: 0.0000e+00\r\nEpoch 78/100\r\n1/1 [==============================] - 0s 18ms/step - loss: 0.7431 - accuracy: 0.0000e+00 - val_loss: 0.7414 - val_accuracy: 0.0000e+00\r\nEpoch 79/100\r\n1/1 [==============================] - 0s 18ms/step - loss: 0.7414 - accuracy: 0.0000e+00 - val_loss: 0.7396 - val_accuracy: 0.0000e+00\r\nEpoch 80/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.7396 - accuracy: 0.0000e+00 - val_loss: 0.7378 - val_accuracy: 0.0000e+00\r\nEpoch 81/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.7378 - accuracy: 0.0000e+00 - val_loss: 0.7361 - val_accuracy: 0.0000e+00\r\nEpoch 82/100\r\n1/1 [==============================] - 0s 20ms/step - loss: 0.7361 - accuracy: 0.0000e+00 - val_loss: 0.7343 - val_accuracy: 0.0000e+00\r\nEpoch 83/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.7343 - accuracy: 0.0000e+00 - val_loss: 0.7326 - val_accuracy: 0.0000e+00\r\nEpoch 84/100\r\n1/1 [==============================] - 0s 20ms/step - loss: 0.7326 - accuracy: 0.0000e+00 - val_loss: 0.7309 - val_accuracy: 0.0000e+00\r\nEpoch 85/100\r\n1/1 [==============================] - 0s 21ms/step - loss: 0.7309 - accuracy: 0.0000e+00 - val_loss: 0.7291 - val_accuracy: 0.0000e+00\r\nEpoch 86/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.7291 - accuracy: 0.0000e+00 - val_loss: 0.7274 - val_accuracy: 0.0000e+00\r\nEpoch 87/100\r\n1/1 [==============================] - 0s 20ms/step - loss: 0.7274 - accuracy: 0.0000e+00 - val_loss: 0.7257 - val_accuracy: 0.0000e+00\r\nEpoch 88/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.7257 - accuracy: 0.0000e+00 - val_loss: 0.7239 - val_accuracy: 0.0000e+00\r\nEpoch 89/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.7239 - accuracy: 0.0000e+00 - val_loss: 0.7222 - val_accuracy: 0.0000e+00\r\nEpoch 90/100\r\n1/1 [==============================] - 0s 20ms/step - loss: 0.7222 - accuracy: 0.0000e+00 - val_loss: 0.7205 - val_accuracy: 0.0000e+00\r\nEpoch 91/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.7205 - accuracy: 0.0000e+00 - val_loss: 0.7188 - val_accuracy: 0.0000e+00\r\nEpoch 92/100\r\n1/1 [==============================] - 0s 21ms/step - loss: 0.7188 - accuracy: 0.0000e+00 - val_loss: 0.7171 - val_accuracy: 0.0000e+00\r\nEpoch 93/100\r\n1/1 [==============================] - 0s 18ms/step - loss: 0.7171 - accuracy: 0.0000e+00 - val_loss: 0.7154 - val_accuracy: 0.0000e+00\r\nEpoch 94/100\r\n1/1 [==============================] - 0s 20ms/step - loss: 0.7154 - accuracy: 0.0000e+00 - val_loss: 0.7137 - val_accuracy: 0.0000e+00\r\nEpoch 95/100\r\n1/1 [==============================] - 0s 18ms/step - loss: 0.7137 - accuracy: 0.0000e+00 - val_loss: 0.7120 - val_accuracy: 0.0000e+00\r\nEpoch 96/100\r\n1/1 [==============================] - 4s 4s/step - loss: 0.7120 - accuracy: 0.0000e+00 - val_loss: 0.7104 - val_accuracy: 0.0000e+00\r\nEpoch 97/100\r\n1/1 [==============================] - 0s 20ms/step - loss: 0.7104 - accuracy: 0.0000e+00 - val_loss: 0.7087 - val_accuracy: 0.0000e+00\r\nEpoch 98/100\r\n1/1 [==============================] - 0s 24ms/step - loss: 0.7087 - accuracy: 0.0000e+00 - val_loss: 0.7070 - val_accuracy: 0.0000e+00\r\nEpoch 99/100\r\n1/1 [==============================] - 0s 18ms/step - loss: 0.7070 - accuracy: 0.0000e+00 - val_loss: 0.7053 - val_accuracy: 0.0000e+00\r\nEpoch 100/100\r\n1/1 [==============================] - 0s 18ms/step - loss: 0.7053 - accuracy: 0.0000e+00 - val_loss: 0.7037 - val_accuracy: 0.0000e+00\r\n```\r\n\r\n### LSTM logs\r\n```\r\nPython 3.8.10 (tags/v3.8.10:3d8993a, May  3 2021, 11:48:03) [MSC v.1928 64 bit (AMD64)] on win32\r\nrunfile('C:/Users/31619/PycharmProjects/nn-drum-midi-synthesis/stackoverflow_2.py', wdir='C:/Users/31619/PycharmProjects/nn-drum-midi-synthesis')\r\n2021-06-28 18:24:32.143194: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudart64_110.dll\r\n2021-06-28 18:24:35.406725: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library nvcuda.dll\r\n2021-06-28 18:24:35.430977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3070 computeCapability: 8.6\r\ncoreClock: 1.725GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s\r\n2021-06-28 18:24:35.431368: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudart64_110.dll\r\n2021-06-28 18:24:35.436952: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cublas64_11.dll\r\n2021-06-28 18:24:35.437214: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cublasLt64_11.dll\r\n2021-06-28 18:24:35.440505: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cufft64_10.dll\r\n2021-06-28 18:24:35.441703: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library curand64_10.dll\r\n2021-06-28 18:24:35.443734: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cusolver64_11.dll\r\n2021-06-28 18:24:35.445838: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cusparse64_11.dll\r\n2021-06-28 18:24:35.446559: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudnn64_8.dll\r\n2021-06-28 18:24:35.446818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\r\n2021-06-28 18:24:35.447414: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-06-28 18:24:35.448554: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3070 computeCapability: 8.6\r\ncoreClock: 1.725GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s\r\n2021-06-28 18:24:35.449097: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\r\n2021-06-28 18:24:36.313003: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-06-28 18:24:36.313208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \r\n2021-06-28 18:24:36.313326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \r\n2021-06-28 18:24:36.313617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1714 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6)\r\n2021-06-28 18:24:36.882377: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\r\nEpoch 1/100\r\n2021-06-28 18:24:39.850036: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cublas64_11.dll\r\n2021-06-28 18:24:44.822070: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cublasLt64_11.dll\r\n2021-06-28 18:24:44.822358: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\r\n1/1 [==============================] - 8s 8s/step - loss: 1.0950 - accuracy: 1.0000 - val_loss: 1.0895 - val_accuracy: 1.0000\r\nEpoch 2/100\r\n1/1 [==============================] - 0s 22ms/step - loss: 1.0895 - accuracy: 1.0000 - val_loss: 1.0856 - val_accuracy: 1.0000\r\nEpoch 3/100\r\n1/1 [==============================] - 0s 26ms/step - loss: 1.0856 - accuracy: 1.0000 - val_loss: 1.0822 - val_accuracy: 1.0000\r\nEpoch 4/100\r\n1/1 [==============================] - 0s 22ms/step - loss: 1.0822 - accuracy: 1.0000 - val_loss: 1.0793 - val_accuracy: 1.0000\r\nEpoch 5/100\r\n1/1 [==============================] - 0s 21ms/step - loss: 1.0793 - accuracy: 1.0000 - val_loss: 1.0766 - val_accuracy: 1.0000\r\nEpoch 6/100\r\n1/1 [==============================] - 0s 20ms/step - loss: 1.0766 - accuracy: 1.0000 - val_loss: 1.0741 - val_accuracy: 1.0000\r\nEpoch 7/100\r\n1/1 [==============================] - 0s 23ms/step - loss: 1.0741 - accuracy: 1.0000 - val_loss: 1.0717 - val_accuracy: 1.0000\r\nEpoch 8/100\r\n1/1 [==============================] - 0s 22ms/step - loss: 1.0717 - accuracy: 1.0000 - val_loss: 1.0694 - val_accuracy: 1.0000\r\nEpoch 9/100\r\n1/1 [==============================] - 0s 22ms/step - loss: 1.0694 - accuracy: 1.0000 - val_loss: 1.0673 - val_accuracy: 1.0000\r\nEpoch 10/100\r\n1/1 [==============================] - 0s 20ms/step - loss: 1.0673 - accuracy: 1.0000 - val_loss: 1.0652 - val_accuracy: 1.0000\r\nEpoch 11/100\r\n1/1 [==============================] - 0s 27ms/step - loss: 1.0652 - accuracy: 1.0000 - val_loss: 1.0631 - val_accuracy: 1.0000\r\nEpoch 12/100\r\n1/1 [==============================] - 0s 24ms/step - loss: 1.0631 - accuracy: 1.0000 - val_loss: 1.0611 - val_accuracy: 1.0000\r\nEpoch 13/100\r\n1/1 [==============================] - 0s 26ms/step - loss: 1.0611 - accuracy: 1.0000 - val_loss: 1.0591 - val_accuracy: 1.0000\r\nEpoch 14/100\r\n1/1 [==============================] - 0s 26ms/step - loss: 1.0591 - accuracy: 1.0000 - val_loss: 1.0571 - val_accuracy: 1.0000\r\nEpoch 15/100\r\n1/1 [==============================] - 0s 22ms/step - loss: 1.0571 - accuracy: 1.0000 - val_loss: 1.0552 - val_accuracy: 1.0000\r\nEpoch 16/100\r\n1/1 [==============================] - 0s 20ms/step - loss: 1.0552 - accuracy: 1.0000 - val_loss: 1.0533 - val_accuracy: 1.0000\r\nEpoch 17/100\r\n1/1 [==============================] - 0s 21ms/step - loss: 1.0533 - accuracy: 1.0000 - val_loss: 1.0515 - val_accuracy: 1.0000\r\nEpoch 18/100\r\n1/1 [==============================] - 0s 20ms/step - loss: 1.0515 - accuracy: 1.0000 - val_loss: 1.0497 - val_accuracy: 1.0000\r\nEpoch 19/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 1.0497 - accuracy: 1.0000 - val_loss: 1.0479 - val_accuracy: 1.0000\r\nEpoch 20/100\r\n1/1 [==============================] - 0s 21ms/step - loss: 1.0479 - accuracy: 1.0000 - val_loss: 1.0460 - val_accuracy: 1.0000\r\nEpoch 21/100\r\n1/1 [==============================] - 0s 26ms/step - loss: 1.0460 - accuracy: 1.0000 - val_loss: 1.0443 - val_accuracy: 1.0000\r\nEpoch 22/100\r\n1/1 [==============================] - 0s 22ms/step - loss: 1.0443 - accuracy: 1.0000 - val_loss: 1.0425 - val_accuracy: 1.0000\r\nEpoch 23/100\r\n1/1 [==============================] - 0s 21ms/step - loss: 1.0425 - accuracy: 1.0000 - val_loss: 1.0407 - val_accuracy: 1.0000\r\nEpoch 24/100\r\n1/1 [==============================] - 0s 22ms/step - loss: 1.0407 - accuracy: 1.0000 - val_loss: 1.0390 - val_accuracy: 1.0000\r\nEpoch 25/100\r\n1/1 [==============================] - 0s 22ms/step - loss: 1.0390 - accuracy: 1.0000 - val_loss: 1.0372 - val_accuracy: 1.0000\r\nEpoch 26/100\r\n1/1 [==============================] - 0s 25ms/step - loss: 1.0372 - accuracy: 1.0000 - val_loss: 1.0355 - val_accuracy: 1.0000\r\nEpoch 27/100\r\n1/1 [==============================] - 2s 2s/step - loss: 1.0355 - accuracy: 1.0000 - val_loss: 1.0338 - val_accuracy: 1.0000\r\nEpoch 28/100\r\n1/1 [==============================] - 0s 25ms/step - loss: 1.0338 - accuracy: 1.0000 - val_loss: 1.0321 - val_accuracy: 1.0000\r\nEpoch 29/100\r\n1/1 [==============================] - 0s 21ms/step - loss: 1.0321 - accuracy: 1.0000 - val_loss: 1.0304 - val_accuracy: 1.0000\r\nEpoch 30/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 1.0304 - accuracy: 1.0000 - val_loss: 1.0287 - val_accuracy: 1.0000\r\nEpoch 31/100\r\n1/1 [==============================] - 0s 21ms/step - loss: 1.0287 - accuracy: 1.0000 - val_loss: 1.0270 - val_accuracy: 1.0000\r\nEpoch 32/100\r\n1/1 [==============================] - 0s 25ms/step - loss: 1.0270 - accuracy: 1.0000 - val_loss: 1.0252 - val_accuracy: 1.0000\r\nEpoch 33/100\r\n1/1 [==============================] - 0s 22ms/step - loss: 1.0252 - accuracy: 1.0000 - val_loss: 1.0236 - val_accuracy: 1.0000\r\nEpoch 34/100\r\n1/1 [==============================] - 0s 21ms/step - loss: 1.0236 - accuracy: 1.0000 - val_loss: 1.0219 - val_accuracy: 1.0000\r\nEpoch 35/100\r\n1/1 [==============================] - 0s 22ms/step - loss: 1.0219 - accuracy: 1.0000 - val_loss: 1.0202 - val_accuracy: 1.0000\r\nEpoch 36/100\r\n1/1 [==============================] - 0s 24ms/step - loss: 1.0202 - accuracy: 1.0000 - val_loss: 1.0185 - val_accuracy: 1.0000\r\nEpoch 37/100\r\n1/1 [==============================] - 0s 21ms/step - loss: 1.0185 - accuracy: 1.0000 - val_loss: 1.0169 - val_accuracy: 1.0000\r\nEpoch 38/100\r\n1/1 [==============================] - 0s 25ms/step - loss: 1.0169 - accuracy: 1.0000 - val_loss: 1.0152 - val_accuracy: 1.0000\r\nEpoch 39/100\r\n1/1 [==============================] - 0s 22ms/step - loss: 1.0152 - accuracy: 1.0000 - val_loss: 1.0136 - val_accuracy: 1.0000\r\nEpoch 40/100\r\n1/1 [==============================] - 0s 22ms/step - loss: 1.0136 - accuracy: 1.0000 - val_loss: 1.0119 - val_accuracy: 1.0000\r\nEpoch 41/100\r\n1/1 [==============================] - 0s 23ms/step - loss: 1.0119 - accuracy: 1.0000 - val_loss: 1.0103 - val_accuracy: 1.0000\r\nEpoch 42/100\r\n1/1 [==============================] - 0s 20ms/step - loss: 1.0103 - accuracy: 1.0000 - val_loss: 1.0086 - val_accuracy: 1.0000\r\nEpoch 43/100\r\n1/1 [==============================] - 0s 20ms/step - loss: 1.0086 - accuracy: 1.0000 - val_loss: 1.0070 - val_accuracy: 1.0000\r\nEpoch 44/100\r\n1/1 [==============================] - 0s 26ms/step - loss: 1.0070 - accuracy: 1.0000 - val_loss: 1.0053 - val_accuracy: 1.0000\r\nEpoch 45/100\r\n1/1 [==============================] - 0s 26ms/step - loss: 1.0053 - accuracy: 1.0000 - val_loss: 1.0036 - val_accuracy: 1.0000\r\nEpoch 46/100\r\n1/1 [==============================] - 0s 20ms/step - loss: 1.0036 - accuracy: 1.0000 - val_loss: 1.0020 - val_accuracy: 1.0000\r\nEpoch 47/100\r\n1/1 [==============================] - 0s 24ms/step - loss: 1.0020 - accuracy: 1.0000 - val_loss: 1.0003 - val_accuracy: 1.0000\r\nEpoch 48/100\r\n1/1 [==============================] - 0s 24ms/step - loss: 1.0003 - accuracy: 1.0000 - val_loss: 0.9986 - val_accuracy: 1.0000\r\nEpoch 49/100\r\n1/1 [==============================] - 0s 22ms/step - loss: 0.9986 - accuracy: 1.0000 - val_loss: 0.9970 - val_accuracy: 1.0000\r\nEpoch 50/100\r\n1/1 [==============================] - 0s 20ms/step - loss: 0.9970 - accuracy: 1.0000 - val_loss: 0.9953 - val_accuracy: 1.0000\r\nEpoch 51/100\r\n1/1 [==============================] - 0s 22ms/step - loss: 0.9953 - accuracy: 1.0000 - val_loss: 0.9936 - val_accuracy: 1.0000\r\nEpoch 52/100\r\n1/1 [==============================] - 0s 24ms/step - loss: 0.9936 - accuracy: 1.0000 - val_loss: 0.9919 - val_accuracy: 1.0000\r\nEpoch 53/100\r\n1/1 [==============================] - 0s 20ms/step - loss: 0.9919 - accuracy: 1.0000 - val_loss: 0.9903 - val_accuracy: 1.0000\r\nEpoch 54/100\r\n1/1 [==============================] - 0s 26ms/step - loss: 0.9903 - accuracy: 1.0000 - val_loss: 0.9886 - val_accuracy: 1.0000\r\nEpoch 55/100\r\n1/1 [==============================] - 0s 23ms/step - loss: 0.9886 - accuracy: 1.0000 - val_loss: 0.9869 - val_accuracy: 1.0000\r\nEpoch 56/100\r\n1/1 [==============================] - 0s 23ms/step - loss: 0.9869 - accuracy: 1.0000 - val_loss: 0.9852 - val_accuracy: 1.0000\r\nEpoch 57/100\r\n1/1 [==============================] - 0s 25ms/step - loss: 0.9852 - accuracy: 1.0000 - val_loss: 0.9835 - val_accuracy: 1.0000\r\nEpoch 58/100\r\n1/1 [==============================] - 0s 26ms/step - loss: 0.9835 - accuracy: 1.0000 - val_loss: 0.9818 - val_accuracy: 1.0000\r\nEpoch 59/100\r\n1/1 [==============================] - 0s 22ms/step - loss: 0.9818 - accuracy: 1.0000 - val_loss: 0.9801 - val_accuracy: 1.0000\r\nEpoch 60/100\r\n1/1 [==============================] - 0s 20ms/step - loss: 0.9801 - accuracy: 1.0000 - val_loss: 0.9784 - val_accuracy: 1.0000\r\nEpoch 61/100\r\n1/1 [==============================] - 0s 21ms/step - loss: 0.9784 - accuracy: 1.0000 - val_loss: 0.9766 - val_accuracy: 1.0000\r\nEpoch 62/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.9766 - accuracy: 1.0000 - val_loss: 0.9749 - val_accuracy: 1.0000\r\nEpoch 63/100\r\n1/1 [==============================] - 0s 21ms/step - loss: 0.9749 - accuracy: 1.0000 - val_loss: 0.9732 - val_accuracy: 1.0000\r\nEpoch 64/100\r\n1/1 [==============================] - 0s 22ms/step - loss: 0.9732 - accuracy: 1.0000 - val_loss: 0.9715 - val_accuracy: 1.0000\r\nEpoch 65/100\r\n1/1 [==============================] - 0s 21ms/step - loss: 0.9715 - accuracy: 1.0000 - val_loss: 0.9698 - val_accuracy: 1.0000\r\nEpoch 66/100\r\n1/1 [==============================] - 0s 28ms/step - loss: 0.9698 - accuracy: 1.0000 - val_loss: 0.9680 - val_accuracy: 1.0000\r\nEpoch 67/100\r\n1/1 [==============================] - 0s 22ms/step - loss: 0.9680 - accuracy: 1.0000 - val_loss: 0.9663 - val_accuracy: 1.0000\r\nEpoch 68/100\r\n1/1 [==============================] - 0s 24ms/step - loss: 0.9663 - accuracy: 1.0000 - val_loss: 0.9646 - val_accuracy: 1.0000\r\nEpoch 69/100\r\n1/1 [==============================] - 0s 20ms/step - loss: 0.9646 - accuracy: 1.0000 - val_loss: 0.9628 - val_accuracy: 1.0000\r\nEpoch 70/100\r\n1/1 [==============================] - 2s 2s/step - loss: 0.9628 - accuracy: 1.0000 - val_loss: 0.9611 - val_accuracy: 1.0000\r\nEpoch 71/100\r\n1/1 [==============================] - 0s 23ms/step - loss: 0.9611 - accuracy: 1.0000 - val_loss: 0.9593 - val_accuracy: 1.0000\r\nEpoch 72/100\r\n1/1 [==============================] - 0s 26ms/step - loss: 0.9593 - accuracy: 1.0000 - val_loss: 0.9576 - val_accuracy: 1.0000\r\nEpoch 73/100\r\n1/1 [==============================] - 0s 27ms/step - loss: 0.9576 - accuracy: 1.0000 - val_loss: 0.9558 - val_accuracy: 1.0000\r\nEpoch 74/100\r\n1/1 [==============================] - 0s 21ms/step - loss: 0.9558 - accuracy: 1.0000 - val_loss: 0.9541 - val_accuracy: 1.0000\r\nEpoch 75/100\r\n1/1 [==============================] - 0s 25ms/step - loss: 0.9541 - accuracy: 1.0000 - val_loss: 0.9523 - val_accuracy: 1.0000\r\nEpoch 76/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.9523 - accuracy: 1.0000 - val_loss: 0.9506 - val_accuracy: 1.0000\r\nEpoch 77/100\r\n1/1 [==============================] - 0s 21ms/step - loss: 0.9506 - accuracy: 1.0000 - val_loss: 0.9488 - val_accuracy: 1.0000\r\nEpoch 78/100\r\n1/1 [==============================] - 0s 19ms/step - loss: 0.9488 - accuracy: 1.0000 - val_loss: 0.9471 - val_accuracy: 1.0000\r\nEpoch 79/100\r\n1/1 [==============================] - 0s 34ms/step - loss: 0.9471 - accuracy: 1.0000 - val_loss: 0.9453 - val_accuracy: 1.0000\r\nEpoch 80/100\r\n1/1 [==============================] - 0s 24ms/step - loss: 0.9453 - accuracy: 1.0000 - val_loss: 0.9436 - val_accuracy: 1.0000\r\nEpoch 81/100\r\n1/1 [==============================] - 0s 21ms/step - loss: 0.9436 - accuracy: 1.0000 - val_loss: 0.9418 - val_accuracy: 1.0000\r\nEpoch 82/100\r\n1/1 [==============================] - 0s 22ms/step - loss: 0.9418 - accuracy: 1.0000 - val_loss: 0.9401 - val_accuracy: 1.0000\r\nEpoch 83/100\r\n1/1 [==============================] - 0s 29ms/step - loss: 0.9401 - accuracy: 1.0000 - val_loss: 0.9383 - val_accuracy: 1.0000\r\nEpoch 84/100\r\n1/1 [==============================] - 0s 22ms/step - loss: 0.9383 - accuracy: 1.0000 - val_loss: 0.9365 - val_accuracy: 1.0000\r\nEpoch 85/100\r\n1/1 [==============================] - 0s 26ms/step - loss: 0.9365 - accuracy: 1.0000 - val_loss: 0.9348 - val_accuracy: 1.0000\r\nEpoch 86/100\r\n1/1 [==============================] - 0s 20ms/step - loss: 0.9348 - accuracy: 1.0000 - val_loss: 0.9330 - val_accuracy: 1.0000\r\nEpoch 87/100\r\n1/1 [==============================] - 0s 21ms/step - loss: 0.9330 - accuracy: 1.0000 - val_loss: 0.9313 - val_accuracy: 1.0000\r\nEpoch 88/100\r\n1/1 [==============================] - 0s 25ms/step - loss: 0.9313 - accuracy: 1.0000 - val_loss: 0.9295 - val_accuracy: 1.0000\r\nEpoch 89/100\r\n1/1 [==============================] - 0s 21ms/step - loss: 0.9295 - accuracy: 1.0000 - val_loss: 0.9277 - val_accuracy: 1.0000\r\nEpoch 90/100\r\n1/1 [==============================] - 0s 21ms/step - loss: 0.9277 - accuracy: 1.0000 - val_loss: 0.9260 - val_accuracy: 1.0000\r\nEpoch 91/100\r\n1/1 [==============================] - 0s 23ms/step - loss: 0.9260 - accuracy: 1.0000 - val_loss: 0.9243 - val_accuracy: 1.0000\r\nEpoch 92/100\r\n1/1 [==============================] - 0s 25ms/step - loss: 0.9243 - accuracy: 1.0000 - val_loss: 0.9225 - val_accuracy: 1.0000\r\nEpoch 93/100\r\n1/1 [==============================] - 0s 22ms/step - loss: 0.9225 - accuracy: 1.0000 - val_loss: 0.9207 - val_accuracy: 1.0000\r\nEpoch 94/100\r\n1/1 [==============================] - 0s 23ms/step - loss: 0.9207 - accuracy: 1.0000 - val_loss: 0.9189 - val_accuracy: 1.0000\r\nEpoch 95/100\r\n1/1 [==============================] - 0s 26ms/step - loss: 0.9189 - accuracy: 1.0000 - val_loss: 0.9171 - val_accuracy: 1.0000\r\nEpoch 96/100\r\n1/1 [==============================] - 0s 21ms/step - loss: 0.9171 - accuracy: 1.0000 - val_loss: 0.9154 - val_accuracy: 1.0000\r\nEpoch 97/100\r\n1/1 [==============================] - 0s 26ms/step - loss: 0.9154 - accuracy: 1.0000 - val_loss: 0.9137 - val_accuracy: 1.0000\r\nEpoch 98/100\r\n1/1 [==============================] - 0s 26ms/step - loss: 0.9137 - accuracy: 1.0000 - val_loss: 0.9119 - val_accuracy: 1.0000\r\nEpoch 99/100\r\n1/1 [==============================] - 0s 20ms/step - loss: 0.9119 - accuracy: 1.0000 - val_loss: 0.9102 - val_accuracy: 1.0000\r\nEpoch 100/100\r\n1/1 [==============================] - 0s 22ms/step - loss: 0.9102 - accuracy: 1.0000 - val_loss: 0.9084 - val_accuracy: 1.0000\r\n\r\n```", "comments": ["@dosier \r\n\r\nCould you please refer the similar issues [#25843](https://github.com/tensorflow/tensorflow/issues/25843), [#8860](https://github.com/keras-team/keras/issues/8860) ,also refer this [comment](https://stackoverflow.com/questions/49987261/what-is-the-difference-between-cudnnlstm-and-lstm-in-keras) , and let us know if it helps.Thanks", "@dosier \r\nCould you please refer [this](https://developer.nvidia.com/blog/optimizing-recurrent-neural-networks-cudnn-5/) also  ,hope it helps.Thanks", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 50486, "title": "Label_image demo always gives same outputs ", "body": "@tensorflow/micro\r\n\r\nHi all !\r\n\r\nWhile testing our models with basic [label_image](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/examples/label_image) example, we faced with strange results.\r\n\r\nWe tried _label_image_ with 2 different YOLO models with their corresponding label.txt. However regardless the input images and labels, the test output is always in the same order as [2 3 0 1]. Finally we also gave the Grace Hopper image from official source and still we faced with same issue. You can see the outputs in the image below.\r\n\r\nNormally our models are working smoothly on PC. But, it is important for us to test them in our iMX6 device with this basic sample. Do you have any idea or solution about this problem ?\r\nThank you in advance.\r\n\r\n![image](https://user-images.githubusercontent.com/56031118/123631875-8b6dac00-d817-11eb-8ba0-17047e522da4.png)\r\n\r\n\r\n\r\n\r\n", "comments": ["@ardtrkc  Could you please submit a new issue [here](https://github.com/tensorflow/tflite-micro/issues/new) since all micro related issues are handled separately.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50486\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50486\">No</a>\n"]}, {"number": 50485, "title": "Fix TransferLiteralFromDevice bug which appears in Tensorflow Master", "body": "The GenericTransferManager::GetByteSizeRequirement() used in GenericTransferManager::TransferLiteralFromDevice() calculate the Memcpy size as ShapeUtil::ByteSizeOf(shape, pointer_size_) + metadata_size for dynamic shape; However, the data and meta memory are allocated separately in Literal. This PR fix this by malloc only one memory to store both the data and meta.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F50485) for more info**.\n\n<!-- need_sender_cla -->", "\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F50485) for more info**.\n\n<!-- need_sender_cla -->", "> @googlebot I signed it!\r\n\r\n", "@cheshire Can you please review this PR ? Thanks!", "@luchangli03 Can you please check @cheshire's comments and keep us posted ? Thanks!"]}, {"number": 50483, "title": "Is there an example or a document for golang or java calling tfs by grpc ?", "body": "**System information**\r\n- TensorFlow version (you are using): 2.5.0\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n", "comments": []}, {"number": 50482, "title": "tf dataset builder issues", "body": "config = tfds.download.DownloadConfig(verify_ssl=False)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nTypeError: __init__() got an unexpected keyword argument 'verify_ssl'\r\n>>> config = tfds.download.DownloadConfig()\r\n>>> builder.download_and_prepare(download_config=config)\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/ubuntu/anaconda3/envs/test_gpu/lib/python3.7/site-packages/tensorflow_datasets/core/api_utils.py\", line 52, in disallow_positional_args_dec\r\n    return fn(*args, **kwargs)\r\n  File \"/home/ubuntu/anaconda3/envs/test_gpu/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_builder.py\", line 262, in download_and_prepare\r\n    download_config=download_config)\r\n  File \"/home/ubuntu/anaconda3/envs/test_gpu/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_builder.py\", line 662, in _make_download_manager\r\n    register_checksums=download_config.register_checksums,\r\n  File \"/home/ubuntu/anaconda3/envs/test_gpu/lib/python3.7/site-packages/tensorflow_datasets/core/api_utils.py\", line 52, in disallow_positional_args_dec\r\n    return fn(*args, **kwargs)\r\n  File \"/home/ubuntu/anaconda3/envs/test_gpu/lib/python3.7/site-packages/tensorflow_datasets/core/download/download_manager.py\", line 177, in __init__\r\n    self._sizes_checksums = checksums.get_all_sizes_checksums()\r\n  File \"/home/ubuntu/anaconda3/envs/test_gpu/lib/python3.7/site-packages/tensorflow_datasets/core/download/checksums.py\", line 129, in get_all_sizes_checksums\r\n    data = _get_sizes_checksums(path)\r\n  File \"/home/ubuntu/anaconda3/envs/test_gpu/lib/python3.7/site-packages/tensorflow_datasets/core/download/checksums.py\", line 119, in _get_sizes_checksums\r\n    url, size, checksum = line.rsplit(' ', 2)\r\nValueError: not enough values to unpack (expected 3, got 1)\r\n\r\n\r\n\r\ni am getting this error after trying to build dataset config file.\r\n\r\n> # Name                    Version                   Build  Channel\r\n_libgcc_mutex             0.1                        main\r\n_openmp_mutex             4.5                       1_gnu\r\n_tflow_select             2.1.0                       gpu    anaconda\r\nabsl-py                   0.13.0           py37h06a4308_0\r\naiohttp                   3.6.3            py37h7b6447c_0    anaconda\r\nastor                     0.8.1                    py37_0    anaconda\r\nastunparse                1.6.3                      py_0    anaconda\r\nasync-timeout             3.0.1                    py37_0    anaconda\r\nattrs                     20.2.0                     py_0    anaconda\r\nbackcall                  0.2.0                    pypi_0    pypi\r\nblas                      1.0                         mkl    anaconda\r\nblinker                   1.4                      py37_0    anaconda\r\nbrotlipy                  0.7.0           py37h7b6447c_1000    anaconda\r\nc-ares                    1.17.1               h27cfd23_0\r\nca-certificates           2020.10.14                    0    anaconda\r\ncached-property           1.5.2                    pypi_0    pypi\r\ncachetools                4.1.1                      py_0    anaconda\r\ncertifi                   2020.6.20                py37_0    anaconda\r\ncffi                      1.14.3           py37he30daa8_0    anaconda\r\nchardet                   3.0.4                 py37_1003    anaconda\r\nclick                     7.1.2                      py_0    anaconda\r\ncoverage                  5.3              py37h7b6447c_0    anaconda\r\ncryptography              3.1.1            py37h1ba5d50_0    anaconda\r\ncudatoolkit               10.1.243             h6bb024c_0    anaconda\r\ncudnn                     7.6.5                cuda10.1_0    anaconda\r\ncupti                     10.1.168                      0    anaconda\r\ncycler                    0.10.0                   pypi_0    pypi\r\ncython                    0.29.23                  pypi_0    pypi\r\ndecorator                 5.0.9                    pypi_0    pypi\r\ndill                      0.3.4                    pypi_0    pypi\r\ndm-tree                   0.1.6                    pypi_0    pypi\r\nflatbuffers               1.12                     pypi_0    pypi\r\nfuture                    0.18.2                   py37_1    anaconda\r\ngast                      0.4.0                      py_0    anaconda\r\ngin-config                0.4.0                    pypi_0    pypi\r\ngoogle-api-core           1.30.0                   pypi_0    pypi\r\ngoogle-api-python-client  2.10.0                   pypi_0    pypi\r\ngoogle-auth               1.32.0                   pypi_0    pypi\r\ngoogle-auth-httplib2      0.1.0                    pypi_0    pypi\r\ngoogle-auth-oauthlib      0.4.1                      py_2    anaconda\r\ngoogle-cloud-bigquery     2.20.0                   pypi_0    pypi\r\ngoogle-cloud-core         1.7.1                    pypi_0    pypi\r\ngoogle-crc32c             1.1.2                    pypi_0    pypi\r\ngoogle-pasta              0.2.0                      py_0    anaconda\r\ngoogle-resumable-media    1.3.1                    pypi_0    pypi\r\ngoogleapis-common-protos  1.53.0                   pypi_0    pypi\r\ngrpcio                    1.34.1                   pypi_0    pypi\r\nh5py                      3.1.0                    pypi_0    pypi\r\nhdf5                      1.10.6               hb1b8bf9_0    anaconda\r\nhttplib2                  0.19.1                   pypi_0    pypi\r\nidna                      2.10                       py_0    anaconda\r\nimportlib-metadata        2.0.0                      py_1    anaconda\r\nimportlib-resources       5.2.0                    pypi_0    pypi\r\nintel-openmp              2020.2                      254    anaconda\r\nipython                   7.25.0                   pypi_0    pypi\r\nipython-genutils          0.2.0                    pypi_0    pypi\r\njedi                      0.18.0                   pypi_0    pypi\r\njoblib                    1.0.1                    pypi_0    pypi\r\nkaggle                    1.5.12                   pypi_0    pypi\r\nkeras-nightly             2.5.0.dev2021032900          pypi_0    pypi\r\nkeras-preprocessing       1.1.2              pyhd3eb1b0_0\r\nkiwisolver                1.3.1                    pypi_0    pypi\r\nld_impl_linux-64          2.35.1               h7274673_9\r\nlibffi                    3.3                  he6710b0_2\r\nlibgcc-ng                 9.3.0               h5101ec6_17\r\nlibgfortran-ng            7.3.0                hdf63c60_0    anaconda\r\nlibgomp                   9.3.0               h5101ec6_17\r\nlibprotobuf               3.14.0               h8c45485_0\r\nlibstdcxx-ng              9.3.0               hd4cf53a_17\r\nmarkdown                  3.3.2                    py37_0    anaconda\r\nmatplotlib                3.4.2                    pypi_0    pypi\r\nmatplotlib-inline         0.1.2                    pypi_0    pypi\r\nmediapy                   1.0.2                    pypi_0    pypi\r\nmkl                       2019.4                      243    anaconda\r\nmkl-service               2.3.0            py37he904b0f_0    anaconda\r\nmkl_fft                   1.2.0            py37h23d657b_0    anaconda\r\nmkl_random                1.1.0            py37hd6b4f25_0    anaconda\r\nmultidict                 4.7.6            py37h7b6447c_1    anaconda\r\nncurses                   6.2                  he6710b0_1\r\nnumpy                     1.19.5                   pypi_0    pypi\r\nnumpy-base                1.19.1           py37hfa32c7d_0    anaconda\r\noauth2client              4.1.3                    pypi_0    pypi\r\noauthlib                  3.1.0                      py_0    anaconda\r\nopencv-python-headless    4.5.2.54                 pypi_0    pypi\r\nopenssl                   1.1.1k               h27cfd23_0\r\nopt-einsum                3.3.0                    pypi_0    pypi\r\nopt_einsum                3.1.0                      py_0    anaconda\r\npackaging                 20.9                     pypi_0    pypi\r\npandas                    1.2.5                    pypi_0    pypi\r\nparso                     0.8.2                    pypi_0    pypi\r\npexpect                   4.8.0                    pypi_0    pypi\r\npickleshare               0.7.5                    pypi_0    pypi\r\npillow                    8.2.0                    pypi_0    pypi\r\npip                       21.1.2           py37h06a4308_0\r\nportalocker               2.0.0                    pypi_0    pypi\r\npromise                   2.3                      py37_0    anaconda\r\nprompt-toolkit            3.0.19                   pypi_0    pypi\r\nproto-plus                1.18.1                   pypi_0    pypi\r\nprotobuf                  3.14.0           py37h2531618_1\r\npsutil                    5.8.0                    pypi_0    pypi\r\nptyprocess                0.7.0                    pypi_0    pypi\r\npy-cpuinfo                8.0.0                    pypi_0    pypi\r\npyasn1                    0.4.8                      py_0    anaconda\r\npyasn1-modules            0.2.8                      py_0    anaconda\r\npycocotools               2.0.2                    pypi_0    pypi\r\npycparser                 2.20                       py_2    anaconda\r\npygments                  2.9.0                    pypi_0    pypi\r\npyjwt                     1.7.1                    py37_0    anaconda\r\npyopenssl                 19.1.0                     py_1    anaconda\r\npyparsing                 2.4.7                    pypi_0    pypi\r\npysocks                   1.7.1                    py37_1    anaconda\r\npython                    3.7.10               h12debd9_4\r\npython-dateutil           2.8.1                    pypi_0    pypi\r\npython-flatbuffers        1.12               pyhd3eb1b0_0\r\npython-slugify            5.0.2                    pypi_0    pypi\r\npytz                      2021.1                   pypi_0    pypi\r\npyyaml                    5.4.1                    pypi_0    pypi\r\nreadline                  8.1                  h27cfd23_0\r\nrequests                  2.24.0                     py_0    anaconda\r\nrequests-oauthlib         1.3.0                      py_0    anaconda\r\nrsa                       4.6                        py_0    anaconda\r\nsacrebleu                 1.5.1                    pypi_0    pypi\r\nscikit-learn              0.24.2                   pypi_0    pypi\r\nscipy                     1.6.2            py37h91f5cce_0\r\nsentencepiece             0.1.96                   pypi_0    pypi\r\nseqeval                   1.2.2                    pypi_0    pypi\r\nsetuptools                52.0.0           py37h06a4308_0\r\nsix                       1.15.0                     py_0    anaconda\r\nsqlite                    3.36.0               hc218d9a_0\r\ntensorboard               2.5.0                      py_0\r\ntensorboard-data-server   0.6.1                    pypi_0    pypi\r\ntensorboard-plugin-wit    1.6.0                      py_0    anaconda\r\ntensorflow                2.5.0                    pypi_0    pypi\r\ntensorflow-addons         0.13.0                   pypi_0    pypi\r\ntensorflow-base           2.4.1           gpu_py37h29c2da4_0\r\ntensorflow-datasets       4.3.0                    pypi_0    pypi\r\ntensorflow-estimator      2.5.0              pyh7b7c402_0\r\ntensorflow-gpu            2.4.1                h30adc30_0\r\ntensorflow-hub            0.12.0                   pypi_0    pypi\r\ntensorflow-metadata       1.1.0                    pypi_0    pypi\r\ntensorflow-model-optimization 0.6.0                    pypi_0    pypi\r\ntermcolor                 1.1.0                    py37_1    anaconda\r\ntext-unidecode            1.3                      pypi_0    pypi\r\ntf-models-official        2.5.0                    pypi_0    pypi\r\ntf-slim                   1.1.0                    pypi_0    pypi\r\nthreadpoolctl             2.1.0                    pypi_0    pypi\r\ntk                        8.6.10               hbc83047_0\r\ntqdm                      4.61.1                   pypi_0    pypi\r\ntraitlets                 5.0.5                    pypi_0    pypi\r\ntypeguard                 2.12.1                   pypi_0    pypi\r\ntyping_extensions         3.7.4.3                    py_0    anaconda\r\nuritemplate               3.0.1                    pypi_0    pypi\r\nurllib3                   1.25.11                    py_0    anaconda\r\nwcwidth                   0.2.5                    pypi_0    pypi\r\nwerkzeug                  1.0.1                      py_0    anaconda\r\nwheel                     0.36.2             pyhd3eb1b0_0\r\nwrapt                     1.12.1           py37h7b6447c_1    anaconda\r\nxz                        5.2.5                h7b6447c_0\r\nyaml                      0.2.5                h7b6447c_0    anaconda\r\nyarl                      1.6.2            py37h7b6447c_0    anaconda\r\nzipp                      3.3.1                      py_0    anaconda\r\nzlib                      1.2.11               h7b6447c_3\r\n", "comments": ["@riyaj8888  Please upgrade you  tfds version to 4.3.0 and it will work.  Please find the gist [here](https://colab.research.google.com/gist/saikumarchalla/d9d06346416670be0ff3f2cbc7e56543/untitled103.ipynb).Thanks!", "@riyaj8888  Is the issue resolved for you?", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50482\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50482\">No</a>\n"]}, {"number": 50481, "title": "Wrong access modifiers in tf::ResourceHandle", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): all\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.5.0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: 11.1\r\n- GPU model and memory: all\r\n\r\n**Describe the current behavior**\r\nDuring implementing an TensorFlow extension I stumbled upon this code line: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/resource_handle.h#L99\r\n\r\nI assume it should be ```private``` instead of ```public```.\r\n\r\n**Describe the expected behavior**\r\nClass probably should prevent direct access to class members.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): no\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nN/A\r\n\r\n**Other info / logs**\r\nN/A", "comments": ["Moving this issue to closed status as pr is merged."]}, {"number": 50480, "title": "int8 conversion error \"num_input_elements != num_output_elements\" using TensorFlow 1.15", "body": "### 1. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- TensorFlow installation (pip package or built from source): pip\r\n- TensorFlow library (version, if pip package or github SHA, if built from source): 1.15.0; 2.3.0\r\n\r\n### 2. Code\r\n\r\nProvide code to help us reproduce your issues using one of the following options:\r\n\r\n####Paste your code here or provide a link to a custom end-to-end colab\r\nI followed *post-training quantization)[https://www.tensorflow.org/lite/performance/post_training_quantization] to convert my pb file to an int8 tf lite model in TensorFlow 1.15.0. But I meet an error: \r\n**num_input_elements != num_output_elements (32400 != 874800)Node number 81 (RESHAPE) failed to prepare.**\r\n\r\n##### conversion code\r\n```\r\n    converter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(\r\n        \"model.pb\", \r\n        [\"input_tensor\"], \r\n        [\"final_output\"], \r\n        input_shapes=input_shape\r\n        )\r\n    converter.allow_custom_ops = True\r\n\r\n    converter.optimizations = [tf.lite.Optimize.DEFAULT] # require representative dataset\r\n    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\n    converter.inference_input_type = tf.int8 \r\n    converter.inference_output_type = tf.int8 \r\n\r\n    # necessary for calibartion\r\n    converter.representative_dataset = representative_data_gen\r\n    tflite_int8_model = converter.convert()\r\n  \r\n    with open(os.path.join(model_root_dir, \"convertedTFLite/int8_default.lite\"), \"wb\") as f:\r\n        f.write(tflite_int8_model)\r\n```\r\n\r\n##### representative dataset\r\n```\r\ndef preprocess_image(src_image, input_tensor_size):\r\n    output_image = src_image[:, :, (2, 1, 0)] # cvtColor\r\n    output_image = cv2.resize(\r\n        output_image,\r\n        dsize=(input_tensor_size[0], input_tensor_size[1]),\r\n        interpolation=cv2.INTER_LINEAR\r\n    )\r\n    output_image = output_image.astype('float32') / 255.0\r\n    img_mean = np.array([0.5, 0.5, 0.5].reshape((1, 1, len([0.5, 0.5, 0.5])))\r\n    img_std = np.array([0.5, 0.5, 0.5]).reshape((1, 1, len([0.5, 0.5, 0.5])))\r\n    output_image -= img_mean\r\n    output_image /= img_std\r\n    \r\n    return output_image\r\n```\r\n\r\n```\r\ndef representative_data_gen(): \r\n    DATASET_DIR = \"train_image\"\r\n    GT_DIR = \"classID\"\r\n    \r\n    train_images = glob.glob(os.path.join(DATASET_DIR, \"*.png\"))\r\n    \r\n    counter = 0\r\n    input_tensor_size = [int(360), int(360)]\r\n    \r\n    for image_path in train_images:\r\n        if os.path.exists(image_path):\r\n            print(str(counter) + \" / \" + str(len(train_images)) + \": \" + image_path)\r\n            input_image = cv2.imread(image_path)\r\n            preprocessed_image = preprocess_image(input_image, input_tensor_size)\r\n            image_in = preprocessed_image[np.newaxis, ...].astype(np.float32)\r\n            counter +=1\r\n            yield [image_in.astype(np.float32)]\r\n\r\n        else:\r\n            continue\r\n```\r\n\r\n### 3. Failure after conversion\r\nWhen I convert the pb file to TFLite int8 model with TensorFlow 1.15.0, the process failed with the following error message:\r\n\r\n```\r\nRuntimeError: tensorflow/lite/kernels/reshape.cc:66 num_input_elements != num_output_elements (32400 != 874800)Node number 81 (RESHAPE) failed to prepare.\r\ntensorflow/lite/kernels/reshape.cc:66 num_input_elements != num_output_elements (32400 != 874800)Node number 81 (RESHAPE) failed to prepare.\r\n```\r\n\r\n\r\nFor comparison, I converted the pb model to fp16 and uint8 precision without representative dataset, and the models were successfully converted. I tried to switch to TensorFlow 2.3.0 and convert the pb model to int8 precision with representative dataset, and the model was successfully converted. \r\nAs a result, the error only happens when converting with TensorFlow 1.15.0. \r\nIs there any method to solve this error?\r\n\r\nThe attachment contains the pb file and the images for representative dataset.\r\n[model_dataset.tar.gz](https://github.com/tensorflow/tensorflow/files/6722569/model_dataset.tar.gz)\r\n\r\nBest regards,\r\nRahn\r\n", "comments": ["Can you try to convert and run the TFLite model with the current TF version?", "Hi, \r\nWhich TF version should be tested? Do you mean TensorFlow 2.5?\r\nI converted and ran the TFLite model with TensorFlow 2.3.0, the model could be converted successfully and produced detection results. However, the error mentioned above only occurs when using TensorFlow 1.15.\r\n", "Right. Our latest version is 2.5.0. We no longer maintain 1.15 branch except for critical security bugs.", "Thank you for the information, I'll convert my model based on TensorFlow 2.5.0 instead of 1.15.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50480\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50480\">No</a>\n"]}, {"number": 50477, "title": "Changing default monitored metric for ReduceLRonPlateau from \"val_loss\" to \"loss\"", "body": "- TensorFlow version: v2 (not relevant, feature change request is documentation-based)\r\n- Willing to contribute it: Yes, it should be a one line change\r\n\r\n\r\nBased on the documentation and my experience with tf, the default monitored metric for the callback ReduceLRonPlateau is \"val_loss\".\r\nI suggest it should be changed to \"loss\" (the training loss).\r\nMy understanding of the rational for reducing the learning rate is that a learning rate that is too high prevents the model from converging to the nearby local optima. While I understand that the end goal is to minimize the validation loss and that monitoring this quantity is tempting, I do not understand the rational for monitoring it to reduce the learning rate.\r\n\r\n\r\nSpecifically, I consider 4 situations as a 2x2 matrix. The training loss is either decreasing, or it is not. Similarly, the validation loss is either decreasing, or it is not.\r\n\r\n(1) If both the training and the validation losses are decreasing, then it does not matter which one is monitored (and the learning rate should not be changed).\r\n\r\n(2) Similarly, if neither the training loss nor the validation loss is decreasing, then it does not matter which one is monitored (and the learning rate should be decreased).\r\n\r\n(3) Now, if the training loss is decreasing, but the validation loss is not, then there are two explanations: \r\n(A) we are likely overfitting and reducing the learning rate is going to make the problem worse. \r\n(B) The validation loss is actually going down on average, but it is too noisy to be captured by the model. In that case too, reducing the learning rate is premature. \r\n/!\\ However this is what the current default metric choice does. /!\\ \r\nAt this point the model should probably be early stopped anyway, but if we decide to keep training it, then we should not make the problem worse (maybe we should even increase the learning rate to help the model escape its local minima, but this is not the point of this post). \r\n\r\n(4) If the training loss is not decreasing but the validation loss is, then I would agree that the current default metric could be better. However I fail to see how this could happen? The only two scenarios I could imagine are:\r\n(A) if the training loss is jumping from one local minima to another, with similar train losses but some local minima leading to better generalization. In that case I agree that reducing the learning rate would lead to premature converging in a local minima, but again this scenario seems unlikely to me.\r\n(B) More likely, there is a higher standard error on the validation metric, and no actual underlying improvement of the generalization of the model. The learning rate should be reduced to improve the training loss, but the current default does not allow it.\r\n\r\nI would agree that this is in the grey area, but so far the coworkers with whom I shared my thoughts ended up agreeing that monitoring the training loss makes more sense and is more intuitive. Some figures do not even mention the validation set in the context of learning rate reduction:\r\n![ReduceLROnPlateau](https://user-images.githubusercontent.com/16949397/123551658-c6e97700-d740-11eb-9eb4-d999a33d6791.png)\r\nSource: https://towardsdatascience.com/the-subtle-art-of-fixing-and-modifying-learning-rate-f1e22b537303\r\n\r\nI personally do not mind changing this parameter for my projects, and I anticipate that the difference in performance will be small, but I did not find any issue regarding this question, so I wanted to at least raise it.\r\n\r\nThank you.", "comments": ["The intent of the callback is to modulate the learning rate when the model's generalization is starting to degrade (overfitting). The set of cases where the *training loss* will enter a plateau is limited: this is unlikely to occur in very high dimensional spaces. Typically the training loss will always keep decreasing even if the model is in a regime where it would benefit from a lower learning rate.\r\n\r\nBut if your intent is to modulate the learning rate based on the training loss, simply passing `monitor='loss'` will do it."]}, {"number": 50476, "title": "I face same problem when I build VGG", "body": "\r\n`import numpy as np\r\nimport tensorflow as tf\r\nfrom PIL import Image\r\nfrom tensorflow.keras import Model,Sequential\r\nfrom tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense,Dropout,BatchNormalization\r\nfrom sklearn.model_selection import train_test_split\r\nfrom keras_preprocessing.image import ImageDataGenerator\r\nfrom PIL import Image\r\nimport os.path\r\nimport glob\r\nimport random\r\n\r\n\r\n\r\n\r\nimage_path=glob.glob('gar/*/*.jpg')\r\n\r\nlabel_type=[image_p.split('\\\\')[1] for image_p in image_path]\r\nlabels=np.unique(label_type)\r\n\r\nindex_to_label=dict((l,n)for l,n in enumerate(labels))\r\nlabel_to_index=dict((n,l)for l,n in index_to_label.items())\r\n\r\nall_labels=[label_to_index.get(name)for name in label_type]\r\n\r\nnp.random.seed(22)\r\nrandom_index=np.random.permutation(len(image_path))\r\n\r\npath=np.array(image_path)[random_index]\r\nsignal_label=np.array(all_labels)[random_index]\r\n\r\nsep=int(len(image_path)*0.7)\r\ntrain_image_path=image_path[:sep]\r\ntrain_y=all_labels[:sep]\r\ntest_image_path=image_path[sep:]\r\ntest_y=all_labels[sep:]\r\n\r\ntrain=tf.data.Dataset.from_tensor_slices((train_image_path,train_y))\r\ntest=tf.data.Dataset.from_tensor_slices((test_image_path,test_y))\r\n\r\ndef load_pic(path,label):\r\n    image=tf.io.read_file(path)\r\n    image=tf.image.decode_jpeg(image,channels=3)\r\n    image=tf.image.resize(image,[256,256])\r\n    image=tf.cast(image,tf.float32)\r\n    image=image/255\r\n    return image,label\r\ntrain=train.map(load_pic)\r\n\r\ntrain=train.shuffle(1000).batch(64)\r\n\r\ndef get_model():\r\n    gmodel=Sequential([\r\n    Conv2D(64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu,input_shape=(256,256,3)),\r\n    Conv2D(64, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\r\n    MaxPooling2D(pool_size=[2, 2], strides=2, padding='same'),\r\n\r\n    # Conv-Conv-Pooling\u5355\u51432,\u8f93\u51fa\u901a\u9053\u63d0\u5347\u81f3128\uff0c\u9ad8\u5bbd\u5927\u5c0f\u51cf\u534a\r\n    Conv2D(128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\r\n    Conv2D(128, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\r\n    # \u9ad8\u5bbd\u51cf\u534a\r\n    MaxPooling2D(pool_size=[2, 2], strides=2, padding='same'),\r\n\r\n    # Conv-Conv-Pooling\u5355\u51433,\u8f93\u51fa\u901a\u9053\u63d0\u5347\u81f3256\uff0c\u9ad8\u5bbd\u5927\u5c0f\u51cf\u534a\r\n    Conv2D(256, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\r\n    Conv2D(256, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\r\n    MaxPooling2D(pool_size=[2, 2], strides=2, padding='same'),\r\n\r\n    # Conv-Conv-Pooling\u5355\u51434,\u8f93\u51fa\u901a\u9053\u63d0\u5347\u81f3512\uff0c\u9ad8\u5bbd\u5927\u5c0f\u51cf\u534a\r\n    Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\r\n    Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\r\n    MaxPooling2D(pool_size=[2, 2], strides=2, padding='same'),\r\n\r\n    # Conv-Conv-Pooling\u5355\u51435,\u8f93\u51fa\u901a\u9053\u63d0\u5347\u81f3512\uff0c\u9ad8\u5bbd\u5927\u5c0f\u51cf\u534a\r\n    Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\r\n    Conv2D(512, kernel_size=[3, 3], padding=\"same\", activation=tf.nn.relu),\r\n    MaxPooling2D(pool_size=[2, 2], strides=2, padding='same'),\r\n    Dense(4)\r\n    ])\r\n\r\n\r\n    return gmodel\r\nmodel=get_model()\r\n# model.summary()\r\n\r\nmodel.compile(\r\n    optimizer=tf.keras.optimizers.Adam(0.005),\r\n    loss=tf.keras.losses.sparse_categorical_crossentropy,\r\n    metrics=['acc']\r\n)\r\nhistory=model.fit(train,epochs=10,validation_data=test)`\r\n\r\n\r\nThe problem show that\r\n tensorflow.python.framework.errors_impl.InvalidArgumentError:  Incompatible shapes: [64,1] vs. [64,8,8]", "comments": [" \"Incompatible shapes: [64,1] vs. [64,8,8]\", it's looks like some ops in your graph with Incompatible shapes, your can print the shapes of key ops with binary search , that is a easy way to debug and solve your problem", "You may also be able to get feedback at https://discuss.tensorflow.org/ \ud83d\udc4d ", "@777ki \r\nPlease refer to similar issues here:l[ink](https://stackoverflow.com/questions/42822844/tensorflow-incompatible-shapes-100-155-vs-128-155-when-combining-cnn-and),[link1](https://github.com/keras-team/keras/issues/11749#issuecomment-804620973).\r\n\r\nKindly create an issue on tensorflow discussion forum for any further queries.\r\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 50475, "title": "'CuDNNLSTM' object has no attribute 'unroll'", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nWindows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nN/A\r\n- TensorFlow installed from (source or binary):\r\nbinary\r\n- TensorFlow version (use command below):\r\n2.5.0\r\n- Python version:\r\n3.8\r\n- Bazel version (if compiling from source):\r\nN/A\r\n- GCC/Compiler version (if compiling from source):\r\nN/A\r\n- CUDA/cuDNN version:\r\nCUDA = 11.3\r\ncuDNN = 8201\r\n- GPU model and memory:\r\nNvidia RTX 3070 (24gb)\r\n\r\n**Describe the current behavior**\r\nModel fails to save using ModelCheckPoint callback. \r\n\r\n**Describe the expected behavior**\r\nModel saves best version using ModelCheckPoint callback\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\nNo\r\n- Briefly describe your candidate solution(if contributing):\r\nN/A\r\n\r\n**Standalone code to reproduce the issue**\r\n```Python\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\nimport numpy\r\nfrom tensorflow.python.keras import Sequential\r\nfrom tensorflow.python.keras.callbacks import ModelCheckpoint\r\nfrom tensorflow.python.keras.layers import CuDNNLSTM\r\n\r\nX = [\r\n    [[1, 1, 1]],\r\n    [[1, 1, 1]]\r\n]\r\n\r\nY = [\r\n    [1, 1, 1],\r\n    [1, 1, 1]\r\n]\r\n\r\nX = numpy.array(X)\r\nY = numpy.array(Y)\r\n\r\nmodel = Sequential()  # initialize a sequential model\r\nmodel.add(CuDNNLSTM(3, return_sequences=False, input_shape=(1, 3)))  # 2nd layer of LSTM\r\nmodel.compile(loss='mse', optimizer='rmsprop', metrics=['accuracy'])\r\n\r\nmodel_checkpoint_callback = ModelCheckpoint(\r\n    filepath='/tmp/checkpoint',\r\n    save_weights_only=False,\r\n    monitor='val_accuracy',\r\n    mode='max',\r\n    save_best_only=True)\r\n\r\nmodel.fit(X, Y, batch_size=1, epochs=100, callbacks=[model_checkpoint_callback], validation_split=0.5)\r\n\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\n\r\n> Traceback (most recent call last):\r\n  File \"<input>\", line 1, in <module>\r\n  File \"C:\\Users\\31619\\AppData\\Local\\JetBrains\\Toolbox\\apps\\PyCharm-P\\ch-0\\211.7442.45\\plugins\\python\\helpers\\pydev\\_pydev_bundle\\pydev_umd.py\", line 197, in runfile\r\n    pydev_imports.execfile(filename, global_vars, local_vars)  # execute the script\r\n  File \"C:\\Users\\31619\\AppData\\Local\\JetBrains\\Toolbox\\apps\\PyCharm-P\\ch-0\\211.7442.45\\plugins\\python\\helpers\\pydev\\_pydev_imps\\_pydev_execfile.py\", line 18, in execfile\r\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\r\n  File \"C:/Users/31619/PycharmProjects/nn-drum-midi-synthesis/stackoverflow.py\", line 30, in <module>\r\n    model.fit(X, Y, batch_size=1, epochs=100, callbacks=[model_checkpoint_callback], validation_split=0.5)\r\n  File \"C:\\Users\\31619\\PycharmProjects\\nn-drum-midi-synthesis\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1229, in fit\r\n    callbacks.on_epoch_end(epoch, epoch_logs)\r\n  File \"C:\\Users\\31619\\PycharmProjects\\nn-drum-midi-synthesis\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\", line 435, in on_epoch_end\r\n    callback.on_epoch_end(epoch, logs)\r\n  File \"C:\\Users\\31619\\PycharmProjects\\nn-drum-midi-synthesis\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\", line 1369, in on_epoch_end\r\n    self._save_model(epoch=epoch, logs=logs)\r\n  File \"C:\\Users\\31619\\PycharmProjects\\nn-drum-midi-synthesis\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\", line 1421, in _save_model\r\n    self.model.save(filepath, overwrite=True, options=self._options)\r\n  File \"C:\\Users\\31619\\PycharmProjects\\nn-drum-midi-synthesis\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 2111, in save\r\n    save.save_model(self, filepath, overwrite, include_optimizer, save_format,\r\n  File \"C:\\Users\\31619\\PycharmProjects\\nn-drum-midi-synthesis\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\save.py\", line 150, in save_model\r\n    saved_model_save.save(model, filepath, overwrite, include_optimizer,\r\n  File \"C:\\Users\\31619\\PycharmProjects\\nn-drum-midi-synthesis\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\save.py\", line 89, in save\r\n    saved_nodes, node_paths = save_lib.save_and_return_nodes(\r\n  File \"C:\\Users\\31619\\PycharmProjects\\nn-drum-midi-synthesis\\venv\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py\", line 1103, in save_and_return_nodes\r\n    _build_meta_graph(obj, signatures, options, meta_graph_def,\r\n  File \"C:\\Users\\31619\\PycharmProjects\\nn-drum-midi-synthesis\\venv\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py\", line 1290, in _build_meta_graph\r\n    return _build_meta_graph_impl(obj, signatures, options, meta_graph_def,\r\n  File \"C:\\Users\\31619\\PycharmProjects\\nn-drum-midi-synthesis\\venv\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py\", line 1207, in _build_meta_graph_impl\r\n    signatures = signature_serialization.find_function_to_export(\r\n  File \"C:\\Users\\31619\\PycharmProjects\\nn-drum-midi-synthesis\\venv\\lib\\site-packages\\tensorflow\\python\\saved_model\\signature_serialization.py\", line 99, in find_function_to_export\r\n    functions = saveable_view.list_functions(saveable_view.root)\r\n  File \"C:\\Users\\31619\\PycharmProjects\\nn-drum-midi-synthesis\\venv\\lib\\site-packages\\tensorflow\\python\\saved_model\\save.py\", line 154, in list_functions\r\n    obj_functions = obj._list_functions_for_serialization(  # pylint: disable=protected-access\r\n  File \"C:\\Users\\31619\\PycharmProjects\\nn-drum-midi-synthesis\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 2713, in _list_functions_for_serialization\r\n    functions = super(\r\n  File \"C:\\Users\\31619\\PycharmProjects\\nn-drum-midi-synthesis\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 3016, in _list_functions_for_serialization\r\n    return (self._trackable_saved_model_saver\r\n  File \"C:\\Users\\31619\\PycharmProjects\\nn-drum-midi-synthesis\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\base_serialization.py\", line 92, in list_functions_for_serialization\r\n    fns = self.functions_to_serialize(serialization_cache)\r\n  File \"C:\\Users\\31619\\PycharmProjects\\nn-drum-midi-synthesis\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\layer_serialization.py\", line 73, in functions_to_serialize\r\n    return (self._get_serialized_attributes(\r\n  File \"C:\\Users\\31619\\PycharmProjects\\nn-drum-midi-synthesis\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\layer_serialization.py\", line 89, in _get_serialized_attributes\r\n    object_dict, function_dict = self._get_serialized_attributes_internal(\r\n  File \"C:\\Users\\31619\\PycharmProjects\\nn-drum-midi-synthesis\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\model_serialization.py\", line 53, in _get_serialized_attributes_internal\r\n    super(ModelSavedModelSaver, self)._get_serialized_attributes_internal(\r\n  File \"C:\\Users\\31619\\PycharmProjects\\nn-drum-midi-synthesis\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\layer_serialization.py\", line 99, in _get_serialized_attributes_internal\r\n    functions = save_impl.wrap_layer_functions(self.obj, serialization_cache)\r\n  File \"C:\\Users\\31619\\PycharmProjects\\nn-drum-midi-synthesis\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\save_impl.py\", line 154, in wrap_layer_functions\r\n    original_fns = _replace_child_layer_functions(layer, serialization_cache)\r\n  File \"C:\\Users\\31619\\PycharmProjects\\nn-drum-midi-synthesis\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\save_impl.py\", line 284, in _replace_child_layer_functions\r\n    child_layer._trackable_saved_model_saver._get_serialized_attributes(\r\n  File \"C:\\Users\\31619\\PycharmProjects\\nn-drum-midi-synthesis\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\layer_serialization.py\", line 89, in _get_serialized_attributes\r\n    object_dict, function_dict = self._get_serialized_attributes_internal(\r\n  File \"C:\\Users\\31619\\PycharmProjects\\nn-drum-midi-synthesis\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\layer_serialization.py\", line 151, in _get_serialized_attributes_internal\r\n    super(RNNSavedModelSaver, self)._get_serialized_attributes_internal(\r\n  File \"C:\\Users\\31619\\PycharmProjects\\nn-drum-midi-synthesis\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\layer_serialization.py\", line 99, in _get_serialized_attributes_internal\r\n    functions = save_impl.wrap_layer_functions(self.obj, serialization_cache)\r\n  File \"C:\\Users\\31619\\PycharmProjects\\nn-drum-midi-synthesis\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\save_impl.py\", line 161, in wrap_layer_functions\r\n    call_collection = LayerCallCollection(layer)\r\n  File \"C:\\Users\\31619\\PycharmProjects\\nn-drum-midi-synthesis\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\save_impl.py\", line 411, in __init__\r\n    self._input_signature = self._generate_input_signature(layer)\r\n  File \"C:\\Users\\31619\\PycharmProjects\\nn-drum-midi-synthesis\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\saving\\saved_model\\save_impl.py\", line 436, in _generate_input_signature\r\n    layer._use_input_spec_as_call_signature):  # pylint: disable=protected-access\r\n  File \"C:\\Users\\31619\\PycharmProjects\\nn-drum-midi-synthesis\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\", line 445, in _use_input_spec_as_call_signature\r\n    if self.unroll:\r\nAttributeError: 'CuDNNLSTM' object has no attribute 'unroll'", "comments": ["@dosier \r\nIn TensorFlow V2.0, the built-in LSTM and GRU layers have been updated to leverage CuDNN kernels by default when a GPU is available. With this change, the prior keras.layers.CuDNNLSTM/CuDNNGRU layers have been deprecated, \r\n\r\nPease refer the [document](https://www.tensorflow.org/guide/keras/rnn#performance_optimization_and_cudnn_kernels).I have done minimal code changes and didn't face any errors.Please find the [gist](https://colab.research.google.com/gist/UsharaniPagadala/e73753dacc1911aafa93cb3addb855e9/untitled119.ipynb#scrollTo=8Eg98fJQ2Q8k) ,and let us know if it helps.Thanks", "Hi @UsharaniPagadala , thanks for the reply. I must be doing something wrong, `tf.python.keras.layers.LSTM` is much slower for me than `tf.python.keras.layers.CuDNNLSTM` is. I can put this in a separate issue though. Unless you have some quick tips on why this might be. \r\n\r\nThese are the logs I get for using the bilt-in LSTM\r\n\r\n> 2021-06-28 17:39:39.494450: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library nvcuda.dll\r\n> 2021-06-28 17:39:39.531066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \r\n> pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3070 computeCapability: 8.6\r\n> coreClock: 1.725GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s\r\n> 2021-06-28 17:39:39.531587: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudart64_110.dll\r\n> 2021-06-28 17:39:39.539789: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cublas64_11.dll\r\n> 2021-06-28 17:39:39.540000: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cublasLt64_11.dll\r\n> 2021-06-28 17:39:39.543534: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cufft64_10.dll\r\n> 2021-06-28 17:39:39.544986: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library curand64_10.dll\r\n> 2021-06-28 17:39:39.547731: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cusolver64_11.dll\r\n> 2021-06-28 17:39:39.550825: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cusparse64_11.dll\r\n> 2021-06-28 17:39:39.551568: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudnn64_8.dll\r\n> 2021-06-28 17:39:39.551831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\r\n> 2021-06-28 17:39:39.552477: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\r\n> To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n> 2021-06-28 17:39:39.553337: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \r\n> pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3070 computeCapability: 8.6\r\n> coreClock: 1.725GHz coreCount: 46 deviceMemorySize: 8.00GiB deviceMemoryBandwidth: 417.29GiB/s\r\n> 2021-06-28 17:39:39.553861: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\r\n> 2021-06-28 17:39:40.017993: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n> 2021-06-28 17:39:40.018269: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \r\n> 2021-06-28 17:39:40.018419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \r\n> 2021-06-28 17:39:40.018710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 5466 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6)\r\n> Model: \"drum_prediction\"\r\n> _________________________________________________________________\r\n> Layer (type)                 Output Shape              Param #   \r\n> =================================================================\r\n> lstm (LSTM)                  (None, 512)               1069056   \r\n> _________________________________________________________________\r\n> dropout (Dropout)            (None, 512)               0         \r\n> _________________________________________________________________\r\n> dense (Dense)                (None, 9)                 4617      \r\n> _________________________________________________________________\r\n> activation (Activation)      (None, 9)                 0         \r\n> =================================================================\r\n> Total params: 1,073,673\r\n> Trainable params: 1,073,673\r\n> Non-trainable params: 0\r\n> _________________________________________________________________\r\n> 2021-06-28 17:39:40.530131: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\r\n> 2021-06-28 17:39:40.530317: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\r\n> 2021-06-28 17:39:40.530479: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1611] Profiler found 1 GPUs\r\n> 2021-06-28 17:39:40.531881: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cupti64_112.dll\r\n> 2021-06-28 17:39:40.643283: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\r\n> 2021-06-28 17:39:40.643559: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1743] CUPTI activity buffer flushed\r\n> 2021-06-28 17:39:40.732297: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\r\n> Epoch 1/500\r\n> 2021-06-28 17:39:43.090319: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cublas64_11.dll\r\n> 2021-06-28 17:39:43.903428: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cublasLt64_11.dll\r\n> 2021-06-28 17:39:43.903753: I tensorflow/stream_executor/cuda/cuda_blas.cc:1838] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\r\n> 1/6 [====>.........................] - ETA: 16s - loss: 0.69322021-06-28 17:39:44.702895: I tensorflow/core/profiler/lib/profiler_session.cc:126] Profiler session initializing.\r\n> 2021-06-28 17:39:44.703048: I tensorflow/core/profiler/lib/profiler_session.cc:141] Profiler session started.\r\n> 2/6 [=========>....................] - ETA: 4s - loss: 0.6877 2021-06-28 17:39:45.172997: I tensorflow/core/profiler/lib/profiler_session.cc:66] Profiler session collecting data.\r\n> 2021-06-28 17:39:45.173997: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1743] CUPTI activity buffer flushed\r\n> 2021-06-28 17:39:45.282066: I tensorflow/core/profiler/internal/gpu/cupti_collector.cc:673]  GpuTracer has collected 2908 callback api events and 2906 activity events. \r\n> 2021-06-28 17:39:45.367369: I tensorflow/core/profiler/lib/profiler_session.cc:159] Profiler session tear down.\r\n> 2021-06-28 17:39:45.461905: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: ./logs/nn-drum-synthesis\\train\\plugins\\profile\\2021_06_28_15_39_45\r\n> 2021-06-28 17:39:45.507035: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for trace.json.gz to ./logs/nn-drum-synthesis\\train\\plugins\\profile\\2021_06_28_15_39_45\\DESKTOP-FEJLLI2.trace.json.gz\r\n> 2021-06-28 17:39:45.624130: I tensorflow/core/profiler/rpc/client/save_profile.cc:137] Creating directory: ./logs/nn-drum-synthesis\\train\\plugins\\profile\\2021_06_28_15_39_45\r\n> 2021-06-28 17:39:45.637734: I tensorflow/core/profiler/rpc/client/save_profile.cc:143] Dumped gzipped tool data for memory_profile.json.gz to ./logs/nn-drum-synthesis\\train\\plugins\\profile\\2021_06_28_15_39_45\\DESKTOP-FEJLLI2.memory_profile.json.gz\r\n> 2021-06-28 17:39:45.666741: I tensorflow/core/profiler/rpc/client/capture_profile.cc:251] Creating directory: ./logs/nn-drum-synthesis\\train\\plugins\\profile\\2021_06_28_15_39_45Dumped tool data for xplane.pb to ./logs/nn-drum-synthesis\\train\\plugins\\profile\\2021_06_28_15_39_45\\DESKTOP-FEJLLI2.xplane.pb\r\n> Dumped tool data for overview_page.pb to ./logs/nn-drum-synthesis\\train\\plugins\\profile\\2021_06_28_15_39_45\\DESKTOP-FEJLLI2.overview_page.pb\r\n> Dumped tool data for input_pipeline.pb to ./logs/nn-drum-synthesis\\train\\plugins\\profile\\2021_06_28_15_39_45\\DESKTOP-FEJLLI2.input_pipeline.pb\r\n> Dumped tool data for tensorflow_stats.pb to ./logs/nn-drum-synthesis\\train\\plugins\\profile\\2021_06_28_15_39_45\\DESKTOP-FEJLLI2.tensorflow_stats.pb\r\n> Dumped tool data for kernel_stats.pb to ./logs/nn-drum-synthesis\\train\\plugins\\profile\\2021_06_28_15_39_45\\DESKTOP-FEJLLI2.kernel_stats.pb\r\n> ", "@dosier \r\nThanks for the update,glad it worked for you.Please move this to closed status and open a new issue with that error.\r\n\r\nThanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50475\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50475\">No</a>\n"]}, {"number": 50473, "title": "[API docs] `tf.keras.Sequential.predict_classes` is deprecated", "body": "https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#predict_classes\r\n\r\n`tf.keras.Sequential.predict_classes` is deprecated - there should be a \"deprecated\" sign, similar to `Model.predict_generator`'s API doc:\r\n\r\n[`/sequential.py`](https://github.com/tensorflow/tensorflow/blob/a4dfb8d1a71385bd6d122e4f27f86dcebb96712d/tensorflow/python/keras/engine/sequential.py#L441-L468):\r\n```\r\n    warnings.warn('`model.predict_classes()` is deprecated and '\r\n                  'will be removed after 2021-01-01. '\r\n                  'Please use instead:'\r\n                  '* `np.argmax(model.predict(x), axis=-1)`, '\r\n                  '  if your model does multi-class classification '\r\n                  '  (e.g. if it uses a `softmax` last-layer activation).'\r\n                  '* `(model.predict(x) > 0.5).astype(\"int32\")`, '\r\n                  '  if your model does binary classification '\r\n                  '  (e.g. if it uses a `sigmoid` last-layer activation).')\r\n```\r\n\r\n![image](https://user-images.githubusercontent.com/19637339/123527506-2e1f1100-d6d8-11eb-96d9-50e0e6a83b5d.png)\r\n\r\ncc @lamberta @MarkDaoust", "comments": ["It looks like there are a few like this that are deprecated, but incompletely marked. \r\n\r\nUsually we use the `@deprecation.deprecated` decorator, it marks things in  a  way that the doc generator understands.\r\n\r\nAt minimum these should have a `Caution:` or `Warning:` in the description so you can't miss it (the decorator adds those).\r\n\r\nI think the `set_deprecated/is_deprecated` functions in \"tensorflow_docs/../api_generator/doc_controls.py\" only affect the listings in the TOC, not within the page.", "I see this has been removed here https://www.tensorflow.org/api_docs/python/tf/keras/Sequential#predict_classes , so we can close this request. Thank you "]}, {"number": 50472, "title": "TypeError: An op outside of the function building code is being passed a \"Graph\" tensor.", "body": "Hi I got following error when I tried to include the KL loss in Flipout layers.  Any helps will be appreciated.  Thanks,\r\n\r\n\r\n\r\n**TypeError: An op outside of the function building code is being passed\r\na \"Graph\" tensor. It is possible to have Graph tensors\r\nleak out of the function building context by including a\r\ntf.init_scope in your function building code.\r\nFor example, the following function will fail:\r\n  @tf.function\r\n  def has_init_scope():\r\n    my_constant = tf.constant(1.)\r\n    with tf.init_scope():\r\n      added = my_constant * 2\r\nThe graph tensor has name: dense_flipout/divergence_kernel:0**\r\n\r\nA example code that would create the same error as follows:\r\n\r\n```\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nimport os\r\n\r\ndef f(x, sigma):\r\n    epsilon = np.random.randn(*x.shape) * sigma\r\n    return 10 * np.sin(2 * np.pi * (x)) + epsilon\r\n\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow.keras import backend as K\r\nfrom tensorflow.keras import activations, initializers\r\nfrom tensorflow.keras.layers import Layer\r\nimport tensorflow_probability as tfp\r\n\r\ntfd = tfp.distributions\r\n\r\nimport warnings\r\nwarnings.filterwarnings('ignore')\r\n\r\nfrom tensorflow.keras.layers import Input\r\nfrom tensorflow.keras.models import Model\r\n\r\ntrain_size = 32\r\nnoise = 1.0\r\n\r\nX = np.linspace(-0.5, 0.5, train_size).reshape(-1, 1)\r\ny = f(X, sigma=noise)\r\ny_true = f(X, sigma=0.0)\r\n\r\nplt.scatter(X, y, marker='+', label='Training data')\r\nplt.plot(X, y_true, label='Truth')\r\nplt.title('Noisy training data and ground truth')\r\nplt.savefig('data.png')\r\nplt.close()\r\n\r\nbatch_size = train_size\r\nnum_batches = train_size / batch_size\r\nkl_weight = 1.0 / num_batches\r\n\r\nx_in = Input(shape=(1,))\r\n\r\nx = tfp.layers.DenseFlipout(20, activation='relu')(x_in)\r\nx = tfp.layers.DenseFlipout(20, activation='relu')(x)\r\nx = tfp.layers.DenseFlipout(1)(x)\r\nmodel = Model(x_in, x)\r\n\r\nfrom tensorflow.keras import callbacks, optimizers, utils\r\n\r\ndef neg_log_likelihood(y_obs, y_pred, sigma=noise):\r\n    dist = tfp.distributions.Normal(loc=y_pred, scale=sigma)\r\n    return K.sum(-dist.log_prob(y_obs)) \r\n\r\nkl = sum(model.losses)\r\nloss = neg_log_likelihood + kl \r\n\r\nmodel.compile(loss=loss, optimizer=optimizers.Adam(lr=0.08), metrics=['mse'])\r\nutils.plot_model(model, to_file = 'model_flipout.png',  show_shapes = True, show_layer_names = True, show_dtype = True, dpi = 600)\r\nmodel.summary()\r\nmodel.fit(X, y, batch_size=batch_size, epochs=1500, verbose=0);\r\nmodel.save(f'flipout.h5')    \r\n\r\nimport tqdm\r\n\r\nX_test = np.linspace(-1.5, 1.5, 1000).reshape(-1, 1)\r\ny_pred_list = []\r\n\r\nfor i in tqdm.tqdm(range(500)):\r\n    y_pred = model.predict(X_test)\r\n    y_pred_list.append(y_pred)\r\n#import ipdb; ipdb.set_trace()                \r\ny_preds = np.concatenate(y_pred_list, axis = 1)\r\ny_mean = np.mean(y_preds, axis = 1)\r\ny_sigma = np.std(y_preds, axis = 1)\r\n\r\nplt.plot(X_test, y_mean, 'r-', label = 'Predictive mean');\r\nplt.plot(X, y_true, 'b-', label='Truth')\r\n\r\nplt.scatter(X, y, marker = '+', label = 'Training data')\r\nplt.fill_between(X_test.ravel(), \r\n                 y_mean + 2 * y_sigma, \r\n                 y_mean - 2 * y_sigma, \r\n                 alpha = 0.5, label='Epistemic uncertainty')\r\nplt.title('Prediction')\r\nplt.legend();\r\nplt.savefig('result_flipout.png')\r\nplt.close()\r\n    \r\n\r\n```", "comments": ["@ckhuangf \r\n\r\nWe see that the issue [template](https://github.com/tensorflow/tensorflow/issues/new?assignees=&labels=type%3Abug&template=00-bug-issue.md) has not been filled, could you please do so as it helps us analyse the issue.\r\n\r\nCould you please refer the similar issues [#32889](https://github.com/tensorflow/tensorflow/issues/32889), [#33729](https://github.com/tensorflow/tensorflow/issues/33729#issuecomment-562656807), and also check this [comment](https://stackoverflow.com/questions/58565913/typeerror-an-op-outside-of-the-function-building-code-is-being-passed-a-graph-t), let us know if it helps.Thanks\r\n\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50472\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50472\">No</a>\n"]}, {"number": 50471, "title": "About the k210 from tflite to kmodel", "body": "System information :\r\n\r\nOS Platform and Distribution : Windows 10\r\nTensorFlow version : tf-nightly 2.6.0 \r\nPython version: 3.8\r\n\r\nHi,\r\n    I have converted my darknet weights to pb, and converted to tflite. Howerver, when I converted my tflite file to kmodel on nncase, it has the error message Fatal: inputs are not compatible to concat. \r\n    And I found that \r\n![image](https://user-images.githubusercontent.com/70742122/123503360-31d57800-d685-11eb-88bc-a60418ca6327.png) when I converted pb to tflite, and it has the tflite file, but I don't know whether the int8 conversion is fine? The original tflite also has the error message.\r\nBelow is my yolov4-tiny-int8.tflite on Netron\r\n![image](https://user-images.githubusercontent.com/70742122/123503463-bde79f80-d685-11eb-96e6-c2fccd817c1a.png)\r\n\r\nDoes any one know the solution or give me some advice about the error?\r\nThanks.\r\n    \r\n", "comments": ["Perhaps https://github.com/kendryte/nncase/issues can be the right place for this issue since your question is related to converting tflite to kmodel on nncase. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50471\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50471\">No</a>\n"]}, {"number": 50470, "title": "Error in .summary() on .pb model imported using 'tf.saved_model.load()'", "body": "I was trying to load .pb model which was saved in \"20180402-114759/\" directory .\r\nmodel can be found [here]( https://github.com/davidsandberg/facenet) under the section \"pretrained model\" .\r\nSo I just tried to check the summary with .summary() method but got an error .\r\n\r\nCode : \r\n```\r\nimport tensorflow as tf\r\nmodel_path = \"20180402-114759/\"\r\nmodel = tf.saved_model.load(model_path)\r\nprint(model.summary())\r\n\r\n```\r\n\r\nError :\r\n```\r\nTraceback (most recent call last):\r\n  File \"E:\\Pathik\\KJ\\internships\\Facial Expression recognition\\20180402-114759\\test.py\", line 7, in <module>\r\n    print(model.summary())\r\nAttributeError: 'AutoTrackable' object has no attribute 'summary'\r\n\r\n```\r\nSystem information :\r\n* OS Platform and Distribution : Windows 10\r\n* TensorFlow version : 2.3.0\r\n* Python version: 3.7.8\r\n\r\nHow to resolve this error ? ", "comments": ["@Patrickbro13 `model.summary` method is available for `keras` models only. As your model is a TF model,  it is throwing an error. Try saving the model as a keras model and then use `model.summary`. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 50469, "title": "Update release notes for TensorFlow 2.6.0", "body": "This PR is intentionally incomplete. One of the Release Owners for 2.6.0\nneeds to fill in the internal release notes for this version before the PR gets\nsubmitted. Click on the :pencil2: icon in the header for `RELEASE.md` under\n\"Files Changed\" above.", "comments": []}, {"number": 50468, "title": "Update release notes for TensorFlow 2.7.0", "body": null, "comments": []}, {"number": 50467, "title": "Softmax layer unexpected and confusing error message", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.4.0-rc4-71-g582c8d236cb 2.4.0\r\n- Python version: 3.8.5\r\n\r\n**Describe the current behavior**\r\nI am getting a strange error message for the following model. The error seems to originate from the softmax layer at the end. \r\nThe message is the following:\r\n\"tensorflow.python.framework.errors_impl.InvalidArgumentError: Dimensions must be equal, but are 2 and 4 for '{{node Sof43628/add/add}} = AddV2[T=DT_DOUBLE](Placeholder, Sof43628/mul)' with input shapes: [?,4,2,1], [?,4,2].\"\r\nThe error is unexpected since I think the model should work and it is confusing since in the softmax layer there is no requirement for matching dimensions. What could be the reason for this error?\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\nimport numpy as np\r\nin0Mas92349 = tf.keras.layers.Input(shape=([4, 2, 1]))\r\nin0Dep9315 = tf.keras.layers.Input(shape=([1, 2, 1]))\r\nin0Ave93999 = tf.keras.layers.Input(shape=([2, 1]))\r\nMas92349 = keras.layers.Masking(mask_value=1, name = 'Mas92349', )(in0Mas92349)\r\nDep9315 = keras.layers.DepthwiseConv2D((1, 2),strides=(1, 1), padding='same', name = 'Dep9315', )(in0Dep9315)\r\nZer31495 = keras.layers.ZeroPadding2D(padding=((3, 0), (0, 0)), name = 'Zer31495', )(Dep9315)\r\nMax17507 = keras.layers.Maximum(name = 'Max17507', )([Mas92349,Zer31495])\r\nAve93999 = keras.layers.AveragePooling1D(pool_size=(2), name = 'Ave93999', )(in0Ave93999)\r\nRes89 = keras.layers.Reshape((1, 1, 1), name = 'Res89', )(Ave93999)\r\nZer84427 = keras.layers.ZeroPadding2D(padding=((3, 0), (1, 0)), name = 'Zer84427', )(Res89)\r\nSub42930 = keras.layers.Subtract(name = 'Sub42930', )([Max17507,Zer84427])\r\nSof43628 = keras.layers.Softmax(axis=1, name = 'Sof43628', )(Sub42930)\r\nmodel = tf.keras.models.Model(inputs=[in0Mas92349,in0Dep9315,in0Ave93999], outputs=Sof43628)\r\n\r\nin0Mas92349 = tf.constant([[[[1.8457], [1.4313]], [[1.8795], [1.1303]], [[1.4792], [1.9199]], [[1.996], [1.583]]]])\r\nin0Dep9315 = tf.constant([[[[0.6111], [0.9861]]]])\r\nin0Ave93999 = tf.constant([[[1.1779], [1.8115]]])\r\nprint (np.array2string(model.predict([in0Mas92349,in0Dep9315,in0Ave93999],steps=1), separator=', '))\r\n```\r\n", "comments": ["@Saduf2019 \r\n\r\nI was able to replicate the issue reported here.Please find the [gist](https://colab.research.google.com/gist/UsharaniPagadala/66cbfa79b54960067d9d48350a535363/untitled121.ipynb) .Thanks\r\n", "@rschumi0 \r\nCan you please refer to similar issues and let is know if it helps: [link](https://github.com/keras-team/keras/issues/11495), [link1](https://github.com/tensorflow/models/issues/8908),[link2](https://stackoverflow.com/questions/64404009/keras-valueerror-dimensions-must-be-equal-but-are-9-and-400-for-node-equal),[link2](https://stackoverflow.com/questions/55411222/tensorflow-error-dimensions-must-be-equal/55412026).", "Hi @rschumi0 ,\r\n\r\nPlease have a look at [tf.keras.layers.Masking docs](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Masking).\r\n\r\nI think that the error message may be confusing so I pushed PR #50586 .", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Moving this to closed status due to lack of activity.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50467\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50467\">No</a>\n"]}, {"number": 50466, "title": "TensorFlow 2.x: Model Training Indefinitely in Graph Mode", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Yes**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Windows 10**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **N/A**\r\n- TensorFlow installed from (source or binary): **binary**\r\n- TensorFlow version (use command below): **pip install tensorflow**\r\n- Python version: **python 3.9.5**\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nI am training the model in both the eager execution mode and the graph mode. The model is training well in the eager execution mode, however running for indefinitely in the graph mode. I tried to debug in multiple way with no success.\r\n\r\n**Describe the expected behavior**\r\nThe model should train in the same way in both eager execution and graph mode. \r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ntf.compat.v1.disable_eager_execution() # comment to enable eager execution mode\r\nprint(\"[INFO] Eager mode: \", tf.executing_eagerly()) # For easy reset of notebook state.\r\n\r\nclass CustomModelV2(tf.keras.Model):\r\n    def __init__(self):\r\n        super(CustomModelV2, self).__init__()\r\n        self.encoder = Encoder(32)\r\n        self.encoder.build(input_shape=(None, 32))\r\n        self.loss_tracker = tf.keras.metrics.Mean(name=\"loss\")\r\n        \r\n    def call(self, inputs, training):\r\n        return self.encoder(inputs, training)\r\n        \r\n    @property\r\n    def metrics(self):\r\n        # We list our `Metric` objects here so that `reset_states()` can be\r\n        # called automatically at the start of each epoch\r\n        # or at the start of `evaluate()`.\r\n        # If you don't implement this property, you have to call\r\n        # `reset_states()` yourself at the time of your choosing.\r\n        return [self.loss_tracker]\r\n\r\n    @tf.function\r\n    def train_step(self, data):\r\n        # Unpack the data. Its structure depends on your model and\r\n        # on what you pass to `fit()`.\r\n        x, y = data\r\n\r\n        with tf.GradientTape() as tape:\r\n            y_pred = self.call(x, training=True)  # Forward pass\r\n\r\n            # Compute the loss value\r\n            # (the loss function is configured in `compile()`)\r\n            r_loss = tf.keras.losses.mean_squared_error(y, y_pred)\r\n            loss = r_loss \r\n\r\n        # Compute gradients\r\n        trainable_vars = self.trainable_variables\r\n        gradients = tape.gradient(loss, trainable_vars)\r\n        \r\n        # Update weights\r\n        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\r\n        \r\n        # Update metrics (includes the metric that tracks the loss)\r\n        self.loss_tracker.update_state(loss)\r\n        \r\n        # Return a dict mapping metric names to current value\r\n        return {\"loss\": self.loss_tracker.result()}\r\n\r\nclass Encoder(tf.keras.Model):\r\n    def __init__(self, input_size):\r\n        super(Encoder, self).__init__(name = 'Encoder')\r\n        self.input_layer   = DenseLayer(128, input_size, 0.0, 0.0, 'float32')\r\n        self.hidden_layer1 = DenseLayer(128, 128, 0.001, 0.0, 'float32')\r\n        self.dropout_laye1 = tf.keras.layers.Dropout(0.2)\r\n        self.hidden_layer2 = DenseLayer(64, 128, 0.001, 0.0, 'float32')      \r\n        self.dropout_laye2 = tf.keras.layers.Dropout(0.2)\r\n        self.hidden_layer3 = DenseLayer(64, 64, 0.001, 0.0, 'float32')\r\n        self.dropout_laye3 = tf.keras.layers.Dropout(0.2)           \r\n        self.output_layer  = LinearLayer(64, 64, 0.001, 0.0, 'float32')\r\n        \r\n    def call(self, input_data, training):\r\n        fx = self.input_layer(input_data)        \r\n        fx = self.hidden_layer1(fx)\r\n        if training:\r\n            fx = self.dropout_laye1(fx)     \r\n        fx = self.hidden_layer2(fx)\r\n        if training:\r\n            fx = self.dropout_laye2(fx) \r\n        fx = self.hidden_layer3(fx)\r\n        if training:\r\n            fx = self.dropout_laye3(fx) \r\n        return self.output_layer(fx)\r\n\r\nclass LinearLayer(tf.keras.layers.Layer):\r\n\r\n    def __init__(self, units, input_dim, weights_regularizer, bias_regularizer, d_type):\r\n        super(LinearLayer, self).__init__()\r\n        self.w = self.add_weight(name='w_linear',\r\n                                shape = (input_dim, units), \r\n                                initializer = tf.keras.initializers.RandomUniform(\r\n                                    minval=-tf.cast(tf.math.sqrt(6/(input_dim+units)), dtype = d_type), \r\n                                    maxval=tf.cast(tf.math.sqrt(6/(input_dim+units)), dtype = d_type), \r\n                                    seed=16751),                                                                   \r\n                                regularizer = tf.keras.regularizers.l1(weights_regularizer), \r\n                                trainable = True)\r\n        self.b = self.add_weight(name='b_linear',\r\n                                 shape = (units,),    \r\n                                 initializer = tf.zeros_initializer(),\r\n                                 regularizer = tf.keras.regularizers.l1(bias_regularizer),\r\n                                 trainable = True)\r\n\r\n    def call(self, inputs):\r\n        return tf.matmul(inputs, self.w) + self.b\r\n\r\nclass DenseLayer(tf.keras.layers.Layer):\r\n\r\n    def __init__(self, units, input_dim, weights_regularizer, bias_regularizer, d_type):\r\n        super(DenseLayer, self).__init__()\r\n        self.w = self.add_weight(name='w_dense',\r\n                                 shape = (input_dim, units), \r\n                                 initializer = tf.keras.initializers.RandomUniform(\r\n                                     minval=-tf.cast(tf.math.sqrt(6.0/(input_dim+units)), dtype = d_type),  \r\n                                     maxval=tf.cast(tf.math.sqrt(6.0/(input_dim+units)), dtype = d_type),  \r\n                                     seed=16751), \r\n                                 regularizer = tf.keras.regularizers.l1(weights_regularizer), \r\n                                 trainable = True)\r\n        self.b = self.add_weight(name='b_dense',\r\n                                 shape = (units,),    \r\n                                 initializer = tf.zeros_initializer(),\r\n                                 regularizer = tf.keras.regularizers.l1(bias_regularizer),\r\n                                 trainable = True)\r\n\r\n    def call(self, inputs):\r\n        x = tf.matmul(inputs, self.w) + self.b\r\n        return tf.nn.elu(x)\r\n\r\n# Just use `fit` as usual\r\nx = tf.data.Dataset.from_tensor_slices(np.random.random((5000, 32)))\r\n\r\ny_numpy = np.random.random((5000, 1))\r\ny_numpy[:, 3:] = None\r\ny = tf.data.Dataset.from_tensor_slices(y_numpy)\r\n\r\nx_window = x.window(30, shift=10, stride=1)\r\nflat_x = x_window.flat_map(lambda t: t)\r\nflat_x_scaled = flat_x.map(lambda t: t * 2)\r\n\r\ny_window = y.window(30, shift=10, stride=1)\r\nflat_y = y_window.flat_map(lambda t: t)\r\nflat_y_scaled = flat_y.map(lambda t: t * 2)\r\n\r\nz = tf.data.Dataset.zip((flat_x_scaled, flat_y_scaled)).batch(32).cache().shuffle(buffer_size=32).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\r\n\r\n# Stopping criteria if the training loss doesn't go down by 1e-3\r\nearly_stop_cb = tf.keras.callbacks.EarlyStopping(\r\n    monitor='loss', min_delta = 1e-3, verbose = 1, mode='min', patience = 3, \r\n    baseline=None, restore_best_weights=True)\r\n\r\n# Construct and compile an instance of CustomModel\r\nmodel = CustomModelV2()\r\n\r\n\r\n  \r\nmodel.compile(optimizer=tf.optimizers.Adagrad(0.01))\r\n\r\nhistory = model.fit(z, epochs=3, callbacks=[early_stop_cb])\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nOutput in Graph Mode: \r\n```\r\nWARNING:tensorflow:Output output_1 missing from loss dictionary. We assume this was done on purpose. The fit and evaluate APIs will not be expecting any data to be passed to output_1.\r\nWARNING:tensorflow:From C:\\Users\\jain432\\Anaconda3\\envs\\tf\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\adagrad.py:87: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCall initializer instance with the dtype argument instead of passing it to the constructor\r\nTrain on None steps\r\nEpoch 1/3\r\n 479916/Unknown - 667s 1ms/step - batch: 239957.5000 - size: 1.0000 - loss: 2.1716e-04\r\n```\r\n\r\nOutput in Eager Mode: \r\n```\r\nEpoch 1/3\r\n468/468 [==============================] - 2s 3ms/step - loss: 0.4173\r\nEpoch 2/3\r\n468/468 [==============================] - 1s 3ms/step - loss: 0.3695\r\nEpoch 3/3\r\n468/468 [==============================] - 1s 3ms/step - loss: 0.3608\r\n```\r\n", "comments": ["@Saduf2019 ,\r\nI was able to reproduce the issue in tv v2.4,v2.5 and nightly.Please find the gist.[Gist1](https://colab.research.google.com/gist/tilakrayal/fefe01827d64a8748282f13088667051/untitled50466.ipynb),[Gist2](https://colab.research.google.com/gist/tilakrayal/10b92d7f7cb04c82b5b677574f99fd80/50466.ipynb)", "@jainmilan \r\nCan you please refer to [this link](https://stackoverflow.com/questions/60141916/errorrootinternal-python-error-in-the-inspect-module-while-installing-tensorfl) and let us know.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Thanks @Saduf2019 for the response. The link you shared discuss a totally different issue. Do you think it is because of the TensorFlow version and it was supported in the previous version? ", "@jainmilan \r\nYou would  need to define steps_per_epoch in model.fit as dataset runs indefinitely", "The steps_per_epoch limits the training but don\u2019t you think it is an inconsistent behavior? Also, to do an indefinite training it might be applying a repeat over the dataset which I didn\u2019t use and that changes the data too. ", "@jainmilan \r\nThis does not seem like a tensorflow bug, it coding related issue, can you open this in discussion forum or stackover flow as there is a bigger community to answer there.", "Moving this to closed status due to lac of activity.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50466\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50466\">No</a>\n", "@Saduf2019: I don\u2019t see any resolution there. The code should ideally output the same thing in both the graph mode and the eager mode. I have already shared a minimal working example that can replicate the issue."]}, {"number": 50465, "title": "Fix indices rank in decompose ResourceScatterOp ", "body": "Since indices.shape[:-1] + tensor.shape[indices.shape[-1]:], we need\r\nindices.shape[-1] to be 1. This fix ensures that indices has the right\r\nrank, S.T above condition is met.\r\n", "comments": ["> Please also add a test along with the code change.\r\n\r\ndone :)", "@smit-hinsu ping?", "> @smit-hinsu ping?\r\n\r\nReplied yesterday at https://github.com/tensorflow/tensorflow/pull/50465#discussion_r665272003", "Ah I missed this, the \"feed\" shown by GitHub here does not show when we answer comments, I don't know if there is a way to see the \"last updates\" that include this kind of information?", "Just need to update the description. ", "> Just need to update the description.\r\n\r\ndone! :)", "nvm, saw some PRs that answered my questions :) "]}, {"number": 50464, "title": "Update 90-keras-issue.md", "body": "Keras-issue template had some formatting errors which are corrected in this PR", "comments": ["@jvishnuvardhan Can you please resolve conflicts? Thanks!", "@gbaned Closing this PR as Copybara is adding some format which is resulting in wrong template. Opened a cl to fix this. Thanks!"]}, {"number": 50462, "title": "Add the newly added kernels_experimental header file to pip package.", "body": "The change adds the kernels_experimental.h header file to `kernels_hdrs` target so that it can appear to pip package.\r\n\r\n@penpornk can you please take a look.", "comments": []}, {"number": 50461, "title": "Why the output tensor device type is GPU even though I set the HostMemory attr?", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.4\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.0\r\n- GPU model and memory: A100\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nHi folks,\r\nI am trying to create an Op recently. This is part of my Op kernel builder:\r\n```\r\nREGISTER_KERNEL_BUILDER(Name(\"Test\").Device(::tensorflow::DEVICE_GPU)\r\n                                                      .HostMemory(\"output\"),\r\n                        TestOp);\r\n\r\nREGISTER_OP(\"Test\")\r\n    .Input(\"tensor: T\")\r\n    .Output(\"output: T\")\r\n    .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {\r\n      ::tensorflow::shape_inference::ShapeHandle output;\r\n      TF_RETURN_IF_ERROR(c->ReplaceDim(c->input(0), 0, c->UnknownDim(), &output));\r\n      c->set_output(0, output);\r\n      return ::tensorflow::Status::OK();\r\n    })\r\n```\r\nFor my Op, it's expected the input is on the device while the output will be on the host. Inside the op_kernel, I used api ```cuPointerGetAttribute``` provided by NVIDIA to verify that the output memory is allocated on the host. However, after I call Op using Python and obtain the ```output``` tensor, I tried to print the device type ```print(output.device)```. I found that the output tensor is on the ```GPU```, which is supposed to be ```CPU``` for my case? I tried the scope ```with tf.device(\"/gpu:0\")``` and ```with tf.device(\"/cpu:0\"), but there was no difference\r\n\r\nI also tried to set the attribute manually inside the Op_kernel.\r\n```\r\n::tensorflow::AllocatorAttributes alloc_attrs;\r\nalloc_attrs.set_on_host(true);\r\nOP_REQUIRES_OK_ASYNC(context, context->allocate_output(0, result_shape, &output), done);\r\n```\r\nBut the result ```print(output.device)``` from Python is still on the device(GPU). \r\n\r\nI am concerned that TF do the Host2Device memory copy automatically.\r\n\r\nSo I wrote another DataPtr Op which reads the output from the above TestOp, and tried to print the memory address:\r\n\r\n```\r\nclass DataPtrOp : public ::tensorflow::OpKernel {\r\n    public:\r\n    explicit DataPtrOp(::tensorflow::OpKernelConstruction* context) : OpKernel(context) {}\r\n\r\n    void Compute(::tensorflow::OpKernelContext* context) override {\r\n        // Grab the input tensor\r\n\r\n        auto input_tensor = context->input(0);\r\n        auto input = std::make_shared<TFTensor>(input_tensor, GetDeviceID(context));\r\n        std::size_t address = reinterpret_cast<std::size_t>(input->data());\r\n        std::cout << \"Test. address:\" << address << std::endl;\r\n        // \r\n       //skip some unrelated code here\r\n       ///\r\n    }\r\n    };\r\n\r\n\r\nREGISTER_KERNEL_BUILDER(Name(\"DataPtr\").Device(::tensorflow::DEVICE_CPU),\r\n                        DataPtrOp);\r\n\r\nREGISTER_OP(\"DataPtr\")\r\n        .Attr(\"T: {uint8, int8, uint16, int16, int32, int64, float16, float32, float64, bool}\")  // \r\n        .Input(\"input: T\")  // Tensor\r\n        .Output(\"output: uint64\")  // scalar\r\n        .SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {\r\n        c->set_output(0, {}); // scalar\r\n        return ::tensorflow::Status::OK();\r\n        });\r\n\r\n```\r\n\r\nThe output tensor memory address from TestOp on the host is the same as the input tensor memory address from DataPtr Op.\r\n\r\nSo I believe that the ```output``` tensor is allocated on the Host. So, is this a bug or issue with ```tensor.device``` API?\r\nIt is very confusing somehow.\r\n\r\n**Describe the expected behavior**\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["AFAIK for each device, we have host and device memory. In the Compute method, you should be also able to read tensor content (if it's on the host memory). \r\n\r\nIt does not look like a bug.", "@szutenberg yep I did verify that the output is on the Host. The issue is that I call the op using Python and use TF python API to ```print(output.device)```, the result is ```GPU```. This is very confusing because the data is actually on CPU but the ```device``` API tells user the tensor device type is ```GPU```. You know, our user usually use python API, which, in this case however does not provide the expected answer.", "@Young768 \r\n\r\nCould you please refer this [comment](https://github.com/tensorflow/tensorflow/issues/34071#issuecomment-592585783), hope it helps.Thanks", "@UsharaniPagadala Hi thanks. It seems it is different from my case? \r\n\r\nFor my case, the ```output``` tensor is expected on the ```CPU```, but the ```device``` API tells user it is ```GPU```.\r\n\r\nI didnt do the ```tf.identity``` intentionally.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@Young768 \r\n\r\nCould you please provide a colab gist with required dependencies to analyse the issue reported .Thanks", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50461\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/50461\">No</a>\n"]}, {"number": 50460, "title": "Blocking on webgl for first initialization", "body": "On the first run of model using webgl backend it takes very long time. I understand that internally it has to set up the gpu but the method blocks and takes a long time(I see this with predict/execute and execute async.) Is this the expected behavior? What is the recommended behavior and any tips on speeding this up? Should we run in webworker? I have about six models I need to initialize. Is there a way to run them all at once?", "comments": ["@rohanmuplara ,\r\n\r\nIn order to expedite the trouble-shooting process, could you please provide the tensorflow version,complete code and dataset to reproduce the issue reported here.", "Sure I am not surer if a dataset is necessary. This is just inference. Tensorflow version is all of them especially latest one. I have found this to be true of any model", "@rohanmuplara ,\r\n\r\nWithout the reproducible code, it would be difficult for us to debug the issue. In order to expedite the trouble-shooting process, could you please provide a minimal code snippet and the TensorFlow version you are using.\r\n\r\nThanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}]