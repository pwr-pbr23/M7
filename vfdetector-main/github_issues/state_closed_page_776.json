[{"number": 30273, "title": "Invalid argument: Expects arg[1] to be bool but float is provided", "body": "**Tensorflow version:1.12 .I want to translate my python code to c++ version and here is my python code below:**\r\n`\r\nimport tensorflow as tf\r\nimport  numpy as np\r\nfrom skimage import io, transform\r\nimport cv2\r\n#import infer\r\nsess = tf.Session()\r\nnew_saver = tf.train.import_meta_graph(r'D:\\CNN_test_result_sizhuangzao_model\\v2_101_ziji_9\\model\\model.meta')\r\nnew_saver.restore(sess,tf.train.latest_checkpoint(r'D:\\CNN_test_result_sizhuangzao_model\\v2_101_ziji_9\\model'))\r\n\r\ngraph = tf.get_default_graph()\r\ninput_x = graph.get_tensor_by_name(\"input:0\")\r\nis_training_x=graph.get_tensor_by_name(\"is_training:0\")\r\n#print (sess.run(\"input:0\"))\r\n\r\njpg_path=r\"D:\\CNN_test_result_sizhuangzao\\chaodacesiji1\\pos.txt\"\r\nfile = open(jpg_path)\r\nlines = file.readlines()\r\nnum=0\r\nfor line in lines: \r\n    img0 = io.imread(line.strip())\r\n    l=img0.shape\r\n    k=l[0]\r\n    c=l[1]\r\n    num+=1\r\n    print(num)\r\n    if  c/k<5:\r\n        continue\r\n    img = transform.resize(img0, (48,160, 1))\r\n    feed_dict={input_x:np.reshape(img, [-1, 48, 160, 1]),is_training_x:False}\r\n\r\n    prob_op = graph.get_operation_by_name('output')\r\n    out_softmax = graph.get_tensor_by_name(\"output:0\")\r\n    img_out_softmax = sess.run(out_softmax,feed_dict)\r\n    prediction_labels = np.argmax(img_out_softmax,1)\r\n`\r\n\r\n**Now this is my c++ version below (There is some wrong but i do not know where it is !)**\r\n\r\n`\r\n#include \"tensorflow/core/framework/graph.pb.h\"\r\n#include <tensorflow/core/public/session_options.h>\r\n#include <tensorflow/core/protobuf/meta_graph.pb.h>\r\n#include <fstream>\r\n#include <utility>\r\n#include <vector>\r\n#include <Eigen/Core>\r\n#include <Eigen/Dense>\r\n\r\n#include \"tensorflow/cc/ops/const_op.h\"\r\n#include \"tensorflow/cc/ops/image_ops.h\"\r\n#include \"tensorflow/cc/ops/standard_ops.h\"\r\n#include \"tensorflow/core/framework/graph.pb.h\"\r\n#include \"tensorflow/core/framework/tensor.h\"\r\n#include \"tensorflow/core/graph/default_device.h\"\r\n#include \"tensorflow/core/graph/graph_def_builder.h\"\r\n#include \"tensorflow/core/lib/core/errors.h\"\r\n#include \"tensorflow/core/lib/core/stringpiece.h\"\r\n#include \"tensorflow/core/lib/core/threadpool.h\"\r\n#include \"tensorflow/core/lib/io/path.h\"\r\n#include \"tensorflow/core/lib/strings/stringprintf.h\"\r\n#include \"tensorflow/core/platform/env.h\"\r\n#include \"tensorflow/core/platform/init_main.h\"\r\n#include \"tensorflow/core/platform/logging.h\"\r\n#include \"tensorflow/core/platform/types.h\"\r\n#include \"tensorflow/core/public/session.h\"\r\n#include \"tensorflow/core/util/command_line_flags.h\"\r\n\r\nusing namespace std;\r\nusing namespace tensorflow;\r\nusing namespace tensorflow::ops;\r\nusing tensorflow::Flag;\r\nusing tensorflow::Tensor;\r\nusing tensorflow::Status;\r\nusing tensorflow::string;\r\nusing tensorflow::int32;\r\n\r\ntypedef std::vector<std::pair<std::string, tensorflow::Tensor>> tensor_dict;\r\nusing tensorflow::Status;\r\n\r\nstatic Status ReadtheFile(tensorflow::Env* env, const string& filename,Tensor* output) {\r\n  tensorflow::uint64 file_size = 0;\r\n  TF_RETURN_IF_ERROR(env->GetFileSize(filename, &file_size));\r\n\r\n  string contents;\r\n  contents.resize(file_size);\r\n\r\n  std::unique_ptr<tensorflow::RandomAccessFile> file;\r\n  TF_RETURN_IF_ERROR(env->NewRandomAccessFile(filename, &file));\r\n\r\n  tensorflow::StringPiece data;\r\n  TF_RETURN_IF_ERROR(file->Read(0, file_size, &data, &(contents)[0]));\r\n  if (data.size() != file_size) {\r\n    return tensorflow::errors::DataLoss(\"Truncated read of '\", filename,\r\n                                        \"' expected \", file_size, \" got \",\r\n                                        data.size());\r\n  }\r\n//  output->scalar<string>()() = data.ToString();\r\n  output->scalar<string>()() = string(data);\r\n  return Status::OK();\r\n}\r\n\r\nStatus ReadImageFile(const string& file_name, const int input_height,\r\n                               const int input_width, const float input_mean,\r\n                               const float input_std,\r\n                               std::vector<Tensor>* out_tensors) {\r\n  auto root = tensorflow::Scope::NewRootScope();\r\n  using namespace ::tensorflow::ops;\r\n\r\n  string input_name = \"file_reader\";\r\n  string output_name = \"normalized\";\r\n\r\n  // read file_name into a tensor named input\r\n  Tensor input(tensorflow::DT_STRING, tensorflow::TensorShape());\r\n  TF_RETURN_IF_ERROR(ReadtheFile(tensorflow::Env::Default(), file_name, &input));\r\n\r\n  // use a placeholder to read input data\r\n  auto file_reader =Placeholder(root.WithOpName(\"input\"), tensorflow::DataType::DT_STRING);\r\n\r\n  std::vector<std::pair<string, tensorflow::Tensor>> inputs = {{\"input\", input},};\r\n\r\n  // Now try to figure out what kind of file it is and decode it.\r\n    const int wanted_channels = 1;\r\n    tensorflow::Output image_reader;\r\n\tif (tensorflow::str_util::EndsWith(file_name, \".png\"))\r\n\t{\r\n\t  image_reader = DecodePng(root.WithOpName(\"png_reader\"), file_reader,\r\n\t\t\t\t\t\t\t   DecodePng::Channels(wanted_channels));\r\n\t}\r\n\telse if (tensorflow::str_util::EndsWith(file_name, \".gif\"))\r\n\t{\r\n\t  // gif decoder returns 4-D tensor, remove the first dim\r\n\t  image_reader =\r\n\t\t  Squeeze(root.WithOpName(\"squeeze_first_dim\"),\r\n\t\t\t\t  DecodeGif(root.WithOpName(\"gif_reader\"), file_reader));\r\n\t}\r\n\telse if (tensorflow::str_util::EndsWith(file_name, \".bmp\"))\r\n\t{\r\n\t  image_reader = DecodeBmp(root.WithOpName(\"bmp_reader\"), file_reader);\r\n\t}\r\n\telse\r\n\t{\r\n\t  // Assume if it's neither a PNG nor a GIF then it must be a JPEG.\r\n\t  image_reader = DecodeJpeg(root.WithOpName(\"jpeg_reader\"), file_reader,\r\n\t\t\t\t\t\t\t\tDecodeJpeg::Channels(wanted_channels));\r\n\t}\r\n  // Now cast the image data to float so we can do normal math on it.\r\n  auto float_caster =Cast(root.WithOpName(\"float_caster\"), image_reader, tensorflow::DT_FLOAT);\r\n\r\n  auto dims_expander = ExpandDims(root.WithOpName(\"expand\"), float_caster, 0);\r\n\r\n  float input_max = 255;\r\n  Div(root.WithOpName(\"div\"),dims_expander,input_max);\r\n\r\n  tensorflow::GraphDef graph;\r\n  TF_RETURN_IF_ERROR(root.ToGraphDef(&graph));\r\n\r\n  std::unique_ptr<tensorflow::Session> session(\r\n      tensorflow::NewSession(tensorflow::SessionOptions()));\r\n  TF_RETURN_IF_ERROR(session->Create(graph));\r\n//  std::vector<Tensor> out_tensors;\r\n//  TF_RETURN_IF_ERROR(session->Run({}, {output_name + \":0\", output_name + \":1\"},\r\n//                                    {}, &out_tensors));\r\n  TF_RETURN_IF_ERROR(session->Run({inputs}, {\"div\"}, {}, out_tensors));\r\n  return Status::OK();\r\n}\r\n\r\nint main()\r\n{\r\n  Session* session;\r\n  Status status = NewSession(SessionOptions(), &session);\r\n\r\n  const std::string graph_fn = \"/media/root/Ubuntu311/projects/Ecology_projects/tensorflowtest/model-0617/model.meta\";\r\n  MetaGraphDef graphdef;\r\n  Status status_load = ReadBinaryProto(Env::Default(), graph_fn, &graphdef); //\u4ecemeta\u6587\u4ef6\u4e2d\u8bfb\u53d6\u56fe\u6a21\u578b;\r\n  if (!status_load.ok()) {\r\n        std::cout << \"ERROR: Loading model failed...\" << graph_fn << std::endl;\r\n        std::cout << status_load.ToString() << \"\\n\";\r\n        return -1;\r\n  }\r\n\r\n  Status status_create = session->Create(graphdef.graph_def()); //\u5c06\u6a21\u578b\u5bfc\u5165\u4f1a\u8bddSession\u4e2d;\r\n  if (!status_create.ok()) {\r\n        std::cout << \"ERROR: Creating graph in session failed...\" << status_create.ToString() << std::endl;\r\n        return -1;\r\n  }\r\n  cout << \"Session successfully created.Load model successfully!\"<< endl;\r\n\r\n  // \u8bfb\u5165\u9884\u5148\u8bad\u7ec3\u597d\u7684\u6a21\u578b\u7684\u6743\u91cd\r\n  const std::string checkpointPath = \"/media/root/Ubuntu311/projects/Ecology_projects/tensorflowtest/model-0617/model\";\r\n  Tensor checkpointPathTensor(DT_STRING, TensorShape());\r\n  checkpointPathTensor.scalar<std::string>()() = checkpointPath;\r\n  status = session->Run(\r\n\t\t  {{ graphdef.saver_def().filename_tensor_name(), checkpointPathTensor },},\r\n\t\t  {},{graphdef.saver_def().restore_op_name()},nullptr);\r\n  if (!status.ok())\r\n  {\r\n\t  throw runtime_error(\"Error loading checkpoint from \" + checkpointPath + \": \" + status.ToString());\r\n  }\r\n  cout << \"Load weights successfully!\"<< endl;\r\n\r\n\r\n  //read image for prediction...\r\n  string image_path= \"/media/root/Ubuntu311/projects/Ecology_projects/copy/cnn-imgs/AABW.jpg\";\r\n   int input_height =48;\r\n   int input_width=160;\r\n   int input_mean=0;\r\n   int input_std=1;\r\n   std::vector<Tensor> resized_tensors;\r\n   Status read_tensor_status =\r\n       ReadImageFile(image_path, input_height, input_width, input_mean,\r\n                               input_std, &resized_tensors);\r\n   if (!read_tensor_status.ok()) {\r\n     LOG(ERROR) << read_tensor_status;\r\n     cout<<\"resing error\"<<endl;\r\n     return -1;\r\n   }\r\n\r\n   const Tensor& resized_tensor = resized_tensors[0];\r\n   std::cout <<\"Read image successfully: \"<< resized_tensor.DebugString()<<endl;\r\n\r\n   std::string Input1Name = \"input\";\r\n   std::string Input2Name = \"is_training\";\r\n   vector<std::pair<string, Tensor> > inputs;\r\n   inputs.push_back(std::make_pair(Input1Name, resized_tensor));\r\n   inputs.push_back(std::make_pair(Input2Name, resized_tensor));\r\n\r\n   vector<tensorflow::Tensor> outputs;\r\n   string output2=\"out_softmax\";\r\n   string output_ = \"output\";\r\n   Status status_run = session->Run(inputs, {output2}, {}, &outputs);\r\n   if (!status_run.ok()) {\r\n       std::cout << \"ERROR: RUN failed...\"  << std::endl;\r\n       std::cout << status_run.ToString() << \"\\n\";\r\n       return -1;\r\n   }\r\n   //Fetch output value\r\n   std::cout << \"Output tensor size:\" << outputs.size() << std::endl;\r\n   for (std::size_t i = 0; i < outputs.size(); i++) {\r\n       std::cout <<\"result: \"<<i<<\" :\"<< outputs[i].DebugString()<<endl;\r\n   }\r\n  cout << \"Prediction successfully!\"<< endl;\r\n\r\n  return 0;\r\n}\r\n`\r\n\r\nI built the c++ version successfully but  the error informations came to me----- \" ERROR: RUN failed...\r\nInvalid argument: Expects arg[1] to be bool but float is provided \". Any help will be much appreciated.", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged//tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.", "Thanks,i have put it here [https://stackoverflow.com/questions/56880358/model-pruner-failed-invalid-argument-invalid-input-graph-when-run-tensorflow-c](url)", "@tangjie77wd ,\r\nThank you. Closing the issue as it is a support question and as you have raised it in Stack Overflow.", "Maybe the problem is in your input / output names are not correct", "Has been solved!", "@tangjie77wd Hi, how did you actually solve this issue? I have encountered a similar issue.  Many thanks", "@tangjie77wd  Could you tell how to slove this issue?", "@felix288 Could you solve you problem?", "you can link here :https://blog.csdn.net/wd1603926823/article/details/99406974 or&nbsp;https://blog.csdn.net/wd1603926823/article/details/98086550\r\n\r\n\r\n\r\n\r\n------------------&nbsp;\u539f\u59cb\u90ae\u4ef6&nbsp;------------------\r\n\u53d1\u4ef6\u4eba:&nbsp;\"panshaohua\"<notifications@github.com&gt;;\r\n\u53d1\u9001\u65f6\u95f4:&nbsp;2020\u5e745\u670812\u65e5(\u661f\u671f\u4e8c) \u665a\u4e0a9:52\r\n\u6536\u4ef6\u4eba:&nbsp;\"tensorflow/tensorflow\"<tensorflow@noreply.github.com&gt;;\r\n\u6284\u9001:&nbsp;\"\u5df4\u536b\"<1603926823@qq.com&gt;;\"Mention\"<mention@noreply.github.com&gt;;\r\n\u4e3b\u9898:&nbsp;Re: [tensorflow/tensorflow] Invalid argument: Expects arg[1] to be bool but float is provided (#30273)\r\n\r\n\r\n\r\n\r\n\r\n \r\n@tangjie77wd  Could you tell how to slove this issue?\r\n \r\n\u2014\r\nYou are receiving this because you were mentioned.\r\nReply to this email directly, view it on GitHub, or unsubscribe."]}, {"number": 30272, "title": "tflite_convert  .h5 to .tflite Init node Conv1/kernel/Assign do esn't exist in graph", "body": "**System information**\r\n- OS Platform and Distribution : Windows 7\r\n- TensorFlow version: tensorflow_gpu-1.14.0\r\n- Python version: 3.7.3 \r\n- CUDA/cuDNN version: 10.1 / 7.6.1\r\n- GPU model and memory: GTX1080Ti / 11GB\r\n\r\n**Describe the current behavior**\r\nafter transfer learning on tensorflow.keras mobilenet v2 and saved .h5,\r\n*`tflite_convert --keras_model_file=tl_mobilenetv2.h5 --output_file=tl_mobilenetv2.tflite --allow_custom_ops`*\r\n\r\n**Describe the Issues**\r\n.tflite is generated, but error message shown:\r\n**E tensorflow/core/grappler/grappler_item_builder.cc:637] Init node Conv1/kernel/Assign doesn't exist in graph**\r\n\r\n**Other info / logs**\r\nCreated TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10143 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1)\r\n2019-07-01 18:16:28.142672: E tensorflow/core/grappler/grappler_item_builder.cc:637] Init node Conv1/kernel/Assign doesn't exist in graph\r\n", "comments": ["Could you share your keras model file with me so I can give it a try? Thanks.", "https://drive.google.com/open?id=1sTwEgYMDPUV5DsXA1sBG_7MxjE9Xicxc ", "I'm also facing the same problem. \r\n\r\nSystem information\r\n\r\nOS Platform and Distribution : Windows 10\r\nTensorFlow version: tensorflow_gpu-1.14.0\r\nPython version: 3.5.6\r\nCUDA/cuDNN version: 10.1 / 7.6.1\r\nGPU model and memory: GTX1050 / 4GB", "I have this issue too. Even the example code located [here](https://www.tensorflow.org/lite/convert/python_api#exporting_a_tfkeras_file_) gives the following error:\r\n\r\n```\r\n>>> tflite_model = converter.convert()\r\n2019-08-28 17:42:49.934545: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\r\n2019-08-28 17:42:49.934746: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session\r\n2019-08-28 17:42:49.937814: E tensorflow/core/grappler/grappler_item_builder.cc:637] Init node dense/kernel/Assign doesn't exist in graph\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/zmk5/.local/lib/python3.6/site-packages/tensorflow/lite/python/lite.py\", line 898, in convert\r\n    **converter_kwargs)\r\n  File \"/home/zmk5/.local/lib/python3.6/site-packages/tensorflow/lite/python/convert.py\", line 404, in toco_convert_impl\r\n    input_data.SerializeToString())\r\n  File \"/home/zmk5/.local/lib/python3.6/site-packages/tensorflow/lite/python/convert.py\", line 172, in toco_convert_protos\r\n    \"TOCO failed. See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\ntensorflow.lite.python.convert.ConverterError: TOCO failed. See console for info.\r\n/bin/sh: 1: toco_from_protos: not found\r\n```\r\n\r\nOS Platform and Distribution : Ubuntu 18.04\r\nTensorFlow version: tensorflow-1.14.0\r\nPython version: 3.6.8", "Same error here.\r\nHas anyone got over it somehow?", "I've been looking and have yet to find a solution. I attempted this with the Command Line operator they provide and it still doesn't work, even for their own example code lol", "Same issue for my as well, \r\n2019-08-29 20:44:30.935433: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\r\n2019-08-29 20:44:30.947953: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2019-08-29 20:44:30.952924: E tensorflow/core/grappler/grappler_item_builder.cc:656] Init node dense/kernel/Assign doesn't exist in graph", "Facing same issue as well,\r\n\r\nLOG:\r\nE tensorflow/core/grappler/grappler_item_builder.cc:637] Init node dense_1/kernel/Assign doesn't exist in graph\r\n\r\nAnyone got a solution?", "Same issue here with tf1.14 on Ubuntu 16.04. Any solutions or ideas yet?", "Same issue here with TF1.14 on Windows 10.", "Just got the same issue with TF1.14 with Mac 10.14.6\r\n\r\n@haozha111, did you get a chance to take a look at rkuo200's h5 file and any idea what may go wrong?", "Same issue here with TF1.14 on Windows 10", "Sorry for the wait. I'm taking a look now. Will update once I got any new findings. Thanks!", "Hi,\r\n\r\nI could convert the keras mobilenet model to tflite without issue using the TF 2 API as documented here:\r\nhttps://www.tensorflow.org/lite/convert/python_api#end-to-end_mobilenet_conversion_\r\n\r\nPlease note that there are API signature changes between TF 1.X and TF2.0. The code instructions in that page is based on TF 2.0 API.\r\n\r\nCould you please use the latest TF 2.0 code (the official 2.0 version has been released last week) and see if that issue could be resolved?\r\n\r\nThanks and sorry for the inconvenience.", "If that issue still exists, could you please share your keras model file (.h5) with me so that I can take a look (the link of above Google Drive is not valid any more).", "Same issue here\r\n[model.h5.zip](https://github.com/tensorflow/tensorflow/files/3821243/model.h5.zip)\r\n\r\n", "Same issue with TF1.14 on raspi4b", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30272\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/30272\">No</a>\n", "Same issue with TF1.15.2... "]}, {"number": 30271, "title": "Failed to load nodelet [/zed/zed_wrapper_node] of type [zed_wrapper/ZEDWrapperNodelet]", "body": "hello i have worked with zed camera for long time when i run my zed camera this morning i got this error \r\n\r\nROS_MASTER_URI=http://localhost:11311\r\n\r\nprocess[zed/zed_wrapper_node-1]: started with pid [2349]\r\nprocess[zed/zed_state_publisher-2]: started with pid [2350]\r\n[ INFO] [1561980098.631115078]: Initializing nodelet with 4 worker threads.\r\n[ERROR] [1561980100.164477981]: Failed to load nodelet [/zed/zed_wrapper_node] of type [zed_wrapper/ZEDWrapperNodelet] even after refreshing the cache: Failed to load library /home/abanay/catkin_ws/devel/lib//libZEDWrapper.so. Make sure that you are calling the PLUGINLIB_EXPORT_CLASS macro in the library code, and that names are consistent between this macro and your XML. Error string: Could not load library (Poco exception = libnvidia-fatbinaryloader.so.384.130: cannot open shared object file: No such file or directory)\r\n[ERROR] [1561980100.164522687]: The error before refreshing the cache was: Failed to load library /home/abanay/catkin_ws/devel/lib//libZEDWrapper.so. Make sure that you are calling the PLUGINLIB_EXPORT_CLASS macro in the library code, and that names are consistent between this macro and your XML. Error string: Could not load library (Poco exception = libnvidia-fatbinaryloader.so.384.130: cannot open shared object file: No such file or directory)\r\n\r\n", "comments": ["@abdo-robotic Looks like this issue is not related to Tensorflow. Can you confirm us. Thanks!", "i reinstalled cuda zed sdk ROS  and i keep getting the same error", "@abdo-robotic Looks this issue is not related Tensorflow, Can you post this issue in appropriate repo for better and faster resolution. Thanks!", "Will close this issue, please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "i reinstalled  ubuntu and cuda, it work well now thank you "]}, {"number": 30270, "title": "Tensorboard Graph is different when using File Writer as opposed to Tensorboard callback", "body": "The graph generated using tensorboard callback and the graph generated using FileWriter are different. Also, I am not able to retrieve scalar values when using FileWriter. Why is the behaviour different when using FileWriter? What changes should be done in FileWriter to get the graph and results similar to as when tensorboard callbacks are used? I have added the code as well as the tensorboard images.\r\n\r\n**System information**\r\n- TF Version: 2.0.0-dev20190527\r\n- TF GIT Version: v1.12.1-2821-gc5b8e15064\r\n- Python Version: 3.6.6\r\n\r\n**Using tensorboard callback**\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n\r\n# Load the data.\r\nfashion_mnist = keras.datasets.fashion_mnist\r\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\r\n\r\n# Pre-processing.\r\ntrain_images = train_images / 255.0\r\ntest_images = test_images / 255.0\r\n\r\ntb_callback = tf.keras.callbacks.TensorBoard(log_dir=\"/tmp/tb_test_1\", histogram_freq=1)  # Create tensorboard callback\r\n\r\ndef create_model():\r\n    return keras.Sequential([\r\n        keras.layers.Flatten(input_shape=(28, 28)),\r\n        keras.layers.Dense(128, activation=tf.nn.relu),\r\n        keras.layers.Dense(10, activation=tf.nn.softmax)\r\n    ])\r\n\r\nmodel = create_model()\r\nmodel.compile(optimizer='adam',\r\n              loss='sparse_categorical_crossentropy',\r\n              metrics=['accuracy'])\r\nmodel.fit(train_images, train_labels, epochs=1, callbacks=[tb_callback], verbose=1)\r\n```\r\n[Tensorboard Graph](https://ibb.co/B68XFrY)\r\n[Tensorboard Scalar](https://ibb.co/jVphDn8)\r\n**Using File Writer**\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n\r\n# Load the data.\r\nfashion_mnist = keras.datasets.fashion_mnist\r\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\r\n\r\n# Pre-processing.\r\ntrain_images = train_images / 255.0\r\ntest_images = test_images / 255.0\r\n\r\nlogdir = '/tmp/tb_test_2/'\r\nwriter = tf.summary.create_file_writer(logdir)\r\n\r\nclass MyModel(keras.Model):\r\n    def __init__(self):\r\n        super(MyModel, self).__init__()\r\n        self.flatten = keras.layers.Flatten()\r\n        self.d1 = keras.layers.Dense(128, activation='relu')\r\n        self.d2 = keras.layers.Dense(10, activation='softmax')\r\n\r\n    def call(self, x):\r\n        x = self.flatten(x)\r\n        x = self.d1(x)\r\n        return self.d2(x)\r\n\r\nmodel = MyModel()\r\noptimizer = keras.optimizers.Adam(0.1)\r\nloss_fn = keras.losses.SparseCategoricalCrossentropy()\r\n\r\n@tf.function\r\ndef train_step(inputs, labels, step):\r\n    with tf.GradientTape() as tape:\r\n        predictions = model(inputs)\r\n        pred_loss = loss_fn(labels, predictions)\r\n        tf.summary.scalar(\"loss\", pred_loss, step=step, description=None)\r\n\r\n    gradients = tape.gradient(pred_loss, model.trainable_variables)\r\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n\r\nfor i in range(5):\r\n    tf.summary.trace_on(graph=True)\r\n    train_step(train_images, train_labels, step=i)\r\n    with writer.as_default():\r\n        tf.summary.trace_export(name=\"test_model\", step=i)\r\n        writer.flush()\r\n```\r\n[Tensorboard Graph]( https://ibb.co/Kqhb8Tg)\r\nTensorboard Scalar is absent.\r\n\r\n", "comments": ["@gupta-vivek ,\r\nThis question is better asked in [Github Tensorboard Repo](https://github.com/tensorflow/tensorboard/issues/) as it will be looked into by the Engineers specialized in Tensorboard.", "I don't think tensorboard is the issue but the way graph is being saved by tensorflow.", "@gupta-vivek Please post this issue on [tensorflow/tensorboard](https://github.com/tensorflow/tensorboard) as its you can get your questions answered fast. Thanks!"]}, {"number": 30269, "title": "Fix two line comments error", "body": "A little change to fix two line comments error.No change to the real code.", "comments": ["@sanjoy i close this pr"]}, {"number": 30268, "title": "Optimizing the Frozen Graph", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):macOS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:Nan\r\n- TensorFlow installed from (source or binary):binary\r\n- TensorFlow version:1.13.0-rc2\r\n- Python version:3.7.2\r\n- Installed using virtualenv? pip? conda?:pip\r\n- Bazel version (if compiling from source):0.27.0\r\n- GCC/Compiler version (if compiling from source):Nan\r\n- CUDA/cuDNN version:Nan\r\n- GPU model and memory:Nan\r\n**Describe the problem**\r\nOptimizing the Frozen Graph using The optimize_for_inference tool\r\nrefering to this [tuto](https://heartbeat.fritz.ai/intro-to-machine-learning-on-android-how-to-convert-a-custom-model-to-tensorflow-lite-e07d2d9d50e3)\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n`bazel build tensorflow/python/tools:optimize_for_inference && \\ bazel-bin/tensorflow/python/tools/optimize_for_inference.py \\ --input=/Users/hak/tensorboard/logs/frozen.pb \\ --output=/Users/hak/tensorboard/logs/frozen_opt.pb \\ --frozen_graph=True \\ --input_names=ImageTensor \\ --output_names=ReziseBilinear_1`\r\nrefer to this \r\n[link](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/optimize_for_inference.py)\r\n### trace back \r\n\r\n> INFO: Build completed successfully, 1 total action\r\n> -bash:  bazel-bin/tensorflow/python/tools/optimize_for_inference.py: No such file or directory\r\n> \r\nAdding that I'm not sure about the input and the output names options\r\nany help??", "comments": ["@essalahsouad Please provide the correct link of optimize_for_inference.py. Please describe the problem in detail. And also if possible provide the minimal code snippet to reproduce the issue. Thanks!", "@gadagashwini could you take a look now ", "@essalahsouad if you read the [link](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/optimize_for_inference.py) you provided carefully, you can find that the command line to run it is\r\n```sh\r\nbazel-bin/tensorflow/python/tools/optimize_for_inference\r\n```\r\ninstead of \r\n```sh\r\nbazel-bin/tensorflow/python/tools/optimize_for_inference.py\r\n```", "@freedomtan thank you, it's my fault"]}, {"number": 30267, "title": "How should i use tf.image.draw_bounding_box() when each batch have different bbox_num ?", "body": "The documents show that bboxes' shape is [batch, num_bounding_boxes, 4]. This means every batch have same number of bbox. \r\nBut in detect, each image may have different number of bboxes. Who can tell me how should i do, thanks !\r\nBTW, I use tf.gather_nd() to get bboxes, is there any method to get dimension-aligned bboxes? \r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): Tensorflow 1.13", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow-tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n"]}, {"number": 30266, "title": "Unable to import  tensorflow", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64 Up to date\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary I think\r\n- TensorFlow version: r1.14\r\n- Python version: 3.6.5\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.1/7.6.1\r\n- GPU model and memory: GTX 1060 6GB\r\n\r\n\r\n\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\aanan\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\platform\\self_check.py\", line 75, in preload_check\r\n    ctypes.WinDLL(build_info.cudart_dll_name)\r\n  File \"C:\\Users\\aanan\\AppData\\Local\\Programs\\Python\\Python36\\lib\\ctypes\\__init__.py\", line 348, in __init__\r\n    self._handle = _dlopen(self._name, mode)\r\nOSError: [WinError 126] The specified module could not be found\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\aanan\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 28, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\aanan\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\aanan\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 30, in <module>\r\n    self_check.preload_check()\r\n  File \"C:\\Users\\aanan\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\platform\\self_check.py\", line 82, in preload_check\r\n    % (build_info.cudart_dll_name, build_info.cuda_version_number))\r\nImportError: Could not find 'cudart64_100.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 10.0 from this URL: https://developer.nvidia.com/cuda-90-download-archive\r\n>>>\r\n\r\nSteps I followed. I'm new to Python commands but I should be able to follow.\r\nhttps://github.com/jvishnuvardhan/Installing-TensorFlow-GPU-on-Windows-10-TF1.12\r\n\r\n\r\nShould I remove 10.1, or is a parallel installation okay? Additionally, after reading the code, it seems there is a simple missing file or two that is causing this issue. Is my diagnosis correct? If not, please guide. My gratitude in advance.\r\n\r\nPS. It appears to me that CUDA 10.0's absence is creating this entire mess. I shall install and report.\r\n\r\nPSS. I cannot remove 10.1 for the following reason:\r\nNVIDIA\u00ae GPU drivers \u2014CUDA 10.0 requires 410.x or higher. CUDA\u00ae Toolkit \u2014TensorFlow supports CUDA 10.0 **(TensorFlow >= 1._13_.0)** CUPTI ships with the CUDA Toolkit. cuDNN SDK **(>= 7.4.1)**\r\n", "comments": ["I have resolved that error simply by installing CUDA 10.0 alongside 10.1, this solves both the requirements of Tensorflow. Now I am unable to test tensorflow with \"import tensorflow as tf. Following is the result of my endeavour.\r\n\r\n C:\\Users\\aanan>python\r\nPython 3.6.5 (v3.6.5:f59c0932b4, Mar 28 2018, 17:00:18) [MSC v.1900 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> hello=tf.constant(\u2018Hello World!\u2019)\r\n  File \"<stdin>\", line 1\r\n    hello=tf.constant(\u2018Hello World!\u2019)\r\n                           ^\r\nSyntaxError: invalid character in identifier\r\n>>> ^Z\r\n\r\n\r\nC:\\Users\\aanan>python", "Double quotes solved the problem. LOL"]}, {"number": 30265, "title": "`tf.contrib.layers.recompute_grad` values on recompute different", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Pro, Version 1809, OS Build 17763.557\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): Tensorflow GPU 1.14.0\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: CUDA 10.0, cuDNN 7.6.0\r\n- GPU model and memory: NVIDIA Quadro M2000M\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n`recompute_grad` returns `_WRONG_VARS_ERR`\r\n\r\n**Describe the expected behavior**\r\nModel trained with `recompute_grad` can perform predictions, as well as to compute specific gradients\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nPlease see [StackOverflow 56829378](https://stackoverflow.com/questions/56829378/valueerror-the-variables-used-on-recompute-were-different-than-the-variables-or)\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nTo visualize the error, I added print statements to `rev_block_lib.py` to output the recomputed versus original variables. This was the result:\r\n\r\n```\r\nORIGINAL VARIABLES\r\n\r\n{<tf.Variable 'fc04/fc04_100000/fc04_100000/kernel:0' shape=(25, 10) dtype=float32>, <tf.Variable 'fc04/fc04_100000/fc04_100000/bias:0' shape=(10,) dtype=float32>}\r\n\r\nRECOMPUTE VARIABLES\r\n\r\n{<tf.Variable 'gradients/fc04/fc04_100000/IdentityN_grad/fc04_100000/fc04_100001/bias:0' shape=(10,) dtype=float32>, <tf.Variable 'gradients/fc04/fc04_100000/IdentityN_grad/fc04_100000/fc04_100001/kernel:0' shape=(25, 10) dtype=float32>}\r\n```", "comments": ["@gitrdonator In order to expedite the trouble-shooting process, please provide a full code snippet to reproduce the issue reported here. Thanks!\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 30264, "title": "[INTEL MKL] Fix \"redundant-transpose removal\" related UT failures.", "body": "Fix UT failures.", "comments": []}, {"number": 30263, "title": "[TF2.0]: Skipping optimization due to error while loading function", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Window 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.0.0-beta1\r\n- Python version: 3.6.0\r\n\r\n**Describe the current behavior**\r\nI'm trying to reproduce the results from the tutorial example about \"Text classification with an RNN\" provided by Tensorflow at: [https://www.tensorflow.org/beta/tutorials/text/text_classification_rnn](url)\r\n\r\nHowever, this warning message constantly appears that shows \"skipping optimization due to error while loading function libraries: Invalid argument: ... \"\r\n\r\nI tried other optimizers, and LSTM or GRU architectures but nothing changes!\r\n\r\n![Untitled](https://user-images.githubusercontent.com/52288474/60402198-595ade00-9b5a-11e9-837f-d60f0518f2d0.jpg)\r\n\r\n \r\n**Code to reproduce the issue**\r\n\r\n```ruby\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\nimport tensorflow as tf\r\nprint(tf.__version__)\r\nimport tensorflow_datasets as tfds\r\n\r\n# plot result\r\nimport matplotlib.pyplot as plt\r\ndef plot_graph(histroy, string):\r\n    plt.plot(histroy.history[string])\r\n    plt.plot(histroy.history['val_' + string])\r\n    plt.xlabel('Epochs')\r\n    plt.ylabel('string')\r\n    plt.legend([string, 'val_'+string])\r\n    plt.show()\r\n\r\n# See available datasets\r\n# print(tfds.list_builders())\r\ndataset, info = tfds.load('imdb_reviews/subwords8k', with_info=True,\r\n                          as_supervised=True)\r\ntrain_dataset, test_dataset = dataset['train'], dataset['test']\r\ntokenizer = info.features['text'].encoder\r\n# print('Vocabulary size: {}'.format(tokenizer.vocab_size))\r\n# sample_string = 'TensorFlow is cool'\r\n# tokenized_string = tokenizer.encode(sample_string)\r\n# print ('Tokenized string is {}'.format(tokenized_string))\r\n# original_string = tokenizer.decode(tokenized_string)\r\n# print ('The original string: {}'.format(original_string))\r\n# assert original_string == sample_string\r\n# for ts in tokenized_string:\r\n#     print('{} -------> {}'.format(ts, tokenizer.decode([ts])))\r\n\r\nBUFFER_SIZE = 10000\r\nBATCH_SIZE = 64\r\ntrain_dataset = train_dataset.shuffle(BUFFER_SIZE)\r\ntrain_dataset = train_dataset.padded_batch(BATCH_SIZE, train_dataset.output_shapes)\r\ntest_dataset = test_dataset.padded_batch(BATCH_SIZE,test_dataset.output_shapes)\r\n\r\n# Build the model\r\nEM_SIZE = 64\r\nmodel = tf.keras.Sequential([\r\n    tf.keras.layers.Embedding(tokenizer.vocab_size, 64),\r\n    tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64)),\r\n    tf.keras.layers.Dense(64, activation= 'relu'),\r\n    tf.keras.layers.Dense(1,activation = 'sigmoid')\r\n])\r\nmodel.compile(loss= 'mse',\r\n            optimizer= 'sgd',\r\n            metrics=['accuracy'])\r\nhistory = model.fit(train_dataset, epochs = 1, validation_data=test_dataset)\r\ntest_loss, test_acc = model.evaluate(test_dataset)\r\nprint('Test Loss: {}'.format(test_loss))\r\nprint('Test Accuracy: {}'.format(test_acc))\r\n```\r\nIt seems that many other users are experiencing similar issues on TF2.0-beta", "comments": ["I am able to execute the code provided by you  without any errors in TF 2.0-beta1 version.Can you check once and let me know is this still an issue?.Thanks!\r\n\r\n", "@ravikyram, I tried running the code and I have the following warning/error print-outs at each and every iteration:\r\n```\r\nSkipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_cudnn_gru_973_1109_specialized_for_SGD_gradients_bidirectional_StatefulPartitionedCall_1_grad_StatefulPartitionedCall_at___inference_keras_scratch_graph_2955' and '__inference___backward_standard_gru_1969_2558' both implement 'gru_fd36615e-65df-4b45-9bd7-8903b889b94c' but their signatures do not match.\r\n```\r\n\r\n* OS Platform: Linux Mint 19.1\r\n* Python version: 3.6.8\r\n* TensorFlow version: 2.0-beta1 (installed from pip, with gpu support)\r\n* GPU enabled (Nvidia Quadro P1000, with CUDA 10.0, properly detected and used by TensorFlow)", "Additionally, the loss and accuracy do not seem to change significantly as training goes - it therefore seems that back-propagation is actually not performed as it should.", "Finally, if I disable the use of the GPU, the `E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] constant folding failed: Invalid argument: Unsupported type: 21` error also shows up at each iteration.\r\n\r\nSo, there definitely is an issue here.", "Experiencing the same issue, any solution?", "@Slacker-WY I am able to execute the code provided by you without any errors in TF 2.0-GPU-beta1 version.Please, find the [file](https://colab.sandbox.google.com/drive/16APmqQgZQFHg0MZRcJTHmSOwPbbKdm2U#scrollTo=fKivRIWC5x5i) for your reference .Please, let me know if i miss something .", "@ravikyram I think you are missing the fact that although it reportedly works on your machine, it does not on a bunch of others. This bug has been experienced by multiple users, and I just ran the exact same code again in TF 2.0-GPU-beta1, which yields the same issue as that first reported by @Slacker-WY.\r\n\r\nI get that TF is a very large (and, let me stress it out, pretty amazing) project receiving a huge number of Issues, part of which are more about user-related bugs than actual software problems, but systematically answering \"it works on my computer\" to try and close issues when there are multiple reports of an issue - whose not showing up on your machine actually underlines (in my humble opinion) that there is something tricky to investigate - does not feel like a very good software maintenance policy.\r\n\r\nAgain, TF 2.0 is a big release with a lot of work and changes, it is bound to include some issues and that's what beta versions are for, but please stop denying that there is something broken here - similar issues have been raised for about a month now, and we are talking about Google's own tutorial code on something \"basic\" (in terms of use - I totally understand that the underlying mechanics and implementation are not exactly simple) not working (at all) on a number of configurations. It might be due to an unnoticed detail (GPU driver version, support of a given type of CPU instructions... I have honestly no idea), or to an actual software issue (by the way, I tested that the code runs properly - except for a compatibility issue with using `test_dataset` as `validation_data` in `model.fit` - on the same system using TF 1.14-GPU in a different virtual environment, so TF 2.0 really seems to be at fault). At any rate, it really seems worth investigating by TF developers.", "> I am able to execute the code provided by you without any errors in TF 2.0-beta1 version.Can you check once and let me know is this still an issue?.Thanks!\r\n\r\nHi, still don't work. The issue is still there. ", "Hi all,\r\napparently seems like the issue (which I had too) is correlated with the activation function of the LSTM/GRU/RNN layer. By changing activation from default 'tanh' to 'sigmoid' the warning disappeared. Hope this will help fixing the problem.\r\nHave a good day!\r\n\r\nFYI I run tensorflow-2.0.0-beta1 on CPU", "> Hi all,\r\n> apparently seems like the issue (which I had too) is correlated with the activation function of the LSTM/GRU/RNN layer. By changing activation from default 'tanh' to 'sigmoid' the warning disappeared. Hope this will help fixing the problem.\r\n> Have a good day!\r\n> \r\n> FYI I run tensorflow-2.0.0-beta1 on CPU\r\n\r\nThanks for your help. I reran the code as per your suggestion, and the \"skipping optimization...\" issue does disappear. However, the issue as reported in #28626 still exists.", "> By changing activation from default 'tanh' to 'sigmoid' the warning disappeared.\r\n\r\nSame here, thanks @Armyke! This is good news in the sense that not everything is broken, but still something worth looking into for developers...\r\n\r\n> However, the issue as reported in #28626 still exists.\r\n\r\nAgain, same for me as for @Slacker-WY, and yielding a major slowdown in the training process (> 20 seconds / batch, when the same operation in TF 1.14 on the same computer runs at about 2 seconds / batch).", "Can also confirm. Switching LSTM activation to \"sigmoid\" stopped the \"skipping optimization\" issue, but \"Unsupported type: 21\" appears in that case.\r\n\r\n**Further, by switching to sigmoid the model trains about half as fast.** However, leaving it at the default tanh does not seem to affect validation convergence (backprop is still working).\r\n\r\nI'm running tensorflow-gpu 2.0.0-beta1 on Windows 10 with a 2080 Ti.\r\n\r\nThis is what prints when I set LSTM activation to tanh (the default):\r\n\r\n`2019-07-05 19:20:02.138247: W tensorflow/core/grappler/optimizers/implementation_selector.cc:199] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_cudnn_lstm_374_550_specialized_for_Nadam_gradients_recurrent1_StatefulPartitionedCall_grad_StatefulPartitionedCall_at___inference_keras_scratch_graph_2911' and '__inference___backward_standard_lstm_974_1476' both implement 'lstm_3f0d94f5-99f8-4499-8983-151b467a13d9' but their signatures do not match.`", "I am having this issue currently as well with 2.0.0 beta 1 on windows 10. I get both 'Unsupported type 21' and 'skipping optimization'. Strangely this issue occurs in Visual Studio Code, but does not occur in Spyder using same exact script and Conda environment. Maybe this will help solve the issue...", "Hi all:\r\n\r\nThis warning message is a red herring and can be ignored. It is raised when we do the implementation selection for RNN based on the availability of GPU for cudnn kernel. It is already suppressed in https://github.com/tensorflow/tensorflow/commit/d8379699d3cf5e951e03e70fcc5335726955f260. \r\n\r\nBtw, you shouldn't change to use other activation function just to avoid this warning. \r\n\r\nConstant folding might be some other issue, but should affect how the final graph. \r\n\r\nAll the warning/error message here is in the graph rewrite stage, which is an optimization process. If the optimazation step failed, it will still use the unoptimized graph, which is still a valid one.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30263\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30263\">No</a>\n", "\r\n> This warning message is a red herring and can be ignored. It is raised when we do the implementation selection for RNN based on the availability of GPU for cudnn kernel. It is already suppressed in [d837969](https://github.com/tensorflow/tensorflow/commit/d8379699d3cf5e951e03e70fcc5335726955f260).\r\n\r\nHi, I don't think this warning message can be ignored and it directly affects the model training. Because unlike the training results shown in the Tensorflow tutorial example,  the training accuracy of mine running exactly the same code doesn't improve at all even after more than 10 min training (as shown below).\r\n![Untitled](https://user-images.githubusercontent.com/52288474/60772310-7e070680-a0c2-11e9-8004-b89c1567d8ad.jpg)\r\n\r\n\r\n\r\n\r\n", "@qlzh727 I am also suffered from constant folding error with large degradation of performance.", "Hi all:\r\n\r\nFirst, let's skip the constant folding issue which is tracked by other ticket.\r\n\r\nSecondly, let me give more details about why the warning message can be ignored, and why you should still use the default activation function (tanh).\r\n\r\nIn 2.0, we implement an improvement for RNN to select different kernel based on GPU availability. Previously, we expect user to build model with CudnnLSTM, CudnnGRU layer explicitly, now you only need LSTM/GRU layer, and it will smartly choose cudnn kernel when the graph is landed on GPU. Under the hood, the we have grappler stages to rewrite the graph. It suppose to optimize the graph if possible. When a grappler stage failed, it will leave the existing graph as is, and unoptimized graph should still behave correctly (just slower). \r\n\r\nIn this particular case, the implementation_selector failed to optimize the function, since it was executed on a function that has been previously optimized (we run optimization multiple rounds). It is fine for it to fail at this stage, which will just leave the function unchanged.\r\n\r\nWhen you change the activation function (from tanh to sigmoid or any other function), it means we cannot use cudnn kernel (which by default use tanh and not configurable). The graph rewrite does not happen since cudnn kernel is not the option here. This means you will force your graph to be executed with normal kernel, and cannot enjoy the speed from cudnn kernel.\r\n\r\nThirdly, we expect the optimized the graph to run samely before and after the optimization mathematically. We also have the unit test to cover that. @Slacker-WY, if somehow your model does not train correctly, probably check the model structure. Btw, since you have previously switch to use sigmoid activation function, does it improve the accuracy?", "@qlzh727 First, thank you for the details as to where the warning comes from, it is really nice to get some insight as to the inner workings of TensorFlow and a clear answer as to what seems to be the origin of the issue. Out of sheer curiosity, is it still possible to actively specify that we want to use CudnnLSTM/GRU (and, I guess, have the model building fail if cudnn is not properly loaded)?\r\n\r\n> Hi, I don't think this warning message can be ignored and it directly affects the model training. Because unlike the training results shown in the Tensorflow tutorial example, the training accuracy of mine running exactly the same code doesn't improve at all even after more than 10 min training (as shown below).\r\n\r\nI still run into the same issue as @Slacker-WY: After training the model (whose architecture and defining / running code are strictly those of the [tutorial](https://www.tensorflow.org/beta/tutorials/text/text_classification_rnn)), with tanh activation and ignoring the warnings raised, for a few epochs, I cannot see any progress in training. To be more precise, the accuracy has gone from roughly 0.49 to roughly 0.51 after three epochs, which is not much of an improvement (the loss has passed from 0.25 to 0.24999 - woo-hoo)...\r\nWhen using sigmoid activation for GRU layers, the training speed becomes painfully slow (about 30 seconds per step, instead of 360 ms with tanh on the same system), seemingly due to the constant folding error. I am currently letting it run in the background and will post results as to the accuracy's evolution through training once it is done.", "So, after more than two and a half hours (!), the first epoch of training using sigmoid activation has run, and results in terms of accuracy are pretty terrible, since it is not better than random (0.49 test accuracy, same on training samples). I started running a second epoch, and could not see any significant metrics change on the first few training steps, save for a slightly higher variability (on the first run, everything was more or less 0.49, now it ranges from 0.46 to 0.52 with more scores below 0.5).\r\n\r\nUnrelatedly (?) if I disable access to the GPU (`export CUDA_VISIBLE_DEVICES=-1` before launching python) I have the same grappler error messages about constant folding, seemingly similarly bad accuracy metrics _but_ I can see the score slowly increasing on the training samples throughout the first epoch (although it is just from 0.46 to 0.5), and training goes way faster, with a little less than 1 second per sample (instead of 25 to 30 with GPU enabled).", "Let me try the colab and see if I can reproduce the issue.", "This is kind of weird, I was not able to reproduce the error when running unmodified code in colab for gpu (warning message ignored).\r\n\r\nEpoch 1/10\r\n391/391 [==============================] - 308s 788ms/step - loss: 0.5505 - accuracy: 0.7161 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\r\nEpoch 2/10\r\n391/391 [==============================] - 131s 336ms/step - loss: 0.3421 - accuracy: 0.8621 - val_loss: 0.4441 - val_accuracy: 0.8329\r\nEpoch 3/10\r\n.....\r\n\r\nNote that in the code snippet from @Slacker-WY, the loss function was updated from \"binary_crossentropy\" to \"mse\" (mean square error), which I think is the cause of issue here. The output of the model is a logic from dense activation with 1 node. Calculate mse does not make much sense to me. ", "@qlzh727 Hi, thank you for your check,\r\n- This issue doesn't show up in colab. I was also able to successfully run the code  in colab environment without any warning message, just like the tutorial example. It shows up when I ran the code in the Pycharm.\r\n- This issues appears whatever the loss function ('binary_crossentropy' or 'mse') or the optimizer  ('adam' or 'sgd' ...) I choose. I changed the loss function to 'mse' because I thought it was the cause of the issue, which it wasn't. \r\n\r\n", "The warning message does show up in the colab if you check the runtime env log. The colab and tutorial should have exact same code (they are generated from same file). \r\n\r\nIt is unclear to me why the same code produce different result on your local env. If it is a configuration issue, I would expect the model to not train at all, rather than training without convergence.", "> Calculate mse does not make much sense to me.\r\n\r\nIndeed! I therefore ran the code again with a binary cross-entropy loss, as I should have in the first place. However, the issue still shows up: with tanh activation on the GRU layers, after three epochs of training the accuracy is still around 0.5; I also trained a model with sigmoid activation on those layers (disabling access to the GPU to speed things up - the speed issue reported yesterday is still showing), but get similarly bad accuracy after three epochs.\r\n\r\n> It is unclear to me why the same code produce different result on your local env. If it is a configuration issue, I would expect the model to not train at all, rather than training without convergence.\r\n\r\nThat is, indeed, very strange. Is there any information about the local environments @Slacker-WY and I are respectively using we could provide you with to try and identify what differs from the Google Colab env? I am also going to try to build TF from source to see whether it changes things (notably to align with the operations supported by my CPU).", "I ran the code (corrected to use the proper loss function) again in two separate virtual environments (still on the same computer), one with TF 1.14 (installed from pip), the other with TF 2.0b1 compiled from source (from the current r2.0 branch). Both installations include GPU support, but I ran tests with and without the GPU. Additionally, Eager execution is by default not enabled on either of those installations (I do not get why this is the case in TF 2.0b1, but that actually served well), so I tested the behaviours with and without it. Spoiler alert: Eager execution unsurprisingly appears to be at fault.\r\n\r\n\r\n**Initial issue (is definitely weird)**\r\n\r\nThe \"skipping optimization\" warning does not show up in either of these two installations. So, could it be that there is some form of mismatch between the pre-compiled version's configuration and my (and @Slacker-WY's) system?\r\n\r\n**Convergence issues (are solved)**\r\n\r\nUsing Adam optimizer instead of SGD solves convergence issues.\r\n\r\nUsing sigmoid activation for the GRU layers instead of the default tanh does not appear to change much; depending on the initial set of weights, it may result in faster or slower convergence speed (as measured by the accuracy reached on the test set after the first training epoch, using the same initial weights and training samples' ordering) and does not alter running times in a significant manner.\r\n\r\n**Eager (breaks everything)**\r\n\r\nWhen Eager execution is enabled (which is not the default on either of my two installations):\r\n\r\n* the constant folding error shows up at each and every training step, whatever the rest of the setup details\r\n\r\n* there seems to be a memory leakage, as I see my RAM usage increase through training (around + 20M per training step, which stack up to be a lot) ; this increase also occurs when running evaluation\r\n\r\n* using the GPU increases training time by a factor of 20~25 as compared with using CPU, while when Eager is not enabled, using the GPU decreases time by around 40 % in TF 2.0b1, and does not change much in TF 1.14 as compared with using CPU (in 2.0b1, with tanh GRU activation, approx. 1 s/step without GPU, 25 with GPU and Eager and 620ms with GPU but not Eager)\r\n\r\n@qlzh727, you mentioned that the constant folding error (which appears to be at the core of the issues I am now reporting) is being dealt with through other issues, but can you confirm that there is some actual activity on the developer side as to it? I know TensorFlow is a huge project and tracking / fixing bugs then integrating those fixes is bound to sometimes take long, but there has not been much activity for the past few weeks on the GitHub issues I found (and sometimes participated in) as to this problem, and it seems to have been harsh to pass the barrier of \"front-row\" issue readers/testers (which was also the case for the present ticket), so it would be reassuring to know that people are actually working on it.", "Based on all this, here are some personal thoughts on TF 2.0, with hope that they can form part of all of the feedback TF developers are getting which may help guide development/release strategy:\r\n\r\nFor the moment, I am going to stick with my source-compiled 2.0b1 installation which does not have Eager execution enabled by default. To be honest, I feel like Google is pushing this feature forward (for obvious (and arguable) user-friendliness and pytorch-competing reasons) a bit too fast, when you consider the bugs that remain and the cost (plus, at some points, blurriness) of optimizing code once you are done with the bare design (for which Eager is rather helpful - although it really was not that painful to use session.run in 0.x and 1.x versions...).\r\n\r\nI really appreciate the effort at cleaning up the package in 2.0, and although I was reluctant to use tf.keras so extensively, I have to admit it embarks a lot of great mechanics. The documentation (I am talking about the docstrings - the new tutorials on the website are very nice), however, is not yet well adjusted (again, it is normal to take time on such a huge project, but why not wait a bit longer before making 2.0 the norm?), and the work at preserving some compatibility between versions creates some necessary confusion, although the effort here is greatly appreciable.\r\n\r\nFinally, the (superficial?) multiplication of engines to create backend graphs (tf.function with and without autograph; tf.keras.backend.function; tf.keras.Model which I guess makes use of the previous) does not help making it clear which to prefer, nor how and when to optimize code. For example, I recently developed a specific kind of layer I found in the literature, and did it by subclassing tf.keras.Layer. Now, if I decorate the call method with tf.function, I get a very significant runtime speedup when feeding it eager tensors and such during development; however, when I build a tf.keras.Model using one or more such layers, the tf.function decoration no longer has any effect on runtime. On the one hand, this is great in the sense that I seemingly do not need to think about decorating my code. On the other hand, this creates even more confusion as to when to use tf.function and when not to (in addition to questions as to what should be optimized to avoid overheads due to some suboptimal conversions within Autograph, as reported in the academic paper which presents it)...\r\n\r\nIn the end, I feel like while the entry cost of TF might have decreased thanks to Eager and keras, it is getting even harder than in 0.x to get a clear understanding of the lower level mechanics and the skill to optimize code, which I find really sad. The graph mechanics allow TF to outperform other frameworks in terms of performance, and while I get that it can be good to let it partly aside when scratching things up, it would be a shame to see TF lose some of its power \"just\" to capture some more users, even more so when it is probably already the predominant framework.", "Has this problem been solved?", "Sort of. The error message no longer shows in the nightly builds, and there has been improvements on the performance dropouts related to not disabling Eager in 2.0. That being said, I personally still cross a lot of situations when disabling Eager (while running in 2.0 to benefit from the API cleanup) makes things smoother (or simply workable in some cases). On the overall, it feels like the beta is, well, a beta, and the 2.0b1 has a lot of issues that are being progressively fixed or improved and incorporated in the nightly builds.", "@jiawei6636 You might want to read and follow the newest messages on #29525 - there appears to be further development as to this specific issue.", "Hi, I got this warning message:\t\r\n\r\n>  2019-08-20 21:53:30.063910: W tensorflow/core/grappler/optimizers/implementation_selector.cc:199] Skipping optimization due to error while loading function libraries: Invalid argument: Functions '__inference___backward_standard_lstm_3015_3517_specialized_for_SGD_gradients_lstm_2_StatefulPartitionedCall_grad_StatefulPartitionedCall_at___inference_keras_scratch_graph_5622' and '__inference___backward_cudnn_lstm_1434_1610' both implement 'lstm_75a56c74-73e4-4a2e-b381-b637dae06737' but their signatures do not match.\r\n\r\n2019-08-20 21:59:55.290415: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:502] constant folding failed: Invalid argument: Unsupported type: 21\r\n> \r\n\r\nSystem information:\r\n\r\n- Windows7 64 bit\r\n- python version: 3.7.2 (tags/v3.7.2:9a3ffc0492, Dec 23 2018, 23:09:28) [MSC v.1916 64 bit (AMD64)]\r\n- keras version: 2.2.4\r\n- tensorflow 2.0.0-beta1\r\n\r\n\r\nI found:\r\nif code like this, no 'type:21' appears\uff1a\r\n> model.add(LSTM(128, activation='relu', input_shape = (dim1, dim2)))\r\n\r\nlike this, 'type:21' appears\uff1a\r\n\r\n> model.add(LSTM(128, activation='relu', return_sequences=True, input_shape = (dim1, dim2)))\r\nmodel.add(LSTM(128))\r\n\r\n\r\n", "> @jiawei6636 You might want to read and follow the newest messages on #29525 - there appears to be further development as to this specific issue.\r\n\r\nI install the tensorflow-gpu==2.0.0-rc0, but the issue still exist.", "> @jiawei6636 You might want to read and follow the newest messages on #29525 - there appears to be further development as to this specific issue.\r\n\r\nAnd some problems occur when I use tf.keras.optimizer.RMSProp() to optimize the LSTM model by a costum training loop like the tutorial. There is no convergence.", "Same issue here.", "I get the same warning as @freetiger20150000 with CPU-only tensorflow built from the r2.0 source on macOS.", "Same error following NMT tutorial (copy and paste everything) using tensorflow2.0 RC on CPU", "I'm facing with the same issue.", "For any of you who is still facing this issue, please see my previous comment about this error in https://github.com/tensorflow/tensorflow/issues/30263#issuecomment-509053940.\r\n\r\nTLDR, this warning message is not an actual error, and can safely ignored. There is also a recent update to just suppress this warning message to avoid the confusion in https://github.com/tensorflow/tensorflow/commit/a913689fddb70729dbce45a2cad44f4bd0f03935", "> \r\n> \r\n> For any of you who is still facing this issue, please see my previous comment about this error in [#30263 (comment)](https://github.com/tensorflow/tensorflow/issues/30263#issuecomment-509053940).\r\n> \r\n> TLDR, this warning message is not an actual error, and can safely ignored. There is also a recent update to just suppress this warning message to avoid the confusion in [a913689](https://github.com/tensorflow/tensorflow/commit/a913689fddb70729dbce45a2cad44f4bd0f03935)\r\n\r\nDoes this issue lower performance? (if you're using Nvidia GPUs) Since I wonder if I would change the GRUs to CUDA optimized, it would speed up my training (which is really slow now).", "@DanielWicz, when you see this message, its means the graph has actually being optimized. In TF 2.0, the default GRU/LSTM layer is capable to auto select the CUDNN kernel, and provide better performance on GPU. You don't have to do switch to other CUDA optimized kernel.", "> There is also a recent update to just suppress this warning message to avoid the confusion in [a913689](https://github.com/tensorflow/tensorflow/commit/a913689fddb70729dbce45a2cad44f4bd0f03935)\r\n\r\n@qlzh727 it seems that your fix has not been incorporated to the released tf2.0.0, see [here in the v2.0.0 tag](https://github.com/tensorflow/tensorflow/blob/64c3d382cadf7bbe8e7e99884bede8284ff67f56/tensorflow/core/grappler/optimizers/implementation_selector.cc#L310). As a result, the warning still shows up. Do you know why your fix isn't in tf2.0.0 and when it will be deployed?\r\n\r\n", "@durandg12, ah, thanks for the notice. It seems that my change is only made to 1.15 and barely miss the 2.0 branch cut. I guess it will be released in 2.1 which will come out very soon. For now you can safely ignore the warning message.", "So I was running tensorflow 2.0 in an ubuntu 18.04 docker container on a mac host. I was seeing the very same problem. All I did was **I changed my activation from the default (which is tanh? ) to relu, and the optimization worked.** I got lucky because relu works good enough for my purposes, but does anyone know a root cause for this issue? ", "@tommathewXC, you shouldn't change the default activation function. When the default activation function is changed, the alternative cudnn kernel can't be used, which means there isn't any optimization at all. As I stated above, the warning message actually means the optimization is done, and can be safely ignored. I have change it to be a vlog to confuse less people, but it didn't reach 2.0.\r\n", "I am not sure this is directly related, but I also get the _'**Skipping optimization due to error while loading function libraries: Invalid argument: Functions(...)**'_ message, and the bug appears to only affect RNN's.\r\n\r\nThe model trains just fine, however, when calling model.save(), only the initial configuration of the model is saved. That is, all biases are zero, and the weights maintain their original values according to the initializer. It appears as if the link between the weights on GPU and those in memory is broken...?\r\n\r\nThis only happens when the model contains RNN's. Convolutions, dense layers etc. do not instigate this bug (one RNN layer is enough to break the entire thing).\r\n\r\nSetup:\r\n-Win 10\r\n-CUDA v10.0\r\n-cuDNN 7.6\r\n-Visual Studio\r\n\r\n![image](https://user-images.githubusercontent.com/49571281/68660896-50334200-053a-11ea-8dc7-c723f86ba287.png)", "We had following set up:\r\n> cuda 10.0\r\n> cudnn 7.6.5\r\n> nvidia driver 410.79\r\n> tensorflow-gpu 2.0.0\r\n> GPU Tesla T4 with 16 GB RAM\r\n> CPU with 4 cores and 8 GB RAM (from 5 to 8)\r\n\r\nAlso, in our case some tensor-flow code were running in above setting while some were not. In our case, this was caused by insufficient RAM, increasing RAM size fixed the issue. ", "this issue is yet un resolved", "I have the same issue as above (https://github.com/tensorflow/tensorflow/issues/30263#issuecomment-509020630)\r\n- Warning: Skipping optimization due to error while loading function libraries....\r\n- Training and Val loss stays pretty much constant\r\n\r\nVersions: Keras 2.2.4, TF 2.0.0", "Still have this issue. ", "No CuDNN, but this solution works for me:\r\n\r\nlstm_layer = keras.layers.RNN(keras.layers.LSTMCell(units), input_shape=(None, input_dim)\r\n\r\n\r\n    # CuDNN is only available at the layer level, and not at the cell level.\r\n    # This means `LSTM(units)` will use the CuDNN kernel,\r\n    # while RNN(LSTMCell(units)) will run on non-CuDNN kernel.\r\n    if allow_cudnn_kernel:\r\n        # The LSTM layer with default options uses CuDNN.\r\n        lstm_layer = keras.layers.LSTM(units, input_shape=(None, input_dim))\r\n    else:\r\n        # Wrapping a LSTMCell in a RNN layer will not use CuDNN.\r\n        lstm_layer = keras.layers.RNN(\r\n            keras.layers.LSTMCell(units), input_shape=(None, input_dim)", "I met the same problem as you in version 2.0.0, is there any solution other than upgrading the version?", "Still have this issue."]}, {"number": 30262, "title": "Get the number of GPUs used in Tensorflow Distributed in a multi node approach", "body": "I am currently trying to compare Horovod and Tensorflow Distributed API. \r\n\r\nWhen using using Horovod, I am able to access the total number of GPUs currently used as follows:\r\n\r\n```python\r\nimport horovod.tensorflow as hvd\r\nsize = hvd.size()\r\n```\r\n\r\nA similar concept is available when using PyTorch Distributed API:\r\n```python\r\nsize = int(os.environ[\"WORLD_SIZE\"])\r\n```\r\n\r\n-----------\r\n\r\nI would like to perform the same operation and obtain the number of GPUs currently in use for multi GPUs/nodes with TF Distributed official API.\r\n\r\nI can't use `CUDA_VISIBLE_DEVICES` environment variable as it would only work on a single node.", "comments": ["I think `Strategy.num_replicas_in_sync` is what you're looking for if you are using distribution strategy:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/distribute/Strategy#num_replicas_in_sync\r\n\r\nDoes this work? \r\n", "Thanks it answered my question."]}, {"number": 30261, "title": "Colab notebook crashes due to RAM overuse on \"Explore overfitting and underfitting\" tutorial", "body": "## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/keras/overfit_and_underfit.ipynb#scrollTo=LqG3MXF5xSjR\r\n\r\n## Description of issue (what needs changing):\r\n\r\nNotebook crashes on the code block training the baseline model, reporting that all RAM has been consumed.\r\n\r\n### Clear description\r\n\r\nUsers should be able to complete the entire notebook without hitting resource limits\r\n\r\nMaybe the model is not defined correctly? This is the summary:\r\n\r\n```\r\nModel: \"sequential\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\ndense (Dense)                (None, 16)                160016    \r\n_________________________________________________________________\r\ndense_1 (Dense)              (None, 16)                272       \r\n_________________________________________________________________\r\ndense_2 (Dense)              (None, 1)                 17        \r\n=================================================================\r\nTotal params: 160,305\r\nTrainable params: 160,305\r\nNon-trainable params: 0\r\n```", "comments": ["Confirmed.\r\n\r\nLog:\r\n```\r\nJul 1, 2019, 10:50:28 AM | WARNING | WARNING:root:kernel 69b47c82-98ca-47b8-b06e-c237cf4a1dfd restarted\r\nJul 1, 2019, 10:50:28 AM | INFO | KernelRestarter: restarting kernel (1/5), keep random ports\r\nJul 1, 2019, 10:50:18 AM | WARNING | tcmalloc: large alloc 2000003072 bytes == 0x1f896c000 @ 0x7f2229ef7887 0x7f22287edbf9 0x7f22287eeacb 0x7f22287eeb84 0x7f22287eef6c 0x7f21fa8c9d79 0x7f21fa9591be 0x7f21fa8f16f7 0x7f21fa8f228c 0x7f21fa8b0ffa 0x7f21fa8b117a 0x7f21fd6d1dce 0x7f21fd4a46e2 0x4f858d 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f6128 0x4f426e 0x5a1481 0x512a60 0x53ee21 0x57ec0c 0x4f88ba 0x4fa6c0 0x4f6128 0x4f7d60 0x4f876d 0x4f98c7 0x4f6128\r\nJul 1, 2019, 10:50:17 AM | WARNING | tcmalloc: large alloc 2000003072 bytes == 0x109a16000 @ 0x7f2229ef51e7 0x5a1c5c 0x7f2208dba650 0x4f8925 0x4f98c7 0x4f7a28 0x4f876d 0x4f98c7 0x4f6128 0x4f426e 0x5a1481 0x512a60 0x53ee21 0x57ec0c 0x4f88ba 0x4fa6c0 0x4f6128 0x4f7d60 0x4f876d 0x4f98c7 0x4f6128 0x56ff4c 0x57c2fe 0x4facb1 0x4f6128 0x4f7d60 0x4f876d 0x4fa6c0 0x4f6128 0x4f7d60 0x4f876d\r\nJul 1, 2019, 10:50:16 AM | WARNING | tcmalloc: large alloc 2000003072 bytes == 0x181612000 @ 0x7f2229ef7887 0x7f22287edbf9 0x7f22287edd17 0x7f22287ef775 0x7f2208dba181 0x7f2208dbaeca 0x7f2208dbc9e6 0x7f2208dbcc2a 0x53b410 0x53bb7b 0x4f9dc1 0x4f6128 0x4f7d60 0x4f876d 0x4fa6c0 0x4f6128 0x4f7d60 0x4f876d 0x4fa6c0 0x4f6128 0x4f7d60 0x4f876d 0x4fa6c0 0x4f6128 0x4f7d60 0x4f876d 0x4fa6c0 0x4f6128 0x4f7d60 0x4f876d 0x4fa6c0\r\nJul 1, 2019, 10:50:14 AM | WARNING | tcmalloc: large alloc 2000003072 bytes == 0x109a16000 @ 0x7f2229ef51e7 0x5a1c5c 0x7f2222013df7 0x4f8925 0x4f98c7 0x4f6128 0x4f7d60 0x4f876d 0x4fa6c0 0x4f6128 0x4f7d60 0x4f876d 0x4fa6c0 0x4f6128 0x4f7d60 0x4f876d 0x4fa6c0 0x4f6128 0x4f7d60 0x4f876d 0x4fa6c0 0x4f6128 0x4f7d60 0x4f876d 0x4fa6c0 0x4f6128 0x4f7d60 0x4f876d 0x4f98c7 0x4f6128 0x4f7d60\r\nJul 1, 2019, 10:50:12 AM | WARNING | tcmalloc: large alloc 2000003072 bytes == 0x926bc000 @ 0x7f2229ef7001 0x7f2221f1fde5 0x7f2221f846f1 0x7f2221f867cf 0x7f222201f158 0x4f8925 0x4f98c7 0x4f6128 0x4f7d60 0x4f876d 0x4fa6c0 0x4f6128 0x517a9a 0x4f858d 0x4f98c7 0x4f6128 0x4f7d60 0x4f876d 0x4f98c7 0x4f6128 0x4f7d60 0x4f876d 0x4fa6c0 0x4f6128 0x4f426e 0x5a1481 0x57c2fe 0x4facb1 0x4f6128 0x4f7d60 0x4f876d\r\nJul 1, 2019, 10:50:10 AM | WARNING | tcmalloc: large alloc 2000003072 bytes == 0x1b362000 @ 0x7f2229ef7001 0x7f2221f1fde5 0x7f2221f846f1 0x7f2221f867cf 0x7f222201f158 0x4f8925 0x4f98c7 0x4f6128 0x4f7d60 0x4f876d 0x4fa6c0 0x4f6128 0x517a9a 0x4f858d 0x4f98c7 0x4f6128 0x4f7d60 0x4f876d 0x4f98c7 0x4f6128 0x4f7d60 0x4f876d 0x4fa6c0 0x4f6128 0x4f426e 0x5a1481 0x57c2fe 0x4facb1 0x4f6128 0x4f7d60 0x4f876d\r\nJul 1, 2019, 10:49:41 AM | INFO | Adapting to protocol v5.1 for kernel 69b47c82-98ca-47b8-b06e-c237cf4a1dfd\r\nJul 1, 2019, 10:49:40 AM | INFO | Kernel started: 69b47c82-98ca-47b8-b06e-c237cf4a1dfd\r\n```", "cc: @craigcitro", "+cc @colaboratory-team for visibility\r\n\r\nThe logs in https://github.com/tensorflow/tensorflow/issues/30261#issuecomment-507362714 do seem to confirm that the notebook is requesting more RAM than the VM has available; I don't think there's anything we can do from the colab side unless it doesn't use that much RAM outside of colab.", "Oookaay ...\r\nTurns out this notebook is set to install `tf-nightly`,  switching to stable (1.14) resolves this issue.\r\nBut this may have caught a bug in nightly.\r\n", "Fixed by switching back from nightly to stable in https://github.com/tensorflow/docs/pull/730\r\ncc @fchollet", "We do need to look into what broke it in nightly. "]}, {"number": 30260, "title": "Updated doc for relu Function.", "body": "This addresses issue #26211. Defined RELU and added a detailed description of arguments, example, and reference to the paper that introduced relu.", "comments": ["This PR seems not necessary:\r\n1. image on medium is not guaranteed to stay\r\n2. the previous explanation seems clear enough."]}, {"number": 30259, "title": "including human ethics inside tensorflow as tf.ethics", "body": "wouldn't it be great to integrate ethics inside tensorflow.like when a baby is born,they get in touch with social norms.as they start to grow up their brain based on social norms/ethics start to react.based on previous norms new norms start to kick off inside brain.\r\n\r\nby the way human ethics has an evolution timeline like the biological evolution.it is changing.\r\n\r\n", "comments": ["This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [StackOverflow](http://stackoverflow.com/questions/tagged//tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!\r\n"]}, {"number": 30258, "title": "Fix KeyError when validation_data was given as a dict", "body": "This fix tries to address the issue raised in #30122 where a KeyError was thrown when validation_data was given as a dict during the mode.fit. This fix fixes the issue.\r\n\r\nThis fix fixes #30122.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Thanks @qlzh727 for the review. The PR has been updated. Please take a look and let me know if there are any other issues.", "Ping @qlzh727, any chance to take a look at the PR?"]}, {"number": 30257, "title": "Update docstring of raises for tf.clip_by_norm", "body": "This fix updates docstring of Raises for tf.clip_by_norm.\r\n\r\nThhis fix fixes #29264.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 30256, "title": "Tensorflow need a long startup time", "body": "when I run the example on https://www.tensorflow.org/tutorials/\r\nIt take around 5 minutes at:\r\nAdding visible gpu devices: 0\r\nbefore the tensorflow begins to compute. As far as I know a lot of people have this problem since a years age, but there seems to be no effective way to sove the problem.\r\nthe only way I know is to compile from source, that is not a good way for a beginner.\r\n\r\nMy environment is Win10, tensorflow-gpu-2.0-beta1\uff0c CUDA 10.0, cuDNN 7.6, python 3.6 and with GTX 850M\r\n\r\nWhen the problem will be fixed\uff1f", "comments": ["Same issue. It take around 2 minutes.@LittleFatHero", "@LittleFatHero Can you elaborate more about the issue and context. And also provide the tutorial link where the issue is pointing. Thanks! ", "> @LittleFatHero Can you elaborate more about the issue and context. And also provide the tutorial link where the issue is pointing. Thanks!\r\n\r\nI install tensorflow on my windows 10 laptop using conda with the following command:\r\n```\r\nconda create -n tf2gpu python=3.6\r\nconda activate tf2gpu\r\nconda install cudatoolkit=10.0\r\nconda install cudnn\r\npip install tensorflow-gpu-2.0-beta1\r\n```  \r\nthen I run the code with the following command:\r\n```\r\npython mnist.py\r\n```\r\nthe code of mnist.py is copy from   https://www.tensorflow.org/tutorials/ .\r\nthen the tf 2.0 begins to run and the screen of the cmd begins to output some run infomation.\r\nBut it take a long time(about five minutes )  and stop output anything when the infomation \"Adding visible gpu devices: 0\" show up. after that It begin to computes.\r\n\r\nthe bug seems no need to fixed ? but it is really annoying.\r\nmore information:\r\n https://github.com/tensorflow/tensorflow/issues/18652", "@LittleFatHero Did you get a chance to go through this [link](https://www.tensorflow.org/beta/guide/using_gpu#limiting_gpu_memory_growth). Thanks!", "> @LittleFatHero Did you get a chance to go through this [link](https://www.tensorflow.org/beta/guide/using_gpu#limiting_gpu_memory_growth). Thanks!\r\n\r\nThank you very much! I will take a look at it and try to figure out a solution!", "@LittleFatHero Were you able to resolve this issue? Thanks!", "> @LittleFatHero Were you able to resolve this issue? Thanks!\r\n\r\nNo, I have go through that link you offer, but I can't find a way to solve this problem, Can you tell me how to fix the problem on detail? Thank you", "Had the same issue. \r\nBut it seems the delay is happening only in first tf run. Subsequent runs happens pretty quickly.\r\nSo, I would run a helloworld immediately after boot, before jumping to my core development! ", "@gunan could you help to find someone familiar with windows GPU build to help with the problem?", "@chsigg This is probably a CUDA compute  capability we have not built TF binary with.", "If you are installing using conda, we should escalate to @jjhelmus", "From the install commands the Python interpreter seems to be installed using conda but the tensorflow is coming from pip.  Note that using the `cudatoolkit` and `cudnn` packages to full fill the CUDA requirements of the pip package is not recommended nor supported. ", "This is the driver compiling all of TensorFlow's CUDA kernels at startup. Your GTX 850M has CUDA compute capability 5.0. We ship TensorFlow with precompiled kernels for the following compute capabilities: 3.5,3.7,5.2,6.0,6.1,7.0\r\n\r\nGPUs with compute capability 5.0 are low end devices which are not recommended for running TensorFlow. See https://en.wikipedia.org/wiki/CUDA\r\n\r\nI'm closing this comment because the original question seems to be answered. Please feel free to reopen if you have further questions.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30256\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30256\">No</a>\n", "Same story. I installed it through Anaconda and it takes forever to toad TF.\r\n\r\nPython 3.9.7\r\nTF 2.4.1\r\nCUDA 10.1\r\nCudnn 7.6.5 \r\n\r\nIt's unbelievable that this was not solved for over a year. Time to switch to Pytorch, I guess."]}, {"number": 30255, "title": "Use environment markers for enum34", "body": "This fix tries to addres the issue raised in #30200 where enum34 caused poetry breaks due to the conditional sys.version_info\r\n\r\nThis fix changes to use environment markers for enum34 (conform to PEP508)\r\n\r\nThis fix fixes #30200.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Will this be merged into a `1.14.1` release?", "@kung-foo if this PR could be merged into the master branch first then possibly it might be cherry-picked for 1.14.1 patch release, depending on the timeline. Otherwise this PR may only show up in the next release.", "Cool. It would be very helpful to get the cherry picked in 1.14 for those of us who are not moving to 2.0 yet.", "Thank you for the fix.\r\n\r\nI'm adding #30200 to the tracker for 1.14.1 patch release, probably will start the patch release process next week or the one after, as soon as 1.13.2 gets out.\r\n\r\nPlease add me as reviewer on the cherry-pick to the r1.14 branch", "Thanks @mihaimaruseac for the help. I have created a PR #30538 to cherry-pick to R1.14."]}, {"number": 30254, "title": "could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED", "body": "Hello,\r\nFor a long time now, I've been trying to resolve problem from the header:\r\ncould not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED\r\nI went through all of the similar issues but none of the solutions worked for me.\r\n\r\nthis log: possibly insufficient driver version: 387.26.0\r\nseems to indicate that I have a bad driver version but for CUDA 9.0 documentation (https://docs.nvidia.com/deploy/cuda-compatibility/index.html#binary-compatibility__table-toolkit-driver) says:\r\nCUDA 9.0 (9.0.76)\t>= 384.81\r\nwhich is lower than I currently have installed (387.26)\r\nI really hope to get some help,\r\ncheers, Kasia\r\n\r\n**System information**\r\nRunning tensorflow inside singularity container:\r\nhttps://singularity-hub.org/collections/3092\r\nsingularity pull --name eric.img shub://Eric716/tensorflow-gpu-cuda9.0:fullversion\r\nsingularity shell --nv eric.img\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nEMI release 3.0 (Monte Bianco)\r\nLSB_VERSION=base-4.0-amd64:base-4.0-noarch:core-4.0-amd64:core-4.0-noarch:graphics-4.0-amd64:graphics-4.0-noarch:printing-4.0-amd64:printing-4.0-noarch\r\nScientific Linux CERN SLC release 6.5 (Carbon)\r\n\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below): tensorflow-gpu      1.8.0\r\nKeras               2.2.4\r\n- Python version: Python 3.5.2\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CUDA Version 9.0.176 / \r\ncuDNN: \r\ncat /usr/include/cudnn.h | grep CUDNN_MAJOR -A 2\r\n#define CUDNN_MAJOR 7\r\n#define CUDNN_MINOR 4\r\n#define CUDNN_PATCHLEVEL 2\r\n\r\nnvidia-smi\r\nDriver Version: 387.26\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\nUsing TensorFlow backend.\r\n2019-06-30 00:10:58.871234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1356] Found device 0 with properties: \r\nname: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\r\npciBusID: 0000:0d:00.0\r\ntotalMemory: 11.17GiB freeMemory: 11.10GiB\r\n2019-06-30 00:10:58.871309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1435] Adding visible gpu devices: 0\r\n2019-06-30 00:10:59.318801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-06-30 00:10:59.318875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:929]      0 \r\n2019-06-30 00:10:59.318897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:942] 0:   N \r\n2019-06-30 00:10:59.320282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 8007 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:0d:00.0, compute capability: 3.7)\r\n2019-06-30 00:11:00.116849: E tensorflow/stream_executor/cuda/cuda_dnn.cc:455] could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED\r\n2019-06-30 00:11:00.380252: E tensorflow/stream_executor/cuda/cuda_dnn.cc:463] possibly insufficient driver version: 387.26.0\r\n2019-06-30 00:11:00.380342: F tensorflow/core/kernels/conv_ops.cc:713] Check failed: stream->parent()->GetConvolveAlgorithms( conv_parameters.ShouldIncludeWinogradNonfusedAlgo<T>(), &algorithms) \r\nAborted\r\n\r\n\r\n\r\n**Code to reproduce the issue**\r\nimport numpy as np\r\nfrom keras.models import Input, Model\r\nfrom keras.layers import Conv1D\r\nfrom keras.optimizers import *\r\nimport keras.backend as K\r\n\r\n\r\ndef conv_model(input_size=(256, 1)):\r\n    cfg = K.tf.ConfigProto(gpu_options={'allow_growth': True, 'per_process_gpu_memory_fraction': 0.7})\r\n    K.set_session(K.tf.Session(config=cfg))\r\n\r\n    inputs = Input(input_size)\r\n    conv = Conv1D(1, 3, padding='same')(inputs)\r\n    model = Model(inputs=inputs, outputs=conv)\r\n    model.compile(optimizer=Adam(lr=2e-4), loss='binary_crossentropy', metrics=['accuracy'])\r\n    return model\r\n\r\n\r\nif __name__ == '__main__':\r\n    num_epochs = 300\r\n    model = conv_model()\r\n    input_batch = np.array([np.concatenate([[[0]]*100, [[1]]*56, [[0]]*100])])\r\n\r\n    for epoch in range(num_epochs):\r\n        loss, acc = model.train_on_batch(input_batch, input_batch)\r\n        print('loss: {}, acc: {}'.format(loss, acc))\r\n\r\n", "comments": ["Please, let us know which version of cuDNN you installed?If not please install cuDNN 7 and let us know if the issue still persists.Thanks!", "@ravikyram \r\nfrom this output:\r\ncat /usr/include/cudnn.h | grep CUDNN_MAJOR -A 2\r\n#define CUDNN_MAJOR 7\r\n#define CUDNN_MINOR 4\r\n#define CUDNN_PATCHLEVEL 2\r\nI assume it's 7.4.2 am I right?", "@kaz94 I don't see any issue with the driver and also your code. Source of the issue is something else.\r\n\r\nDid you install tensorflow from source?\r\nDid you check whether there is any issue with the driver 387.26? \r\nDid you try upgrading or downgrading the version of driver (example downgrading to 384.81)\r\nThanks!", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "> @kaz94 I don't see any issue with the driver and also your code. Source of the issue is something else.\r\n> \r\n> Did you install tensorflow from source?\r\n> Did you check whether there is any issue with the driver 387.26?\r\n> Did you try upgrading or downgrading the version of driver (example downgrading to 384.81)\r\n> Thanks!\r\n\r\nI have the same issue with `tensorflow-gpu==1.8.0`, `cudnn==7.0.5` and `cuda=9.1.84` on ubuntu 16.04\r\nBelow is the log:\r\n\r\nHi everyone,\r\nI am trying to reproduce the results mentioned in paper  https://github.com/f90/Wave-U-Net ; but when I run the repo's scripts I get the following errors:\r\n```\r\n2019-07-25 05:51:38.470459: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:94] Filling up shuffle buffer (this may take a while): 2001 of 8000\r\n2019-07-25 05:51:48.423484: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:94] Filling up shuffle buffer (this may take a while): 4201 of 8000\r\n2019-07-25 05:51:58.262603: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:94] Filling up shuffle buffer (this may take a while): 6448 of 8000\r\n2019-07-25 05:52:04.644012: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:129] Shuffle buffer filled.\r\n2019-07-25 05:52:04.890160: E tensorflow/stream_executor/cuda/cuda_dnn.cc:455] could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED\r\n2019-07-25 05:52:04.890268: E tensorflow/stream_executor/cuda/cuda_dnn.cc:463] possibly insufficient driver version: 384.183.0\r\n2019-07-25 05:52:04.890282: E tensorflow/stream_executor/cuda/cuda_dnn.cc:427] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM\r\n2019-07-25 05:52:04.890291: F tensorflow/core/kernels/conv_ops.cc:713] Check failed: stream->parent()->GetConvolveAlgorithms( conv_parameters.ShouldIncludeWino\r\ngradNonfusedAlgo<T>(), &algorithms) \r\nAborted (core dumped)\r\n```\r\nPlease help.\r\nThankyou", "@vinaykumar2491 Please create a new issue with platform details, standalone code and any other details that will help in resolving the issue faster. Thanks!"]}, {"number": 30253, "title": "Problem Passing Tensor Attr to Custom Op in Eager Execution Mode", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Windows 10:\r\n- TensorFlow installed from binary:\r\n- TensorFlow version 1.14:\r\n- Python version 3.7:\r\n- CUDA/cuDNN version 10:\r\n\r\nI am defining a new custom Op in C++, which takes in a single attribute of type tensor and a single input tensor variable. A stripped version of the Op code is below:\r\n\r\n    #include \"tensorflow/core/framework/op.h\"\r\n    #include \"tensorflow/core/framework/op_kernel.h\"\r\n    \r\n    using namespace tensorflow;\r\n    \r\n    REGISTER_OP(\"DoStuff\")\r\n        .Attr(\"attr: tensor = { dtype: DT_FLOAT }\")\r\n        .Input(\"in: float\")\r\n        .Output(\"out: float\");\r\n    \r\n    class DoStuffOp : public OpKernel {\r\n    public:\r\n        explicit DoStuffOp(OpKernelConstruction *context) : OpKernel(context) {\r\n            OP_REQUIRES_OK(context, context->GetAttr(\"attr\", &attr_));\r\n            // ...\r\n        }\r\n    \r\n        void Compute(OpKernelContext *context) override {\r\n            // ...\r\n        }\r\n    \r\n    private:\r\n        Tensor attr_;\r\n    };\r\n    \r\n    REGISTER_KERNEL_BUILDER(Name(\"DoStuff\").Device(DEVICE_CPU), DoStuffOp);\r\n\r\nI can compile the Op into a .so file fine. Now, the following code runs.\r\n\r\n    import tensorflow as tf\r\n    dostufflib = tf.load_op_library('build/do_stuff.so')\r\n    sess = tf.InteractiveSession() \r\n\r\n    sample_in = np.random.rand(3,3)\r\n    sample_in_t = tf.convert_to_tensor(sample_in, dtype=np.float32)\r\n    sample_atrr = np.zeros([3,3], dtype=np.float32)\r\n    sample_attr_t = tf.contrib.util.make_tensor_proto(sample_atrr)\r\n\r\n    Y = dostufflib.do_stuff(in=sample_in_t, attr=sample_attr_t)\r\n\r\nHowever, if I try to use eager execution mode i.e.\r\n\r\n    import tensorflow as tf\r\n    tf.compat.v1.enable_eager_execution()\r\n    dostufflib = tf.load_op_library('build/do_stuff.so')\r\n    \r\n    sample_in = np.random.rand(3,3)\r\n    sample_in_t = tf.convert_to_tensor(sample_in, dtype=np.float32)\r\n    sample_atrr = np.zeros([3,3], dtype=np.float32)\r\n    sample_attr_t = tf.contrib.util.make_tensor_proto(sample_atrr)\r\n    \r\n    Y = dostufflib.do_stuff(in=sample_in_t, attr=sample_attr_t)\r\n\r\nI get the following error,\r\n\r\n    tensorflow.python.framework.errors_impl.UnimplementedError: Attr sample_locs has unhandled type 6\r\n", "comments": ["facing the similar issue and the error message is \r\nAttributeError: Tensor.op is meaningless when eager execution is enabled.\r\n", "The \"Attr sample_locs has unhandled type 6\" is also a problem in TF 2.x.x. FYI, for those suffering this problem, in the meantime, it seems that passing lists works ok. So it possible to flatten your numpy array / tensor and pass a python list to your custom op and recreate a matrix instead that.", "It is possible that the Eager execution runtime does not support tensor attrs. In general, though, you should never use an attr for values that can be an input. So attrs should be used for things that affect the signature like number or type of inputs or outputs. The main reason for Tensor attrs in the first place was for the Const op, which is handled in a different way in eager execution.", "> It is possible that the Eager execution runtime does not support tensor attrs.\r\n\r\nIndeed and this is true for TF2.0 as well:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/1c83755e5a1269b528042e6d318d66e363ffc349/tensorflow/python/eager/pywrap_tfe_src.cc#L412\r\n\r\nIt's a pity because, having eager execution the default option for TF2.0, it's not even possible to use e.g. `tf.compat.v1.summary.image()` :\r\n```\r\ntensorflow.python.framework.errors_impl.UnimplementedError: Attr bad_color has unhandled type 6 [Op:ImageSummary] name: input_image\r\n```", "Thanks for digging up the code @dtarakanov1. Regarding the image summary, you should be able to use `tf.compat.v2.summary.image` which should be compatible with Eager mode execution.\r\n\r\nAs @josh11b has mentioned, it seems like using a tensor attr isn't recommended. Instead, the tensor should be an input.\r\n\r\nThus, I am closing the issue, but please feel free to re-open if need to support tensor attributes in eager mode is necessary.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30253\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30253\">No</a>\n", "Please don't close the issue. My question differs from the original problem.", "dtarakanov1@: I agree that your need to use image summaries differs slightly. However, isn't the recommendation for the original issue to use tensors as an input vs an attribute?"]}, {"number": 30252, "title": "TPU Outfeed Dequeue Many", "body": "I have an application that is bottlenecked by waiting for elements to be dequeued from the TPU. Is there any way to dequeue many from the outfeed in a single operation?\r\n\r\nRight now my program runs two threads in parallel:\r\n  1. a computation followed by an outfeed_enqueue\r\n  2. a outfeed_dequeue that collects elements from the outfeed and acts on them\r\n\r\nfor Thread 1. I can execute the op ~30 times for every dequeue in Thread 2. So ideally, I'd like to dequeue the 30 batches that are sitting in my outfeed queue instead of a single batch at a time. Is there a way to do this?\r\n\r\nI'm running TF 1.13 (although I'm sure TF 1.14 would be fine too).", "comments": ["@aidangomez Please have look at [TPU parallel execution](https://www.tensorflow.org/api_docs/python/tf/tpu/shard). Please let us know if that helps. Thanks! "]}, {"number": 30250, "title": "How to maintain the FIFOQueue when training", "body": "Hi, I want to use FIFOQueue to keep K elements in training process.\r\n```python\r\n    input_tensor = tf.placeholder(tf.float32, shape=[None, 224, 224, 3], name='x')\r\n    model = SEVGGModel(input_tensor, input_tensor)\r\n    print(model.output_feature, model.output_feature_map, model.output_feature_norm)\r\n    import os\r\n    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\r\n    sess = tf.Session()\r\n    sess.run(tf.initialize_all_variables())\r\n    # coord = tf.train.Coordinator()\r\n    # threads = tf.train.start_queue_runners(coord=coord, sess=sess)\r\n\r\n    print(sess.run(model.last_ele_queue.size()))\r\n    print('ref is ', model.last_ele_queue.queue_ref)\r\n    with tf.control_dependencies([model.enqueue_op]):\r\n        # output_tensor = tf.cond(\r\n        #     tf.equal(model.last_ele_queue.size(), 0),\r\n        #     lambda: 0.,\r\n        #     lambda: model.last_ele_queue.dequeue_many(30)\r\n        # )\r\n        loss_tensor = model.build_loss(True)\r\n    for i in range(100):\r\n        feed_dict = {\r\n            input_tensor: np.random.random([30, 224, 224, 3]) * i\r\n        }\r\n        # sess.run(model.enqueue_op, feed_dict=feed_dict)  ## with or without\r\n        print(i, sess.run(model.last_ele_queue.size()))\r\n        _, loss_value = sess.run([model.enqueue_op, loss_tensor], feed_dict=feed_dict)\r\n        # print(np.shape(values), np.max(values), np.min(values))\r\n        print('loss_value ', loss_value)\r\n    print(sess.run(model.last_ele_queue.size()))\r\n```\r\nthe loss value can be see as the sum of all elements in Queue and the feed_dict is the element in the Queue..\r\nI found when I use the code sess.run(model.enqueue_op, feed_dict=feed_dict), I think the loss value should be double. But the result is not. The result of with or without this line are same.\r\n\r\nSo can you help me explain it?\r\n\r\nThanks you!", "comments": ["@UpCoder Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nIn order to expedite the trouble-shooting process, please provide a full code snippet to reproduce the issue reported here. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 30249, "title": ".tflite converted model (from .h5 file) not working as expected", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes, custom model to count fingers, but the TFLite converter code is same as example scripts provided in API docs.\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: All android devices using TFlite example app (replaced the sample models with my custom tflite model)\r\n- TensorFlow installed from (source or binary): pip installed tensorflow-gpu AND tf-nightly-gpu\r\n- TensorFlow version (use command below): Tried on 1.14, 1.13, 1.14-nightly, 2.0.0-beta1\r\n- Python version: 3.6.7\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: Cuda 10.0\r\n- GPU model and memory: GTX 1060 6GB\r\n\r\n**Describe the current behavior**\r\nI've trained a simple CNN to count number of fingers held up. The model works really well (~99% accuracy on test images). Now, I'm trying to deploy this model on the edge by converting the saved model (.h5 file) to a .tflite file.\r\n\r\nUsing tf.lite.TFLiteConverter.from_keras_model_file(), it converts and gives me a .tflite file with this error:\r\n`tensorflow/core/grappler/grappler_item_builder.cc:637] Init node conv2d/kernel/Assign doesn't exist in graph`\r\n\r\nNow, when I load this tflite file and try to make predictions on the same input images, it always predicts 'ZERO' which is the first class label and with probability = 0.003922. The rest of the classes are always 0.00, I get the same results when loading my tflite model in the Android Image classification example app from Tensorflow repo's.\r\n\r\n**Describe the expected behavior**\r\nI expect my .tflite model to behave the same as my Tensorflow .h5 model. But it always predicts \r\nthe first class label with the same probability score. \r\nI've tried converting to .tflite with TF-gpu versions 1.14, 1.13, nightly 1.14 and TF-2.0.0-beta1\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n**My custom model:**\r\n```\r\nredacted\r\n```\r\n\r\n**Code I used to convert to .tflite:** \r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model_file(\"fingers_latest.h5\")\r\ntflite_model = converter.convert()\r\nopen(\"fingers_latest.tflite\", \"wb\").write(tflite_model)\r\n```\r\n\r\n\r\n**Code to load and test the .tflite model:**\r\n\r\n```\r\nimport tensorflow as tf\r\nimport tkinter as tk\r\nfrom tkinter import filedialog\r\nimport PIL\r\nfrom PIL import Image\r\nimport numpy as np\r\nimport time\r\n\r\n# DEF. PARAMETERS\r\nimg_row, img_column = 256, 256\r\nnum_channel = 3\r\nnum_batch = 1\r\ninput_mean = 0\r\ninput_std = 255\r\nfloating_model = False\r\n\r\npath_1 = r\"./models/fingers_latest.tflite\"\r\nlabels_path = \"./models/labels.txt\"\r\n\r\ndef load_labels(filename):\r\n    my_labels = []\r\n    input_file = open(filename, 'r')\r\n    for l in input_file:\r\n        my_labels.append(l.strip())\r\n    return my_labels\r\n\r\ninterpreter = tf.lite.Interpreter(path_1)\r\ninterpreter.allocate_tensors()\r\n\r\n# obtaining the input-output shapes and types\r\ninput_details = interpreter.get_input_details()\r\noutput_details = interpreter.get_output_details()\r\nprint(input_details, '\\n', output_details)\r\n\r\n# file selection window for input selection\r\nroot = tk.Tk()\r\nroot.withdraw()\r\nfile_path = filedialog.askopenfilename()\r\ninput_img = Image.open(file_path)\r\ninput_img = input_img.resize((img_row, img_column))\r\ninput_img = np.expand_dims(input_img, axis=0)\r\n\r\ninput_img = (np.float32(input_img) - input_mean) / input_std\r\n\r\ninterpreter.set_tensor(input_details[0]['index'], input_img)\r\n\r\n# running inference\r\ninterpreter.invoke()\r\n\r\noutput_data = interpreter.get_tensor(output_details[0]['index'])\r\nresults = np.squeeze(output_data)\r\n\r\ntop_k = results.argsort()[-5:][::-1]\r\nlabels = load_labels(labels_path)\r\nfor i in top_k:\r\n    print('{0:08.6f}'.format(float(results[i] / 255.0)) + \":\", labels[i]) \r\n```\r\n\r\n\r\nWhy does this tflite model not work as expected? Am I missing something during the conversion or using operations that aren't supported in TFlite? Please help!\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n[My .h5 model and a test file, if you would like to try it yourself](https://drive.google.com/drive/folders/1_jiRqHgRUyV5YBNcDPKPtZMGjUpkf8sC)", "comments": ["Solved the issue, closing it.", "Can you please post your solution as well, i am facing the same problem."]}, {"number": 30248, "title": "tf.io.write_file not working in tf.function decorated function", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.2 and Windows 10\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0.0-beta1\r\n- Python version: 3.7\r\n\r\n**Describe the current behavior**\r\n`tf.io.write_file` creates file in eager execution but produces no output file when decorated with `@tf.function`.\r\n\r\n**Describe the expected behavior**\r\n`tf.io.write_file` should create an output file whether or not being decorated with `@tf.function`.\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\n\r\n@tf.function\r\ndef writeJPEG_graph(img_decoded, filename):\r\n    out = tf.cast(img_decoded, tf.uint8)\r\n    out = tf.image.encode_jpeg(out, quality=100)\r\n    tf.io.write_file(filename, out)\r\n    \r\ndef writeJPEG_eager(img_decoded, filename):\r\n    out = tf.cast(img_decoded, tf.uint8)\r\n    out = tf.image.encode_jpeg(out, quality=100)\r\n    tf.io.write_file(filename, out)\r\n\r\nimg = tf.fill([256,256,3], 127) # example gray image\r\nwriteJPEG_graph(img, \"./tfwrite_graph.jpg\") # \"tfwrite_graph.jpg\" not created\r\nwriteJPEG_eager(img, \"./tfwrite_eager.jpg\") # \"tfwrite_eager.jpg\" created\r\n```", "comments": ["I have tried on colab with TF version 2.0 beta1 and was able to reproduce the issue.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=30248\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=30248\">No</a>\n", "This also happens in 1.14, and sadly inhibits visualizing images augmented in `tf.data.Dataset` pipelines (since they are run as a Graph)", "Unfortunately the fix didn't make it into the 1.14 release, and will only be available in 2.0.\r\n\r\nIn 1.14, `write_file` should still be usable using the old-style `tf.control_dependencies`.", "@junghau \r\nI ran the code shared and do not face any error, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/92c7fe5bb5088ca162cd180e8fc90dcb/untitled.ipynb)."]}, {"number": 30247, "title": "[tflite] include headers to fix undeclared PROT_READ on macos", "body": "nnapi delegate doesn't compile on macOS after https://github.com/tensorflow/tensorflow/commit/19f417d905980cb7f2098e48c147cb301c087573. Add ` #include <sys/mman.h>` to fix it.", "comments": ["@freedomtan Can you please resolve conflicts? Thanks!", "close this, because c455914 rolled back 19f417d, the commit introduced the problem."]}, {"number": 30245, "title": "[docs] Fixes docs for weighted_cross_entropy_with_logits", "body": "## What?\r\n\r\nThis PR fixes spacing issues in docs for `weighted_cross_entropy_with_logits` operation.\r\n\r\n## Why?\r\n\r\nCurrently, there is no spacing between sections and everything looks jumbled up. See:\r\nhttps://www.tensorflow.org/api_docs/python/tf/nn/weighted_cross_entropy_with_logits", "comments": []}, {"number": 30244, "title": "issue 27543 workaround, allow model with inputs not used to be saved successfully", "body": "This is a workaround for #27543, allowing model with inputs not used to be saved successfully\r\n\r\nI think this PR should also be merged to r1.14 and r2.0 branch, this issue does not exist before r1.14\r\n\r\n```\r\nimport numpy as np\r\n\r\nimport tensorflow as tf\r\nimport tensorflow.keras as tfk\r\nSequence = tfk.utils.Sequence\r\n\r\nDense = tfk.layers.Dense\r\nInput = tfk.layers.Input\r\n\r\nModel = tfk.models.Model\r\n\r\ndef special_loss(weights):\r\n    def special_loss_internal(true, pred):\r\n        return (true - pred / weights)\r\n    return special_loss_internal\r\n\r\n# Model 1 which does not have Flatten\r\ninput_tensor1 = Input(shape=[200], name='input_1')\r\ninput_tensor2 = Input(shape=[10], name='input_2')\r\noutput_tensor1 = Dense(units=10, name='output_1')(input_tensor1)\r\noutput_tensor2 = Dense(units=10, name='output_2')(input_tensor1)\r\n\r\nneuralnet = Model(inputs=[input_tensor1, input_tensor2], outputs=[output_tensor1, output_tensor2])\r\nneuralnet.compile(loss=special_loss(input_tensor2), optimizer='adam')\r\n\r\nneuralnet.save(\"test.h5\")\r\n```\r\n\r\nwhich performs successfully with this patch.\r\n\r\nand to load the `.h5` model back\r\n```\r\nimport numpy as np\r\n\r\nimport tensorflow as tf\r\nimport tensorflow.keras as tfk\r\nSequence = tfk.utils.Sequence\r\n\r\nDense = tfk.layers.Dense\r\nInput = tfk.layers.Input\r\n\r\nModel = tfk.models.Model\r\n\r\ndef special_loss(weights):\r\n    def special_loss_internal(true, pred):\r\n        return (true - pred / weights)\r\n    return special_loss_internal\r\n\r\n# Model 1 which does not have Flatten\r\ninput_tensor1 = Input(shape=[200], name='input_1')\r\ninput_tensor2 = Input(shape=[10], name='input_2')\r\noutput_tensor1 = Dense(units=10, name='output_1')(input_tensor1)\r\noutput_tensor2 = Dense(units=10, name='output_2')(input_tensor1)\r\n\r\nneuralnet = Model(inputs=[input_tensor1, input_tensor2], outputs=[output_tensor1, output_tensor2])\r\nneuralnet.compile(loss=special_loss(input_tensor2), optimizer='adam')\r\n\r\nmodel = neuralnet.load_weights('test.h5')\r\n```\r\n\r\nwhich also performs successfully with this patch.\r\n", "comments": ["@henrysky Thanks for adding this workaround!  This issue has been fixed in this change: https://github.com/tensorflow/tensorflow/commit/401bbfc33684c21325d81a03708fe123d59ce527#diff-4ee308ea180d49ae81691348531a2b6d\r\n\r\n"]}, {"number": 30243, "title": "[mlir] make mlir related stuff build on macos", "body": "`bazel build --config opt tensorflow/compiler/mlir/...` doesn't work on macOS.\r\n1. `exp10()` is not a standard C function, macos has `__exp10()`\r\n2. include `\"mlir/StandardOps/Ops.h\"` earlier to avoid `TRUE` and`FALSE` being defined in `<mach/boolean.h>`", "comments": ["One suggestion, else it looks good, thanks", "rebased to resolve conflicts and replaced `exp10(X)` with `pow(10.0, X)`", "Thanks for your work and review. BTW, I cannot build related stuff after 22385cc65e2, either reverting it or more modifications needed. See the error message below\r\n```\r\nERROR: /Users/freedom/work/tf-py3/tensorflow/compiler/mlir/lite/BUILD:209:1: C++ compilation of rule '//tensorflow/compiler/mlir/lite:tensorflow_lite_legalize_tf' failed (Exit 1)\r\ntensorflow/compiler/mlir/lite/transforms/lower_static_tensor_list.cc:319:8: error: call to implicitly-deleted copy constructor of 'mlir::Function'\r\n  auto func = getFunction();\r\n       ^      ~~~~~~~~~~~~~\r\nexternal/local_config_mlir/include/mlir/IR/Function.h:315:10: note: copy constructor of 'Function' is implicitly deleted because field 'body' has a deleted copy constructor\r\n  Region body;\r\n         ^\r\nexternal/local_config_mlir/include/mlir/IR/Region.h:118:14: note: copy constructor of 'Region' is implicitly deleted because field 'blocks' has a deleted copy constructor\r\n  RegionType blocks;\r\n             ^\r\nexternal/llvm/include/llvm/ADT/ilist.h:395:3: note: 'iplist' has been explicitly marked deleted here\r\n  iplist(const iplist &X) = delete;\r\n  ^\r\n1 error generated.\r\n```", "Could you rebase? We've changed function to be value typed. If that doesn't work, I'll apply your change to head and commit it.", "Yes, 604988b works. The only change needed is replacing `exp10()`. I'll update with additional `\"mlir/StandardOps/Ops.h\"`removed."]}, {"number": 30242, "title": "tensorflow ", "body": "", "comments": ["Hi, please edit/format your issue after reading the following issue template guide:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/ISSUE_TEMPLATE.md\r\n\r\nIt becomes really difficult to solve anything without describing the problem properly. ", "Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the code snippet to reproduce the issue. If you are unclear what to include see the issue template displayed in the Github new [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}]