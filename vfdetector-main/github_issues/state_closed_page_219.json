[{"number": 48040, "title": "win10 build tensorflow2.4.1,ERROR: C:/tensorflow/tensorflow/python/util/BUILD:609:27: C++ compilation of rule '//tensorflow/python/util:fast_module_type.so' failed (Exit 2): python.exe failed: error executing command", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None\r\n- TensorFlow installed from (source or binary):  source \r\n- TensorFlow version:2.4.1\r\n- Python version:3.8.6\r\n- Installed using virtualenv? pip? conda?:pip\r\n- Bazel version (if compiling from source):3.7.2\r\n- GCC/Compiler version (if compiling from source):MSVC2019\r\n- CUDA/cuDNN version:11.0 / 8.0.5\r\n- GPU model and memory: GeForce RTX 2080 ti\r\n\r\n\r\n\r\n**Describe the problem**\r\nERROR: C:/tensorflow/tensorflow/python/util/BUILD:609:27: C++ compilation of rule '//tensorflow/python/util:fast_module_type.so' failed (Exit 2): python.exe failed: error executing command\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nbazel clean\r\nbazel build --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\ncd C:/users/zn58887/_bazel_zn58887/xv6zejqw/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.0\r\n    SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\ATLMFC\\include;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\winrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\cppwinrt\r\n    SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\ATLMFC\\lib\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\lib\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\lib\\um\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.19041.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.19041.0\\um\\x64\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\\\Extensions\\Microsoft\\IntelliCode\\CLI;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\bin\\HostX64\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\VC\\VCPackages;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\TeamFoundation\\Team Explorer;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\MSBuild\\Current\\bin\\Roslyn;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Team Tools\\Performance Tools\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Team Tools\\Performance Tools;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\vs2019\\\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\vs2019\\;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.8 Tools\\x64\\;C:\\Program Files (x86)\\HTML Help Workshop;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\10.0.19041.0\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\\\MSBuild\\Current\\Bin;C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\Tools\\;;C:\\Windows\\system32;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\CMake\\bin;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\Ninja\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=C:/Python38/python.exe\r\n    SET PYTHON_LIB_PATH=C:/Python38/lib/site-packages\r\n    SET RUNFILES_MANIFEST_ONLY=1\r\n    SET TEMP=C:\\Users\\zn58887\\AppData\\Local\\Temp\r\n    SET TF2_BEHAVIOR=1\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=7.5\r\n    SET TMP=C:\\Users\\zn58887\\AppData\\Local\\Temp\r\n  C:/Python38/python.exe -B external/local_config_cuda/crosstool/windows/msvc_wrapper_for_nvcc.py /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /bigobj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/bin /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/nsync /Ibazel-out/x64_windows-opt/bin/external/nsync /Iexternal/local_config_python /Ibazel-out/x64_windows-opt/bin/external/local_config_python /Iexternal/pybind11 /Ibazel-out/x64_windows-opt/bin/external/pybind11 /Iexternal/bazel_tools /Ibazel-out/x64_windows-opt/bin/external/bazel_tools /Ibazel-out/x64_windows-opt/bin/external/pybind11/_virtual_includes/pybind11 /Ithird_party/eigen3/mkl_include /Ibazel-out/x64_windows-opt/bin/third_party/eigen3/mkl_include /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/nsync/public /Ibazel-out/x64_windows-opt/bin/external/nsync/public /Iexternal/local_config_python/python_include /Ibazel-out/x64_windows-opt/bin/external/local_config_python/python_include /Iexternal/pybind11/include /Ibazel-out/x64_windows-opt/bin/external/pybind11/include /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /showIncludes /MD /O2 /DNDEBUG /W0 /D_USE_MATH_DEFINES -DWIN32_LEAN_AND_MEAN -DNOGDI /experimental:preprocessor /d2ReducedOptimizeHugeFunctions /arch:AVX /std:c++14 -fno-strict-aliasing -fexceptions /Fobazel-out/x64_windows-opt/bin/tensorflow/python/util/_objs/fast_module_type.so/fast_module_type.obj /c tensorflow/python/util/fast_module_type.cc\r\nExecution platform: @local_execution_config_platform//:platform\r\ncl: \u547d\u4ee4\u884c warning D9035 :\u201cexperimental:preprocessor\u201d\u9009\u9879\u5df2\u5426\u51b3\uff0c\u5e76\u5c06\u5728\u5c06\u6765\u7684\u7248\u672c\u4e2d\u79fb\u9664\r\ncl: \u547d\u4ee4\u884c warning D9036 :\u4f7f\u7528\u201cZc:preprocessor\u201d\u800c\u4e0d\u4f7f\u7528\u201cexperimental:preprocessor\u201d\r\ncl: \u547d\u4ee4\u884c warning D9002 :\u5ffd\u7565\u672a\u77e5\u9009\u9879\u201c-fno-strict-aliasing\u201d\r\ncl: \u547d\u4ee4\u884c warning D9002 :\u5ffd\u7565\u672a\u77e5\u9009\u9879\u201c-fexceptions\u201d\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:  bazel-out/x64_windows-opt/bin/external/local_config_python/python_include\\Python.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:   C:\\users\\zn58887\\_bazel_zn58887\\xv6zejqw\\execroot\\org_tensorflow\\bazel-out\\x64_windows-opt\\bin\\external\\local_config_python\\python_include\\patchlevel.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:   C:\\users\\zn58887\\_bazel_zn58887\\xv6zejqw\\execroot\\org_tensorflow\\bazel-out\\x64_windows-opt\\bin\\external\\local_config_python\\python_include\\pyconfig.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:    C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\io.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt_io.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt_share.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:       C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:        C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\vcruntime.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:         C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\sal.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:          C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\concurrencysal.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:         C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\vadefs.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt_wio.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:    C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\float.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:    C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\shared\\basetsd.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:    C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\stdio.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt_wstdio.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt_stdio_config.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:   C:\\users\\zn58887\\_bazel_zn58887\\xv6zejqw\\execroot\\org_tensorflow\\bazel-out\\x64_windows-opt\\bin\\external\\local_config_python\\python_include\\pymacconfig.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:   C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\limits.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:   C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\string.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:    C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt_memory.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt_memcpy_s.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\errno.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:      C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\vcruntime_string.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:    C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt_wstring.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:   C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\stdlib.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:    C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt_malloc.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:    C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt_search.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\stddef.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:    C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt_wstdlib.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:   C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\assert.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:   C:\\users\\zn58887\\_bazel_zn58887\\xv6zejqw\\execroot\\org_tensorflow\\bazel-out\\x64_windows-opt\\bin\\external\\local_config_python\\python_include\\pyport.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:    C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\inttypes.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29333\\include\\stdint.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:    C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\math.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt_math.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt_math_defines.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:    C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\time.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\corecrt_wtime.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:    C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\sys/stat.h\r\n\u6ce8\u610f: \u5305\u542b\u6587\u4ef6:     C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.19041.0\\ucrt\\sys/types.h", "comments": [" I've upgrade win10 SDK to 10.0.19041.0, but still with error.\r\nReally need some help!", "@ZoeZhang91 \r\nCan you please check your pip version and numpy version, refer to this [comment here](https://github.com/tensorflow/tensorflow/issues/41061#issuecomment-656017717) and verify your [system requirements](47824)", "Yes, my pip version is 20.2.1, numpy version is 1.20.1, python 3.8.6 is also 64bit. \r\nAfter the command: bazel clean, I rebuild the source, and here's another error :\r\n\r\nERROR: C:/tensorflow/tensorflow/python/util/BUILD:329:27: C++ compilation of rule '//tensorflow/python/util:_tf_stack.so' failed (Exit 2): python.exe failed: error executing command\r\n\r\nand the error LOG seems like as above. ", "@ZoeZhang91 \r\nIs this still an issue.", "@ZoeZhang91,\r\n\r\nTensorflow v2.4.1 source incompatible with Numpy version 1.20.1. Downgrade numpy ~= 1.19.5 will resolve the issues.\r\n\r\n`pip install numpy==1.19.5`", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48040\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48040\">No</a>\n"]}, {"number": 48039, "title": "Expression issue of BatchNormalization layer", "body": "A issue about the expression in the BatchNormalization layer.\r\n\r\n## URL(s) with the issue:\r\nhttps://keras.io/api/layers/normalization_layers/batch_normalization/\r\n\r\n## Description of issue (what needs changing):\r\nIn the provided URL, during inference, this layer returns:\r\n(batch - self.moving_mean) / (self.moving_var + epsilon) * gamma + beta.\r\n\r\nBut, I think a square operation is missing. It should return:\r\n(batch - self.moving_mean) / **sqrt**(self.moving_var + epsilon) * gamma + beta.\r\n\r\nSimilarly, the square operation should be add in the equation during training, as:\r\n(batch - mean(batch)) / **sqrt**(var(batch) + epsilon) * gamma + beta.\r\n\r\nPlease refer to Algorithm 1 in the paper: \r\n_Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift_", "comments": ["@zwang1995,\r\nCan you please share the link corresponding to the statement, \r\n\r\n> Please refer to Algorithm 1 in the paper:\r\n> Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift.\r\n\r\nso that we can double check? Thanks!", "@rmothukuru \r\nHere is the link: https://arxiv.org/abs/1502.03167", "@zwang1995,\r\nSorry, but we couldn't find the expression you mentioned in that link. Can you please provide the exact link? Thanks! ", "@rmothukuru \r\nIn Algorithm 1, in the normalize step, there is a **square root** for (sigma**2 + epsilon). \r\nAnd the **square root** is missing in the document for BatchNormalization layer.", "@zwang1995,\r\nIf I am not wrong, you are referring to the `formulae` mentioned in [this link](https://paperswithcode.com/method/batch-normalization). Your point is valid but the expression has been simplified by removing the `Square Root` in the `Denominator` because **_`Square root of (sigma ** 2)`_** will be **_`sigma`_** itself, and the value, **_`epsilon`_** is a very very small number (usually negligible), which has been added to avoid **_`Divide By Zero`_** condition.\r\n\r\nHope this clarifies about the expressions in the [documentation of Batch Normalization](https://www.tensorflow.org/api_docs/python/tf/keras/layers/BatchNormalization). Thanks!", "@rmothukuru,\r\nIt did clarified. Thank you!"]}, {"number": 48038, "title": "Named dictionary outputs in tf.keras.Model do not work with defining seperate metrics per output", "body": "### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**: Yes\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux-4.9.0-4-amd64-x86_64-with-Ubuntu-18.04-bionic\r\n-   **TensorFlow installed from (source or binary)**: Source\r\n-   **TensorFlow version (use command below)**: 2.3.0 also tested in 2.4.1 \r\n-   **Python version**: 3.6.9\r\n\r\n### Describe the problem\r\nUsing a custom model with named outputs doesn't work when defining seperate metrics per output\r\nThere was already a bug for which dict outputs did not work here: [#34199\r\n](https://github.com/tensorflow/tensorflow/issues/34199) but this was closed due to it being resolved apparently\r\n\r\n### Describe the expected behavior\r\nWhen using a list or tuple everything works fine but when using a dictionary as outputs it fails. Would expect it to work the same as when using a list or tuple\r\n\r\n### Source code / logs\r\nThis code is based on the [this example](https://towardsdatascience.com/building-a-multi-output-convolutional-neural-network-with-keras-ed24c7bc1178) on how to make a multi-output network\r\n\r\n```\r\nfrom tensorflow.keras.models import Model\r\nfrom tensorflow.keras.layers import BatchNormalization\r\nfrom tensorflow.keras.layers import Conv2D\r\nfrom tensorflow.keras.layers import MaxPooling2D\r\nfrom tensorflow.keras.layers import Activation\r\nfrom tensorflow.keras.layers import Dropout\r\nfrom tensorflow.keras.layers import Lambda\r\nfrom tensorflow.keras.layers import Dense\r\nfrom tensorflow.keras.layers import Flatten\r\nfrom tensorflow.keras.layers import Input\r\nimport tensorflow as tf\r\n\r\nclass UtkMultiOutputModel():\r\n    def make_default_hidden_layers(self, inputs):\r\n        x = Conv2D(16, (3, 3), padding=\"same\")(inputs)\r\n        x = Activation(\"relu\")(x)\r\n        x = BatchNormalization(axis=-1)(x)\r\n        x = MaxPooling2D(pool_size=(3, 3))(x)\r\n        x = Dropout(0.25)(x)\r\n        x = Conv2D(32, (3, 3), padding=\"same\")(x)\r\n        x = Activation(\"relu\")(x)\r\n        x = BatchNormalization(axis=-1)(x)\r\n        x = MaxPooling2D(pool_size=(2, 2))(x)\r\n        x = Dropout(0.25)(x)\r\n        x = Conv2D(32, (3, 3), padding=\"same\")(x)\r\n        x = Activation(\"relu\")(x)\r\n        x = BatchNormalization(axis=-1)(x)\r\n        x = MaxPooling2D(pool_size=(2, 2))(x)\r\n        x = Dropout(0.25)(x)\r\n        return x\r\n\r\n    def build_race_branch(self, inputs, num_races):\r\n        x = self.make_default_hidden_layers(inputs)\r\n        x = Flatten()(x)\r\n        x = Dense(128)(x)\r\n        x = Activation(\"relu\")(x)\r\n        x = BatchNormalization()(x)\r\n        x = Dropout(0.5)(x)\r\n        x = Dense(num_races)(x)\r\n        x = Activation(\"softmax\", name=\"race_output\")(x)\r\n        return x\r\n\r\n    def build_gender_branch(self, inputs, num_genders=2):\r\n        x = Lambda(lambda c: tf.image.rgb_to_grayscale(c))(inputs)\r\n        x = self.make_default_hidden_layers(inputs)\r\n        x = Flatten()(x)\r\n        x = Dense(128)(x)\r\n        x = Activation(\"relu\")(x)\r\n        x = BatchNormalization()(x)\r\n        x = Dropout(0.5)(x)\r\n        x = Dense(num_genders)(x)\r\n        x = Activation(\"sigmoid\", name=\"gender_output\")(x)\r\n        return x\r\n\r\n    def build_age_branch(self, inputs):   \r\n        x = self.make_default_hidden_layers(inputs)\r\n        x = Flatten()(x)\r\n        x = Dense(128)(x)\r\n        x = Activation(\"relu\")(x)\r\n        x = BatchNormalization()(x)\r\n        x = Dropout(0.5)(x)\r\n        x = Dense(1)(x)\r\n        x = Activation(\"linear\", name=\"age_output\")(x)\r\n        return x\r\n\r\n    def assemble_full_model(self, width, height, num_races):\r\n        input_shape = (height, width, 3)\r\n        inputs = Input(shape=input_shape)\r\n        age_branch = self.build_age_branch(inputs)\r\n        race_branch = self.build_race_branch(inputs, num_races)\r\n        gender_branch = self.build_gender_branch(inputs)\r\n        model = Model(inputs=inputs,\r\n                     outputs = {'A' : age_branch, 'B' : race_branch, 'C' : gender_branch},\r\n                     name=\"face_net\")\r\n        return model\r\n    \r\nmodel = UtkMultiOutputModel().assemble_full_model(IM_WIDTH, IM_HEIGHT, num_races=len(dataset_dict['race_alias']))\r\n\r\nmodel.compile(optimizer=opt, \r\n              loss={\r\n                  'age_output': 'mse', \r\n                  'race_output': 'categorical_crossentropy', \r\n                  'gender_output': 'binary_crossentropy'},\r\n              loss_weights={\r\n                  'age_output': 4., \r\n                  'race_output': 1.5, \r\n                  'gender_output': 0.1},\r\n\r\n              # this will not work when outputs is a dict, but will work when outputs is a list or tuple\r\n              metrics={\r\n                  'age_output': ['mae', 'accuracy'], \r\n                  'race_output': ['accuracy', 'mae'],\r\n                  'gender_output': ['accuracy', 'mae']})\r\n\r\n             # this will work with a dict, list and tuple but is not what I want\r\n             # metrics=['accuracy']\r\n\r\nhistory = model.fit_generator(train_gen,\r\n                    steps_per_epoch=len(train_idx)//batch_size,\r\n                    epochs=epochs,\r\n                    validation_data=valid_gen,\r\n                    validation_steps=len(valid_idx)//valid_batch_size)\r\n```\r\n\r\nThis is the traceback from the above code:\r\n```\r\nEpoch 1/4\r\nWARNING:tensorflow:Gradients do not exist for variables ['conv2d_15/kernel:0', 'conv2d_15/bias:0', 'batch_normalization_20/gamma:0', 'batch_normalization_20/beta:0', 'conv2d_16/kernel:0', 'conv2d_16/bias:0', 'batch_normalization_21/gamma:0', 'batch_normalization_21/beta:0', 'conv2d_17/kernel:0', 'conv2d_17/bias:0', 'batch_normalization_22/gamma:0', 'batch_normalization_22/beta:0', 'dense_10/kernel:0', 'dense_10/bias:0', 'batch_normalization_23/gamma:0', 'batch_normalization_23/beta:0', 'dense_11/kernel:0', 'dense_11/bias:0'] when minimizing the loss.\r\nWARNING:tensorflow:Gradients do not exist for variables ['conv2d_15/kernel:0', 'conv2d_15/bias:0', 'batch_normalization_20/gamma:0', 'batch_normalization_20/beta:0', 'conv2d_16/kernel:0', 'conv2d_16/bias:0', 'batch_normalization_21/gamma:0', 'batch_normalization_21/beta:0', 'conv2d_17/kernel:0', 'conv2d_17/bias:0', 'batch_normalization_22/gamma:0', 'batch_normalization_22/beta:0', 'dense_10/kernel:0', 'dense_10/bias:0', 'batch_normalization_23/gamma:0', 'batch_normalization_23/beta:0', 'dense_11/kernel:0', 'dense_11/bias:0'] when minimizing the loss.\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-12-a8fc86d7fb42> in <module>\r\n     21                     callbacks=[checkpoint_cb, tensorboard_cb],\r\n     22                     validation_data=valid_gen,\r\n---> 23                     validation_steps=len(valid_idx)//valid_batch_size)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)\r\n    322               'in a future version' if date is None else ('after %s' % date),\r\n    323               instructions)\r\n--> 324       return func(*args, **kwargs)\r\n    325     return tf_decorator.make_decorator(\r\n    326         func, new_func, 'deprecated',\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\r\n   1827         use_multiprocessing=use_multiprocessing,\r\n   1828         shuffle=shuffle,\r\n-> 1829         initial_epoch=initial_epoch)\r\n   1830 \r\n   1831   @deprecation.deprecated(\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in _method_wrapper(self, *args, **kwargs)\r\n    106   def _method_wrapper(self, *args, **kwargs):\r\n    107     if not self._in_multi_worker_mode():  # pylint: disable=protected-access\r\n--> 108       return method(self, *args, **kwargs)\r\n    109 \r\n    110     # Running inside `run_distribute_coordinator` already.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\r\n   1096                 batch_size=batch_size):\r\n   1097               callbacks.on_train_batch_begin(step)\r\n-> 1098               tmp_logs = train_function(iterator)\r\n   1099               if data_handler.should_sync:\r\n   1100                 context.async_wait()\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    778       else:\r\n    779         compiler = \"nonXla\"\r\n--> 780         result = self._call(*args, **kwds)\r\n    781 \r\n    782       new_tracing_count = self._get_tracing_count()\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    821       # This is the first call of __call__, so we have to initialize.\r\n    822       initializers = []\r\n--> 823       self._initialize(args, kwds, add_initializers_to=initializers)\r\n    824     finally:\r\n    825       # At this point we know that the initialization is complete (or less\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)\r\n    695     self._concrete_stateful_fn = (\r\n    696         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n--> 697             *args, **kwds))\r\n    698 \r\n    699     def invalid_creator_scope(*unused_args, **unused_kwds):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)\r\n   2853       args, kwargs = None, None\r\n   2854     with self._lock:\r\n-> 2855       graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n   2856     return graph_function\r\n   2857 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n   3211 \r\n   3212       self._function_cache.missed.add(call_context_key)\r\n-> 3213       graph_function = self._create_graph_function(args, kwargs)\r\n   3214       self._function_cache.primary[cache_key] = graph_function\r\n   3215       return graph_function, args, kwargs\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   3073             arg_names=arg_names,\r\n   3074             override_flat_arg_shapes=override_flat_arg_shapes,\r\n-> 3075             capture_by_value=self._capture_by_value),\r\n   3076         self._function_attributes,\r\n   3077         function_spec=self.function_spec,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    984         _, original_func = tf_decorator.unwrap(python_func)\r\n    985 \r\n--> 986       func_outputs = python_func(*func_args, **func_kwargs)\r\n    987 \r\n    988       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)\r\n    598         # __wrapped__ allows AutoGraph to swap in a converted function. We give\r\n    599         # the function a weak reference to itself to avoid a reference cycle.\r\n--> 600         return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    601     weak_wrapped_fn = weakref.ref(wrapped_fn)\r\n    602 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)\r\n    971           except Exception as e:  # pylint:disable=broad-except\r\n    972             if hasattr(e, \"ag_error_metadata\"):\r\n--> 973               raise e.ag_error_metadata.to_exception(e)\r\n    974             else:\r\n    975               raise\r\n\r\nValueError: in user code:\r\n\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:806 train_function  *\r\n        return step_function(self, iterator)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:796 step_function  **\r\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1211 run\r\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2585 call_for_each_replica\r\n        return self._call_for_each_replica(fn, args, kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2945 _call_for_each_replica\r\n        return fn(*args, **kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:789 run_step  **\r\n        outputs = model.train_step(data)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:759 train_step\r\n        self.compiled_metrics.update_state(y, y_pred, sample_weight)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:388 update_state\r\n        self.build(y_pred, y_true)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/compile_utils.py:319 build\r\n        self._metrics, y_true, y_pred)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py:1139 map_structure_up_to\r\n        **kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py:1221 map_structure_with_tuple_paths_up_to\r\n        expand_composites=expand_composites)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py:854 assert_shallow_structure\r\n        input_length=len(input_tree), shallow_length=len(shallow_tree)))\r\n\r\n    ValueError: The two structures don't have the same sequence length. Input structure has length 6, while shallow structure has length 3.\r\n```\r\n", "comments": ["@WoutRuyters,\r\nOn running the code, I am facing an error stating `NameError: name 'IM_WIDTH' is not defined`. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/99151bef74c69eb29c330212a5e63113/48038.ipynb).\r\n\r\nIn order to expedite the trouble-shooting process, could you please provide a minimal code snippet to reproduce the issue reported here and also the dataset you are using. Thanks! ", "@amahendrakar \r\nThe dataset I am using can be found on [this google drive](https://drive.google.com/drive/folders/0BxYys69jI14kU0I1YUQyY1ZDRUE) and is calledUTKface.tar.gz, you will have to unzip this first\r\n\r\nthe full code to run everything is as follows:\r\n```\r\nimport numpy as np \r\nimport pandas as pd\r\nimport os\r\nimport glob\r\nimport pandas as pd\r\nimport matplotlib.pyplot as plt\r\n\r\ndataset_folder_name = '/data/UTKFace'\r\n\r\nTRAIN_TEST_SPLIT = 0.7\r\nIM_WIDTH = IM_HEIGHT = 198\r\ndataset_dict = {\r\n    'race_id': {\r\n        0: 'white', \r\n        1: 'black', \r\n        2: 'asian', \r\n        3: 'indian', \r\n        4: 'others'\r\n    },\r\n    'gender_id': {\r\n        0: 'male',\r\n        1: 'female'\r\n    }\r\n}\r\ndataset_dict['gender_alias'] = dict((g, i) for i, g in dataset_dict['gender_id'].items())\r\ndataset_dict['race_alias'] = dict((r, i) for i, r in dataset_dict['race_id'].items())\r\n```\r\n\r\nto parse the dataset:\r\n```\r\ndef parse_dataset(dataset_path, ext='jpg'):\r\n    \"\"\"\r\n    Used to extract information about our dataset. It does iterate over all images and return a DataFrame with\r\n    the data (age, gender and sex) of all files.\r\n    \"\"\"\r\n    def parse_info_from_file(path):\r\n        \"\"\"\r\n        Parse information from a single file\r\n        \"\"\"\r\n        try:\r\n            filename = os.path.split(path)[1]\r\n            filename = os.path.splitext(filename)[0]\r\n            age, gender, race, _ = filename.split('_')\r\n            return int(age), dataset_dict['gender_id'][int(gender)], dataset_dict['race_id'][int(race)]\r\n        except Exception as ex:\r\n            return None, None, None\r\n        \r\n    files = glob.glob(os.path.join(dataset_path, \"*.%s\" % ext))\r\n    \r\n    records = []\r\n    for file in files:\r\n        info = parse_info_from_file(file)\r\n        records.append(info)\r\n        \r\n    df = pd.DataFrame(records)\r\n    df['file'] = files\r\n    df.columns = ['age', 'gender', 'race', 'file']\r\n    df = df.dropna()\r\n    \r\n    return df\r\ndf = parse_dataset(dataset_folder_name)\r\ndf.head()\r\n```\r\n\r\nto generate data:\r\n```\r\nfrom tensorflow.keras.utils import to_categorical\r\nfrom PIL import Image\r\nclass UtkFaceDataGenerator():\r\n    \"\"\"\r\n    Data generator for the UTKFace dataset. This class should be used when training our Keras multi-output model.\r\n    \"\"\"\r\n    def __init__(self, df):\r\n        self.df = df\r\n        \r\n    def generate_split_indexes(self):\r\n        p = np.random.permutation(len(self.df))\r\n        train_up_to = int(len(self.df) * TRAIN_TEST_SPLIT)\r\n        train_idx = p[:train_up_to]\r\n        test_idx = p[train_up_to:]\r\n        train_up_to = int(train_up_to * TRAIN_TEST_SPLIT)\r\n        train_idx, valid_idx = train_idx[:train_up_to], train_idx[train_up_to:]\r\n        \r\n        # converts alias to id\r\n        self.df['gender_id'] = self.df['gender'].map(lambda gender: dataset_dict['gender_alias'][gender])\r\n        self.df['race_id'] = self.df['race'].map(lambda race: dataset_dict['race_alias'][race])\r\n        self.max_age = self.df['age'].max()\r\n        \r\n        return train_idx, valid_idx, test_idx\r\n    \r\n    def preprocess_image(self, img_path):\r\n        \"\"\"\r\n        Used to perform some minor preprocessing on the image before inputting into the network.\r\n        \"\"\"\r\n        im = Image.open(img_path)\r\n        im = im.resize((IM_WIDTH, IM_HEIGHT))\r\n        im = np.array(im) / 255.0\r\n        \r\n        return im\r\n        \r\n    def generate_images(self, image_idx, is_training, batch_size=16):\r\n        \"\"\"\r\n        Used to generate a batch with images when training/testing/validating our Keras model.\r\n        \"\"\"\r\n        \r\n        # arrays to store our batched data\r\n        images, ages, races, genders = [], [], [], []\r\n        while True:\r\n            for idx in image_idx:\r\n                person = self.df.iloc[idx]\r\n                \r\n                age = person['age']\r\n                race = person['race_id']\r\n                gender = person['gender_id']\r\n                file = person['file']\r\n                \r\n                im = self.preprocess_image(file)\r\n                \r\n                ages.append(age / self.max_age)\r\n                races.append(to_categorical(race, len(dataset_dict['race_id'])))\r\n                genders.append(to_categorical(gender, len(dataset_dict['gender_id'])))\r\n                images.append(im)\r\n                \r\n                # yielding condition\r\n                if len(images) >= batch_size:\r\n                    yield np.array(images), [np.array(ages), np.array(races), np.array(genders)]\r\n                    images, ages, races, genders = [], [], [], []\r\n                    \r\n            if not is_training:\r\n                break\r\n                \r\ndata_generator = UtkFaceDataGenerator(df)\r\ntrain_idx, valid_idx, test_idx = data_generator.generate_split_indexes() \r\n```\r\n\r\nto build the model:\r\n```\r\nfrom tensorflow.keras.models import Model\r\nfrom tensorflow.keras.layers import BatchNormalization\r\nfrom tensorflow.keras.layers import Conv2D\r\nfrom tensorflow.keras.layers import MaxPooling2D\r\nfrom tensorflow.keras.layers import Activation\r\nfrom tensorflow.keras.layers import Dropout\r\nfrom tensorflow.keras.layers import Lambda\r\nfrom tensorflow.keras.layers import Dense\r\nfrom tensorflow.keras.layers import Flatten\r\nfrom tensorflow.keras.layers import Input\r\nimport tensorflow as tf\r\nclass UtkMultiOutputModel():\r\n    \"\"\"\r\n    Used to generate our multi-output model. This CNN contains three branches, one for age, other for \r\n    sex and another for race. Each branch contains a sequence of Convolutional Layers that is defined\r\n    on the make_default_hidden_layers method.\r\n    \"\"\"\r\n    def make_default_hidden_layers(self, inputs):\r\n        \"\"\"\r\n        Used to generate a default set of hidden layers. The structure used in this network is defined as:\r\n        \r\n        Conv2D -> BatchNormalization -> Pooling -> Dropout\r\n        \"\"\"\r\n        x = Conv2D(16, (3, 3), padding=\"same\")(inputs)\r\n        x = Activation(\"relu\")(x)\r\n        x = BatchNormalization(axis=-1)(x)\r\n        x = MaxPooling2D(pool_size=(3, 3))(x)\r\n        x = Dropout(0.25)(x)\r\n        x = Conv2D(32, (3, 3), padding=\"same\")(x)\r\n        x = Activation(\"relu\")(x)\r\n        x = BatchNormalization(axis=-1)(x)\r\n        x = MaxPooling2D(pool_size=(2, 2))(x)\r\n        x = Dropout(0.25)(x)\r\n        x = Conv2D(32, (3, 3), padding=\"same\")(x)\r\n        x = Activation(\"relu\")(x)\r\n        x = BatchNormalization(axis=-1)(x)\r\n        x = MaxPooling2D(pool_size=(2, 2))(x)\r\n        x = Dropout(0.25)(x)\r\n        return x\r\n    def build_race_branch(self, inputs, num_races):\r\n        \"\"\"\r\n        Used to build the race branch of our face recognition network.\r\n        This branch is composed of three Conv -> BN -> Pool -> Dropout blocks, \r\n        followed by the Dense output layer.\r\n        \"\"\"\r\n        x = self.make_default_hidden_layers(inputs)\r\n        x = Flatten()(x)\r\n        x = Dense(128)(x)\r\n        x = Activation(\"relu\")(x)\r\n        x = BatchNormalization()(x)\r\n        x = Dropout(0.5)(x)\r\n        x = Dense(num_races)(x)\r\n        x = Activation(\"softmax\", name=\"race_output\")(x)\r\n        return x\r\n    def build_gender_branch(self, inputs, num_genders=2):\r\n        \"\"\"\r\n        Used to build the gender branch of our face recognition network.\r\n        This branch is composed of three Conv -> BN -> Pool -> Dropout blocks, \r\n        followed by the Dense output layer.\r\n        \"\"\"\r\n        x = Lambda(lambda c: tf.image.rgb_to_grayscale(c))(inputs)\r\n        x = self.make_default_hidden_layers(inputs)\r\n        x = Flatten()(x)\r\n        x = Dense(128)(x)\r\n        x = Activation(\"relu\")(x)\r\n        x = BatchNormalization()(x)\r\n        x = Dropout(0.5)(x)\r\n        x = Dense(num_genders)(x)\r\n        x = Activation(\"sigmoid\", name=\"gender_output\")(x)\r\n        return x\r\n    def build_age_branch(self, inputs):   \r\n        \"\"\"\r\n        Used to build the age branch of our face recognition network.\r\n        This branch is composed of three Conv -> BN -> Pool -> Dropout blocks, \r\n        followed by the Dense output layer.\r\n        \"\"\"\r\n        x = self.make_default_hidden_layers(inputs)\r\n        x = Flatten()(x)\r\n        x = Dense(128)(x)\r\n        x = Activation(\"relu\")(x)\r\n        x = BatchNormalization()(x)\r\n        x = Dropout(0.5)(x)\r\n        x = Dense(1)(x)\r\n        x = Activation(\"linear\", name=\"age_output\")(x)\r\n        return x\r\n    def assemble_full_model(self, width, height, num_races):\r\n        \"\"\"\r\n        Used to assemble our multi-output model CNN.\r\n        \"\"\"\r\n        input_shape = (height, width, 3)\r\n        inputs = Input(shape=input_shape)\r\n        age_branch = self.build_age_branch(inputs)\r\n        race_branch = self.build_race_branch(inputs, num_races)\r\n        gender_branch = self.build_gender_branch(inputs)\r\n        model = Model(inputs=inputs,\r\n                     outputs = {'A' : age_branch, 'B' : race_branch, 'C' : gender_branch},\r\n                     name=\"face_net\")\r\n        return model\r\n    \r\nmodel = UtkMultiOutputModel().assemble_full_model(IM_WIDTH, IM_HEIGHT, num_races=len(dataset_dict['race_alias']))\r\n```\r\n\r\nto compile the model:\r\n```\r\nfrom tensorflow.keras.optimizers import Adam\r\ninit_lr = 1e-4\r\nepochs = 4\r\nopt = Adam(lr=init_lr, decay=init_lr / epochs)\r\nmodel.compile(optimizer=opt, \r\n              loss={\r\n                  'age_output': 'mse', \r\n                  'race_output': 'categorical_crossentropy', \r\n                  'gender_output': 'binary_crossentropy'},\r\n              loss_weights={\r\n                  'age_output': 4., \r\n                  'race_output': 1.5, \r\n                  'gender_output': 0.1},\r\n              metrics={\r\n                  'age_output': ['mae', 'accuracy'], \r\n                  'race_output': ['accuracy', 'mae'],\r\n                  'gender_output': ['accuracy', 'mae']})\r\n \r\n             #metrics = ['accuracy'] will work but this is not the goal I want to say per output what metrics I want\r\n```\r\n\r\nto train the model:\r\n```\r\nfrom tensorflow.keras.callbacks import ModelCheckpoint\r\nbatch_size = 32\r\nvalid_batch_size = 32\r\ntrain_gen = data_generator.generate_images(train_idx, is_training=True, batch_size=batch_size)\r\nvalid_gen = data_generator.generate_images(valid_idx, is_training=True, batch_size=valid_batch_size)\r\n\r\ncheckpoint_cb = tf.keras.callbacks.ModelCheckpoint('/git/research-manifest/ads_ml/data/tf2/experiment1/checkpoints/cp-{epoch:04d}.ckpt',\r\n                                        save_best_only=True,\r\n                                        save_weights_only=True\r\n)\r\n\r\ntensorboard_cb = tf.keras.callbacks.TensorBoard('/git/research-manifest/ads_ml/data/tf2/experiment1/checkpoints/logs',\r\n                                    histogram_freq=1,\r\n                                    write_graph=True,\r\n                                    update_freq='epoch',\r\n                                    profile_batch=0)\r\n\r\nhistory = model.fit_generator(train_gen,\r\n                    steps_per_epoch=len(train_idx)//batch_size,\r\n                    epochs=epochs,\r\n                    callbacks=[checkpoint_cb, tensorboard_cb],\r\n                    validation_data=valid_gen,\r\n                    validation_steps=len(valid_idx)//valid_batch_size)\r\n```\r\n\r\n\r\n", "@WoutRuyters,\r\nOn running the above code, I am facing a different error stating `ValueError: No gradients provided for any variable`. \r\n\r\nPlease find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/a2ba4e4690bde13706c6a7d926dc70d5/48038.ipynb#scrollTo=dRebaTQg2v5K). Thanks!", "Hi @amahendrakar,\r\nI can't find why your code keeps giving an error. I made a notebook in colab with working code which results in the error that I stated when opening this issue, you can find it [here](https://colab.research.google.com/drive/1t2Sd2KMO-2gP6bSQP7mBl5P0Xu28__-d?usp=sharing). Thanks!", "@WoutRuyters,\r\nThank you for the Colab gist.\r\n\r\n@jvishnuvardhan,\r\nI was able to reproduce the issue with TF v2.4, TF v2.5.0rc0 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/482cb9cb6ead22fec60998d28bd39ce2/48038.ipynb). Thanks!", "@WoutRuyters Named dictionary output actually work but the keys should match. I updated your code with dictionary inputs as shown below.\r\n\r\nReplaced the following line\r\n`outputs = {'steve' : age_branch, 'bob' : race_branch, 'joost' : gender_branch},`\r\nwith this line\r\n` outputs = {'age_output' : age_branch, 'race_output' : race_branch, 'gender_output' : gender_branch},`\r\n         \r\n\r\nI also updated one line in `generate_images ` method as shown below to output a dictionary\r\n\r\nReplaced the following line\r\n`yield np.array(images), [np.array(ages), np.array(races), np.array(genders)]\r\n`\r\nwith this line\r\n` yield np.array(images), {'age_output':np.array(ages), 'race_output': np.array(races), 'gender_output':np.array(genders)}\r\n`\r\n\r\nPlease check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/2d78652f8bc5e7d1ed01c7aadbf929dd/48038.ipynb). \r\n\r\nPlease verify once and close the issue if this was resolved for you. Thanks!\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@jvishnuvardhan Sorry for the late reply!\r\nThis has solved my problem and thus the issue can be closed, thank you for your help and time!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48038\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48038\">No</a>\n"]}, {"number": 48037, "title": "How to use Allgather, Allreduce", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n", "comments": ["@chenxinhua \r\n\r\nKindly open a [stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow) issue for this as it is not a bug or feature request, Please post this kind of support questions at Stackoverflow. There is a big community to support and learn from your questions.\r\nThanks!\r\nYou may refer to:\r\n[link](https://github.com/horovod/horovod/issues/679), [link1](https://towardsdatascience.com/a-quick-guide-to-distributed-training-with-tensorflow-and-horovod-on-amazon-sagemaker-dae18371ef6e)", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 48035, "title": "[INTEL MKL] Updated the DNNL version from v2.1 to v2.2 release candidate", "body": "", "comments": ["@penpornk , this is the TensorFlow 2.5 targeted DNNL version. please review. Thanks a lot!", "The oneDNN CI Build [failed](https://tensorflow-ci.intel.com/job/tensorflow-mkl-linux-cpu-pr/8624/). Is this expected?", "> The oneDNN CI Build [failed](https://tensorflow-ci.intel.com/job/tensorflow-mkl-linux-cpu-pr/8624/). Is this expected?\r\n\r\n@penpornk It is failing a bf16 remapper test that I don't see in our internal tests.  We will try to reproduce. \r\nI would recommend you go ahead and merge, we will submit a patch if we can reproduce.  Thanks.", "@agramesh1 Got it. I'll merge this if other tests pass. Thank you for the quick reply!", "@penpornk , regard to the build error found in the Ubuntu CPU CI test, we couldn't reproduce it in our local machine or our internal testing machine. This could be another similar issues we had before. probably we only need to add the following lines in the third_party/mkl_dnn/mkldnn_v1.BUILD to fix it?\r\n\r\n```\r\na/third_party/mkl_dnn/mkldnn_v1.BUILD\r\n+++ \r\nb/third_party/mkl_dnn/mkldnn_v1.BUILD\r\n@@ -93,6 +93,7 @@ _TEXTUAL_HDRS_LIST = glob([\r\n\"include/**/*\",\r\n\"src/common/*.hpp\",\r\n\"src/common/ittnotify/*.h\",\r\n+ \"src/common/ittnotify/legacy/*.h\",\r\n\"src/cpu/*.hpp\",\r\n\"src/cpu/**/*.hpp\",\r\n```", "@cuixiaom Thank you for the suggestion! I've already fixed it internally with a similar fix (changing `\"src/common/ittnotify/*.h\",` to `\"src/common/ittnotify/**/*.h\",`).", "Dear @penpornk and @vpirogov, may you please comment: there is another update planned to add oneDNN v2.2 release, correct? Currently the sources for `mkl_dnn_v1` have been updated to https://github.com/oneapi-src/oneDNN/archive/3d1e248f293cb962eb73bfc1298a0c66a3ad3298.tar.gz, but it seems to be not the final v2.2 release, right?", "Hi @alenik01, TF 2.5 will likely use this commit (unless there are some patches needed). For the master branch, I think we will update to the final v2.2 release once they are out. Cc'ing @agramesh1 for more info.", "@penpornk @alenik01 there was a fix made after this commit, and we expect that it will tagged v2.2.  So looks like we will have a patch for upgrading to the tagged branch.", "@agramesh1 @penpornk, many thanks for the clarification.", "@alenik01 The update to v2.2 went into master yesterday (#48248). We are cherry-picking the update into TF 2.5 (#48345).", "@penpornk, thanks for pointing this out, I will update `mkl_dnn_acl_compatible` accordingly.", "@alenik01 Thank you! Do you think we can go back to using the same repository now that the branch cut is done? ", "@penpornk, we, unfortunately, have some problems with compiling JIT'ed sources (currently they are excluded in Bazel for our repository build).", "@alenik01 Using the [mkl_dnn_v1](https://github.com/tensorflow/tensorflow/blob/74f6ab85bcec784e58d81998cdc420466a472f71/tensorflow/workspace2.bzl#L182-L183) repository will only force you to use the same [BUILD file](https://github.com/tensorflow/tensorflow/blob/master/third_party/mkl_dnn/mkldnn_v1.BUILD). You can still use a different build target (like [how it was before the ACL PR](https://github.com/tensorflow/tensorflow/blob/1bcd2dadc6627be30c83022d30343c8251b9f2d2/third_party/mkl_dnn/mkldnn_v1.BUILD#L139-L170)) and exclude the x64 sources.", "@penpornk, having the same BUILD file with different targets is indeed possible. May you please comment, will `mkl_dnn_v1` repository be updated in terms of oneDNN version from time to time? E.g., v2.3 release is scheduled for the end of June.", "@alenik01 Yes, the [mkl_dnn_v1](https://github.com/tensorflow/tensorflow/blob/74f6ab85bcec784e58d81998cdc420466a472f71/tensorflow/workspace2.bzl#L182-L183) repository is updated from time to time by the @TensorFlow-MKL team. (But not necessarily every minor release, for example, from v1.6.4, we skipped v1.7-v1.8 and upgraded to v2.1.) cc: @agramesh1\r\n\r\nIf in the future you need to use a different oneDNN version from `mkl_dnn_v1` or need a different update schedule, we can create a separate repo again. :)\r\n\r\n", "@alenik01 @penpornk we don't have any specific schedule for updating oneDNN, we do skip revs if there is no need to upgrade.", "@penpornk @agramesh1 Many thanks for the explanation. The point is that if a new functionality will be added to oneDNN v2.3 we would like to update the repository, thus I suggest to keep separate BUILD files and repositories for some time.", "@alenik01 Sounds good to me. Thank you for the clarification!"]}, {"number": 48034, "title": "Installing tensorflow nightly", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- windows 10:\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip install tf-nightly\r\n\r\n- TensorFlow version:2.5.0\r\n- Python version:3.9\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: 6 gb ram and gt710\r\n\r\n\r\n\r\n**Describe the problem**\r\nit just threw a lot of exception errors , i'm 17 y/o noobie, really aint into this .....\r\ntotal noobie\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 171, in _merge_into_criterion\r\n    crit = self.state.criteria[name]\r\nKeyError: 'tf-nightly-gpu'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 438, in _error_catcher        \r\n    yield\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 519, in read\r\n    data = self._fp.read(amt) if not fp_closed else b\"\"\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\cachecontrol\\filewrapper.py\", line 62, in read\r\n    data = self.__fp.read(amt)\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\http\\client.py\", line 458, in read\r\n    n = self.readinto(b)\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\http\\client.py\", line 502, in readinto\r\n    n = self.fp.readinto(b)\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\socket.py\", line 704, in readinto\r\n    return self._sock.recv_into(b)\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\ssl.py\", line 1241, in recv_into\r\n    return self.read(nbytes, buffer)\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\ssl.py\", line 1099, in read\r\n    return self._sslobj.read(len, buffer)\r\nsocket.timeout: The read operation timed out\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\cli\\base_command.py\", line 189, in _main\r\n    status = self.run(options, args)\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\cli\\req_command.py\", line 178, in wrapper\r\n    return func(self, options, args)\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\commands\\install.py\", line 316, in run\r\n    requirement_set = resolver.resolve(\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\resolver.py\", line 121, in resolve\r\n    self._result = resolver.resolve(\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 453, in resolve\r\n    state = resolution.resolve(requirements, max_rounds=max_rounds)\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 318, in resolve\r\n    name, crit = self._merge_into_criterion(r, parent=None)\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 173, in _merge_into_criterion\r\n    crit = Criterion.from_requirement(self._p, requirement, parent)\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\resolvelib\\resolvers.py\", line 82, in from_requirement   \r\n    if not cands:\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\resolvelib\\structs.py\", line 124, in __bool__\r\n    return bool(self._sequence)\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 143, in __bool__\r\n    return any(self)\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\found_candidates.py\", line 38, in _iter_built\r\n    candidate = func()\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\factory.py\", line 167, in _make_candidate_from_link\r\n    self._link_candidate_cache[link] = LinkCandidate(\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 300, in __in    super().__init__(\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 144, in __init__\r\n    self.dist = self._prepare()\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 226, in _pre    dist = self._prepare_distribution()\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\resolution\\resolvelib\\candidates.py\", line 311, in _prepare_distribution\r\n    return self._factory.preparer.prepare_linked_requirement(\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 457, in prepare_linked_requirement\r\n    return self._prepare_linked_requirement(req, parallel_builds)\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 480, in _prepare_linked_re    local_file = unpack_url(\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 230, in unpack_url        \r\n    file = get_http_url(\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\operations\\prepare.py\", line 108, in get_http_url      \r\n    from_path, content_type = download(link, temp_dir.path)\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\network\\download.py\", line 163, in __call__\r\n    for chunk in chunks:\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\cli\\progress_bars.py\", line 159, in iter\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_internal\\network\\utils.py\", line 64, in response_chunks\r\n    for chunk in response.raw.stream(\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 576, in stream\r\n    data = self.read(amt=amt, decode_content=decode_content)\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 541, in read\r\n    raise IncompleteRead(self._fp_bytes_read, self.length_remaining)\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\contextlib.py\", line 135, in __exit__\r\n  File \"c:\\users\\ts\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\pip\\_vendor\\urllib3\\response.py\", line 443, in _error_catcher        \r\n    raise ReadTimeoutError(self._pool, None, \"Read timed out.\")\r\npip._vendor.urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Read timed out.\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@ideepankarsharma2003,\r\nCould you please check if you are facing the same issue with other Python packages like `numpy` and `pandas` as well?\r\n\r\nAlternatively to install the TensorFlow package, you can download the `.whl` file for Windows 10 and Python 3.9 from [this link](https://pypi.org/project/tf-nightly/2.5.0.dev20210323/#files) and install it offline.\r\n\r\nThanks!", "I don't have a GPU though , I think", "> @ideepankarsharma2003,\n> Could you please check if you are facing the same issue with other Python packages like `numpy` and `pandas` as well?\n> \n> Alternatively to install the TensorFlow package, you can download the `.whl` file for Windows 10 and Python 3.9 from [this link](https://pypi.org/project/tf-nightly/2.5.0.dev20210323/#files) and install it offline.\n> \n> Thanks!\n\nThanks I'll see if it works", "It looks like a timeout issue.\r\n\r\nCan you try `pip install tf-nightly-cpu`?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "It's done thanks guys", "@ideepankarsharma2003,\r\nThank you for the update. \r\n\r\nClosing this issue as it is resolved. Please feel free to re-open if necessary.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48034\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48034\">No</a>\n"]}, {"number": 48033, "title": "tf2.4.0 and 2.4.1 keras history.history is different from each epoch end ", "body": "i run the code on colab\r\nthe code is :[https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/zh-cn/guide/keras/train_and_evaluate.ipynb?hl=zh_CN#scrollTo=mGYBLPAR13g3](url)\r\n\r\n\r\n**and below is epcoh end** \r\n\r\nFit model on training data\r\nEpoch 1/2\r\n782/782 [==============================] - 3s 3ms/step - loss: 0.5712 - sparse_categorical_accuracy: 0.8411 - val_loss: 0.2025 - val_sparse_categorical_accuracy: 0.9416\r\nEpoch 2/2\r\n782/782 [==============================] - 2s 3ms/step - loss: 0.1734 - sparse_categorical_accuracy: 0.9493 - val_loss: 0.1453 - val_sparse_categorical_accuracy: 0.9571\r\n\r\n**and keras history.history below**\r\n\r\n{'loss': [0.33999016880989075, 0.16297979652881622],\r\n 'sparse_categorical_accuracy': [0.9027799963951111, 0.9526399970054626],\r\n 'val_loss': [0.20245662331581116, 0.14533831179141998],\r\n 'val_sparse_categorical_accuracy': [0.9416000247001648, 0.957099974155426]}\r\n\r\n**i find the two is different.\r\nfor example train sparse_categorical_accuracy of epoch 1 is 0.8411 but in history.history is 0.9027799963951111.**\r\n\r\n**but when i set verbose=2 in model.fit have no this problem**\r\n\r\n\r\n**i try tf 2.3.2 and other low version have no question\u3002**\r\n\r\n**what changes in tf2.4.0 \u3002i could not find the change log in \uff1ahttps://github.com/tensorflow/tensorflow/blob/master/RELEASE.md**\r\n\r\n\r\n\r\n", "comments": ["Hi, I have the same issue, and I reported it in this related bug report:\r\nhttps://github.com/tensorflow/tensorflow/issues/46713", "@zhaoyun0071 \r\nThe code provided is fairly complex hence it would be difficult for us to pinpoint the issue. Could you please get the example down to the simplest possible repro? That will allow us to determine the source of the issue easily. Thanks!\r\n", "> @zhaoyun0071\u6240\u63d0\u4f9b\u7684\u4ee3\u7801\u76f8\u5f53\u590d\u6742\uff0c\u56e0\u6b64\u6211\u4eec\u5f88\u96be\u786e\u5b9a\u95ee\u9898\u3002\r\n> \u4f60\u80fd\u628a\u4f8b\u5b50\u5f52\u7ed3\u4e3a\u6700\u7b80\u5355\u7684\u53cd\u9a73\u5417\uff1f\u8fd9\u5c06\u4f7f\u6211\u4eec\u80fd\u591f\u5f88\u5bb9\u6613\u5730\u786e\u5b9a\u95ee\u9898\u7684\u6839\u6e90\u3002\u8c22\u8c22\uff01\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\n\r\ninputs = keras.Input(shape=(784,), name=\"digits\")\r\nx = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\r\nx = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\r\noutputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\r\n\r\nmodel = keras.Model(inputs=inputs, outputs=outputs)\r\n\r\n(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\r\n\r\n\r\nx_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\r\nx_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\r\n\r\ny_train = y_train.astype(\"float32\")\r\ny_test = y_test.astype(\"float32\")\r\n\r\n\r\nx_val = x_train[-10000:]\r\ny_val = y_train[-10000:]\r\nx_train = x_train[:-10000]\r\ny_train = y_train[:-10000]\r\n\r\n\r\nmodel.compile(\r\n    optimizer=keras.optimizers.RMSprop(),  \r\n    loss=keras.losses.SparseCategoricalCrossentropy(),\r\n    metrics=[keras.metrics.SparseCategoricalAccuracy()],\r\n)\r\n\r\n\r\nprint(\"Fit model on training data\")\r\nhistory = model.fit(\r\n    x_train,\r\n    y_train,\r\n    batch_size=64,\r\n    epochs=1,\r\n    validation_data=(x_val, y_val),\r\n)\r\n\r\n\r\nprint(history.history)", "@zhaoyun0071 \r\ni ran the code shared on tf 2.4.1, tf 2.4.0 and nightly, i do not see any striking differences, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/64831a7dcb16b0eaf3e0c11b9fe40a8b/untitled580.ipynb)", "If it is indeed the same issue than mine, last working should be tf 2.3, not tf 2.4.0. I tried the 2.5.0-rc0 branch a few days ago, and the issue is still there.", "> @zhaoyun0071\r\n> i ran the code shared on tf 2.4.1, tf 2.4.0 and nightly, i do not see any striking differences, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/64831a7dcb16b0eaf3e0c11b9fe40a8b/untitled580.ipynb)\r\n\r\nI mean 2.4.0 and 2.4.1have the same question\u3002\r\nthey are different from 2.3.0 and other low version!\r\nyou can try 2.3.0,see the history loss and epoch loss", "> @zhaoyun0071\r\n> i ran the code shared on tf 2.4.1, tf 2.4.0 and nightly, i do not see any striking differences, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/64831a7dcb16b0eaf3e0c11b9fe40a8b/untitled580.ipynb)\r\n\r\nyou can try 2.3.0,see the history loss and epoch loss are same.\r\nbut 2.4.0  the history loss and epoch loss are different", "I can reproduce the issue. The issue is mainly with `loss` and `sparse_categorical_accuracy` in training only. The validation metrics are matching with the  validation metrics in `history` object but the training metrics are not matching. [Here](https://colab.research.google.com/gist/jvishnuvardhan/83c64c997276e080d5fa11f59d4d33c3/untitled580.ipynb) is a gist with `tf-nightly` for our reference. Thanks!\r\n\r\n[Here](https://colab.research.google.com/gist/jvishnuvardhan/5c9d674f5ff419d651771896a940268a/untitled580.ipynb) is a gist with `TF2.3` that shows matching in metrics (training and validation) w.r.t. metrics in `history` object.\r\n\r\n@zhaoyun0071 We will take a look at this issue and respond. Thanks for creating this issue. ", "I also have this issue with the training metrics in tf-2.4.1 using python 3.8 and a custom loss function and `verbose=1`. It looks like the history object is correct and the debug info is incorrect. If I use `verbose=2`, the issue disappears.\r\n\r\n```\r\nEpoch 20/20\r\n6/6 [==============================] - 0s 78ms/step - loss: 0.0290\r\n```\r\n```python\r\nhistory = model.fit(..., verbose=1)\r\n# history['loss'][-1] = 0.04953611642122269\r\nactual_losses = model.loss(y_true, y_pred).numpy()\r\n# actual_losses[-1] = 0.050000716\r\n```", "@zhaoyun0071 Looks like this was resolved in recent `tf-nightly`. I couldn't reproduce the error anymore. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/3aceaaeb392ce0baece7c1ab2d4d239f/untitled580.ipynb).\r\n\r\nPlease verify once and close the issue if this was resolved for you. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48033\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48033\">No</a>\n"]}, {"number": 48032, "title": "NotImplementedError: Conversion for TF op 'Bucketize' not implemented.", "body": "Error encountered while converting the TensorFlow model to CoreML model:\r\nNotImplementedError: Conversion for TF op 'Bucketize' not implemented.\r\n\r\nTensorFlow uses the following code for training:\r\n\r\nnumeric_column = tf. Feature_column. Numeric_column (col)\r\nbuket_col = tf. Feature_column. Bucketized_column (numeric_column, boundary_dict [col])\r\nembedding_column = tf.feature_column. Embedding_column (buket_col, K + 1)\r\n\r\nHow do I skip support for bucketized_column?\r\n", "comments": ["Could you ask a feature request for the CoreML converter instead? The missing support should be completed in the Core ML conversion side not in the TensorFlow project."]}, {"number": 48031, "title": "How does tf.nn.erosion2d work? its output seems unmatched with the formular shown in doc", "body": "output[b, y, x, c] =\r\n   min_{dy, dx} value[b,\r\n                      strides[1] * y - rates[1] * dy,\r\n                      strides[2] * x - rates[2] * dx,\r\n                      c] -\r\n                kernel[dy, dx, c]", "comments": ["@shaofengzeng,\r\nCould you please let us know the TensorFlow version you are using along with the output you got and the expected output, so that we can look into it. Thanks!", "Thank you for reply.\r\nTensorflow version:1.14\r\nFor example, if we input an image like,\r\n`image = [[1 1 1 1 1]\r\n                [1 1 1 1 1]\r\n                [0 1 1 1 1]\r\n                [0 1 1 1 1]\r\n                [0 0 1 1 1]]`\r\nand set kernel\r\n`kernel=[[1. 0.]\r\n             [1. 1.]]`\r\nwe applied the erosion operation as follows,\r\n`output = tf.nn.erosion2d(tf.to_float(tf.constant(image[np.newaxis,:,:,np.newaxis])),\r\n                                       tf.to_float(tf.constant(kernel)[..., tf.newaxis]),\r\n                                       [1, 1, 1, 1],\r\n                                       [1, 1, 1, 1],\r\n                                       'SAME')[..., 0]`\r\nthe output will be \r\n`[[[ 0.  0.  0.  0.  0.]\r\n  [ 0.  0.  0.  0.  0.]\r\n  [-1.  0.  0.  0.  0.]\r\n  [-1.  0.  0.  0.  0.]\r\n  [-1. -1.  0.  0. -0.]]]`\r\nwhich is exactly the same as the input image (if plus 1 for each elements).\r\n\r\nAs the tf documentation said 'the grayscale morphological 2-D erosion is given by:'\r\n`output[b, y, x, c] =\r\n   min_{dy, dx} value[b,\r\n                      strides[1] * y - dilations[1] * dy,\r\n                      strides[2] * x - dilations[2] * dx,\r\n                      c] - filters[dy, dx, c]`\r\nIt seems that the output cannot matched the formulation no matter how we padded the image (I suppose tf pad 0s or big values on the sides of the image)\r\nMaybe i'm wrong, but can you tell me more about erosion2d ?\r\nThank you !\r\n", "@shaofengzeng,\r\nWhile running the given code snippet, I am facing an error stating `TypeError: erosion2d_v2() missing 1 required positional argument: 'dilations'`. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/1b76751200662d17959e1d8bbbcd81af/48031.ipynb#scrollTo=FLtmRycjVdym).\r\n\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code so that we can reproduce the issue on our end.\r\n\r\nAlso, TensorFlow 1.x is not actively supported. Could you please update TensorFlow to the latest stable version v2.4 and check if you are facing the same issue. Thanks!", "> @shaofengzeng,\r\n> While running the given code snippet, I am facing an error stating `TypeError: erosion2d_v2() missing 1 required positional argument: 'dilations'`. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/1b76751200662d17959e1d8bbbcd81af/48031.ipynb#scrollTo=FLtmRycjVdym).\r\n> \r\n> In order to expedite the trouble-shooting process, could you please provide the complete code so that we can reproduce the issue on our end.\r\n> \r\n> Also, TensorFlow 1.x is not actively supported. Could you please update TensorFlow to the latest stable version v2.4 and check if you are facing the same issue. Thanks!\r\n\r\nThanks for your reply. I have solved the problem.\r\nBefore the operation, tensorflow flip (both up and down left and right) the kernel first", "> Thanks for your reply. I have solved the problem.\r\n\r\n@shaofengzeng,\r\nThank you for the update. Closing this issue as it is resolved, please feel free to re-open if necessary. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48031\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48031\">No</a>\n"]}, {"number": 48030, "title": "[INTEL MKL] Fix a build error within mkl_util", "body": "This PR fixes a build problem found in a downstream TF project, with details in comments of this merged PR\r\n \r\nhttps://github.com/tensorflow/tensorflow/pull/47745\r\n   ", "comments": []}, {"number": 48029, "title": "Fix hexagon build and add option for -G0 compiler flag.", "body": "Tested the following commands:\r\n\r\nunit tests + keyword_benchmark with reference kernels:\r\n```\r\nmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=hexagon -j8 test\r\nmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=hexagon -j8 run_keyword_benchmark\r\n```\r\n\r\ninitial setup for optimized kernels:\r\n```\r\ntensorflow/lite/micro/tools/make/targets/hexagon/download_hexagon.sh <path to downloaded static_lib>\r\n```\r\n\r\nunit tests + keyword benchmark with optimized kernels:\r\n```\r\nmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=hexagon OPTIMIZED_KERNEL_DIR=hexagon -j8 test\r\nmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=hexagon OPTIMIZED_KERNEL_DIR=hexagon -j8 run_keyword_benchmark\r\n```\r\n\r\nManually confirmed that `-G0` is added as a compiler flag with:\r\n```\r\nmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=hexagon OPTIMIZED_KERNEL_DIR=hexagon HEXAGON_LPI_BUILD=true -j8 microlite\r\n```\r\n\r\nThe timing information while running the benchmark is not useful. We will need target-specific implementation of micro_time.cc. Filed http://b/183544132 for that.\r\n\r\nProgress towards http://b/183462077\r\n", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 48028, "title": "Add GPU support for sparse reorder", "body": "This PR adds GPU support to `tf.sparse.reorder`.\r\n\r\ncc. @nluehr @benbarsdell ", "comments": ["@sanjoy This PR is related to the sparse_to_dense op. Can you help review? Thanks."]}, {"number": 48025, "title": "Converted TensorFlow Lite MaskRCNN model, conversion was successful but outputs were wrong", "body": "### 1. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installation (pip package or built from source): pip\r\n- TensorFlow library (version, if pip package or github SHA, if built from source): '2.5.0-dev20210318'\r\n\r\n### 2. Code\r\n\r\nThis [folder](https://drive.google.com/drive/folders/1Ot7GzI69t0ywdAhwvwaOj1VQFQfloqT4?usp=sharing) has the converted model, and also the code used to convert the model.\r\n\r\n### 3. Failure after conversion\r\nThe conversion is successful, but the output tensors don't look right. I expect the MaskRCNN model to have four output tensors, however, this model seems to have 7 as shown in the image below. Beside, I tried inference with one image on Android, but the output tensors are either all zeros, or some meaningless numbers.\r\n \r\n![Capture](https://user-images.githubusercontent.com/5137261/112209456-d90ec300-8bef-11eb-8239-27d55e6360aa.PNG)\r\n\r\n", "comments": ["For the multiple input/output naming/ordering issue, we recommend using TFLite signature def API.\r\n\r\nSignatureDef provides meaningful/generic names for inputs/outputs which doesn't rely on specific model details. More on [SignatureDefs](https://www.tensorflow.org/tfx/serving/signature_defs#signaturedef_structure) here.\r\nIf your saved model has a defined signatureDef then it will be exported during conversion to TFLite and then you can use the Signature inputs/outputs for inference and not relying on inputs/outputs order or tensor names.\r\n\r\nSignatureDef support is new thing available in nightly and will be available in 2.5\r\n\r\nThen use the nightly for converting to tflite. The generated tflite file will have the SignatureDef details.\r\nUsing Python API (as an example) you can do something like\r\n\r\nmy_signature = interpreter.get_signature_runner(\"my_method\")\r\nresults = my_signature(input_1=input_tensor_1, input_2=input_tensor_2)\r\nprint(results[\"my_output\"])\r\n", "So I will need to explicitly define SignatureDefs for the model first? How do I do that?\r\n\r\n```\r\nmy_signature = interpreter.get_signature_runner(\"my_method\")  <- where should I look for \"my_method\"?\r\nresults = my_signature(input_1=input_tensor_1, input_2=input_tensor_2) <- what does this line do?\r\nprint(results[\"my_output\"])\r\n```\r\nYou mean I can use this code to get the signature that was pre-defined in the model? Sorry I'm really confused.\r\n\r\n@abattery @amahendrakar ", "To utilize signature def concept, the model should be exported as a TF saved model and the signature def information can be defined while exporting.\r\n\r\nAnd then, you can put your saved model to TFLiteConverter API. TFLite model will contain the signatures and the above option will be available.\r\n\r\nPlease refer to https://www.tensorflow.org/guide/saved_model.", "@Yu-Hang,\r\nAny updates regarding this? Could you please let us know if this is still an issue. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48025\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48025\">No</a>\n"]}, {"number": 48024, "title": "Add pre-load CPU feature guard check", "body": "Compile a small shared library that performs an x86 CPU feature guard\r\ncheck that compares the features enabled during compile-time with the\r\nfeatures available at run-time (using the `CPUID` instruction). This\r\ncomparison is done during static initialization and the process is\r\naborted with an error message if we have compiled with a feature that is\r\nnot supported by the current CPU.\r\n\r\nSuch a check is already performed during static initialization of the\r\nlibrary `libtensorflow_framework.so.2`, but since this library performs\r\nmany actions during initialization, there is a high risk of triggering\r\nan illegal instruction before we reach the check, depending on the\r\n(undefined) static initialization order.\r\n\r\nBecause of this we compile a separate shared library that we load as a\r\nself-check before loading `_pywrap_tensorflow_internal.so`.\r\n\r\nWe also change to use `<iostream>` for printing in case of a failed\r\ncheck, as use of the logging framework might itself trigger an\r\nillegal instruction (it did in my testing).\r\n\r\nTested by attempting to use a wheel built with AVX-512 on an AMD CPU:\r\n\r\nBefore:\r\n\r\n```\r\n$ python -c 'import tensorflow'\r\nIllegal instruction\r\n```\r\n\r\nAfter:\r\n\r\n```\r\n$ python -c 'import tensorflow'\r\nThe TensorFlow library was compiled to use AVX512F instructions, but these aren't available on your machine.\r\nAborted\r\n```", "comments": ["Thank you for the review @mihaimaruseac. I resubmitted it with a buildifier fix now. ", "Are the build failures blocking the merge? They don't seem related to me, [for example](https://source.cloud.google.com/results/invocations/256e7708-cce8-4421-8447-c96ad7ba2aba/log):\r\n```\r\nERROR: 'sandboxed' was requested for default strategies but no strategy with that identifier was registered. Valid values are: [standalone, worker, local]\r\n```", "Those are not related, hopefully the CI should be fixed now", "Thanks, looks like all of them passed now, so should be ready to merge?", "Just an observation: as I understand it this code makes it *less* likely to trigger an illegal instruction, but I don't see any reason why it *cannot* do so if built with compiler flags that enable instructions that aren't available.\r\n\r\n(We had the same problem in JAX for AVX instructions, and have done the same thing this PR does in the hope of catching the problem sooner: https://github.com/google/jax/blob/main/jaxlib/cpu_feature_guard.c\r\nWe additionally made that library plain C to minimize the amount of code that is compiled.\r\n\r\nWe have a TODO about compiling that module with different and more conservative CPU feature flags so the cpu feature guard module itself does not crash. Nothing stops the compiler from using, say, an AVX instruction even in such a trivial module.)", "@hawkinsp Yes, exactly, it is not guaranteed that this will detect it before we hit an illegal instruction, it just makes it more likely. \r\n\r\nThanks for the JAX link and the confirmation that you do something similar.\r\n\r\nI agree it would be even better to compile the check without these instructions enabled and then instead check against the configure-time options, however it seems like that would require some additional build system machinery to extract that information from the compiler (given e.g. `-march=native`) and then pass that to the check without actually compiling with it enabled.", "Seems like there was an error reported by import/copybara in the last attempt, do you know what that is @gbaned?", "Seems like this got stuck? Any help? :-)", "Turns out the C++ code also needs some fixing (`std::cerr` and `std::cout` doesn't go well with some Android targets) so I made it use `LOG(WARNING)` and merged only the C++ code in first. Would you mind opening a new PR so we can continue figuring out the linking part? Thank you again for your patience!", "Thanks for the help @penpornk!\r\n\r\nI don't think `tf_cc_binary` is appropriate because that pulls in `libtensorflow_framework.so.2`, while we want this check to run *before* that library is loaded. I think the second suggestion about `tf_native_cc_binary` sounds like the way to go to avoid pulling in other dependencies. I tested the targets you mentioned with this approach without being able to reproduce any segfaults. I created a pull request, let's see how it goes: #51409 "]}, {"number": 48023, "title": "How to convert conv3d layer ?", "body": "### 1. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10  + anaconda\r\n- TensorFlow installation (pip package or built from source): 2.4.1\r\n- TensorFlow library (version, if pip package or github SHA, if built from source): pip package\r\n\r\n### 2. Describe the problem\r\nI'm using a model containing conv3d layers. I've got an error when converting the model to \r\ntflite saying that conv3d op is neither a custom op nor a flex op. \r\n\r\n**Question 1 : how to quantize a conv3d layers ?**\r\n\r\nI tried to add \"f.lite.OpsSet.SELECT_TF_OPS\" to the converter supported ops. The code worked\r\nwithout errors but I don't know if the conv3d layers were correctly quantized or not (to int8).\r\n\r\n**Question2 : does adding \"Select TensorFlow operators\" affect  quantization ? if yes how ?**\r\n\r\n\r\n### 3. Code\r\n\r\n#### Option B: Paste your code here or provide a link to a custom end-to-end colab\r\n\r\n```\r\nmodel_path = os.path.join(os.getcwd(), \"models\", \"best-model.hdf5\")\r\n    # load best weights\r\nloaded_model = tf.keras.models.load_model(model_path)\r\n\r\n\r\nno_quant_converter = tf.lite.TFLiteConverter.from_keras_model(loaded_model)\r\n\r\nno_quant_tflite_model = no_quant_converter.convert()\r\n\r\n# write the model to a tflite file as binary file\r\ntflite_no_quant_file = os.path.join(os.getcwd(), \"models\", \"tflite_models\", \"best-model_no_quant.tflite\") \r\nwith open(tflite_no_quant_file, \"wb\") as f:\r\n    f.write(no_quant_tflite_model)\r\n```\r\n\r\n### 4. Failure after conversion\r\nerror : \r\n![image](https://user-images.githubusercontent.com/33780694/112195173-ef297d00-8c09-11eb-823d-49ab2942a97d.png)\r\n\r\n\r\n\r\n", "comments": ["There is a new builtin op support for conv3d in the tf-nightly. Could you try your conversion script under the tf-nightly version?", "@abattery  Thank you for your reply, when running under the tf-nightly version, I get \"error: 'tf.BiasAdd' op is neither a custom op nor a flex op\".\r\n I wonder if there is a possible method or implementation that allows me to properly quantify this layer (conv3d) because it is an essential layer in my architecture. Also, I would like to know what effect \"Select TensorFlow operators\" will produce in the quantize architecture, especially since conv3d is at the start of the network. In other words, if using the conv3d Select TensorFlow operator doesn't fall back to float32 operation, I can tolerate an increase in the interpreter binary size.\r\n", "For the BiasAdd op, you can rely on the solution https://www.tensorflow.org/lite/guide/ops_select.\r\n\r\nSelect TF operators won't be quantized and the only a subset of TFLite builtin operators only quantizable. That means that conv3d operator will be only executed with float32 tensors.", "Thank you very much. Just one more thing, are there any methods that can be used to find out from a quantized (.tflite) file which operators are quantized and which operators are not? Also, is there any works in the community to quantize certain Select TF operators(specially conv3d)?", "As far as I know, there are no on-going works for conv3d quantization for now from the community. If you can open your model in the netron, you can see there are some float ops that are always placed in between dequantize and quantize ops.", "Thanks, my goal is to test the quantization of a model that contains conv3d layers on google coral usb edge tpu (knowing that this hardware only run int8 ops). Is this possible?", "@thaink could you share the status of hardware acceleration support for conv3d op?", "The answer is no. TFLite quantizer won't place 8bit conv3d op since there is no 8bit tensor support from the builtin op.\r\nThanks for filing the issue. We will consider this as a feature request for 8bit tensor support for conv3d op.", "Thank you @abattery ", "@ahmedhajyahmed Current Conv3d implementation only support float type, no quantization supported yet.\r\nAbout hardware acceleration, I think it does support ege tpu.", "Even though edge tpu supports conv3d op quantization, the TFLite quantizer won't replace the given float conv3d op with quantized conv3d op since there is no quantized CPU kernel for conv3d op. If we would enable conv3d quantization path, it needs to implement the CPU kernel for the quantization path to provide the default CPU fallback whenever the delegation is not available.", "@abattery  so the 8 bit quantization is impossible and the only possible one is float 16 for GPU ?\r\nAnd what do you advice me to do in my situation ?", "@impjdi do we support float16 conv3d op in GPU delegate?", "IMO, using float32 model with GPU delegate is an option.", "If you `grep` `Convolution3DAttributes` inside `//tensorflow/lite/delegates/gpu`, you will see that there is some support.  However, I don't see a legit code path how you could trigger that in a \"normal\" way, because I don't see the reference to any 3D op in the `gpu/common/model_builder.cc` which is the entry point for GPU IR.", "thanks guys for your help @abattery @impjdi @thaink I will close the incident now", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48023\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48023\">No</a>\n"]}, {"number": 48022, "title": "TensorFlow Lite allocation error after successful conversion: tfl.Slice node failed to prepare", "body": "### 1. System information\r\n\r\n- Linux 5.11.4-arch1-1 #1 SMP PREEMPT Sun, 07 Mar 2021 18:00:49 +0000 x86_64 GNU/Linux\r\n- TensorFlow 2.4.1 from `tensorflow-opt-cuda` package (https://archlinux.org/packages/community/x86_64/tensorflow-opt-cuda)\r\n\r\n### 2. Code\r\n\r\nPlease unzip this protobuf file before running the code: [allocate-fail-protobuf.zip](https://github.com/tensorflow/tensorflow/files/6191821/allocate-fail-protobuf.zip)\r\n\r\n```python\r\n# use tensorflow API v1\r\nimport tensorflow.compat.v1 as tf\r\ntf.disable_v2_behavior()\r\n\r\nPROTOBUF_PATH = \"allocate-fail.pb\"\r\n\r\nwith tf.gfile.GFile(PROTOBUF_PATH, \"rb\") as fprotobuf:\r\n    graphDef = tf.GraphDef()\r\n    graphDef.ParseFromString(fprotobuf.read())\r\n\r\nX = tf.placeholder(dtype=tf.float32, shape=[1, 309], name=\"X\")\r\nP = tf.placeholder(dtype=tf.float32, shape=[1], name=\"P\")\r\n\r\nYhat, = tf.import_graph_def(\r\n    graphDef,\r\n\r\n    input_map={\r\n        \"runtime/X:0\": X,\r\n        \"runtime/P:0\": P,\r\n    },\r\n    name=\"model\",\r\n    return_elements=[f\"runtime/Y/fast/32:0\"]\r\n)\r\n\r\nwith tf.Session() as session:\r\n    converter = tf.lite.TFLiteConverter.from_session(\r\n        session,\r\n        input_tensors=[X, P],\r\n        output_tensors=[Yhat]\r\n    )\r\n    flatbuffer = converter.convert()\r\n\r\ninterpreter = tf.lite.Interpreter(model_content=flatbuffer)\r\ninterpreter.allocate_tensors()\r\n```\r\n\r\n\r\n### 3. Failure after conversion\r\nThe computational graph converts without an error, but when I try to allocate tensors there's internal error within TensorFlow Lite C modules:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/barabanus/work/4a-games/pfnn-tools/test/tflite-allocate-fail.py\", line 34, in <module>\r\n    interpreter.allocate_tensors()\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/lite/python/interpreter.py\", line 259, in allocate_tensors\r\n    return self._interpreter.AllocateTensors()\r\nRuntimeError: Invalid begin and size.Node number 20 (SLICE) failed to prepare.\r\n```\r\nThe error refers to `tfl.Slice` operation within the graph.\r\n\r\n### 5. Any other info / logs\r\n\r\nTFLite model after conversion: [allocate-fail-flatbuffer.zip](https://github.com/tensorflow/tensorflow/files/6191844/allocate-fail-flatbuffer.zip)\r\n\r\nThe full log:\r\n```\r\n2021-03-23 19:48:41.585258: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\nWARNING:tensorflow:From /usr/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nnon-resource variables are not supported in the long term\r\n2021-03-23 19:48:42.626809: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-03-23 19:48:42.627325: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\r\n2021-03-23 19:48:42.739393: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\r\n2021-03-23 19:48:42.739422: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (rb15): /proc/driver/nvidia/version does not exist\r\n2021-03-23 19:48:42.739809: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-03-23 19:48:42.740475: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-03-23 19:48:42.740514: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\r\n2021-03-23 19:48:42.742921: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\r\n2021-03-23 19:48:42.743008: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2021-03-23 19:48:42.743161: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-03-23 19:48:42.757234: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200660000 Hz\r\n2021-03-23 19:48:42.758795: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:928] Optimization results for grappler item: graph_to_optimize\r\n  function_optimizer: function_optimizer did nothing. time = 0.004ms.\r\n  function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\r\n2021-03-23 19:48:42.764013: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\r\n2021-03-23 19:48:42.764171: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2021-03-23 19:48:42.764396: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-03-23 19:48:42.766009: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:928] Optimization results for grappler item: graph_to_optimize\r\n  function_optimizer: function_optimizer did nothing. time = 0.002ms.\r\n  function_optimizer: function_optimizer did nothing. time = 0ms.\r\n\r\n2021-03-23 19:48:42.776385: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored output_format.\r\n2021-03-23 19:48:42.776410: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:319] Ignored drop_control_dependency.\r\n2021-03-23 19:48:42.786790: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-03-23 19:48:42.786850: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\r\nTraceback (most recent call last):\r\n  File \"/home/barabanus/work/4a-games/pfnn-tools/test/tflite-allocate-fail.py\", line 34, in <module>\r\n    interpreter.allocate_tensors()\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/lite/python/interpreter.py\", line 259, in allocate_tensors\r\n    return self._interpreter.AllocateTensors()\r\nRuntimeError: Invalid begin and size.Node number 20 (SLICE) failed to prepare.\r\n```", "comments": ["Could you verify the given input is also valid in your TF model as well?", "@abattery @Saduf2019 Let me modify the example to show yout that it works fine:\r\n\r\n```python\r\n# use tensorflow API v1\r\nimport tensorflow.compat.v1 as tf\r\ntf.disable_v2_behavior()\r\n\r\nPROTOBUF_PATH = \"tflite-allocate-fail.pb\"\r\n\r\nwith tf.gfile.GFile(PROTOBUF_PATH, \"rb\") as fprotobuf:\r\n    graphDef = tf.GraphDef()\r\n    graphDef.ParseFromString(fprotobuf.read())\r\n\r\nX = tf.placeholder(dtype=tf.float32, shape=[1, 309], name=\"X\")\r\nP = tf.placeholder(dtype=tf.float32, shape=[1], name=\"P\")\r\n\r\nYhat, = tf.import_graph_def(\r\n    graphDef,\r\n\r\n    input_map={\r\n        \"runtime/X:0\": X,\r\n        \"runtime/P:0\": P,\r\n    },\r\n    name=\"model\",\r\n    return_elements=[f\"runtime/Y/fast/32:0\"]\r\n)\r\n\r\nwith tf.Session() as session:\r\n\r\n    result = session.run(\r\n        Yhat,\r\n        feed_dict={\r\n            X: tf.random.normal(shape=[1, 309]).eval(session=session),\r\n            P: tf.random.normal(shape=[1]).eval(session=session),\r\n    })\r\n    print(result)\r\n\r\n    converter = tf.lite.TFLiteConverter.from_session(\r\n        session,\r\n        input_tensors=[X, P],\r\n        output_tensors=[Yhat]\r\n    )\r\n    flatbuffer = converter.convert()\r\n    with open(\"allocate-fail.tflite\", \"wb\") as fout:\r\n        fout.write(flatbuffer)\r\n\r\n\r\ninterpreter = tf.lite.Interpreter(model_content=flatbuffer)\r\ninterpreter.allocate_tensors()\r\n```\r\n\r\nWe used this graph (with correct weights) successfully within our TF project until we migrated to TFLite and came across this issue.", "I verified that the above error is gone at the tf-nightly version.", "@barabanus \r\nPlease move this to closed status if resolved.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48022\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48022\">No</a>\n"]}, {"number": 48020, "title": "Use reference_ops::Softmax() for RunSoftmaxFloatReference().", "body": "If we use TFLITE_SOFTMAX_USE_UINT16_LUT table look up optimization\r\nfor softmax[1], the float look up table will not be initialized.\r\nThe optimized_ops::Softmax<float, float>() call will crash.\r\nThis commit turns to use reference_ops::Softmax<float, float>()\r\ninstead. That reference call should always be available.\r\n\r\n[1]\r\nhttps://github.com/tensorflow/tensorflow/blob/8f8b15c9cdd4f549354cc0e97c81ed9ab6096f67/tensorflow/lite/kernels/activations.cc#L602-L619", "comments": ["Is this test case failed at your end? Please elaborate more on describing the test failures including the error message and how to reproduce it.", "> Is this test case failed at your end? Please elaborate more on describing the test failures including the error message and how to reproduce it.\r\n\r\n@abattery\r\nSorry for the false alarm.\r\nI have another overloading for the softmax kernel in my local branch. So, the test calls the wrong path and hits crash."]}, {"number": 48019, "title": "steps_per_epoch documentation not in accordance with the tutorials on the tf website", "body": "The documentation for the `steps_per_epoch` argument to the `tf.keras.Model.fit()` function, located [here](https://github.com/tensorflow/tensorflow/blob/85c8b2a817f95a3e979ecd1ed95bff1dc1335cff/tensorflow/python/keras/engine/training.py#L942), specifies that:\r\n\r\n> If x is a `tf.data` dataset, and 'steps_per_epoch' is None, the epoch will run until the input dataset is exhausted.\r\n\r\nAlso, the default value of `steps_per_epoch` is **None**.\r\n\r\nIn the [Load images tutorial](https://www.tensorflow.org/tutorials/load_data/images#train_a_model), the `train_ds` variable is passed to `Model.fit()` for training, and is a `tf.data.Dataset` on which several `.map()`s have been applied before:\r\n\r\n![image](https://user-images.githubusercontent.com/25421460/112180016-74f1fc00-8bfb-11eb-8549-1dd9f00937bd.png)\r\n\r\nFollowing the documentation, how can the steps (underlined in red in the picture) be displayed?\r\n\r\nPlease feel free to ask if you need any more detail!", "comments": ["@BlueskyFR Steps in the above example are estimated as (number of samples in your dataset / the batch size). In this example `number of samples` are 2936 and `batch_size` is 32. so ceil(2936/32) = 92. \r\n\r\n> When training with input tensors such as\r\n>             TensorFlow data tensors, the default `None` is equal to\r\n>             the number of samples in your dataset divided by\r\n>             the batch size, or 1 if that cannot be determined.\r\n\r\n`tf.keras.preprocessing.image_dataset_from_directory` returns a dataset object\r\n\r\n> A tf.data.Dataset object.\r\n> If label_mode is None, it yields float32 tensors of shape (batch_size, image_size[0], image_size[1], num_channels), encoding images (see below for rules regarding num_channels).\r\n\r\nAs it is not a `dataset` iterator that was set to be repeated indefinitely, the number of steps can be estimated.\r\n\r\nPlease verify once and close the issue if this was resolved for you. Thanks!", "@jvishnuvardhan thanks for your answer: I might have missunderstood the documentation on some points but it is not very clear in my opinion: with a `tf.data.Dataset`, should the total number of steps be displayed by `.fit()`?\r\n\r\nIn my code, `model.fit()` displays `X/Unknown` (with X being the current step), and I am trying to know why.\r\nWhen I call `len(ds)` on my Dataset object, it only works if `ds.map()` was never called. The first time I call **map** on my dataset, `len(ds)` becomes unavailable so I though this was the problem.\r\n\r\nReading the documentation, I found no explanation to my problem: I think this part is not very clear about that behavior.", "@BlueskyFR The code in the tutorial was not printing `X/unknown`. Are you talking about your code? Can you please share a standalone code to reproduce the issue?\r\n\r\nIn some other cases where data generator is used, that code will output `X/unknown` as dataset generator doesn't know how many batches are there in the data until it completes one full epoch. \r\n\r\n[This response](https://github.com/tensorflow/tensorflow/issues/39277) to a similar issue might help you. Thanks!\r\n\r\nPlease verify once and close the issue if this was resolved for you. Thanks!", "@BlueskyFR [This](https://github.com/tensorflow/tensorflow/issues/36321) might help you. Thanks!", "I am closing this issue as this was resolved. Please feel free to reopen if I am mistaken. Please feel free to raise any PR If you want to update any tutorial or guide. Thanks!", "> I am closing this issue as this was resolved. Please feel free to reopen if I am mistaken. Please feel free to raise any PR If you want to update any tutorial or guide. Thanks!\n\nSorry for the late response, I will provide a code sample to reproduce the problem.", "Sure. You could also raise any PR to update the docs. Thanks!"]}, {"number": 48018, "title": "TensorFlow Lite conversion error when using the slice semantics to expand the last dimension", "body": "### 1. System information\r\n\r\n- Linux 5.11.4-arch1-1 #1 SMP PREEMPT Sun, 07 Mar 2021 18:00:49 +0000 x86_64 GNU/Linux\r\n- TensorFlow 2.4.1 from `tensorflow-opt-cuda` package (https://archlinux.org/packages/community/x86_64/tensorflow-opt-cuda)\r\n\r\n### 2. Code\r\n\r\nPlease unzip this protobuf file before running the code: [tflite-strided-slice-fail.zip](https://github.com/tensorflow/tensorflow/files/6191669/tflite-strided-slice-fail.zip)\r\n\r\n\r\n```python\r\n# use tensorflow API v1\r\nimport tensorflow.compat.v1 as tf\r\ntf.disable_v2_behavior()\r\n\r\nPROTOBUF_PATH = \"tflite-strided-slice-fail.pb\"\r\n\r\nwith tf.gfile.GFile(PROTOBUF_PATH, \"rb\") as fprotobuf:\r\n    graphDef = tf.GraphDef()\r\n    graphDef.ParseFromString(fprotobuf.read())\r\n\r\nX = tf.placeholder(dtype=tf.float32, shape=[1, 309], name=\"X\")\r\nP = tf.placeholder(dtype=tf.float32, shape=[1], name=\"P\")\r\n\r\nYhat, = tf.import_graph_def(\r\n    graphDef,\r\n\r\n    input_map={\r\n        \"runtime/X:0\": X,\r\n        \"runtime/P:0\": P,\r\n    },\r\n    name=\"model\",\r\n    return_elements=[f\"runtime/Y/fast/32:0\"]\r\n)\r\n\r\nwith tf.Session() as session:\r\n    converter = tf.lite.TFLiteConverter.from_session(\r\n        session,\r\n        input_tensors=[X, P],\r\n        output_tensors=[Yhat]\r\n    )\r\n    flatbuffer = converter.convert()\r\n```\r\n\r\n### 3. Failure after conversion\r\n```\r\nConverterError: /usr/lib/python3.9/site-packages/tensorflow/python/framework/importer.py:400:0: error: 'tf.StridedSlice' op is neither a custom op nor a flex op\r\n/usr/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:538:0: note: called from\r\n/home/barabanus/work/4a-games/pfnn-tools/test/tflite-fail-1.py:14:0: note: called from\r\n/usr/lib/python3.9/site-packages/IPython/utils/py3compat.py:168:0: note: called from\r\n/usr/lib/python3.9/site-packages/IPython/core/interactiveshell.py:2740:0: note: called from\r\n/usr/lib/python3.9/site-packages/IPython/core/shellapp.py:377:0: note: called from\r\n/usr/lib/python3.9/site-packages/IPython/core/shellapp.py:452:0: note: called from\r\n/usr/lib/python3.9/site-packages/IPython/core/shellapp.py:328:0: note: called from\r\n/usr/lib/python3.9/site-packages/IPython/terminal/ipapp.py:323:0: note: called from\r\n/usr/lib/python3.9/site-packages/traitlets/config/application.py:87:0: note: called from\r\n<unknown>:0: error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):\r\n\ttf.StridedSlice {begin_mask = 0 : i64, device = \"\", ellipsis_mask = 1 : i64, end_mask = 0 : i64, new_axis_mask = 0 : i64, shrink_axis_mask = 2 : i64}\r\n```\r\n\r\n### 5. Any other info / logs\r\nThe problem has to do with the slice semantics when I try to expand the last dimension of a tensor like `tensor[..., None]` to match matrix multiplication dimensions requirement. Usually it works, but I found an example of computational graph which fails to convert with TFLite.\r\n\r\nThe problem has been solved by replacing the slice semantics `X[..., None]` with `tf.expand_dims(X, axis=-1)` and `Y[0]` with `tf.squeeze(Y, axis=0)`, but it should have been worked with the slice semantics.\r\n\r\nThe full log:\r\n```\r\n2021-03-23 19:32:32.072655: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\nWARNING:tensorflow:From /usr/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nnon-resource variables are not supported in the long term\r\n2021-03-23 19:32:33.177145: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-03-23 19:32:33.177749: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\r\n2021-03-23 19:32:33.290409: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\r\n2021-03-23 19:32:33.290438: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (rb15): /proc/driver/nvidia/version does not exist\r\n2021-03-23 19:32:33.290815: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-03-23 19:32:33.291632: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-03-23 19:32:33.291674: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\r\n2021-03-23 19:32:33.294267: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\r\n2021-03-23 19:32:33.294368: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2021-03-23 19:32:33.294574: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-03-23 19:32:33.310613: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 2200660000 Hz\r\n2021-03-23 19:32:33.312516: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:928] Optimization results for grappler item: graph_to_optimize\r\n  function_optimizer: function_optimizer did nothing. time = 0.005ms.\r\n  function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n\r\n2021-03-23 19:32:33.318140: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\r\n2021-03-23 19:32:33.318275: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2021-03-23 19:32:33.318494: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-03-23 19:32:33.320979: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:928] Optimization results for grappler item: graph_to_optimize\r\n  function_optimizer: function_optimizer did nothing. time = 0.003ms.\r\n  function_optimizer: function_optimizer did nothing. time = 0.001ms.\r\n\r\n2021-03-23 19:32:33.331507: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored output_format.\r\n2021-03-23 19:32:33.331542: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:319] Ignored drop_control_dependency.\r\n2021-03-23 19:32:33.341942: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-03-23 19:32:33.341994: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\r\nloc(callsite(\"model/runtime/strided_slice_26\"(\"/usr/lib/python3.9/site-packages/tensorflow/python/framework/importer.py\":400:0) at callsite(\"/usr/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py\":538:0 at \"/home/barabanus/work/4a-games/pfnn-tools/test/tflite-fail-1.py\":14:0))): error: 'tf.StridedSlice' op is neither a custom op nor a flex op\r\nerror: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):\r\n\ttf.StridedSlice {begin_mask = 0 : i64, device = \"\", ellipsis_mask = 1 : i64, end_mask = 0 : i64, new_axis_mask = 0 : i64, shrink_axis_mask = 2 : i64}\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/lite/python/convert.py\", line 210, in toco_convert_protos\r\n    model_str = wrap_toco.wrapped_toco_convert(model_flags_str,\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/lite/python/wrap_toco.py\", line 32, in wrapped_toco_convert\r\n    return _pywrap_toco_api.TocoConvert(\r\nException: /usr/lib/python3.9/site-packages/tensorflow/python/framework/importer.py:400:0: error: 'tf.StridedSlice' op is neither a custom op nor a flex op\r\n/usr/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:538:0: note: called from\r\n/home/barabanus/work/4a-games/pfnn-tools/test/tflite-fail-1.py:14:0: note: called from\r\n<unknown>:0: error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):\r\n\ttf.StridedSlice {begin_mask = 0 : i64, device = \"\", ellipsis_mask = 1 : i64, end_mask = 0 : i64, new_axis_mask = 0 : i64, shrink_axis_mask = 2 : i64}\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/barabanus/work/4a-games/pfnn-tools/test/tflite-fail-1.py\", line 31, in <module>\r\n    flatbuffer = converter.convert()\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/lite/python/lite.py\", line 1947, in convert\r\n    return super(TFLiteConverter, self).convert()\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/lite/python/lite.py\", line 1300, in convert\r\n    result = _toco_convert_impl(\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/lite/python/convert.py\", line 608, in toco_convert_impl\r\n    data = toco_convert_protos(\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/lite/python/convert.py\", line 216, in toco_convert_protos\r\n    raise ConverterError(str(e))\r\ntensorflow.lite.python.convert.ConverterError: /usr/lib/python3.9/site-packages/tensorflow/python/framework/importer.py:400:0: error: 'tf.StridedSlice' op is neither a custom op nor a flex op\r\n/usr/lib/python3.9/site-packages/tensorflow/python/util/deprecation.py:538:0: note: called from\r\n/home/barabanus/work/4a-games/pfnn-tools/test/tflite-fail-1.py:14:0: note: called from\r\n<unknown>:0: error: failed while converting: 'main': Ops that can be supported by the flex runtime (enabled via setting the -emit-select-tf-ops flag):\r\n\ttf.StridedSlice {begin_mask = 0 : i64, device = \"\", ellipsis_mask = 1 : i64, end_mask = 0 : i64, new_axis_mask = 0 : i64, shrink_axis_mask = 2 : i64}\r\n```", "comments": ["Please use the Select TF option. https://www.tensorflow.org/lite/guide/ops_select\r\n\r\nSince the strided slice op in TFLite builtin supports not all of the cases in TF's strided slice op, you need to link the TF op through the Select TF option.", "@abattery Thank you for examining this issue. Unfortunately, using TF within our runtime environment is not possible. I fixed the issue by replacing `tensor[..., None]` with `tf.expand_dims(tensor, axis=-1)`.\r\n\r\nUsually, `tensor[..., None]` works without a problem within both TF and TFLite. Before I tried to post this issue I failed to make a simple example for which `tensor[..., None]` would not convert to TFLite, so TFLite is aware of this kind of strided slice op. I used a simplified example from the real project instead where `tensor[..., None]` doesn't convert.\r\n\r\nI suggest to modify TFLite converter so that when it meets dimension expansion using slice semantics it replaces the op with `tf.expand_dims()`.", "Actually, FYI, @thaink is working on all the cases of TF strided slice op in TFLite op. Thanks for the suggestion. Closing since the problem has been resolved.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48018\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48018\">No</a>\n", "@abattery Could you please link this issue with the one @thaink works with? I'll double check the issue is fixed.", "Closed because you fixed the issue by using the other pattern with expand_dims op. @thaink is working on delivering the improvement of TFLite strided slice op kernel, which hasn't been done yet. \r\n\r\n@thaink could you notify this thread once you complete the strided slice op kernel work?", "I think it is fair to keep this bug opened. My PR for supporting ellipsis_mask and new_axis_mask is almost complete. I'll send it shortly.", "The feature is added at commit be1238ceddf16e5668547b0702228a5b1aed2527. you can try to convert it with tomorrow's nightly.", "@thaink Thank you very much, I'll do it these weekends", "I probably wait for updated `tensorflow-opt-cuda` package and then reopen the issue in the case it's not fixed. Thank you very much for your work.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48018\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48018\">No</a>\n"]}, {"number": 48017, "title": "Can't install Tensorflow for Golang", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -\r\n- TensorFlow installed from (source or binary): go get\r\n- TensorFlow version: 2.4.1\r\n- Python version: 3.8\r\n- Installed using virtualenv? pip? conda?: pip, conda\r\n- Bazel version (if compiling from source): -\r\n- GCC/Compiler version (if compiling from source): -\r\n- CUDA/cuDNN version:-\r\n- GPU model and memory: virtgl\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nCan't install Tensorflow for Golang\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n```\r\n~$ sudo go get github.com/tensorflow/tensorflow/tensorflow/go\r\n[sudo] heslo pre pou\u017e\u00edvate\u013ea gg187on: \r\ngo: downloading github.com/tensorflow/tensorflow v1.15.5\r\ngo: downloading github.com/tensorflow/tensorflow v2.4.1+incompatible\r\ngo: downloading github.com/golang/protobuf v1.5.1\r\ngo: downloading google.golang.org/protobuf v1.26.0\r\ngithub.com/tensorflow/tensorflow/tensorflow/go imports\r\n    github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto: cannot find module providing package github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto\r\n```\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@gg187on,\r\nPlease take a look at this [README.md](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/go/README.md) file with the installation instructions for TensorFlow in Go.\r\n\r\nAlso, please go through issues [#39744](https://github.com/tensorflow/tensorflow/issues/39744) and [#41808](https://github.com/tensorflow/tensorflow/issues/41808) with a similar error log and check if it helps. Thanks!", "Tried steps from README.md and got error:\r\n\r\n```\r\ngithub.com/tensorflow/tensorflow/tensorflow/go imports\r\n\tgithub.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto: cannot find module providing package github.com/tensorflow/tensorflow/tensorflow/go/core/protobuf/for_core_protos_go_proto\r\n```\r\n\r\nI have bazel version 4.0.0\r\n```\r\n~$ bazel --version \r\nbazel 4.0.0\r\n```", "I tried literally everything, but it still don't want install. Always same error, I did exactly all commands as written in README.md even with optional steps, and always same...", "I'm having exact same issue, followed the README.md as suggested above", "I read whole https://github.com/tensorflow/tensorflow/issues/35133 and it seems like Tensorflow dev can't fix their library for some time. It has always some problems.", "https://github.com/tensorflow/tensorflow/issues/35133#issuecomment-807404740\r\n\r\nseems to work,...", "> [#35133 (comment)](https://github.com/tensorflow/tensorflow/issues/35133#issuecomment-807404740)\r\n> \r\n> seems to work,...\r\n\r\nthank you, it worked perfectly for me", "I had the same problem, seems like the release doesn't handle the new module changes correctly. Anyway, I've put together a small script to generate the proto code, see below. Run this after you've done a go get in your module to get the tf module (basically till the point when you get the proto missing error).\r\n\r\n# Edit these as necessary\r\ngo=~/go\r\nver=tensorflow@v2.4.1+incompatible\r\n\r\n# Looks like go:generate actions expect the protos to be here\r\nmkdir -p $go/src/github.com/tensorflow\r\nln -s $go/pkg/mod/github.com/tensorflow/$ver $go/src/github.com/tensorflow/tensorflow\r\n\r\n# To trigger go:generate actions\r\ncd $go/pkg/mod/github.com/tensorflow/$ver\r\nchmod -R +w .\r\nln -s vendor/github.com/tensorflow/tensorflow/tensorflow/go/core tensorflow/go\r\nln -s vendor/github.com/tensorflow/tensorflow/tensorflow/go/stream_executor tensorflow/go\r\ngo mod init github.com/tensorflow/tensorflow\r\ngo generate github.com/tensorflow/tensorflow/tensorflow/go/op", "Ok, it seems I hit another problem (is APi broken, from docs on TensorFlow, it seems like if it was for another (older) version of TF), and also it seems it's hard to do parallelism with TensorFlow lib. What I learned for last week is that, Golang is not machine learning ready. So if anyone want to do machine learning, I would rather recommend Python or C or even JS.", "Hey @gg187on I have really setup DevContainer with TensorFlow for Go 1.16.1. You can use it right now without any issue with compiler.\r\n\r\nhttps://github.com/giautm/tensorflow-go-example\r\n\r\nFYI: DevContainer is feature of VSCode (https://code.visualstudio.com/docs/remote/containers). So, It requirements you have VSCode, Docker on your machine.", "> Ok, it seems I hit another problem\r\n\r\n@gg187on,\r\nAny updates regarding this issue? Could you please share the error log so that we can look into it. Thanks!", "I am having the issue:\r\n\r\nNo such file or directory\r\n   20 | // #include \"tensorflow/c/c_api.h\"\r\n      |           ^~~~~~~~~~~~~~~~~~~~~~\r\ncompilation terminated.\r\n", "> I am having the issue:\r\n\r\n@wiktoria-n,\r\nCould you please submit a new issue from [this link](https://github.com/tensorflow/tensorflow/issues/new/choose) and fill in the template, so that we can track the issue there. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48017\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48017\">No</a>\n"]}, {"number": 48015, "title": "Tensorflow C++ get_visible_devices", "body": "### System information\r\n\r\n-   I wrote custom code\r\n-   Windows 10 64-bit\r\n-   Tensorflow compiled from source\r\n-   Tensorflow v2.4\r\n-   Python v3.8\r\n-   Bazel v3.1\r\n-   Visual Studio Build Tools 2019\r\n-   CUDA 11.0\r\n\r\n### Describe the problem\r\nHello, I am trying to get the visible GPU devices in my C++ program that integrates Tensorflow compiled from source. I can't find the C++ equivalent function of the Python tf.config.get_visible_devices() documented here https://www.tensorflow.org/api_docs/python/tf/config/get_visible_devices .\r\nIs this function or a similar one implemented in C++?\r\nI found a similar function in the GPUOptions but I got a linking error when try to building the program and I am not sure that the function is meant to read the available GPU devices.\r\n\r\n### Source code / logs\r\nConfigProto* config = &options.config;\r\nauto gpu_options = config->gpu_options();\r\nstring pi = gpu_options.visible_device_list();\r\n\r\nThank you,\r\nMauro\r\n", "comments": ["A little update. I was able to read the devices once the Session is established through this code:\r\n\r\n```\r\nvector<DeviceAttributes> devices;\r\nsession->ListDevices(&devices);\r\n```\r\nBut I need a similar function to read the devices before the Session is established. \r\nDirectly with CUDA library is possible through this function:\r\n\r\n```\r\ncudaGetDeviceCount(&deviceCount);\r\nfor (device = 0; device < deviceCount; ++device) {\r\n        cudaDeviceProp deviceProp;\r\n        cudaGetDeviceProperties(&deviceProp, device);\r\n}\r\n```\r\n\r\nBut I want to do this using Tensorflow Library in C++ in order to not depend directly from CUDA.\r\nIs it possible someway?\r\nThank you,\r\nRegards\r\n\r\nMauro", "Can you use `DeviceFactory::AddDevices`?", "Thank you @sanjoy for the suggestion. I saw the implementation of that function and it may be the one which I need.\r\nMore precisely, I am using this piece of code\r\n```\r\nvector<unique_ptr<Device>> devices;\r\nauto gpu_factory = tensorflow::DeviceFactory::GetFactory(\"GPU\");\r\nif (gpu_factory) {\r\n gpu_factory->CreateDevices(options, \"GPU\", &devices);\r\n}\r\n```\r\n\r\nI got this compilation error in the final application that integrates Tensorflow:\r\n\r\n```\r\n1>D:\\Progetti\\_UNSTABLE\\workspace_library\\sb_lib\\source\\sb_tensorflow.cpp(1116): message : vedere il riferimento all'istanza 'std::unique_ptr<tensorflow::Device,std::default_delete<tensorflow::Device>>' di modello classe di cui \u00e8 in corso la compilazione\r\n1>C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29910\\include\\memory(3283,25): error C2338: can't delete an incomplete type\r\n1>C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.28.29910\\include\\memory(3284,1): warning C4150: eliminazione del puntatore al tipo incompleto 'tensorflow::Device'. Non \u00e8 stato chiamato nessun distruttore\r\n```\r\n\r\nIt may refer to the fact that the compiler cannot find the destructor of the base class of Device. I tried to export the destructor of DeviceBase through TF_EXPORT macro like I did previously for other compilation errors, but this didn't solve the issue.\r\nAny ideas?\r\nThank you", "I managed to solve this issue by using another function:\r\n\r\n    vector<string> devs_gpu;\r\n   \r\n    auto gpu_factory = DeviceFactory::GetFactory(\"GPU\");\r\n    CHECK_TF_FN_RETURN(gpu_factory->ListPhysicalDevices(&devs_gpu));\r\n\r\n    for(int i=0; i<devs_gpu.size(); i++)\r\n    {\r\n        unordered_map<string, string> details;\r\n        CHECK_TF_FN_GOTO(gpu_factory->GetDeviceDetails(i, &details));\r\n    }\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48015\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48015\">No</a>\n"]}, {"number": 48013, "title": "RuntimeError: Input pipelines based on Queues are not supported when eager execution is enabled. Please use tf.data to ingest data into your model instead.", "body": "OS Platform and Distribution (e.g., Linux Ubuntu 20.04): RHEL 7.7\r\nTensorFlow version: 2.4.1\r\nPython version: 3.8.5\r\nCPU\r\nNVIDIA Corporation GP102\r\nI try to run this code\r\npython -m CycleGAN_TensorFlow.create_cyclegan_dataset --image_path_a=folder_a --image_path_b=folder_b --dataset_name=\"horse2zebra_train\" --do_shuffle=0\r\n\r\nI have this error\r\nRuntimeError: Input pipelines based on Queues are not supported when eager execution is enabled. Please use tf.data to ingest data into your model instead.", "comments": ["@438-gm-24 \r\nCan you share more details for us to analyse, simple stand alone code to replicate the issue faced or a colab gist with the code and error.", "WARNING:tensorflow:\r\nThe TensorFlow contrib module will not be included in TensorFlow 2.0.\r\nFor more information, please see:\r\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\r\n  * https://github.com/tensorflow/addons\r\n  * https://github.com/tensorflow/io (for I/O related ops)\r\nIf you depend on functionality not listed there, please file an issue.\r\n\r\nWARNING:tensorflow:From project4/data_loader.py:9: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\r\nWARNING:tensorflow:From /home/pdiene/.local/lib/python2.7/site-packages/tensorflow/python/training/input.py:278: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\r\nWARNING:tensorflow:From /home/pdiene/.local/lib/python2.7/site-packages/tensorflow/python/training/input.py:190: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\r\nWARNING:tensorflow:From /home/pdiene/.local/lib/python2.7/site-packages/tensorflow/python/training/input.py:199: __init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nTo construct input pipelines, use the `tf.data` module.\r\nWARNING:tensorflow:From /home/pdiene/.local/lib/python2.7/site-packages/tensorflow/python/training/input.py:199: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nTo construct input pipelines, use the `tf.data` module.\r\nWARNING:tensorflow:From project4/data_loader.py:11: __init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.TextLineDataset`.\r\nWARNING:tensorflow:From project4/data_loader.py:55: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\r\n\r\nWARNING:tensorflow:From project4/data_loader.py:66: The name tf.random_crop is deprecated. Please use tf.image.random_crop instead.\r\n", "I update the code like this \r\nimport tensorflow as tf\r\n\r\nfrom . import cyclegan_datasets\r\nfrom . import model\r\n\r\n\r\ndef _load_samples(csv_name, image_type):\r\n    filename_queue =  tf.compat.v1.train.string_input_producer(\r\n        [csv_name])\r\n\r\n    reader = tf.compat.v1.TextLineReader()\r\n    _, csv_filename = reader.read(filename_queue)\r\n\r\n    record_defaults = [tf.constant([], dtype=tf.string),\r\n                       tf.constant([], dtype=tf.string)]\r\n\r\n    filename_i, filename_j = tf.io.decode_csv(\r\n        records=csv_filename, record_defaults=record_defaults)\r\n\r\n    file_contents_i = tf.io.read_file(filename_i)\r\n    file_contents_j = tf.io.read_file(filename_j)\r\n    if image_type == '.jpg':\r\n        image_decoded_A = tf.image.decode_jpeg(\r\n            file_contents_i, channels=model.IMG_CHANNELS)\r\n        image_decoded_B = tf.image.decode_jpeg(\r\n            file_contents_j, channels=model.IMG_CHANNELS)\r\n    elif image_type == '.png':\r\n        image_decoded_A = tf.image.decode_png(\r\n            file_contents_i, channels=model.IMG_CHANNELS, dtype=tf.uint8)\r\n        image_decoded_B = tf.image.decode_png(\r\n            file_contents_j, channels=model.IMG_CHANNELS, dtype=tf.uint8)\r\n\r\n    return image_decoded_A, image_decoded_B\r\ndef load_data(dataset_name, image_size_before_crop,\r\n              do_shuffle=True, do_flipping=False):\r\n     \r\n    \"\"\"\r\n    :param dataset_name: The name of the dataset.\r\n    :param image_size_before_crop: Resize to this size before random cropping.\r\n    :param do_shuffle: Shuffle switch.\r\n    :param do_flipping: Flip switch.\r\n    :return:\r\n    \"\"\"\r\n    if dataset_name not in cyclegan_datasets.DATASET_TO_SIZES:\r\n        raise ValueError('split name %s was not recognized.'\r\n                         % dataset_name)\r\n\r\n    csv_name = cyclegan_datasets.PATH_TO_CSV[dataset_name]\r\n\r\n    image_i, image_j = _load_samples(\r\n        csv_name, cyclegan_datasets.DATASET_TO_IMAGETYPE[dataset_name])\r\n\r\n    # Preprocessing:\r\n    image_i = tf.image.resize(\r\n        image_i, [image_size_before_crop, image_size_before_crop])\r\n    image_j = tf.image.resize(\r\n        image_j, [image_size_before_crop, image_size_before_crop])\r\n\r\n    if do_flipping is True:\r\n        image_i = tf.image.random_flip_left_right(image_i)\r\n        image_j = tf.image.random_flip_left_right(image_j)\r\n\r\n    image_i = tf.image.random_crop(\r\n        image_i, [model.IMG_HEIGHT, model.IMG_WIDTH, 3])\r\n    image_j = tf.image.random_crop(\r\n        image_j, [model.IMG_HEIGHT, model.IMG_WIDTH, 3])\r\n\r\n    image_i = tf.subtract(tf.compat.v1.div(image_i, 127.5), 1)\r\n    image_j = tf.subtract(tf.compat.v1.div(image_j, 127.5), 1)\r\n\r\n    # Batch\r\n    if do_shuffle is True:\r\n        images_i, images_j = tf.compat.v1.train.shuffle_batch(\r\n            [image_i, image_j], 1, 5000, 100)\r\n    else:\r\n        images_i, images_j = tf.compat.v1.train.batch(\r\n            [image_i, image_j], 1)\r\n\r\n    inputs = {\r\n        'images_i': images_i,\r\n        'images_j': images_j\r\n    }\r\n\r\n    return inputs\r\nbut i have the same error \r\n\r\n", "@tensorflowbutler \r\nCode shared is full of [indentation errors](https://colab.research.google.com/gist/Saduf2019/c94b6dd0903441e6e1e834ab1299aa93/untitled575.ipynb), please share a colab gist with issue reported or simple stand alone indented code with all dependencies such that we can replicate the issue reported.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48013\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48013\">No</a>\n"]}, {"number": 48012, "title": "How to pass -add_postprocessing_op=true while using tflite_convert in tensorflow2.x", "body": "How we can pass -add_postprocessing_op=true while creating PB file for tflite_convert \r\n\r\npython object_detection/export_tflite_ssd_graph.py --pipeline_config_path=pipeline.config --trained_checkpoint_prefix=model.ckpt-4000 --output_directory=saved_model --add_postprocessing_op=true\r\n\r\nAbove scripts should output two files In saved_model directory: tflite_graph.pb and tflite_graph.pbtxt\r\n\r\nAbove script i used in tensorflow1.13 if it need to be changed or modify please share the solution, thanks in advance\r\n\r\nRegards\r\nVivek", "comments": ["Could you leave your question at the tensorflow/models repository, which owns the objection_detector scripts?\r\nThis repo is mainly for the TensorFlow project not the TF model garden.\r\nhttps://github.com/tensorflow/models"]}, {"number": 48011, "title": "How to generate tflite file for object detection on android in tensorflow 2.3", "body": "I am using SSD pretrained model ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8, I trained it on tensorflow 2.3, after checkpoint has been generated i have downloaded it on my windows machine.\r\n\r\nCan someone please share scripts require to generate tflite file for android, also following scripts works for me in tensorflow 1.13 which is not supported in 2.x\r\n\r\npython object_detection/export_tflite_ssd_graph.py --pipeline_config_path=pipeline.config --trained_checkpoint_prefix=model.ckpt-4000 --output_directory=saved_model --add_postprocessing_op=true\r\n\t\r\ntflite_convert --graph_def_file=tflite_graph.pb --output_file=saved_model.tflite --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor --output_arrays=TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3 --default_ranges_min=0 --default_ranges_max=255 --inference_type=QUANTIZED_UINT8 --mean_values=128 --std_dev_values=128 --change_concat_input_ranges=false --allow_custom_ops\r\n", "comments": ["Could you leave your question at the tensorflow/models repository, which owns the objection_detector scripts?\r\nThis repo is mainly for the TensorFlow project not the TF model garden.\r\nhttps://github.com/tensorflow/models\r\n", "How can i move it to tensorflow/models", "Maybe you can just upload a new issue at there and close."]}, {"number": 48010, "title": "Getting error in each second step in model training in gcloud tensorflow2.3 python 3.7, error - model_lib_v2.py:651", "body": "Hi while running a training job in gcloud, continuously getting following error in each step, why this is occurring and how to resolve it\r\n\r\nI 2021-03-23T10:34:36.455145835Z master-replica-0 Step 20900 per-step time 11.124s loss=1.705 master-replica-0 \r\nE 2021-03-23T10:34:36.455868005Z master-replica-0 I0323 10:34:36.455145 140138105964352 model_lib_v2.py:651] Step 20900 per-step time 11.124s loss=1.705 master-replica-0 \r\n{\r\n insertId: \"1m02xqjg250xpg0\"  \r\n jsonPayload: {\r\n  created: 1616495676.455868   \r\n  levelname: \"**ERROR**\"   \r\n  lineno: 328   \r\n  message: \"I0323 10:34:36.455145 140138105964352 model_lib_v2.py:651] Step 20900 per-step time 11.124s loss=1.705\"   \r\n  pathname: \"/runcloudml.py\"   \r\n }\r\n labels: {\u2026}  \r\n logName: \"projects/tuberculosis-240217/logs/master-replica-0\"  \r\n receiveTimestamp: \"2021-03-23T10:34:39.125659068Z\"  \r\n resource: {\u2026}  \r\n severity: \"ERROR\"  \r\n timestamp: \"2021-03-23T10:34:36.455868005Z\"  \r\n}\r\n\r\n", "comments": ["@vmishra2019 \r\nPlease provide minimal code such that we can reproduce the issues, can you first try to upgrade to stable version 2.4 and let us know if you face the issue.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 48009, "title": "Allow Server-Side Encryption KMS option when uploading objects to S3 with Tensorflow", "body": "\r\n**System information**\r\n- TensorFlow version (you are using): 2.4.1\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nProductive systems frequently impose a requirement to use server-side encryption (SSE) to protect all data stored on S3, e.g. via [AWS KMS](https://docs.aws.amazon.com/kms/latest/developerguide/services-s3.html).\r\n\r\nTensorflow (and tensorboard) has an integration with S3, but it does not seem to support specifying SSE options for write operations. \r\n\r\nIs there a way in the current tensorflow code to specify SSE options for file uploads to S3?\r\n\r\nIf not, I'd suggest to add such a feature, e.g. by exposing an environment variable for extra arguments to S3 file upload operations (S3_UPLOAD_EXTRA_ARGS).\r\n\r\nCurrent behaviour in this scenario is to issue an  error:\r\n`tensorflow.python.framework.errors_impl.FailedPreconditionError: AWS Credentials have not been set properly. Unable to access the specified S3 location [Op:CreateSummaryFileWriter]`\r\n\r\nwhen following this stock example but using an S3 bucket with SSE enabled: [link](https://www.tensorflow.org/tensorboard/get_started#using_tensorboard_with_keras_modelfit)\r\n\r\n\r\n**Will this change the current api? How?**\r\n\r\nThis would not change the current api if the function that uploads data to S3 reads an environment variable and passes relevant information on to AWS SDK.\r\n\r\n\r\n**Who will benefit with this feature?**\r\n\r\nAny users of Tensorflow in production systems as they will typically use server-side encryption (e.g. kms) with S3.\r\n\r\n", "comments": ["S3 filesystem is moving to SIG IO, as a plugin.", "> S3 filesystem is moving to SIG IO, as a plugin.\r\n\r\n@mihaimaruseac Crossposted this issue on tensorflow/io repository", "Thanks for tagging the newly created thread. It's better to maintain one issue for discussion,Therefore closing this issue for now. ", "Hi @ymodak @mihaimaruseac,\r\n\r\nTo get TensorFlow S3 writing to work with KMS on our productive system, I patched the TensorFlow C++ source code and built TensorFlow from source.\r\nThe GetTransferManager method in the s3_file_system.cc of the TensorFlow Release 2.4 branch was modified as follows:\r\n\r\n```C++\r\nstd::shared_ptr<Aws::Transfer::TransferManager>\r\nS3FileSystem::GetTransferManager(\r\n    const Aws::Transfer::TransferDirection& direction) {\r\n  std::shared_ptr<Aws::S3::S3Client> s3_client = this->GetS3Client();\r\n  std::lock_guard<mutex> lock(this->initialization_lock_);\r\n  if (this->transfer_managers_[direction].get() == nullptr) {\r\n    Aws::Transfer::TransferManagerConfiguration config(\r\n        this->GetExecutor().get());\r\n    config.s3Client = s3_client;\r\n\r\n    // Adding the following code: Allowing to enable KMS option\r\n    const char* kmsFlag = getenv(\"S3_ENABLE_KMS\");\r\n    Aws::String enableKms = \"0\";\r\n    if (kmsFlag) {\r\n      enableKms = Aws::String(kmsFlag);\r\n    }\r\n    if (enableKms == \"1\") {\r\n      config.createMultipartUploadTemplate.SetServerSideEncryption(Aws::S3::Model::ServerSideEncryption::aws_kms);\r\n      config.uploadPartTemplate.SetSSECustomerAlgorithm(\"aws_kms\");\r\n      config.putObjectTemplate.SetServerSideEncryption(Aws::S3::Model::ServerSideEncryption::aws_kms);\r\n    }     \r\n\r\n```\r\nThe crossposted tensorflow/io issue's conclusion is that S3 support for Server Side Encryption is only likely to release after Release 2.6.\r\n\r\nIs there interest in broadening the scope of this modification to support S3 writing with Server Side Encryption before TensorFlow 2.6?\r\n"]}, {"number": 48008, "title": "Split UniqueOpGPU compilation into multiple files", "body": "Avoids long single-file compilation time (>4 mins). No functional change.\r\n\r\ncc @nluehr @sanjoy ", "comments": ["@benbarsdell Can you please resolve conflicts? Thanks!", "Thank you @benbarsdell !\r\nI am finding that unique_op_gpu is taking forever to compile (going on 6 minutes... and this is a very fast machine...)\r\nThis will be much appreciated to merge this in.", "> @benbarsdell Can you please resolve conflicts? Thanks!\r\n\r\nDon't worry about this, I'll take care of it."]}, {"number": 48007, "title": "Converted Object Detection model trained with q-aware training still has fake quantization layers", "body": "### 1. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installation (pip package or built from source): pip\r\n- TensorFlow library (version, if pip package or github SHA, if built from source): 1.15\r\n\r\n### 2. Code\r\n\r\nI Trained a MobileNetV2SSD using the Object Detection API including this block:\r\n```\r\ngraph_rewriter {\r\n  quantization {\r\n    delay: 0\r\n    weight_bits: 8\r\n    activation_bits: 8\r\n  }\r\n}\r\n```\r\n\r\nThen I exported the model for tflite using the command `python object_detection/export_tflite_ssd_graph.py \r\n`.\r\nFinally, I converted to tflite using this code:\r\n```\r\nimport tensorflow as tf \r\nfrom PIL import Image\r\nimport numpy as np \r\nimport os\r\nimport sys\r\n\r\ndef _representative_dataset_gen(): \r\n    images_path = \"/work/data/repr_dataset\"\r\n    if images_path is None: \r\n        raise Exception( \r\n             \"Image directory is None, full integer quantization requires images directory!\" \r\n        ) \r\n    imagePaths = os.listdir((images_path)) \r\n    for p in imagePaths: \r\n        image = Image.open(os.path.join(images_path, p))\r\n        image = image.resize((300, 300)) \r\n        image = np.asarray(image)\r\n        image = np.expand_dims(image, axis=1) \r\n        image = image.reshape(1, 300, 300, 3)\r\n        yield [image.astype(\"float32\")]\r\n\r\nsaved_model_path = sys.argv[1] \r\ninput_arrays = [\"normalized_input_image_tensor\"] \r\noutput_arrays = ['TFLite_Detection_PostProcess', \r\n    'TFLite_Detection_PostProcess:1', \r\n    'TFLite_Detection_PostProcess:2', \r\n    'TFLite_Detection_PostProcess:3']\r\ninput_shapes = {\"normalized_input_image_tensor\" : [1, 300, 300, 3]} \r\nconverter = tf.lite.TFLiteConverter.from_frozen_graph(saved_model_path,input_arrays, \r\n     output_arrays, input_shapes) \r\nconverter.allow_custom_ops = True \r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT] \r\nconverter.representative_dataset = _representative_dataset_gen \r\n\r\n\r\ntflite_model_quant = converter.convert() \r\nwith open('quantized.tflite', \"wb\") as tflite_file: \r\n     tflite_file.write(tflite_model_quant)\r\n```\r\n\r\n### 3. Failure after conversion\r\nThe converted model includes quantization/dequantization/fake quantization layers:\r\n![quantized tflite](https://user-images.githubusercontent.com/8984671/112117585-cbd7e100-8bbb-11eb-8b20-325fb7f98365.png)\r\nAs a result, the inference time on an embedded system equipped with a NPU+NNAPI delegate is very high. I don't think this is normal. Is there a way to fix it?", "comments": ["@ethkim could you triage this issue?", "@FSet89,\r\nTensorFlow 1.x is not actively supported. Could you please update TensorFlow to the latest stable version v2.4.1 and check if you are facing the same issue. Thanks!", "> @FSet89,\r\n> TensorFlow 1.x is not actively supported. Could you please update TensorFlow to the latest stable version v2.4.1 and check if you are facing the same issue. Thanks!\r\n\r\n@amahendrakar  I just tried but the graph_rewrite option seems not to work on TF2, so I cannot test quantization-aware training on TF2", "@FSet89,\r\n\r\nWe are checking to see if this is still an issue, Can you check if this problem still persists with latest stable version of TF i.e `2.7.0`? You can also take a look at this [function](https://www.tensorflow.org/api_docs/python/tf/compat/v1/mixed_precision/enable_mixed_precision_graph_rewrite) from TF for graph_rewrite and let us know if that's what you're looking for.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48007\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48007\">No</a>\n"]}, {"number": 48006, "title": "Fix nms apis", "body": "```T_threshold``` is never used in the current kernel and it causes a bug when passing args without type-specific in float16 kernel. So I replace ```T_threshold``` with ```T```.\r\nUnfortunately, it breaks compatibility tests.", "comments": ["/CC @sanjoy @nluehr can you comment here?\r\n\r\nI'm pretty sure this does not break backwards compatibility if `T` and `T_threshold` must always be the same (which I have not verified myself). But to be safe, I think it's probably better to enforce they are the same on the Python level rather than changing the C++ op.", "Is it guaranteed that `T` and `T_threshold` are the same even for old savedmodels?  Adding in Cesar for advice.", "I dont' think that can be guaranteed, so I'm inclined to go with @reedwm's suggestion about doing at the Python level (at least as a first pass)."]}, {"number": 48004, "title": "MLIR binaries build fails due to missing dependency declaration", "body": "With the TF git version HEAD at \r\n\r\ncommit b725e835c68bb50bea582cac0aceeb828d3d6ea9 (HEAD -> master, origin/master, origin/HEAD)\r\nAuthor: A. Unique TensorFlower <gardener@tensorflow.org>\r\nDate:   Mon Mar 22 22:00:12 2021 -0700\r\n\r\n$ bazel build --copt=-UNDEBUG --linkopt='-fuse-ld=lld'  tensorflow/compiler/mlir:all\r\n\r\nyields:\r\n\r\n```\r\nINFO: Analyzed 15 targets (0 packages loaded, 0 targets configured).\r\nINFO: Found 15 targets...\r\nERROR: /home/uday/tensorflow-upstream/tensorflow/compiler/xla/service/gpu/BUILD:437:16: undeclared inclusion(s) in rule '//tensorflow/compiler/xla/service/gpu:nccl_collective_thunks':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/compiler/xla/service/gpu/nccl_all_gather_thunk.cc':\r\n  'bazel-out/k8-opt/bin/tensorflow/compiler/mlir/hlo/_virtual_includes/lhlo_ops_inc_gen/mlir-hlo/Dialect/mhlo/IR/lhlo_ops_structs.h.inc'\r\nINFO: Elapsed time: 39.406s, Critical Path: 36.14s\r\nINFO: 329 processes: 67 internal, 262 local.\r\n```\r\n\r\nSystem information\r\nUbuntu Linux 20.04.02 LTS\r\nbazel 3.7.2\r\ngcc (Ubuntu 9.3.0-17ubuntu1~20.04) 9.3.0\r\nTF configured with GPU/CUDA support\r\n\r\nCC: @jpienaar @joker-eph \r\n", "comments": ["This looks like a duplicate of https://github.com/tensorflow/tensorflow/issues/47386.\r\n\r\n@bondhugula, can you try doing \"bazel clean --expunge\" and then rebuilding? We are tracking this issue on the bazel side in https://github.com/bazelbuild/bazel/issues/13135.", "> This looks like a duplicate of #47386.\r\n> \r\n> @bondhugula, can you try doing \"bazel clean --expunge\" and then rebuilding? We are tracking this issue on the bazel side in [bazelbuild/bazel#13135](https://github.com/bazelbuild/bazel/issues/13135).\r\n\r\nThanks @jurahul - clean with expunging works. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48004\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48004\">No</a>\n"]}]