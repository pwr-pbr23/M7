[{"number": 15957, "title": "Switching branch and run ./configure does not regenerate spec.json", "body": "When building from source with TensorFlow and switch to another branch, error returned even if I rerun `./configure`:\r\n\r\n```\r\nubuntu@ubuntu:~/tensorflow$ bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\n..........\r\nubuntu@ubuntu:~/tensorflow$ git checkout -b test\r\nubuntu@ubuntu:~/tensorflow$ ./configure\r\n..........\r\nubuntu@ubuntu:~/tensorflow$ bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\n..........\r\nINFO: Analysed target //tensorflow/tools/pip_package:build_pip_package (252 packages loaded).\r\nINFO: Found 1 target...\r\nERROR: /home/ubuntu/tensorflow/tensorflow/core/BUILD:1671:1: Executing genrule //tensorflow/core:version_info_gen failed (Exit 1)\r\nTraceback (most recent call last):\r\n  File \"tensorflow/tools/git/gen_git_source.py\", line 284, in <module>\r\n    generate(args.generate)\r\n  File \"tensorflow/tools/git/gen_git_source.py\", line 229, in generate\r\n    (old_branch, new_branch))\r\nRuntimeError: Run ./configure again, branch was 'refs/heads/master' but is now 'refs/heads/test'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 9.025s, Critical Path: 0.30s\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\n\r\nI think the issue is that `spec.json` is not updated when running `./configure`\r\n\r\n\r\n```\r\nubuntu@ubuntu:~/tensorflow$ cat /home/ubuntu/.cache/bazel/_bazel_ubuntu/ad1e09741bb4109fbc70ef8216b59ee2/external/local_config_git/gen/spec.json\r\n{\r\n  \"path\": \"/home/ubuntu/.cache/bazel/_bazel_ubuntu/ad1e09741bb4109fbc70ef8216b59ee2/external/org_tensorflow/\", \r\n  \"git\": true, \r\n  \"branch\": \"refs/heads/master\"\r\n}\r\nubuntu@ubuntu:~/tensorflow$ \r\n```\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: master\r\n- **Python version**:  2.7.12\r\n- **Bazel version (if compiling from source)**: 0.9.0\r\n- **GCC/Compiler version (if compiling from source)**: gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.5) \r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**:\r\n\r\n```sh\r\ngit checkout -b test\r\n./configure\r\nbazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n  ", "comments": ["@jart could you take a look at this?", "@case540 This is a bug with git autoconf. I've reproduced it.\r\n\r\nThe quick fix would probably be to say `export TF_CONFIG_TIME=\"$(date)\"` in configure.py and add it to the `environ` list in git_configure.bzl.\r\n\r\nThe best fix might be to not call `repository_ctx.execute()` inside `git_configure`. Instead, consider having it only create symlinks (e.g. branch_ref, head) and then generate a BUILD file with a genrule that cats them into spec.json.", "@jart @case540 I added a PR #16196 to take a quick fix as suggested. Please take a look."]}, {"number": 15956, "title": "Tensorflow-lite breaks Android module. ", "body": "Inserting Tensorflow lite inside an android module/library like this:\r\n\r\n```\r\napply plugin: 'com.android.library'\r\n[some code]\r\n\r\ndependencies {\r\n    compile fileTree(dir: 'libs', include: ['*.jar'])\r\n\r\n    implementation 'org.tensorflow:tensorflow-lite:+'\r\n}\r\n```\r\n\r\nResults in this error when including the module and trying to running for Android API 19:\r\n\r\n> Error:Error converting bytecode to dex:\r\n> Cause: com.android.dex.DexException: Multiple dex files define LR;\r\n\r\nThe module I am trying to include contains no classes, files  or other dependencies. All it has I a dependency of Tensorflow-lite. If I insert tensorflow lite directly inside the app, the problem goes away. \r\n\r\nThe problem doesn't happen in API 21+, and it only happens for API <= 19\r\n\r\nI am using android gradle plugin 3.0.1, but I also trying with 3.1.0-alpha-04/5/6/7. \r\n\r\nIs there a solution or work around to this problem?\r\n", "comments": ["@aselle @andrehentz @petewarden have you seen things like this?", "No solution yet, but one workaround is to revert to gradle 2.3.3.", "Hi @andrehentz, thanks for the response! This workaround doesn't work due to this issue: [https://github.com/tensorflow/tensorflow/issues/15699](https://github.com/tensorflow/tensorflow/issues/15699)\r\n\r\nI believe this happens because TensorFlow lite is built using Java 8. ", "Hi folks, I can see that there's an commit fixing to problem. Is there a tutorial teaching how to compile the TF lite into a Android library, so I can use the commit? The READ teaches how to compile the app, but doesn't give much information about the tensorflow lite as a jar. ", "We are working on scripting this step. For now, you can try placing the following script in tensorflow/contrib/lite/java. You should be able to invoke it from your toplevel tensorflow dir.\r\n\r\n```\r\n#!/bin/bash\r\n# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\r\n#\r\n# Licensed under the Apache License, Version 2.0 (the \"License\");\r\n# you may not use this file except in compliance with the License.\r\n# You may obtain a copy of the License at\r\n#\r\n#     http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n# Unless required by applicable law or agreed to in writing, software\r\n# distributed under the License is distributed on an \"AS IS\" BASIS,\r\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n# See the License for the specific language governing permissions and\r\n# limitations under the License.\r\n# ==============================================================================\r\nset -e\r\nset -x\r\n\r\nTMPDIR=`mktemp -d`\r\ntrap \"rm -rf $TMPDIR\" EXIT\r\n\r\nVERSION=1.0\r\n\r\nBUILDER=bazel\r\nBASEDIR=tensorflow/contrib/lite\r\nCROSSTOOL=\"//external:android/crosstool\"\r\nHOST_CROSSTOOL=\"@bazel_tools//tools/cpp:toolchain\"\r\n\r\nBUILD_OPTS=\"--cxxopt=--std=c++11 -c opt\"\r\nCROSSTOOL_OPTS=\"--crosstool_top=$CROSSTOOL --host_crosstool_top=$HOST_CROSSTOOL\"\r\n\r\ntest -d $BASEDIR || (echo \"Aborting: not at top-level build directory\"; exit 1)\r\n\r\nfunction build_basic_aar() {\r\n  local OUTDIR=$1\r\n  $BUILDER build $BUILD_OPTS $BASEDIR/java:tensorflowlite.aar\r\n  unzip -d $OUTDIR $BUILDER-bin/$BASEDIR/java/tensorflowlite.aar\r\n  # targetSdkVersion is here to prevent the app from requesting spurious\r\n  # permissions, such as permission to make phone calls. It worked for v1.0,\r\n  # but minSdkVersion might be the preferred way to handle this.\r\n  sed -i -e 's/<application>/<uses-sdk android:targetSdkVersion=\"25\"\\/><application>/' $OUTDIR/AndroidManifest.xml\r\n}\r\n\r\nfunction build_arch() {\r\n  local ARCH=$1\r\n  local CONFIG=$2\r\n  local OUTDIR=$3\r\n  mkdir -p $OUTDIR/jni/$ARCH/\r\n  $BUILDER build $BUILD_OPTS $CROSSTOOL_OPTS --cpu=$CONFIG \\\r\n    $BASEDIR/java:libtensorflowlite_jni.so\r\n  cp $BUILDER-bin/$BASEDIR/java/libtensorflowlite_jni.so $OUTDIR/jni/$ARCH/\r\n}\r\n\r\nrm -rf $TMPDIR\r\nmkdir -p $TMPDIR/jni\r\n\r\nbuild_basic_aar $TMPDIR\r\nbuild_arch arm64-v8a arm64-v8a $TMPDIR\r\nbuild_arch armeabi-v7a armeabi-v7a $TMPDIR\r\nbuild_arch x86 x86 $TMPDIR\r\nbuild_arch x86_64 x86_64 $TMPDIR\r\n\r\nAAR_FILE=`realpath tflite-${VERSION}.aar`\r\n(cd $TMPDIR && zip $AAR_FILE -r *)\r\necho \"New AAR file is $AAR_FILE\"\r\n```\r\n", "Hello, thanks for the fast response and for the great library. I ran the script and built a version of tensorflow in my machine (Note: it only works with NDK 14b, as explained in the README of TF life). \r\n\r\nI included the tensorflow-1.0.aar in my android project, but the problem persists. I still get the error for AGP 3.1.0-alpha08:\r\n\r\nError:Program type already present: R.", "@leandroBorgesFerreira So you did exclude the official version of tensorflow-lite:0.1.1 dependency right? Also, could you unzip your aar to see if AndroidManifest.xml looks something like:\r\n \\<manifest xmlns:android=\"http://schemas.android.com/apk/res/android\"\r\n          package=\"org.tensorflow.lite\"\\>\r\n(without the fix, it was package=\"\")\r\n\r\nAlso, there's a new target checked in yesterday. See commit here:\r\nhttps://github.com/tensorflow/tensorflow/commit/eee4473a676886c3193960cba0966fc078974c33#diff-ec9dc59500edaf4e99c2a4fde3ff5ac1\r\n\r\nYou can sync pass that commit and try the bazel command there. I had a similar setup as you did (use a library to depend on TensorFlow lite). I could repro and I verified the fix w/ the aar built out by that latest target.", "@isaisachen I just unziped the aar and the package is still \"\", so I am not compiling the latest version. I just ran the script presented by andrehentz and the aar was generated, did you compiled tensorflow in some different way?", "Never mind totally works, I was being just dumb hahaha. Thanks for the help folks!", "@leandroBorgesFerreira Great to hear it works now.\r\n\r\nre:\"did you compiled tensorflow in some different way\" - As I mentioned earlier, a new target has been added and you can simply run below command to build the aar. But it's doing almost the same thing as the script provided by andrehentz:\r\n\r\nbazel build --cxxopt='--std=c++11' -c opt --fat_apk_cpu=x86,x86_64,arm64-v8a,armeabi-v7a tensorflow/contrib/lite/java:tensorflow-lite "]}, {"number": 15955, "title": "Branch 181174976", "body": "", "comments": ["@tensorflow-jenkins, test this please.", "The 5 tests that failed passes when I `bazel test`ed them from my own branch.\r\n\r\n```\r\n$ bazel test //tensorflow/python/debug:analyzer_cli_test //tensorflow/python/debug:curses_ui_test //tensorflow/python/debug:tensor_format_test //tensorflow/python/eager:tensor_test //tensorflow/python:special_math_ops_test\r\n...\r\n//tensorflow/python:special_math_ops_test                                PASSED in 2.5s\r\n//tensorflow/python/debug:analyzer_cli_test                              PASSED in 2.4s\r\n//tensorflow/python/debug:curses_ui_test                                 PASSED in 1.0s\r\n//tensorflow/python/debug:tensor_format_test                             PASSED in 0.8s\r\n//tensorflow/python/eager:tensor_test                                    PASSED in 1.0s\r\n```\r\n  \r\n  ", "@tensorflow-jenkins, test this please.", "The failing tests are disabled via internal commit 181212111. This will get propagated externally with the next daily push."]}, {"number": 15954, "title": "TypeError: Input 'split_dim' of 'Split' Op has type float32 ", "body": "Hi,\r\n\r\nI use Tensorflow 1.5.0rc0  on windows (Python 3.5.2 )and I have this issue: \r\nTypeError: Input 'split_dim' of 'Split' Op has type float32 that does not match expected type of int32. I have seen some answers for older versions of tensor flow but is there any fix for the new version?\r\n\r\n", "comments": ["Can you please tell us how to reproduce your problem? What did you run, and what does the entire error output look like?\r\n\r\nPlease provide details about what platform you are using  (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?  Make sure you also include the exact command if possible to produce  the output included in your test case. If you are unclear what to include  see the issue template displayed in  [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n\r\n We ask for this in the issue submission template, because    it is really difficult to help without that information. Thanks!", "### System information\r\n- Windows 7\r\n- TensorFlow 1.4 installed with pip and then upgraded to 1.5.0-rc0 \r\n- TensorFlow version 1.5.0-rc0\r\n- Python version 3.5.2\r\n\r\n### Problem\r\nI am using the code for social LSTM (long short-term memory) which you can find here: https://github.com/vvanirudh/social-lstm-tf\r\n\r\nwhen I want to train my model, no matter whether it is a normal or social LSTM I get the following error. \r\n### Error\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\ga67zod\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 510, in _apply_op_helper\r\n    preferred_dtype=default_dtype)\r\n  File \"C:\\Users\\ga67zod\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1013, in internal_convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"C:\\Users\\ga67zod\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 857, in _TensorTensorConversionFunction\r\n    (dtype.name, t.dtype.name, str(t)))\r\nValueError: Tensor conversion requested dtype int32 for Tensor with dtype float32: 'Tensor(\"Placeholder:0\", shape=(?, 8, 2), dtype=float32)'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\ga67zod\\Desktop\\social-lstm-tf\\lstm\\train.py\", line 125, in <module>\r\n    main()\r\n  File \"C:\\Users\\ga67zod\\Desktop\\social-lstm-tf\\lstm\\train.py\", line 60, in main\r\n    train(args)\r\n  File \"C:\\Users\\ga67zod\\Desktop\\social-lstm-tf\\lstm\\train.py\", line 77, in train\r\n    model = Model(args)\r\n  File \"C:\\Users\\ga67zod\\Desktop\\social-lstm-tf\\lstm\\model.py\", line 80, in __init__\r\n    inputs = tf.split(1, args.seq_length, self.input_data)\r\n  File \"C:\\Users\\ga67zod\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1330, in split\r\n    axis=axis, num_split=num_or_size_splits, value=value, name=name)\r\n  File \"C:\\Users\\ga67zod\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 6922, in _split\r\n    \"Split\", split_dim=axis, value=value, num_split=num_split, name=name)\r\n  File \"C:\\Users\\ga67zod\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 533, in _apply_op_helper\r\n    (prefix, dtypes.as_dtype(input_arg.type).name))\r\nTypeError: Input 'split_dim' of 'Split' Op has type float32 that does not match expected type of int32.\r\n\r\nHere you can find the code for Training the model: \r\n### Source code / logs\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport argparse\r\nimport os\r\nimport time\r\nimport pickle\r\nfrom model import Model\r\nfrom utils import DataLoader\r\n\r\ndef main():\r\n    parser = argparse.ArgumentParser()\r\n    # RNN size parameter (dimension of the output/hidden state)\r\n    parser.add_argument('--rnn_size', type=int, default=128,\r\n                        help='size of RNN hidden state')\r\n    # Number of layers parameter\r\n    # TODO: (improve) Number of layers not used. Only a single layer implemented\r\n    parser.add_argument('--num_layers', type=int, default=1,\r\n                        help='number of layers in the RNN')\r\n    # Type of recurrent unit parameter\r\n    # Model currently not used. Only LSTM implemented\r\n    parser.add_argument('--model', type=str, default='lstm',\r\n                        help='rnn, gru, or lstm')\r\n    # Size of each batch parameter\r\n    parser.add_argument('--batch_size', type=int, default=50,\r\n                        help='minibatch size')\r\n    # Length of sequence to be considered parameter\r\n    parser.add_argument('--seq_length', type=int, default=8,\r\n                        help='RNN sequence length')\r\n    # Number of epochs parameter\r\n    parser.add_argument('--num_epochs', type=int, default=100,\r\n                        help='number of epochs')\r\n    # Frequency at which the model should be saved parameter\r\n    parser.add_argument('--save_every', type=int, default=400,\r\n                        help='save frequency')\r\n    # Gradient value at which it should be clipped\r\n    # TODO: (resolve) Clipping gradients for now. No idea whether we should\r\n    parser.add_argument('--grad_clip', type=float, default=10.,\r\n                        help='clip gradients at this value')\r\n    # Learning rate parameter\r\n    parser.add_argument('--learning_rate', type=float, default=0.003,\r\n                        help='learning rate')\r\n    # Decay rate for the learning rate parameter\r\n    parser.add_argument('--decay_rate', type=float, default=0.95,\r\n                        help='decay rate for rmsprop')\r\n    # Dropout probability parameter\r\n    # Dropout not implemented.\r\n    parser.add_argument('--keep_prob', type=float, default=0.8,\r\n                        help='dropout keep probability')\r\n    # Dimension of the embeddings parameter\r\n    parser.add_argument('--embedding_size', type=int, default=128,\r\n                        help='Embedding dimension for the spatial coordinates')\r\n    parser.add_argument('--leaveDataset', type=int, default=3,\r\n                        help='The dataset index to be left out in training')\r\n    # Lambda regularization parameter (L2)\r\n    parser.add_argument('--lambda_param', type=float, default=0.05,\r\n                        help='L2 regularization parameter')\r\n    args = parser.parse_args()\r\n    train(args)\r\n\r\n\r\ndef train(args):\r\n    datasets = list(range(4))\r\n    # Remove the leaveDataset from datasets\r\n    datasets.remove(args.leaveDataset)\r\n\r\n    # Create the data loader object. This object would preprocess the data in terms of\r\n    # batches each of size args.batch_size, of length args.seq_length\r\n    data_loader = DataLoader(args.batch_size, args.seq_length, datasets, forcePreProcess=True)\r\n\r\n    # Save the arguments int the config file\r\n    with open(os.path.join('save_lstm', 'config.pkl'), 'wb') as f:\r\n        pickle.dump(args, f)\r\n\r\n    # Create a Vanilla LSTM model with the arguments\r\n    model = Model(args)\r\n\r\n    # Initialize a TensorFlow session\r\n    with tf.Session() as sess:\r\n        # Initialize all the variables in the graph\r\n        sess.run(tf.initialize_all_variables())\r\n        # Add all the variables to the list of variables to be saved\r\n        saver = tf.train.Saver(tf.all_variables())\r\n\r\n        # For each epoch\r\n        for e in range(args.num_epochs):\r\n            # Assign the learning rate (decayed acc. to the epoch number)\r\n            sess.run(tf.assign(model.lr, args.learning_rate * (args.decay_rate ** e)))\r\n            # Reset the pointers in the data loader object\r\n            data_loader.reset_batch_pointer()\r\n            # Get the initial cell state of the LSTM\r\n            state = sess.run(model.initial_state)\r\n\r\n            # For each batch in this epoch\r\n            for b in range(data_loader.num_batches):\r\n                # Tic\r\n                start = time.time()\r\n                # Get the source and target data of the current batch\r\n                # x has the source data, y has the target data\r\n                x, y = data_loader.next_batch()\r\n\r\n                # Feed the source, target data and the initial LSTM state to the model\r\n                feed = {model.input_data: x, model.target_data: y, model.initial_state: state}\r\n                # Fetch the loss of the model on this batch, the final LSTM state from the session\r\n                train_loss, state, _ = sess.run([model.cost, model.final_state, model.train_op], feed)\r\n                # Toc\r\n                end = time.time()\r\n                # Print epoch, batch, loss and time taken\r\n                print(\r\n                    \"{}/{} (epoch {}), train_loss = {:.3f}, time/batch = {:.3f}\"\r\n                    .format(\r\n                        e * data_loader.num_batches + b,\r\n                        args.num_epochs * data_loader.num_batches,\r\n                        e,\r\n                        train_loss, end - start))\r\n\r\n                # Save the model if the current epoch and batch number match the frequency\r\n                if (e * data_loader.num_batches + b) % args.save_every == 0 and ((e * data_loader.num_batches + b) > 0):\r\n                    checkpoint_path = os.path.join('save_lstm', 'model.ckpt')\r\n                    saver.save(sess, checkpoint_path, global_step=e * data_loader.num_batches + b)\r\n                    print(\"model saved to {}\".format(checkpoint_path))\r\nif __name__ == '__main__':\r\n    main()\r\n\r\n###\r\nThank you in advance,\r\nNassim", "Any chance that this update, in the 1.5.0 release notes, affected your code: \r\n\r\ntf.split now takes arguments in a reversed order and with different\r\nkeywords. In particular, we now match NumPy order as\r\ntf.split(value, num_or_size_splits, axis).\r\n", "Thank you, that was it! "]}, {"number": 15953, "title": "tf.Print() re/direction", "body": "## Feature Request\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A\r\n- **TensorFlow installed from (source or binary)**: N/A\r\n- **TensorFlow version (use command below)**: latest (1.5.0-rc0)\r\n- **Python version**:  N/A\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\nhttps://github.com/tensorflow/tensorflow/blob/a77096897f1a8068ca8f57ffb6e3d9e28508cc27/tensorflow/core/platform/default/logging.cc#L89\r\nIt would be nice to be able to direct the string to a log file instead of `stderr` (following the **TODO** in the code)\r\n\r\n  ", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "reposting for the butler\r\nSystem information\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): N/A\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): N/A\r\nTensorFlow installed from (source or binary): N/A\r\nTensorFlow version (use command below): latest (1.5.0-rc0)\r\nPython version: N/A\r\nBazel version (if compiling from source): N/A\r\nGCC/Compiler version (if compiling from source): N/A\r\nCUDA/cuDNN version: N/A\r\nGPU model and memory: N/A\r\nExact command to reproduce: N/A", "It seems like a good idea to have an environmental variable, say TF_LOG_FILE, where setting it would append logs to that file.\r\n\r\n/CC @ebrevdo, @petewarden what do you think of this idea?", "What about if instead it would go to Python `logging` interface? Tensorflow is already using it for Python part of the code, so maybe C code can interact with that and send it that way?", "I considered using `tf.py_func()` for logging but was afraid it would cause a slow down.", "How often does C code log something in comparison with Python code?\r\n\r\nMaybe it could be a setting based on env variable? In our case it would be great if we could ingest all the messages from all our workers and store them together and we are currently using Python logging for that.", "I won't have cycles to work on this; so unassigning for triage.", "I haven't done any work on the logging, outside of mobile devices, so unassigning myself so that it can be triaged.", "@asimshankar would you find someone to assign this too who will be willing to take it on, or else close it?", "@tomerk is exploring some improvements to `tf.Print` in general, so assigning to him to evaluate whether we'd want to take this on.", "Nagging Assignee @tomerk: It has been 59 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Let's move this conversation here:https://github.com/tensorflow/community/pull/14"]}, {"number": 15952, "title": "LSTM in eager is 15 slower than in tensorflow on CPU", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.3.0-rc1-6744-gf99275a 1.6.0-dev20180105\r\n- **Python version**: 3.5.2\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: none\r\n- **GPU model and memory**: none\r\n- **Exact command to reproduce**: \r\n\r\n```\r\ngit clone https://gist.github.com/idavydov/1060b3fae833af436cdad11913c9e7e1\r\ncd 1060b3fae833af436cdad11913c9e7e1\r\ntime python lstm_test_tensorflow.py\r\ntime python lstm_test_eager.py\r\n```\r\n\r\n### Describe the problem\r\nLSTM in eager seeems to work 15 times slower than LSTM in tensorflow, when running on CPU (`tf.nn.dynamic_rnn`).  Tensorflow time: 9s, eager time: 149s.\r\n\r\n### Source code / logs\r\n## lstm_test_tensorflow.py\r\n```\r\n#!/usr/bin/env python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n\r\n# use 1 CPU\r\nconf=tf.ConfigProto(\r\n    intra_op_parallelism_threads=1,\r\n    inter_op_parallelism_threads=1)\r\n\r\nn_iter = 100\r\n\r\nn_layers = 2\r\n\r\nbatch_size = 32\r\nseq_len = 1000\r\ninput_dim = 7\r\ndata = np.random.uniform(size=(batch_size, seq_len, input_dim))\r\n\r\nx = tf.placeholder(tf.float32, shape=(batch_size, seq_len, input_dim))\r\n\r\ncells = [tf.contrib.rnn.LSTMCell(input_dim) for _ in range(n_layers)]\r\nmulticell = tf.contrib.rnn.MultiRNNCell(cells)\r\nrnn_outputs, final_state = tf.nn.dynamic_rnn(multicell, x, dtype=tf.float32)\r\n\r\ninit = tf.global_variables_initializer()\r\n\r\nwith tf.Session(config=conf) as sess:\r\n    sess.run(init)\r\n    for _ in range(n_iter):\r\n        sess.run(rnn_outputs, {x: data})\r\n```\r\n\r\n## lstm_test_eager.py\r\n```\r\n#!/usr/bin/env python\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.eager as tfe\r\n\r\n# use 1 CPU\r\nconf=tf.ConfigProto(\r\n    intra_op_parallelism_threads=1,\r\n    inter_op_parallelism_threads=1)\r\n\r\ntfe.enable_eager_execution(conf)\r\n\r\nn_iter = 100\r\n\r\nn_layers = 2\r\n\r\nbatch_size = 32\r\nseq_len = 1000\r\ninput_dim = 7\r\ndata = tf.random_uniform((batch_size, seq_len, input_dim))\r\n\r\ncells = [tf.contrib.rnn.LSTMCell(input_dim) for _ in range(n_layers)]\r\nmulticell = tf.contrib.rnn.MultiRNNCell(cells)\r\n\r\n\r\nfor _ in range(n_iter):\r\n    tf.nn.dynamic_rnn(multicell, data, dtype=tf.float32)\r\n```", "comments": ["I've got a helpful [feedback](https://www.reddit.com/r/MachineLearning/comments/7p057n/d_are_lstms_in_pytorch_3_times_slower_than_in/) on reddit. It seems that this LSTM size is unusually small (only seven inputs).\r\n\r\nIf `input_dim` is set to 300, and config is not used (eager does seem to respect `intra_op_parallelism_threads` and `inter_op_parallelism_threads`), CPU time is comparable."]}, {"number": 15951, "title": "[Build] Source build at HEAD generating XLA erros on Mac OS", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS High Sierra\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: HEAD@a770968\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: 0.9.0\r\n- **GCC/Compiler version (if compiling from source)**: 9.0.0\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: Build procedures on doc optimized for native arch and XLA enabled.\r\n\r\n### Describe the problem\r\nBuilding TensorFlow on Mac OS with XLA enabled and configuration given above optimized for native arch and CPU only yields the following errors:\r\n```\r\nERROR: /Users/adriano/MachineLearning/tensorflow/tensorflow/compiler/xla/service/cpu/BUILD:522:1: C++ compilation of rule '//tensorflow/compiler/xla/service/cpu:runtime_fft' failed (Exit 1)\r\nIn file included from tensorflow/compiler/xla/service/cpu/runtime_fft.cc:21:\r\n./tensorflow/compiler/xla/service/cpu/runtime_fft_impl.h:42:30: error: implicit instantiation of undefined template 'std::__1::array<long long, 3>'\r\n  const std::array<int64, 3> fft_shape = {\r\n                             ^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/__tuple:222:64: note: template is declared here\r\ntemplate <class _Tp, size_t _Size> struct _LIBCPP_TEMPLATE_VIS array;\r\n                                                               ^\r\nIn file included from tensorflow/compiler/xla/service/cpu/runtime_fft.cc:21:\r\n./tensorflow/compiler/xla/service/cpu/runtime_fft_impl.h:65:30: error: implicit instantiation of undefined template 'std::__1::array<long long, 3>'\r\n  const std::array<int64, 3> fft_shape = {\r\n                             ^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/__tuple:222:64: note: template is declared here\r\ntemplate <class _Tp, size_t _Size> struct _LIBCPP_TEMPLATE_VIS array;\r\n                                                               ^\r\nIn file included from tensorflow/compiler/xla/service/cpu/runtime_fft.cc:21:\r\n./tensorflow/compiler/xla/service/cpu/runtime_fft_impl.h:106:30: error: implicit instantiation of undefined template 'std::__1::array<long long, 3>'\r\n  const std::array<int64, 3> fft_shape = {\r\n                             ^\r\n/Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/include/c++/v1/__tuple:222:64: note: template is declared here\r\ntemplate <class _Tp, size_t _Size> struct _LIBCPP_TEMPLATE_VIS array;\r\n                                                               ^\r\n3 errors generated.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 1997.286s, Critical Path: 88.18s\r\nFAILED: Build did NOT complete successfully\r\n\r\n```\r\n", "comments": ["Hopefully resolved by CL 181506335, which adds \"#include <array>\" to the runtime_fft_impl.h file. LMK if that doesn't work.", "@brianwa84 Cool, thanks!"]}, {"number": 15950, "title": "Update 1_notmnist.ipynb", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address on your commit.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot. The email used to register you as an authorized contributor must be the email used for the Git commit.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_sender_cla -->"]}, {"number": 15949, "title": "Building TensorFlow on Windows: patch and rm", "body": "### System information\r\n- **Have I written custom code**: Yes, provided below.\r\n- **OS Platform and Distribution**: Windows 10 1709, Build 16299.192\r\n- **TensorFlow installed from (source or binary)**: Binary, Attempting source build of master\r\n- **TensorFlow version**: 1.4.0\r\n- **Python version**: 3.6\r\n- **Bazel version**:  0.9.0\r\n- **GCC/Compiler version**:  MSYS2 Shell, GCC unknown.\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A, CPU is i7-8550U, 8 GB memory\r\n- **Exact command to reproduce**: Any `bazel build` on Windows. Please see Description.\r\n\r\n### Describe the problem\r\nBuilding TensorFlow on Windows has been a struggle with compatibility due to the fact that for many, MSYS will not run `patch` when installed from the MSYS2 shell. I have found a reliable way to resolve the issue: using Choco to install `patch`, moving patch.exe to a folder FOLDERNAME within its default directory, and then running %FOLDERNAME%/patch.exe with the flag `--binary` (to use CR LF line breaks) with a custom batch script compiled into a executable.\r\n\r\n`bazel build` now completes `patch` commands without issue. But as it often is, another hurdle exists to the finish line. Bazel now attempts to recursively force remove a file using `rm -rf`, which obviously does not exist as a package in Choco as a bash command. MSYS will run it, but not from the command line.\r\n\r\nIs there any way to get around the use of `rm`, or make a compatible solution for Windows using `del`?\r\n\r\nI have ensured that #15829 has been installed. Still fails\r\n\r\nIf this is better left to the Bazel developers, please close this issue. \r\n\r\n### Source code\r\n\r\n#### patch.bat\r\n``` sh\r\nstart C:\\ProgramData\\chocolatey\\lib\\patch\\tools\\bin\\%FOLDERNAME%\\patch.exe --binary\r\nexit\r\n```\r\n\r\n### Logs\r\n``` sh\r\nC:\\tensorflow>bazel build --config=mkl --config=monolithic -c opt --copt=-march=native --copt=-mmmx --copt=-msse --copt=-msse2 --copt=-msse3 --copt=-mssse3 --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-mavx2 --copt=-maes --copt=-mfpmath=both //tensorflow/tools/pip_package:build_pip_package\r\n#ERROR: C:/tensorflow/tensorflow/python/BUILD:4646:1: no such package '@cython//': Traceback (most recent call last):\r\n        File \"C:/tensorflow/third_party/repo.bzl\", line 86\r\n                _apply_delete(ctx, ctx.attr.delete)\r\n        File \"C:/tensorflow/third_party/repo.bzl\", line 68, in _apply_delete\r\n                _execute_and_check_ret_code(ctx, cmd)\r\n        File \"C:/tensorflow/third_party/repo.bzl\", line 44, in _execute_and_check_ret_code\r\n                fail(\"Non-zero return code({1}) when ...))\r\nNon-zero return code(127) when executing 'C:\\msys64\\usr\\bin\\bash.exe -c rm -rf C:/users/eric/appdata/local/temp/_bazel_eric/x1e5egqw/external/cython/BUILD.bazel':\r\nStdout:\r\nStderr: /usr/bin/bash: rm: command not found\r\n and referenced by '//tensorflow/python:framework/fast_tensor_util.pyx_cython_translation'\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: Loading failed\r\nINFO: Elapsed time: 61.324s\r\nFAILED: Build did NOT complete successfully (92 packages loaded)\r\n```\r\n\r\n  ", "comments": ["@mrry could you take a look into this or redirect?", "@meteorcloudy Is this a known issue with the Bazel/Windows build?", "This happens because `C:\\msys64\\usr\\bin` is not in your PATH environment variable. So all Bash commands  (eg. rm, ls, cat ...) couldn't be found.\r\n\r\nThere are two workarounds for this:\r\n- `set PATH=%PATH%;c:\\msys64\\usr\\bin`, then run `bazel shutdown` to make bazel pick up the new PATH value\r\n- Run Bazel in MSYS terminal so that necessary directories are already added into PATH.\r\n\r\nIdeally, we should replace all usages of shell command to batch command(native on Windows). But due to the functionality of batch is very limited, we still have to rely on Bash for a while.\r\n\r\n", "Hello @EricHallahan  did you solve the problem? I also got the same error as yours while `'C:\\msys64\\usr\\bin'` is also in my PATH.  I am on Windows 7, Python3.6, Bazel 0.21, Tensorflow: master brach (without any modification). I am trying to build without cuda, without ROCm. ", "My personal solution was to use Windows Subsystem for Linux instead. Obviously, that does not exist on Windows 7.", "I found that this issue appears if HDD is busy by something else, for example torrents."]}, {"number": 15948, "title": "Error converting to .tflite Using Toco", "body": "### System information\r\n- **Have I written custom code**: Yes. See network definition code [here](https://gist.github.com/OluwoleOyetoke/30f2cac788042c495f1ae34a6b742a1d). For complete project, see [here](https://github.com/OluwoleOyetoke/Computer_Vision_Using_TensorFlowLite)\r\n- **OS Platform and Distribution**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: Yes\r\n- **TensorFlow version (use command below)**: tensorflow (1.4.0)\r\n- **Python version**:  Python 2.7.12\r\n- **Bazel version (if compiling from source)**: Bazel 0.9.0\r\n- **GCC/Compiler version (if compiling from source)**: gcc 5.4.1 20160904\r\n- **CUDA/cuDNN version**: Null\r\n- **GPU model and memory**: Null\r\n- **Exact command to reproduce**: bazel-bin/tensorflow/contrib/lite/toco/toco --input_format=TENSORFLOW_GRAPHDEF --input_file=$1 --output_format=TFLITE --output_file=$2 --inference_type=$3 --#input_type=$4 --input_arrays=$5 --output_arrays=$6 --inference_input_type=$7 --input_shapes=1,227,227,3\r\n\r\n### Problem Description, Source Code and Logs\r\nWhen I try to use Toco to convert my Custom AlexNet Model from TensorFlow to TensorFlowLite, I repeatedly get a dimensions error as shown below\r\n\r\n    F tensorflow/contrib/lite/toco/graph_transformations/propagate_fixed_sizes.cc:982] Check failed: input_dims.size() == 4 (2 vs. 4)\r\n\r\nHere is how I call toco:\r\n\r\n    bazel-bin/tensorflow/contrib/lite/toco/toco \\\r\n    --input_format=TENSORFLOW_GRAPHDEF \\\r\n    --input_file=/tmp/output_graph.pb \\\r\n    --output_format=TFLITE \\\r\n    --output_file=/tmp/my_model.lite \\\r\n    --inference_type=FLOAT \\\r\n    --inference_input_type=FLOAT \\\r\n    --input_arrays=input_layer \\\r\n    --output_arrays=classes_tensor\\\r\n    --input_shapes=1,227,227,3\r\n\r\nHere is my terminal print out during the operation: \r\n\r\n    INFO: Analysed 0 targets (4 packages loaded).\r\n    INFO: Found 0 targets...\r\n    INFO: Elapsed time: 5.267s, Critical Path: 0.03s\r\n    INFO: Build completed successfully, 1 total action\r\n    2018-01-05 10:24:23.011483: W tensorflow/contrib/lite/toco/toco_cmdline_flags.cc:178] --input_type is deprecated. It was an ambiguous flag that set both --input_data_types and --inference_input_type. If you are trying to complement the input file with information about the type of input arrays, use --input_data_type. If you are trying to control the quantization/dequantization of real-numbers input arrays in the output file, use --inference_input_type.\r\n    2018-01-05 10:24:25.853112: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: IsVariableInitialized\r\n    2018-01-05 10:24:25.853197: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RefSwitch\r\n    2018-01-05 10:24:25.853241: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: RandomShuffleQueueV2\r\n    2018-01-05 10:24:25.853268: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1122] Converting unsupported operation: QueueDequeueUpToV2\r\n    2018-01-05 10:24:26.207160: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 64 operators, 90 arrays (0 quantized)\r\n    2018-01-05 10:24:27.327055: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 15 operators, 33 arrays (0 quantized)\r\n    2018-01-05 10:24:27.327262: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 15 operators, 34 arrays (0 quantized)\r\n    2018-01-05 10:24:27.327356: F tensorflow/contrib/lite/toco/graph_transformations/propagate_fixed_sizes.cc:982] Check failed: input_dims.size() == 4 (2 vs. 4)\r\n    /home/olu/Dev/scratch_train_sign/freeze_graph_tf.sh: line 28:  8881 Aborted \r\n\r\nI went into the propagate_fixed_sizes.cc file, and around line line 982 I found this comment below\r\n\r\n    // The current ArgMax implementation only supports 4-dimensional inputs with\r\n    // the last dimension as the axis to perform ArgMax for.\r\n\r\nThe only place in my training code where I used ArgMax is as below:\r\n\r\n     predictions = { \"classes\": tf.argmax(input=logits, axis=1, name=\"classes_tensor\"), \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\") }\r\n\r\nThe failure messaged printed out seem not to be sufficient enough for me to understand what exactly the problem is. My trained TensorFow Model is fine and I have been able to run inferences on it, however, converting these saved model to TFLite doesn't work. Could this mean the current TFLite version does not support the conversion of some custom TF models yet?. Please I will be glad to know what exactly I may be doing wrong. \r\n\r\nThank you \r\n\r\n  ", "comments": ["@aselle @andrehentz @petewarden any suggestions?", "Maybe it could work using tf 1.5", "TF Lite doesn't completely support argmax at the moment. Does it work if yo uset the output to softmax_tensor instead?", "@andrehentz I have tried using 'softmax_tensor' as output, and it worked properly.\r\n@leandroBorgesFerreira I'm yet to try using the tf 1.5", "ArgMax is not supported by TFLite, even though toco partially understands it. Toco is an analysis engine, so the message is confusing that has a different set of supported things than TFLite. I realize this is confusing. ", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "@aselle can we write the argmax op for toco and rebuild it? Would it be similar to adding a custom op in tensorflow?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Argmax is supported now. I'll close this one but please reopen if you still encounter issues.", "@andrehentz I am still facing this isssue\r\nI am on tf 1.10\r\n"]}, {"number": 15947, "title": "Windows: Override /DEIGEN_STRONG_INLINE=inline for //tensorflow/core/kernels:conv_ops", "body": "This change reduces the Windows building time by more than 15 minutes\r\n\r\nFix #10521", "comments": ["Testing: http://ci.tensorflow.org/view/TF%20pull%20requests/job/tensorflow-pr-win-bazel/53/console", "@gunan Do you prefer to apply `/DEIGEN_STRONG_INLINE=inline` to `tf_copts` or just for `conv_ops` when `--define=override_eigen_strong_inline=true`?\r\n  ", "Well, since we saw that it degrades performance of the final binary, I prefer it to be optional.\r\nIf making it optional is too difficult, then it should only be set for conv_ops_3d\r\n", "@gunan Yes, I'm making it optional ;) \r\nYou can switch it on by `--define=override_eigen_strong_inline=true`, otherwise it won't be enabled. Just asking should we apply it to all ops or just conv_ops when switching it on?", "That is great!\r\nI think it should just apply to conv ops, unless we see that more files are taking longer than 5 minutes to build.", "Great, then this PR is ready to review!", "@tensorflow-jenkins test this please"]}, {"number": 15946, "title": "Support for large number of classes when using tf.metrics.mean_per_class_accuracy()", "body": "`tf.metrics.mean_per_class_accuracy()` uses a `num_classes x num_classes` matrix to keep track of accuracies for each class. This wastes a lot of memory and doesn't work well for large number of classes (e.g. matrix size for 500k classes is 500000^2*4 = 1 terabyte).\r\n\r\nBy switching to two 1-D variables of size `num_classes` instead, memory usage is reduced considerably. One variable keeps track of correct predictions for each class, while the other variable keeps track of the total number of predictions for each class.", "comments": ["Can one of the admins verify this patch?", "Ouch. I wonder why the original code was unnecessarily quadratic.", "I don't think this needs API review since metric variables are not persisted and the API for the metric function does not change.", "Thanks for the quick review, @alextp ", "Oops, I should've run the tests. I only tested it in my own project. At first glance I see two problems:\r\n- The tests are using float instead of int as type for labels. This isn't supported based on the documentation. But I can cast the labels to int64 to match the old behavior.\r\n- The tests require the update function to return the confusion matrix. I can fix the tests, but I'm not sure if anyone is using the matrix in their projects. Is changing this ok, since it's not really documented?", "I added some changes in commit 5e86e3f.", "@alextp could you take a look at the latest changes?"]}, {"number": 15945, "title": "DataLossError when loading saved model from r1.4 (Unable to read file ... failed to seek to header entry)", "body": "I have a few saved models stored, these were built using _version 1.2.0-rc1_ \r\nWhen I try to load any of these saved models using _version 1.4.1_, I get the following error:\r\n```\r\nINFO:tensorflow:Restoring parameters from b'../models/export_output/1510150323/variables/variables'\r\n2018-01-08 19:42:35.838751: W tensorflow/core/framework/op_kernel.cc:1192] Data loss: Unable to read file (../models/export_output/1510150323/variables/variables.index). Perhaps the file is corrupt or was produced by a newer version of TensorFlow with format changes (failed to seek to header entry): corrupted compressed block contents\r\n--------quite a few entries of the above log-------------\r\n2018-01-08 19:42:36.134122: W tensorflow/core/framework/op_kernel.cc:1192] Data loss: Unable to read file (../models/export_output/1510150323/variables/variables.index). Perhaps the file is corrupt or was produced by a newer version of TensorFlow with format changes (failed to seek to header entry): corrupted compressed block contents\r\n2018-01-08 19:42:36.134144: W tensorflow/core/framework/op_kernel.cc:1192] Data loss: Unable to read file (../models/export_output/1510150323/variables/variables.index). Perhaps the file is corrupt or was produced by a newer version of TensorFlow with format changes (failed to seek to header entry): corrupted compressed block contents\r\n2018-01-08 19:42:36.134177: W tensorflow/core/framework/op_kernel.cc:1192] Data loss: Unable to read file (../models/export_output/1510150323/variables/variables.index). Perhaps the file is corrupt or was produced by a newer version of TensorFlow with format changes (failed to seek to header entry): corrupted compressed block contents\r\nTraceback (most recent call last):\r\n  File \"/home/amsha/virtualenv/tf14-no-gpu-p3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1323, in _do_call\r\n    return fn(*args)\r\n  File \"/home/amsha/virtualenv/tf14-no-gpu-p3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1302, in _run_fn\r\n    status, run_metadata)\r\n  File \"/home/amsha/virtualenv/tf14-no-gpu-p3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 473, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.DataLossError: Unable to read file (../models/export_output/1510150323/variables/variables.index). Perhaps the file is corrupt or was produced by a newer version of TensorFlow with format changes (failed to seek to header entry): corrupted compressed block contents\r\n\t [[Node: save_1/RestoreV2_159 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2_159/tensor_names, save_1/RestoreV2_159/shape_and_slices)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/media/Files/Research/FoodClassification/deployment/deployment.py\", line 308, in _main\r\n    tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], EXPORT_MODEL_DIR)\r\n  File \"/home/amsha/virtualenv/tf14-no-gpu-p3/lib/python3.6/site-packages/tensorflow/python/saved_model/loader_impl.py\", line 226, in load\r\n    saver.restore(sess, variables_path)\r\n  File \"/home/amsha/virtualenv/tf14-no-gpu-p3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1666, in restore\r\n    {self.saver_def.filename_tensor_name: save_path})\r\n  File \"/home/amsha/virtualenv/tf14-no-gpu-p3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 889, in run\r\n    run_metadata_ptr)\r\n  File \"/home/amsha/virtualenv/tf14-no-gpu-p3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1120, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/amsha/virtualenv/tf14-no-gpu-p3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1317, in _do_run\r\n    options, run_metadata)\r\n  File \"/home/amsha/virtualenv/tf14-no-gpu-p3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1336, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.DataLossError: Unable to read file (../models/export_output/1510150323/variables/variables.index). Perhaps the file is corrupt or was produced by a newer version of TensorFlow with format changes (failed to seek to header entry): corrupted compressed block contents\r\n\t [[Node: save_1/RestoreV2_159 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2_159/tensor_names, save_1/RestoreV2_159/shape_and_slices)]]\r\n\r\nCaused by op 'save_1/RestoreV2_159', defined at:\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/media/Files/Research/FoodClassification/deployment/deployment.py\", line 308, in _main\r\n    tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], EXPORT_MODEL_DIR)\r\n  File \"/home/amsha/virtualenv/tf14-no-gpu-p3/lib/python3.6/site-packages/tensorflow/python/saved_model/loader_impl.py\", line 216, in load\r\n    saver = tf_saver.import_meta_graph(meta_graph_def_to_load, **saver_kwargs)\r\n  File \"/home/amsha/virtualenv/tf14-no-gpu-p3/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1810, in import_meta_graph\r\n    **kwargs)\r\n  File \"/home/amsha/virtualenv/tf14-no-gpu-p3/lib/python3.6/site-packages/tensorflow/python/framework/meta_graph.py\", line 660, in import_scoped_meta_graph\r\n    producer_op_list=producer_op_list)\r\n  File \"/home/amsha/virtualenv/tf14-no-gpu-p3/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 313, in import_graph_def\r\n    op_def=op_def)\r\n  File \"/home/amsha/virtualenv/tf14-no-gpu-p3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\r\n    op_def=op_def)\r\n  File \"/home/amsha/virtualenv/tf14-no-gpu-p3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nDataLossError (see above for traceback): Unable to read file (../models/export_output/1510150323/variables/variables.index). Perhaps the file is corrupt or was produced by a newer version of TensorFlow with format changes (failed to seek to header entry): corrupted compressed block contents\r\n\t [[Node: save_1/RestoreV2_159 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save_1/Const_0_0, save_1/RestoreV2_159/tensor_names, save_1/RestoreV2_159/shape_and_slices)]]\r\n```\r\nI was able to load the same models in _version 1.2.0-rc1_.\r\nI tried building a new saved model using _version 1.4.1_ , that I was able to load in both versions without any problems. \r\n\r\nThe versions I tested were both built, without cuda. \r\nOS: arch linux", "comments": ["Could you try in 1.5RC0? Header compression was accidentally disabled in 1.4.", "I have to build it. Yes, i'll try it and let you know.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?"]}, {"number": 15944, "title": "Fix tensorflow::CurrentStackTrace when TF_GENERATE_BACKTRACE isn't defined", "body": "Fix http://ci.tensorflow.org/job/tf-master-win-bzl/2227/console\r\nculprit: https://github.com/tensorflow/tensorflow/commit/05386f42f18d66bf9ff1d69edf5c47591e60f804", "comments": []}, {"number": 15943, "title": "add_n: issue with IndexedSlices", "body": "inside function add_n, line 2117, shouldn't\r\n\"if not all(isinstance(x, ops.Tensor) for x in inputs):\" check also whether x is IndexedSlices instead of merely Tensor? i.e. replace the statement with:\r\n\r\nif not ( (all(isinstance(x, ops.Tensor) for x in inputs)) | (all(isinstance(x, ops.IndexedSlices) for x in inputs)) ):\r\n\r\nThanks!\r\n\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Have I written custom code: no\r\nTensorFlow installed from CPU\r\nTensorFlow version 1.4.1\r\nBazel version N/A\r\nCUDA/cuDNN version N/A\r\nGPU model and memory N/A\r\nExact command to reproduce N/A", "Could you please help me concerning the proposed replacement?\r\n\r\nThank you", "I am having the some problem when trying to get the gradients during back-propagation when using lookup word embeddings. I suppose that there is a small bug in add_n function. Is this the case ?", "The original poster has replied to this issue after the stat:awaiting response label was applied.", "If you make your change, the C++ `AddN` op will fail since it doesn't support IndexedSlices. I don't know much about IndexedSlices, but most ops do not seem to support them.\r\n\r\nI don't know anything about word embeddings or how `add_n` is useful to them. /CC @ispirmustafa, can you comment?", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Assignee @ispirmustafa: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@ebrevdo could you please take a look?", "Yes; the check should be:\r\n\r\n```python\r\nall(isinstance(x, (ops.Tensor, ops.IndexedSlices)) for x in inputs\r\n```\r\n\r\nnote you'll also have to change the n=1 case to return the IndexedSlices values through an identity, instead of calling identity() on the entire object.\r\n\r\nWould you like to submit a PR doing this?", "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you.", "I submitted a PR as per comments from @ebrevdo, which fixed the issue for me."]}, {"number": 15942, "title": "build_all_ios.sh:  x86_64 compilation failed.", "body": "when i compile build_all_ios.sh:   \r\n\r\n****tensorflow 1.1 :**   is OK.... build success....**\r\n\r\nwhen i load \"xxxx.pb\" model,  error:\r\n\r\nInvalid argument: No OpKernel was registered to support Op 'Mul' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  device='CPU'; T in [DT_FLOAT]\r\n\t [[Node: UpSample2D_2/mul = Mul[T=DT_INT32](UpSample2D_2/mul/x, UpSample2D_2/Const)]]\r\n\r\nHow to solver ?\r\n\r\n**tensorflow 1.4 :**   \r\n\r\nmake: *** [/Users/open/Downloads/tensorflow-1.4/tensorflow/contrib/makefile/gen/host_obj/tensorflow/core/lib/random/distribution_sampler.o] Error 1\r\n+ '[' 2 -ne 0 ']'\r\n+ echo 'i386 compilation failed.'\r\ni386 compilation failed.\r\n+ exit 1\r\n## \r\n**tensorflow 1.5 :**   \r\n\r\nld: symbol(s) not found for architecture x86_64\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\nmake: *** [/Users/open/Downloads/tensorflow-1.5/tensorflow/contrib/makefile/gen/bin/ios_X86_64/benchmark] Error 1\r\n+ '[' 2 -ne 0 ']'\r\n+ echo 'x86_64 compilation failed.'\r\nx86_64 compilation failed.\r\n+ exit 1\r\n\r\n\r\nHow to solver ?\r\n\r\n**python:3.6.3  mac OS:  10.12.6**\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Have I written custom code : No\r\nOS Platform and Distribution:  python:3.6.3 mac OS: 10.12.6\r\nTensorFlow installed from:  use \"pip install tensorflow\"  \r\nTensorFlow version: 1.4.0\r\nBazel version: no Bazel\r\nCUDA/cuDNN version: no cuda ,i'm in mac\r\nGPU model and memory: no\r\n", "**How to solver the first question ?**\r\n  when i load \"xxxx.pb\" model, error:\r\nCould not create TensorFlow Graph: Invalid argument: No OpKernel was registered to support Op 'Mul' with these attrs. Registered devices: [CPU], Registered kernels:\r\ndevice='CPU'; T in [DT_FLOAT]\r\n[[Node: UpSample2D_2/mul = Mul[T=DT_INT32](UpSample2D_2/mul/x, UpSample2D_2/Const)]]\r\n\r\n**if the tf code simple. the \"xxxx.pb\" can  load....\r\nwhen i use  \"tf.nn.conv2d_transpose\"  , i get the error ....**   python can load it, but xcode load error.....\r\n  \r\n  ", "I am having the same error when running tensorflow/contrib/makefile/build_all_ios.sh on my Macbook Pro: 10.13.2\r\npython:3.6.3\r\nTensorFlow version: 1.4.0", "you need delete  compile_ios_tensorflow.sh  \" exit 1 \"....", "I am really new to all of this, where can I delete that?\r\n\r\nAre you referring to the entire file in \"makeFile\"?", "The original poster has replied to this issue after the stat:awaiting response label was applied.", "So, we're trying to use tflite for mobile needs. I think it's probably the better supported option. Would that work for you?", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @aselle: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @aselle: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @aselle: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @aselle: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 15941, "title": "Import Error: No module named '_pywrap_tensorflow'", "body": "On running the following command: import tensorflow I get an error:\r\n\r\n`C:\\Users\\Neerav>python\r\nPython 3.5.0 (v3.5.0:374f501f4567, Sep 13 2015, 02:27:37) [MSC v.1900 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Neerav\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\r\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])\r\n  File \"C:\\Users\\Neerav\\AppData\\Local\\Programs\\Python\\Python35\\lib\\imp.py\", line 296, in find_module\r\n    raise ImportError(_ERR_MSG.format(name), name=name)\r\nImportError: No module named '_pywrap_tensorflow'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Neerav\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 54, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Neerav\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 28, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"C:\\Users\\Neerav\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\r\n    import _pywrap_tensorflow\r\nImportError: No module named '_pywrap_tensorflow'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\Neerav\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Users\\Neerav\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 60, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Neerav\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\r\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])\r\n  File \"C:\\Users\\Neerav\\AppData\\Local\\Programs\\Python\\Python35\\lib\\imp.py\", line 296, in find_module\r\n    raise ImportError(_ERR_MSG.format(name), name=name)\r\nImportError: No module named '_pywrap_tensorflow'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Neerav\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 54, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Neerav\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 28, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"C:\\Users\\Neerav\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\r\n    import _pywrap_tensorflow\r\nImportError: No module named '_pywrap_tensorflow'\r\n\r\n\r\nError importing tensorflow.  Unless you are using bazel,\r\nyou should not try to import tensorflow from its source directory;\r\nplease exit the tensorflow source tree, and relaunch your python interpreter\r\nfrom there.`\r\n\r\n\r\nI have the following system features:\r\n\r\nwindows 64 bit\r\npython 3.5.0 64 bit\r\nNvidia computing toolkit/CUDA/v8.0./(the cuDNN version 6.0)\r\nall of them are added to my path location also which is: Python\\Python35\\Scripts\r\ni have tensorflow in Python\\Python35\\Lib\\site-packages\\tensorflow\r\nI even have a _pywrap_tensorflow.so file and pywrap_tensorflow.py", "comments": ["need urgent help\r\n", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 15940, "title": "[tensorflow lite] add setUseNNAPI to the Interpreter class", "body": "add setUseNNAPI to the Interpreter class", "comments": ["Can one of the admins verify this patch?", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "#16065, seems to do this and more. So I am inclined to acept that one."]}, {"number": 15939, "title": "Slim VGG losses increase gradually with default training configuration", "body": "Hi, when I try to train imagenet with slim vgg network with default configuration,\r\nThe loss increases gradually from ~0.1 to over 10000. \r\nI am not even able to debug this issue because, all tensors losses are encapsulated inside slim.\r\nIs there any way to debug this issue? ", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "I find out that there was something wrong with the imagenet tfrecord.\r\nActually, in tfrecord image was labeled beyond 1000, larger than 1000.\r\nI remade the tfrecord, and mobilenet and resnet is learning.\r\nAnyway, thank you~", "Closing since the issue is resolved."]}, {"number": 15938, "title": "An easy problem about tensorflow tf.reduce_mean op", "body": "I know... there might not be a suitable palce to ask this question, but I really hope someone cloud help me.\r\n\r\ni want to use the \"tf.reduce_mean\" to obtain the mean of an array (ignore the zeros element)\r\neg:\r\n    data = [[1,2,3],[4,5,6],[0,0,0]]   \r\n    i want to obtain mean= [2.5, 3.5, 4.5]  \r\n    but  tf.reduce_mean op gets the mean=[1.6, 2.3, 3]\r\n\r\nThank you very much!\r\n  ", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 15937, "title": "tensorflow/contrib/lite/toco/dump_graphviz.cc: In function 'void toco::DumpGraphviz(const toco::Model&, std::__cxx11::string*)': tensorflow/contrib/lite/toco/dump_graphviz.cc:329:35: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]    for (int op_index = 0; op_index < ops_to_dump.size(); op_index++) {                                    ^ Target //tensorflow/contrib/lite/toco:toco failed to build", "body": "tensorflow/contrib/lite/toco/dump_graphviz.cc: In function 'void toco::DumpGraphviz(const toco::Model&, std::__cxx11::string*)':\r\ntensorflow/contrib/lite/toco/dump_graphviz.cc:329:35: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   for (int op_index = 0; op_index < ops_to_dump.size(); op_index++) {\r\n                                   ^\r\nTarget //tensorflow/contrib/lite/toco:toco failed to build", "comments": ["export FILE_ZYX1=/home/zyx/Desktop/code/tensorflow-for-poets-2-master\r\nexport FILE_ZYX2=/home/zyx/Desktop/code/tensorflow-master\r\n\r\ncd $FILE_ZYX1\r\nIMAGE_SIZE=224\r\nARCHITECTURE=\"mobilenet_0.50_${IMAGE_SIZE}\"\r\nsudo python -m scripts.retrain -h\r\npython -m scripts.retrain \\\r\n  --bottleneck_dir=tf_files/bottlenecks \\\r\n  --how_many_training_steps=5000 \\\r\n  --model_dir=tf_files/models/ \\\r\n  --summaries_dir=tf_files/training_summaries/${ARCHITECTURE} \\\r\n  --output_graph=tf_files/retrained_graph_phone.pb \\\r\n  --output_labels=tf_files/retrained_graph_phone.txt \\\r\n  --architecture=${ARCHITECTURE} \\\r\n  --image_dir=tf_files/games\r\n\r\n\r\n\r\npython -m scripts.label_image \\\r\n    --labels=$FILE_ZYX1/tf_files/retrained_graph_phone.txt  \\\r\n    --graph=$FILE_ZYX1/tf_files/retrained_graph_phone.pb  \\\r\n    --image=$FILE_ZYX1/tf_files/games/CloseEyes/FvVuasra3qty1wSw2dXSzMnMit00.mp4-312.jpg\r\n\r\ncd $FILE_ZYX2\r\n# bazel build -c opt --copt=-mavx tensorflow/examples/image_retraining:retrain \r\nbazel build tensorflow/python/tools:optimize_for_inference  -c opt --copt=-msse4\r\nbazel-bin/tensorflow/python/tools/optimize_for_inference \\\r\n  --input=$FILE_ZYX1/tf_files/retrained_graph_phone.pb \\\r\n  --output=$FILE_ZYX1/tf_files/retrained_optimize_phone.pb \\\r\n  --input_names=\"input\" \\\r\n  --output_names=\"final_result\"\r\n\r\n\r\ncd $FILE_ZYX2\r\nbazel run -c opt --copt=-mavx --config=opt \\\r\n  //tensorflow/contrib/lite/toco:toco -- \\\r\n  --input_file=$FILE_ZYX1/tf_files/retrained_optimize_phone.pb \\\r\n  --output_file=$FILE_ZYX1/tf_files/retrained_optimize_phone.pb.lite \\\r\n  --input_format=TENSORFLOW_GRAPHDEF \\\r\n  --output_format=TFLITE \\\r\n  --inference_type=FLOAT \\\r\n  --input_shapes=1,224,224,3 \\\r\n  --input_arrays=input \\\r\n  --output_array=final_result\r\n"]}, {"number": 15936, "title": "bazel ubuntu 16.04 bazel build tensorflow/python/tools:optimize_for_inference", "body": "./tensorflow/core/platform/macros.h:78:30: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (x)\r\n                              ^\r\n./tensorflow/core/util/tensor_format.h:340:3: note: in expansion of macro 'CHECK'\r\n   CHECK(index >= 0 && index < dimension_attributes.size())\r\n   ^\r\n./tensorflow/core/util/tensor_format.h: In instantiation of 'T tensorflow::GetFilterDim(tensorflow::gtl::ArraySlice<T>, tensorflow::FilterTensorFormat, char) [with T = long long int]':\r\n./tensorflow/core/util/tensor_format.h:381:54:   required from here\r\n./tensorflow/core/util/tensor_format.h:355:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   CHECK(index >= 0 && index < dimension_attribute.size())\r\n                             ^\r\n./tensorflow/core/platform/macros.h:78:30: note: in definition of macro 'TF_PREDICT_FALSE'\r\n #define TF_PREDICT_FALSE(x) (x)\r\n                              ^\r\n./tensorflow/core/util/tensor_format.h:355:3: note: in expansion of macro 'CHECK'\r\n   CHECK(index >= 0 && index < dimension_attribute.size())\r\n   ^\r\nERROR: /home/zyx/Desktop/code/tensorflow-master/tensorflow/contrib/lite/toco/BUILD:169:1: C++ compilation of rule '//tensorflow/contrib/lite/toco:graph_transformations' failed (Exit 1)\r\nIn file included from external/gemmlowp/public/../internal/dispatch_gemm_shape.h:20:0,\r\n                 from external/gemmlowp/public/gemmlowp.h:19,\r\n                 from ./tensorflow/contrib/lite/kernels/internal/common.h:48,\r\n                 from ./tensorflow/contrib/lite/toco/runtime/types.h:18,\r\n                 from ./tensorflow/contrib/lite/toco/model.h:25,\r\n                 from ./tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.h:23,\r\n                 from tensorflow/contrib/lite/toco/graph_transformations/resolve_tensorflow_matmul.cc:20:\r\nexternal/gemmlowp/public/../internal/../internal/kernel_default.h:88:2: error: #error \"SIMD not enabled, you'd be getting a slow software fallback. Consider enabling SIMD extensions (for example usin\r\ng -msse4 if you're on modern x86). If that's not an option, and you would like to continue with the slow fallback, define GEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK.\"\r\n #error \\\r\n  ^\r\nTarget //tensorflow/python/tools:optimize_for_inference failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 637.451s, Critical Path: 54.99s\r\nFAILED: Build did NOT complete successfully", "comments": ["export FILE_ZYX1=/home/zyx/Desktop/code/tensorflow-for-poets-2-master\r\nexport FILE_ZYX2=/home/zyx/Desktop/code/tensorflow-master\r\n\r\ncd $FILE_ZYX1\r\nIMAGE_SIZE=224\r\nARCHITECTURE=\"mobilenet_0.50_${IMAGE_SIZE}\"\r\nsudo python -m scripts.retrain -h\r\npython -m scripts.retrain \\\r\n  --bottleneck_dir=tf_files/bottlenecks \\\r\n  --how_many_training_steps=5000 \\\r\n  --model_dir=tf_files/models/ \\\r\n  --summaries_dir=tf_files/training_summaries/${ARCHITECTURE} \\\r\n  --output_graph=tf_files/retrained_graph_phone.pb \\\r\n  --output_labels=tf_files/retrained_graph_phone.txt \\\r\n  --architecture=${ARCHITECTURE} \\\r\n  --image_dir=tf_files/games\r\n\r\n\r\n\r\npython -m scripts.label_image \\\r\n    --labels=$FILE_ZYX1/tf_files/retrained_graph_phone.txt  \\\r\n    --graph=$FILE_ZYX1/tf_files/retrained_graph_phone.pb  \\\r\n    --image=$FILE_ZYX1/tf_files/games/CloseEyes/FvVuasra3qty1wSw2dXSzMnMit00.mp4-312.jpg\r\n\r\ncd $FILE_ZYX2\r\n# bazel build -c opt --copt=-mavx tensorflow/examples/image_retraining:retrain \r\nbazel build tensorflow/python/tools:optimize_for_inference  -c opt --copt=-msse4\r\nbazel-bin/tensorflow/python/tools/optimize_for_inference \\\r\n  --input=$FILE_ZYX1/tf_files/retrained_graph_phone.pb \\\r\n  --output=$FILE_ZYX1/tf_files/retrained_optimize_phone.pb \\\r\n  --input_names=\"input\" \\\r\n  --output_names=\"final_result\"\r\n\r\n\r\ncd $FILE_ZYX2\r\nbazel run -c opt --copt=-mavx --config=opt \\\r\n  //tensorflow/contrib/lite/toco:toco -- \\\r\n  --input_file=$FILE_ZYX1/tf_files/retrained_optimize_phone.pb \\\r\n  --output_file=$FILE_ZYX1/tf_files/retrained_optimize_phone.pb.lite \\\r\n  --input_format=TENSORFLOW_GRAPHDEF \\\r\n  --output_format=TFLITE \\\r\n  --inference_type=FLOAT \\\r\n  --input_shapes=1,224,224,3 \\\r\n  --input_arrays=input \\\r\n  --output_array=final_result\r\n"]}, {"number": 15935, "title": "android CameraActivity: Exception!", "body": "tensorflow: CameraActivity: Exception!\r\njava.lang.RuntimeException: Error initializing box priors from file:///android_asset/multibox_location_priors.txt\r\n                                                                     at org.tensorflow.demo.TensorFlowMultiBoxDetector.create(TensorFlowMultiBoxDetector.java:121)\r\n                                                                     at org.tensorflow.demo.DetectorActivity.onPreviewSizeChosen(DetectorActivity.java:146)\r\n                                                                     at org.tensorflow.demo.CameraActivity.onPreviewFrame(CameraActivity.java:120)\r\n                                                                     at android.hardware.Camera$EventHandler.handleMessage(Camera.java:1189)\r\n                                                                     at android.os.Handler.dispatchMessage(Handler.java:102)\r\n                                                                     at android.os.Looper.loop(Looper.java:135)\r\n                                                                     at android.app.ActivityThread.main(ActivityThread.java:5372)\r\n                                                                     at java.lang.reflect.Method.invoke(Native Method)\r\n                                                                     at java.lang.reflect.Method.invoke(Method.java:372)\r\n                                                                     at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:1117)\r\n                                                                     at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:810)\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 15934, "title": "Update docs and test cases for missing types in `tf.zeros_like`", "body": "`zeros_like` supports POD types as well as strings. However, some of the types are missing in the documentation.\r\n\r\nThis fix update docs for missing types in `tf.zeros_like` where `half` and `string` are supported but not listed. \r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>\r\n  ", "comments": []}, {"number": 15933, "title": "Tensorflow 1.4.1 on Linux (CentOS-7.4) and Tensorflow 1.4.1 on MacOSX producing *very* different results in image creation simulation.", "body": " \r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No.\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  \r\nLinux CentOS-7.4 and MacOSx 10.10.5\r\n\r\n- **TensorFlow installed from (source or binary)**: Both; Installed from binary, then, built and installed from source. Same behaviour on each install.\r\n\r\n- **TensorFlow version (use command below)**:\r\nTensorflow 1.4.0 and Tensorflow 1.4.1\r\n\r\n- **Python version**: \r\n2.7.14 (installed from binary, and then built and installed from source\r\n\r\n- **Bazel version (if compiling from source)**:\r\nBazel 0.9.0.  Source built and installed successfully, Python .whl file built & installed successfully.\r\n\r\n- **GCC/Compiler version (if compiling from source)**:\r\nXcode7.2.1 and the Gnu gFortran, 5.2.  (needed gFortran for SciPy install.  All installs OK.)\r\n\r\n- **CUDA/cuDNN version**:\r\nN/A - compiled and running CPU versions only for now.\r\n\r\n- **GPU model and memory**:\r\n\r\n- **Exact command to reproduce**:\r\n(See supplied test program - based on the Laplace PDE (\"Raindrops on Pond\") simulation example\r\nfrom Tensorflow Tutorial)\r\n \r\nDescription of Problem:\r\n I've run into a curious situation.  I am getting very different behaviour in Tensorflow 1.4.1 on Linux and Tensorflow 1.4.1 on MacOSX, in straightforward image-generation simulation, based on the \"Raindrops on a Pond\" (Laplace PDE) example from the Tensorflow Tutorial.\r\n\r\nI must stress that *both* Tensorflow installations seem to be 100% correct, and operate other tests correctly, producing the same numeric results for simple models.\r\n\r\nI have also built Tensorflow 1.4.1 completely from source, and the Python 2.7.14 as well, on the MacOSX (MacBook) machine, in order to build the Python using \"--enable-unicode=ucs4\", since that was one difference I was able to find, between the two version.  But even with the Macbook now running exactly the same Python 2.7.14 as the Linux box, I am still getting wildly divergent evoluationary behaviour as when I iterate the simple simulation.   The numbers just zoom off in very different directions on each machine, and the generated images show this.  \r\n\r\nOn the MacOSX, the simulation evolves very quickly to a pure white canvas (all \"255\"s), but on the Linux platform, the image grows more complex, with the generated numbers bifurcating between large negative and large positive - and hence when np.clip-ed, to range 0-255, show a complex moire-style pattern.\r\n\r\nI have confirmed all related libraries and packages seem to be the same versions.  The difference seems to be in the operation of Tensorflow.  \r\n\r\nThis seems pretty serious, as each platform is Intel.  The Linux box (CentOS-7.4) is Core-i3, while the Macbook is Core-i5.  But both are 64-bit, and both Tensorflow installations seem to be correct.  I have tried both the binary version, and then built a complete local version of Tensorflow 1.4.1 for the Macbook from source.  Both seem to be Ok, and operate correctly.  The Linux version of Tensorflow 1.4.0 was installed from binary appears to be operating correctly, albeit differently, but just for this one program.\r\n\r\nWhen the sample program runs, it will display fourteen 400x400 images, as well as the numeric values of the row-20 of the \"a\" array (400 numbers).   The program can be started from an Xterm shell window, with \"python LapTest.py\".  It does not need Jupyter or IPython.  With SciPy loaded, the images are rendered as .PNG files on both platforms, using Preview on the MacOSX MacBook, and ImageMagick on the CentOS-7.4 Linux box.   Program runs fine to completion, and all looks ok on both machines.\r\n\r\nBut the results - even with the simple initial pseudo-random conditions - evolve completely differently, and consistantly.  The Macbook version of Tensorflow 1.4.1 goes to a pure white screen, while the LInux Tensorflow 1.4.1 configuration evolves to a complex, chaotic, moire-pattern.  \r\n\r\nLeaving aside the question of even which machine is \"correct\", the expected result is of course that both machines should at least show clear evidence of similar behaviour.\r\n\r\nNo change was made to the test program, \"LapTest.py\", from one machine to the other.   The different behaviour is not related to how the images are displayed, which is working fine on both platforms.   A copy of this simple program is provided.   I have removed or commented out the IPython/Jupyter dependent code, so this program can be run on plain vanilla Python 2.7.14, as long the appropriate packages (tensorflow, numpy, scipy, PIL (Pillow version), matplotlib, imageio ...) are available\r\n\r\nExample of Source code to demostrate behaviour:     LapTest.py \r\n``` \r\n#-------------------------------------------------------------------------------\r\n# Prgm: LapTest.py\r\n#\r\n# --- the Tensorflow LaPlace Image example (Uses PIL(Pillow ver.), and numpy)\r\n# --- updated for TensorFlow 1.4.1 running on CentOS-7.4 & Python 2.7.14\r\n#     compiled (configured, actually) with the \"--enable-unicode=ucs4\" option\r\n#                                             (Python compile default is ucs2)\r\n#                                             (which caused TensorFlow 1.4 to)\r\n#                                             (fail to load. Building Python )\r\n#                                             (with ucs4, => pip can install )\r\n#                                             (TensorFlow 1.4.0 successfully.)\r\n#\r\n# --- This version of program tested on: MacOSX 10.10.5. (Yosemite)\r\n# --- LapTest.py on Linux (CentOS-7.4), and LapTest.py on MacOSX, with Tensorflow-1.4.1 and\r\n#     Python 2.7.14 (with ucs4 enabled on both Python versions), show *very*\r\n#     different behaviour, and produce very different results.\r\n#     Note: CentOS-7.4 is using Linux kernel: 4.14.9-1el7.elrepo.x86_64    \r\n#\r\n# --- Import various libraries for simulation\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport scipy.misc\r\nimport imageio\r\nimport os\r\nimport sys\r\nimport subprocess\r\nimport PIL\r\nimport time    \r\n\r\n\r\n# --- Import for visualization and jpeg encoder  \r\nimport matplotlib\r\nmatplotlib.rcParams[\"backend\"]= 'TkAgg'\r\nfrom matplotlib import pyplot as plt\r\n# from PIL import Image, ImageDraw\r\nfrom io import BytesIO\r\n#  from IPython.display import clear_output, Image, display\r\n\r\n#--- we need this to get a sane for-loop...\r\ndef jump_range(start, end, step):\r\n    while start <= end:\r\n        yield start\r\n        start += step\r\n\r\n# --- function for displaying state of the pond's surface as an image\r\ndef DisplayArray(a, fmt='jpeg', rng=[0,1]):\r\n  global proc\r\n  # proc.kill() \r\n  # \"\"\"Display an array as a picture. \"\"\"\r\n  a = (a - float(rng[0]))/float(rng[1] - rng[0])*37\r\n  amod = np.clip(a, 0, 255)\r\n  a = np.uint8(amod)\r\n#  a = np.clip(a, 0, 255) \r\n#  a = np.uint8(a) \r\n#  np.clip(a, 0, 255, out=a )\r\n#  a = a.astype('uint8')\r\n  print \" \"\r\n  print \" ----------- This is a: => row 20  ------------\"\r\n  print a[20]\r\n  print \" ----------------------------------------------\"\r\n  f = BytesIO()\r\n  # --- this is the cool, realtime thing that runs in Jupyter-IPython Notebook\r\n  PIL.Image.fromarray(a).save(f,fmt)\r\n  # --- clear_output(wait = True)  --- only for IPython\r\n  # display(Image(data=f.getvalue()))\r\n  # --- write the image\r\n  # --- write the simulation images to .jpg files\r\n  scipy.misc.imsave(\"tensor.jpg\", a)\r\n  pic = PIL.Image.open(\"tensor.jpg\")\r\n  # --- new approach... use subprocess, wait for time(2) then kill it\r\n  # proc = subprocess.Popen([\"display\", \"./tensor.jpg\"])\r\n  # time.sleep(0.5)\r\n  pic.show()\r\n  # clear_output(wait=True)\r\n  # --- this line below doesn't work outside of the Jupyter environment...\r\n  # display(Image(data=f.getvalue()))\r\n  #\r\n  # pic.close()  <--- does not work to close image.  Just removes the pointer to image in memory\r\n    \r\ndef DisplayArrayToFile(a, fmt='jpeg', rng=[0,1]):\r\n  # \"\"\"Display an array as a picture to a file... \"\"\"\r\n  a = (a - rng[0])/float(rng[1] - rng[0])*37\r\n  a = np.uint8(np.clip(a, 0, 255))\r\n  f = BytesIO()\r\n  # --- this is the cool, realtime thing that runs in Jupyter-IPython Notebook\r\n  PIL.Image.fromarray(a).save(f,fmt)\r\n  # clear_output(wait = True)\r\n  # display(Image(data=f.getvalue()))\r\n  # --- write the image\r\n  # --- this is my stuff to write the simulation images to .jpg files\r\n  #scipy.misc.imsave (\"tensor_new.jpg\", a)\r\n  imageio.imwrite(\"tensor_new.jpg\", a)\r\n  # --- image = PIL.Image.open(\"tensor_new.jpg\")\r\n  # --- image.show()\r\n  # clear_output(wait=True)\r\n  # display(Image(data=f.getvalue()))\r\n  #\r\n \r\n# --- make print stmt print the whole array... (not just part of it...)\r\nnp.set_printoptions(threshold=np.nan)\r\n  \r\n# --- make interactive session for testing - can use regular session also\r\nsess = tf.InteractiveSession()\r\n# sess = tf.Session()\r\n\r\n# --- computational functions go here... once we get jpeg pic working\r\ndef make_kernel(a):\r\n  \"\"\"Transform a 2D array into a convolutional kernel \"\"\"\r\n  a = np.asarray(a)\r\n  a = a.reshape(list(a.shape) + [1,1])\r\n  return tf.constant(a, dtype=1)\r\n\r\n\r\ndef simple_conv(x, k):\r\n  \"\"\" A simplified 2D convolutional operation \"\"\"\r\n  x = tf.expand_dims(tf.expand_dims(x, 0), -1)\r\n  y = tf.nn.depthwise_conv2d(x, k, [1, 1, 1, 1], padding='SAME')\r\n  return y[0, :, :, 0]\r\n\r\n\r\ndef laplace(x):\r\n  \"\"\"Compute the 2D laplacian of an array \"\"\"\r\n  laplace_k = make_kernel([[0.5, 1.0, 0.5],\r\n                           [1.0, -6., 1.0],\r\n                           [0.5, 1.0, 0.5]])  \r\n  return simple_conv(x, laplace_k)\r\n\r\n\r\n\r\n# --- Define the PDE - the pond surface is a perfect 400x400 square\r\nN = 400\r\n\r\n# --- list of display points...\r\ndispval = jump_range(0, 12500, 1000)\r\n# --- dispval has to be a list...\r\ndispval = list(dispval)\r\nprint \"We will look at these values: \",dispval\r\n\r\n# --- now, we create some \"raindrops\"\r\n# --- Initial Conditions -- some rain drops hit the pond\r\n# --- set everything to zero\r\nu_init = np.zeros([N, N], dtype=np.float32)\r\nut_init = np.zeros([N, N], dtype=np.float32)\r\n\r\n# Some material accretion occurs (raindrops hit pond) at random points\r\nfor n in range(40):\r\n  a,b = np.random.randint(0, N, 2)\r\n  u_init[a,b] = np.random.uniform()\r\n\r\n# --- Create and Display the jpeg image...\r\n# proc = subprocess.Popen([\"display\", \"./tensor.jpg\"])\r\n# DisplayArray(u_init, rng=[-0.1, 0.1])\r\n\r\n# Parameters\r\n# eps -- time resolution\r\n# damping -- wave damping\r\neps = tf.placeholder(tf.float32, shape=())\r\ndamping = tf.placeholder(tf.float32, shape=())\r\n\r\n# --- Create vaiables for simulation state\r\nU  = tf.Variable(u_init)\r\nUt = tf.Variable(u_init)\r\n\r\n# --- Discretized PDE update rules\r\nU_  = U + eps * Ut\r\nUt_ = Ut + eps * (laplace(U) - damping * Ut)\r\n\r\n# --- Operation to update the state\r\nstep = tf.group(\r\n  U.assign(U_),\r\n  Ut.assign(Ut_))\r\n\r\n# --- Run the simulation forward with a simple FOR loop.\r\n# --- Initialize state to initial conditions\r\ntf.global_variables_initializer().run(session=sess)\r\n\r\n# --- Run 12701 steps of PDE\r\nfor i in range(12701):\r\n  # Step simulation  (damping was 0.04, I made it negative .14)\r\n   with sess.as_default(): step.run( {eps: 0.03, damping: -0.14})\r\n# --- to see everything...\r\n#   with sess.as_default(): print \"U.eval()   .... \", U.eval()[20]  # --- ,\"   \", Ut.eval()\r\n# ------\r\n\r\n   if (i in dispval) :\r\n       with sess.as_default(): DisplayArray(U.eval(), rng=[-0.1, 0.1])\r\n       print \"                                ------ For iteration:  \",i\r\n       sys.stdout.flush()\r\n       print \"U.eval()   ....... \"\r\n       with sess.as_default(): print   U.eval()[20]      # --- ,\"   \", Ut.eval()\r\n       print \"                                --- End of iteration:  \",i\r\n       sys.stdout.flush()\r\n       continue\r\n#\r\n# --- to show each iteration...\r\n#  with sess.as_default(): DisplayArray(U.eval(), rng=[-0.1, 0.1])\r\nprint \"Done at: \",i\r\n\r\n# --- Ok, we are done...\r\nwith sess.as_default(): DisplayArray(U.eval(), rng=[-0.1, 0.1])\r\n\r\nwith sess.as_default(): DisplayArrayToFile(U.eval(), rng=[-0.1, 0.1])\r\nprint \"Last Image Written to file: tensor_new.jpg. Done.\"   \r\n#--------------- done ------------------\r\n```\r\n\r\nIf someone could try this program on a supported version of Linux (ie. the Ubuntu version that TensorFlow officially supports), that would be helpful.  I am running a recent version of the Linux kernel on the CentOS-7.4 box  (uname -a reports: kernel version 4.14.9-1.el7.elrepo.x86_64 ).  Really like to nail down what is happening.  I have attached images of results I am seeing on the two machines, first the Linux box, second is the Macbook.   \r\n\r\n![laptest_linux_img_20180107_150905_sml](https://user-images.githubusercontent.com/16905336/34654259-45838fc6-f3c7-11e7-93b1-96751153c3a4.jpg)\r\n![laptest_mac_img_20180107_151332_sml](https://user-images.githubusercontent.com/16905336/34654263-4c961b44-f3c7-11e7-8998-f3122f6d9e7c.jpg)\r\n", "comments": ["Installing from binary ( https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-1.4.1-cp27-none-linux_x86_64.whl ) on Ubuntu 17.10, Python 2.7.14, i also see the moire-style pattern evolution.\r\n![screen shot 2018-01-08 at 9 22 33 pm](https://user-images.githubusercontent.com/22581048/34706141-5072c606-f4ba-11e7-80f9-83b909d8466d.png)\r\n", "Thank you, quaeler, for posting your results.   This is really useful.  I was starting to think that there must be a problem in my Linux installation, because the MacOS version basically blows up to almost a white screen by interation 3000.  I've been investigating various examples of 32-bit overflow bugs and problems in various Python packages, looking at anywhere TensorFlow or Python is producing different results on different platforms, and there are a few.  \r\n\r\nOne that I found was a production server versus a development environment giving completely different results, which turned out to be a bug in a library called \"bottleneck\", used in the \"pandas\" data tool for Python.  There is a Stackoverflow note on that issue: https://stackoverflow.com/questions/43525492/unexpected-32-bit-integer-overflow-in-pandas-numpy-int64-python-3-6?noredirect=1&lq=1   \r\n\r\nI am wondering if some of the speed-up code from \"bottleneck\" made it into TensorFlow, with the 32-bit overflow bug included, in one of the versions.  Possible?\r\n\r\nHere are the results of just the first three images, .ie the initial image (supposed to be stars), and the generated image at iteration 1000, and at iteration 2000, after which I interrupted the program. I changed the laplace damping value from a positive number in the TensorFlow example of \"raindrops on a pond\" to a negative value  to simulate accretion... stars forming instead of raindrops falling.\r\n\r\nYou can see, the Macbook version evolves completely differently, with the generated values all going to positive numbers, while the Linux version evolves to what you are also seeing, a tensor of positive and negative values, which creates an interesting pattern.  I basically have the same issue the fellow in the \"integer-overflow-in-pandas-numpy\" had, two machines with identical software and basically the same architecture that *should* behave the same, but clearly do not.  Something is amiss.\r\n\r\nI've checked that the defaults in the two Python's seem to be the same, all the packages are the same, and have just updated Pillow to 5.0.0 on both machines, with no change in observed behaviour.  I will try to reduce this issue to a simple case where one of the machines is producing an obviously wrong result. \r\n\r\n![linux_img_20180109_152259_sml](https://user-images.githubusercontent.com/16905336/34741796-dc34be28-f551-11e7-816e-ddda7b18ed9b.jpg)\r\n![mac_img_20180109_152340_sml](https://user-images.githubusercontent.com/16905336/34741802-e2d0e946-f551-11e7-9a73-b1f65c98d98b.jpg)\r\n", "@Gemesys a simple reproduction case would be very useful. Please let us know what you find. ", "Unfortunately, to add a problem to this problem, running this with Python 2.7.10 on macOS 10.12.6 and installing from https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.4.1-py2-none-any.whl produces the Linux-esque behavior.\r\n\r\n![screen shot 2018-01-09 at 5 13 53 pm](https://user-images.githubusercontent.com/22581048/34751302-aa2e180c-f560-11e7-8381-daa4121d8b6d.png)\r\n\r\n  ", "Thank-you so much for this, quaeler!  This is really helpful.  The behaviour on your 10.12.6 macos matches *exactly* what I am seeing on my Linux box, which seems to be very stable, and does not show any evidence of any other issue anywhere, so far.  I'm running Firefox 52.2 ESR, and a bunch of Tcl/Tk stuff, including an editor, some encryption stuff, and such.    It all works, and I have confidence in the configuration.  Your run Ubuntu was slightly different - but what you have provided here looks exactly like what I see, almost pixel-for-pixel.  (I've attached proper screen-shot image from my Linux machine.)  The simulation begins with  pesudo-random  values, but evolves always - despite changes in images size - to what you are showing here.  I ran a 1200x1200 image sequence yesterday, and it still looked the same.   I've downloaded and run some floating-point test/check software from here:  http://www.math.utah.edu/~beebe/software/ieee/ \r\nand the screen-shot of running fpshow.c shows the repesentation of floating-point constants on the left for the Linux-CentOS-7.4 box and on the right for the MacBook, running 10.10.5 macos.  (Centre is the info in the ieeeftn.h file, with explanations and indication of what is expected to be seen).   In running different sizes of the output image, I notice that the behaviour matches between the two machines up to an image of about 90x90.  Above that, the Mac blows up (image goes all white), ie. behaviour diverges.   \r\n\r\nLooks like a memory or overflow problem.  The output of the \"fpshow.c\" program (provided below) shows that floating point representation between the Linux and Macbook  are the same, for the 64-bit words.  Linux side does show extranious data in next location, whereas Mac shows zeros, but that is an artifact of the fpshow.c program being written for 32-bit, I think. It's just showing next 64-bit memory location.  The 64-bit numeric stuff is same on both, as far as I can tell.  Both machines have 4 GB memory, for \"gcc --version\" Linux box reports: \" 4.8.5 20150623 (Red Hat 4.8.5-16)\", and the Mac reports: \"Apple LLVM version 7.0.2 (clang-700.1.01)  Target: x86_64-apple-darwin14.5.0, Thread model: posix\".   \r\n\r\nI will try to make a more simple test case.  But what you have provided here, suggests there is a bug in the Apple's macos (10.10.5 - Yosemite) memory management or floating-point calculation operation. \r\n\r\nI also found an issue where a fellow reported  bizarre training results for a network.  Instead of a smooth curve of improvement (as the backprop progressed), he got these serious and strange discontiuous results - which yes, can happen if you are falling down a steep gradient in a new location on the error surface,  but his results were curious - looked almost like a hardware failure, but then the training would recover.   If there is a floating-point calculation issue, that only shows up in some cases, it might be the cause of this guy's strange training results.  (Like the early 1995 Intel FPU bug. It was only apparent sometimes, for some calculations.)\r\n\r\nBut the fact that an upgraded version of the macos produces *exactly* the behaviour seen on my Linux box, suggests Apple's Yosemite is the culprit.  I won't upgrade the Mac, as I would like to determine what is happening here.  Results of the \"fpshow.c\" program (which \"ieeeftn.h\") from the above site (Univ. of Utah..), shown below.  Linux and Mac floating-point representation seem the same, as one would expect.  Also provide proper (not  just Android-phone image..) screen shot from my Linux box, showing expected behaviour, same as what you are seeing on your macOS 10.12.6. \r\n\r\n![fpshow_results](https://user-images.githubusercontent.com/16905336/34789850-d18a46b6-f60d-11e7-8d87-41446dcb07a1.jpg)\r\n![laptestl_py_screenshot_2018-01-10 14-50-43](https://user-images.githubusercontent.com/16905336/34792871-7c62859a-f617-11e7-94ba-84d3666090c0.jpg)\r\n", "Given what quaeler reported, I uninstalled my built-from-source version of Tensorflow-1.4.1 on the Macbook, and installed the binary version of Tensorflow that quaeler used to get the correct simulation results he shows for Sierra macos.  Then, I edited my .bash_profile to revert to the previous, binary installed Python (2.7.14), which has ucs2 encoding for unicode characters. (Thats the one issue I know is different between the Linux binary Tensorflow and the Mac binary Tensorflow.  The Linux binary is built with unicode=ucs4, and requires a Python built the same way.)  \r\n\r\nI ran the LapTest.py program on the Mac with binary Tensorflow and binary Python (2.7.14 from Sept. 2017), and confirmed I still get the blank image.  I've attached a proper screenshot below, which shows the results - all blank white screens, after the simulation runs for just 3000 iterations.  The floating point values in the U.eval() matrix (used to create the display image), for row=20 are provided in the xterm window, showing **all**l high-valued, positive values.  On the Linux machine, these values are a mixture of postive and negative values (and hence an image is produced).\r\n\r\nWhen run on Linux, the simulation evolves in the fashion quaeler reports for Mac Sierra, and I am seeing for Linux/CentOS-7.4.  The numbers evolve the same way, and a similar image appears,  even with a larger surface area, showing same evidence of moire-style patterns.  The same inspection of the U.eval() matrix at row[20] shows high-valued **positive and negative values**, which are shown in the attached screenshot from the Linux box.   \r\n\r\nI thought it might be the CPU vectorization being problematic, but what is interesting is the Macbook compiled-from-source Tensorflow-1.4.1 does not offer the warning messages about cpu vector instructions sse4.1, sse4.2 and avx (\"Your CPU has these, but this version is not compiled to use them: SSE4.1, SSE4.2 AVX\"), but the binary version I just re-installed *does* offer this warning, so I am guessing that the ./configure and/or Bazel setup sees these CPU options are available, and compiles the code in Tensorflow to use these?  So since the behaviour is the same on the Yosemite (10.10.15) Macbook for both compiled and binary Tensorflow, we can rule out the problem being from the use of the vector instructions?   Or when you compile Tensorflow for CPU, do you have to explicitly set some options to use these instructions, and that assumption is not correct?  \r\n\r\nOn each screen shot, the table at right is the U.eval() values for row[20].  The image display routine just uses np.clip to clamp the image-pixel values to between 0 and 255, so a large negative number becomes a zero (black), and a large positive number becomes a 255 (white). \r\n\r\nTo summarize: The Linux Tensorflow binary for 1.4.1 for both Ubuntu 17 and CentOS-7.4 have the simulation evolve to a big tensor of high-value positive and negative numbers, and pattern in the image is generated.  The same numerical evolution occurs on a Macbook running Sierra  Macos  10.12.6.   \r\n\r\n![screenshot_laptest_mac_2018-01-11-1](https://user-images.githubusercontent.com/16905336/34836495-0e41663a-f6c6-11e7-8084-5a314c7322b7.jpg)\r\n![screenshot_laptest_600_2018-01-11_9-25-23](https://user-images.githubusercontent.com/16905336/34836507-18505802-f6c6-11e7-9569-c48762f499f3.jpg)\r\nAnd now, what is particularly annoying, is that I cannot re-install my built-from-source version of TensorFlow-1.4.1, despite having pointed to and started the locally-built Python without problem.\r\nThere is a wrapper file in the /usr/local/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so which is failing on a \"Symbol not found: _PyUnicodeUCS_AsASCIIString\"   Arrgh!\r\nWhat looks to have happened, is that installing the binay Tensorflow (with it's unicode=ucs2 default) has trashed the local-built  Python 2.7 library.  I have the ucs4 Python in the path, any attempt to import my local built TensorFlow in Python is failing.    I will have to resolve this before I can determine what is wrong with the TensorFlow math under Yosemite.", "In case anyone is following this, here is the protocol for switching back to your custom-built TF version, from a binary one.  Just go to the directory where you built TF, and run ./configure to make sure you are pointing to your local python (I have a binary version installed in the ..frameworks area, and a local built one in /usr/local/bin with the site packages in /usr/local/lib/python2.7/site-packages/... ).  Do a \"bazel build\", (runs real quick, nothing needs to be compiled...), and then run \"bazel-bin/tensorflow/tools/pip_package/build_pip_package  /tmp/tensorflow_pkg\"  and you will get the .whl file in ./tmp/tensorflow_pkg.  Uninstall the binary TensorFlow  in python with \"pip uninstall tensorflow\".  Then change the name of the built .whl file if you need to  (mine gets built as \"tensorflow-1.4.1-cp27-cp27m-macosx_10_4_x86_64.whl, and I have to rename or copy it to: \"tensorflow-1.4.1-py2-none-any.whl\", and you can then use  \"pip install ... \" to install it successfully.  Start Python, and \"import tensorflow as tf\".  This was failing for me, until it re-did the Bazel build.  (Note: I am using Bazel 0.9.0, built from source.)\r\n\r\nThis gets me back to using my local-built TensorFlow and Python 2.7, with the unicode=ucs4 (same as the Linux binary Tensorflow and its local-built Python 2.7. ).   Note, you can check which unicode level your Python is built with using : \"import sys\" and then \"print sys.maxunicode\".  If you get \"1114111\", you are unicode=ucs4, if you get \"65535\", you are unicode=ucs2.\r\n\r\nOnce I rebuilt TensorFlow pointing to the right Python, and rebuilt the .whl file, and un-installed and then installed the new wheel file with pip install, I was again able to successfully import it, and run the test programs.\r\n\r\nWhat is really curious, is that this switching between versions made absolutely no difference in the behaviour of the Macbook's version of the simulation test.  On the Macbook with macos 10.10.5, the test floating-point values all go to large numbers, (and a pure white image)  whereas on the other three platforms, the results oscillate between large positive and large negative numbers (and generate the moire-pattern image.).  All processors are little-endian Intel multi-core devices, and their behaviour should not diverge this way.   I've seen strange results like this before, and it was due to a serious flaw in a very low-level routine that converted between large floating-point values, and a 10-byte extended precision format that was rarely (but occasionally) used.  Only when code used the 80-bit field, did the numbers go squirrelly  - and when they did go off, it was only by a small amount.  But the problem would show up on scientific graphs - the numbering on the axis would be \"1 2 3 4 5 6 7 8 9 9\" instead of \"1 2 3 4 5 6 7 8 9 10\".      The situation here looks similar.  Very large floating point numbers are being flipped between registers, pipelines, and/or memory, and somewhere, some are getting mis-converted or precision is being dropped incorrectly - or maybe added incorrectly?    \r\n\r\nThese type of errors are not uncommon.  In the current MySql 5.7 release notes, deep on page 99 of an almost 400 page document, there is a reference to a JSON parsing error of a floating point number with a large negative exponent that apparently could crash the server.  Image attached.  Full document is at:  https://downloads.mysql.com/docs/mysql-5.7-relnotes-en.pdf \r\n\r\nAs I said earlier, I will try to construct a more simple test-case that will illustrate the problem, but there is enough here that it might bear looking into by someone who knows the internals of TensorFlow.   It is possible that the Macbook Yosemite operation is correct, and that the other three platforms are propagating erroneous results, perhaps due to flawed interprocessor communication or pipelining/prefetching errors.  Until this evident calculation issue is understood, it is realistic to expect TensorFlow to give different training results on different machines of similar architecture, which is a real concern.   \r\n\r\n![example_of_floating_point_exponent_parse_fail](https://user-images.githubusercontent.com/16905336/34840668-b0adfca0-f6d3-11e7-8a39-e5f96a57db35.jpg)\r\n", "As promised, here is a more direct example of the operational difference noted between MacOS and Linux versions of TensorFlow 1.4.1.  I've removed all randomness from the initial conditions of the test program, and removed the need to use scipy, PIL/Pillow and matplotlib (and the TkAgg backend).   All we are basically doing here his calling TensorFlow routines: \"tf.expand_dims\" and \"tf.nn.depthwise_conv2d\" to set things up, \"tf.group\" to define the step, \"tf.global_variables_initializer\" to initialize variables, and \"step.run\" to iterate.  \r\n\r\nRow 20 of the matrix \"U\" is displayed using U.eval.  This prints 400 numbers.  After only 1000 iterations, the Linux version of TensorFlow 1.4.1 shows the first number in row 20 of U as a value that is typically around 1.4 to 1.5.  The MacOS version (running on MacOS 10.10.5 (Yosemite)), typically shows a value around 0.336 to 0.337.  One can simply interupt the running Python program with control-c, and examine the 400 numbers displayed for iteration 1000, when the program displays the iteration=1000 information.  \r\n\r\nThese differences remain essentially the same, with small floating-point numeric variations between runs, the source of which is unclear at this time. Each machine shows small variations in its results each time, after only 1000 iterations  (a few percentage points different).  This may be due to characteristic operation of the floating-point solid-state electronics.   But between platforms, the difference exceeds 300 percent, and this has to be seen as unacceptable.  From run to run, this magnitude of difference remains consistant.  So far, I have been unable to detect any specifc flaw in floating point operations on the Macbook Pro running under MacOS 10.10.5, nor on the HP box, which is running under CentOS Linux 7.4.\r\n\r\nTensorFlow is producing quite different results on two different (but architecturally similar) computers.  \r\n\r\nThe test program, \"laptestnum.py\"  is attached below.\r\n\r\n```\r\n#-------------------------------------------------------------------------------\r\n# Prgm: laptestnum.py\r\n#\r\n# --- all randomness at startup is removed.  Program begins with specified\r\n# --- input values that are exactly the same for each run.\r\n#\r\n# --- this is a stripped-down version of LapTest.py, just produces numbers,\r\n# --- and a final image to \"tensor_new.jpg\".  Does not require scipy.misc\r\n# --- does not require PIL/Pillow image processing library\r\n# --- does not use or require matplotlib or TkAgg backend\r\n# --- does not produce images while running - only outputs row 20 of matrix U.eval()\r\n# --- \r\n# --- one may interrupt program with ctrl-c after only 1000 iterations, and\r\n# --- note the dramatic difference between the Apple Mac (10.10.5 MacOS) and\r\n# --- Linux version.  \r\n#\r\n# --- the Tensorflow LaPlace Image example (Uses PIL(Pillow ver.), and numpy)\r\n# --- updated for TensorFlow 1.4.0 running on CentOS-7.4 & Python 2.7.14\r\n#     compiled (configured, actually) with the \"--enable-unicode=ucs4\" option\r\n#                                             (Python compile default is ucs2)\r\n#                                             (which caused TensorFlow 1.4 to)\r\n#                                             (fail to load. Building Python )\r\n#                                             (with ucs4, => pip can install )\r\n#                                             (TensorFlow 1.4.0 successfully.)\r\n\r\n# --- Import various libraries for simulation\r\nimport tensorflow as tf\r\nimport numpy as np\r\n# import scipy.misc\r\nimport imageio\r\n# import os\r\nimport sys\r\nimport subprocess\r\n# import PIL\r\n# import time    \r\n\r\n\r\n# --- Import for visualization and jpeg encoder  \r\n# import matplotlib\r\n# matplotlib.rcParams[\"backend\"]= 'TkAgg'\r\n# from matplotlib import pyplot as plt\r\n# from PIL import Image, ImageDraw\r\nfrom io import BytesIO\r\n#  from IPython.display import clear_output, Image, display\r\n\r\n#--- we need this to get a sane for-loop...\r\ndef jump_range(start, end, step):\r\n    while start <= end:\r\n        yield start\r\n        start += step\r\n\r\n# --- function for displaying state of the pond's surface as an image\r\ndef DisplayArray(a, fmt='jpeg', rng=[0,1]):\r\n  global proc\r\n  # proc.kill() \r\n  # \"\"\"Display an array as a picture. \"\"\"\r\n  a = (a - float(rng[0]))/float(rng[1] - rng[0])*37\r\n  amod = np.clip(a, 0, 255)\r\n  a = np.uint8(amod)\r\n#  a = np.clip(a, 0, 255) \r\n#  a = np.uint8(a) \r\n#  np.clip(a, 0, 255, out=a )\r\n#  a = a.astype('uint8')\r\n  print \" \"\r\n  print \" ----------- This is a: => row 20  ------------\"\r\n  print a[20]\r\n  print \" ----------------------------------------------\"\r\n  f = BytesIO()\r\n  # --- this is the cool, realtime thing that runs in Jupyter-IPython Notebook\r\n  # PIL.Image.fromarray(a).save(f,fmt)\r\n  # --- clear_output(wait = True)  --- only for IPython\r\n  # display(Image(data=f.getvalue()))\r\n  # --- write the image\r\n  # --- write the simulation images to .jpg files\r\n  # scipy.misc.imsave(\"tensor.jpg\", a)\r\n  # pic = PIL.Image.open(\"tensor.jpg\")\r\n  # --- new approach... use subprocess, wait for time(2) then kill it\r\n  # proc = subprocess.Popen([\"display\", \"./tensor.jpg\"])\r\n  # time.sleep(0.5)\r\n  # pic.show()\r\n  # clear_output(wait=True)\r\n  # --- this line below doesn't work outside of the Jupyter environment...\r\n  # display(Image(data=f.getvalue()))\r\n  #\r\n  # pic.close()  <--- does not work to close image.  Just removes the pointer to image in memory\r\n    \r\ndef DisplayArrayToFile(a, fmt='jpeg', rng=[0,1]):\r\n  # \"\"\"Display an array as a picture to a file... \"\"\"\r\n  a = (a - float(rng[0]))/float(rng[1] - rng[0])*37\r\n  a = np.uint8(np.clip(a, 0, 255))\r\n  f = BytesIO()\r\n  # --- this is the cool, realtime thing that runs in Jupyter-IPython Notebook\r\n  # PIL.Image.fromarray(a).save(f,fmt)\r\n  # clear_output(wait = True)\r\n  # display(Image(data=f.getvalue()))\r\n  # --- write the image\r\n  # --- this is my stuff to write the simulation images to .jpg files\r\n  #scipy.misc.imsave (\"tensor_new.jpg\", a)\r\n  imageio.imwrite(\"tensor_new.jpg\", a)\r\n  # --- image = PIL.Image.open(\"tensor_new.jpg\")\r\n  # --- image.show()\r\n  # clear_output(wait=True)\r\n  # display(Image(data=f.getvalue()))\r\n  #\r\n \r\n# --- make print stmt print the whole array... (not just part of it...)\r\nnp.set_printoptions(threshold=np.nan)\r\n  \r\n# --- make interactive session for testing - can use regular session also\r\nsess = tf.InteractiveSession()\r\n# sess = tf.Session()\r\n\r\n# --- computational functions go here... once we get jpeg pic working\r\ndef make_kernel(a):\r\n  \"\"\"Transform a 2D array into a convolutional kernel \"\"\"  \r\n  a = np.asarray(a, dtype=np.float32)\r\n  a = a.reshape(list(a.shape) + [1,1])\r\n  return tf.constant(a, dtype=1)\r\n\r\n\r\ndef simple_conv(x, k):\r\n  \"\"\" A simplified 2D convolutional operation \"\"\"\r\n  x = tf.expand_dims(tf.expand_dims(x, 0), -1)\r\n  print \"simple_conv x dtype is: \", x.dtype\r\n  print \" x is ....:\", x\r\n  print \"simple_conv k dtype is: \", k.dtype\r\n  print \" k is ....:\", k\r\n  y = tf.nn.depthwise_conv2d(x, k, [1, 1, 1, 1], padding='SAME')\r\n  print \"simple_conv y dtype is: \", y.dtype\r\n  print \" y is ....\", y\r\n  return y[0, :, :, 0]\r\n\r\n\r\ndef laplace(x):\r\n  \"\"\"Compute the 2D laplacian of an array \"\"\"\r\n  laplace_k = make_kernel([[0.5, 1.0, 0.5],\r\n                           [1.0, -6., 1.0],\r\n                           [0.5, 1.0, 0.5]])  \r\n  return simple_conv(x, laplace_k)\r\n\r\n\r\n\r\n# --- Define the PDE - the pond surface is a perfect 400x400 square\r\nprint \"\\nLaplace PDE Simulation Test \\n\"\r\nN = 400\r\nprint \"Surface square side is: \",N\r\n\r\n# --- list of display points...\r\ndispval = jump_range(0, 12500, 1000)\r\n# --- dispval has to be a list...\r\ndispval = list(dispval)\r\nprint \"We will look at these values: \",dispval\r\n\r\n# --- now, we create some \"raindrops\"\r\n# --- Initial Conditions -- some rain drops hit the pond\r\n# --- set everything to zero\r\nu_init = np.zeros([N, N], dtype=np.float32)\r\nut_init = np.zeros([N, N], dtype=np.float32)\r\n\r\n# Some material accretion occurs (raindrops hit pond) at random points\r\n# for n in range(40):\r\n#   a,b = np.random.randint(0, N, 2)\r\n#   u_init[a,b] = np.random.uniform()\r\n\r\n# --- not random.  Fixed & same each run\r\nu_init[10,20]   = 1.4565\r\nu_init[12,100]  = 0.7522\r\nu_init[112,37]  = 1.21223\r\nu_init[230,139] = 0.9756\r\nu_init[301,205] = 1.7899\r\nu_init[372,347] = 0.4588\r\nu_init[74,193]  = 0.11987\r\nu_init[89,312]  = 1.1877\r\nu_init[178,287] = 1.5744\r\nu_init[197,276] = 0.9876\r\n\r\n\r\nu_init[101,21]  = 0.4565\r\nu_init[132,290] = 1.2522\r\nu_init[212,207] = 1.41223\r\nu_init[130,139] = 1.5672\r\nu_init[201,115] = 0.7899\r\nu_init[162,307] = 1.4588\r\nu_init[274,163] = 1.9187\r\nu_init[189,212] = 0.1877\r\nu_init[278,187] = 1.3744\r\nu_init[156,76]  = 1.9876\r\n\r\n\r\n# --- Create and Display the jpeg image...\r\n# proc = subprocess.Popen([\"display\", \"./tensor.jpg\"])\r\n# DisplayArray(u_init, rng=[-0.1, 0.1])\r\n\r\n# Parameters\r\n# eps -- time resolution\r\n# damping -- wave damping\r\neps = tf.placeholder(tf.float32, shape=())\r\ndamping = tf.placeholder(tf.float32, shape=())\r\n\r\n# --- Create vaiables for simulation state\r\nU  = tf.Variable(u_init)\r\nUt = tf.Variable(u_init)\r\n\r\n# --- Discretized PDE update rules\r\nU_  = U + eps * Ut\r\nUt_ = Ut + eps * (laplace(U) - damping * Ut)\r\n\r\n# --- Operation to update the state\r\nstep = tf.group(\r\n  U.assign(U_),\r\n  Ut.assign(Ut_))\r\n\r\n# --- Run the simulation forward with a simple FOR loop.\r\n# --- Initialize state to initial conditions\r\ntf.global_variables_initializer().run(session=sess)\r\n\r\n# --- Run 12701 steps of PDE\r\nfor i in range(12701):\r\n  # Step simulation  (damping was 0.04, I made it negative .14)\r\n   with sess.as_default(): step.run( {eps: 0.03, damping: -0.14})\r\n# --- to see everything...\r\n#   with sess.as_default(): print \"U.eval()   .... \", U.eval()[20]  # --- ,\"   \", Ut.eval()\r\n# ------\r\n\r\n   if (i in dispval) :\r\n       print \"                                ------ Showing iteration:  \",i\r\n       sys.stdout.flush()\r\n       with sess.as_default(): DisplayArray(U.eval(), rng=[-0.1, 0.1])\r\n       print \"                                ------ Within  iteration:  \",i\r\n       sys.stdout.flush()\r\n       print \"U.eval()[20]   ....... \"\r\n       with sess.as_default(): print   U.eval()[20]      # --- ,\"   \", Ut.eval()\r\n       print \"                                ------- End of iteration:  \",i\r\n       sys.stdout.flush()\r\n       continue\r\n#\r\n# --- to show each iteration...\r\n#  with sess.as_default(): DisplayArray(U.eval(), rng=[-0.1, 0.1])\r\nprint \"Done at: \",i\r\n\r\n# --- Ok, we are done...\r\nwith sess.as_default(): DisplayArray(U.eval(), rng=[-0.1, 0.1])\r\nprint \"U.eval()[20]   ....... \"\r\nwith sess.as_default(): print   U.eval()[20]      # --- ,\"   \", Ut.eval()\r\nprint \"Done. ---  Square side size was: \",N\r\n\r\nwith sess.as_default(): DisplayArrayToFile(U.eval(), rng=[-0.1, 0.1])\r\nprint \"Last Image Written to file: tensor_new.jpg. Done.\"   \r\n#--------------- done ------------------\r\n```\r\n", "Continued nice work - thank you so much.\r\n\r\nCan confirm on my 10.12.6 macOS install:\r\n```\r\n                                ------ Within  iteration:   1000\r\nU.eval()[20]   ....... \r\n[ 1.55104232e+00  1.91745281e-01 -1.13406909e+00  6.31072104e-01\r\n  1.93640149e+00 -3.73377651e-01 -1.74114001e+00  6.54113710e-01\r\n  1.28882718e+00 -1.54986036e+00 -1.63447249e+00  1.18530083e+00\r\n...\r\n```\r\n\r\n( @cy89 )", "Thanx quaeler, for the 10.12.6 macOS results.  Your numbers are\nsimilar, but not exactly same as on my CentOS-7.4 HP box.  (The signs\nare the same, numbers a little different, maybe 5% variance.)\nLooks like something curious with Macbook Pro, Core-i5 maybe, since it\ngoes so far different so early.\n\nI've found the Univ. of Calif. Berkeley (UCB) floating-point test\nsuite by W. Kahan, circa 1989-1992.  It is a whole bunch of Fortran-77\nprograms that check and verify floating-point math, at various levels\nof precision. Before I open up TensorFlow in any detail, I figured I\nbetter do this kind of check.  The programs use CPP (the C\npre-processor), => great bunches of #defines for different levels of\nprecision (real *4, real *8 and even real *16 (quad precision, I\nguess...)).   The Makefile's won't run, but I think I can get some of\nthe key test programs running.  This stuff was mostly written for DEC\nVax and Sun Workstations, & parts of it retain aggressive copyright\nnotices - but it has been published, so I am going to use it.\n\nI have \"gfortran\" on both CentOS and MacOS, (downloaded gfortran 5.2\nas a .dmg for the Mac), so I should be able to convert and compile at\nleast some of the programs, and see what differences I can find.  It\nlooks like the error occurs when exponents get big, ie. over 30 or 40.\n\nOnce I get some of the stuff running, I will post results - tonite or\ntomorrow.   - Mark.\n\n\nOn 1/17/18, loki der quaeler <notifications@github.com> wrote:\n> Continued nice work - thank you so much.\n>\n> Can confirm on my 10.12.6 macOS install:\n> ```\n>                                 ------ Within  iteration:   1000\n> U.eval()[20]   .......\n> [ 1.55104232e+00  1.91745281e-01 -1.13406909e+00  6.31072104e-01\n>   1.93640149e+00 -3.73377651e-01 -1.74114001e+00  6.54113710e-01\n>   1.28882718e+00 -1.54986036e+00 -1.63447249e+00  1.18530083e+00\n> ...\n> ```\n>\n> --\n> You are receiving this because you were mentioned.\n> Reply to this email directly or view it on GitHub:\n> https://github.com/tensorflow/tensorflow/issues/15933#issuecomment-358468608\n", "Attached is part of a test suite from Univ. of California Berkeley, which was used to test and verify floating point operations on several machines, from DEC VAX and Sun Microsystems machines to early P/C's. It was originally written for Fortran77.  I've converted the \"pi.F\" program (to \"pi_new.F\") to compile and run in gFortran (GNU Fortran), in DP (double-precision) mode.   What I am seeing, is that the MacOS and CentOS-7.4 Linux produce exactly the same results, up to where the remainder value reaches floating point values where the exponent is near or slightly above 25.  (see the attached single screenshot, which shows the MacOS result on the left, the CentOS-7.4 result on the right.)\r\n\r\ni downloaded and installed \"gfortran\" binary for MacOS (the version 5.2 for Yosemite), and gfortran 4.8.5 (and gcc 4.8.5) are installed with CentOS-7.4.  On the Macbook, I installed macOS gfortran ver. 5.2 (for 10.10 Yosemite), as a .dmg binary.  Fortran binaries for MacOS available here:\r\nhttps://gcc.gnu.org/wiki/GFortranBinaries\r\n\r\nThe \"pi_new.F\" program can be compiled with the following command line:\r\n\r\n```\r\ngfortran -cpp -D DP  pi_new.F -o  pi_new\r\n```\r\n\r\nThe program calculates pi using progressively larger operands, and reports the results.  It also makes \r\n![screen_shot_pi_new_test_2018_01_19_1](https://user-images.githubusercontent.com/16905336/35179205-6c4df074-fd63-11e7-831f-5e4695eea65f.png)\r\ntests for internal consistancy, which both platforms pass.  At iteration 8, the remainders are different. And at iterations 19 to 24 show serious divergence in the remainder values.   The remainder on iteration 23 on the Macbook, is the value for the the remainder for iteration 22 on the CentOS box, but with the sign flipped.   The remainder for iteration 22 on the Macbook (-1.37753244... E-40), is the value for the remainder for iteration 23 on the CentOS box, but again, with the sign flipped to positive.  But by iterations 24, 25 and 26, the results are exactly the same, only to diverge again for iterations 27 and 28.   To me, this seems to indicate a rather serious issue, which appears to be independent of TensorFlow.  The MacBook is giving different results than the 64-bit Linux box. \r\n\r\nSo far, I just have this one program converted, but I will try to convert the entire test suite, and run it to see if the MacOS - Linux 64-bit floating-point calculations divergence shows up in other calculations.\r\nThe \"pi_new.F\" program source is below...\r\n\r\n```\r\nC \"@(#)pirats.F 1.2 92/05/29 SMI\"\r\n\r\n#define STDERR 0\r\n#define STDOUT 6\r\n#define STDIN 5\r\n#ifdef SP\r\n#define REAL real*4\r\n#define EXPO e0\r\n#endif\r\n#ifdef DP\r\n#define REAL real*8\r\n#define EXPO d0\r\n#endif\r\n#ifdef QP\r\n#define REAL real*16\r\n#define EXPO q0\r\n#endif\r\n\r\n#ifdef TRIGP\r\n#define SIN sinp\r\n#define COS cosp\r\n#define TAN tanp\r\n#define ASIN asinp\r\n#define ACOS acosp\r\n#define ATAN atanp\r\n#else\r\n#define SIN sin\r\n#define COS cos\r\n#define TAN tan\r\n#define ASIN asin\r\n#define ACOS acos\r\n#define ATAN atan\r\n#endif\r\n\r\n      PROGRAM PIRATS\r\nC\r\nC.... PIRATS                     Copyright (C) by W. Kahan, Mar. 8, 1989\r\nC\r\nC.... This program finds close rational approximations\r\nC.... A/B to PI, and computes the differences C = PI-A/B to\r\nC.... working precision within errors no bigger than E.  Working\r\nC.... precision arithmetic is presumed to carry no more than about\r\nC.... 110 sig. dec., and to be rounded reasonably like a DEC VAX\r\nC.... or an HP calculator or in conformity with IEEE 754/854.\r\nC.... Then the program tests argument reductions in functions SIN,\r\nC.... COS and TAN, checking to see whether they are consistent\r\nC.... with the hypothesis that their actual periods are some single\r\nC.... close approximation 2*P to 2*PI if not 2*PI itself.\r\nC\r\n      INTEGER NPI\r\n      PARAMETER (NPI = 210)\r\nC\r\nC.... The following array of NPI+1 divisors D(J) > 0 in the continued\r\nC.... fraction PI = D(0)+1/(D(1)+1/(D(2)+1/(D(3)+...))) will incur an\r\nC.... error in PI no worse than 3.6E-234. Only D(NPI) isn't an integer.\r\nC.... This data is based upon DJ's computed by Stewart McDonald\r\nC.... in 1983 from an algorithm due to W. Gosper.  W. K.\r\nC\r\n      INTEGER I,J,INC\r\n      REAL D(0:NPI),EPS,RDX,FL,A,B,C,E,R\r\n      DATA (D(I),I = 0,99)/\r\n     1   3. EXPO ,7. EXPO ,15. EXPO ,1. EXPO ,292. EXPO ,1. EXPO ,\r\n     1\t1. EXPO ,1. EXPO ,2. EXPO ,1. EXPO ,\r\n     2   3. EXPO ,1. EXPO ,14. EXPO ,2. EXPO ,1. EXPO ,1. EXPO ,\r\n     1\t2. EXPO ,2. EXPO ,2. EXPO ,2. EXPO ,\r\n     3   1. EXPO ,84. EXPO ,2. EXPO ,1. EXPO ,1. EXPO ,15. EXPO ,\r\n     1\t3. EXPO ,13. EXPO ,1. EXPO ,4. EXPO ,\r\n     4   2. EXPO ,6. EXPO ,6. EXPO ,99. EXPO ,1. EXPO ,2. EXPO ,\r\n     1\t2. EXPO ,6. EXPO ,3. EXPO ,5. EXPO ,\r\n     5   1. EXPO ,1. EXPO ,6. EXPO ,8. EXPO ,1. EXPO ,7. EXPO ,1. EXPO,\r\n     1\t2. EXPO ,3. EXPO ,7. EXPO ,\r\n     6   1. EXPO ,2. EXPO ,1. EXPO ,1. EXPO ,12. EXPO ,1. EXPO ,\r\n     1\t1. EXPO ,1. EXPO ,3. EXPO ,1. EXPO ,\r\n     7   1. EXPO ,8. EXPO ,1. EXPO ,1. EXPO ,2. EXPO ,1. EXPO ,6. EXPO,\r\n     1\t1. EXPO ,1. EXPO ,5. EXPO ,\r\n     8   2. EXPO ,2. EXPO ,3. EXPO ,1. EXPO ,2. EXPO ,4. EXPO ,4. EXPO,\r\n     1 \t16. EXPO ,1. EXPO ,161. EXPO , 45. EXPO ,1. EXPO ,22. EXPO ,\r\n     1\t1. EXPO ,2. EXPO ,2. EXPO,1. EXPO,4. EXPO ,1. EXPO ,2. EXPO ,\r\n     2  24. EXPO ,1. EXPO ,2. EXPO ,1. EXPO ,3. EXPO ,1. EXPO ,2. EXPO, \r\n     1  1. EXPO ,1. EXPO ,10. EXPO /\r\n\r\n      DATA (D(I),I = 100,199)/\r\n     1   2. EXPO ,5. EXPO ,4. EXPO ,1. EXPO ,2. EXPO ,2. EXPO ,8. EXPO ,\r\n     1\t1. EXPO ,5. EXPO ,2. EXPO ,\r\n     2   2. EXPO ,26. EXPO ,1. EXPO ,4. EXPO ,1. EXPO ,1. EXPO ,8. EXPO \r\n     1\t,2. EXPO ,42. EXPO ,2. EXPO ,\r\n     3   1. EXPO ,7. EXPO ,3. EXPO ,3. EXPO ,1. EXPO ,1. EXPO ,7. EXPO ,\r\n     1\t2. EXPO ,4. EXPO ,9. EXPO ,\r\n     4   7. EXPO ,2. EXPO ,3. EXPO ,1. EXPO ,57. EXPO ,1. EXPO ,18. EXPO\r\n     1\t ,1. EXPO ,9. EXPO ,19. EXPO ,\r\n     5   1. EXPO ,2. EXPO ,18. EXPO ,1. EXPO ,3. EXPO ,7. EXPO ,30. EXPO\r\n     1\t ,1. EXPO ,1. EXPO ,1. EXPO ,\r\n     6   3. EXPO ,3. EXPO ,3. EXPO ,1. EXPO ,2. EXPO ,8. EXPO ,1. EXPO ,\r\n     1\t1. EXPO ,2. EXPO ,1. EXPO ,\r\n     7   15. EXPO ,1. EXPO ,2. EXPO ,13. EXPO ,1. EXPO ,2. EXPO ,1. EXPO\r\n     1\t ,4. EXPO ,1. EXPO ,12. EXPO ,\r\n     8   1. EXPO ,1. EXPO ,3. EXPO ,3. EXPO ,28. EXPO ,1. EXPO ,10. EXPO\r\n     1\t ,3. EXPO ,2. EXPO ,20. EXPO ,\r\n     9   1. EXPO ,1. EXPO ,1. EXPO ,1. EXPO ,4. EXPO ,1. EXPO ,1. EXPO ,\r\n     1\t1. EXPO ,5. EXPO ,3. EXPO , 2. EXPO ,1. EXPO ,6. EXPO ,1. EXPO ,\r\n     1\t4. EXPO ,1. EXPO ,120. EXPO ,2. EXPO ,1. EXPO ,1. EXPO /\r\n      DATA (D(I),I = 200,NPI)/\r\n     1   3. EXPO ,1. EXPO ,23. EXPO ,1. EXPO ,15. EXPO ,1. EXPO ,3. EXPO\r\n     1\t ,7. EXPO ,1. EXPO ,16. EXPO ,\r\n     2   1.338371961073448 EXPO \r\n     3   /\r\nC\r\nC.... Environmental constants EPS, RDX, FL\r\nC\r\n      CALL ENVCNS(EPS,RDX,FL)\r\nC\r\nC.... for adequate accuracy\r\nC\r\n      INC = INT(LOG(FL)/LOG(2.6 EXPO ))\r\nC\r\n      PRINT 1000\r\n1000  FORMAT(1X,'PIRATS: computes  PI = A/B+C and R = PI-P.'/\r\n     1   /1X,1X,'J',1X,18X,'A',18X,'/',18X,'B'\r\n     2   /1X,2X,1X,27X,'+',5X,'C'\r\n     3   /1X,2X,1X,41X,'R',5X,'+/-',5X,'E'\r\n     4   )\r\nC\r\nC.... Initialize A, B\r\nC\r\n      A = D(0)\r\n      B = 1. EXPO \r\nC\r\n      DO 100 J = 1,NPI-INC+5\r\nC\r\nC.... Get next pair A, B\r\nC\r\n         CALL NEXTAB(D(J),A,B)\r\n         IF (A.GT.FL.OR.B.GT.FL) THEN\r\n\t    GOTO 110\r\n\t ENDIF\r\nC\r\nC....    Get C = PI-A/B+/-E\r\nC\r\n         CALL GETCE(NPI,J,INC,EPS,FL,D,C,E)\r\nC\r\nC....    Get R = PI-P+/-E\r\nC\r\n         CALL TSTRIG(EPS,A,B,C,E,R)\r\nC\r\nC....    Display these numbers\r\nC\r\n         CALL DISPLA(J,A,B,C,E,R)\r\nC\r\nC....    Test them for consistency\r\nC\r\n         CALL COMPAR(E,R)\r\n100   CONTINUE\r\n110   CONTINUE\r\nC\r\nC.... Normal termination.\r\nC\r\n      PRINT *,'Pi.F -- Normal Termination. '\r\n      PRINT *,'I want to: call ucbpass'\r\nC      call ucbpass\r\n      STOP\r\n      END\r\nC\r\n\tREAL function volatilizer(x)\r\n\tREAL x\r\n\tvolatilizer=x\r\n\tend\r\n\r\n      SUBROUTINE ENVCNS(EPS,RDX,FL)\r\n      REAL EPS,RDX,FL\r\nC\r\nC.... Environmental constants.  This subroutine computes\r\nC....    EPS = nextafter(1,2)-1 = 1.000...001-1\r\nC....    RDX = RaDiX of floating-point arithmetic (2, 10, 16)\r\nC....    FL = RDX/EPS = last of consecutive floating-point integers\r\nC....                       among 1, 2, 3, ..., FL-2, FL-1, FL.\r\nC\r\nC.... local variables\r\nC\r\n\tREAL volatilizer\r\n      REAL H,X,Y,T,U,V\r\nC\r\nC.... First seek EPS\r\nC\r\n      T = 4. EXPO /3. EXPO \r\n      X = T-1. EXPO \r\n      Y = ABS((X+X-1. EXPO )+X)/64. EXPO \r\n      EPS = 0. EXPO \r\n      IF (Y.EQ.0. EXPO ) THEN\r\n\t PRINT *,'Is 4/3 exact?'\r\n         GOTO 299\r\n      ENDIF\r\n200   IF (EPS.NE.0. EXPO ) GOTO 210\r\n         U = volatilizer(1. EXPO +Y)\r\n         EPS = volatilizer(U-1. EXPO) \r\n         Y = Y+Y\r\n      GOTO 200\r\nC\r\nC     Now seek EPS/RDX = 1-nextafter(1,0) = 1-0.999...999 :\r\nC\r\n210   H = 1. EXPO /2. EXPO \r\n      T = 2. EXPO /3. EXPO \r\n      X = T-H\r\n      Y = ABS((X+X-H)+X)/64. EXPO \r\n      V = 0. EXPO \r\n      IF (Y.EQ.0. EXPO ) THEN\r\n\t PRINT *,'Is 2/3 exact?'\r\n         GOTO 299\r\n      ENDIF\r\n220   IF (V.NE.0. EXPO ) GOTO 230\r\n         U = volatilizer((H-Y)+H)\r\n         V = volatilizer((H-U)+H)\r\n         Y = Y+Y\r\n      GOTO 220\r\nC\r\nC.... in case Division is dirty\r\nC\r\n230   RDX = AINT(EPS/V+0.0001 EXPO )\r\n      IF (RDX.LT.2. EXPO ) THEN\r\n\t PRINT 5000,'Radix =',RDX\r\n5000     FORMAT(1X,A,F4.0)\r\n         GOTO 299\r\n      ENDIF\r\nC\r\nC.... Confirm that RDX = Radix of Floating-point arithmetic.\r\nC\r\n      T = RDX\r\n      X = 1. EXPO \r\nC\r\nC.... until X.EQ.0 or X.EQ.RDX\r\nC\r\n240   IF (X.NE.1. EXPO ) GOTO 250\r\n         T = T+T\r\n         U = volatilizer(T+1. EXPO)\r\n         X = volatilizer(U-T)\r\n      GOTO 240\r\n250   IF (X.EQ.0. EXPO ) THEN\r\n         Y = 1. EXPO \r\n260      IF (X.NE.0. EXPO ) GOTO 270\r\n            Y = Y+Y\r\n            U = volatilizer(T+Y)\r\n            X = volatilizer(U-T)\r\n\t GOTO 260\r\n      ENDIF\r\n270   IF (X.NE.RDX) THEN\r\n         PRINT 6000,'Is Radix ',X,' or ',RDX,'?'\r\n6000     FORMAT(1X,A,F4.0,A,F4.0,A)\r\n\t GOTO 299\r\n      ENDIF\r\nC\r\nC.... Confirm that FL = RDX/EPS:\r\nC\r\n      FL = RDX\r\n      X = 1. EXPO \r\n280   IF (X.NE.1. EXPO ) GOTO 290\r\n         FL = volatilizer(FL*RDX)\r\n\t U = volatilizer(FL+1. EXPO)\r\n\t X = volatilizer(U-FL)\r\n      GOTO 280\r\n290   IF (FL*V.EQ.1. EXPO ) THEN\r\n\t RETURN\r\n      ENDIF\r\nC\r\nC.... ENVCNS cannot compute environmental constants correctly:\r\nC\r\n      PRINT 3000,'Is FL ',FL,' or ',1. EXPO /V,'?'\r\n3000  FORMAT(1X,A6,1PE45.37E3/1X,2X,A4,1PE45.37E3,A1)\r\n299   PRINT *,'Subroutine ENVCNS cannot compute correctly the'\r\n      PRINT *,'Environmental constants'\r\n      PRINT *,'EPS = 1.000...001 - 1 , and'\r\n      PRINT *,'FL = Last consecutive Floating-point integer'\r\n      PRINT *,'        among 1, 2, 3, ..., FL-2, FL-1, FL.'\r\n      PRINT *,'Please substitute them for the subroutine.'\r\n      PRINT *,'I want to: call ucbfail'\r\nC\tcall ucbfail\r\n      STOP\r\n      END\r\nC\r\n      SUBROUTINE NEXTAB(DJ,A,B)\r\n      REAL DJ,A,B\r\nC\r\nC.... Get next pair A, B\r\nC\r\nC.... local variables\r\nC\r\n      REAL T,A0,B0\r\n      SAVE A0,B0\r\n      DATA A0,B0/1. EXPO ,0. EXPO /\r\nC\r\n      T = DJ*B+B0\r\n      B0 = B\r\n      B = T\r\n      T = DJ*A+A0\r\n      A0 = A\r\n      A = T\r\nC\r\nC.... Now A/B = D0+1/(D1+1/(D2+...+1/DJ)).\r\nC\r\n      RETURN\r\n      END\r\nC\r\n      SUBROUTINE GETCE(NPI,J,INC,EPS,FL,D,C,E)\r\n      INTEGER NPI,J,INC\r\n      REAL EPS,FL,D(0:NPI),C,E\r\nC\r\nC.... This subroutine computes the continued fraction's tail\r\nC....    Z = D(J+1)+1/(D(J+2)+1/(D(J+3)+1/(D(J+4)+...)))\r\nC.... to working accuracy by using INC terms of it, and then\r\nC.... computes the effect C of cutting it off to get A/B .\r\nC....\r\nC.... Get  C = PI-A/B+/-E\r\nC\r\nC.... local variables\r\nC\r\n      INTEGER I,I9\r\n      REAL X,Y,Z\r\nC\r\n      I9 = MIN(NPI,J+INC)\r\n      Z = D(I9)\r\n      DO 400 I = I9-1,J+1,-1\r\n         Z = D(I)+1. EXPO /Z\r\n400   CONTINUE\r\n      X = FL*FL\r\nC\r\nC.... C = 1/Z-1/X always\r\nC\r\n      C = 1. EXPO /Z-1. EXPO /X\r\n      DO 410 I = J,1,-1\r\n\t Y = D(I)\r\n         Z = Y+1. EXPO /Z\r\n\t X = Y+1. EXPO /X\r\n\t C = -C/(X*Z)\r\n410   CONTINUE\r\nC\r\nC.... E > accumulated roundoff (mixed arithmetic)\r\nC\r\n      E = 4. EXPO *J*EPS*ABS(C)\r\n      RETURN\r\n      END\r\nC\r\n      SUBROUTINE TSTRIG(EPS,A,B,C,E,R)\r\n      REAL EPS,A,B,C,E,R\r\nC\r\nC.... Get R = PI-P+/-E\r\nC\r\nC     This subroutine tests whether the programs that compute\r\nC     TRIG(X) = trig(X*PI/P) for TRIG = SIN, COS or TAN\r\nC     always use the same approximation P to PI during their\r\nC     argument reduction.  If so, 3 or 4 values R = Q+C\r\nC     derived from A = B*(PI-C+/-E) ought to agree.\r\nC\r\nC.... local variables\r\nC\r\n      REAL Q,Q0,S,W,W0,X,Y\r\n      CHARACTER*11 TS\r\nC\r\n      REAL FNODD\r\n      CHARACTER FNS\r\nC\r\n      CHARACTER*10 SI,CO,TA\r\n      DATA SI,CO,TA/'arcsin(sin','arcsin(cos','arctan(tan'/\r\nC\r\nC.... FNODD(floating-point integer X) = (-1)**X\r\nC\r\n      FNODD(X) = (AINT(ABS(X)*0.5 EXPO +0.125 EXPO )*2. EXPO -ABS(X))*\r\n     1\t2. EXPO +1. EXPO \r\nC\r\nC.... FNS(1) = '+', FNS(-1) = '-'\r\nC\r\n      FNS(X) = CHAR(44-INT(X))\r\nC\r\n      Q = ATAN(TAN(A))/B\r\n      R = Q+C\r\n      W = 3. EXPO *EPS*ABS(Q)\r\n      E = E+W\r\n      S = FNODD(B)\r\n      X = A\r\n      Y = B\r\n      TS = FNS(S)//SI\r\n      Q0 = ASIN(SIN(X))/Y*S\r\n      W0 = W+6. EXPO *EPS*ABS(Q0)\r\n      CALL WHET(Q,Q0,W0,X,Y,A,B,TS,TA)\r\n      X = A*0.5 EXPO \r\n      Y = B*0.5 EXPO \r\n      IF (S.LT.0. EXPO ) THEN\r\nC\r\nC....    (B+1) is even\r\nC\r\n         S = FNODD((B+1. EXPO )*0.5 EXPO )\r\n         TS = FNS(S)//CO\r\n         Q0 = ASIN(COS(X))/Y*S\r\n         W0 = W+6. EXPO *EPS*ABS(Q0)\r\n      ELSE\r\nC\r\nC....    B = 2y is even\r\nC\r\n         TS = ' '//TA\r\n         Q0 = ATAN(TAN(X))/Y\r\n         W0 = 3. EXPO *EPS*ABS(Q0)\r\n\t CALL WHET(Q,Q0,W0,X,Y,A,B,TS,TA)\r\n         S = FNODD(Y)\r\n         TS = FNS(S)//SI\r\n\t Q0 = ASIN(SIN(X))/Y*S\r\n         W0 = W+6. EXPO *EPS*ABS(Q0)\r\n      ENDIF\r\n      CALL WHET(Q,Q0,W0,X,Y,A,B,TS,TA)\r\n      RETURN\r\n      END\r\nC\r\n      SUBROUTINE WHET(Q,Q0,W0,X,Y,A,B,TS,TA)\r\n      REAL Q,Q0,W0,X,Y,A,B\r\n      CHARACTER*(*) TS,TA\r\nC\r\nC.... Test whether Q0.EQ.Q within +/- W0 (.GE.->.GT.)\r\nC\r\n      IF (ABS(Q-Q0).GT.W0) THEN\r\nC\r\nC....    Difference too big suggests P is not a constant after all.\r\nC\r\n         PRINT 4000,TS,X,')/',Y,' =',Q0,' differs from ',\r\n     1      TA,A,')/',B,' =',Q,' too much.'\r\n4000  FORMAT(/1X,4X,70('%')\r\n     1   /1X,4X,A11,0PF38.1,A\r\n     2   /1X,4X,11X,0PF38.1,A\r\n     3   /1X,4X,11X,1PE45.37E3,A\r\n     4   /1X,4X,1X,A10,0PF38.1,A\r\n     5   /1X,4X,11X,0PF38.1,A\r\n     6   /1X,4X,11X,1PE45.37E3,A\r\n     7   /1X,4X,70('%')\r\n     8   /)\r\n\r\n\r\n      PRINT *,'I want to: call ucbfail'\r\nC\tcall ucbfail\r\n      ENDIF\r\n      RETURN\r\n      END\r\nC\r\n      SUBROUTINE DISPLA(J,A,B,C,E,R)\r\n      INTEGER J\r\n      REAL A,B,C,E,R\r\nC\r\nC     Display Formatting\r\nC\r\nC.... display  J, A, B, C, R, E\r\nC\r\n      PRINT 2000,J,A,B,C,R,E\r\n2000  FORMAT(1X,I2,1X,F37.0,'/',F37.0\r\n     1   /1X,2X,1X,27X,'+',1X,1PE45.37E3\r\n     2   /1X,2X,1X,1X,1PE45.37E3,1X,'+/-',1PE16.8E3\r\n     3   )\r\n      RETURN\r\n      END\r\nC\r\n      SUBROUTINE COMPAR(E,R)\r\n      REAL E,R\r\nC\r\nC.... test for consistency\r\nC\r\nC.... local variables\r\nC\r\n      REAL E0,R0\r\n      SAVE E0,R0\r\n      DATA E0,R0/0.1416 EXPO ,0. EXPO /\r\nC\r\nC.... .LT.->.LE.\r\nC\r\n      IF (ABS(R-R0).LE.E+E0) THEN\r\n\t E0 = E\r\n         R0 = R\r\n      ELSE\r\n         PRINT *,'Varying R implies defective argument reduction.'\r\n         PRINT *,'I want to: call ucbfail'\r\nC\tcall ucbfail\r\n         STOP\r\n      ENDIF\r\n      RETURN\r\n      END\r\n```\r\n\r\nWill update here with results for full ucb floating point test suite when I get it to compile & run.", "Same divergent results for macOS 10.12.6 (gfortran 6.3.0) v. Ubuntu 17.10 (gfortran 7.2.0) running on the same hardware (i7-5557U)\r\n\r\n![screen shot 2018-01-19 at 7 55 48 pm](https://user-images.githubusercontent.com/22581048/35179637-21962cd2-fd53-11e7-9be1-30187cb4eb77.png)\r\n\r\n", "Different symptoms but same problem here.  Running MacOS 10.13.02.  Running Python 3.6.0.\r\n\r\nTensorflow 1.4.1 produces not just different results but essentially erroneous results.  A very simple conv_net fails to converge, but does converge with 1.2.1.  \r\n\r\nThe sample data and the nn design come from the Coursera deeplearning.ai course sequence.  They provide sandboxed Jupyter notebooks that run Python 3.5 with tensorflow 1.2.1.\r\n\r\nSeems like a serious problem with tf 1.4.1, which seems to be latest version that PyPi provides with Python binding.\r\n\r\nWhen 1.5 has released python bindings and a pre-compiled binary I'll give it a try.", "I can confirm that the same problem occurs with the latest (as of 1/20/2018) nightly build:\r\n1.6.0-dev20180119.  I'd say this problem is very severe. I am downgrading to 1.2.1.", "Thanx quaeler and lewisl for posting your results.  This gets more interesting and surprising the deeper we go.  I had expected an upgrade to MacOS and Xcode+gfortran would probably resolve the divergence issue, but quaeler's results show this not to be the case.  And lewisl's situation seems to confirm my worst fears - that this apparently tiny divergence could result in the failure of a network to train correctly.\r\n\r\nThe Fortran test program is part of a suite of tests from Univ. of California Berkeley, which I found on the Utah site, where a collection of floating-point arithmetic tests are located, its url is: http://www.math.utah.edu/~beebe/software/ieee/#other.   The UCB test suite looks like it was developed by W. Kahan who worked on (\"invented\" might be the better term) the IEEE 754 arithmetic methods, and it was then extended by Sun Microsystems.  This was a big issue back in 1995, when the first Pentium chip came to market, and was shown to have a critical flaw in it's floating-point hardware, where it would produce wrong results under certain special circumstances.  Test suites were developed to verify floating-point math, and run multiple tests for both accuracy and consistancy of results.\r\n\r\nThe Utah software collection refers to the UCB test suite, and it can be downloaded as a tarball from:  http://www.netlib.org/fp/ucbtest.tgz\r\n\r\nI've downloaded this test suite, and converted enough of it to get it running on both the MacOS and CentOS-7.4.  It is fairly comprehensive, and identifies several \"ulp\" differences - both on each machine, and between the two platforms.  (\"Ulp\" is the term used which means \"unit in the last place\", and is considered a better measure and check of floating-point accuracy than the term \"epsilon\").. (Here is a note about 'ulp':  https://www.jessesquires.com/blog/floating-point-swift-ulp-and-epsilon/  )\r\n\r\nThe \"UCBTest\" suite is useful in that it runs both C and Fortran programs, in both single-precision and double-precision (53 bit significance).  I've converted it so it now compiles and runs on both 64-bit machines.  (I might have made conversion errors, keep that in mind.  There are compile warnings...)\r\n\r\nFor now, running the full test suite on both machines results in 47 out of 56 tests passing on the CentOS/HP box, and 45 out of 56 tests passing on the MacOS/MacBook.  I am still checking details, but there is one program (which compiles into four different executables: cpar_SP, cpar_DP, fpar_SP and fpar_DP => c = C source, f = Fortran source, SP=single precision, DP=double precision), and the \"par\" refers to \"paranoid\" - implies you run this because you are concerned your numbers are not being calculated correctly! ).  The results of all four \"par\" programs indicated \"UCBPASS\" on both machines, so there does not seem to be anything obviously wrong related to rounding and/or plus/minus infinity and the handling of \"NaN\" (not a number) values.\r\n\r\nAttached screen images show results of the full UCBTest suite, run on each machine.  Note that the \"NME\" and the \"PME\" (Negative Maximum and Postive Maximum ULP error observed) for the last test displayed (the LOG(X) test) is slightly different between each machine.   Also, it took some effort to get the UCBTest suite to compile and run on each machine  (some of the code is quite old), and the tests run directly from the Makefiles that are used to build the programs, which complicates conversion.   Some of the \"fails\" could be due to conversion issues.  But this suite of tests is comprehensive, and is highlighting other divergence issues.   I want continue down this \"rabbit-hole\" until I can get a clearer sense of what is going on, and why the MacOS seems to be generating different results than the Linux platforms.  We now know that both CentOS and Ubuntu - current versions - seem to agree on how they do their math - but the MacOS is producing different results. \r\n\r\nI just want to caution that I might be making a mistake or an error in conversion, here.  In an effort to factor out issues that might be related to the \"gfortran\" compiler, I have been looking at the results generated by the C programs.  There appear to be cases where the divergence is serious.  I want to make sure I am getting proper compile results on each platform.\r\n![screenshot_macos_full_ucbtest_2018-01-23_11d47am](https://user-images.githubusercontent.com/16905336/35289540-a180f9f6-0035-11e8-8cec-9f46d1b72d9d.png)\r\n![screenshot_centos_run_ucbtest_23jan2018](https://user-images.githubusercontent.com/16905336/35289565-b1342652-0035-11e8-83dc-ef485944fd47.png)\r\n", "Let me know if there is more I can provide. I can provide the jupyter notebook of the python code if that would be helpful.\r\n\r\nThanks for all your serious digging.\r\n\r\n- Lewis\r\n\r\nOn Jan 23, 2018, at 12:17 PM, GemesysCanada <notifications@github.com<mailto:notifications@github.com>> wrote:\r\n\r\n\r\nThanx quaeler and lewisl for posting your results. This gets more interesting and surprising the deeper we go. I had expected an upgrade to MacOS and Xcode+gfortran would probably resolve the divergence issue, but quaeler's results show this not to be the case. And lewisl's situation seems to confirm my worst fears - that this apparently tiny divergence could result in the failure of a network to train correctly.\r\n\r\nThe Fortran test program is part of a suite of tests from Univ. of California Berkeley, which I found on the Utah site, where a collection of floating-point arithmetic tests are located, its url is: http://www.math.utah.edu/~beebe/software/ieee/#other<http://www.math.utah.edu/%7Ebeebe/software/ieee/#other>. The UCB test suite looks like it was developed by W. Kahan who worked on (\"invented\" might be the better term) the IEEE 754 arithmetic methods, and it was then extended by Sun Microsystems. This was a big issue back in 1995, when the first Pentium chip came to market, and was shown to have a critical flaw in it's floating-point hardware, where it would produce wrong results under certain special circumstances. Test suites were developed to verify floating-point math, and run multiple tests for both accuracy and consistancy of results.\r\n\r\nThe Utah software collection refers to the UCB test suite, and it can be downloaded as a tarball from: http://www.netlib.org/fp/ucbtest.tgz\r\n\r\nI've downloaded this test suite, and converted enough of it to get it running on both the MacOS and CentOS-7.4. It is fairly comprehensive, and identifies several \"ulp\" differences - both on each machine, and between the two platforms. (\"Ulp\" is the term used which means \"unit in the last place\", and is considered a better measure and check of floating-point accuracy than the term \"epsilon\").. (Here is a note about 'ulp': https://www.jessesquires.com/blog/floating-point-swift-ulp-and-epsilon/ )\r\n\r\nThe \"UCBTest\" suite is useful in that it runs both C and Fortran programs, in both single-precision and double-precision (53 bit significance). I've converted it so it now compiles and runs on both 64-bit machines. (I might have made conversion errors, keep that in mind. There are compile warnings...)\r\n\r\nFor now, running the full test suite on both machines results in 47 out of 56 tests passing on the CentOS/HP box, and 45 out of 56 tests passing on the MacOS/MacBook. I am still checking details, but there is one program (which compiles into four different executables: cpar_SP, cpar_DP, fpar_SP and fpar_DP => c = C source, f = Fortran source, SP=single precision, DP=double precision), and the \"par\" refers to \"paranoid\" - implies you run this because you are concerned your numbers are not being calculated correctly! ). The results of all four \"par\" programs indicated \"UCBPASS\" on both machines, so there does not seem to be anything obviously wrong related to rounding and/or plus/minus infinity and the handling of \"NaN\" (not a number) values.\r\n\r\nAttached screen images show results of the full UCBTest suite, run on each machine. Note that the \"NME\" and the \"PME\" (Negative Maximum and Postive Maximum ULP error observed) for the last test displayed (the LOG(X) test) is slightly different between each machine. Also, it took some effort to get the UCBTest suite to compile and run on each machine (some of the code is quite old), and the tests run directly from the Makefiles that are used to build the programs, which complicates conversion. Some of the \"fails\" could be due to conversion issues. But this suite of tests is comprehensive, and is highlighting other divergence issues. I want continue down this \"rabbit-hole\" until I can get a clearer sense of what is going on, and why the MacOS seems to be generating different results than the Linux platforms. We now know that both CentOS and Ubuntu - current versions - seem to agree on how they do their math - but the MacOS is producing different results.\r\n\r\nI just want to caution that I might be making a mistake or an error in conversion, here. In an effort to factor out issues that might be related to the \"gfortran\" compiler, I have been looking at the results generated by the C programs. There appear to be cases where the divergence is serious. I want to make sure I am getting proper compile results on each platform.\r\n[screenshot_macos_full_ucbtest_2018-01-23_11d47am]<https://user-images.githubusercontent.com/16905336/35289540-a180f9f6-0035-11e8-8cec-9f46d1b72d9d.png>\r\n[screenshot_centos_run_ucbtest_23jan2018]<https://user-images.githubusercontent.com/16905336/35289565-b1342652-0035-11e8-83dc-ef485944fd47.png>\r\n\r\n\u2014\r\nYou are receiving this because you commented.\r\nReply to this email directly, view it on GitHub<https://github.com/tensorflow/tensorflow/issues/15933#issuecomment-359861868>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ABGLLbx0vHOJSGX1bwAkH4pPpWQtJOiRks5tNhQzgaJpZM4RVyqU>.\r\n", "It was possible that the gfortran compiler might be responsible for the divergence in results between MacOS and Linux, so here is the C version of Kahan's PIRATS test program.  I basically just hacked it out of the UCBTest suite, and made a stand-alone version of it.  It can be compiled and run on MacOS under Apple's gcc (on Macbook: \"gcc --version\" reports: LLVM 7.0.2 (clang-700.1.81)) and CentOS-7.4 Linux (Same results seen on  Ubuntu also, as per what quaeler has reported). (My version of CentOS's gcc reports for \"gcc --version\":  4.8.5  20150623 (Red Hat 4.8.5-16)). \r\n\r\nThis C version of PIRATS shows the same divergence as the gFortran version does.  I've provided it here, because it make it easier to run this on different machines to see what results are reported - i.e. no need to download and install a version of gfortran.   Interestingly, the \"single precision\" versions of PIRATS generate results that are exactly the same across both machines.  And the gfortran versions on both machines match exactly the C version results obtained on each machine.  So, regardless of using C or gFortran, the same divergence is evident between MacOS and Linux.  And based on quaeler's results, the divergence that PIRATS demostrates is evident across old and new versions of MacOS, versus current CentOS and Ubuntu Linux.   \r\n\r\n```\r\n/*\r\nC.... PIRATS                     Copyright (C) by W. Kahan, Mar. 8, 1989\r\nC\r\nC.... This program finds close rational approximations\r\nC.... A/B to PI, and computes the differences C = PI-A/B to\r\nC.... working precision within errors no bigger than E.  Working\r\nC.... precision arithmetic is presumed to carry no more than about\r\nC.... 110 sig. dec., and to be rounded reasonably like a DEC VAX\r\nC.... or an HP calculator or in conformity with IEEE 754/854.\r\nC.... Then the program tests argument reductions in functions SIN,\r\nC.... COS and TAN, checking to see whether they are consistent\r\nC.... with the hypothesis that their actual periods are some single\r\nC.... close approximation 2*P to 2*PI if not 2*PI itself.\r\nC\r\nc     INTEGER NPI\r\nc     PARAMETER (NPI = 210)\r\nC\r\nC.... The following array of NPI+1 divisors D(J) > 0 in the continued\r\nC.... fraction PI = D(0)+1/(D(1)+1/(D(2)+1/(D(3)+...))) will incur an\r\nC.... error in PI no worse than 3.6E-234. Only D(NPI) isn't an integer.\r\nC.... This data is based upon DJ's computed by Stewart McDonald\r\nC.... in 1983 from an algorithm due to W. Gosper.  W. K.\r\nC\r\nC --- Mod. standalone - Mark Langdon, GEMESYS Ltd., Waterloo, Jan.2018\r\nC --- to check Clang/Xcode on MacOS versus gcc (GCC) 4.8.5 on CentOS-7.4 \r\nC --- for # divergence related to curious behaviour of TensorFlow 1.4.1\r\n*/\r\n\r\n#include \"ucbtest.h\"\r\n\r\ntypedef long int integer;\r\ntypedef char *address;\r\n\r\ntypedef long ftnlen;\r\n\r\n#define VOID void\r\n\r\n#define abs(x) ((x) >= 0 ? (x) : -(x))\r\n#define min(a,b) ((a) <= (b) ? (a) : (b))\r\n#define aint(x) ((x>0) ? FLOOR(x) : -FLOOR(-x) )\r\n\r\n/* Table of constant values */\r\n\r\nstatic integer c__210 = 210;\r\nstatic integer c__2 = 2;\r\n\r\n/* Main program */ MAIN__()\r\n{\r\n    /* Initialized data */\r\n\r\n    static GENERIC d[211] = { 3.,7.,15.,1.,292.,1.,1.,1.,2.,1.,3.,1.,14.,\r\n\t    2.,1.,1.,2.,2.,2.,2.,1.,84.,2.,1.,1.,15.,3.,13.,1.,4.,2.,6.,6.,\r\n\t    99.,1.,2.,2.,6.,3.,5.,1.,1.,6.,8.,1.,7.,1.,2.,3.,7.,1.,2.,1.,1.,\r\n\t    12.,1.,1.,1.,3.,1.,1.,8.,1.,1.,2.,1.,6.,1.,1.,5.,2.,2.,3.,1.,2.,\r\n\t    4.,4.,16.,1.,161.,45.,1.,22.,1.,2.,2.,1.,4.,1.,2.,24.,1.,2.,1.,3.,\r\n\t    1.,2.,1.,1.,10.,2.,5.,4.,1.,2.,2.,8.,1.,5.,2.,2.,26.,1.,4.,1.,1.,\r\n\t    8.,2.,42.,2.,1.,7.,3.,3.,1.,1.,7.,2.,4.,9.,7.,2.,3.,1.,57.,1.,18.,\r\n\t    1.,9.,19.,1.,2.,18.,1.,3.,7.,30.,1.,1.,1.,3.,3.,3.,1.,2.,8.,1.,1.,\r\n\t    2.,1.,15.,1.,2.,13.,1.,2.,1.,4.,1.,12.,1.,1.,3.,3.,28.,1.,10.,3.,\r\n\t    2.,20.,1.,1.,1.,1.,4.,1.,1.,1.,5.,3.,2.,1.,6.,1.,4.,1.,120.,2.,1.,\r\n\t    1.,3.,1.,23.,1.,15.,1.,3.,7.,1.,16.,1.338371961073448 };\r\n\r\n    /* System generated locals */\r\n    integer i__1;\r\n\r\n    /* Local variables */\r\n    static GENERIC a, b, c, e;\r\n    static integer j;\r\n    static GENERIC r;\r\n    extern /* Subroutine */ int getce_();\r\n    static GENERIC fl;\r\n    extern /* Subroutine */ int displa_(), nextab_(), compar_(), envcns_(), \r\n\t    tstrig_();\r\n    static integer inc;\r\n    static GENERIC eps, rdx;\r\n\r\n/* MCL --- remove for stand-alnone pi.c version: pi_new.c  \r\n\tucbstart( __FILE__, __LINE__);\r\n\tdefault_precision();\r\n       --- */\r\n\r\n/* .... Environmental constants EPS, RDX, FL */\r\n\r\n    (void) envcns_(&eps, &rdx, &fl);\r\n\r\n/* .... for adequate accuracy */\r\n\r\n    inc = (integer) (LOG(fl) / LOG(2.6));\r\n\r\n/*      PRINT 1000 */\r\n/* 1000  FORMAT(1X,'PIRATS: computes  PI = A/B+C and R = PI-P.'/ */\r\n/*     1   /1X,1X,'J',1X,18X,'A',18X,'/',18X,'B' */\r\n/*     2   /1X,2X,1X,27X,'+',5X,'C' */\r\n/*     3   /1X,2X,1X,41X,'R',5X,'+/-',5X,'E' */\r\n/*     4   ) */\r\n\t(void) printf(\" PIRATS: computes  PI = A/B+C and R = PI-P.\\n\");\r\n\r\n/* .... Initialize A, B */\r\n\r\n    a = d[0];\r\n    b = 1.;\r\n\r\n    i__1 = 210 - inc + 5;\r\n    for (j = 1; j <= i__1; ++j) {\r\n\r\n/* .... Get next pair A, B */\r\n\r\n\tnextab_(&d[j], &a, &b);\r\n\tif (a > fl || b > fl) {\r\n\t    goto L110;\r\n\t}\r\n\r\n/* ....    Get C = PI-A/B+/-E */\r\n\r\n\tgetce_(&c__210, &j, &inc, &eps, &fl, d, &c, &e);\r\n\r\n/* ....    Get R = PI-P+/-E */\r\n\r\n\ttstrig_(&eps, &a, &b, &c, &e, &r);\r\n\r\n/* ....    Display these numbers */\r\n\r\n\tdispla_(&j, &a, &b, &c, &e, &r);\r\n\r\n/* ....    Test them for consistency */\r\n\r\n\tcompar_(&e, &r);\r\n/* L100: */\r\n    }\r\nL110:\r\n/* \tPRINT *,'Fin' */\r\n\r\n/* .... Normal termination. */\r\n\r\n    printf(\"Confirming:  UCBPASS  \\n\");\r\n\r\n/* --- MCL: remove for standalone ver:     (void) ucbpass( __FILE__, __LINE__); */\r\n\r\n\r\n} /* MAIN__ */\r\n\r\n\r\n#ifdef __STDC__\r\nVOID s_cat(char *lp, char *rpp[], ftnlen rnp[], ftnlen *np, ftnlen ll)\r\n#else\r\nVOID s_cat(lp, rpp, rnp, np, ll) char *lp, *rpp[]; ftnlen rnp[], *np, ll;\r\n#endif\r\n{\r\nftnlen i, n, nc;\r\nchar *f__rp;\r\n\r\nn = (int)*np;\r\nfor(i = 0 ; i < n ; ++i)\r\n\t{\r\n\tnc = ll;\r\n\tif(rnp[i] < nc)\r\n\t\tnc = rnp[i];\r\n\tll -= nc;\r\n\tf__rp = rpp[i];\r\n\twhile(--nc >= 0)\r\n\t\t*lp++ = *f__rp++;\r\n\t}\r\nwhile(--ll >= 0)\r\n\t*lp++ = ' ';\r\n}\r\n\r\n/* Subroutine */ int envcns_(eps, rdx, fl)\r\nGENERIC *eps, *rdx, *fl;\r\n{\r\n    /* System generated locals */\r\n#ifdef __STDC__\r\nvolatile\r\n#endif\r\n    GENERIC d__1;\r\n\r\n    /* Local variables */\r\n#ifdef __STDC__\r\nvolatile\r\n#endif\r\n    static GENERIC h, t, u, v, x, y;\r\n\r\n/* .... Environmental constants.  This subroutine computes */\r\n/* ....    EPS = nextafter(1,2)-1 = 1.000...001-1 */\r\n/* ....    RDX = RaDiX of floating-point arithmetic (2, 10, 16) */\r\n/* ....    FL = RDX/EPS = last of consecutive floating-point integers */\r\n/* ....                       among 1, 2, 3, ..., FL-2, FL-1, FL. */\r\n\r\n/* .... local variables */\r\n\r\n\r\n/* .... First seek EPS */\r\n\r\n    t = TOGENERIC(4) / TOGENERIC(3) ;\r\n    x = t - 1.;\r\n    y = (d__1 = x + x - 1. + x, abs(d__1)) / 64.;\r\n    *eps = 0.;\r\n    if (y == 0.) {\r\n/* \t PRINT *,'Is 4/3 exact?' */\r\n\tprintf(\" Is 4/3 exact? \\n\");\r\n\tgoto L299;\r\n    }\r\nL200:\r\n    if (*eps != 0.) {\r\n\tgoto L210;\r\n    }\r\n    u = y + 1.;\r\n    *eps = u - 1.;\r\n    y += y;\r\n    goto L200;\r\n\r\n/*     Now seek EPS/RDX = 1-nextafter(1,0) = 1-0.999...999 : */\r\n\r\nL210:\r\n    h = TOGENERIC(1) / TOGENERIC(2) ;\r\n    t = TOGENERIC(2) / TOGENERIC(3) ;\r\n    x = t - h;\r\n    y = (d__1 = x + x - h + x, abs(d__1)) / 64.;\r\n    v = 0.;\r\n    if (y == 0.) {\r\n/* \t PRINT *,'Is 2/3 exact?' */\r\n\tprintf(\" Is 2/3 exact? \\n\");\r\n\tgoto L299;\r\n    }\r\nL220:\r\n    if (v != 0.) {\r\n\tgoto L230;\r\n    }\r\n    u = h - y + h;\r\n    v = h - u + h;\r\n    y += y;\r\n    goto L220;\r\n\r\n/* .... in case Division is dirty */\r\n\r\nL230:\r\n    d__1 = *eps / v + 1e-4;\r\n    *rdx = aint(d__1);\r\n    if (*rdx < 2.) {\r\n/* \t PRINT 5000,'Radix =',RDX */\r\n#ifdef QP\r\n\tprintf(\" Radix = %Lg \\n\",*rdx);\r\n#else\r\n\tprintf(\" Radix = %g \\n\",*rdx);\r\n#endif\r\n/* L5000: */\r\n\tgoto L299;\r\n    }\r\n\r\n/* .... Confirm that RDX = Radix of Floating-point arithmetic. */\r\n\r\n    t = *rdx;\r\n    x = 1.;\r\n\r\n/* .... until X.EQ.0 or X.EQ.RDX */\r\n\r\nL240:\r\n    if (x != 1.) {\r\n\tgoto L250;\r\n    }\r\n    t += t;\r\n    u = t + 1.;\r\n    x = u - t;\r\n    goto L240;\r\nL250:\r\n    if (x == 0.) {\r\n\ty = 1.;\r\nL260:\r\n\tif (x != 0.) {\r\n\t    goto L270;\r\n\t}\r\n\ty += y;\r\n\tu = t + y;\r\n\tx = u - t;\r\n\tgoto L260;\r\n    }\r\nL270:\r\n    if (x != *rdx) {\r\n/*         PRINT 6000,'Is Radix ',X,' or ',RDX,'?' */\r\n#ifdef QP\r\n\tprintf(\" Is Radix %Lg or %Lg ? \\n\",x,rdx);\r\n#else\r\n\tprintf(\" Is Radix %g or %g ? \\n\",x,rdx);\r\n#endif\r\n/* L6000: */\r\n\tgoto L299;\r\n    }\r\n\r\n/* .... Confirm that FL = RDX/EPS: */\r\n\r\n    *fl = *rdx;\r\n    x = 1.;\r\nL280:\r\n    if (x != 1.) {\r\n\tgoto L290;\r\n    }\r\n    *fl *= *rdx;\r\n    u = *fl + 1.;\r\n    x = u - *fl;\r\n    goto L280;\r\nL290:\r\n    if (*fl * v == 1.) {\r\n\treturn 0;\r\n    }\r\n\r\n/* .... ENVCNS cannot compute environmental constants correctly: */\r\n\r\n/*      PRINT 3000,'Is FL ',FL,' or ',1. d0 /V,'?' */\r\n#ifdef QP\r\n        printf(\" Is FL %Lg or %Lg ? \\n\",*fl,1.0/v);\r\n#else\r\n        printf(\" Is FL %g or %g ? \\n\",*fl,1.0/v);\r\n#endif\r\n/* 3000  FORMAT(1X,A6,1PE45.37E3/1X,2X,A4,1PE45.37E3,A1) */\r\nL299:\r\n/* \tPRINT *,'Subroutine ENVCNS cannot compute correctly the' */\r\n/*      PRINT *,'Environmental constants' */\r\n/*      PRINT *,'EPS = 1.000...001 - 1 , and' */\r\n/*      PRINT *,'FL = Last consecutive Floating-point integer' */\r\n/*      PRINT *,'        among 1, 2, 3, ..., FL-2, FL-1, FL.' */\r\n/*      PRINT *,'Please substitute them for the subroutine.' */\r\n\tprintf(\" envcns cannnot compute correctly the Environmental constants. \\n\");\r\n\tprintf(\"Confirming:  UCBFAIL  \\n\");\r\n        /* MCL --- removed for standalone version. (void) ucbfail( __FILE__ , __LINE__ ); */\r\n} /* envcns_ */\r\n\r\n\r\n/* Subroutine */ int nextab_(dj, a, b)\r\nGENERIC *dj, *a, *b;\r\n{\r\n    /* Initialized data */\r\n\r\n    static GENERIC a0 = 1.;\r\n    static GENERIC b0 = 0.;\r\n\r\n    static GENERIC t;\r\n\r\n\r\n/* .... Get next pair A, B */\r\n\r\n/* .... local variables */\r\n\r\n\r\n    t = *dj * *b + b0;\r\n    b0 = *b;\r\n    *b = t;\r\n    t = *dj * *a + a0;\r\n    a0 = *a;\r\n    *a = t;\r\n\r\n/* .... Now A/B = D0+1/(D1+1/(D2+...+1/DJ)). */\r\n\r\n    return 0;\r\n} /* nextab_ */\r\n\r\n\r\n/* Subroutine */ int getce_(npi, j, inc, eps, fl, d, c, e)\r\ninteger *npi, *j, *inc;\r\nGENERIC *eps, *fl, *d, *c, *e;\r\n{\r\n    /* System generated locals */\r\n    integer i__1, i__2;\r\n\r\n    /* Local variables */\r\n    static integer i;\r\n    static GENERIC x, y, z;\r\n    static integer i9;\r\n\r\n\r\n/* .... This subroutine computes the continued fraction's tail */\r\n/* ....    Z = D(J+1)+1/(D(J+2)+1/(D(J+3)+1/(D(J+4)+...))) */\r\n/* .... to working accuracy by using INC terms of it, and then */\r\n/* .... computes the effect C of cutting it off to get A/B . */\r\n/* .... */\r\n/* .... Get  C = PI-A/B+/-E */\r\n\r\n/* .... local variables */\r\n\r\n\r\n/* Computing MIN */\r\n    i__1 = *npi, i__2 = *j + *inc;\r\n    i9 = min(i__1,i__2);\r\n    z = d[i9];\r\n    i__1 = *j + 1;\r\n    for (i = i9 - 1; i >= i__1; --i) {\r\n\tz = d[i] + 1. / z;\r\n/* L400: */\r\n    }\r\n    x = *fl * *fl;\r\n\r\n/* .... C = 1/Z-1/X always */\r\n\r\n    *c = 1. / z - 1. / x;\r\n    for (i = *j; i >= 1; --i) {\r\n\ty = d[i];\r\n\tz = y + 1. / z;\r\n\tx = y + 1. / x;\r\n\t*c = -(*c) / (x * z);\r\n/* L410: */\r\n    }\r\n\r\n/* .... E > accumulated roundoff (mixed arithmetic) */\r\n\r\n    *e = *j * 4. * *eps * abs(*c);\r\n    return 0;\r\n} /* getce_ */\r\n\r\n\r\n/* Subroutine */ int tstrig_(eps, a, b, c, e, r)\r\nGENERIC *eps, *a, *b, *c, *e, *r;\r\n{\r\n    /* Initialized data */\r\n\r\n    static char si[10+1] = \"arcsin(sin\";\r\n    static char co[10+1] = \"arcsin(cos\";\r\n    static char ta[10+1] = \"arctan(tan\";\r\n\r\n    /* System generated locals */\r\n    address a__1[2];\r\n    integer i__1[2];\r\n    GENERIC d__1, d__2;\r\n    char ch__1[1];\r\n\r\n    /* Local variables */\r\n    extern /* Subroutine */ int whet_();\r\n    static GENERIC q, s, w, x, y, q0, w0;\r\n    static char ts[11];\r\n\r\n\r\n/* .... Get R = PI-P+/-E */\r\n\r\n/*     This subroutine tests whether the programs that compute */\r\n/*     TRIG(X) = trig(X*PI/P) for TRIG = sin, cos or tan */\r\n/*     always use the same approximation P to PI during their */\r\n/*     argument reduction.  If so, 3 or 4 values R = Q+C */\r\n/*     derived from A = B*(PI-C+/-E) ought to agree. */\r\n\r\n/* .... local variables */\r\n\r\n\r\n\r\n\r\n/* .... FNODD(floating-point integer X) = (-1)**X */\r\n\r\n\r\n/* .... FNS(1) = '+', FNS(-1) = '-' */\r\n\r\n\r\n    q = ATAN(TAN(*a)) / *b;\r\n    *r = q + *c;\r\n    w = *eps * 3. * abs(q);\r\n    *e += w;\r\n    d__1 = abs(*b) * .5 + .125;\r\n    s = (aint(d__1) * 2. - abs(*b)) * 2. + 1.;\r\n    x = *a;\r\n    y = *b;\r\n/* Writing concatenation */\r\n    ch__1[0] = 44 - (integer) s;\r\n    i__1[0] = 1, a__1[0] = ch__1;\r\n    i__1[1] = 10, a__1[1] = si;\r\n    s_cat(ts, a__1, i__1, &c__2, 11L);\r\n    q0 = ASIN(SIN(x)) / y * s;\r\n    w0 = w + *eps * 6. * abs(q0);\r\n    whet_(&q, &q0, &w0, &x, &y, a, b, ts, ta, 11L, 10L);\r\n    x = *a * .5;\r\n    y = *b * .5;\r\n    if (s < 0.) {\r\n\r\n/* ....    (B+1) is even */\r\n\r\n\td__1 = (*b + 1.) * .5;\r\n\td__2 = abs(d__1) * .5 + .125;\r\n\ts = (aint(d__2) * 2. - abs(d__1)) * 2. + 1.;\r\n/* Writing concatenation */\r\n\tch__1[0] = 44 - (integer) s;\r\n\ti__1[0] = 1, a__1[0] = ch__1;\r\n\ti__1[1] = 10, a__1[1] = co;\r\n\ts_cat(ts, a__1, i__1, &c__2, 11L);\r\n\tq0 = ASIN(COS(x)) / y * s;\r\n\tw0 = w + *eps * 6. * abs(q0);\r\n    } else {\r\n\r\n/* ....    B = 2y is even */\r\n\r\n/* Writing concatenation */\r\n\ti__1[0] = 1, a__1[0] = \" \";\r\n\ti__1[1] = 10, a__1[1] = ta;\r\n\ts_cat(ts, a__1, i__1, &c__2, 11L);\r\n\tq0 = ATAN(TAN(x)) / y;\r\n\tw0 = *eps * 3. * abs(q0);\r\n\twhet_(&q, &q0, &w0, &x, &y, a, b, ts, ta, 11L, 10L);\r\n\td__1 = abs(y) * .5 + .125;\r\n\ts = (aint(d__1) * 2. - abs(y)) * 2. + 1.;\r\n/* Writing concatenation */\r\n\tch__1[0] = 44 - (integer) s;\r\n\ti__1[0] = 1, a__1[0] = ch__1;\r\n\ti__1[1] = 10, a__1[1] = si;\r\n\ts_cat(ts, a__1, i__1, &c__2, 11L);\r\n\tq0 = ASIN(SIN(x)) / y * s;\r\n\tw0 = w + *eps * 6. * abs(q0);\r\n    }\r\n    whet_(&q, &q0, &w0, &x, &y, a, b, ts, ta, 11L, 10L);\r\n    return 0;\r\n} /* tstrig_ */\r\n\r\n\r\n/* Subroutine */ int whet_(q, q0, w0, x, y, a, b, ts, ta, ts_len, ta_len)\r\nGENERIC *q, *q0, *w0, *x, *y, *a, *b;\r\nchar *ts, *ta;\r\nftnlen ts_len;\r\nftnlen ta_len;\r\n{\r\n    /* System generated locals */\r\n    GENERIC d__1;\r\n\r\n\r\n/* .... Test whether Q0.EQ.Q within +/- W0 (.GE.->.GT.) */\r\n\r\n    if ((d__1 = *q - *q0, abs(d__1)) > *w0) {\r\n\r\n/* ....    Difference too big suggests P is not a constant after all. \r\n*/\r\n\r\n/*         PRINT 4000,TS,X,')/',Y,' =',Q0,' differs from ', */\r\n/*     1      TA,A,')/',B,' =',Q,' too much.' */\r\n/* 4000  FORMAT(/1X,4X,70('%') */\r\n/*     1   /1X,4X,A11,0PF38.1,A */\r\n/*     2   /1X,4X,11X,0PF38.1,A */\r\n/*     3   /1X,4X,11X,1PE45.37E3,A */\r\n/*     4   /1X,4X,1X,A10,0PF38.1,A */\r\n/*     5   /1X,4X,11X,0PF38.1,A */\r\n/*     6   /1X,4X,11X,1PE45.37E3,A */\r\n/*     7   /1X,4X,70('%') */\r\n/*     8   /) */\r\n#ifdef QP\r\n\tprintf(\" %s %Lg / %Lg  differs from %s %Lg / %Lg = %Lg too much.\\n\",\r\n#else\r\n\tprintf(\" %s %g / %g  differs from %s %g / %g = %g too much.\\n\",\r\n#endif\r\n\t\tts,*x,*y,*q0,ta,*a,*b,*q);\r\n\r\n\r\n\tprintf(\"Confirming:  UCBFAIL  \\n\");\r\n        /* MCL --- Removed for standalone version: (void) ucbfail( __FILE__ , __LINE__ ); */\r\n    }\r\n    return 0;\r\n} /* whet_ */\r\n\r\n\r\n/* Subroutine */ int displa_(j, a, b, c, e, r)\r\ninteger *j;\r\nGENERIC *a, *b, *c, *e, *r;\r\n{\r\n\r\n/*     Display Formatting */\r\n\r\n/* .... display  J, A, B, C, R, E */\r\n\r\n/*      PRINT 2000,J,A,B,C,R,E */\r\n/* 2000  FORMAT(1X,I2,1X,F37.0,'/',F37.0 */\r\n/*     1   /1X,2X,1X,27X,'+',1X,1PE45.37E3 */\r\n/*     2   /1X,2X,1X,1X,1PE45.37E3,1X,'+/-',1PE16.8E3 */\r\n/*     3   ) */\r\n#ifdef QP\r\n\tprintf(\" J %3d A %37.0Lf / B %37.0Lf + C %45.37Le \\n\",\r\n\t\t*j,*a,*b,*c);\r\n\tprintf(\" J %3d R %45.37Le +- %17.9Le \\n\",\r\n\t\t*j,*r,*e);\r\n#endif\r\n#ifdef DP\r\n\tprintf(\" J %2d A %17.0f / B %17.0f + C %25.17e \\n\",\r\n\t\t*j,*a,*b,*c);\r\n\tprintf(\" J %2d R %25.17e +- %17.9e \\n\",\r\n\t\t*j,*r,*e);\r\n#endif\r\n#ifdef SP\r\n\tprintf(\" J %2d A %9.0f / B %9.0f + C %17.9e \\n\",\r\n\t\t*j,*a,*b,*c);\r\n\tprintf(\" J %2d R %17.9e +- %17.9e \\n\",\r\n\t\t*j,*r,*e);\r\n#endif\r\n    return 0;\r\n} /* displa_ */\r\n\r\n\r\n/* Subroutine */ int compar_(e, r)\r\nGENERIC *e, *r;\r\n{\r\n    /* Initialized data */\r\n\r\n    static GENERIC e0 = .1416;\r\n    static GENERIC r0 = 0.;\r\n\r\n    /* System generated locals */\r\n    GENERIC d__1;\r\n\r\n/* .... test for consistency */\r\n\r\n/* .... local variables */\r\n\r\n\r\n/* .... .LT.->.LE. */\r\n\r\n    if ((d__1 = *r - r0, abs(d__1)) <= *e + e0) {\r\n\te0 = *e;\r\n\tr0 = *r;\r\n    } else {\r\n/*         PRINT *,'Varying R implies defective argument reduction.' \r\n*/\r\n\tprintf(\" Varying R implies defective argument reduction. \\n\");\r\n\tprintf(\"Confirming:  UCBFAIL  \\n\");\r\n        /* --- MCL removed for standalone version: (void) ucbfail( __FILE__ , __LINE__ ); */\r\n    }\r\n    return 0;\r\n} /* compar_ */\r\n\r\n/* Main program alias */ int main () { MAIN__ (); }\r\n```\r\n\r\nYou will also need this file:   ucbtest.h\r\n\r\n```\r\n#ifndef _UCBTEST\r\n\r\n#define _UCBTEST\r\n\r\n/*\tspecial definitions for Sun test harness\t*/\r\n\r\n#ifdef SP\r\n#undef SP\r\n#define FLOAT\r\n#endif\r\n\r\n#ifdef DP\r\n#undef DP\r\n#define DOUBLE\r\n#endif\r\n\r\n#ifdef QP\r\n#undef QP\r\n#define LONGDOUBLE\r\n#endif\r\n\r\n#ifndef SUN_IEEE\r\n#if (sunpro_version >= 100) || (sunos_version/100 == 4)\r\n#define SUN_IEEE\r\n#endif\r\n#endif\r\n\r\n#ifndef SUN_MATH\r\n#if (sunpro_version >= 300)\r\n#define SUN_MATH\r\n#endif\r\n#endif\r\n\r\n/*\tGlobal macro definitions.\t*/\r\n\r\n#ifdef PC\r\n#define FINT\tlong\t\t/* C equivalent of Fortran integer */\r\n#define INT32\tlong\t\t/* 32 bit int */\r\n#define UINT32\tunsigned long\t/* 32 bit unsigned */\r\n#else\r\n#define FINT\tint\t\t/* C equivalent of Fortran integer */\r\n#define INT32\tint\t\t/* 32 bit int */\r\n#define UINT32\tunsigned int\t/* 32 bit unsigned */\r\n#endif\r\n\r\n#ifdef SUN_MATH\r\n#include <sunmath.h>\r\n#endif\r\n#include <math.h>\r\n\r\n#ifndef NTESTS\r\n#define NTESTS 1000000L   /* DOS wants L specifier added */\r\n#endif\r\n\r\n#if defined(__STDC__) || defined(DOS)\r\n#define ANSI_PROTOTYPES\r\n#define PROTO(p)  p\r\n#else\r\n#undef ANSI_PROTOTYPES\r\n#define PROTO(p)  ()\r\n#endif\r\n\r\n#ifdef FLOAT\r\n#define SP\r\n#define GENERIC float\r\n#define GENERIC_STRING \"float\"\r\n#define PRECISION_STRING \"single\"\r\n#define ABS(X) fabs((double)(X))\r\n#define MOD(X,Y) fmod((double)(X),(double)(Y))\r\n#define CEIL(X) ceil((double)(X))\r\n#define FLOOR(X) floor((double)(X))\r\n#if defined(__STDC__) && !defined(NO_FUNCF)\r\n#define SQRT(X) sqrtf((float)(X))\r\n#define LOG(X) logf((float)(X))\r\n#define SIN(X) sinf((float)(X))\r\n#define COS(X) cosf((float)(X))\r\n#define TAN(X) tanf((float)(X))\r\n#define ASIN(X) asinf((float)(X))\r\n#define ACOS(X) acosf((float)(X))\r\n#define ATAN(X) atanf((float)(X))\r\n#define POW(X,Y) powf((float)(X),(float)(Y))\r\nextern float sqrtf(float);\r\nextern float logf(float);\r\nextern float sinf(float);\r\nextern float cosf(float);\r\nextern float tanf(float);\r\nextern float asinf(float);\r\nextern float acosf(float);\r\nextern float atanf(float);\r\nextern float powf(float,float);\r\n#else\r\n#define SQRT(X) sqrt((double)(X))\r\n#define LOG(X) log((double)(X))\r\n#define SIN(X) sin((double)(X))\r\n#define COS(X) cos((double)(X))\r\n#define TAN(X) tan((double)(X))\r\n#define ASIN(X) asin((double)(X))\r\n#define ACOS(X) acos((double)(X))\r\n#define ATAN(X) atan((double)(X))\r\n#define POW(X,Y) pow((double)(X),(double)(Y))\r\n#endif\r\n#endif\r\n\r\n#ifdef DOUBLE\r\n#define DP\r\n#define GENERIC double\r\n#define GENERIC_STRING \"double\"\r\n#define PRECISION_STRING \"double\"\r\n#define ABS(X) fabs((double)(X))\r\n#define MOD(X,Y) fmod((double)(X),(double)(Y))\r\n#define CEIL(X) ceil((double)(X))\r\n#define FLOOR(X) floor((double)(X))\r\n#define SQRT(X) sqrt((double)(X))\r\n#define LOG(X) log((double)(X))\r\n#define SIN(X) sin((double)(X))\r\n#define COS(X) cos((double)(X))\r\n#define TAN(X) tan((double)(X))\r\n#define ASIN(X) asin((double)(X))\r\n#define ACOS(X) acos((double)(X))\r\n#define ATAN(X) atan((double)(X))\r\n#define POW(X,Y) pow((double)(X),(double)(Y))\r\n#endif\r\n\r\n#ifdef LONGDOUBLE\r\n#define QP\r\n#define GENERIC long double\r\n#define GENERIC_STRING \"long double\"\r\n#define PRECISION_STRING \"extended\"\r\n#define ABS(X) fabsl((long double)(X))\r\n#define MOD(X,Y) fmodl((long double)(X),(long double)(Y))\r\n#define CEIL(X) ceill((long double)(X))\r\n#define FLOOR(X) floorl((long double)(X))\r\n#define SQRT(X) sqrtl((long double)(X))\r\n#define LOG(X) logl((long double)(X))\r\n#define SIN(X) sinl((long double)(X))\r\n#define COS(X) cosl((long double)(X))\r\n#define TAN(X) tanl((long double)(X))\r\n#define ASIN(X) asinl((long double)(X))\r\n#define ACOS(X) acosl((long double)(X))\r\n#define ATAN(X) atanl((long double)(X))\r\n#define POW(X,Y) powl((long double)(X),(long double)(Y))\r\nextern long double fabsl(long double);\r\nextern long double fmodl(long double, long double);\r\nextern long double ceill(long double);\r\nextern long double floorl(long double);\r\nextern long double sqrtl(long double);\r\nextern long double logl(long double);\r\nextern long double sinl(long double);\r\nextern long double cosl(long double);\r\nextern long double tanl(long double);\r\nextern long double asinl(long double);\r\nextern long double acosl(long double);\r\nextern long double atanl(long double);\r\nextern long double powl(long double, long double);\r\n#endif\r\n\r\n#define TOGENERIC(X) ((GENERIC)(X))\r\n#define ZERO ((GENERIC)(0))\r\n#define ONE  ((GENERIC)(1))\r\n#define TWO  ((GENERIC)(2))\r\n#define FOUR ((GENERIC)(4))\r\n\r\nextern UINT32 ntests, nregions;\r\nextern UINT32 significand_length;\r\n\r\n\r\n/*\tIEEE features with machine-dependent syntax \t*/\r\n\r\nextern void round_nearest PROTO((void));\r\nextern void round_positive PROTO((void));\r\nextern void round_zero PROTO((void));\r\nextern void generic_precision PROTO((void));\r\nextern void default_precision PROTO((void));\r\n\r\n/*\tCommon ucbtest functions\t\t\t*/\r\n\r\nextern void ucbstart PROTO((char *file,int line));\r\nextern void ucbfail PROTO((char *file,int line));\r\nextern void ucbpass PROTO((char *file,int line));\r\n\r\n#include \"stdio.h\"\r\n\r\n#ifdef sunos_version\r\n\r\n#if (sunos_version/100 >= 4)\r\n#include \"stdlib.h\"\r\n#endif\r\n\r\n#else\r\n#include \"stdlib.h\"\r\n#endif\r\n\r\n#ifndef __NEWVALID\r\nextern UINT32 get_significand PROTO((void));\r\nextern void ucbdivtest_ PROTO((int *, char **));\r\nextern void ucbmultest_ PROTO((int *, char **));\r\nextern void ucbsqrtest_ PROTO((int *, char **));\r\nextern void ucbfindpitest_ PROTO((int *, char **));\r\nextern void ucbeeftest_ PROTO((int *, char **));\r\n#endif\r\n\r\n#endif /* _UCBTEST */\r\n```\r\nThe PIRATS program can be compiled in \"double-precision\" mode using this file:\r\n\r\ncompile_pi_new_c_DP\r\n```\r\n#!/bin/sh\r\n#\r\n# --- pre-process and compile the pi_new.c program to executable: pinewcDP\r\n#\r\n# (((((((((((((((  Double Precision Verson  )))))))))))))))\r\ngcc -cpp -D DP  pi_new.c -lm -o pinewcDP\r\n\r\n# --- you can run \"pinewcDP\" stand-alone, and check if it passes or fails.\r\n# --- if it passes, it will say: \"Confirming: UCBPASS\". \r\n```\r\n\r\nIf you want to run the test in single-precision (32-bit instead of 64-bit), you can do it with this:\r\n\r\ncompile_pi_new_c_SP\r\n```\r\n#!/bin/sh\r\n#\r\n# --- pre-process and compile the pi_new.c program to executable: pinewcSP\r\n#\r\n# (((((((((((((((  Single Precision Verson  )))))))))))))))\r\ngcc -cpp -D SP  pi_new.c -lm -o pinewcSP\r\n\r\n# --- you can run \"pinewcSP\" stand-alone, and check if it passes or fails.\r\n# --- if it passes, it will say: \"Confirming: UCBPASS\". \r\n```\r\n\r\nI'll make a more detailed review of the UCBTest suiite, and post the results here.  It would seem to me the differences between MacOS and Linux results have to be affecting TensorFlow, in more areas than just PDE simulations and image-creation, as lewisl's post indicates is happening.\r\n", "The original poster has replied to this issue after the stat:awaiting response label was applied.", "Cracked it.  Got a solution (workaround, essentially), and a probable cause.  The MacBook running MacOS Yosemite (10.10.5) looks to be doing it's rounding and/or floating-point math wrong.  Based on Quaeler's results which shows the simulation running on MacOS Sierra 10.12.6 same as on Linux platforms (CentOS-7.4 and Ubuntu), it's clear the evolution of the Laplace PDE (partial differential equation) simulation to the complex moire-pattern is the correct evolution, and the MacOS Yosemite 10.10.5 has a flaw in how it is doing 32-bit floating math.  On GNU Linux systems, both 32-bit and 64-bit (CentOS-6.6 and CentOS-7.4 confirmed) it is possible to explicitly control precision, using a routine \"fesetprec\", which can be lifted from a handbook of code:  (see here)  https://books.google.ca/books?id=OjUyDwAAQBAJ&pg=PA127&lpg=PA127&dq=ieee.c+++fesetprec+to+control+precision&source=bl&ots=VLtoiOfYfE&sig=BfdtySalckBzIB-mbV_Uy4uXLL4&hl=en&sa=X&ved=0ahUKEwjD1r6BzujYAhUH94MKHTNhDowQ6AEIJzAA#v=onepage&q=ieee.c%20%20%20fesetprec%20to%20control%20precision&f=false\r\n\r\nThe \"fesetprec\" invokes a macro, called: \"_FPU_SETCW\", which generates some assembler code to set values in the Intel control word which, on IA-32 architectures, is used to explicitly control precision of floating point calculations.  The macro's _FPU_GETCW and _FPU_SETCW are available on GNU Linux systems in the \"fpu_control.h\" include file, in /usr/include.  The Intel spec for 8087 and 80387 FPU's allowed this.  The newer/newest MMX (and now SSE and SSE2 and SSE3 and such) architectures are indicated as not using this control word -but curiously, if you run test programs to explicity set precision, and then run precision-dependent code, you can see that on *both* architectures - IA-32, and the newer 64-bit Intel Core-i3 and Core-i5 chips, this control word can *still* be set, at least on Linux machines.  I've confirmed this.\r\n\r\nI downloaded and converted the UCBTest suite which exercises a bunch of floating-point calculations, and then I also pulled together a working example of a test program (from the Handbook previously mentioned), which sets the precison control-word.  Basically, you define your vars as \"long double\", but then you can tweak the control-word to run in float, double, or long-double.  The test program \"chkprec.c\" gives three different results, depending on the precision selected.  This program works the same on both CentOS 6.6 and CentOS 7.4.   Long-double on a 32-bit box is probably going to be compiled as REAL*10 (the 80-bit extended precision - which Intel chips do their math in - and which has been a fixture of Intel architecture since the first IBM P/C.)  I know a tiny bit about this, because my \"gDOSbox\" app (free, no ads, no tracking on Google Playstore) is special, because I know it has had its conversion math fixed so that mapping from 32-bit (\"float\"), and 64-bit (double precision) to 80-bit (extended precision), was not originally being done correctly, (in the open-source DOSbox code), but is being done correctly in gDOSbox.   Most public DOSbox's would not run high-precision Fortran or C progams correctly. The math in \"gDOSbox\" can be run correctly, and the APL interpreters and Fortran compilers that it supports (WF77 - Watcom Fortran is one of them), do their math correctly (I've checked).\r\n\r\nFor NN (Neural Net) applications, matrix-math must be done correctly, and the TensorFlow Laplace sim was a great exercise of matrix math.  The routine used is called: \"tf.nn.depthwise_conv2d\" (if you import TensorFlow into Python as \"tf\").  It is documented here: \r\nhttps://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d\r\n\r\nYou might also want to look at this, if learning about tf.nn.depthwise_conv2d:\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.5/tensorflow/python/ops/nn_impl.py\r\n\r\nWhat I found using UCBTest and chkprec.c, was that the Macbook Pro, under Yosemite (MacOS 10.10.5) does not support the explicit-setting of precision in the same manner that Linux does.  There is no provision for setting the precision control-word on the Mac under Yosemite, or if there is, it is substantially different than is the case for Linux.  My version of chkprec.c on the MacBook is an ugly hack, with three different functions, one in each precision level (float, double, and long double), and it was only in this way that I could reproduce the results I was getting on Linux, where the precision control word could be set to the desired precision using fsetprec.  This means that math-calc code written for Linux which relies on the ability to explicitly control precision, probably won't run correctly on the Mac, unless low-level changes are made.  Also, there are differences in the \"UCBfail\"s that occur on the Macbook, as opposed to the Linux boxes.  What is interesting, is the 64-bit Linux runs the UCBTest suite better than the 32-bit Linux (CentOS 6.6) does.  And both the Linux 64-bit and the MacOS 64-bit pass the cpar_DP and cpar_SP (\"paranoid\") tests, as well as the DP and SP (double and single precision) tests for \"mul\" and \"div\".    But the \"cpi_DP\" test iterates differently on Mac versus Linux 64-bit, and only in a few places where the exponents are large negative (E-26, E-38, E-40, and such).  \r\n\r\nI will post the various test programs to my github account.\r\n\r\nIn order to get the Laplace PDE simulation to iterate-and-evolve correctly (so you get a funky image of a moire-pattern, and some dark-matter black-space, instead of just a blank screen, as the MacBook was doing), I changed all the 32-bit (\"float\" level precision, like REAL*4 in Fortran), into 64-bit doubles (like REAL*8 in Fortran).   The TensorFlow documentation indicates that the tf.nn.depthwise_conv2d is able to operate in either mode, and it does.  It appears that TensorFlow is operating correctly, and it appears the bug that shows up in MacOS only manifests itself if the Python (numpy) variables are 32-bit (or \"float).  \r\n\r\nChange all the variables to 64-bit, and the simulation works the same on both machines.\r\nI'll monitor this thread for a bit, and if the TensorFlow authors don't close it, I will, as it appears not to be a TensorFlow issue, but is a MacOS issue, which as Quaeler discovered, can be resolved by upgrading to MacOS 10.12.6 (Sierra), and probably the newer \"High Sierra\" as well.    If you have other reasons for wishing to maintain your MacBook at Yosemite, but still want to run TensorFlow (in CPU mode), then I would recommend doing your network math and back-propagations with 64-bit floats, not 32-bit values.  I ran the sim forward with 57500 iterations, and the exponents are up around E+132 and E+133... big numbers, but still calculating correctly.    The final image and numeric (U(eval) at row 20) images for MacBook and Linux (CentOS-7.4) provided below.  \r\n\r\nHope all this helps anyone else struggling with wrong floating-point number problems on their MacBooks using TensorFlow.   The problem likely resides somewhere in the Xcode 7.2.1 - Clang 700x compiler used to build Python and TensorFlow, and again, is most likely resolved by using later versions of the compiler where the floating-point flaws appear to have been corrected.  (But they aren't all fixed.  Some of the test programs we have tried still show variance between Linux and MacOS results. The \"PIRATS\" program (see above) still shows some different numbers on each platform.)\r\n\r\nIn my work with Xerion, I found it was critical to set the TCL-precision variable to it's highest value (17 or 18 or some such thing), if I wanted to write the network-weights out to a file, for subsequent loading at a later time, if the file was an ascii (not binary) numeric represetation.  The default was 8 digits after the decimal, and if you wrote and re-read network weights at that precision, your network was destroyed.  Weight digits 10 or 12 past the decimal place made a difference to network operation, and it became clear a very high level of precision was essential.   If you are working with neural networks, you might want to read W. Kahan's paper from his IEEE 754 lecture.  https://people.eecs.berkeley.edu/~wkahan/ieee754status/IEEE754.PDF    It illustrates some of the issues and edge-case conditions that floating-point calculations run up against, and the choices and trade-offs that were made to create a viable floating-point calculation standard.   It is a good paper, and it provides background on why floating-point calculations can fail to operate as expected.\r\n(Images of Laptest_64 sim on each platform follow..)\r\n![laptest_64_700_centos74_screenshot_2018-01-29_10_32pm](https://user-images.githubusercontent.com/16905336/35584502-34d92556-05c3-11e8-9485-b8629e501347.jpg)\r\n![laptest_64_700_57k_macos_screenshot_2018-01-30_1_24am](https://user-images.githubusercontent.com/16905336/35584523-46e5b3b8-05c3-11e8-92c3-8cf00b9bb8ab.jpg)\r\n", "(a) This is **excellent** work - thank you.\r\n(b) On the larger scale of things, I don't know what one does with this information in a helpful manner (for TF or otherwise.) It should be disseminated so that it is definitely \"public knowledge\", but I'm short on a useful idea how to do this. @cy89 ? @martinwicke ?", "Thanks for putting so much work into this.  Really helps with the underlying cause.\r\n\r\nOn a somewhat discouraging note I\u2019ll point out that upgrading MacOS very likely won\u2019t help. The symptoms I saw\u2014a conv-net that won\u2019t converge (cost and accuracy remaining flat regardless of number of epochs of SDG\u2014occur with higher versions of tensorflow on MacOS High Sierra 10.13.3 (the latest).\r\n\r\nI\u2019ll try re-ihstalling tf 1.4.1 and making all the numpy arrays 64 bit and see what happens and report back.\r\n\r\nAgain, thanks for all of your work on this.\r\n\r\nOn Jan 30, 2018, at 9:11 PM, GemesysCanada <notifications@github.com<mailto:notifications@github.com>> wrote:\r\n\r\n\r\nCracked it. Got a solution (workaround, essentially), and a probable cause. The MacBook running MacOS Yosemite (10.10.5) looks to be doing it's rounding and/or floating-point math wrong. Based on Quaeler's results which shows the simulation running on MacOS Sierra 10.12.6 same as on Linux platforms (CentOS-7.4 and Ubuntu), it's clear the evolution of the Laplace PDE (partial differential equation) simulation to the complex moire-pattern is the correct evolution, and the MacOS Yosemite 10.10.5 has a flaw in how it is doing 32-bit floating math. On GNU Linux systems, both 32-bit and 64-bit (CentOS-6.6 and CentOS-7.4 confirmed) it is possible to explicitly control precision, using a routine \"fesetprec\", which can be lifted from a handbook of code: (see here) https://books.google.ca/books?id=OjUyDwAAQBAJ&pg=PA127&lpg=PA127&dq=ieee.c+++fesetprec+to+control+precision&source=bl&ots=VLtoiOfYfE&sig=BfdtySalckBzIB-mbV_Uy4uXLL4&hl=en&sa=X&ved=0ahUKEwjD1r6BzujYAhUH94MKHTNhDowQ6AEIJzAA#v=onepage&q=ieee.c%20%20%20fesetprec%20to%20control%20precision&f=false\r\n\r\nThe \"fesetprec\" invokes a macro, called: \"_FPU_SETCW\", which generates some assembler code to set values in the Intel control word which, on IA-32 architectures, is used to explicitly control precision of floating point calculations. The macro's _FPU_GETCW and _FPU_SETCW are available on GNU Linux systems in the \"fpu_control.h\" include file, in /usr/include. The Intel spec for 8087 and 80387 FPU's allowed this. The newer/newest MMX (and now SSE and SSE2 and SSE3 and such) architectures are indicated as not using this control word -but curiously, if you run test programs to explicity set precision, and then run precision-dependent code, you can see that on both architectures - IA-32, and the newer 64-bit Intel Core-i3 and Core-i5 chips, this control word can still be set, at least on Linux machines. I've confirmed this.\r\n\r\nI downloaded and converted the UCBTest suite which exercises a bunch of floating-point calculations, and then I also pulled together a working example of a test program (from the Handbook previously mentioned), which sets the precison control-word. Basically, you define your vars as \"long double\", but then you can tweak the control-word to run in float, double, or long-double. The test program \"chkprec.c\" gives three different results, depending on the precision selected. This program works the same on both CentOS 6.6 and CentOS 7.4. Long-double on a 32-bit box is probably going to be compiled as REAL*10 (the 80-bit extended precision - which Intel chips do their math in - and which has been a fixture of Intel architecture since the first IBM P/C.) I know a tiny bit about this, because my \"gDOSbox\" app (free, no ads, no tracking on Google Playstore) is special, because I know it has had its conversion math fixed so that mapping from 32-bit (\"float\"), and 64-bit (double precision) to 80-bit (extended precision), was not originally being done correctly, (in the open-source DOSbox code), but is being done correctly in gDOSbox. Most public DOSbox's would not run high-precision Fortran or C progams correctly. The math in \"gDOSbox\" can be run correctly, and the APL interpreters and Fortran compilers that it supports (WF77 - Watcom Fortran is one of them), do their math correctly (I've checked).\r\n\r\nFor NN (Neural Net) applications, matrix-math must be done correctly, and the TensorFlow Laplace sim was a great exercise of matrix math. The routine used is called: \"tf.nn.depthwise_conv2d\" (if you import TensorFlow into Python as \"tf\"). It is documented here:\r\nhttps://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d\r\n\r\nYou might also want to look at this, if learning about tf.nn.depthwise_conv2d:\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.5/tensorflow/python/ops/nn_impl.py\r\n\r\nWhat I found using UCBTest and chkprec.c, was that the Macbook Pro, under Yosemite (MacOS 10.10.5) does not support the explicit-setting of precision in the same manner that Linux does. There is no provision for setting the precision control-word on the Mac under Yosemite, or if there is, it is substantially different than is the case for Linux. My version of chkprec.c on the MacBook is an ugly hack, with three different functions, one in each precision level (float, double, and long double), and it was only in this way that I could reproduce the results I was getting on Linux, where the precision control word could be set to the desired precision using fsetprec. This means that math-calc code written for Linux which relies on the ability to explicitly control precision, probably won't run correctly on the Mac, unless low-level changes are made. Also, there are differences in the \"UCBfail\"s that occur on the Macbook, as opposed to the Linux boxes. What is interesting, is the 64-bit Linux runs the UCBTest suite better than the 32-bit Linux (CentOS 6.6) does. And both the Linux 64-bit and the MacOS 64-bit pass the cpar_DP and cpar_SP (\"paranoid\") tests, as well as the DP and SP (double and single precision) tests for \"mul\" and \"div\". But the \"cpi_DP\" test iterates differently on Mac versus Linux 64-bit, and only in a few places where the exponents are large negative (E-26, E-38, E-40, and such).\r\n\r\nI will post the various test programs to my github account.\r\n\r\nIn order to get the Laplace PDE simulation to iterate-and-evolve correctly (so you get a funky image of a moire-pattern, and some dark-matter black-space, instead of just a blank screen, as the MacBook was doing), I changed all the 32-bit (\"float\" level precision, like REAL4 in Fortran), into 64-bit doubles (like REAL8 in Fortran). The TensorFlow documentation indicates that the tf.nn.depthwise_conv2d is able to operate in either mode, and it does. It appears that TensorFlow is operating correctly, and it appears the bug that shows up in MacOS only manifests itself if the Python (numpy) variables are 32-bit (or \"float).\r\n\r\nChange all the variables to 64-bit, and the simulation works the same on both machines.\r\nI'll monitor this thread for a bit, and if the TensorFlow authors don't close it, I will, as it appears not to be a TensorFlow issue, but is a MacOS issue, which as Quaeler discovered, can be resolved by upgrading to MacOS 10.12.6 (Sierra), and probably the newer \"High Sierra\" as well. If you have other reasons for wishing to maintain your MacBook at Yosemite, but still want to run TensorFlow (in CPU mode), then I would recommend doing your network math and back-propagations with 64-bit floats, not 32-bit values. I ran the sim forward with 57500 iterations, and the exponents are up around E+132 and E+133... big numbers, but still calculating correctly. The final image and numeric (U(eval) at row 20) images for MacBook and Linux (CentOS-7.4) provided below.\r\n\r\nHope all this helps anyone else struggling with wrong floating-point number problems on their MacBooks using TensorFlow. The problem likely resides somewhere in the Xcode 7.2.1 - Clang 700x compiler used to build Python and TensorFlow, and again, is most likely resolved by using later versions of the compiler where the floating-point flaws appear to have been corrected. (But they aren't all fixed. Some of the test programs we have tried still show variance between Linux and MacOS results. The \"PIRATS\" program (see above) still shows some different numbers on each platform.)\r\n\r\nIn my work with Xerion, I found it was critical to set the TCL-precision variable to it's highest value (17 or 18 or some such thing), if I wanted to write the network-weights out to a file, for subsequent loading at a later time, if the file was an ascii (not binary) numeric represetation. The default was 8 digits after the decimal, and if you wrote and re-read network weights at that precision, your network was destroyed. Weight digits 10 or 12 past the decimal place made a difference to network operation, and it became clear a very high level of precision was essential. If you are working with neural networks, you might want to read W. Kahan's paper on IEEE 754, and the choices and trade-offs that were made to create a viable floating-point math standard.\r\n(Images of Laptest_64 sim on each platform follow..)\r\n[laptest_64_700_centos74_screenshot_2018-01-29_10_32pm]<https://user-images.githubusercontent.com/16905336/35584502-34d92556-05c3-11e8-9485-b8629e501347.jpg>\r\n[laptest_64_700_57k_macos_screenshot_2018-01-30_1_24am]<https://user-images.githubusercontent.com/16905336/35584523-46e5b3b8-05c3-11e8-92c3-8cf00b9bb8ab.jpg>\r\n\r\n\u2014\r\nYou are receiving this because you commented.\r\nReply to this email directly, view it on GitHub<https://github.com/tensorflow/tensorflow/issues/15933#issuecomment-361699391>, or mute the thread<https://github.com/notifications/unsubscribe-auth/ABGLLW_4IC2Z9S4xQ2BvfxcMKWwYPXD-ks5tP2legaJpZM4RVyqU>.\r\n\r\n", "@skye awaiting response or awaiting tensorflower?", "Ah sorry, I didn't read through the thread carefully enough. @lewisl thank you for digging into this and finding a solution! @MarkDaoust are you in charge of docs? It sounds like there are numerical problems running TF on MacOS Yosemite, which we may wanna warn about in the docs (see @lewisl's comment above this one, starting with \"Cracked it.\").", "Wow this is quite a thread... what would be the right way to document this? A note on the install_mac  page? Can someone with a little more context suggest the text?\r\n", "Wow indeed: @Gemesys, this is excellent numerical detective work! \r\n\r\n@MarkDaoust I think that the install_mac page is a good place to start. It seems to me like our baseline requirement is already MacOS X 10.11 (El Capitan) or higher. \r\n\r\nThe most numerically conservative thing to do would be to raise the minimum required version to 10.12.6 (Sierra) as @Gemesys reports. That seems pretty narrow, as Sierra has only been out since 13 June 2016. \r\n\r\nIf we don't want to make TF drop support for El Capitan early, then I'd suggest making the recommendation line longer:\r\n\r\n    * macOS X 10.11 (El Capitan or higher) is supported. Note that there are accuracy-affecting numerical issues before macOS X 10.12.6 (Sierra) that are described in [GitHub#15933](https://github.com/tensorflow/tensorflow/issues/15933#issuecomment-366331383), so 10.12.6 or higher is preferred. \r\n\r\n", "I'm happy to drop support for El Capitan. Apple is pretty good about making sure people can upgrade, the upgrades are free, and I'd think not too many users remain on El Capitan. I would still add a warning to the install page to motivate it, since installation will actually work fine.\r\n\r\n```\r\nNote that there are known accuracy-affecting numerical issues before macOS X 10.12.6 (Sierra) that are described in [GitHub#15933](https://github.com/tensorflow/tensorflow/issues/15933#issuecomment-366331383). \r\n```", "It would be interesting to find out more about how the OS can play any role here. After all, the floating-point control word is a CPU feature, not an OS feature. There have been cases where OSes or drivers still managed to corrupt such CPU state by means of interrupts, or alternatively, one could imagine that some OS might have a buggy implementation of saving/restoring registers in context-switches... it would be interesting to find that out.", "Is this issue resolved after the fix?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "> Is this issue resolved after the fix?\r\n\r\nThe docs are updated on versions/master/ is that a sufficient resolution?"]}, {"number": 15932, "title": "General change in batch size Performance Question", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A\r\n- **TensorFlow installed from (source or binary)**: N/A\r\n- **TensorFlow version (use command below)**: 1.4.1\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\nI have opened a question on StackOverflow. I suspect only a developer can answer the question. The link to the question is here:\r\nhttps://stackoverflow.com/questions/48099754/does-a-change-in-batch-size-impact-performance\r\n\r\nThe question is around Reinforcement Learning and if there will be a speed improvement if the batch size of the graph is not changed. RL usually has a training batch and a \"next_action\" type of single sample (batch size =1). The network is intermittently hit with either the training batch size or batch size of 1. Does TF take a performance hit every time the graph sees a different batch size through the feed_dict()? If this is the case, should 2 graphs be created so the batch size doesn't change from call to call?\r\n\r\nIf you post the answer here I will copy it to StackOverflow.\r\n\r\nThanks\r\n\r\n### Source code / logs\r\nN/A\r\n\r\n  ", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "@tensorflowbutler Updated", "The original poster has replied to this issue after the stat:awaiting response label was applied.", "@ebrevdo wanna take that one?", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ebrevdo: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ebrevdo: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ebrevdo: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Any thoughts on this or should we close it as unknown?", "Nagging Assignee @ebrevdo: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Doesn't look like anyone has time to answer this question.  I am closing it as the project has found a different approach (in graph data queue)."]}, {"number": 15931, "title": "Making SQLite better", "body": "", "comments": ["Can one of the admins verify this patch?", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Closing due to inactivity. I welcome further participation in writing this implementation if you want."]}, {"number": 15930, "title": "Discontinuity at halfway point in graph output", "body": "- **I have written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nto reproduce the error:\r\n1) convert HnH_gate.txt to HnH_gate.py\r\n2) Edit mypath in out() method at end of file for your system.  Save \r\n3) in python: run HnH_gate.py\r\n4) run out() to create csv files for the good and bad output\r\n            i) out(\"101\", new_probka_good)\r\n            ii) out(\"102\", new_probka_bad)\r\n5) Plot data from hh_101.csv and hh_102.csv and verify the discontinuity at half way point in hh_102.csv\r\n6) Two additional tests can be run:\r\n          i) Edit parameter timepoints in main() to show error remaps to half way point.\r\n          ii) My temporary correction is to create 2x points and throw half away.  this is done in p_update() setting cut_in_half = True\r\n\r\n7) This same error was found running the code in Tensorflow 1.4 on MacOS Sierra.  My system info is:\r\n\r\n\r\n== cat /etc/issue ===============================================\r\nLinux PAULP-XPS15 4.4.0-43-Microsoft #1-Microsoft Wed Dec 31 14:42:53 PST 2014 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"16.04.3 LTS (Xenial Xerus)\"\r\nVERSION_ID=\"16.04\"\r\nVERSION_CODENAME=xenial\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux PAULP-XPS15 4.4.0-43-Microsoft #1-Microsoft Wed Dec 31 14:42:53 PST 2014 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy (1.13.3)\r\nnumpydoc (0.7.0)\r\nprotobuf (3.4.1)\r\ntensorflow (1.3.0)\r\ntensorflow-tensorboard (0.1.5)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.3.0\r\ntf.GIT_VERSION = b'unknown'\r\ntf.COMPILER_VERSION = b'unknown'\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\n./tf_env_collect.sh: line 105: nvidia-smi: command not found\r\n\r\n== cuda libs  ===================================================\r\n\r\n\r\n### Describe the problem\r\nI am running a RNN for a Hodgkin and Huxley type gating of an ion channel protein\r\ncalled HnH_gate.py.\r\nThe program takes a placeholder vmem and produces a timeseries output of the size\r\ntimepoints.\r\nAt the halfway point in the timeseries there is a discontinuity in the results\r\nThis only appears with some arrays fed to my tf.placeholder.  Others produce normal\r\nresults.  I can correct for the problem by doubling the number of timepoints requested\r\nand throwing half away.\r\n\r\nThe array:\r\nvmem_list_good = [[-100.0, -90.0, -80.0, -70.0, -60.0, -50.0, -41.0, -30.0, -20.0, -10.0, 0.0, 10.0, 20.0, 30.0, 40.0, 50.0],\r\n                [-100.0, -90.0, -80.0, -70.0, -60.0, -50.0, -41.0, -30.0, -20.0, -10.0, 0.0, 10.0, 20.0, 30.0, 40.0, 50.0]]\r\nappears to work perfectly\r\nThe array:\r\nvmem_list_bad = [[80.0, 60.0, 40.0, 20.0, 00.0, -20.0, -41.0, -60.0, -80.0, -55.0, 0.0, 10.0, 20.0, 30.0, 40.0, 50.0],\r\n            [70.0, 50.0, 30.0, 10.0, -10.0, -30.0, -50.0, -70.0, -90.0, -30.0, -10.0, 0.0, 10.0, 20.0, 30.0, 40.0]]\r\n\r\nshows the error.\r\n\r\nTo see my temporary correction, edit the parameter in the HH.p_update() method\r\nto: cut_in_half = True\r\n\r\nI have written a short output routine to export the simulation to a csv file,\r\njust edit the path and provide a string to make a unique filename:\r\n\r\nout(\"101\", new_probka_good)\r\nout(\"102\", new_probka_bad)\r\n\r\n### Source code / logs\r\nprogram file is: HnH_gate.py (provided as HnH_gate.txt)\r\nHnH_gate.txt  (convert to HnH_gate.py)\r\n[HnH_gate.txt](https://github.com/tensorflow/tensorflow/files/1610057/HnH_gate.txt)\r\n\r\nSystem and Error Description: HnH_gate_bug_report.txt\r\n[HnH_gate_bug_report.txt](https://github.com/tensorflow/tensorflow/files/1610056/HnH_gate_bug_report.txt)\r\n\r\nOutput example demonstrating problem: Artifact plotting new_probka_bad.py\r\n[Artifact plotting new_probka_bad.pdf](https://github.com/tensorflow/tensorflow/files/1610058/Artifact.plotting.new_probka_bad.pdf)\r\n\r\nThanks for your help.\r\nPaul\r\n  \r\n  ", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "I have edited the file to show the info requested upfront.  The problem has also been seen reproduced on Tensorflow 1.4 on MacOS Sierra.  \r\n", "resolved as a tiling artifact."]}, {"number": 15929, "title": "C API, SIGABRT abort, Non-OK-status: RegisterAlreadyLocked, Invalid name.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nWorking with public C API.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nMacOS 10.13.2 (17C88)\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary\r\n- **TensorFlow version (use command below)**:\r\n- libtensorflow 1.4.1 (from brew package)\r\n- **Python version**: \r\nnon\r\n- **Bazel version (if compiling from source)**:\r\nnon\r\n- **GCC/Compiler version (if compiling from source)**:\r\nApple Swift version 4.0.3 (swiftlang-900.0.74.1 clang-900.0.39.2), lldb-900.0.64, Swift-4.0\r\n- **CUDA/cuDNN version**:\r\nnon\r\n- **GPU model and memory**:\r\nnon\r\n- **Exact command to reproduce**:\r\nUsing swift code as example (https://github.com/Octadero/Example).\r\n\r\n### Describe the problem\r\nDear TensorFlow community, \r\nIt is really strange issue, from time to time at the same code, I have SIGABRT crash.\r\n```\r\n2018-01-05 21:03:55.627002: F tensorflow/core/framework/op.cc:165] Non-OK-status: RegisterAlreadyLocked(deferred_[i]) status: Invalid argument: Invalid name: {\\242\t\u0001\r\n(lldb) bt\r\n* thread #1, queue = 'com.apple.main-thread', stop reason = signal SIGABRT\r\n    frame #0: 0x00007fff528f7e3e libsystem_kernel.dylib`__pthread_kill + 10\r\n    frame #1: 0x0000000108cd41b4 libsystem_pthread.dylib`pthread_kill + 333\r\n    frame #2: 0x00007fff52854312 libsystem_c.dylib`abort + 127\r\n    frame #3: 0x0000000108e600c0 libtensorflow_framework.so`tensorflow::internal::LogMessageFatal::~LogMessageFatal() + 32\r\n    frame #4: 0x0000000108e600d0 libtensorflow_framework.so`tensorflow::internal::LogMessageFatal::~LogMessageFatal() + 16\r\n    frame #5: 0x0000000108d28676 libtensorflow_framework.so`tensorflow::OpRegistry::MustCallDeferred() const + 406\r\n    frame #6: 0x0000000108d2819d libtensorflow_framework.so`tensorflow::OpRegistry::LookUp(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tensorflow::OpRegistrationData const**) const + 61\r\n    frame #7: 0x0000000108d0c875 libtensorflow_framework.so`tensorflow::FunctionLibraryDefinition::LookUp(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tensorflow::OpRegistrationData const**) const + 117\r\n    frame #8: 0x0000000108d27b0a libtensorflow_framework.so`tensorflow::OpRegistryInterface::LookUpOpDef(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, tensorflow::OpDef const**) const + 42\r\n    frame #9: 0x0000000108d81b65 libtensorflow_framework.so`tensorflow::Graph::AddNode(tensorflow::NodeDef const&, tensorflow::Status*) + 69\r\n    frame #10: 0x0000000108d8177a libtensorflow_framework.so`tensorflow::Graph::Graph(tensorflow::OpRegistryInterface const*) + 458\r\n    frame #11: 0x00000001004f7d73 libtensorflow.so`TF_NewGraph + 51\r\n  * frame #12: 0x00000001066b739d CAPI`newGraph() at Graph.swift:26\r\n    frame #13: 0x00000001063021b3 TensorFlowKit`Graph.init() at Graph.swift:36\r\n    frame #14: 0x000000010630214a TensorFlowKit`Graph.__allocating_init() at Graph.swift:0\r\n    frame #15: 0x0000000106500f2d TensorFlowKit`static SavedModel.load(exportPath=\"/Users/Volodymyr/Projects/Examples/03_Reinforcement/Resources/save/\", tags=1 value, options=0x00000001098e35d0, self=TensorFlowKit.SavedModel) at SavedModel.swift:221\r\n    frame #16: 0x00000001000069f4 03_Reinforcement`static Network.loadGraph(self=_3_Reinforcement.Network) at Network.swift:146\r\n    frame #17: 0x0000000100003428 03_Reinforcement`Network.init() at Network.swift:73\r\n    frame #18: 0x0000000100002e4c 03_Reinforcement`Network.__allocating_init() at Network.swift:0\r\n    frame #19: 0x0000000100008656 03_Reinforcement`main at main.swift:32\r\n    frame #20: 0x00007fff527a8115 libdyld.dylib`start + 1\r\n    frame #21: 0x00007fff527a8115 libdyld.dylib`start + 1\r\n```\r\nSanitizer options can't help to resolve that issue. List of libs loaded in attached file.\r\n[dyld_log.txt](https://github.com/tensorflow/tensorflow/files/1609977/dyld_log.txt)\r\n\r\n\r\n### Source code / logs\r\nUsing C API I am alloc [new Graph by TF_NewGraph()](https://github.com/Octadero/TensorFlow/blob/34addfc80cb7f220a7d9afa310f8a9845dba0d36/Sources/CAPI/Graph.swift#L26)", "comments": ["I'm not at all well versed enough with Swift and how libraries are loaded/managed in it. However, just looking at the error message, it seems to be coming from the call to `RegisterAlreadyLocked` [here](https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/core/framework/op.cc#L165), which in turn is returning an error from [here](https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/core/framework/op_def_util.cc#L232).\r\n\r\nThis, in turn, is suggesting that an incorrect (or corrupted) `OpDef` structure is being processed.\r\n\r\nAre you registering any custom operations? Or is it possible that there is some memory stomping happening that is corrupting the in-memory `OpDef` structures?", "Hello, thanks for response, \r\n That is clear enough that crash at  MustCallDeferred func. But how to fix that not clear. \r\nAs you can see `name` is kind of \"memory trash\".\r\n>Are you registering any custom operations?\r\n\r\nNo,\r\n\r\n>Is it possible that there is some memory stomping happening ...\r\n\r\nYes you are right, but I am calling `TF_NewGraph()` and all memory management encapsulated in c_api.cc.  \r\n  ", "Is there a way you can reproduce the crash using a simple C program? That might make it easier to debug (without having to dig through Swift code, which I'm not familiar with)", "Ok, I will try. ", "It was Swift memory management issue related to C module. \r\nThanks."]}, {"number": 15928, "title": "Utility classes for writing Java source code from a C++ process (part 2)", "body": "Part 2 of pull request #14094 that has been splitted into several commits.\r\n\r\nThis part features only a language-agnostic writer that outputs generated source code into a file or in memory. Note that this class is being kept apart from the Java-specific code generators since it could be a good candidate to be moved in the core io library in the future (ref #13748).\r\n\r\ncc: @asimshankar ", "comments": ["Can one of the admins verify this patch?", "Test failures are unrelated. Mering PR. Thanks, @karllessard "]}]