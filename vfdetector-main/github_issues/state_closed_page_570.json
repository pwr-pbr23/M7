[{"number": 36590, "title": "Building a static library for windows with visual studio.", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.1\r\n- Are you willing to contribute it (Yes/No): yes (but not sure I can)\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nI want a feature to build a static library for C++ integrating on windows with visual studio. Or a static library that is available for download.\r\n\r\n**Will this change the current api? How?**\r\nNo, it will not change the api.\r\n\r\n**Who will benefit with this feature?**\r\nEveryone who has a C++ project in visual studio and want to implement tensorflow.\r\n\r\n**Any Other info.**\r\nIt would have been nice with a full guide to how to do it. This is something I could contribute with if we ever get the feature.", "comments": ["@JesperLindberg \r\nCould you please verify on the latest version if this is still an issue.", "@Saduf2019 I will close this as I no longer has anyway of checking this. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36590\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36590\">No</a>\n"]}, {"number": 36589, "title": "[DOC]: Update the docs regarding Variable.assign", "body": "Fix #35667 and Update the docs regarding `Variable.assign` and mention the fact that `variable_shape=False` is not enough and the `tf.Variable` has to be initialized with `shape=TensorShape(None)`", "comments": ["Hi @Bharat123rox,\r\n\r\nThanks for taking the time to make a PR, but this still doesn't look right.\r\n\r\nSetting:\r\n\r\n```\r\nv = tf.Variable([1,2,3], validate_shape=False, shape=None)                                                                                                  \r\nv.assign([1,2])          \r\n```\r\ngives:\r\n\r\n```\r\nValueError: Shapes (3,) and (2,) are incompatible\r\n```\r\n\r\nYou're editing VariableV1.... so maybe you were testing this in graph mode?\r\n\r\n```\r\nimport tensorflow.compat.v1 as tf\r\ntf.disable_v2_behavior()    \r\ntf.Variable([1,2,3.], validate_shape=False, shape=None)\r\na = v.assign([1,2.])\r\n```\r\nLooks okay so far ... but all that's done is move the error from compile time to execution time.\r\n\r\n```\r\ni = tf.global_variables_initializer()\r\nwith tf.Session() as sess:\r\n  sess.run(i)\r\n  sess.run(a)\r\n```\r\n\r\n```\r\n  InvalidArgumentError: Assign requires shapes of both tensors to match. lhs shape= [3] rhs shape= [2]\r\n  \t [[node Assign (defined at site-packages/tensorflow_core/python/framework/ops.py:1751) ]]\r\n```\r\n\r\nDo you have a working example? If not I'd just delete the line about changing the variable shape.", "@Bharat123rox Can you please check MarkDaoust's comments and keep us posted? Thanks!", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "I don't think this resolves the issue. Closing."]}, {"number": 36588, "title": "Software requirement may lack VC++ runtime", "body": "## URL(s) with the issue:\r\n\r\n[Software requirements](https://www.tensorflow.org/install/gpu#software_requirements)\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe requirement may lack the dependency of [Microsoft Visual C++ Redistributable for Visual Studio](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads) runtime.\r\n\r\n### Clear description\r\n\r\nAfter installation, TF raises an error with `ImportError: DLL load failed: The specified module could not be found.`\r\n\r\nFixed after installing [Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017 and 2019](https://aka.ms/vs/16/release/vc_redist.x64.exe) via [error page](https://www.tensorflow.org/install/errors) and issue https://github.com/tensorflow/tensorflow/issues/22794 & https://github.com/tensorflow/tensorflow/issues/22512\r\n\r\nWanna confirm whether Microsoft Visual C++ Redistributable for Visual Studio must be installed and its version. If true, please add this information to [software requirements](https://www.tensorflow.org/install/gpu#software_requirements).\r\n\r\n### Submit a pull request?\r\n\r\nIf confirmation, I can PR to [tensorflow/docs](https://github.com/tensorflow/docs/blob/master/site/en/install/gpu.md).\r\n\r\n---\r\nPS.. here comes system info to trace that issue.\r\nHardware:\r\n```\r\nProcessor: Intel(R) Core(TM) i7-7500U CPU @ 2.70GHz (4 CPUs), ~2.9GHz\r\nMemory: 16384MB RAM\r\nCard name: NVIDIA GeForce 940MX\r\nManufacturer: NVIDIA\r\nChip type: GeForce 940MX\r\n```\r\nSoftware:\r\n```\r\nOperating System: Windows 10 Pro 64-bit (10.0, Build 18363) (18362.19h1_release.190318-1202) \r\n(conda)TensorFlow: 2.1.0 (install via pypi)\r\n(conda)cudatoolkit: 10.1.243 (install via anaconda)\r\n(conda)cudnn: 7.6.5 (install via anaconda)\r\nNvidia Driver Version: 441.87\r\n```\r\nIt can be reproduced in `conda install` or `native install`.\r\n\r\nHope those info helps.\r\n\r\nThanks in advance! :-)", "comments": ["Confirmed with [TF 2.1 release note](https://github.com/tensorflow/tensorflow/releases/tag/v2.1.0).", "@kuri-leo I am closing this issue as the docs have already been updates as you can see [here](https://www.tensorflow.org/install/source_windows#install_visual_c_build_tools_2019). If I misinterpreted the issue, please open it again. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36588\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36588\">No</a>\n", "@gowthamkpr Oh, that is another point. It should be clarified that the issue occurs during install tf2.1 via pip directly, not from source code. So, I believe info should also be updated to [system-requirements](https://www.tensorflow.org/install/pip#system-requirements). Related PR is https://github.com/tensorflow/docs/pull/1453, and now it's ready to pull."]}, {"number": 36587, "title": "Unable to reset tensorflow model", "body": "I am trying to find the optimal number of neurons in the model. For that I am using a loop for number of layers. But instead of resetting the tensorflow model, it's adding layers to it. I tried K.clear_session(),sess.close(), gc.collect(). It doesn't works. Cuda.close() terminates the program, I am using tensorflow 1.10, win 10.", "comments": ["@Tarungarg98 Could you please provide us with simple standalone code to reproduce the issue in our environment, Thanks", "![image](https://user-images.githubusercontent.com/44539397/74142273-8d34d080-4c1e-11ea-9fa0-bb6a955c9ba9.png)\r\n\r\n\r\nI am varying the number of neurons with variable y, but it's not creating a mew model with every loop", "@Tarungarg98  Please fill the template and provide complete editable code for us to replicate and help.", "OS : Windows 10\r\nTensorflow version : 1.10.0 - gpu\r\nLaptop: HP cc-102-tx\r\nCuda : 9.0\r\nGraphics Card - NVIDIA GEForce 940MX \r\nRAM -8 GB\r\n\r\nCode :\r\nfor x in ['relu','tanh']:\r\n\tfor y in range(1,20):\r\n\t\tfor z in [1500]:\r\n\t\t\tmodel = Sequential()\r\n\t\t\tmodel.add(Dense(y, input_dim=4, activation=x))\r\n\t\t\tmodel.add(Dense(2, activation='linear'))\r\n\t\t\topt = tf.keras.optimizers.SGD(lr=0.01, momentum=0.9,decay=1e-5, nesterov=True)\r\n\t\t\tmodel.compile(loss='mean_squared_error', optimizer=opt,metrics=['accuracy'])\r\n\t\t\tmodel.fit(x_train, y_train, validation_data=(x_validate, y_validate), epochs=z,verbose=1,callbacks=[tensorboard_callback])\r\n\r\n", "@Tarungarg98  Could you please share complete implementable code, so we could replicate it in our environment to see where the issue lies and help you.", "def nn(x,y,x_train,x_validate,x_test,y_train,y_validate,y_test,results,output):\r\n\tK.clear_session()\r\n\tmodel=None\r\n\tmodel= Sequential()\r\n\tmodel.add(Dense(y, input_dim=4, activation=x))\r\n\tmodel.add(Dense(2, activation='linear'))\r\n\topt = tf.keras.optimizers.Adam(lr=0.01, decay=1e-3)\r\n\tmodel.compile(loss='mean_squared_error', optimizer=opt,metrics=['accuracy'])\r\n\t# fit model\r\n\tprint('Training :',x,y)\r\n\tlog_dir=\"logs/test3/\" + x+'_'+str(y)+'_3000_'+datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n\ttensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\r\n\tmodel.fit(x_train, y_train, validation_data=(x_validate, y_validate), epochs=3000,verbose=0,callbacks=[tensorboard_callback])\r\n", "Every time I call this function I need to create a new model, but it's not creating one", "I'm seeing a similar issue in my project using TF2.0. Should I open a separate issue referencing this one for that?", "@acvander Please create a separate issue for that.", "@Tarungarg98 I have tried to replicate issue faced by you with the code provided, here is the [link](https://colab.sandbox.google.com/gist/Saduf2019/a538dda0514ef28bd545d4311d1c937e/untitled31.ipynb) for the same, unless we have the complete executable code[with dependencies] to see what issue is faced by you we will not be able to help.", "I updated the code in the editor\r\nIt works on fine on colab but not on my PC\r\nON colab the model is resetting but on PC it's not resetting.\r\n\r\nAttaching the snip of my results \r\n![image](https://user-images.githubusercontent.com/44539397/74315138-d874ed80-4d9c-11ea-9f9e-910bdf48ecd8.png)\r\n", "[link](https://colab.research.google.com/gist/Tarungarg98/d7a247e1fe961f267f6c8d7cf6c7abeb/untitled31.ipynb)", "@Tarungarg98  Please share \"data_nn.csv\" to try this on local environment.", "@Saduf2019  Added", "@Tarungarg98  I have not received the csv. please drag and drop the zip file in the comment box.", "\r\n[data_nn.zip](https://github.com/tensorflow/tensorflow/files/4191100/data_nn.zip)\r\n", "@Tarungarg98 I have replicated your issue on my local as well [result is same as the colab link you have shared above] and understand that when you execute your code on colab the dependencies are taken care, whereas on local your imports were not as expected, [\"keras.backend\" from keras] please use:\r\n\r\nfrom tensorflow.keras import backend as K instead of #import keras.backend as K\r\n\r\nCould you please make this change and let us know if you still face the issue.", "It works after making the change. Thank you"]}, {"number": 36586, "title": "Updating the template of \"others\" type of issues", "body": "", "comments": []}, {"number": 36585, "title": "Updating the template of TFLiteConverter related issues", "body": "", "comments": ["@jvishnuvardhan Could you please resolve the conflicts? Thanks!", "Closing this as required changed were carried out using another cl/294974844"]}, {"number": 36584, "title": "Updating the template of tflite component", "body": "", "comments": []}, {"number": 36583, "title": "Updating the template of Feature type", "body": "", "comments": []}, {"number": 36582, "title": "Updating the template of Build/Install", "body": "", "comments": []}, {"number": 36581, "title": "tf.GradientTape.gradients() does not support graph control flow operations like tf.cond or tf.while at this time. Use tf.gradients() instead.", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["@chih-wei-chen, Please provide the information asked in the Template. Thanks!", "@chih-wei-chen, Can you provide the code snippet to replicate the reported issue along with Tensorflow version. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 36580, "title": "Stuck while using TFRecordWriter - TypeError: <class 'tensorflow.python.framework.ops.EagerTensor'>, but expected one of: (<class 'int'>,)", "body": "I'm using Tensorflow-GPU 1.15.0 in a Colab notebook (Python 3.6.10) with local runtime on a Windows 10 device. I'm receiving the error above when trying to write the predictions I've created to a TfRecord File. It is based on [this](https://github.com/google/earthengine-api/blob/master/python/examples/ipynb/TF_demo1_keras.ipynb) colab notebook. It works fine on that hosted runtime but Running this job there is not an option as it takes too long.\r\n\r\n```\r\n# Instantiate the writer.\r\nwriter = tf.python_io.TFRecordWriter(outputImageFile)\r\n\r\n# Every patch-worth of predictions we'll dump an example into the output\r\n# file with a single feature that holds our predictions. Since our predictions\r\n# are already in the order of the exported data, the patches we create here\r\n# will also be in the right order.\r\npatch = [[], [], [], []]\r\ncurPatch = 1\r\nfor prediction in predictions:\r\n  patch[0].append(tf.argmax(prediction, 1))\r\n  patch[1].append(prediction[0][0])\r\n  patch[2].append(prediction[0][1])\r\n  patch[3].append(prediction[0][2])\r\n  # Once we've seen a patches-worth of class_ids...\r\n  if (len(patch[0]) == PATCH_WIDTH * PATCH_HEIGHT):\r\n    print('Done with patch ' + str(curPatch) + ' of ' + str(PATCHES) + '...')\r\n    # Create an example\r\n    example = tf.train.Example(\r\n      features=tf.train.Features(\r\n        feature={\r\n          'prediction': tf.train.Feature(\r\n              int64_list=tf.train.Int64List(\r\n                  value=patch[0])),\r\n          'bareProb': tf.train.Feature(\r\n              float_list=tf.train.FloatList(\r\n                  value=patch[1])),\r\n          'vegProb': tf.train.Feature(\r\n              float_list=tf.train.FloatList(\r\n                  value=patch[2])),\r\n          'waterProb': tf.train.Feature(\r\n              float_list=tf.train.FloatList(\r\n                  value=patch[3])),\r\n        }\r\n      )\r\n    )\r\n    # Write the example to the file and clear our patch array so it's ready for\r\n    # another batch of class ids\r\n    writer.write(example.SerializeToString())\r\n    patch = [[], [], [], []]\r\n    curPatch += 1\r\n\r\nwriter.close()\r\n```\r\n\r\n**Error:**\r\n```\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-26-d7a6c8a0115c> in <module>\r\n     21           'prediction': tf.train.Feature(\r\n     22               int64_list=tf.train.Int64List(\r\n---> 23                   value=patch[0])),\r\n     24           'bareProb': tf.train.Feature(\r\n     25               float_list=tf.train.FloatList(\r\n\r\nc:\\anaconda\\envs\\tfcollab\\lib\\site-packages\\google\\protobuf\\internal\\python_message.py in init(self, **kwargs)\r\n    533             field_value = [_GetIntegerEnumValue(field.enum_type, val)\r\n    534                            for val in field_value]\r\n--> 535           copy.extend(field_value)\r\n    536         self._fields[field] = copy\r\n    537       elif field.cpp_type == _FieldDescriptor.CPPTYPE_MESSAGE:\r\n\r\nc:\\anaconda\\envs\\tfcollab\\lib\\site-packages\\google\\protobuf\\internal\\containers.py in extend(self, elem_seq)\r\n    279       raise\r\n    280 \r\n--> 281     new_values = [self._type_checker.CheckValue(elem) for elem in elem_seq_iter]\r\n    282     if new_values:\r\n    283       self._values.extend(new_values)\r\n\r\nc:\\anaconda\\envs\\tfcollab\\lib\\site-packages\\google\\protobuf\\internal\\containers.py in <listcomp>(.0)\r\n    279       raise\r\n    280 \r\n--> 281     new_values = [self._type_checker.CheckValue(elem) for elem in elem_seq_iter]\r\n    282     if new_values:\r\n    283       self._values.extend(new_values)\r\n\r\nc:\\anaconda\\envs\\tfcollab\\lib\\site-packages\\google\\protobuf\\internal\\type_checkers.py in CheckValue(self, proposed_value)\r\n    136       message = ('%.1024r has type %s, but expected one of: %s' %\r\n    137                  (proposed_value, type(proposed_value), six.integer_types))\r\n--> 138       raise TypeError(message)\r\n    139     if not self._MIN <= int(proposed_value) <= self._MAX:\r\n    140       raise ValueError('Value out of range: %d' % proposed_value)\r\n\r\nTypeError: <tf.Tensor: id=408263, shape=(1,), dtype=int64, numpy=array([5], dtype=int64)> has type <class 'tensorflow.python.framework.ops.EagerTensor'>, but expected one of: (<class 'int'>,)\r\n```", "comments": ["@smescarzaga \r\n\r\nI tried to reproduce the issue by the link you have provided. But i am seeing the error when tried to execute the code `EEException: Permission denied.`Please, help me in reproducing the issue. Thanks!", "@smescarzaga Please respond to the above comment.", "> @smescarzaga\r\n> \r\n> I tried to reproduce the issue by the link you have provided. But i am seeing the error when tried to execute the code `EEException: Permission denied.`Please, help me in reproducing the issue. Thanks!\r\n\r\nThe notebook was authored by Google Earth Engine developers and is public facing, not sure how I can help with your specific exception. Did you authorize earth engine api?", "@smescarzaga I am closing this issue as it is not related to bug/performance, build/install, feature request or doc related issues. Please post this issue on stackoverflow where there is a wider community to help. Thanks!", "Please, can anyone tell what is the cause of this error?\r\nI am also getting the same error, and unable to find the solution elsewhere.", "I am getting this same error when I use the output dataset from tf.data.Dataset.from_tensor_slices() in both tf.data.experimental.TFRecordWriter as well as tf.io.TFRecordWriter.\r\nHowever if I use the original features (in numpy format without transformations) passing it with a loop, I get error with boolean features and no error is if convert it to int.\r\nThe serialize_example for one observation run individually does not throw error with boolean values, and not even in TFRecordWriter.\r\n\r\nSee the attached notebook for the full run and error message. The code is one on the Tensorflow examples for TFExample and TFRecord.\r\n\r\nI am using Tensorflow v2.1.0 with Python 3.6 installed in a conda env on a Windows 10 Machine.\r\n\r\n[tf2_tfexample_tfrecord.zip](https://github.com/tensorflow/tensorflow/files/4789997/tf2_tfexample_tfrecord.zip)\r\n\r\n\r\nAny help or suggestion would be appreciated.\r\n", "> I am getting this same error when I use the output dataset from tf.data.Dataset.from_tensor_slices() in both tf.data.experimental.TFRecordWriter as well as tf.io.TFRecordWriter.\r\n> However if I use the original features (in numpy format without transformations) passing it with a loop, I get error with boolean features and no error is if convert it to int.\r\n> The serialize_example for one observation run individually does not throw error with boolean values, and not even in TFRecordWriter.\r\n> \r\n> See the attached notebook for the full run and error message. The code is one on the Tensorflow examples for TFExample and TFRecord.\r\n> \r\n> I am using Tensorflow v2.1.0 with Python 3.6 installed in a conda env on a Windows 10 Machine.\r\n> \r\n> [tf2_tfexample_tfrecord.zip](https://github.com/tensorflow/tensorflow/files/4789997/tf2_tfexample_tfrecord.zip)\r\n> \r\n> Any help or suggestion would be appreciated.\r\n\r\nI use TF2.3.0 and python3.7 run the code from the 'TFRecord and tf.Example' of 'Load and preprocess data' in Tensorflow Tutorials, and i also get this error:\"TypeError: <tf.Tensor: shape=(), dtype=bool, numpy=True> has type <class 'tensorflow.python.framework.ops.EagerTensor'>, but expected one of: (<class 'int'>,) [Op:EagerPyFunc]\"\r\nHave you solved the problem?\r\nAppreciating for your reply", "I meet the same error, please ask for solution? Thanks", "I recreate a conda environment, pip install 2.x.x(in my code use 2.4.1), it will install python package for example numpy and so on. Then the problem can fix.", "I meet the error in win10, but I run the same code in ubuntu is no problem"]}, {"number": 36579, "title": "TPU proto_buf error after migration from 1.3 to 2.1", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 9\r\n- TensorFlow installed from (source or binary):  GCP TF 2.1 image\r\n- TensorFlow version (use command below):  TF v: 2.1.0 Keras v: 2.2.4-tf\r\n- Python version: 3.5.3\r\n- TPU software version is 2.1\r\n\r\nI tried sample from here and it works: https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy\r\n\r\nWhen I try to convert my own, **perfectly working TPU model**, from 1.3 to 2.1 using DistributedStrategy it fails.\r\n\r\nWhen I run the below code in Jupyter, kernel dies when it goes to `fit`\r\n\r\n```\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\n\r\nimport tensorflow as tf\r\nimport tensorflow.keras as k\r\n\r\nprint('TF v:', tf.__version__, 'Keras v:', k.__version__)\r\n\r\nresolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://xx.xx.xx.xx:8470')\r\ntf.config.experimental_connect_to_cluster(resolver)\r\ntf.tpu.experimental.initialize_tpu_system(resolver)    \r\n\r\nstrategy = tf.distribute.experimental.TPUStrategy(resolver) \r\n```\r\n```\r\nwith strategy.scope():\r\n    \r\n    model = k.Sequential()\r\n    model.add(k.layers.Conv1D(filters=16,  kernel_size=2, activation = 'relu', input_shape=(window_size, 1) ))\r\n    model.add(k.layers.Conv1D(filters=32,  kernel_size=2, activation = 'relu'))\r\n    model.add(k.layers.Conv1D(filters=64,  kernel_size=2, activation = 'relu'))\r\n    model.add(k.layers.Conv1D(filters=128, kernel_size=2, activation = 'relu'))\r\n    model.add(k.layers.MaxPooling1D(pool_size=2))\r\n    model.add(k.layers.Flatten())\r\n    model.add(k.layers.Dense(cats, activation='softmax'))\r\n    \r\n    # summary\r\n    print(model.metrics_names)\r\n    print(model.summary())\r\n\r\n    print('--')\r\n    model.compile(optimizer='adam', loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\r\n                  metrics=['categorical_accuracy'])\r\n    print('--')\r\n```\r\n```\r\nmodel.fit(X, y, batch_size = window_size, shuffle=False, epochs = 5)\r\n```\r\n\r\nOutput:\r\n```\r\nTF v: 2.1.0 Keras v: 2.2.4-tf\r\nINFO:tensorflow:Initializing the TPU system: xxxxxxxxxx:8470\r\nINFO:tensorflow:Initializing the TPU system: xxxxxxxxxx:8470\r\nINFO:tensorflow:Clearing out eager caches\r\nINFO:tensorflow:Clearing out eager caches\r\nINFO:tensorflow:Finished initializing TPU system.\r\nINFO:tensorflow:Finished initializing TPU system.\r\nINFO:tensorflow:Found TPU system:\r\nINFO:tensorflow:Found TPU system:\r\nINFO:tensorflow:*** Num TPU Cores: 8\r\nINFO:tensorflow:*** Num TPU Cores: 8\r\nINFO:tensorflow:*** Num TPU Workers: 1\r\nINFO:tensorflow:*** Num TPU Workers: 1\r\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\r\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\r\n```\r\n```\r\n['loss']\r\nModel: \"sequential\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nconv1d (Conv1D)              (None, 1279, 16)          48        \r\n_________________________________________________________________\r\nconv1d_1 (Conv1D)            (None, 1278, 32)          1056      \r\n_________________________________________________________________\r\nconv1d_2 (Conv1D)            (None, 1277, 64)          4160      \r\n_________________________________________________________________\r\nconv1d_3 (Conv1D)            (None, 1276, 128)         16512     \r\n_________________________________________________________________\r\nmax_pooling1d (MaxPooling1D) (None, 638, 128)          0         \r\n_________________________________________________________________\r\nflatten (Flatten)            (None, 81664)             0         \r\n_________________________________________________________________\r\ndense (Dense)                (None, 4)                 326660    \r\n=================================================================\r\nTotal params: 348,436\r\nTrainable params: 348,436\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\nNone\r\n--\r\n--\r\n```\r\nI can see this error in the console though - I am not sure where the proto-buf is coming and why did it work in TF 1.3 - hence I consider this a bug.\r\n```\r\nE0208 17:03:32.001652096    4567 proto_buffer_writer.h:83]   assertion failed: byte_count_ < total_size_\r\n```\r\n\r\nIf I cut data 50 times the fit starts but fails immediately with different error:\r\n```\r\nNotFoundError: No registered 'Identity' OpKernel for 'TPU' devices compatible with node {{node Identity}}\r\n```\r\n\r\nFull traceback:\r\n```\r\nTrain on 27720 samples\r\nEpoch 1/5\r\n    0/27720 [..............................] - ETA: 0s\r\n---------------------------------------------------------------------------\r\nNotFoundError                             Traceback (most recent call last)\r\n<ipython-input-14-fae0bbeaa27e> in <module>\r\n----> 1 model.fit(X, y, batch_size = window_size, shuffle=False, epochs = epochs_n)\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    817         max_queue_size=max_queue_size,\r\n    818         workers=workers,\r\n--> 819         use_multiprocessing=use_multiprocessing)\r\n    820 \r\n    821   def evaluate(self,\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/keras/engine/training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    327                 training_data_iter._initializer  # pylint: disable=pointless-statement\r\n    328               else:\r\n--> 329                 training_data_iter = iter(training_dataset)\r\n    330 \r\n    331             training_result = run_one_epoch(\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/distribute/input_lib.py in __iter__(self)\r\n    563 \r\n    564     worker_iterators = _create_iterators_per_worker(self._cloned_datasets,\r\n--> 565                                                     self._input_workers)\r\n    566     iterator = DistributedIterator(self._input_workers, worker_iterators,\r\n    567                                    self._strategy)\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/distribute/input_lib.py in _create_iterators_per_worker(worker_datasets, input_workers)\r\n   1009       worker_devices = input_workers.compute_devices_for_worker(i)\r\n   1010       iterator = _SingleWorkerDatasetIterator(worker_datasets[i], worker,\r\n-> 1011                                               worker_devices)\r\n   1012       iterators.append(iterator)\r\n   1013   return iterators\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/distribute/input_lib.py in __init__(self, dataset, worker, devices)\r\n    862     self._worker = worker\r\n    863     self._devices = devices\r\n--> 864     self._make_iterator()\r\n    865 \r\n    866   def _make_iterator(self):\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/distribute/input_lib.py in _make_iterator(self)\r\n    868     with ops.device(self._worker):\r\n    869       self._iterator = multi_device_iterator_ops.MultiDeviceIterator(\r\n--> 870           self._dataset, self._devices)\r\n    871 \r\n    872   def get_next(self, device, name=None):\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/data/ops/multi_device_iterator_ops.py in __init__(self, dataset, devices, max_buffer_size, prefetch_buffer_size, source_device)\r\n    292                                     self._experimental_slack)\r\n    293         if context.executing_eagerly():\r\n--> 294           self._device_iterators.append(dataset_ops.make_one_shot_iterator(ds))\r\n    295         else:\r\n    296           self._device_iterators.append(\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py in make_one_shot_iterator(dataset)\r\n   2479     return dataset._make_one_shot_iterator()  # pylint: disable=protected-access\r\n   2480   except AttributeError:\r\n-> 2481     return DatasetV1Adapter(dataset)._make_one_shot_iterator()  # pylint: disable=protected-access\r\n   2482 \r\n   2483 \r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/data/ops/dataset_ops.py in _make_one_shot_iterator(self)\r\n   2057   def _make_one_shot_iterator(self):  # pylint: disable=missing-docstring\r\n   2058     if context.executing_eagerly():\r\n-> 2059       return iterator_ops.OwnedIterator(self)\r\n   2060 \r\n   2061     _ensure_same_dataset_graph(self)\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py in __init__(self, dataset, components, element_spec)\r\n    592           context.context().device_spec.device_type != \"CPU\"):\r\n    593         with ops.device(\"/cpu:0\"):\r\n--> 594           self._create_iterator(dataset)\r\n    595       else:\r\n    596         self._create_iterator(dataset)\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/data/ops/iterator_ops.py in _create_iterator(self, dataset)\r\n    617               output_types=self._flat_output_types,\r\n    618               output_shapes=self._flat_output_shapes))\r\n--> 619       gen_dataset_ops.make_iterator(ds_variant, self._iterator_resource)\r\n    620       # Delete the resource when this object is deleted\r\n    621       self._resource_deleter = IteratorResourceDeleter(\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/gen_dataset_ops.py in make_iterator(dataset, iterator, name)\r\n   2703         pass  # Add nodes to the TensorFlow graph.\r\n   2704     except _core._NotOkStatusException as e:\r\n-> 2705       _ops.raise_from_not_ok_status(e, name)\r\n   2706   # Add nodes to the TensorFlow graph.\r\n   2707   _, _, _op, _outputs = _op_def_library._apply_op_helper(\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/framework/ops.py in raise_from_not_ok_status(e, name)\r\n   6604   message = e.message + (\" name: \" + name if name is not None else \"\")\r\n   6605   # pylint: disable=protected-access\r\n-> 6606   six.raise_from(core._status_to_exception(e.code, message), None)\r\n   6607   # pylint: enable=protected-access\r\n   6608 \r\n\r\n/usr/local/lib/python3.5/dist-packages/six.py in raise_from(value, from_value)\r\n\r\nNotFoundError: No registered 'Identity' OpKernel for 'TPU' devices compatible with node {{node Identity}}\r\n\t (OpKernel was found, but attributes didn't match) Requested Attributes: T=DT_HALF\r\n\t.  Registered:  device='XLA_GPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, ..., DT_HALF, DT_UINT32, DT_UINT64, DT_RESOURCE, DT_VARIANT]\r\n  device='XLA_CPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, ..., DT_HALF, DT_UINT32, DT_UINT64, DT_RESOURCE, DT_VARIANT]\r\n  device='XLA_TPU_JIT'; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_COMPLEX64, DT_INT64, DT_BOOL, DT_BFLOAT16, DT_UINT32, DT_UINT64, DT_RESOURCE, DT_VARIANT]\r\n  device='XLA_CPU'; T in [DT_UINT8, DT_QUINT8, DT_UINT16, DT_INT8, DT_QINT8, ..., DT_DOUBLE, DT_COMPLEX64, DT_COMPLEX128, DT_BOOL, DT_BFLOAT16]\r\n  device='TPU'; T in [DT_INT32, DT_UINT32, DT_BFLOAT16, DT_FLOAT, DT_DOUBLE, DT_BOOL, DT_COMPLEX64, DT_INT64, DT_UINT64]\r\n  device='TPU_SYSTEM'\r\n  device='GPU'; T in [DT_HALF]\r\n  device='GPU'; T in [DT_BFLOAT16]\r\n  device='GPU'; T in [DT_FLOAT]\r\n  device='GPU'; T in [DT_DOUBLE]\r\n  device='GPU'; T in [DT_INT64]\r\n  device='GPU'; T in [DT_UINT16]\r\n  device='GPU'; T in [DT_INT16]\r\n  device='GPU'; T in [DT_UINT8]\r\n  device='GPU'; T in [DT_INT8]\r\n  device='GPU'; T in [DT_COMPLEX64]\r\n  device='GPU'; T in [DT_COMPLEX128]\r\n  device='GPU'; T in [DT_VARIANT]\r\n  device='DEFAULT'; T in [DT_STRING]\r\n  device='DEFAULT'; T in [DT_VARIANT]\r\n  device='DEFAULT'; T in [DT_RESOURCE]\r\n  device='CPU'\r\n\r\n\t [[Identity]] [Op:MakeIterator]\r\n```\r\n\r\n", "comments": ["@maxima120 Can you please create a standalone code to reproduce the issue? You could use [colab](https://colab.sandbox.google.com/gist/jvishnuvardhan/9d7972363297f592f5a071af6afa885f/untitled814.ipynb) or any other approach to share a standalone code. Thanks!", "I promise to get to it in couple days. Thank you for quick response ", "there is any solution?", "Hi walidayech, did you run into the same issue? Do you have a reproduction? ", "> @maxima120 Can you please create a standalone code to reproduce the issue? You could use [colab](https://colab.sandbox.google.com/gist/jvishnuvardhan/9d7972363297f592f5a071af6afa885f/untitled814.ipynb) or any other approach to share a standalone code. Thanks!\r\n\r\n@maxima120 Any progress from your side? Thanks! ", "Closing for now. Please do re-open if you have a repro for the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36579\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36579\">No</a>\n"]}, {"number": 36578, "title": "Go: NewTensor & Value performance improvement", "body": "Considerable improvements in NewTensor & Value performance for non-String Tensors. \r\n\r\n```\r\nname                           old time/op    new time/op    delta\r\nTensor/New/[150528]int32-16      1.95ms \u00b1 1%    0.11ms \u00b114%   -94.12%  (p=0.000 n=8+7)\r\nTensor/New/[]float32-16          12.2ms \u00b1 1%     0.8ms \u00b166%   -93.68%  (p=0.000 n=7+8)\r\nTensor/New/[][]float32-16        14.0ms \u00b1 1%     1.2ms \u00b114%   -91.36%  (p=0.000 n=8+8)\r\nTensor/New/[][][]float32-16      13.9ms \u00b1 1%     1.3ms \u00b1 7%   -90.81%  (p=0.000 n=8+8)\r\nTensor/Value/[150528]int32-16     549\u00b5s \u00b1 5%      61\u00b5s \u00b1 2%   -88.83%  (p=0.000 n=8+8)\r\nTensor/Value/[]float32-16        11.9ms \u00b1 0%     0.5ms \u00b1 1%   -95.89%  (p=0.000 n=7+8)\r\nTensor/Value/[][]float32-16      14.9ms \u00b1 1%     0.5ms \u00b1 1%   -96.35%  (p=0.000 n=8+8)\r\nTensor/Value/[][][]float32-16    14.9ms \u00b1 1%     0.5ms \u00b1 2%   -96.33%  (p=0.000 n=8+8)\r\n\r\nname                           old alloc/op   new alloc/op   delta\r\nTensor/New/[150528]int32-16       606kB \u00b1 0%       0kB \u00b1 0%   -99.99%  (p=0.000 n=8+8)\r\nTensor/New/[]float32-16          4.01MB \u00b1 0%    0.00MB \u00b1 0%  -100.00%  (p=0.000 n=8+8)\r\nTensor/New/[][]float32-16        4.48MB \u00b1 0%    0.00MB \u00b1 0%  -100.00%  (p=0.000 n=8+8)\r\nTensor/New/[][][]float32-16      4.48MB \u00b1 0%    0.00MB \u00b1 0%  -100.00%  (p=0.000 n=8+8)\r\nTensor/Value/[150528]int32-16    1.21MB \u00b1 0%    0.61MB \u00b1 0%   -50.00%  (p=0.000 n=8+8)\r\nTensor/Value/[]float32-16        8.01MB \u00b1 0%    4.01MB \u00b1 0%   -50.00%  (p=0.000 n=8+8)\r\nTensor/Value/[][]float32-16      9.21MB \u00b1 0%    4.25MB \u00b1 0%   -53.82%  (p=0.000 n=8+8)\r\nTensor/Value/[][][]float32-16    9.23MB \u00b1 0%    4.25MB \u00b1 0%   -53.93%  (p=0.000 n=8+8)\r\n\r\nname                           old allocs/op  new allocs/op  delta\r\nTensor/New/[150528]int32-16        4.00 \u00b1 0%      3.00 \u00b1 0%   -25.00%  (p=0.000 n=8+8)\r\nTensor/New/[]float32-16            4.00 \u00b1 0%      3.00 \u00b1 0%   -25.00%  (p=0.000 n=8+8)\r\nTensor/New/[][]float32-16         20.0k \u00b1 0%      0.0k \u00b1 0%   -99.98%  (p=0.000 n=8+8)\r\nTensor/New/[][][]float32-16       20.0k \u00b1 0%      0.0k \u00b1 0%   -99.98%  (p=0.000 n=8+8)\r\nTensor/Value/[150528]int32-16      7.00 \u00b1 0%      2.00 \u00b1 0%   -71.43%  (p=0.000 n=8+8)\r\nTensor/Value/[]float32-16          7.00 \u00b1 0%      2.00 \u00b1 0%   -71.43%  (p=0.000 n=8+8)\r\nTensor/Value/[][]float32-16       40.0k \u00b1 0%      0.0k \u00b1 0%   -99.99%  (p=0.000 n=8+8)\r\nTensor/Value/[][][]float32-16     40.2k \u00b1 0%      0.0k \u00b1 0%   -99.99%  (p=0.000 n=8+8)\r\n```\r\nDiscussed in https://github.com/tensorflow/tensorflow/issues/36288. We avoid using binary.Write as this is both quite wordy and causes a large number of allocations with tensors of order 2 or above. What we do instead is just copy the memory directly when we can. Note since we're looking for native byte order for the machine copying memory is OK as it is in native byte order and Go primitive types are fundamentally the same as C primitive types as these are the machine's primitive types.", "comments": ["I've got a follow-up PR making similar improvements for string tensors. NewTensor and Value take less than a tenth of the time and cause 1,000,000 times fewer allocations. I've parked it here for now: https://github.com/philpearl/tensorflow/pull/1\r\n\r\nI feel I should note that I took interest in this because we encountered a real problem serving models with Go. Manipulating the Tensors caused so many allocations that the Go GC could not keep up and the memory usage exploded. We were very lucky it didn't cause a major outage.", "This was rolled back due to MemorySanitizer complaining about unsafe pointer arithmetic in TestSessionRunNeg from session_test.go. I haven't looked closely at it yet.", "Seems like it hit one of the throws in this function:\r\nhttps://github.com/golang/go/blob/master/src/runtime/checkptr.go#L22", "I'm on vacation for another week. I'll take a look when I get back.\n\nOn Fri, 21 Feb 2020, 14:01 Jonathan Hseu, <notifications@github.com> wrote:\n\n> Seems like it hit one of the throws in this function:\n> https://github.com/golang/go/blob/master/src/runtime/checkptr.go#L22\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/36578?email_source=notifications&email_token=AADPPXG5OSDBTTQVIDFDYLTREBFKPA5CNFSM4KR3XF62YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEMUHVQA#issuecomment-589855424>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AADPPXCNKWMADMGZ5JFBEFTREBFKPANCNFSM4KR3XF6Q>\n> .\n>\n", "It looks like the new checkptr stuff in Go 1.14 (which is enabled with -race or -msan) doesn't cope with pointer arithmetic if the pointer is obtained from a slice via reflection. I can just turn checkptr off in the failing routine with a go:nocheckptr pragma. But I'll see if I can find a neater way.", "Have fixed in https://github.com/tensorflow/tensorflow/pull/37190.\r\n\r\nJust FYI I'm developing on the v2.1 tag as the master branch doesn't build straightforwardly. Would it be possible to commit a proper set of generated files so `go build` and `go test` just work out of the box?", "Yeah, I proposed that here:\r\nhttps://github.com/tensorflow/tensorflow/pull/36523\r\n\r\nBut it ended up being a bit controversial. The Go team suggested that it often causes issues due to conflicts between the generated protobufs from bazel and the checked-in versions. I don't have a great solution for now besides asking users to run `go generate` manually.", "Hi, I wrote the checkptr feature. I found this issue searching GitHub for instances of \"go:nocheckptr\".\r\n\r\ncheckptr isn't expected to have false positives, but the pointer safety rules are somewhat subtle, so at times how to write code to satisfy it might be non-obvious. If you need help with this, feel free to add me as a reviewer.\r\n\r\nIn commit fa5ff875a5bb7eec732db332e4143340942ff855, there were two significant issues:\r\n\r\n1. It's not safe to allocate variables of type `reflect.SliceHeader`. That type is only allowed to be used as a pointer to an actual slice-typed variable. You'd probably benefit from adding a helper function like:\r\n\r\n        func setSlice(h *reflect.SliceHeader, ptr unsafe.Pointer, len, cap int) {\r\n            h.Data = uintptr(ptr)\r\n            h.Len = len\r\n            h.Cap = cap\r\n        }\r\n\r\n   and using that everywhere you need to unsafely mutate a slice.\r\n\r\n2. The result value from reflect.Value.Pointer must be immediately converted to unsafe.Pointer, before converting back again to uintptr for any pointer arithmetic. (See https://github.com/google/go-cmp/issues/167#issuecomment-546093202 for explanation why.)\r\n\r\n   E.g., in setSliceInSlice, it needed to be `unsafe.Pointer(uintptr(unsafe.Pointer(slice.Pointer())) + (uintptr(index) * sliceSize))`.", "Thanks @mdempsky! That point about casting uintptr returns is particularly subtle to say the least."]}, {"number": 36577, "title": "TensorFlow2.0 keras.DenseFeatures can not deal with sparseTensor", "body": "Hello, I find tf.keras.layers.DenseFeatures can not deal with SparseTensor, when using tensorflow 1.15: tf.feature_column.input_layer  without this problem\r\n\r\nhere is my problem code\r\n```\r\nfea['hisList'] = tf.io.VarLenFeature(tf.int64)\r\ntmp = tf.feature_column.categorical_column_with_hash_bucket('hisList', 1000, dtype=tf.string)\r\nemb = tf.feature_column.embedding_column(tmp , 12)\r\nfeature_layer = tf.keras.layers.DenseFeatures([emb])\r\n```\r\n\r\nwhen without using tf.keras.Input\r\n```\r\n    model = tf.keras.Sequential([\r\n      feature_layer,\r\n      tf.keras.layers.Dense(64, activation='relu'),\r\n      tf.keras.layers.Dense(128, activation='relu'),\r\n      tf.keras.layers.Dense(1, activation='sigmoid')\r\n    ])\r\n```\r\nValueError: All SparseTensor and RaggedTensor inputs must be explicitly declared using a keras.Input() with sparse=True or ragged=True. We found an undeclared input SparseTensor\r\n\r\nwhen using tf.keras.Input\r\n```\r\n    Input = tf.keras.Input(shape=(32, ),sparse=True)\r\n    model = tf.keras.Sequential([\r\n      Input\r\n      feature_layer,\r\n      tf.keras.layers.Dense(64, activation='relu'),\r\n      tf.keras.layers.Dense(128, activation='relu'),\r\n      tf.keras.layers.Dense(1, activation='sigmoid')\r\n    ])\r\n```\r\nValueError: ('We expected a dictionary here. Instead we got: ', <tensorflow.python.framework.sparse_tensor.SparseTensor object at 0x00000210C00CCCF8>)", "comments": ["@caizd1994, Thanks for reporting this issue. \r\nCould you provide the complete standalone code to analyze the reported issue. Thanks!", "@caizd1994, Please share the code snippet to replicate the issue. Thanks", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 36576, "title": "Windows 10 building from source: cl.exe failed: error executing command...", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 64 bit\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: r2.0\r\n- Python version: 3.7.6 (tags/v3.7.6:43364a7ae0, Dec 19 2019, 00:42:30) [MSC v.1916 64 bit (AMD64)]\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): 0.26.1\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: release 10.0, V10.0.130 / cudnn-10.0-windows10-x64-v7.6.5.32, Note that I am trying to compile without cuda support.\r\n- GPU model and memory: GTX 1060 6GB\r\n\r\n\r\n\r\n**Describe the problem**\r\nI am trying to compile a C++ library on this current machine, I will later import the lib on a work machine.\r\nI followed the guidelines on: https://www.tensorflow.org/install/source_windows\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nMore specifically:\r\n1: do the pip3 installs.\r\n2: download bazel 0.26.1 as an .exe, put it in my path\r\n3: install msys2, add to path and run: pacman -S git patch unzip\r\n4: *I did NOT* download visual studio 2019 since it says on the tested build configs that MSVC 2017 (which I have) should be used for r2.0\r\n5: git clone and git checkout r2.0\r\n6: python ./configure using all default and n to all other\r\n7: running bazel build //tensorflow:tensorflow_dll_import_lib as stated on: https://github.com/tensorflow/tensorflow/pull/24963\r\n\r\nAfter about an hour I got the error posted further down.\r\n\r\n**Any other info / logs**\r\n```\r\ntensorflow/core/kernels/unique_op.cc(240): note: see reference to class template instantiation 'tensorflow::UniqueOp<bool,tensorflow::int32>' being compiled\r\nERROR: C:/users/jesper/documents/tensorflow/tensorflow/core/grappler/optimizers/data/BUILD:712:1: C++ compilation of rule '//tensorflow/core/grappler/optimizers/data:rebatch' failed (Exit 2): cl.exe failed: error executing command\r\n  cd C:/users/jesper/_bazel_jesper/mqwe2qxk/execroot/org_tensorflow\r\n  SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\INCLUDE;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\include\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\winrt;\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\amd64;C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\VCPackages;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\IDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\Tools;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Team Tools\\Performance Tools\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Team Tools\\Performance Tools;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x86;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.6.1 Tools\\x64\\;;C:\\Windows\\system32\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=C:/Users/Jesper/AppData/Local/Programs/Python/Python37/python.exe\r\n    SET PYTHON_LIB_PATH=C:/Users/Jesper/AppData/Local/Programs/Python/Python37/lib/site-packages\r\n    SET RUNFILES_MANIFEST_ONLY=1\r\n    SET TEMP=C:\\Users\\Jesper\\AppData\\Local\\Temp\r\n    SET TF2_BEHAVIOR=1\r\n    SET TF_CONFIGURE_IOS=0\r\n    SET TMP=C:\\Users\\Jesper\\AppData\\Local\\Temp\r\n  C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/amd64/cl.exe /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0601 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /bigobj /Zm500 /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/bin /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/local_config_sycl /Ibazel-out/x64_windows-opt/bin/external/local_config_sycl /Iexternal/nsync /Ibazel-out/x64_windows-opt/bin/external/nsync /Iexternal/gif_archive /Ibazel-out/x64_windows-opt/bin/external/gif_archive /Iexternal/jpeg /Ibazel-out/x64_windows-opt/bin/external/jpeg /Iexternal/com_google_protobuf /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf /Iexternal/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/bin/external/com_googlesource_code_re2 /Iexternal/farmhash_archive /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive /Iexternal/fft2d /Ibazel-out/x64_windows-opt/bin/external/fft2d /Iexternal/highwayhash /Ibazel-out/x64_windows-opt/bin/external/highwayhash /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/snappy /Ibazel-out/x64_windows-opt/bin/external/snappy /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/nsync/public /Ibazel-out/x64_windows-opt/bin/external/nsync/public /Iexternal/gif_archive /Ibazel-out/x64_windows-opt/bin/external/gif_archive /Iexternal/gif_archive/windows /Ibazel-out/x64_windows-opt/bin/external/gif_archive/windows /Iexternal/com_google_protobuf/src /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf/src /Iexternal/farmhash_archive/src /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive/src /Iexternal/zlib_archive /Ibazel-out/x64_windows-opt/bin/external/zlib_archive /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /D__CLANG_SUPPORT_DYN_ANNOTATION__ /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /DEIGEN_HAS_TYPE_TRAITS=0 /DTF_USE_SNAPPY /showIncludes /MD /O2 /Oy- /DNDEBUG /wd4117 -D__DATE__=\"redacted\" -D__TIMESTAMP__=\"redacted\" -D__TIME__=\"redacted\" /Gy /Gw -w -w -DWIN32_LEAN_AND_MEAN -DNOGDI /Fobazel-out/x64_windows-opt/bin/tensorflow/core/grappler/optimizers/data/_objs/rebatch/rebatch.obj /c tensorflow/core/grappler/optimizers/data/rebatch.cc\r\nExecution platform: @bazel_tools//platforms:host_platform\r\ntensorflow/core/grappler/optimizers/data/rebatch.cc(66): fatal error C1001: An internal error has occurred in the compiler.\r\n(compiler file 'msc1.cpp', line 1468)\r\n To work around this problem, try simplifying or changing the program near the locations listed above.\r\nPlease choose the Technical Support command on the Visual C++\r\n Help menu, or open the Technical Support help file for more information\r\nInternal Compiler Error in C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\bin\\amd64\\cl.exe.  You will be prompted to send an error report to Microsoft later.\r\nINTERNAL COMPILER ERROR in 'C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\bin\\amd64\\cl.exe'\r\n    Please choose the Technical Support command on the Visual C++\r\n    Help menu, or open the Technical Support help file for more information\r\nTarget //tensorflow:tensorflow_dll_import_lib failed to build\r\nINFO: Elapsed time: 3372.778s, Critical Path: 1297.23s\r\nINFO: 2289 processes: 2289 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n", "comments": ["tf version: 2.0.0\r\nbazel version: 0.26.1\r\nvs version: 2015,2017,2019(all tried)\r\nconfigure: cuda yes, another no\r\nbuild cmd: bazel build --config=opt --config=v2 //tensorflow:libtensorflow_cc.so\r\n`same error as above`.\r\n\r\n", "@ihuale https://github.com/guikarist/tensorflow-windows-build-script this script works if u follow the instructions fully, however its not the latest version of tf.", "@JesperLindberg \r\n\r\nI can see Microsoft Visual Studio 14.0 in the error log. Can you please cross check you have installed MSVC 2017 . Thanks!", "@JesperLindberg thanks, but i use that script before, now i need tf>=2.0", "@ravikyram I uninstalled everything that had to do with VS and installed VS 2017 again and it built successfully.\r\n@ihuale I will try build 2.1 and use it in VS 2017, will get back to you if I find any success.", "@JesperLindberg ok, thanks\uff0clooking forward to your good news", "@ihuale I switched to libtoch (pytorch) 1.4 instead. At least it windows supported and cmake makes it much easier than bazel.", "@JesperLindberg Sorry for replying so late, i just found one solution according this [solution](https://github.com/tensorflow/tensorflow/issues/31520#issuecomment-524584978 \"issues\"),  edit file like that, and use vs2019, bazel 0.24.1, cuda 10.1, at last, i build tensorflow_cc.dll(tensorflow 2.0.0 ) successed!\r\nbut there still are some error when i use  tensorflow_cc.lib, i got some lnk 2001 error, and then , follow this [ add symbol to def_file_filter.py.tpl](https://github.com/tensorflow/tensorflow/issues/30552#issuecomment-512348156 \"issues\"), i fixed some lnk 2001 error.\r\nwhen i use savedmodel api on tensorflow_cc.dll, i just found `LoadSavedModel` dose not have `TF_EXPORT` macro, so add it.\r\nThe above steps at least worked for me...", "@ihuale Thanks, however I am locked to vs 2017 since I am on a work computer with no admin rights.", "> @ihuale Thanks, however I am locked to vs 2017 since I am on a work computer with no admin rights.\r\n\r\ni just tried vs2015, vs2017, vs2019 one by one, only vs2019 successed...", "@ihuale Oh man.. Well I got libtorch working without any problems. Also their syntax is very close to their python syntax so I guess I will stick with pytorch. Thanks for the help though."]}, {"number": 36575, "title": "[DOCS] Building Tensorflow with Select Ops Update", "body": "The Android AAR `tensorflow-lite-with-select-tf-ops` target with select TensorFlow ops has been removed. Now `tensorflow-lite-select-tf-ops` should used. Updating the documentation to match what's in master branch.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F36575) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F36575) for more info**.\n\n<!-- ok -->", "I've just taken a deeper look at this, and considering [this note](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/java/BUILD#L36), maybe a longer update is required, instructing users to \"also include the core tensorflow-lite runtime\" ", "@sdurandeu Can you please resolve conflicts? Thanks!", "Thanks for flagging, but looks like the docs have been updated separate to address this."]}, {"number": 36574, "title": "TensorFlow 2.0 - ValueError: tf.function-decorated", "body": "Hello, I have a code (for MNIST dataset) in which I am doing the following steps:\r\n\r\n1. Train model\r\n1. Prune model (using \"tensorflow_model_optimization\" for say p%)\r\n1. Create a mask of pruned model, so that the sparsity is maintained in subsequent steps\r\n1. Reset weights of non-pruned model to random initialized weights when model was initialized\r\n\r\nI do the following steps iteratively 'n' times.\r\n\r\nThe code can be found in:\r\nhttps://github.com/arjun-majumdar/tensorflow_codes/blob/master/Recreating_Error.ipynb\r\n\r\n\r\nFor retraining a pruned model, I use 'GradientTape' along with mask. Now, the first time the model is trained using *train_one_step()* and *test_step()* functions which are @tf.function annotated functions, things work fine. But when I try to use them again (in cell 76 of Jupyter notebook), it gives me the error:\r\n\r\n> ---------------------------------------------------------------------------\r\n> ValueError                                Traceback (most recent call last)\r\n> <ipython-input-76-9827a84843f1> in <module>\r\n>      13     for x, y in train_dataset:\r\n>      14         # train_step(x, y)\r\n> ---> 15         train_one_step(model_gt_stripped, mask_model_stripped, optimizer, x, y)\r\n>      16 \r\n>      17     for x_t, y_t in test_dataset:\r\n> \r\n> ~/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n>     455 \r\n>     456     tracing_count = self._get_tracing_count()\r\n> --> 457     result = self._call(*args, **kwds)\r\n>     458     if tracing_count == self._get_tracing_count():\r\n>     459       self._call_counter.called_without_tracing()\r\n> \r\n> ~/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in _call(self, *args, **kwds)\r\n>     485       # In this case we have created variables on the first call, so we run the\r\n>     486       # defunned version which is guaranteed to never create variables.\r\n> --> 487       return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n>     488     elif self._stateful_fn is not None:\r\n>     489       # Release the lock early so that multiple threads can perform the call\r\n> \r\n> ~/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in __call__(self, *args, **kwargs)\r\n>    1820   def __call__(self, *args, **kwargs):\r\n>    1821     \"\"\"Calls a graph function specialized to the inputs.\"\"\"\r\n> -> 1822     graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n>    1823     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n>    1824 \r\n> \r\n> ~/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n>    2148         graph_function = self._function_cache.primary.get(cache_key, None)\r\n>    2149         if graph_function is None:\r\n> -> 2150           graph_function = self._create_graph_function(args, kwargs)\r\n>    2151           self._function_cache.primary[cache_key] = graph_function\r\n>    2152         return graph_function, args, kwargs\r\n> \r\n> ~/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n>    2039             arg_names=arg_names,\r\n>    2040             override_flat_arg_shapes=override_flat_arg_shapes,\r\n> -> 2041             capture_by_value=self._capture_by_value),\r\n>    2042         self._function_attributes,\r\n>    2043         # Tell the ConcreteFunction to clean up its graph once it goes out of\r\n> \r\n> ~/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n>     913                                           converted_func)\r\n>     914 \r\n> --> 915       func_outputs = python_func(*func_args, **func_kwargs)\r\n>     916 \r\n>     917       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n> \r\n> ~/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in wrapped_fn(*args, **kwds)\r\n>     356         # __wrapped__ allows AutoGraph to swap in a converted function. We give\r\n>     357         # the function a weak reference to itself to avoid a reference cycle.\r\n> --> 358         return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n>     359     weak_wrapped_fn = weakref.ref(wrapped_fn)\r\n>     360 \r\n> \r\n> ~/.local/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py in wrapper(*args, **kwargs)\r\n>     903           except Exception as e:  # pylint:disable=broad-except\r\n>     904             if hasattr(e, \"ag_error_metadata\"):\r\n> --> 905               raise e.ag_error_metadata.to_exception(e)\r\n>     906             else:\r\n>     907               raise\r\n> \r\n> ValueError: in converted code:\r\n> \r\n>     <ipython-input-44-d0ca499a4063>:29 train_one_step  *\r\n>         optimizer.apply_gradients(zip(grad_mask_mul, model.trainable_variables))\r\n>     /home/majumdar/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:435 apply_gradients\r\n>         self._create_slots(var_list)\r\n>     /home/majumdar/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/adam.py:146 _create_slots\r\n>         self.add_slot(var, 'm')\r\n>     /home/majumdar/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py:587 add_slot\r\n>         initial_value=initial_value)\r\n>     /home/majumdar/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py:260 __call__\r\n>         return cls._variable_v2_call(*args, **kwargs)\r\n>     /home/majumdar/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py:254 _variable_v2_call\r\n>         shape=shape)\r\n>     /home/majumdar/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py:65 getter\r\n>         return captured_getter(captured_previous, **kwargs)\r\n>     /home/majumdar/.local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py:413 invalid_creator_scope\r\n>         \"tf.function-decorated function tried to create \"\r\n> \r\n>     ValueError: tf.function-decorated function tried to create variables on non-first call.\r\n> \r\n> \r\n\r\n\r\nThe only way of avoiding this \"ValueError\" is by rerunning the *train_one_step()* and *test_step()* @tf.function annotated functions!\r\n\r\nWhy is this happening?\r\n\r\nThanks!", "comments": ["@arjun-majumdar ,\r\nCan you please take a look at the link of[ Stack-overflow](https://stackoverflow.com/questions/58352326/running-the-tensorflow-2-0-code-gives-valueerror-tf-function-decorated-functio) and let me know if it helps.Thanks!", "Going through the link and the related tutorial. ", "Hello, I have the following issue which doesn't make sense. The code that I have is as follows:\r\n\r\n```\r\n@tf.function\r\ndef train_step(model, mask_model, optimizer, x, y):\r\n    with tf.GradientTape() as tape:\r\n        y_pred = model(x)\r\n        loss = loss_fn(y, y_pred)\r\n    \r\n    grads = tape.gradient(loss, model.trainable_variables)\r\n    \r\n    optimizer.apply_gradients(zip(grads, model.trainable_variables))\r\n    \r\n    train_loss(loss)\r\n    train_accuracy(y, y_pred)\r\n    \r\n    return None\r\n\r\n\r\n@tf.function\r\ndef test_step(model, optimizer, data, labels):\r\n    \"\"\"\r\n    Function to test model performance\r\n    on testing dataset\r\n    \"\"\"\r\n    \r\n    predictions = model(data)\r\n    t_loss = loss_fn(labels, predictions)\r\n\r\n    test_loss(t_loss)\r\n    test_accuracy(labels, predictions)\r\n\r\n    return None\r\n\r\n\r\n# User input parameters for Early Stopping in manual implementation-\r\nminimum_delta = 0.001\r\npatience = 3\r\n\r\nbest_val_loss = 1\r\nloc_patience = 0\r\n\r\n\r\n# Initialize a neural network model-\r\nmodel_gt = pruned_nn(pruning_params_unpruned)\r\n\r\n# Strip model of pruning layers-\r\nmodel_gt_stripped = sparsity.strip_pruning(model_gt)\r\n\r\nfor i in range(1, 6):\r\n    \r\n    print(\"\\n\\n\\nOuter loop: {0}\\n\\n\".format(i))\r\n    \r\n    # Initialize parameters for Early Stopping manual implementation-\r\n    best_val_loss = 1\r\n    loc_patience = 0\r\n    \r\n    for epoch in range(num_epochs):\r\n    \r\n        if loc_patience >= patience:\r\n            print(\"\\n'EarlyStopping' called!\\n\")\r\n            break\r\n        \r\n        # Reset the metrics at the start of the next epoch\r\n        train_loss.reset_states()\r\n        train_accuracy.reset_states()\r\n        test_loss.reset_states()\r\n        test_accuracy.reset_states()\r\n        \r\n        '''\r\n        # Initialize 'grad_mask_mul' list-\r\n        grad_mask_mul = []\r\n    \r\n        # Initialize all values to one-\r\n        for wts in mask_model_stripped.trainable_weights:\r\n            grad_mask_mul.append(wts.assign(tf.ones_like(input = wts,dtype = tf.float32)))\r\n    \r\n        # Convert from Python list to tf.Tensor-\r\n        grad_mask_mul = tf.convert_to_tensor(grad_mask_mul, dtype=tf.float32)\r\n    \r\n        print(\"type(grad_mask_mul): {0}\".format(type(grad_mask_mul)))\r\n        '''\r\n    \r\n        for x, y in train_dataset:\r\n            train_step(model_gt_stripped, mask_model_stripped, optimizer, x, y)\r\n            # train_one_step(model_gt_stripped, mask_model, optimizer, x, y, grad_mask_mul)\r\n\r\n\r\n        for x_t, y_t in test_dataset:\r\n            # test_step(x_t, y_t)\r\n            test_step(model_gt_stripped, optimizer, x_t, y_t)\r\n\r\n        template = 'Epoch {0}, Loss: {1:.4f}, Accuracy: {2:.4f}, Test Loss: {3:.4f}, Test Accuracy: {4:4f}'        \r\n        \r\n        print(template.format(epoch + 1, \r\n                              train_loss.result(), train_accuracy.result()*100,\r\n                              test_loss.result(), test_accuracy.result()*100))\r\n    \r\n        # Count number of non-zero parameters in each layer and in total-\r\n        # print(\"layer-wise manner model, number of nonzero parameters in each layer are: \\n\")\r\n\r\n        model_sum_params = 0\r\n    \r\n        for layer in model_gt_stripped.trainable_weights:\r\n            # print(tf.math.count_nonzero(layer, axis = None).numpy())\r\n            model_sum_params += tf.math.count_nonzero(layer, axis = None).numpy()\r\n    \r\n        print(\"Total number of trainable parameters = {0}\\n\".format(model_sum_params))\r\n\r\n    \r\n        # Code for manual Early Stopping:\r\n        if np.abs(test_loss.result() < best_val_loss) >= minimum_delta:\r\n            # update 'best_val_loss' variable to lowest loss encountered so far-\r\n            best_val_loss = test_loss.result()\r\n        \r\n            # reset 'loc_patience' variable-\r\n            loc_patience = 0\r\n        \r\n        else:  # there is no improvement in monitored metric 'val_loss'\r\n            loc_patience += 1  # number of epochs without any improvement\r\n\r\n```\r\n\r\nIf, I re-execute the **for i in range(1, 6):** block of code again, why do I get the \"_ValueError: tf.function-decorated function tried to create variables on non-first call._\" ?\r\n\r\nWhat I am not getting is that \"train_step()\" and \"test_step()\" \"tf.function\" annotated functions are already traced and the AutoGraphs (or, tf.Graph object) are created for it. Also, the parameters being provided to these functions are not changing. Is the \"ValueError\" happening due to the line:\r\n\r\n_grads = tape.gradient(loss, model.trainable_variables)_ within \"train_step()\" function\r\n\r\nand\r\n\r\n_predictions = model(data)_ within \"test_step()\" function\r\n\r\nSince, these are the only two lines within the two functions which are creating a variable, but then again, the gradients with respect to the parameters and the model's predictions will always be made within the \"tf.function\" annotated functions. You cannot pass such values as parameters to the function(s).\r\n\r\n\r\nThanks\r\n\r\n    ", "@arjun-majumdar \r\nplease provide us with simple indented stand alone code with all dependencies, for us to replicate it in our environment and analyse the issue faced by you.\r\nplease find the [gist](https://colab.sandbox.google.com/gist/Saduf2019/34097314dfd69412c30f2328cdcffb8c/36574.ipynb) of the code shared by you and error faced.", "https://github.com/arjun-majumdar/tensorflow_codes/blob/master/Recreating_Error.ipynb", "@arjun-majumdar have you seen this related issue #27120 ?\r\n\r\n[This comment](https://github.com/tensorflow/tensorflow/issues/27120#issuecomment-540071844) might help you. Try creating a wrapper function for your train_one_step() function and then call separately when you train your different models.", "@nikitamaia Let me have a look and get back to you. Thanks!", "Hi @arjun-majumdar were you able to get your code working by creating a wrapper function?", "Hello @nikitamaia the TF annotated funtion after wrapping function works, however, the performance benefits gained by '@tf.function' annotation is lost.\r\n\r\nAlso, why should the graph generated be retraced if the neural network architecture isn't changing and/or the data type of the tensors are also not changing.\r\n", "Sorry for the late response here. Wanted to provide a quick update that this does seem to be a bug. I know the workaround of wrapping the function is not ideal, but I can update this thread when there's progress on this. ", "@nikitamaia Thanks for the reply. I will be happy to receive an update if there is a fix/solution found for this bug.", "The [Better Performance With tf.function guide ](https://www.tensorflow.org/guide/function#creating_tfvariables)has now been updated to provide more detail about this error and about using using tf.variables with multiple Keras models or optimizers. Closing this issue now since there is a workaround provided in the docs.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36574\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36574\">No</a>\n", "@nikitamaia I'm afraid that isn't the workround, it's just the rule, not fitting the user's demand"]}, {"number": 36573, "title": "Fix typo: obejct -> object", "body": "Fix simple typo", "comments": ["Closing due to #34985"]}, {"number": 36572, "title": "add documentation for Discrepancy between keras.layers.Reshape and tf.keras.layers.Reshape", "body": "resolves #36428 ", "comments": ["I think this change is needed, so thank you for adding the documentation.\r\n\r\nCould you add a note that clarifies that the behavior deviates from Keras when using shape inference?", "I have added that", "Can you review this, please? @rthadur "]}, {"number": 36571, "title": "Change \u201cjobs\u201d to \u201croles\u201d to avoid confusion", "body": "Workers and parameter servers should be something like \u201croles\u201d instead of \u201cjobs\u201d to avoid confusion.", "comments": []}, {"number": 36570, "title": "Small docstring fix in description of keras predict", "body": "There is no gradient update in predict.", "comments": []}, {"number": 36569, "title": "gcc4.9.0 build error:  insn does not satisfy its constraints", "body": "HI :\r\n    I want to use avx512 to compile tensorflow, so get update gcc from 4.8.5 to 4.9.0, tensorflow is 1.14.\r\n\r\nbazel command:\r\n```\r\nbazel build tensorflow:libtensorflow_cc.so -c opt --copt=-march=native --copt=-mfpmath=both  --copt=-mfma --copt=-mavx --copt=-mavx2 --copt=-mavx512f\r\n```\r\n\r\nerror:\r\n```\r\nexternal/fft2d/fft/fftsg.c: In function 'cftf162':\r\nexternal/fft2d/fft/fftsg.c:3028:1: error: insn does not satisfy its constraints:\r\n }\r\n ^\r\n(insn 488 487 335 2 (set (reg:DF 28 xmm7 [orig:225 D.7431 ] [225])\r\n        (plus:DF (reg:DF 28 xmm7 [orig:225 D.7431 ] [225])\r\n            (reg:DF 55 xmm18 [orig:225 D.7431 ] [225]))) external/fft2d/fft/fftsg.c:2937 764 {*fop_df_comm_mixed}\r\n     (nil))\r\nexternal/fft2d/fft/fftsg.c:3028:1: internal compiler error: in copyprop_hardreg_forward_1, at regcprop.c:775\r\n0x82e7d8 _fatal_insn(char const*, rtx_def const*, char const*, int, char const*)\r\n\t../../gcc/rtl-error.c:109\r\n0x82e7ff _fatal_insn_not_found(rtx_def const*, char const*, int, char const*)\r\n\t../../gcc/rtl-error.c:120\r\n0x8098a1 copyprop_hardreg_forward_1\r\n\t../../gcc/regcprop.c:775\r\n0x8098a1 copyprop_hardreg_forward\r\n\t../../gcc/regcprop.c:1110\r\n0x8098a1 execute\r\n\t../../gcc/regcprop.c:1283\r\nPlease submit a full bug report,\r\nwith preprocessed source if appropriate.\r\nPlease include the complete backtrace with any bug report.\r\nSee <http://gcc.gnu.org/bugs.html> for instructions.\r\nTarget //tensorflow:libtensorflow_cc.so failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\n```\r\n\r\nit seemd that fftsg.c may be has error, but when I compile fftsg.c only, there was no error.\r\n```\r\ngcc fftsg.c -mavx -mavx2 -mavx512f -march=native -mfma -lm //it's ok\r\n```", "comments": ["I use gcc-7.3.0 and build succeed. so I think, this is a gcc bug.", "@haolujun, Glad that its resolved. Tensorflow tested build configuration doc says Tensorflow supports GCC 7.3.1. Please take a look at doc [here](https://www.tensorflow.org/install/source#tested_build_configurations). Thanks", "@haolujun, Closing since its resolved. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36569\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36569\">No</a>\n"]}, {"number": 36568, "title": "[CI] PR merging and CI checks are not completed in time.", "body": "> This template is for miscellaneous issues not covered by the other issue categories.\r\n>\r\n> For questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n>\r\n> If you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n> \r\n> For high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n> \r\n> \r\n\r\n\r\nThis issue is not on bugs of Tensorflow. So, I chose the \"Issue: Other Issues\" category. I want to talk about on (1) the merging time of the PR and (2) the execution time of the CI checks (3) the build task cost of CI facilities in order to provide the below goals. \r\n- Reducing the waiting time of the Tensorflow contributors\r\n- Helping the reviewers in order that they can concentrate on the productive reviews on submitted PRs\r\n\r\nI summarized three cases among the lots of working PRs as follows. \r\n\r\n- (1) PR https://github.com/tensorflow/tensorflow/pull/36523: About the merging time\r\n   - When the reviewer **frankchn** of two reviewers approved the PR, The CI checks work. Then, all checks are passed. It seems that the PR is still not merged due to the 1 pending reviewer (**gunan**). In this case, what are the criteria to merge this PR as a final step?\r\n   - Screenshot:\r\n      ![image](https://user-images.githubusercontent.com/82404/74029403-f7b3f980-49ef-11ea-81cc-c57e2673b4e2.png)\r\n\r\n- (2) PR https://github.com/tensorflow/tensorflow/pull/33524 : About the execution cost of CI checks\r\n   - It's weird. When **omalleyt12** approved the PR 33524, the three checks are still keeping the \"Waiting for status ....\" after 2hour. Why do not CI checks start a task? Does the CI system require 2hour+ to check the PR status?\r\n      - Ubuntu CPU Expected \u2014 Waiting for status to be reported  Required\r\n      - Ubuntu Sanity Expected \u2014 Waiting for status to be reported Required\r\n      - import/copybara Expected \u2014 Waiting for status to be reported\r\n   - Screenshot: \r\n      ![image](https://user-images.githubusercontent.com/82404/74030714-1071de80-49f3-11ea-9861-415988076e32.png)\r\n\r\n- (3) PR https://github.com/tensorflow/tensorflow/pull/36526: About CI cost for Tensorflow build task\r\n   - It seems that the build cost of Tensorflow is too big by introducing JAVA-based Bazel. Why Tensorflow community still not use Cmake (or Meson) instead of Bazel? Is a reason is to be used for the Bazel-based Android software platform by default? When CI checks run the build test, What is the CI/CD software to run the Baze-based build scripts (e.g., Windows, Mac, Ubuntu)? Is this Kbuilder?\r\n   - Screenshot:\r\n   ![image](https://user-images.githubusercontent.com/82404/74078873-24f5bb80-4a73-11ea-8858-11fb1e9670a2.png)\r\n\r\n\r\nI want someone to tell me on a reason and the CI/CI direction of the Tensorflow community in case of (1) and (2) above.\r\n\r\nAnd, what is the CI software used to run [scripts](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/ci_build/presubmit) if the submitted PRs are correct or not?  For example, Hudson, Jenkins, Travis-CI, Circle-CI, QuickBuild, SWARM-CI, Bamboo, Buildbot, Continuum, Cruise Control, easyCIS, FinalBuilder, Mojo, Gump, Parabuild, Pulse, Sin, Teamcity, Team Foundation, and Zed.\r\n\r\n", "comments": ["#36527 ", "As mentioned in the other issue, this is not the place to discuss this and in any case this won't change."]}, {"number": 36567, "title": "Corrected docstring for tf.signal.frame", "body": "Corrected docstring for tf.signal.frame.\r\n\r\nIssue opened here: https://github.com/tensorflow/tensorflow/issues/36547", "comments": ["@jmsmdy Can you please check alextp's comments and keep us posted? Thanks!", "> @jmsmdy Can you please check alextp's comments and keep us posted? Thanks!\r\n\r\nJust added a new commit which converted the python example into a doctest. Let me know if I've done this correctly."]}, {"number": 36566, "title": "Issue", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: Latest as of 2/7/2020\r\n- Python version: 3.7.4\r\n- Installed using virtualenv? pip? conda?: Tried with pip did not work tried with virtualenv did not work\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source):NA\r\n- CUDA/cuDNN version:nA\r\n- GPU model and memory: Rtx 1070 16 Gig of ram\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\npip install virtualenv \r\npip3 install --user --upgrade tensorflow\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\r\nERROR: No matching distribution found for tensorflow", "comments": ["@KDDaddy01,\r\nMay I know which operating system you are using?\r\n\r\nCould you please try the below commands and let us know if it works? Thanks! \r\n```\r\npip3 install --upgrade pip\r\npip3 install tensorflow\r\n```", "@KDDaddy01,\r\nAny updates regarding this issue? Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36566\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/36566\">No</a>\n"]}, {"number": 36565, "title": "TFv1.15.0 run tf_cnn_benchmarks.py bug", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": []}, {"number": 36564, "title": "TFv1.15.0 run tf_cnn_benchmarks.py bug", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": []}, {"number": 36563, "title": "TFv1.15.0 run tf_cnn_benchmarks.py bug", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": []}, {"number": 36562, "title": "TFv1.15.0 run tf_cnn_benchmarks.py bug", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": []}, {"number": 36561, "title": "tfds.load() gives ConnectionResetError", "body": "I am running tensorflow 2.0.0 (python 3.7.4) on a conda virtual environment on Mac. I am trying to get the IMDb dataset through the following command:\r\n\r\n`import tensorflow_datasets as tfds\r\n\r\ntfds.load('imdb_reviews/subwords8k', split=(tfds.Split.TRAIN, tfds.Split.TEST), with_info = True, as_supervised = True)`\r\n\r\nto which I am getting the following error:\r\n\r\n> ConnectionError: ('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer'))\r\n\r\nNo support is available on stackoverflow or any other programming community site.", "comments": ["@anas0001, \r\nLooks like the error is not related to TensorFlow. I was able to run the above code without any issues. Please check the Gist [here](https://colab.sandbox.google.com/gist/amahendrakar/d12d905b7e466652551dea6bad15dc84/36561.ipynb).\r\n\r\nRegarding the connection error, could you please take a look at [this](https://stackoverflow.com/questions/38853972/python-client-error-connection-reset-by-peer) similar StackOverflow issue. Thanks!", "@amahendrakar Yes, your notebook is working just fine.\r\n\r\nSince I was working with 'TensorFlow Datasets' (instead of 'Requests' issue in your StackOverflow link), I tried replicated that solution by installing the TensorFlow/TensorFlow Datasets security modules in terminal by using these commands:\r\n\r\n> conda install -c anaconda \"tensorflow[security]\"\r\n> conda install -c anaconda \"tensorflow_datasets[security]\"\r\n\r\n(Used conda since I'm working in spyder)\r\nAnd some security packages were indeed installed but my issue is still persistent.", "Please provide the complete stacktrace. ", "This is the complete stacktrace:\r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 672, in urlopen\r\n>     chunked=chunked,\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 421, in _make_request\r\n>     six.raise_from(e, None)\r\n> \r\n>   File \"<string>\", line 3, in raise_from\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 416, in _make_request\r\n>     httplib_response = conn.getresponse()\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/http/client.py\", line 1344, in getresponse\r\n>     response.begin()\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/http/client.py\", line 306, in begin\r\n>     version, status, reason = self._read_status()\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/http/client.py\", line 267, in _read_status\r\n>     line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/socket.py\", line 589, in readinto\r\n>     return self._sock.recv_into(b)\r\n> \r\n> ConnectionResetError: [Errno 54] Connection reset by peer\r\n> \r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/site-packages/requests/adapters.py\", line 449, in send\r\n>     timeout=timeout\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 720, in urlopen\r\n>     method, url, error=e, _pool=self, _stacktrace=sys.exc_info()[2]\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/site-packages/urllib3/util/retry.py\", line 400, in increment\r\n>     raise six.reraise(type(error), error, _stacktrace)\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/site-packages/urllib3/packages/six.py\", line 734, in reraise\r\n>     raise value.with_traceback(tb)\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 672, in urlopen\r\n>     chunked=chunked,\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 421, in _make_request\r\n>     six.raise_from(e, None)\r\n> \r\n>   File \"<string>\", line 3, in raise_from\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/site-packages/urllib3/connectionpool.py\", line 416, in _make_request\r\n>     httplib_response = conn.getresponse()\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/http/client.py\", line 1344, in getresponse\r\n>     response.begin()\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/http/client.py\", line 306, in begin\r\n>     version, status, reason = self._read_status()\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/http/client.py\", line 267, in _read_status\r\n>     line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/socket.py\", line 589, in readinto\r\n>     return self._sock.recv_into(b)\r\n> \r\n> ProtocolError: ('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer'))\r\n> \r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n> \r\n>   File \"/Users/User/nlp1.py\", line 13, in <module>\r\n>     (train_data, test_data), info = tfds.load('imdb_reviews/subwords8k', split=(tfds.Split.TRAIN, tfds.Split.TEST), with_info = True, as_supervised = True)\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_datasets/core/api_utils.py\", line 52, in disallow_positional_args_dec\r\n>     return fn(*args, **kwargs)\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_datasets/core/registered.py\", line 300, in load\r\n>     dbuilder.download_and_prepare(**download_and_prepare_kwargs)\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_datasets/core/api_utils.py\", line 52, in disallow_positional_args_dec\r\n>     return fn(*args, **kwargs)\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_builder.py\", line 287, in download_and_prepare\r\n>     download_config=download_config)\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_builder.py\", line 948, in _download_and_prepare\r\n>     max_examples_per_split=download_config.max_examples_per_split,\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_datasets/core/dataset_builder.py\", line 804, in _download_and_prepare\r\n>     for split_generator in self._split_generators(dl_manager):\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_datasets/text/imdb.py\", line 129, in _split_generators\r\n>     arch_path = dl_manager.download(_DOWNLOAD_URL)\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_datasets/core/download/download_manager.py\", line 301, in download\r\n>     return _map_promise(self._download, url_or_urls)\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_datasets/core/download/download_manager.py\", line 395, in _map_promise\r\n>     res = utils.map_nested(_wait_on_promise, all_promises)\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_datasets/core/utils/py_utils.py\", line 143, in map_nested\r\n>     return function(data_struct)\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_datasets/core/download/download_manager.py\", line 379, in _wait_on_promise\r\n>     return p.get()\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/site-packages/promise/promise.py\", line 510, in get\r\n>     return self._target_settled_value(_raise=True)\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/site-packages/promise/promise.py\", line 514, in _target_settled_value\r\n>     return self._target()._settled_value(_raise)\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/site-packages/promise/promise.py\", line 224, in _settled_value\r\n>     reraise(type(raise_val), raise_val, self._traceback)\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/site-packages/six.py\", line 703, in reraise\r\n>     raise value\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/site-packages/promise/promise.py\", line 842, in handle_future_result\r\n>     resolve(future.result())\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/concurrent/futures/_base.py\", line 428, in result\r\n>     return self.__get_result()\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/concurrent/futures/_base.py\", line 384, in __get_result\r\n>     raise self._exception\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/concurrent/futures/thread.py\", line 57, in run\r\n>     result = self.fn(*self.args, **self.kwargs)\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/site-packages/tensorflow_datasets/core/download/downloader.py\", line 231, in _sync_download\r\n>     response = session.get(url, stream=True)\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/site-packages/requests/sessions.py\", line 546, in get\r\n>     return self.request('GET', url, **kwargs)\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/site-packages/requests/sessions.py\", line 533, in request\r\n>     resp = self.send(prep, **send_kwargs)\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/site-packages/requests/sessions.py\", line 646, in send\r\n>     r = adapter.send(request, **kwargs)\r\n> \r\n>   File \"/Users/User/anaconda3/envs/tf/lib/python3.7/site-packages/requests/adapters.py\", line 498, in send\r\n>     raise ConnectionError(err, request=request)\r\n> \r\n> ConnectionError: ('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer'))", "Thanks for the stack trace. [Python software foundation](https://github.com/psf/requests/issues) can be good platform to raise this issue.\r\nI see the error is raised by [getresponse() method](https://docs.python.org/3.7/library/http.client.html?highlight=get%20response#http.client.HTTPConnection.getresponse) and does not depend on TF module.\r\nThanks!", "Thank You for the support"]}]