[{"number": 1720, "title": "Eigen version in cmake mismatch", "body": "In `tensorflow/contrib/cmake/external/eigen.cmake`, both `eigen_archive_hash` and `eigen_HASH` don't match those in `tensorflow/workspace.bzl` and the source (e.g. `third_party/eigen3/Eigen/Cholesky`). This leads to build failure when using cmake.\n\nCould anyone update `tensorflow/contrib/cmake/external/eigen.cmake`?\n", "comments": ["Fixed, I believe.\n", "(with 2c2f422a628d83a591fb5d20d46deecc47655ead)\n", "Brilliant! Now even [CLion](https://www.jetbrains.com/clion/)'s debugging seems to work.\n", "@phisiart \r\nwhich version of tensorflow and clion you used, can teach me the configuration process import tensorflow source code . After installing the plugin, import the source directly? Still need to run other steps?"]}, {"number": 1719, "title": "Reduction of CPU test time for cwise_ops_test and rnn_test.", "body": "Reduce test scenarios for CPU-only tests by checking for whether\ncuda has been enabled in the binary to avoid running CPU tests twice.\n\nAlso avoids testing the cross product of broadcasting shapes, dtypes,\nand functions in the bcast code.  Instead, we only test broadcasting\nof all the various shapes for exactly one datatype and function (add),\nwhich should test the broadcasting behavior (which should not be function\nor type specific), and then testing only the cross product of\ndatatypes and functions with one shape.  Reduces cwise_ops_test\nin non-opt mode from 100 seconds to 20.\n\nAlso reduce the number of timesteps in one of the rnn_test tests\nfrom 8 to 3 (enough to check the recurrency).  The changes reduce\nthe runtime from 65 seconds to 19, and there are probably other\nchanges that can be made to the test to reduce it further.\n", "comments": ["rnn_test and cwise_ops_test timed out at 65 seconds, even though I ran them locally and they run in far less.\n\ntesting again, I have a feeling there's interference due to recent changes that cause multiple tests to run at the same time.  Since all the other tests are cached, only these two tests will run and we'll see the actual runtime.\n\n@tensorflow-jenkins: test this please\n", "Interesting, I tried running rnn_test and cwise_ops_test as exclusive mode.  on the cpu_python3 suite they both pass in ~20 seconds.  on normal cpu python2 they were running exclusively (I watched the log) but they still timed out -- not sure what's going on anymore :(\n\n@caisq, @jendap for advice?\n", "@tensorflow-jenkins test this please. \n", "@vrv You think --jobs=1 will help? We could change the scripts so that they run these two tests with --jobs=1 and the rest in the normal (parallel) way.\n", "It's possible --jobs=1 will help -- I'm still unsure myself why python3 linux is fine but the python2 linux one isn't :(\n", "@tensorflow-jenkins test this please\n", "Well, I tried.  Maybe someone else can figure out what's broken about this.\n"]}, {"number": 1718, "title": "Merge changes from internal for March 30", "body": "(Resolved conflicts hopefully correctly this time)\n", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->\n"]}, {"number": 1717, "title": "Upstream changes from internal for March 30", "body": "", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->\n"]}, {"number": 1716, "title": "Update index.md", "body": "change the code style to `bash`\nAt before, it's quite like a sentence but not a command, especially in the following link: \nhttps://www.tensorflow.org/versions/master/tutorials/mnist/tf/index.html#tensorflow-mechanics-101\n\nin the webpage, \"`\" only makes the code to be bold, but not code style\n", "comments": ["Can one of the admins verify this patch?\n"]}, {"number": 1715, "title": "Update to correct method name in local example", "body": "This is to help #1713 \n", "comments": ["Can one of the admins verify this patch?\n", "Thanks!\n", "Thanks!\n"]}, {"number": 1714, "title": "translate.py -- dev set batches", "body": "The code to evaluate the dev set at each checkpoint selects a random sample from the dev set for each bucket which is only as large as the minibatch size.\n\nThis seems very non-standard to have such a small dev set that changes from checkpoint to checkpoint.\n\nI modified my code to use a larger fixed dev set, but getting errors because the shape of the model depends on the batch size.\n\n```\ntensorflow.python.framework.errors.InvalidArgumentError: Incompatible shapes: [260,512] vs. [64,512]\n     [[Node: model_with_buckets/sequence_loss/sequence_loss_by_example/sampled_softmax_loss_9/add_2 = Add[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](model_with_buckets/sequence_loss/sequence_loss_by_example/sampled_softmax_loss_9/add_1, model_with_buckets/sequence_loss/sequence_loss_by_example/sampled_softmax_loss_9/SparseToDense)]]\nCaused by op u'model_with_buckets/sequence_loss/sequence_loss_by_example/sampled_softmax_loss_9/add_2', defined at:\n\n```\n\nAny suggestions for constructing model so that it accommodates a flexible batch size?\n\nI suppose this a feature request to update translate.py, otherwise let me know if I should take this issue over to Stack Overflow.\n", "comments": ["I think that the model in translate.py should work fine with variable batch size, it looks like it's changed to 1 in the decode function.\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/translate/translate.py#L212\n\nDid you try setting model.batch_size=260 before decoding, and then setting it back again? On the other hand, if you want a truly proper testing, it would probably be better to have a parallel process reading the latest checkpoint and running in decode-mode, e.g. to avoid using sampled softmax.\n", "Yes, setting model.batch_size works fine. Issue closed. Thanks.\n"]}, {"number": 1713, "title": "Update to correct method name in local example.", "body": "There is an error in the current distributed TensorFlow documentation which caused me a little trouble when verifying that installation was correct.\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "Thanks! (I know it sucks to have to sign a CLA for a doc change).\n", "Oh man - didn't see that one coming. I don't want to sign this before running this by a lawyer. I'm going to close this PR for now. If someone who has signed it (or is an Alphabet Employee) gets motivated they can make a similar change.\n"]}, {"number": 1712, "title": "Skflow fix imports", "body": "Currently `from tensorflow.contrib import skflow` doesn't import all the things. This adds `__init__.py` files to the BUILD file and correct absolute imports.\n", "comments": ["squash commits?\n", "@vrv done\n", "LGTM. \n"]}, {"number": 1711, "title": "error import tensorflow", "body": "I have installed the tensorflow and set the environment variables. However I got the following error when importing tensor flow:\n\nImportError: /myproject/lib/python2.7/sitepackages/tensorflow/python/_pywrap_tensorflow.so: invalid ELF header\n\nCan anyone help me? Thanks\n", "comments": ["Can you run `uname -a` in your terminal and report what gets printed?\n", "solved\n", "@cheng6076 Could you share the solution.\n", "I think I have installed the wrong version\n\n2016-04-09 11:00 GMT+01:00 Lingliang Zhang notifications@github.com:\n\n> @cheng6076 https://github.com/cheng6076 Could you share the solution.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/1711#issuecomment-207760851\n", "I had the same problem when I mistakenly installed the OSX version on Linux.  When doing a pip install especially, ensure the $TF_BINARY_URL references the correct OS, Python Version, CPU/GPU architecture\n\nhttps://www.tensorflow.org/versions/r0.10/get_started/os_setup.html#using-pip\n", "> Can you run `uname -a` in your terminal and report what gets printed?\r\n\r\nLinux raspberry 4.9.0-11-686 #1 SMP Debian 4.9.189-3+deb9u1 (2019-09-20) i686 GNU/Linux\r\n\r\nI am facing this issue. I couldn't find the solution on how to choose the right .whl file for installation.", "same error here withh nvidia jetson. How can i fix it ?"]}, {"number": 1710, "title": "move dropout to later chapters where it can truly work", "body": "@Sohl-Dickstein \nThis is to replace #1620 ,\nremove dropout in the very beginning tutorial on MNIST since it doesn't work in that network architecture,\nand move it to Tensorflow Mechanics 101, where it can truly work and we give more detailed explanation on dropout:\n\n`After all training epochs, the accuracy on test data will be around 98.5%.\nHowever if we remove dropout in the network architecture, the accuracy will\ndecrease to 98.2%. This is because dropout can reduce the effect of overfitting.\nIf we do not have dropout, the accuracy on training data will eventually become\n100%, however the accuracy on test data will soon increase to 98.2% but get\nstalled there. By adding dropout, the accuracy on training data increase slower,\nbut the generalization ability will become better.`\n", "comments": ["Can one of the admins verify this patch?\n", "@Sohl-Dickstein ,what's your opinion?\n", "Sorry for the delay. I will get a change review back to you in two days\n(Monday PST). Thank you for the contribution!\n\nOn Sat, Apr 2, 2016, 09:13 Wenjian Huang notifications@github.com wrote:\n\n> @Sohl-Dickstein https://github.com/Sohl-Dickstein ,what's your opinion?\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> \n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/1710#issuecomment-204747240\n", "I have some concerns about this pull request. This modification requires training for 10 times more learning steps, with twice the batch size, and with a model that has several hundred times the number of parameters. We want the models in these tutorials to run as quickly as possible, and this seems like a big step backwards in that respect. Even with that size increase, the performance change due to dropout is very small. There are also two images in the tutorial (graph visualization, and tensorboard screen shot) that will no longer be accurate after this change.\n\nLet me suggest a much more light weight change. How about placing a footnote link at the end of the first sentence in the dropout section in the original MNIST for Experts tutorial, then adding the following footnote text to the end of the tutorial:\n\n\"For this small convolutional network, performance is actually nearly identical with and without dropout. Dropout is often very effective at reducing overfitting, but it is most useful when training very large neural networks.\"\n\nInstructions for adding footnotes in markdown are here:\n\nhttp://stackoverflow.com/questions/25579868/how-do-i-add-footnotes-to-github-flavoured-markdown\n"]}, {"number": 1709, "title": "Update build_pip_package.sh for generating a tarball", "body": "Update build_pip_package.sh for generating a tarball\n\nOne can generate a single wheel file using:\n\n```\n    bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\n```\n\nOne can also generate an extra tarball file using:\n\n```\n    bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg tarball\n```\n", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "Can one of the admins verify this patch?\n", "Can one of the admins verify this patch?\n", "Hello, I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "Close this as it is a mistake. The tarball only contains the generated dynamic libraries that might be not suitable for other environment, e.g., the `GLIBC_2.14 not found` error.\n"]}, {"number": 1708, "title": "update tensorflow mechanics 101 index.md", "body": "Update `tensorflow mechanics 101 index.md` according to the `fully_connected_feed.py`.\nNow we don't need `sess.graph_def` but only need `sess.graph`.\n", "comments": ["Can one of the admins verify this patch?\n"]}, {"number": 1707, "title": "Clip gradients option in contrib.layers.optimize_loss broken", "body": "Using the nightly build from 30 Mar 2016 trying to call:\n\n```\ntrain_op = tf.contrib.layers.optimize_loss(train_loss,\n              global_step,\n              0.002,\n              \"Adam\",\n              clip_gradients=10.0)\n```\n\nwill throw:\n\n```\nTypeError: List of Tensors when single Tensor expected\n```\n\nI think `opt.compute_gradients()` returns a list of tuples not tensors so [line 106](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/optimizers.py#L106) needs to replace `gradients` with `[g[0] for g in gradients]`.\n", "comments": ["fixed by commit 3ab39c186d2a7e260023b68809963d0813566473\n"]}, {"number": 1706, "title": "rename var mu to learning_rate", "body": "Trying to resolve some problems with commit...done\n\nRename variable `mu` to `learing_rate` for paper consistency. \n\nThis is a second try, first try I have broke the file somehow (some waste lines leaked in it in merge commits). Now I have updated my local master branch from remote master, made a new branch for just this commit and made one commit ahead master. Hope it will be ok now.\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks, you can you try to squash the commits to get rid of all of those merge commits?\n", "Still trying. Constantly got an merge error while squashing commits into one with `git rebase`\n", "I could make a commit from github web-editor. But it adds a /newline character at the end of ipynb file. Maybe it's good to have one (usually) but I think it's not so good to have all this in one commit\n", "The merge commits are distracting -- maybe clone a new copy of your local repo, rebase to head, and then apply your changes?\n\n```\ngit clone ... your fork\ngit remote add upstream https://github.com/tensorflow/tensorflow.git\ngit fetch upstream\ngit rebase upstream/master\ngit checkout -b new_branch\n... make edits ...\ngit push -u origin new_branch\n```\n", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "@vrv  Ok, finally, thanks to your instructions, looks like it's done! Please double check if my happiness is too early.\n", "Great, thanks!  @tensorflow-jenkins: test this please\n"]}, {"number": 1705, "title": "Also taking contributions from the Gerrit?", "body": "In my opinion doing code review on GitHub is horrible except for very small fixes / tweaks. In addition, all those merge commits from \"pull requests\" really clutter up the git log.\n\nI wonder if TensorFlow would consider also taking patches from Gerrit. Blaze (Bazel) does this: all external pull requests are not merged directly, but committed through the Gerrit repo. As a result, their commit history looks much cleaner: https://github.com/bazelbuild/bazel/commits/master.\n", "comments": ["@Dominator008, thanks for your comments. We did start out with maintaining both gerrit and github and accepting changes via both systems. However, the maintenance burden became too much, and with the limited human resources we had (have), we decided to focus on making the  github process as robust as possible. Gerrit indeed has superior code review interface, but unfortunately, we are unable to dedicate resources to maintain multiple sources of truth for TensorFlow code.\n", "For what it's worth, github now allows squash and merge, creating no merge commits. Yay!\n", "@vrv Wow finally. That's a nice one.\n"]}, {"number": 1704, "title": "\"Setting up TensorFlow for Development\" no longer works with recent TF versions", "body": "### Environment info\n\nOperating System: OS X 10.11, Ubuntu 15.10\nSource build, commit hash: e39d8feebb9666a331345cd8d960f5ade4652bba\n### Steps to reproduce\n\nI have TF as a submodule and build it local to the project. I use more or less the exact same commands in the [development setup](https://www.tensorflow.org/versions/r0.7/get_started/os_setup.html#setting-up-tensorflow-for-development). The only minor change is that I don't run `python setup.py develop` (under OS X, this breaks my Anaconda python installation completely via screwing with the site-packages). So the steps are (in Makefile syntax):\n\n``` bash\ngit submodule update --init --recursive\ncd $(TF_DIR) && ./configure\ncd $(TF_DIR) && bazel build -c opt //tensorflow/tools/pip_package:build_pip_package\ncd $(TF_INSTALL_DIR) && ln -s $(addprefix ../../,$(wildcard $(TF_DIR)/bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles/*)) .\n$(TF_INSTALL_DIR) && ln -s $(addprefix ../../,$(wildcard $(TF_DIR)/tensorflow/tools/pip_package/*)) .\n```\n\nThe prefix commands are for making globs work in Make. I have confirmed they expand to the same symlink commands.\n### Issue\n\nImporting tensorflow no longer works using development guidelines. Specifically, assuming tensorflow is cloned into $TF_DIR, symlinked into `$TF_INSTALL_DIR`, and built by bazel in $BAZEL_TMP, this no longer works: (output sanitized manually)\n\n```\n$ PYTHONPATH=$TF_INSTALL_DIR python\nPython 2.7.10 (default, Oct 14 2015, 16:09:02) \n[GCC 5.2.1 20151010] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import tensorflow as tf\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"$TF_INSTALL_DIR/tensorflow/__init__.py\", line 23, in <module>\n    from tensorflow.python import *\n  File \"$TF_INSTALL_DIR/tensorflow/python/__init__.py\", line 49, in <module>\n    from tensorflow.core.framework.graph_pb2 import *\n  File \"$TF_INSTALL_DIR/tensorflow/core/framework/graph_pb2.py\", line 6, in <module>\n    from google.protobuf import descriptor as _descriptor\n  File \"$BAZEL_TMP/tensorflow/bazel-out/local_linux-opt/bin/tensorflow/tools/pip_package/build_pip_package.runfiles/google/protobuf/descriptor.py\", line 46, in <module>\n    from google.protobuf.pyext import _message\n  File \"$BAZEL_TMP/tensorflow/bazel-out/local_linux-opt/bin/tensorflow/tools/pip_package/build_pip_package.runfiles/google/protobuf/pyext/__init__.py\", line 2, in <module>\n    __import__('pkg_resources').declare_namespace(__name__)\n  File \"/usr/local/lib/python2.7/dist-packages/pkg_resources/__init__.py\", line 2226, in declare_namespace\n    _handle_ns(packageName, path_item)\n  File \"/usr/local/lib/python2.7/dist-packages/pkg_resources/__init__.py\", line 2195, in _handle_ns\n    path.sort(key=sort_key)\n  File \"/usr/local/lib/python2.7/dist-packages/pkg_resources/__init__.py\", line 2193, in sort_key\n    return sys_path.index(_normalize_cached(os.sep.join(parts)))\nValueError: '$BAZEL_TMP/tensorflow/bazel-out/local_linux-opt/bin/tensorflow/tools/pip_package/build_pip_package.runfiles' is not in list\n```\n\nLinux output shown, but OS X also fails with a similar exception.\n### What have you tried?\n\nI believe the issue comes down to the same one as #1535. I am creating this issue separately so that if it turns out to be a different problem, it isn't muddled. If it's the same, we can close it.\n\nThe exception is a result of namespace package resolution in google.protobuf trying to find `$BAZEL_TMP/tensorflow/bazel-out/local_linux-opt/bin/tensorflow/tools/pip_package/build_pip_package.runfiles/google/protobuf/pyext`. It is trying to find it in a list of system paths which includes `$TF_INSTALL_DIR`. Recall that due to the development setup rules, the files in `$TF_INSTALL_DIR` are symlinks to files in `$BAZEL_TMP`. Specifically, `$TF_INSTALL_DIR/google/protobuf` is the same directory as `$BAZEL_TMP/google/protobuf`. (I have verified this with `pwd -P`.\n\nWhat seems to be going on is that Python is attempting to unify the protobuf namespace package, but its filename (`$BAZEL_TMP/google/protobuf/pyext`) does not match the `sys.path` entry (`$TF_INSTALL_DIR`).\n\n**Note:** This only appears to be a problem when trying to use the development install rules, and it only appears to be a problem when there's another tensorflow or protobuf installed in the system somewhere else. At least on OS X; the other version of tensorflow on my Linux machine is in use by other users, so I can't uninstall it safely. I have not attempted to create a clean virtual environment just for my development directory (for one, because virtual environments are a pain in the neck; and two, that's part of the whole point of having a local build of tensorflow).\n\nWorkaround: Replacing the symlinks with a recursive copy (from `$BAZEL_TMP` to `$TF_INSTALL_DIR`) is apparently sufficient to convince Python that it's unified the namespace packages correctly, and it chooses the `$TF_INSTALL_DIR` specified in `$PYTHONPATH`.\n\nSo I don't know what the appropriate solution here is, but the problem seems to be the result of a convergence of semi-hacky solutions, any one of which alone might not be an issue, but work together to cause problems:\n- There's no clean way to extract the necessary files from a built tensorflow without going through pip install. Perhaps there's a method using pip I'm not aware of (maybe something with `--target`?).\n- Python namespace packages have poor path resolution semantics. It looks like this ship has sailed.\n- The symlink approach is kind of coarse and tricky to script around.\n", "comments": ["Hi @rdadolf , I met this problem just now by coincidence. I tried rebuilding the project but the problem was   not solved. Then I tried `pip uninstall tensorflow` and `python setup.py develop`. Everything goes happy now.\n", "Yep, this is one workaround. I mentioned that this did alleviate the issue in the \"**Note:**\" piece above, and I think a similar approach was mentioned in the other issue I referenced. I should have probably placed it more prominently.\n\nThis doesn't help a whole lot with shared systems, however. I have other folks who work on an older, stable install of TF on the same system (and sometimes I'm one of them), so uninstalling isn't a solution in my case. I believe virtualenv's have been tried, and they may work here, but one of the whole ideas behind a local install was to avoid that route.\n\nI'm glad that this solved your problem, though.\n\nTo devs: if it looks like this problem is too much of a pain for not enough benefit, another stopgap would be to update the development setup docs to point out that you either need to have protobuf version compatibility and/or uninstall other versions of tensorflow to do this. Might save some folks in @wangg12's situation some headache.\n", "@rdadolf I'm also using a shared system. But for python, I installed an anaconda just for me. So there won't be any problem to influence others' environment.\n", "For those that land on this ticket from Google searches, you might also want to check out https://github.com/tensorflow/tensorflow/issues/2591 which outlines a typo in the `master` docs.\n", "Just a followup on @orionr's mention: the typo in #2591 is a recent addition: prior to around May 24 2016, the line in the setup documentation didn't have this issue, since the `org_tensorflow` part didn't exist. (This is the [relevant diff](https://github.com/tensorflow/tensorflow/pull/2336/files#diff-1cf444a338533a8469b274d1cd1b7229).) So the original issue in this thread is not a symptom.\n\nThank you for mentioning it, though. They are similar issues, and it's tricky to find all of the relevant issue/commit threads in github. This helped me eliminate another recent problem regarding bazel versioning.\n", "Given the [recent flux](https://github.com/tensorflow/tensorflow/commit/14ac2235699509f512b44b71160239c153ab413d), I thought I'd update this issue based on a more recent version (79174af).\n\nFirst, I've updated to bazel 2.3 to avoid [this problem](https://github.com/tensorflow/tensorflow/issues/2497#issuecomment-221631692), so the relevant commands now use the `org_tensorflow` syntax (with the typo fix).\n\nThe changes to protobuf have not solved these issues, they've just broken them in different ways.\n\n**Change in behavior regarding manual import**\n\nIt looks like the change has broken the way I was importing TensorFlow in the original issue. I.e, running through the TensorFlow development setup instructions without the `setup.py` step and just importing from the directory no longer works. The specific commands are (_not_ in Makefile syntax this time, to make things easier to read):\n\n```\ncd $TF_DIR && ./configure\ncd $TF_DIR && bazel build -c opt //tensorflow/tools/pip_package:build_pip_package\nrm -r $TF_INSTALL_DIR\nmkdir $TF_INSTALL_DIR\ncd $TF_INSTALL_DIR && cp -r $TF_DIR/bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles/org_tensorflow/* .\ncd $TF_INSTALL_DIR && cp -r $TF_DIR/tensorflow/tools/pip_package/* .\n```\n\nExample 1: In a clean environment, `protobuf` is not found.\n\n```\nPYTHONPATH=$TF_INSTALL_DIR python\n>>> import tensorflow as tf\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"$TF_INSTALL_DIR/tensorflow/__init__.py\", line 23, in <module>\n    from tensorflow.python import *\n  File \"$TF_INSTALL_DIR/tensorflow/python/__init__.py\", line 58, in <module>\n    raise ImportError(msg)\nImportError: Traceback (most recent call last):\n  File \"$TF_INSTALL_DIR/tensorflow/python/__init__.py\", line 52, in <module>\n    from tensorflow.core.framework.graph_pb2 import *\n  File \"$TF_INSTALL_DIR/tensorflow/core/framework/graph_pb2.py\", line 6, in <module>\n    from google.protobuf import descriptor as _descriptor\nImportError: No module named google.protobuf\n\nError importing tensorflow.  Unless you are using bazel,\nyou should not try to import tensorflow from its source directory;\nplease exit the tensorflow source tree, and relaunch your python interpreter\nfrom there.\n```\n\nExample 2: In a mixed environment (i.e., one with a system-installed version of tensorflow and a custom verstion. In this case, they are the _same_ version of protobuf, so we don't get an error as in the original issue):\n\n```\nPYTHONPATH=$TF_INSTALL_DIR python\n>>> import tensorflow as tf\n>>> tf.__file__\n$TF_INSTALL_DIR/tensorflow/__init__.pyc\n>>> import google.protobuf\n>>> google.protobuf.__file__\n$SYSTEM_SITE_PACKAGES/google/protobuf/__init__.pyc\n```\n\nIt looks like the changes have made importing directly impossible. That's unfortunate, but I understand that it wasn't a supported behavior in the first place. So I bit the bullet and tried to make things work as in the first bullet point I mentioned in the original file (working through `setup.py` or `pip`).\n\n**Installing via \"Setting up TensorFlow for Development\"**\n\nSame commands as before, but this time using the `setup.py` as written (and a separate build directory):\n\n```\ncd $TF_DIR && ./configure\ncd $TF_DIR && bazel build -c opt //tensorflow/tools/pip_package:build_pip_package\nrm -r $TF_BUILD_DIR\nmkdir $TF_BUILD_DIR\ncd $TF_BUILD_DIR && ln -s $TF_DIR/bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles/org_tensorflow/* .\ncd $TF_BUILD_DIR && ln -s $TF_DIR/tensorflow/tools/pip_package/* .\npython $TF_BUILD_DIR/setup.py develop\n```\n\nNote: this is _not_ safe. This can overwrite files in your `site-packages` directory, including replacing existing `easy_install` and `wheel` scripts and modifying your existing `sys.path` through `.pth` files. If there's a flaw here (or, say a mismatch between the version of `setuptools` that TensorFlow just installed and your other tools like, say `pip` or `conda`) and you're not using some type of sandboxing (virtualenv, VM, etc.), python is basically broken until you manually remove the offending files TensorFlow installs (and you won't be able to use the `--uninstall` option because of the same underlying issue). Also, if you already had a working version of tensorflow, it's now gone, as they conflict and `setup.py` will remove the other. So as before, I hope you were working in a sandbox.\n\nSo this sort of works, but it doesn't solve my original problem of having any sort of control over where the library was installed. So there are a couple of possible solutions:\n\n**Flags to `setup.py`**\n`setup.py develop` takes an `--install-dir` flag. Long story short, it doesn't work. 1) it requires pre-modifying your environment, 2) it doesn't _actually_ obey the flag---it still modifies files in your default `site-packages`, and 3) it doesn't actually work: python doesn't find the library, even when the directory is specified in `PYTHONPATH`.\n\nCounter-intuitively, `setup.py install` has different options, including a `--prefix` flag, which doesn't do quite the same thing. Except it turns out that this the same problems.\n\nUltimately, both of these use `.pth` files as an underlying mechanism. Because python only reads `.pth` files from four specific directories, these methods are unworkable.\n\n**Flags to pip**\nSo the remaining option is to forget the \"development\" options altogether and attempt to use the pip package. Recent versions of `pip` take a `--prefix` option, which is supposed to support this. So the commands are:\n\n```\ncd $TF_DIR && ./configure\ncd $TF_DIR && bazel build -c opt //tensorflow/tools/pip_package:build_pip_package\n$TF_DIR/bazel-bin/tensorflow/tools/pip_package/build_pip_package $TF_BUILD_DIR\npip install $TF_BUILD_DIR/tensorflow-0.8.0-py2-none-any.whl --prefix=$TF_INSTALL_DIR\n```\n\nand we get this output:\n\n```\nThu Jun 2 16:27:58 EDT 2016 : === Using tmpdir: /var/folders/mw/kf4sryxx1xvgh2kyg9_yxvsw0000gn/T/tmp.XXXXXXXXXX.PYkoZMt7\n/var/folders/mw/kf4sryxx1xvgh2kyg9_yxvsw0000gn/T/tmp.XXXXXXXXXX.PYkoZMt7 ~/scratch/tensorflow\nThu Jun 2 16:27:58 EDT 2016 : === Building wheel\n~/scratch/tensorflow\nThu Jun 2 16:28:10 EDT 2016 : === Output wheel file is in: $TF_BUILD_DIR\nProcessing $TF_BUILD_DIR/tensorflow-0.8.0-py2-none-any.whl\nRequirement already satisfied (use --upgrade to upgrade): six>=1.10.0 in $SYSTEM_SITE_PACKAGES (from tensorflow==0.8.0)\nCollecting protobuf==3.0.0b2 (from tensorflow==0.8.0)\n  Using cached protobuf-3.0.0b2-py2.py3-none-any.whl\nRequirement already satisfied (use --upgrade to upgrade): numpy>=1.10.1 in $SYSTEM_SITE_PACKAGES (from tensorflow==0.8.0)\nRequirement already satisfied (use --upgrade to upgrade): wheel in $SYSTEM_SITE_PACKAGES (from tensorflow==0.8.0)\nRequirement already satisfied (use --upgrade to upgrade): setuptools in $SYSTEM_SITE_PACKAGES/setuptools-21.2.1-py2.7.egg (from protobuf==3.0.0b2->tensorflow==0.8.0)\nInstalling collected packages: protobuf, tensorflow\nSuccessfully installed protobuf tensorflow\n```\n\nAnd we try importing...\n\n```\nPYTHONPATH=$TF_INSTALL_DIR/lib/python2.7/site-packages python\n>>> import tensorflow\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"$TF_INSTALL_DIR/lib/python2.7/site-packages/tensorflow/__init__.py\", line 23, in <module>\n    from tensorflow.python import *\n  File \"$TF_INSTALL_DIR/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 58, in <module>\n    raise ImportError(msg)\nImportError: Traceback (most recent call last):\n  File \"$TF_INSTALL_DIR/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 52, in <module>\n    from tensorflow.core.framework.graph_pb2 import *\n  File \"$TF_INSTALL_DIR/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py\", line 6, in <module>\n    from google.protobuf import descriptor as _descriptor\nImportError: No module named google.protobuf\n\nError importing tensorflow.  Unless you are using bazel,\nyou should not try to import tensorflow from its source directory;\nplease exit the tensorflow source tree, and relaunch your python interpreter\nfrom there.\n```\n\nWhich brings us back to a similar problem. It seems nigh-on impossible to get tensorflow to import protobuf using the new system unless it's installed in the default user or system directory. I believe this boils down to the same namespace packaging issue, but that's just a conjecture at this point.\n\n**TL;DR**\nThe new protobuf mechanism doesn't actually solve this problem. Installing tensorflow in a non-standard location seems to cause protobuf imports to fail regardless of how or where.\n", "@rdadolf - thanks for updating to the latest, which eliminates the issue I was commenting on. This might be silly, but have you considered adjusting your `PYTHONPATH` variable? With that you might be able to get it to find your tensorflow package as well as protobuf. Basically something like this, if `import google.protobuf` succeeded when you ran `python` without the path:\n\n```\nPYTHONPATH=$TF_INSTALL_DIR/lib/python2.7/site-packages:$PYTHONPATH python\n>>> import tensorflow\n...\n```\n\nAnd, of course, using virtualenv might help (it works great for me), but it looks like you specifically don't want to go that route, since you have it as a submodule. Good luck!\n", "Yep. That's the ultimate goal here: place tensorflow in directory X, and point `PYTHONPATH` to it, and write `import tensorflow`, where X is a directory of my choosing. Each one of these examples actually sets `PYTHONPATH` to `TF_INSTALL_DIR` before running, just like you mention. It certainly _seemed_ like it should be that easy. Unfortunately, it seems that either due some combination of the packaging tools and the way the TensorFlow and/or protobuf packages are written, it's not.\n\nI do understand the virtualenv perspective. Without getting into too much of a holy war, virtualenv takes a very different approach to solving the problem, one that is pretty narrow in scope. Part of my hope was that I would only have to have one solution for dealing with versioning, environment, and consistency. virtualenv can only handle a small piece of the python-only part of that. For instance, there's a collection of training data and preprocessing which needs similar solutions: externally managed, place it in directory X, point Y to it, etc. Virtualenv isn't much help there. Same with some low-level instrumentation code which we use. And this is compounded by running on a variety of machines and platforms. So while I'll admit I'm a little biased because I don't much like virtualenv's approach to the world, I'd also really like to avoid adding more complexity in a lot of places just because of idiosyncrasies in the way tensorflow's package is written. (Especially since it was working two weeks ago!)\n", "Only thing I would suggest is to concatenate to the existing PYTHONPATH rather than overriding it. Take one more look at my previous comment and the :$PYTHONPATH inserted in the middle. If that doesn't work I guess we'll need to hear from the real maintainers.\n\n> On Jun 2, 2016, at 3:18 PM, Bob Adolf notifications@github.com wrote:\n> \n> Yep. That's the ultimate goal here: place tensorflow in directory X, and point PYTHONPATH to it, and write import tensorflow, where X is a directory of my choosing. Each one of these examples actually sets PYTHONPATH to TF_INSTALL_DIR before running, just like you mention. It certainly seemed like it should be that easy. Unfortunately, it seems that either due some combination of the packaging tools and the way the TensorFlow and/or protobuf packages are written, it's not.\n> \n> I do understand the virtualenv perspective. Without getting into too much of a holy war, virtualenv takes a very different approach to solving the problem, one that is pretty narrow in scope. Part of my hope was that I would only have to have one solution for dealing with versioning, environment, and consistency. virtualenv can only handle a small piece of the python-only part of that. For instance, there's a collection of training data and preprocessing which needs similar solutions: externally managed, place it in directory X, point Y to it, etc. Virtualenv isn't much help there. Same with some low-level instrumentation code which we use. And this is compounded by running on a variety of machines and platforms. So while I'll admit I'm a little biased because I don't much like virtualenv's approach to the world, I'd also really like to avoid adding more complexity in a lot of places just because of idiosyncrasies in the way tensorflow's package is written. (Especially since it wa s working two weeks ago!)\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub, or mute the thread.\n", "This would be nice to figure out with \"just use PYTHONPATH\" way.  This way one could start `ipython notebook` to play around with their tensorflow changes in Jupyter, but current way is limiting you to `simple_console.py`\n", "These set of commands work for me :\n\n```\nmkdir tensorflow\nexport TF_INSTALL_DIR=/tmp/tensorflow\npip install --prefix=$TF_INSTALL_DIR https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.9.0rc0-cp27-none-linux_x86_64.whl\nCollecting tensorflow==0.9.0rc0 from https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.9.0rc0-cp27-none-linux_x86_64.whl\nUsing cached https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.9.0rc0-cp27-none-linux_x86_64.whl\nRequirement already satisfied (use --upgrade to upgrade): six>=1.10.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==0.9.0rc0)\nRequirement already satisfied (use --upgrade to upgrade): protobuf==3.0.0b2 in /usr/local/lib/python2.7/dist-packages (from tensorflow==0.9.0rc0)\nRequirement already satisfied (use --upgrade to upgrade): wheel in /usr/lib/python2.7/dist-packages (from tensorflow==0.9.0rc0)\nRequirement already satisfied (use --upgrade to upgrade): numpy>=1.8.2 in /usr/lib/python2.7/dist-packages (from tensorflow==0.9.0rc0)\nRequirement already satisfied (use --upgrade to upgrade): setuptools in /usr/local/lib/python2.7/dist-packages (from protobuf==3.0.0b2->tensorflow==0.9.0rc0)\nInstalling collected packages: tensorflow\nSuccessfully installed tensorflow\n\nPYTHONPATH=$TF_INSTALL_DIR/lib/python2.7/site-packages:$PYTHONPATH python\nPython 2.7.6 (default, Jun 22 2015, 17:58:13) \n[GCC 4.8.2] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import tensorflow as tf\ntf>>> tf.__file__\n'/tmp/tensorflow/lib/python2.7/site-packages/tensorflow/__init__.pyc'\n\nmkdir /tmp/tensorflow\nexport TF_INSTALL_DIR=/tmp/tensorflow\n```\n\nI am on a Ubuntu 14.04, though. Can you give this a shot? Having said that, `virtualenv` is our tested installation methodology. We need lot more people asking for this way on installation before we can start thinking about supporting and testing this. Feel free to keep this open in case you really want to see this supported, otherwise please close the issue.\n", "@rdadolf Closing this one out due to inactivity. I don't see anything fundamentally broken about using `pip` with `--prefix` and using `$PYTHONPATH` later, at least in the platforms I tried. Please feel free to reopen if you think this is still an issue worth solving.\n"]}, {"number": 1703, "title": "Revert \"mu to learning_rate\"", "body": "Reverts tensorflow/tensorflow#1638\n", "comments": ["(this brought in a weird merge commit, reverting).\n"]}, {"number": 1702, "title": "Print operation flattens the tensors", "body": "### Environment info\n\nOperating System: Linux\nUsing: pip, 0.7.1 for Python 3\n### Steps to reproduce\n\nRun:\n\n```\na=tf.constant([[1], [2]])\nb=tf.Print(a, [a])\n```\n### Output\n\n```\nI tensorflow/core/kernels/logging_ops.cc:79] [1 2]\n```\n\nwhile the tensor evalutes to:\n\n```\narray([[1],\n       [2]], dtype=int32)\n```\n### Expected output\n\n```\nI tensorflow/core/kernels/logging_ops.cc:79] [[1], [2]]\n```\n", "comments": ["Thanks for filing this issue. `tf.Print` is primarily as a tool for debugging during graph execution. Making the output nicely formatted is not going to be high priority for us in the near future. But the code to print out the tensor is here [1]. I am marking this issue as 'Contributions welcome' :)\n\n[1] https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/tensor.cc#L628\n", "If anyone haven't fix this issue , I want to work on it . I have submitted the contribution license today.\n", "@mrry @keveman \nMy solution is , cut the total array into the format , in the `SummarizeArray` method.\nFor example, cut a tensor of shape (2,2) with the total-array data 1,2,3,4 to print [[1,2][3,4]]\n\nWondering if there exists a method that do the same?\n", "This might be easier. tf.Print was created before we have convenient ways to calling python runtime:\n\n```\ndef Print(inp, data):\n  def np_print(*args):\n    for x in args:\n      print(x)\n  return tf.with_dependencies([tf.py_func(np_print, data, [])], inp)\n\ng = tf.Graph()\nwith g.as_default():\n  x = tf.random_uniform([2, 2])\n  y = tf.random_uniform([2, 2])\n  z = tf.random_uniform([2, 2])\n  x = Print(x, [x, y, z])\n\nwith tf.Session(graph=g) as sess:\n  x.eval()\n```\n", "Is this issue fixed?\n", "@Mistobaan  Yes, fixed\n", "So now I get this error when I try and print some gradients:\r\nValueError: Shapes must be equal rank, but are 3 and 2\r\n\tFrom merging shape 10 with other shapes. for 'Print/packed' (op: 'Pack') with input shapes: [2,1,2], [2,2], [2,1,2], [2,2], [2,2,2], [2,2], [2,2,2], [2,2], [2,2,1], [2,1], [2,2,1], [2,1]."]}, {"number": 1701, "title": "Building from source with CUDA PATH problem", "body": "### Environment info\n\nOperating System: Fedora 23\n\nIf installed from sources, provide the commit hash:\n8e035ea\n### Steps to reproduce\n1.  ../bazel/output/bazel --output_base=/projects/.cache build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures\n### What have you tried?\n1.  ./configure on root directory\n2.  cuda_config.sh script \n3.  building without --config=cuda is successful.\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\nOutput from build\nhttp://pastebin.com/17BejSXD\n\nI noticed that PATH in the log doesn't have the directory to libcudart.so.7.5, which is here:\n/usr/local/cuda/lib64/\n\necho $LD_LIBRARY_PATH:\n:/usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/lib/nvidia:/usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/lib/nvidia:/usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/lib/nvidia\n\nPointers will be welcome.\n", "comments": ["changed the PATH and still have this problem.  Will make a new issue.\n"]}, {"number": 1700, "title": "Upstream changes from internal for March 29", "body": "", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->\n", "@tensorflow-jenkins: test this please\n"]}, {"number": 1699, "title": "Android Bazel Build - Java Failure", "body": "Ran into another build issue when running `bazel build //tensorflow/examples/android:tensorflow_demo --verbose_failures`\n\n```\nWARNING: /Users/username/tensorflow/tensorflow/core/BUILD:632:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:avgpooling_op.h' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /Users/username/tensorflow/tensorflow/core/BUILD:632:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib_lite: please do not import '//tensorflow/core/kernels:bounds_check.h' directly. You should either move the file to this package or depend on an appropriate rule there.\n...\nLots more of the same warnings\n...\nWARNING: /Users/username/tensorflow/tensorflow/core/BUILD:665:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib: please do not import '//tensorflow/core/kernels:where_op.cc' directly. You should either move the file to this package or depend on an appropriate rule there.\nWARNING: /Users/username/tensorflow/tensorflow/core/BUILD:665:12: in srcs attribute of cc_library rule //tensorflow/core:android_tensorflow_lib: please do not import '//tensorflow/core/kernels:xent_op.cc' directly. You should either move the file to this package or depend on an appropriate rule there.\nINFO: Found 1 target...\nERROR: /private/var/tmp/_bazel_username/d0aa3a34ac01d28ffabd89cde457364e/external/bazel_tools/src/tools/android/java/com/google/devtools/build/android/BUILD:8:1: Java compilation in rule '@bazel_tools//src/tools/android/java/com/google/devtools/build/android:AndroidResourceProcessingAction' failed: java failed: error executing command \n  (cd /private/var/tmp/_bazel_username/d0aa3a34ac01d28ffabd89cde457364e/tensorflow && \\\n  exec env - \\\n  external/local_jdk/bin/java -Xbootclasspath/p:external/bazel_tools/third_party/java/jdk/langtools/javac.jar -client -jar external/bazel_tools/tools/jdk/JavaBuilder_deploy.jar @bazel-out/host/bin/external/bazel_tools/src/tools/android/java/com/google/devtools/build/android/AndroidResourceProcessingAction.jar-2.params): com.google.devtools.build.lib.shell.AbnormalTerminationException: Process terminated by signal 11: java failed: error executing command \n  (cd /private/var/tmp/_bazel_username/d0aa3a34ac01d28ffabd89cde457364e/tensorflow && \\\n  exec env - \\\n  external/local_jdk/bin/java -Xbootclasspath/p:external/bazel_tools/third_party/java/jdk/langtools/javac.jar -client -jar external/bazel_tools/tools/jdk/JavaBuilder_deploy.jar @bazel-out/host/bin/external/bazel_tools/src/tools/android/java/com/google/devtools/build/android/AndroidResourceProcessingAction.jar-2.params): com.google.devtools.build.lib.shell.AbnormalTerminationException: Process terminated by signal 11.\nTarget //tensorflow/examples/android:tensorflow_demo failed to build\nINFO: Elapsed time: 0.743s, Critical Path: 0.53s\n```\n\nI am on OSX 10.11, had to download android ndk-r10e (since r11e didn't seem to work). Java version is 1.8.0_73 and Bazel version is 0.2.0 with TensorFlow 0.7.1. My WORKSPACE is configured as follows in the beginning. I changed the build_tools_version for the androidsdk to 23.0.2 (from 23.0.1) since that's what I have locally on my machine. Any pointers?\n\n```\nandroid_sdk_repository(\n    name = \"androidsdk\",\n    api_level = 23,\n    build_tools_version = \"23.0.2\",\n    path = \"/Users/mchong5/Library/Android/sdk\",\n)\n\nandroid_ndk_repository(\n    name=\"androidndk\",\n    path=\"/Users/mchong5/android-ndk-r10e/\",\n    api_level=21)\n```\n", "comments": ["I was unable to reproduce with a fresh Bazel 0.2.0 install and tensorflow download. This is on OSX 10.11.3, with Java 1.8.0_72-b15 and ndk r10e.\n\nFor reference I installed bazel from [here](https://github-cloud.s3.amazonaws.com/releases/20773773/dc48f278-da3a-11e5-9243-85bbaa6e4f62.sh?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAISTNZFOVBIJMK3TQ%2F20160330%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20160330T225519Z&X-Amz-Expires=300&X-Amz-Signature=824c159effdd075803132a589805fedbcd4813908d24fe983b86c7e4f3d7b8bb&X-Amz-SignedHeaders=host&actor_id=3376817&response-content-disposition=attachment%3B%20filename%3Dbazel-0.2.0-installer-darwin-x86_64.sh&response-content-type=application%2Foctet-stream) and installed with:\n\n```\nchmod +x bazel-0.2.0-installer-darwin-x86_64.sh; \nsudo ./bazel-0.2.0-installer-darwin-x86_64.sh\n```\n\nI downloaded TF with:\n`git clone --recursive https://github.com/tensorflow/tensorflow/`\n\nAnd appended the following to my WORKSPACE:\n\n```\nandroid_sdk_repository(\n    name = \"androidsdk\",\n    api_level = 23,\n    build_tools_version = \"23.0.2\",\n    # Replace with path to Android SDK on your system\n    path = \"/Users/andrewharp/Library/Android/sdk\",\n)\n\nandroid_ndk_repository(\n    name=\"androidndk\",\n    path=\"/Users/andrewharp/Downloads/android-ndk-r10e\",\n    api_level=21)\n```\n\nI doubt it's related, but what happens if you strip the trailing slash off your android ndk path? \n", "Well, it was that trailing slash! \n"]}, {"number": 1698, "title": "Revert \"Fix wrong parenthesis.\"", "body": "Reverts tensorflow/tensorflow#1648 -- it's breaking the mac build\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "(this was a mistake, right?  the tests passed on the mac build)\n", "(Closing, feel free to reopen if you disagree)\n"]}, {"number": 1697, "title": "Update fully_connected_feed.py", "body": "\"os.path\" and \"numpy\" were unused, so I removed them.\nThe tfevents-output-file was not completely written in IPython, so I added \"summary_writer.flush()\" to fix it.\n", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins: test this please\n"]}, {"number": 1696, "title": "[skflow] Fix skflow imports in examples", "body": "cc: @ilblackdragon \n", "comments": ["Can one of the admins verify this patch?\n", "There is an easier fix - `__init__` files on the way weren't in the BUILD file.\nAdded a PR #1712 for that. Please take a look, and I'll close this one.\n"]}, {"number": 1695, "title": "Android Bazel Build Error", "body": "I'm at the step where I enter `bazel build //tensorflow/examples/android:tensorflow_demo` and I get the following output:\n\n```\nERROR: /Users/mchong5/tensorflow/WORKSPACE:5:13: invalid character: '?'.\nERROR: /Users/mchong5/tensorflow/WORKSPACE:5:14: invalid character: '?'.\nERROR: /Users/mchong5/tensorflow/WORKSPACE:5:50: invalid character: '?'.\nERROR: /Users/mchong5/tensorflow/WORKSPACE:5:51: invalid character: '?'.\nERROR: /Users/mchong5/tensorflow/WORKSPACE:10:11: invalid character: '?'.\nERROR: /Users/mchong5/tensorflow/WORKSPACE:10:12: invalid character: '?'.\nERROR: /Users/mchong5/tensorflow/WORKSPACE:10:46: invalid character: '?'.\nERROR: /Users/mchong5/tensorflow/WORKSPACE:10:47: invalid character: '?'.\nERROR: /Users/mchong5/tensorflow/WORKSPACE:5:49: syntax error at '?': expected ,\nERROR: /Users/mchong5/tensorflow/WORKSPACE:6:1: non-keyword arg after keyword arg.\nERROR: no such package 'external': Error encountered while dealing with the WORKSPACE file: Failed to parse WORKSPACE file.\nINFO: Elapsed time: 0.557s\n```\n\nMy WORKSPACE is modified as follows... I'm not sure why it is telling me there are invalid characters\n\n```\nandroid_sdk_repository(\n    name = \"androidsdk\",\n    api_level = 23,\n    build_tools_version = \"23.0.2\",\n    path = \u201c/Users/mchong5/Library/Android/sdk\u201d,\n)\n\nandroid_ndk_repository(\n    name=\"androidndk\",\n    path=\u201c/Users/mchong5/android-ndk-r11b/\u201d,\n    api_level=21)\n```\n\nFor reference, I am on OSX 10.11 using Bazel 0.2.0 built from source with tensorflow 0.7.1\n", "comments": ["It looks like you have non-ascii quotes around the paths. Did you use a rich text editor to make the edits?\n", "It looks like that was it! I didn't even catch that the quotations looked different. Thanks\n", "I am also at this step and I have a similar problem. When I entered \"bazel build -c opt //tensorflow/examples/android:tensorflow_demo\", I got an error message: \"ERROR: Analysis of target '//tensorflow/examples/android:tensorflow_demo' failed; build aborted.\"\r\n\r\nMy WORKSPACE is:\r\n\r\nandroid_sdk_repository(\r\n    name = \"androidsdk\",\r\n    api_level = 26,\r\n    # Ensure that you have the build_tools_version below installed in the\r\n    # SDK manager as it updates periodically.\r\n    build_tools_version = \"26.0.1\",\r\n    # Replace with path to Android SDK on your system\r\n    path = \"/Users/ST/AppData/Local/Android/Sdk/\",\r\n)\r\n\r\nandroid_ndk_repository(\r\n    name=\"androidndk\",\r\n    path=\"/Users/ST/AppData/Local/Android/Sdk/ndk-bundle/\",\r\n    # This needs to be 14 or higher to compile TensorFlow.\r\n    # Please specify API level to >= 21 to build for 64-bit\r\n    # archtectures or the Android NDK will automatically select biggest\r\n    # API level that it supports without notice.\r\n    # Note that the NDK version is not the API level.\r\n    api_level=14)\r\n\r\nI am using Windows 10. Is there anyone knowing how to solve this problem?"]}, {"number": 1694, "title": "Fix typos in messages", "body": "It's \"overwriting\", not \"overwritting\". Also fixed missing space after a full stop.\n", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins: test this please\n"]}, {"number": 1693, "title": "R0.7", "body": "", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n"]}, {"number": 1692, "title": "TF fails to compile on Ubuntu 14.04: crosstool_wrapper_driver_is_not_gcc failed", "body": "Hello, \nI'm trying to build TF from source and I'm getting the error included below. \nI've seen similar issues but none of the fixes works for me.\n\nWhat doesn't work:\n- official \"installation and setup\" steps (duh...) with bazel 0.2.0\n- updating bazel from 0.2.0 to master\n- compiling with `--spawn_strategy=standalone`\n- including `-fPIC` flag in `gpus/crosstools/CROSSTOOL`\n- deleting `-fPIE` flag from the same file\n\nThe command I use is:\n`bazel build -c opt --config=cuda --spawn_strategy=standalone --verbose_failures //tensorflow/cc:tutorials_example_trainer`\n\nthe error is:\n\n```\nERROR: /home/marcin/Moje/Software/tensorflow/tensorflow/cc/BUILD:61:1: Linking of rule '//tensorflow/cc:tutorials_example_trainer' failed: crosstool_wrapper_driver_is_not_gcc failed: error executing command \n  (cd /home/marcin/.cache/bazel/_bazel_marcin/259f71b95269c287fa42ef117628b45f/tensorflow && \\\n  exec env - \\\n  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc  ...\n...\n/usr/bin/ld: /usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libz.a(crc32.o): relocation R_X86_64_32 against `.rodata' can not be used when making a shared object; recompile with -fPIC\n/usr/lib/gcc/x86_64-linux-gnu/4.8/../../../x86_64-linux-gnu/libz.a: error adding symbols: Bad value\ncollect2: error: ld returned 1 exit status\n```\n\nthe full error message is here:\n[https://gist.github.com/elanmart/f462692553e1e53fc540](https://gist.github.com/elanmart/f462692553e1e53fc540)\n", "comments": ["Pretty old unattended bug. Was the issue resolved?\n", "I can confirm this is no longer an issue, so closing this issue. \n\n@elanmart, feel free to reopen if you still see the problem with the latest TensorFlow, Cuda SDK and Cudnn library. \n"]}, {"number": 1691, "title": "fix mem leaks for dynamic rnn", "body": "Fix mem leaks in tensor array and stack.\n\nTests `tensorflow/python/kernel_tests/rnn_*.py` pass.\n", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins: test this please (I'm assuming this is correct ahead of time).\n\n@ebrevdo: is it worth adding C++ tests that would catch this memory leak?  (It's interesting that the python one doesn't expose it).\n", "Can you do a favor and run the tests with blaze test -c dbg ?  This should check that you don't unref once too many times.\n", "Sure, this is what I ran\n`bazel test -c dbg //tensorflow/python:rnn_test`\nAnd this was the output\n\n``````\n...\n//tensorflow/python:rnn_test                                             PASSED in 58.9s\n\nExecuted 1 out of 1 tests: 1 test passes.\nThere were tests whose specified size is too big. Use the --test_verbose_timeout_warnings command line option to see which ones these are.```\n``````\n", "Great!  Can you rebase on HEAD so we can merge?\n", "Yup, done!\n", "@tensorflow-jenkins: test this please\n", "@vrv Can this be detected with a special -fsanitize=leak in the CI build matrix running tests?\n", "Thanks!!\n"]}]