[{"number": 52009, "title": "Update MklDnnMatMulFwdPrimitiveFactory to support Arm Compute Library", "body": "Related to issue #47415 and PR #47775. Adding support for caching inner product primitives.\r\nIncludes patch file for oneDNN to include inner product, eltwise primitives and updates to ACL thread binding.", "comments": ["Hi, the AMD build seems to fail on an unrelated reason..\r\n```\r\nROCM_PATH \"/opt/rocm-4.2.0\" does not exist\r\n```", "Thanks!"]}, {"number": 52008, "title": "Updated keras version", "body": "Updating keras to stable version. Reference #51901", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F52008) for more info**.\n\n<!-- need_sender_cla -->", "@sanatmpa1 Can you please sign CLA. Thanks!"]}, {"number": 52007, "title": "Refactor SparseSliceGradOp to use a functor", "body": "- This is in preparation for adding a GPU implementation.\r\n- No functional change.\r\n- Also adds some explicit tests.\r\n\r\ncc @nluehr ", "comments": ["@penpornk Can you please review this PR ? Thanks!", "@penpornk Can you please review this PR ? Thanks!", "@benbarsdell Can you please resolve conflicts? Thanks!", "Rebased (strangely I didn't get any conflicts).", "Rebased again.", "@penpornk Can you please review this PR ? Thanks!", "Rebased.", "Out of interest, what's up with all the `FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/52007` in unrelated commits?"]}, {"number": 52005, "title": "Instance Segmentation for TFLite", "body": "Hello there,\r\nthis is not so much of an urgent matter. Nevertheless I wanted to ask, are there any good and maintained open source Instance Segmentation networks that will convert easily to TFLite? I started of with Mask R-CNN but soon realised that the SELECT_OPS flag would slow down the inference time significantly, also because gpu and npu are not available then. I need some model that is natively supported on TFLite (without SELECT_OPS). As far as I understood there are problems with dynamic tensors on GPU/NPU, which is bad because most instance segmenation models use anchors or regions of interest that are resized throughout the model and the segmented individually. I already thought about a single shot detector with sementic segmentation but could not find anything.\r\nI found YOLACT-EDGE (https://github.com/haotian-liu/yolact_edge) until I realized that it is in pytorch :(.\r\n\r\nAnybody any ideas? ", "comments": ["@CodeMonkey3435 Could you please refer to the [link](https://www.tensorflow.org/lite/examples/segmentation/overview) and let us know if it helps ? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 52004, "title": "Add GPU implementation of SparseSlice", "body": "cc @nluehr ", "comments": ["@chsigg  Can you please review this PR ? Thanks!", "@chsigg Can you please review this PR ? Thanks!", "@benbarsdell  Can you please resolve conflicts? Thanks!", "Rebased."]}, {"number": 52003, "title": "shared_embedding_columns ", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52003\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52003\">No</a>\n"]}, {"number": 52001, "title": "Computing Jacobian and Gradient with GradientTape is extremely slow", "body": "<em>Please make sure that this is an issue related to performance of TensorFlow.\r\nAs per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:performance_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS Linux 7\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.6.0\r\n- Python version: 3.9\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nI want to compute the Jacobian and Gradient of my model for a loss function, but the model just throws a warning about retracing and gets stuck\r\n\r\n**Describe the expected behavior**\r\nNormal training should occur\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n```\r\ndef compute_loss_theta(tape, parameter, concept, output, x):\r\n\r\n    b = x.shape[0]\r\n    in_dim = (x.shape[1], x.shape[2])\r\n\r\n    feature_dim = in_dim[0]*in_dim[1]\r\n\r\n    J = tape.batch_jacobian(concept, x)\r\n    \r\n    grad_fx = tape.gradient(output, x)\r\n    grad_fx = tf.reshape(grad_fx,shape=(b, feature_dim))\r\n    J = tf.reshape(J, shape=(b, feature_dim, feature_dim))\r\n\r\n    parameter = tf.expand_dims(parameter, axis =1)\r\n\r\n    loss_theta_matrix = grad_fx - tf.matmul(parameter, J)\r\n\r\n    loss_theta = tf.norm(loss_theta_matrix)\r\n\r\n    return loss_theta\r\n\r\n\r\nfor i in range(10):\r\n    for x, y in train_dataset:\r\n\r\n        with tf.GradientTape(persistent=True) as tape:\r\n            tape.watch(x)\r\n            \r\n            parameter, concept, output = model(x)\r\n\r\n            loss_theta = compute_loss_theta(tape, parameter, concept, output , x)\r\n\r\n            loss_y = loss_object(y_true=y, y_pred=output)\r\n                \r\n            loss_value = loss_y + eps*loss_theta\r\n\r\n        gradients = tape.gradient(loss_value, model.trainable_weights)\r\n        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\r\n```\r\n\r\nThis function is extremely slow. I want to compute the loss as given in the self-explanatory neural network. Input has a shape of (32, 365, 3) where 32 is the batch size. The loss I want to minimize is Equation 3 of the [paper](https://papers.nips.cc/paper/2018/file/3e9f0fc9b2f89e043bc6233994dfcf76-Paper.pdf). \r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Hi @melioristic ,Could you please providing a link  to the **train_dataset** and update the full error stack trace in above template too? It helps expedite the issue.", "@mohantym I tried to reproduce this slow behavior. And then looking through the details I found that the Jacobian part is not slow. I was just trying to predict long sequences. You can close this issue. Just on a side note, can you please look through the [notebook](https://colab.research.google.com/drive/1jPPbaxDpkrMSgxS_APtrYGWw1xhbp7lg?usp=sharing) that I have shared here? In the last block can you just see the computation and let me know if this is the fastest way to update the gradients or not. Any suggestion would be really helpful. \r\nP.S. you can close the issue. Thank you for your time. ", "@melioristic  , I was able to remove the warning messages though by changing tabs to put tape.gradient() and opt.apply_gradients() to keep them in context with tf.gradient. Providing [GIST ](https://colab.research.google.com/gist/mohantym/209d13b76a8ef6d50f7057d587991e85/senn_reproducible.ipynb#scrollTo=tS0fJ6emB4GW)for reference.", "@mohantym Thanks I think, I will assume that this is the fastest it can work in eager mode. I made this a function and added @tf.function decorator and its speed increased considerably.", "Yes ,Agreed! @melioristic ,Checked with `@tf.function(autograph=True) ` earlier  , was able to reduce  existing time  approx 4 times (Around 0.25 after first two batch) . Ok! Feel to Free to close this issue  if it helped .Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 51999, "title": "tensorflow-macos fails to install due to wheel build failure", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Monterey beta 6\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version: tensorflow-macos 2.5.0\r\n- Python version: 3.8.10, 3.9.7\r\n- Installed using virtualenv? pip? conda?: Mambaforge 4.10.3-5, conda, pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source): Xcode 13 beta 6\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: Apple G13G, 16GB system RAM\r\n\r\n\r\n\r\n**Describe the problem**\r\nWhen attempting to install tensorflow-macos with either Python 3.8 or 3.9, it fails when it tries to install grpcio.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```\r\nconda create -n tf python=3.8\r\n```\r\n\r\nor:\r\n\r\n```\r\nconda create -n tf\r\n```\r\n\r\nThen following with:\r\n```\r\nconda activate tf\r\nconda install -c apple tensorflow-deps\r\npip install tensorflow-macos\r\n```\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n[pip.log](https://github.com/tensorflow/tensorflow/files/7165907/pip.log)\r\n\r\nnumpy appears to be trying to install a version of wheels that thinks that anything that isn't x86 has altivec.\r\n", "comments": ["Oops, I just realized this is probably best covered by Apple's Tensorflow repository issue tracker. I can leave this here if it's useful to anyone, though.", "@kode54 ,\r\nEvery TensorFlow release is compatible with a certain version, for more information please take a look at the tested build [configurations](https://www.tensorflow.org/install/source#cpu_2).In this case, can you please try installing TensorFlow v2.5 with compatible compiler and bazel version and check if you are facing the same error. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51999\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51999\">No</a>\n"]}, {"number": 51998, "title": " [Intel oneDNN] update curl version to 7.78.0-cherrypick to r2.4", "body": "PiperOrigin-RevId: 393777488\r\nChange-Id: Iaad20d85315b0bdd42bf7fb389df8c8f13179639", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F51998) for more info**.\n\n<!-- need_sender_cla -->", "@pranve Can you please sign CLA. Thanks!", "@googlebot I signed it!"]}, {"number": 51997, "title": "Wrong output result  to the IDE consoles  from Tensor Stream 2.3.4 and 2.6.0.  and wrong result in IDEs", "body": "Hi all!\r\n**System configuration**\r\nOS Platform and Distribution : Linux Debian 10 4.19.0-17-amd64\r\nTensorFlow installed: binary from pypi.org \r\nTensorFlow version: 2.3.4 and 2.6.0 \r\nPython version:3.7.12\r\nInstalled from: compile from source\r\nBazel version \u2013 not using\r\nGCC/Compiler version \u2013 not using\r\nCUDA/cuDNN version \u2013 not using\r\nGPU model and memory: AMD FX-8350,  16GB RAM\r\n\r\n**Bug describing**\r\nI recently encountered an unexpected problem with output to the IDE console. I prefer to use the Spyder 5 IDE. I started learning DL from the book \u201cDeep Learning with Python Second Edition\u201d by Francois Cholet MEAP 2020. When I compiling the code for Chapter 4 \" Getting started with neural networks: classification and regression\", namely, in 4.1 Classification of film reviews: an example of binary classification and \"4.2.1 The Reuters dataset\" in the Spyder 5.14 IDE,  the values of loss function and accuracy began   different than in the book. \r\n\r\nI spent a lot of time trying changing the CUDA Toolkit of various versions, changing   the  operating system from Debian to Ubuntu and return back \u2013 but the results in the Spyder console always was different then the result  in the book. \r\n\r\nFor the sake of interest, I typed this code from this book in Google Collaboration - and a miracle happened - the data from the book and from the console of the Colaboratory notebook coincided. \r\nAfter that, I installed various versions of Tensorflow without support for CUDA drivers in different Python 3.7.12 virtual environments.\r\n\r\nAs a result, the output of the Jupyter  notebooks console in both virtual environments for different versions of Tensorflow coincided with the final data in the book. I also used different IDEs for different virtual environments - Eclipse 2021-06 for TF 2.3.4 and Spyder 5.14 for TF2. 6. 0 - in both IDEs, the console output and the final result were different from the results in the book and in Jupiter notebooks.\r\n\r\nPlease open the case to fix this bug. \r\nBest regards, Vadim Maklakov.  \r\n\r\n[ch_4_IMDB_issue.tar.gz](https://github.com/tensorflow/tensorflow/files/7165248/ch_4_IMDB_issue.tar.gz)", "comments": ["Hi @Vadim-Maklakov!  I checked your files , There was no Error stack trace in your notebooks.\r\nso It is not a bug or feature request, for any further queries you may open this issue in [tf discussion forum ](https://discuss.tensorflow.org/)as there is a larger community there.Thank you!", "Hi, @mohantym !\r\n\r\nThe problem isn't in the jupyter notebooks  files.\r\nPlease load the \"ch_4_IMDB_binary_classification.py\" script in the other IDE, for example Spyder or Pydev, run it  and  check    results and plots will be equal results  from the jupyter notebooks  files. In my case I see very distinguished  results from IDE and jupyter notebooks files and I  attach its  in the my first post bellow logs from IDE consoles and plots files from Spyder and Pydev IDE .\r\n\r\nI see that loss function and accuracy   values  for fires training model and final training model  differ considerably then jupyter notebooks results.\r\n \r\nAs I understand and Spyder and Jupyter notebooks  use the same IPython  but why  its  give different results in the end in the console and plots?\r\n\r\nIt turns out in the end that all the code in the future I should write code only Jupyter notebook and  me forbidden  use other IDE for Python?\r\n\r\n\r\nBest regards, Vadim Maklakov,  ", "Hi, @mohantym !\r\nDo you compile  `ch_4_IMDB_binary_classification.py` script in the other IDE than Jupyter notebook? \r\nWhat results are output in the console and the values \u200b\u200bof variables in IPython in your case?\r\nWhy does scikit-learn give the same final results for Jupyter notebook  and Spyder 4/5 and Eclipse PyDev?", "Hi @sanatmpa1 ,Could you please look into this issue?", "@Vadim-Maklakov I ran your code in colab and local terminal. I notice same results but don't know whether those results are matching with the results mentioned in the book. \r\n\r\nHere is the stacktrace from terminal\r\n\r\n```\r\n(base) vishnuvardhanj-macbookpro:ch_4_IMDB_issue vishnuvardhanj$ python3 ch_4_IMDB_binary_classification.py\r\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\r\n17465344/17464789 [==============================] - 1s 0us/step\r\n<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\r\n/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\r\n  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\r\n/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\r\n  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\r\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\r\n1646592/1641221 [==============================] - 0s 0us/step\r\n2021-09-20 17:23:25.962502: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-09-20 17:23:25.962739: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-09-20 17:23:27.823250: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\r\nEpoch 1/20\r\n30/30 [==============================] - 4s 94ms/step - loss: 0.6932 - acc: 0.4978 - val_loss: 0.6932 - val_acc: 0.4947\r\nEpoch 2/20\r\n30/30 [==============================] - 1s 19ms/step - loss: 0.6931 - acc: 0.5095 - val_loss: 0.6932 - val_acc: 0.4947\r\nEpoch 3/20\r\n30/30 [==============================] - 1s 19ms/step - loss: 0.6931 - acc: 0.5032 - val_loss: 0.6932 - val_acc: 0.4947\r\nEpoch 4/20\r\n30/30 [==============================] - 1s 18ms/step - loss: 0.6931 - acc: 0.5041 - val_loss: 0.6932 - val_acc: 0.4947\r\nEpoch 5/20\r\n30/30 [==============================] - 1s 18ms/step - loss: 0.6931 - acc: 0.5051 - val_loss: 0.6932 - val_acc: 0.4947\r\nEpoch 6/20\r\n30/30 [==============================] - 1s 17ms/step - loss: 0.6931 - acc: 0.5078 - val_loss: 0.6932 - val_acc: 0.4947\r\nEpoch 7/20\r\n30/30 [==============================] - 0s 16ms/step - loss: 0.6931 - acc: 0.5079 - val_loss: 0.6932 - val_acc: 0.4947\r\nEpoch 8/20\r\n30/30 [==============================] - 0s 16ms/step - loss: 0.6931 - acc: 0.5086 - val_loss: 0.6932 - val_acc: 0.4947\r\nEpoch 9/20\r\n30/30 [==============================] - 0s 15ms/step - loss: 0.6931 - acc: 0.5040 - val_loss: 0.6932 - val_acc: 0.4947\r\nEpoch 10/20\r\n30/30 [==============================] - 0s 15ms/step - loss: 0.6931 - acc: 0.5026 - val_loss: 0.6932 - val_acc: 0.4947\r\nEpoch 11/20\r\n30/30 [==============================] - 1s 17ms/step - loss: 0.6931 - acc: 0.5047 - val_loss: 0.6932 - val_acc: 0.4947\r\nEpoch 12/20\r\n30/30 [==============================] - 0s 16ms/step - loss: 0.6931 - acc: 0.5060 - val_loss: 0.6932 - val_acc: 0.4947\r\nEpoch 13/20\r\n30/30 [==============================] - 0s 15ms/step - loss: 0.6932 - acc: 0.4959 - val_loss: 0.6932 - val_acc: 0.4947\r\nEpoch 14/20\r\n30/30 [==============================] - 0s 16ms/step - loss: 0.6931 - acc: 0.5047 - val_loss: 0.6932 - val_acc: 0.4947\r\nEpoch 15/20\r\n30/30 [==============================] - 0s 17ms/step - loss: 0.6931 - acc: 0.5035 - val_loss: 0.6932 - val_acc: 0.4947\r\nEpoch 16/20\r\n30/30 [==============================] - 0s 16ms/step - loss: 0.6931 - acc: 0.5054 - val_loss: 0.6932 - val_acc: 0.4947\r\nEpoch 17/20\r\n30/30 [==============================] - 0s 17ms/step - loss: 0.6931 - acc: 0.5037 - val_loss: 0.6932 - val_acc: 0.4947\r\nEpoch 18/20\r\n30/30 [==============================] - 0s 15ms/step - loss: 0.6931 - acc: 0.5050 - val_loss: 0.6932 - val_acc: 0.4947\r\nEpoch 19/20\r\n30/30 [==============================] - 1s 18ms/step - loss: 0.6932 - acc: 0.5002 - val_loss: 0.6932 - val_acc: 0.4947\r\nEpoch 20/20\r\n30/30 [==============================] - 1s 17ms/step - loss: 0.6931 - acc: 0.5046 - val_loss: 0.6932 - val_acc: 0.4947\r\n49/49 [==============================] - 2s 21ms/step - loss: 0.2500 - acc: 0.4964\r\n782/782 [==============================] - 2s 2ms/step - loss: 0.2500 - acc: 0.5000\r\n```\r\n\r\nAlso, check results from [colab](https://colab.research.google.com/gist/jvishnuvardhan/57d46ad98ed02f06d7bbe568f9891e28/untitled1050.ipynb). I also pasted your code in colab and ran that also. [gist here](https://colab.research.google.com/gist/jvishnuvardhan/adad828d560b01976552912e5e39435a/untitled1051.ipynb)\r\n\r\nI notice all three are matching. Not sure about `Spyder IDE`. \r\n\r\nI don't think this is related to bugs/performance. Please post any further questions in [TF Forum](https://discuss.tensorflow.org/tag/help_request) where there is a big community to support each other. Thanks!", "Hi, @jvishnuvardhan!\r\nI think that isn't topic for forum and this issue belong Tensorflow developer.\r\nI get the same values \u200b\u200bas you  above when I executing the script `ch_4_IMDB_binary_classification.py` in the  Python console or using IDE Spyder, Eclipse PyDev or Pycharm. \r\nThis result of both cases -  you and me -  when executing as script or compiling in the  IDE Spyder, Eclipse PyDev or Pycharm.  does not match the result console output in the book  which must have  be this:\r\n```\r\nEpoch 1/20\r\n2021-09-21 16:43:34.579784: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\r\n 8/30 [=======>......................] - ETA: 0s - loss: 0.6436 - acc: 0.6494\r\n2021-09-21 16:43:35.770346: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\r\n30/30 [==============================] - 3s 41ms/step - loss: 0.5253 - acc: 0.7831 - val_loss: 0.3976 - val_acc: 0.8716\r\nEpoch 2/20\r\n30/30 [==============================] - 1s 22ms/step - loss: 0.3144 - acc: 0.9030 - val_loss: 0.3158 - val_acc: 0.8854\r\nEpoch 3/20\r\n30/30 [==============================] - 1s 22ms/step - loss: 0.2335 - acc: 0.9269 - val_loss: 0.2900 - val_acc: 0.8887\r\nEpoch 4/20\r\n30/30 [==============================] - 1s 22ms/step - loss: 0.1835 - acc: 0.9429 - val_loss: 0.2745 - val_acc: 0.8910\r\nEpoch 5/20\r\n30/30 [==============================] - 1s 22ms/step - loss: 0.1523 - acc: 0.9524 - val_loss: 0.2796 - val_acc: 0.8886\r\nEpoch 6/20\r\n30/30 [==============================] - 1s 22ms/step - loss: 0.1258 - acc: 0.9621 - val_loss: 0.3459 - val_acc: 0.8712\r\nEpoch 7/20\r\n30/30 [==============================] - 1s 22ms/step - loss: 0.1059 - acc: 0.9701 - val_loss: 0.3153 - val_acc: 0.8828\r\nEpoch 8/20\r\n30/30 [==============================] - 1s 22ms/step - loss: 0.0913 - acc: 0.9753 - val_loss: 0.3264 - val_acc: 0.8789\r\nEpoch 9/20\r\n30/30 [==============================] - 1s 22ms/step - loss: 0.0763 - acc: 0.9789 - val_loss: 0.3627 - val_acc: 0.8713\r\nEpoch 10/20\r\n30/30 [==============================] - 1s 22ms/step - loss: 0.0644 - acc: 0.9840 - val_loss: 0.3556 - val_acc: 0.8795\r\nEpoch 11/20\r\n30/30 [==============================] - 1s 21ms/step - loss: 0.0518 - acc: 0.9871 - val_loss: 0.3862 - val_acc: 0.8788\r\nEpoch 12/20\r\n30/30 [==============================] - 1s 21ms/step - loss: 0.0435 - acc: 0.9905 - val_loss: 0.4076 - val_acc: 0.8770\r\nEpoch 13/20\r\n30/30 [==============================] - 1s 22ms/step - loss: 0.0351 - acc: 0.9926 - val_loss: 0.4554 - val_acc: 0.8678\r\nEpoch 14/20\r\n30/30 [==============================] - 1s 21ms/step - loss: 0.0293 - acc: 0.9940 - val_loss: 0.4661 - val_acc: 0.8715\r\nEpoch 15/20\r\n30/30 [==============================] - 1s 22ms/step - loss: 0.0228 - acc: 0.9961 - val_loss: 0.4923 - val_acc: 0.8716\r\nEpoch 16/20\r\n30/30 [==============================] - 1s 22ms/step - loss: 0.0189 - acc: 0.9973 - val_loss: 0.5289 - val_acc: 0.8688\r\nEpoch 17/20\r\n30/30 [==============================] - 1s 21ms/step - loss: 0.0150 - acc: 0.9981 - val_loss: 0.5599 - val_acc: 0.8704\r\nEpoch 18/20\r\n30/30 [==============================] - 1s 22ms/step - loss: 0.0137 - acc: 0.9977 - val_loss: 0.5907 - val_acc: 0.8697\r\nEpoch 19/20\r\n30/30 [==============================] - 1s 23ms/step - loss: 0.0077 - acc: 0.9997 - val_loss: 0.6228 - val_acc: 0.8668\r\nEpoch 20/20\r\n30/30 [==============================] - 1s 20ms/step - loss: 0.0078 - acc: 0.9992 - val_loss: 0.6653 - val_acc: 0.8689\r\n```\r\nI get same result output console  as book  when I run code in the  local Jupyter  notebook with TF2.5.1 GPU edition (see attach bellow) or when I using [Google Colab](https://colab.research.google.com/drive/14Ft90fajq3kuRcAMwMbwboeDyg1k9PyE?usp=sharing) with TF2.6.0 CPU edition\r\n\r\nThe main problem is that Tensorflow  used the same Ipython backend but  it gives different results for  different applications. I my case only local Jupyter  notebook  and Google Colab get right result, but Python console or using IDE Spyder, Eclipse PyDev or Pycharm get wrong result. In our case and   Python console and Google Colab get wrong result.\r\n\r\n[IMDB_issue_TF251.ipynb.zip](https://github.com/tensorflow/tensorflow/files/7203984/IMDB_issue_TF251.ipynb.zip)\r\n", "Hi all!\r\nFor experiment I complied  TF2.5.1 with clang-12 and get the same result -  the output between for simple same code int the Jupyter/Colab  are distinguish that output for Spyder, Eclipse PyDev, PyCharm.\r\nSince in the case of writing any large project, it is necessary to check the results of the project in Jupyter/Colab.\r\n Such is the grimace of modern artificial intelligence -  an \r\nin some cases  the same IPython get  different output result values for  Jupyter/Colab and Spyder/Eclipse PyDev,/Pycharm and require manual and visual checking :(", "Hi all! My banal mistake type in this code\r\n```\r\ndef vectorize_sequences(sequences, dimension=10000):\r\n    results = np.zeros((len(sequences), dimension))\r\n    for i, sequence in enumerate(sequences):\r\n        results[i, sequence] = 1.0\r\n-       return results\r\n+    return results \r\n```\r\nProblem solved, I am closing this ticket with my banal mistake. \r\nMy apologies for everybody the unnecessary trouble."]}, {"number": 51995, "title": "Profile TensorFlow Performance: Multiple occurences of single Conv2D op", "body": "\r\n------------------------\r\n\r\n### System information\r\n\r\n-   **Custom Code**\r\n-   **Linux Ubuntu 20.04**\r\n-   **TensorFlow installed from (source or binary)**: Binary\r\n-   **TensorFlow version (use command below)**: 2.6\r\n-   **Python version**: 3.8\r\n-   **Bazel version (if compiling from source)**: None\r\n-   **GCC/Compiler version (if compiling from source)**: None\r\n-   **CUDA/cuDNN version**: 11.4/8.2\r\n-   **GPU model and memory**: RTX3090/24GB\r\n-   **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nProfile NN layers runtime on GPU device (I am concerned only with inference). I am using\r\ntf.profiler module. \r\n\r\n### Source code / logs\r\nI have created a dummy network with just a single convolution layer.\r\ndummy_net.py\r\n```\r\nimport tensorflow as tf\r\nimport os\r\n\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\r\n\r\nclass Net(tf.keras.Model):\r\n    def __init__(self) -> None:\r\n        super().__init__()\r\n        self.conv = tf.keras.layers.Conv2D(6,3)\r\n    \r\n    def call(self, x):\r\n        x = self.conv(x)\r\n        return x\r\n```\r\nAnd testing it on random input.\r\n\r\ntest_dummy_net.py\r\n\r\n```\r\nimport tensorflow as tf\r\nimport dummy_net\r\n\r\ninp = tf.random.uniform([1,300,300,3])\r\nmodel = dummy_net.Net()\r\ntf.profiler.experimental.start('./dummy_infer_logs')\r\ny = model(inp)\r\ntf.profiler.experimental.stop()\r\ntf.debugging.set_log_device_placement(True)\r\n```\r\nWhen I check profile logs in the TensorBoard, it shows that Conv2D op has occurred multiple times.\r\n![image](https://user-images.githubusercontent.com/25697952/133319278-cb43ff62-9b35-4909-bfce-84fb9692f5cb.png)\r\n\r\nWhen I add more Conv2D layers, occurrences go on increasing. For example, for 4 Conv2D layers more than 1900 occurrences are shown. This makes it difficult to get exact run times.\r\n\r\nAlso, why same operations are also run on the host?\r\n![image](https://user-images.githubusercontent.com/25697952/133319852-30e13c82-955f-43ec-8ca5-b561b41bde4b.png)\r\n", "comments": ["@shelkesagar29 ,\r\nWe see that the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose) has not been filled, could you please do so as it helps us analyse the issue.Also tensorflow is compatible with specific cuda and cudnn version.Please refer the [link](https://www.tensorflow.org/install/source#gpu) for the same and try to install as mentioned.Thanks", "I could not change template. I am closing this and have opened #52048 "]}, {"number": 51994, "title": "when convert keras model to tflite .. gives me this !!", "body": "Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONV_2D, DEPTHWISE_CONV_2D, FULLY_CONNECTED, MAX_POOL_2D, MUL, SOFTMAX. Here is a list of operators for which you will need custom implementations: Elu.\r\n\r\n", "comments": ["https://www.tensorflow.org/lite/guide/ops_select\r\n\r\nPlease convert with the Select TF option as suggested."]}, {"number": 51992, "title": "AttributeError: module 'tensorflow.compat.v2.__internal__.tracking' has no attribute 'DelegatingTrackableMixin'", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Yes**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Ubuntu 20.04.2 LTS** \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **no**\r\n- TensorFlow installed from (source or binary): **pip**\r\n- TensorFlow version (use command below): **2.7.0-dev20210806**\r\n- Python version: **3.6**\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: **no GPU in use**\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\n\r\n**Error when trying to load model.Worked in 2.6.0 and previouse.**\r\n\r\nError message in short: \r\n\r\n**AttributeError: module 'tensorflow.compat.v2.__internal__.tracking' has no attribute 'DelegatingTrackableMixin'**\r\n**logs below** \r\n\r\n**Describe the expected behavior**\r\n\r\n**Should just load a model** \r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\ntfVersion=tf.version.VERSION.replace(\".\", \"\")\r\nprint('TensorFlow Version: '+tf.version.VERSION)\r\nimport pathlib as path\r\n\r\nif __name__ == '__main__':\r\n     saved_model_dir= path.Path.cwd() / 'model' / 'Pump_LSTM_Fapi_OOP_1_tf_260' \r\n     model=tf.keras.models.load_model(saved_model_dir)\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n**MODEL**\r\n[Pump_LSTM_Fapi_OOP_1_tf_260.zip](https://github.com/tensorflow/tensorflow/files/7163177/Pump_LSTM_Fapi_OOP_1_tf_260.zip)\r\n\r\n\r\n**TRACEBACK**\r\n\r\n> TensorFlow Version: 2.7.0-dev20210806\r\n> Traceback (most recent call last):\r\n> \r\n>   File \"/home/base/Documents/Git/KundenProjekte2021/Ginko/pump_sensor/untitled0.py\", line 41, in <module>\r\n>     model=tf.keras.models.load_model(saved_model_dir)\r\n> \r\n>   File \"/home/base/anaconda3/envs/AInight/lib/python3.6/site-packages/tensorflow/python/util/lazy_loader.py\", line 62, in __getattr__\r\n>     module = self._load()\r\n> \r\n>   File \"/home/base/anaconda3/envs/AInight/lib/python3.6/site-packages/tensorflow/python/util/lazy_loader.py\", line 45, in _load\r\n>     module = importlib.import_module(self.__name__)\r\n> \r\n>   File \"/home/base/anaconda3/envs/AInight/lib/python3.6/importlib/__init__.py\", line 126, in import_module\r\n>     return _bootstrap._gcd_import(name[level:], package, level)\r\n> \r\n>   File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n> \r\n>   File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n> \r\n>   File \"<frozen importlib._bootstrap>\", line 941, in _find_and_load_unlocked\r\n> \r\n>   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n> \r\n>   File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n> \r\n>   File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n> \r\n>   File \"<frozen importlib._bootstrap>\", line 941, in _find_and_load_unlocked\r\n> \r\n>   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n> \r\n>   File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n> \r\n>   File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n> \r\n>   File \"<frozen importlib._bootstrap>\", line 941, in _find_and_load_unlocked\r\n> \r\n>   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n> \r\n>   File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n> \r\n>   File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n> \r\n>   File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n> \r\n>   File \"<frozen importlib._bootstrap>\", line 665, in _load_unlocked\r\n> \r\n>   File \"<frozen importlib._bootstrap_external>\", line 678, in exec_module\r\n> \r\n>   File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n> \r\n>   File \"/home/base/anaconda3/envs/AInight/lib/python3.6/site-packages/keras/__init__.py\", line 25, in <module>\r\n>     from keras import models\r\n> \r\n>   File \"/home/base/anaconda3/envs/AInight/lib/python3.6/site-packages/keras/models.py\", line 20, in <module>\r\n>     from keras import metrics as metrics_module\r\n> \r\n>   File \"/home/base/anaconda3/envs/AInight/lib/python3.6/site-packages/keras/metrics.py\", line 26, in <module>\r\n>     from keras import activations\r\n> \r\n>   File \"/home/base/anaconda3/envs/AInight/lib/python3.6/site-packages/keras/activations.py\", line 20, in <module>\r\n>     from keras.layers import advanced_activations\r\n> \r\n>   File \"/home/base/anaconda3/envs/AInight/lib/python3.6/site-packages/keras/layers/__init__.py\", line 23, in <module>\r\n>     from keras.engine.input_layer import Input\r\n> \r\n>   File \"/home/base/anaconda3/envs/AInight/lib/python3.6/site-packages/keras/engine/input_layer.py\", line 21, in <module>\r\n>     from keras.engine import base_layer\r\n> \r\n>   File \"/home/base/anaconda3/envs/AInight/lib/python3.6/site-packages/keras/engine/base_layer.py\", line 43, in <module>\r\n>     from keras.mixed_precision import loss_scale_optimizer\r\n> \r\n>   File \"/home/base/anaconda3/envs/AInight/lib/python3.6/site-packages/keras/mixed_precision/loss_scale_optimizer.py\", line 257, in <module>\r\n>     class LossScaleOptimizer(tf.__internal__.tracking.DelegatingTrackableMixin,\r\n> \r\n> AttributeError: module 'tensorflow.compat.v2.__internal__.tracking' has no attribute 'DelegatingTrackableMixin'\r\n", "comments": ["@JanderHungrige ,\r\nCan you please take a look at this [comment](https://github.com/tensorflow/tensorflow/issues/51850#issuecomment-913445468) from the issue with similar error and let us know if you are facing same issue.Thanks", "Yes it is indeed. Thank you for your quick help.", "@JanderHungrige ,\r\n Glad the issue is resolved for you, please feel free to move this to closed status.Thanks!\r\n\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51992\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51992\">No</a>\n"]}, {"number": 51991, "title": "Add memory optimization flag in tf.config.optimizer.set_experimental_options", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.6 (latest)\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nMemory optimizer is not included in tf.config.optimizer.set_experimental_options [link](https://www.tensorflow.org/api_docs/python/tf/config/optimizer/set_experimental_options). We would like to have such useful control option. \r\nSome similar optimizers, such as shape optimization or loop optimization is already included, we guess it is possible to also have \"memory optimization\".\r\n\r\n**Will this change the current api? How?**\r\nIt will add a new option \"memory_optimizatior\" in tf.config.optimizer.set_experimental_options. \r\nUser can manually change the option.\r\n```\r\n tf.config.optimizer.set_experimental_options({'memory_optimizer': False})\r\n```\r\n\r\n**Who will benefit with this feature?**\r\nUsers who want to do some debug may turn off the memory optimization. It maybe helpful to figure out some issues.\r\n\r\n\r\n**Any Other info.**\r\n", "comments": ["Hi @Saduf2019 ,Could you please look at this feature request?", "@retonym \r\nPlease feel free to create a pr for the proposed change or share the link where the change is to be made.", "@Saduf2019 Sure. We will create the PR, once it is ready", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 51990, "title": "IndexError: tuple index out of range", "body": "![9](https://user-images.githubusercontent.com/26819449/133263607-e9733e7c-b6d5-4d11-87e2-8dbc740009c6.JPG)\r\n\r\n![9 1](https://user-images.githubusercontent.com/26819449/133263637-5905c37b-0c77-4ff9-a983-426e3aea5f9d.JPG)\r\n\r\n tensor flow = 2.2\r\n keras = 2.4.3\r\n \r\nI am not able to solve this error.\r\nCan you please tell me where should I refer?\r\nThanks!\r\n", "comments": ["@starboyvarun \r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!"]}, {"number": 51989, "title": "progress bar display error when calling model.evaluate method after a load_model or clone_model", "body": "progress bar display error when calling model.evaluate method after a load_model or clone_model\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): \r\nYes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): \r\nUbuntu 20.04.3 LTS (GNU/Linux 5.4.0-80-generic x86_64)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nNo\r\n- TensorFlow installed from (source or binary):\r\nBinary (pip install tensorflow==2.4)\r\n- TensorFlow version (use command below):\r\nv2.4.0-rc4-71-g582c8d236cb 2.4.0\r\n- Python version:\r\nPython 3.8.1\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\ncuda-11.2\r\ncudnn/11.0-v8.0.0\r\n- GPU model and memory:\r\nGeForce RTX 2070\r\n\r\n**Describe the current behavior**\r\nAfter a clone_model, or a load_model, the model.evaluate method doesn't display the same metrics results in progress_bar and in returned values (wrong ones in progress bar):\r\n\r\nresults = model_copy.evaluate(test_ds2)\r\nprint(results)\r\n\r\n40/40 [==============================] - 0s 1ms/step - loss: 0.1934 - accuracy: **0.9419**\r\n[0.16363045573234558, **0.9517999887466431**]\r\n\r\nIt seems that ProgbarLogger  stateful_metrics is not set for loss and metrics (here accuracy), due to a late assignment to self.model.metrics (tensorflow/python/keras/callbacks.py l.1047) leading to an average value display of these values instead of a single final value (tensorflow/python/keras/utils/generic_utils.py l.551)\r\n\r\n\r\n**Describe the expected behavior**\r\nThis behavior is different when the evaluate function is called after a fit call (which set the model.metrics) and lead to the right display\r\n40/40 [==============================] - 0s 1ms/step - loss: 0.1636 - acc: **0.9518**\r\n[0.16363045573234558, **0.9517999887466431**]\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\nNO, not sure to see where to handle this issue\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nfew lines codes with MNIST and simplest model.\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import backend as K\r\nfrom tensorflow.keras.layers import ReLU\r\nfrom tensorflow.keras.optimizers import Adam\r\nfrom tensorflow.keras import layers\r\n\r\n\r\nphysical_devices = tf.config.experimental.list_physical_devices('GPU')\r\ntf.config.experimental.set_memory_growth(physical_devices[0], True)\r\n\r\n\r\nfrom tensorflow.keras.datasets import mnist\r\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n\r\n\r\ndef prepare_data(x, y):\r\n    x=x.astype('float32')\r\n    y=y.astype('int32')\r\n    # convert from range int[0,255] to float32[-1,1]\r\n    x/=255\r\n    x = 2*x -1\r\n    x=x.reshape((-1,28,28,1))\r\n    y=tf.keras.utils.to_categorical(y,num_classes=10)\r\n    return x, y\r\n\r\n# prepare the data\r\nx_train, y_train = prepare_data(x_train, y_train)\r\nx_test, y_test = prepare_data(x_test, y_test)\r\n\r\n\r\nepochs = 2 #200\r\nbatch_size = 256\r\n\r\n##simplest model\r\nK.clear_session()\r\nmodel = tf.keras.Sequential([\r\n    layers.Flatten(),\r\n    layers.Dense(100),\r\n    layers.ReLU(),\r\n    layers.Dense(120),\r\n    layers.ReLU(),\r\n    layers.Dense(10)\r\n]\r\n)\r\n\r\nloss_function = tf.losses.CategoricalCrossentropy(from_logits=True)\r\noptimizer = Adam(lr=0.001)\r\nmodel.compile(loss=loss_function,optimizer=optimizer, metrics=['acc'])\r\n\r\n\r\nmodel.fit(x_train,y_train,batch_size=batch_size,epochs=epochs,validation_data=(x_test,y_test))\r\n\r\n\r\nprint(\"Run evaluate on test dataset\")\r\ntest_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\r\nresults = model.evaluate(test_ds)\r\nprint(results)\r\n\r\n##---------------------------\r\nprint(\"Cpy model \")\r\nmodel_copy= tf.keras.models.clone_model(model)\r\nmodel_copy.build((None, 28,28,1)) # replace 10 with number of variables in input layer\r\nmodel_copy.compile(loss=loss_function,optimizer=optimizer, metrics=[\"accuracy\"])\r\nmodel_copy.set_weights(model.get_weights())\r\n\r\nprint(\"Run evaluate with dataset on copied model\")\r\ntest_ds2 = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)\r\nresults = model_copy.evaluate(test_ds2)\r\nprint(results)  \r\n\r\n```\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@franckma31 ,\r\nI was able to run the mentioned code and get the same result in tf v2.6. Could you please create a virtual environment and test your code again. It helps. Thanks!\r\n", "Hi Tilakrayal, \r\nThanks for your answer.\r\nHere is a colab notebook that should reproduce the bug with tf==2.4\r\n\r\n[https://colab.research.google.com/drive/19_vQm5LeR82PiT7uZd20WyEtKo652D3p?usp=sharing](https://colab.research.google.com/drive/19_vQm5LeR82PiT7uZd20WyEtKo652D3p?usp=sharing)", "@franckma31 ,\r\nAs mentioned above can you please upgrade to latest stable tensorflow v2.6 which resolves the issue.Thanks!", "Yes I know that this issue is resolved in 2.5 and 2.6, but I do think that I'm not the only tensorflow user that, due to other lib dependencies, cannot upgrade to 2.5. \r\nAnd that means that tf users will report false accuracy just because they rely on the progbar information. TF 2.4 is only 9 months old, I thought that it was still maintained, and that this issue could help. Quite a bit disapointed.\r\n\r\nIf for you this is not an issue, please feel free to close it", "@franckma31 ,\r\nAs it was bug in tf v2.4, it has been resolved in latest stable version 2.6.Please upgrade to v2.6 and try to test your code.It helps.Thanks", "No comment. As I said even if on this simple example, you can verify on the colab that it does work on 2.6, for my project I can not upgrade to 2.6 and I do think that  such a bug should be fixed even for 2.4, it may lead to false results in publications, or industrial products. Regards", "@franckma31 \r\nAs there have been below changes and the issue is resolved in tf 2.6, upgrading would help as many bugs get fixed in later versions, in case is still remains an issue please open this in keras and move this issue to closed status.\r\n\r\nPlease post this issue on [keras-team/keras repo](https://github.com/keras-team/keras/issues).\r\nTo know more refer to:\r\nhttps://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51989\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51989\">No</a>\n"]}, {"number": 51987, "title": "Wrong wording of missing CPU instructions", "body": "Have a look at the code at https://github.com/tensorflow/tensorflow/blob/3d3c6db1ca2d50f6f07722cd800144f8f736167c/tensorflow/core/platform/cpu_feature_guard.cc#L150-L157\r\n\r\nThis outputs e.g. \r\n\r\n> This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n\r\nJudging from the naming `missing_instructions` I suppose there is a \"not\" missing in that warning.", "comments": ["This is correct wording. E.g. if CPU supports AVX2 but tensorflow is built without AVX2 support, AVX2 is in missing_instructions. Close this. OneDNN has dynamic instruction dispatch (thus can contain AVX2), but other parts of TF must be specifically built with AVX2.", "So a TensorFlow build without avx2 enabled which builds oneDNN alongside its build doesn't use avx2, but the oneDNN part does use it?\r\nIntresting...\r\nThen maybe the wording can be improved?", "@Flamefire,\r\n\r\nAs the wording is correct already, Can you suggest how the wording can be improved ? Thanks!", "\"The TensorFlow binaries were not build with the following CPU instruction sets: <...> To enable them rebuild ...\\n Note that oneDNN is used for various performance-critical operations and may dynamically use those CPU instructions sets nonetheless.\"\r\n\r\nOr so... And maybe make sure that oneDNN is actually used/built because I don't see any switch checking if oneDNN support is enabled around that message.", "@Flamefire,\r\n\r\nCan you submit a PR for updating this [file](https://github.com/tensorflow/tensorflow/blob/3d3c6db1ca2d50f6f07722cd800144f8f736167c/tensorflow/core/platform/cpu_feature_guard.cc#L150-L157) with the change you want to propose? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51987\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51987\">No</a>\n"]}, {"number": 51986, "title": "Cannot install tensorflow-macos", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac mini(M1) ver.12.0(Monterey)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.5.0\r\n- Python version: 3.9.7\r\n- Installed using virtualenv? pip? conda?: Conda and pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nI tried to install Tensorflow-metal by following [Getting Started with tensorflow-metal PluggableDevice](https://developer.apple.com/metal/tensorflow-plugin/).\r\n\r\nI was successful up to `conda install -c apple tensorflow-deps`,but error occurred in `python -m pip install tensorflow-macos`.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n```\r\n(Download Miniforge3-MacOSX-arm64.sh)\r\nchmod +x ~/Downloads/Miniforge3-MacOSX-arm64.sh\r\nsh ~/Downloads/Miniforge3-MacOSX-arm64.sh\r\nsource ~/miniforge3/bin/activate\r\n\r\nconda install -c apple tensorflow-deps\r\npython -m pip install tensorflow-macos\r\npython -m pip install tensorflow-metal\r\n```\r\n\r\n**Any other info / logs**\r\n\r\nerror file is [git hub gist](https://gist.github.com/tetuomi/66ff78288c81ff819f947b70746318e2#file-error-txt)\r\n", "comments": ["@tetuomi ,\r\nPlease refer to similar issues #44751,#47782 and for installation please take a look at this [link](https://github.com/apple/tensorflow_macos). It helps.", "@tilakrayal \r\nThanks for the response!\r\n\r\nI executed bellow command without error.\r\nmaybe succeed.\r\n```\r\npip install --upgrade -t   \"${VIRTUAL_ENV}/lib/python3.9/site-packages\" --no-dependencies --force tensorflow-macos\r\n```\r\n<br>\r\n<details>\r\n<summary>conda list</summary>\r\n\r\n# Name                    Version                   Build  Channel\r\n\r\nabsl-py                   0.10.0             pyhd8ed1ab_1    conda-forge\r\naiohttp                   3.7.4.post0      py39h5161555_0    conda-forge\r\nastunparse                1.6.3              pyhd8ed1ab_0    conda-forge\r\nasync-timeout             3.0.1                   py_1000    conda-forge\r\nattrs                     21.2.0             pyhd8ed1ab_0    conda-forge\r\nblinker                   1.4                        py_1    conda-forge\r\nbrotlipy                  0.7.0           py39h5161555_1001    conda-forge\r\nc-ares                    1.17.2               h3422bc3_0    conda-forge\r\nca-certificates           2021.5.30            h4653dfc_0    conda-forge\r\ncached-property           1.5.2                hd8ed1ab_1    conda-forge\r\ncached_property           1.5.2              pyha770c72_1    conda-forge\r\ncachetools                4.2.2              pyhd8ed1ab_0    conda-forge\r\ncertifi                   2021.5.30        py39h2804cbe_0    conda-forge\r\ncffi                      1.14.6           py39h52b1de0_1    conda-forge\r\nchardet                   4.0.0            py39h2804cbe_1    conda-forge\r\ncharset-normalizer        2.0.0              pyhd8ed1ab_0    conda-forge\r\nclick                     8.0.1            py39h2804cbe_0    conda-forge\r\ncolorama                  0.4.4              pyh9f0ad1d_0    conda-forge\r\ncryptography              3.4.7            py39h73257c9_0    conda-forge\r\ndataclasses               0.8                pyhc8e2a94_3    conda-forge\r\nflatbuffers               2.0.0                hbdafb3b_0    conda-forge\r\ngast                      0.4.0              pyh9f0ad1d_0    conda-forge\r\ngoogle-auth               1.35.0             pyh6c4a22f_0    conda-forge\r\ngoogle-auth-oauthlib      0.4.6              pyhd8ed1ab_0    conda-forge\r\ngoogle-pasta              0.2.0              pyh8c360ce_0    conda-forge\r\ngrpcio                    1.38.1           py39h9e1b6db_0    conda-forge\r\nh5py                      3.1.0           nompi_py39h99babb8_100    conda-forge\r\nhdf5                      1.10.6          nompi_h0fc092c_1114    conda-forge\r\nidna                      3.1                pyhd3deb0d_0    conda-forge\r\nimportlib-metadata        4.8.1            py39h2804cbe_0    conda-forge\r\nkeras                     2.6.0              pyhd8ed1ab_0    conda-forge\r\nkeras-preprocessing       1.1.2              pyhd8ed1ab_0    conda-forge\r\nkrb5                      1.19.2               hd92b7a7_0    conda-forge\r\nlibblas                   3.9.0           11_osxarm64_openblas    conda-forge\r\nlibcblas                  3.9.0           11_osxarm64_openblas    conda-forge\r\nlibclang                  11.1.0          default_h0fdd720_1    conda-forge\r\nlibcurl                   7.79.0               h8fe1914_0    conda-forge\r\nlibcxx                    12.0.1               h168391b_0    conda-forge\r\nlibedit                   3.1.20191231         hc8eb9b7_2    conda-forge\r\nlibev                     4.33                 h642e427_1    conda-forge\r\nlibffi                    3.4.2                hbdafb3b_1    conda-forge\r\nlibgfortran               5.0.0.dev0      11_0_1_hf114ba7_23    conda-forge\r\nlibgfortran5              11.0.1.dev0         hf114ba7_23    conda-forge\r\nliblapack                 3.9.0           11_osxarm64_openblas    conda-forge\r\nlibllvm11                 11.1.0               h93073aa_2    conda-forge\r\nlibnghttp2                1.43.0               hf3018f0_0    conda-forge\r\nlibopenblas               0.3.17          openmp_h5dd58f0_1    conda-forge\r\nlibprotobuf               3.18.0               hccf11d3_0    conda-forge\r\nlibssh2                   1.9.0                hb80f160_6    conda-forge\r\nllvm-openmp               12.0.1               hf3c4609_1    conda-forge\r\nmarkdown                  3.3.4              pyhd8ed1ab_0    conda-forge\r\nmultidict                 5.1.0            py39h5161555_1    conda-forge\r\nncurses                   6.2                  h9aa5885_4    conda-forge\r\nnumpy                     1.19.5           py39h1f3b974_2    conda-forge\r\noauthlib                  3.1.1              pyhd8ed1ab_0    conda-forge\r\nopenssl                   1.1.1l               h3422bc3_0    conda-forge\r\nopt_einsum                3.3.0              pyhd8ed1ab_1    conda-forge\r\npip                       21.2.4             pyhd8ed1ab_0    conda-forge\r\nprotobuf                  3.18.0           py39hfb83b0d_0    conda-forge\r\npyasn1                    0.4.8                      py_0    conda-forge\r\npyasn1-modules            0.2.7                      py_0    conda-forge\r\npycparser                 2.20               pyh9f0ad1d_2    conda-forge\r\npyjwt                     2.1.0              pyhd8ed1ab_0    conda-forge\r\npyopenssl                 20.0.1             pyhd8ed1ab_0    conda-forge\r\npysocks                   1.7.1            py39h2804cbe_3    conda-forge\r\npython                    3.9.7           h54d631c_1_cpython    conda-forge\r\npython_abi                3.9                      2_cp39    conda-forge\r\npyu2f                     0.1.5              pyhd8ed1ab_0    conda-forge\r\nreadline                  8.1                  hedafd6a_0    conda-forge\r\nrequests                  2.26.0             pyhd8ed1ab_0    conda-forge\r\nrequests-oauthlib         1.3.0              pyh9f0ad1d_0    conda-forge\r\nrsa                       4.7.2              pyh44b312d_0    conda-forge\r\nscipy                     1.7.0            py39h5060c3b_0    conda-forge\r\nsetuptools                58.0.4           py39h2804cbe_0    conda-forge\r\nsix                       1.15.0             pyh9f0ad1d_0    conda-forge\r\nsqlite                    3.36.0               h72a2b83_1    conda-forge\r\ntensorboard               2.6.0              pyhd8ed1ab_1    conda-forge\r\ntensorboard-data-server   0.6.0            py39hfb8cd70_0    conda-forge\r\ntensorboard-plugin-wit    1.8.0              pyh44b312d_0    conda-forge\r\n**tensorflow-deps           2.6.0                         0    apple\r\ntensorflow-macos          2.5.0                    pypi_0    pypi\r\ntensorflow-metal          0.1.2                    pypi_0    pypi**\r\ntermcolor                 1.1.0                      py_2    conda-forge\r\ntk                        8.6.11               he1e0b03_1    conda-forge\r\ntqdm                      4.62.2             pyhd8ed1ab_0    conda-forge\r\ntyping-extensions         3.7.4.3                       0    conda-forge\r\ntyping_extensions         3.7.4.3                    py_0    conda-forge\r\ntzdata                    2021a                he74cb21_1    conda-forge\r\nurllib3                   1.26.6             pyhd8ed1ab_0    conda-forge\r\nwerkzeug                  2.0.1              pyhd8ed1ab_0    conda-forge\r\nwheel                     0.35.1             pyh9f0ad1d_0    conda-forge\r\nwrapt                     1.12.1           py39h5161555_3    conda-forge\r\nxz                        5.2.5                h642e427_1    conda-forge\r\nyarl                      1.6.3            py39h5161555_2    conda-forge\r\nzipp                      3.5.0              pyhd8ed1ab_0    conda-forge\r\nzlib                      1.2.11            h31e879b_1009    conda-forge\r\n\r\n</details>\r\n\r\nI was able to use GPU, but test is slow(?)\r\n\r\n<details>\r\n<summary>Test code</summary>\r\n\r\n```\r\nimport tensorflow as tf\r\n#from tensorflow.python.compiler.mlcompute import mlcompute\r\n\r\ntf.compat.v1.disable_eager_execution()\r\n#mlcompute.set_mlc_device(device_name='gpu')\r\n#print(\"is_apple_mlc_enabled %s\" % mlcompute.is_apple_mlc_enabled())\r\n#print(\"is_tf_compiled_with_apple_mlc %s\" % mlcompute.is_tf_compiled_with_apple_mlc())\r\nprint(f\"eagerly? {tf.executing_eagerly()}\")\r\nprint(tf.config.list_logical_devices())\r\n\r\nfrom tensorflow.keras import datasets, layers, models\r\n\r\n(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\r\ntrain_images, test_images = train_images / 255.0, test_images / 255.0\r\nclass_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\r\n               'dog', 'frog', 'horse', 'ship', 'truck']\r\nmodel = models.Sequential()\r\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))\r\nmodel.add(layers.MaxPooling2D((2, 2)))\r\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\nmodel.add(layers.MaxPooling2D((2, 2)))\r\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\r\nmodel.add(layers.Flatten())\r\nmodel.add(layers.Dense(64, activation='relu'))\r\nmodel.add(layers.Dense(10))\r\nmodel.compile(optimizer='adam',\r\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n              metrics=['accuracy'])\r\nhistory = model.fit(train_images, train_labels, epochs=10,\r\n                    validation_data=(test_images, test_labels))\r\n```\r\n</details>\r\n\r\n\r\n<details>\r\n<summary>Output</summary>\r\n\r\n```\r\nInit Plugin\r\nInit Graph Optimizer\r\nInit Kernel\r\neagerly? False\r\nMetal device set to: Apple M1\r\n\r\nsystemMemory: 8.00 GB\r\nmaxCacheSize: 2.67 GB\r\n\r\n2021-09-17 10:31:05.072070: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\r\n2021-09-17 10:31:05.072453: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\r\n[LogicalDevice(name='/device:CPU:0', device_type='CPU'), LogicalDevice(name='/device:GPU:0', device_type='GPU')]\r\nTrain on 50000 samples, validate on 10000 samples\r\n2021-09-17 10:31:05.810489: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\r\n2021-09-17 10:31:05.810523: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\r\n2021-09-17 10:31:05.822293: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\r\n2021-09-17 10:31:05.823214: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\r\n2021-09-17 10:31:05.846792: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\r\n2021-09-17 10:31:05.911894: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\r\nEpoch 1/10\r\n2021-09-17 10:31:05.917312: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\r\n50000/50000 [==============================] - ETA: 0s - loss: 1.4909 - accuracy: 0.4600/Users/NAME/.local/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\r\n  warnings.warn('`Model.state_updates` will be removed in a future version. '\r\n2021-09-17 10:31:19.453811: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\r\n50000/50000 [==============================] - 15s 300us/sample - loss: 1.4909 - accuracy: 0.4600 - val_loss: 1.2483 - val_accuracy: 0.5509\r\nEpoch 2/10\r\n50000/50000 [==============================] - 14s 283us/sample - loss: 1.1333 - accuracy: 0.6020 - val_loss: 1.0202 - val_accuracy: 0.6373\r\nEpoch 3/10\r\n50000/50000 [==============================] - 14s 284us/sample - loss: 0.9841 - accuracy: 0.6535 - val_loss: 0.9950 - val_accuracy: 0.6497\r\nEpoch 4/10\r\n50000/50000 [==============================] - 14s 285us/sample - loss: 0.8839 - accuracy: 0.6910 - val_loss: 0.8935 - val_accuracy: 0.6936\r\nEpoch 5/10\r\n50000/50000 [==============================] - 14s 284us/sample - loss: 0.8092 - accuracy: 0.7140 - val_loss: 0.8907 - val_accuracy: 0.6943\r\nEpoch 6/10\r\n50000/50000 [==============================] - 14s 284us/sample - loss: 0.7508 - accuracy: 0.7363 - val_loss: 0.8767 - val_accuracy: 0.7036\r\nEpoch 7/10\r\n50000/50000 [==============================] - 14s 283us/sample - loss: 0.6978 - accuracy: 0.7538 - val_loss: 0.8459 - val_accuracy: 0.7169\r\nEpoch 8/10\r\n50000/50000 [==============================] - 14s 283us/sample - loss: 0.6538 - accuracy: 0.7708 - val_loss: 0.8494 - val_accuracy: 0.7113\r\nEpoch 9/10\r\n50000/50000 [==============================] - 14s 284us/sample - loss: 0.6114 - accuracy: 0.7847 - val_loss: 0.8723 - val_accuracy: 0.7148\r\nEpoch 10/10\r\n50000/50000 [==============================] - 14s 282us/sample - loss: 0.5738 - accuracy: 0.7961 - val_loss: 0.8718 - val_accuracy: 0.7182\r\n```\r\n</details>\r\n\r\n\r\n![image](https://user-images.githubusercontent.com/39522526/133710501-9405e0d6-fd2c-4cc9-9b36-a577457f884e.png)\r\n\r\nI wanted to run on CPU, so I uninstalled Tensorflow-metal.(```python -m pip uninstall Tensorflow-metal```)\r\nAccording to GPU History, did not use GPU.\r\n_Output_ and _Output on CPU_ are not so different.\r\nI don't think that I run properly on GPU.\r\n\r\n<details>\r\n<summary>Output on CPU</summary>\r\n\r\neagerly? False\r\n[LogicalDevice(name='/device:CPU:0', device_type='CPU')]\r\nTrain on 50000 samples, validate on 10000 samples\r\n2021-09-17 10:53:11.080971: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\r\nEpoch 1/10\r\n49984/50000 [============================>.] - ETA: 0s - loss: 2.0294 - accuracy: 0.2540/Users/NAME/.local/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\r\n  warnings.warn('`Model.state_updates` will be removed in a future version. '\r\n50000/50000 [==============================] - 14s 286us/sample - loss: 2.0293 - accuracy: 0.2540 - val_loss: 1.8248 - val_accuracy: 0.3404\r\nEpoch 2/10\r\n50000/50000 [==============================] - 15s 301us/sample - loss: 1.6499 - accuracy: 0.4058 - val_loss: 1.7012 - val_accuracy: 0.3879\r\nEpoch 3/10\r\n50000/50000 [==============================] - 16s 322us/sample - loss: 1.4730 - accuracy: 0.4674 - val_loss: 1.4277 - val_accuracy: 0.4839\r\nEpoch 4/10\r\n50000/50000 [==============================] - 17s 341us/sample - loss: 1.3658 - accuracy: 0.5095 - val_loss: 1.4735 - val_accuracy: 0.4736\r\nEpoch 5/10\r\n50000/50000 [==============================] - 17s 343us/sample - loss: 1.2800 - accuracy: 0.5431 - val_loss: 1.2749 - val_accuracy: 0.5413\r\nEpoch 6/10\r\n50000/50000 [==============================] - 16s 330us/sample - loss: 1.2105 - accuracy: 0.5713 - val_loss: 1.2096 - val_accuracy: 0.5618\r\nEpoch 7/10\r\n50000/50000 [==============================] - 16s 321us/sample - loss: 1.1456 - accuracy: 0.5956 - val_loss: 1.1682 - val_accuracy: 0.5827\r\nEpoch 8/10\r\n50000/50000 [==============================] - 16s 327us/sample - loss: 1.0915 - accuracy: 0.6166 - val_loss: 1.1136 - val_accuracy: 0.6054\r\nEpoch 9/10\r\n50000/50000 [==============================] - 16s 327us/sample - loss: 1.0422 - accuracy: 0.6350 - val_loss: 1.0747 - val_accuracy: 0.6213\r\nEpoch 10/10\r\n50000/50000 [==============================] - 15s 305us/sample - loss: 0.9947 - accuracy: 0.6507 - val_loss: 1.0297 - val_accuracy: 0.6369\r\n</details>", "I run the above Test code on Google CoLab.\r\nthe above output is not slow?\r\nAm I running on GPU properly?\r\n\r\n![image](https://user-images.githubusercontent.com/39522526/133716499-a6ee12a1-69d2-41d0-a36d-7d848073531e.png)\r\n", "@tetuomi ,\r\nGlad the suggestion worked for you.Please move this issue to closed status as it answers your above question and for any further queries please open a new issue from [here](https://github.com/tensorflow/models/issues/new/choose).Thanks!", "@tilakrayal \r\nOK. Thanks for helps!!!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51986\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51986\">No</a>\n"]}, {"number": 51985, "title": "[ROCm] Fix ROCm logger for kernel name", "body": "This PR fixes launch kernel name for logging in ROCm.", "comments": []}, {"number": 51984, "title": "[MLIR][TF][SCF] Introduce tf.IfRegion -> scf.if lowering", "body": "Lowering for `tf.IfRegion` -> `scf.if` implemented in a new pass\r\n`convert-tf-control-flow-to-scf`, which is added in\r\n`tensorflow/transforms` and can be used for all direct control flow\r\nlowerings from the TensorFlow dialect to the SCF dialect (without going\r\nthrough dialects like HLO, which involve tuples, for example). Currently\r\nthis pass has one pattern `ConvertIfRegionOp`. It lowers the\r\n`tf.IfRegion` op to `scf.if`.\r\n\r\nSigned-off-by: Srishti Srivastava <srishti.srivastava@polymagelabs.com>", "comments": ["Thanks for the contribution! \r\n\r\nFYI: using MHLO does not have to involve tuples (actually we'd like to remove them from MHLO entirely).\r\n\r\nI'm curious about the plan for this new directory: what's the motivation and what about the redundancy with the other paths (through MHLO and TOSA)?\r\n\r\nMaybe this was discussed elsewhere and I missed it? (Feel free to post a pointer then)\r\n", "> Thanks for the contribution!\r\n> \r\n> FYI: using MHLO does not have to involve tuples (actually we'd like to remove them from MHLO entirely).\r\n> \r\n> I'm curious about the plan for this new directory: what's the motivation and what about the redundancy with the other paths (through MHLO and TOSA)?\r\n> \r\n> Maybe this was discussed elsewhere and I missed it? (Feel free to post a pointer then)\r\n\r\nHi. A path through MHLO (which is currently using tuples) exists but it involves tupling and then detupling. So, the motivation for this PR is to have a direct path from the `tensorflow` dialect to the `SCF` dialect in order to avoid this overhead.", "> > Thanks for the contribution!\r\n> > FYI: using MHLO does not have to involve tuples (actually we'd like to remove them from MHLO entirely).\r\n> > I'm curious about the plan for this new directory: what's the motivation and what about the redundancy with the other paths (through MHLO and TOSA)?\r\n> > Maybe this was discussed elsewhere and I missed it? (Feel free to post a pointer then)\r\n> \r\n> Hi. A path through MHLO (which is currently using tuples) exists but it involves tupling and then detupling. So, the motivation for this PR is to have a direct path from the `tensorflow` dialect to the `SCF` dialect in order to avoid this overhead.\r\n\r\n@bondhugula , maybe you can elaborate more on this, if I have missed something?", "Are you concerned with the runtime performance with the \u201coverhead\u201d here?\r\nI\u2019m a bit worried about redundant code paths in the codebase, which is why I\u2019m trying to identify the elements to balance here.", "> with the runtime performance with the \u201coverhead\u201d here?\r\n\r\nYes, runtime performance.", "I\u2019m interested to look deeper into the MHLO path instead: do you have an example we can walk through?", "> I\u2019m interested to look deeper into the MHLO path instead: do you have an example we can walk through?\r\n\r\nSure. Let's look at the `tf.If` op in the function @testValidConvertIfOp1 of this PR.", "> Are you concerned with the runtime performance with the \u201coverhead\u201d here?\r\n> I\u2019m a bit worried about redundant code paths in the codebase, which is why I\u2019m trying to identify the elements to balance here.\r\n\r\nA `tf.if` to `scf.if` lowering (and similarly `tf.while` to `scf.while`) would appear to be the natural path towards code generation or further lowering without any abrupt drop in abstraction. Both the TF and SCF dialect ops on `if` and `while` do not use any tuples and there isn't a need to go through intermediate dialects. The lowering path going through TOSA could naturally make use of this as both TOSA and SCF dialects are present upstream - so you get a self-contained upstream target to convert these to. @silvasean had earlier reported on a similar conversion of Torch `if` ops to scf.if for example which was also natural.\r\n\r\n", "@srishti-pm Can you get rid of the merge commit from your PR and have your changes in a single commit?", "\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F51984) for more info**.\n\n<!-- need_sender_cla -->", "@joker-eph, can you please review this PR?", "> @joker-eph, can you please review this PR?\r\n\r\nBefore looking at the code, I'm trying to wrap my head around the direction here. This PR does not fit into the existing paths (it is quite visible by adding a top-level directory in compiler/mlir), so I'm cautious here. I'll try to get back to this this week, but ping me on Monday if you don't hear back.", "> > @joker-eph, can you please review this PR?\r\n> \r\n> Before looking at the code, I'm trying to wrap my head around the direction here. This PR does not fit into the existing paths (it is quite visible by adding a top-level directory in compiler/mlir), so I'm cautious here. I'll try to get back to this this week, but ping me on Monday if you don't hear back.\r\n\r\nHi @joker-eph, pinging you for reviewing this!", "Ok, let's integrate this into `tensorflow/compiler/mlir/tensorflow/transforms/...` instead of a top-level here.\r\nAlso I think the code will be simple if you place it after the `-tf-functional-control-flow-to-regions`: the control flow will already be expressed with region.", "> Ok, let's integrate this into `tensorflow/compiler/mlir/tensorflow/transforms/...` instead of a top-level here.\r\n> Also I think the code will be simple if you place it after the `-tf-functional-control-flow-to-regions`: the control flow will already be expressed with region.\r\n\r\nSure, I'll do this.", "@joker-eph , I have addressed your comments and modified my task goal and implementation accordingly.\r\n\r\n1. Instead of converting `tf.If` to `scf.if`, I am converting `tf.IfRegion` to `scf.if`.\r\n2. Instead of having a new directory for the `SCF` dialect, I have added my pass in `tensorflow/transforms`", "@joker-eph , I have addressed all your comments given on this PR.", "@joker-eph , the PR is ready for review again !", "Thanks @srishti-pm !\r\n\r\nThis will get into our automation for merging, you don't need to do anything else now (assuming the bots manage to pass all the tests).", "> Thanks @srishti-pm !\r\n> \r\n> This will get into our automation for merging, you don't need to do anything else now (assuming the bots manage to pass all the tests).\r\n\r\nGreat, thanks @joker-eph !", "Sorry for the delay, this got stuck in the automation. I just unblock it and it resumes its flow in the pipeline. I expect this to get merged tomorrow.", "CI is complaining right now with:\r\n```\r\nthird_party/tensorflow/compiler/mlir/tensorflow/transforms/convert_tf_control_flow_to_scf.cc:49:12: error: unused variable 'scfYield' [-Werror,-Wunused-variable]\r\n      auto scfYield = rewriter.create<scf::YieldOp>(currentTerminator->getLoc(),\r\n           ^\r\nthird_party/tensorflow/compiler/mlir/tensorflow/transforms/convert_tf_control_flow_to_scf.cc:95:5: error: ignoring return value of function declared with 'nodiscard' attribute [-Werror,-Wunused-result]\r\n    applyPatternsAndFoldGreedily(getOperation(), std::move(patterns));\r\n    ^~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n```", "(You also need to rebase)", "> CI is complaining right now with:\r\n> \r\n> ```\r\n> third_party/tensorflow/compiler/mlir/tensorflow/transforms/convert_tf_control_flow_to_scf.cc:49:12: error: unused variable 'scfYield' [-Werror,-Wunused-variable]\r\n>       auto scfYield = rewriter.create<scf::YieldOp>(currentTerminator->getLoc(),\r\n>            ^\r\n> third_party/tensorflow/compiler/mlir/tensorflow/transforms/convert_tf_control_flow_to_scf.cc:95:5: error: ignoring return value of function declared with 'nodiscard' attribute [-Werror,-Wunused-result]\r\n>     applyPatternsAndFoldGreedily(getOperation(), std::move(patterns));\r\n>     ^~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n> ```\r\n\r\n@joker-eph , I have addressed these issues and resolved the conflict by rebasing.", "> > with the runtime performance with the \u201coverhead\u201d here?\r\n> \r\n> Yes, runtime performance.\r\n\r\nRuntime as in of the generated code? Or of the compiler? (and also is that if you decide to lower all to MHLO first before doing the conversion to SCF vs just doing it for control flow ops?)", "> > > with the runtime performance with the \u201coverhead\u201d here?\r\n> > \r\n> > \r\n> > Yes, runtime performance.\r\n> \r\n> Runtime as in of the generated code? Or of the compiler? (and also is that if you decide to lower all to MHLO first before doing the conversion to SCF vs just doing it for control flow ops?)\r\n\r\nOf the compiler.", "@joker-eph @jpienaar, I have addressed all the comments given on the PR:\r\n1. Modified the variable naming style.\r\n2. Removed extraneous information from the pass description in the `.td` file.", "Thanks @joker-eph :)", "Sure! Sorry it took so long... We'll do better next time :)", "> Sure! Sorry it took so long... We'll do better next time :)\r\n\r\nDefinitely !"]}, {"number": 51983, "title": "How to reduce time of Host-side TensorFlow operations(_Send, _HostSend) in GPU reference", "body": "Dear all,\r\n       When I do a simple model refence on GPU, it seems that the kernel launch time is much more significant than compute time(kernel launch nearly 90% to overall). Accoring to the profiler result, the Host-side TensorFlow operations such as _Send and _HostSend type  seems to be the problem. Is there any solution to this problem?\r\n\r\nEnv: tensorflow2.2.0 + cuda10.1\r\n\r\nThanks,\r\nAsher\r\n\r\nPS:\r\noverview_page:\r\n![\u56fe\u7247](https://user-images.githubusercontent.com/51115601/133186394-887ad5d5-f0cc-40e8-818d-e4b8e8b74b1b.png)\r\ntensorflow_stats:\r\n![\u56fe\u7247](https://user-images.githubusercontent.com/51115601/133186502-0679d674-fb30-4574-b526-a4c879ce778a.png)\r\n", "comments": ["Hi @AsherXian903 ,Could you please share a stand alone code to reproduce this issue as it will help expedite the issue!", "Here is the model:\r\n[saved_model.tar.gz](https://github.com/tensorflow/tensorflow/files/7166175/saved_model.tar.gz)\r\n\r\nHere is the code:\r\n```\r\nBATCH_SIZE = 10\r\nLOOP_CNT = 10\r\ndef predict():\r\n    print(\"predict\")\r\n    with tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.4))) as sess:\r\n      # First load the SavedModel into the session\r\n      model_dir = \"./model_dir\"\r\n      tf.compat.v1.saved_model.loader.load(\r\n          sess, [tf.saved_model.SERVING],\r\n          model_dir)\r\n      op_1 = sess.graph.get_tensor_by_name('user/logits/BiasAdd:0')\r\n      op_2 = sess.graph.get_tensor_by_name('bias:0')\r\n      input_schema = [\"interest_category_all:0\", \"location_code2:0\", \"from:0\", \"os_version:0\", \"gender:0\", \"wm:0\", \"login_freq_num:0\", \"os_br\r\nand:0\", \"platform_type:0\", \"interest_word_all:0\", \"lift_state_all:0\", \"age:0\"]\r\n      empty_list_10 = [\"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\", \"\"]\r\n      input_data = [2*empty_list_10, \"30804\", \"10B5395010\", \"92210000\", \"402\", \"20005_0002\", \"30\", \"90103000\", \"android\", [\"\u7f8e\u98df\", \"\u8fd0\u52a8\", \">\r\n\u7f8e\u98df\u535a\u4e3b\", \"\u5403\", \"\u5065\u8eab\", \"\u8fd0\u52a8\u5065\u8eab\", \"\u5065\u8eab\u8fd0\u52a8\", \"\u5065\u8eab\u8fbe\u4eba\", \"\u98df\", \"\u751f\u6d3b\", \"\u51cf\u80a5\", \"\u597d\u5403\u7684\", \"\u840c\u5ba0\", \"\u6599\u7406\", \"\u7f8e\u5973\", \"\u8863\u670d\", \"\u5ba0\u7269\", \"\u52a8\u6f2b\",\r\n\"\u5403\u7684\", \"\u7626\u8eab\", \"\u98df\u7269\", \"\u5403\u559d\u73a9\u4e50\", \"\u52a8\u7269\", \"\u7f51\u7ea2\", \"\u53a8\u623f\"], empty_list_10, \"1025\"]\r\n      input_tensor = {}\r\n      for i in range(0, len(input_schema)):\r\n        input_tensor[sess.graph.get_tensor_by_name(input_schema[i])] = []\r\n        for j in range(0, BATCH_SIZE):\r\n          input_tensor[sess.graph.get_tensor_by_name(input_schema[i])].append(np.reshape(input_data[i], (-1)).tolist())\r\n      print(\"start local predict\")\r\n      t0 = time.time()\r\n      tf.profiler.experimental.start('logdir')\r\n      for i in range(0, LOOP_CNT):\r\n        ret = sess.run([op_1, op_2], feed_dict=input_tensor)\r\n      tf.profiler.experimental.stop()\r\n      print(time.time() - t0, \"seconds process time\")\r\n      print(\"end local predict\")\r\n```", "Hi @AsherXian903 ,Could you please check again with TF 2.5/2.6  ? please share a stand alone code for  model.fit() operation  to check above performance parameters  .I checked the above code though, It ran fine in TF 2.6 in colab . providing [Gist ](https://colab.research.google.com/gist/mohantym/b9af2378dd1de2a65c06fa488a529fc7/github_51983.ipynb)for reference", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 51982, "title": "[oneDNN] BatchMatMulV2+Mul+AddV2 fusion with oneDNN CPU backend", "body": "This PR does a fusion of BatchMatMulV2 + Mul + AddV2 with oneDNN CPU backend using grappler remapper optimizer. Such pattern is common in Transformer based language models. It improves inference performance for higher batch sizes.", "comments": ["@mdfaijul Can you please resolve conflicts? Thanks!", "@gbaned Resolved conflicts, thanks!", "@penpornk Thank you very much for the comments. I have addressed those. Please check.", "@penpornk Could you please let me know what is failed as shown `Google internal checks FAILED`?"]}, {"number": 51981, "title": "OSError: SavedModel file does not exist but I never explicitly saved a model", "body": "I am trying to load a model from a URL with hub.load, but TF is trying to find a saved version of the model on my computer, even though I never saved the model.\r\n\r\nWhen I did this the very first time, it worked no problem and loaded the model from the URL. But I believe now it's not working because it's looking for some sort of cached model file that doesn't actually exist. Note that I'm running this in a Jupyter notebook.\r\n\r\nAny ideas how to solve this? Below find my code and traceback error.\r\n\r\n`module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"`\r\n`model = hub.load(module_url)`\r\n\r\nOSError                                   Traceback (most recent call last)\r\n<ipython-input-5-51e1a5214226> in <module>\r\n    198 \r\n    199 module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\r\n--> 200 model = hub.load(module_url)\r\n    201 #def embed(input):\r\n    202 #    return model(input)\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow_hub/module_v2.py in load(handle, tags, options)\r\n    104         module_path, tags=tags, options=options)\r\n    105   else:\r\n--> 106     obj = tf.compat.v1.saved_model.load_v2(module_path, tags=tags)\r\n    107   obj._is_hub_module_v1 = is_hub_module_v1  # pylint: disable=protected-access\r\n    108   return obj\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py in load(export_dir, tags, options)\r\n    862   \"\"\"\r\n    863   metrics.IncrementReadApi(_LOAD_V2_LABEL)\r\n--> 864   result = load_internal(export_dir, tags, options)[\"root\"]\r\n    865   metrics.IncrementRead()\r\n    866   return result\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py in load_internal(export_dir, tags, options, loader_cls, filters)\r\n    876     tags = nest.flatten(tags)\r\n    877   saved_model_proto, debug_info = (\r\n--> 878       loader_impl.parse_saved_model_with_debug_info(export_dir))\r\n    879 \r\n    880   if (len(saved_model_proto.meta_graphs) == 1 and\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/saved_model/loader_impl.py in parse_saved_model_with_debug_info(export_dir)\r\n     58     parsed. Missing graph debug info file is fine.\r\n     59   \"\"\"\r\n---> 60   saved_model = _parse_saved_model(export_dir)\r\n     61 \r\n     62   debug_info_path = os.path.join(\r\n\r\n~/anaconda3/lib/python3.7/site-packages/tensorflow/python/saved_model/loader_impl.py in parse_saved_model(export_dir)\r\n    119         \"SavedModel file does not exist at: %s%s{%s|%s}\" %\r\n    120         (export_dir, os.path.sep, constants.SAVED_MODEL_FILENAME_PBTXT,\r\n--> 121          constants.SAVED_MODEL_FILENAME_PB))\r\n    122 \r\n    123 \r\n\r\nOSError: SavedModel file does not exist at: /var/folders/6z/8r9107bj20dcmrqn9kp8l2n40000gp/T/tfhub_modules/063d866c06683311b44b4992fd46003be952409c/{saved_model.pbtxt|saved_model.pb}\r\n\r\n", "comments": ["@bensilver95 \r\nCan you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Please refer to the [link1](https://stackoverflow.com/questions/62358745/oserror-savedmodel-file-does-not-exist-at-c-users-munib-new-folder-saved-mod),[ link2](https://github.com/tensorflow/tensorflow/issues/22480) and let us know if it helps? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 51980, "title": "revert PR #47351 (doesn't work)", "body": "PR 47351 doesn't work as expected. The `msvc_cl_debug` condition would need to be checked against the toolchain, not against the compiler switch, e.g. like this:\r\n```\r\nselects.config_setting_group(\r\n++    name = \"msvc_cl_debug\",\r\n++    match_all = [\r\n++        \"@bazel_tools//src/conditions:windows_msvc\",\r\n++        \":debug\",\r\n++    ],\r\n++    visibility = [\"//visibility:public\"],\r\n++)\r\n```\r\nBut even a fix like this would not lead to the desired outcome because `bazel` will add `/DEBUG:FULL` in `dbg` mode after `/DEBUG:FASTBUILD` and thus override it. The only way to compile with `/DEBUG:FASTBUILD` is using `--compilation_mode=fastbuild` or `--compilation_mode=dbg --features=fastbuild`. So PR 47351 is not necessary. Thus revert it.", "comments": []}, {"number": 51979, "title": "How can I use tf.config.experimental.VirtualDeviceConfiguration and keras.model.fit together", "body": "I am trying to use tf.config.experimental.VirtualDeviceConfiguration to let my model run faster.\r\nMy original model was built like this method:\r\n```python\r\n\r\ndef deepfm_model(xxx):\r\n    \u00b7\u00b7\u00b7\u00b7\u00b7\u00b7\r\n\r\ntf.config.set_soft_device_placement(True)\r\ntf.debugging.set_log_device_placement(True)\r\n\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\nif gpus:\r\n  try:\r\n    tf.config.experimental.set_virtual_device_configuration(\r\n        gpus[0],\r\n        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096),\r\n         tf.config.experimental.VirtualDeviceConfiguration(memory_limit=4096)])\r\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\r\n    print(len(gpus), \"Physical GPU,\", len(logical_gpus), \"Logical GPUs\")\r\n\r\nstrategy = tf.distribute.MirroredStrategy()\r\ndataset=xxx\r\ndataset = strategy.experimental_distribute_dataset(dataset)\r\n\r\nmodel = deepfm_model(inputs, outputs)\r\nmodel.compile(optimizer=\"adam\", loss=\"mse\", metrics=[xxx])\r\nmodel.fit(dataset, epochs=10, verbose=0,use_multiprocessing=True,workers=2,)\r\n```\r\n\r\nwhen I  set_log_device_placement,I saw model has been build in both 2 Vgpus,but only one gpu use for compute:\r\n\r\n```\r\n2021-09-12 18:17:38.908813: I tensorflow/core/common_runtime/placer.cc:114] Identity_76: (Identity): /job:localhost/replica:0/task:0/device:CPU:0\r\nFakeSink0: (Identity): /job:localhost/replica:0/task:0/device:CPU:0\r\n2021-09-12 18:17:38.908821: I tensorflow/core/common_runtime/placer.cc:114] FakeSink0: (Identity): /job:localhost/replica:0/task:0/device:CPU:0\r\nFakeSink1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0\r\n2021-09-12 18:17:38.908829: I tensorflow/core/common_runtime/placer.cc:114] FakeSink1: (Identity): /job:localhost/replica:0/task:0/device:CPU:0\r\nFakeSink2: (Identity): /job:localhost/replica:0/task:0/device:CPU:0\r\n2021-09-12 18:17:38.908837: I tensorflow/core/common_runtime/placer.cc:114] FakeSink2: (Identity): /job:localhost/replica:0/task:0/device:CPU:0\r\nFakeSink3: (Identity): /job:localhost/replica:0/task:0/device:CPU:0\r\n2021-09-12 18:17:38.908844: I tensorflow/core/common_runtime/placer.cc:114] FakeSink3: (Identity): /job:localhost/replica:0/task:0/device:CPU:0\r\n```\r\n\r\nCan I have an example to see how can I use tf.config.experimental.VirtualDeviceConfiguration\r\nin tf.keras like  model.compile && model.fit   method?\r\n\r\nMy model is simple and I want to use a vgpu to improve its computational efficiency\uff0cthank you", "comments": ["@somelaoda ,\r\nCan you please  limit your [gpu](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth) and try, also try on upgraded tf as in 2.6 the stable version and see if it helps.Thanks!", "I've set it up tf.config.set_soft_device_placement(True)\r\nand VirtualDeviceConfiguration(memory_limit=4096)\r\n\r\nFor now, tf 2.6 remains the same question=\u3002=", "@somelaoda ,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code and dataset to reproduce the issue reported here.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51979\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51979\">No</a>\n"]}, {"number": 51978, "title": "\"Unimplemented:  Deterministic GPU implementation of unsorted segment reduction op not available\" with AUC metric and TF_DETERMINISTIC_OPS", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): OpenSUSE LEAP 15.2\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.6.0-rc2-32-g919f693420e 2.6.0\r\n- Python version: Python 3.9.6\r\n- CUDA/cuDNN version: 11.2 and 8.1.1, I believe\r\n- GPU model and memory: Quadro RTX 6000\r\n\r\nReproduces on Colab with GPU.\r\n\r\n**Describe the current behavior**\r\n\r\n```\r\nTraceback (most recent call last):\r\n[...]\r\n  File \"/home/bers/proj/bug.py\", line 12, in <module>\r\n    model.fit(x=data, y=data)\r\n  File \"/data2/bers/opt/pyenv/versions/3.9.6/lib/python3.9/site-packages/keras/engine/training.py\", line 1184, in fit\r\n    tmp_logs = self.train_function(iterator)\r\n  File \"/data2/bers/opt/pyenv/versions/3.9.6/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\", line 885, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/data2/bers/opt/pyenv/versions/3.9.6/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py\", line 950, in _call\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"/data2/bers/opt/pyenv/versions/3.9.6/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3039, in __call__\r\n    return graph_function._call_flat(\r\n  File \"/data2/bers/opt/pyenv/versions/3.9.6/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 1963, in _call_flat\r\n    return self._build_call_outputs(self._inference_function.call(\r\n  File \"/data2/bers/opt/pyenv/versions/3.9.6/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 591, in call\r\n    outputs = execute.execute(\r\n  File \"/data2/bers/opt/pyenv/versions/3.9.6/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\", line 59, in quick_execute\r\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\ntensorflow.python.framework.errors_impl.UnimplementedError: 2 root error(s) found.\r\n  (0) Unimplemented:  Deterministic GPU implementation of unsorted segment reduction op not available.\r\n\t [[node UnsortedSegmentSum (defined at home/bers/proj/bug.py:12) ]]\r\n\t [[assert_less_equal/Assert/AssertGuard/pivot_f/_13/_39]]\r\n  (1) Unimplemented:  Deterministic GPU implementation of unsorted segment reduction op not available.\r\n\t [[node UnsortedSegmentSum (defined at home/bers/proj/bug.py:12) ]]\r\n0 successful operations.\r\n0 derived errors ignored. [Op:__inference_train_function_513]\r\n\r\nFunction call stack:\r\ntrain_function -> train_function\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nNo error (works in TF 2.5.0)\r\n\r\n**Standalone code to reproduce the issue**\r\n```python\r\nimport os\r\n\r\nos.environ[\"TF_DETERMINISTIC_OPS\"] = \"True\"\r\n\r\nimport tensorflow as tf\r\n\r\ndata = tf.ones((1, 1))\r\nlayer = tf.keras.layers.Input(shape=[1])\r\nmodel = tf.keras.models.Model(inputs=layer, outputs=layer)\r\nmodel.compile(loss=\"categorical_crossentropy\", metrics=\"AUC\")\r\nmodel.fit(x=data, y=data)\r\n```\r\n", "comments": ["Hi @bersbersbers ! I could not  replicate the issue in Stable version [2.5](https://colab.research.google.com/gist/mohantym/2269d888b8eb38da4a564023327fa800/github_51978.ipynb#scrollTo=fTqv7A-IlDek) ,[2.6](https://colab.research.google.com/gist/mohantym/7e3a1d7e67fa1d1cfc193afe779710d7/github_51978.ipynb) and 2.6rc2.0 and [nightly ](https://colab.research.google.com/gist/mohantym/5120ec9094a96646004e02ed134b908e/github_51978.ipynb#scrollTo=Lsq-8jz6lXAI)though. Can you please post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999) . Thanks! ", "@mohamedadaly as I said, you need to test using GPU:\r\nEdit - Notebook settings - Hardware accelerator - GPU, Save.\r\n\r\nThen, you can repro in Colab:\r\n![image](https://user-images.githubusercontent.com/12128514/133073490-f8548fa1-cda3-4fdd-bdba-017e5d54b7e9.png)\r\n\r\n\r\nCan you transfer this issue to keras-team/keras?", "Same issue in https://github.com/tensorflow/tensorflow/issues/51466", "@edwardyehuang correct. That bug has no repro steps, however, so my guess is that that issue should be merged into this issue.", "ok @bersbersbers , Is the issue still replicating ? Feel to free to close this issue if it helped.", "> \r\n> \r\n> ok @bersbersbers , Is the issue still replicating ? Feel to free to close this issue if it helped.\r\n\r\nIssue 51466 also did not have a solution.\r\n\r\nSince TensorFlow 2.5, when TF_DETERMINISTIC_OPS  = 1, calling any of non-deterministic ops (if there is no deterministic implementation ) will raise an \"UnimplementedError\", this is the root cause (https://github.com/tensorflow/community/blob/master/rfcs/20210119-determinism.md)\r\n\r\nI think TensorFlow should allows user to use deterministic ops and non-deterministic ops togther (mixed mode ?), before all ops has a deterministic implementation.\r\n\r\n", "@pkanwar23 Will you please look into the issue?", "@mohantym \n> ok @bersbersbers , Is the issue still replicating ?\n\nYes it is. It was working in TF2.5 and fails in TF2.6.", "Ok! @bersbersbers , Could you see the comment at this [issue1](https://github.com/tensorflow/tensorflow/issues/39751)  ,[issue2](https://stackoverflow.com/questions/50744565/how-to-handle-non-determinism-when-training-on-a-gpu/50746919#50746919) and try again after editing the code like below.\r\n\r\n\r\n```\r\nimport os\r\nos.environ[\"TF_DETERMINISTIC_OPS\"] = \"True\"\r\n\r\nimport tensorflow as tf\r\nseed=1441# any random number\r\ntf.random.set_seed(seed)\r\ndata = tf.ones((1, 1))\r\nlayer = tf.keras.layers.Input(shape=[1])\r\nmodel = tf.keras.models.Model(inputs=layer, outputs=layer)\r\nmodel.compile(loss=\"categorical_crossentropy\", metrics=\"AUC\")\r\nmodel.fit(x=data, y=data)\r\n\r\n```", "@mohantym as you can easily test yourself on Colab, this code raises the same issue (after correcting `seed==1441` to `seed=1441`).", "> Ok! @bersbersbers , Could you see the comment at this [issue1](https://github.com/tensorflow/tensorflow/issues/39751) ,[issue2](https://stackoverflow.com/questions/50744565/how-to-handle-non-determinism-when-training-on-a-gpu/50746919#50746919) and try again after editing the code like below.\r\n> \r\n> ```\r\n> import os\r\n> os.environ[\"TF_DETERMINISTIC_OPS\"] = \"True\"\r\n> \r\n> import tensorflow as tf\r\n> seed==1441# any random number\r\n> tf.random.set_seed(seed)\r\n> data = tf.ones((1, 1))\r\n> layer = tf.keras.layers.Input(shape=[1])\r\n> model = tf.keras.models.Model(inputs=layer, outputs=layer)\r\n> model.compile(loss=\"categorical_crossentropy\", metrics=\"AUC\")\r\n> model.fit(x=data, y=data)\r\n> ```\r\n\r\nMy issue is solved with TF_DISABLE_SEGMENT_REDUCTION_OP_DETERMINISM_EXCEPTIONS = 1", "Please try again with python 3.8/python 3.7 .  Hey @sanatmpa1 ,Could you please look at this issue!", "@mohantym I already said in https://github.com/tensorflow/tensorflow/issues/51978#issuecomment-918809168 that your corrected code reproduces the issue. There is no point in me trying again.\r\n\r\nAs also said before, it repros on Colab which *is* using Python 3.7 already. So there is point in trying again with Python 3.8/3.7, either.", "> My issue is solved with TF_DISABLE_SEGMENT_REDUCTION_OP_DETERMINISM_EXCEPTIONS = 1\r\n\r\nThis works for me, too:\r\n\r\n```python\r\nimport os\r\n\r\nos.environ[\"TF_DETERMINISTIC_OPS\"] = \"True\"\r\nos.environ[\"TF_DISABLE_SEGMENT_REDUCTION_OP_DETERMINISM_EXCEPTIONS\"] = \"True\"\r\n\r\nimport tensorflow as tf\r\n\r\ndata = tf.ones((1, 1))\r\nlayer = tf.keras.layers.Input(shape=[1])\r\nmodel = tf.keras.models.Model(inputs=layer, outputs=layer)\r\nmodel.compile(loss=\"categorical_crossentropy\", metrics=\"AUC\")\r\nmodel.fit(x=data, y=data)\r\n```\r\n\r\nHowever, I wonder: setting `TF_DISABLE_SEGMENT_REDUCTION_OP_DETERMINISM_EXCEPTIONS` was not necessary in `tensorflow==2.5.1`. So what has changed?\r\n- Was the AUC metric non-deterministic in `tensorflow==2.5.1`, and a missing exception was added in `tensorflow==2.6.0` to make users aware of that fact?\r\n- Was the AUC metric deterministic in `tensorflow==2.5.1`, and this is a regression in `tensorflow==2.6.0`?", "This is fixed with https://github.com/tensorflow/tensorflow/pull/51861, and the fix will be in TF 2.7.\r\n\r\nI'm unsure if the AUC metric was nondeterministic in TF 2.5. It used `tf.math.unsorted_segment_sum`, which was nondeterminsitic in certain cases, but it's possible AUC did not use it in a nondeterministic way. The exception for `unsorted_segment_sum` was added in TF 2.6, but `unsorted_segment_sum` was nondeterministic before that in certain cases. In any case, this is now fixed, so it's not worth looking into.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51978\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51978\">No</a>\n", "Verified, thank you all!"]}, {"number": 51977, "title": "ValueError: The first argument to `Layer.call` must always be passed.", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@Minhthien1122 \r\nIn order to expedite the trouble-shooting process,Can you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose).please provide a code snippet to reproduce the issue reported here. Please refer to the similar[ issue](https://stackoverflow.com/questions/61884398/getting-this-error-in-my-custom-layer-using-layer-subclassing-in-tensorflow-2-0) and let us know if it helps? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51977\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/51977\">No</a>\n"]}, {"number": 51976, "title": "Bump tensorflow-io-gcs-filesystem to 0.21.0", "body": "This PR bumps tensorflow-io-gcs-filesystem to 0.21.0 so that TF 2.7\r\nbranch cut can carry the latest change which includes the fix that removes the extra\r\nbuild directory in the python pip package (https://github.com/tensorflow/io/pull/1497)\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["@mihaimaruseac Wondering if you can take a look at this PR. It will be great if this PR can be part of the 2.7 branch as it does fixes an issue in pip packages (tensorflow/io#1497)", "Sorry, I was OOO.\r\n\r\nCan you make a cherry-pick once this lands, please?", "Please add me to the cherrypick to review and get approved before a release on 2.7 branch", "Thanks @mihaimaruseac for the help. The PR of cherry-pick has been created in #52267"]}, {"number": 51975, "title": "Fix crash of max_pool3d when ksize is 0 or negative", "body": "This PR tries to address the issue raised in #51936 where\r\nmax_pool3d will crash when any dim of ksize is 0 or negative.\r\n\r\nWhile the original issue was raised toward tf.keras.layers.MaxPooling3D,\r\nthe issue can also be triggered when max_pool3d is called directly\r\nwith tensorflow itself.\r\n\r\nFor that reason a separate fix inside tensorflow is also fixed here.\r\n\r\nThis PR fixes #51936.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 51974, "title": "How to extract the weight and bias from GRU and feed to a GRUcell layers?", "body": "Hi ,  I find that in pytorch, there are ways to extract  the bias and weights from a trained GRU layers and apply them to a GRUcell as follows:\r\n\r\n    def get_gru_cell(self, gru): \r\n        gru_cell = nn.GRUCell(gru.input_size, gru.hidden_size)\r\n        gru_cell.weight_hh.data = gru.weight_hh_l0.data\r\n        gru_cell.weight_ih.data = gru.weight_ih_l0.data\r\n        gru_cell.bias_hh.data = gru.bias_hh_l0.data\r\n        gru_cell.bias_ih.data = gru.bias_ih_l0.data\r\n        return gru_cell\r\n\r\nwhere gru param is a trained pytorch's GRU layers(nn.GRU).\r\nI want to know how to rewrite this implementation by Tensorflow2.3?\r\nFor example I try to rewrite it in TF2 as follows:\r\n\r\n    def get_gru_cell(self, gru):\r\n        gru_cell = tf.keras.layers.GRUCell(gru.units)\r\n        gru_cell.set_weights(gru.get_weights())\r\n        return gru_cell\r\n\r\nBut I get value_error:\r\nValueError: You called `set_weights(weights)` on layer \"gru_cell_2\" with a weight list of length 3, but the layer was expecting 0 weights. Provided weights: [array([[-0.017596  , -0.01114826, -0.05229527, .....\r\n\r\nCan anyone tell me how to rewrite it correctly? Thanks!", "comments": ["Ok , I find that I should build layer and give a input shape before do layers.set_weights(), which is different from Pytorch.\r\nBecause I have solved the problem, I close this issue."]}]