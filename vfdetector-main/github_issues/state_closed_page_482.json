[{"number": 39334, "title": "value error raised whern calling export_saved_model() with estimator model", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux CentOS\r\n- TensorFlow version (use command below): TensorFlow 2.0 CPU | v2.0.0-rc2-26-g64c3d38 2.0.0\r\n- Python version: python3.6\r\n- CUDA/cuDNN version: None\r\n- GPU model and memory: None\r\n\r\n## Value Error raised whern calling `export_saved_model()` with estimator model\r\nI am trying to export my trained estimator model for serving. The estimator model was converted from keras model with `tf.keras.estimator.model_to_estimator`, and I have successfully trained and evaluated it. However, when I am trying to save the model to local disk for serving,  a bug just bothered me... the codes and the logs are as listed below: \r\n\r\n## codes\r\n```python\r\nmodel_estimator = tf.keras.estimator.model_to_estimator(keras_model=model)\r\n# ...\r\nmodel_estimator.train(input_fn=dataset_func, steps=STEPS_PER_EPOCH)\r\nmodel_estimator.evaluate(input_fn=dataset_func, steps=STEPS_PER_EPOCH)\r\n# ...\r\nmodel_estimator.export_saved_model(model_path, serving_input_fn) # bug comes from here\r\n```\r\n## log for Error info\r\n```python\r\nINFO:tensorflow:Calling model_fn.\r\n[2020-05-09 13:20:56] - estimator.py[line:1147] - INFO: Calling model_fn.\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py in _apply_op_helper(self, op_type_name, name, **keywords)\r\n    470                 preferred_dtype=default_dtype,\r\n--> 471                 as_ref=input_arg.is_ref)\r\n    472             if input_arg.number_attr and len(\r\n\r\n/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py in internal_convert_n_to_tensor(values, dtype, name, as_ref, preferred_dtype, ctx)\r\n   1364             preferred_dtype=preferred_dtype,\r\n-> 1365             ctx=ctx))\r\n   1366   return ret\r\n\r\n/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx, accept_composite_tensors)\r\n   1270           \"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\" %\r\n-> 1271           (dtype.name, value.dtype.name, value))\r\n   1272     return value\r\n\r\nValueError: Tensor conversion requested dtype int64 for Tensor with dtype float32: <tf.Tensor 'no_mask_4_115/no_mask_4/Identity:0' shape=(None, 1) dtype=float32>\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-76-01ac33b3b8f1> in <module>\r\n----> 1 model_estimator.export_saved_model(model_path, serving_input_fn)\r\n\r\n/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py in export_saved_model(self, export_dir_base, serving_input_receiver_fn, assets_extra, as_text, checkpoint_path, experimental_mode)\r\n    733         as_text=as_text,\r\n    734         checkpoint_path=checkpoint_path,\r\n--> 735         strip_default_attrs=True)\r\n    736 \r\n    737   def experimental_export_all_saved_models(\r\n\r\n/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py in _export_all_saved_models(self, export_dir_base, input_receiver_fn_map, assets_extra, as_text, checkpoint_path, strip_default_attrs)\r\n    856             builder, input_receiver_fn_map, checkpoint_path,\r\n    857             save_variables, mode=ModeKeys.PREDICT,\r\n--> 858             strip_default_attrs=strip_default_attrs)\r\n    859         save_variables = False\r\n    860 \r\n\r\n/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py in _add_meta_graph_for_mode(self, builder, input_receiver_fn_map, checkpoint_path, save_variables, mode, export_tags, check_variables, strip_default_attrs)\r\n    929           labels=getattr(input_receiver, 'labels', None),\r\n    930           mode=mode,\r\n--> 931           config=self.config)\r\n    932 \r\n    933       export_outputs = export_lib.export_outputs_for_mode(\r\n\r\n/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/estimator.py in _call_model_fn(self, features, labels, mode, config)\r\n   1146 \r\n   1147     logging.info('Calling model_fn.')\r\n-> 1148     model_fn_results = self._model_fn(features=features, **kwargs)\r\n   1149     logging.info('Done calling model_fn.')\r\n   1150 \r\n\r\n/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/keras.py in model_fn(features, labels, mode)\r\n    286         features=features,\r\n    287         labels=labels,\r\n--> 288         optimizer_config=optimizer_config)\r\n    289     model_output_names = []\r\n    290     # We need to make sure that the output names of the last layer in the model\r\n\r\n/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/keras.py in _clone_and_build_model(mode, keras_model, custom_objects, features, labels, optimizer_config)\r\n    225       in_place_reset=(not keras_model._is_graph_network),\r\n    226       optimizer_iterations=global_step,\r\n--> 227       optimizer_config=optimizer_config)\r\n    228 \r\n    229   if sample_weight_tensors is not None:\r\n\r\n/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/models.py in clone_and_build_model(model, input_tensors, target_tensors, custom_objects, compile_clone, in_place_reset, optimizer_iterations, optimizer_config)\r\n    632         clone = clone_model(model, input_tensors=input_tensors)\r\n    633     else:\r\n--> 634       clone = clone_model(model, input_tensors=input_tensors)\r\n    635 \r\n    636     if all([isinstance(clone, Sequential),\r\n\r\n/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/models.py in clone_model(model, input_tensors, clone_function)\r\n    420   else:\r\n    421     return _clone_functional_model(\r\n--> 422         model, input_tensors=input_tensors, layer_fn=clone_function)\r\n    423 \r\n    424 \r\n\r\n/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/models.py in _clone_functional_model(model, input_tensors, layer_fn)\r\n    193   input_tensors, output_tensors, created_layers = (\r\n    194       network.reconstruct_from_config(model_config,\r\n--> 195                                       created_layers=created_layers))\r\n    196   metrics_names = model.metrics_names\r\n    197   model = Model(input_tensors, output_tensors, name=model.name)\r\n\r\n/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py in reconstruct_from_config(config, custom_objects, created_layers)\r\n   1850       if layer in unprocessed_nodes:\r\n   1851         for node_data in unprocessed_nodes.pop(layer):\r\n-> 1852           process_node(layer, node_data)\r\n   1853 \r\n   1854   input_tensors = []\r\n\r\n/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py in process_node(layer, node_data)\r\n   1797       if not isinstance(input_tensors, dict) and len(flat_input_tensors) == 1:\r\n   1798         input_tensors = flat_input_tensors[0]\r\n-> 1799       output_tensors = layer(input_tensors, **kwargs)\r\n   1800 \r\n   1801       # Update node index map.\r\n\r\n/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    845                     outputs = base_layer_utils.mark_as_return(outputs, acd)\r\n    846                 else:\r\n--> 847                   outputs = call_fn(cast_inputs, *args, **kwargs)\r\n    848 \r\n    849             except errors.OperatorNotAllowedInGraphError as e:\r\n\r\n/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/merge.py in call(self, inputs)\r\n    180         return y\r\n    181     else:\r\n--> 182       return self._merge_function(inputs)\r\n    183 \r\n    184   @tf_utils.shape_type_conversion\r\n\r\n/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/layers/merge.py in _merge_function(self, inputs)\r\n    392 \r\n    393   def _merge_function(self, inputs):\r\n--> 394     return K.concatenate(inputs, axis=self.axis)\r\n    395 \r\n    396   @tf_utils.shape_type_conversion\r\n\r\n/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/keras/backend.py in concatenate(tensors, axis)\r\n   2706     return sparse_ops.sparse_concat(axis, tensors)\r\n   2707   else:\r\n-> 2708     return array_ops.concat([to_dense(x) for x in tensors], axis)\r\n   2709 \r\n   2710 \r\n\r\n/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/util/dispatch.py in wrapper(*args, **kwargs)\r\n    178     \"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\r\n    179     try:\r\n--> 180       return target(*args, **kwargs)\r\n    181     except (TypeError, ValueError):\r\n    182       # Note: convert_to_eager_tensor currently raises a ValueError, not a\r\n\r\n/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/array_ops.py in concat(values, axis, name)\r\n   1429           dtype=dtypes.int32).get_shape().assert_has_rank(0)\r\n   1430       return identity(values[0], name=name)\r\n-> 1431   return gen_array_ops.concat_v2(values=values, axis=axis, name=name)\r\n   1432 \r\n   1433 \r\n\r\n/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_array_ops.py in concat_v2(values, axis, name)\r\n   1255   _attr_N = len(values)\r\n   1256   _, _, _op = _op_def_lib._apply_op_helper(\r\n-> 1257         \"ConcatV2\", values=values, axis=axis, name=name)\r\n   1258   _result = _op.outputs[:]\r\n   1259   _inputs_flat = _op.inputs\r\n\r\n/usr/local/anaconda3/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py in _apply_op_helper(self, op_type_name, name, **keywords)\r\n    497                                 (prefix, dtype.name))\r\n    498               else:\r\n--> 499                 raise TypeError(\"%s that don't all match.\" % prefix)\r\n    500             else:\r\n    501               raise TypeError(\r\n\r\nTypeError: Tensors in list passed to 'values' of 'ConcatV2' Op have types [int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, float32, float32, float32, float32, float32, float32, float32, float32, float32, float32, float32, float32, float32, float32, float32, float32, float32, float32, float32, float32, float32, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, float32, float32, float32, float32, float32, float32, float32, int64, int64, int64, int64, int64, int64, int64, float32, float32, float32, float32, float32, float32, float32, float32, float32, float32, float32, float32, float32, float32, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, float32, float32, float32, float32, float32, float32, float32, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, float32, float32, float32, float32, float32, float32, float32, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64, int64] that don't all match.\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39334\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39334\">No</a>\n"]}, {"number": 39333, "title": "master build error(windows10)", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): N/A\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64 1909\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): master 2.2.0\r\n- Python version: 3.8.2\r\n- Bazel version (if compiling from source): 3.1.0\r\n- GCC/Compiler version (if compiling from source): Visual Studio 2019  compiler\r\n- CUDA/cuDNN version: 10.2/7.6.5\r\n- GPU model and memory: RTX2080Ti GDDR6 11GB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nbazel build\r\n\r\n**Describe the expected behavior**\r\nsuccess as always\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n1. ./configure ( and set to user cuda 10.2 and cudnn 7.6.5 )\r\n2. bazel build --define=no_tensorflow_py_deps=true --copt=-nvcc_options=disable-warnings //tensorflow/tools/pip_package:build_pip_package\r\n\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n```\r\nExecution platform: @local_execution_config_platform//:platform\r\n.\\tensorflow/core/kernels/cuda_sparse.h(39): error: identifier \"cusparseDnMatDescr_t\" is undefined\r\n\r\n.\\tensorflow/core/kernels/cuda_sparse.h(40): error: identifier \"cusparseSpMatDescr_t\" is undefined\r\n\r\n.\\tensorflow/core/kernels/cuda_sparse.h(41): error: identifier \"cusparseSpMMAlg_t\" is undefined\r\n\r\n3 errors detected in the compilation of \"C:/Users/ALAN-W~1/AppData/Local/Temp/nvcc_inter_files_tmp_dir/tmp4sztyoaw/kernels_gpu.cu.cpp1.ii\".\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n```", "comments": ["@alanpurple,\r\nCould you please provide the exact sequence of commands / steps that you executed before running into the problem. Thanks!", "@amahendrakar \r\nupdated", "Got the same error using CUDA10.2. They are probably not compatible.", "@amahendrakar \r\nanother error ( May 12th 2020)\r\n\r\n\r\n```\r\nERROR: D:/repo/tensorflow/tensorflow/core/kernels/BUILD:3674:1: C++ compilation of rule '//tensorflow/core/kernels:determinant_op_gpu' failed (Exit 1): python.exe failed: error executing command\r\n  cd C:/users/alan-workstation/_bazel_alan-workstation/ibqopsat/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.2\r\n    SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.25.28610\\ATLMFC\\include;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.25.28610\\include;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\winrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\cppwinrt\r\n    SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.25.28610\\ATLMFC\\lib\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.25.28610\\lib\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\lib\\um\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.18362.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.18362.0\\um\\x64;\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.25.28610\\bin\\HostX64\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\VC\\VCPackages;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\TeamFoundation\\Team Explorer;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\MSBuild\\Current\\bin\\Roslyn;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Team Tools\\Performance Tools\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Team Tools\\Performance Tools;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\vs2019\\\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\vs2019\\;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.8 Tools\\x64\\;C:\\Program Files (x86)\\HTML Help Workshop;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\FSharp\\;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\10.0.18362.0\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\\\MSBuild\\Current\\Bin;C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\Tools\\;;C:\\WINDOWS\\system32;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\CMake\\bin;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\Ninja;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\VC\\Linux\\bin\\ConnectionManagerExe\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=C:/Anaconda3/python.exe\r\n    SET PYTHON_LIB_PATH=C:/Anaconda3/lib/site-packages\r\n    SET RUNFILES_MANIFEST_ONLY=1\r\n    SET TEMP=C:\\Users\\ALAN-W~1\\AppData\\Local\\Temp\r\n    SET TF2_BEHAVIOR=1\r\n    SET TF_CONFIGURE_IOS=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=7.5\r\n    SET TF_ENABLE_XLA=1\r\n    SET TF_NEED_CUDA=1\r\n    SET TMP=C:\\Users\\ALAN-W~1\\AppData\\Local\\Temp\r\n  C:/Anaconda3/python.exe -B external/local_config_cuda/crosstool/windows/msvc_wrapper_for_nvcc.py /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /bigobj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/bin /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/local_config_sycl /Ibazel-out/x64_windows-opt/bin/external/local_config_sycl /Iexternal/nsync /Ibazel-out/x64_windows-opt/bin/external/nsync /Iexternal/gif /Ibazel-out/x64_windows-opt/bin/external/gif /Iexternal/libjpeg_turbo /Ibazel-out/x64_windows-opt/bin/external/libjpeg_turbo /Iexternal/com_google_protobuf /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf /Iexternal/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/bin/external/com_googlesource_code_re2 /Iexternal/farmhash_archive /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive /Iexternal/fft2d /Ibazel-out/x64_windows-opt/bin/external/fft2d /Iexternal/highwayhash /Ibazel-out/x64_windows-opt/bin/external/highwayhash /Iexternal/zlib /Ibazel-out/x64_windows-opt/bin/external/zlib /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/snappy /Ibazel-out/x64_windows-opt/bin/external/snappy /Iexternal/local_config_cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda /Iexternal/local_config_tensorrt /Ibazel-out/x64_windows-opt/bin/external/local_config_tensorrt /Iexternal/mkl_dnn /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn /Iexternal/curl /Ibazel-out/x64_windows-opt/bin/external/curl /Iexternal/boringssl /Ibazel-out/x64_windows-opt/bin/external/boringssl /Iexternal/jsoncpp_git /Ibazel-out/x64_windows-opt/bin/external/jsoncpp_git /Iexternal/aws /Ibazel-out/x64_windows-opt/bin/external/aws /Iexternal/aws-c-common /Ibazel-out/x64_windows-opt/bin/external/aws-c-common /Iexternal/aws-c-event-stream /Ibazel-out/x64_windows-opt/bin/external/aws-c-event-stream /Iexternal/aws-checksums /Ibazel-out/x64_windows-opt/bin/external/aws-checksums /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cublas_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cudnn_header /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/nsync/public /Ibazel-out/x64_windows-opt/bin/external/nsync/public /Iexternal/gif /Ibazel-out/x64_windows-opt/bin/external/gif /Iexternal/gif/windows /Ibazel-out/x64_windows-opt/bin/external/gif/windows /Iexternal/com_google_protobuf/src /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf/src /Iexternal/farmhash_archive/src /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive/src /Iexternal/zlib /Ibazel-out/x64_windows-opt/bin/external/zlib /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda /Iexternal/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/include /Iexternal/local_config_cuda/cuda/cublas/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cublas/include /Iexternal/mkl_dnn/include /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/include /Iexternal/mkl_dnn/src /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src /Iexternal/mkl_dnn/src/common /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/common /Iexternal/mkl_dnn/src/cpu /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu /Iexternal/mkl_dnn/src/cpu/gemm /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu/gemm /Iexternal/mkl_dnn/src/cpu/xbyak /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu/xbyak /Iexternal/curl/include /Ibazel-out/x64_windows-opt/bin/external/curl/include /Iexternal/boringssl/src/include /Ibazel-out/x64_windows-opt/bin/external/boringssl/src/include /Iexternal/jsoncpp_git/include /Ibazel-out/x64_windows-opt/bin/external/jsoncpp_git/include /Iexternal/aws/aws-cpp-sdk-core/include /Ibazel-out/x64_windows-opt/bin/external/aws/aws-cpp-sdk-core/include /Iexternal/aws/aws-cpp-sdk-s3/include /Ibazel-out/x64_windows-opt/bin/external/aws/aws-cpp-sdk-s3/include /Iexternal/aws/aws-cpp-sdk-transfer/include /Ibazel-out/x64_windows-opt/bin/external/aws/aws-cpp-sdk-transfer/include /Iexternal/aws-c-common/include /Ibazel-out/x64_windows-opt/bin/external/aws-c-common/include /Iexternal/aws-c-event-stream/include /Ibazel-out/x64_windows-opt/bin/external/aws-c-event-stream/include /Iexternal/aws-checksums/include /Ibazel-out/x64_windows-opt/bin/external/aws-checksums/include /DTENSORFLOW_USE_CUSTOM_CONTRACTION_KERNEL /DTENSORFLOW_USE_MKLDNN_CONTRACTION_KERNEL /DCURL_STATICLIB /DPLATFORM_WINDOWS /DENABLE_CURL_CLIENT /DOPENSSL_IS_BORINGSSL /DTF_USE_SNAPPY /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /DEIGEN_HAS_TYPE_TRAITS=0 /D__CLANG_SUPPORT_DYN_ANNOTATION__ /showIncludes /MD /O2 /DNDEBUG /w /D_USE_MATH_DEFINES -DWIN32_LEAN_AND_MEAN -DNOGDI -nvcc_options=disable-warnings /std:c++14 -x cuda -DGOOGLE_CUDA=1 --cuda-gpu-arch=sm_75 -DGOOGLE_CUDA=1 -DTENSORFLOW_USE_NVCC=1 -DTENSORFLOW_USE_XLA=1 -DTENSORFLOW_MONOLITHIC_BUILD /DPLATFORM_WINDOWS /DEIGEN_HAS_C99_MATH /DTENSORFLOW_USE_EIGEN_THREADPOOL /DEIGEN_AVOID_STL_ARRAY /Iexternal/gemmlowp /wd4018 /wd4577 /DNOGDI /DTF_COMPILE_LIBRARY -nvcc_options=relaxed-constexpr -nvcc_options=ftz=true /Fobazel-out/x64_windows-opt/bin/tensorflow/core/kernels/_objs/determinant_op_gpu/determinant_op_gpu.cu.o /c tensorflow/core/kernels/determinant_op_gpu.cu.cc\r\nExecution platform: @local_execution_config_platform//:platform\r\nThe command line is too long.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 689.653s, Critical Path: 78.32s\r\nINFO: 1861 processes: 1861 local.\r\nFAILED: Build did NOT complete successfully\r\n```", "> _Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template_\r\n> \r\n> **System information**\r\n> \r\n> * Have I written custom code (as opposed to using a stock example script provided in TensorFlow): N/A\r\n> * OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 x64 1909\r\n> * Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n> * TensorFlow installed from (source or binary): source\r\n> * TensorFlow version (use command below): master 2.2.0\r\n> * Python version: 3.8.2\r\n> * Bazel version (if compiling from source): 3.1.0\r\n> * GCC/Compiler version (if compiling from source): Visual Studio 2019  compiler\r\n> * CUDA/cuDNN version: 10.2/7.6.5\r\n> * GPU model and memory: RTX2080Ti GDDR6 11GB\r\n> \r\n> You can collect some of this information using our environment capture\r\n> [script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\n> You can also obtain the TensorFlow version with:\r\n> \r\n> 1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n> 2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n> \r\n> **Describe the current behavior**\r\n> bazel build\r\n> \r\n> **Describe the expected behavior**\r\n> success as always\r\n> \r\n> **Standalone code to reproduce the issue**\r\n> Provide a reproducible test case that is the bare minimum necessary to generate\r\n> the problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n> \r\n> 1. ./configure ( and set to user cuda 10.2 and cudnn 7.6.5 )\r\n> 2. bazel build --define=no_tensorflow_py_deps=true --copt=-nvcc_options=disable-warnings //tensorflow/tools/pip_package:build_pip_package\r\n> \r\n> **Other info / logs** Include any logs or source code that would be helpful to\r\n> diagnose the problem. If including tracebacks, please include the full\r\n> traceback. Large logs and files should be attached.\r\n> \r\n> ```\r\n> Execution platform: @local_execution_config_platform//:platform\r\n> .\\tensorflow/core/kernels/cuda_sparse.h(39): error: identifier \"cusparseDnMatDescr_t\" is undefined\r\n> \r\n> .\\tensorflow/core/kernels/cuda_sparse.h(40): error: identifier \"cusparseSpMatDescr_t\" is undefined\r\n> \r\n> .\\tensorflow/core/kernels/cuda_sparse.h(41): error: identifier \"cusparseSpMMAlg_t\" is undefined\r\n> \r\n> 3 errors detected in the compilation of \"C:/Users/ALAN-W~1/AppData/Local/Temp/nvcc_inter_files_tmp_dir/tmp4sztyoaw/kernels_gpu.cu.cpp1.ii\".\r\n> Target //tensorflow/tools/pip_package:build_pip_package failed to build\r\n> ```\r\n\r\nGot the same error, windows 10, Cuda 10.2\r\nI think the problem lies in these files that are downloaded separately\r\n```\r\n#include \"third_party/gpus/cuda/include/cuda.h\"\r\n#include \"third_party/gpus/cuda/include/cusparse.h\"\r\n```", "Meanwhile I managed to build version 2.2.0rc4 with basel 2 without any problems", "@yarik1988 \r\n\r\n2.2.0 branch has no problem, this issue is about master branch", "Can you do a bisect on master branch to identify a commit where the build stops breaking?", "> @amahendrakar\r\n> another error ( May 12th 2020)\r\n> \r\n> ```\r\n> ERROR: D:/repo/tensorflow/tensorflow/core/kernels/BUILD:3674:1: C++ compilation of rule '//tensorflow/core/kernels:determinant_op_gpu' failed (Exit 1): python.exe failed: error executing command\r\n>   cd C:/users/alan-workstation/_bazel_alan-workstation/ibqopsat/execroot/org_tensorflow\r\n>   SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.2\r\n>     SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.25.28610\\ATLMFC\\include;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.25.28610\\include;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\winrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\cppwinrt\r\n>     SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.25.28610\\ATLMFC\\lib\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.25.28610\\lib\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\lib\\um\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.18362.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.18362.0\\um\\x64;\r\n>     SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.25.28610\\bin\\HostX64\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\VC\\VCPackages;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\TeamFoundation\\Team Explorer;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\MSBuild\\Current\\bin\\Roslyn;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Team Tools\\Performance Tools\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Team Tools\\Performance Tools;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\vs2019\\\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\vs2019\\;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.8 Tools\\x64\\;C:\\Program Files (x86)\\HTML Help Workshop;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\FSharp\\;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\10.0.18362.0\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\\\MSBuild\\Current\\Bin;C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\Tools\\;;C:\\WINDOWS\\system32;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\CMake\\bin;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\Ninja;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\VC\\Linux\\bin\\ConnectionManagerExe\r\n>     SET PWD=/proc/self/cwd\r\n>     SET PYTHON_BIN_PATH=C:/Anaconda3/python.exe\r\n>     SET PYTHON_LIB_PATH=C:/Anaconda3/lib/site-packages\r\n>     SET RUNFILES_MANIFEST_ONLY=1\r\n>     SET TEMP=C:\\Users\\ALAN-W~1\\AppData\\Local\\Temp\r\n>     SET TF2_BEHAVIOR=1\r\n>     SET TF_CONFIGURE_IOS=0\r\n>     SET TF_CUDA_COMPUTE_CAPABILITIES=7.5\r\n>     SET TF_ENABLE_XLA=1\r\n>     SET TF_NEED_CUDA=1\r\n>     SET TMP=C:\\Users\\ALAN-W~1\\AppData\\Local\\Temp\r\n>   C:/Anaconda3/python.exe -B external/local_config_cuda/crosstool/windows/msvc_wrapper_for_nvcc.py /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /bigobj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/bin /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/bin/external/com_google_absl /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/local_config_sycl /Ibazel-out/x64_windows-opt/bin/external/local_config_sycl /Iexternal/nsync /Ibazel-out/x64_windows-opt/bin/external/nsync /Iexternal/gif /Ibazel-out/x64_windows-opt/bin/external/gif /Iexternal/libjpeg_turbo /Ibazel-out/x64_windows-opt/bin/external/libjpeg_turbo /Iexternal/com_google_protobuf /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf /Iexternal/com_googlesource_code_re2 /Ibazel-out/x64_windows-opt/bin/external/com_googlesource_code_re2 /Iexternal/farmhash_archive /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive /Iexternal/fft2d /Ibazel-out/x64_windows-opt/bin/external/fft2d /Iexternal/highwayhash /Ibazel-out/x64_windows-opt/bin/external/highwayhash /Iexternal/zlib /Ibazel-out/x64_windows-opt/bin/external/zlib /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/snappy /Ibazel-out/x64_windows-opt/bin/external/snappy /Iexternal/local_config_cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda /Iexternal/local_config_tensorrt /Ibazel-out/x64_windows-opt/bin/external/local_config_tensorrt /Iexternal/mkl_dnn /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn /Iexternal/curl /Ibazel-out/x64_windows-opt/bin/external/curl /Iexternal/boringssl /Ibazel-out/x64_windows-opt/bin/external/boringssl /Iexternal/jsoncpp_git /Ibazel-out/x64_windows-opt/bin/external/jsoncpp_git /Iexternal/aws /Ibazel-out/x64_windows-opt/bin/external/aws /Iexternal/aws-c-common /Ibazel-out/x64_windows-opt/bin/external/aws-c-common /Iexternal/aws-c-event-stream /Ibazel-out/x64_windows-opt/bin/external/aws-c-event-stream /Iexternal/aws-checksums /Ibazel-out/x64_windows-opt/bin/external/aws-checksums /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cuda_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/local_config_tensorrt/_virtual_includes/tensorrt_headers /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cublas_headers_virtual /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/_virtual_includes/cudnn_header /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/nsync/public /Ibazel-out/x64_windows-opt/bin/external/nsync/public /Iexternal/gif /Ibazel-out/x64_windows-opt/bin/external/gif /Iexternal/gif/windows /Ibazel-out/x64_windows-opt/bin/external/gif/windows /Iexternal/com_google_protobuf/src /Ibazel-out/x64_windows-opt/bin/external/com_google_protobuf/src /Iexternal/farmhash_archive/src /Ibazel-out/x64_windows-opt/bin/external/farmhash_archive/src /Iexternal/zlib /Ibazel-out/x64_windows-opt/bin/external/zlib /Iexternal/double_conversion /Ibazel-out/x64_windows-opt/bin/external/double_conversion /Iexternal/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda /Iexternal/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/include /Iexternal/local_config_cuda/cuda/cublas/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cublas/include /Iexternal/mkl_dnn/include /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/include /Iexternal/mkl_dnn/src /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src /Iexternal/mkl_dnn/src/common /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/common /Iexternal/mkl_dnn/src/cpu /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu /Iexternal/mkl_dnn/src/cpu/gemm /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu/gemm /Iexternal/mkl_dnn/src/cpu/xbyak /Ibazel-out/x64_windows-opt/bin/external/mkl_dnn/src/cpu/xbyak /Iexternal/curl/include /Ibazel-out/x64_windows-opt/bin/external/curl/include /Iexternal/boringssl/src/include /Ibazel-out/x64_windows-opt/bin/external/boringssl/src/include /Iexternal/jsoncpp_git/include /Ibazel-out/x64_windows-opt/bin/external/jsoncpp_git/include /Iexternal/aws/aws-cpp-sdk-core/include /Ibazel-out/x64_windows-opt/bin/external/aws/aws-cpp-sdk-core/include /Iexternal/aws/aws-cpp-sdk-s3/include /Ibazel-out/x64_windows-opt/bin/external/aws/aws-cpp-sdk-s3/include /Iexternal/aws/aws-cpp-sdk-transfer/include /Ibazel-out/x64_windows-opt/bin/external/aws/aws-cpp-sdk-transfer/include /Iexternal/aws-c-common/include /Ibazel-out/x64_windows-opt/bin/external/aws-c-common/include /Iexternal/aws-c-event-stream/include /Ibazel-out/x64_windows-opt/bin/external/aws-c-event-stream/include /Iexternal/aws-checksums/include /Ibazel-out/x64_windows-opt/bin/external/aws-checksums/include /DTENSORFLOW_USE_CUSTOM_CONTRACTION_KERNEL /DTENSORFLOW_USE_MKLDNN_CONTRACTION_KERNEL /DCURL_STATICLIB /DPLATFORM_WINDOWS /DENABLE_CURL_CLIENT /DOPENSSL_IS_BORINGSSL /DTF_USE_SNAPPY /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /DEIGEN_HAS_TYPE_TRAITS=0 /D__CLANG_SUPPORT_DYN_ANNOTATION__ /showIncludes /MD /O2 /DNDEBUG /w /D_USE_MATH_DEFINES -DWIN32_LEAN_AND_MEAN -DNOGDI -nvcc_options=disable-warnings /std:c++14 -x cuda -DGOOGLE_CUDA=1 --cuda-gpu-arch=sm_75 -DGOOGLE_CUDA=1 -DTENSORFLOW_USE_NVCC=1 -DTENSORFLOW_USE_XLA=1 -DTENSORFLOW_MONOLITHIC_BUILD /DPLATFORM_WINDOWS /DEIGEN_HAS_C99_MATH /DTENSORFLOW_USE_EIGEN_THREADPOOL /DEIGEN_AVOID_STL_ARRAY /Iexternal/gemmlowp /wd4018 /wd4577 /DNOGDI /DTF_COMPILE_LIBRARY -nvcc_options=relaxed-constexpr -nvcc_options=ftz=true /Fobazel-out/x64_windows-opt/bin/tensorflow/core/kernels/_objs/determinant_op_gpu/determinant_op_gpu.cu.o /c tensorflow/core/kernels/determinant_op_gpu.cu.cc\r\n> Execution platform: @local_execution_config_platform//:platform\r\n> The command line is too long.\r\n> Target //tensorflow/tools/pip_package:build_pip_package failed to build\r\n> INFO: Elapsed time: 689.653s, Critical Path: 78.32s\r\n> INFO: 1861 processes: 1861 local.\r\n> FAILED: Build did NOT complete successfully\r\n> ```\r\n\r\nThis could happen if you have several versions of CUDA Toolkit installed and each of them is located in Path. In this case, cleaning up the Path and assembly from the beginning will help. After running configure.py in file .tf_configure.bazelrc will be something like that: \r\n\r\n> build --action_env TF_CUDA_VERSION=\"10.1\"\r\n>build --action_env TF_CUDNN_VERSION=\"7\"\r\n>build --action_env CUDA_TOOLKIT_PATH=\"C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.1\"\r\n\r\nAt the moment, the master branch builds perfectly.", "@alanpurple,\r\nIs this still an issue? Could you please check @skaldek's comment above and check if you are still facing the same error? Thanks!", "@amahendrakar \r\nno error currently, @skaldek 's comment is right, there should not be multiple versions of cuda", "@alanpurple,\r\nThank you for the update. Marking this issue as close, as it is resolved. Please feel free to re-open the issue if necessary.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39333\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39333\">No</a>\n"]}, {"number": 39332, "title": "AdditiveAttention score calculation", "body": "Bahdanau's paper specifies that the score is calculated as:\r\n\r\n`score(st,hi)=v\u22a4atanh(Wa[st;hi]) `\r\n\r\nWhile the actualy implemention's score is calcuted as:\r\n```\r\n    return math_ops.reduce_sum(\r\n        scale * math_ops.tanh(q_reshaped + k_reshaped), axis=-1)\r\n```\r\n\r\nThe explaination:\r\n```\r\n\r\n 1. Reshape `query` and `value` into shapes `[batch_size, Tq, 1, dim]`\r\n     and `[batch_size, 1, Tv, dim]` respectively.\r\n  2. Calculate scores with shape `[batch_size, Tq, Tv]` as a non-linear\r\n     sum: `scores = tf.reduce_sum(tf.tanh(query + value), axis=-1)`\r\n  3. Use scores to calculate a distribution with shape\r\n     `[batch_size, Tq, Tv]`: `distribution = tf.nn.softmax(scores)`.\r\n  4. Use `distribution` to create a linear combination of `value` with\r\n     shape `batch_size, Tq, dim]`:\r\n     `return tf.matmul(distribution, value)`.\r\n```\r\n\r\nWhy such a difference? \r\n\r\nThe Tensorflow's attention tutorial is more consistent with the paper:\r\nhttps://www.tensorflow.org/tutorials/text/nmt_with_attention#restore_the_latest_checkpoint_and_test\r\n\r\n", "comments": ["@ichenjia Are you talking about [this](https://www.tensorflow.org/addons/api_docs/python/tfa/seq2seq/BahdanauAttention). Can you please explain the issue in detail. Thanks!", "> @ichenjia Are you talking about [this](https://www.tensorflow.org/addons/api_docs/python/tfa/seq2seq/BahdanauAttention). Can you please explain the issue in detail. Thanks!\r\n\r\nNo, I am not talking about the Add-on. I am talking about how Keras implemented the BahanauAttention layer at \r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/v2.1.0/tensorflow/python/keras/layers/dense_attention.py\r\n\r\nThe score calculation seems off to me. \r\n", "Adding @roumposg who is the original author of the dense_attention in keras.", "Thanks for your comment. The reason we did that is to be consistent with the previous implementation for RNN `tf.contrib.seq2seq.BahdanauAttention`. The main difference is the weight matrices W1 and W2 in the [scores](https://www.tensorflow.org/tutorials/text/nmt_with_attention#write_the_encoder_and_decoder_model), right? You can do that by including two Dense layers before the Attention layer.", "The weight is one issue, which as you mentioned can be resolved easily with Dense layers. I have bigger issue with the way you calculate the score. \r\n\r\nThe paper's formular is:\r\n\r\n`score(st,hi)=v\u22a4 tanh(Wa[st;hi])`\r\n\r\nAs you can see, they are concating st and hi. But in  your implementation, you added the q and k together:\r\n\r\n`math_ops.reduce_sum(\r\n        scale * math_ops.tanh(q_reshaped + k_reshaped), axis=-1)`\r\n\r\nWhy do you sum instead of concat? \r\n", "We followed eq (4) from the [encoder and decoder model](https://www.tensorflow.org/tutorials/text/nmt_with_attention#write_the_encoder_and_decoder_model). As you say, in the initial paper by Bahdanau et al, they use a feed-forward neural network to calculate the scores. But we did not implement that method.\r\n\r\nAFAIK, newer models, Transformer, BERT etc, all use the dot-product attention, so we did not do more work on other ways of calculating the scores.", "you are right that the newer models all used dot product or scaled dot product. But since your documentation specifically mentioned it is Bahdanau's model, I thought you'd adhere to  the original score calculation. Maybe the solution is to point this out in the documentation? ", "You are right, maybe we should not mention Bahdanau in the documentation, or we should point to a better reference, or both. Thanks for pointing it out.", "Not sure if I should reuse the same issue, but I noticed a typo in the documentation, namely, `value` was written in place of `key` in the score calculation. The correct explanation would be:\r\n```\r\n  1. Reshape `query` and `key` into shapes `[batch_size, Tq, 1, dim]`\r\n     and `[batch_size, 1, Tv, dim]` respectively.\r\n  2. Calculate scores with shape `[batch_size, Tq, Tv]` as a non-linear\r\n     sum: `scores = tf.reduce_sum(tf.tanh(query + key), axis=-1)`\r\n```", "Hi There,\n\n This is a stale issue. As you are using an older version of tensorflow, we are checking to see if you still need help on this issue. Please test the issue with the latest TensorFlow (TF2.7 and tf-nightly). If the issue still persists with the newer versions of TF, please feel free to open it in [keras-team/keras](https://github.com/keras-team/keras/issues) repository by providing details about the issue and a standalone code to reproduce the issue. Thanks! \n\n Please note that Keras development has moved to a separate Keras-team/keras repository to focus entirely on only Keras. Thanks! "]}, {"number": 39331, "title": "How to extract_sub_graph in TF2?", "body": "My goal is to get partial model (`tf.Graph`) as feature extractor.\r\n\r\nIn TF1, the following utility can be used to get partial TF graph: https://www.tensorflow.org/api_docs/python/tf/compat/v1/graph_util/extract_sub_graph, how do I achieve same functionality given this util is deprecated?\r\n\r\n\r\n```\r\n[20200521 15:34:24 WARNING (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.compat.v1.graph_util.extract_sub_graph`\r\n```", "comments": ["Graphs as a concept don't exist in TF2 - you can tf.function various pieces of code and under the hood they'll get converted to graphs. As a result,  such utilities as extract_sub_graph don't make that much sense. \r\n\r\nWould be great to understand what your use case exactly is and why you need such a feature. Also, such questions are better suited for stack overflow where the community can help understand your use case and provide recommendations.", "@rohan100jain In my use case I want to learn an embedding for a DNN workload by applying a GNN on the actual DNN. In this scenario it is too important for me to extract a graph representation of the actual TF workload. Any ideas or pointers for how I could achieve this goal?"]}, {"number": 39330, "title": "Added POC for tf_program", "body": "This PR attempts to add the first prototype for Tensorflow program. It is a direct conversion from a python function to mlir module. The target dialect is tf dialect (with some added operations such as tfp.If, tfp.While, tfp.And and tfp.Or). It can transform a simple Fibonacci program (using while loop)", "comments": []}, {"number": 39329, "title": "CategoricalCrossentropy Label Smoothing Bug for tensors with dim > 2", "body": "The flag \"label_smoothing\" in tf.keras.losses.CategoricalCrossentropy does not behave as expected for tensors with dimension > 2. When this parameter is set to non zero value it can on occasion cause severe learning instability and divergence. Looking at the source code the current code is as follows (found [here](https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/losses.py#L1521)):\r\n\r\n```\r\ndef _smooth_labels():\r\n    num_classes = math_ops.cast(array_ops.shape(y_true)[1], y_pred.dtype)\r\n    return y_true * (1.0 - label_smoothing) + (label_smoothing / num_classes)\r\n```\r\nWhen the y_true tensor has dimension > 2 (for example when using a U-net architecture to classify each pixel of an image), the num_classes will be incorrect.\r\nI think the correct way to look up the num_classes is to get the size of dim=-1:\r\n\r\n`num_classes = math_ops.cast(array_ops.shape(y_true)[-1], y_pred.dtype)`", "comments": ["@osushkov,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the TensorFlow version you are using. Thanks!", "The TF version is as in the linked code in my bug description, 2.2.0. I do not have a code snippet at hand to reproduce this as I came upon it working on a larger project with many dependencies. The error in the code is fairly obvious, as the linked function will only be valid for tensors of rank 2, whereas CategoricalCrossentropy is expected to work for any rank.", "This has been fixed in https://github.com/tensorflow/tensorflow/commit/5f1ee72e97e09da9171b2c226d4f10f05e89a38a. Thank you!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39329\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39329\">No</a>\n"]}, {"number": 39328, "title": "Build failure in tensorflow/tensorflow:devel docker container on MacOS Catalina 10.15.4", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Catalina 10.15.4 Docker 19.03.8 \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source from within docker container of image tensorflow/tensorflow:devel \r\n- TensorFlow version: Release 2.0.1\r\n- Python version:3.6.9\r\n- Installed using virtualenv? pip? conda?: //tensorflow/tools/lib_package:libtensorflow\r\n- Bazel version (if compiling from source): 3.0.0\r\n- GCC/Compiler version (if compiling from source):  7.5.0\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A Docker Host GPU is AMD Radeon R9 M295X 4 GB\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nTried to perform a build of tensorflowlib from within docker container using the following sequence of actions outlined below. Unable to diagnose source of build failure.....File /usr/share/doc/gcc-7/README.Bugs outlined in stack trace is not available in the docker cotainer provided by image tensorflow/tensorflow:devel\r\n\r\n$ docker run -it -w /tensorflow_src -v $PWD/lib:/mnt -e HOST_PERMS=\"$(id -u):$(id -g)\" \\\r\n    tensorflow/tensorflow:devel bash\r\n\r\n$ git pull\r\n$ ./configure #accept default python paths and no to all other questions\r\n$  bazel build --config=opt --config=monolithic --config=noaws --config=nogcp --config=nohdfs --config=nonccl //tensorflow/tools/lib_package:libtensorflow\r\n\r\n\r\nReceived the following error.....\r\n\r\nINFO: From Compiling tensorflow/core/framework/function_handle_cache.cc:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:41:0,\r\n                 from ./tensorflow/core/framework/numeric_types.h:24,\r\n                 from ./tensorflow/core/framework/allocator.h:26,\r\n                 from ./tensorflow/core/framework/tensor.h:22,\r\n                 from ./tensorflow/core/framework/attr_value_util.h:24,\r\n                 from ./tensorflow/core/framework/function.h:30,\r\n                 from ./tensorflow/core/framework/function_handle_cache.h:20,\r\n                 from tensorflow/core/framework/function_handle_cache.cc:15:\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:30:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 20> Packet32q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:31:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 21> Packet16q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:32:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 22> Packet32q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:33:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 23> Packet16q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:34:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 25> Packet16q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:35:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 26> Packet8q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:36:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 27> Packet8q32i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:37:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 28> Packet4q32i;\r\n                                         ^\r\nINFO: From Compiling tensorflow/cc/framework/cc_op_gen.cc:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:41:0,\r\n                 from ./tensorflow/core/framework/numeric_types.h:24,\r\n                 from ./tensorflow/core/framework/allocator.h:26,\r\n                 from ./tensorflow/core/framework/tensor.h:22,\r\n                 from ./tensorflow/core/framework/attr_value_util.h:24,\r\n                 from tensorflow/cc/framework/cc_op_gen.cc:25:\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:30:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 20> Packet32q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:31:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 21> Packet16q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:32:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 22> Packet32q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:33:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 23> Packet16q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:34:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 25> Packet16q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:35:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 26> Packet8q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:36:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 27> Packet8q32i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:37:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 28> Packet4q32i;\r\n                                         ^\r\nINFO: From Compiling tensorflow/core/ops/nn_ops.cc:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:41:0,\r\n                 from ./tensorflow/core/framework/numeric_types.h:24,\r\n                 from ./tensorflow/core/framework/allocator.h:26,\r\n                 from ./tensorflow/core/framework/tensor.h:22,\r\n                 from ./tensorflow/core/framework/attr_value_util.h:24,\r\n                 from ./tensorflow/core/framework/node_def_util.h:22,\r\n                 from ./tensorflow/core/framework/shape_inference.h:21,\r\n                 from ./tensorflow/core/framework/common_shape_fns.h:20,\r\n                 from tensorflow/core/ops/nn_ops.cc:18:\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:30:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 20> Packet32q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:31:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 21> Packet16q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:32:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 22> Packet32q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:33:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 23> Packet16q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:34:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 25> Packet16q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:35:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 26> Packet8q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:36:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 27> Packet8q32i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:37:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 28> Packet4q32i;\r\n                                         ^\r\nINFO: From Compiling tensorflow/core/framework/function.cc:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:41:0,\r\n                 from ./tensorflow/core/framework/numeric_types.h:24,\r\n                 from ./tensorflow/core/framework/allocator.h:26,\r\n                 from ./tensorflow/core/framework/tensor.h:22,\r\n                 from ./tensorflow/core/framework/attr_value_util.h:24,\r\n                 from ./tensorflow/core/framework/function.h:30,\r\n                 from tensorflow/core/framework/function.cc:16:\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:30:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 20> Packet32q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:31:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 21> Packet16q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:32:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 22> Packet32q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:33:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 23> Packet16q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:34:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 25> Packet16q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:35:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 26> Packet8q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:36:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 27> Packet8q32i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:37:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 28> Packet4q32i;\r\n                                         ^\r\nINFO: From Compiling tensorflow/core/util/batch_util.cc:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:41:0,\r\n                 from ./tensorflow/core/framework/numeric_types.h:24,\r\n                 from ./tensorflow/core/framework/allocator.h:26,\r\n                 from ./tensorflow/core/framework/tensor.h:22,\r\n                 from ./tensorflow/core/util/batch_util.h:18,\r\n                 from tensorflow/core/util/batch_util.cc:16:\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:30:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 20> Packet32q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:31:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 21> Packet16q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:32:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 22> Packet32q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:33:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 23> Packet16q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:34:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 25> Packet16q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:35:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 26> Packet8q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:36:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 27> Packet8q32i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:37:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 28> Packet4q32i;\r\n                                         ^\r\nERROR: /tensorflow_src/tensorflow/compiler/xla/service/BUILD:260:1: C++ compilation of rule '//tensorflow/compiler/xla/service:hlo_evaluator' failed (Exit 4)\r\ngcc: internal compiler error: Killed (program cc1plus)\r\nPlease submit a full bug report,\r\nwith preprocessed source if appropriate.\r\nSee <file:///usr/share/doc/gcc-7/README.Bugs> for instructions.\r\nTarget //tensorflow/tools/lib_package:libtensorflow failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 16423.036s, Critical Path: 155.94s\r\nINFO: 4629 processes: 4629 local.\r\nFAILED: Build did NOT complete successfully\r\n\r\n", "comments": ["@dcs3spp Can you please try recent TF versions like `TF2.2` or `TF2.1` and let us know whether those builds works for you. Thanks!", "@jvishnuvardhan Repeated the build steps detailed above for TF2.2 and encountered the same problem. I did a git pull from within the docker container and received commit eed4bb5cc10125abc6d175050062372dce34bfd2. \r\n\r\nI am running Docker on MacOS (see earlier posting) and compiling with --config opt (-march=core2 -Wno-sign-compare) to target the build for an old Intel Core2 CPU. Maybe the issue is that I am compiling on a MacOS targeting Intel core2??? When I compile on Linux machine with Intel Core i5 CPU builds fine.....\r\n\r\nI managed to successfully build libtensorflow on Linux Intel i5 bare metal, to an installation of Shinobi that requires it in /opt/shinobi/node_modules/@tensorflow/tfjs-node/deps and received the following message in the logs:\r\n\r\n``` sh\r\nHi there. Looks like you are running TensorFlow.js in Node.js. To speed things up dramatically, install our node\r\nbackend, which binds to TensorFlow C++ by running npm i @tensorflow/tfjs-node or npm i @tensorflow/tfjs-node-gpu\r\nif you have CUDA. Then call require('@tensorflow/tfjs-node'); (-gpu suffic for CUDA) at the start of your program.\r\nVisit https://github.com/tensorflow/tfjs-node for more details.\r\n```\r\n\r\nNot sure if this message is produced by @tensorflow/tfjs-node or Shinobi, have also posted [question](https://discord.com/channels/264819784292499457/264819784292499457/710108628962770944) on Shinobi discord community chat and awaiting response. Does this message signify that the CPU optimised library is not being utilised or can it be ignored?\r\n\r\nI am new to all this but after reading DEVELOPMENT.md included in the tfjs-node installation I tried running the tests for tfjs-node. However the tests failed to build successfully so have raised a separate [issue](https://github.com/tensorflow/tfjs/issues/3264)\r\n\r\nFull bazel build output from docker container on MacOS is:\r\n``` sh\r\nExtracting Bazel installation...\r\nStarting local Bazel server and connecting to it...\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=235\r\nINFO: Reading rc options for 'build' from /tensorflow_src/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /tensorflow_src/.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=v2\r\nINFO: Reading rc options for 'build' from /tensorflow_src/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/lib/python3/dist-packages --python_path=/usr/bin/python3 --config=xla --action_env TF_CONFIGURE_IOS=0\r\nINFO: Found applicable config definition build:v2 in file /tensorflow_src/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:xla in file /tensorflow_src/.bazelrc: --action_env=TF_ENABLE_XLA=1 --define=with_xla_support=true\r\nINFO: Found applicable config definition build:opt in file /tensorflow_src/.tf_configure.bazelrc: --copt=-march=core2 --copt=-Wno-sign-compare --host_copt=-march=native --define with_default_optimizations=true\r\nINFO: Found applicable config definition build:monolithic in file /tensorflow_src/.bazelrc: --define framework_shared_object=false\r\nINFO: Found applicable config definition build:noaws in file /tensorflow_src/.bazelrc: --define=no_aws_support=true\r\nINFO: Found applicable config definition build:nogcp in file /tensorflow_src/.bazelrc: --define=no_gcp_support=true\r\nINFO: Found applicable config definition build:nohdfs in file /tensorflow_src/.bazelrc: --define=no_hdfs_support=true\r\nINFO: Found applicable config definition build:nonccl in file /tensorflow_src/.bazelrc: --define=no_nccl_support=true\r\nINFO: Found applicable config definition build:linux in file /tensorflow_src/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels\r\nINFO: Found applicable config definition build:dynamic_kernels in file /tensorflow_src/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS\r\nDEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = \"1556410077 -0400\"\r\nDEBUG: Call stack for the definition of repository 'io_bazel_rules_docker' which is a git_repository (rule definition at /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/external/bazel_tools/tools/build_defs/repo/git.bzl:195:18):\r\n - <builtin>\r\n - /root/.cache/bazel/_bazel_root/43801f1e35f242fb634ebbc6079cf6c5/external/bazel_toolchains/repositories/repositories.bzl:37:9\r\n - /tensorflow_src/WORKSPACE:37:1\r\nWARNING: /tensorflow_src/tensorflow/core/BUILD:1746:1: in linkstatic attribute of cc_library rule //tensorflow/core:lib_internal: setting 'linkstatic=1' is recommended if there are no object files. Since this rule was created by the macro 'cc_library', the error might have been caused by the macro implementation\r\nWARNING: /tensorflow_src/tensorflow/core/BUILD:2156:1: in linkstatic attribute of cc_library rule //tensorflow/core:framework_internal: setting 'linkstatic=1' is recommended if there are no object files. Since this rule was created by the macro 'tf_cuda_library', the error might have been caused by the macro implementation\r\nINFO: Analyzed target //tensorflow/tools/lib_package:libtensorflow (190 packages loaded, 16901 targets configured).\r\nINFO: Found 1 target...\r\nINFO: From Compiling external/snappy/snappy-stubs-internal.cc:\r\ncc1plus: warning: command line option '-Wno-implicit-function-declaration' is valid for C/ObjC but not for C++\r\nINFO: From Compiling external/llvm-project/llvm/lib/Support/UnicodeCaseFold.cpp [for host]:\r\nexternal/llvm-project/llvm/lib/Support/UnicodeCaseFold.cpp:8:1: warning: multi-line comment [-Wcomment]\r\n //   utils/unicode-case-fold.py \\\r\n ^\r\nINFO: From Compiling external/llvm-project/llvm/lib/MC/ELFObjectWriter.cpp [for host]:\r\nexternal/llvm-project/llvm/lib/MC/ELFObjectWriter.cpp: In function 'uint64_t {anonymous}::ELFWriter::writeObject(llvm::MCAssembler&, const llvm::MCAsmLayout&)':\r\nexternal/llvm-project/llvm/lib/MC/ELFObjectWriter.cpp:1193:36: warning: 'AddrsigSection' may be used uninitialized in this function [-Wmaybe-uninitialized]\r\n       SectionOffsets[AddrsigSection] = std::make_pair(SecStart, SecEnd);\r\n                                    ^\r\nINFO: From Compiling external/llvm-project/llvm/lib/MC/MachObjectWriter.cpp [for host]:\r\nexternal/llvm-project/llvm/lib/MC/MachObjectWriter.cpp: In member function 'void llvm::MachObjectWriter::writeNlist(llvm::MachObjectWriter::MachSymbolData&, const llvm::MCAsmLayout&)':\r\nexternal/llvm-project/llvm/lib/MC/MachObjectWriter.cpp:381:13: warning: 'AliaseeInfo' may be used uninitialized in this function [-Wmaybe-uninitialized]\r\n     Address = AliaseeInfo->StringIndex;\r\n     ~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~\r\nINFO: From Compiling external/llvm-project/llvm/lib/Support/APFloat.cpp [for host]:\r\nexternal/llvm-project/llvm/lib/Support/APFloat.cpp: In member function 'llvm::Expected<llvm::APFloatBase::opStatus> llvm::detail::IEEEFloat::convertFromDecimalString(llvm::StringRef, llvm::APFloatBase::roundingMode)':\r\nexternal/llvm-project/llvm/lib/Support/APFloat.cpp:2784:38: warning: 'D.llvm::decimalInfo::exponent' may be used uninitialized in this function [-Wmaybe-uninitialized]\r\n     fs = roundSignificandWithExponent(decSignificand, partCount,\r\n          ~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n                                       D.exponent, rounding_mode);\r\n                                       ~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nexternal/llvm-project/llvm/lib/Support/APFloat.cpp:2720:36: warning: 'D.llvm::decimalInfo::normalizedExponent' may be used uninitialized in this function [-Wmaybe-uninitialized]\r\n              (D.normalizedExponent + 1) * 28738 <=\r\n              ~~~~~~~~~~~~~~~~~~~~~~^~~~\r\nexternal/llvm-project/llvm/lib/Support/APFloat.cpp:2781:16: warning: 'D.llvm::decimalInfo::lastSigDigit' may be used uninitialized in this function [-Wmaybe-uninitialized]\r\n     } while (p <= D.lastSigDigit);\r\n              ~~^~~~~~~~~~~~~~~~~\r\nexternal/llvm-project/llvm/lib/Support/APFloat.cpp:2740:58: warning: 'D.llvm::decimalInfo::firstSigDigit' may be used uninitialized in this function [-Wmaybe-uninitialized]\r\n     partCount = static_cast<unsigned int>(D.lastSigDigit - D.firstSigDigit) + 1;\r\n                                           ~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~\r\nINFO: From Compiling external/snappy/snappy.cc:\r\ncc1plus: warning: command line option '-Wno-implicit-function-declaration' is valid for C/ObjC but not for C++\r\nINFO: From Compiling tensorflow/core/platform/default/stacktrace_handler.cc:\r\ntensorflow/core/platform/default/stacktrace_handler.cc: In function 'void tensorflow::testing::InstallStacktraceHandler()':\r\ntensorflow/core/platform/default/stacktrace_handler.cc:103:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   for (int i = 0; i < sizeof(handled_signals) / sizeof(int); i++) {\r\n                   ~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/core/platform/default/stacktrace_handler.cc:117:7: warning: ignoring return value of 'ssize_t write(int, const void*, size_t)', declared with attribute warn_unused_result [-Wunused-result]\r\n       (void)write(STDERR_FILENO, buf, strlen(buf));\r\n       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/core/platform/default/stacktrace_handler.cc:124:7: warning: ignoring return value of 'ssize_t write(int, const void*, size_t)', declared with attribute warn_unused_result [-Wunused-result]\r\n       (void)write(STDERR_FILENO, buf, strlen(buf));\r\n       ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/core/platform/default/stacktrace_handler.cc: In function 'void tensorflow::testing::StacktraceHandler(int, siginfo_t*, void*)':\r\ntensorflow/core/platform/default/stacktrace_handler.cc:79:3: warning: ignoring return value of 'ssize_t write(int, const void*, size_t)', declared with attribute warn_unused_result [-Wunused-result]\r\n   (void)write(STDERR_FILENO, buf, strlen(buf));\r\n   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/core/platform/default/stacktrace_handler.cc:89:3: warning: ignoring return value of 'ssize_t write(int, const void*, size_t)', declared with attribute warn_unused_result [-Wunused-result]\r\n   (void)write(STDERR_FILENO, stacktrace.c_str(), stacktrace.length());\r\n   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/core/platform/default/stacktrace_handler.cc: In function 'void tensorflow::testing::SafePrintStackTrace()':\r\ntensorflow/core/platform/default/stacktrace_handler.cc:46:3: warning: ignoring return value of 'ssize_t write(int, const void*, size_t)', declared with attribute warn_unused_result [-Wunused-result]\r\n   (void)write(STDERR_FILENO, begin_msg, strlen(begin_msg));\r\n   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/core/platform/default/stacktrace_handler.cc:57:3: warning: ignoring return value of 'ssize_t write(int, const void*, size_t)', declared with attribute warn_unused_result [-Wunused-result]\r\n   (void)write(STDERR_FILENO, end_msg, strlen(end_msg));\r\n   ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nINFO: From Compiling tensorflow/core/platform/platform_strings.cc:\r\nIn file included from tensorflow/core/platform/platform_strings.cc:16:0:\r\n./tensorflow/core/platform/platform_strings.h:96:1: warning: multi-line comment [-Wcomment]\r\n // #define TF_PLAT_STR_(x) \\\r\n ^\r\nINFO: From Compiling external/llvm-project/llvm/lib/Support/YAMLParser.cpp [for host]:\r\nexternal/llvm-project/llvm/lib/Support/YAMLParser.cpp: In member function 'bool llvm::yaml::Scanner::findBlockScalarIndent(unsigned int&, unsigned int, unsigned int&, bool&)':\r\nexternal/llvm-project/llvm/lib/Support/YAMLParser.cpp:1521:17: warning: 'LongestAllSpaceLine' may be used uninitialized in this function [-Wmaybe-uninitialized]\r\n         setError(\r\n         ~~~~~~~~^\r\n             \"Leading all-spaces line must be smaller than the block indent\",\r\n             ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\n             LongestAllSpaceLine);\r\n             ~~~~~~~~~~~~~~~~~~~~\r\nINFO: From Compiling external/llvm-project/llvm/lib/Support/VirtualFileSystem.cpp [for host]:\r\nexternal/llvm-project/llvm/lib/Support/VirtualFileSystem.cpp: In member function 'std::unique_ptr<llvm::vfs::RedirectingFileSystem::Entry> llvm::vfs::RedirectingFileSystemParser::parseEntry(llvm::yaml::Node*, llvm::vfs::RedirectingFileSystem*, bool)':\r\nexternal/llvm-project/llvm/lib/Support/VirtualFileSystem.cpp:1500:5: warning: 'Kind' may be used uninitialized in this function [-Wmaybe-uninitialized]\r\n     switch (Kind) {\r\n     ^~~~~~\r\nINFO: From Compiling external/snappy/snappy-stubs-internal.cc:\r\ncc1plus: warning: command line option '-Wno-implicit-function-declaration' is valid for C/ObjC but not for C++\r\nINFO: From Compiling tensorflow/core/platform/numbers.cc:\r\ntensorflow/core/platform/numbers.cc: In function 'std::__cxx11::string tensorflow::strings::HumanReadableNumBytes(tensorflow::int64)':\r\ntensorflow/core/platform/numbers.cc:459:8: warning: '%lld' directive output may be truncated writing between 1 and 19 bytes into a region of size between 7 and 8 [-Wformat-truncation=]\r\n string HumanReadableNumBytes(int64 num_bytes) {\r\n        ^~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/core/platform/numbers.cc:459:8: note: directive argument in the range [0, 9223372036854775807]\r\nIn file included from /usr/include/stdio.h:862:0,\r\n                 from /usr/include/c++/7/cstdio:42,\r\n                 from /usr/include/c++/7/ext/string_conversions.h:43,\r\n                 from /usr/include/c++/7/bits/basic_string.h:6361,\r\n                 from /usr/include/c++/7/string:52,\r\n                 from ./tensorflow/core/platform/numbers.h:19,\r\n                 from tensorflow/core/platform/numbers.cc:15:\r\n/usr/include/x86_64-linux-gnu/bits/stdio2.h:65:44: note: '__builtin_snprintf' output between 3 and 22 bytes into a destination of size 8\r\n        __bos (__s), __fmt, __va_arg_pack ());\r\n                                            ^\r\nINFO: From Compiling external/snappy/snappy.cc:\r\ncc1plus: warning: command line option '-Wno-implicit-function-declaration' is valid for C/ObjC but not for C++\r\nINFO: From Compiling tensorflow/core/framework/bfloat16.cc:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:41:0,\r\n                 from ./tensorflow/core/framework/numeric_types.h:24,\r\n                 from ./tensorflow/core/framework/bfloat16.h:19,\r\n                 from tensorflow/core/framework/bfloat16.cc:16:\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:30:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 20> Packet32q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:31:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 21> Packet16q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:32:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 22> Packet32q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:33:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 23> Packet16q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:34:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 25> Packet16q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:35:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 26> Packet8q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:36:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 27> Packet8q32i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:37:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 28> Packet4q32i;\r\n                                         ^\r\nINFO: From Compiling tensorflow/core/framework/allocator_registry.cc:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:41:0,\r\n                 from ./tensorflow/core/framework/numeric_types.h:24,\r\n                 from ./tensorflow/core/framework/allocator.h:26,\r\n                 from ./tensorflow/core/framework/allocator_registry.h:23,\r\n                 from tensorflow/core/framework/allocator_registry.cc:18:\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:30:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 20> Packet32q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:31:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 21> Packet16q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:32:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 22> Packet32q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:33:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 23> Packet16q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:34:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 25> Packet16q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:35:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 26> Packet8q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:36:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 27> Packet8q32i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:37:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 28> Packet4q32i;\r\n                                         ^\r\ntensorflow/core/framework/allocator_registry.cc: In member function 'tensorflow::SubAllocator* tensorflow::AllocatorFactoryRegistry::GetSubAllocator(int)':\r\ntensorflow/core/framework/allocator_registry.cc:116:43: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n     if (best_entry->sub_allocators.size() < (index + 1)) {\r\n         ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~\r\nINFO: From Compiling tensorflow/core/framework/cpu_allocator_impl.cc:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:41:0,\r\n                 from ./tensorflow/core/framework/numeric_types.h:24,\r\n                 from ./tensorflow/core/framework/allocator.h:26,\r\n                 from tensorflow/core/framework/cpu_allocator_impl.cc:18:\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:30:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 20> Packet32q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:31:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 21> Packet16q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:32:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 22> Packet32q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:33:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 23> Packet16q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:34:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 25> Packet16q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:35:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 26> Packet8q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:36:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 27> Packet8q32i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:37:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 28> Packet4q32i;\r\n                                         ^\r\ntensorflow/core/framework/cpu_allocator_impl.cc: In member function 'virtual void* tensorflow::{anonymous}::CPUAllocator::AllocateRaw(size_t, size_t)':\r\ntensorflow/core/framework/cpu_allocator_impl.cc:78:19: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n     if (num_bytes > LargeAllocationWarningBytes() &&\r\n         ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nINFO: From Compiling external/snappy/snappy-sinksource.cc:\r\ncc1plus: warning: command line option '-Wno-implicit-function-declaration' is valid for C/ObjC but not for C++\r\nINFO: From Compiling tensorflow/core/platform/protobuf.cc:\r\ntensorflow/core/platform/protobuf.cc: In member function 'virtual bool tensorflow::TStringOutputStream::Next(void**, int*)':\r\ntensorflow/core/platform/protobuf.cc:29:16: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   if (old_size < target_->capacity()) {\r\n       ~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~\r\nINFO: From Compiling tensorflow/core/platform/default/logging.cc:\r\ntensorflow/core/platform/default/logging.cc: In member function 'bool tensorflow::internal::LogFirstNState::ShouldLog(int)':\r\ntensorflow/core/platform/default/logging.cc:369:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   if (counter_value < n) {\r\n       ~~~~~~~~~~~~~~^~~\r\nINFO: From Compiling tensorflow/core/lib/strings/proto_serialization.cc:\r\ntensorflow/core/lib/strings/proto_serialization.cc: In function 'bool tensorflow::SerializeToBufferDeterministic(const google::protobuf::MessageLite&, char*, size_t)':\r\ntensorflow/core/lib/strings/proto_serialization.cc:75:44: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   return !output_stream.HadError() && size == output_stream.ByteCount();\r\n                                       ~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nINFO: From Compiling external/snappy/snappy-sinksource.cc:\r\ncc1plus: warning: command line option '-Wno-implicit-function-declaration' is valid for C/ObjC but not for C++\r\nINFO: From ProtoCompile tensorflow/core/debug/debug_service.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/eager_service.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/conv_autotuning.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/example/example_parser_configuration.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/verifier_config.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/device_filters.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/util/event.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/util/test_log.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/util/memmapped_file_system.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/trackable_object_graph.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/transport_options.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/saved_model.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/saved_object_graph.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/saver.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/tensorflow_server.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/struct.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/rewriter_config.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/allocation_description.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/remote_fused_graph_execute_info.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/profiler/profiler_options.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/config.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/lib/core/error_codes.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/profiler/protobuf/xplane.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/graph_debug_info.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/data/experimental/snapshot.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/tensor_description.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/versions.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/reader_base.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/attr_value.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/op_def.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/function.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/cost_graph.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/device_attributes.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/tensor.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/tensor_shape.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/types.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/profiler/tfprof_output.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/resource_handle.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/example/example.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/example/feature.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/graph.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/api_def.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/node_def.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/graph_transfer_info.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/debug.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/tpu/topology.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/kernel_def.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/log_memory.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/error_codes.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/compiler/xla/service/hlo_profile_printer_data.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/summary.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From Compiling tensorflow/core/platform/status.cc:\r\ntensorflow/core/platform/status.cc: In member function 'virtual void tensorflow::{anonymous}::StatusLogSink::Send(const tensorflow::TFLogEntry&)':\r\ntensorflow/core/platform/status.cc:77:26: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n     if (messages_.size() > num_messages_) messages_.pop_front();\r\n         ~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~\r\nINFO: From Compiling tensorflow/core/platform/file_system_helper.cc:\r\ntensorflow/core/platform/file_system_helper.cc: In function 'tensorflow::Status tensorflow::internal::GetMatchingPaths(tensorflow::FileSystem*, tensorflow::Env*, const string&, std::vector<std::__cxx11::basic_string<char> >*)':\r\ntensorflow/core/platform/file_system_helper.cc:106:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n     for (int i = 0; i < children.size(); ++i) {\r\n                     ~~^~~~~~~~~~~~~~~~~\r\nINFO: From Compiling tensorflow/core/platform/file_system.cc:\r\ntensorflow/core/platform/file_system.cc: In member function 'tensorflow::StringPiece tensorflow::FileSystem::Extension(tensorflow::StringPiece) const':\r\ntensorflow/core/platform/file_system.cc:312:11: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   if (pos == StringPiece::npos) {\r\n       ~~~~^~~~~~~~~~~~~~\r\nINFO: From Compiling tensorflow/core/platform/env.cc:\r\ntensorflow/core/platform/env.cc: In member function 'bool tensorflow::Env::FilesExist(const std::vector<std::__cxx11::basic_string<char> >&, std::vector<tensorflow::Status>*)':\r\ntensorflow/core/platform/env.cc:217:25: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n       for (int i = 0; i < itr.second.size(); ++i) {\r\n                       ~~^~~~~~~~~~~~~~~~~~~\r\nINFO: From Compiling tensorflow/core/framework/allocator.cc:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:41:0,\r\n                 from ./tensorflow/core/framework/numeric_types.h:24,\r\n                 from ./tensorflow/core/framework/allocator.h:26,\r\n                 from tensorflow/core/framework/allocator.cc:16:\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:30:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 20> Packet32q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:31:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 21> Packet16q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:32:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 22> Packet32q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:33:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 23> Packet16q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:34:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 25> Packet16q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:35:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 26> Packet8q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:36:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 27> Packet8q32i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:37:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 28> Packet4q32i;\r\n                                         ^\r\nINFO: From Compiling tensorflow/core/framework/tracking_allocator.cc:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:41:0,\r\n                 from ./tensorflow/core/framework/numeric_types.h:24,\r\n                 from ./tensorflow/core/framework/allocator.h:26,\r\n                 from ./tensorflow/core/framework/tracking_allocator.h:20,\r\n                 from tensorflow/core/framework/tracking_allocator.cc:16:\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:30:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 20> Packet32q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:31:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 21> Packet16q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:32:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 22> Packet32q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:33:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 23> Packet16q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:34:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 25> Packet16q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:35:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 26> Packet8q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:36:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 27> Packet8q32i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:37:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 28> Packet4q32i;\r\n                                         ^\r\nINFO: From Compiling tensorflow/core/framework/tensor_shape.cc:\r\ntensorflow/core/framework/tensor_shape.cc: In instantiation of 'void tensorflow::TensorShapeBase<Shape>::InitDims(tensorflow::gtl::ArraySlice<long long int>) [with Shape = tensorflow::TensorShape; tensorflow::gtl::ArraySlice<long long int> = absl::lts_2020_02_25::Span<const long long int>]':\r\ntensorflow/core/framework/tensor_shape.cc:791:16:   required from here\r\ntensorflow/core/framework/tensor_shape.cc:190:11: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n     if (s > kMaxSmall) {\r\n         ~~^~~~~~~~~~~\r\ntensorflow/core/framework/tensor_shape.cc: In instantiation of 'void tensorflow::TensorShapeBase<Shape>::InitDims(tensorflow::gtl::ArraySlice<long long int>) [with Shape = tensorflow::PartialTensorShape; tensorflow::gtl::ArraySlice<long long int> = absl::lts_2020_02_25::Span<const long long int>]':\r\ntensorflow/core/framework/tensor_shape.cc:792:16:   required from here\r\ntensorflow/core/framework/tensor_shape.cc:190:11: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\nINFO: From Compiling tensorflow/core/lib/io/zlib_outputbuffer.cc:\r\ntensorflow/core/lib/io/zlib_outputbuffer.cc: In member function 'void tensorflow::io::ZlibOutputBuffer::AddToInputBuffer(tensorflow::StringPiece)':\r\ntensorflow/core/lib/io/zlib_outputbuffer.cc:101:22: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   if (bytes_to_write > free_tail_bytes) {\r\n       ~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~\r\ntensorflow/core/lib/io/zlib_outputbuffer.cc: In member function 'virtual tensorflow::Status tensorflow::io::ZlibOutputBuffer::Append(tensorflow::StringPiece)':\r\ntensorflow/core/lib/io/zlib_outputbuffer.cc:157:22: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   if (bytes_to_write <= AvailableInputSpace()) {\r\n       ~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/core/lib/io/zlib_outputbuffer.cc:165:22: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   if (bytes_to_write <= AvailableInputSpace()) {\r\n       ~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\r\nINFO: From Compiling tensorflow/core/lib/io/snappy/snappy_outputbuffer.cc:\r\ntensorflow/core/lib/io/snappy/snappy_outputbuffer.cc: In member function 'tensorflow::Status tensorflow::io::SnappyOutputBuffer::Write(tensorflow::StringPiece)':\r\ntensorflow/core/lib/io/snappy/snappy_outputbuffer.cc:79:22: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   if (bytes_to_write <= AvailableInputSpace()) {\r\n       ~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/core/lib/io/snappy/snappy_outputbuffer.cc:90:22: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   if (bytes_to_write <= AvailableInputSpace()) {\r\n       ~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/core/lib/io/snappy/snappy_outputbuffer.cc: In member function 'void tensorflow::io::SnappyOutputBuffer::AddToInputBuffer(tensorflow::StringPiece)':\r\ntensorflow/core/lib/io/snappy/snappy_outputbuffer.cc:147:22: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   if (bytes_to_write > free_tail_bytes) {\r\n       ~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~\r\nINFO: From Compiling tensorflow/core/lib/io/inputbuffer.cc:\r\ntensorflow/core/lib/io/inputbuffer.cc: In member function 'tensorflow::Status tensorflow::io::InputBuffer::ReadNBytes(tensorflow::int64, std::__cxx11::string*)':\r\ntensorflow/core/lib/io/inputbuffer.cc:88:18: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   if (bytes_read < bytes_to_read) result->resize(bytes_read);\r\n       ~~~~~~~~~~~^~~~~~~~~~~~~~~\r\ntensorflow/core/lib/io/inputbuffer.cc: In member function 'tensorflow::Status tensorflow::io::InputBuffer::Hint(tensorflow::int64)':\r\ntensorflow/core/lib/io/inputbuffer.cc:207:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   if (bytes_to_read > size_) {\r\n       ~~~~~~~~~~~~~~^~~~~~~\r\ntensorflow/core/lib/io/inputbuffer.cc:233:46: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   if (errors::IsOutOfRange(s) && data.size() == bytes_to_read) {\r\n                                  ~~~~~~~~~~~~^~~~~~~~~~~~~~~~\r\nINFO: From Compiling tensorflow/core/lib/io/snappy/snappy_inputbuffer.cc:\r\ntensorflow/core/lib/io/snappy/snappy_inputbuffer.cc: In member function 'tensorflow::Status tensorflow::io::SnappyInputBuffer::ReadCompressedBlockLength(tensorflow::uint32*)':\r\ntensorflow/core/lib/io/snappy/snappy_inputbuffer.cc:137:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n     for (int i = 0; i < readable; i++) {\r\n                     ~~^~~~~~~~~~\r\nINFO: From Compiling tensorflow/core/lib/io/random_inputstream.cc:\r\ntensorflow/core/lib/io/random_inputstream.cc: In member function 'virtual tensorflow::Status tensorflow::io::RandomAccessInputStream::SkipNBytes(tensorflow::int64)':\r\ntensorflow/core/lib/io/random_inputstream.cc:95:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n     if (data.size() < bytes_to_read) {\r\n         ~~~~~~~~~~~~^~~~~~~~~~~~~~~\r\nINFO: From ProtoCompile tensorflow/core/protobuf/bfc_memory_map.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/tensor_slice.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/step_stats.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/compiler/xla/xla_data.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/variable.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/cluster.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/control_flow.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/debug_event.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/meta_graph.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/queue_runner.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/named_tensor.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/example/example.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/remote_tensor_handle.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/device_properties.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/tensor_bundle.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/util/saved_tensor_slice.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/util/saved_tensor_slice.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/autotuning.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/stream_executor/dnn.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/grappler/costs/op_performance_data.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/autotuning.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/error_codes.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/types.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/grappler/costs/op_performance_data.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/tensor_shape.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/kernel_def.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/tensor_description.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/util/test_log.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/resource_handle.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/graph_debug_info.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/tensor.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/example/example_parser_configuration.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/allocation_description.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/debug.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/attr_value.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/api_def.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/tensor_bundle.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/cost_graph.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/cluster.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/device_attributes.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/node_def.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/saved_model.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/op_def.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/function.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/versions.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/named_tensor.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/graph.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/graph_transfer_info.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/tensorflow_server.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/trackable_object_graph.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/log_memory.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/reader_base.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/remote_fused_graph_execute_info.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/step_stats.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/summary.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/tensor_slice.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/framework/variable.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/lib/core/error_codes.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/profiler/protobuf/xplane.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/profiler/profiler_options.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/bfc_memory_map.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/config.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/control_flow.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/data/experimental/snapshot.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/debug_event.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/device_filters.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/device_properties.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/meta_graph.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/queue_runner.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/remote_tensor_handle.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/rewriter_config.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/saved_object_graph.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/saver.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/struct.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/transport_options.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/verifier_config.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/util/event.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/util/memmapped_file_system.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/stream_executor/dnn.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/conv_autotuning.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From Compiling tensorflow/core/protobuf/autotuning.pb.cc:\r\nIn file included from bazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.cc:4:0:\r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.h:241:13: warning: In the GNU C Library, \"major\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"major\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"major\", you should undefine it after including <sys/types.h>.\r\n   ::PROTOBUF_NAMESPACE_ID::int32 major() const;\r\n             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                                                                                                                                                                                                     \r\nIn file included from bazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.cc:4:0:\r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.h:246:13: warning: In the GNU C Library, \"minor\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"minor\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"minor\", you should undefine it after including <sys/types.h>.\r\n   ::PROTOBUF_NAMESPACE_ID::int32 minor() const;\r\n             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                                                                                                                                                                                                     \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.h:385:13: warning: In the GNU C Library, \"major\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"major\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"major\", you should undefine it after including <sys/types.h>.\r\n   ::PROTOBUF_NAMESPACE_ID::int32 major() const;\r\n             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                                                                                                                                                                                                     \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.h:390:13: warning: In the GNU C Library, \"minor\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"minor\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"minor\", you should undefine it after including <sys/types.h>.\r\n   ::PROTOBUF_NAMESPACE_ID::int32 minor() const;\r\n             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                                                                                                                                                                                                     \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.h:1294:13: warning: In the GNU C Library, \"major\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"major\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"major\", you should undefine it after including <sys/types.h>.\r\n inline ::PROTOBUF_NAMESPACE_ID::int32 CudnnVersion::major() const {\r\n             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                                                                                                                                                                                 \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.h:1308:13: warning: In the GNU C Library, \"minor\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"minor\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"minor\", you should undefine it after including <sys/types.h>.\r\n inline ::PROTOBUF_NAMESPACE_ID::int32 CudnnVersion::minor() const {\r\n             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                                                                                                                                                                                 \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.h:1340:13: warning: In the GNU C Library, \"major\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"major\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"major\", you should undefine it after including <sys/types.h>.\r\n inline ::PROTOBUF_NAMESPACE_ID::int32 ComputeCapability::major() const {\r\n             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                                                                                                                                                                            \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.h:1354:13: warning: In the GNU C Library, \"minor\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"minor\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"minor\", you should undefine it after including <sys/types.h>.\r\n inline ::PROTOBUF_NAMESPACE_ID::int32 ComputeCapability::minor() const {\r\n             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                                                                                                                                                                            \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.cc:521:13: warning: In the GNU C Library, \"major\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"major\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"major\", you should undefine it after including <sys/types.h>.\r\n   if (this->major() != 0) {\r\n             ^~~~~~~~~~~~~~~                                                                                                                                                                                                                                                                                                                                                         \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.cc:522:13: warning: In the GNU C Library, \"major\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"major\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"major\", you should undefine it after including <sys/types.h>.\r\n     ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteInt32(1, this->major(), output);\r\n             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                                                                                                                                                        \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.cc:526:13: warning: In the GNU C Library, \"minor\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"minor\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"minor\", you should undefine it after including <sys/types.h>.\r\n   if (this->minor() != 0) {\r\n             ^~~~~~~~~~~~~~~                                                                                                                                                                                                                                                                                                                                                         \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.cc:527:13: warning: In the GNU C Library, \"minor\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"minor\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"minor\", you should undefine it after including <sys/types.h>.\r\n     ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteInt32(2, this->minor(), output);\r\n             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                                                                                                                                                        \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.cc:549:13: warning: In the GNU C Library, \"major\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"major\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"major\", you should undefine it after including <sys/types.h>.\r\n   if (this->major() != 0) {\r\n             ^~~~~~~~~~~~~~~                                                                                                                                                                                                                                                                                                                                                         \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.cc:550:13: warning: In the GNU C Library, \"major\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"major\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"major\", you should undefine it after including <sys/types.h>.\r\n     target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteInt32ToArray(1, this->major(), target);\r\n             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                                                                                                                                        \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.cc:554:13: warning: In the GNU C Library, \"minor\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"minor\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"minor\", you should undefine it after including <sys/types.h>.\r\n   if (this->minor() != 0) {\r\n             ^~~~~~~~~~~~~~~                                                                                                                                                                                                                                                                                                                                                         \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.cc:555:13: warning: In the GNU C Library, \"minor\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"minor\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"minor\", you should undefine it after including <sys/types.h>.\r\n     target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteInt32ToArray(2, this->minor(), target);\r\n             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                                                                                                                                        \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.cc:585:13: warning: In the GNU C Library, \"major\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"major\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"major\", you should undefine it after including <sys/types.h>.\r\n   if (this->major() != 0) {\r\n             ^~~~~~~~~~~~~~~                                                                                                                                                                                                                                                                                                                                                         \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.cc:588:13: warning: In the GNU C Library, \"major\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"major\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"major\", you should undefine it after including <sys/types.h>.\r\n         this->major());\r\n             ^~~~~~~~~~~                                                                                                                                                                                                                                                                                                                                                             \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.cc:592:13: warning: In the GNU C Library, \"minor\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"minor\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"minor\", you should undefine it after including <sys/types.h>.\r\n   if (this->minor() != 0) {\r\n             ^~~~~~~~~~~~~~~                                                                                                                                                                                                                                                                                                                                                         \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.cc:595:13: warning: In the GNU C Library, \"minor\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"minor\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"minor\", you should undefine it after including <sys/types.h>.\r\n         this->minor());\r\n             ^~~~~~~~~~~                                                                                                                                                                                                                                                                                                                                                             \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.cc:632:13: warning: In the GNU C Library, \"major\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"major\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"major\", you should undefine it after including <sys/types.h>.\r\n   if (from.major() != 0) {\r\n             ^~~~~~~~~~~~~~                                                                                                                                                                                                                                                                                                                                                          \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.cc:633:13: warning: In the GNU C Library, \"major\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"major\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"major\", you should undefine it after including <sys/types.h>.\r\n     set_major(from.major());\r\n             ^~~~~~~~~~~~~~~~                                                                                                                                                                                                                                                                                                                                                        \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.cc:635:13: warning: In the GNU C Library, \"minor\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"minor\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"minor\", you should undefine it after including <sys/types.h>.\r\n   if (from.minor() != 0) {\r\n             ^~~~~~~~~~~~~~                                                                                                                                                                                                                                                                                                                                                          \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.cc:636:13: warning: In the GNU C Library, \"minor\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"minor\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"minor\", you should undefine it after including <sys/types.h>.\r\n     set_minor(from.minor());\r\n             ^~~~~~~~~~~~~~~~                                                                                                                                                                                                                                                                                                                                                        \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.cc:838:13: warning: In the GNU C Library, \"major\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"major\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"major\", you should undefine it after including <sys/types.h>.\r\n   if (this->major() != 0) {\r\n             ^~~~~~~~~~~~~~~                                                                                                                                                                                                                                                                                                                                                         \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.cc:839:13: warning: In the GNU C Library, \"major\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"major\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"major\", you should undefine it after including <sys/types.h>.\r\n     ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteInt32(1, this->major(), output);\r\n             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                                                                                                                                                        \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.cc:843:13: warning: In the GNU C Library, \"minor\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"minor\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"minor\", you should undefine it after including <sys/types.h>.\r\n   if (this->minor() != 0) {\r\n             ^~~~~~~~~~~~~~~                                                                                                                                                                                                                                                                                                                                                         \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.cc:844:13: warning: In the GNU C Library, \"minor\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"minor\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"minor\", you should undefine it after including <sys/types.h>.\r\n     ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteInt32(2, this->minor(), output);\r\n             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                                                                                                                                                        \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.cc:861:13: warning: In the GNU C Library, \"major\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"major\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"major\", you should undefine it after including <sys/types.h>.\r\n   if (this->major() != 0) {\r\n             ^~~~~~~~~~~~~~~                                                                                                                                                                                                                                                                                                                                                         \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.cc:862:13: warning: In the GNU C Library, \"major\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"major\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"major\", you should undefine it after including <sys/types.h>.\r\n     target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteInt32ToArray(1, this->major(), target);\r\n             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                                                                                                                                        \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.cc:866:13: warning: In the GNU C Library, \"minor\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"minor\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"minor\", you should undefine it after including <sys/types.h>.\r\n   if (this->minor() != 0) {\r\n             ^~~~~~~~~~~~~~~                                                                                                                                                                                                                                                                                                                                                         \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.cc:867:13: warning: In the GNU C Library, \"minor\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"minor\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"minor\", you should undefine it after including <sys/types.h>.\r\n     target = ::PROTOBUF_NAMESPACE_ID::internal::WireFormatLite::WriteInt32ToArray(2, this->minor(), target);\r\n             ^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~                                                                                                                                                                                                                                                                        \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.cc:892:13: warning: In the GNU C Library, \"major\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"major\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"major\", you should undefine it after including <sys/types.h>.\r\n   if (this->major() != 0) {\r\n             ^~~~~~~~~~~~~~~                                                                                                                                                                                                                                                                                                                                                         \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.cc:895:13: warning: In the GNU C Library, \"major\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"major\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"major\", you should undefine it after including <sys/types.h>.\r\n         this->major());\r\n             ^~~~~~~~~~~                                                                                                                                                                                                                                                                                                                                                             \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.cc:899:13: warning: In the GNU C Library, \"minor\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"minor\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"minor\", you should undefine it after including <sys/types.h>.\r\n   if (this->minor() != 0) {\r\n             ^~~~~~~~~~~~~~~                                                                                                                                                                                                                                                                                                                                                         \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.cc:902:13: warning: In the GNU C Library, \"minor\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"minor\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"minor\", you should undefine it after including <sys/types.h>.\r\n         this->minor());\r\n             ^~~~~~~~~~~                                                                                                                                                                                                                                                                                                                                                             \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.cc:932:13: warning: In the GNU C Library, \"major\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"major\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"major\", you should undefine it after including <sys/types.h>.\r\n   if (from.major() != 0) {\r\n             ^~~~~~~~~~~~~~                                                                                                                                                                                                                                                                                                                                                          \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.cc:933:13: warning: In the GNU C Library, \"major\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"major\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"major\", you should undefine it after including <sys/types.h>.\r\n     set_major(from.major());\r\n             ^~~~~~~~~~~~~~~~                                                                                                                                                                                                                                                                                                                                                        \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.cc:935:13: warning: In the GNU C Library, \"minor\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"minor\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"minor\", you should undefine it after including <sys/types.h>.\r\n   if (from.minor() != 0) {\r\n             ^~~~~~~~~~~~~~                                                                                                                                                                                                                                                                                                                                                          \r\nbazel-out/k8-opt-exec-50AE0418/bin/tensorflow/core/protobuf/autotuning.pb.cc:936:13: warning: In the GNU C Library, \"minor\" is defined\r\n by <sys/sysmacros.h>. For historical compatibility, it is\r\n currently defined by <sys/types.h> as well, but we plan to\r\n remove this soon. To use \"minor\", include <sys/sysmacros.h>\r\n directly. If you did not intend to use a system-defined macro\r\n \"minor\", you should undefine it after including <sys/types.h>.\r\n     set_minor(from.minor());\r\n             ^~~~~~~~~~~~~~~~                                                                                                                                                                                                                                                                                                                                                        \r\ncc1plus: warning: unrecognized command line option '-Wno-unknown-warning-option'\r\nINFO: From ProtoCompile tensorflow/core/example/feature.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/tpu/tpu_embedding_output_layout.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/tpu/tpu_embedding_configuration.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/tpu/optimization_parameters.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/compiler/xla/xla_data.pb.h:\r\nbazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/compiler/jit/xla_activity.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/kernels/boosted_trees/boosted_trees.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/compiler/xla/xla.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/compiler/xla/service/hlo.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/compiler/tf2xla/tf2xla.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/compiler/xla/service/hlo_execution_profile_data.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/compiler/tf2xla/host_compute_metadata.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/tpu/compile_metadata.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/tpu/dynamic_padding.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/worker.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/protobuf/master.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/profiler/profile.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/profiler/tfprof_log.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/profiler/tfprof_options.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/debug/debugger_event_metadata.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/data/service/common.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/data/service/master.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From ProtoCompile tensorflow/core/data/service/worker.pb.h:\r\nbazel-out/k8-opt/bin/external/com_google_protobuf/src: warning: directory does not exist.\r\nINFO: From Compiling tensorflow/core/framework/log_memory.cc:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:41:0,\r\n                 from ./tensorflow/core/framework/numeric_types.h:24,\r\n                 from ./tensorflow/core/framework/allocator.h:26,\r\n                 from ./tensorflow/core/framework/tensor.h:22,\r\n                 from ./tensorflow/core/framework/log_memory.h:19,\r\n                 from tensorflow/core/framework/log_memory.cc:16:\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:30:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 20> Packet32q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:31:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 21> Packet16q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:32:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 22> Packet32q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:33:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 23> Packet16q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:34:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 25> Packet16q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:35:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 26> Packet8q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:36:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 27> Packet8q32i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:37:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 28> Packet4q32i;\r\n                                         ^\r\nINFO: From Compiling tensorflow/core/framework/variant_tensor_data.cc:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:41:0,\r\n                 from ./tensorflow/core/framework/numeric_types.h:24,\r\n                 from ./tensorflow/core/framework/allocator.h:26,\r\n                 from ./tensorflow/core/framework/tensor.h:22,\r\n                 from ./tensorflow/core/framework/variant_tensor_data.h:22,\r\n                 from tensorflow/core/framework/variant_tensor_data.cc:16:\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:30:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 20> Packet32q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:31:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 21> Packet16q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:32:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 22> Packet32q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:33:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 23> Packet16q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:34:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 25> Packet16q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:35:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 26> Packet8q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:36:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 27> Packet8q32i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:37:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 28> Packet4q32i;\r\n                                         ^\r\nINFO: From Compiling tensorflow/core/framework/tensor.cc:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:41:0,\r\n                 from ./tensorflow/core/framework/numeric_types.h:24,\r\n                 from ./tensorflow/core/framework/allocator.h:26,\r\n                 from ./tensorflow/core/framework/tensor.h:22,\r\n                 from tensorflow/core/framework/tensor.cc:30:\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:30:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 20> Packet32q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:31:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 21> Packet16q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:32:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 22> Packet32q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:33:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 23> Packet16q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:34:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 25> Packet16q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:35:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 26> Packet8q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:36:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 27> Packet8q32i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:37:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 28> Packet4q32i;\r\n                                         ^\r\nINFO: From Compiling tensorflow/core/framework/types.cc:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:41:0,\r\n                 from ./tensorflow/core/framework/types.h:27,\r\n                 from tensorflow/core/framework/types.cc:16:\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:30:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 20> Packet32q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:31:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 21> Packet16q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:32:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 22> Packet32q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:33:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 23> Packet16q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:34:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 25> Packet16q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:35:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 26> Packet8q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:36:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 27> Packet8q32i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:37:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 28> Packet4q32i;\r\n                                         ^\r\nINFO: From Compiling tensorflow/core/framework/variant_op_registry.cc:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:41:0,\r\n                 from ./tensorflow/core/framework/types.h:27,\r\n                 from ./tensorflow/core/framework/variant_op_registry.h:27,\r\n                 from tensorflow/core/framework/variant_op_registry.cc:16:\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:30:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 20> Packet32q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:31:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 21> Packet16q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:32:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 22> Packet32q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:33:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 23> Packet16q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:34:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 25> Packet16q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:35:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 26> Packet8q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:36:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 27> Packet8q32i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:37:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 28> Packet4q32i;\r\n                                         ^\r\nINFO: From Compiling tensorflow/core/framework/variant.cc:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:41:0,\r\n                 from ./tensorflow/core/framework/numeric_types.h:24,\r\n                 from ./tensorflow/core/framework/allocator.h:26,\r\n                 from ./tensorflow/core/framework/tensor.h:22,\r\n                 from ./tensorflow/core/framework/variant_tensor_data.h:22,\r\n                 from ./tensorflow/core/framework/variant.h:28,\r\n                 from tensorflow/core/framework/variant.cc:16:\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:30:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 20> Packet32q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:31:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 21> Packet16q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:32:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 22> Packet32q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:33:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 23> Packet16q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:34:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 25> Packet16q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:35:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 26> Packet8q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:36:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 27> Packet8q32i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:37:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 28> Packet4q32i;\r\n                                         ^\r\nINFO: From Compiling tensorflow/core/util/tensor_format.cc:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:41:0,\r\n                 from ./tensorflow/core/framework/numeric_types.h:24,\r\n                 from ./tensorflow/core/framework/allocator.h:26,\r\n                 from ./tensorflow/core/framework/tensor.h:22,\r\n                 from ./tensorflow/core/util/tensor_format.h:22,\r\n                 from tensorflow/core/util/tensor_format.cc:16:\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:30:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 20> Packet32q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:31:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 21> Packet16q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:32:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 22> Packet32q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:33:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 23> Packet16q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:34:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 25> Packet16q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:35:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 26> Packet8q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:36:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 27> Packet8q32i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:37:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 28> Packet4q32i;\r\n                                         ^\r\nINFO: From Compiling tensorflow/core/util/padding.cc:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:41:0,\r\n                 from ./tensorflow/core/framework/numeric_types.h:24,\r\n                 from ./tensorflow/core/framework/allocator.h:26,\r\n                 from ./tensorflow/core/framework/tensor.h:22,\r\n                 from ./tensorflow/core/util/tensor_format.h:22,\r\n                 from ./tensorflow/core/util/padding.h:26,\r\n                 from tensorflow/core/util/padding.cc:16:\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:30:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 20> Packet32q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:31:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 21> Packet16q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:32:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 22> Packet32q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:33:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 23> Packet16q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:34:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 25> Packet16q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:35:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 26> Packet8q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:36:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 27> Packet8q32i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:37:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 28> Packet4q32i;\r\n                                         ^\r\ntensorflow/core/util/padding.cc: In function 'tensorflow::Status tensorflow::CheckValidPadding(tensorflow::Padding, const std::vector<long long int>&, int, tensorflow::TensorFormat)':\r\ntensorflow/core/util/padding.cc:40:34: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n     if (explicit_paddings.size() != 2 * num_dims) {\r\n         ~~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~\r\nINFO: From Compiling tensorflow/core/framework/kernel_shape_util.cc:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:41:0,\r\n                 from ./tensorflow/core/framework/numeric_types.h:24,\r\n                 from ./tensorflow/core/framework/allocator.h:26,\r\n                 from ./tensorflow/core/framework/tensor.h:22,\r\n                 from ./tensorflow/core/util/tensor_format.h:22,\r\n                 from ./tensorflow/core/util/padding.h:26,\r\n                 from ./tensorflow/core/framework/kernel_shape_util.h:22,\r\n                 from tensorflow/core/framework/kernel_shape_util.cc:15:\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:30:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 20> Packet32q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:31:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 21> Packet16q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:32:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 22> Packet32q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:33:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 23> Packet16q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:34:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 25> Packet16q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:35:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 26> Packet8q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:36:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 27> Packet8q32i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:37:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 28> Packet4q32i;\r\n                                         ^\r\nINFO: From Compiling tensorflow/core/framework/typed_allocator.cc:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:41:0,\r\n                 from ./tensorflow/core/framework/numeric_types.h:24,\r\n                 from ./tensorflow/core/framework/allocator.h:26,\r\n                 from ./tensorflow/core/framework/typed_allocator.h:21,\r\n                 from tensorflow/core/framework/typed_allocator.cc:16:\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:30:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 20> Packet32q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:31:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 21> Packet16q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:32:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 22> Packet32q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:33:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 23> Packet16q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:34:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 25> Packet16q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:35:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 26> Packet8q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:36:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 27> Packet8q32i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:37:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 28> Packet4q32i;\r\n                                         ^\r\nINFO: From Compiling tensorflow/core/framework/attr_value_util.cc:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:41:0,\r\n                 from ./tensorflow/core/framework/numeric_types.h:24,\r\n                 from ./tensorflow/core/framework/allocator.h:26,\r\n                 from ./tensorflow/core/framework/tensor.h:22,\r\n                 from ./tensorflow/core/framework/attr_value_util.h:24,\r\n                 from tensorflow/core/framework/attr_value_util.cc:16:\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:30:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 20> Packet32q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:31:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 21> Packet16q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:32:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 22> Packet32q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:33:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 23> Packet16q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:34:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 25> Packet16q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:35:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 26> Packet8q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:36:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 27> Packet8q32i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:37:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 28> Packet4q32i;\r\n                                         ^\r\nINFO: From Compiling tensorflow/core/framework/op_def_util.cc:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:41:0,\r\n                 from ./tensorflow/core/framework/numeric_types.h:24,\r\n                 from ./tensorflow/core/framework/allocator.h:26,\r\n                 from ./tensorflow/core/framework/tensor.h:22,\r\n                 from ./tensorflow/core/framework/attr_value_util.h:24,\r\n                 from tensorflow/core/framework/op_def_util.cc:23:\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:30:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 20> Packet32q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:31:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 21> Packet16q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:32:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 22> Packet32q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:33:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 23> Packet16q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:34:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 25> Packet16q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:35:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 26> Packet8q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:36:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 27> Packet8q32i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:37:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 28> Packet4q32i;\r\n                                         ^\r\ntensorflow/core/framework/op_def_util.cc: In function 'tensorflow::Status tensorflow::OpDefCompatible(const tensorflow::OpDef&, const tensorflow::OpDef&)':\r\ntensorflow/core/framework/op_def_util.cc:664:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   for (int i = 0; i < old_in_ref.size(); ++i) {\r\n                   ~~^~~~~~~~~~~~~~~~~~~\r\ntensorflow/core/framework/op_def_util.cc:680:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   for (int i = 0; i < old_out_ref.size(); ++i) {\r\n                   ~~^~~~~~~~~~~~~~~~~~~~\r\nINFO: From Compiling tensorflow/core/framework/op_def_builder.cc:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:41:0,\r\n                 from ./tensorflow/core/framework/numeric_types.h:24,\r\n                 from ./tensorflow/core/framework/allocator.h:26,\r\n                 from ./tensorflow/core/framework/tensor.h:22,\r\n                 from ./tensorflow/core/framework/attr_value_util.h:24,\r\n                 from tensorflow/core/framework/op_def_builder.cc:23:\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:30:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 20> Packet32q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:31:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 21> Packet16q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:32:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 22> Packet32q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:33:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 23> Packet16q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:34:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 25> Packet16q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:35:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 26> Packet8q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:36:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 27> Packet8q32i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:37:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 28> Packet4q32i;\r\n                                         ^\r\nINFO: From Compiling tensorflow/core/framework/node_def_util.cc:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:41:0,\r\n                 from ./tensorflow/core/framework/numeric_types.h:24,\r\n                 from ./tensorflow/core/framework/allocator.h:26,\r\n                 from ./tensorflow/core/framework/tensor.h:22,\r\n                 from ./tensorflow/core/framework/attr_value_util.h:24,\r\n                 from ./tensorflow/core/framework/node_def_util.h:22,\r\n                 from tensorflow/core/framework/node_def_util.cc:16:\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:30:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 20> Packet32q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:31:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 21> Packet16q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:32:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 22> Packet32q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:33:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 23> Packet16q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:34:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 25> Packet16q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:35:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 26> Packet8q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:36:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 27> Packet8q32i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:37:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 28> Packet4q32i;\r\n                                         ^\r\ntensorflow/core/framework/node_def_util.cc: In function 'tensorflow::Status tensorflow::InputTypeForNode(const tensorflow::NodeDef&, const tensorflow::OpDef&, int, tensorflow::DataType*)':\r\ntensorflow/core/framework/node_def_util.cc:508:28: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n     if (input_types.size() > input_port) {\r\n         ~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~\r\ntensorflow/core/framework/node_def_util.cc: In function 'tensorflow::Status tensorflow::OutputTypeForNode(const tensorflow::NodeDef&, const tensorflow::OpDef&, int, tensorflow::DataType*)':\r\ntensorflow/core/framework/node_def_util.cc:531:29: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n     if (output_types.size() > output_port) {\r\n         ~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~\r\nINFO: From Compiling tensorflow/core/framework/node_properties.cc:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:41:0,\r\n                 from ./tensorflow/core/framework/types.h:27,\r\n                 from ./tensorflow/core/framework/node_properties.h:21,\r\n                 from tensorflow/core/framework/node_properties.cc:16:\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:30:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 20> Packet32q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:31:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 21> Packet16q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:32:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 22> Packet32q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:33:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 23> Packet16q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:34:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 25> Packet16q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:35:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 26> Packet8q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:36:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 27> Packet8q32i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:37:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 28> Packet4q32i;\r\n                                         ^\r\nINFO: From Compiling tensorflow/core/framework/shape_inference.cc:\r\nIn file included from ./third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:41:0,\r\n                 from ./tensorflow/core/framework/numeric_types.h:24,\r\n                 from ./tensorflow/core/framework/allocator.h:26,\r\n                 from ./tensorflow/core/framework/tensor.h:22,\r\n                 from ./tensorflow/core/framework/attr_value_util.h:24,\r\n                 from ./tensorflow/core/framework/node_def_util.h:22,\r\n                 from ./tensorflow/core/framework/shape_inference.h:21,\r\n                 from tensorflow/core/framework/shape_inference.cc:15:\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:30:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 20> Packet32q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:31:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 21> Packet16q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:32:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 22> Packet32q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:33:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 23> Packet16q8i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:34:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 25> Packet16q8u;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:35:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 26> Packet8q16i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:36:41: warning: ignoring attributes on template argument '__m256i {aka __vector(4) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m256i, 27> Packet8q32i;\r\n                                         ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX2.h:37:41: warning: ignoring attributes on template argument '__m128i {aka __vector(2) long long int}' [-Wignored-attributes]\r\n typedef eigen_packet_wrapper<__m128i, 28> Packet4q32i;\r\n                                         ^\r\ntensorflow/core/framework/shape_inference.cc: In constructor 'tensorflow::shape_inference::InferenceContext::InferenceContext(int, const tensorflow::AttrSlice&, const tensorflow::OpDef&, const std::vector<tensorflow::PartialTensorShape>&, const std::vector<const tensorflow::Tensor*>&, const std::vector<tensorflow::PartialTensorShape>&, const std::vector<std::unique_ptr<std::vector<std::pair<tensorflow::PartialTensorShape, tensorflow::DataType> > > >&)':\r\ntensorflow/core/framework/shape_inference.cc:65:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   for (int i = 0; i < input_handle_shapes_and_types.size(); ++i) {\r\n                   ~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/core/framework/shape_inference.cc:72:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n     for (int j = 0; j < v->size(); ++j) {\r\n                     ~~^~~~~~~~~~~\r\ntensorflow/core/framework/shape_inference.cc: In member function 'tensorflow::Status tensorflow::shape_inference::InferenceContext::set_output(tensorflow::StringPiece, const std::vector<tensorflow::shape_inference::ShapeHandle>&)':\r\ntensorflow/core/framework/shape_inference.cc:126:14: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n     if (size != shapes.size()) {\r\n         ~~~~~^~~~~~~~~~~~~~~~\r\ntensorflow/core/framework/shape_inference.cc: In member function 'tensorflow::Status tensorflow::shape_inference::InferenceContext::ExpandOutputs(int)':\r\ntensorflow/core/framework/shape_inference.cc:184:23: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   if (new_output_size < outputs_.size()) {\r\n       ~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~\r\ntensorflow/core/framework/shape_inference.cc: In member function 'void tensorflow::shape_inference::InferenceContext::PostInputInit(std::vector<std::unique_ptr<std::vector<tensorflow::shape_inference::ShapeAndType> > >)':\r\ntensorflow/core/framework/shape_inference.cc:213:22: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   if (inputs_.size() != num_inputs_from_node_def) {\r\n       ~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/core/framework/shape_inference.cc: In member function 'tensorflow::Status tensorflow::shape_inference::InferenceContext::MakeShapeFromShapeTensorTreatScalarAsUnknownShape(int, tensorflow::shape_inference::ShapeHandle*)':\r\ntensorflow/core/framework/shape_inference.cc:721:17: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   if (input_idx < input_tensors_as_shapes_.size() &&\r\n       ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/core/framework/shape_inference.cc: In member function 'tensorflow::Status tensorflow::shape_inference::InferenceContext::MakeShapeFromShapeTensor(int, tensorflow::shape_inference::ShapeHandle*)':\r\ntensorflow/core/framework/shape_inference.cc:739:17: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   if (input_idx < input_tensors_as_shapes_.size() &&\r\n       ~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/core/framework/shape_inference.cc: In member function 'tensorflow::Status tensorflow::shape_inference::InferenceContext::AttachContext(const tensorflow::Status&)':\r\ntensorflow/core/framework/shape_inference.cc:1102:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   for (int i = 0; i < inputs_.size(); ++i) {\r\n                   ~~^~~~~~~~~~~~~~~~\r\ntensorflow/core/framework/shape_inference.cc:1104:11: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n         i < input_tensors_as_shapes_.size() &&\r\n         ~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/core/framework/shape_inference.cc:1109:48: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n     } else if (requested_input_tensor_[i] && i < input_tensors_.size() &&\r\n                                              ~~^~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/core/framework/shape_inference.cc: In member function 'bool tensorflow::shape_inference::InferenceContext::MergeHandleShapesAndTypes(const std::vector<tensorflow::shape_inference::ShapeAndType>&, std::vector<tensorflow::shape_inference::ShapeAndType>*)':\r\ntensorflow/core/framework/shape_inference.cc:1143:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   for (int i = 0; i < shapes_and_types.size(); ++i) {\r\n                   ~~^~~~~~~~~~~~~~~~~~~~~~~~~\r\ntensorflow/core/framework/shape_inference.cc:1167:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   for (int i = 0; i < new_values.size(); ++i) {\r\n                   ~~^~~~~~~~~~~~~~~~~~~\r\ntensorflow/core/framework/shape_inference.cc: In member function 'bool tensorflow::shape_inference::InferenceContext::RelaxHandleShapesAndMergeTypes(const std::vector<tensorflow::shape_inference::ShapeAndType>&, std::vector<tensorflow::shape_inference::ShapeAndType>*)':\r\ntensorflow/core/framework/shape_inference.cc:1202:21: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   for (int i = 0; i < shapes_and_types.size(); ++i) {\r\n                   ~~^~~~~~~~~~~~~~~~~~~~~~~~~\r\nERROR: /tensorflow_src/tensorflow/core/kernels/BUILD:3688:1: C++ compilation of rule '//tensorflow/core/kernels:matrix_logarithm_op' failed (Exit 4)\r\ngcc: internal compiler error: Killed (program cc1plus)\r\nPlease submit a full bug report,\r\nwith preprocessed source if appropriate.\r\nSee <file:///usr/share/doc/gcc-7/README.Bugs> for instructions.\r\nTarget //tensorflow/tools/lib_package:libtensorflow failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 1577.241s, Critical Path: 61.37s\r\nINFO: 3718 processes: 3718 local.\r\nFAILED: Build did NOT complete successfully\r\n```", "@dcs3spp We are checking to see if you still need help on this issue. We recommend that you upgrade to 2.6 which is latest stable version of TF and let us know if the issue still persists in newer versions. we will get you the right help.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39328\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39328\">No</a>\n"]}, {"number": 39327, "title": "[XLA] Fix a bug in the copy operations", "body": "We found this bug in a TF1 model and the bug is also upstream. So I'm sending the fix.\r\n\r\nNote, the test isn't ideal. When the bug is there, it read and write bound memory that are outside the tensor. This will generate an CUDA_ERROR_ILLEGAL_ADDRESS error only when the wrong addresses aren't allocated. But in other cases, they could be allocated to other tensor.\r\n\r\nIn CUDA, I would allocate an overly big tensors and fill them with dummy values. Then after the code, I would check the output that shouldn't change and see if it changed. I'm not sure if we can do this with reasonable effort with XLA.", "comments": ["The import failed and the WIndows and Mac CI failed, but I can't see the logs.", "The windows error has a pretty useless message, but I think it implies that it's not your fault: `tensorflow\\compiler\\xla\\literal.cc(1166) : fatal error C1001: An internal error has occurred in the compiler.`\r\n\r\nThe ubuntu and mac failures also seem to not be your fault as they look like tf_runtime related compilation problems.\r\n\r\nI'll try find what's causing them and let you know once they're handled.", "> The windows error has a pretty useless message, but I think it implies that it's not your fault: `tensorflow\\compiler\\xla\\literal.cc(1166) : fatal error C1001: An internal error has occurred in the compiler.`\r\n> \r\n> The ubuntu and mac failures also seem to not be your fault as they look like tf_runtime related compilation problems.\r\n> \r\n> I'll try find what's causing them and let you know once they're handled.\r\n\r\nSorry for the breakage in tf_to_cubin and cubin_creator, this was a CL by me. Should be fixed by now.", "tf_runtime is still broken, and it seems this is hard to fix. The team did some refactoring in tf_runtime that means that tensorflow cannot update the tf_runtime hash, but without updating there are also breakages. Hopefully the team will find a solution soon."]}, {"number": 39326, "title": "No module named 'tensorflow.python.types' when building estimator from master branch", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nLunux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary):\r\nPip install tensorflow==2.2.0\r\n- TensorFlow version:\r\n2.2.0\r\n- Python version:\r\n3.6\r\n- Installed using virtualenv? pip? conda?:\r\npip\r\n- Bazel version (if compiling from source):\r\n2.0.0 & 0.25.0\r\n- GCC/Compiler version (if compiling from source):\r\n5.4.0\r\n\r\n**Describe the problem**\r\nI'm trying to compile the estimator binary from the tensorflow/estimator master branch, using the bazel commands that listed on the readme page. The building failed with the error:\r\n\r\n```\r\nFile \"/home/ubuntu/.cache/bazel/_bazel_ubuntu/9e73ac3ed666d141725dcd5fe404d502/sandbox/linux-sandbox/2/execroot/org_tensorflow_estimator/bazel-out/host/bin/tensorflow_estimator/python/estimator/api/create_tensorflow_estimator.python.estimator_api_1_estimator_python_api_gen_compat_v1.runfiles/org_tensorflow_estimator/tensorflow_estimator/python/estimator/model_fn.py\", line 29, in <module>\r\n    from tensorflow.python.types import core\r\nModuleNotFoundError: No module named 'tensorflow.python.types'\r\n```\r\n\r\nI tried to clean the directory and checkout the `esitimator/r2.2` branch, built with the same environment and command. That build was passed with no error.\r\nCould someone suggest why master branch is having this import issue? Thanks\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n```\r\ngit clone https://github.com/tensorflow/estimator.git\r\npip uninstall -y tensorflow\r\npip install tensorflow==2.2.0\r\nbazel build //tensorflow_estimator/tools/pip_package:build_pip_package\r\n```\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```\r\n/home/ubuntu/estimator/tensorflow_estimator/python/estimator/api/BUILD:38:1: Executing genrule //tensorflow_estimator/python/estimator/api:estimator_python_api_gen_compat_v1 failed (Exit 1) bash failed: error executing command /bin/bash -c ... (remaining 1 argument(s) skipped)\r\n\r\nUse --sandbox_debug to see verbose messages from the sandbox\r\nTraceback (most recent call last):\r\n  File \"/home/ubuntu/.cache/bazel/_bazel_ubuntu/9e73ac3ed666d141725dcd5fe404d502/sandbox/linux-sandbox/2/execroot/org_tensorflow_estimator/bazel-out/host/bin/tensorflow_estimator/python/estimator/api/create_tensorflow_estimator.python.estimator_api_1_estimator_python_api_gen_compat_v1.runfiles/org_tensorflow_estimator/tensorflow_estimator/python/estimator/api/create_python_api_wrapper.py\", line 26, in <module>\r\n    from tensorflow_estimator.python.estimator import estimator_lib  # pylint: disable=unused-import\r\n  File \"/home/ubuntu/.cache/bazel/_bazel_ubuntu/9e73ac3ed666d141725dcd5fe404d502/sandbox/linux-sandbox/2/execroot/org_tensorflow_estimator/bazel-out/host/bin/tensorflow_estimator/python/estimator/api/create_tensorflow_estimator.python.estimator_api_1_estimator_python_api_gen_compat_v1.runfiles/org_tensorflow_estimator/tensorflow_estimator/python/estimator/estimator_lib.py\", line 22, in <module>\r\n    from tensorflow_estimator.python.estimator.canned.baseline import BaselineClassifier\r\n  File \"/home/ubuntu/.cache/bazel/_bazel_ubuntu/9e73ac3ed666d141725dcd5fe404d502/sandbox/linux-sandbox/2/execroot/org_tensorflow_estimator/bazel-out/host/bin/tensorflow_estimator/python/estimator/api/create_tensorflow_estimator.python.estimator_api_1_estimator_python_api_gen_compat_v1.runfiles/org_tensorflow_estimator/tensorflow_estimator/python/estimator/canned/baseline.py\", line 59, in <module>\r\n    from tensorflow_estimator.python.estimator import estimator\r\n  File \"/home/ubuntu/.cache/bazel/_bazel_ubuntu/9e73ac3ed666d141725dcd5fe404d502/sandbox/linux-sandbox/2/execroot/org_tensorflow_estimator/bazel-out/host/bin/tensorflow_estimator/python/estimator/api/create_tensorflow_estimator.python.estimator_api_1_estimator_python_api_gen_compat_v1.runfiles/org_tensorflow_estimator/tensorflow_estimator/python/estimator/estimator.py\", line 51, in <module>\r\n    from tensorflow_estimator.python.estimator import model_fn as model_fn_lib\r\n  File \"/home/ubuntu/.cache/bazel/_bazel_ubuntu/9e73ac3ed666d141725dcd5fe404d502/sandbox/linux-sandbox/2/execroot/org_tensorflow_estimator/bazel-out/host/bin/tensorflow_estimator/python/estimator/api/create_tensorflow_estimator.python.estimator_api_1_estimator_python_api_gen_compat_v1.runfiles/org_tensorflow_estimator/tensorflow_estimator/python/estimator/model_fn.py\", line 29, in <module>\r\n    from tensorflow.python.types import core\r\nModuleNotFoundError: No module named 'tensorflow.python.types'\r\nTarget //tensorflow_estimator/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nERROR: /home/ubuntu/estimator/tensorflow_estimator/tools/pip_package/BUILD:18:1 Executing genrule //tensorflow_estimator/python/estimator/api:estimator_python_api_gen_compat_v1 failed (Exit 1) bash failed: error executing command /bin/bash -c ... (remaining 1 argument(s) skipped)\r\n\r\nUse --sandbox_debug to see verbose messages from the sandbox\r\nINFO: Elapsed time: 5.025s, Critical Path: 1.66s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully\r\n```", "comments": ["`tf.estimator` is installed silently when you install the TensorFlow pip package. So you may skip building tf.estimator package locally.\r\n", "> `tf.estimator` is installed silently when you install the TensorFlow pip package. So you may skip building tf.estimator package locally.\r\n\r\nhi, we need to modify the estimator source codes before building it. To have our customized estimator binary, the building process cannot be skipped. thanks", "Can you post the output of `pip list` before and after building TF Estimator?", "> Can you post the output of `pip list` before and after building TF Estimator?\r\n\r\nhey, sorry for the late reply. the result of pip list is:\r\n\r\n```\r\n~/estimator$ pip list\r\nPackage                            Version\r\n---------------------------------- --------------\r\nabsl-py                            0.9.0\r\nalabaster                          0.7.12\r\nanaconda-client                    1.7.2\r\nanaconda-navigator                 1.9.7\r\nanaconda-project                   0.8.3\r\nappdirs                            1.4.4\r\nasn1crypto                         1.3.0\r\nastroid                            2.3.3\r\nastunparse                         1.6.3\r\natomicwrites                       1.3.0\r\nattrs                              19.3.0\r\nawscli                             1.18.65\r\nBabel                              2.8.0\r\nbackcall                           0.1.0\r\nbackports.functools-lru-cache      1.6.1\r\nbackports.shutil-get-terminal-size 1.0.0\r\nbackports.tempfile                 1.0\r\nbackports.weakref                  1.0.post1\r\nbcrypt                             3.1.7\r\nbeautifulsoup4                     4.8.2\r\nbitarray                           1.2.1\r\nbleach                             3.1.0\r\nboto                               2.49.0\r\nboto3                              1.9.162\r\nbotocore                           1.16.15\r\ncachetools                         4.1.0\r\ncertifi                            2020.4.5.1\r\ncffi                               1.13.2\r\nchardet                            3.0.4\r\nClick                              7.0\r\ncloudpickle                        1.2.2\r\nclyent                             1.2.2\r\ncolorama                           0.4.3\r\nconda                              4.8.2\r\nconda-build                        3.18.11\r\nconda-package-handling             1.6.0\r\nconda-verify                       3.4.2\r\nconfigparser                       5.0.0\r\ncontextlib2                        0.6.0.post1\r\ncryptography                       2.8\r\ncycler                             0.10.0\r\nCython                             0.29.14\r\ncytoolz                            0.10.1\r\ndask                               2.10.1\r\ndecorator                          4.4.1\r\ndefusedxml                         0.6.0\r\ndistlib                            0.3.0\r\ndistributed                        2.10.0\r\ndocutils                           0.15.2\r\nentrypoints                        0.3\r\net-xmlfile                         1.0.1\r\nFabric3                            1.14.post1\r\nfastcache                          1.1.0\r\nfilelock                           3.0.12\r\nFlask                              1.1.1\r\nFlask-Cors                         3.0.8\r\nfuture                             0.18.2\r\ngast                               0.3.3\r\ngevent                             1.4.0\r\nglob2                              0.7\r\ngmpy2                              2.0.8\r\ngoogle-auth                        1.14.2\r\ngoogle-auth-oauthlib               0.4.1\r\ngoogle-pasta                       0.2.0\r\ngreenlet                           0.4.15\r\ngrpcio                             1.28.1\r\nh5py                               2.10.0\r\nHeapDict                           1.0.1\r\nhtml5lib                           1.0.1\r\nidna                               2.9\r\nimagesize                          1.2.0\r\nimportlib-metadata                 1.5.0\r\ninflect                            4.1.0\r\nipykernel                          5.1.4\r\nipython                            7.12.0\r\nipython-genutils                   0.2.0\r\nipywidgets                         7.5.1\r\nisort                              4.3.21\r\nitsdangerous                       1.1.0\r\njaraco.itertools                   5.0.0\r\njdcal                              1.4.1\r\njedi                               0.16.0\r\njeepney                            0.4.2\r\nJinja2                             2.11.1\r\njmespath                           0.9.4\r\njoblib                             0.14.1\r\njson5                              0.9.0\r\njsonschema                         3.2.0\r\njupyter                            1.0.0\r\njupyter-client                     5.3.4\r\njupyter-console                    6.1.0\r\njupyter-core                       4.6.1\r\njupyterlab                         1.2.6\r\njupyterlab-launcher                0.13.1\r\njupyterlab-server                  1.0.6\r\nKeras-Preprocessing                1.1.0\r\nkeyring                            21.1.0\r\nkiwisolver                         1.1.0\r\nlazy-object-proxy                  1.4.3\r\nlibarchive-c                       2.8\r\nlief                               0.9.0\r\nllvmlite                           0.31.0\r\nlocket                             0.2.0\r\nlxml                               4.3.0\r\nMarkdown                           3.2.1\r\nMarkupSafe                         1.1.1\r\nmccabe                             0.6.1\r\nmistune                            0.8.4\r\nmore-itertools                     8.2.0\r\nmpmath                             1.1.0\r\nmsgpack                            0.6.1\r\nmultipledispatch                   0.6.0\r\nnavigator-updater                  0.2.1\r\nnb-conda                           2.2.1\r\nnb-conda-kernels                   2.2.2\r\nnbconvert                          5.4.1\r\nnbformat                           5.0.4\r\nnetworkx                           2.4\r\nnltk                               3.4.5\r\nnose                               1.3.7\r\nnotebook                           6.0.3\r\nnumpy                              1.16.0\r\nnumpydoc                           0.9.2\r\noauthlib                           3.1.0\r\nolefile                            0.46\r\nopenpyxl                           3.0.3\r\nopt-einsum                         3.2.1\r\npackaging                          20.1\r\npandocfilters                      1.4.2\r\nparamiko                           2.7.1\r\nparso                              0.6.0\r\npartd                              1.1.0\r\npath                               13.1.0\r\npathlib2                           2.3.5\r\npep8                               1.7.1\r\npexpect                            4.8.0\r\npickleshare                        0.7.5\r\nPillow                             5.4.1\r\npip                                20.1.1\r\npkginfo                            1.5.0.1\r\npluggy                             0.13.1\r\nply                                3.11\r\nportpicker                         1.3.1\r\nprometheus-client                  0.7.1\r\nprompt-toolkit                     3.0.3\r\nprotobuf                           3.11.3\r\npsutil                             5.6.7\r\nptyprocess                         0.6.0\r\npy                                 1.8.1\r\npyasn1                             0.4.8\r\npyasn1-modules                     0.2.8\r\npycodestyle                        2.5.0\r\npycosat                            0.6.3\r\npycparser                          2.19\r\npycrypto                           2.6.1\r\npycurl                             7.43.0.5\r\npyflakes                           2.1.1\r\nPygments                           2.5.2\r\npykerberos                         1.2.1\r\npylint                             2.4.4\r\nPyNaCl                             1.3.0\r\npyodbc                             4.0.24\r\npyOpenSSL                          19.1.0\r\npyparsing                          2.4.6\r\npyrsistent                         0.15.7\r\nPySocks                            1.7.1\r\npytest                             5.0.1\r\npytest-openfiles                   0.4.0\r\npytest-remotedata                  0.3.2\r\npython-dateutil                    2.8.1\r\npytz                               2019.3\r\nPyYAML                             3.13\r\npyzmq                              17.1.2\r\nQtAwesome                          0.6.1\r\nqtconsole                          4.6.0\r\nQtPy                               1.9.0\r\nrequests                           2.23.0\r\nrequests-oauthlib                  1.3.0\r\nrope                               0.16.0\r\nrsa                                3.4.2\r\nruamel-yaml                        0.15.87\r\ns3fs                               0.1.5\r\ns3transfer                         0.2.1\r\nscikit-learn                       0.23.0\r\nscipy                              1.4.1\r\nSecretStorage                      3.1.2\r\nSend2Trash                         1.5.0\r\nsetuptools                         46.1.3\r\nshadowsocks                        2.8.2\r\nsimplegeneric                      0.8.1\r\nsingledispatch                     3.4.0.3\r\nsix                                1.12.0\r\nsnowballstemmer                    2.0.0\r\nsortedcollections                  1.1.2\r\nsortedcontainers                   2.1.0\r\nsoupsieve                          1.9.5\r\nSphinx                             2.3.1\r\nsphinxcontrib-applehelp            1.0.1\r\nsphinxcontrib-devhelp              1.0.1\r\nsphinxcontrib-htmlhelp             1.0.2\r\nsphinxcontrib-jsmath               1.0.1\r\nsphinxcontrib-qthelp               1.0.2\r\nsphinxcontrib-serializinghtml      1.1.3\r\nsphinxcontrib-websupport           1.1.2\r\nspyder                             3.3.6\r\nspyder-kernels                     0.5.2\r\nSQLAlchemy                         1.3.13\r\nsympy                              1.5.1\r\ntb-nightly                         2.3.0a20200604\r\ntblib                              1.6.0\r\ntensorboard                        2.2.1\r\ntensorboard-plugin-wit             1.6.0.post3\r\ntensorflow                         2.2.0\r\ntermcolor                          1.1.0\r\nterminado                          0.8.3\r\ntestpath                           0.4.4\r\nthreadpoolctl                      2.0.0\r\ntoolz                              0.10.0\r\ntornado                            6.0.3\r\ntqdm                               4.42.0\r\ntraitlets                          4.3.3\r\ntyping                             3.6.4\r\nunicodecsv                         0.14.1\r\nurllib3                            1.25.9\r\nvirtualenv                         20.0.21\r\nwcwidth                            0.1.8\r\nwebencodings                       0.5.1\r\nWerkzeug                           1.0.1\r\nwheel                              0.34.2\r\nwidgetsnbextension                 3.5.1\r\nwrapt                              1.12.1\r\nwurlitzer                          2.0.0\r\nxlrd                               1.2.0\r\nXlsxWriter                         1.2.7\r\nxlwt                               1.3.0\r\nzict                               1.0.0\r\nzipp                               2.1.0\r\n```\r\n\r\nI've compared the pip list result of before and after building tf estimator, the results are the same.\r\nThank you", "Hmm, let's try building while you have installed `tf-nightly`. That is, let's try running the following\r\n\r\n```\r\npip uninstall -y tensorflow tensorboard\r\npip install tf-nightly\r\n# now build estimator from master's branch, probably after a new sync\r\n```", "> Hmm, let's try building while you have installed `tf-nightly`. That is, let's try running the following\r\n> \r\n> ```\r\n> pip uninstall -y tensorflow tensorboard\r\n> pip install tf-nightly\r\n> # now build estimator from master's branch, probably after a new sync\r\n> ```\r\n\r\nThanks for the suggestion. I've tried to uninstall tensorflow, tensorflow-gpu and tensorboard, then install tf-nightly:\r\n```\r\nubuntu@ip-172-31-14-213:~/estimator$ pip show tf-nightly\r\nName: tf-nightly\r\nVersion: 2.5.0.dev20200629\r\nSummary: TensorFlow is an open source machine learning framework for everyone.\r\nHome-page: https://www.tensorflow.org/\r\nAuthor: Google Inc.\r\nAuthor-email: packages@tensorflow.org\r\nLicense: Apache 2.0\r\nLocation: /home/ubuntu/anaconda3/lib/python3.7/site-packages\r\nRequires: scipy, tf-estimator-nightly, opt-einsum, google-pasta, wrapt, wheel, absl-py, h5py, termcolor, tb-nightly, six, astunparse, gast, numpy, keras-preprocessing, grpcio, protobuf\r\n\r\n```\r\n\r\nThen fetch and pull the latest estimator/master. Run the build with \r\n`bazel build //tensorflow_estimator/tools/pip_package:build_pip_package\r\n`\r\nThe build failed with a new error:\r\n\r\nAttributeError: module 'tensorflow' has no attribute 'compat'\r\n\r\n", "Full error message:\r\n\r\n```\r\nubuntu@ip-172-31-14-213:~/estimator$ bazel build //tensorflow_estimator/tools/pip_package:build_pip_package\r\nINFO: Analyzed target //tensorflow_estimator/tools/pip_package:build_pip_package (0 packages loaded, 0 targets configured).\r\nINFO: Found 1 target...\r\nERROR: /home/ubuntu/estimator/tensorflow_estimator/BUILD:79:19: Executing genrule //tensorflow_estimator:estimator_python_api_gen_compat_v2 failed (Exit 1) bash failed: error executing command /bin/bash -c ... (remaining 1 argument(s) skipped)\r\n\r\nUse --sandbox_debug to see verbose messages from the sandbox\r\n2020-06-29 18:42:13.382333: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64/openmpi/lib/:/usr/local/cuda/lib64:/usr/local/lib:/usr/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/mpi/lib:/lib/:/home/ubuntu/src/cntk/bindings/python/cntk/libs:/usr/local/cuda/lib64:/usr/local/lib:/usr/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/mpi/lib:/usr/lib64/openmpi/lib/:/usr/local/cuda/lib64:/usr/local/lib:/usr/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/mpi/lib:/lib/:\r\n2020-06-29 18:42:13.382396: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\nTraceback (most recent call last):\r\n  File \"/home/ubuntu/.cache/bazel/_bazel_ubuntu/9e73ac3ed666d141725dcd5fe404d502/sandbox/linux-sandbox/5/execroot/org_tensorflow_estimator/bazel-out/host/bin/tensorflow_estimator/create_tensorflow_estimator.python.estimator_api_2_estimator_python_api_gen_compat_v2.runfiles/org_tensorflow_estimator/tensorflow_estimator/python/estimator/api/create_python_api_wrapper.py\", line 26, in <module>\r\n    from tensorflow_estimator.python.estimator import estimator_lib  # pylint: disable=unused-import\r\n  File \"/home/ubuntu/.cache/bazel/_bazel_ubuntu/9e73ac3ed666d141725dcd5fe404d502/sandbox/linux-sandbox/5/execroot/org_tensorflow_estimator/bazel-out/host/bin/tensorflow_estimator/create_tensorflow_estimator.python.estimator_api_2_estimator_python_api_gen_compat_v2.runfiles/org_tensorflow_estimator/tensorflow_estimator/python/estimator/estimator_lib.py\", line 22, in <module>\r\n    from tensorflow_estimator.python.estimator.canned.baseline import BaselineClassifier\r\n  File \"/home/ubuntu/.cache/bazel/_bazel_ubuntu/9e73ac3ed666d141725dcd5fe404d502/sandbox/linux-sandbox/5/execroot/org_tensorflow_estimator/bazel-out/host/bin/tensorflow_estimator/create_tensorflow_estimator.python.estimator_api_2_estimator_python_api_gen_compat_v2.runfiles/org_tensorflow_estimator/tensorflow_estimator/python/estimator/canned/baseline.py\", line 59, in <module>\r\n    from tensorflow_estimator.python.estimator import estimator\r\n  File \"/home/ubuntu/.cache/bazel/_bazel_ubuntu/9e73ac3ed666d141725dcd5fe404d502/sandbox/linux-sandbox/5/execroot/org_tensorflow_estimator/bazel-out/host/bin/tensorflow_estimator/create_tensorflow_estimator.python.estimator_api_2_estimator_python_api_gen_compat_v2.runfiles/org_tensorflow_estimator/tensorflow_estimator/python/estimator/estimator.py\", line 53, in <module>\r\n    from tensorflow_estimator.python.estimator import util as estimator_util\r\n  File \"/home/ubuntu/.cache/bazel/_bazel_ubuntu/9e73ac3ed666d141725dcd5fe404d502/sandbox/linux-sandbox/5/execroot/org_tensorflow_estimator/bazel-out/host/bin/tensorflow_estimator/create_tensorflow_estimator.python.estimator_api_2_estimator_python_api_gen_compat_v2.runfiles/org_tensorflow_estimator/tensorflow_estimator/python/estimator/util.py\", line 75, in <module>\r\n    class _DatasetInitializerHook(tf.compat.v1.train.SessionRunHook):\r\nAttributeError: module 'tensorflow' has no attribute 'compat'\r\nTarget //tensorflow_estimator/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nERROR: /home/ubuntu/estimator/tensorflow_estimator/tools/pip_package/BUILD:18:10 Executing genrule //tensorflow_estimator:estimator_python_api_gen_compat_v2 failed (Exit 1) bash failed: error executing command /bin/bash -c ... (remaining 1 argument(s) skipped)\r\n\r\nUse --sandbox_debug to see verbose messages from the sandbox\r\nINFO: Elapsed time: 1.926s, Critical Path: 1.73s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully\r\n```", "It could be the Bazel cache already contains stale data. Let's give this one more try. Can you run the following commands please (in the clone of Estimator)?\r\n\r\n```\r\nbazel clean --expunge\r\ncd ..\r\nrm -rf estimator\r\npython -m virtualenv venv\r\nsource venv/bin/activate\r\npip install tf-nightly\r\ngit clone $estimator_repo_url  # fill in with the URL from which you clone\r\ncd estimator\r\nbazel build //tensorflow_estimator/tools/pip_package:build_pip_package &> log.txt\r\ndeactivate\r\n```\r\n\r\nAnd then attach `log.txt` in a reply. If possible, also copy-paste the output of all the commands above (which first reset environment to a clean state, then create a virtual environment for python packages to ensure no collusion with system-wide installs, then clones estimator and builds the pip package)", "If you try uninstalling and reinstaling tensorflow-estimator=1.x, it might work. Did for me. ", "> It could be the Bazel cache already contains stale data. Let's give this one more try. Can you run the following commands please (in the clone of Estimator)?\r\n> \r\n> ```\r\n> bazel clean --expunge\r\n> cd ..\r\n> rm -rf estimator\r\n> python -m virtualenv venv\r\n> source venv/bin/activate\r\n> pip install tf-nightly\r\n> git clone $estimator_repo_url  # fill in with the URL from which you clone\r\n> cd estimator\r\n> bazel build //tensorflow_estimator/tools/pip_package:build_pip_package &> log.txt\r\n> deactivate\r\n> ```\r\n> \r\n> And then attach `log.txt` in a reply. If possible, also copy-paste the output of all the commands above (which first reset environment to a clean state, then create a virtual environment for python packages to ensure no collusion with system-wide installs, then clones estimator and builds the pip package)\r\n\r\nbuilding in virtualenv worked. thank you!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39326\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39326\">No</a>\n", "Hello.\r\n\r\nI've been trying to install TensorFlow with Anaconda on Windows for a few days now. Every version of the 2.x.x branch of TensorFlow is defective, and, is impossible to get running because of import errors.\r\n\r\nI landed on this ticket's page because I had to downgrade TensorFlow from 2.3 (2.2. and 2.3 are completely broken and wouldn't work with any CUDA GPUs) to 2.1. And, when trying to run 2.1 version, it is unable to import the estimator because estimator cannot import `tensorflow.python.types`. I looked at the code that requires this package, and I cannot find anything in the entire distribution of the tons of different packages named \"tensorflow-something\" anything similar to \"types.core\", as that what's being used actually in the code. \r\n\r\nThis ticket was unhelpful in understanding how to solve the problem. Not even in understanding what the problem actually is. I would appreciate some information on what this missing package is, and how to find it, if I'm missing it.\r\n\r\nPS. I will not use Bazel to build TensorFlow. It's another extremely broken and convoluted system. I have no faith that going down that path will not just create more problems. I just want to find a distribution that works on Windows 10. Is this too much to ask?", "Hi can someone guide me how to resolve this issue.\r\n\r\n  from tensorflow_estimator.python.estimator import model_fn\r\n  File \"/home/fazal/anaconda3/lib/python3.6/site-packages/tensorflow_estimator/python/estimator/model_fn.py\", line 29, in <module>\r\n    from tensorflow.python.types import core\r\nModuleNotFoundError: No module named 'tensorflow.python.types'\r\n", "> ModuleNotFoundError: No module named 'tensorflow.python.types'\r\n\r\nHave you tried upgrading pip3 and reinstalling it?"]}, {"number": 39325, "title": "[INTEL MKL] Enabling DNNL SGEMM and removing all code related to MKL matmuls.", "body": "This PR enables DNNL SGEMM for fp32 and bfloat16. It also removes all code related to mkl binary blob matmuls especially for types like double and complex. These types will go through native tensorflow backend now. ", "comments": []}, {"number": 39324, "title": "Add blank_index parameter for ctc_greedy_decoder", "body": "This PR resolves issue #32903. \r\n\r\nAdded an extra parameter in ctc_greedy_decoder to be able to specify the blank index. Also updated test cases and documentation.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F39324) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F39324) for more info**.\n\n<!-- ok -->", "Hello @ebrevdo, are there any updates on this?", "@ebrevdo, Any update on this PR? Please. Thanks!", "Approved.  You should fix the comments that are one space past the end of line; linter requires 2 spaces.", "@pvarouktsis Any update on this PR? Please. Thanks!", "@gbaned Sorry! I don't have any updates yet! I 'll start working as soon as possible.", "@pvarouktsis Any update on this PR? Please. Thanks!", "Yes, I'm still active! I will have an update soon!", "@pvarouktsis  Can you please check @ebrevdo's comments and keep us posted ? Thanks!", "@ebrevdo thanks a lot! Did not know that I should have a default value for backwards compatibility! I' ll proceed to these changes.", "Thanks!  You will additionally need to make sure that the blank_index you\ncalculate is not out of bounds to avoid segfaults.\n\nOn Thu, Nov 5, 2020 at 10:25 AM Panagiotis Varouktsis <\nnotifications@github.com> wrote:\n\n> @ebrevdo <https://github.com/ebrevdo> thanks a lot! Did not know that I\n> should have a default value for backwards compatibility! I' ll proceed to\n> these changes.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/39324#issuecomment-722556414>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AANWFGYQB3YRP3BGLTLNKT3SOLUYXANCNFSM4M4M6RBA>\n> .\n>\n", "Alright! I appreciate your help!", "@pvarouktsis Any update on this PR? Please. Thanks!", "Unfortunately not yet, but I will have an update soon.", "@pvarouktsis can you please check sanity build failures ?", "Yes, will do!", "@pvarouktsis  Any update on this PR? Please. Thanks!", "Yes, I'm still valid! I'll try to have an update soon!", "Yes, I'm still valid!", "@pvarouktsis Any update on this PR? Please. Thanks!", "Sorry, I do not have any updates yet!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "Yes, I'm still valid.", "@ebrevdo Can you please review this PR ? Thanks!", "Thank you very much!"]}, {"number": 39322, "title": "C++ compilation of rule '//tensorflow/core/kernels:sparse_reduce_op' failed (Exit 1)", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Debian GNU/Linux 9.12 (stretch)\r\n- TensorFlow version: 2.1\r\n- Python version: 3.7\r\n- Installed using virtualenv? pip? conda?: N/A\r\n- Bazel version (if compiling from source): 3.1.0\r\n- GCC/Compiler version (if compiling from source): gcc (Debian 6.3.0-18+deb9u1) 6.3.0 20170516\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n\r\n\r\n**Describe the problem**\r\nI'm trying to build tensorflow from source, it keeps running for several hours then the build fails and I get the error:\r\n\r\n```\r\nERROR: /home/emadboctor/tensorflow/tensorflow/core/kernels/BUILD:5398:1: C++ compilation of rule '//tensorflow/core/kernels:sparse_reduce_op' failed (Exit 1)\r\n    In file included from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:104:0,\r\n                     from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                     from ./tensorflow/core/framework/numeric_types.h:20,\r\n                     from ./tensorflow/core/framework/allocator.h:26,\r\n                     from ./tensorflow/core/framework/op_kernel.h:24,\r\n                     from tensorflow/core/kernels/sparse_reduce_op.cc:20:\r\n    external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorReduction.h: In static member function 'static void std::_Function_handler<void(_ArgTypes ...), _Functor>::_M_invoke(const std::_Any_data&, _ArgTypes&& ...) [with _Functor = Eigen::internal::TensorExecutor<Expression, Eigen::ThreadPoolDevice, Vectorizable, Tiling>::run(const Expression&, const Eigen::ThreadPoolDevice&) [with Expression = const Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::TensorFixedSize<std::complex<float>, Eigen::Sizes<>, 1, long int>, 16, Eigen::MakePointer>, const Eigen::TensorReductionOp<Eigen::internal::SumReducer<std::complex<float> >, const Eigen::DimensionList<long int, 1ul>, const Eigen::TensorMap<Eigen::Tensor<std::complex<float>, 1, 1, long int>, 0, Eigen::MakePointer>, Eigen::MakePointer> >; bool Vectorizable = true; Eigen::internal::TiledEvaluation Tiling = (Eigen::internal::TiledEvaluation)0u]::<lambda(Eigen::internal::TensorExecutor<const Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::TensorFixedSize<std::complex<float>, Eigen::Sizes<>, 1, long int>, 16, Eigen::MakePointer>, const Eigen::TensorReductionOp<Eigen::internal::SumReducer<std::complex<float> >, const Eigen::DimensionList<long int, 1ul>, const Eigen::TensorMap<Eigen::Tensor<std::complex<float>, 1, 1, long int>, 0, Eigen::MakePointer>, Eigen::MakePointer> >, Eigen::ThreadPoolDevice, true, (Eigen::internal::TiledEvaluation)0u>::StorageIndex, Eigen::internal::TensorExecutor<const Eigen::TensorAssignOp<Eigen::TensorMap<Eigen::TensorFixedSize<std::complex<float>, Eigen::Sizes<>, 1, long int>, 16, Eigen::MakePointer>, const Eigen::TensorReductionOp<Eigen::internal::SumReducer<std::complex<float> >, const Eigen::DimensionList<long int, 1ul>, const Eigen::TensorMap<Eigen::Tensor<std::complex<float>, 1, 1, long int>, 0, Eigen::MakePointer>, Eigen::MakePointer> >, Eigen::ThreadPoolDevice, true, (Eigen::internal::TiledEvaluation)0u>::StorageIndex)>; _ArgTypes = {long int, long int}]':\r\n    external/eigen_archive/unsupported/Eigen/CXX11/src/Tensor/TensorReduction.h:806:9: internal compiler error: in emit_move_insn, at expr.c:3547\r\n             values[i] = internal::InnerMostDimReducer<Self, Op>::reduce(*this, firstIndex + i * num_values_to_reduce,\r\n             ^~~~~~\r\n    Please submit a full bug report,\r\n    with preprocessed source if appropriate.\r\n    See <file:///usr/share/doc/gcc-6/README.Bugs> for instructions.\r\n    Target //tensorflow/tools/pip_package:build_pip_package failed to build\r\n    Use --verbose_failures to see the command lines of failed build steps.\r\n    ERROR: /home/emadboctor/tensorflow/tensorflow/tools/pip_package/BUILD:65:1 C++ compilation of rule '//tensorflow/core/kernels:sparse_reduce_op' failed (Exit 1)\r\n    INFO: Elapsed time: 8153.055s, Critical Path: 926.03s\r\n    INFO: 8566 processes: 8566 local.\r\n    FAILED: Build did NOT complete successfully\r\n```\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n```\r\napt update && apt install -y \\\r\n        build-essential \\\r\n        libc-ares-dev \\\r\n        libjpeg-dev \\\r\n        openjdk-8-jdk \\\r\n        gcc \\\r\n        g++ \\\r\n        python3-pip \\\r\n```\r\n\r\n    pip3 install six numpy wheel setuptools mock && \\\r\n        pip3 install keras_applications --no-deps && \\\r\n        pip3 install keras_preprocessing --no-deps\r\n\r\n    sudo apt-get update\r\n    sudo apt-get -y upgrade\r\n    wget https://dl.google.com/go/go1.13.3.linux-amd64.tar.gz\r\n    sudo tar -xvf go1.13.3.linux-amd64.tar.gz\r\n    sudo mv go /usr/local\r\n    export GOROOT=/usr/local/go\r\n    export GOPATH=$HOME/Projects/Proj1\r\n    export PATH=$GOPATH/bin:$GOROOT/bin:$PATH\r\n    go get github.com/bazelbuild/bazelisk\r\n    mkdir -p ~/bin\r\n    ln -s $(go env GOPATH)/bin/bazelisk ~/bin/bazel\r\n    export PATH=$HOME/bin:$PATH\r\n    git clone https://github.com/tensorflow/tensorflow\r\n    cd tensorflow\r\n    ./configure\r\n\r\nConfiguration:\r\n\r\n    emadboctor@reg-build-vm:~/tensorflow$ ./configure \r\n    You have bazel 3.0.0 installed.\r\n    Please specify the location of python. [Default is /usr/bin/python3]: /usr/bin/python3\r\n    \r\n    \r\n    Found possible Python library paths:\r\n      /usr/local/lib/python3.5/dist-packages\r\n      /usr/lib/python3/dist-packages\r\n    Please input the desired Python library path to use.  Default is [/usr/local/lib/python3.5/dist-packages]\r\n    /usr/local/lib/python3.5/dist-packages\r\n    Do you wish to build TensorFlow with OpenCL SYCL support? [y/N]: n\r\n    No OpenCL SYCL support will be enabled for TensorFlow.\r\n    \r\n    Do you wish to build TensorFlow with ROCm support? [y/N]: n\r\n    No ROCm support will be enabled for TensorFlow.\r\n    \r\n    Do you wish to build TensorFlow with CUDA support? [y/N]: n\r\n    No CUDA support will be enabled for TensorFlow.\r\n    \r\n    Do you wish to download a fresh release of clang? (Experimental) [y/N]: y\r\n    Clang will be downloaded and used to compile tensorflow.\r\n    \r\n    Please specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native -Wno-sign-compare]: -config=mkl\r\n    \r\n    \r\n    Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n\r\n    Not configuring the WORKSPACE for Android builds.\r\n    \r\n    Preconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n    \t--config=mkl         \t# Build with MKL support.\r\n    \t--config=monolithic  \t# Config for mostly static monolithic build.\r\n    \t--config=ngraph      \t# Build with Intel nGraph support.\r\n    \t--config=numa        \t# Build with NUMA support.\r\n    \t--config=dynamic_kernels\t# (Experimental) Build kernels into separate shared objects.\r\n    \t--config=v2          \t# Build TensorFlow 2.x instead of 1.x.\r\n    Preconfigured Bazel build configs to DISABLE default on features:\r\n    \t--config=noaws       \t# Disable AWS S3 filesystem support.\r\n    \t--config=nogcp       \t# Disable GCP support.\r\n    \t--config=nohdfs      \t# Disable HDFS support.\r\n    \t--config=nonccl      \t# Disable NVIDIA NCCL support.\r\n    Configuration finished\r\n    emadboctor@reg-build-vm:~/tensorflow$\r\n\r\nThen:\r\n\r\n    bazel build -c opt \\\r\n                --define=grpc_no_ares=true  \\\r\n                --linkopt=\"-lrt\" \\\r\n                --linkopt=\"-lm\" \\\r\n                --host_linkopt=\"-lrt\" \\\r\n                --host_linkopt=\"-lm\" \\\r\n                --action_env=\"LD_LIBRARY_PATH=${LD_LIBRARY_PATH}\" \\\r\n                --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both \\\r\n                --copt=-w \\\r\n                --jobs=26 \\\r\n                //tensorflow/tools/pip_package:build_pip_package\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@emadboctorx \r\nCan you please refer to these issues [related to the gcc version]  and let us know if it helps:\r\n #28877 #38594 [link](https://github.com/tensorflow/models/issues/130)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39322\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39322\">No</a>\n", "i have try gcc 4.8, 5.4, 6.3, 7.3, 8.3, 9.3 ,there is no one can build successfully... ", "Issue still persists"]}, {"number": 39321, "title": "Add gradient for QR decomposition of wide matrices (nrows < ncols)", "body": "This PR adds the gradient calculation for the QR decomposition of real wide input matrices (num_rows < num_cols).  \r\n\r\nThe gradient for the QR decomposition was requested in issue [#6504](https://github.com/tensorflow/tensorflow/issues/6504) .\r\nCurrently Tf supports the QR gradient calculation for square and deep matrices (rows >= cols), when full_matrices = False.\r\n\r\nThere are TODO(pfau) items  to add the gradient calculation for wide matrices and for the cases with full_matrices=True in the test file [qr_op_test.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/kernel_tests/qr_op_test.py) .\r\n\r\nThis PR resolves one and a half TODO items: \r\n- wide real input matrix (nrows < ncols) and full_matrices = False.\r\n- wide real input matrix (nrows < ncols) and full_matrices = True.\r\n\r\nCode is largely based on the following references:\r\n- [Liao et al. Differentiable Programming Tensor Networks](https://journals.aps.org/prx/pdf/10.1103/PhysRevX.9.031041)\r\n- [Ionescu et al. Matrix Backpropagation for Deep Networks with Structured Layers](https://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Ionescu_Matrix_Backpropagation_for_ICCV_2015_paper.pdf)\r\n- [Giles, M. An extended collection of matrix derivative results\r\nfor forward and reverse mode algorithmic\r\ndifferentiation](https://people.maths.ox.ac.uk/gilesm/files/NA-08-01.pdf)", "comments": ["Hi @rmlarsen can you please take a look and let me know your thoughts? thanks", "@D-Roberts Can you please check build failures. Thanks!", "@gbaned I pushed another commit that should hopefully fix the build failures.", "@ezhulenev thank you for your review. @gbaned please let me know if there is anything else necessary to do here. "]}, {"number": 39320, "title": "Breakpoints do not stop inside tf.function", "body": "**System information**\r\n\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): binary (pip)\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: 3.7\r\n- CUDA/cuDNN version: CUDA 10.1 / cuDNN 7\r\n- GPU model and memory: GeForce RTX 2060 6GB GDDR6\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nIf in the code from below you set a breakpoint in the line `print('Dummy function')` it will not stop.\r\n```\r\nimport tensorflow as tf\r\n\r\ndef read_tfrecord(x):\r\n    print('Dummy function')\r\n    return x\r\n\r\ndataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\r\nprint(dataset)\r\ndataset = dataset.map(lambda x: read_tfrecord(x))\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nThe code execution should stop at that line and you should be able to debug that function.\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\ndef read_tfrecord(x):\r\n    print('Dummy function')\r\n    return x\r\n\r\ndataset = tf.data.Dataset.from_tensor_slices([1, 2, 3])\r\nprint(dataset)\r\ndataset = dataset.map(lambda x: read_tfrecord(x))\r\n```\r\n\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\n\r\nFirst I though it was a problem with the debugger that I was using so I created an issue there (https://github.com/jupyterlab/debugger/issues/435).\r\n\r\nThen they said it might be to the underlying debugger that it was using (ptvsd / debugpy) since the problem was also present in Visual Studio Code, and both debuggers use the same, so I created an issue there as well (https://github.com/microsoft/debugpy/issues/228).\r\n\r\nAnd they now point out that it might be related to how tensorflow is build, so maybe the problem comes from Tensorflow and the way it creates the threads, read comment: https://github.com/microsoft/debugpy/issues/228#issuecomment-624908204\r\n\r\n", "comments": ["@edurenye \r\n\r\nI have tried in colab with TF version 2.2-rc4 .Please, find the gist [here.](https://colab.sandbox.google.com/gist/ravikyram/46a30c34caf46264e947d1737ad5a7b2/untitled871.ipynb)Is this the expected behavior?Thanks!", "You can't test in colab, colab doesn't have a debugger that you can use to set breakpoints as far as I know.\r\nYou need jupyter or Visual Studio Code.\r\n\r\nYou can't do something like this in colab:\r\n![debug_map](https://user-images.githubusercontent.com/6824576/81548935-50dc5200-937e-11ea-8286-b261065f0ff3.png)\r\n", "Yes I was able to reproduce this.\r\n![image](https://user-images.githubusercontent.com/47574994/81738873-463dbd80-944f-11ea-91a0-06bcda41de2e.png)\r\n", "@edurenye can you check whether you can set a breakpoint within `tf.function`? tf.data wraps all user defined functions in `tf.function` and I suspect that the behavior you have observed is not specific to tf.data and applies generally to all `tf.function`s.", "@jsimsa I tried with the following code:\r\n```\r\nimport tensorflow as tf\r\n\r\n@tf.function\r\ndef f(x, y):\r\n    print('Operate')\r\n    return x ** 2 + y\r\n\r\nx = tf.constant([2, 3])\r\ny = tf.constant([3, -2])\r\nf(x, y)\r\n```\r\n\r\nAnd I set a breakpoint as before, it did not stop at the breakpoint.\r\n\r\nSo, yes, it happens with all `tf.function`s.\r\n", "> Note: AutoGraph is compatible with Eager, but the converse is not always true, so exercise care when making modifications to the code while debugging.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/debugging.md#debugging-tffunction-tfconfigexperimental_execute_functions_eagerly", "\"In Tensorflow 2.0, eager execution is enabled by default.\" Is that not true?\r\n\r\nThank you! I'll try that, but there is something fishy here.", "That documentation is obsolete apparently.\r\n\r\nI got this:\r\n```\r\nAttributeError: module 'tensorflow._api.v2.config' has no attribute 'run_functions_eagerly'\r\n```\r\n", "@edurenye What is you code snippet?", "```\r\nimport tensorflow as tf\r\n\r\ntf.config.run_functions_eagerly(True)\r\n\r\n@tf.function\r\ndef f(x, y):\r\n    print('Operate')\r\n    return x ** 2 + y\r\n\r\nx = tf.constant([2, 3])\r\ny = tf.constant([3, -2])\r\nf(x, y)\r\n```\r\n", "I don't get `AttributeError: module 'tensorflow._api.v2.config' has no attribute 'run_functions_eagerly` with your code. What TF version are you using?", "As says in the issue description, I'm using version 2.2.\r\n\r\nAnd seems that this method just exists in Nightly. I can't test right now, but I will when I have time.\r\n\r\nBut I don't understand why this is needed if TF 2.0 should be eager by default, my guess is that everything is eager except the `tf.function`.\r\n\r\nThe other thing is that even if is not eager, the debug should stop the breakpoints anyway after the graph is created and during the execution of the code.\r\n", "On TF 2.2 was `tf.config.experimental_run_functions_eagerly(True)`.\r\nI think the point is:\r\n> To get performant and portable models, use tf.function to make graphs out of your programs. \r\n\r\n> When using @tf.function, you can temporarily toggle graph execution by using tf.config.experimental_execute_functions_eagerly. This will effectively run the annotated code eagerly, **without transformation**. Since AutoGraph has semantics consistent with Eager, it's an effective way to debug the code step-by-step.\r\n", "Reassigning to @jaingaurav for triage as this is not specific to tf.data.", "Thank you very much @bhack !!! It works perfectly.", "@edurenye \r\n\r\nGlad to know it worked. Please close this thread as the issue was resolved. Thanks!", "Yes, thank you!\r\n\r\nI guess this:\r\n\r\n> The other thing is that even if is not eager, the debug should stop the breakpoints anyway after the graph is created and during the execution of the code.\r\n\r\nIs not compatible with this:\r\n\r\n> To get performant and portable models, use tf.function to make graphs out of your programs.\r\n\r\nSo I can close this issue.\r\nAnd I will close the issues from the other projects as well.\r\n\r\nThank you very much everybody that was involved!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39320\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39320\">No</a>\n", "> The other thing is that even if is not eager, the debug should stop the breakpoints anyway after the graph is created and during the execution of the code\r\n\r\nIf the code is transformed debugging with the orignal breakpoint doesn't make sense.", "Sorry for hijacking this thread, but the solution does not work for me with tensorflow 2.4.1, pycharm and windows. Using the example posted above and an additional `tf.config.run_functions_eagerly(True)` at the top yields the following error message:\r\n\r\n\"UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs\"\r\n\r\nHmm, https://github.com/tensorflow/tensorflow/issues/30653 seems to give more information"]}, {"number": 39319, "title": "Add macro TF_C_RETURN_IF_ERROR", "body": "@mihaimaruseac \r\nWe add this macro to `tf_status.h`as a C version of `TF_RETURN_IF_ERROR`", "comments": ["@mihaimaruseac \r\nIt seems that Tensorflow C does not provide a logging function. As we avoid using core/platform/env/logging, should we write another logging function ?", "Sorry, took a while to analyze the full impact of this.\r\n\r\nThis will increase API surface and since the plugins cannot call back TF code it won't help much.\r\n\r\nWhich means we can only `fprintf(stderr` (`std::cerr`) in here but at this point it's no better than having  the macro in every plugin that needs it.", "So I will close this PR ?", "Yes, I think that's best. Sorry for the wasted time and the initial misdirection.", "Don't worry about it :smile:\r\n"]}, {"number": 39318, "title": "Adds support for xcore.ai platform in Micro", "body": "This is the initial TFL4u port to the xcore.ai platform from XMOS. This port is just using reference/portable_optimized kernels.\r\n\r\nThis PR allows xcore binaries to be generated which can be run on the included simulator, or the Explorer Board dev kit which is expected by August 2020.\r\n\r\nPassing all unit tests (requires trying and failing to get the tools downloaded, example below):\r\n\r\n`$ make -f tensorflow/lite/micro/tools/make/Makefile TARGET=\"xcore\" clean clean_downloads && make -f tensorflow/lite/micro/tools/make/Makefile TARGET=\"xcore\" test_greedy_memory_planner_test || true && pushd tensorflow/lite/micro/tools/make/downloads/xtimecomposer/xTIMEcomposer/15.0.0/ && source SetEnv && popd  && make -f tensorflow/lite/micro/tools/make/Makefile TARGET=\"xcore\" test`\r\n\r\n[micro]", "comments": []}, {"number": 39317, "title": "tfjs-node does not work with Node14", "body": "This is due to the new N-API-Version '6' which is missing from package.json.\r\n\r\nThe library builds apparently without issues (as N-API '5'), but the install.js script fails to symlink or copy tensorflow.dll (because folder for N-API '6' does not exist).\r\n", "comments": ["@jeffrson,\r\nAs this is a TF-js issue, could you please raise a new issue in the TF-js repo from [this link](https://github.com/tensorflow/tfjs/issues/new), so that we can track it there. Thanks!", "https://github.com/tensorflow/tfjs/issues/3236"]}, {"number": 39316, "title": "bug report:All feature_columns must be _FeatureColumn instances. Given: SequenceNumericColumn(key='volume', shape=(1,), default_value=0.0, dtype=tf.float32, normalizer_fn=None)", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip install \r\n- TensorFlow version (use command below): tensorflow-gpu 2.2.0 and 2.1.0\r\n- Python version:python3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:10.1\r\n- GPU model and memory:8g\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\nmy code is:\r\n# -*- coding: utf-8 -*-\r\nimport pandas as pd\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow import feature_column\r\nfrom tensorflow.keras.experimental import SequenceFeatures\r\n\r\nvolume = feature_column.sequence_numeric_column('volume')\r\nlstm_columns = [volume]\r\nfeatures = tf.io.parse_example(..., features=feature_column.make_parse_example_spec(lstm_columns))\r\n\r\nsequence_feature_layer = SequenceFeatures(lstm_columns) #\u8fd4\u56de\u7279\u5f81\u5217\u7684\u957f\u5ea6\u548c tensor\r\nsequence_input, sequence_length = sequence_feature_layer(features)\r\n\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/zy/PycharmProjects/keras-tcn-master/brain_LD.py\", line 104, in <module>\r\n    features = tf.io.parse_example(..., features=feature_column.make_parse_example_spec(lstm_columns))\r\n  File \"/home/zy/anaconda3/envs/tf1/lib/python3.6/site-packages/tensorflow_core/python/feature_column/feature_column.py\", line 806, in make_parse_example_spec\r\n    'Given: {}'.format(column))\r\nValueError: All feature_columns must be _FeatureColumn instances. Given: SequenceNumericColumn(key='volume', shape=(1,), default_value=0.0, dtype=tf.float32, normalizer_fn=None)\r\n\r\n it looks like a bug ? can you fix it?\r\n\r\n\r\n\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@anavanab99 \r\nCode provided seems incomplete, In order to expedite the trouble-shooting process, please provide a simple standalone code to reproduce the issue reported here, if possible share a colab gist to analyse the error Thanks!\r\n", "> @Saduf2019 \r\n> Code provided seems incomplete, In order to expedite the trouble-shooting process, please provide a simple standalone code to reproduce the issue reported here, if possible share a colab gist to analyse the error Thanks!\r\n\r\nI solved the problem by reinstalling tensorflow, but another problem bothered me. The cases in the official tensorflow documentation are as follows:\r\ndnn_activation='relu'\r\nvolume = tf.feature_column.numeric_column('volume', shape=number_shape)\r\nl_list=[volume]\r\nfeatures = tf.io.parse_example(\r\nserialized=record, features=tf.feature_column.make_parse_example_spec(l_list))\r\ninput_l=keras.layers.DenseFeatures(l_list)\r\ndnn1=keras.layers.Dense(300,activation=dnn_activation)(input_l)\r\noutput=keras.layers.Dense(1,activation='tanh')(dnn1)\r\nmodel = Model(inputs = [input_l],outputs = [output])\r\nmodel.compile(loss = \"mae\",optimizer = \"Adam\")\r\n\r\nI tried to input the feature column to keras model, but the code features = tf.io.parse_example (\r\nserialized = record, features = tf.feature_column.make_parse_example_spec (l_list))\r\nIn the case of serialized = record, what type of object should be filled here to complete parse_example? I studied the official API carefully, but the official API filled in serialized = ... instead. I can't understand how to complete the code. I tried to fill in various methods such as tfrecord, fill in tensor, and I couldn't complete the code. My data is a csv file. Can you provide a complete example, including data reading, feature column processing, and training?? I really cannot complete the code. Thank you very much, this is very important to me. Thank you very much, my email: 402868327@qq.com", "@anavanab99 \r\nAs the reported issue is resolved please create a new issue for the new issue faced.", "@anavanab99\r\nAutomatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39316\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39316\">No</a>\n", "I have this \"bug\" in applying \"sequence_numeric_column\" tf1.15.\r\nexactly same error! but what should I do to fix this?\r\nI've tried reinstall tensorflow, nothing changes. Plz help"]}, {"number": 39315, "title": "Failed to convert .pb file to rflite", "body": "**System information**\r\nUbuntu 16.04\r\nTensorFlow 2.1.0 installed from anaconda\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\n\r\n```\r\n    import tensorflow as tf\r\n\r\n    import numpy as np\r\n    import torch\r\n\r\n    def load_pb(path_to_pb):\r\n        with tf.compat.v1.gfile.GFile(path_to_pb, 'rb') as f:\r\n            graph_def = tf.compat.v1.GraphDef()\r\n            graph_def.ParseFromString(f.read())\r\n        with tf.compat.v1.Graph().as_default() as graph:\r\n            tf.compat.v1.import_graph_def(graph_def, name='')\r\n        return graph, graph_def\r\n\r\n    tf_graph, graph_def = load_pb('./model120.pb')\r\n    sess = tf.compat.v1.Session(graph=tf_graph)\r\n\r\n    # Show tensor names in graph\r\n    for op in tf_graph.get_operations():\r\n        print(op.values())\r\n\r\n    output_tensor = tf_graph.get_tensor_by_name('test_output:0')\r\n    input_tensor = tf_graph.get_tensor_by_name('test_input:0')\r\n\r\n    dummy_input = np.zeros(shape=(1, 3, 672, 672)).astype(np.float32)\r\n\r\n    output = sess.run(output_tensor, feed_dict={input_tensor: dummy_input})\r\n\r\n    print('>==============================<')\r\n    print(output.shape)\r\n    print(output)\r\n    print('<==============================>')\r\n\r\n    converter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph('/home/marat/OCR/yolo3/model120.pb', ['test_input'], ['test_output'])\r\n    tflite_model = converter.convert()\r\n    open(\"model120.tflite\", \"wb\").write(tflite_model)\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/marat/OCR/yolo3/torch2tflite.py\", line 93, in <module>\r\n    tflite_model = converter.convert()\r\n  File \"/home/marat/anaconda3/envs/cexp/lib/python3.7/site-packages/tensorflow_core/lite/python/lite.py\", line 1007, in convert\r\n    **converter_kwargs)\r\n  File \"/home/marat/anaconda3/envs/cexp/lib/python3.7/site-packages/tensorflow_core/lite/python/convert.py\", line 457, in toco_convert_impl\r\n    enable_mlir_converter=enable_mlir_converter)\r\n  File \"/home/marat/anaconda3/envs/cexp/lib/python3.7/site-packages/tensorflow_core/lite/python/convert.py\", line 203, in toco_convert_protos\r\n    raise ConverterError(\"See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\ntensorflow.lite.python.convert.ConverterError: See console for info.\r\n2020-05-08 16:44:59.629678: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/home/marat/anaconda3/lib\r\n2020-05-08 16:44:59.629746: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/home/marat/anaconda3/lib\r\n2020-05-08 16:44:59.629754: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\r\n2020-05-08 16:45:00.211158: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-05-08 16:45:00.216250: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3407935000 Hz\r\n2020-05-08 16:45:00.216513: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55eb58a38390 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-05-08 16:45:00.216527: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-05-08 16:45:00.218143: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-05-08 16:45:00.220636: E tensorflow/stream_executor/cuda/cuda_driver.cc:351] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\r\n2020-05-08 16:45:00.220672: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: saturn\r\n2020-05-08 16:45:00.220678: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: saturn\r\n2020-05-08 16:45:00.220727: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 440.64.0\r\n2020-05-08 16:45:00.220762: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 440.64.0\r\n2020-05-08 16:45:00.220768: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 440.64.0\r\n2020-05-08 16:45:00.240198: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: If\r\n2020-05-08 16:45:00.240265: F tensorflow/lite/toco/import_tensorflow.cc:114] Check failed: attr.value_case() == AttrValue::kType (1 vs. 6)\r\nFatal Python error: Aborted\r\n\r\nCurrent thread 0x00007fc41d0f2700 (most recent call first):\r\n  File \"/home/marat/anaconda3/envs/cexp/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 56 in execute\r\n  File \"/home/marat/anaconda3/envs/cexp/lib/python3.7/site-packages/absl/app.py\", line 250 in _run_main\r\n  File \"/home/marat/anaconda3/envs/cexp/lib/python3.7/site-packages/absl/app.py\", line 299 in run\r\n  File \"/home/marat/anaconda3/envs/cexp/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py\", line 40 in run\r\n  File \"/home/marat/anaconda3/envs/cexp/lib/python3.7/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 93 in main\r\n  File \"/home/marat/anaconda3/envs/cexp/bin/toco_from_protos\", line 8 in <module>\r\nAborted (core dumped)\r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n\r\n```\r\nhttps://drive.google.com/open?id=12CN_l_VlAFFCt28lWvF9xqVfRAxY1M8b\r\n```\r\n\r\n**Failure details**\r\n\r\nNo information at all about exact converter failure reason\r\n\r\n```\r\n2020-05-08 16:54:52.542355: F tensorflow/lite/toco/import_tensorflow.cc:114] Check failed: attr.value_case() == AttrValue::kType (1 vs. 6)\r\nFatal Python error: Aborted\r\n```\r\nIts seems thath problem with this code com from pytorch `F.interpolate `", "comments": ["Hi Jaesung, seems to be related with control flow issue - can you take a look?\r\n```\r\n2020-05-08 16:45:00.240198: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: If\r\n```", "Hi MaratZakirov,\r\n\r\nCould you convert the model with tf.enable_control_flow_v2()? https://www.tensorflow.org/api_docs/python/tf/compat/v1/enable_control_flow_v2", "Hi @abattery , thank you for answer\r\n\r\n> with tf.enable_control_flow_v2()\r\n\r\nDid you mean `tf.compat.v1.enable_control_flow_v2()` ?\r\nThis:\r\n```\r\n    with tf.compat.v1.enable_control_flow_v2():\r\n        converter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph('/home/marat/OCR/yolo3/model120.pb', ['test_input'], ['test_output'])\r\n        tflite_model = converter.convert()\r\n        open(\"model120.tflite\", \"wb\").write(tflite_model)\r\n```\r\nGives:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/marat/OCR/yolo3/torch2tflite.py\", line 93, in <module>\r\n    with tf.compat.v1.enable_control_flow_v2():\r\nAttributeError: __enter__\r\n```\r\nI also tried to save *.pb (GraphDef file) to saved_model and permanently getting same result, same tflite file in terms of \"executability\".\r\n\r\nIt is seems that `F.interpolate(x, scale_factor=2, mode='nearest')` which yolo3 has kills process of transformation to tflite. I made module with only that operation and TF dies", "The line, \"tf.compat.v1.enable_control_flow_v2()\" should be appeared before creating the graph.", "> The line, \"tf.compat.v1.enable_control_flow_v2()\" should be appeared before creating the graph.\r\nThis is does not help either, see minimalistic example\r\n```\r\nimport torch\r\nimport torch.nn.functional as F\r\nimport os\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\r\n\r\nclass SimpleNet(torch.nn.Module):\r\n    def __init__(self):\r\n        super(SimpleNet, self).__init__()\r\n\r\n    def forward(self, x):\r\n        x = F.interpolate(x, scale_factor=2, mode='nearest')\r\n        return x\r\n\r\nimg_tensor = torch.zeros(1, 3, 128, 128)\r\n\r\nif 1:\r\n    model = SimpleNet().eval()\r\n    dummy_output = model(img_tensor)\r\n    print(dummy_output.detach().cpu().numpy().shape, dummy_output.detach().cpu().numpy())\r\n    torch.onnx.export(model, img_tensor, './dummy.onnx', input_names=['test_input'], output_names=['test_output'])\r\n\r\nif 1:\r\n    import onnx\r\n    import tensorflow.compat.v1 as tf\r\n    tf.compat.v1.enable_control_flow_v2()\r\n    from onnx_tf.backend import prepare\r\n    model_onnx = onnx.load('./dummy.onnx')\r\n    tf_rep = prepare(model_onnx)\r\n    tf_rep.export_graph('./dummy.pb')\r\n\r\nif 1:\r\n    import tensorflow as tf\r\n\r\n    def load_pb(path_to_pb):\r\n        with tf.compat.v1.gfile.GFile(path_to_pb, 'rb') as f:\r\n            graph_def = tf.compat.v1.GraphDef()\r\n            graph_def.ParseFromString(f.read())\r\n        with tf.compat.v1.Graph().as_default() as graph:\r\n            tf.compat.v1.import_graph_def(graph_def, name='')\r\n        return graph, graph_def\r\n\r\n    tf_graph, graph_def = load_pb('./dummy.pb')\r\n    sess = tf.compat.v1.Session(graph=tf_graph)\r\n\r\n    # Show tensor names in graph\r\n    for op in tf_graph.get_operations():\r\n        print(op.values())\r\n\r\n    output_tensor = tf_graph.get_tensor_by_name('test_output:0')\r\n    input_tensor = tf_graph.get_tensor_by_name('test_input:0')\r\n\r\n    dummy_input = img_tensor.numpy()\r\n\r\n    output = sess.run(output_tensor, feed_dict={input_tensor: dummy_input})\r\n\r\n    print('TF output')\r\n    print(output.shape)\r\n    print(output)\r\n\r\n    converter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph('/home/marat/OCR/yolo3/dummy.pb', ['test_input'], ['test_output'])\r\n    tflite_model = converter.convert()\r\n    open(\"model120.tflite\", \"wb\").write(tflite_model)\r\n```\r\nI print *.pb files (by using    \r\n```\r\n for n in sess.graph.get_operations():\r\n     print(n)\r\n```\r\n in both cases (w/ tf.compat.v1.enable_control_flow_v2() and w/o) and found that files are just the same.\r\n\r\nSee [dummy.pb](https://drive.google.com/open?id=1QqA8N-Jzi8tT2ZR5nV_LL6IByOjEwN3g)\r\nand [dummy.txt](https://drive.google.com/open?id=1K0yk1MdLqrgskE-WF4PIE1uCoAON2Wlu)\r\n", "@MaratZakirov I think this was resolved in `tf-nightly`. I couldn't reproduce the issue. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/5538e8a959ff169e96467c6f7dca3837/untitled.ipynb).\r\n\r\nPlease verify once and close the issue if this was resolved for you. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "I am closing this issue. Please feel free to reopen if the issue persists again. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39315\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39315\">No</a>\n"]}, {"number": 39314, "title": "[Regression] batch_begin/end callbacks no longer get batch number and size", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- TensorFlow installed from (source or binary): Bianry\r\n- TensorFlow version (use command below): 2.2.0\r\n\r\n**Describe the current behavior**\r\n\r\nThe callbacks are documented at https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback#on_train_batch_begin as `logs: dict. Has keys batch and size representing the current batch number and the size of the batch.`\r\n\r\nThe same used to be the case for `on_train_batch_end` in 2.1 but this seems to have been dropped for unknown reason. In 2.1 the `on_train_batch_begin` had a `logs[`size`]=1` which was plain wrong but the value in `on_train_batch_end` was correct so that could be used.\r\n\r\nHowever in 2.2 the `size` log has been removed from `on_train_batch_end` causing existing code to break.\r\n\r\nFurthermore contrary to the documentation for neither callback the size is included\r\n\r\n**Describe the expected behavior**\r\n\r\nThe size should be correctly reported to both callbacks for them to use.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nInstead of coming up with a MWE I quote the code directly:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/engine/training.py#L847 does not even pass a `logs` parameter so that is clearly wrong\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/engine/training.py#L855 uses the result of the `train_function` obtained at https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/keras/engine/training.py#L848 which does not contain batch number or size either.", "comments": ["@Flamefire Thanks for the issue! For batch number, you can use the `batch` argument to those methods: `on_train_batch_begin(batch, logs)`\r\n\r\nThe batch size is no longer passed to the logs, this is expected due a rewrite of `Model.fit`. Could you explain your use case? I can advise on how this can be achieved with the new implementation", "> The batch size is no longer passed to the logs, this is expected due a rewrite of Model.fit\r\n\r\nThis is surprising as it is a breaking change not mentioned in the release notes and contradicts the above linked documentation and even the current docstring: https://github.com/tensorflow/tensorflow/blob/1186e3f2098793952aa82bf356dfe51b967fb26c/tensorflow/python/keras/callbacks.py#L418\r\n\r\n> Could you explain your use case? I can advise on how this can be achieved with the new implementation\r\n\r\nI have a callback counting the number of examples processed (doing further statistics later). In general the batch size may not be constant (e.g. trailing batch) and passing the batch size to the callback and only counting batches duplicates the batch size and is hence error prone.", "> I have a callback counting the number of examples processed (doing further statistics later). In general the batch size may not be constant (e.g. trailing batch) and passing the batch size to the callback and only counting batches duplicates the batch size and is hence error prone.\r\n\r\nI think this is best handled by a custom `Metric`:\r\n\r\n```python\r\nclass Count(tf.keras.metrics.Metric):\r\n  def __init__(self, name=None, dtype=None, **kwargs):\r\n    super(Count, self).__init__(name, dtype, **kwargs)\r\n    self.count = tf.Variable(0)\r\n\r\n  def update_state(self, y_true, y_pred, sample_weight=None):\r\n    first_tensor = tf.nest.flatten(y_true)[0]\r\n    batch_size = tf.shape(first_tensor)[0]\r\n    self.count.assign_add(batch_size)\r\n\r\n  def result(self):\r\n    return tf.identity(self.count)\r\n```\r\n\r\nThis metric would keep a running total of samples seen each epoch, and the results would be passed to `logs`\r\n\r\n> This is surprising as it is a breaking change not mentioned in the release notes and contradicts the above linked documentation and even the current docstring\r\n\r\nGood point, we need to update the docstring\r\n\r\nEDIT: fixed the metric code", "This looks promising. Can this be used in TF 2.1 too? IIRC the metrics are not passed to the callbacks in 2.1.\r\n\r\n2 questions on the code: Why is the `flatten` required? Isn't `y_true` a Tensor with the first dim being the batch size already?   \r\nWhat is the identity for? It's a no-op isn't it?", "Yep this should work in TF2.1 as well, here's a full example (had to fix the metric code a bit):\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nclass Count(tf.keras.metrics.Metric):\r\n  def __init__(self, name=None, dtype=None, **kwargs):\r\n    super(Count, self).__init__(name, dtype, **kwargs)\r\n    self.count = tf.Variable(0)\r\n\r\n  def update_state(self, y_true, y_pred, sample_weight=None):\r\n    first_tensor = tf.nest.flatten(y_true)[0]\r\n    batch_size = tf.shape(first_tensor)[0]\r\n    self.count.assign_add(batch_size)\r\n\r\n  def result(self):\r\n    return tf.identity(self.count)\r\n\r\n\r\nclass PrintInfo(tf.keras.callbacks.Callback):\r\n  def on_train_batch_end(self, batch, logs):\r\n    print('Batch number: {}'.format(batch))\r\n    print('Samples seen this epoch: {}'.format(logs['counter']))\r\n\r\nmodel = tf.keras.Sequential([tf.keras.layers.Dense(1)])\r\nmodel.compile(optimizer='sgd', loss='mse', metrics=[Count(name='counter')])\r\nx, y = tf.ones((10, 10)), tf.ones((10, 1))\r\nmodel.fit(x, y, batch_size=2, callbacks=[PrintInfo()], verbose=2)\r\n```", "> 2 questions on the code: Why is the flatten required? Isn't y_true a Tensor with the first dim being the batch size already?\r\n\r\nIt's to handle the case where a multi-output Model is used (just to be robust). If your Model only has 1 output it's not needed. `tf.nest.flatten` will turn any nested Python structure (tuple, list, dict, etc) into a flat list\r\n\r\n> What is the identity for? It's a no-op isn't it?\r\n\r\nJust to make sure we're not returning the `tf.Variable` directly. It's probably ok to do this, but this protects from accidental modification", "@Flamefire if you are satisfied with the solution, can you please close this issue ?", "Well it is a breaking change that was not announced so \"satisfied\" is relative. But there is a solution now.\r\n\r\nI'd say once the documentation (e.g. https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/Callback#on_train_batch_begin)  is updated this can be closed as that is part of this report and I'm not sure this has been fixed yet.", "I would also like to use the same technique to use the batch size in `on_train_batch_begin`, so I used the example above by just replacing `on_train_batch_end` with `on_train_batch_begin`, but it doesn't work. Any suggestion to solve this? ", "@Flamefire sorry for not announcing the breaking change, this was a miss. The api docstrings have now been updated in this commit [591fb](https://github.com/tensorflow/tensorflow/commit/3f973428767cfbbbeeb412b3d7e0be8e566591fb). I will close this issue now. Thanks!\r\n\r\n@KTTrev for your issue, please file a separate issue with a minimal code sample repro of what you are trying to do and what is not working. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39314\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39314\">No</a>\n", "For anyone else finding this: A better implementation of the Count-metric is likely:\r\n\r\n```\r\nclass Count(tf.keras.metrics.Metric):\r\n    \"\"\"Metric which counts the number of examples seen\"\"\"\r\n    def __init__(self, name='count', dtype=tf.int64, **kwargs):\r\n        super().__init__(name, dtype, **kwargs)\r\n        self.count = self.add_weight(name, initializer='zeros')\r\n\r\n    def update_state(self, y_true, y_pred, sample_weight=None):\r\n        first_tensor = tf.nest.flatten(y_true)[0]\r\n        batch_size = tf.shape(first_tensor)[0]\r\n        self.count.assign_add(tf.cast(batch_size, dtype=self.dtype))\r\n\r\n    def result(self):\r\n        return self.count\r\n```\r\n\r\nThis counts the total number of examples even in Multi-Worker mode and is resettable via `reset_states`"]}, {"number": 39313, "title": "Use Eager execution or decorate this function with @tf.function.", "body": "\r\nhi,dear\r\nWhen I define a class,then use map, got the error:\r\n```\r\nclass Func(tf.keras.layers.Layer):\r\n    def __init__(self, **kwargs):\r\n        super(Func, self).__init__(**kwargs)\r\n\r\n    def build(self, input_shape):\r\n        super(Func, self).build(input_shape)\r\n\r\n    def call(self, x):\r\n        return x    \r\n\r\nx=tf.constant([1,2,3])\r\nwith tf.Session() as sess:\r\n    inputs=list(map(Func(),x))\r\n    print(sess.run(inputs))\r\n```\r\nI have tried the \r\n`tf.compat.v1.disable_eager_execution()`\r\nbut no use\r\nCould you pls help me ?\r\nthx\r\n\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., win10 64bit):\r\n- TensorFlow installed from (pip):\r\n- TensorFlow version (use command below):1.15\r\n- Python version:3.6.8\r\n- CUDA/cuDNN version:No\r\n- GPU model and memory:No\r\n\r\n\r\n", "comments": ["I set [x] ,then solved this.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39313\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39313\">No</a>\n"]}, {"number": 42802, "title": "How to translate the content under tensorflow.org/resources/learn-ml?", "body": "Some resources under tensorflow.org/resources/learn-ml like this one https://developers.google.com/machine-learning/crash-course are useful and are already translated to multiple languages, therefore, I want to translate them into Arabic. However, their source code isn't in this repository and I couldn't find it in other repositories. \r\n\r\nSo, could explain the procedure to translate them? \r\n\r\nThanks.", "comments": ["@lamberta  Could you help regarding this enquiry? Thanks.", "Sorry for the delay, @mohamed-ali \r\n\r\nThe [ML Crash Course](https://developers.google.com/machine-learning/crash-course) is not part of tensorflow.org so out-of-scope for this project.\r\n\r\nThe community translations here in the docs-l10n repo are restricted to technical content (guides and tutorials). Landing pages, such as the [resources/learn-ml](https://www.tensorflow.org/resources/learn-ml) are translated using a different process (with different prioritization), so also out-of-scope for this project. Thanks"]}, {"number": 39312, "title": "Saving model in Single Writer Multiple Reader (SWMR) mode", "body": "Hello, Can I set SWMR mode when I'm saving my model to h5 file? I need a concurrent reading of an HDF5 file while it is being written from another training process. It's useful in multi-agent reinforcement learning. Thanks.\r\n", "comments": ["@markub3327 Can you explain the issue in detail and why would it be helpful to the community? Is it a new feature that you are talking about? Thanks!", "### What is SWMR\r\n&ensp; The SWMR is the feature of an HDF5 file (h5py includes support from version 2.5.0). The SWMR features allow simple concurrent reading of an HDF5 file while it is being written from another process. The writer process creates the target file and it switches file into SWMR mode.\r\nThe reader process opens the file with swmr=True.\r\n\r\nhttp://docs.h5py.org/en/stable/swmr.html\r\n\r\n### Why would it be helpful to the community? \r\nWhen we have a game, where every agent is running in own environment on another process (python multiprocessing). Agents are collecting experiences for one learner network that is on another process too. We need to read the learner's model file that is updated by the learner in update_timestep period (it's periodically saving learner's weights to h5 file). Agents in another process can at the same time read from the learner's h5 file while the learner's process is writing to the file. It's maybe dangerous, how many times we can open the model (h5) file while we're writing to it from another process?\r\n\r\nHow we can share the Keras model between processes or many computers in the local network when the model file is too large? I think that the best option is saving it to file then share it between multiple processes/computers in the local network (agents).\r\n\r\n### Is it a new feature that you are talking about?\r\nIt isn't a new feature in h5 files, but when we're saving Keras model SWMR mode is not an option to enable.\r\n"]}, {"number": 39311, "title": "Fix bogomips extraction on s390x arch", "body": "@penpornk , please see PR for bogomips extraction on s390x architecture.\r\n\r\nThanks.", "comments": []}, {"number": 39310, "title": "Fix bogomips extraction on s390x arch", "body": "@penpornk , please see PR for `bogomips` extraction on s390x architecture.\r\n\r\nThanks.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F39310) for more info**.\n\n<!-- need_sender_cla -->"]}, {"number": 39309, "title": "Bazel build fails on MacOS Catalina - Unable to find numpy package despite PYTHON_LIB_PATH set to the directory containing the numpy package", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Catalina 10.15.4\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version: RELEASE.md => Release 2.0.1 building from source\r\n- Python version: 3.6.6\r\n- Installed using virtualenv? pip? conda?: pyenv\r\n- Bazel version (if compiling from source): 3.0.0\r\n- GCC/Compiler version (if compiling from source): 4.2.1 (Apple clang version 11.0.3 (clang-1103.0.32.59))\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: AMD Radeon R9 M295X 4 GB graphics\r\n\r\n\r\n**Describe the problem**\r\nTrying to build from source as documented [here](https://www.tensorflow.org/install/source) fails for me on MacOS Cataline 10.15.4...the bazel build process cannot find numpy package even though a listing of the PYTHON_LIB_PATH shows the numpy package is present:\r\n\r\n``` bash\r\n$ ls /Users/simon/Library/Python/3.6/lib/python/site-packages\r\n\r\nKeras_Applications-1.0.8.dist-info/  easy_install.py                      keras_applications/                  libpasteurize/                       numpy/                               pkg_resources/                       six-1.14.0.dist-info/                wheel-0.34.2.dist-info/\r\nKeras_Preprocessing-1.1.0.dist-info/ future/                              keras_preprocessing/                 mock/                                numpy-1.18.4.dist-info/              setuptools/                          six.py\r\n__pycache__/                         future-0.18.2.dist-info/             libfuturize/                         mock-4.0.2.dist-info/                past/                                setuptools-46.1.3.dist-info/         wheel/\r\n```\r\nI am using Python 3.6.6 via pyenv.\r\n\r\nSalient output from bazel build process included below. Full error log from build process included at the the end of report.\r\n\r\n``` bash\r\nERROR: An error occurred during the fetch of repository 'local_execution_config_python':\r\n   Traceback (most recent call last):\r\n\tFile \"/Users/simon/src/libs/third-party/tensorflow/third_party/py/python_configure.bzl\", line 213\r\n\t\t_get_numpy_include(<2 more arguments>)\r\n\tFile \"/Users/simon/src/libs/third-party/tensorflow/third_party/py/python_configure.bzl\", line 187, in _get_numpy_include\r\n\t\texecute(repository_ctx, <3 more arguments>)\r\n\tFile \"/Users/simon/src/libs/third-party/tensorflow/third_party/remote_config/common.bzl\", line 208, in execute\r\n\t\tfail(<1 more arguments>)\r\nProblem getting numpy include path.\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nModuleNotFoundError: No module named 'numpy'\r\nIs numpy installed?\r\n\r\nPYTHON_BIN_PATH=/Users/simon/.pyenv/versions/3.6.6/bin/python3 --action_env\r\n\r\nPYTHON_LIB_PATH=/Users/simon/Library/Python/3.6/lib/python/site-packages\r\n```\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n$ pyenv version system\r\n3.6.6 (set by /Users/simon/.pyenv/version)\r\n\r\n$ pip install -U --user pip six numpy wheel setuptools mock 'future>=0.17.1'\r\n$ pip install -U --user keras_applications --no-deps\r\n$ pip install -U --user keras_preprocessing --no-deps\r\n\r\n# required python packages exist as shown in stdout log from pip install\r\nRequirement already up-to-date: pip in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (20.1)\r\nRequirement already up-to-date: six in /Users/simon/Library/Python/3.6/lib/python/site-packages (1.14.0)\r\nRequirement already up-to-date: numpy in /Users/simon/Library/Python/3.6/lib/python/site-packages (1.18.4)\r\nRequirement already up-to-date: wheel in /Users/simon/Library/Python/3.6/lib/python/site-packages (0.34.2)\r\nRequirement already up-to-date: setuptools in /Users/simon/Library/Python/3.6/lib/python/site-packages (46.1.3)\r\nRequirement already up-to-date: mock in /Users/simon/Library/Python/3.6/lib/python/site-packages (4.0.2)\r\nRequirement already up-to-date: future>=0.17.1 in /Users/simon/Library/Python/3.6/lib/python/site-packages (0.18.2)\r\nRequirement already up-to-date: keras_applications in /Users/simon/Library/Python/3.6/lib/python/site-packages (1.0.8)\r\nRequirement already up-to-date: keras_preprocessing in /Users/simon/Library/Python/3.6/lib/python/site-packages (1.1.0)\r\n\r\n$ ./configure\r\nPlease specify the location of python. [Default is /Users/simon/.pyenv/versions/3.6.6/bin/python3]:  /Users/simon/.pyenv/versions/3.6.6/bin/python3 \r\nPlease input the desired Python library path to use.  Default is [/Users/simon/.pyenv/versions/3.6.6/lib/python3.6/site-packages] /Users/simon/Library/Python/3.6/lib/python/site-packages\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: n\r\nDo you wish to download a fresh release of clang? (Experimental) [y/N]: n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native -Wno-sign-compare]: -march=core2 -Wno-sign-compare\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n\r\nDo you wish to build TensorFlow with iOS support? [y/N]: n\r\n\r\n$  bazel build --config=opt --config=monolithic --config=noaws --config=nogcp --config=nohdfs --config=nonccl //tensorflow/tools/lib_package:libtensorflow\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nWhen run the above build steps, error message displayed because numpy package was not found.\r\n\r\n``` bash\r\nbazel build --config=opt --config=monolithic --config=noaws --config=nogcp --config=nohdfs --config=nonccl //tensorflow/tools/lib_package:libtensorflow\r\nStarting local Bazel server and connecting to it...\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=298\r\nINFO: Reading rc options for 'build' from /Users/simon/src/libs/third-party/tensorflow/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /Users/simon/src/libs/third-party/tensorflow/.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=v2\r\nINFO: Reading rc options for 'build' from /Users/simon/src/libs/third-party/tensorflow/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/Users/simon/.pyenv/versions/3.6.6/bin/python3 --action_env PYTHON_LIB_PATH=/Users/simon/Library/Python/3.6/lib/python/site-packages --python_path=/Users/simon/.pyenv/versions/3.6.6/bin/python3 --config=xla --action_env TF_CONFIGURE_IOS=0\r\nINFO: Found applicable config definition build:v2 in file /Users/simon/src/libs/third-party/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:xla in file /Users/simon/src/libs/third-party/tensorflow/.bazelrc: --action_env=TF_ENABLE_XLA=1 --define=with_xla_support=true\r\nINFO: Found applicable config definition build:opt in file /Users/simon/src/libs/third-party/tensorflow/.tf_configure.bazelrc: --copt=-march=core2 --copt=-Wno-sign-compare --host_copt=-march=native --define with_default_optimizations=true\r\nINFO: Found applicable config definition build:monolithic in file /Users/simon/src/libs/third-party/tensorflow/.bazelrc: --define framework_shared_object=false\r\nINFO: Found applicable config definition build:noaws in file /Users/simon/src/libs/third-party/tensorflow/.bazelrc: --define=no_aws_support=true\r\nINFO: Found applicable config definition build:nogcp in file /Users/simon/src/libs/third-party/tensorflow/.bazelrc: --define=no_gcp_support=true\r\nINFO: Found applicable config definition build:nohdfs in file /Users/simon/src/libs/third-party/tensorflow/.bazelrc: --define=no_hdfs_support=true\r\nINFO: Found applicable config definition build:nonccl in file /Users/simon/src/libs/third-party/tensorflow/.bazelrc: --define=no_nccl_support=true\r\nINFO: Found applicable config definition build:macos in file /Users/simon/src/libs/third-party/tensorflow/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14\r\nINFO: Call stack for the definition of repository 'local_config_python' which is a python_configure (rule definition at /Users/simon/src/libs/third-party/tensorflow/third_party/py/python_configure.bzl:294:20):\r\n - <builtin>\r\n - /Users/simon/src/libs/third-party/tensorflow/tensorflow/workspace.bzl:104:5\r\n - /Users/simon/src/libs/third-party/tensorflow/WORKSPACE:19:1\r\nINFO: Call stack for the definition of repository 'local_execution_config_python' which is a local_python_configure (rule definition at /Users/simon/src/libs/third-party/tensorflow/third_party/py/python_configure.bzl:275:26):\r\n - <builtin>\r\n - /Users/simon/src/libs/third-party/tensorflow/third_party/toolchains/remote_config/rbe_config.bzl:158:5\r\n - /Users/simon/src/libs/third-party/tensorflow/third_party/toolchains/remote_config/configs.bzl:6:5\r\n - /Users/simon/src/libs/third-party/tensorflow/tensorflow/workspace.bzl:93:5\r\n - /Users/simon/src/libs/third-party/tensorflow/WORKSPACE:19:1\r\nERROR: An error occurred during the fetch of repository 'local_execution_config_python':\r\n   Traceback (most recent call last):\r\n\tFile \"/Users/simon/src/libs/third-party/tensorflow/third_party/py/python_configure.bzl\", line 213\r\n\t\t_get_numpy_include(<2 more arguments>)\r\n\tFile \"/Users/simon/src/libs/third-party/tensorflow/third_party/py/python_configure.bzl\", line 187, in _get_numpy_include\r\n\t\texecute(repository_ctx, <3 more arguments>)\r\n\tFile \"/Users/simon/src/libs/third-party/tensorflow/third_party/remote_config/common.bzl\", line 208, in execute\r\n\t\tfail(<1 more arguments>)\r\nProblem getting numpy include path.\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nModuleNotFoundError: No module named 'numpy'\r\nIs numpy installed?\r\nINFO: Call stack for the definition of repository 'com_google_protobuf' which is a tf_http_archive (rule definition at /Users/simon/src/libs/third-party/tensorflow/third_party/repo.bzl:134:19):\r\n - <builtin>\r\n - /Users/simon/src/libs/third-party/tensorflow/tensorflow/workspace.bzl:559:5\r\n - /Users/simon/src/libs/third-party/tensorflow/WORKSPACE:19:1\r\nInternal error thrown during build. Printing stack trace: java.lang.NullPointerException: //tensorflow/tools/lib_package:libtensorflow BuildConfigurationValue.Key[e4e94f4998e8c26abbc5eb2bf9d33e94aa6f63e0a9af8b8373f7ec758ef26105] false\r\n\tat com.google.common.base.Preconditions.checkNotNull(Preconditions.java:895)\r\n\tat com.google.devtools.build.skyframe.DelegatingWalkableGraph.getDirectDeps(DelegatingWalkableGraph.java:121)\r\n\tat com.google.devtools.build.lib.skyframe.SkyframeBuildView.assertSaneAnalysisError(SkyframeBuildView.java:773)\r\n\tat com.google.devtools.build.lib.skyframe.SkyframeBuildView.processErrors(SkyframeBuildView.java:616)\r\n\tat com.google.devtools.build.lib.skyframe.SkyframeBuildView.configureTargets(SkyframeBuildView.java:454)\r\n\tat com.google.devtools.build.lib.analysis.BuildView.update(BuildView.java:404)\r\n\tat com.google.devtools.build.lib.buildtool.AnalysisPhaseRunner.runAnalysisPhase(AnalysisPhaseRunner.java:213)\r\n\tat com.google.devtools.build.lib.buildtool.AnalysisPhaseRunner.execute(AnalysisPhaseRunner.java:124)\r\n\tat com.google.devtools.build.lib.buildtool.BuildTool.buildTargets(BuildTool.java:145)\r\n\tat com.google.devtools.build.lib.buildtool.BuildTool.processRequest(BuildTool.java:290)\r\n\tat com.google.devtools.build.lib.runtime.commands.BuildCommand.exec(BuildCommand.java:95)\r\n\tat com.google.devtools.build.lib.runtime.BlazeCommandDispatcher.execExclusively(BlazeCommandDispatcher.java:564)\r\n\tat com.google.devtools.build.lib.runtime.BlazeCommandDispatcher.exec(BlazeCommandDispatcher.java:208)\r\n\tat com.google.devtools.build.lib.server.GrpcServerImpl.executeCommand(GrpcServerImpl.java:603)\r\n\tat com.google.devtools.build.lib.server.GrpcServerImpl.lambda$run$2(GrpcServerImpl.java:659)\r\n\tat io.grpc.Context$1.run(Context.java:595)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.base/java.lang.Thread.run(Unknown Source)\r\n\r\nINFO: Elapsed time: 3.854s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (16 packages loaded, 36 targets configured)\r\n    currently loading: tensorflow ... (3 packages)\r\n    Fetching @local_config_cc_toolchains; fetching\r\nInternal error thrown during build. Printing stack trace: java.lang.NullPointerException: //tensorflow/tools/lib_package:libtensorflow BuildConfigurationValue.Key[e4e94f4998e8c26abbc5eb2bf9d33e94aa6f63e0a9af8b8373f7ec758ef26105] false\r\n\tat com.google.common.base.Preconditions.checkNotNull(Preconditions.java:895)\r\n\tat com.google.devtools.build.skyframe.DelegatingWalkableGraph.getDirectDeps(DelegatingWalkableGraph.java:121)\r\n\tat com.google.devtools.build.lib.skyframe.SkyframeBuildView.assertSaneAnalysisError(SkyframeBuildView.java:773)\r\n\tat com.google.devtools.build.lib.skyframe.SkyframeBuildView.processErrors(SkyframeBuildView.java:616)\r\n\tat com.google.devtools.build.lib.skyframe.SkyframeBuildView.configureTargets(SkyframeBuildView.java:454)\r\n\tat com.google.devtools.build.lib.analysis.BuildView.update(BuildView.java:404)\r\n\tat com.google.devtools.build.lib.buildtool.AnalysisPhaseRunner.runAnalysisPhase(AnalysisPhaseRunner.java:213)\r\n\tat com.google.devtools.build.lib.buildtool.AnalysisPhaseRunner.execute(AnalysisPhaseRunner.java:124)\r\n\tat com.google.devtools.build.lib.buildtool.BuildTool.buildTargets(BuildTool.java:145)\r\n\tat com.google.devtools.build.lib.buildtool.BuildTool.processRequest(BuildTool.java:290)\r\n\tat com.google.devtools.build.lib.runtime.commands.BuildCommand.exec(BuildCommand.java:95)\r\n\tat com.google.devtools.build.lib.runtime.BlazeCommandDispatcher.execExclusively(BlazeCommandDispatcher.java:564)\r\n\tat com.google.devtools.build.lib.runtime.BlazeCommandDispatcher.exec(BlazeCommandDispatcher.java:208)\r\n\tat com.google.devtools.build.lib.server.GrpcServerImpl.executeCommand(GrpcServerImpl.java:603)\r\n\tat com.google.devtools.build.lib.server.GrpcServerImpl.lambda$run$2(GrpcServerImpl.java:659)\r\n\tat io.grpc.Context$1.run(Context.java:595)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n\tat java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n\tat java.base/java.lang.Thread.run(Unknown Source)\r\njava.lang.NullPointerException: //tensorflow/tools/lib_package:libtensorflow BuildConfigurationValue.Key[e4e94f4998e8c26abbc5eb2bf9d33e94aa6f63e0a9af8b8373f7ec758ef26105] false\r\n\tat com.google.common.base.Preconditions.checkNotNull(Preconditions.java:895)\r\n\tat com.google.devtools.build.skyframe.DelegatingWalkableGraph.getDirectDeps(DelegatingWalkableGraph.java:121)\r\n\tat com.google.devtools.build.lib.skyframe.SkyframeBuildView.assertSaneAnalysisError(SkyframeBuildView.java:773)\r\n\tat com.google.devtools.build.lib.skyframe.SkyframeBuildView.processErrors(SkyframeBuildView.java:616)\r\n\tat com.google.devtools.build.lib.skyframe.SkyframeBuildView.configureTargets(SkyframeBuildView.java:454)\r\n\tat com.google.devtools.build.lib.analysis.BuildView.update(BuildView.java:404)\r\n\tat com.google.devtools.build.lib.buildtool.AnalysisPhaseRunner.runAnalysisPhase(AnalysisPhaseRunner.java:213)\r\n\tat com.google.devtools.build.lib.buildtool.AnalysisPhaseRunner.execute(AnalysisPhaseRunner.java:124)\r\n\tat com.google.devtools.build.lib.buildtool.BuildTool.buildTargets(BuildTool.java:145)\r\n\tat com.google.devtools.build.lib.buildtool.BuildTool.processRequest(BuildTool.java:290)\r\n\tat com.google.devtools.build.lib.runtime.commands.BuildCommand.exec(BuildCommand.java:95)\r\n\tat com.google.devtools.build.lib.runtime.BlazeCommandDispatcher.execExclusively(BlazeCommandDispatcher.java:564)\r\n\tat com.google.devtools.build.lib.runtime.BlazeCommandDispatcher.exec(BlazeCommandDispatcher.java:208)\r\n\tat com.google.devtools.build.lib.server.GrpcServerImpl.executeCommand(GrpcServerImpl.java:603)\r\n\tat com.google.devtools.build.lib.server.GrpcServerImpl.lambda$run$2(GrpcServerImpl.java:659)\r\n\tat io.grpc.Context$1.run(Context.java:595)\r\nFAILED: Build did NOT complete successfully (16 packages loaded, 36 targets configured)\r\n    currently loading: tensorflow ... (3 packages)\r\n    Fetching @local_config_cc_toolchains; fetching\r\n```", "comments": ["Solved by running eval $(pyenv init -) before running ./configure", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39309\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39309\">No</a>\n"]}, {"number": 39308, "title": "Extension of the Data API `take` method to accept percent values", "body": "**System information**\r\n- TensorFlow version (you are using): 2.1.0\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n**Describe the feature and the current behavior/state.**\r\nThe Tensorflow Data API defines the [`take` method](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#take) which makes it possible to process a certain number of dataset elements. Currently it seems to be only possible to specify an absolute number of elements to be consumed (example: 32). It would be a nice addition if the take method could also receive a percentage value (0.0 - 1.0) that permits the consumption of a certain percentage of the dataset (exmaple: 0.2 for 20% of the dataset). This would be especially helpful for experiments that require an incremental increase in the amount of training data.\r\n\r\n**Will this change the current api? How?**\r\nIf the signature of the take method is extended to accept float as well as integer values, a fundamental change to the API should not be necessary.\r\n\r\n**Who will benefit with this feature?**\r\nThis would be especially helpful for experiments that require an incremental increase in the amount of training data (for example in active learning scenarios).", "comments": ["The challenge with supporting percentage is that it is not clear what the right behavior is for a dataset whose cardinality is not statically known (or infinite). What would you expect in those cases?\r\n\r\nOn a related note, could your use case be addressed by taking any 20% of the dataset (as opposed to the initial 20%)? If so, you could achieve that by using `filter`.", "In the streaming case, where the total size of a dataset is not known or cannot be determined in advance, I would expect the method to throw a meaningful exception that clearly states that selection by percentage is not applicable to streaming data and therefore not supported.\r\n\r\nIn any case, the selection by percentage should be deterministic, so that it can be expected that the same 20% of data used in a previous training run will be used in the current run. ", "Thanks. If you do not care about selecting the first 20% but any 20% (approximately), then you can do so by filter:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\ndataset = tf.data.Dataset.range(50)\r\ndataset = dataset.filter(lambda _: tf.less(tf.random.uniform(shape=[], maxval=100, dtype=tf.int32, seed=12), 20))\r\n\r\n# Iterating through the dataset multiple times will print the same elements \r\n# because we use a fixed seed for the random uniform call.\r\nfor elem in dataset:\r\n  print(elem)\r\n\r\nfor elem in dataset:\r\n  print(elem) \r\n```\r\n", "@milost,\r\nCan you please confirm if the above workaround has resolved your issue and consequently, if we can close this issue? Thanks! ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@milost,\r\nAutomatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n\r\nPlease refer the [Documentation of Dataset Filter](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#filter) and [jsimsa's answer](https://github.com/tensorflow/tensorflow/issues/39308#issuecomment-631706979)."]}, {"number": 39307, "title": "Golang Tensorflow v2.2.0 fails install", "body": "**System information**\r\n- OS Platform and Distribution (Macos catalina 10.15.4):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nFollowing https://github.com/tensorflow/tensorflow/blob/master/tensorflow/go/README.mdhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/go/README.md\r\n\r\n`go generate github.com/tensorflow/tensorflow/tensorflow/go/op`\r\nfails with `failed to process \"api_def_VarHandleOp.pbtxt\": Attribute allowed_devices not defined in base api for VarHandleOp\r\nexit status 1\r\ngo/src/github.com/tensorflow/tensorflow/tensorflow/go/op/generate.go:18: running \"go\": exit status 1`\r\n\r\n`go test github.com/tensorflow/tensorflow/tensorflow/go` passes \r\n\r\nbuilding or running go code using tensorflow then proceeds to fail with the following output \r\n`go: finding github.com/tensorflow/tensorflow/tensorflow/go/core/core_protos_go_proto latest\r\ngo: finding github.com/tensorflow/tensorflow/tensorflow/go/core latest\r\ngo: finding github.com/tensorflow/tensorflow/tensorflow/go latest\r\ngo: finding github.com/tensorflow/tensorflow/tensorflow latest\r\nbuild command-line-arguments: cannot load github.com/tensorflow/tensorflow/tensorflow/go/core/core_protos_go_proto: cannot find module providing package github.com/tensorflow/tensorflow/tensorflow/go/core/core_protos_go_proto`\r\n\r\nthe code run is the example that prints tf library version from https://www.tensorflow.org/install/lang_go\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["`FROM golang:1.13 AS builder\r\n\r\nWORKDIR /app\r\n\r\nCOPY libtf22.tar.gz /app/libtf22.tar.gz\r\n\r\nRUN tar -C /usr/local -xzf libtf22.tar.gz\r\n\r\nRUN ldconfig`\r\n\r\nRunning in Docker with the above Dockerfile, where libtf22.tar.gz is a libtensorflow build from from the v2.2.0 tag. (Which seems to work, if i use that tar.gz file and install tf 2.1 via go get, and run the tf_hello.go example, i get hello from version 2.2).\r\n\r\ndoing `go get -d github.com/tensorflow/tensorflow/tensorflow/go`\r\nProduces \r\n`package github.com/tensorflow/tensorflow/tensorflow/go/core/core_protos_go_proto: cannot find package \"github.com/tensorflow/tensorflow/tensorflow/go/core/core_protos_go_proto\" in any of:\r\n\t/usr/local/go/src/github.com/tensorflow/tensorflow/tensorflow/go/core/core_protos_go_proto (from $GOROOT)\r\n\t/go/src/github.com/tensorflow/tensorflow/tensorflow/go/core/core_protos_go_proto (from $GOPATH)` \r\n\r\nthe files are downloaded to /${GOPATH}/src/github.com/tensorflow though\r\n\r\nSkipping Step 2 build the TensorFlow C Library\r\n`cd ${GOPATH}/src/github.com/tensorflow/tensorflow\r\n./configure\r\nbazel build -c opt //tensorflow:libtensorflow.so`\r\n\r\nAs it has already been build from, following: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/lib_package/README.md\r\n\r\n`go generate github.com/tensorflow/tensorflow/tensorflow/go/op` in linux container also fails with:\r\n\r\n`failed to process \"api_def_VarHandleOp.pbtxt\": Attribute allowed_devices not defined in base api for VarHandleOp\r\nexit status 1\r\n/go/src/github.com/tensorflow/tensorflow/tensorflow/go/op/generate.go:18: running \"go\": exit status 1`\r\n\r\n\r\n\r\n", "Okay managed to get `go generate` to work, by doing \r\n`cd ${GOPATH}/github.com/src/tensorflow/tensorflow`\r\n`git checkout tags/v2.2.0`\r\n`go generate github.com/tensorflow/tensorflow/tensorflow/go/op`\r\nThis has now placed a lot of generated protobufs in `tensorflow/go/vendor/github.com/tensorflow/tensorflow/tensorflow/go/core/core_protos_go_proto`\r\n\r\nNow doing \r\n`go mod tidy` in my src directory seems to understand that there the core_protos for go exists. \r\n\r\nOutputting the following: \r\n\r\n`go: finding github.com/tensorflow/tensorflow/tensorflow/go/core/framework/tensor_shape_go_proto latest\r\ngo: finding github.com/tensorflow/tensorflow/tensorflow/go/core/core_protos_go_proto latest\r\ngo: finding github.com/tensorflow/tensorflow/tensorflow/go/core/framework/types_go_proto latest\r\ngo: finding github.com/tensorflow/tensorflow/tensorflow/go/core/framework latest\r\ngo: finding github.com/tensorflow/tensorflow/tensorflow/go/core latest\r\ngo: finding github.com/tensorflow/tensorflow/tensorflow/go latest\r\ngo: finding github.com/tensorflow/tensorflow/tensorflow latest`\r\n\r\nBut doing \r\n`go run main.go`\r\nor \r\n`go build main.go`\r\nSeems to try and download the module and fails with the following output \r\n`go: finding github.com/tensorflow/tensorflow/tensorflow/go/core/core_protos_go_proto latest\r\ngo: finding github.com/tensorflow/tensorflow/tensorflow/go/core latest\r\ngo: finding github.com/tensorflow/tensorflow/tensorflow/go latest\r\ngo: finding github.com/tensorflow/tensorflow/tensorflow latest\r\nbuild command-line-arguments: cannot load github.com/tensorflow/tensorflow/tensorflow/go/core/core_protos_go_proto: cannot find module providing package github.com/tensorflow/tensorflow/tensorflow/go/core/core_protos_go_proto`\r\n\r\nPerhaps @ymodak has an idea on what could be wrong in this case(Perhaps i am just doing something wrong with go mod) ", "@JacobSMoller Have you found a solution for this? I have the exact same issue.", "@ConverJens Sorry didn't get a notification for you writing me.\r\n\r\nYes not a nice solution. But i did make it work... \r\n\r\nHere is a public bucket with working libtensorflow 2.2 for unix and osx (If you haven't got them already)\r\n\r\nhttps://console.cloud.google.com/storage/browser/vml-tf-lib?forceOnBucketsSortingFiltering=false&project=dev-vml-cm\r\n\r\nThe next step is the not so nice step...\r\n\r\n`FROM golang:1.13 AS builder\r\n\r\nARG GO_MOD_TF_PATH=/go/pkg/mod/github.com/tensorflow/tensorflow@v2.2.0+incompatible/tensorflow/go\r\nARG GO_SRC_TF_PATH=/go/src/github.com/tensorflow/tensorflow/tensorflow/go/vendor/github.com/tensorflow/tensorflow/tensorflow/go/core/\r\n\r\nWORKDIR /build-lib\r\nRUN apt-get update && apt-get install -y --no-install-recommends ca-certificates autoconf automake libtool curl make g++ unzip curl\r\n\r\nRUN wget https://storage.googleapis.com/pub/gsutil.tar.gz  && tar xfz gsutil.tar.gz -C $HOME && rm gsutil.tar.gz\r\nENV PATH ${PATH}:/root/gsutil\r\n\r\nRUN wget https://github.com/protocolbuffers/protobuf/releases/download/v3.11.4/protoc-3.11.4-linux-x86_64.zip\r\nRUN unzip -o protoc-3.11.4-linux-x86_64.zip -d /usr/local bin/protoc\r\nRUN unzip -o protoc-3.11.4-linux-x86_64.zip -d /usr/local 'include/*'\r\nRUN rm protoc-3.11.4-linux-x86_64.zip\r\n\r\n\r\nRUN gsutil cp gs://vml-tf-lib/libtensorflow-unix.tar.gz .\r\nRUN tar -C /usr/local -xzf libtensorflow-unix.tar.gz\r\nRUN ldconfig\r\nRUN rm libtensorflow-unix.tar.gz\r\n\r\nWORKDIR /build-lib\r\nRUN go get -d github.com/tensorflow/tensorflow/tensorflow/go/op; exit 0\r\nWORKDIR /go/src/github.com/tensorflow/tensorflow/tensorflow\r\nRUN git checkout tags/v2.2.0\r\nWORKDIR /build-lib\r\nRUN go generate github.com/tensorflow/tensorflow/tensorflow/go/op\r\nWORKDIR /app\r\nCOPY go.sum /app/go.sum\r\nCOPY go.mod /app/go.mod\r\nRUN go mod download\r\nRUN mkdir -p ${GO_MOD_TF_PATH}/core\r\nRUN cp -r ${GO_SRC_TF_PATH}/core_protos_go_proto ${GO_MOD_TF_PATH}/core/core_protos_go_proto\r\nRUN cp -r ${GO_SRC_TF_PATH}/framework ${GO_MOD_TF_PATH}/core/framework\r\n\r\nRUN rm ${GO_MOD_TF_PATH}/core/core_protos_go_proto/autotuning.pb.go\r\nRUN rm ${GO_MOD_TF_PATH}/core/core_protos_go_proto/conv_autotuning.pb.go\r\n\r\nCOPY tftimer/tf.go /app/tf.go\r\nRUN go build tf.go\r\n\r\nFROM debian:bullseye AS runner\r\n\r\nWORKDIR /app\r\n\r\nRUN apt-get update && apt-get install -y --no-install-recommends ca-certificates\r\n\r\nCOPY --from=builder /app/tf /app/tf\r\nCOPY --from=builder /usr/local /usr/local\r\nRUN ldconfig`\r\n\r\nSo to make it work i do the \r\n\r\n`go get -d` as suggested in go documentation\r\nThen do go generate\r\nthen I use go mod download to get the tensorflow package.\r\nAnd finally copy the generated protos over from the downloaded source code to the GOPATH/pkg/mod/github.com/tensorflow/tensorflow@v2.2.0+incompatible/tensorflow/go/core\r\n\r\nNot nice in anyway. But haven't been able to find a better way. ", "@JacobSMoller Thanks for the detailed answer! I will try it the week after next and let you know how it goes!", "@JacobSMoller Thanks for the hint. I tried it, but failed with\r\nStep 23/38 : COPY go.sum /app/go.sum\r\nCOPY failed: stat /var/lib/docker/tmp/docker-builder720470318/go.sum: no such file or directory\r\n\r\nwhere do you get the go.sum and go.mod files from?", "They are generated when using go modules. \r\n\r\nhttps://blog.golang.org/using-go-modules\r\n", "Fixed as part of:\r\nhttps://github.com/tensorflow/tensorflow/commit/e5e495db7bee77cd0fd5dda3b06bd743cbcf1ef8\r\n\r\nNote that it requires from master:\r\n`bazel build -c opt //tensorflow/tools/lib_package:libtensorflow`\r\n`tar -xzvf the package in /usr/local`\r\n`go generate github.com/tensorflow/tensorflow/tensorflow/go/op`", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39307\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39307\">No</a>\n", "@jhseu This as far as I can tell, still doesn't enable users to do `go get github.com/tensorflow/tensorflow/tensorflow/go`\r\nand simply run things. \r\n\r\nWhen using go modules I still need to generate the protobufs in $GOPATH/src/github.com/tensorflow/tensorflow And then move the generated protobufs in to $GOPATH/pkg/mod/github.com/tensorflow/...\r\n\r\n\r\nAlso doing the go generate command from master now returns a new error:\r\n\r\n`2020/07/27 13:07:50 failed to process \"api_def_BatchFunction.pbtxt\": Attribute enable_large_batch_splitting not defined in base api for BatchFunction\r\nexit status 1\r\ngo/src/github.com/tensorflow/tensorflow/tensorflow/go/op/generate.go:18: running \"go\": exit status`", "@JacobSMoller Yeah, `go get` doesn't work for now. I made a pull request to fix it, but there were some objections to supporting both the bazel and generated protobufs to make it work.\r\n\r\nFor that error: it occurs when there's a version mismatch between libtensorflow.so and the TF ops in the source code. See my command above for building libtensorflow.so.", "@jhseu alright thanks :)\r\n\r\nSo no road map for having a go gettable Tensorflow isntallation :)? ", "I've spend a good day and a half truign to get this installed on my Ubuntu machine. Tried most things mentioned above, and have built everything from scratch. After installing Protobuf, it's not able to generate the protobufs\r\n\r\n```\r\n$ go generate github.com/tensorflow/tensorflow/tensorflow/go/op\r\ngoogle/protobuf/any.proto: File not found.\r\ngoogle/protobuf/duration.proto: File not found.\r\ntensorflow/core/protobuf/autotuning.proto:10:1: Import \"google/protobuf/any.proto\" was not found or had errors.\r\ntensorflow/core/protobuf/autotuning.proto:11:1: Import \"google/protobuf/duration.proto\" was not found or had errors.\r\ntensorflow/core/protobuf/autotuning.proto:61:3: \"google.protobuf.Duration\" is not defined.\r\ntensorflow/core/protobuf/autotuning.proto:74:3: \"google.protobuf.Any\" is not defined.\r\n../genop/main.go:17: running \"bash\": exit status 1\r\ngo/op/generate.go:17: running \"go\": exit status 1\r\n```", "@silverark How are you installing protoc? It looks like you're missing the default protos from your installation. Typically they're in /usr/local/include after installation, like so:\r\n```\r\njhseu0:~$ locate any.proto\r\n/usr/include/google/protobuf/any.proto\r\n```", "Thanks @jhseu. Turns out I had a different version of proto hidden in my ~/local\r\n\r\nFinally managed to get it working but only without module. If I use `go mod` in my project it downloads the version into pkg which is still broken. I'm currently at the stage @JacobSMoller is describing. "]}, {"number": 39306, "title": "Unable to use small_bert for tensorflow lite", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Catalina Version 10.15.3\r\n- TensorFlow installed from (source or binary): tensorflow-2.2.0-cp37-cp37m-macosx_10_11_x86_64.whl\r\n- TensorFlow version (or github SHA if from source): 2.2.0-dev20200507\r\n\r\nFollowing the demo notebook https://www.tensorflow.org/lite/tutorials/model_maker_text_classification, I wanted to change the BertClassifierModelSpec to use a smaller bert model on tensorflow hub\r\n\r\n```\r\nmodel_spec = BertClassifierModelSpec(uri='https://tfhub.dev/google/small_bert/bert_uncased_L-2_H-128_A-2/1')\r\n\r\ntrain_data = TextClassifierDataLoader.from_folder(os.path.join(data_path, 'train'), model_spec=model_spec, class_labels=['pos', 'neg'])\r\n\r\ntest_data = TextClassifierDataLoader.from_folder(os.path.join(data_path, 'test'), model_spec=model_spec, is_training=False, shuffle=False)\r\n\r\nmodel = text_classifier.create(train_data, model_spec=model_spec, epochs=1)\r\n```\r\n\r\nwhich led to the following error:\r\n```\r\nINFO:tensorflow:Retraining the models...\r\nINFO:tensorflow:Retraining the models...\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-22-dfbd96b901f3> in <module>()\r\n----> 1 model = text_classifier.create(train_data, model_spec=model_spec, epochs=1)\r\n\r\n6 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_hub/keras_layer.py in _get_callable(self)\r\n    294     if self._signature not in self._func.signatures:\r\n    295       raise ValueError(\"Unknown signature %s in %s (available signatures: %s).\"\r\n--> 296                        % (self._signature, self._handle, self._func.signatures))\r\n    297     f = self._func.signatures[self._signature]\r\n    298     if not callable(f):\r\n\r\nValueError: Unknown signature default in https://tfhub.dev/google/small_bert/bert_uncased_L-2_H-128_A-2/1 (available signatures: _SignatureMap({'tokenization_info': <ConcreteFunction pruned() at 0x7F8969733860>, 'mlm': <ConcreteFunction pruned(mlm_positions, segment_ids, input_mask, input_ids) at 0x7F8969701F98>, 'tokens': <ConcreteFunction pruned(input_ids, input_mask, segment_ids) at 0x7F8969095DA0>})).\r\n```", "comments": ["@wing-yiu,\r\nPlease check these links from similar issues and let us know if it helps. Thanks!\r\n- [Issue #1](https://github.com/google-research/ALBERT/issues/110)\r\n- [Issue #2](https://github.com/google-research/ALBERT/issues/27)", "Hi, I've tried to modify the demo code in https://github.com/tensorflow/examples/blob/9d117bf6eb03d1f60cecb02cb4d7ab6fbf552139/tensorflow_examples/lite/model_maker/core/task/model_spec.py line 349 to explicitly specify the signature as mentioned in the issues.\r\n```\r\n if is_tf2:\r\n    bert_model = hub.KerasLayer(hub_module_url, trainable=hub_module_trainable,\r\n                                signature='tokens', signature_outputs_as_dict = True)\r\n    pooled_output, _ = bert_model([input_word_ids, input_mask, input_type_ids])\r\n```\r\n\r\nthis is the new error I get\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<timed exec> in <module>\r\n\r\n~/Documents/GitHub/scamshield/tensorflow_examples/lite/model_maker/core/task/text_classifier.py in create(train_data, model_spec, shuffle, batch_size, epochs, validation_data)\r\n     58 \r\n     59   tf.compat.v1.logging.info('Retraining the models...')\r\n---> 60   text_classifier.train(train_data, validation_data, epochs, batch_size)\r\n     61 \r\n     62   return text_classifier\r\n\r\n~/Documents/GitHub/scamshield/tensorflow_examples/lite/model_maker/core/task/text_classifier.py in train(self, train_data, validation_data, epochs, batch_size)\r\n    121                                                 steps_per_epoch,\r\n    122                                                 validation_steps,\r\n--> 123                                                 self.num_classes)\r\n    124 \r\n    125     return self.model\r\n\r\n~/Documents/GitHub/scamshield/tensorflow_examples/lite/model_maker/core/task/model_spec.py in run_classifier(self, train_input_fn, validation_input_fn, epochs, steps_per_epoch, validation_steps, num_classes)\r\n    532       if validation_input_fn is not None:\r\n    533         evaluation_dataset = validation_input_fn()\r\n--> 534       bert_model, _ = _get_classifier_model()\r\n    535       optimizer = bert_model.optimizer\r\n    536 \r\n\r\n~/Documents/GitHub/scamshield/tensorflow_examples/lite/model_maker/core/task/model_spec.py in _get_classifier_model()\r\n    513           hub_module_url=self.uri,\r\n    514           hub_module_trainable=self.trainable,\r\n--> 515           is_tf2=self.is_tf2)\r\n    516 \r\n    517       classifier_model.optimizer = optimization.create_optimizer(\r\n\r\n~/Documents/GitHub/scamshield/tensorflow_examples/lite/model_maker/core/task/model_spec.py in create_classifier_model(bert_config, num_labels, max_seq_length, initializer, hub_module_url, hub_module_trainable, is_tf2)\r\n    340     bert_model = hub.KerasLayer(hub_module_url, trainable=hub_module_trainable,\r\n    341                                 signature='tokens', signature_outputs_as_dict = True)\r\n--> 342     pooled_output, _ = bert_model([input_word_ids, input_mask, input_type_ids])\r\n    343   else:\r\n    344     print(\"else\")\r\n\r\n~/.local/share/virtualenvs/scamshield-_qogcCHJ/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, *args, **kwargs)\r\n    934                     not base_layer_utils.is_in_eager_or_tf_function()):\r\n    935                   with auto_control_deps.AutomaticControlDependencies() as acd:\r\n--> 936                     outputs = call_fn(cast_inputs, *args, **kwargs)\r\n    937                     # Wrap Tensors in `outputs` in `tf.identity` to avoid\r\n    938                     # circular dependencies.\r\n\r\n~/.local/share/virtualenvs/scamshield-_qogcCHJ/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py in wrapper(*args, **kwargs)\r\n    260       except Exception as e:  # pylint:disable=broad-except\r\n    261         if hasattr(e, 'ag_error_metadata'):\r\n--> 262           raise e.ag_error_metadata.to_exception(e)\r\n    263         else:\r\n    264           raise\r\n\r\nValueError: in user code:\r\n\r\n    /Users/wingyiu/.local/share/virtualenvs/scamshield-_qogcCHJ/lib/python3.7/site-packages/tensorflow_hub/keras_layer.py:206 call  *\r\n        self._check_trainability()\r\n    /Users/wingyiu/.local/share/virtualenvs/scamshield-_qogcCHJ/lib/python3.7/site-packages/tensorflow_hub/keras_layer.py:265 _check_trainability  *\r\n        raise ValueError(\r\n\r\n    ValueError: Setting hub.KerasLayer.trainable = True is unsupported when loading from the hub.Module format of TensorFlow 1.\r\n```\r\n\r\nI believe it is because the smaller model is a hub module is not in TensorFlow 2.x format. Is there a working example for smaller BERT models that are not in TensorFlow 2.x format that works with TensorFlow Lite?", "@wing-yiu Yes there is no small_bert implemented in tensorflow 2.0. You can browse the hub modules that are implemented in tensorflow 2.0 [here](https://tfhub.dev/s?subtype=module,placeholder&tf-version=tf2).", "Hi, may I know if there are other text classification models that are compatible with tensorflow lite?\r\n\r\nOnly https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1 in the example works. \r\n\r\nThese do not work\r\nhttps://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2\r\nhttps://tfhub.dev/tensorflow/albert_lite_base/1\r\nhttps://tfhub.dev/tensorflow/albert_en_base/1\r\n\r\nsame problem as @r-wheeler mentioned in https://github.com/tensorflow/tensorflow/issues/34396", "I am sort sure if this will solve your issue but we have a few text embedding modules in tensorflow hub that you can use. You can find them [here](https://tfhub.dev/s?tf-version=tf2&q=lite). You can specifically take a look at Albert, a lite version of BERT [here](https://tfhub.dev/tensorflow/albert_lite_base/1). ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing this issue as it has been inactive for 2 weeks. Please add additional comments for us to open this issue again. Thanks! this issuea", "As advised, I have tried to use albert lite but to no avail. The following error was produced using tensorflow version 2.3.0-dev20200624\r\n\r\n```\r\ninput_word_ids = tf.keras.layers.Input(shape=(max_seq_length,),\r\n                                       dtype=tf.int32,\r\n                                       name=\"input_word_ids\")\r\ninput_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32,\r\n                                   name=\"input_mask\")\r\nsegment_ids = tf.keras.layers.Input(shape=(max_seq_length,),\r\n                                    dtype=tf.int32,\r\n                                    name=\"segment_ids\")\r\n\r\nlitebert = hub.KerasLayer(\"https://tfhub.dev/tensorflow/albert_lite_base/1\",\r\n                          signature=\"tokens\",\r\n                          signature_outputs_as_dict=True,\r\n                          name=\"albert_lite\")\r\n\r\npooled_output = litebert(dict(input_ids=input_word_ids,\r\n                              input_mask=input_mask,\r\n                              segment_ids=segment_ids))[\"pooled_output\"]\r\n\r\noutput = tf.keras.layers.Dropout(rate=0.0001)(pooled_output)\r\n\r\noutput = tf.keras.layers.Dense(\r\n    2,\r\n    name='output',\r\n    dtype=tf.float32)(output)\r\n\r\nmodel = tf.keras.Model(\r\n        inputs=[input_word_ids, input_mask, segment_ids],\r\n        outputs=output)\r\n\r\nmodel.compile()\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\ntflite_model = converter.convert()\r\nwith tf.io.gfile.GFile(os.path.join(path, \"temp.tflite\"), 'wb') as f:\r\n    f.write(tflite_model)\r\n```\r\n\r\nEverything works fine until I try to convert to tensorflow lite, error below:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n~/.local/share/virtualenvs/scamshield-_qogcCHJ/lib/python3.7/site-packages/tensorflow/python/framework/importer.py in _import_graph_def_internal(graph_def, input_map, return_elements, validate_colocation_constraints, name, producer_op_list)\r\n    496         results = c_api.TF_GraphImportGraphDefWithResults(\r\n--> 497             graph._c_graph, serialized, options)  # pylint: disable=protected-access\r\n    498         results = c_api_util.ScopedTFImportGraphDefResults(results)\r\n\r\nInvalidArgumentError: Input 3 of node functional_13/albert_lite/StatefulPartitionedCall was passed float from functional_13/albert_lite/172304:0 incompatible with expected resource.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-42-e5954aede490> in <module>\r\n      4 # converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\r\n      5 #                                        tf.lite.OpsSet.SELECT_TF_OPS]\r\n----> 6 tflite_model = converter.convert()\r\n      7 with tf.io.gfile.GFile(os.path.join(path, \"temp.tflite\"), 'wb') as f:\r\n      8     f.write(tflite_model)\r\n\r\n~/.local/share/virtualenvs/scamshield-_qogcCHJ/lib/python3.7/site-packages/tensorflow/lite/python/lite.py in convert(self)\r\n    807     frozen_func, graph_def = (\r\n    808         _convert_to_constants.convert_variables_to_constants_v2_as_graph(\r\n--> 809             self._funcs[0], lower_control_flow=False))\r\n    810 \r\n    811     input_tensors = [\r\n\r\n~/.local/share/virtualenvs/scamshield-_qogcCHJ/lib/python3.7/site-packages/tensorflow/python/framework/convert_to_constants.py in convert_variables_to_constants_v2_as_graph(func, lower_control_flow, aggressive_inlining)\r\n   1107 \r\n   1108   frozen_func = _construct_concrete_function(func, output_graph_def,\r\n-> 1109                                              converted_input_indices)\r\n   1110   return frozen_func, output_graph_def\r\n   1111 \r\n\r\n~/.local/share/virtualenvs/scamshield-_qogcCHJ/lib/python3.7/site-packages/tensorflow/python/framework/convert_to_constants.py in _construct_concrete_function(func, output_graph_def, converted_input_indices)\r\n    999   new_func = wrap_function.function_from_graph_def(output_graph_def,\r\n   1000                                                    new_input_names,\r\n-> 1001                                                    new_output_names)\r\n   1002 \r\n   1003   # Manually propagate shape for input tensors where the shape is not correctly\r\n\r\n~/.local/share/virtualenvs/scamshield-_qogcCHJ/lib/python3.7/site-packages/tensorflow/python/eager/wrap_function.py in function_from_graph_def(graph_def, inputs, outputs)\r\n    648     importer.import_graph_def(graph_def, name=\"\")\r\n    649 \r\n--> 650   wrapped_import = wrap_function(_imports_graph_def, [])\r\n    651   import_graph = wrapped_import.graph\r\n    652   return wrapped_import.prune(\r\n\r\n~/.local/share/virtualenvs/scamshield-_qogcCHJ/lib/python3.7/site-packages/tensorflow/python/eager/wrap_function.py in wrap_function(fn, signature, name)\r\n    626           signature=signature,\r\n    627           add_control_dependencies=False,\r\n--> 628           collections={}),\r\n    629       variable_holder=holder,\r\n    630       signature=signature)\r\n\r\n~/.local/share/virtualenvs/scamshield-_qogcCHJ/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    984         _, original_func = tf_decorator.unwrap(python_func)\r\n    985 \r\n--> 986       func_outputs = python_func(*func_args, **func_kwargs)\r\n    987 \r\n    988       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\n~/.local/share/virtualenvs/scamshield-_qogcCHJ/lib/python3.7/site-packages/tensorflow/python/eager/wrap_function.py in __call__(self, *args, **kwargs)\r\n     85 \r\n     86   def __call__(self, *args, **kwargs):\r\n---> 87     return self.call_with_variable_creator_scope(self._fn)(*args, **kwargs)\r\n     88 \r\n     89   def call_with_variable_creator_scope(self, fn):\r\n\r\n~/.local/share/virtualenvs/scamshield-_qogcCHJ/lib/python3.7/site-packages/tensorflow/python/eager/wrap_function.py in wrapped(*args, **kwargs)\r\n     91     def wrapped(*args, **kwargs):\r\n     92       with variable_scope.variable_creator_scope(self.variable_creator_scope):\r\n---> 93         return fn(*args, **kwargs)\r\n     94 \r\n     95     return wrapped\r\n\r\n~/.local/share/virtualenvs/scamshield-_qogcCHJ/lib/python3.7/site-packages/tensorflow/python/eager/wrap_function.py in _imports_graph_def()\r\n    646 \r\n    647   def _imports_graph_def():\r\n--> 648     importer.import_graph_def(graph_def, name=\"\")\r\n    649 \r\n    650   wrapped_import = wrap_function(_imports_graph_def, [])\r\n\r\n~/.local/share/virtualenvs/scamshield-_qogcCHJ/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)\r\n    505                 'in a future version' if date is None else ('after %s' % date),\r\n    506                 instructions)\r\n--> 507       return func(*args, **kwargs)\r\n    508 \r\n    509     doc = _add_deprecated_arg_notice_to_docstring(\r\n\r\n~/.local/share/virtualenvs/scamshield-_qogcCHJ/lib/python3.7/site-packages/tensorflow/python/framework/importer.py in import_graph_def(***failed resolving arguments***)\r\n    403       return_elements=return_elements,\r\n    404       name=name,\r\n--> 405       producer_op_list=producer_op_list)\r\n    406 \r\n    407 \r\n\r\n~/.local/share/virtualenvs/scamshield-_qogcCHJ/lib/python3.7/site-packages/tensorflow/python/framework/importer.py in _import_graph_def_internal(graph_def, input_map, return_elements, validate_colocation_constraints, name, producer_op_list)\r\n    499       except errors.InvalidArgumentError as e:\r\n    500         # Convert to ValueError for backwards compatibility.\r\n--> 501         raise ValueError(str(e))\r\n    502 \r\n    503     # Create _DefinedFunctions for any imported functions.\r\n\r\nValueError: Input 3 of node functional_13/albert_lite/StatefulPartitionedCall was passed float from functional_13/albert_lite/172304:0 incompatible with expected resource.\r\n```\r\n"]}, {"number": 39304, "title": "What happen to the tensorflow/lite/micro/examples/hello_world/create_sine_model.ipynb ?", "body": "\r\n", "comments": ["This question is better asked on StackOverflow since it is not a bug or feature request. There is also a larger community that reads questions there and provide better and faster support for such issues. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}]