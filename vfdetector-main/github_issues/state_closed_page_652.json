[{"number": 34055, "title": "model.reset_states() does not work for bidirectional-RNNs in tf.keras.", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **YES**.\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **macOS 10.14.6**\r\n- TensorFlow installed from (source or binary): **binary**\r\n- TensorFlow version (use command below): **2.0.0**\r\n- Python version: **3.7.4**\r\n- GPU model and memory: **none (MacBook Pro, Core i5, Iris Graphics 6100, 1.5 GB)**\r\n\r\n**Describe the current behavior**\r\nState handling in RNNs with a Bidirectional wrapper has changed in tf.keras from keras with TF 1.x.  In the old keras with TF 1.x, using `stateful=True` in a bidi-RNN had no effect -- i.e., all bidi-RNN models behaved as if  `stateful=False`.  Therefore `model.reset_states()` did not do anything.\r\n\r\nIn the new tf.keras, `stateful=True` in a bidi-RNN does have an effect -- the fwd-RNN is stateful and the bwd-RNN is stateful.  This is a good change IMO -- even though stateful bidi-RNNs are unusual, this is the best way to implement.  However, in tf.keras, the `model.reset_states()` does not do anything for bidi-RNN models (SimpleRNN, GRU, LSTM).  \r\n\r\n**Describe the expected behavior**\r\n\r\nFor the minimal example script provided below, here is the output:\r\n\r\n```\r\nFWD::\r\nnon_stateful: [ 1.   -0.5   0.25]\r\nstateful: [ 1.   -0.5   0.25]\r\ndelta: [0. 0. 0.]\r\nBWD::\r\nnon_stateful: [1. 0. 0.]\r\nstateful: [1. 0. 0.]\r\ndelta: [0. 0. 0.]\r\nFWD::\r\nnon_stateful: [ 1.   -0.5   0.25]\r\nstateful: [ 0.875   -0.4375   0.21875]\r\ndelta: [-0.125    0.0625  -0.03125]\r\nBWD::\r\nnon_stateful: [1. 0. 0.]\r\nstateful: [ 0.875  0.25  -0.5  ]\r\ndelta: [-0.125  0.25  -0.5  ]\r\n\r\n** RESETING STATES in STATEFUL MODEL **\r\n\r\nFWD::\r\nnon_stateful: [ 1.   -0.5   0.25]\r\nstateful: [ 0.890625   -0.4453125   0.22265625]\r\ndelta: [-0.109375    0.0546875  -0.02734375]\r\nBWD::\r\nnon_stateful: [1. 0. 0.]\r\nstateful: [ 0.890625  0.21875  -0.4375  ]\r\ndelta: [-0.109375  0.21875  -0.4375  ]\r\n```\r\n\r\nThe results after the **STATE RESET**  should be the same as the first set of results -- i.e., the last (third) set of results should produce the same result for the stateful and non-stateful models (same as the first set of results).  \r\n\r\n**Code to reproduce the issue**\r\n\r\n```python\r\nimport numpy as np\r\nTF2 = True\r\nif TF2:\r\n\t### currently, there is a bug in tf.keras: model.reset_states() does not work\r\n\tfrom tensorflow.keras.layers import Input, Dense, SimpleRNN, GRU, LSTM, Bidirectional\r\n\tfrom tensorflow.keras.models import Model\r\nelse:\r\n\t### in the old keras, bidi-RNNs with stateful=True behave smae as stateful=False\r\n\tfrom keras.layers import Input, Dense, SimpleRNN, GRU, LSTM, Bidirectional\r\n\tfrom keras.models import Model\r\n\r\nsequence_length = 3\r\nfeature_dim = 1\r\nfeatures_in = Input(batch_shape=(1, sequence_length, feature_dim)) \r\n\r\nrnn_out = Bidirectional( SimpleRNN(1, activation=None, use_bias=False, return_sequences=True, return_state=False, stateful=False))(features_in)\r\nstateless_model = Model(inputs=[features_in], outputs=[rnn_out])\r\n\r\nstateful_rnn_out = Bidirectional( SimpleRNN(1, activation=None, use_bias=False, return_sequences=True, return_state=False, stateful=True))(features_in)\r\nstateful_model = Model(inputs=features_in, outputs=stateful_rnn_out)\r\n\r\ntoy_weights = [ np.asarray([[1.0]], dtype=np.float32), np.asarray([[-0.5]], dtype=np.float32), np.asarray([[1.0]], dtype=np.float32), np.asarray([[-0.5]], dtype=np.float32)]\r\n\r\nstateless_model.set_weights(toy_weights)\r\nstateful_model.set_weights(toy_weights)\r\n\r\nx_in = np.zeros(sequence_length)\r\nx_in[0] = 1\r\nx_in = x_in.reshape( (1, sequence_length, feature_dim) )\r\n\r\ndef print_bidi_out(non_stateful_out, stateful_out):\r\n\tfb = ['FWD::', 'BWD::']\r\n\r\n\tfor i in range(2):\r\n\t\tprint(fb[i])\r\n\t\tprint(f'non_stateful: {non_stateful_out.T[i]}')\r\n\t\tprint(f'stateful: {stateful_out.T[i]}')\r\n\t\tprint(f'delta: {stateful_out.T[i]-non_stateful_out.T[i]}')\r\n\r\n\r\nnon_stateful_out = stateless_model.predict(x_in).reshape((sequence_length,2))\r\nstateful_out = stateful_model.predict(x_in).reshape((sequence_length,2))\r\nprint_bidi_out(non_stateful_out, stateful_out)\r\n\r\nnon_stateful_out = stateless_model.predict(x_in).reshape((sequence_length,2))\r\nstateful_out = stateful_model.predict(x_in).reshape((sequence_length,2))\r\nprint_bidi_out(non_stateful_out, stateful_out)\r\n\r\nprint('\\n** RESETING STATES in STATEFUL MODEL **\\n')\r\nstateful_model.reset_states()\r\nnon_stateful_out = stateless_model.predict(x_in).reshape((sequence_length,2))\r\nstateful_out = stateful_model.predict(x_in).reshape((sequence_length,2))\r\nprint_bidi_out(non_stateful_out, stateful_out)\r\n```\r\n", "comments": ["Note: this is an issue with tf.keras vs. keras (not TF 1.x vs TF 2.0)", "I could replicate issue on colab with Tf 2.0. \r\nPlease take a look at [gist](https://colab.sandbox.google.com/gist/gadagashwini/0d4771e1d00b215c8f06577915bf7fef/untitled246.ipynb). Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34055\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34055\">No</a>\n"]}, {"number": 34054, "title": "[INTEL MKL] Fix Eigen related compilation error.", "body": "A compilation error occurred due to the upgrade for Eigen. Commit - https://github.com/tensorflow/tensorflow/commit/7b62d787c0d05a2619d88af3e5fb337dad02f66a", "comments": []}, {"number": 34053, "title": "How to use hub.KerasLayer without the Sequential API", "body": "I don't know if its a bug.\r\nI'm following this tutorial https://www.tensorflow.org/tutorials/keras/text_classification_with_hub which is working fine.\r\nI'm trying to replace the sequential model: \r\n```\r\nmodel = tf.keras.Sequential()\r\nmodel.add(hub_layer)\r\nmodel.add(layers.Dense(16, activation='relu'))\r\nmodel.add(layers.Dense(1, activation='sigmoid'))\r\n```\r\nby:\r\n\r\n```\r\nclass model(tf.keras.Model):\r\n    def __init__(self, hub_layer):\r\n        super().__init__()\r\n        self.embedding = hub_layer\r\n        self.dense1 = layers.Dense(16, activation='relu')\r\n        self.dense2 = layers.Dense(1, activation='sigmoid')\r\n    def call(self, x):\r\n        x = self.embedding(x)\r\n        x = self.dense1(x)\r\n        return self.dense2(x)\r\n```\r\nWhich is throwing:\r\n```\r\nValueError: Python inputs incompatible with input_signature:\r\n      inputs: (\r\n        Tensor(\"input_1_35:0\", shape=(None, 1), dtype=string))\r\n      input_signature: (\r\n        TensorSpec(shape=(None,), dtype=tf.string, name=None))\r\n```\r\nI didn't change anything else.\r\nIf this a bug or I'm doing something wrong ? The second model should act exactly like the first one.\r\n", "comments": ["Issue is replicating with Tf 2.0.\r\nPlease see the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/5ece921ce20ee180da6a24cca64d4bcc/text_classification_with_hub.ipynb). Thanks!", "This seems to be fixed with TF  '2.1.0-rc1'. You may try above gist. Thanks!", "I am closing this issue as it was resolved with recent `tf-nightly`. Please feel free to reopen if the issue persists again. Thanks!"]}, {"number": 34052, "title": "[Intel MKL] Fixing a memory leak problem", "body": "The changes in this PR fix a potential memory leak by reusing the same variable instead of creating new one each iteration. This change is owned by @guizili0 who can advise if it is possible to write a unit test for that.", "comments": ["@mahmoud-abuzaina can you please include description of what changes are included , and also is it possible to write test cases around the changes ?", "@rthadur I have updated the description.", "All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F34052) for more info**.\n\n<!-- need_author_consent -->", "@googlebot I consent.", "@googlebot I consent.", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F34052) for more info**.\n\n<!-- ok -->"]}, {"number": 34051, "title": "Decrease tolerance of TF-TRT python tests for TFv2", "body": "TFv1 had already reduced tolerance", "comments": []}, {"number": 34050, "title": "[ROCm] Fix for the broken ROCm CSB.", "body": "The following commit breaks the --config=rocm build\r\n\r\nhttps://github.com/tensorflow/tensorflow/commit/bf9c196f37b9cbb3109b2891aaf9da85bf5f712a\r\n\r\nThe above commit adds support for complex type in the optimizers. Complex types are not supported on the ROCm platform. Support for it needs to be excluded on the ROCm platform, and that is what this \"fix\" does.\r\n\r\n-----------------------------------\r\n\r\n@chsigg, @whchung please review\r\n\r\nIf possible, we would like to get this PR merged before the cutoff for TF2.1 tomorrow\r\nthanks", "comments": ["@chsigg gentle ping", "@chsigg gentle ping", "@rthadur , anything we can do to help get this PR merged?"]}, {"number": 34049, "title": "Do not assume order on std::unordered_map", "body": "This fixes TF-TRT unit test TRTEngineOpTestBase.DynamicShapes", "comments": []}, {"number": 34048, "title": "fix(keras): load_model should pass custom_objects when loading models in tf format", "body": "```python\r\n# this fails if the loaded model is a SavedModel (saved with format=\"tf\") \r\nfrom tensorflow.keras import models\r\nmodel = models.load_model(\"/path/to/tf_model\", custom_objects={\"custom_loss\": custom_loss})\r\n```\r\n\r\nThe `custom_object` should be passed to the compile correctly (as it is with when loading a h5 file).\r\n\r\nShould fix: #33646\r\n", "comments": ["Anybody going to take a look at this? Is there something left I have to take care of?", "@tanzhenyu gentle ping for review?", "same issue here, when you save the model in tf format, you can't re-load the model with custom_objects, this should be fixed.", "Issue still presists. Would be great if someone could take a look for a review.", "Thanks for the PR! A similar fix was submitted and this issue should be resolved in nightly ", "Is there any other method to reload this function without modifing the original tensorflow code?"]}, {"number": 34047, "title": "ResourceApplyGradientDescent happens on CPU?", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 19.10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CUDA Version: 10.1\r\n```bash\r\ntf-docker /opt/project/src > nvcc --version\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2018 NVIDIA Corporation\r\nBuilt on Sat_Aug_25_21:08:01_CDT_2018\r\nCuda compilation tools, release 10.0, V10.0.130\r\n```\r\n- GPU model and memory: GeForce GTX 1050, 4042MiB\r\n\r\nI use the official tensorflow docker image: `tensorflow/tensorflow:2.0.0-gpu-py3`\r\n\r\n**Describe the current behavior**\r\nI experience fluctuating GPU utilization when I train a simple language model on artificial data using a custom training loop.\r\n![Peek 2019-11-06 17-01](https://user-images.githubusercontent.com/2678217/68315470-197fa680-00b8-11ea-936d-b2c588259558.gif)\r\n\r\n**Describe the expected behavior**\r\nI would expect to get GPU utilization more stable at 100% (or very close to it), since the model is very simple and I expect all (heavy) ops to be able to run on the GPU.\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\n#tf.debugging.set_log_device_placement(True)\r\n\r\nVOCAB_SIZE = 32000\r\nBATCH_SIZE = 20\r\nLEARNING_RATE = 0.001\r\n\r\nclass SimpleModel(tf.keras.Model):\r\n    def __init__(self, target_vocab_size):\r\n        super(SimpleModel, self).__init__()\r\n        self.d_model = 1024\r\n        self.embedding = tf.keras.layers.Embedding(target_vocab_size, self.d_model)\r\n        self.body = tf.keras.layers.Dense(self.d_model)\r\n\r\n    def call(self, input, training):\r\n        # input shape: (batch, seq_len)\r\n        x = self.embedding(input)  # (batch, seq_len, d_model)\r\n        x = self.body(x)\r\n        logits = tf.matmul(x, self.embedding.embeddings, transpose_b=True)\r\n        return logits\r\n\r\n\r\ndef get_dataset():\r\n    ds = tf.data.Dataset.from_tensor_slices(tf.random.uniform((1000, 20), 0, VOCAB_SIZE, dtype=tf.int64))\r\n    ds = ds.padded_batch(BATCH_SIZE, padded_shapes=[None])\r\n    ds = ds.repeat()\r\n    ds = ds.prefetch(2)\r\n    return ds\r\n\r\n\r\ndef train(ds, model, optimizer):\r\n\r\n    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\r\n\r\n    def calculate_loss(real, pred):\r\n        loss_ = loss_object(real, pred)\r\n        return tf.reduce_mean(loss_)\r\n\r\n    @tf.function\r\n    def train_step(batch):\r\n        tar_inp = batch[:, :-1]\r\n        tar_real = batch[:, 1:]\r\n\r\n        with tf.GradientTape() as tape:\r\n            logits = model(tar_inp, True)\r\n            loss = calculate_loss(tar_real, logits)\r\n\r\n        gradients = tape.gradient(loss, model.trainable_variables)\r\n        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n        return None\r\n\r\n    #tf.summary.trace_on(graph=True, profiler=True)\r\n\r\n    for i, batch in enumerate(ds):\r\n        _ = train_step(batch)\r\n\r\n        #if i == 10:\r\n        #   tf.summary.trace_export(name=\"model_trace\", step=0, profiler_outdir=\"/tmp/profiling/5\")\r\n        #   break\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    ds = get_dataset()\r\n    model = SimpleModel(VOCAB_SIZE)\r\n    optimizer = tf.keras.optimizers.SGD(LEARNING_RATE)\r\n\r\n    train(ds, model, optimizer)\r\n```\r\n\r\n**Other info / logs**\r\nWhen inspecting the trace in Tensorboard I see two memcpys happening between training steps (green and blue boxes):\r\n![Screenshot from 2019-11-06 17-16-15](https://user-images.githubusercontent.com/2678217/68316249-7039b000-00b9-11ea-9b44-88f3f58fa5e1.png)\r\n\r\nZooming in between two steps, I also see a ResourceApplyGradientDescent op happening on the CPU:\r\n![Screenshot from 2019-11-06 17-19-48](https://user-images.githubusercontent.com/2678217/68316446-c73f8500-00b9-11ea-863a-b050eddeab8d.png)\r\n\r\nAre ResourceApply* ops supposed to happen on the host (CPU)?", "comments": ["@TobiasNorlund, Please refer this [link](https://www.tensorflow.org/guide/gpu). The document describes the GPU utilization. Thanks! ", "Even if I explicitly pin the GPU to the op applying gradients, there is still no change. It is still performed on the CPU according to trace.\r\n```\r\n        with tf.device('/job:localhost/replica:0/task:0/device:GPU:0'):\r\n            gradients = tape.gradient(loss, model.trainable_variables)\r\n            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n```\r\n\r\nIs this to be expected?", "To me the smoking gun here seems to be this line when I enable logging:\r\n\r\n```\r\n2019-12-27 10:09:44.089327: I tensorflow/core/common_runtime/eager/execute.cc:533] Executing op VarHandleOp in device /job:localhost/replica:0/task:0/device:CPU:0\r\n```\r\n\r\nand then in the graph we have:\r\n\r\n```\r\nnode {\r\n  name: \"simple_model_embedding_embedding_lookup_readvariableop_resource\"\r\n  op: \"_Arg\"\r\n  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_RESOURCE\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_handle_dtypes\"\r\n    value {\r\n      list {\r\n        type: DT_FLOAT\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"_handle_shapes\"\r\n    value {\r\n      list {\r\n        shape {\r\n          dim {\r\n            size: 32000\r\n          }\r\n          dim {\r\n            size: 1024\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n  attr {\r\n    key: \"index\"\r\n    value {\r\n      i: 1\r\n    }\r\n  }\r\n}\r\n\r\n...\r\n\r\nnode {\r\n  name: \"SGD/SGD/update/ResourceApplyGradientDescent\"\r\n  op: \"ResourceApplyGradientDescent\"\r\n  input: \"simple_model_embedding_embedding_lookup_readvariableop_resource\"\r\n  input: \"SGD/Identity_2\"\r\n  input: \"AddN\"\r\n  device: \"/job:localhost/replica:0/task:0/device:CPU:0\"\r\n  attr {\r\n    key: \"T\"\r\n    value {\r\n      type: DT_FLOAT\r\n    }\r\n  }\r\n  attr {\r\n    key: \"use_locking\"\r\n    value {\r\n      b: true\r\n    }\r\n  }\r\n}\r\n```\r\n\r\nIt looks like in eager mode we create the resource variable on the CPU that causes the `ResourceApplyGradientDescent` to also run on the CPU.  I'm not sure why we're creating the resource variable on the CPU in the first place, the other variables are put on the GPU as expected.\r\n\r\nAssigning to @qqfish ", "Was able to run your code in Tensorflow GPU 2.5, please find the gist [here](https://colab.research.google.com/gist/sachinprasadhs/5cada4be64e2596e22261cf99ca5343d/34047.ipynb) and let us know if you are still facing the issue. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34047\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34047\">No</a>\n", "I am also struggling with this issue when I apply mixed-precision training. @TobiasNorlund @sanjoy @qqfish Did you find out what the problem is?"]}, {"number": 34045, "title": "`==` fails where `tf.equal` works when using tf.data.Dataset.from_generator + @tf.function (TF 2.0)", "body": "\r\n\"==\" works in my `augment` function (with `@tf.function` decorator) , but `tf.equal` works.\r\n\r\ntensorflow version : 2.0.0-beta1\r\npython version : python3.6\r\n\r\n**Minimal reproducable example**\r\nJust chuck this in a `\u0167est.py` file and run `python3.6 test.py`:\r\n```\r\nimport tensorflow as tf\r\n# tf.__version__ yields 2\r\nimport tensorflow_hub as hub\r\nimport numpy as np\r\n\r\n@tf.function\r\ndef augment(x, y):\r\n    tf.print(tf.where(tf.equal(y, 0))) # works\r\n    # tf.print(tf.where(y == 0)) # doesn't work for some reason\r\n    return tf.data.Dataset.from_tensors((x, y))\r\n\r\ndef gen():\r\n    for i in range(400):\r\n        yield np.zeros(shape=(299, 299, 3)), np.zeros(shape=(6,))\r\n\r\ndataset = tf.data.Dataset.from_generator(gen, (tf.int64, tf.int64), (tf.TensorShape([299,299,3]), tf.TensorShape([6])))\r\n\r\nclass Trainer:\r\n    def __init__(self, batch_size):\r\n        self.input_shape = [299, 299, 3]\r\n        self.model = self.create_model()\r\n        self.dataset = dataset\r\n        self.dataset_size = self._get_dataset_size()\r\n        split_point = int(0.8 * self.dataset_size)\r\n        self.batch_size = batch_size\r\n        self.train_ds = self.dataset.take(split_point).flat_map(augment).repeat().batch(self.batch_size)\r\n        self.train_ds_size = split_point\r\n\r\n        self.validation_ds = self.dataset.skip(split_point).repeat().batch(self.batch_size)\r\n        self.validation_ds_size = self.dataset_size - split_point\r\n        assert self.validation_ds_size + self.train_ds_size == self.dataset_size\r\n\r\n    def create_model(self):\r\n        model = tf.keras.Sequential()\r\n        model.add(hub.KerasLayer(\"https://tfhub.dev/google/tf2-preview/inception_v3/feature_vector/4\",\r\n                                 output_shape=[2048],\r\n                                 input_shape=self.input_shape,\r\n                                 trainable=False))\r\n        model.add(tf.keras.layers.Dense(units=6, activation=\"softmax\"))\r\n        model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\r\n        return model\r\n\r\n    def _get_dataset_size(self):\r\n        dataset_length = [i for i, _ in enumerate(self.dataset)][-1] + 1\r\n        return dataset_length\r\n\r\n    def train(self, epochs):\r\n        callbacks = [\r\n            tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2),\r\n            # tf.keras.callbacks.ModelCheckpoint('./model.h5', save_best_only=True),\r\n            # tf.keras.callbacks.TensorBoard(log_dir='./logs', write_graph=True)\r\n        ]\r\n\r\n        self.model.fit(self.train_ds,\r\n                       epochs=epochs,\r\n                       steps_per_epoch=self.train_ds_size // self.batch_size,\r\n                       validation_data=self.validation_ds,\r\n                       validation_steps=self.validation_ds_size // self.batch_size,\r\n                       verbose=2,\r\n                       callbacks=callbacks)\r\ntrainer = Trainer(3)\r\ntrainer.train(epochs=2)\r\n```", "comments": ["@fredo838 \r\n\r\nCan you please try with latest TF 2.0 version  `!pip install tensorflow==2.0.0` . I am not seeing any error message with` tf.print(tf.where(y == 0)` with latest TF 2.0 version. Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/8b88e7ed4b5b54488df459fe05d667ed/untitled336.ipynb). Thanks!", "I got a `distribution not found`, that's why I wasn't on the latest version. After upgrading `pip`, installing `python3 -m pip install tensorflow==2.0.0`, Issue was resolved."]}, {"number": 34044, "title": "Patch @com_google_absl to always export //absl/time:time symbols", "body": "This should fix tensorflow/addons#663, caused by changing logic in Bazel on which symbols we export (see https://github.com/bazelbuild/bazel/issues/7362).", "comments": ["Rephrased the comment, PTAL.", "Hmmm seems there was a copybara error? Gentle bump to see if this can get through as it's breaking our  pin to nightly. ", "This is breaking internal builds\r\n\r\n```\r\nundefined reference to symbol 'clock_gettime@@GLIBC_2.2.5'\r\n```"]}, {"number": 34043, "title": "Unsupported numpy type: NPY_LONGLONG", "body": "**System information**\r\nLinux Mint 19\r\nDell XPS 7590 laptop\r\nPython 3.7.4 Anaconda\r\nTensorflow version: v2.0.0-rc2-26-g64c3d38 2.0.0 (pip tensorflow-gpu with GPU disabled)\r\nNumpy version: 1.17.3\r\n\r\n**Describe the current behavior**\r\nTensorflow 2.0 raises a ValueError if a Numpy array of type np.longlong is converted to a tf.Tensor.\r\n\r\n**Describe the expected behavior**\r\nA np.array(dtype=np.longlong) should automatically convert to tf.Tensor(dtype=np.int64), as was the case in Tensorflow 1.15.\r\n\r\n**Code to reproduce the issue**\r\n```python\r\n>>> import numpy as np\r\n>>> import tensorflow as tf\r\n>>> x = np.ones(10, dtype=np.longlong)\r\n>>> x_tf = tf.convert_to_tensor(x)\r\nTraceback (most recent call last):\r\n  File \"/home/wibble/.conda/envs/drum-model/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-24-31172ca6f870>\", line 1, in <module>\r\n    tf.constant(x)\r\n  File \"/home/wibble/.conda/envs/drum-model/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\", line 227, in constant\r\n    allow_broadcast=True)\r\n  File \"/home/wibble/.conda/envs/drum-model/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\", line 235, in _constant_impl\r\n    t = convert_to_eager_tensor(value, ctx, dtype)\r\n  File \"/home/wibble/.conda/envs/drum-model/lib/python3.7/site-packages/tensorflow_core/python/framework/constant_op.py\", line 96, in convert_to_eager_tensor\r\n    return ops.EagerTensor(value, ctx.device_name, dtype)\r\nValueError: Failed to convert a NumPy array to a Tensor (Unsupported numpy type: NPY_LONGLONG).\r\n```\r\n", "comments": ["@chrism0dwk, Thanks for reporting this issue.\r\nIssue is replicating on colab with Tf 2.0 and it is working as expected in Tf 1.15. \r\nPlease take a look at [gist](https://colab.sandbox.google.com/gist/gadagashwini/c645c20cf82e371fbfd71690808dc9b8/untitled242.ipynb). Thanks!\r\n", "I tried with tf-nightly (`tf-nightly-2.1.0.dev20191106`) and it looks to be fine. Think this issue has been resolved.", "Glad to know it's in the pipeline for the next release.  Thanks all.", "Closing this issue since its resolved with tf-nightly. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34043\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34043\">No</a>\n", "I am facing with this issue. What is the solution? Using tf-nighty?"]}, {"number": 34042, "title": "Error building 1.13", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version: 1.13\r\n- Python version: 2.7\r\n- Installed using virtualenv? pip? conda?: Pip\r\n- Bazel version (if compiling from source): 0.21\r\n- GCC/Compiler version (if compiling from source): 5.4.0\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: NVIDIA GeForce RTX 2080 TI (x2), 32GB RAM\r\n\r\n\r\n\r\n**Describe the problem**\r\nError when trying to build Tensor Flow 1.13\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nsudo bazel build --config=opt --config=cuda --incompatible_strict_action_env=false //tensorflow/tools/pip_package:build_pip_package\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n`ERROR: /home/issa/Downloads/tensorflow/tensorflow/BUILD:579:1: Executing genrule //tensorflow:tf_python_api_gen_v1 failed (Exit 1)\r\nTraceback (most recent call last):\r\n  File \"/home/issa/.cache/bazel/_bazel_root/ee4098cabb6d80cd53ff67b126befee0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py\", line 27, in <module>\r\n    from tensorflow.python.tools.api.generator import doc_srcs\r\n  File \"/home/issa/.cache/bazel/_bazel_root/ee4098cabb6d80cd53ff67b126befee0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/__init__.py\", line 63, in <module>\r\n    from tensorflow.python.framework.framework_lib import *  # pylint: disable=redefined-builtin\r\n  File \"/home/issa/.cache/bazel/_bazel_root/ee4098cabb6d80cd53ff67b126befee0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/framework/framework_lib.py\", line 52, in <module>\r\n    from tensorflow.python.framework.importer import import_graph_def\r\n  File \"/home/issa/.cache/bazel/_bazel_root/ee4098cabb6d80cd53ff67b126befee0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/framework/importer.py\", line 28, in <module>\r\n    from tensorflow.python.framework import function\r\n  File \"/home/issa/.cache/bazel/_bazel_root/ee4098cabb6d80cd53ff67b126befee0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/framework/function.py\", line 36, in <module>\r\n    from tensorflow.python.ops import resource_variable_ops\r\n  File \"/home/issa/.cache/bazel/_bazel_root/ee4098cabb6d80cd53ff67b126befee0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/ops/resource_variable_ops.py\", line 39, in <module>\r\n    from tensorflow.python.ops import variables\r\n  File \"/home/issa/.cache/bazel/_bazel_root/ee4098cabb6d80cd53ff67b126befee0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/ops/variables.py\", line 133, in <module>\r\n    \"* `ONLY_FIRST_TOWER`: Deprecated alias for `ONLY_FIRST_REPLICA`.\\n  \")\r\nAttributeError: attribute '__doc__' of 'type' objects is not writable\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 2121.083s, Critical Path: 421.25s\r\nINFO: 10541 processes: 10541 local.\r\nFAILED: Build did NOT complete successfully\r\n`\r\n", "comments": ["@issanospam ,\r\n Please take a look at the Tensorflow [tested build configuration](https://www.tensorflow.org/install/source#tested_build_configurations).Tensorflow 1.13.0 supports GCC 4.8. Thanks!", "Got a similar error when building Tensorflow 1.14 with GCC 4.8. Everything else seems to match the tested build configuration.\r\n\r\n`ERROR: /home/issa/Downloads/tensorflow/tensorflow/BUILD:745:1: Executing genrule //tensorflow:tf_python_api_gen_v1 failed (Exit 1)\r\nTraceback (most recent call last):\r\n  File \"/home/issa/.cache/bazel/_bazel_root/ee4098cabb6d80cd53ff67b126befee0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py\", line 27, in <module>\r\n    from tensorflow.python.tools.api.generator import doc_srcs\r\n  File \"/home/issa/.cache/bazel/_bazel_root/ee4098cabb6d80cd53ff67b126befee0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/__init__.py\", line 63, in <module>\r\n    from tensorflow.python.framework.framework_lib import *  # pylint: disable=redefined-builtin\r\n  File \"/home/issa/.cache/bazel/_bazel_root/ee4098cabb6d80cd53ff67b126befee0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/framework/framework_lib.py\", line 52, in <module>\r\n    from tensorflow.python.framework.importer import import_graph_def\r\n  File \"/home/issa/.cache/bazel/_bazel_root/ee4098cabb6d80cd53ff67b126befee0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/framework/importer.py\", line 28, in <module>\r\n    from tensorflow.python.framework import function\r\n  File \"/home/issa/.cache/bazel/_bazel_root/ee4098cabb6d80cd53ff67b126befee0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/framework/function.py\", line 37, in <module>\r\n    from tensorflow.python.ops import resource_variable_ops\r\n  File \"/home/issa/.cache/bazel/_bazel_root/ee4098cabb6d80cd53ff67b126befee0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/ops/resource_variable_ops.py\", line 41, in <module>\r\n    from tensorflow.python.ops import variables\r\n  File \"/home/issa/.cache/bazel/_bazel_root/ee4098cabb6d80cd53ff67b126befee0/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/ops/variables.py\", line 137, in <module>\r\n    \"* `ONLY_FIRST_TOWER`: Deprecated alias for `ONLY_FIRST_REPLICA`.\\n  \")\r\nAttributeError: attribute '__doc__' of 'type' objects is not writable\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 4661.374s, Critical Path: 341.79s\r\nINFO: 17053 processes: 17053 local.\r\nFAILED: Build did NOT complete successfully`", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34042\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34042\">No</a>\n"]}, {"number": 34041, "title": "Training with TPU model.fit error, while GPU works well", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):No\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):Using Colab\r\n- TensorFlow version (use command below):v2.0.0-rc2-26-g64c3d38\r\n- Python version:3.6\r\n- Bazel version (if compiling from source):N/A\r\n- GCC/Compiler version (if compiling from source):N/A\r\n- CUDA/cuDNN version:N/A\r\n- GPU model and memory:TPU\r\n\r\n**Describe the current behavior**\r\nDoing a transfer learning with InceptionV3 model on a medium-sized dataset (tfds, CatsVsDogs).\r\nFor the same code, when training with GPU, the code runs smoothly.\r\nSwitching to TPU produces this (And often other various) errors\r\n\r\n```\r\nInternalError: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:worker/replica:0/task:0/device:CPU:0 in order to run DatasetCardinality: Unable to parse tensor proto\r\nAdditional GRPC error information:\r\n{\"created\":\"@1573042445.409490969\",\"description\":\"Error received from peer\",\"file\":\"external/grpc/src/core/lib/surface/call.cc\",\"file_line\":1039,\"grpc_message\":\"Unable to parse tensor proto\",\"grpc_status\":3} [Op:DatasetCardinality]\r\n```\r\n\r\n**Describe the expected behavior**\r\nTPU training should run similarly to GPU training (without errors in this case)\r\n\r\n**Code to reproduce the issue**\r\nPlease find the Colab gist to reproduce the issue [\"https://gist.github.com/MikeOfZen/abadf58b9c68acd1b33c6e39af7b3f7a.js\"](url)\r\n\r\n**Other info / logs**\r\n*The issue occurs in both TF 1.15 and 2.0 versions.\r\nAttempting to use .take() to provide cardinality to the dataset didn't help (I've used it successfully to solve a similar issue before)\r\n\r\nOverall, I've gotten a number of various odd errors when trying to do TPU training.\r\nSpecifically, if caching for this dataset is enabled (should be ~25Gb) all sorts of wild errors pop up from the TPU side, probably due to OOM or buffer overflows.\r\n", "comments": ["@MikeOfZen \r\n\r\nThanks for reporting the issue.\r\nCan you please provide us the correct Colab gist link to reproduce the issue.Thanks!", "Sorry, took the wrong link format.\r\nhttps://gist.github.com/MikeOfZen/abadf58b9c68acd1b33c6e39af7b3f7a", "Hi @MikeOfZen, sorry for the very late response here but if you're still facing an issue please update the thread with a reproducible colab notebook since I cannot access the bucket. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34041\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34041\">No</a>\n"]}, {"number": 34040, "title": "tf.keras.model_to_estimator() fails with custom loss/custom metrics", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 10.14.4 \r\n- TensorFlow installed from (source or binary): binary\r\n```\r\nnumpy                              1.17.2     \r\nnumpydoc                           0.9.1      \r\nprotobuf                           3.9.2      \r\ntensorflow                         2.0.0      \r\ntensorflow-addons                  0.6.0      \r\ntensorflow-estimator               2.0.0      \r\ntensorflow-serving-api             2.0.0    \r\npython                             3.7.4\r\n```\r\n**Describe the current behavior**\r\nI am using a custom loss function that requires extra input (the number of words in the sentence). When compiling the model, the InputLayer used in the custom loss function does not get transferred into the new graph. Since the function is stateful, I receive the following error:\r\n```Traceback (most recent call last):\r\n  File \"/src/automated-document-processing/nlp-tfx/bugreport.py\", line 93, in <module>\r\n    estimator = tf.keras.estimator.model_to_estimator(keras_model=model, model_dir=params[\"eval_dir\"])\r\n  File \"/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/estimator/__init__.py\", line 166, in model_to_estimator_v2\r\n    use_v2_estimator=True)\r\n  File \"/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/keras.py\", line 576, in model_to_estimator\r\n    config, save_object_ckpt)\r\n  File \"/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/keras.py\", line 381, in _save_first_checkpoint\r\n    custom_objects)\r\n  File \"/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/keras.py\", line 227, in _clone_and_build_model\r\n    optimizer_config=optimizer_config)\r\n  File \"/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/models.py\", line 679, in clone_and_build_model\r\n    target_tensors=target_tensors)\r\n  File \"/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 373, in compile\r\n    self._compile_weights_loss_and_weighted_metrics()\r\n  File \"/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 1653, in _compile_weights_loss_and_weighted_metrics\r\n    self.total_loss = self._prepare_total_loss(masks)\r\n  File \"/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 1713, in _prepare_total_loss\r\n    per_sample_losses = loss_fn.call(y_true, y_pred)\r\n  File \"/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/losses.py\", line 221, in call\r\n    return self.fn(y_true, y_pred, **self._fn_kwargs)\r\n  File \"/src/automated-document-processing/nlp-tfx/bugreport.py\", line 80, in CRFLoss\r\n    transition_params=transition_params,\r\n  File \"/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_addons/text/crf.py\", line 196, in crf_log_likelihood\r\n    transition_params)\r\n  File \"/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_addons/text/crf.py\", line 68, in crf_sequence_score\r\n    return _multi_seq_fn()\r\n  File \"/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_addons/text/crf.py\", line 59, in _multi_seq_fn\r\n    unary_scores = crf_unary_score(tag_indices, sequence_lengths, inputs)\r\n  File \"/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_addons/text/crf.py\", line 232, in crf_unary_score\r\n    sequence_lengths, maxlen=tf.shape(tag_indices)[1], dtype=tf.float32)\r\n  File \"/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\", line 3568, in sequence_mask\r\n    with ops.name_scope(name, \"SequenceMask\", [lengths, maxlen]):\r\n  File \"/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 6337, in __enter__\r\n    g_from_inputs = _get_graph_from_inputs(self._values)\r\n  File \"/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 5982, in _get_graph_from_inputs\r\n    _assert_same_graph(original_graph_element, graph_element)\r\n  File \"/src/.anaconda/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 5917, in _assert_same_graph\r\n    (item, original_item))\r\nValueError: Tensor(\"loss/myscores_loss/strided_slice_3:0\", shape=(), dtype=int32) must be from the same graph as Tensor(\"nwords:0\", shape=(None,), dtype=int32).\r\n```\r\n\r\n**Describe the expected behavior**\r\nAllow custom stateful loss/metrics functions in `model_to_estimator` or update the documentation that it is not supported. \r\n\r\n**Code to reproduce the issue**\r\n```from typing import Any, Dict\r\n\r\nimport tensorflow as tf\r\n\r\n\r\nfrom typing import Text, Tuple, List, Dict, Any, Union\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport tensorflow_addons as tfa\r\nfrom tensorflow.python.ops import math_ops\r\n\r\n\r\ndef _split_iob_tag(tag: Text) -> Tuple[Text, Union[Text, None]]:\r\n    \"\"\"Handle tags <pad>, <unk>, O, B-foo, and I-foo.\"\"\"\r\n    if tag[:2] not in [\"B-\", \"I-\"]:\r\n        return (tag, None)\r\n    return tuple(tag.split(\"-\", maxsplit=2))  # type: ignore\r\n\r\n\r\ndef iob_transition_params(tags: List[Text]) -> tf.constant:\r\n    \"\"\"Return transition matrix suitable for tf.contrib.crf.crf_decode.\"\"\"\r\n    mat = np.zeros((len(tags), len(tags)))\r\n    for i, i_tag in enumerate(tags):\r\n        i_type, i_name = _split_iob_tag(i_tag)\r\n        for j, j_tag in enumerate(tags):\r\n            j_type, j_name = _split_iob_tag(j_tag)\r\n            if (i_type == \"O\" and j_type == \"I\") or (\r\n                i_type in [\"B\", \"I\"] and j_type == \"I\" and i_name != j_name\r\n            ):\r\n                mat[i][j] = -np.inf\r\n    return tf.constant(mat, dtype=tf.float32)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    params: Dict[str, Any] = {\r\n        \"dim\": 300,\r\n        \"dropout\": 0.5,\r\n        \"batch_size\": 3,\r\n        \"buffer\": 15000,\r\n        \"lstm_size\": 10,\r\n        \"eval_dir\": \"../results/\",\r\n        \"saved_model_dir\": \"../final_model/\",\r\n        \"training_data\": \"some_data\",\r\n        \"window_length\": 512,\r\n        \"embedding_dimension\": 300,\r\n    }\r\n\r\n    tags = {'I-tag1', 'B-tag1','I-tag2', 'B-tag2','I-tag3', 'B-tag3', 'O'}\r\n\r\n    dropout = params[\"dropout\"]\r\n\r\n    embeddings = tf.keras.Input(\r\n        shape=(params[\"window_length\"], params[\"embedding_dimension\"],),\r\n        dtype=tf.float32,\r\n        name=\"embedding_sequence\",\r\n    )\r\n    nwords = tf.keras.Input(shape=(), dtype=tf.int32, name=\"nwords\",)\r\n    lstm_cell_fw = tf.keras.layers.LSTM(params[\"lstm_size\"], return_sequences=True)(\r\n        embeddings\r\n    )\r\n    output = tf.keras.layers.Dropout(rate=dropout)(lstm_cell_fw)\r\n    logits = tf.keras.layers.Dense(len(tags), name=\"myscores\")(output)\r\n\r\n    # CRF\r\n    transition_params = iob_transition_params(tags)\r\n\r\n    def custom_loss(seqlen):\r\n        def CRFLoss(y_true, y_pred):\r\n            y_true = math_ops.cast(y_true, tf.int32)\r\n            y_true = tf.reshape(y_true, [-1, 512])\r\n\r\n            log_likelihood, _ = tfa.text.crf.crf_log_likelihood(\r\n                inputs=y_pred,\r\n                tag_indices=y_true,\r\n                sequence_lengths=seqlen,\r\n                transition_params=transition_params,\r\n            )\r\n\r\n            return tf.reduce_mean(-log_likelihood)\r\n\r\n        return CRFLoss\r\n\r\n    model = tf.keras.Model(\r\n        inputs=[embeddings, nwords], outputs=logits, name=\"ner_simple\"\r\n    )\r\n\r\n    model.compile(optimizer=\"adam\", loss=custom_loss(nwords), metrics=[\"accuracy\"])\r\n    estimator = tf.keras.estimator.model_to_estimator(keras_model=model, model_dir=params[\"eval_dir\"])\r\n```\r\n**Other info / logs**\r\nRelated to https://github.com/netrack/keras-metrics/issues/39\r\n", "comments": ["I could reproduce the issue with Tf 2.0.\r\nPTAL at colab [gist](https://colab.sandbox.google.com/gist/gadagashwini/d1bd904336b76d7beb9683f44a57a8e8/untitled241.ipynb). Thanks!", "I have tried in colab with TF version 2.2, nightly version(`2.3.0-dev20200612`) and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/4c408e7c7c0993b6428102ba38aaa7f4/untitled16.ipynb).Thanks!", "Was able to reproduce the issue in TF v2.5 ,please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/97544465634cfabf0be32f1f64f0407a/untitled27.ipynb)..Thanks !", "Was able to replicate the issue with TF 2.6.0-dev20210606,please find the gist[ here](https://colab.research.google.com/gist/sushreebarsa/7c149d327fff5d7266c62ad38566de72/untitled243.ipynb) ..Thanks !", "I'm getting different error while reproducing your issue [here](https://colab.research.google.com/gist/sachinprasadhs/2cb8a59daa3d23e16e7456803ed3b736/untitled243.ipynb), could you please check and update the code. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34040\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34040\">No</a>\n"]}, {"number": 34039, "title": "tf.data.Dataset fixed size batching with subsequent map() under tf.distribute.MirroredStrategy leads to a crash", "body": "**System information**\r\nThe same environment as in https://github.com/tensorflow/tensorflow/issues/33531\r\n\r\n**Code to reproduce the issue**\r\n\r\nIt took me a few **weeks** of debugging to reproduce! **IMPORTANT: I DO NOT THINK IT WILL REPRODUCE IN COLAB, YOU NEED AT LEAST 2 GPUS.**\r\n\r\n```python\r\n#!/usr/bin/env python3\r\nimport sys\r\nimport tensorflow as tf\r\n\r\ndef main():\r\n    strategy = tf.distribute.MirroredStrategy()\r\n    batch_size = 12\r\n    features_shape = 372, 558, 3\r\n    labels = 10\r\n    sample = tf.random.uniform(features_shape)\r\n\r\n    def batch_print(b, l):\r\n        tf.print(\"shape\", b.shape, tf.shape(b))\r\n        tf.print(b[10])  # <<< crash here\r\n        return b, l\r\n\r\n    ds_train = tf.data.Dataset.from_tensors([sample]).map(lambda s: (tf.squeeze(s), tf.ones((labels,)))) \\\r\n        .repeat().batch(batch_size, drop_remainder=True).map(batch_print)\r\n    ds_val = tf.data.Dataset.from_tensors([sample]).map(lambda s: (tf.squeeze(s), tf.ones((labels,)))) \\\r\n        .repeat().batch(batch_size, drop_remainder=True).take(10)\r\n\r\n    import tensorflow_core.python.keras.backend\r\n    original_input = tensorflow_core.python.keras.layers.Input\r\n\r\n    def create_input(*args, **kwargs):\r\n        return original_input(*args, batch_size=batch_size, **kwargs)\r\n\r\n    # monkey-patch the input layer to ensure the fixed tensor shape\r\n    tensorflow_core.python.keras.layers.Input = create_input\r\n\r\n    with strategy.scope():\r\n        model = tf.keras.applications.DenseNet121(\r\n            weights=None, input_shape=features_shape, classes=labels)\r\n        model.build((batch_size,) + features_shape)\r\n        model.summary()\r\n        optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\r\n        cross_entropy = tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1)\r\n        model.compile(optimizer=optimizer, loss=cross_entropy, metrics=[\"accuracy\"])\r\n    model.fit(ds_train, validation_data=ds_val, epochs=1, steps_per_epoch=100)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    sys.exit(main())\r\n```\r\n\r\nAs you see, I am feeding a `tf.data.Dataset` pipeline to a Keras model under `tf.distribute.MirroredStrategy`. In my case, there are 4 GPUs. Here is the log which indicates a crash:\r\n\r\n<details>\r\n<summary>Full log</summary>\r\n<pre>\r\n2019-11-06 11:09:37.077575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1, 2, 3\r\n2019-11-06 11:09:37.077858: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutorwith strength 1 edge matrix:\r\n2019-11-06 11:09:37.077880: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1 2 3\r\n2019-11-06 11:09:37.077894: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y N N\r\n2019-11-06 11:09:37.077904: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N N N\r\n2019-11-06 11:09:37.077914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 2:   N N N Y\r\n2019-11-06 11:09:37.077923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 3:   N N Y N\r\n2019-11-06 11:09:37.084775: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:0 with 10470 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)\r\n2019-11-06 11:09:37.086075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:1 with 10470 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:03:00.0, compute capability: 6.1)\r\n2019-11-06 11:09:37.087140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:2 with 10470 MB memory) -> physical GPU (device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:82:00.0, compute capability: 6.1)\r\n2019-11-06 11:09:37.088126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/device:GPU:3 with 10470 MB memory) -> physical GPU (device: 3, name: GeForce GTX 1080 Ti, pci bus id: 0000:83:00.0, compute capability: 6.1)\r\nModel: \"densenet121\"\r\n__________________________________________________________________________________________________\r\nLayer (type)                    Output Shape         Param #     Connected to\r\n==================================================================================================\r\ninput_1 (InputLayer)            [(3, 372, 558, 3)]   0\r\n__________________________________________________________________________________________________\r\nzero_padding2d (ZeroPadding2D)  (3, 378, 564, 3)     0           input_1[0][0]\r\n__________________________________________________________________________________________________\r\nconv1/conv (Conv2D)             (3, 186, 279, 64)    9408        zero_padding2d[0][0]\r\n__________________________________________________________________________________________________\r\nconv1/bn (BatchNormalization)   (3, 186, 279, 64)    256         conv1/conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv1/relu (Activation)         (3, 186, 279, 64)    0           conv1/bn[0][0]\r\n__________________________________________________________________________________________________\r\nzero_padding2d_1 (ZeroPadding2D (3, 188, 281, 64)    0           conv1/relu[0][0]\r\n__________________________________________________________________________________________________\r\npool1 (MaxPooling2D)            (3, 93, 140, 64)     0           zero_padding2d_1[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block1_0_bn (BatchNormali (3, 93, 140, 64)     256         pool1[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block1_0_relu (Activation (3, 93, 140, 64)     0           conv2_block1_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block1_1_conv (Conv2D)    (3, 93, 140, 128)    8192        conv2_block1_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block1_1_bn (BatchNormali (3, 93, 140, 128)    512         conv2_block1_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block1_1_relu (Activation (3, 93, 140, 128)    0           conv2_block1_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block1_2_conv (Conv2D)    (3, 93, 140, 32)     36864       conv2_block1_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block1_concat (Concatenat (3, 93, 140, 96)     0           pool1[0][0]\r\n                                                                 conv2_block1_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block2_0_bn (BatchNormali (3, 93, 140, 96)     384         conv2_block1_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block2_0_relu (Activation (3, 93, 140, 96)     0           conv2_block2_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block2_1_conv (Conv2D)    (3, 93, 140, 128)    12288       conv2_block2_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block2_1_bn (BatchNormali (3, 93, 140, 128)    512         conv2_block2_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block2_1_relu (Activation (3, 93, 140, 128)    0           conv2_block2_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block2_2_conv (Conv2D)    (3, 93, 140, 32)     36864       conv2_block2_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block2_concat (Concatenat (3, 93, 140, 128)    0           conv2_block1_concat[0][0]\r\n                                                                 conv2_block2_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block3_0_bn (BatchNormali (3, 93, 140, 128)    512         conv2_block2_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block3_0_relu (Activation (3, 93, 140, 128)    0           conv2_block3_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block3_1_conv (Conv2D)    (3, 93, 140, 128)    16384       conv2_block3_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block3_1_bn (BatchNormali (3, 93, 140, 128)    512         conv2_block3_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block3_1_relu (Activation (3, 93, 140, 128)    0           conv2_block3_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block3_2_conv (Conv2D)    (3, 93, 140, 32)     36864       conv2_block3_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block3_concat (Concatenat (3, 93, 140, 160)    0           conv2_block2_concat[0][0]\r\n                                                                 conv2_block3_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block4_0_bn (BatchNormali (3, 93, 140, 160)    640         conv2_block3_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block4_0_relu (Activation (3, 93, 140, 160)    0           conv2_block4_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block4_1_conv (Conv2D)    (3, 93, 140, 128)    20480       conv2_block4_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block4_1_bn (BatchNormali (3, 93, 140, 128)    512         conv2_block4_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block4_1_relu (Activation (3, 93, 140, 128)    0           conv2_block4_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block4_2_conv (Conv2D)    (3, 93, 140, 32)     36864       conv2_block4_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block4_concat (Concatenat (3, 93, 140, 192)    0           conv2_block3_concat[0][0]\r\n                                                                 conv2_block4_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block5_0_bn (BatchNormali (3, 93, 140, 192)    768         conv2_block4_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block5_0_relu (Activation (3, 93, 140, 192)    0           conv2_block5_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block5_1_conv (Conv2D)    (3, 93, 140, 128)    24576       conv2_block5_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block5_1_bn (BatchNormali (3, 93, 140, 128)    512         conv2_block5_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block5_1_relu (Activation (3, 93, 140, 128)    0           conv2_block5_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block5_2_conv (Conv2D)    (3, 93, 140, 32)     36864       conv2_block5_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block5_concat (Concatenat (3, 93, 140, 224)    0           conv2_block4_concat[0][0]\r\n                                                                 conv2_block5_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block6_0_bn (BatchNormali (3, 93, 140, 224)    896         conv2_block5_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block6_0_relu (Activation (3, 93, 140, 224)    0           conv2_block6_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block6_1_conv (Conv2D)    (3, 93, 140, 128)    28672       conv2_block6_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block6_1_bn (BatchNormali (3, 93, 140, 128)    512         conv2_block6_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block6_1_relu (Activation (3, 93, 140, 128)    0           conv2_block6_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block6_2_conv (Conv2D)    (3, 93, 140, 32)     36864       conv2_block6_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv2_block6_concat (Concatenat (3, 93, 140, 256)    0           conv2_block5_concat[0][0]\r\n                                                                 conv2_block6_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\npool2_bn (BatchNormalization)   (3, 93, 140, 256)    1024        conv2_block6_concat[0][0]\r\n__________________________________________________________________________________________________\r\npool2_relu (Activation)         (3, 93, 140, 256)    0           pool2_bn[0][0]\r\n__________________________________________________________________________________________________\r\npool2_conv (Conv2D)             (3, 93, 140, 128)    32768       pool2_relu[0][0]\r\n__________________________________________________________________________________________________\r\npool2_pool (AveragePooling2D)   (3, 46, 70, 128)     0           pool2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block1_0_bn (BatchNormali (3, 46, 70, 128)     512         pool2_pool[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block1_0_relu (Activation (3, 46, 70, 128)     0           conv3_block1_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block1_1_conv (Conv2D)    (3, 46, 70, 128)     16384       conv3_block1_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block1_1_bn (BatchNormali (3, 46, 70, 128)     512         conv3_block1_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block1_1_relu (Activation (3, 46, 70, 128)     0           conv3_block1_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block1_2_conv (Conv2D)    (3, 46, 70, 32)      36864       conv3_block1_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block1_concat (Concatenat (3, 46, 70, 160)     0           pool2_pool[0][0]\r\n                                                                 conv3_block1_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block2_0_bn (BatchNormali (3, 46, 70, 160)     640         conv3_block1_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block2_0_relu (Activation (3, 46, 70, 160)     0           conv3_block2_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block2_1_conv (Conv2D)    (3, 46, 70, 128)     20480       conv3_block2_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block2_1_bn (BatchNormali (3, 46, 70, 128)     512         conv3_block2_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block2_1_relu (Activation (3, 46, 70, 128)     0           conv3_block2_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block2_2_conv (Conv2D)    (3, 46, 70, 32)      36864       conv3_block2_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block2_concat (Concatenat (3, 46, 70, 192)     0           conv3_block1_concat[0][0]\r\n                                                                 conv3_block2_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block3_0_bn (BatchNormali (3, 46, 70, 192)     768         conv3_block2_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block3_0_relu (Activation (3, 46, 70, 192)     0           conv3_block3_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block3_1_conv (Conv2D)    (3, 46, 70, 128)     24576       conv3_block3_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block3_1_bn (BatchNormali (3, 46, 70, 128)     512         conv3_block3_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block3_1_relu (Activation (3, 46, 70, 128)     0           conv3_block3_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block3_2_conv (Conv2D)    (3, 46, 70, 32)      36864       conv3_block3_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block3_concat (Concatenat (3, 46, 70, 224)     0           conv3_block2_concat[0][0]\r\n                                                                 conv3_block3_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block4_0_bn (BatchNormali (3, 46, 70, 224)     896         conv3_block3_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block4_0_relu (Activation (3, 46, 70, 224)     0           conv3_block4_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block4_1_conv (Conv2D)    (3, 46, 70, 128)     28672       conv3_block4_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block4_1_bn (BatchNormali (3, 46, 70, 128)     512         conv3_block4_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block4_1_relu (Activation (3, 46, 70, 128)     0           conv3_block4_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block4_2_conv (Conv2D)    (3, 46, 70, 32)      36864       conv3_block4_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block4_concat (Concatenat (3, 46, 70, 256)     0           conv3_block3_concat[0][0]\r\n                                                                 conv3_block4_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block5_0_bn (BatchNormali (3, 46, 70, 256)     1024        conv3_block4_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block5_0_relu (Activation (3, 46, 70, 256)     0           conv3_block5_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block5_1_conv (Conv2D)    (3, 46, 70, 128)     32768       conv3_block5_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block5_1_bn (BatchNormali (3, 46, 70, 128)     512         conv3_block5_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block5_1_relu (Activation (3, 46, 70, 128)     0           conv3_block5_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block5_2_conv (Conv2D)    (3, 46, 70, 32)      36864       conv3_block5_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block5_concat (Concatenat (3, 46, 70, 288)     0           conv3_block4_concat[0][0]\r\n                                                                 conv3_block5_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block6_0_bn (BatchNormali (3, 46, 70, 288)     1152        conv3_block5_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block6_0_relu (Activation (3, 46, 70, 288)     0           conv3_block6_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block6_1_conv (Conv2D)    (3, 46, 70, 128)     36864       conv3_block6_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block6_1_bn (BatchNormali (3, 46, 70, 128)     512         conv3_block6_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block6_1_relu (Activation (3, 46, 70, 128)     0           conv3_block6_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block6_2_conv (Conv2D)    (3, 46, 70, 32)      36864       conv3_block6_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block6_concat (Concatenat (3, 46, 70, 320)     0           conv3_block5_concat[0][0]\r\n                                                                 conv3_block6_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block7_0_bn (BatchNormali (3, 46, 70, 320)     1280        conv3_block6_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block7_0_relu (Activation (3, 46, 70, 320)     0           conv3_block7_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block7_1_conv (Conv2D)    (3, 46, 70, 128)     40960       conv3_block7_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block7_1_bn (BatchNormali (3, 46, 70, 128)     512         conv3_block7_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block7_1_relu (Activation (3, 46, 70, 128)     0           conv3_block7_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block7_2_conv (Conv2D)    (3, 46, 70, 32)      36864       conv3_block7_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block7_concat (Concatenat (3, 46, 70, 352)     0           conv3_block6_concat[0][0]\r\n                                                                 conv3_block7_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block8_0_bn (BatchNormali (3, 46, 70, 352)     1408        conv3_block7_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block8_0_relu (Activation (3, 46, 70, 352)     0           conv3_block8_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block8_1_conv (Conv2D)    (3, 46, 70, 128)     45056       conv3_block8_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block8_1_bn (BatchNormali (3, 46, 70, 128)     512         conv3_block8_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block8_1_relu (Activation (3, 46, 70, 128)     0           conv3_block8_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block8_2_conv (Conv2D)    (3, 46, 70, 32)      36864       conv3_block8_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block8_concat (Concatenat (3, 46, 70, 384)     0           conv3_block7_concat[0][0]\r\n                                                                 conv3_block8_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block9_0_bn (BatchNormali (3, 46, 70, 384)     1536        conv3_block8_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block9_0_relu (Activation (3, 46, 70, 384)     0           conv3_block9_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block9_1_conv (Conv2D)    (3, 46, 70, 128)     49152       conv3_block9_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block9_1_bn (BatchNormali (3, 46, 70, 128)     512         conv3_block9_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block9_1_relu (Activation (3, 46, 70, 128)     0           conv3_block9_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block9_2_conv (Conv2D)    (3, 46, 70, 32)      36864       conv3_block9_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block9_concat (Concatenat (3, 46, 70, 416)     0           conv3_block8_concat[0][0]\r\n                                                                 conv3_block9_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block10_0_bn (BatchNormal (3, 46, 70, 416)     1664        conv3_block9_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block10_0_relu (Activatio (3, 46, 70, 416)     0           conv3_block10_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block10_1_conv (Conv2D)   (3, 46, 70, 128)     53248       conv3_block10_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block10_1_bn (BatchNormal (3, 46, 70, 128)     512         conv3_block10_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block10_1_relu (Activatio (3, 46, 70, 128)     0           conv3_block10_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block10_2_conv (Conv2D)   (3, 46, 70, 32)      36864       conv3_block10_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block10_concat (Concatena (3, 46, 70, 448)     0           conv3_block9_concat[0][0]\r\n                                                                 conv3_block10_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block11_0_bn (BatchNormal (3, 46, 70, 448)     1792        conv3_block10_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block11_0_relu (Activatio (3, 46, 70, 448)     0           conv3_block11_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block11_1_conv (Conv2D)   (3, 46, 70, 128)     57344       conv3_block11_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block11_1_bn (BatchNormal (3, 46, 70, 128)     512         conv3_block11_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block11_1_relu (Activatio (3, 46, 70, 128)     0           conv3_block11_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block11_2_conv (Conv2D)   (3, 46, 70, 32)      36864       conv3_block11_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block11_concat (Concatena (3, 46, 70, 480)     0           conv3_block10_concat[0][0]\r\n                                                                 conv3_block11_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block12_0_bn (BatchNormal (3, 46, 70, 480)     1920        conv3_block11_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block12_0_relu (Activatio (3, 46, 70, 480)     0           conv3_block12_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block12_1_conv (Conv2D)   (3, 46, 70, 128)     61440       conv3_block12_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block12_1_bn (BatchNormal (3, 46, 70, 128)     512         conv3_block12_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block12_1_relu (Activatio (3, 46, 70, 128)     0           conv3_block12_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block12_2_conv (Conv2D)   (3, 46, 70, 32)      36864       conv3_block12_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv3_block12_concat (Concatena (3, 46, 70, 512)     0           conv3_block11_concat[0][0]\r\n                                                                 conv3_block12_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\npool3_bn (BatchNormalization)   (3, 46, 70, 512)     2048        conv3_block12_concat[0][0]\r\n__________________________________________________________________________________________________\r\npool3_relu (Activation)         (3, 46, 70, 512)     0           pool3_bn[0][0]\r\n__________________________________________________________________________________________________\r\npool3_conv (Conv2D)             (3, 46, 70, 256)     131072      pool3_relu[0][0]\r\n__________________________________________________________________________________________________\r\npool3_pool (AveragePooling2D)   (3, 23, 35, 256)     0           pool3_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block1_0_bn (BatchNormali (3, 23, 35, 256)     1024        pool3_pool[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block1_0_relu (Activation (3, 23, 35, 256)     0           conv4_block1_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block1_1_conv (Conv2D)    (3, 23, 35, 128)     32768       conv4_block1_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block1_1_bn (BatchNormali (3, 23, 35, 128)     512         conv4_block1_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block1_1_relu (Activation (3, 23, 35, 128)     0           conv4_block1_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block1_2_conv (Conv2D)    (3, 23, 35, 32)      36864       conv4_block1_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block1_concat (Concatenat (3, 23, 35, 288)     0           pool3_pool[0][0]\r\n                                                                 conv4_block1_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block2_0_bn (BatchNormali (3, 23, 35, 288)     1152        conv4_block1_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block2_0_relu (Activation (3, 23, 35, 288)     0           conv4_block2_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block2_1_conv (Conv2D)    (3, 23, 35, 128)     36864       conv4_block2_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block2_1_bn (BatchNormali (3, 23, 35, 128)     512         conv4_block2_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block2_1_relu (Activation (3, 23, 35, 128)     0           conv4_block2_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block2_2_conv (Conv2D)    (3, 23, 35, 32)      36864       conv4_block2_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block2_concat (Concatenat (3, 23, 35, 320)     0           conv4_block1_concat[0][0]\r\n                                                                 conv4_block2_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block3_0_bn (BatchNormali (3, 23, 35, 320)     1280        conv4_block2_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block3_0_relu (Activation (3, 23, 35, 320)     0           conv4_block3_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block3_1_conv (Conv2D)    (3, 23, 35, 128)     40960       conv4_block3_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block3_1_bn (BatchNormali (3, 23, 35, 128)     512         conv4_block3_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block3_1_relu (Activation (3, 23, 35, 128)     0           conv4_block3_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block3_2_conv (Conv2D)    (3, 23, 35, 32)      36864       conv4_block3_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block3_concat (Concatenat (3, 23, 35, 352)     0           conv4_block2_concat[0][0]\r\n                                                                 conv4_block3_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block4_0_bn (BatchNormali (3, 23, 35, 352)     1408        conv4_block3_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block4_0_relu (Activation (3, 23, 35, 352)     0           conv4_block4_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block4_1_conv (Conv2D)    (3, 23, 35, 128)     45056       conv4_block4_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block4_1_bn (BatchNormali (3, 23, 35, 128)     512         conv4_block4_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block4_1_relu (Activation (3, 23, 35, 128)     0           conv4_block4_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block4_2_conv (Conv2D)    (3, 23, 35, 32)      36864       conv4_block4_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block4_concat (Concatenat (3, 23, 35, 384)     0           conv4_block3_concat[0][0]\r\n                                                                 conv4_block4_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block5_0_bn (BatchNormali (3, 23, 35, 384)     1536        conv4_block4_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block5_0_relu (Activation (3, 23, 35, 384)     0           conv4_block5_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block5_1_conv (Conv2D)    (3, 23, 35, 128)     49152       conv4_block5_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block5_1_bn (BatchNormali (3, 23, 35, 128)     512         conv4_block5_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block5_1_relu (Activation (3, 23, 35, 128)     0           conv4_block5_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block5_2_conv (Conv2D)    (3, 23, 35, 32)      36864       conv4_block5_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block5_concat (Concatenat (3, 23, 35, 416)     0           conv4_block4_concat[0][0]\r\n                                                                 conv4_block5_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block6_0_bn (BatchNormali (3, 23, 35, 416)     1664        conv4_block5_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block6_0_relu (Activation (3, 23, 35, 416)     0           conv4_block6_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block6_1_conv (Conv2D)    (3, 23, 35, 128)     53248       conv4_block6_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block6_1_bn (BatchNormali (3, 23, 35, 128)     512         conv4_block6_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block6_1_relu (Activation (3, 23, 35, 128)     0           conv4_block6_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block6_2_conv (Conv2D)    (3, 23, 35, 32)      36864       conv4_block6_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block6_concat (Concatenat (3, 23, 35, 448)     0           conv4_block5_concat[0][0]\r\n                                                                 conv4_block6_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block7_0_bn (BatchNormali (3, 23, 35, 448)     1792        conv4_block6_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block7_0_relu (Activation (3, 23, 35, 448)     0           conv4_block7_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block7_1_conv (Conv2D)    (3, 23, 35, 128)     57344       conv4_block7_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block7_1_bn (BatchNormali (3, 23, 35, 128)     512         conv4_block7_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block7_1_relu (Activation (3, 23, 35, 128)     0           conv4_block7_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block7_2_conv (Conv2D)    (3, 23, 35, 32)      36864       conv4_block7_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block7_concat (Concatenat (3, 23, 35, 480)     0           conv4_block6_concat[0][0]\r\n                                                                 conv4_block7_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block8_0_bn (BatchNormali (3, 23, 35, 480)     1920        conv4_block7_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block8_0_relu (Activation (3, 23, 35, 480)     0           conv4_block8_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block8_1_conv (Conv2D)    (3, 23, 35, 128)     61440       conv4_block8_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block8_1_bn (BatchNormali (3, 23, 35, 128)     512         conv4_block8_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block8_1_relu (Activation (3, 23, 35, 128)     0           conv4_block8_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block8_2_conv (Conv2D)    (3, 23, 35, 32)      36864       conv4_block8_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block8_concat (Concatenat (3, 23, 35, 512)     0           conv4_block7_concat[0][0]\r\n                                                                 conv4_block8_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block9_0_bn (BatchNormali (3, 23, 35, 512)     2048        conv4_block8_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block9_0_relu (Activation (3, 23, 35, 512)     0           conv4_block9_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block9_1_conv (Conv2D)    (3, 23, 35, 128)     65536       conv4_block9_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block9_1_bn (BatchNormali (3, 23, 35, 128)     512         conv4_block9_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block9_1_relu (Activation (3, 23, 35, 128)     0           conv4_block9_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block9_2_conv (Conv2D)    (3, 23, 35, 32)      36864       conv4_block9_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block9_concat (Concatenat (3, 23, 35, 544)     0           conv4_block8_concat[0][0]\r\n                                                                 conv4_block9_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block10_0_bn (BatchNormal (3, 23, 35, 544)     2176        conv4_block9_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block10_0_relu (Activatio (3, 23, 35, 544)     0           conv4_block10_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block10_1_conv (Conv2D)   (3, 23, 35, 128)     69632       conv4_block10_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block10_1_bn (BatchNormal (3, 23, 35, 128)     512         conv4_block10_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block10_1_relu (Activatio (3, 23, 35, 128)     0           conv4_block10_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block10_2_conv (Conv2D)   (3, 23, 35, 32)      36864       conv4_block10_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block10_concat (Concatena (3, 23, 35, 576)     0           conv4_block9_concat[0][0]\r\n                                                                 conv4_block10_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block11_0_bn (BatchNormal (3, 23, 35, 576)     2304        conv4_block10_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block11_0_relu (Activatio (3, 23, 35, 576)     0           conv4_block11_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block11_1_conv (Conv2D)   (3, 23, 35, 128)     73728       conv4_block11_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block11_1_bn (BatchNormal (3, 23, 35, 128)     512         conv4_block11_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block11_1_relu (Activatio (3, 23, 35, 128)     0           conv4_block11_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block11_2_conv (Conv2D)   (3, 23, 35, 32)      36864       conv4_block11_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block11_concat (Concatena (3, 23, 35, 608)     0           conv4_block10_concat[0][0]\r\n                                                                 conv4_block11_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block12_0_bn (BatchNormal (3, 23, 35, 608)     2432        conv4_block11_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block12_0_relu (Activatio (3, 23, 35, 608)     0           conv4_block12_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block12_1_conv (Conv2D)   (3, 23, 35, 128)     77824       conv4_block12_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block12_1_bn (BatchNormal (3, 23, 35, 128)     512         conv4_block12_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block12_1_relu (Activatio (3, 23, 35, 128)     0           conv4_block12_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block12_2_conv (Conv2D)   (3, 23, 35, 32)      36864       conv4_block12_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block12_concat (Concatena (3, 23, 35, 640)     0           conv4_block11_concat[0][0]\r\n                                                                 conv4_block12_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block13_0_bn (BatchNormal (3, 23, 35, 640)     2560        conv4_block12_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block13_0_relu (Activatio (3, 23, 35, 640)     0           conv4_block13_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block13_1_conv (Conv2D)   (3, 23, 35, 128)     81920       conv4_block13_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block13_1_bn (BatchNormal (3, 23, 35, 128)     512         conv4_block13_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block13_1_relu (Activatio (3, 23, 35, 128)     0           conv4_block13_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block13_2_conv (Conv2D)   (3, 23, 35, 32)      36864       conv4_block13_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block13_concat (Concatena (3, 23, 35, 672)     0           conv4_block12_concat[0][0]\r\n                                                                 conv4_block13_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block14_0_bn (BatchNormal (3, 23, 35, 672)     2688        conv4_block13_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block14_0_relu (Activatio (3, 23, 35, 672)     0           conv4_block14_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block14_1_conv (Conv2D)   (3, 23, 35, 128)     86016       conv4_block14_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block14_1_bn (BatchNormal (3, 23, 35, 128)     512         conv4_block14_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block14_1_relu (Activatio (3, 23, 35, 128)     0           conv4_block14_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block14_2_conv (Conv2D)   (3, 23, 35, 32)      36864       conv4_block14_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block14_concat (Concatena (3, 23, 35, 704)     0           conv4_block13_concat[0][0]\r\n                                                                 conv4_block14_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block15_0_bn (BatchNormal (3, 23, 35, 704)     2816        conv4_block14_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block15_0_relu (Activatio (3, 23, 35, 704)     0           conv4_block15_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block15_1_conv (Conv2D)   (3, 23, 35, 128)     90112       conv4_block15_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block15_1_bn (BatchNormal (3, 23, 35, 128)     512         conv4_block15_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block15_1_relu (Activatio (3, 23, 35, 128)     0           conv4_block15_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block15_2_conv (Conv2D)   (3, 23, 35, 32)      36864       conv4_block15_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block15_concat (Concatena (3, 23, 35, 736)     0           conv4_block14_concat[0][0]\r\n                                                                 conv4_block15_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block16_0_bn (BatchNormal (3, 23, 35, 736)     2944        conv4_block15_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block16_0_relu (Activatio (3, 23, 35, 736)     0           conv4_block16_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block16_1_conv (Conv2D)   (3, 23, 35, 128)     94208       conv4_block16_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block16_1_bn (BatchNormal (3, 23, 35, 128)     512         conv4_block16_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block16_1_relu (Activatio (3, 23, 35, 128)     0           conv4_block16_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block16_2_conv (Conv2D)   (3, 23, 35, 32)      36864       conv4_block16_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block16_concat (Concatena (3, 23, 35, 768)     0           conv4_block15_concat[0][0]\r\n                                                                 conv4_block16_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block17_0_bn (BatchNormal (3, 23, 35, 768)     3072        conv4_block16_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block17_0_relu (Activatio (3, 23, 35, 768)     0           conv4_block17_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block17_1_conv (Conv2D)   (3, 23, 35, 128)     98304       conv4_block17_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block17_1_bn (BatchNormal (3, 23, 35, 128)     512         conv4_block17_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block17_1_relu (Activatio (3, 23, 35, 128)     0           conv4_block17_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block17_2_conv (Conv2D)   (3, 23, 35, 32)      36864       conv4_block17_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block17_concat (Concatena (3, 23, 35, 800)     0           conv4_block16_concat[0][0]\r\n                                                                 conv4_block17_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block18_0_bn (BatchNormal (3, 23, 35, 800)     3200        conv4_block17_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block18_0_relu (Activatio (3, 23, 35, 800)     0           conv4_block18_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block18_1_conv (Conv2D)   (3, 23, 35, 128)     102400      conv4_block18_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block18_1_bn (BatchNormal (3, 23, 35, 128)     512         conv4_block18_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block18_1_relu (Activatio (3, 23, 35, 128)     0           conv4_block18_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block18_2_conv (Conv2D)   (3, 23, 35, 32)      36864       conv4_block18_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block18_concat (Concatena (3, 23, 35, 832)     0           conv4_block17_concat[0][0]\r\n                                                                 conv4_block18_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block19_0_bn (BatchNormal (3, 23, 35, 832)     3328        conv4_block18_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block19_0_relu (Activatio (3, 23, 35, 832)     0           conv4_block19_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block19_1_conv (Conv2D)   (3, 23, 35, 128)     106496      conv4_block19_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block19_1_bn (BatchNormal (3, 23, 35, 128)     512         conv4_block19_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block19_1_relu (Activatio (3, 23, 35, 128)     0           conv4_block19_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block19_2_conv (Conv2D)   (3, 23, 35, 32)      36864       conv4_block19_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block19_concat (Concatena (3, 23, 35, 864)     0           conv4_block18_concat[0][0]\r\n                                                                 conv4_block19_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block20_0_bn (BatchNormal (3, 23, 35, 864)     3456        conv4_block19_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block20_0_relu (Activatio (3, 23, 35, 864)     0           conv4_block20_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block20_1_conv (Conv2D)   (3, 23, 35, 128)     110592      conv4_block20_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block20_1_bn (BatchNormal (3, 23, 35, 128)     512         conv4_block20_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block20_1_relu (Activatio (3, 23, 35, 128)     0           conv4_block20_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block20_2_conv (Conv2D)   (3, 23, 35, 32)      36864       conv4_block20_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block20_concat (Concatena (3, 23, 35, 896)     0           conv4_block19_concat[0][0]\r\n                                                                 conv4_block20_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block21_0_bn (BatchNormal (3, 23, 35, 896)     3584        conv4_block20_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block21_0_relu (Activatio (3, 23, 35, 896)     0           conv4_block21_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block21_1_conv (Conv2D)   (3, 23, 35, 128)     114688      conv4_block21_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block21_1_bn (BatchNormal (3, 23, 35, 128)     512         conv4_block21_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block21_1_relu (Activatio (3, 23, 35, 128)     0           conv4_block21_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block21_2_conv (Conv2D)   (3, 23, 35, 32)      36864       conv4_block21_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block21_concat (Concatena (3, 23, 35, 928)     0           conv4_block20_concat[0][0]\r\n                                                                 conv4_block21_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block22_0_bn (BatchNormal (3, 23, 35, 928)     3712        conv4_block21_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block22_0_relu (Activatio (3, 23, 35, 928)     0           conv4_block22_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block22_1_conv (Conv2D)   (3, 23, 35, 128)     118784      conv4_block22_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block22_1_bn (BatchNormal (3, 23, 35, 128)     512         conv4_block22_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block22_1_relu (Activatio (3, 23, 35, 128)     0           conv4_block22_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block22_2_conv (Conv2D)   (3, 23, 35, 32)      36864       conv4_block22_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block22_concat (Concatena (3, 23, 35, 960)     0           conv4_block21_concat[0][0]\r\n                                                                 conv4_block22_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block23_0_bn (BatchNormal (3, 23, 35, 960)     3840        conv4_block22_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block23_0_relu (Activatio (3, 23, 35, 960)     0           conv4_block23_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block23_1_conv (Conv2D)   (3, 23, 35, 128)     122880      conv4_block23_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block23_1_bn (BatchNormal (3, 23, 35, 128)     512         conv4_block23_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block23_1_relu (Activatio (3, 23, 35, 128)     0           conv4_block23_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block23_2_conv (Conv2D)   (3, 23, 35, 32)      36864       conv4_block23_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block23_concat (Concatena (3, 23, 35, 992)     0           conv4_block22_concat[0][0]\r\n                                                                 conv4_block23_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block24_0_bn (BatchNormal (3, 23, 35, 992)     3968        conv4_block23_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block24_0_relu (Activatio (3, 23, 35, 992)     0           conv4_block24_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block24_1_conv (Conv2D)   (3, 23, 35, 128)     126976      conv4_block24_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block24_1_bn (BatchNormal (3, 23, 35, 128)     512         conv4_block24_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block24_1_relu (Activatio (3, 23, 35, 128)     0           conv4_block24_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block24_2_conv (Conv2D)   (3, 23, 35, 32)      36864       conv4_block24_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv4_block24_concat (Concatena (3, 23, 35, 1024)    0           conv4_block23_concat[0][0]\r\n                                                                 conv4_block24_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\npool4_bn (BatchNormalization)   (3, 23, 35, 1024)    4096        conv4_block24_concat[0][0]\r\n__________________________________________________________________________________________________\r\npool4_relu (Activation)         (3, 23, 35, 1024)    0           pool4_bn[0][0]\r\n__________________________________________________________________________________________________\r\npool4_conv (Conv2D)             (3, 23, 35, 512)     524288      pool4_relu[0][0]\r\n__________________________________________________________________________________________________\r\npool4_pool (AveragePooling2D)   (3, 11, 17, 512)     0           pool4_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block1_0_bn (BatchNormali (3, 11, 17, 512)     2048        pool4_pool[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block1_0_relu (Activation (3, 11, 17, 512)     0           conv5_block1_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block1_1_conv (Conv2D)    (3, 11, 17, 128)     65536       conv5_block1_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block1_1_bn (BatchNormali (3, 11, 17, 128)     512         conv5_block1_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block1_1_relu (Activation (3, 11, 17, 128)     0           conv5_block1_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block1_2_conv (Conv2D)    (3, 11, 17, 32)      36864       conv5_block1_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block1_concat (Concatenat (3, 11, 17, 544)     0           pool4_pool[0][0]\r\n                                                                 conv5_block1_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block2_0_bn (BatchNormali (3, 11, 17, 544)     2176        conv5_block1_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block2_0_relu (Activation (3, 11, 17, 544)     0           conv5_block2_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block2_1_conv (Conv2D)    (3, 11, 17, 128)     69632       conv5_block2_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block2_1_bn (BatchNormali (3, 11, 17, 128)     512         conv5_block2_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block2_1_relu (Activation (3, 11, 17, 128)     0           conv5_block2_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block2_2_conv (Conv2D)    (3, 11, 17, 32)      36864       conv5_block2_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block2_concat (Concatenat (3, 11, 17, 576)     0           conv5_block1_concat[0][0]\r\n                                                                 conv5_block2_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block3_0_bn (BatchNormali (3, 11, 17, 576)     2304        conv5_block2_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block3_0_relu (Activation (3, 11, 17, 576)     0           conv5_block3_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block3_1_conv (Conv2D)    (3, 11, 17, 128)     73728       conv5_block3_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block3_1_bn (BatchNormali (3, 11, 17, 128)     512         conv5_block3_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block3_1_relu (Activation (3, 11, 17, 128)     0           conv5_block3_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block3_2_conv (Conv2D)    (3, 11, 17, 32)      36864       conv5_block3_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block3_concat (Concatenat (3, 11, 17, 608)     0           conv5_block2_concat[0][0]\r\n                                                                 conv5_block3_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block4_0_bn (BatchNormali (3, 11, 17, 608)     2432        conv5_block3_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block4_0_relu (Activation (3, 11, 17, 608)     0           conv5_block4_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block4_1_conv (Conv2D)    (3, 11, 17, 128)     77824       conv5_block4_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block4_1_bn (BatchNormali (3, 11, 17, 128)     512         conv5_block4_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block4_1_relu (Activation (3, 11, 17, 128)     0           conv5_block4_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block4_2_conv (Conv2D)    (3, 11, 17, 32)      36864       conv5_block4_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block4_concat (Concatenat (3, 11, 17, 640)     0           conv5_block3_concat[0][0]\r\n                                                                 conv5_block4_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block5_0_bn (BatchNormali (3, 11, 17, 640)     2560        conv5_block4_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block5_0_relu (Activation (3, 11, 17, 640)     0           conv5_block5_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block5_1_conv (Conv2D)    (3, 11, 17, 128)     81920       conv5_block5_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block5_1_bn (BatchNormali (3, 11, 17, 128)     512         conv5_block5_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block5_1_relu (Activation (3, 11, 17, 128)     0           conv5_block5_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block5_2_conv (Conv2D)    (3, 11, 17, 32)      36864       conv5_block5_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block5_concat (Concatenat (3, 11, 17, 672)     0           conv5_block4_concat[0][0]\r\n                                                                 conv5_block5_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block6_0_bn (BatchNormali (3, 11, 17, 672)     2688        conv5_block5_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block6_0_relu (Activation (3, 11, 17, 672)     0           conv5_block6_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block6_1_conv (Conv2D)    (3, 11, 17, 128)     86016       conv5_block6_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block6_1_bn (BatchNormali (3, 11, 17, 128)     512         conv5_block6_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block6_1_relu (Activation (3, 11, 17, 128)     0           conv5_block6_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block6_2_conv (Conv2D)    (3, 11, 17, 32)      36864       conv5_block6_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block6_concat (Concatenat (3, 11, 17, 704)     0           conv5_block5_concat[0][0]\r\n                                                                 conv5_block6_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block7_0_bn (BatchNormali (3, 11, 17, 704)     2816        conv5_block6_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block7_0_relu (Activation (3, 11, 17, 704)     0           conv5_block7_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block7_1_conv (Conv2D)    (3, 11, 17, 128)     90112       conv5_block7_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block7_1_bn (BatchNormali (3, 11, 17, 128)     512         conv5_block7_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block7_1_relu (Activation (3, 11, 17, 128)     0           conv5_block7_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block7_2_conv (Conv2D)    (3, 11, 17, 32)      36864       conv5_block7_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block7_concat (Concatenat (3, 11, 17, 736)     0           conv5_block6_concat[0][0]\r\n                                                                 conv5_block7_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block8_0_bn (BatchNormali (3, 11, 17, 736)     2944        conv5_block7_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block8_0_relu (Activation (3, 11, 17, 736)     0           conv5_block8_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block8_1_conv (Conv2D)    (3, 11, 17, 128)     94208       conv5_block8_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block8_1_bn (BatchNormali (3, 11, 17, 128)     512         conv5_block8_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block8_1_relu (Activation (3, 11, 17, 128)     0           conv5_block8_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block8_2_conv (Conv2D)    (3, 11, 17, 32)      36864       conv5_block8_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block8_concat (Concatenat (3, 11, 17, 768)     0           conv5_block7_concat[0][0]\r\n                                                                 conv5_block8_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block9_0_bn (BatchNormali (3, 11, 17, 768)     3072        conv5_block8_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block9_0_relu (Activation (3, 11, 17, 768)     0           conv5_block9_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block9_1_conv (Conv2D)    (3, 11, 17, 128)     98304       conv5_block9_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block9_1_bn (BatchNormali (3, 11, 17, 128)     512         conv5_block9_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block9_1_relu (Activation (3, 11, 17, 128)     0           conv5_block9_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block9_2_conv (Conv2D)    (3, 11, 17, 32)      36864       conv5_block9_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block9_concat (Concatenat (3, 11, 17, 800)     0           conv5_block8_concat[0][0]\r\n                                                                 conv5_block9_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block10_0_bn (BatchNormal (3, 11, 17, 800)     3200        conv5_block9_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block10_0_relu (Activatio (3, 11, 17, 800)     0           conv5_block10_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block10_1_conv (Conv2D)   (3, 11, 17, 128)     102400      conv5_block10_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block10_1_bn (BatchNormal (3, 11, 17, 128)     512         conv5_block10_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block10_1_relu (Activatio (3, 11, 17, 128)     0           conv5_block10_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block10_2_conv (Conv2D)   (3, 11, 17, 32)      36864       conv5_block10_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block10_concat (Concatena (3, 11, 17, 832)     0           conv5_block9_concat[0][0]\r\n                                                                 conv5_block10_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block11_0_bn (BatchNormal (3, 11, 17, 832)     3328        conv5_block10_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block11_0_relu (Activatio (3, 11, 17, 832)     0           conv5_block11_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block11_1_conv (Conv2D)   (3, 11, 17, 128)     106496      conv5_block11_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block11_1_bn (BatchNormal (3, 11, 17, 128)     512         conv5_block11_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block11_1_relu (Activatio (3, 11, 17, 128)     0           conv5_block11_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block11_2_conv (Conv2D)   (3, 11, 17, 32)      36864       conv5_block11_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block11_concat (Concatena (3, 11, 17, 864)     0           conv5_block10_concat[0][0]\r\n                                                                 conv5_block11_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block12_0_bn (BatchNormal (3, 11, 17, 864)     3456        conv5_block11_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block12_0_relu (Activatio (3, 11, 17, 864)     0           conv5_block12_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block12_1_conv (Conv2D)   (3, 11, 17, 128)     110592      conv5_block12_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block12_1_bn (BatchNormal (3, 11, 17, 128)     512         conv5_block12_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block12_1_relu (Activatio (3, 11, 17, 128)     0           conv5_block12_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block12_2_conv (Conv2D)   (3, 11, 17, 32)      36864       conv5_block12_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block12_concat (Concatena (3, 11, 17, 896)     0           conv5_block11_concat[0][0]\r\n                                                                 conv5_block12_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block13_0_bn (BatchNormal (3, 11, 17, 896)     3584        conv5_block12_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block13_0_relu (Activatio (3, 11, 17, 896)     0           conv5_block13_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block13_1_conv (Conv2D)   (3, 11, 17, 128)     114688      conv5_block13_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block13_1_bn (BatchNormal (3, 11, 17, 128)     512         conv5_block13_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block13_1_relu (Activatio (3, 11, 17, 128)     0           conv5_block13_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block13_2_conv (Conv2D)   (3, 11, 17, 32)      36864       conv5_block13_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block13_concat (Concatena (3, 11, 17, 928)     0           conv5_block12_concat[0][0]\r\n                                                                 conv5_block13_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block14_0_bn (BatchNormal (3, 11, 17, 928)     3712        conv5_block13_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block14_0_relu (Activatio (3, 11, 17, 928)     0           conv5_block14_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block14_1_conv (Conv2D)   (3, 11, 17, 128)     118784      conv5_block14_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block14_1_bn (BatchNormal (3, 11, 17, 128)     512         conv5_block14_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block14_1_relu (Activatio (3, 11, 17, 128)     0           conv5_block14_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block14_2_conv (Conv2D)   (3, 11, 17, 32)      36864       conv5_block14_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block14_concat (Concatena (3, 11, 17, 960)     0           conv5_block13_concat[0][0]\r\n                                                                 conv5_block14_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block15_0_bn (BatchNormal (3, 11, 17, 960)     3840        conv5_block14_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block15_0_relu (Activatio (3, 11, 17, 960)     0           conv5_block15_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block15_1_conv (Conv2D)   (3, 11, 17, 128)     122880      conv5_block15_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block15_1_bn (BatchNormal (3, 11, 17, 128)     512         conv5_block15_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block15_1_relu (Activatio (3, 11, 17, 128)     0           conv5_block15_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block15_2_conv (Conv2D)   (3, 11, 17, 32)      36864       conv5_block15_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block15_concat (Concatena (3, 11, 17, 992)     0           conv5_block14_concat[0][0]\r\n                                                                 conv5_block15_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block16_0_bn (BatchNormal (3, 11, 17, 992)     3968        conv5_block15_concat[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block16_0_relu (Activatio (3, 11, 17, 992)     0           conv5_block16_0_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block16_1_conv (Conv2D)   (3, 11, 17, 128)     126976      conv5_block16_0_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block16_1_bn (BatchNormal (3, 11, 17, 128)     512         conv5_block16_1_conv[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block16_1_relu (Activatio (3, 11, 17, 128)     0           conv5_block16_1_bn[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block16_2_conv (Conv2D)   (3, 11, 17, 32)      36864       conv5_block16_1_relu[0][0]\r\n__________________________________________________________________________________________________\r\nconv5_block16_concat (Concatena (3, 11, 17, 1024)    0           conv5_block15_concat[0][0]\r\n                                                                 conv5_block16_2_conv[0][0]\r\n__________________________________________________________________________________________________\r\nbn (BatchNormalization)         (3, 11, 17, 1024)    4096        conv5_block16_concat[0][0]\r\n__________________________________________________________________________________________________\r\nrelu (Activation)               (3, 11, 17, 1024)    0           bn[0][0]\r\n__________________________________________________________________________________________________\r\navg_pool (GlobalAveragePooling2 (3, 1024)            0           relu[0][0]\r\n__________________________________________________________________________________________________\r\nfc1000 (Dense)                  (3, 10)              10250       avg_pool[0][0]\r\n==================================================================================================\r\nTotal params: 7,047,754\r\nTrainable params: 6,964,106\r\nNon-trainable params: 83,648\r\n__________________________________________________________________________________________________\r\nTrain for 100 steps, validate for 10 steps\r\n2019-11-06 11:12:15.235702: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamiclibrary libcublas.so.10.0\r\nshape TensorShape([12, 372, 558, 3]) [12 372 558 3]\r\n2019-11-06 11:12:15.481528: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index 10 of dimension 0 out of bounds.\r\nshape TensorShape([12, 372, 558, 3]) [12 372 558 3]\r\n2019-11-06 11:12:15.485747: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index 10 of dimension 0 out of bounds.\r\nshape TensorShape([12, 372, 558, 3]) [12 372 558 3]\r\n2019-11-06 11:12:15.488817: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index 10 of dimension 0 out of bounds.\r\n2019-11-06 11:12:15.489183: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Invalid argument: {{function_node __inference_Dataset_map_batch_print_35}} slice index 10 of dimension 0 out of bounds.\r\n         [[{{node strided_slice}}]]\r\n         [[MultiDeviceIteratorGetNextFromShard]]\r\n         [[RemoteCall]]\r\n         [[IteratorGetNext_2]]\r\n         [[Identity_4/_188]]\r\n2019-11-06 11:12:15.489398: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Invalid argument: {{function_node __inference_Dataset_map_batch_print_35}} slice index 10 of dimension 0 out of bounds.\r\n         [[{{node strided_slice}}]]\r\n         [[MultiDeviceIteratorGetNextFromShard]]\r\n         [[RemoteCall]]\r\n         [[IteratorGetNext_2]]\r\nshape TensorShape([12, 372, 558, 3]) [12 372 558 3]\r\n2019-11-06 11:12:15.494247: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index 10 of dimension 0 out of bounds.\r\n2019-11-06 11:12:15.887854: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Invalid argument: {{function_node __inference_Dataset_map_batch_print_35}} slice index 10 of dimension 0 out of bounds.\r\n         [[{{node strided_slice}}]]\r\n         [[MultiDeviceIteratorGetNextFromShard]]\r\n         [[RemoteCall]]\r\n         [[IteratorGetNext_2]]\r\n         [[replica_2/metrics/accuracy/AssignAddVariableOp_1/_39]]\r\n  1/100 [..............................] - ETA: 3:57:11Traceback (most recent call last):\r\n  File \"/user/vmarkovtsev/images/efficientoffice/efficientoffice/shape_bug.py\", line 45, in <module>\r\n    sys.exit(main())\r\n  File \"/user/vmarkovtsev/images/efficientoffice/efficientoffice/shape_bug.py\", line 41, in main\r\n    model.fit(ds_train, validation_data=ds_val, epochs=1, steps_per_epoch=100)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\", line 728, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 324, in fit\r\n    total_epochs=epochs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 123, in run_one_epoch\r\n    batch_outs = execution_function(iterator)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\", line 86, in execution_function\r\n    distributed_function(input_fn))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\", line 457, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\", line 520, in _call\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\", line 1823, in __call__\r\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\", line 1141, in _filtered_call\r\n    self.captured_inputs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\", line 1224, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\", line 511, in call\r\n    ctx=ctx)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\", line 67, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: 4 root error(s) found.\r\n  (0) Invalid argument:   slice index 10 of dimension 0 out of bounds.\r\n         [[node strided_slice (defined at /local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]\r\n         [[MultiDeviceIteratorGetNextFromShard]]\r\n         [[RemoteCall]]\r\n         [[IteratorGetNext_2]]\r\n         [[Identity_4/_188]]\r\n  (1) Invalid argument:   slice index 10 of dimension 0 out of bounds.\r\n         [[node strided_slice (defined at /local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]\r\n         [[MultiDeviceIteratorGetNextFromShard]]\r\n         [[RemoteCall]]\r\n         [[IteratorGetNext_2]]\r\n  (2) Cancelled:\r\n  (3) Cancelled:\r\n0 successful operations.\r\n1 derived errors ignored. [Op:__inference_distributed_function_166689]\r\n\r\nFunction call stack:\r\ndistributed_function -> distributed_function -> distributed_function -> distributed_function -> distributed_function ->distributed_function\r\n</pre>\r\n</details>\r\n\r\nThis is how the log ends - the crash:\r\n\r\n```\r\nTrain for 100 steps, validate for 10 steps\r\n2019-11-06 11:12:15.235702: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamiclibrary libcublas.so.10.0\r\nshape TensorShape([12, 372, 558, 3]) [12 372 558 3]\r\n2019-11-06 11:12:15.481528: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index 10 of dimension 0 out of bounds.\r\nshape TensorShape([12, 372, 558, 3]) [12 372 558 3]\r\n2019-11-06 11:12:15.485747: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index 10 of dimension 0 out of bounds.\r\nshape TensorShape([12, 372, 558, 3]) [12 372 558 3]\r\n2019-11-06 11:12:15.488817: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index 10 of dimension 0 out of bounds.\r\n2019-11-06 11:12:15.489183: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Invalid argument: {{function_node __inference_Dataset_map_batch_print_35}} slice index 10 of dimension 0 out of bounds.\r\n         [[{{node strided_slice}}]]\r\n         [[MultiDeviceIteratorGetNextFromShard]]\r\n         [[RemoteCall]]\r\n         [[IteratorGetNext_2]]\r\n         [[Identity_4/_188]]\r\n2019-11-06 11:12:15.489398: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Invalid argument: {{function_node __inference_Dataset_map_batch_print_35}} slice index 10 of dimension 0 out of bounds.\r\n         [[{{node strided_slice}}]]\r\n         [[MultiDeviceIteratorGetNextFromShard]]\r\n         [[RemoteCall]]\r\n         [[IteratorGetNext_2]]\r\nshape TensorShape([12, 372, 558, 3]) [12 372 558 3]\r\n2019-11-06 11:12:15.494247: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at strided_slice_op.cc:108 : Invalid argument: slice index 10 of dimension 0 out of bounds.\r\n2019-11-06 11:12:15.887854: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Invalid argument: {{function_node __inference_Dataset_map_batch_print_35}} slice index 10 of dimension 0 out of bounds.\r\n         [[{{node strided_slice}}]]\r\n         [[MultiDeviceIteratorGetNextFromShard]]\r\n         [[RemoteCall]]\r\n         [[IteratorGetNext_2]]\r\n         [[replica_2/metrics/accuracy/AssignAddVariableOp_1/_39]]\r\n  1/100 [..............................] - ETA: 3:57:11Traceback (most recent call last):\r\n  File \"/user/vmarkovtsev/images/efficientoffice/efficientoffice/shape_bug.py\", line 45, in <module>\r\n    sys.exit(main())\r\n  File \"/user/vmarkovtsev/images/efficientoffice/efficientoffice/shape_bug.py\", line 41, in main\r\n    model.fit(ds_train, validation_data=ds_val, epochs=1, steps_per_epoch=100)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\", line 728, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 324, in fit\r\n    total_epochs=epochs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 123, in run_one_epoch\r\n    batch_outs = execution_function(iterator)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\", line 86, in execution_function\r\n    distributed_function(input_fn))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\", line 457, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\", line 520, in _call\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\", line 1823, in __call__\r\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\", line 1141, in _filtered_call\r\n    self.captured_inputs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\", line 1224, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\", line 511, in call\r\n    ctx=ctx)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\", line 67, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: 4 root error(s) found.\r\n  (0) Invalid argument:   slice index 10 of dimension 0 out of bounds.\r\n         [[node strided_slice (defined at /local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]\r\n         [[MultiDeviceIteratorGetNextFromShard]]\r\n         [[RemoteCall]]\r\n         [[IteratorGetNext_2]]\r\n         [[Identity_4/_188]]\r\n  (1) Invalid argument:   slice index 10 of dimension 0 out of bounds.\r\n         [[node strided_slice (defined at /local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1751) ]]\r\n         [[MultiDeviceIteratorGetNextFromShard]]\r\n         [[RemoteCall]]\r\n         [[IteratorGetNext_2]]\r\n  (2) Cancelled:\r\n  (3) Cancelled:\r\n0 successful operations.\r\n1 derived errors ignored. [Op:__inference_distributed_function_166689]\r\n\r\nFunction call stack:\r\ndistributed_function -> distributed_function -> distributed_function -> distributed_function -> distributed_function ->distributed_function\r\n```\r\n\r\nThis is why the bug is so spicy: both the static and dynamic shapes are 12, but if you try to access an element under index 3+ (3 = 12 / 4), you crash. I am really interested in why.\r\n\r\nIf you remove `drop_remainder=True`, the code works.", "comments": ["This has to do with how tf.data rebatches datasets for distribution strategy. We recently changed the implementation of rebatching such that this will no longer happen; the fix will be available in TF 2.1. Let us know if this is still an issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34039\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34039\">No</a>\n"]}, {"number": 34038, "title": "TF 2.0 distribution strategy throws invalid argument error", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): somewhat\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): DGX\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/z\r\n- TensorFlow installed from (source or binary): docker image\r\n- TensorFlow version (use command below): 2.0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version:  10.1\r\n- GPU model and memory:  Telsa V100-SXM2\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nFrom the [docs](https://www.tensorflow.org/guide/gpu#with_tfdistributestrategy):\r\n\r\n```python\r\ntf.debugging.set_log_device_placement(True)\r\n\r\nstrategy = tf.distribute.MirroredStrategy()\r\nwith strategy.scope():\r\n  inputs = tf.keras.layers.Input(shape=(1,))\r\n  predictions = tf.keras.layers.Dense(1)(inputs)\r\n  model = tf.keras.models.Model(inputs=inputs, outputs=predictions)\r\n  model.compile(loss='mse',\r\n                optimizer=tf.keras.optimizers.SGD(learning_rate=0.2))\r\n\r\n```\r\n\r\nI adapted this (I hope correctly for multiple gpus)\r\n\r\n```python\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\ngpus_to_use = gpus[-3:]\r\n\r\nif gpus:\r\n    # Restrict TensorFlow to only allocate 1GB of memory on the first GPU\r\n    try:\r\n        tf.config.experimental.set_visible_devices(gpus_to_use, 'GPU')\r\n        for gpu in gpus_to_use:\r\n            tf.config.experimental.set_memory_growth(gpu, True)        \r\n            gb = 1024\r\n            tf.config.experimental.set_virtual_device_configuration(\r\n                gpu,\r\n                [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=12*gb)]\r\n            )\r\n        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\r\n        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\r\n    except RuntimeError as e:\r\n        # Virtual devices must be set before GPUs have been initialized\r\n        print(e)\r\n```\r\nwhich prints `8 Physical GPUs, 3 Logical GPUs` as expected\r\n\r\nThen, calling just this line:\r\n```python\r\nstrategy = tf.distribute.MirroredStrategy()\r\n```\r\nthrows:\r\n```\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-18-2f6e99f3473c> in <module>\r\n----> 1 strategy = tf.distribute.MirroredStrategy()\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/mirrored_strategy.py in __init__(self, devices, cross_device_ops)\r\n    354   def __init__(self, devices=None, cross_device_ops=None):\r\n    355     extended = MirroredExtended(\r\n--> 356         self, devices=devices, cross_device_ops=cross_device_ops)\r\n    357     super(MirroredStrategy, self).__init__(extended)\r\n    358 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/mirrored_strategy.py in __init__(self, container_strategy, devices, cross_device_ops)\r\n    394                      \"any local devices.\")\r\n    395     self._cross_device_ops = cross_device_ops\r\n--> 396     self._initialize_strategy(devices)\r\n    397 \r\n    398     # TODO(b/128995245): Enable last partial batch support in graph mode.\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/mirrored_strategy.py in _initialize_strategy(self, devices)\r\n    408         \"No duplicates allowed in `devices` argument: %s\" % (devices,))\r\n    409     if _is_device_list_local(devices):\r\n--> 410       self._initialize_local(devices)\r\n    411     else:\r\n    412       self._initialize_multi_worker(devices)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/mirrored_strategy.py in _initialize_local(self, devices)\r\n    418     self._input_workers = input_lib.InputWorkers(self._device_map)\r\n    419     self._inferred_cross_device_ops = None if self._cross_device_ops else (\r\n--> 420         cross_device_ops_lib.choose_the_best(devices))\r\n    421     self._host_input_device = numpy_dataset.SingleDevice(\"/cpu:0\")\r\n    422 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/distribute/cross_device_ops.py in choose_the_best(devices, session_config)\r\n   1194   \"\"\"\r\n   1195   requested_devices = set([device_util.canonicalize(d) for d in devices])\r\n-> 1196   machine_devices = device_lib.list_local_devices(session_config=session_config)\r\n   1197   using_devices = set()\r\n   1198   for d in machine_devices:\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/device_lib.py in list_local_devices(session_config)\r\n     39   return [\r\n     40       _convert(s)\r\n---> 41       for s in pywrap_tensorflow.list_devices(session_config=session_config)\r\n     42   ]\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/pywrap_tensorflow_internal.py in list_devices(session_config)\r\n   2247     return ListDevicesWithSessionConfig(session_config.SerializeToString())\r\n   2248   else:\r\n-> 2249     return ListDevices()\r\n   2250 \r\n   2251 \r\n\r\nInvalidArgumentError: device CUDA:0 not supported by XLA service\r\n\twhile setting up XLA_GPU_JIT device number 0\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nIt just works as in the docs\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\nSee above. Docker image `tensorflow/tensorflow:2.0.0-gpu-py3-jupyter` with `nvidia-docker`\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Hi guys, I have the same issue only using:\r\n\r\n``` python\r\nimport tensorflow as tf\r\n\r\ngpus = tf.config.experimental.list_physical_devices('GPU')\r\ntf.config.experimental.set_visible_devices(gpus[0:2], 'GPU')\r\n\r\nstrategy = tf.distribute.MirroredStrategy()\r\n```", "I just verified and I believe this is resolved in the nightly and the fix should be available in 2.1.0. Please let me know if you are able to still reproduce with the nightly or the 2.1.0-rc1 release.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34038\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34038\">No</a>\n"]}, {"number": 34036, "title": "Please let load_weights load only weights as its name describes", "body": "\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.0.0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current confusing/bad behavior/state.**\r\n\r\nLook at the end of [this tutorial](https://www.tensorflow.org/guide/keras/save_and_serialize):\r\n\r\n```\r\n# Recreate the model\r\nnew_model = get_model()\r\nnew_model.compile(loss='sparse_categorical_crossentropy',\r\n                  optimizer=keras.optimizers.RMSprop())\r\n\r\n# This initializes the variables used by the optimizers,\r\n# as well as any stateful metric variables\r\nnew_model.train_on_batch(x_train[:1], y_train[:1])\r\n\r\n# Load the state of the old model\r\nnew_model.load_weights('path_to_my_weights')\r\n\r\n# Check that the model state has been preserved\r\nnew_predictions = new_model.predict(x_test)\r\nnp.testing.assert_allclose(predictions, new_predictions, rtol=1e-6, atol=1e-6)\r\n\r\n# The optimizer state is preserved as well,\r\n# so you can resume training where you left off\r\nnew_first_batch_loss = new_model.train_on_batch(x_train[:64], y_train[:64])\r\nassert first_batch_loss == new_first_batch_loss\r\n```\r\n\r\nLook more closely:\r\n\r\n```\r\n# Load the state of the old model\r\nnew_model.load_weights('path_to_my_weights')\r\n# The optimizer state is preserved as well\r\n```\r\n\r\nI'm sorry, but, are you serious? Why on earth do you think it's a good idea to let a **load_weights** function restore anything other than the **WEIGHTS** of the model? Is this deep learning from 3019? Maybe it's a documentation issue?\r\n\r\nIf you mean to give the users the option to save or load other variables in addition to the model's weights, please create new functions, e.g. **save_variables()** and **load_variables()**.\r\n\r\n**Will this change the current api? How?**\r\nYes, in a good way.\r\n\r\n**Who will benefit with this feature?**\r\nEverybody.\r\n", "comments": ["@netw0rkf10w,\r\nSorry for the delayed response. \r\n\r\n1. Can you please let us know the reference which states that `load_weights` preserves the **`Optimizer`** state as well.\r\n2. Even if if it is so, please let us know the disadvantage of that functionality.", "Hi @rmothukuru.\r\n\r\n> 1. Can you please let us know the reference which states that `load_weights` preserves the **`Optimizer`** state as well.\r\n\r\nI no longer use TensorFlow, but isn't this clear from the description that I posted above? (Look at this comment in the tutorial: `The optimizer state is preserved as well`.)\r\n\r\n> 2. Even if if it is so, please let us know the disadvantage of that functionality.\r\n\r\nThe issue here is not with the functionality, but a mismatch between the name of a function and what it does. **It is confusing**. If I use a `load_weights` function, I'd expect it to only load weights, nothing else (by default).\r\n\r\nIt's fine if this is not an issue, TensorFlow users get confused all the time anyway.", "@netw0rkf10w,\r\nThank you for your response. It's been more than an year that you raised this issue and no other Developer in the community expressed their **confusion** regarding this, Surprisingly. So, closing this issue as it is neither a Bug nor Feature.", "@rmothukuru Note that the behavior of the `load_weights` function has been changed (and the above tutorial has also been largely updated). If it was good then it wouldn't have been changed, so the issue I created was actually very relevant at that time (i.e., nearly two years ago).\r\n\r\nYour replies above show that you were confused when reading this issue, which is because you take nearly two years to read it."]}, {"number": 34035, "title": "Issues converting recurrent ML-Agents model to TFLite (Tensorflow 1.15)", "body": "Hi\r\n\r\nI have been tryingt to convert a frozen graph def created by [ML-Agents](https://github.com/Unity-Technologies/ml-agents) to TFLite. However, there is an input variable to the model, which is defined by:\r\n\r\n```\r\nself.sequence_length = tf.placeholder(\r\n            shape=None, dtype=tf.int32, name=\"sequence_length\"\r\n        )\r\n```\r\n\r\nwhich seems to cause problems in the conversion.\r\n\r\nIf I convert without passing shapes the following happens:\r\n\r\n```\r\ntflite_convert --output_file=model.tflite --graph_def_file=unity/ml-agents/models/ppo-0/RoverLearning/frozen_graph_def.pb --input_arrays=vector_observation,epsilon,recurrent_in,sequence_length --output_arrays=action\r\n```\r\n\r\n```\r\n2019-11-05 13:59:21.589574: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-11-05 13:59:21.602134: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe2bf9e7280 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2019-11-05 13:59:21.602151: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\nTraceback (most recent call last):\r\n  File \"/Users/dwright/anaconda3/envs/mlagents/bin/tflite_convert\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/tensorflow_core/lite/python/tflite_convert.py\", line 515, in main\r\n    app.run(main=run_main, argv=sys.argv[:1])\r\n  File \"/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/tensorflow_core/lite/python/tflite_convert.py\", line 511, in run_main\r\n    _convert_tf1_model(tflite_flags)\r\n  File \"/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/tensorflow_core/lite/python/tflite_convert.py\", line 199, in _convert_tf1_model\r\n    output_data = converter.convert()\r\n  File \"/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py\", line 898, in convert\r\n    self._set_batch_size(batch_size=1)\r\n  File \"/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py\", line 1032, in _set_batch_size\r\n    shape = tensor.shape.as_list()\r\n  File \"/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/tensorflow_core/python/framework/tensor_shape.py\", line 1171, in as_list\r\n    raise ValueError(\"as_list() is not defined on an unknown TensorShape.\")\r\nValueError: as_list() is not defined on an unknown TensorShape.\r\n```\r\nI added some debut messages to `lite.py` and found that the issue is with the variable `sequence_length`\r\n\r\n\r\nIf I pass the shapes to the command like this: \r\n\r\n```\r\ntflite_convert --output_file=model.tflite --graph_def_file=unity/ml-agents/models/ppo-0/RoverLearning/frozen_graph_def.pb --input_arrays=vector_observation,epsilon,recurrent_in,sequence_length --output_arrays=action --input_shapes=1,7:1,2:7,40:1\r\n```\r\n\r\nI get a similar error:\r\n\r\n```\r\n2019-11-05 14:25:44.658772: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-11-05 14:25:44.677569: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fee79ed3960 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2019-11-05 14:25:44.677591: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2019-11-05 14:25:44.741840: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\r\n2019-11-05 14:25:44.741948: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2019-11-05 14:25:44.819310: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:786] Optimization results for grappler item: graph_to_optimize\r\n2019-11-05 14:25:44.819337: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 304 nodes (-81), 371 edges (-83), time = 56.212ms.\r\n2019-11-05 14:25:44.819342: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 304 nodes (0), 371 edges (0), time = 8.713ms.\r\nTraceback (most recent call last):\r\n  File \"/Users/dwright/anaconda3/envs/mlagents/bin/tflite_convert\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/tensorflow_core/lite/python/tflite_convert.py\", line 515, in main\r\n    app.run(main=run_main, argv=sys.argv[:1])\r\n  File \"/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/tensorflow_core/lite/python/tflite_convert.py\", line 511, in run_main\r\n    _convert_tf1_model(tflite_flags)\r\n  File \"/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/tensorflow_core/lite/python/tflite_convert.py\", line 199, in _convert_tf1_model\r\n    output_data = converter.convert()\r\n  File \"/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py\", line 983, in convert\r\n    **converter_kwargs)\r\n  File \"/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py\", line 449, in toco_convert_impl\r\n    enable_mlir_converter=enable_mlir_converter)\r\n  File \"/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py\", line 200, in toco_convert_protos\r\n    raise ConverterError(\"See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\ntensorflow.lite.python.convert.ConverterError: See console for info.\r\n2019-11-05 14:25:46.811578: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-05 14:25:46.811623: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-05 14:25:46.811639: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-05 14:25:46.811649: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-05 14:25:46.811675: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-05 14:25:46.811685: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-05 14:25:46.811695: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-05 14:25:46.811705: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-05 14:25:46.811986: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-05 14:25:46.812009: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-05 14:25:46.812022: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-05 14:25:46.812033: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-05 14:25:46.812378: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2019-11-05 14:25:46.812411: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-05 14:25:46.812433: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2019-11-05 14:25:46.812448: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-05 14:25:46.812468: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-05 14:25:46.812497: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2019-11-05 14:25:46.812507: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-05 14:25:46.812525: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-05 14:25:46.812544: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-05 14:25:46.812559: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-05 14:25:46.812567: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-05 14:25:46.812580: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-05 14:25:46.812588: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-05 14:25:46.812613: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3\r\n2019-11-05 14:25:46.812631: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-05 14:25:46.812640: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-05 14:25:46.812661: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3\r\n2019-11-05 14:25:46.812680: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-05 14:25:46.812694: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-05 14:25:46.812708: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-05 14:25:46.812724: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-05 14:25:46.812751: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: LoopCond\r\n2019-11-05 14:25:46.812763: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: LoopCond\r\n2019-11-05 14:25:46.812864: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2019-11-05 14:25:46.812928: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3\r\n2019-11-05 14:25:46.812951: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3\r\n2019-11-05 14:25:46.813037: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3\r\n2019-11-05 14:25:46.813111: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3\r\n2019-11-05 14:25:46.813301: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2019-11-05 14:25:46.816417: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 185 operators, 322 arrays (0 quantized)\r\n2019-11-05 14:25:46.818204: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 103 operators, 180 arrays (0 quantized)\r\n2019-11-05 14:25:46.819853: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 103 operators, 180 arrays (0 quantized)\r\n2019-11-05 14:25:46.819987: F tensorflow/lite/toco/graph_transformations/propagate_fixed_sizes.cc:1616] Check failed: *packed_shape == shape All input arrays to Pack operators must have the same shape. Input \"sequence_length\" is different.\r\nFatal Python error: Aborted\r\n\r\nCurrent thread 0x0000000111d5b5c0 (most recent call first):\r\n  File \"/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 52 in execute\r\n  File \"/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/absl/app.py\", line 250 in _run_main\r\n  File \"/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/absl/app.py\", line 299 in run\r\n  File \"/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py\", line 40 in run\r\n  File \"/Users/dwright/anaconda3/envs/mlagents/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 89 in main\r\n  File \"/Users/dwright/anaconda3/envs/mlagents/bin/toco_from_protos\", line 8 in <module>\r\n```\r\n\r\nAny help is highly appreciated! ", "comments": ["Hi\r\n\r\nI'm exploring the same rabbit hole (ml-agents -> tflite); currently at about the same point.\r\n\r\nHere are a few learnings that may help:\r\n- try the python api instead of command line util (it's recommended): https://www.tensorflow.org/lite/convert/python_api\r\n- if you happen to be on windows, the windows distrib of tensorflow seems to be missing lite or just the converter, but seems to work fine running it in the linux sub system (e.g. ubuntu): https://docs.microsoft.com/en-us/windows/wsl/install-win10.\r\n- perhaps try the older version of tf lite converter api, that matches the tf version used by ml-agents (1.7): https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/r1/convert/python_api.md#additional-instructions\r\n- maybe try reporting this in the ml-agents repo instead (as ml-agents is well aware of tensorflow, but likely less so vice versa)\r\n\r\nIf you get any further pls let me know - I'll do the same!\r\n\r\nCheers\r\nMatt", "Ha, just found your post in ml-agents repo!", "Note https://www.tensorflow.org/lite/convert/rnn#not_currently_supported which mentions RNN usage of `sequence_length` is not supported, but will be by end of 2019...\r\n\r\nMaybe it is supported in previous version of converter.\r\n\r\nMy case isn't an RNN btw, so sounds like your rabbit hole might be a bit longer.", "Wow, thanks @kaploink! I will look into those suggestions and keep you up to date! Could you tell me what your set up and objective is, just for information?", "@wrd90 \r\nI'm making a low cost quadruped robot running on arduino or raspberry pi (tbd), and using unity's ml-agents to teach it to walk.\r\n\r\nI've got the physical prototype robot and the corresponding trained ml-agents model, now at the pointy end of trying to put them together...\r\n\r\nCurrently at the conversion to tflite stage.\r\n\r\nHow did you find out what the input arrays/shape should be...?", "That sounds cool @mp-airwallex! \r\n\r\nI found the shapes by visualizing `frozen_graph_def.pb` using tensorboard", "err, oops, wrong account!  kaploink == mp-airwallex\r\n\r\nah, awesome, thanks", "@kaploink I almost figured ;) \r\n\r\nI tried to replace the `LSTMCell` with the drop-in replacements suggested in your link, but there seems to be a problem which sounds much like the initial error message in the initial conversion:\r\n\r\n```\r\nSorting model, may take a while... Done!\r\nIGNORED: Cast unknown layer\r\nIGNORED: AddV2 unknown layer\r\nIGNORED: Shape unknown layer\r\nIGNORED: TensorListReserve unknown layer\r\nIGNORED: TensorListFromTensor unknown layer\r\nIGNORED: EmptyTensorList unknown layer\r\nIGNORED: EmptyTensorList unknown layer\r\nIGNORED: EmptyTensorList unknown layer\r\nIGNORED: EmptyTensorList unknown layer\r\nIGNORED: EmptyTensorList unknown layer\r\nIGNORED: EmptyTensorList unknown layer\r\nIGNORED: EmptyTensorList unknown layer\r\nIGNORED: EmptyTensorList unknown layer\r\nIGNORED: EmptyTensorList unknown layer\r\nIGNORED: EmptyTensorList unknown layer\r\nIGNORED: EmptyTensorList unknown layer\r\nIGNORED: EmptyTensorList unknown layer\r\nIGNORED: EmptyTensorList unknown layer\r\nIGNORED: EmptyTensorList unknown layer\r\nIGNORED: EmptyTensorList unknown layer\r\nIGNORED: EmptyTensorList unknown layer\r\nIGNORED: EmptyTensorList unknown layer\r\nIGNORED: While unknown layer\r\nIGNORED: TensorListStack unknown layer\r\nTraceback (most recent call last):\r\n  File \"/Users/dwright/anaconda3/envs/mlagents/bin/mlagents-learn\", line 11, in <module>\r\n    load_entry_point('mlagents', 'console_scripts', 'mlagents-learn')()\r\n  File \"/Users/dwright/MSE/projects/rainSim/unity/ml-agents/ml-agents/mlagents/trainers/learn.py\", line 417, in main\r\n    run_training(0, run_seed, options, Queue())\r\n  File \"/Users/dwright/MSE/projects/rainSim/unity/ml-agents/ml-agents/mlagents/trainers/learn.py\", line 255, in run_training\r\n    tc.start_learning(env)\r\n  File \"/Users/dwright/MSE/projects/rainSim/unity/ml-agents/ml-agents/mlagents/trainers/trainer_controller.py\", line 219, in start_learning\r\n    self._export_graph()\r\n  File \"/Users/dwright/MSE/projects/rainSim/unity/ml-agents/ml-agents/mlagents/trainers/trainer_controller.py\", line 129, in _export_graph\r\n    self.trainers[brain_name].export_model()\r\n  File \"/Users/dwright/MSE/projects/rainSim/unity/ml-agents/ml-agents/mlagents/trainers/trainer.py\", line 152, in export_model\r\n    self.policy.export_model()\r\n  File \"/Users/dwright/MSE/projects/rainSim/unity/ml-agents/ml-agents/mlagents/trainers/tf_policy.py\", line 230, in export_model\r\n    tf2bc.convert(frozen_graph_def_path, self.model_path + \".nn\")\r\n  File \"/Users/dwright/MSE/projects/rainSim/unity/ml-agents/ml-agents/mlagents/trainers/tensorflow_to_barracuda.py\", line 1552, in convert\r\n    i_model, args\r\n  File \"/Users/dwright/MSE/projects/rainSim/unity/ml-agents/ml-agents/mlagents/trainers/tensorflow_to_barracuda.py\", line 1377, in process_model\r\n    process_layer(n, o_context, args)\r\n  File \"/Users/dwright/MSE/projects/rainSim/unity/ml-agents/ml-agents/mlagents/trainers/tensorflow_to_barracuda.py\", line 1220, in process_layer\r\n    assert all_elements_equal(input_ranks)\r\nAssertionError\r\n``` \r\n\r\nHowever, it seems that the issue with this message is during conversion from `frozen_graph_def.pb` to the barracuda model, which for me is secondary, as long as I have a valid frozen graph to convert to TFLite. So I tried to convert this, but I still get the initial error message...", "@wrd90\r\nAh okay, well looks like the tf pros have been adding some labels so sounds like they might have some answers for you soon.\r\n\r\nThe tflite conversion worked fine for me (non-RNN) using a slightly adjusted version of your command (`tflite_convert --output_file=model.tflite --graph_def_file=./frozen_graph_def.pb --input_arrays=vector_observation,epsilon --output_arrays=action`), so thanks heaps for that.  I've been able to continue onto tflite inference test (worked :) ), and now chucking it on the pi and hooking up to sensors & motors.  Not bothering with microcontroller version yet - will optimise later.\r\n\r\nCheers", "@kaploink Glad to hear you've been able to get some inference results! I have decided to move away from LSTMs for now. Instead I am currently buffering my observations and actions, which I then feed into the network as well. I am hoping this will perform well enough, but so far I have not seen any significant differences in the learning process compared to the LSTM version. Due to time restrictions in my project I had to find a workaround for now. Also I expect the support for RNNs only to be added to TF2, to which ML-Agents will need to migrate first. \r\nCheers", "@dav1d-wright \r\nAs many issues have been fixed in the latest version could you please try on the latest stable version [2.4/2.5/2.6] and let us know.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34035\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34035\">No</a>\n"]}, {"number": 34034, "title": "TensorFlow Lite currently doesn't support control flow ops: Merge, Switch. ", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 18.04.3 LTS\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version (or github SHA if from source):1.15.0\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n2019-11-06 14:51:12.818885: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX\r\nWARNING:tensorflow:From /home/mannam-pc/.local/lib/python3.6/site-packages/tensorflow_core/lite/python/convert_saved_model.py:60: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nThis function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\r\n2019-11-06 14:51:14.238827: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\r\n2019-11-06 14:51:14.239039: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2019-11-06 14:51:14.342213: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:786] Optimization results for grappler item: graph_to_optimize\r\n2019-11-06 14:51:14.342263: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   function_optimizer: function_optimizer did nothing. time = 0.003ms.\r\n2019-11-06 14:51:14.342276: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2019-11-06 14:51:17.338864: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\r\n2019-11-06 14:51:17.338999: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2019-11-06 14:51:17.758703: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:786] Optimization results for grappler item: graph_to_optimize\r\n2019-11-06 14:51:17.758752: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 1632 nodes (-1290), 2168 edges (-1454), time = 256.269ms.\r\n2019-11-06 14:51:17.758768: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 1632 nodes (0), 2168 edges (0), time = 73.402ms.\r\nTraceback (most recent call last):\r\n  File \"tflite_converter.py\", line 40, in <module>\r\n    tflite_model_quant = converter.convert()\r\n  File \"/home/mannam-pc/.local/lib/python3.6/site-packages/tensorflow_core/lite/python/lite.py\", line 983, in convert\r\n    **converter_kwargs)\r\n  File \"/home/mannam-pc/.local/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py\", line 449, in toco_convert_impl\r\n    enable_mlir_converter=enable_mlir_converter)\r\n  File \"/home/mannam-pc/.local/lib/python3.6/site-packages/tensorflow_core/lite/python/convert.py\", line 200, in toco_convert_protos\r\n    raise ConverterError(\"See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\ntensorflow.lite.python.convert.ConverterError: See console for info.\r\n2019-11-06 14:51:20.478994: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.479075: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.479089: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.479101: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.479122: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.479135: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.479196: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2019-11-06 14:51:20.479212: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-06 14:51:20.479236: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2019-11-06 14:51:20.479245: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-06 14:51:20.479256: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.479270: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.479279: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-06 14:51:20.479287: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.479299: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.479309: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-06 14:51:20.479320: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3\r\n2019-11-06 14:51:20.479334: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.479345: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: LoopCond\r\n2019-11-06 14:51:20.479366: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2019-11-06 14:51:20.479425: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3\r\n2019-11-06 14:51:20.479439: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3\r\n2019-11-06 14:51:20.479472: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: ParseSingleExample\r\n2019-11-06 14:51:20.479499: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3\r\n2019-11-06 14:51:20.479541: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2019-11-06 14:51:20.479552: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-06 14:51:20.479564: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2019-11-06 14:51:20.479574: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-06 14:51:20.479586: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2019-11-06 14:51:20.479595: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-06 14:51:20.479606: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.479622: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.479632: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-06 14:51:20.479642: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.479654: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.479664: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-06 14:51:20.479673: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.479685: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.479695: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-06 14:51:20.479707: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3\r\n2019-11-06 14:51:20.479726: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.479740: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: LoopCond\r\n2019-11-06 14:51:20.479763: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2019-11-06 14:51:20.479776: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2019-11-06 14:51:20.479804: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3\r\n2019-11-06 14:51:20.479817: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3\r\n2019-11-06 14:51:20.479827: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3\r\n2019-11-06 14:51:20.479846: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2019-11-06 14:51:20.479875: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3\r\n2019-11-06 14:51:20.479889: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3\r\n2019-11-06 14:51:20.479917: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2019-11-06 14:51:20.479984: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DecodeRaw\r\n2019-11-06 14:51:20.480005: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Substr\r\n2019-11-06 14:51:20.480058: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DecodeJpeg\r\n2019-11-06 14:51:20.480074: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Substr\r\n2019-11-06 14:51:20.480086: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Substr\r\n2019-11-06 14:51:20.480138: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Substr\r\n2019-11-06 14:51:20.480161: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DecodeJpeg\r\n2019-11-06 14:51:20.480195: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DecodePng\r\n2019-11-06 14:51:20.480262: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Substr\r\n2019-11-06 14:51:20.480284: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DecodeGif\r\n2019-11-06 14:51:20.480303: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: DecodeBmp\r\n2019-11-06 14:51:20.480349: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2019-11-06 14:51:20.481401: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2019-11-06 14:51:20.481417: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-06 14:51:20.481430: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2019-11-06 14:51:20.481441: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-06 14:51:20.481453: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2019-11-06 14:51:20.481463: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-06 14:51:20.481473: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2019-11-06 14:51:20.481483: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-06 14:51:20.481495: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2019-11-06 14:51:20.481504: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-06 14:51:20.481515: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2019-11-06 14:51:20.481525: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-06 14:51:20.481536: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2019-11-06 14:51:20.481546: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-06 14:51:20.481557: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2019-11-06 14:51:20.481566: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-06 14:51:20.481577: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2019-11-06 14:51:20.481587: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-06 14:51:20.481598: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2019-11-06 14:51:20.481607: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-06 14:51:20.481618: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.481633: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.481644: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-06 14:51:20.481653: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3\r\n2019-11-06 14:51:20.481665: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.481675: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-06 14:51:20.481685: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3\r\n2019-11-06 14:51:20.481696: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.481706: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-06 14:51:20.481716: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3\r\n2019-11-06 14:51:20.481727: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.481737: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-06 14:51:20.481746: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.481756: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-06 14:51:20.481766: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.481777: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.481787: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-06 14:51:20.481797: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.481808: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.481823: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-06 14:51:20.481833: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.481844: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.481855: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-06 14:51:20.481865: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.481877: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.481886: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-06 14:51:20.481896: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.481907: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.481917: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2019-11-06 14:51:20.481929: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3\r\n2019-11-06 14:51:20.481943: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.481955: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.481967: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.481998: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.482011: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: LoopCond\r\n2019-11-06 14:51:20.482039: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2019-11-06 14:51:20.482053: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2019-11-06 14:51:20.482065: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2019-11-06 14:51:20.482077: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2019-11-06 14:51:20.482089: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2019-11-06 14:51:20.482462: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3\r\n2019-11-06 14:51:20.482478: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3\r\n2019-11-06 14:51:20.482490: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3\r\n2019-11-06 14:51:20.482502: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3\r\n2019-11-06 14:51:20.482513: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3\r\n2019-11-06 14:51:20.482524: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3\r\n2019-11-06 14:51:20.482534: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3\r\n2019-11-06 14:51:20.482544: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3\r\n2019-11-06 14:51:20.482555: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3\r\n2019-11-06 14:51:20.482565: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3\r\n2019-11-06 14:51:20.482612: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2019-11-06 14:51:20.482629: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3\r\n2019-11-06 14:51:20.482642: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3\r\n2019-11-06 14:51:20.482655: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3\r\n2019-11-06 14:51:20.482667: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3\r\n2019-11-06 14:51:20.482680: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3\r\n2019-11-06 14:51:20.482691: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3\r\n2019-11-06 14:51:20.482749: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: NonMaxSuppressionV5\r\n2019-11-06 14:51:20.482798: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size\r\n2019-11-06 14:51:20.482893: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Size\r\n2019-11-06 14:51:20.482945: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2019-11-06 14:51:20.483080: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2019-11-06 14:51:20.483096: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2019-11-06 14:51:20.483113: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2019-11-06 14:51:20.483125: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2019-11-06 14:51:20.509188: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 1122 operators, 2035 arrays (0 quantized)\r\n2019-11-06 14:51:20.575870: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 1085 operators, 1966 arrays (0 quantized)\r\n2019-11-06 14:51:20.648615: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 1085 operators, 1966 arrays (0 quantized)\r\n2019-11-06 14:51:20.729953: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 583 operators, 1191 arrays (0 quantized)\r\n2019-11-06 14:51:20.751767: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 583 operators, 1191 arrays (0 quantized)\r\n2019-11-06 14:51:20.769313: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 583 operators, 1191 arrays (0 quantized)\r\n2019-11-06 14:51:20.801282: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 896 bytes, theoretical optimal value: 896 bytes.\r\n2019-11-06 14:51:20.804680: I tensorflow/lite/toco/toco_tooling.cc:454] Number of parameters: 4600257\r\n2019-11-06 14:51:20.806064: W tensorflow/lite/toco/tflite/operator.cc:2706] Op DecodeRaw is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\r\n2019-11-06 14:51:20.806081: W tensorflow/lite/toco/tflite/operator.cc:2706] Op Substr is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\r\n2019-11-06 14:51:20.806102: W tensorflow/lite/toco/tflite/operator.cc:2706] Op DecodeJpeg is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\r\n2019-11-06 14:51:20.806111: W tensorflow/lite/toco/tflite/operator.cc:2706] Op Substr is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\r\n2019-11-06 14:51:20.806120: W tensorflow/lite/toco/tflite/operator.cc:2706] Op Substr is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\r\n2019-11-06 14:51:20.806131: W tensorflow/lite/toco/tflite/operator.cc:2706] Op Substr is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\r\n2019-11-06 14:51:20.806141: W tensorflow/lite/toco/tflite/operator.cc:2706] Op DecodeJpeg is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\r\n2019-11-06 14:51:20.806150: W tensorflow/lite/toco/tflite/operator.cc:2706] Op DecodePng is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\r\n2019-11-06 14:51:20.806161: W tensorflow/lite/toco/tflite/operator.cc:2706] Op DecodeGif is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\r\n2019-11-06 14:51:20.806343: W tensorflow/lite/toco/tflite/operator.cc:2706] Op NonMaxSuppressionV5 is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\r\n2019-11-06 14:51:20.806600: W tensorflow/lite/toco/tflite/operator.cc:2706] Op DecodeRaw is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\r\n2019-11-06 14:51:20.806614: W tensorflow/lite/toco/tflite/operator.cc:2706] Op Substr is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\r\n2019-11-06 14:51:20.806635: W tensorflow/lite/toco/tflite/operator.cc:2706] Op DecodeJpeg is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\r\n2019-11-06 14:51:20.806644: W tensorflow/lite/toco/tflite/operator.cc:2706] Op Substr is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\r\n2019-11-06 14:51:20.806653: W tensorflow/lite/toco/tflite/operator.cc:2706] Op Substr is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\r\n2019-11-06 14:51:20.806664: W tensorflow/lite/toco/tflite/operator.cc:2706] Op Substr is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\r\n2019-11-06 14:51:20.806674: W tensorflow/lite/toco/tflite/operator.cc:2706] Op DecodeJpeg is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\r\n2019-11-06 14:51:20.806684: W tensorflow/lite/toco/tflite/operator.cc:2706] Op DecodePng is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\r\n2019-11-06 14:51:20.806696: W tensorflow/lite/toco/tflite/operator.cc:2706] Op DecodeGif is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\r\n2019-11-06 14:51:20.806892: W tensorflow/lite/toco/tflite/operator.cc:2706] Op NonMaxSuppressionV5 is a valid TensorFlow op but has not been whitelisted for the TensorFlow Lite flex op set.\r\n2019-11-06 14:51:20.807143: E tensorflow/lite/toco/toco_tooling.cc:481] We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nTensorFlow Lite currently doesn't support control flow ops: Merge, Switch. We are working on supporting control flow ops, please see github issue at https://github.com/tensorflow/tensorflow/issues/28485. Some of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, EQUAL, EXP, EXPAND_DIMS, FILL, GATHER, GREATER, GREATER_EQUAL, LESS, LOGICAL_AND, LOGICAL_OR, LOGISTIC, MAXIMUM, MINIMUM, MUL, PACK, PAD, RANGE, RESHAPE, RESIZE_BILINEAR, SELECT, SHAPE, SLICE, SPLIT, SQUEEZE, STRIDED_SLICE, SUB, SUM, TILE, TOPK_V2, TRANSPOSE, UNPACK, WHERE, ZEROS_LIKE. Here is a list of operators for which you will need custom implementations: DecodeGif, DecodeJpeg, DecodePng, DecodeRaw, NonMaxSuppressionV5, Substr.\r\nTraceback (most recent call last):\r\n  File \"/home/mannam-pc/.local/bin/toco_from_protos\", line 8, in <module>\r\n    sys.exit(main())\r\n  File \"/home/mannam-pc/.local/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 89, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"/home/mannam-pc/.local/lib/python3.6/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/home/mannam-pc/.local/lib/python3.6/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/home/mannam-pc/.local/lib/python3.6/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/home/mannam-pc/.local/lib/python3.6/site-packages/tensorflow_core/lite/toco/python/toco_from_protos.py\", line 52, in execute\r\n    enable_mlir_converter)\r\nException: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nTensorFlow Lite currently doesn't support control flow ops: Merge, Switch. We are working on supporting control flow ops, please see github issue at https://github.com/tensorflow/tensorflow/issues/28485. Some of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CAST, CONCATENATION, CONV_2D, DEPTHWISE_CONV_2D, EQUAL, EXP, EXPAND_DIMS, FILL, GATHER, GREATER, GREATER_EQUAL, LESS, LOGICAL_AND, LOGICAL_OR, LOGISTIC, MAXIMUM, MINIMUM, MUL, PACK, PAD, RANGE, RESHAPE, RESIZE_BILINEAR, SELECT, SHAPE, SLICE, SPLIT, SQUEEZE, STRIDED_SLICE, SUB, SUM, TILE, TOPK_V2, TRANSPOSE, UNPACK, WHERE, ZEROS_LIKE. Here is a list of operators for which you will need custom implementations: DecodeGif, DecodeJpeg, DecodePng, DecodeRaw, NonMaxSuppressionV5, Substr.\r\n\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n\r\nhttps://drive.google.com/drive/folders/1gamFb0Lr6vJV7wYwHXJIhbFjk-jg_cpj?usp=sharing\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nHere is my source code :\r\n\r\nhttps://drive.google.com/open?id=1EbJjiK6EAGqKhzrCXFBTZOuHcR6OiBdQ\r\n", "comments": ["Hi, even I am facing these issues while converting the model to Tflite versions. Any solutions for this.\r\nI am using TF 1.14 and Ubuntu 18.04 ", "hello, i have the same problem.\r\ndid you resolve this problem of unsupported control flow ops: Merge, Switch by tensorflow lite?", "> hello, i have the same problem.\r\n> did you resolve this problem of unsupported control flow ops: Merge, Switch by tensorflow lite?\r\n\r\nI have not been able to solve this problem yet", "TF Lite doesn't support v1 style control flow (switch, merge), but we support v2 control flow(while, if).\r\n\r\nCan you rebuild your model with latest version of tensorflow and then try use our new mlir-based converter?\r\n\r\nmore details : https://groups.google.com/a/tensorflow.org/forum/#!topic/tflite/C7Ag0sUrLYg", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34034\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34034\">No</a>\n"]}, {"number": 34033, "title": "how to use tensorflow lite gpu delegate in android object detection ? ", "body": "private Interpreter tfLite;\r\npublic static Classifier create(\r\n      final AssetManager assetManager,\r\n      final String modelFilename,\r\n      final String labelFilename,\r\n      final int inputSize,\r\n      final boolean isQuantized)\r\n      throws IOException \r\n{\r\n        -------------------------\r\n      try {\r\n          GpuDelegate delegate = new GpuDelegate();\r\n          Interpreter.Options options = (new Interpreter.Options()).addDelegate(delegate);\r\n          /*d.tfLite = new Interpreter(loadModelFile(assetManager, modelFilename));*/\r\n         d.tfLite = new Interpreter(loadModelFile(assetManager, modelFilename), options);\r\n        while (true) {\r\n           writeToInput(input);\r\n           d.tfLite.run(input, output);\r\n           readFromOutput(output);\r\n      }\r\n       delegate.close();\r\n       -------------------------\r\n}\r\n   what does it means for input and output ? how to transmit parameter  input and out ? ", "comments": ["@WestbrookZero \r\nCan you please go through the [link ](https://www.tensorflow.org/lite/performance/gpu)and see if it helps you. Thanks!", "@WestbrookZero \r\n\r\nAny updates please. Thanks!", "I read the tensorflow lite website gpu delegate tutorial , I used android aar , implementation 'org.tensorflow:tensorflow-lite-gpu:0.0.0-nightly' \uff0cbut there is still cpu increasing too much . if i used   implementation 'org.tensorflow:tensorflow-lite-gpu:2.0.0' ,  there is no cpu increasing , but can't recognize image . ", "The detection sample ships a quantized model, which isn't accelerated on the GPU. We'll likely be addressing this in a future update which has both float/quantized models in the sample. \r\n\r\nNote that you should really try to avoid re-creating the Interpreter/Delegate for just a single inference call.  Please have a look at our detection example @ https://github.com/tensorflow/examples/blob/master/lite/examples/object_detection/android/README.md.", "@jdduke  I used float SSDMobileNetV2 model \uff0candroid aar gpu version \u201corg.tensorflow:tensorflow-lite-gpu:0.0.0-nightly\u201d , but cpu is still increasing . i  refer to  \"https://github.com/tensorflow/examples/blob/master/lite/examples/object_detection/android/README.md\" this demo ,  It is to change the code below \r\n`d.tfLite = new Interpreter(loadModelFile(assetManager, modelFilename));`\r\nWith the following code\r\n`import org.tensorflow.lite.gpu.GpuDelegate;\r\nprivate GpuDelegate gpuDelegate;\r\nGpuDelegate delegate = new GpuDelegate();\r\nInterpreter.Options options = (new Interpreter.Options()).addDelegate(delegate);\r\nd.tfLite = new Interpreter(loadModelFile(assetManager, modelFilename), options);`\r\nI don't know what does it mean \" try to avoid re-creating the Interpreter/Delegate for just a single inference call \" ", "My comment about avoiding recreation was based on your snippet in the original issue report. If that's not how you're actually using it in the app, that's fine.\r\n\r\nWhat device(s) are you testing against? And can you provide a link to the exact .tflite model you're using? Thanks.", "I used android device , link : https://storage.googleapis.com/download.tensorflow.org/models/tflite/gpu/mobile_ssd_v2_float_coco.tflite", "> I used android device \r\n\r\nYes, but which android device exactly? Can you output the result of `adb shell getprop ro.product.device`? Performance can vary widely depending on the CPU/GPU that is used. For instance, on a Pixel 4, CPU w/ 4 threads is 30ms, and the GPU is 10ms. On a Pixel 3a, CPU w/ 4 threads is 100ms, and the GPU is 30ms."]}, {"number": 34032, "title": "build tensorflow com_google_protobuf//:protobuf_lite' failed ", "body": "                                                                     ^\r\ntensorflow/python/framework/python_op_gen_internal.cc:565:48: warning: comparison between signed and unsigned integer expressions [-Wsign-compare]\r\n   for (int i = 0; i < params_with_default.size(); ++i) {\r\n                                                ^\r\nERROR: /home/lid/.cache/bazel/_bazel_root/61773a13f73ad6653303d056b5da0c0b/external/com_google_protobuf/BUILD:106:1: C++ compilation of rule '@com_google_protobuf//:protobuf_lite' failed (Exit 1): arm-linux-gnueabi-gcc failed: error executing command \r\n  (cd /home/lid/.cache/bazel/_bazel_root/61773a13f73ad6653303d056b5da0c0b/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin \\\r\n    PWD=/proc/self/cwd \\\r\n  /sources/toolchain/gcc-linaro-4.9.4-2017.01-x86_64_arm-linux-gnueabi/bin/arm-linux-gnueabi-gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -isystem /usr/include -isystem /usr/include/arm-linux-gnueabi -MD -MF bazel-out/armeabi-opt/bin/external/com_google_protobuf/_objs/protobuf_lite/strutil.pic.d '-frandom-seed=bazel-out/armeabi-opt/bin/external/com_google_protobuf/_objs/protobuf_lite/strutil.pic.o' -fPIC -iquote external/com_google_protobuf -iquote bazel-out/armeabi-opt/genfiles/external/com_google_protobuf -iquote bazel-out/armeabi-opt/bin/external/com_google_protobuf -isystem external/com_google_protobuf/src -isystem bazel-out/armeabi-opt/genfiles/external/com_google_protobuf/src -isystem bazel-out/armeabi-opt/bin/external/com_google_protobuf/src '-march=armv7-a' '-mfpu=neon-vfpv4' '-mfloat-abi=hard' -O3 '-std=c++11' '-DS_IREAD=S_IRUSR' '-DS_IWRITE=S_IWUSR' -funsafe-math-optimizations -ftree-vectorize -fomit-frame-pointer -DRASPBERRY_PI -DHAVE_PTHREAD -DHAVE_ZLIB -Woverloaded-virtual -Wno-sign-compare -Wno-unused-function -Wno-write-strings -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -no-canonical-prefixes -fno-canonical-system-headers -c external/com_google_protobuf/src/google/protobuf/stubs/strutil.cc -o bazel-out/armeabi-opt/bin/external/com_google_protobuf/_objs/protobuf_lite/strutil.pic.o)\r\nExecution platform: @bazel_tools//platforms:host_platform\r\nIn file included from /usr/include/bits/byteswap.h:35:0,\r\n                 from /usr/include/endian.h:60,\r\n                 from /usr/include/bits/waitstatus.h:64,\r\n                 from /usr/include/stdlib.h:42,\r\n                 from external/com_google_protobuf/src/google/protobuf/stubs/strutil.h:36,\r\n                 from external/com_google_protobuf/src/google/protobuf/stubs/strutil.cc:33:\r\nexternal/com_google_protobuf/src/google/protobuf/stubs/port.h: In function 'int google::protobuf::Base64EscapeInternal(const unsigned char*, int, char*, int, const char*, bool)':\r\nexternal/com_google_protobuf/src/google/protobuf/stubs/port.h:380:45: error: invalid 'asm': invalid operand for code 'w'\r\n   static uint16 ToHost16(uint16 x) { return bswap_16(x); }\r\n                                             ^\r\nexternal/com_google_protobuf/src/google/protobuf/stubs/port.h:380:45: error: invalid 'asm': invalid operand for code 'w'\r\n   static uint16 ToHost16(uint16 x) { return bswap_16(x); }\r\n                                             ^\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 1203.894s, Critical Path: 62.17s\r\nINFO: 901 processes: 901 local.\r\nFAILED: Build did NOT complete successfully\r\nlid@lid-VirtualBox:~/cc_work/tensorflow-on-arm-2.0.0/build_tensorflow$ \r\n", "comments": ["@horo2016 ,\r\nCan you please let us know steps followed before facing the issue ?Thanks!\r\n", "build_tensorflow.sh\r\n`#!/bin/bash\r\n\r\n[ -f \"$1\" ] && {\r\n  source \"$1\"\r\n} || {\r\n  echo -ne \"Use: $0 <config>\\n\\tFor prepare environment only, uses: $0 <config> prepare\\n\"\r\n  exit 1\r\n}\r\n\r\nDIR=\"$(realpath $(dirname $0))\"\r\nsource \"./patch.sh\"\r\n\r\n# builtin variables\r\nRED='\\033[0;31m'\r\nBLUE='\\033[1;36m'\r\nNC='\\033[0m'\r\nTF_PYTHON_VERSION=${TF_PYTHON_VERSION:-\"3\"}\r\nTF_VERSION=${TF_VERSION:-\"v1.14.0\"}\r\nTF_BUILD_OUTPUT=${TF_BUILD_OUTPUT:-\"/tmp/tensorflow_pkg\"}\r\nBAZEL_VERSION=${BAZEL_VERSION:-\"0.24.1\"}\r\nCROSSTOOL_WHEEL_ARCH=${CROSSTOOL_WHEEL_ARCH:-\"any\"}\r\nTF_GIT_URL=${TF_GIT_URL:-\"https://github.com/tensorflow/tensorflow\"}\r\nWORKDIR=${WORKDIR:-\"$DIR\"}\r\nBAZEL_BIN=/home/lid/bin/bazel # \"$(command -v bazel)\"\r\n\r\nfunction log_failure_msg() {\r\n\techo -ne \"[${RED}ERROR${NC}] $@\\n\"\r\n}\r\n\r\nfunction log_app_msg() {\r\n\techo -ne \"[${BLUE}INFO${NC}] $@\\n\"\r\n}\r\n\r\nfunction create_workdir()\r\n{\r\n  WORKDIR=${WORKDIR}/sources/\r\n  if [ ! -d $WORKDIR ]; then\r\n    mkdir -p ${WORKDIR} || {\r\n      log_failure_msg \"error when creates workdir $WORKDIR\"\r\n      exit 1\r\n    }\r\n  fi\r\n  return 0\r\n}\r\n\r\nfunction build_bazel()\r\n{\r\n  mkdir -p ${WORKDIR}/bin/\r\n\r\n  # force compiling bazel if version is different or not found\r\n  if [ -z \"$BAZEL_BIN\" ] || [ \"$($BAZEL_BIN version | grep -i 'label' | awk '{ print $3 }' | tr -d '-')\" != \"${BAZEL_VERSION}\" ]; then\r\n      BAZEL_BIN=\"${WORKDIR}/bin/bazel-${BAZEL_VERSION}\"\r\n  fi\r\n\r\n  PATH=\"${WORKDIR}/bin/:${PATH}\"\r\n\r\n  if [ -f \"$BAZEL_BIN\" ]; then\r\n    log_app_msg \"bazel already installed.\"\r\n    # make sure using correct bazel version\r\n    rm -f ${WORKDIR}/bin/bazel &>/dev/null\r\n    ln -sf \"${WORKDIR}/bin/bazel-${BAZEL_VERSION}\" \"${WORKDIR}/bin/bazel\" &>/dev/null\r\n    return 0\r\n  fi\r\n\r\n  cd $WORKDIR\r\n\r\n  if [ ! -f bazel-${BAZEL_VERSION}-dist.zip ]; then\r\n    wget --no-check-certificate https://github.com/bazelbuild/bazel/releases/download/${BAZEL_VERSION}/bazel-${BAZEL_VERSION}-dist.zip\r\n  fi\r\n\r\n  if [ ! -d bazel-${BAZEL_VERSION} ]; then\r\n    mkdir bazel-${BAZEL_VERSION}\r\n    unzip bazel-${BAZEL_VERSION}-dist.zip -d bazel-${BAZEL_VERSION}/\r\n    rm -f bazel-${BAZEL_VERSION}-dist.zip\r\n    cd bazel-${BAZEL_VERSION}/\r\n    if [ \"$BAZEL_PATCH\" == \"yes\" ]; then\r\n      bazel_patch || {\r\n        log_failure_msg \"error when apply patch\"\r\n        exit 1\r\n      }\r\n    fi\r\n  else\r\n    cd bazel-${BAZEL_VERSION}/\r\n  fi\r\n\r\n  ./compile.sh\r\n  if [ ! -f ./output/bazel ]; then\r\n    log_failure_msg \"error when compile bazel\"\r\n    exit 1\r\n  fi\r\n\r\n  chmod +x output/bazel\r\n  mv output/bazel \"${WORKDIR}/bin/bazel-${BAZEL_VERSION}\"\r\n  ln -sf \"${WORKDIR}/bin/bazel-${BAZEL_VERSION}\" \"${WORKDIR}/bin/bazel\" &>/dev/null\r\n\r\n  return 0\r\n}\r\n\r\nfunction toolchain()\r\n{\r\n  [ \"$CROSSTOOL_COMPILER\" != \"yes\" ] && return 0\r\n\r\n  CROSSTOOL_DIR=\"${WORKDIR}/toolchain/${CROSSTOOL_DIR}/\"\r\n\r\n  [ ! -d \"${CROSSTOOL_DIR}/${CROSSTOOL_NAME}/bin/\" ] && {\r\n    mkdir -p ${WORKDIR}/toolchain/\r\n    wget --no-check-certificate $CROSSTOOL_URL -O toolchain.tar.xz || {\r\n      log_failure_msg \"error when download crosstool\"\r\n      exit 1\r\n    }\r\n    tar xf toolchain.tar.xz -C ${WORKDIR}/toolchain/ || {\r\n      log_failure_msg \"error when extract crosstool\"\r\n      exit 1\r\n    }\r\n    rm toolchain.tar.xz &>/dev/null\r\n  }\r\n\r\n}\r\n\r\nfunction download_tensorflow()\r\n{\r\n  cd ${WORKDIR}\r\n  if [ ! -d tensorflow ]; then\r\n    git clone --recurse-submodules ${TF_GIT_URL} || return 1\r\n    cd tensorflow/\r\n  else\r\n    cd tensorflow/\r\n    $BAZEL_BIN clean &>/dev/null\r\n\r\n    # clean temp branch\r\n    git reset --hard\r\n    git clean -f -d\r\n    git checkout master\r\n    git branch -D __temp__\r\n    git pull\r\n  fi\r\n\r\n  git checkout ${TF_VERSION} || {\r\n    log_failure_msg \"error when using tensorflow version ${TF_VERSION}\"\r\n    exit 1\r\n  }\r\n\r\n  # creates a temp branch for apply some patches and reuse cloned folder\r\n  git checkout -b __temp__\r\n\r\n  # sets git local config for apply patch\r\n  git config user.email \"temp@example.com\"\r\n  git config user.name \"temp\"\r\n\r\n  if [ ! -z \"$CROSSTOOL_DIR\" ] && [ ! -z \"$CROSSTOOL_NAME\" ]; then\r\n    tf_toolchain_patch \"$CROSSTOOL_NAME\" \"$CROSSTOOL_DIR\" \"$CROSSTOOL_EXTRA_INCLUDE\" || {\r\n      log_failure_msg \"error when apply crosstool patch\"\r\n      exit 1\r\n    }\r\n  fi\r\n\r\n  git add .\r\n  git commit -m \"temp modifications\"\r\n\r\n  return 0\r\n}\r\n\r\nfunction configure_tensorflow()\r\n{\r\n  # configure tensorflow\r\n  cd ${WORKDIR}/tensorflow\r\n  $BAZEL_BIN clean\r\n  export PYTHON_BIN_PATH=$(command -v python${TF_PYTHON_VERSION})\r\n  export ${TF_BUILD_VARS}\r\n\r\n  # if need_cuda is enabled, search sdk\r\n  if [ \"$TF_NEED_CUDA\" == \"1\" ]; then\r\n     local nvcc_path=$(command -v nvcc)\r\n\r\n     if [ ! -z \"$nvcc_path\" ]; then\r\n         local cuda_location=$(echo $nvcc_path | sed 's/\\/bin\\/nvcc//')\r\n         local cuda_version=$(cat \"${cuda_location}/version.txt\" | awk '{ print $3 }' | cut -d'.' -f-2)\r\n         local cudnn_version=$(readlink $(find \"${cuda_location}/\" -iname '*libcudnn.so') | cut -d'.' -f3)\r\n\r\n         export CUDA_TOOLKIT_PATH=\"$cuda_location\"\r\n         export TF_CUDA_VERSION=$cuda_version\r\n         export TF_CUDNN_VERSION=$cudnn_version\r\n     else\r\n         export TF_NEED_CUDA=0\r\n     fi\r\n  fi\r\n\r\n  yes '' | ./configure || {\r\n      log_failure_msg \"error when configure tensorflow\"\r\n      exit 1\r\n  }\r\n  return 0\r\n}\r\n\r\nfunction build_tensorflow()\r\n{\r\n  cd ${WORKDIR}/tensorflow\r\n\r\n  if [ ! -z \"$BAZEL_AVALIABLE_RAM\" ] && [ ! -z \"$BAZEL_AVALIABLE_CPU\" ] && [ ! -z \"$BAZEL_AVALIABLE_IO\" ]; then\r\n    BAZEL_LOCAL_RESOURCES=\"--local_resources ${BAZEL_AVALIABLE_RAM},${BAZEL_AVALIABLE_CPU},${BAZEL_AVALIABLE_IO}\"\r\n  fi\r\n\r\n  [[ \"${BAZEL_EXTRA_FLAGS}\" == *\"build_pip_package\"* ]] && BAZEL_EXTRA_FLAGS+=\" --python_path=python${TF_PYTHON_VERSION}\"\r\n\r\n  /home/lid/bin/bazel build ${BAZEL_LOCAL_RESOURCES} -c opt ${BAZEL_COPT_FLAGS} --verbose_failures ${BAZEL_EXTRA_FLAGS} || return 1\r\n\r\n  # Build a wheel, if needs\r\n  [[ \"${BAZEL_EXTRA_FLAGS}\" == *\"build_pip_package\"* ]] && {\r\n    unset BDIST_OPTS\r\n    # if crosscompile was activated, builds universal wheel\r\n    if [ ! -z \"$CROSSTOOL_DIR\" ] && [ ! -z \"$CROSSTOOL_NAME\" ]; then\r\n      export BDIST_OPTS=\"--universal\"\r\n    fi\r\n\r\n    mkdir -p ${TF_BUILD_OUTPUT} || {\r\n      log_failure_msg \"error when creates output dir $TF_BUILD_OUTPUT\"\r\n      exit 1\r\n    }\r\n\r\n    # build a wheel.\r\n    bazel-bin/tensorflow/tools/pip_package/build_pip_package $TF_BUILD_OUTPUT || return 1\r\n\r\n    if [ ! -z \"$BDIST_OPTS\" ]; then\r\n      local f=\"${TF_BUILD_OUTPUT}/$(ls -t $TF_BUILD_OUTPUT | grep -i '.whl' | head -n1)\"\r\n      local new_f=\"$(echo $f | sed -rn \"s/tensorflow-([^-]+)-([^-]+)-.*/tensorflow-\\1-\\2-none-${CROSSTOOL_WHEEL_ARCH}.whl/p\")\"\r\n      mv $f $new_f\r\n      log_app_msg \"wheel was renamed of $f for $new_f\"\r\n    fi\r\n  }\r\n\r\n  [[ \"${BAZEL_EXTRA_FLAGS}\" == *\"libtensorflow\"* ]] && {\r\n    cp bazel-bin/tensorflow/libtensorflow* $TF_BUILD_OUTPUT &>/dev/null\r\n    cp bazel-bin/tensorflow/lite/libtensorflowlite* $TF_BUILD_OUTPUT &>/dev/null\r\n    cp tensorflow/c/c_api.h $TF_BUILD_OUTPUT &>/dev/null\r\n    log_app_msg \"Library files moved to $TF_BUILD_OUTPUT\"\r\n  }\r\n\r\n  log_app_msg \"Done.\"\r\n}\r\n\r\n\r\nfunction prepare_env()\r\n{\r\n\r\n  create_workdir\r\n  toolchain\r\n  download_tensorflow\r\n  echo -ne \"Workdir:            \\t${WORKDIR}\\n\"\r\n  echo -ne \"Bazel binary:       \\t${BAZEL_BIN}\\n\"\r\n  [ ! -z \"$CROSSTOOL_DIR\" ] && echo -ne \"Toolchain directory:\\t${CROSSTOOL_DIR}\\n\"\r\n}\r\n\r\n\r\nfunction main()\r\n{\r\n    prepare_env\r\n    configure_tensorflow\r\n    build_tensorflow\r\n}\r\n[ \"$2\" == \"prepare\" ] && prepare_env || main`\r\napq8053.conf\r\n`TF_PATCH=\"yes\"\r\nTF_VERSION=\"v2.0.0\"\r\n\r\n# export tensorflow variables to configure\r\nTF_BUILD_VARS=\"TF_NEED_GDR=0\"\r\nTF_BUILD_VARS+=\" TF_NEED_AWS=0\"\r\nTF_BUILD_VARS+=\" TF_NEED_GCP=0\"\r\nTF_BUILD_VARS+=\" TF_NEED_CUDA=0\"\r\nTF_BUILD_VARS+=\" TF_NEED_HDFS=0\"\r\nTF_BUILD_VARS+=\" TF_NEED_OPENCL_SYCL=0\"\r\nTF_BUILD_VARS+=\" TF_NEED_VERBS=0\"\r\nTF_BUILD_VARS+=\" TF_NEED_MPI=0\"\r\nTF_BUILD_VARS+=\" TF_NEED_MKL=0\"\r\nTF_BUILD_VARS+=\" TF_NEED_JEMALLOC=1\"\r\nTF_BUILD_VARS+=\" TF_ENABLE_XLA=0\"\r\nTF_BUILD_VARS+=\" TF_NEED_S3=0\"\r\nTF_BUILD_VARS+=\" TF_NEED_IGNITE=0\"\r\nTF_BUILD_VARS+=\" TF_NEED_ROCM=0\"\r\n\r\nBAZEL_VERSION=\"0.24.1\"\r\n\r\n\r\nBAZEL_COPT_FLAGS=\"--copt=-march=armv7-a --copt=-mfpu=neon-vfpv4 --copt=-mfloat-abi=hard --copt=-O3\"\r\nBAZEL_COPT_FLAGS+=\" --copt=-std=c++11 --copt=-DS_IREAD=S_IRUSR --copt=-DS_IWRITE=S_IWUSR\"\r\nBAZEL_COPT_FLAGS+=\" --config=monolithic --copt=-funsafe-math-optimizations\"\r\nBAZEL_COPT_FLAGS+=\" --copt=-ftree-vectorize --copt=-fomit-frame-pointer --copt=-DRASPBERRY_PI\"\r\nBAZEL_COPT_FLAGS+=\" --config=v2 --config=noaws --config=nohdfs --config=noignite --define tensorflow_mkldnn_contraction_kernel=0\"\r\nBAZEL_EXTRA_FLAGS=\"--cpu=armeabi --crosstool_top=//tools/local_arm_compiler:toolchain //tensorflow/tools/pip_package:build_pip_package\"\r\n\r\nCROSSTOOL_COMPILER=\"yes\"\r\nCROSSTOOL_URL=\"http://172.16.3.144/gcc-linaro-4.9.4-2017.01-x86_64_arm-linux-gnueabi.tar.xz\"\r\nCROSSTOOL_DIR=\"gcc-linaro-4.9.4-2017.01-x86_64_arm-linux-gnueabi\"\r\nCROSSTOOL_NAME=\"arm-linux-gnueabi\"\r\nCROSSTOOL_WHEEL_ARCH=\"linux_armv7l\"\r\n`\r\n\r\nat last run \r\nsudo ./build_tensorflow.sh  configs/apq8053.conf", "how do we fix this  when i compile ?", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34032\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34032\">No</a>\n"]}, {"number": 34031, "title": "How to add android_sdk_repository rule into workspace.bzl?", "body": "I build tensorflow without android. Now i want to add android_sdk_repository and android_ndk rule into workspace.bzl so that i can build the apk.\r\n\r\nI've tried adding :\r\nandroid_sdk_repository(\r\nname = \"androidsdk\",\r\n// Set the path to the directory the Android SDK was unzipped into.\r\npath = \"/home/shaurya/Android/Sdk\",\r\n// Set the API level of the installed SDK Platform.\r\napi_level = 28,\r\n// Set the version of the build tools (a directory inside build-tools)\r\nbuild_tools_version=\"28.0.2\"\r\n)\r\ninto workspace.bzl inside tensorflow but i'm getting this error :name 'android_sdk_repository' is not defined need help.", "comments": ["Please write configurations into **WORKSPACE** or **.bazelrc**, check the [Android quickstart\r\n](https://www.tensorflow.org/lite/guide/android#build_tensorflow_lite_locally) for more details.", "ok, but as you see, while i'm trying to write these configurations, i'm getting the above mentioned error. Can you please let me know the exact format so that I can add it into workspace.bzl?\r\n", "Rather than modifying it manually, have you tried instead running the `configure` script in the root checkout directory, and explicitly pointing the script to your Android SDK/NDK when prompted?", "@shauryad15 As suggested by @jdduke, there are some options\r\n1. try `configure`\r\n2. read the article I mentioned and write configurations to `.tf_configure.bazelrc` manually\r\n3. write your configurations into `WORKSPACE`, see this [bazel doc](https://docs.bazel.build/versions/master/be/android.html) for what/how to write.", "@jdduke Ok, so you're suggesting me to rebuild tensorflow?\r\n@freedomtan can you please provide me the link?\r\n", "@shauheen links were in previous comments already."]}, {"number": 34030, "title": "how to assign a different gpu to each session in a process .", "body": "tensorflow c API\uff1aI want to create multiple sessions for different models in a process, how to assign a different gpu to each session.\r\n", "comments": ["@liupengkd \r\n\r\nLooks like this issue is duplicate of #33996 ?. Please, confirm.Thanks!", "@liupengkd\r\n\r\n@ravikyram \r\ni have solved please check my file", "@liupengkd \r\n\r\nPlease, let me know if we can close this issue since it looks to be fixed. Thanks!"]}, {"number": 34029, "title": "error on saving RNN layer with recurrent_dropout parameter as saved_model ", "body": "```\r\nlayer_input   = Input(shape=(10, 100)) \r\n    layer_bi_rnn  = Bidirectional(GRU(units=10,recurrent_dropout=0.2, return_sequences=True))(layer_input)\r\n    layer_dense   = TimeDistributed(Dense(5))(layer_bi_rnn)\r\n    layer_act     = Activation('softmax')(layer_dense)\r\n    model         = Model([layer_input], layer_act)\r\n\r\n    model.compile(loss='categorical_crossentropy')\r\n```\r\n\r\nsave this model as saved_model on `tf-nightly 2.1.0-dev20191104` raise bug as : \r\n\r\n```\r\nAttempted to save a function b'__inference_forward_lstm_1_layer_call_fn_19037' which references a symbolic Tensor Tensor(\"dropout/mul_1:0\", shape=(None, 256), dtype=float32) that is not a simple constant. This is not supported.\r\n```\r\n\r\nafter trying to change some parameter, i got the conclusion that this issue happens because of `recurrent_dropout` parameter. Any suggestion? ", "comments": ["@deaputri ,\r\nLooks like the code provided is in complete,Can you share a simple and standalone code to reproduce the issue?Thanks!", "@deaputri ,\r\nHi, the provided code is not enough to replicate. can you please provide complete code to reproduce ?Thanks!", "```\r\nfrom tensorflow.compat.v2.keras.layers import Bidirectional, GRU, Input, Activation\r\nfrom tensorflow.compat.v2.keras.layers import TimeDistributed, Dense, Dropout\r\nfrom tensorflow.compat.v2.keras.optimizers import Adam\r\nfrom tensorflow.keras import backend as K\r\nfrom tensorflow.keras.models import Model\r\nimport tensorflow as tf\r\n\r\ndef create_model():\r\n\r\n    layer_input   = Input(shape=(20, 256)) \r\n    layer_bi_rnn  = Bidirectional(GRU(units=512, dropout=0.2, recurrent_dropout=0.2, return_sequences=True, recurrent_initializer='glorot_uniform'))(layer_input)\r\n    layer_dropout = Dropout(0.2)(layer_bi_rnn)\r\n    layer_dense   = TimeDistributed(Dense(50))(layer_dropout)\r\n    layer_act     = Activation('softmax')(layer_dense)\r\n    model         = Model([layer_input], layer_act)\r\n\r\n    model.compile(loss='categorical_crossentropy',\r\n                  optimizer=Adam(0.001))\r\n\r\n    return model\r\n\r\nmodel = create_model()\r\ntf.saved_model.save(model, 'testdata/')\r\n```", "@deaputri ,\r\nWhen tried running the given code for` tf-nightly`, i got the following error. Kindly find the [gist](https://colab.sandbox.google.com/gist/oanush/8eda00767d8043f8415d7911c6eee738/34029.ipynb) of colab.Thanks!", "same error, saving any recurrent model with dropout or recurrent_dropout will raise a error.", "@BolunHan i can save the model just using dropout. would u try?", "@oanush i'm using `tf-nightly==2.1.0-dev20191104` by using `!pip install tf-nightly==2.1.0-dev20191104`", "\r\n@deaputri I just figure out that if you call \r\n`model.save(\"some_path_not_ended_with.h5.model\") `\r\nadding dropout or recurrent_dropout will cause a error.\r\nhowever, if your given file path ended with '.h5', everything works just fine.", "@BolunHan actually i want to save the model as SavedModel. As the tensorflow documentation on [here](https://www.tensorflow.org/guide/saved_model), the code is `tf.saved_model.save(pretrained_model, \"/tmp/mobilenet/1/\")`.  I have no problem on saving as the .model of .h5 even with tensorflow only (not using tf-nightly)", "@deaputri thx. I will give it a try.\r\nI was using tf.keras to build my recurrent network\r\n`model = tf.keras.Model(inputs=inputs, outputs=outputs)\r\nmodel.save(\"given_file_path\")`\r\nsave model using tf.keras will cause the problem.\r\nI didn't test `tf.saved_model.save()` method", "@BolunHan There are lots model type we can use to save. This tensor [doc](https://www.tensorflow.org/tutorials/keras/save_and_load) may help you.", "@BolunHan Did @deaputri comment help you solve the problem?", "Closing this issue as it has been inactive for more than 3 weeks. Please add additional comments and we can open this issue again. Thanks!", "Can we open this back up? I'm having this same issue and I'm running on a relatively new tensorflow nightly deploy.", "https://github.com/tensorflow/tensorflow/issues/33247", "same error! use dropout & recurrent_dropout in GRU, when complete train and use tf.saved_model.save will raise an error. I try to save model directly without train, that will be ok.", "@NLP-ZY Just make sure the save_path of your model ended with \".h5\", which solved my own problem.", "Thanks! but I should save in tf format to use tf serving.", "@deaputri This was resolved in `tf-nightly`. Please check the [gist here](https://colab.sandbox.google.com/gist/jvishnuvardhan/172a07741aa76b82fa1a128c08e33f5a/untitled775.ipynb).\r\n\r\nI am closing this issue as it was resolved. Please feel free to reopen if the issue persists again. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34029\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34029\">No</a>\n"]}, {"number": 34028, "title": "tensorflow keras SavedModel for LSTM fails", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):  2.0\r\n- Python version: 3.6.1\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nAttempting to save LSTM based tf.keras model to a SavedModel it fails with error:\r\n\r\n`ValueError: Attempted to save a function b'__inference_lstm_layer_call_fn_5041' which references a symbolic Tensor Tensor(\"dropout/mul_1:0\", shape=(None, 2048), dtype=float32) that is not a simple constant. This is not supported.`\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n`BASE_DATA_PATH = 'C:\\Grewe\\Classes\\CS663\\Mat\\LSTM\\data' `\r\n`model_file = os.path.join(BASE_DATA_PATH, 'my_model.h5')`\r\n`model = tf.keras.models.load_model(model_file)`\r\n`model.summary()`\r\n\r\n\r\n`print('\\n# Generate predictions ')`\r\n`predictions = model.predict(valid_dataset, verbose=1 )`\r\n`print('predictions shape:', predictions.shape)`\r\n`print(predictions)`\r\n`print(len(predictions))`\r\n\r\n\r\n`saved_model_dir = os.path.join(BASE_DATA_PATH, 'saved_model\\catsdogsCNN')`\r\n`!mkdir -#p saved_model_dir`\r\n`model.save(saved_model_dir) `\r\n\r\n\r\n[pythonLSTMCode.txt](https://github.com/tensorflow/tensorflow/files/3812314/pythonLSTMCode.txt)\r\n\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nSee attached python file that contains the original training code for the sequential LSTM model defined as:\r\n`model = tf.keras.Sequential([\r\n    tf.keras.layers.Masking(mask_value=0.),\r\n    tf.keras.layers.LSTM(512, dropout=0.5, recurrent_dropout=0.5),\r\n    tf.keras.layers.Dense(256, activation='relu'),\r\n    tf.keras.layers.Dropout(0.5),\r\n    tf.keras.layers.Dense(len(LABELS), activation='softmax')\r\n])`\r\n", "comments": ["@grewe \r\n\r\nCan you please share all the supporting files (`UCF-101, .txt files`) for reproducing the issue. Thanks!", "The data is a UCF101 data set.  I have added a zip below AND it contains results from running the part of the code that performs CNN feature extraction on the video data that can take hours to do on a normal laptop.  So each .avi file has a corresponding .npy file containing the CNN feature extraction output.  So, I would block out the part of the code that contains the feature extraction....if you unzip and change the names of the directory paths it should work.\r\n\r\nIf you want I have also provided a link to my trained model saved in h5 that you could simply run the portion of the code that loads the model runs prediction to get input layer setup and then try to save.\r\nSEE attached for a reduced version of the code attached in previous comment --that only loads my stored h5 file, does a few predictions then tries to save to a SavedModel directory format and fails with error reported.   If you use this then it will run quickly \r\n\r\n**IMPORTANT:**  following the suggestion of the error, after loading my h5 file I do some predictions and get a different error when attempt SavedModel.   I do not understand why h5 format does not save the input shape information and I have to do predictions to reset when reloading model ---however if using original code that trains model and does SavedModel attempt the error is exactly the same.   \r\n\r\n[LSTM_SimpleCodeVersion.py.txt](https://github.com/tensorflow/tensorflow/files/3820468/LSTM_SimpleCodeVersion.py.txt)\r\n\r\n\r\nTraining data - BOTH videos and .npy files with feature vectors from each video to feed into [LSTM](url)\r\n[http://borg.csueastbay.edu/~grewe/CS663/Mat/LSTM/data/UCF-101_WithTraininData_InceptionV3CNN_trainedOnImageNet_Sampled_40_per_video.zip](url)\r\n\r\nModel file\r\n[http://borg.csueastbay.edu/~grewe/CS663/Mat/LSTM/data/Good17EpochModel/my_model.h5](url)", "Here are the URLs again for the 2 resources\r\n\r\nMODEL\r\n[](url)http://borg.csueastbay.edu/~grewe/CS663/Mat/LSTM/data/Good17EpochModel/my_model.h5\r\n\r\nTraining data - BOTH videos and .npy files with feature vectors from each video to feed into\r\n[](url) http://borg.csueastbay.edu/~grewe/CS663/Mat/LSTM/data/UCF-101_WithTraininData_InceptionV3CNN_trainedOnImageNet_Sampled_40_per_video.zip", "Any ideas on this issue?", "@grewe, I am unable to open the zip file that you have shared. Please help us to replicate the issue with more information. Thanks!", "@grewe \r\nAny update on this issue please. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "same error. I use parameter dropout & recurrent_dropout in GRU Layer, when I complete my train, use tf.saved_model.save(model, \"path/save/model/1\"), raise an error \"ValueError: Attempted to save a function b'__inference_gru_layer_call_fn_60270' which references a symbolic Tensor Tensor(\"dropout/mul_1:0\", shape=(None, 200), dtype=float32) that is not a simple constant. This is not supported.\"", "### Network\r\n```\r\nclass SiameseRNN(tfk.Model):\r\n    def __init__(self, embeddings):\r\n        super(SiameseRNN, self).__init__()\r\n        self.embedding_layer = tfk.layers.Embedding(embeddings.shape[0], embeddings.shape[1], trainable=False,\r\n                                                    embeddings_initializer=tf.initializers.Constant(embeddings))\r\n        self.gru_layer = tfk.layers.GRU(FLAGS.gru_units, dropout=FLAGS.rnn_dropout,\r\n                                        recurrent_dropout=FLAGS.rnn_recurrent_dropout)\r\n        self.batchnorm_layer1 = tfk.layers.BatchNormalization()\r\n        self.dropout_layer = tfk.layers.Dropout(FLAGS.dropout_rate)\r\n        self.dense_layer1 = tfk.layers.Dense(FLAGS.dense_units, activation=FLAGS.dense1_activation)\r\n        self.batchnorm_layer2 = tfk.layers.BatchNormalization()\r\n        self.dense_layer2 = tfk.layers.Dense(1, FLAGS.dense2_activation)\r\n\r\n    def call(self, inputs, training=False):\r\n        x1 = inputs[0]\r\n        x2 = inputs[1]\r\n        x1_mask = inputs[2]\r\n        x2_mask = inputs[3]\r\n        x1_embed = self.embedding_layer(x1)\r\n        x2_embed = self.embedding_layer(x2)\r\n        x1_encoding = self.gru_layer(x1_embed, mask=x1_mask, training=training)\r\n        x2_encoding = self.gru_layer(x2_embed, mask=x2_mask, training=training)\r\n        x1_x2_encoding_concat = tf.concat([x1_encoding, x2_encoding], axis=-1)\r\n        x1_x2_encoding_concat = self.batchnorm_layer1(x1_x2_encoding_concat, training=training)\r\n        x1_x2_encoding_concat = self.dropout_layer(x1_x2_encoding_concat, training=training)\r\n        hidden = self.dense_layer1(x1_x2_encoding_concat)\r\n        hidden = self.batchnorm_layer2(hidden, training=training)\r\n        y_pred = self.dense_layer2(hidden)\r\n        return y_pred\r\n```\r\n### Train & save\r\n```\r\nmodel.compile(optimizer=optimizer, loss=tf.losses.binary_crossentropy, metrics=[\"acc\"])\r\n        model.fit(x=[x1, x2, x1_mask, x2_mask], y=y, batch_size=FLAGS.batch_size, epochs=FLAGS.epochs,\r\n                  validation_data=([val_x1, val_x2, val_x1_mask, val_x2_mask], val_y))\r\n        model.summary()\r\n        tf.saved_model.save(model, FLAGS.save_path)\r\n```\r\n### Error\r\n```\r\nValueError: Attempted to save a function b'__inference_gru_layer_call_fn_60270' which references a symbolic Tensor Tensor(\"dropout/mul_1:0\", shape=(None, 200), dtype=float32) that is not a simple constant. This is not supported.\r\n```\r\nIf don't use parameter dropout & recurrent_dropout, tf.saved_mode.save can save the model successfully", "I get the same error with /opt/anaconda3/bin/python. but it works fine with my /Library/Frameworks/Python.framework/Versions/3.7/bin/python3 "]}, {"number": 34027, "title": " TFLM: print micro interpreter's tensors and nodes info as tflite.", "body": "@wangtz @suharshs \r\nPlease review it again.\r\ncalling tflite::PrintInterpreterState(&interpreter); Next will be printed:\r\n\r\nInterpreter has 8 tensors and 3 nodes\r\nInputs: 3\r\nOutputs: 5\r\n\r\nTensor   0 Conv2D_bias          kTfLiteInt32  kTfLiteMemNone         32 bytes ( 0.0 MB)  8\r\nTensor   1 MatMul_bias          kTfLiteInt32  kTfLiteMemNone         16 bytes ( 0.0 MB)  4\r\nTensor   2 Relu                 kTfLiteUInt8  kTfLiteMemNone       4000 bytes ( 0.0 MB)  1 25 20 8\r\nTensor   3 Reshape_1            kTfLiteUInt8  kTfLiteMemNone       1960 bytes ( 0.0 MB)  1 49 40 1\r\nTensor   4 add_1                kTfLiteUInt8  kTfLiteMemNone          4 bytes ( 0.0 MB)  1 4\r\nTensor   5 labels_softmax       kTfLiteUInt8  kTfLiteMemNone          4 bytes ( 0.0 MB)  1 4\r\nTensor   6 weights_quant/FakeQuantWithMinMaxVars kTfLiteUInt8  kTfLiteMemNone        640 bytes ( 0.0 MB)  1 10 8 8\r\nTensor   7 weights_quant_1/FakeQuantWithMinMaxVars/transpose kTfLiteUInt8  kTfLiteMemNone      16000 bytes ( 0.0 MB)  4 4000\r\n\r\nNode   0 Operator Builtin Code   4 DEPTHWISE_CONV_2D\r\n  Inputs: 3 6 0\r\n  Outputs: 2\r\nNode   1 Operator Builtin Code   9 FULLY_CONNECTED\r\n  Inputs: 2 7 1\r\n  Outputs: 4\r\nNode   2 Operator Builtin Code  25 SOFTMAX\r\n  Inputs: 4\r\n  Outputs: 5", "comments": []}, {"number": 34026, "title": "UnboundLocalError: local variable 'weights_normed' referenced before assignment", "body": "This is my code, it can be trained normally, but when he tests, he gives an error.\r\n![image](https://user-images.githubusercontent.com/50411057/68261608-9f313100-007b-11ea-93e8-54c497055e91.png)\r\n", "comments": ["@gyc521zsc ,\r\nCan you please assemble a minimal reproducible code snippet to reflect this issue? Also include your TensorFlow version.Thanks!", "Thank you for your reply.    tensorflow-gpu==1.1.0\r\n![image](https://user-images.githubusercontent.com/50411057/68382740-49e64400-018f-11ea-8536-f47c5164400e.png)\r\n\r\n\r\nI have a problem: LossTensor is inf or nan : Tensor had NaN values\r\n![image](https://user-images.githubusercontent.com/50411057/68382860-874ad180-018f-11ea-92c1-bc00f64d259a.png)\r\n\r\n\r\nI added a few lines of code, but it's still wrong.\r\n![image](https://user-images.githubusercontent.com/50411057/68383127-02ac8300-0190-11ea-9c05-23b61d2c50c9.png)\r\n\r\nlooking forward to your reply!\r\n\r\n\r\n", "@gyc521zsc ,\r\nCan you please provide the minimal reproducible code in colab gist or .ipynb file format so that we can try replicate the issue from our end. Thanks!", "@gyc521zsc ,\r\nAny update on the issue?Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 34025, "title": "Understanding warning \"5 out of the last 5 calls to <function XXX> triggered tf.function retracing\"", "body": "**System information**\r\n- Have I written custom code: Yes, below.\r\n- Linux Ubuntu 16.04 \r\n- TensorFlow 2.1.0-dev20191103, binary install.\r\n- Python 3.6\r\n- CUDA 10.0 / cnDNN 7.6.4\r\n- 4 * NVIDIA TITAN X (12GB)\r\n\r\nI defined a very simple training script with a custom loss function and `.fit()` as below. The `loss_fn`  is very simple and I think every time it takes tensors **of the same shape and type**. But I'm getting the **following warning message**. Interesting is that I'm getting the message only when training **with multiple GPUs**. Is it a bug? Is it harmful? Is it really affecting the computational cost?\r\n\r\nWarning message:\r\n```\r\nWARNING:tensorflow:5 out of the last 5 calls to <function loss_fn at 0x7f0070ef0e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_re\r\nlax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\r\n```\r\nCode:\r\n````python\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras.layers import (Conv2D, Conv3D, Dense)\r\n\r\n\r\n@tf.function\r\ndef loss_fn(y_pred, y_true):\r\n    return tf.reduce_mean(tf.math.square(y_pred - y_true))\r\n\r\nif __name__ == \"__main__\":\r\n\r\n    BATCH_SIZE_PER_SYNC = 4\r\n    strategy = tf.distribute.MirroredStrategy()\r\n    num_gpus = strategy.num_replicas_in_sync\r\n    global_batch_size = BATCH_SIZE_PER_SYNC * num_gpus\r\n    print('num GPUs: {}, global batch size: {}'.format(num_gpus, global_batch_size))\r\n\r\n\r\n    # fake data ------------------------------------------------------\r\n    fakea = np.random.rand(global_batch_size, 10, 200, 200, 128).astype(np.float32)\r\n    targets = np.random.rand(global_batch_size, 200, 200, 14).astype(np.float32)\r\n\r\n    fakea = tf.constant(fakea)\r\n    targets = tf.constant(targets)\r\n\r\n    # tf.Dataset ------------------------------------------------------\r\n    def gen():\r\n        while True:\r\n            yield (fakea, targets)\r\n\r\n    dataset = tf.data.Dataset.from_generator(gen,\r\n        (tf.float32, tf.float32),\r\n        (tf.TensorShape(fakea.shape), tf.TensorShape(targets.shape)))\r\n\r\n    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\r\n\r\n    # training ------------------------------------------------------\r\n    callbacks = [tf.keras.callbacks.TensorBoard(log_dir='./logs')]\r\n    training = True\r\n    with strategy.scope():\r\n        va = keras.Input(shape=(10, 200, 200, 128), dtype=tf.float32, name='va')\r\n        x = Conv3D(64, kernel_size=3, strides=1, padding='same')(va)\r\n        x = Conv3D(64, kernel_size=3, strides=1, padding='same')(x)\r\n        x = Conv3D(64, kernel_size=3, strides=1, padding='same')(x)\r\n        x = tf.reduce_max(x, axis=1, name='maxpool')                         \r\n        b = Conv2D(14, kernel_size=3, padding='same')(x)\r\n        model = keras.Model(inputs=va, outputs=b, name='net')\r\n        optimizer = keras.optimizers.RMSprop()\r\n\r\n        model.compile(optimizer=optimizer, loss=loss_fn)\r\n        model.fit(x=dataset, epochs=10, steps_per_epoch=100, callbacks=callbacks)\r\n````\r\n", "comments": ["I get the same error if trying to predict in a for-loop (due to variable length inputs).\r\n\r\nI have to call `model.predict(np.expand_dims(xi, axis = 0))` on each sample individually, or tensorflow will attempt to concatenate predictions and fail.\r\n\r\nThis is probably calling something several times, when it shouldn't.", "I have the same issue when training my model. Any updates on this?", "same issue", "same here, only with multi gpu setup, singel gpu has no warnings", "I think the warning is red herring. The function is traced on every GPU, so presumably if one has 5 or more than 5 GPUs on the machine, the warning will be printed out. Perhaps try adding a print statement inside the tf.function (https://www.tensorflow.org/tutorials/customization/performance), and see how many times the function has actually been traced? As long as it not traced per step, it should be fine. If you have less than 5 GPUs though, it might be a bug.", "When calling a simple RNN with input sequences of various lengths, it seems that the model gets traced once for each sequence length, as you can see in [this Colab](https://colab.research.google.com/drive/1Aj51rVjkpUesVz3dSTvih7kW9CT_QjRA). Here's the code:\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n\r\nmodel = keras.models.Sequential([\r\n    keras.layers.SimpleRNN(10, return_sequences=True, input_shape=[None, 4]),\r\n    keras.layers.Dense(1)\r\n])\r\nmodel.compile(loss=\"mse\", optimizer=\"nadam\")\r\n\r\nX_train = tf.random.uniform(shape=[100, 50, 4])\r\ny_train = tf.random.uniform(shape=[100, 1])\r\nmodel.fit(X_train, y_train)\r\n\r\nfor length in range(1, 20):\r\n    X_new = tf.random.uniform([1, length, 4])\r\n    model.predict(X_new)\r\n```\r\n\r\nI get the dreaded warning:\r\n\r\n```\r\nWARNING:tensorflow:5 out of the last 5 calls to <function _make_execution_function.<locals>.distributed_function at 0x7fe3de7c0268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\r\nWARNING:tensorflow:6 out of the last 6 calls to <function _make_execution_function.<locals>.distributed_function at 0x7fe3de7c0268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\r\n...\r\n```\r\n\r\nPerhaps there's a way to force the model to use a single graph instead of tracing a new one for each input shape?", "> I think the warning is red herring. The function is traced on every GPU\r\n\r\nI think we had the same idea, exactly as I stated here #33649\r\n", "Hi @bela127 and @ckkuang ,\r\nIn my code example, I'm not using any GPU at all. Just calling an RNN with input sequences of varying lengths.", "UPDATE:\r\nis it possible its only a problem with the:\r\n`keras.layers.SimpleRNN(10, return_sequences=True, input_shape=[None, 4])`\r\nIm not sure but `return_sequences=TRUE` when im correct will return the hole RNN Sequence, not just the last element, so for different sized inputs you will get different sized outputs.\r\n`Dens` needs a fixed sized input.\r\nSo it will be retraced every time.\r\n\r\nwhen you try to use the same dense layer for every single output you cant do this with `Sequential`, because it would be a parallel operation. If this is the case i my have a solution for you...\r\n\r\nOLD:\r\nyes i see @ageron,\r\nhad the same problem with Keras functional api, it seams the functional keras api has problems with variable length inputs, different than the batchdim\r\n\r\na workaround is using the layer class api and subclass Keras Layer.\r\nhere you can update the call method with tf.function annotation with \"relax_shape:\r\n\r\n`@tf.function( experimental_relax_shapes=True)`\r\n\r\nor explicit:\r\n\r\n`self.call = tf.function(self.call,input_signature=[(tf.TensorSpec([None, None, None, 3], dtype=tf.float32), (tf.TensorSpec([None], dtype=tf.float32), tf.TensorSpec([None, 15, 3], dtype=tf.float32)), tf.TensorSpec([], dtype=tf.float32), tf.TensorSpec([], dtype=tf.float32))])`\r\nin `__init__` or `build`\r\n\r\nBut i agree the functional api should although support this.", "I am also getting this error on a classical functional model without `tf.function` and variable-length inputs in a for loop using `predict`. This happens only in tf 2.2.0rc2, and as soon as I switch back to tf 2.1 the problem disappears.", "I am also facing the same issue with Tensorflow 2.2.0-rc2 while training with variable lengths in a loop.", "@ywpkwon I tried the code you originally linked in a colab with tf-nightly-gpu and I don't see the warnings anymore. Please re-open if you still see the warning.\r\n\r\n@ageron @bela127, others- Please file a separate ticket for the RNN issue or other issues without multi GPU. \r\n\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34025\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34025\">No</a>\n", "@guptapriya \r\n\r\nHere is a new code snippet you can use to reproduce the issue in tf 2.2.0rc2:\r\n```python\r\nfrom random import randint\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import Conv1D\r\nfrom tensorflow.keras.models import Sequential\r\n\r\nmodel = Sequential()\r\nmodel.add(Conv1D(8, 3))\r\nmodel.build([None, 12, 1])\r\n\r\npredict_tensors = [\r\n    tf.random.normal([randint(1, 8), randint(4, 40), 1])\r\n    for _ in range(10)\r\n]\r\nfor t in predict_tensors:\r\n    _ = model.predict(t)\r\n```\r\n\r\nI am using Python 3.6.8, on Ubuntu 16.04, without GPU and tf installed from pip.\r\nThis got me the following warnings:\r\n```\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0406 09:22:52.525994 139643050075904 def_function.py:598] 5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f00a7fc1268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\r\nW0406 09:22:52.615050 139643050075904 def_function.py:598] 6 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f00a7fc1268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\r\nW0406 09:22:52.653312 139643050075904 def_function.py:598] 7 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f00a7fc1268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\r\nW0406 09:22:52.706550 139643050075904 def_function.py:598] 8 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f00a7fc1268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\r\n```\r\n\r\nDo you want me to file a separate ticket? I think it looks like the same issue.", "@zaccharieramzi - yes please file a separate ticket as this is a Keras issue without distribution strategy. The error message might be the same but the root causes are different. ", "I have same issue with my model trained with MirroredStrategy().\r\nUsing TF2.1 with four TitanXp\r\n\r\n```\r\nWARNING:tensorflow:11 out of the last 11 calls to <function _make_execution_function.<locals>.distributed_function at 0x7f85182bab00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\r\n```", "@SangwonSUH, are you using variable inputs (see https://github.com/tensorflow/tensorflow/issues/38561)?", "> @SangwonSUH, are you using variable inputs (see #38561)?\r\n\r\nYes, I do\r\n```\r\ntf.keras.layers.Input((128, None, 6))\r\n```\r\nI will fix the input layer of my model, and try prediction again.\r\nThank you!", "> I have same issue with my model trained with MirroredStrategy().\r\n> Using TF2.1 with four TitanXp\r\n> \r\n> ```\r\n> WARNING:tensorflow:11 out of the last 11 calls to <function _make_execution_function.<locals>.distributed_function at 0x7f85182bab00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\r\n> ```\r\n\r\nI have a very similar issue using MirroredStrategy:\r\n\r\n`WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9dc8698598> triggered tf.function retracing.`\r\n\r\nHowever, I placed a print statement inside the tf.function distributed training step and it appears to only be executed twice - matching the number of GPUs I am distributing onto. It may be an erroneous message, which is annoying, as it spams the output.\r\n\r\n I do notice that mirroredstrategy is significantly (10x) slower than using a single GPU, which I did not expect.", "you have to place the print statement in `make_predict_function` not in `distributed training step`\r\nfor debugging the statement should be placed in the exact function that is mentioned in the message:\r\n`WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9dc8698598> triggered tf.function retracing.`\r\n\r\nI guess it relay is traced every time if it does not stop appearing in the output after a few runs, that is why your training is so slow.", "> you have to place the print statement in `make_predict_function` not in `distributed training step`\r\n> for debugging the statement should be placed in the exact function that is mentioned in the message:\r\n> `WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9dc8698598> triggered tf.function retracing.`\r\n> \r\n> I guess it relay is traced every time if it does not stop appearing in the output after a few runs, that is why your training is so slow.\r\n\r\n I cannot place a print function inside make_predict_function as that isn't anything I've written - it's tensorflow code. Also note it is 'predict_function' that is causing the issue. This implies that it's the input causing the retracing.\r\n\r\nHowever, the error also only appears when distributing, not when running on one GPU.", "tf.functions can only handle a pre defined input shape, if the shape changes, or if diferent python objects get passed, tensorflow automagically rebuilds the function.\r\n\r\nso i would suggest you check and print all the input parameter that get passed to `Model.make_predict_function.<locals>.predict_function` if a input is no tensor or if the shape changes you have found the problem", "> tf.functions can only handle a pre defined input shape, if the shape changes, or if diferent python objects get passed, tensorflow automagically rebuilds the function.\r\n> \r\n> so i would suggest you check and print all the input parameter that get passed to `Model.make_predict_function.<locals>.predict_function` if a input is no tensor or if the shape changes you have found the problem\r\n\r\n The inputs to my training function that calls strategy.run() print out to:\r\n\r\n```\r\nPerReplica:{ \r\n  0: Tensor(\"reals:0\", shape=(16, 256, 256, 3), dtype=float32)\r\n  1: Tensor(\"reals_1:0\", shape=(16, 256, 256, 3), dtype=float32)\r\n} \r\n```\r\nHowever, I don't think I have any control over this, as these come directly from a distributed tf.dataset.\r\n\r\nIf we print out the input for the actual distributed training function, we see as expected:\r\n\r\n```\r\nTensor(\"reals:0\", shape=(16, 256, 256, 3), dtype=float32)\r\nTensor(\"reals_1:0\", shape=(16, 256, 256, 3), dtype=float32)  \r\n```", "the training loop code could be helpful, but i think this is not a bug and could be a question for stack overflow.\r\n\r\none way or the other, could you post a minimal example of your training loop code, that reproduces your issue, so one can check if its a bug or a implementation error on your side?\r\n", "> the training loop code could be helpful, but i think this is not a bug and could be a question for stack overflow.\r\n> \r\n> one way or the other, could you post a minimal example of your training loop code, that reproduces your issue, so one can check if its a bug or a implementation error on your side?\r\n\r\nThis is all I'm really doing:\r\n```\r\ndataset = strategy.experimental_distribute_dataset(dataset)\r\n\r\n@tf.function(experimental_relax_shapes=True)\r\ndef distributed_train_step(self, data):\r\n    per_replica_losses = self.strategy.run(self.train_op, args=(data,))\r\n    reduced_loss = self.strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=0)\r\n\r\n    return reduced_loss\r\n\r\nfor batch in dataset:\r\n    distributed_train_step(batch)\r\n```\r\n\r\nMy trainop is standard, calls model(inputs) and calculates a simple loss. The only 'strange' thing I may be doing is generating some noise inside the training op using tf.random.normal and calling model2(noise) but I fail to see how a tensorflow op could cause this issue,\r\n\r\n\r\n\r\n\r\n", "like i said earlier, the input to or what ever happens in your : `Model.make_predict_function.<locals>.predict_function` courses the retracing.\r\n\r\nwith only the code you have provided a reproduction of the issue is not possible.\r\n\r\nthe relevant information is inside `Model.make_predict_function.<locals>.predict_function` and the inputs to this function.\r\n\r\nthis is where the issue originates, are you using any python code in your model or do you produce differently shaped outputs inside the model? what model are you using?\r\n\r\none thing im missing in your training loop is the `with strategy:` block, do you have this in your code? your model should be created inside this scope and the loop should run in the scope, the rest of your training loop seams to be fine.", "me too.. how to solve this problem ? ", "I have the same problem too... model.predict_on_batch(input) gives the warning as \r\n\r\n\"WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f8fe3fdc940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\" \r\n\r\nHow to solve this problem??", "I was getting this same warning message. Using a LSTM model with variable sequence lengths. Upgrading from TF 2.2 to TF 2.3 seems to have fixed it.", "Am using only 1 gpu and still am facing this retracing issue.\r\nAfter trying out verious fixes to this problem by searching over the internet, nothing worked. Including tf-nightly-gpu since its first of all not detecting my gpu. \r\n**So I have just downgraded from tf 2.3.0 to tf 2.2.1 and it has fixed this issue for now.**", "same problem with tf 2.3.0, without gpu", "Same here. Any updates?", "same here with tf 2.3.1 without GPU:\r\nWARNING:tensorflow:6 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fc1f07e1ca0> triggered tf.function retracing. \r\n\r\nI did pass tensors with different shapes into the predict function because I have different batch sizes. But how to solve it? Align all the batches to the same size?", "Facing same issue, when I try to read different size images in colab.", "@vikxoxo\r\n\r\n> Facing same issue, when I try to read different size images in colab.\r\n\r\nyes, that is normal, a tf-function can only compute the input for a fixed size.\r\nif you use different sized images the function needs to be traced for every image size, which is slow and that is why you get a warning.\r\n\r\nmost layers do not (yet) support variable image shapes, some just cant (mathematical)", "@RuralHunter \r\n\r\n> I did pass tensors with different shapes into the predict function because I have different batch sizes. But how to solve it? Align all the batches to the same size?\r\n\r\nfor batch dimensions it is a little  bit difference, if all your operations in your model support a variable batch dimension it can work without retracing.\r\nbut if you build your own layer and make it a tf-function you have to take special care that it supports a variable dimension.\r\ninfo is here: https://www.tensorflow.org/api_docs/python/tf/function\r\nyou will need: **input_signature** or  **experimental_relax_shapes** \r\n\r\n", "Facing this issue. Please help ! ", "I had tensorflow 2.1.0 and i am using python2.7 so what i did is that i downgraded tensorflow to  1.1.0 and the error is gone. seems like that fixed the issue. ", "@zubaidah93 , [Python 2 is officially dead](https://www.python.org/psf/press-release/pr20191220/?utm_source=thenewstack&utm_medium=website&utm_campaign=platform), it is not supported anymore, there are no updates anymore, including security updates, so it is even unsafe to use it. You should really upgrade to Python 3. And TensorFlow 1.1.0 is several years old. If you want to use TensorFlow 1, you should install TensorFlow 1.15 instead. But TensorFlow 2 is much better.", "I solved this issue by replacing model.fit() with for loop, just like this:\r\nAt first, my model.fit():\r\n`\r\nyoro_model.fit(x=my_train_batch_generator,\r\n                steps_per_epoch=int(len(files_path_list_train) // BATCH_SIZE),\r\n                epochs=EPOCH,   \r\n                verbose=1,  \r\n                workers= 48,   \r\n                validation_data = my_test_batch_generator,\r\n                validation_steps=int(len(files_path_list_test)//BATCH_SIZE) \r\n                )\r\n`\r\n\r\nafter changing the code above to code below:\r\n`num_batches = int(len(files_path_list_train) // BATCH_SIZE)\r\nnum_val = int(len(files_path_list_test) // BATCH_SIZE)\r\noptimizer = tf.keras.optimizers.Adam()\r\nfor i in range(EPOCH):\r\n    print(\"\\n----------epoch %d \"%i)\r\n    for batch_index in range(num_batches):\r\n        X, Y = my_train_batch_generator.__getitem__(batch_index)\r\n        # Y = Y.astype('float32')\r\n        with tf.GradientTape() as tape:\r\n            tape.watch(yoro_model.variables)\r\n            y_pred = yoro_model(X)\r\n            loss = yoro_loss(y_true=Y, y_pred=y_pred)\r\n            print(\"batch %d : train loss %f\"%(batch_index,loss.numpy()))\r\n    grads = tape.gradient(loss, yoro_model.variables)\r\n    optimizer.apply_gradients(grads_and_vars=zip(grads,yoro_model.variables))\r\n    # validation\r\n    for val_batch_index in range(num_val):\r\n        X_val, Y_val = my_test_batch_generator.__getitem__(val_batch_index)\r\n        y_val_pred = yoro_model(X_val)\r\n        val_loss = yoro_loss(y_true=Y_val, y_pred=y_val_pred)\r\n        print(\"batch %d : val loss %f\"%(val_batch_index,val_loss.numpy()))`\r\nthe WARNING disappeared.\r\n\r\nHope it helps!", "I found my problem was because of multi-threading. I added an empty predict() call before launching threads and the retrace warning was gone.", "> Am using only 1 gpu and still am facing this retracing issue.\r\n> After trying out verious fixes to this problem by searching over the internet, nothing worked. Including tf-nightly-gpu since its first of all not detecting my gpu.\r\n> **So I have just downgraded from tf 2.3.0 to tf 2.2.1 and it has fixed this issue for now.**\r\n\r\nI got the same issue. \r\nnow downgrade to tf 2.2.1 working. Thanks "]}, {"number": 34024, "title": "Group Convolution not working in TF 2.0.0", "body": "The merged PR #25818 enables group convolution by allowing the input's depth to be multiples of the filter's in_depth parameter rather than exactly equal.\r\n\r\nHowever, as you can see below, whenever I attempt to perform a group convolution, it results in an ambiguous error \"No Algorithm Found\". Same issue if I make the filter's in_depth = 1.\r\nMaking the convolution filter in_depth parameter equal to the channels of the input (=16) it works (regular convolution).\r\n\r\nAm I missing something or is this not supported for eager execution?\r\n\r\nTensorflow installed via: pip3 install --upgrade tensorflow-gpu\r\nOS: Ubuntu 18.04.1, kernel: 5.0.0-15 lowlatency.\r\nGTX 1080Ti , cuda: 10.1 , cudnn-7.6.0\r\n\r\n(I left tensorflow initialization log in case it provides relevant information)\r\n```\r\nPython 3.7.4 (default, Aug 13 2019, 20:35:49)\r\n[GCC 7.3.0] :: Anaconda, Inc. on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> print(tf.version.GIT_VERSION, tf.version.VERSION)\r\nv2.0.0-rc2-26-g64c3d38 2.0.0\r\n>>> tf.nn.conv2d(tf.random.normal((11,13,17,16)), tf.random.normal((3,5,16//2,7)), padding='SAME',strides=[1,1,1,1]).shape\r\n2019-11-05 18:00:39.800225: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2019-11-05 18:00:39.841613: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-05 18:00:39.842211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties:\r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.6705\r\npciBusID: 0000:1d:00.0\r\n2019-11-05 18:00:39.842279: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-05 18:00:39.843083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties:\r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.645\r\npciBusID: 0000:1e:00.0\r\n2019-11-05 18:00:39.843414: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2019-11-05 18:00:39.844684: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n2019-11-05 18:00:39.846034: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\r\n2019-11-05 18:00:39.847021: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\r\n2019-11-05 18:00:39.849473: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\r\n2019-11-05 18:00:39.850970: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\r\n2019-11-05 18:00:39.855126: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2019-11-05 18:00:39.855289: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-05 18:00:39.856005: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-05 18:00:39.856903: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-05 18:00:39.857518: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-05 18:00:39.858304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\r\n2019-11-05 18:00:39.858525: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-11-05 18:00:39.877459: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3699425000 Hz\r\n2019-11-05 18:00:39.878231: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563f2440c8b0 executing computations on platform Host. Devices:\r\n2019-11-05 18:00:39.878267: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\r\n2019-11-05 18:00:40.042173: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-05 18:00:40.068620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-05 18:00:40.069774: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x563f244af3e0 executing computations on platform CUDA. Devices:\r\n2019-11-05 18:00:40.069799: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1\r\n2019-11-05 18:00:40.069819: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (1): GeForce GTX 1080 Ti, Compute Capability 6.1\r\n2019-11-05 18:00:40.071588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-05 18:00:40.072539: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties:\r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.6705\r\npciBusID: 0000:1d:00.0\r\n2019-11-05 18:00:40.072670: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-05 18:00:40.073607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 1 with properties:\r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.645\r\npciBusID: 0000:1e:00.0\r\n2019-11-05 18:00:40.073652: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2019-11-05 18:00:40.073666: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n2019-11-05 18:00:40.073678: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\r\n2019-11-05 18:00:40.073688: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\r\n2019-11-05 18:00:40.073699: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\r\n2019-11-05 18:00:40.073710: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\r\n2019-11-05 18:00:40.073720: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2019-11-05 18:00:40.073771: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-05 18:00:40.074334: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-05 18:00:40.074891: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-05 18:00:40.075465: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-05 18:00:40.075960: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0, 1\r\n2019-11-05 18:00:40.075991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n2019-11-05 18:00:40.077335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-11-05 18:00:40.077350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 1\r\n2019-11-05 18:00:40.077358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N Y\r\n2019-11-05 18:00:40.077364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 1:   Y N\r\n2019-11-05 18:00:40.077488: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-05 18:00:40.078794: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-05 18:00:40.080681: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-05 18:00:40.081210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10478 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:1d:00.0, compute capability: 6.1)\r\n2019-11-05 18:00:40.081733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-11-05 18:00:40.082722: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10479 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:1e:00.0, compute capability: 6.1)\r\n2019-11-05 18:00:40.562956: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n2019-11-05 18:00:41.155546: W tensorflow/core/framework/op_kernel.cc:1622] OP_REQUIRES failed at conv_ops.cc:1069 : Not found: No algorithm worked!\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/bahaa/miniconda3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\", line 1913, in conv2d_v2\r\n    name=name)\r\n  File \"/home/bahaa/miniconda3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py\", line 2010, in conv2d\r\n    name=name)\r\n  File \"/home/bahaa/miniconda3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\", line 1039, in conv2d\r\n    _six.raise_from(_core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.NotFoundError: No algorithm worked! [Op:Conv2D]\r\n>>> tf.nn.conv2d(tf.random.normal((11,13,17,16)), tf.random.normal((3,5,16,7)), padding='SAME',strides=[1,1,1,1]).shape\r\nTensorShape([11, 13, 17, 7])\r\n```\r\n\r\n\r\n", "comments": ["Could reproduce the issue with TF 2.0 on colab.\r\nPlease take a look at the [gist](https://colab.sandbox.google.com/gist/gadagashwini/3ea3118c557f04b1f6deda7665b636fd/untitled238.ipynb). Thanks!", "I've implemented a GroupConv2D as a tf.keras.layers.Layer by taking inspiration from [the sources of Conv2D](https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/layers/convolutional.py#L391-L498).\r\nThis seems to work using tensorflow 2.0.0 (however, only on GPU. On CPU it crashes if groups != 1, because there is no implementation for the group convolutions).\r\n\r\nThe thing is that `tf.nn.conv2d` seems to be the only thing that supports it right now.\r\nI also tried to add the group parameter to the base class `tf.python.keras.layers.convolutional.Conv`, but the conv op that end up being called just crashes with the group-based kernel shape.\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.python.framework import tensor_shape\r\nfrom tensorflow.python.keras.utils import conv_utils\r\nimport tensorflow.keras.activations as activations\r\nimport tensorflow.keras.regularizers as regularizers\r\nimport tensorflow.keras.initializers as initializers\r\nimport tensorflow.keras.constraints as constraints\r\nfrom tensorflow.python.ops import array_ops\r\nfrom tensorflow.python.ops import nn\r\n\r\n\r\nclass GroupConvBase(tf.keras.layers.Layer):\r\n\r\n    def __init__(self, rank, filters, kernel_size, groups=1, strides=1, padding='VALID', data_format=None,\r\n                 dilation_rate=1,\r\n                 activation=None, use_bias=True, kernel_initializer='glorot_uniform',\r\n                 bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None,\r\n                 kernel_constraint=None, bias_constraint=None, **kwargs):\r\n        super().__init__(activity_regularizer=activity_regularizer, **kwargs)\r\n        if filters % groups != 0:\r\n            raise ValueError(\"Groups must divide filters evenly, but got {}/{}\".format(filters, groups))\r\n\r\n        self.filters = filters\r\n        self.groups = groups\r\n        self.kernel_size = conv_utils.normalize_tuple(kernel_size, rank, 'kernel_size')\r\n        self.data_format = data_format\r\n        self.padding = padding\r\n        self.strides = conv_utils.normalize_tuple(strides, rank, 'strides')\r\n        self.dilation_rate = conv_utils.normalize_tuple(dilation_rate, rank, 'dilation_rate')\r\n        self.activation = activations.get(activation)\r\n        self.use_bias = use_bias\r\n        self.kernel_initializer = initializers.get(kernel_initializer)\r\n        self.bias_initializer = initializers.get(bias_initializer)\r\n        self.kernel_regularizer = regularizers.get(kernel_regularizer)\r\n        self.bias_regularizer = regularizers.get(bias_regularizer)\r\n        self.kernel_constraint = constraints.get(kernel_constraint)\r\n        self.bias_constraint = constraints.get(bias_constraint)\r\n\r\n    def build(self, input_shape):\r\n        input_shape = tensor_shape.TensorShape(input_shape)\r\n        if conv_utils.normalize_data_format(self.data_format) == 'channels_first':\r\n            channel_axis = 1\r\n        else:\r\n            channel_axis = -1\r\n        if input_shape.dims[channel_axis].value is None:\r\n            raise ValueError('The channel dimension of the inputs '\r\n                             'should be defined. Found `None`.')\r\n        input_dim = int(input_shape[channel_axis])\r\n        kernel_shape = self.kernel_size + (input_dim // self.groups, self.filters)\r\n\r\n        self.kernel = self.add_weight(\r\n            name='kernel',\r\n            shape=kernel_shape,\r\n            initializer=self.kernel_initializer,\r\n            regularizer=self.kernel_regularizer,\r\n            constraint=self.kernel_constraint,\r\n            trainable=True,\r\n            dtype=self.dtype)\r\n        if self.use_bias:\r\n            self.bias = self.add_weight(\r\n                name='bias',\r\n                shape=(self.filters,),\r\n                initializer=self.bias_initializer,\r\n                regularizer=self.bias_regularizer,\r\n                constraint=self.bias_constraint,\r\n                trainable=True,\r\n                dtype=self.dtype)\r\n        else:\r\n            self.bias = None\r\n\r\n        self.built = True\r\n\r\n    def call(self, inputs):\r\n        outputs = tf.nn.conv2d(inputs, self.kernel, strides=self.strides,\r\n                                       data_format=self.data_format, dilations=self.dilation_rate,\r\n                                       name=self.name,\r\n                                       padding=self.padding)\r\n\r\n        if self.use_bias:\r\n            if self.data_format == 'channels_first':\r\n                if self.rank == 1:\r\n                    # nn.bias_add does not accept a 1D input tensor.\r\n                    bias = array_ops.reshape(self.bias, (1, self.filters, 1))\r\n                    outputs += bias\r\n                else:\r\n                    outputs = nn.bias_add(outputs, self.bias, data_format='NCHW')\r\n            else:\r\n                outputs = nn.bias_add(outputs, self.bias, data_format='NHWC')\r\n\r\n        if self.activation is not None:\r\n            return self.activation(outputs)\r\n        return outputs\r\n\r\n    def get_config(self):\r\n        config = {\r\n            'filters': self.filters,\r\n            'kernel_size': self.kernel_size,\r\n            \"groups\": self.groups,\r\n            'strides': self.strides,\r\n            'padding': self.padding,\r\n            'data_format': self.data_format,\r\n            'dilation_rate': self.dilation_rate,\r\n            'activation': activations.serialize(self.activation),\r\n            'use_bias': self.use_bias,\r\n            'kernel_initializer': initializers.serialize(self.kernel_initializer),\r\n            'bias_initializer': initializers.serialize(self.bias_initializer),\r\n            'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\r\n            'bias_regularizer': regularizers.serialize(self.bias_regularizer),\r\n            'activity_regularizer':\r\n                regularizers.serialize(self.activity_regularizer),\r\n            'kernel_constraint': constraints.serialize(self.kernel_constraint),\r\n            'bias_constraint': constraints.serialize(self.bias_constraint)\r\n        }\r\n        return {list(super(GroupConvBase, self).get_config().items()) + list(config.items())}\r\n\r\n\r\nclass GroupConv2D(GroupConvBase):\r\n\r\n    def __init__(self, filters, kernel_size,\r\n                 groups, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None,\r\n                 use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None,\r\n                 bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None,\r\n                 **kwargs):\r\n        super(GroupConv2D, self).__init__(rank=2,\r\n                                          filters=filters, kernel_size=kernel_size, groups=groups, strides=strides,\r\n                                          padding=padding.upper(),\r\n                                          data_format=data_format, dilation_rate=dilation_rate,\r\n                                          activation=activations.get(activation),\r\n                                          use_bias=use_bias, kernel_initializer=initializers.get(kernel_initializer),\r\n                                          bias_initializer=initializers.get(bias_initializer),\r\n                                          kernel_regularizer=regularizers.get(kernel_regularizer),\r\n                                          bias_regularizer=regularizers.get(bias_regularizer),\r\n                                          activity_regularizer=regularizers.get(activity_regularizer),\r\n                                          kernel_constraint=constraints.get(kernel_constraint),\r\n                                          bias_constraint=constraints.get(bias_constraint),\r\n                                          **kwargs)\r\n\r\n\r\nif __name__ == '__main__':\r\n    gc = GroupConv2D(16, (3, 3), groups=4, padding=\"same\")\r\n    with tf.GradientTape() as tape:\r\n        out = gc(tf.random.normal(shape=(8, 32, 32, 16)))\r\n        summed = tf.reduce_sum(out)\r\n        grad = tape.gradient(summed, gc.variables)\r\n        print(grad)\r\n```", "@RunOrVeith Thanks for verifying that it works for GPU.\r\nI realized my mistake, my bad!!\r\nThe filter output should also be a multiple of the groups G,  (since any operation will produce G output featuremaps). Therefore, \r\n```\r\n>>> C= 30  #input's depth\r\n>>> G= 5 #a divisor of the input's depth\r\n>>> K= 7 #multiples of G for the ouput featuremaps\r\n>>> tf.nn.conv2d(tf.random.normal((11,13,17,C)), tf.random.normal((3,5,C//G, G*K)), padding='SAME',strides=[1,1]).shape \r\nTensorShape([11, 13, 17, 35])\r\n```\r\nwhile\r\n```\r\n>>> tf.nn.conv2d(tf.random.normal((11,13,17,C)), tf.random.normal((3,5,C//G, G*K + 1)), padding='SAME',strides=[1,1]).shape \r\n\r\n---------------------------------------------------------------------------\r\nNotFoundError                             Traceback (most recent call last)\r\n<ipython-input-27-10c09d6bfa5d> in <module>\r\n      2 G= 5 #a divisor of the input's depth\r\n      3 K= 7 #multiples of G for the ouput featuremaps\r\n----> 4 tf.nn.conv2d(tf.random.normal((11,13,17,C)), tf.random.normal((3,5,C//G, G*K+1)), padding='SAME',strides=[1,1]).shape\r\n\r\n~/miniconda3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py in conv2d_v2(input, filters, strides, padding, data_format, dilations, name)\r\n   1911                 data_format=data_format,\r\n   1912                 dilations=dilations,\r\n-> 1913                 name=name)\r\n   1914 \r\n   1915 \r\n\r\n~/miniconda3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_ops.py in conv2d(input, filter, strides, padding, use_cudnn_on_gpu, data_format, dilations, name, filters)\r\n   2008                            data_format=data_format,\r\n   2009                            dilations=dilations,\r\n-> 2010                            name=name)\r\n   2011 \r\n   2012 \r\n\r\n~/miniconda3.7/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_nn_ops.py in conv2d(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\r\n   1037       else:\r\n   1038         message = e.message\r\n-> 1039       _six.raise_from(_core._status_to_exception(e.code, message), None)\r\n   1040   # Add nodes to the TensorFlow graph.\r\n   1041   if not isinstance(strides, (list, tuple)):\r\n\r\n~/miniconda3.7/lib/python3.7/site-packages/six.py in raise_from(value, from_value)\r\n\r\nNotFoundError: No algorithm worked! [Op:Conv2D]\r\n```\r\n\r\nI think whenever the keras Conv2D gets to support this, there should be checks for the filter output as well (divides by G evenly). Ie, both input's depth and output's depth should divide by G evenly.\r\nThanks again!\r\n\r\n#25818 was only about supporting group convolutions through cuDNN, I am not sure whether I should keep this issue open because the CPU one isn't implemented yet (given the generic issue title). \r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34024\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/34024\">No</a>\n", "> I've implemented a GroupConv2D as a tf.keras.layers.Layer by taking inspiration from [the sources of Conv2D](https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/layers/convolutional.py#L391-L498).\r\n> This seems to work using tensorflow 2.0.0 (however, only on GPU. On CPU it crashes if groups != 1, because there is no implementation for the group convolutions).\r\n> \r\n> The thing is that `tf.nn.conv2d` seems to be the only thing that supports it right now.\r\n> I also tried to add the group parameter to the base class `tf.python.keras.layers.convolutional.Conv`, but the conv op that end up being called just crashes with the group-based kernel shape.\r\n> \r\n> ```python\r\n> import tensorflow as tf\r\n> from tensorflow.python.framework import tensor_shape\r\n> from tensorflow.python.keras.utils import conv_utils\r\n> import tensorflow.keras.activations as activations\r\n> import tensorflow.keras.regularizers as regularizers\r\n> import tensorflow.keras.initializers as initializers\r\n> import tensorflow.keras.constraints as constraints\r\n> from tensorflow.python.ops import array_ops\r\n> from tensorflow.python.ops import nn\r\n> \r\n> \r\n> class GroupConvBase(tf.keras.layers.Layer):\r\n> \r\n>     def __init__(self, rank, filters, kernel_size, groups=1, strides=1, padding='VALID', data_format=None,\r\n>                  dilation_rate=1,\r\n>                  activation=None, use_bias=True, kernel_initializer='glorot_uniform',\r\n>                  bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None,\r\n>                  kernel_constraint=None, bias_constraint=None, **kwargs):\r\n>         super().__init__(activity_regularizer=activity_regularizer, **kwargs)\r\n>         if filters % groups != 0:\r\n>             raise ValueError(\"Groups must divide filters evenly, but got {}/{}\".format(filters, groups))\r\n> \r\n>         self.filters = filters\r\n>         self.groups = groups\r\n>         self.kernel_size = conv_utils.normalize_tuple(kernel_size, rank, 'kernel_size')\r\n>         self.data_format = data_format\r\n>         self.padding = padding\r\n>         self.strides = conv_utils.normalize_tuple(strides, rank, 'strides')\r\n>         self.dilation_rate = conv_utils.normalize_tuple(dilation_rate, rank, 'dilation_rate')\r\n>         self.activation = activations.get(activation)\r\n>         self.use_bias = use_bias\r\n>         self.kernel_initializer = initializers.get(kernel_initializer)\r\n>         self.bias_initializer = initializers.get(bias_initializer)\r\n>         self.kernel_regularizer = regularizers.get(kernel_regularizer)\r\n>         self.bias_regularizer = regularizers.get(bias_regularizer)\r\n>         self.kernel_constraint = constraints.get(kernel_constraint)\r\n>         self.bias_constraint = constraints.get(bias_constraint)\r\n> \r\n>     def build(self, input_shape):\r\n>         input_shape = tensor_shape.TensorShape(input_shape)\r\n>         if conv_utils.normalize_data_format(self.data_format) == 'channels_first':\r\n>             channel_axis = 1\r\n>         else:\r\n>             channel_axis = -1\r\n>         if input_shape.dims[channel_axis].value is None:\r\n>             raise ValueError('The channel dimension of the inputs '\r\n>                              'should be defined. Found `None`.')\r\n>         input_dim = int(input_shape[channel_axis])\r\n>         kernel_shape = self.kernel_size + (input_dim // self.groups, self.filters)\r\n> \r\n>         self.kernel = self.add_weight(\r\n>             name='kernel',\r\n>             shape=kernel_shape,\r\n>             initializer=self.kernel_initializer,\r\n>             regularizer=self.kernel_regularizer,\r\n>             constraint=self.kernel_constraint,\r\n>             trainable=True,\r\n>             dtype=self.dtype)\r\n>         if self.use_bias:\r\n>             self.bias = self.add_weight(\r\n>                 name='bias',\r\n>                 shape=(self.filters,),\r\n>                 initializer=self.bias_initializer,\r\n>                 regularizer=self.bias_regularizer,\r\n>                 constraint=self.bias_constraint,\r\n>                 trainable=True,\r\n>                 dtype=self.dtype)\r\n>         else:\r\n>             self.bias = None\r\n> \r\n>         self.built = True\r\n> \r\n>     def call(self, inputs):\r\n>         outputs = tf.nn.conv2d(inputs, self.kernel, strides=self.strides,\r\n>                                        data_format=self.data_format, dilations=self.dilation_rate,\r\n>                                        name=self.name,\r\n>                                        padding=self.padding)\r\n> \r\n>         if self.use_bias:\r\n>             if self.data_format == 'channels_first':\r\n>                 if self.rank == 1:\r\n>                     # nn.bias_add does not accept a 1D input tensor.\r\n>                     bias = array_ops.reshape(self.bias, (1, self.filters, 1))\r\n>                     outputs += bias\r\n>                 else:\r\n>                     outputs = nn.bias_add(outputs, self.bias, data_format='NCHW')\r\n>             else:\r\n>                 outputs = nn.bias_add(outputs, self.bias, data_format='NHWC')\r\n> \r\n>         if self.activation is not None:\r\n>             return self.activation(outputs)\r\n>         return outputs\r\n> \r\n>     def get_config(self):\r\n>         config = {\r\n>             'filters': self.filters,\r\n>             'kernel_size': self.kernel_size,\r\n>             \"groups\": self.groups,\r\n>             'strides': self.strides,\r\n>             'padding': self.padding,\r\n>             'data_format': self.data_format,\r\n>             'dilation_rate': self.dilation_rate,\r\n>             'activation': activations.serialize(self.activation),\r\n>             'use_bias': self.use_bias,\r\n>             'kernel_initializer': initializers.serialize(self.kernel_initializer),\r\n>             'bias_initializer': initializers.serialize(self.bias_initializer),\r\n>             'kernel_regularizer': regularizers.serialize(self.kernel_regularizer),\r\n>             'bias_regularizer': regularizers.serialize(self.bias_regularizer),\r\n>             'activity_regularizer':\r\n>                 regularizers.serialize(self.activity_regularizer),\r\n>             'kernel_constraint': constraints.serialize(self.kernel_constraint),\r\n>             'bias_constraint': constraints.serialize(self.bias_constraint)\r\n>         }\r\n>         return {list(super(GroupConvBase, self).get_config().items()) + list(config.items())}\r\n> \r\n> \r\n> class GroupConv2D(GroupConvBase):\r\n> \r\n>     def __init__(self, filters, kernel_size,\r\n>                  groups, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None,\r\n>                  use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None,\r\n>                  bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None,\r\n>                  **kwargs):\r\n>         super(GroupConv2D, self).__init__(rank=2,\r\n>                                           filters=filters, kernel_size=kernel_size, groups=groups, strides=strides,\r\n>                                           padding=padding.upper(),\r\n>                                           data_format=data_format, dilation_rate=dilation_rate,\r\n>                                           activation=activations.get(activation),\r\n>                                           use_bias=use_bias, kernel_initializer=initializers.get(kernel_initializer),\r\n>                                           bias_initializer=initializers.get(bias_initializer),\r\n>                                           kernel_regularizer=regularizers.get(kernel_regularizer),\r\n>                                           bias_regularizer=regularizers.get(bias_regularizer),\r\n>                                           activity_regularizer=regularizers.get(activity_regularizer),\r\n>                                           kernel_constraint=constraints.get(kernel_constraint),\r\n>                                           bias_constraint=constraints.get(bias_constraint),\r\n>                                           **kwargs)\r\n> \r\n> \r\n> if __name__ == '__main__':\r\n>     gc = GroupConv2D(16, (3, 3), groups=4, padding=\"same\")\r\n>     with tf.GradientTape() as tape:\r\n>         out = gc(tf.random.normal(shape=(8, 32, 32, 16)))\r\n>         summed = tf.reduce_sum(out)\r\n>         grad = tape.gradient(summed, gc.variables)\r\n>         print(grad)\r\n> ```\r\n\r\nDo you sure this achieve the goal of grouped convolution?", "Can group conv work on cpu now (tf 2.4.x) ?", "> Can group conv work on cpu now (tf 2.4.x) ?\r\n\r\n\r\nI don't think it is working (tf 2.5.0). My grouped conv3d works on gpu, but failed on cpu for group!=1.\r\n"]}]