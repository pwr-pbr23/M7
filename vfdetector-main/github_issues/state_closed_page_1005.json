[{"number": 23212, "title": "Ambiguity with tf.nn.embedding_lookup_sparse", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow 1.9.0\r\n- Python 3.6.6\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nThe tf.nn.embedding_lookup_sparse need two tf.SparseTensor (sp_ids and sp_weights) but I can't figure out why. Specifically, it seems to me that the columns of the indices of sp_ids and sp_weights are useless (see the example in the doc). This could be changed to use only one SparseTensor with:\r\n- rows of indices pointing to the index of the element of the batch.\r\n- columns of indices pointing to the index of the target element of the embedding (params).\r\n- values corresponding to the weights. \r\n\r\nSmall example of two operations doing the same things:\r\ntf.sparse_tensor_dense_matmul(sparse_tensor, embeddings)\r\ntf.nn.embedding_lookup_sparse(embeddings, sparse_ids, sparse_weights, \"sum\")\r\nHere sparse_ids and sparse_weights have the same indices, the values of sparse_ids are the columns of indices of sparse_tensor and the values of weights are the values of  sparse_tensor. The three sparse tensors share the same rows of indices. \r\n\r\nps: It might not work in higher dimensional embedding lookups, I just wanted to point out the fact that embedding_lookup and embedding_lookup_sparse, despite their close names, have actually a very different usability. \r\n\r\n\r\n**Will this change the current api? How?**\r\nI can't really say.  tf.nn.embedding_lookup_sparse(params, sp_ids, sp_weights...) could become tf.nn.embedding_lookup_sparse(params, sparse_ids...) to be more consistent with tf.nn.embedding_lookup.\r\n\r\n\r\n**Who will benefit with this feature?**\r\nI don't really know. \r\n\r\n\r\n**Any Other info.**\r\n\r\nHave I written custom code: no\r\nOS Platform and Distribution: linux, but not relevant\r\nTensorFlow installed from: pip\r\nTensorFlow version: 1.9.0\r\nBazel version: ?\r\nCUDA/cuDNN version: no CUDA\r\nGPU model and memory: no GPU\r\nExact command to reproduce: See above\r\nMobile device: not relevant\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "@brochier  - Hi, could you please provide the information asked ?", "@drpngx  -  PTAL", "Both fields of `sp_ids` are useful. It is assumed that `sp_weights` is \"aligned\" with `sp_ids` in the sense that `sp_ids.indices == sp_weights.indices`. Only `sp_ids.indices[:, 0]` (the first dimension) is used.", "Nagging Assignees @MarkDaoust, @harshini-gadige: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 23211, "title": "Replacing generator activation from relu to leaky_relu to avoid sparse gradients", "body": "- Replaced generator activation from relu to leaky_relu to avoid sparse gradients. Even though the markdown in notebook mentions - _\"We use leaky relu activation except for the last layer which uses tanh activation\"_, the code uses relu activation. (The generated outputs are also much better when leaky_relu is used. See image below)\r\n![](https://user-images.githubusercontent.com/9641196/47428074-cccc7480-d7af-11e8-948d-243a52cb9053.gif)\r\n- The input noise (input to the generator) is sampled from the normal distribution\r\n`noise = tf.random_normal([BATCH_SIZE, noise_dim])` but the comment above this line mentions -  _\"generating noise from a uniform distribution\"_. Also changed this to avoid confusion.\r\n\r\n", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it", "CLAs look good, thanks!\n\n<!-- ok -->", "@alextp @asimshankar Can you please take a look?", "Can you base this off of https://github.com/tensorflow/tensorflow/pull/23035 ? That has a lot of other changes we want to make and should be merged soon.", "Thanks for your pull request @gowtham1997. FYI I already fixed the activation issue of the generator (it should have been LeakyReLU) in [this commit](https://github.com/tensorflow/tensorflow/pull/23035/commits/db6c86cffa294c7e35e9f81e6f92a7a53b3a531c). It might be easier if I just fix the text regarding the input noise input distribution in my PR #23035 if that's the only change, or you can PR against my branch. As @alextp mentioned there are lots of changes in PR #23035 pending merge soon.", "Sure @alextp \r\n@margaretmz  Your PR seems to take care of both my changes and a lot more, so I don't think I can add anything by sending a PR against your branch."]}, {"number": 23210, "title": "Different inference time on my computer and server with the same gpu", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nWin10\r\n\r\n- TensorFlow installed from (source or binary):\r\nanaconda3\r\n\r\n- TensorFlow version (use command below):\r\ntensorflow-gpu1.11.0\r\n\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n\r\n- Python version:\r\npython3.6.6\r\n\r\n- Bazel version (if compiling from source): N/A\r\n\r\n- GCC/Compiler version (if compiling from source): N/A\r\n\r\n- CUDA/cuDNN version:\r\nCUDA9.0\r\n\r\n- GPU model and memory:\r\nNVIDIA GeForce GTX 1080 Ti  11264MiB\r\n\r\n**Describe the current behavior**\r\nI have trained a 2 classified ResNet18\uff0c when I use it for inference on different machine, the time is as follow:\r\nabout 2.0s on my conputer\uff0c\r\nabout 1.6s on my workmate's computer (win10,  tensorflow-gpu of version 1.9, python 3.6.6, CUDA9.0,  NVIDIA GeForce GTX 1080 Ti 11264MiB)\uff0c \r\nabout 0.65s on a server (Ubuntu16.04, tensorflow-gpu of version 1.9, python 3.6,2, CUDA9.0, NVIDIA GeForce GTX 1080 Ti 11171MiB), \r\nabout 0.22s on another server (Ubuntu16.04,  tensorflow-gpu of version 1.8, python 2.7.13,  CUDA9.0, NVIDIA GeForce GTX 1080 Ti 11171MiB). \r\nThe code is exactly the same, only change is the model path and data path. Why there is so huge difference?\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```\r\nmodel_path = 'D:/proj_tf/models_pb/slice_cor.pb'\r\nimage_path = 'D:/proj_tf/data/'\r\nfiles_in = ['0205_256_06.raw', '0205_256_07.raw', '0205_256_08.raw']\r\ndata_image = np.zeros((3, 256, 256, 3), dtype=np.float32)\r\nfor index in range(3):\r\n    image_file = os.path.join(image_path, files_in[index])\r\n    data_tmp = np.fromfile(image_file, dtype=np.float32)\r\n    data_tmp.shape = 256, 256\r\n    min_value = data_tmp.min()\r\n    max_value = data_tmp.max()\r\n    data_tmp -= min_value\r\n    data_tmp /= (max_value - min_value)\r\n    for i in range(3):\r\n        data_image[index, :, :, i] = data_tmp\r\n    \r\nos.environ['CUDA_VISIBLE_DEVICES'] = '0'\r\nconfig = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False)\r\nconfig.gpu_options.per_process_gpu_memory_fraction = 0.7\r\nsess = tf.Session(config=config)\r\nwith gfile.FastGFile(model_path, 'rb') as f:\r\n    graph_def = tf.GraphDef()\r\n    graph_def.ParseFromString(f.read())\r\n    sess.graph.as_default()\r\n    tf.import_graph_def(graph_def, name=\"\")\r\n    \r\n    sess.run(tf.global_variables_initializer())\r\n    inp = sess.graph.get_tensor_by_name('data:0')\r\n    out = sess.graph.get_tensor_by_name('softmax:0')\r\n    \r\n    start_time = time.time()\r\n    pred_slice = sess.run(out, {inp: data_image})\r\n    end_time = time.time()\r\n    \r\n    print(\"time for inference : \", end_time - start_time)\r\n    sess.close()   \r\n```\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nBazel version\nExact command to reproduce\nMobile device"]}, {"number": 23209, "title": "expect delta_delta op for speech", "body": "\r\ndelta_delta is common in speech task, expected to be implemented. And also expect to expand the feature op of audio process in future.\r\n\r\n**System information**\r\n- TF1.11\r\n- No\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nadd delta_detla Op to audio feature \r\n\r\n\r\n**Who will benefit with this feature?**\r\npeople  who doing ASR.\r\n\r\n**Any Other info.**\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Along with other transformations, delta_delta is common in speech tasks. You can leverage math libraries such as scipy to write your own function and take advantage of its abundant fft libraries.\r\n\r\n", "@wt-huang  I want using TF to deploy APP\uff0cand make the feature extraction as one part of graph. So the common pipeline of speech is important.", "see https://github.com/didi/delta/blob/master/delta/layers/ops/kernels/delta_delta_op.cc"]}, {"number": 23208, "title": "TfLiteCameraDemo.apk with NNAPI", "body": "Can someone please upload a version of TfLiteCameraDemo.apk that supports NNAPI?", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Hi\r\nThanks for the response! \ud83d\udc4d \r\nI'm writing a HAL for neuralnetwork for an AVD (Android Virtual Device), and I want to run an mobile application who uses the NNAPI on the AVD in order to test my HAL.\r\n\r\nSo I wanted to get, if possible, the version of TfLiteCameraDemo.apk who uses google's NNAPI (Android 8.1+).\r\n\r\nThanks a lot! :)", "You can download TfLiteCameraDemo.apk from [TensorFlow Android Demo App](https://www.tensorflow.org/lite/demo_android) or write your own app to support whichever version.", "Closing as this is resolved, free to reopen if problem persists."]}, {"number": 23206, "title": "Switch from Deprecated to Current Docker Images on Docker Hub", "body": "This PR is intended as follow-up to the proposal in Issue #23170 to host Tensorflow's currently developed Dockerfile images on Docker Hub.\r\n\r\nFrom the Issue:\r\n\r\n>Tensorflow's Dockerfiles are [currently located](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/dockerfiles/dockerfiles) at `tensorflow/tensorflow/tools/dockerfiles/dockerfiles/`. The parent directory (`tensorflow/tensorflow/tools/dockerfiles/`) includes instructions to build the images from that directory. This is done so the Dockerfiles have the `bashrc` file in their build context to `COPY` into containers at runtime. \r\n>\r\n>There are another set of Dockerfiles at `tensorflow/tensorflow/tools/docker/` which are marked deprecated/for-deletion. These deprecated Dockerfiles are the ones currently hosted on [Docker Hub](https://hub.docker.com/r/tensorflow/tensorflow/).\r\n>\r\n>I propose Tensorflow switch their publicly available Docker images from the deprecated set to current ones. With minimal upfront effort, all eight current images could be hosted on Docker Hub and automatically rebuilt with each repo update.\r\n\r\nI pushed the images from this PR to the `imburbank/tensorflow` [repo](https://hub.docker.com/r/imburbank/tensorflow/ 'Docker Hub') on Docker Hub for now. All the images can be run with `imburbank/tensorflow:[Docker Tag Name]`. The hosted images:tags are as follows:\r\n\r\n| Dockerfile Location                                                                          |  Docker Tag Name          |\r\n|----------------------------------------------------------------------------------------|----------------------------------|\r\n| `tools/dockerfiles/dockerfiles/cpu.Dockerfile`                                  | latest                               |\r\n| `tools/dockerfiles/dockerfiles/cpu-devel.Dockerfile`                        | latest-devel                      |\r\n| `tools/dockerfiles/dockerfiles/cpu-jupyter.Dockerfile`                      | latest-jupyter                    |\r\n| `tools/dockerfiles/dockerfiles/cpu-devel-jupyter.Dockerfile`            | latest-devel-jupyter          |\r\n| `tools/dockerfiles/dockerfiles/nvidia.Dockerfile`                              | latest-gpu                        |\r\n| `tools/dockerfiles/dockerfiles/nvidia-devel.Dockerfile`                    | latest-gpu-devel               |\r\n| `tools/dockerfiles/dockerfiles/nvidia-jupyter.Dockerfile`                  | latest-gpu-jupyter             |\r\n| `tools/dockerfiles/dockerfiles/nvidia-devel-jupyter.Dockerfile`        | latest-gpu-devel-jupyter   |\r\n\r\nFor example, to run `nvidia.Dockerfile`:\r\n\r\n```bash\r\ndocker run --runtime=nvidia -u $(id -u):$(id -g) -v $(pwd):/my-devel -it imburbank/tensorflow:latest-gpu\r\n```\r\n\r\nI also propose that Tensorflow take over hosting these images in the official Docker Hub repo. \r\n\r\nAs a follow up, the `README.md`s at `tensorflow/tools/dockerfiles/` and `tensorflow/tools/docker/` should be updated when Tensorflow begins hosting the current images.", "comments": ["Thanks for the work you put in to this. We can't accept your PR, though, since there is a lot of hidden complexity to how we manage and deploy our Dockerfiles to Docker Hub. I'll explain more in #23170."]}, {"number": 23205, "title": "static_rnn has no remind", "body": "pip show tensorflow-gpu\r\nName: tensorflow-gpu\r\nVersion: 1.11.0\r\nSummary: TensorFlow is an open source machine learning framework for everyone.\r\nHome-page: https://www.tensorflow.org/\r\nAuthor: Google Inc.\r\nAuthor-email: opensource@google.com\r\nLicense: Apache 2.0\r\nLocation: c:\\anaconda\\lib\\site-packages\r\nRequires: protobuf, termcolor, wheel, keras-applications, setuptools, absl-py, grpcio, six, gast, astor, numpy, keras-preprocessing, tensorboard\r\n\r\nLib/site-packages/tensorflow/nn/__init__.py has something wrong\r\n\r\n```python\r\nfrom tensorflow.python.ops.nn import static_rnn  wrong\r\nfrom tensorflow.python.ops.rnn import static_rnn right\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "I apologize, but I am having a hard time understanding what the problem is, where the problem is, and what version it affects. Please resubmit and pay attention to the [issue template ](https://github.com/tensorflow/tensorflow/issues/new/choose). Please provide all the information it asks. Thank you.\r\n", "When I use RNN, I cannot find the source code of `static_rnn` function.\r\n\r\nThe below is the reason :\r\nLib/site-packages/tensorflow/nn/init.py has something wrong\r\n\r\nThis file is one of the tensorflow-gpu library .\r\nAnd the reason is wrong package .\r\n\r\n* wrong\r\n```python\r\nfrom tensorflow.python.ops.nn import static_rnn  \r\n```\r\n* right\r\n```python\r\nfrom tensorflow.python.ops.rnn import static_rnn\r\n```", "You can write a program like below and try to view the source code of static_rnn\r\n\r\n```python\r\nimport tensorflow as tf\r\nx=tf.nn.static_rnn()\r\n```"]}, {"number": 23204, "title": "Remove redundant word \"the\"", "body": "", "comments": ["Nagging Assignee @ymodak: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Thanks @johnlinp\r\n\r\nCan you resolve that conflict in: \"tensorflow/contrib/lite/python/op_hint.py\"", "Hi @MarkDaoust, the conflict is resolved. Thanks.", "Thanks for the fix!"]}, {"number": 23203, "title": "Allows cond_v2 to return tensors in nested output structures. Resolved merge conflicts and squashed into one commit.", "body": "@skye Had to reopen the pull request since it got closed for some reason while I was squashing commits", "comments": ["@ymodak can you rerun the tests and try to get this in? I'm OOO until Tuesday (and can't find how to add labels on my phone)", "@skye  Yes. I will work on this.", "@skye @ymodak Sorry there was a minor typo when copying the last fix. All tests should pass now.  "]}, {"number": 23202, "title": "What are the differences between cold_start_filter and filter_continuation ?", "body": "<em>Please make sure that this is a documentation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:doc_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version: Master\r\n- Doc Link:\r\nhttps://www.tensorflow.org/api_docs/python/tf/contrib/timeseries/saved_model_utils/cold_start_filter\r\n\r\n**Describe the documentation issue**\r\n\r\nIt is not clear what are the differences between  cold_start_filter and filter_continuation. And in what condition they should be used? \r\n\r\nAnd for \"Filtering refers to updating model state based on new observations.\" , is the model state == model ? why one should update it  ?\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "@StevenLOL  \r\n- Both cold_start_filter and filter_continuation update model state based on new observations.\r\n- cold_start_filter starts from the model's default or uninformed state. filter_continuation applies filtering subsequent to cold_start_filter. \r\n- Model state is not the same as model, the former is being updated with new  observations in features and normally contains previous and current cell information depending on how you build the model. \r\n- The reason behind filtering is you need to update model state based on new observation in time series.\r\n\r\n"]}, {"number": 23201, "title": "CMake can't find cublas device", "body": "**System information**\r\n- Windows 10 Pro\r\n- TensorFlow installed from source\r\n- TensorFlow 1.11\r\n- Python 3.6\r\n- CMake 3.10.1\r\n- CUDA 10/cuDNN 7.3.1\r\n- NVIDIA Geforce 980GTX\r\n\r\n\r\nI am trying to build Tensorflow (with GPU) under Windows 10 with CUDA 10 and cuDNN 7.3.1 using CMake. \r\nHowever, when I enable GPU, it cannot find following file: cublas_device.lib. It seems, this file is not included in CUDA 10 anymore. Is there another way to build with GPU support (if possible, with CUDA 10 and not 9)?\r\n\r\nHere's the detailed error message\r\n\r\n```\r\nCMake Error: The following variables are used in this project, but they are set to NOTFOUND.\r\nPlease set them or make sure they are set and tested correctly in the CMake files:\r\nCUDA_cublas_device_LIBRARY (ADVANCED)\r\n    linked by target \"contrib_memory_stats_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"functional_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"sdca_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"candidate_sampling_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"user_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"dataset_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"contrib_image_distort_image_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"contrib_seq2seq_beam_search_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"contrib_boosted_trees_training_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"ctc_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"checkpoint_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"contrib_bigquery_reader_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"contrib_tensor_forest_stats_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"data_flow_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"contrib_layers_sparse_feature_cross_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"sdca_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"candidate_sampling_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"control_flow_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"contrib_factorization_clustering_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"summary_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"resource_variable_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"contrib_image_sirds_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"contrib_boosted_trees_prediction_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"lookup_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"script_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"tf_core_gpu_kernels\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"grpc_tensorflow_server\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"contrib_data_dataset_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"audio_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"array_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"tf_tutorials_example_trainer\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"batch_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"bitwise_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"boosted_trees_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"checkpoint_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"control_flow_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"cudnn_rnn_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"data_flow_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"dataset_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"decode_proto_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"resource_variable_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"encode_proto_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"functional_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"image_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"sparse_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"io_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"linalg_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"list_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"lookup_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"logging_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"user_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"manip_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"math_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"spectral_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"nn_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"no_op_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"parsing_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"random_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"remote_fused_graph_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"debug_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"rpc_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"script_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"set_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"sendrecv_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"sparse_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"spectral_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"state_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"stateless_random_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"string_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"summary_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"training_ops_gen_cc\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"tf_label_image_example\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"proto_text\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"ctc_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"compare_graphs\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"transform_graph\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"summarize_graph\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"benchmark_model\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"contrib_nearest_neighbor_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"audio_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"array_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"batch_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"bitwise_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"boosted_trees_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"math_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"cudnn_rnn_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"decode_proto_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"encode_proto_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"image_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"io_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"linalg_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"list_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"logging_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"nn_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"manip_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"parsing_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"random_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"remote_fused_graph_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"rpc_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"set_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"state_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"string_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"training_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"contrib_boosted_trees_model_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"contrib_boosted_trees_split_handler_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"contrib_boosted_trees_quantiles_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"contrib_boosted_trees_stats_accumulator_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"contrib_coder_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"contrib_factorization_factorization_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"contrib_framework_variable_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"contrib_input_pipeline_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"contrib_image_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"contrib_nccl_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"contrib_periodic_resample_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"contrib_resampler_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"contrib_rnn_gru_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"contrib_rnn_lstm_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"contrib_tensor_forest_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"contrib_tensor_forest_hybrid_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"contrib_tensor_forest_model_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"contrib_text_skip_gram_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"contrib_gcs_config_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n    linked by target \"stateless_random_ops_gen_python\" in directory C:/Users/kai/Documents/Libs/tensorflow/tensorflow/contrib/cmake\r\n```\r\n\r\nThanks\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "TensorFlow is built and tested against CUDA 9.0 officially. Although it is compatible with CUDA 10 but its not supported by TF yet.\r\nTo use TensorFlow against CUDA 10. You have to build it yourself from the sources. You can also refer this [installation manual](https://www.pugetsystems.com/labs/hpc/Install-TensorFlow-with-GPU-Support-on-Windows-10-without-a-full-CUDA-install-1172/) which has benefited other users. Hope this helps solving your issue. ", "@ymodak  I am building it from source via CMake, but this is exactly where the problem occurs. \r\nThank you for linking the manual, however I'd like to use Tensorflow for C++ and the manual unfortunately is not referring to this. ", "Please go through this [answer](https://stackoverflow.com/a/33622489) posted on Stack Overflow. Hope it helps.", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Update CMake to the latest version can fix this problem."]}, {"number": 23200, "title": "r1.12: \"No module named enum\"", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- Linux Ubuntu 16.04.1\r\n- no mobile device\r\n- TensorFlow installed from github\r\n- TensorFlow version: r1.12\r\n- Python version: 2.7\r\n- Installed using virtualenv? pip? conda?: apt-get\r\n- Bazel version (if compiling from source): 0.17.1\r\n- GCC/Compiler version (if compiling from source): 5.4.0\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n\r\n\r\n**Describe the problem**\r\n File \"/home/amcp011/.cache/bazel/_bazel_amcp011/2a4bcc1a1f556f9e46df7e271eeaa164/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/ops/variables.py\", line 20, in <module>\r\n    import enum  # pylint: disable=g-bad-import-order\r\nImportError: No module named enum\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nbazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nERROR: /home/amcp011/local/tensorflow/tensorflow/BUILD:533:1: Executing genrule //tensorflow:tf_python_api_gen_v1 failed (Exit 1)\r\nTraceback (most recent call last):\r\n  File \"/home/amcp011/.cache/bazel/_bazel_amcp011/2a4bcc1a1f556f9e46df7e271eeaa164/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py\", line 27, in <module>\r\n    from tensorflow.python.tools.api.generator import doc_srcs\r\n  File \"/home/amcp011/.cache/bazel/_bazel_amcp011/2a4bcc1a1f556f9e46df7e271eeaa164/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/__init__.py\", line 70, in <module>\r\n    from tensorflow.python.framework.framework_lib import *  # pylint: disable=redefined-builtin\r\n  File \"/home/amcp011/.cache/bazel/_bazel_amcp011/2a4bcc1a1f556f9e46df7e271eeaa164/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/framework/framework_lib.py\", line 52, in <module>\r\n    from tensorflow.python.framework.importer import import_graph_def\r\n  File \"/home/amcp011/.cache/bazel/_bazel_amcp011/2a4bcc1a1f556f9e46df7e271eeaa164/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/framework/importer.py\", line 27, in <module>\r\n    from tensorflow.python.framework import function\r\n  File \"/home/amcp011/.cache/bazel/_bazel_amcp011/2a4bcc1a1f556f9e46df7e271eeaa164/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/framework/function.py\", line 36, in <module>\r\n    from tensorflow.python.ops import resource_variable_ops\r\n  File \"/home/amcp011/.cache/bazel/_bazel_amcp011/2a4bcc1a1f556f9e46df7e271eeaa164/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/ops/resource_variable_ops.py\", line 38, in <module>\r\n    from tensorflow.python.ops import variables\r\n  File \"/home/amcp011/.cache/bazel/_bazel_amcp011/2a4bcc1a1f556f9e46df7e271eeaa164/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/ops/variables.py\", line 20, in <module>\r\n    import enum  # pylint: disable=g-bad-import-order\r\nImportError: No module named enum\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 128.659s, Critical Path: 101.44s\r\nINFO: 72 processes: 72 local.\r\nFAILED: Build did NOT complete successfully\r\n", "comments": ["Can you try installing enum and building again. You can do something like this:\r\npip install --upgrade pip enum34", "I changed to python 3.6 from the ananconda3 distribution and now I get:\r\n\r\nERROR: /home/amcp011/local/tensorflow/tensorflow/python/eager/BUILD:10:1: undeclared inclusion(s) in rule '//tensorflow/python/eager:pywrap_tfe_lib':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/python/eager/pywrap_tensor.cc':\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/arrayobject.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/ndarrayobject.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/ndarraytypes.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/npy_common.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/numpyconfig.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/_numpyconfig.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/npy_endian.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/npy_cpu.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/utils.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/_neighborhood_iterator_imp.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/__multiarray_api.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/npy_interrupt.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/ufuncobject.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/npy_math.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/npy_common.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/arrayobject.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/__ufunc_api.h'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 2047.164s, Critical Path: 434.58s\r\nINFO: 2724 processes: 2724 local.\r\nFAILED: Build did NOT complete successfully\r\n", "@jjhelmus may have some input on the 2nd issue. I think this is a configuration issue.", "Is numpy installed into the conda environment?  Was `site-packages` directory of the environment detected by the configuration script and selected?", "> Is numpy installed into the conda environment? Was `site-packages` directory of the environment detected by the configuration script and selected?\r\n\r\nHi @jjhelmus , same here:\r\n\r\n```\r\nERROR: /home/diicic/master/tensorflow/tensorflow/python/eager/BUILD:10:1: undeclared inclusion(s) in rule '//tensorflow/python/eager:pywrap_tfe_lib':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/python/eager/pywrap_tensor.cc':\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/arrayobject.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/ndarrayobject.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/ndarraytypes.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/npy_common.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/numpyconfig.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/_numpyconfig.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/npy_endian.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/npy_cpu.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/utils.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/_neighborhood_iterator_imp.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/__multiarray_api.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/npy_interrupt.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/ufuncobject.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/npy_math.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/npy_common.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/arrayobject.h'\r\n  'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/__ufunc_api.h'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\n```\r\n\r\nNumpy is installed with pip/pip3\r\n\r\n```\r\ndiicic@diicic-MS-7B45:~$ pip3 install numpy\r\nRequirement already satisfied: numpy in ./.local/lib/python3.6/site-packages (1.15.3)\r\ndiicic@diicic-MS-7B45:~$ pip install numpy\r\nRequirement already satisfied: numpy in ./.local/lib/python3.6/site-packages (1.15.3)\r\n```\r\nDuring ./config script y selected /usr/lib/python3 for python installation dir and /usr/lib/python3/dist-packages (default) for the packages.\r\n\r\nRegards.\r\n\r\nDani", "I got same problem :\r\n\r\nSystem information:\r\n\r\n    Linux Ubuntu 16.04 LTS\r\n    no mobile device\r\n    TensorFlow installed from github\r\n    TensorFlow version: r1.12\r\n    Python version: 3.5.2\r\n    Installed using virtualenv? pip? conda?: apt-get\r\n    Bazel version (if compiling from source): 0.15.0\r\n    GCC/Compiler version (if compiling from source): 5.4.0\r\n    CUDA/cuDNN version: N/A\r\n    GPU model and memory: N/A\r\n\r\n.tf_configure.bazelrc:\r\n```\r\nbuild --action_env PYTHON_BIN_PATH=\"/usr/bin/python3\"\r\nbuild --action_env PYTHON_LIB_PATH=\"/usr/local/lib/python3.5/dist-packages\"\r\nbuild --python_path=\"/usr/bin/python3\"\r\nbuild:ignite --define with_ignite_support=true\r\nbuild:xla --define with_xla_support=true\r\nbuild --action_env TF_NEED_OPENCL_SYCL=\"0\"\r\nbuild --action_env TF_NEED_ROCM=\"0\"\r\nbuild --action_env TF_NEED_CUDA=\"0\"\r\nbuild --action_env TF_DOWNLOAD_CLANG=\"0\"\r\nbuild:opt --copt=-march=native\r\nbuild:opt --host_copt=-march=native\r\nbuild:opt --define with_default_optimizations=true\r\nbuild:v2 --define=tf_api_version=2\r\n```\r\n\r\n```\r\n~/tensorflow$ pip3 install numpy\r\nRequirement already satisfied: numpy in /usr/local/lib/python3.5/dist-packages (1.14.3)\r\n```\r\n\r\nError:\r\n```\r\nERROR: /home/rayan/tensorflow/tensorflow/python/eager/BUILD:10:1: undeclared inclusion(s) in rule '//tensorflow/python/eager:pywrap_tfe_lib':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/python/eager/pywrap_tensor.cc':\r\n  'bazel-out/k8-opt/genfiles/external/local_config_python/python_include/numpy/arrayobject.h'\r\n  'bazel-out/k8-opt/genfiles/external/local_config_python/python_include/numpy/ndarrayobject.h'\r\n  'bazel-out/k8-opt/genfiles/external/local_config_python/python_include/numpy/ndarraytypes.h'\r\n  'bazel-out/k8-opt/genfiles/external/local_config_python/python_include/numpy/npy_common.h'\r\n  'bazel-out/k8-opt/genfiles/external/local_config_python/python_include/numpy/numpyconfig.h'\r\n  'bazel-out/k8-opt/genfiles/external/local_config_python/python_include/numpy/_numpyconfig.h'\r\n  'bazel-out/k8-opt/genfiles/external/local_config_python/python_include/numpy/npy_endian.h'\r\n  'bazel-out/k8-opt/genfiles/external/local_config_python/python_include/numpy/npy_cpu.h'\r\n  'bazel-out/k8-opt/genfiles/external/local_config_python/python_include/numpy/utils.h'\r\n  'bazel-out/k8-opt/genfiles/external/local_config_python/python_include/numpy/_neighborhood_iterator_imp.h'\r\n  'bazel-out/k8-opt/genfiles/external/local_config_python/python_include/numpy/__multiarray_api.h'\r\n  'bazel-out/k8-opt/genfiles/external/local_config_python/python_include/numpy/npy_interrupt.h'\r\n  'bazel-out/k8-opt/genfiles/external/local_config_python/python_include/numpy/ufuncobject.h'\r\n  'bazel-out/k8-opt/genfiles/external/local_config_python/python_include/numpy/npy_math.h'\r\n  'bazel-out/k8-opt/genfiles/external/local_config_python/python_include/numpy/npy_common.h'\r\n  'bazel-out/k8-opt/genfiles/external/local_config_python/python_include/numpy/arrayobject.h'\r\n  'bazel-out/k8-opt/genfiles/external/local_config_python/python_include/numpy/__ufunc_api.h'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\n\r\n```", "I did some more test. I had the same issue with tensorflow version r1.11.\r\nIt finally worked when I reverted to r1.10.", "What to do?\r\n\r\n****System information**\r\n\r\n* OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n* Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n* TensorFlow installed from (source or binary): source\r\n* TensorFlow version: 1.13.0rc2\r\n* Python version: 3.7.2\r\n* Installed using virtualenv? pip? conda?: pip\r\n* Bazel version (if compiling from source): 0.22\r\n* GCC/Compiler version (if compiling from source): 6.5.0\r\n* CUDA/cuDNN version: 10.0/7.3\r\n* GPU model and memory: RTX 2070 and 8GB\r\n\r\n**Describe the problem**\r\n\r\nERROR: /home/max/tensorflow/tensorflow/python/eager/BUILD:10:1: undeclared inclusion(s) in rule '//tensorflow/python/eager:pywrap_tfe_lib':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/python/eager/pywrap_tensor.cc':\r\n'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/arrayobject.h'\r\n'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/ndarrayobject.h'\r\n'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/ndarraytypes.h'\r\n'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/npy_common.h'\r\n'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/numpyconfig.h'\r\n'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/_numpyconfig.h'\r\n'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/npy_endian.h'\r\n'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/npy_cpu.h'\r\n'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/utils.h'\r\n'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/_neighborhood_iterator_imp.h'\r\n'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/__multiarray_api.h'\r\n'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/npy_interrupt.h'\r\n'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/ufuncobject.h'\r\n'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/npy_math.h'\r\n'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/npy_common.h'\r\n'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/arrayobject.h'\r\n'bazel-out/host/genfiles/external/local_config_python/python_include/numpy/__ufunc_api.h'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build**", "`pip install --upgrade pip enum34` didn't helped.\r\n\r\n`bazel build tensorflow/python/tools:optimize_for_inference`\r\n\r\n```\r\nERROR: /Users/my_user/external_projects/tensorflow/tensorflow/python/keras/api/BUILD:28:1: Executing genrule //tensorflow/python/keras/api:keras_python_api_gen_compat_v1 failed (Exit 1)\r\nTraceback (most recent call last):\r\n  File \"/private/var/tmp/_bazel_my_user/747948fb577123a5771581be02ddf56a/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_1_keras_python_api_gen_compat_v1.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py\", line 27, in <module>\r\n    from tensorflow.python.tools.api.generator import doc_srcs\r\n  File \"/private/var/tmp/_bazel_my_user/747948fb577123a5771581be02ddf56a/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_1_keras_python_api_gen_compat_v1.runfiles/org_tensorflow/tensorflow/python/__init__.py\", line 63, in <module>\r\n    from tensorflow.python.framework.framework_lib import *  # pylint: disable=redefined-builtin\r\n  File \"/private/var/tmp/_bazel_my_user/747948fb577123a5771581be02ddf56a/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_1_keras_python_api_gen_compat_v1.runfiles/org_tensorflow/tensorflow/python/framework/framework_lib.py\", line 52, in <module>\r\n    from tensorflow.python.framework.importer import import_graph_def\r\n  File \"/private/var/tmp/_bazel_my_user/747948fb577123a5771581be02ddf56a/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_1_keras_python_api_gen_compat_v1.runfiles/org_tensorflow/tensorflow/python/framework/importer.py\", line 28, in <module>\r\n    from tensorflow.python.framework import function\r\n  File \"/private/var/tmp/_bazel_my_user/747948fb577123a5771581be02ddf56a/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_1_keras_python_api_gen_compat_v1.runfiles/org_tensorflow/tensorflow/python/framework/function.py\", line 37, in <module>\r\n    from tensorflow.python.ops import resource_variable_ops\r\n  File \"/private/var/tmp/_bazel_my_user/747948fb577123a5771581be02ddf56a/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_1_keras_python_api_gen_compat_v1.runfiles/org_tensorflow/tensorflow/python/ops/resource_variable_ops.py\", line 41, in <module>\r\n    from tensorflow.python.ops import variables\r\n  File \"/private/var/tmp/_bazel_my_user/747948fb577123a5771581be02ddf56a/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/python/keras/api/create_tensorflow.python_api_1_keras_python_api_gen_compat_v1.runfiles/org_tensorflow/tensorflow/python/ops/variables.py\", line 20, in <module>\r\n    import enum  # pylint: disable=g-bad-import-order\r\nImportError: No module named enum\r\nTarget //tensorflow/python/tools:optimize_for_inference failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\n```", "I can do `import enum`\r\n\r\n```\r\npython -c \"import enum; print(enum.__file__)\"\r\n/usr/local/Cellar/python/3.6.5_1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/enum.py\r\n```\r\n\r\nHow to check if `bazel build tensorflow/python/tools:optimize_for_inference` use the right python?", "TF's build uses python based on which python version you use during configure.py run.", "@amcphail Can you please confirm if your issue is resolved.", "I reverted to the anaconda version of TF.", "@amcphail please confirm if we may proceed to move this issue to resolved.", "Yes.\n\nOn Wed, 19 Feb 2020, 19:41 Saduf2019, <notifications@github.com> wrote:\n\n> @amcphail <https://github.com/amcphail> please confirm if we may proceed\n> to move this issue to resolved.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/23200?email_source=notifications&email_token=AAKAZJ3FZRMEQ27IZIFYO7LRDTH73A5CNFSM4F63FSO2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEMGRTII#issuecomment-588061089>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAKAZJ54ZNCDPZFJA46KKV3RDTH73ANCNFSM4F63FSOQ>\n> .\n>\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/23200\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/23200\">No</a>\n"]}, {"number": 23199, "title": "Problem mixing tf.cast and tf.control_dependencies", "body": "**System information**\r\n- Windows 10 1809.\r\n- TensorFlow installed from (source or binary): binary.\r\n- TensorFlow version (use command below): 1.11.0 (cpu).\r\n- Python version: 3.6.6.\r\n\r\n**Describe the current behavior**\r\n\r\nReturns inf.\r\n\r\n**Describe the expected behavior**\r\n\r\nShould return 1.0.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\n\r\nwith tf.Session() as sess:\r\n    n = tf.Variable(initial_value=0, dtype=tf.int32)\r\n    v = tf.Variable(initial_value=1., dtype=tf.float32)\r\n\r\n    inc_n = tf.assign_add(n, 1)\r\n    foo = 1. / tf.cast(n, tf.float32)\r\n\r\n    with tf.control_dependencies([inc_n]):\r\n        test = tf.assign(v, foo) # doesn't work\r\n        # test = tf.assign(v, 1. / tf.cast(n, tf.float32)) # works\r\n\r\n    sess.run(tf.global_variables_initializer())\r\n    print(sess.run(test))\r\n```\r\n\r\n**Other info / logs**\r\n\r\nAlso tested it on ubuntu 18, tf 1.11 gpu (from source, cuda 10), works fine.\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "OS Platform and Distribution: Windows 10 1809.\r\nBazel version: N/A (using binary).\r\nCUDA/cuDNN version: N/A (using cpu).\r\nGPU model and memory: N/A (using cpu).\r\nExact command to reproduce: Source code included.\r\nMobile device: N/A.", "@pisiiki When using `inc_n = tf.assign_add(n, 1)`, you need to make sure that the 2 args have the same type, which is not the case in the above code.  You would want to fix that before using `tf.control_dependencies()`.", "@wt-huang I can't see how these two parameters may have different types, one is an int32 tf variable (n), and the other is a python int. Please notice there are a couple of tf variables in the code. I was unable to simplify even more the example.\r\n\r\nThe problem comes after I cast n to tf.float32 to update the other tf variable (v). If I do it with an intermediate tensor (foo) the computation fails, if I write everything inside control_dependencies it works. This looks very suspicious to me also because it didn't work on windows but it did on linux.", "@pisiiki They are not the same data type, v and foo are not the same type either. The above code has the same issue on Linux and returns inf too. \r\nThe tf.control_dependencies is nothing but a wrapper for Graph.control_dependencies() using the default graph. You can also convert from one data type to the other. ", "@wt-huang thanks for the explanation. I have refactored my code to rely less on tf variables. I was trying to limit state copying between python and tf for some sequence modelling experiments but the resulting code was very tricky to write and understand. Also I'm on v1.12 now so I'm good to go now."]}, {"number": 23198, "title": "ResourceExhaustedError (see above for traceback): OOM when allocating tensor", "body": "Hi, \r\nI want to feed CNN with my database. for this aim, I use ImageDataGenerator and I put my code here. but after implementing it produces this error:  \r\n\"ResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[32,32,512,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n\t [[Node: conv2d_1/convolution = Conv2D[T=DT_FLOAT, data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](conv2d_1/convolution-0-TransposeNHWCToNCHW-LayoutOptimizer, conv2d_1/kernel/read)]]\"\r\n\r\nmy database has 3 folders( train, test and validation). train and validation have 7 classes. train contains 564 images and validation contains 191 images. it is smal database but I do not know why it produces this error! could you please guide me about this problem? I do not know how can I solve this?\r\n\r\n```\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nfrom keras.preprocessing.image import ImageDataGenerator\r\nfrom sklearn.utils import shuffle\r\nfrom sklearn.cross_validation import train_test_split\r\nfrom keras import backend as K\r\n#K.set_image_dim_ordering('th')\r\n\r\nfrom keras.utils import np_utils\r\nfrom keras.models import Sequential\r\nfrom keras.layers.core import Dense, Dropout, Activation, Flatten\r\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\r\nfrom keras.optimizers import SGD,RMSprop,adam\r\n\r\n\r\ntrain_datagen = ImageDataGenerator(\r\n        rescale=1./255,\r\n        shear_range=0.2,\r\n        zoom_range=0.2,\r\n        horizontal_flip=True)\r\n#\r\nvalid_datagen = ImageDataGenerator(\r\n        rescale=1./255,\r\n        shear_range=0.2,\r\n        zoom_range=0.2,\r\n        horizontal_flip=True)\r\n#\r\ntest_datagen = ImageDataGenerator(rescale=1./255)\r\n#\r\ntrain_generator = train_datagen.flow_from_directory(\r\n    directory=r\"E:\\databasetest\\train\",\r\n    target_size=(512, 512),\r\n    color_mode=\"grayscale\",\r\n    batch_size=32,\r\n    class_mode=\"categorical\",\r\n    shuffle=True,\r\n    seed=42\r\n)\r\n#\r\nvalid_generator = valid_datagen.flow_from_directory(\r\n   directory=r\"E:\\databasetest\\validation\",\r\n    target_size=(512, 512),\r\n    color_mode=\"grayscale\",\r\n    batch_size=32,\r\n    class_mode=\"categorical\",\r\n    shuffle=True,\r\n    seed=42\r\n)\r\n#\r\ntest_generator = test_datagen.flow_from_directory(\r\n    directory=r\"E:\\databasetest\\test\",\r\n    target_size=(512, 512),\r\n    color_mode=\"grayscale\",\r\n    batch_size=16,\r\n    class_mode=None,\r\n    shuffle=False,\r\n    seed=42\r\n)\r\n#\r\n## neural network model\r\nmodel = Sequential()\r\nmodel.add(Conv2D(32, (3,3),border_mode='same', input_shape = (512, 512, 1), activation = 'relu'))\r\nmodel.add(Activation('relu'))\r\nmodel.add(Conv2D(32, 3, 3))\r\nmodel.add(Activation('relu'))\r\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\r\nmodel.add(Dropout(0.5))\r\n\r\nmodel.add(Conv2D(64, 3, 3))\r\nmodel.add(Activation('relu'))\r\n#model.add(Convolution2D(64, 3, 3))\r\n#model.add(Activation('relu'))\r\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\r\nmodel.add(Dropout(0.5))\r\n\r\nmodel.add(Flatten())\r\nmodel.add(Dense(64))\r\nmodel.add(Activation('relu'))\r\nmodel.add(Dropout(0.5))\r\nmodel.add(Dense(7))\r\nmodel.add(Activation('softmax'))\r\n\r\nmodel.summary()\r\n\r\nmodel.compile(loss = 'categorical_crossentropy',\r\n              optimizer = 'rmsprop',\r\n              metrics = ['accuracy'])\r\nSTEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\r\nSTEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\r\nmodel.fit_generator(generator=train_generator,\r\n                    steps_per_epoch=STEP_SIZE_TRAIN,\r\n                    validation_data=valid_generator,\r\n                    validation_steps=STEP_SIZE_VALID,\r\n                    epochs=10\r\n)\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "A `ResourceExhaustedError` is typically raised when a particular tensor could not be allocated on the requested device. \r\n@nadianaji could you add additional details on your GPU? Is the same GPU being used to drive a display? What's the output of `nvidia-smi`? ", "> A `ResourceExhaustedError` is typically raised when a particular tensor could not be allocated on the requested device.\r\n> @nadianaji could you add additional details on your GPU? Is the same GPU being used to drive a display? What's the output of `nvidia-smi`?\r\n\r\nmy GPU model is GeForce GTX 1050 Ti. I have 16 GB RAM. yes it is the same GPU to drive a display. what should I do now? I need some help", "@nadianaji a 1050 Ti has a limited amount of memory (4 GB). My recommendations:\r\n    - Try reducing your `target_size` from `(512, 512)` to something more manageable. I would start from a small patch such as 64 or 128 and move from there until the `ResourceExhaustedError` is raised again.\r\n    - Try reducing the batch size (this wouldn't be my first choice, but something like 16 could also help reduce pressure on the memory).\r\n\r\nI am almost certain that reducing your `target_size` would definitely help. Let me know if this helps.", "thank you for the response. what is this memory (4GB)? is it different from RAM?", "You are most welcomed. \r\n\r\nTypically discrete GPUs have dedicated graphics memory. If I\u2019m not mistaken, the 1050 Ti has 4 GB of GDDR5 memory. Although you have 16 GB of main memory for your host CPU, your GPU is limited to the available discrete memory. Since you are also driving a display, you probably have around 3.5 GB available for TensorFlow.\r\n\r\nIf this resolves your issue, you can go ahead and mark it as solved. If not, please let me know.", "Hello ,\r\n\r\nI Found the same issue on Kaggle with GPU enable and RAM upto 14 GB\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nconv2d_92 (Conv2D)           (None, 148, 148, 32)      320       \r\n_________________________________________________________________\r\nflatten_8 (Flatten)          (None, 700928)            0         \r\n_________________________________________________________________\r\ndense_22 (Dense)             (None, 15)                10513935  \r\n=================================================================\r\nTotal params: 10,514,255\r\nTrainable params: 10,514,255\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\n\r\n\r\n---------------------------------------------------------------------------\r\nResourceExhaustedError                    Traceback (most recent call last)\r\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1291     try:\r\n-> 1292       return fn(*args)\r\n   1293     except errors.OpError as e:\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)\r\n   1276       return self._call_tf_sessionrun(\r\n-> 1277           options, feed_dict, fetch_list, target_list, run_metadata)\r\n   1278 \r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py in _call_tf_sessionrun(self, options, feed_dict, fetch_list, target_list, run_metadata)\r\n   1366         self._session, options, feed_dict, fetch_list, target_list,\r\n-> 1367         run_metadata)\r\n   1368 \r\n\r\nResourceExhaustedError: OOM when allocating tensor with shape[700928,15] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n\t [[{{node training_7/Adam/Variable_6/Assign}} = Assign[T=DT_FLOAT, _grappler_relax_allocator_constraints=true, use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_7/Adam/Variable_6, training_7/Adam/zeros_2)]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nResourceExhaustedError                    Traceback (most recent call last)\r\n<ipython-input-111-68d8efa0c1a3> in <module>\r\n      8 datagen.fit(data)\r\n      9 val = datagen.flow(data , one_hot_target , batch_size=32)\r\n---> 10 history =  model.fit_generator(val , steps_per_epoch=10 , epochs=100)\r\n     11 \r\n     12 # train_datagen = ImageDataGenerator(\r\n\r\n/opt/conda/lib/python3.6/site-packages/Keras-2.2.4-py3.6.egg/keras/legacy/interfaces.py in wrapper(*args, **kwargs)\r\n     89                 warnings.warn('Update your `' + object_name + '` call to the ' +\r\n     90                               'Keras 2 API: ' + signature, stacklevel=2)\r\n---> 91             return func(*args, **kwargs)\r\n     92         wrapper._original_function = func\r\n     93         return wrapper\r\n\r\n/opt/conda/lib/python3.6/site-packages/Keras-2.2.4-py3.6.egg/keras/engine/training.py in fit_generator(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\r\n   1416             use_multiprocessing=use_multiprocessing,\r\n   1417             shuffle=shuffle,\r\n-> 1418             initial_epoch=initial_epoch)\r\n   1419 \r\n   1420     @interfaces.legacy_generator_methods_support\r\n\r\n/opt/conda/lib/python3.6/site-packages/Keras-2.2.4-py3.6.egg/keras/engine/training_generator.py in fit_generator(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\r\n    213                 outs = model.train_on_batch(x, y,\r\n    214                                             sample_weight=sample_weight,\r\n--> 215                                             class_weight=class_weight)\r\n    216 \r\n    217                 outs = to_list(outs)\r\n\r\n/opt/conda/lib/python3.6/site-packages/Keras-2.2.4-py3.6.egg/keras/engine/training.py in train_on_batch(self, x, y, sample_weight, class_weight)\r\n   1215             ins = x + y + sample_weights\r\n   1216         self._make_train_function()\r\n-> 1217         outputs = self.train_function(ins)\r\n   1218         return unpack_singleton(outputs)\r\n   1219 \r\n\r\n/opt/conda/lib/python3.6/site-packages/Keras-2.2.4-py3.6.egg/keras/backend/tensorflow_backend.py in __call__(self, inputs)\r\n   2695 \r\n   2696     def __call__(self, inputs):\r\n-> 2697         if hasattr(get_session(), '_make_callable_from_options'):\r\n   2698             if py_any(is_sparse(x) for x in self.inputs):\r\n   2699                 if py_any(is_tensor(x) for x in inputs):\r\n\r\n/opt/conda/lib/python3.6/site-packages/Keras-2.2.4-py3.6.egg/keras/backend/tensorflow_backend.py in get_session()\r\n    204                     v._keras_initialized = True\r\n    205                 if uninitialized_vars:\r\n--> 206                     session.run(tf.variables_initializer(uninitialized_vars))\r\n    207     # hack for list_devices() function.\r\n    208     # list_devices() function is not available under tensorflow r1.3.\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n    885     try:\r\n    886       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 887                          run_metadata_ptr)\r\n    888       if run_metadata:\r\n    889         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n   1108     if final_fetches or final_targets or (handle and feed_dict_tensor):\r\n   1109       results = self._do_run(handle, final_targets, final_fetches,\r\n-> 1110                              feed_dict_tensor, options, run_metadata)\r\n   1111     else:\r\n   1112       results = []\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n   1284     if handle is None:\r\n   1285       return self._do_call(_run_fn, feeds, fetches, targets, options,\r\n-> 1286                            run_metadata)\r\n   1287     else:\r\n   1288       return self._do_call(_prun_fn, handle, feeds, fetches)\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1306           self._config.experimental.client_handles_error_formatting):\r\n   1307         message = error_interpolation.interpolate(message, self._graph)\r\n-> 1308       raise type(e)(node_def, op, message)\r\n   1309 \r\n   1310   def _extend_graph(self):\r\n\r\nResourceExhaustedError: OOM when allocating tensor with shape[700928,15] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n\t [[{{node training_7/Adam/Variable_6/Assign}} = Assign[T=DT_FLOAT, _grappler_relax_allocator_constraints=true, use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_7/Adam/Variable_6, training_7/Adam/zeros_2)]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\r\nCaused by op 'training_7/Adam/Variable_6/Assign', defined at:\r\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\r\n    app.launch_new_instance()\r\n  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\r\n    app.start()\r\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 499, in start\r\n    self.io_loop.start()\r\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 132, in start\r\n    self.asyncio_loop.run_forever()\r\n  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\r\n    self._run_once()\r\n  File \"/opt/conda/lib/python3.6/asyncio/base_events.py\", line 1434, in _run_once\r\n    handle._run()\r\n  File \"/opt/conda/lib/python3.6/asyncio/events.py\", line 145, in _run\r\n    self._callback(*self._args)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 758, in _run_callback\r\n    ret = callback()\r\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\r\n    return fn(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1233, in inner\r\n    self.run()\r\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\r\n    yielded = self.gen.send(value)\r\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 359, in dispatch_queue\r\n    yield self.process_one()\r\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 346, in wrapper\r\n    runner = Runner(result, future, yielded)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1080, in __init__\r\n    self.run()\r\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 1147, in run\r\n    yielded = self.gen.send(value)\r\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 346, in process_one\r\n    yield gen.maybe_future(dispatch(*args))\r\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\r\n    yielded = next(result)\r\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 259, in dispatch_shell\r\n    yield gen.maybe_future(handler(stream, idents, msg))\r\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\r\n    yielded = next(result)\r\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 513, in execute_request\r\n    user_expressions, allow_stdin,\r\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/gen.py\", line 326, in wrapper\r\n    yielded = next(result)\r\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\r\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\r\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2817, in run_cell\r\n    raw_cell, store_history, silent, shell_futures)\r\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2843, in _run_cell\r\n    return runner(coro)\r\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\r\n    coro.send(None)\r\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3018, in run_cell_async\r\n    interactivity=interactivity, compiler=compiler, result=result)\r\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3183, in run_ast_nodes\r\n    if (yield from self.run_code(code, result)):\r\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3265, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-111-68d8efa0c1a3>\", line 10, in <module>\r\n    history =  model.fit_generator(val , steps_per_epoch=10 , epochs=100)\r\n  File \"/opt/conda/lib/python3.6/site-packages/Keras-2.2.4-py3.6.egg/keras/legacy/interfaces.py\", line 91, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.6/site-packages/Keras-2.2.4-py3.6.egg/keras/engine/training.py\", line 1418, in fit_generator\r\n    initial_epoch=initial_epoch)\r\n  File \"/opt/conda/lib/python3.6/site-packages/Keras-2.2.4-py3.6.egg/keras/engine/training_generator.py\", line 39, in fit_generator\r\n    model._make_train_function()\r\n  File \"/opt/conda/lib/python3.6/site-packages/Keras-2.2.4-py3.6.egg/keras/engine/training.py\", line 509, in _make_train_function\r\n    loss=self.total_loss)\r\n  File \"/opt/conda/lib/python3.6/site-packages/Keras-2.2.4-py3.6.egg/keras/legacy/interfaces.py\", line 91, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.6/site-packages/Keras-2.2.4-py3.6.egg/keras/optimizers.py\", line 488, in get_updates\r\n    vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\r\n  File \"/opt/conda/lib/python3.6/site-packages/Keras-2.2.4-py3.6.egg/keras/optimizers.py\", line 488, in <listcomp>\r\n    vs = [K.zeros(K.int_shape(p), dtype=K.dtype(p)) for p in params]\r\n  File \"/opt/conda/lib/python3.6/site-packages/Keras-2.2.4-py3.6.egg/keras/backend/tensorflow_backend.py\", line 704, in zeros\r\n    return variable(v, dtype=dtype, name=name)\r\n  File \"/opt/conda/lib/python3.6/site-packages/Keras-2.2.4-py3.6.egg/keras/backend/tensorflow_backend.py\", line 402, in variable\r\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 145, in __call__\r\n    return cls._variable_call(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 141, in _variable_call\r\n    aggregation=aggregation)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 120, in <lambda>\r\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2441, in default_variable_creator\r\n    expected_shape=expected_shape, import_scope=import_scope)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 147, in __call__\r\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1104, in __init__\r\n    constraint=constraint)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1256, in _init_from_args\r\n    validate_shape=validate_shape).op\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 221, in assign\r\n    validate_shape=validate_shape)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 61, in assign\r\n    use_locking=use_locking, name=name)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3272, in create_op\r\n    op_def=op_def)\r\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1768, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[700928,15] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n\t [[{{node training_7/Adam/Variable_6/Assign}} = Assign[T=DT_FLOAT, _grappler_relax_allocator_constraints=true, use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_7/Adam/Variable_6, training_7/Adam/zeros_2)]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\r\n\r\n", "@nadianaji Is this still an issue for you?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Hello!\r\n\r\nI stumbled on this post, and I know that it has been closed for more than a year now. However, I got the same problem when using 3D CNN with Keras on my machine.\r\nThe weird thing is that when checking the memory allocation on my machine it does not even get close to saturation before this OOM error appears.\r\nI have 64 GB of RAM, 2 GPUs (NVIDIA Quadro P5000). The GPUs have a dedicated memory of 16 GB and 32 GB of shared memory.\r\nI'm only using 2 layers of conv3D of size 16 each. When I go up to 32, I get the OOM error.\r\n\r\nCan you please help? Is this purely a memory hardware problem? Or could it be something else? (software, tensorflow, etc.)\r\n\r\nThank you!\r\n\r\nHere is the code for building the model:\r\n\r\n    model = Sequential()\r\n    model.add(Conv3D(32, kernel_size=(3,3,3),  kernel_regularizer=l2(l2_lambda), activation='selu', padding='same', kernel_initializer='glorot_uniform', input_shape=(64, 64, 38, 1)))\r\n    model.add(MaxPooling3D(pool_size=(2,2,2)))\r\n\r\n    model.add(Conv3D(32, kernel_size=(3,3,3),  kernel_regularizer=l2(l2_lambda), activation='selu', padding='same', kernel_initializer='glorot_uniform', input_shape=(64, 64, 38, 1)))\r\n    model.add(MaxPooling3D(pool_size=(2,2,2)))\r\n\r\n    model.add(Flatten())\r\n    model.add(Dense(256, kernel_regularizer=l2(l2_lambda), activation='selu', kernel_initializer='glorot_uniform'))\r\n\r\n    model.add(Dense(no_classes, activation='softmax'))\r\n    model = multi_gpu_model(model, gpus = 2)\r\n    # Compile the model\r\n    model.compile(loss=keras.losses.categorical_crossentropy,\r\n                optimizer=keras.optimizers.Adam(lr=learning_rate),\r\n                metrics=['accuracy'])"]}, {"number": 23197, "title": "Fix error that bugs Keras during multi-gpu with batch normalization", "body": "Here are the issues that lead to this bug:\r\nhttps://github.com/keras-team/keras/issues/10008\r\nhttps://github.com/keras-team/keras/issues/10490\r\n\r\nIf you use `multi_gpu_model` in Keras, it causes an error.  I tracked this to the following stack:\r\n\r\n```\r\n  File \"/home/sean/env3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 1858, in normalize_batch_in_training\r\n    if not _has_nchw_support() and list(reduction_axes) == [0, 2, 3]:\r\n  File \"/home/sean/env3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 291, in _has_nchw_support\r\n    explicitly_on_cpu = _is_current_explicit_device('CPU')\r\n  File \"/home/sean/env3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 266, in _is_current_explicit_device\r\n    device = _get_current_tf_device()\r\n  File \"/home/sean/env3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 247, in _get_current_tf_device\r\n    g._apply_device_functions(op)\r\n  File \"/home/sean/env3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 4259, in _apply_device_functions\r\n    op._set_device(device_spec.function(op))\r\n  File \"/home/sean/env3/lib/python3.6/site-packages/tensorflow/python/framework/device.py\", line 306, in _device_function\r\n    current_device = DeviceSpec.from_string(node_def.device or \"\")\r\n  File \"/home/sean/env3/lib/python3.6/site-packages/tensorflow/python/framework/device.py\", line 231, in from_string\r\n    return DeviceSpec().parse_from_string(spec)\r\n  File \"/home/sean/env3/lib/python3.6/site-packages/tensorflow/python/framework/device.py\", line 149, in parse_from_string\r\n    splits = [x.split(\":\") for x in spec.split(\"/\")]\r\nAttributeError: 'DeviceSpec' object has no attribute 'split'\r\n```\r\n\r\nThe fix is that for some reason, the node_def.device from `device.py` is being passed in as a `DeviceSpec` instance, not a string as expected.  However, I noticed a couple of lines above that, there is a check to see if `spec` is a `DeviceSpec` instance.  I went ahead and added this check to this line as well, and it fixes the issue.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "Also what about unit tests and such? I'm not familiar with contributing to this project.", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "@owsd Can you please resolve the merge conflicts and make requested changes to move ahead with this PR? Thanks!", "@owsd  gentle ping to resolve the merge conflicts", "I am facing the same problem on TF 1.13.1 and keras 2.2.4.\r\n\r\nI have tracked it one step further to:\r\n`self._device_function_stack.peek_objs()` in `_apply_device_functions(self, op)` returning a `<tensorflow.python.framework.device.DeviceSpec object at 0x7fc3ab9259e8>` as second in iteration.\r\n\r\n```python3.6/site-packages/keras/backend/tensorflow_backend.py in _get_current_tf_device()\r\n    246     op = _TfDeviceCaptureOp()\r\n    247     print('K.', op.device)\r\n--> 248     g._apply_device_functions(op)\r\n    249     return op.device\r\n    250 \r\n\r\npython3.6/site-packages/tensorflow/python/framework/ops.py in _apply_device_functions(self, op)\r\n   4244       if device_spec.function is None:\r\n   4245         break\r\n-> 4246       op._set_device(device_spec.function(op))\r\n   4247     op._device_code_locations = self._snapshot_device_function_stack_metadata()\r\n   4248     # pylint: enable=protected-access\r\n\r\npython3.6/site-packages/tensorflow/python/framework/device.py in _device_function(node_def)\r\n    313     def _device_function(node_def):\r\n    314       print(\"-\", node_def.device, \"-\")\r\n--> 315       current_device = DeviceSpec.from_string(node_def.device or \"\")\r\n```\r\n\r\nFrom my reading this does not seem to be dependent on the way keras calls tensorflow, but dependent on the population of the device_function_stack of the graph.\r\n\r\nedit: the device_function_stack is the graph_device_function_stack\r\nUnfortunately, I can't really determine how to reproduce the error, but I tried to multi_gpu_model() a pretrained DenseNet121 from keras.", "I cant really provide a better minimal working example right now, but maybe this helps.\r\n\r\n[tensorflow_23197_minimal.py.txt](https://github.com/tensorflow/tensorflow/files/3026051/tensorflow_23197_minimal.py.txt)\r\n", "However, this Pull Requests solution seems to fix things."]}, {"number": 23196, "title": "sess.run() returns inconsistent results", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): b'v1.10.1-0-g4dcfddc' 1.10.1\r\n- Python version: Python 3.6.6 :: Anaconda, Inc.\r\n- Bazel version (if compiling from source): Build label: 0.16.1\r\n- GCC/Compiler version (if compiling from source): gcc (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\n- CUDA/cuDNN version: CUDA 8.0, CuDNN 7\r\n- GPU model and memory: GeForce GTX 1080 Ti x 4\r\n\r\n\r\n```\r\n\r\n== cat /etc/issue ===============================================\r\nLinux *** 4.15.0-36-generic #39~16.04.1-Ubuntu SMP Tue Sep 25 08:59:23 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"16.04.5 LTS (Xenial Xerus)\"\r\nVERSION_ID=\"16.04\"\r\nVERSION_CODENAME=xenial\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux *** 4.15.0-36-generic #39~16.04.1-Ubuntu SMP Tue Sep 25 08:59:23 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy            1.14.5   \r\nprotobuf         3.6.1    \r\ntensorflow       1.10.1   \r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.10.1\r\ntf.GIT_VERSION = b'v1.10.1-0-g4dcfddc'\r\ntf.COMPILER_VERSION = b'v1.10.1-0-g4dcfddc'\r\nSanity check: array([1], dtype=int32)\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH /usr/local/cuda/extras/CUPTI/lib64\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nWed Oct 24 04:18:19 2018       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 108...  Off  | 00000000:05:00.0  On |                  N/A |\r\n| 47%   67C    P0    80W / 250W |    144MiB / 11175MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  GeForce GTX 108...  Off  | 00000000:06:00.0 Off |                  N/A |\r\n| 76%   87C    P2   152W / 250W |   8428MiB / 11178MiB |    100%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  GeForce GTX 108...  Off  | 00000000:09:00.0 Off |                  N/A |\r\n| 43%   64C    P2    81W / 250W |   4774MiB / 11178MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  GeForce GTX 108...  Off  | 00000000:0A:00.0 Off |                  N/A |\r\n| 26%   43C    P0    73W / 250W |     12MiB / 11178MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0      1426      G   /usr/lib/xorg/Xorg                            51MiB |\r\n|    0      3507      G   /usr/lib/xorg/Xorg                            14MiB |\r\n|    1      9564      C   python                                      5133MiB |\r\n|    1     14381      C   /home/***/torch/install/bin/luajit         3283MiB |\r\n|    2      7595      C   python                                      4611MiB |\r\n|    2     12553      C   python                                       151MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/lib/python3.5/dist-packages/torch/lib/libcudart-5d6d23a3.so.8.0.61\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart_static.a\r\n/usr/local/cuda-8.0/targets/x86_64-linux/lib/libcudart.so.8.0.61\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-8.0/doc/man/man7/libcudart.7\r\n\r\n```\r\n\r\n**Describe the current behavior**\r\nConsider following two source codes\r\n```Python\r\nimport tensorflow as tf\r\n\r\nimg = tf.random_normal((10, 10, 3), dtype=tf.float32, seed=12345)\r\nmask = tf.random_normal((10, 10, 1), dtype=tf.float32, seed=12345)\r\n\r\nnormalization_factor = tf.reduce_sum(mask) * 3\r\nmasked_img = img * mask\r\nmasked_img_sqr = img * masked_img # = img ^ 2 * mask\r\n\r\nmean = tf.reduce_sum(masked_img) / normalization_factor\r\nvariance = tf.reduce_sum(masked_img_sqr) / normalization_factor\r\nvariance = variance - tf.square(mean)\r\nadjusted_variance = tf.maximum(variance, 1. / normalization_factor)\r\nstddev = tf.sqrt(variance)\r\n\r\nimg = (img - mean) / stddev\r\nwhiten_img = img\r\n\r\nrand = tf.random_normal(\r\n    shape=(10, 10, 3),\r\n    mean=0., stddev=1., dtype=tf.float32,\r\n    seed=12345, name='random_back')\r\nimg = img * mask + rand * (1 - mask)\r\n\r\nimg = tf.concat([img, mask], axis=-1)\r\n\r\n\r\ndebug_info = {\r\n  'mean': mean,\r\n  'variance': variance,\r\n  'stddev': stddev,\r\n  'adjusted_variance': adjusted_variance,\r\n  'threshold': 1. / normalization_factor,\r\n  'normalization_factor': normalization_factor,\r\n  'whiten_img_minmax': [tf.reduce_min(whiten_img[..., :3]), tf.reduce_max(whiten_img[..., :3])],\r\n  'minmax_mask': [tf.reduce_min(img[..., 3]), tf.reduce_max(img[..., 3])],\r\n}\r\n\r\nwith tf.Session() as sess:\r\n  print(sess.run(debug_info))\r\n```\r\n\r\n```Python\r\nimport tensorflow as tf\r\n\r\nimg = tf.random_normal((10, 10, 3), dtype=tf.float32, seed=12345)\r\nmask = tf.random_normal((10, 10, 1), dtype=tf.float32, seed=12345)\r\n\r\nnormalization_factor = tf.reduce_sum(mask) * 3\r\nmasked_img = img * mask\r\nmasked_img_sqr = img * masked_img # = img ^ 2 * mask\r\n\r\nmean = tf.reduce_sum(masked_img) / normalization_factor\r\nvariance = tf.reduce_sum(masked_img_sqr) / normalization_factor\r\nvariance = variance - tf.square(mean)\r\nadjusted_variance = tf.maximum(variance, 1. / normalization_factor)\r\nstddev = tf.sqrt(variance)\r\n\r\nimg = (img - mean) / stddev\r\nwhiten_img = img\r\n\r\nrand = tf.random_normal(\r\n    shape=(10, 10, 3),\r\n    mean=0., stddev=1., dtype=tf.float32,\r\n    seed=12345, name='random_back')\r\nimg = img * mask + rand * (1 - mask)\r\n\r\nimg = tf.concat([img, mask], axis=-1)\r\n\r\n\r\ndebug_info = {\r\n  'mean': mean,\r\n  'variance': variance,\r\n  'stddev': stddev + 0,\r\n  'adjusted_variance': adjusted_variance,\r\n  'threshold': 1. / normalization_factor,\r\n  'normalization_factor': normalization_factor,\r\n  'whiten_img_minmax': [tf.reduce_min(whiten_img[..., :3]), tf.reduce_max(whiten_img[..., :3])],\r\n  'minmax_mask': [tf.reduce_min(img[..., 3]), tf.reduce_max(img[..., 3])],\r\n}\r\n\r\nwith tf.Session() as sess:\r\n  print(sess.run(debug_info))\r\n```\r\n\r\nThe only difference between them is `'stddev': stddev,` and `'stddev': stddev + 0,`\r\n\r\nBut the first code (with `'stddev': stddev,`) outputs\r\n```\r\n{..., 'stddev': 1.1902559, ...}\r\n```\r\nand the second (with `'stddev': stddev + 0,`) outputs\r\n```\r\n{..., 'stddev': 0.8401555, ...}\r\n```\r\n\r\nIt seems like that the correct output is `'stddev': 0.8401555,`\r\nBut in the first code, `1./stddev = 1./0.8401555 = 1.1902559` was calculated\r\n\r\nHere is the screenshot\r\n![image](https://user-images.githubusercontent.com/5780122/47388961-15e7de80-d746-11e8-8959-f37c46e66c8b.png)\r\n\r\n\r\n**Describe the expected behavior**\r\n\r\nThe outputs of two codes should be correct (consistent at least) \r\n\r\n**Code to reproduce the issue**\r\n\r\n**Other info / logs**\r\n", "comments": ["The bug can be reproduced with a shorter snippet:\r\n```python\r\nimport tensorflow as tf\r\n\r\nmask = tf.random_normal((10, 10, 1), dtype=tf.float32, seed=12345)\r\nX = tf.reduce_sum(mask * mask)\r\nsqrtX = tf.sqrt(X)\r\noutput = tf.reduce_min(mask / sqrtX)\r\n\r\nwith tf.Session() as sess:\r\n    print(sess.run([X, sqrtX, output]))\r\n# prints [121.88353, 0.09057899, -0.22156183]\r\n# however 0.09 != sqrt(121.88), but 0.09 == 1.0 / sqrt(1212.88)\r\n```\r\n", "> The bug can be reproduced with a shorter snippet:\r\n> \r\n> ```python\r\n> import tensorflow as tf\r\n> \r\n> mask = tf.random_normal((10, 10, 1), dtype=tf.float32, seed=12345)\r\n> X = tf.reduce_sum(mask * mask)\r\n> sqrtX = tf.sqrt(X)\r\n> output = tf.reduce_min(mask / sqrtX)\r\n> \r\n> with tf.Session() as sess:\r\n>     print(sess.run([X, sqrtX, output]))\r\n> # prints [121.88353, 0.09057899, -0.22156183]\r\n> # however 0.09 != sqrt(121.88), but 0.99 == 1.0 / sqrt(1212.88)\r\n> ```\r\n\r\nThank you for simplifying my code to reproduce the same problem.", "According to my experiments, the shorter bug-reproducing code leads to correct `[121.88354, 11.040088, -0.22156183]` on tensorflow-gpu v1.8.0 and v1.9.0, but prints incorrect `[121.88354, 0.09057899, -0.22156183]` on tensorflow-gpu v1.10.0.", "@ppwwyyxx @shyoshyo @csy530216 The issue has been solved in the latest version `tb-nightly 1.13.0a20181104`.", "Nagging Assignee @harshini-gadige: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 23195, "title": "Segfault reading dataset more than once (`make_batched_features_dataset`)", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **No**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **macOS 10.14 Mojave**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **NA**\r\n- TensorFlow installed from (source or binary): **Binary / pip**\r\n- TensorFlow version (use command below): **`('v1.11.0-rc2-4-gc19e29306c', '1.11.0')`**\r\n- Python version: **2.7.10**\r\n- Bazel version (if compiling from source): **NA**\r\n- GCC/Compiler version (if compiling from source): **NA**\r\n- CUDA/cuDNN version: **NA**\r\n- GPU model and memory: **NA**\r\n\r\n[Gist of full output of `./tools/tf_env_collect.sh](https://gist.github.com/brianmartin/2b43dca69453478ed33b49f1029e03fe)\r\n\r\n**Exact command to reproduce:**\r\n\r\n```\r\n$ wget https://gist.githubusercontent.com/brianmartin/4f221eb838dce8099342f829fb13253d/raw/00c2a1736b9a292f8a6fb88164d240a766468744/gistfile1.txt\r\n$ python gistfile1.txt\r\n```\r\n\r\n**Describe the current behavior**\r\n\r\nCurrent behavior in 1.11.0, 1.12.0rcX is that the included script segfaults (11: SIGSEGV).\r\n\r\n**Describe the expected behavior**\r\n\r\nExpected behavior is no segfault. Version 1.10.1, 1.10.0, and 1.9.0 do not segfault. I have not checked lower versions.\r\n\r\n**Code to reproduce the issue**\r\n\r\nSee a full script which reproduces this issue along two different code paths here: https://gist.github.com/brianmartin/4f221eb838dce8099342f829fb13253d\r\n\r\nThe segfault occurs when reading the dataset a second time. The first read works as expected.\r\n\r\nFor reference the two code samples which produce datasets which cause a segfault on second read are:\r\n\r\n```py\r\n    dataset = make_batched_features_dataset(file_pattern=data_file,\r\n                                            batch_size=1,\r\n                                            features=feature_spec)\r\n```\r\n\r\nI've also dug into `make_batched_features_dataset` and minified down to this repro:\r\n\r\n```py\r\n    from tensorflow.contrib.data.python.ops import parsing_ops\r\n    from tensorflow.python.data.ops import readers\r\n\r\n    dataset = Dataset.from_tensor_slices([data_file]) \\\r\n                     .interleave(readers.TFRecordDataset, cycle_length=1) \\\r\n                     .batch(batch_size=1) \\\r\n                     .apply(parsing_ops.parse_example_dataset(feature_spec))\r\n```\r\n\r\n------\r\n\r\nPlease let me know if there's anything else I can provide or help with! This is blocking us from upgrading to the latest Tensorflow version in [spotify/spotify-tensorflow](https://github.com/spotify/spotify-tensorflow).", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Updated!", "@shivaniag As we discussed offline, can you please take a look at this issue, in case there\u2019s a bug in `ParseExampleDataset`? Thanks!", "I've dug in a bit more. For a FixedLenFeature, this test case still succeeds on the first read and fails on the second read -- no change there. But it fails with an exception rather than the segfault we see with VarLenFeature.\r\n\r\nI've updated the gist to reproduce in tensorflow>=1.11.0 here: https://gist.github.com/brianmartin/4f221eb838dce8099342f829fb13253d\r\n\r\nThe exception on the second, failing read (after seeing the first read succeed):\r\n\r\n```\r\nAttempting first read..\r\n2018-10-30 10:53:26.766551: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n{'f0': <tf.Tensor: id=26, shape=(1, 1), dtype=int64, numpy=array([[1]])>}\r\nAttempting second identical read..\r\nTraceback (most recent call last):\r\n  File \"/Users/brianm/wrk/spotify-tensorflow-brianmartin/scratch.py\", line 109, in <module>\r\n    main()\r\n  File \"/Users/brianm/wrk/spotify-tensorflow-brianmartin/scratch.py\", line 104, in main\r\n    run(make_it_fail, read_fn, var_len=var_len)\r\n  File \"/Users/brianm/wrk/spotify-tensorflow-brianmartin/scratch.py\", line 79, in run\r\n    _print_first(read_fn(data_file, feature_spec))\r\n  File \"/Users/brianm/wrk/spotify-tensorflow-brianmartin/scratch.py\", line 35, in _print_first\r\n    print next(xs.__iter__())\r\n  File \"/Users/brianm/wrk/spotify-tensorflow-brianmartin/venv/lib/python2.7/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 139, in __iter__\r\n    return iterator_ops.EagerIterator(self)\r\n  File \"/Users/brianm/wrk/spotify-tensorflow-brianmartin/venv/lib/python2.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 521, in __init__\r\n    ds_variant = dataset._as_variant_tensor()  # pylint: disable=protected-access\r\n  File \"/Users/brianm/wrk/spotify-tensorflow-brianmartin/venv/lib/python2.7/site-packages/tensorflow/contrib/data/python/ops/parsing_ops.py\", line 90, in _as_variant_tensor\r\n    **dataset_ops.flat_structure(self))\r\n  File \"/Users/brianm/wrk/spotify-tensorflow-brianmartin/venv/lib/python2.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 3963, in parse_example_dataset\r\n    ctx=_ctx)\r\n  File \"/Users/brianm/wrk/spotify-tensorflow-brianmartin/venv/lib/python2.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 4015, in parse_example_dataset_eager_fallback\r\n    attrs=_attrs, ctx=_ctx, name=name)\r\n  File \"/Users/brianm/wrk/spotify-tensorflow-brianmartin/venv/lib/python2.7/site-packages/tensorflow/python/eager/execute.py\", line 66, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"/Users/brianm/wrk/spotify-tensorflow-brianmartin/venv/lib/python2.7/site-packages/six.py\", line 737, in raise_from\r\n    raise value\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Expected len(dense_defaults) == len(dense_keys) but got: 1 vs. 0 [Op:ParseExampleDataset]\r\n```\r\n", "@brianmartin Thank you very much for narrowing down the bug, we have fixed it and are going to submit it soon, will update you when that is done."]}, {"number": 23194, "title": "Add support for ppc64le in dockerfiles", "body": "Enable dockerfile editing environment for ppc64le\r\nAdd new .Dockerfile and .partial.Dockerfile files for ppc64le architecture.", "comments": ["Related to https://github.com/tensorflow/tensorflow/issues/14934", "Nagging Assignee @ymodak: It has been 25 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 23193, "title": "Prevent Empty Checkpointable Data Structure Restores", "body": "Referes to Issue https://github.com/tensorflow/tensorflow/issues/23192", "comments": []}, {"number": 23191, "title": "Build from source Java", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): r1.11\r\n- Python version:3.6\r\n- Installed using virtualenv? pip? conda?: conda\r\n- Bazel version (if compiling from source): 0.18.0\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: nVidia970M\r\n- Have I written custom code: N/A\r\n- TensorFlow version: r1.11\r\n- Exact command to reproduce: `bazel build --config=opt --config=cuda //tensorflow/java:tensorflow //tensorflow/java:libtensorflow_jni`\r\n\r\nError when installing tensorflow with java, generates the following error lines\r\n\r\n```\r\ntensorflow/java/BUILD:54:1: Building tensorflow/java/libprocessor_library-class.jar (1 source file) failed: Worker process quit or closed its stdin stream when we tried to send a WorkRequest:\r\n\r\n---8<---8<--- Exception details ---8<---8<---\r\njava.io.IOException:\r\n        at com.google.devtools.build.lib.windows.WindowsSubprocess.writeStream(WindowsSubprocess.java:252)\r\n        at com.google.devtools.build.lib.windows.WindowsSubprocess.access$000(WindowsSubprocess.java:33)\r\n        at com.google.devtools.build.lib.windows.WindowsSubprocess$ProcessOutputStream.write(WindowsSubprocess.java:52)\r\n        at com.google.protobuf.CodedOutputStream$OutputStreamEncoder.doFlush(CodedOutputStream.java:3003)\r\n        at com.google.protobuf.CodedOutputStream$OutputStreamEncoder.flushIfNotAvailable(CodedOutputStream.java:2998)\r\n        at com.google.protobuf.CodedOutputStream$OutputStreamEncoder.writeUInt32NoTag(CodedOutputStream.java:2825)\r\n        at com.google.protobuf.CodedOutputStream$OutputStreamEncoder.writeTag(CodedOutputStream.java:2670)\r\n        at com.google.protobuf.CodedOutputStream$OutputStreamEncoder.writeMessage(CodedOutputStream.java:2774)\r\n        at com.google.devtools.build.lib.worker.WorkerProtocol$WorkRequest.writeTo(WorkerProtocol.java:1009)\r\n        at com.google.protobuf.AbstractMessageLite.writeDelimitedTo(AbstractMessageLite.java:98)\r\n        at com.google.devtools.build.lib.worker.WorkerSpawnRunner.execInWorker(WorkerSpawnRunner.java:318)\r\n        at com.google.devtools.build.lib.worker.WorkerSpawnRunner.actuallyExec(WorkerSpawnRunner.java:160)\r\n        at com.google.devtools.build.lib.worker.WorkerSpawnRunner.exec(WorkerSpawnRunner.java:115)\r\n        at com.google.devtools.build.lib.exec.AbstractSpawnStrategy.exec(AbstractSpawnStrategy.java:106)\r\n        at com.google.devtools.build.lib.exec.AbstractSpawnStrategy.exec(AbstractSpawnStrategy.java:75)\r\n        at com.google.devtools.build.lib.exec.SpawnActionContextMaps$ProxySpawnActionContext.exec(SpawnActionContextMaps.java:362)\r\n        at com.google.devtools.build.lib.analysis.actions.SpawnAction.internalExecute(SpawnAction.java:288)\r\n        at com.google.devtools.build.lib.analysis.actions.SpawnAction.execute(SpawnAction.java:295)\r\n        at com.google.devtools.build.lib.skyframe.SkyframeActionExecutor.executeActionTask(SkyframeActionExecutor.java:994)\r\n        at com.google.devtools.build.lib.skyframe.SkyframeActionExecutor.prepareScheduleExecuteAndCompleteAction(SkyframeActionExecutor.java:923)\r\n        at com.google.devtools.build.lib.skyframe.SkyframeActionExecutor.access$800(SkyframeActionExecutor.java:121)\r\n        at com.google.devtools.build.lib.skyframe.SkyframeActionExecutor$ActionRunner.call(SkyframeActionExecutor.java:763)\r\n        at com.google.devtools.build.lib.skyframe.SkyframeActionExecutor$ActionRunner.call(SkyframeActionExecutor.java:718)\r\n        at java.base/java.util.concurrent.FutureTask.run(Unknown Source)\r\n        at com.google.devtools.build.lib.skyframe.SkyframeActionExecutor.executeAction(SkyframeActionExecutor.java:471)\r\n        at com.google.devtools.build.lib.skyframe.ActionExecutionFunction.checkCacheAndExecuteIfNeeded(ActionExecutionFunction.java:505)\r\n        at com.google.devtools.build.lib.skyframe.ActionExecutionFunction.compute(ActionExecutionFunction.java:215)\r\n        at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:418)\r\n        at com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$WrappedRunnable.run(AbstractQueueVisitor.java:368)\r\n        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n        at java.base/java.lang.Thread.run(Unknown Source)\r\n---8<---8<--- End of exception details ---8<---8<---\r\n\r\n---8<---8<--- Start of log, file at C:/users/eduar/_bazel_eduar/gr3cukxm/bazel-workers/worker-0-Javac.log ---8<---8<---\r\nError: Could not create the Java Virtual Machine.\r\nError: A fatal exception has occurred. Program will exit.\r\nUnrecognized VM option 'CompactStrings'\r\n---8<---8<--- End of log ---8<---8<---\r\nINFO: Elapsed time: 281.132s, Critical Path: 94.67s\r\nINFO: 602 processes: 602 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nTensorFlow version\nExact command to reproduce\nMobile device", "I would like to encourage you to refer to these [instructions](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/java/README.md) if you haven't already and recommend using CUDA version 9.0. [GPU support](https://www.tensorflow.org/install/gpu#windows_setup). Since TensorFlow is built and tested against CUDA 9.0. For using CUDA 10, you have to build yourself from sources. Also installation on Windows requires the more experimental [bazel on Windows](https://docs.bazel.build/versions/master/windows.html).", "yes, I have exactly followed the [instructions,](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/java/README.md) up to point three where it is declared\r\n\r\n````\r\n./configure\r\nbazel build --config opt \\\r\n  //tensorflow/java:tensorflow \\\r\n  //tensorflow/java:libtensorflow_jni\r\n````\r\nyes, I tried to create the package from the source with Cuda 10", "Looks like a bazel bug to me?", "Okay, but what is the solution?\r\n\r\nThe error is in this part `tensorflow/java/BUILD:54:1`\r\n\r\n```\r\njava_library(\r\n    name = \"processor_library\",\r\n    srcs = glob([\"src/gen/java/org/tensorflow/processor/**/*.java\"]),\r\n    javacopts = JAVACOPTS,\r\n    resources = glob([\"src/gen/resources/META-INF/services/javax.annotation.processing.Processor\"]),\r\n    deps = [\r\n        \"@com_google_guava\",\r\n        \"@com_squareup_javapoet\",\r\n    ],\r\n)\r\n````", "I have the same problem, the code updated last Friday, is this problem solved now?\r\nI compile on window7 and not ADD CUDA\r\n```\r\nERROR: D:/temp/tensorflow/tensorflow/java/BUILD:54:1: Building tensorflow/java/libprocessor_library-class.jar (1 source file) failed: Worker process quit or closed its stdin stream when we tried to send a WorkRequest:\r\n\r\n---8<---8<--- Exception details ---8<---8<---\r\njava.io.IOException:\r\n        at com.google.devtools.build.lib.windows.WindowsSubprocess.writeStream(WindowsSubprocess.java:252)\r\n        at com.google.devtools.build.lib.windows.WindowsSubprocess.access$000(WindowsSubprocess.java:33)\r\n        at com.google.devtools.build.lib.windows.WindowsSubprocess$ProcessOutputStream.write(WindowsSubprocess.java:52)\r\n        at com.google.protobuf.CodedOutputStream$OutputStreamEncoder.doFlush(CodedOutputStream.java:3003)\r\n        at com.google.protobuf.CodedOutputStream$OutputStreamEncoder.flushIfNotAvailable(CodedOutputStream.java:2998)\r\n        at com.google.protobuf.CodedOutputStream$OutputStreamEncoder.writeUInt32NoTag(CodedOutputStream.java:2825)\r\n        at com.google.protobuf.CodedOutputStream$OutputStreamEncoder.writeTag(CodedOutputStream.java:2670)\r\n        at com.google.protobuf.CodedOutputStream$OutputStreamEncoder.writeMessage(CodedOutputStream.java:2774)\r\n        at com.google.devtools.build.lib.worker.WorkerProtocol$WorkRequest.writeTo(WorkerProtocol.java:1009)\r\n        at com.google.protobuf.AbstractMessageLite.writeDelimitedTo(AbstractMessageLite.java:98)\r\n        at com.google.devtools.build.lib.worker.WorkerSpawnRunner.execInWorker(WorkerSpawnRunner.java:318)\r\n        at com.google.devtools.build.lib.worker.WorkerSpawnRunner.actuallyExec(WorkerSpawnRunner.java:160)\r\n        at com.google.devtools.build.lib.worker.WorkerSpawnRunner.exec(WorkerSpawnRunner.java:115)\r\n        at com.google.devtools.build.lib.exec.AbstractSpawnStrategy.exec(AbstractSpawnStrategy.java:106)\r\n        at com.google.devtools.build.lib.exec.AbstractSpawnStrategy.exec(AbstractSpawnStrategy.java:75)\r\n        at com.google.devtools.build.lib.exec.SpawnActionContextMaps$ProxySpawnActionContext.exec(SpawnActionContextMaps.java:362)\r\n        at com.google.devtools.build.lib.analysis.actions.SpawnAction.internalExecute(SpawnAction.java:288)\r\n        at com.google.devtools.build.lib.analysis.actions.SpawnAction.execute(SpawnAction.java:295)\r\n        at com.google.devtools.build.lib.skyframe.SkyframeActionExecutor.executeActionTask(SkyframeActionExecutor.java:1001)\r\n        at com.google.devtools.build.lib.skyframe.SkyframeActionExecutor.prepareScheduleExecuteAndCompleteAction(SkyframeActionExecutor.java:930)\r\n        at com.google.devtools.build.lib.skyframe.SkyframeActionExecutor.access$800(SkyframeActionExecutor.java:121)\r\n        at com.google.devtools.build.lib.skyframe.SkyframeActionExecutor$ActionRunner.call(SkyframeActionExecutor.java:770)\r\n        at com.google.devtools.build.lib.skyframe.SkyframeActionExecutor$ActionRunner.call(SkyframeActionExecutor.java:725)\r\n        at java.base/java.util.concurrent.FutureTask.run(Unknown Source)\r\n        at com.google.devtools.build.lib.skyframe.SkyframeActionExecutor.executeAction(SkyframeActionExecutor.java:478)\r\n        at com.google.devtools.build.lib.skyframe.ActionExecutionFunction.checkCacheAndExecuteIfNeeded(ActionExecutionFunction.java:519)\r\n        at com.google.devtools.build.lib.skyframe.ActionExecutionFunction.compute(ActionExecutionFunction.java:216)\r\n        at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate.run(AbstractParallelEvaluator.java:422)\r\n        at com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$WrappedRunnable.run(AbstractQueueVisitor.java:368)\r\n        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n        at java.base/java.lang.Thread.run(Unknown Source)\r\n---8<---8<--- End of exception details ---8<---8<---\r\n\r\n---8<---8<--- Start of log, file at C:/users/xiahaobo.tobosoft/_bazel_xiahaobo/lj4hacgi/bazel-workers/worker-0-Javac.log ---8<---8<---\r\nError: Could not create the Java Virtual Machine.\r\nError: A fatal exception has occurred. Program will exit.\r\nUnrecognized VM option 'CompactStrings'\r\n```", "@meteorcloudy could you route this issue within the bazel team?", "@meteorcloudy  please help !!!", "After googling the error `Unrecognized VM option 'CompactStrings'`\r\nLooks like it's related to https://github.com/bazelbuild/bazel/issues/5726\r\n@cushon Is this problem already resolved?", "Is that build using `--distinct_host_configuration=false`?\r\n\r\nThe crash indicates it's using a JDK 8 `--host_javabase` with the default Java toolchain, which only supports JDK 9 or newer.\r\n\r\nWhich bazel distribution is being used here? Is it the one with an embedded JDK?", "We do add `build --distinct_host_configuration=false` into `.tf_configure.bazelrc` on Windows. You can also remove it, but the build will take much longer time. @xiahaobo Can you try removing `--distinct_host_configuration=false` from that bazelrc file?", "it ok ! thanks @meteorcloudy ", "@gunan But there are other problems, I compile under window 7, should generate tensorflow_jni.dll, but generate tensorflow_jni.so.\r\nI run the code at MS-DOS, Is there some wrong with my configure? \r\n```\r\nbazel build --config opt //tensorflow/tools/lib_package:libtensorflow_jni.tar.gz //tensorflow/java:libtensorflow.jar //tensorflow/java:libtensorflow-src.jar\r\n```", "@xiahaobo You can just rename it to `tensorflow_jni.dll`, we haven't fix the extension on Windows, but the library is built as a DLL.", "Closing this out since I understand it to be resolved, but please let me know if I'm mistaken. Thanks!"]}, {"number": 23190, "title": "Implement server Stop method", "body": "Currently \"Stop\" function is not implemented in `GrpcServer`. It leads to the fact, that `GrpcServer` can't be used inside other processes (like in #23022). I've implemented stop method so that server stops and doesn't abort the process during destructor execution.\r\n\r\n@mrry, could you please have a look as the author of this functionality?", "comments": ["I found one more issue, eager service breaks loop immediately after \"stop\" message. Looks like it's wrong, so I changed behavior to be similar to other services (master and worker).", "@dmitrievanthony wondering if this PR still valid , if yes could you please re base your branch.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 23189, "title": "text8.zip", "body": "Hello Guys\r\npreviously the code was working on my MacBook, now it doesn't work and I don't understand why. I have the error below:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/payam/Desktop/tensorflow/tensorflow/examples/tutorials/word2vec/word2vec_basic.py\", line 73, in <module>\r\n    filename = maybe_download('text8.zip', 31344016)\r\n  File \"/Users/payam/Desktop/tensorflow/tensorflow/examples/tutorials/word2vec/word2vec_basic.py\", line 69, in maybe_download\r\n    raise Exception('Failed to verify {0}. Can you get to it with a browser?'.format(local_filename))\r\nException: Failed to verify /var/folders/bp/cd99npls7q7g9y8f34lhwnq80000gn/T/text8.zip. Can you get to it with a browser?\r\n9207808\r\n\r\nProcess finished with exit code 1", "comments": ["It looks like you haven't provided the information requested by the template. We ask this because it will help us to narrow down our focus on your specific issue since system configurations can vary broadly Please resubmit and pay attention to the [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose). Please provide all the information it asks. Thank you.\r\n", "have the same problem, have you solved this?"]}, {"number": 23188, "title": "Allow the method `model_to_estimator` to have a regression signature", "body": "Up to now, the method `model_to_estimator` that converts a Keras model into an tf.estimator.Estimator\r\ndoes not permit to change the parameters' dictionary `export_outputs` of the instance of the tf.estimator.EstimatorSpec returned by this function. (see https://www.tensorflow.org/api_docs/python/tf/estimator/EstimatorSpec).\r\n\r\nHowever, with the recently available \"what-if tool\" interface, the exported model served with tensorflow_serving must have a specific signature_def (either classify or regress). This commit aims to allow the user to export a model that has a signature_def `regress` instead of `predict` which can be in turn served and used via Tensorboard/what-if tool.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "> I signed it!\r\n\r\n", "CLAs look good, thanks!\n\n<!-- ok -->", "Hi @paulilhe  seems to be you are merging in to different branch other than master , please create a new PR for Master Branch."]}, {"number": 23187, "title": "Error : Check failed: IsConstantParameterArray", "body": "**System information**\r\n\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): 16.04.5 LTS \r\nTensorFlow installed from (source or binary): binary\r\nTensorFlow version (use command below): 1.13.0-dev20181023\r\nPython version: \r\nBazel version (if compiling from source):\r\nGCC/Compiler version (if compiling from source):\r\nCUDA/cuDNN version: 9.0.176 / 9\r\nGPU model and memory: GeForce GTX 1080ti / 11175MiB\r\n\r\n**Describe the current behavior**\r\n\r\nI want to convert a custom graph from TF to TFLite using 'TFLiteconverter'\r\nbut I faced below error:\r\n\r\n> tensorflow.contrib.lite.python.convert.ConverterError: TOCO failed. See console for info.\r\n> 2018-10-23 10:13:26.786330: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 784 operators, 1332 arrays (0 quantized)\r\n> 2018-10-23 10:13:26.797260: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 511 operators, 912 arrays (0 quantized)\r\n> 2018-10-23 10:13:26.806327: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 511 operators, 912 arrays (0 quantized)\r\n> 2018-10-23 10:13:26.806920: F tensorflow/contrib/lite/toco/graph_transformations/resolve_batch_normalization.cc:45] Check failed: IsConstantParameterArray(*model, bn_op->inputs[1]) && IsConstantParameterArray(*model, bn_op->inputs[2]) && IsConstantParameterArray(*model, bn_op->inputs[3]) Batch normalization resolution requires that mean, multiplier and offset arrays be constant.\r\n> Aborted (core dumped)\r\n> \r\n\r\nHow can I fix it?\r\n\r\n**Code to reproduce the issue**\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\ngraph_def_file = \"/path/graph.pb\"\r\ninput_arrays = [\"Placeholder\"]\r\noutput_arrays = [\"final\"]\r\n\r\nconverter = tf.contrib.lite.TFLiteConverter.from_frozen_graph(\r\n  graph_def_file, input_arrays, output_arrays)\r\nconverter.inference_type = tf.contrib.lite.constants.FLOAT\r\ntflite_model = converter.convert()\r\nopen(\"converted_model.tflite\", \"wb\").write(tflite_model)\r\n```\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Please provide the information requested by the @tensorflowbutler.\r\nCan you please try using tf-nightly version if haven't already?", "> Please provide the information requested by the @tensorflowbutler.\r\n> Can you please try using tf-nightly version if haven't already?\r\n\r\nI modified my System Information\r\nalso I already use tf-nightly version using docker.\r\n\r\ncommend below:\r\n`docker run --name tensorflow-nightly-gpu --runtime=nvidia -it -p 6006:6006 tensorflow/tensorflow:nightly-gpu bash`", "Same issue here. @Jeong-Heon did you solve the problem?", "You are converting a training graph. Please create a eval graph, freeze it and then run tflite_convert.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "> You are converting a training graph. Please create a eval graph, freeze it and then run tflit\r\n\r\nPlease explain."]}, {"number": 23186, "title": "Add Linux and Android makefile", "body": "", "comments": ["In general we only resort to Makefiles for architectures and platforms that are either unsupported by bazel, or for which bazel support is buggy/experimental. Android/Linux are both fairly well-supported by bazel, so I'm curious what the motivation is for this change? There's no description provided.", "@jdduke We want to use lite without java api, and use subset of the lite ops for small size of lib.  Also we are not familiar with bazel.", "You don't have to use the full set of ops. If you build a static library (via bazel), you can provide a custom OpResolver with a smaller set of ops to trim the binary size. See also https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/apis.md.\r\n\r\nWe have a shared library target for the C API in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/c/BUILD#L20. We'll be introducing one for the C++ API, but for now you can tweak the version_script.lds to preserve the C++ symbols.", "@jdduke Does have a guide for compile Android tflite .so or .a lib without Java API? or C api under Android?", "Sure, for Android, make sure your bazel Android environment is configured properly (see [this guide](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/java/demo)). You can build the C library with:\r\n\r\n```\r\nbazel build -c opt --cxxopt=--std=c++11 \\\r\n  --config=android_arm \\\r\n  //tensorflow/lite/experimental/c:libtensorflowlite_c.so\r\n```\r\n\r\nIf you want to use the C++ API you'll need to tweak the [linker script](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/experimental/c/BUILD#L20) to avoid stripping the C++ symbols.", "@jdduke Is there an integration example with Linux c++? We have [only model inference in a mobile app](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/devguide.md#3-use-the-tensorflow-lite-model-for-inference-in-a-mobile-app). What it is suggested for a standalone app on a linux host? XLA AOT? Tensorflow standard with c++ api?", "Sure, you can look at our [minimal](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/examples/minimal) and [label_image](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/examples/label_image) samples for guidance, they should both run on a Linux host using the usual `bazel` build commands.", "I'm going to tentatively close this for now. We're going to add proper C/C++ shared library targets over the next month or so as we move the C API out of experimental."]}, {"number": 23185, "title": "Eager execution: variables can't be iterated (unlike Tensor)", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): pip binary\r\n- TensorFlow version (use command below): v1.10.0-0-g656e7a2b34 1.10.0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\n\r\n**Describe the current behavior**\r\n**Describe the expected behavior**\r\n\r\nVariable is expected to be iterable, just as EagerTensor, but right now it raises TypeErrors\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\nimport numpy\r\ntf.enable_eager_execution()\r\nx = tf.contrib.eager.Variable(numpy.zeros([3, 4, 5]))\r\nprint(type(x + 0))\r\nlist(x + 0) # ok\r\nprint(type(x))\r\nlist(x) # TypeError: 'Variable' object is not iterable.\r\n```\r\n\r\nOutput:\r\n```\r\n<class 'EagerTensor'>\r\n<class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'>\r\n```\r\n\r\nExact command to reproduce: \r\n```\r\npython script.py\r\n```\r\n(to please tensorflowbuttler)", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nExact command to reproduce", "This is by design, otherwise Python would attempt to iterate over the variable's Tensor from 0\u00a0\u00a0to infinity. You can use tf.unstack to loop over tensor or convert to numpy array using session.run.\r\n\r\n\r\n", "@wt-huang \r\nyou probably missed I am talking about eager mode. In eager mode, there is no session and all tensors have known dimensions, so iteration is not a problem (see examples I provided). It's just not implemented for a variable."]}, {"number": 23184, "title": "CUDA 9.1 and Tensorflow GPU 1.5.0 Visual Studio 2017 and Python 3.6 error", "body": "I installed CUDA 9.1, cuDNN 7.31 for CUDA 9.1 and I have installed Visual Studio 2017. However when I run the CUDA samples I get these following outputs:\r\n![capture](https://user-images.githubusercontent.com/24243687/47340754-d2955d80-d6bc-11e8-8f8c-c4dad2375cf6.PNG)\r\n![3](https://user-images.githubusercontent.com/24243687/47340755-d45f2100-d6bc-11e8-8223-2e3146168de0.PNG)\r\n\r\nBut when I try to fit my model using tensorflow-gpu it show \"python.exe\" stopped working and then when I click Debug, I get this output inside my Visual Studio 2017:\r\n![2](https://user-images.githubusercontent.com/24243687/47340798-ee006880-d6bc-11e8-8197-b50eb52d57c9.PNG)\r\n\r\nAny idea what might fix this issue?", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "TensorFlow expects [CUDA 9.0](https://www.tensorflow.org/install/gpu#software_requirements). Please install version 9.0 and change the [path var](https://www.tensorflow.org/install/gpu#windows_setup).\r\n", "Anyway I fixed this issue through this process of installation: https://www.pugetsystems.com/labs/hpc/Install-TensorFlow-with-GPU-Support-on-Windows-10-without-a-full-CUDA-install-1172/"]}, {"number": 23183, "title": "Provide Clear Instructions to build tensorflow from source", "body": "Hi\r\n  The instructions to build tensorflow from source are not clear, simple or easy to understand.\r\n\r\nI would like a concise set of steps to build tensorflow from source for ubuntu 16.04\r\n\r\nThanks+", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "@radiantone You can follow the instruction guide. Let us know which part you don't understand.\r\nWe do recommend building TensorFlow from source.\r\n\r\n\r\n"]}, {"number": 23182, "title": "Different results got using different batch sizes (cannot fully fit into GPU memory therefore evaluating different batch each time)", "body": "**System information**\r\n- Have I written custom code: **Yes**\r\n- OS Platform and Distribution: **Linux Ubuntu 18.04.1** \r\n- Mobile device: N/A\r\n- TensorFlow installed from: **binary, tensorflow-gpu from anaconda**\r\n- TensorFlow version: **b'unknown', 1.11.0**\r\n- Python version: **3.6.6**\r\n- Bazel version: N/A\r\n- GCC/Compiler version: N/A\r\n- CUDA/cuDNN version: **10.0, Driver Version: 410.66**\r\n- GPU model and memory: **TITAN Xp, 12195MiB**\r\n\r\n**Describe the current behavior**\r\nI'm trying to batch evaluate MLP (with same structure but different parameter) on GPU. Since the whole batch is too big to fit into GPU memory, I have to create smaller batches from the whole batch. Since the size of whole batch is not divisible by the size of little batch, the last little batch will be smaller than usual. It turns out the results in the last small batch is way smaller than previous batches.\r\n\r\n**Describe the expected behavior**\r\nThe result should be the same since batch size should not affect the result itself.\r\n\r\n**Exact command to reproduce**\r\nPut any of the following examples in a `jupyter` cell, and run it\r\nPut any of the following examples in `xxx.py`, and run `python xxx.py` should also be fine\r\n\r\n**Code to reproduce the issue**\r\nA small example:\r\n\r\n    import tensorflow as tf\r\n    import numpy as np\r\n    with tf.Session():\r\n        x = tf.Variable(np.random.rand(43, 60000).astype('f2'))\r\n        w = tf.Variable(np.ones((58624, 43), 'f2'))\r\n        b = tf.Variable(np.ones((58624, 1), 'f2'))\r\n        v1 = w @ x + b\r\n        w = tf.Variable(np.ones((5376, 43), 'f2'))\r\n        b = tf.Variable(np.ones((5376, 1), 'f2'))\r\n        v2 = w @ x + b\r\n        tf.global_variables_initializer().run()\r\n        print(v1.eval(), v2.eval()) # they should have the same value while they dont\r\n\r\nThe actual example:\r\n\r\n    import tensorflow as tf\r\n    import numpy as np\r\n    with tf.Session():\r\n        x = tf.Variable(np.ones((43, 60000), 'f2'))\r\n        y = tf.Variable(np.ones((8, 60000), 'f2'))\r\n        w = tf.Variable(np.ones((916* 64, 43), 'f2'))\r\n        b = tf.Variable(np.ones((916* 64, 1), 'f2'))\r\n        v = tf.Variable(np.ones((916, 8, 64), 'f2'))\r\n        c = tf.Variable(np.ones((916, 8, 1), 'f2'))\r\n        r = tf.linalg.norm(tf.cast(v@tf.reshape(tf.tanh(w@x+b),(916,64,60000))+c,'float32'),axis=(1,2))# prevent overflow\r\n        w = tf.Variable(np.ones((84* 64, 43), 'f2'))\r\n        b = tf.Variable(np.ones((84* 64, 1), 'f2'))\r\n        v = tf.Variable(np.ones((84, 8, 64), 'f2'))\r\n        c = tf.Variable(np.ones((84, 8, 1), 'f2'))\r\n        R = tf.linalg.norm(tf.cast(v@tf.reshape(tf.tanh(w@x+b),(84,64,60000))+c,'float32'),axis=(1,2)) # prevent overflow\r\n        tf.global_variables_initializer().run()\r\n        print(r.eval()[::100], R.eval()[::10]) # summary, they should have the same value while they dont\r\n\r\n**Other info / logs**\r\nI created a stack overflow question (https://stackoverflow.com/questions/52921884/tensorflow-result-inconsistent-across-batch-size) but since no body solved the problem, I submitted an issue here. It seems that this problem does not occur with small batches, it sometimes is not stably reproducible ", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nExact command to reproduce", "Sorry for the delay (12h time zone difference), updated accordingly ", "@ZisIsNotZis I was able to run the first code snippet in GPU and received consistent results across all batches. Didn't observe different result in last batch as you mentioned.\r\n\r\nAlso, I noticed that the first code runs very slowly and consumes a lot of memory, i.e. close to 8G, which may be the reason for abnormal behavior. You may need to do some optimization there.\r\n\r\n", "That's wired. I just updated everything to latest (i.e. `conda update --all`), including ubuntu drivers (i.e. `apt update` and `ubuntu-drivers autoinstall`) and the result is still inconsistent. For first code, it gives the result:\r\n\r\n    [[23.03 22.25 20.97 ... 22.72 25.58 20.19]\r\n     [23.03 22.25 20.97 ... 22.72 25.58 20.19]\r\n     [23.03 22.25 20.97 ... 22.72 25.58 20.19]\r\n     ...\r\n     [23.03 22.25 20.97 ... 22.72 25.58 20.19]\r\n     [23.03 22.25 20.97 ... 22.72 25.58 20.19]\r\n     [23.03 22.25 20.97 ... 22.72 25.58 20.19]] [[24.03 23.25 21.97 ... 23.72 26.58 21.19]\r\n     [24.03 23.25 21.97 ... 23.72 26.58 21.19]\r\n     [24.03 23.25 21.97 ... 23.72 26.58 21.19]\r\n     ...\r\n     [24.03 23.25 21.97 ... 23.72 26.58 21.19]\r\n     [24.03 23.25 21.97 ... 23.72 26.58 21.19]\r\n     [24.03 23.25 21.97 ... 23.72 26.58 21.19]]\r\n\r\nwhere `v2.eval()` is apparently off `v1.eval()` by 1. The second code gives:\r\n\r\n    [1906641.6 1906641.6 1906641.6 1906641.6 1906641.6 1906641.6 1906641.6\r\n     1906641.6 1906641.6 1906641.6] [45033.324 45033.324 45033.324 45033.324 45033.324 45033.324 45033.324\r\n     45033.324 45033.324]\r\n\r\nwhich is also inconsistent. I'm wondering if that is a anaconda-specific problem since I didn't do the standard `pip install tensorflow-gpu`. It might also be a gpu-memory-size problem since you might have an even better GPU.\r\n\r\nFor optimizing part, I thought I would get higher efficiency if put larger batch (i.e. larger matrix multiplication) on GPU instead of smaller batch multiple times. Is that correct? Do I have to split matrix multiplication manually or there are some function in Tensorflow that can help me with that?\r\n\r\nThank you!\r\n", "I have also come across inconsistencies when batch-evaluating a model against a dataset. I am using the tf.Estimator framework with tf.data. The loss obtained from the `evaluate` method can get very different depending solely on the batch size. The reason why I need to batch is because some bigger datasets don't fit in my GPU. BUT I also tested the same evaluation routine disabling GPU, and the problem persists, see below.\r\nSome info:\r\nDataset size: 18254\r\nHow I call `evaluate`:\r\n```\r\ndata = classifier.evaluate(\r\n    lambda: input_eval_function(\r\n        csv_used=\"my.csv\"\r\n    ),\r\n    name='eval_test',\r\n    steps=None\r\n)\r\nprint(data)\r\n```\r\nHow my input function looks like:\r\n```\r\ndef input_eval_function(csv_used):\r\n    dataset = tf.data.TextLineDataset(filenames=csv_used).skip(1)\r\n    dataset = dataset.map(_parse_lines_from_csv).batch(**BATCH_SIZE**, drop_remainder=False)\r\n    return dataset\r\n```\r\nSome pairs of (BATCH_SIZE, loss) when running with GPU:\r\nBATCH_SIZE = 1, loss = 135.25769\r\nBATCH_SIZE = 100, loss = 135.41405\r\nBATCH_SIZE = 1000, loss = 148.7542\r\nBATCH_SIZE = 5000, loss = 143.71754\r\nBATCH_SIZE = 9127 (half dataset), loss = 135.29721\r\nBATCH_SIZE = 11000, loss = 142.64745\r\nBATCH_SIZE = 15000, loss = 173.06819\r\nBATCH_SIZE = 18000, loss = 303.47687\r\nBATCH_SIZE = 18100, loss = 128.06966\r\nBATCH_SIZE = 18254 (whole dataset), loss = 135.29533\r\nBATCH_SIZE = 20000 (buffer bigger than dataset), loss = 135.29533\r\n\r\nOBS1: The results are consistent per batch size, that is, running the code multiple times using the same batch size always yields the same results.\r\n\r\nThe results using GPU are generally inconsistent with the results without GPU. This happens when I turn off GPU usage by adding the line `os.environ['CUDA_VISIBLE_DEVICES'] = '-1'`:\r\nBATCH_SIZE = 1, loss = 135.25769 ->consistent or no notable difference when compared to GPU\r\nBATCH_SIZE = 100, loss = 135.41402 ->+- consistent with difference in 0.00001\r\nBATCH_SIZE = 1000, loss = 148.75395 ->+- consistent with difference in 0.001\r\nBATCH_SIZE = 5000, loss = 143.70166 ->+- (in)consistent with difference in 0.01\r\nBATCH_SIZE = 9127 (half dataset), loss = 135.20308 ->inconsistent with difference in 0.1\r\nBATCH_SIZE = 11000, loss = 142.51755 ->inconsistent with difference in 0.1\r\nBATCH_SIZE = 15000, loss = 172.92397 ->inconsistent with difference in 1.0\r\nBATCH_SIZE = 18000, loss = 302.61243 ->inconsistent with difference in 1.0\r\nBATCH_SIZE = 18100, loss = 127.067825 ->inconsistent with difference in 1.0\r\nBATCH_SIZE = 18254 (whole dataset), loss = 133.20801 ->inconsistent with difference in 1.0\r\nBATCH_SIZE = 20000 (buffer bigger than dataset), loss = 133.20801 ->inconsistent with difference in 1.0\r\n\r\nThat is:\r\n\r\n1)I confirm that I am also experiencing different evaluation results when using different sizes of batch, even though I am using steps=None, which should imply using the whole dataset.\r\n2)The results with enabled GPU are slightly different from the ones without using GPU.\r\n\r\nNumber 2 may be linked to how computation is performed in GPU in contrast with CPU, so I am not really concerned, nor it is the aim of this github issue. BUT number 1 is concerning: changing the batch size is having a huge impact on the value of the calculated loss.\r\n\r\nobs: I went further and compared these results with the ones obtained using the package tensorflow, that is , not tensorflow-gpu. These seem to be equal to the ones obtained using tensorflow-gpu with GPU disabled (expected).", "I just tested with the standard pip-installed `tensorflow-gpu`, it has the same behavior.\r\n\r\n- TensorFlow installed from: **pip, tensorflow-gpu**\r\n- TensorFlow version: **v1.12.0-0-ga6d8ffae09, 1.12.0**\r\n- Python version: **3.6.7**\r\n- CUDA/cuDNN version: **10.0, Driver Version: 410.73**", "Hi, I'm sorry but I'm wondering what is the status of this issue? I'm doing some research about neural network optimization. It's more about understanding what it looks like etc. and I kind of cannot go on if the computation result might be wrong.\r\n\r\nThank you!", "I have similar issues. Basically, it happens also if you are using CPU only. \r\nIf I feed the same input data for training to the evaluation to the estimator, the loss reported is consistent between training and evaluation but if I change the batch size during the evaluation, the loss is very off. It looks like a bug in the way the avg loss is calculated.", "@ZisIsNotZis I tried with latest stable version of Tensorflow 1.14.0. I got the expected result as below\r\n```\r\n[1906641.6 1906641.6 1906641.6 1906641.6 1906641.6 1906641.6 1906641.6\r\n 1906641.6 1906641.6 1906641.6] [45033.324 45033.324 45033.324 45033.324 45033.324 45033.324 45033.324\r\n 45033.324 45033.324]\r\n```\r\nCan you check with latest stable version. Let us know. Thanks! ", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=23182\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=23182\">No</a>\n"]}, {"number": 23181, "title": "how to get the Projective transform matrix ,which will be used to tf.contrib.image.transform??", "body": "i wanna do Projective transform in tensorflow, but tf.contrib.image.transform needs some args as follows:\r\n'''\r\nimages,\r\ntransforms,\r\ninterpolation='NEAREST',\r\nname=None\r\n''''\r\ni dont know how to get the transforms matrix.\r\nOPENCV has this function: getPerspectiveTransform(pts0,pts1),but i cant find Similar function in tensorflow.\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "@EricWu123 You can use perspective_transform.py, refer to [Perspective Transformer Nets](https://github.com/tensorflow/models/tree/master/research/ptn) for more details."]}]