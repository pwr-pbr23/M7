[{"number": 47426, "title": "In EXPO load coco-ssd model speed very slow", "body": "Hello, I'm running a demo test in expo, but I found coco-ssh model loading is really slow or nothing happens. By the way I'm in China, is it caused by internet restrictions? Please give some help, thanks. \r\nthis.model = await cocossd.load() // loading, no response\r\n\r\nMy code:\r\nimport React from 'react'\r\nimport {\r\n  StyleSheet,\r\n  Text,\r\n  View,\r\n  ActivityIndicator,\r\n  StatusBar,\r\n  Image,\r\n  TouchableOpacity\r\n} from 'react-native'\r\nimport * as tf from '@tensorflow/tfjs'\r\nimport { fetch } from '@tensorflow/tfjs-react-native'\r\nimport * as cocossd from '@tensorflow-models/coco-ssd'\r\nimport * as jpeg from 'jpeg-js'\r\nimport * as ImagePicker from 'expo-image-picker'\r\nimport Constants from 'expo-constants'\r\nimport * as Permissions from 'expo-permissions'\r\n\r\nclass App extends React.Component {\r\n  state = {\r\n    isTfReady: false,\r\n    isModelReady: false,\r\n    predictions: null,\r\n    image: null\r\n  }\r\n\r\n  async componentDidMount() {\r\n    await tf.ready()\r\n    this.setState({\r\n      isTfReady: true\r\n    })\r\n    this.model = await cocossd.load()\r\n    this.setState({ isModelReady: true })\r\n    this.getPermissionAsync()\r\n  }\r\n\r\n  getPermissionAsync = async () => {\r\n    if (Constants.platform.ios) {\r\n      const { status } = await Permissions.askAsync(Permissions.CAMERA_ROLL)\r\n      if (status !== 'granted') {\r\n        alert('Sorry, we need camera roll permissions to make this work!')\r\n      }\r\n    }\r\n  }\r\n\r\n  imageToTensor(rawImageData) {\r\n    const TO_UINT8ARRAY = true\r\n    const { width, height, data } = jpeg.decode(rawImageData, TO_UINT8ARRAY)\r\n    // Drop the alpha channel info for mobilenet\r\n    const buffer = new Uint8Array(width * height * 3)\r\n    let offset = 0 // offset into original data\r\n    for (let i = 0; i < buffer.length; i += 3) {\r\n      buffer[i] = data[offset]\r\n      buffer[i + 1] = data[offset + 1]\r\n      buffer[i + 2] = data[offset + 2]\r\n\r\n      offset += 4\r\n    }\r\n\r\n    return tf.tensor3d(buffer, [height, width, 3])\r\n  }\r\n\r\n  classifyImage = async () => {\r\n    try {\r\n      const imageAssetPath = Image.resolveAssetSource(this.state.image)\r\n      const response = await fetch(imageAssetPath.uri, {}, { isBinary: true })\r\n      const rawImageData = await response.arrayBuffer()\r\n      const imageTensor = this.imageToTensor(rawImageData)\r\n      const predictions = await this.model.classify(imageTensor)\r\n      this.setState({ predictions })\r\n      console.log(predictions)\r\n    } catch (error) {\r\n      console.log(error)\r\n    }\r\n  }\r\n\r\n  selectImage = async () => {\r\n    try {\r\n      let response = await ImagePicker.launchImageLibraryAsync({\r\n        mediaTypes: ImagePicker.MediaTypeOptions.All,\r\n        allowsEditing: true,\r\n        aspect: [4, 3]\r\n      })\r\n\r\n      if (!response.cancelled) {\r\n        const source = { uri: response.uri }\r\n        this.setState({ image: source })\r\n        this.classifyImage()\r\n      }\r\n    } catch (error) {\r\n      console.log(error)\r\n    }\r\n  }\r\n\r\n  renderPrediction = prediction => {\r\n    return (\r\n      <Text key={prediction.className} style={styles.text}>\r\n        {prediction.className}\r\n      </Text>\r\n    )\r\n  }\r\n\r\n  render() {\r\n    const { isTfReady, isModelReady, predictions, image } = this.state\r\n\r\n    return (\r\n      <View style={styles.container}>\r\n        <StatusBar barStyle='light-content' />\r\n        <View style={styles.loadingContainer}>\r\n          <Text style={styles.text}>\r\n            TFJS ready? {isTfReady ? <Text>\u2705</Text> : ''}\r\n          </Text>\r\n\r\n          <View style={styles.loadingModelContainer}>\r\n            <Text style={styles.text}>Model ready? </Text>\r\n            {isModelReady ? (\r\n              <Text style={styles.text}>\u2705</Text>\r\n            ) : (\r\n              <ActivityIndicator size='small' />\r\n            )}\r\n          </View>\r\n        </View>\r\n        <TouchableOpacity\r\n          style={styles.imageWrapper}\r\n          onPress={isModelReady ? this.selectImage : undefined}>\r\n          {image && <Image source={image} style={styles.imageContainer} />}\r\n\r\n          {isModelReady && !image && (\r\n            <Text style={styles.transparentText}>Tap to choose image</Text>\r\n          )}\r\n        </TouchableOpacity>\r\n        <View style={styles.predictionWrapper}>\r\n          {isModelReady && image && (\r\n            <Text style={styles.text}>\r\n              Predictions: {predictions ? '' : 'Predicting...'}\r\n            </Text>\r\n          )}\r\n          {isModelReady &&\r\n            predictions &&\r\n            predictions.map(p => this.renderPrediction(p))}\r\n        </View>\r\n        <View style={styles.footer}>\r\n          <Text style={styles.poweredBy}>Powered by:</Text>\r\n          <Image source={require('./assets/tfjs.jpg')} style={styles.tfLogo} />\r\n        </View>\r\n      </View>\r\n    )\r\n  }\r\n}\r\n\r\nconst styles = StyleSheet.create({\r\n  container: {\r\n    flex: 1,\r\n    backgroundColor: '#171f24',\r\n    alignItems: 'center'\r\n  },\r\n  loadingContainer: {\r\n    marginTop: 80,\r\n    justifyContent: 'center'\r\n  },\r\n  text: {\r\n    color: '#ffffff',\r\n    fontSize: 16\r\n  },\r\n  loadingModelContainer: {\r\n    flexDirection: 'row',\r\n    marginTop: 10\r\n  },\r\n  imageWrapper: {\r\n    width: 280,\r\n    height: 280,\r\n    padding: 10,\r\n    borderColor: '#cf667f',\r\n    borderWidth: 5,\r\n    borderStyle: 'dashed',\r\n    marginTop: 40,\r\n    marginBottom: 10,\r\n    position: 'relative',\r\n    justifyContent: 'center',\r\n    alignItems: 'center'\r\n  },\r\n  imageContainer: {\r\n    width: 250,\r\n    height: 250,\r\n    position: 'absolute',\r\n    top: 10,\r\n    left: 10,\r\n    bottom: 10,\r\n    right: 10\r\n  },\r\n  predictionWrapper: {\r\n    height: 100,\r\n    width: '100%',\r\n    flexDirection: 'column',\r\n    alignItems: 'center'\r\n  },\r\n  transparentText: {\r\n    color: '#ffffff',\r\n    opacity: 0.7\r\n  },\r\n  footer: {\r\n    marginTop: 40\r\n  },\r\n  poweredBy: {\r\n    fontSize: 20,\r\n    color: '#e69e34',\r\n    marginBottom: 6\r\n  },\r\n  tfLogo: {\r\n    width: 125,\r\n    height: 70\r\n  }\r\n})\r\n\r\nexport default App\r\n\r\n\r\npackage.json:\r\n{\r\n  \"dependencies\": {\r\n    \"expo-gl\": \"~9.2.0\",\r\n    \"jpeg-js\": \"0.3.6\",\r\n    \"expo-constants\": \"~9.3.3\",\r\n    \"@tensorflow/tfjs\": \"1.2.11\",\r\n    \"expo-permissions\": \"~10.0.0\",\r\n    \"expo-image-picker\": \"~9.2.0\",\r\n    \"@tensorflow/tfjs-core\": \"^1.2.8\",\r\n    \"react-native-image-picker\": \"1.1.0\",\r\n    \"@tensorflow/tfjs-converter\": \"1.2.1\",\r\n    \"@react-native-community/blur\": \"3.3.1\",\r\n    \"@tensorflow-models/mobilenet\": \"2.0.4\",\r\n    \"@tensorflow/tfjs-react-native\": \"0.1.0-alpha.2\",\r\n    \"@react-native-community/async-storage\": \"~1.12.0\",\r\n    \"@tensorflow-models/coco-ssd\": \"^2.2.1\"\r\n  }\r\n}\r\n", "comments": ["@amicotin,\r\nTensorFlow.js issues are tracked in tensorflow/tfjs repo. Could you please submit a new issue from [this link](https://github.com/tensorflow/tfjs/issues/new/choose) and fill in the template, so that we can track the issue there. Thanks!\r\n", "@amahendrakar Sorry for my mistake, I will do that. Thank you."]}, {"number": 47423, "title": "Add thread name in the error message when thread creation fails.", "body": "This PR adds thread name in the error message when thread creation fails. It helps with debugging when thread creation fails.", "comments": ["@hawkinsp would you mind taking a look? Thanks.", "@rohan100jain do you know about the windows bazel failure? Why is it happening only on windowns?", "@allenlavoie thanks for the approval. Please let me know when it can be merged.", "@burgerkingeater useful diff, thanks!"]}, {"number": 47422, "title": "conflict numpy version between tensorflow and tf-nighty", "body": "When I install tf-nighty as below command:\r\n`pip3 install tf-nightly`\r\n\r\n\r\nthe error appear as below:\r\n\r\n```\r\nRequirement already satisfied: zipp>=0.5 in /home/hoaphan/.local/lib/python3.6/site-packages (from importlib-metadata->markdown>=2.6.8->tb-nightly~=2.4.0.a->tf-nightly) (3.4.0)\r\nInstalling collected packages: numpy\r\n  Attempting uninstall: numpy\r\n    Found existing installation: numpy 1.18.5\r\n    Uninstalling numpy-1.18.5:\r\n      Successfully uninstalled numpy-1.18.5\r\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\ntensorflow 2.3.1 requires numpy<1.19.0,>=1.16.0, but you have numpy 1.19.5 which is incompatible.\r\nSuccessfully installed numpy-1.19.5\r\n```\r\nthis mean:\r\nthe tensorflow requires numpy <1.19.0\r\nbut the tf-nighty requires numpy 1.19.5\r\n\r\nso I cannot install tensorflow and tf-nighty at same time,\r\nso please help me solve this issue.", "comments": ["@hoaquocphan,\r\n[TF v2.3.2](https://github.com/tensorflow/tensorflow/blob/9edbe5075f79a4a95ed14a2be831f9b59e61f49d/tensorflow/tools/pip_package/setup.py#L63) requires `numpy >= 1.16.0, < 1.19.0`, whereas for [TF v2.4](https://github.com/tensorflow/tensorflow/blob/85c8b2a817f95a3e979ecd1ed95bff1dc1335cff/tensorflow/tools/pip_package/setup.py#L84) and the latest [TF-nightly](https://github.com/tensorflow/tensorflow/blob/dba62c7e9fc0c2eec534d70334eb13bb05370c90/tensorflow/tools/pip_package/setup.py#L81) the required version is `numpy~=1.19.2`.\r\n\r\nIn this case, I'd suggest you to install **`numpy v1.19.2`**, as it is compatible with the latest stable version of TensorFlow i.e. v2.4.1.\r\n\r\n\r\n\r\n> so I cannot install tensorflow and tf-nighty at same time,\r\n\r\nAlso, you can only import any one release of TensorFlow in the script. So, I'd recommend using separate virtual environments for each version. \r\n\r\nThanks!", "Since tf-nightly and tensorflow use the same code, you should **never** install both in the same environment. Usually, the latest one overrides most of the other. This is the way pip works and TF can do nothing in this case. That's why you should use `venv`/`virtualenv`.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47422\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47422\">No</a>\n"]}, {"number": 47421, "title": "NotFoundError: It shows libcudart.so.8.0, but I am using CUDA 10.0.", "body": "Hello everyone.\r\nI wanted to use TensorFlow 1.13.1, so I installed it in the following environment.\r\n-----system information-----\r\nOS:Ubuntu18.04.5 64bit\r\nCPU:Intel Core  i7-10700 @2.90Ghz x 16\r\nRAM:16GB\r\nGPU:Gefoce RTX2060\r\nCUDA:10.0.130\r\ncuDNN:7.4\r\nGPU driver:460.32.03\r\npython2.7\r\n-----------------------------------\r\n\r\n-----The following error message will be displayed-----\r\ntensorflow.python.framework.errors_impl.NotFoundError: libcudart.so.8.0: cannot open shared object file: No such file or directory\r\n-------------------------------------------------\r\nThe TensorFlow website describes it as compatible with Python 2.7, 3.3 to 3.7 GCC 4.8 Bazel 0.19.2 cuDNN7.4 CUDA10.0. Why am I being suggested a CUDA 8.0 environment?\r\nI have tried to install other versions of TensorFlow, but they all give me the same error.\r\nCan someone please help me?\r\nThank you\r\n", "comments": ["@hitobito2009 \r\nIs there any particular reason for using tf 1.x, as there is no support for 1.x please upgrade to 2.x and let us know if you face any issues.\r\n\r\nYou may also refer to similar error issues: [link](https://github.com/tensorflow/tensorflow/issues/5343), [link](https://stackoverflow.com/questions/43162667/importerror-libcudart-so-8-0-cannot-open-shared-object-file-no-such-file-or-d), [link2](https://github.com/tensorflow/tensorflow/issues/8900)", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47421\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47421\">No</a>\n"]}, {"number": 47420, "title": "evaluate", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1.  It must be a bug, a feature request, or a significant problem with the\r\n    documentation (for small docs fixes please send a PR instead).\r\n2.  The form below must be filled out.\r\n3.  It shouldn't be a TensorBoard issue. Those go\r\n    [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**:\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**:\r\n-   **TensorFlow installed from (source or binary)**:\r\n-   **TensorFlow version (use command below)**:\r\n-   **Python version**:\r\n-   **Bazel version (if compiling from source)**:\r\n-   **GCC/Compiler version (if compiling from source)**:\r\n-   **CUDA/cuDNN version**:\r\n-   **GPU model and memory**:\r\n-   **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": []}, {"number": 47419, "title": "Support all fp types in GPU SparseTensorDenseMatMul", "body": "Adds Eigen::half for CPU, and Eigen::half, double, and complex for GPU.\r\n\r\ncc @nluehr ", "comments": ["I'm investigating the test failures.", "I've fixed the complex type test failures (I just missed https://github.com/tensorflow/tensorflow/pull/47355) and added support for float32 accumulation for float16 input/output, along with tests for float16.", "The tests were running on the GPU, it was just that https://github.com/tensorflow/tensorflow/pull/47355 changed (fixed) the handling of complex conjugates (on CPU), and my local branch didn't have that commit.", "When we build internally I see a bunch of references to quiet_NaN not being supported for complex<float> and complex<double>:\r\n\r\n```\r\nthird_party/tensorflow/core/kernels/sparse_tensor_dense_matmul_op_gpu.cu.cc:104:9: note: in instantiation of function template specialization 'tensorflow::SparseTensorDenseMatMulKernel<std::complex<float>, std::complex<float>, int, false, false>' requested here\r\n        SparseTensorDenseMatMulKernel<T, Tsum, Tindices, ADJ_A, ADJ_B>,\r\n        ^\r\nIn file included from third_party/tensorflow/core/kernels/sparse_tensor_dense_matmul_op_gpu.cu.cc:20:\r\nIn file included from ./third_party/tensorflow/core/framework/bounds_check.h:21:\r\nIn file included from third_party/eigen3/Eigen/Core:155:\r\n./third_party/eigen3/Eigen/src/Core/util/Meta.h:293:84: error: non-void function does not return a value [-Werror,-Wreturn-type]\r\n  static T quiet_NaN() { assert(false && \"quiet_NaN not supported for this type\"); }\r\n                                                                                   ^\r\n./third_party/eigen3/Eigen/src/Core/NumTraits.h:208:39: note: in instantiation of member function 'Eigen::internal::device::numeric_limits<std::complex<double>>::quiet_NaN' requested here\r\n    return numext::numeric_limits<T>::quiet_NaN();\r\n                                      ^\r\nthird_party/tensorflow/core/kernels/sparse_tensor_dense_matmul_op_gpu.cu.cc:104:9: note: in instantiation of function template specialization 'tensorflow::SparseTensorDenseMatMulKernel<std::complex<double>, std::complex<double>, int, false, false>' requested here\r\n        SparseTensorDenseMatMulKernel<T, Tsum, Tindices, ADJ_A, ADJ_B>,\r\n        ^\r\nIn file included from third_party/tensorflow/core/kernels/sparse_tensor_dense_matmul_op_gpu.cu.cc:20:\r\nIn file included from ./third_party/tensorflow/core/framework/bounds_check.h:21:\r\nIn file included from third_party/eigen3/Eigen/Core:163:\r\n```\r\n\r\nI see the float and double specializations [there](https://gitlab.com/libeigen/eigen/-/blob/master/Eigen/src/Core/util/Meta.h), but nothing for complex types. Do you know where it's supposed to be coming from?", "I didn't realize there was no NumTraits implementation for complex (I guess compiler warning flags are more strict internally?).\r\nI've pushed a fix for it."]}, {"number": 47418, "title": "[INTEL MKL] Fixed mkl unit test build error due to benchmark test api change", "body": "", "comments": []}, {"number": 47416, "title": "Use zeros_like(x) in favour of zeros(shape(x)) when computing gradients", "body": "This PR uses `zeros_like(x)` in favour of `zeros(shape(x))` in gradient definitions.\r\n\r\nThis simplifies the code and slightly improves performance since it can use the fused `ZerosLike` kernel instead of requiring both `Shape` and `Zeros`.", "comments": ["Thanks for the cleanup! We appreciate it!", "My changes in `eager/function.py` broke the `while_v2` unittests for some reason. I reverted the changes causing this failure."]}, {"number": 47415, "title": "Changes to MklConvFwdPrimitiveFactory to support Arm Compute Library backend", "body": "**System information**\r\n- TensorFlow version (you are using): 2.4.1\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\nAt the moment MklConvFwdPrimitiveFactory reuses already created oneDNN primitives, stored in the vector `fwd_primitives`, with the help of [GetConvFwd](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/mkl/mkl_conv_ops.cc#L401-L404) function which creates a key from convolution parameters stored in MklConvFwdParams and compares this key with the keys of existing primitives. However, when oneDNN is built with [Arm Compute Library](https://github.com/ARM-software/ComputeLibrary) (ACL, see also oneDNN [build options](https://oneapi-src.github.io/oneDNN/dev_guide_build_options.html)) there is specific requirement to create a separate primitive per constant weights tensor, this is a restriction implied by ACL code design which does not allow to use primitive caching mechanism in MklConvFwdPrimitiveFactory as it is. The solution may be to add a new entry, `void* filter_address`, to [MklConvFwdParams](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/mkl/mkl_conv_ops.cc#L58-L93) struct and to include the address of weights to the key in [CreateKey](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/mkl/mkl_conv_ops.cc#L361-L399) function:\r\n\r\n    ...\r\n    key_creator.AddAsKey(convFwdDims.filter_dims);\r\n    #ifdef DNNL_AARCH64_USE_ACL\r\n    key_creator.AddAsKey(convFwdDims.filter_address);\r\n    #endif\r\n    key_creator.AddAsKey(convFwdDims.bias_dims);\r\n    ...\r\n\r\n**Will this change the current api? How?**\r\nThe only API change is the addition of a new field to [CreateKey](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/mkl/mkl_conv_ops.cc#L361-L399) and [MklConvFwdParams](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/mkl/mkl_conv_ops.cc#L58-L93) in `mkl_conv_ops.cc`, this is related to the limitations of ACL which is designed to create a separate primitive per weights tensor.\r\n\r\n**Who will benefit with this feature?**\r\nThe users who run inference regime with TensorFlow on AArch64-based machines.\r\n\r\n**Any Other info.**\r\nThis Issue is raised mainly to get feedback from maintainers of the oneDNN to TensorFlow integration.", "comments": ["Please have a look, @agramesh1 ", "> Please have a look, @agramesh1\r\n\r\n Adding @gzmkl from Intel-TF team who can help.", "Closed due to the raised PR."]}, {"number": 47414, "title": "dummy", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F47414) for more info**.\n\n<!-- need_sender_cla -->", "Please don't send spam PRs. You can be banned."]}, {"number": 47412, "title": "Add axis argument", "body": "Fix /issues/39230.\r\nThis pull request will add the axis argument in tensorflow.keras.losses.categorical_crossentropy() and in tensorflow.keras.losses.binary_crossentropy() as in tensorflow.keras.losses.sparse_categorical_crossentropy().", "comments": ["@advaitjain ,  can you please review this pr ?", "I'm not familiar with the keras codebase and not a suitable reviewer for this PR. An appropriate reviewer should get assigned soon.", "@rthadur , can you please review this PR?", "Adding Francois since this make API interface change.", "@deeb02, @fchollet I have added the unittest. Please review it.", "@qlzh727, @fchollet  any update on this one?", "@fchollet by using a parameterized test, do you mean to define `axis=0` as a funtion parameter? Like `def func(self, axis=0)` ? If so , I will make the change. Btw, I have fixed the tests.", "@deeb02 , @fchollet any update on this one?", "@around-star Can you please address Ubuntu Sanity errors? Thanks!", "@gbaned Apologies for my late response. Can you please trigger the check run?", "It looks like we still have several failing tests:\r\n\r\n```\r\n//third_party/tensorflow/python/keras:metrics_test\r\n//third_party/tensorflow/tools/docs:tf_doctest\r\n```\r\n\r\nPlease take a look.", "@fchollet the [error](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/util/dispatch.py#L181-L182) seems to occur in [dispatch decorator](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/losses.py#L1764). I added the `axis` argument in `BinaryCrossentropy` and `CategoricalCrossentropy` as well. Should this solve the issue?", "@bhack can you please take a look at this? The the [error](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/util/dispatch.py#L181-L182) seems to occur in [dispatch decorator](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/losses.py#L1764). I am not sure what is causing this or how to solve it. Can you please help?", "@around-star Are you testing this locally or with the CI?", "@bhack I am testing this with the CI", "I've not the cache ready to quickly compile this. Have you tried to add your new `axis` param to `_ragged_tensor_categorical_crossentropy` and `_ragged_tensor_binary_crossentropy`?", "@bhack no I didn't. Should I add the `axis` param in `_ragged_tensor_categorical_crossentropy` and `_ragged_tensor_binary_crossentropy` and commit ?", "Yes and I think also in the related `fn = functools.partial(`", "You need to run `bazel tensorflow/tools/api/tests:api_compatibility_test -- --update_goldens True` and then commit.", "@bhack Apologies for my late response.\r\n\r\n> You need to run bazel tensorflow/tools/api/tests:api_compatibility_test -- --update_goldens True and then commit.\r\n\r\nCan you please expand on this? Like do I need to check the test locally, and if so , is there any guide?", "I have run `bazel run tensorflow/tools/api/tests:api_compatibility_test -- --update_goldens True` but the build fails.", "Run this in a Tensorflow  container on your branch.\n\nFollow the process described in [these messages](https://github.com/tensorflow/tensorflow/issues/48557#issuecomment-825626775)", "@bhack Sorry for my late response, I had my exams. I am facing the error \r\n\r\n> Server terminated abruptly (error code: 14, error message: 'Socket closed', log file: '/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/server/jvm.out')\r\n\r\nI tried [reducing ram](https://github.com/tensorflow/tensorflow/issues/35051#issuecomment-623751066) but the error still persists.", "I think you need to reduce also the number of the cores.", "if you mean `--local_cpu_resources=1 ` , I tried it too", "It is strange cause generally this bugs is always related to resources limitation.\r\nSee:\r\nhttps://github.com/tensorflow/tensorflow/issues/8860\r\nhttps://github.com/tensorflow/tensorflow/issues/41480 "]}, {"number": 47411, "title": "No algorithm worked on Ubuntu 20.04 LTS with CUDA 11.0 and Tensorflow 2.4.1", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1.  It must be a bug, a feature request, or a significant problem with the\r\n    documentation (for small docs fixes please send a PR instead).\r\n2.  The form below must be filled out.\r\n3.  It shouldn't be a TensorBoard issue. Those go\r\n    [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**: Yes. It's the tensorflow.keras version of [mnist_convnet](https://keras.io/examples/vision/mnist_convnet/)\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 20.04 LTS\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**: N/A\r\n-   **TensorFlow installed from (source or binary)**: installed via pip inside conda environment\r\n-   **TensorFlow version (use command below)**: 2.4.1\r\n-   **Python version**: 3.8.8\r\n-   **Bazel version (if compiling from source)**: N/A\r\n-   **GCC/Compiler version (if compiling from source)**: N/A\r\n-   **CUDA/cuDNN version**: 11.0/8.04\r\n-   **GPU model and memory**: Nvidia RTX 2080 Super Max-Q, 8G\r\n-   **Exact command to reproduce**: See [mnist_convnet](https://keras.io/examples/vision/mnist_convnet/) (in which I have replaced all keras with tensorflow.keras)\r\n\r\n### Describe the problem\r\n\r\nI have installed tensorflow inside the conda base environment via `pip install --upgrade pip` and `pip install --upgrade tensorflow`, and the latter version is 2.4.1 (which should support CUDA 11.0). But as I tested the code from [mnist_convnet](https://keras.io/examples/vision/mnist_convnet/) (in which I have replaced all keras with tensorflow.keras), the code doesn't work and showed\r\n```\r\nNotFoundError:  No algorithm worked!\r\n\t [[node sequential/conv2d/Conv2D (defined at <ipython-input-4-e30d719c0a87>:6) ]] [Op:__inference_train_function_728]\r\n\r\nFunction call stack:\r\ntrain_function\r\n```\r\n\r\nHere are some strange things about it. \r\n1. I have no problem with running a dense neural network, as shown in [keras_example](https://www.tensorflow.org/datasets/keras_example). The training was smooth and fast.\r\n2. I have no problem with CUDA 10.1. I mean after uninstall ingCUDA 11.0 and all associated CUDNN, and installing CUDA 10.1 and corresponding CUDNN, then the code in [mnist_convnet](https://keras.io/examples/vision/mnist_convnet/) worked.\r\n\r\n### Source code / logs\r\n```python\r\nimport numpy as np\r\nfrom tensorflow import keras\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import layers\r\n\r\n\r\n# Model / data parameters\r\nnum_classes = 10\r\ninput_shape = (28, 28, 1)\r\n\r\n# the data, split between train and test sets\r\n(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\r\n\r\n# Scale images to the [0, 1] range\r\nx_train = x_train.astype(\"float32\") / 255\r\nx_test = x_test.astype(\"float32\") / 255\r\n# Make sure images have shape (28, 28, 1)\r\nx_train = np.expand_dims(x_train, -1)\r\nx_test = np.expand_dims(x_test, -1)\r\n\r\n# convert class vectors to binary class matrices\r\ny_train = keras.utils.to_categorical(y_train, num_classes)\r\ny_test = keras.utils.to_categorical(y_test, num_classes)\r\n\r\nmodel = keras.Sequential(\r\n    [\r\n        keras.Input(shape=input_shape),\r\n        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\r\n        layers.MaxPooling2D(pool_size=(2, 2)),\r\n        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\r\n        layers.MaxPooling2D(pool_size=(2, 2)),\r\n        layers.Flatten(),\r\n        layers.Dropout(0.5),\r\n        layers.Dense(num_classes, activation=\"softmax\"),\r\n    ]\r\n)\r\nmodel.summary()\r\n\r\nbatch_size = 128\r\nepochs = 15\r\n\r\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\r\n\r\nmodel.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\r\n```\r\nThen the error came:\r\n```\r\nNotFoundError                             Traceback (most recent call last)\r\n<ipython-input-4-e30d719c0a87> in <module>\r\n      4 model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\r\n      5 \r\n----> 6 model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\r\n\r\n~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\r\n   1098                 _r=1):\r\n   1099               callbacks.on_train_batch_begin(step)\r\n-> 1100               tmp_logs = self.train_function(iterator)\r\n   1101               if data_handler.should_sync:\r\n   1102                 context.async_wait()\r\n\r\n~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    826     tracing_count = self.experimental_get_tracing_count()\r\n    827     with trace.Trace(self._name) as tm:\r\n--> 828       result = self._call(*args, **kwds)\r\n    829       compiler = \"xla\" if self._experimental_compile else \"nonXla\"\r\n    830       new_tracing_count = self.experimental_get_tracing_count()\r\n\r\n~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    886         # Lifting succeeded, so variables are initialized and we can run the\r\n    887         # stateless function.\r\n--> 888         return self._stateless_fn(*args, **kwds)\r\n    889     else:\r\n    890       _, _, _, filtered_flat_args = \\\r\n\r\n~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)\r\n   2940       (graph_function,\r\n   2941        filtered_flat_args) = self._maybe_define_function(args, kwargs)\r\n-> 2942     return graph_function._call_flat(\r\n   2943         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\r\n   2944 \r\n\r\n~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)\r\n   1916         and executing_eagerly):\r\n   1917       # No tape is watching; skip to running the function.\r\n-> 1918       return self._build_call_outputs(self._inference_function.call(\r\n   1919           ctx, args, cancellation_manager=cancellation_manager))\r\n   1920     forward_backward = self._select_forward_and_backward_functions(\r\n\r\n~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py in call(self, ctx, args, cancellation_manager)\r\n    553       with _InterpolateFunctionError(self):\r\n    554         if cancellation_manager is None:\r\n--> 555           outputs = execute.execute(\r\n    556               str(self.signature.name),\r\n    557               num_outputs=self._num_outputs,\r\n\r\n~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     57   try:\r\n     58     ctx.ensure_initialized()\r\n---> 59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n     60                                         inputs, attrs, num_outputs)\r\n     61   except core._NotOkStatusException as e:\r\n\r\nNotFoundError:  No algorithm worked!\r\n\t [[node sequential/conv2d/Conv2D (defined at <ipython-input-4-e30d719c0a87>:6) ]] [Op:__inference_train_function_728]\r\n\r\nFunction call stack:\r\ntrain_function\r\n```\r\n\r\n\r\n", "comments": ["The same code in [mnist_convnet](https://keras.io/examples/vision/mnist_convnet/) works perfectly on Windows 10, with the same version of CUDA (11.0) and CUDNN (8.04). \r\n\r\nA temporary solution for me is \r\n```python\r\nfrom tensorflow.compat.v1 import ConfigProto\r\nfrom tensorflow.compat.v1 import InteractiveSession\r\nconfig = ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\nsession = InteractiveSession(config=config)\r\n```\r\nBut I am using tensorflow 2.4.1, which shouldn't depend on version 1.x to run.", "@YIMINGMA,\r\nI was able to run the code without any issues, please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/a8cd7d105807762f8534051ba6323453/47411.ipynb).\r\n\r\nSeems like the error was caused due to TensorFlow consuming all the GPU memory. To prevent this, you can use the solution already working for you. Or else, you can also try any of the alternatives suggested in [link #1](https://github.com/tensorflow/tensorflow/issues/25138), [link #2](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth). \r\n\r\nThanks!", "Hi @amahendrakar ! Thank you for your help. But I have found in both links you provided, solutions that work use either `tensorflow.compat.v1 ` or  `tf.config.experimental`, which means these are not supposed to be current version's feature. But anyway, they work.\r\n\r\nI don't know whether this is a TensorFlow bug or CUDA/CUDNN bug, but I have decided to switch back to CUDA 10.1. Thanks for your help!\r\n", "@YIMINGMA,\r\nThank you for the update. Closing this issue as it is resolved. Please feel free to re-open if mistaken.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47411\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47411\">No</a>\n"]}, {"number": 47410, "title": "Add support for probability/thresholds in meanIoU", "body": "Fixes #39173\r\n\r\nCurrently the meanIoU function requires that if there are `num_classes` in the model's output, each value in `y_pred` must be an integer in the range `[0, num_classes-1]`. This is a problem because most ML models will generate outputs of `num_classes` probabilities in the range `[0-1]` (shape `[dim1, dim2, ..., num_classes]` or `[dim1, dim2, ..., num_classes -1 ]`) , not outputs of shape `[dim1, dim2, ...]` with integer class values. #39173 discusses this further. \r\n\r\nAdding support for probabilities and thresholding will require changes to the API, and I would love to hear your thoughts on the best way to accomplish this.\r\n\r\n## This PR adds the following:\r\n* New optional `threshold` argument in the `meanIoU` initializer. Single configurable threshold shared across all predicted classes, used to turn 0-1 probabilities into 0 or 1 integer predictions\r\n* Support for passing in probabilities instead of integer class labels\r\n* New tests\r\n\r\n\r\n## TODO:\r\n* Add some sort of toggle to select between `classID` mode and `probability` mode. This is needed because if there are more than two classes and `y_pred` is in the current format, values will include integers `[0, 1, 2, ... n]`, and the probability mode would turn all values over the threshold to `1`, giving incorrect results\r\n    * What is the best way to do this? One option would just be to add a `from_probability` field to `meanIoU` that defaults to false, but I'm not sure if there's a better way. #45690 is working towards adding support for logits, so we may need a way to switch between class labels, probabilities, and logins.\r\n* Ensure that results are correct when `num_classes > 2` (no tests at present)\r\n* When in probability mode, ensure that the last dimension of `y_pred` and `y_true` is either `num_classes` or `num_classes - 1`", "comments": ["As an aside, are there any guides for debugging TensorFlow Python unit tests under Bazel?\r\n\r\nI saw from [this stack overflow post](https://stackoverflow.com/questions/51709590/can-i-use-python-debugger-in-bazel-test) that you can do something like `bazel run --run_under=\"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/pdb.py\"\r\n`, but I'm not sure if there is a better way to accomplish this. The workflow I'd like is to be able to run just one test in `metrics_test.py` at a time (saving time on tests I don't care about) and step through it with a debugger.\r\n\r\nIn the span of working on this PR I was just using print statements in combination with `--test_output=streamed`, and I'm assuming there must be a better way to do this.", "I would prefer, [#45690](https://github.com/tensorflow/tensorflow/pull/45690), which doesn't change the original interface, and dealing with both situation of `y_pred` being passed as logits tensor or probability tensor. Also, it supports multi-class label rather than just binary classification.", "Thanks for your feedback @motionlife ! I took another look at your PR, and I do think it better addresses the core of what I was trying to get to with this PR.\r\n\r\nAs far as I can tell, the only situations in which `greater_equal()` will be more helpful than `argmax()` are:\r\n1) When users want to be able to adjust the threshold themselves\r\n2) When one element in the output may have multiple labels, e.g. this pixel is both a person *and* a t-shirt. (I'm not sure how common this is)\r\n\r\n\r\nFor now #45690 meets my needs, but if there is interest in addressing the two points above for #39173 I would be glad to contribute.", "Hi @TylerADavis, Thank you for the contribution.\r\nFor now we also think #45690 is a better approach because it requires no API change. You are right that it doesn't support multi-label classification, which is a bummer, but as far as I can see, your approach (as it is right now) doesn't either, because it still uses confusion_matrix which AFAIK assumes a single class per element. A multi-label MeanIoU would also be a valuable addition IMO.", "Hi @TylerADavis,\r\nAs I said before, we preferred a non PI changing solution for the moment. But if your change adds support to multi-label classification, that's good justification for changing the API. Fee free to submit this PR again, addressing the TODOs you yourself placed."]}, {"number": 47409, "title": "Add int8_t support for micro op zeros_like", "body": "Continue to work on issue #46049. Two changes were made:\r\n1. Added int8_t support. Note the TFLite counterpart does not yet support int8_t;\r\n2. Consolidated the test code with the typename template.", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "Interesting. Last night this PR was passing all tests except one. Now it's failing four. Probably it's caused by a change in the master? "]}, {"number": 47408, "title": "lite: nnapi: Fix fd leak in NNMemory's destructor", "body": "Valid fd values are non-negative, including zero.", "comments": []}, {"number": 47406, "title": "How to run a model training command in redhat linux slurm file?", "body": "<em>Hello , I am trying to run a model training command  for object detection in cluster server. For this reason, I need to run a final command in a particular directory . As I am working on a cluster server, I am creating a slurm file. After the basic instructions, I  wrote the directory where the training command will be executed and now I am unable to connect the training command with the slurm file.</em>\r\n\r\n![Slurrm _ssd](https://user-images.githubusercontent.com/68661510/109196179-ff605080-7760-11eb-963d-8e46fbb6fcd7.png)\r\n", "comments": ["@Homayra22 \r\nWe see that the issue template has not been filled, could you please do so as it helps us analyse the issue [tf version, steps followed before you ran into this error or stand alone code to reproduce the issue faced]\r\n\r\nPlease paste error logs its easy to search the issue.", "Thanks, my problem is solved. I just used the full forms of all the slurm commands and delete \" -l\" from the first line. Also, I run the model training code without \" srun python 3\" command. ", "@Homayra22\r\nPlease move this issue to closed status as its resolved.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47406\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47406\">No</a>\n"]}, {"number": 47405, "title": "Login loop caused by unmet packages in gpu Ubuntu16.04 installation guide", "body": "**System information**\r\n- OS Platform and Distribution Linux Ubuntu 16.04:\r\n- GeForce GTX TITAN 2070\r\nOther inapplicable cause I following a guide: \r\nhttps://www.tensorflow.org/install/gpu?hl=ur#ubuntu_1604_cuda_110\r\n\r\n**Describe the problem**\r\n23th line \r\n`sudo apt-get install --no-install-recommends     cuda-11-0     libcudnn8=8.0.4.30-1+cuda11.0      libcudnn8-dev=8.0.4.30-1+cuda11.0`\r\n\r\nleads to\r\n`Reading package lists... Done\r\nBuilding dependency tree       \r\nReading state information... Done\r\nlibcudnn8-dev is already the newest version (8.0.4.30-1+cuda11.0).\r\nlibcudnn8 is already the newest version (8.0.4.30-1+cuda11.0).\r\nThe following additional packages will be installed:\r\n  cuda-demo-suite-11-0 cuda-drivers cuda-drivers-460 cuda-runtime-11-0\r\n  nvidia-460 nvidia-460-dev\r\nRecommended packages:\r\n  nvidia-prime | bumblebee\r\nThe following packages will be REMOVED:\r\n  nvidia-450\r\nThe following NEW packages will be installed:\r\n  cuda-11-0 cuda-demo-suite-11-0 cuda-drivers cuda-drivers-460\r\n  cuda-runtime-11-0 nvidia-460 nvidia-460-dev\r\n0 upgraded, 7 newly installed, 1 to remove and 66 not upgraded.\r\nNeed to get 0 B/168 MB of archives.\r\nAfter this operation, 93,2 MB of additional disk space will be used.\r\nDo you want to continue? [Y/n] `\r\n\r\nIf 'yes' is choosen next reboot leads to login loop because of\r\n\"NVIDIA NVML Driver/library version mismatch\"\r\nnvidia 450 was installed at 19th line and nvidia 460 after 23th line\r\n\r\nDeleting nvidia 460 allowing to login normally,with nvidia smi giving 450 version,\r\nbut \r\n```\r\nfrom tensorflow.python.client import device_lib\r\ndevice_lib.list_local_devices()\r\n```\r\nStill don't show accessible GPU.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nhttps://www.tensorflow.org/install/gpu?hl=ur#ubuntu_1604_cuda_110\r\nexcept 19th line\r\n`sudo apt-get install --no-install-recommends nvidia-driver-450`\r\ndue to\r\nhttps://github.com/tensorflow/tensorflow/issues/47402\r\ninstead of it \r\n`sudo apt-get install --no-install-recommends nvidia-450`\r\nAnd\r\n`sudo apt-get update --allow-unauthenticated` before 2nd line\r\ndue to\r\n`W: Failed to fetch https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/InRelease  Could not resolve host: developer.download.nvidia.com`\r\n", "comments": ["@GrigoriiTarasov,\r\nAs mentioned in [#47402](https://github.com/tensorflow/tensorflow/issues/47402#issuecomment-786553342), except for the `sudo apt-get install --no-install-recommends nvidia-driver-450` command, I was able to install CUDA without any issues. \r\n\r\nCould you please skip that particular command and let us know if you are still facing the same issue. Thanks!", "@amahendrakar \r\nI really appreciate your help. \r\nYes  if purge, remove and rm all nvidia and cuda and follow guide without nvidia-driver-450 and without reboot those time no login stuck", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47405\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47405\">No</a>\n"]}, {"number": 47404, "title": "Layer .input_shape and .output_shape wrongly claim \"The layer has never been called\"", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 11.2\r\n- TensorFlow installed from (source or binary): https://github.com/apple/tensorflow_macos\r\n- TensorFlow version (use command below): v1.12.1-44680-gc3fea33a21 2.4.0-rc0\r\n- Python version: 3.8.6\r\n\r\n**Describe the current behavior**\r\nFor a layer `l`, `l.input_shape` and `l.output_shape` raise the error \"AttributeError: The layer has never been called and thus has no defined input shape\", even though the layer has definitely been called.\r\n\r\n**Describe the expected behavior**\r\nAfter a layer `l` has been called, `l.input_shape` and `l.output_shape` return shapes.\r\n\r\n**Standalone code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\nl = tf.keras.layers.Dense(units=2)\r\nl(tf.ones((5,3)))  # Call the layer, defining the input shape\r\nprint(l.input_shape)  # Expected: (None, 3)\r\nprint(l.output_shape)  # Expected: (None, 2)\r\n```\r\n\r\n**Other info / logs**\r\n* It's possible I'm using the API wrongly. But I'm pretty sure the claim \"The layer has never been called\" is false.\r\n* This works as expected if I wrap the layer in a `tf.keras.Sequential`. Is there an assumption that the layer is inside a `tf.keras.Model`?", "comments": ["I am able to replicate the issue reported on tf 2.4 and nightly, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/84c0436c69514c3e84766ef1c5886aad/untitled552.ipynb)", "Your assumption is correct, you need to instantiate the `tf.keras.model` before inspecting the shapes of the layers. `dense layer` by itself has no attribute `output_shape`.\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense#example\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47404\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47404\">No</a>\n", "Thanks @ymodak - makes sense. `.output_shape` seems like a private API so I can't really complain - as you say, I should be calling a model, not a layer."]}, {"number": 47403, "title": "Tensorflow and flask has an error loading model.", "body": "Hello \r\nAccording to this closed issue, https://github.com/tensorflow/tensorflow/issues/44467\r\nI tried to install h5py == 2.10.0 version on my venv\r\nBut still got same error\r\n\r\n![image](https://user-images.githubusercontent.com/75870530/109180833-46346180-77c6-11eb-9988-8925782f5bc8.png)\r\n![image](https://user-images.githubusercontent.com/75870530/109180849-4cc2d900-77c6-11eb-83a7-0c35caad603b.png)\r\n![image](https://user-images.githubusercontent.com/75870530/109180894-54827d80-77c6-11eb-9629-c21b75c8b590.png)\r\n\r\nPlease help me\r\nThanks All!", "comments": ["According to https://github.com/tensorflow/tensorflow/issues/44467 , they used tensorflow 2.1 but I am using 1.4, is that a problem?", "But I couldn't get that version.\r\n![image](https://user-images.githubusercontent.com/75870530/109181253-ad521600-77c6-11eb-8d15-39da91f59497.png)\r\nPlease look, and let me get correct version.\r\nThanks", "@liming-developer-python I think you should look once here #39130, check the py ver. you are using, maybe that's creating an issue.", "@Abduttayyeb Thanks for your advise\r\nI installed python tensorflow 2.1.0 successfully But have same error continuosly.\r\nPlease can you tell me another solution to solve that loading model error?\r\n![image](https://user-images.githubusercontent.com/75870530/109241139-caf99c80-7813-11eb-99fa-809dff940087.png)\r\n", "@liming-developer-python \r\nPlease verify if you have 64 bit python version and OS.\r\nPlease refer to similar issues : #47365, #47151, #42163, \r\n\r\nCould you please update pip using the below commands and check if you are still facing the same issue?\r\npip install --upgrade pip\r\npip install tensorflow.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47403\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47403\">No</a>\n"]}, {"number": 47402, "title": "Install gpu Ubuntu16.04 misses crucial steps: \"unable to locate package nvidia-driver-450\"", "body": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/install/gpu?hl=ur#ubuntu_1604_cuda_110\r\n## Description of issue (what needs changing):\r\n\r\n19th line:\r\n`sudo apt-get install --no-install-recommends nvidia-driver-450`\r\nleads to error: \r\n`E: Unable to locate package nvidia-driver-450`\r\n\r\n", "comments": ["Was able to reproduce the issue. Please take a look at the below screenshot for reference\r\n\r\n![Screenshot 2021-02-26 3 05 53 PM](https://user-images.githubusercontent.com/57165142/109282900-28a5dd00-7844-11eb-9d29-83ec21948a20.png)\r\n\r\nThanks!\r\n", "@GrigoriiTarasov,\r\nWith reference to issue [#44301](https://github.com/tensorflow/tensorflow/issues/44301#issuecomment-716250923), ignoring the `sudo apt-get install --no-install-recommends nvidia-driver-450` command seems to work in this case.\r\n\r\nCould you please skip that particular step and check if you are able to install TensorFlow. Thanks!", "@amahendrakar\r\nThanks a lot!\r\nI confirm that skipping 19th line works.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47402\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47402\">No</a>\n"]}, {"number": 47401, "title": "Burst mode execution in NNAPI", "body": "How can we use the burst mode of execution while using the NNAPI delegate? There seems to be no API exposed to select the mode of execution and by default, the NNAPI delegate selects only between async and sync mode based on version. If we want to select a mode of execution through an android application, what should be the approach? ", "comments": ["@miaowang14 could you take a look at this issue?", "Good question! We are actually working on (and testing with) exposing Burst mode through NNAPI delegate.\r\n\r\nHopefully we can land it soon, will keep you updated on this.", "Thanks very much\n\u1427\n\nOn Fri, Feb 26, 2021 at 3:00 AM Miao Wang <notifications@github.com> wrote:\n\n> Good question! We are actually working on (and testing with) exposing\n> Burst mode through NNAPI delegate.\n>\n> Hopefully we can land it soon, will keep you updated on this.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/47401#issuecomment-786240427>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AJ3U3RHZYNHL7WULEX7H5YDTA26NXANCNFSM4YGVB4RA>\n> .\n>\n\n\n-- \nKriti Kukreja\n", "@kukzile \r\nPlease move this to closed status as this is already in process."]}, {"number": 47399, "title": "Unable to build TFLite for Microcontrollers on Mac OS ", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04): mac OS Mojave (version: 10.14.6)\r\n- TensorFlow installed from (source or binary): from source \r\n- Tensorflow version (commit SHA if source):\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): zephyr_vexriscv (from [this tutorial](https://blog.tensorflow.org/2020/06/running-and-testing-tf-lite-on-microcontrollers.html)\r\n\r\n**Describe the problem**\r\nI have created my own test project base on [this tutorial](https://blog.tensorflow.org/2020/06/running-and-testing-tf-lite-on-microcontrollers.html), but when I build it using the following command: \r\n**make -f tensorflow/lite/micro/tools/make/Makefile TARGET=\"zephyr_vexriscv\" ruby1_bin**\r\n \r\nI have got this error message:\r\ntensorflow/lite/micro/tools/make/Makefile:417: warning: overriding recipe for target 'tensorflow/lite/micro/tools/make/downloads/person_model_int8'\r\ntensorflow/lite/micro/tools/make/Makefile:417: warning: ignoring old recipe for target 'tensorflow/lite/micro/tools/make/downloads/person_model_int8'\r\ng++ -std=c++11 -fno-rtti -fno-exceptions -fno-threadsafe-statics -fno-unwind-tables -ffunction-sections -fdata-sections -fmessage-length=0 -DTF_LITE_STATIC_MEMORY -DTF_LITE_DISABLE_X86_NEON -O3 -Werror -Wsign-compare -Wdouble-promotion -Wshadow -Wunused-variable -Wmissing-field-initializers -Wunused-function -Wswitch -Wvla -Wall -Wextra -Wstrict-aliasing -Wno-unused-parameter  -I. -Itensorflow/lite/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/micro/tools/make/downloads/flatbuffers/include -Itensorflow/lite/micro/tools/make/downloads/ruy -Itensorflow/lite/micro/tools/make/downloads/kissfft -o tensorflow/lite/micro/tools/make/gen/zephyr_vexriscv_x86_64/bin/ruby1 tensorflow/lite/micro/tools/make/gen/zephyr_vexriscv_x86_64/obj/tensorflow/lite/micro/examples/ruby1/main.o tensorflow/lite/micro/tools/make/gen/zephyr_vexriscv_x86_64/obj/tensorflow/lite/micro/examples/ruby1/model_28.o tensorflow/lite/micro/tools/make/gen/zephyr_vexriscv_x86_64/lib/libtensorflow-microlite.a  -lm\r\nUndefined symbols for architecture x86_64:\r\n  \"_stbi_load\", referenced from:\r\n      _main in main.o\r\nld: symbol(s) not found for architecture x86_64\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)\r\nmake: *** [tensorflow/lite/micro/examples//ruby1/Makefile.inc:13: tensorflow/lite/micro/tools/make/gen/zephyr_vexriscv_x86_64/bin/ruby1] Error 1\r\n\r\n", "comments": ["Hi @Sehaba95! \r\nWe are checking to see whether you still need help in this issue .Supported Micro controllers for Tensorflow can be found [here](https://www.tensorflow.org/lite/microcontrollers). You can refer this[ link](https://github.com/milinddeore/TfLite-Standalone-build-Linux-MacOS) for building TFLite in Mac OS .Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47399\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47399\">No</a>\n"]}, {"number": 47398, "title": "[XLA:GPU] Updated hlo_to_llvm_ir to also emit PTX and re-enable tests using it.", "body": "@sanjoy ", "comments": ["@nouiz  Can you please address Ubuntu Sanity errors? Thanks!", "Done. I also updated the new tests. I had forgot the CHECK-LABEL.", "I did some clean up of the tests.", "Seems auto-merge is not happening but the changes are merged into master now, so we can close this. Thank you for the PR.", "I do not see the new commit in the master branch:\r\n```\r\ncommit 979cabfc2df277a143c88303f78d172374358ad4 (origin/upstream-hlo_to_llvm_ir, upstream-hlo_to_llvm_ir)\r\nAuthor: Frederic Bastien <fbastien@nvidia.com>\r\nDate:   Tue Mar 9 08:13:12 2021 -0800\r\n\r\n    Added check for SM 70.\r\n\r\ncommit 3bb586d99c375b2bd0a1d285e616d366e7da6c9d\r\nAuthor: Frederic Bastien <fbastien@nvidia.com>\r\nDate:   Tue Mar 9 08:04:08 2021 -0800\r\n\r\n    Simplify the check.\r\n\r\ncommit 57b2b07fd97fef115d6e3618384d620b3b41c4d7\r\nAuthor: Frederic Bastien <fbastien@nvidia.com>\r\nDate:   Tue Mar 9 07:59:11 2021 -0800\r\n\r\n    Combine tests into a single file.\r\n\r\ncommit 482a34c6ae000f7154a145cfcb8889523ccba750\r\nAuthor: Frederic Bastien <fbastien@nvidia.com>\r\nDate:   Tue Mar 9 07:48:11 2021 -0800\r\n\r\n    Combine tests into a single file.\r\n\r\ncommit 32de6bb747b092265a70d75430d40a57307b399a\r\nAuthor: Frederic Bastien <fbastien@nvidia.com>\r\nDate:   Tue Mar 9 07:39:05 2021 -0800\r\n\r\n    Combine tests into a single file.\r\n```\r\n\r\nDo you need to include them manually?", "You'll have to open a new PR, your original change has already been merged at bcf9c308e231d90721a064460e9fbe3287131f54.", "https://github.com/tensorflow/tensorflow/pull/47707"]}, {"number": 47397, "title": "Add missing closing backtick", "body": "", "comments": []}, {"number": 47396, "title": "BestExporter exports worse model when training tasks restart.", "body": "BestExporter is widely used in my company to avoid model degradation with time. But BestExporter exports worse model when training task restart.\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution: Distributed training.\r\n- TensorFlow installed from (source or binary):binary.\r\n- TensorFlow version (use command below): All versions(TF1.14, TF1.15, TF2.x).\r\n\r\n**Describe the current behavior**\r\n\r\nThere are scenes for example we need to restart training tasks: \r\n\r\n1. continuous training(not online streaming training): Training with new data and check if its satisfies the best exporter condition.\r\n2. Failure restart: In local or distributed training, worker failure is common, thanks to the checkpoint, we can restart failed task.\r\n\r\nFor example, old best AUC is 0.85, but when we restart training task,  [self._has_exported](https://github.com/tensorflow/estimator/blob/master/tensorflow_estimator/python/estimator/exporter.py#L295) in BestExporter is False, and TF will export new saved model ignoring whether current eval_result(for example AUC=0.79) is better than best_result(AUC=0.80)  loaded from event files created by last running task or not. And next all eval_results(for example AUC=0.80, AUC=0.81) are worse than old AUC=0.85 unfortunately which means all newer saved_models are worse than old one and may cause worse online business metrics.\r\n\r\nThis bug was imported in [issue](https://github.com/tensorflow/estimator/pull/41)  and  [this commit](https://github.com/tensorflow/estimator/commit/43921b4552d1c30acc31d3b5989112cb397383e0#diff-5e0426432b8f40323ca256ef0d11b27ec3a7b4cc9d4042d228b17d0b13d73cfb).\r\n\r\n**Describe the expected behavior**\r\n\r\nExport REAL best model.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nHas been proved in production environment.\r\n\r\n", "comments": ["@wuxianxingkong \r\nPlease share simple stand alone code to replicate the issue reported or a colab gist with the error and code.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47396\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47396\">No</a>\n"]}, {"number": 47395, "title": "tflite api doesnt return input shape in c++", "body": "I am using a functional model which  I converted it to tflite  in tf2.4.0 but I dont get shape of input tensor in c++ but Its  visible in python\r\n\r\n```\r\ninterpreter = tf.lite.Interpreter(model_path=\"model.tflite\")\r\ninterpreter.allocate_tensors()\r\ninput_details = interpreter.get_input_details()\r\nprint(input_details)\r\nprint(input_details[0]['shape'])  ##Returns  shape of input tensor [1  100 100 1]\r\n```\r\n\r\n```\r\nstd::unique_ptr<tflite::FlatBufferModel> model = tflite::FlatBufferModel::BuildFromFile(\"model.tflite\");\r\ntflite::ops::builtin::BuiltinOpResolver resolver;\r\ntflite::InterpreterBuilder builder(*model, resolver);\r\nstd::unique_ptr<tflite::Interpreter> interpreter;\r\nbuilder(&interpreter);\r\ninterpreter->AllocateTensors();\r\nstd::cout <<\"Input variable name: \"<<interpreter->GetInputName(0)<<std::endl; // Works\r\nstd::vector<int> inputs_vec = interpreter->inputs();  // Returns [0]. Size of vector is 1\r\n\r\n\r\n```\r\n", "comments": ["The `tflite::Interpreter` class has the `input_tensor` method to get the `TfLiteTensor` object. In the `TfLiteTensor` object, there is a shape information at the `dims` field.\r\n\r\nPlease refer to https://www.tensorflow.org/lite/api_docs/cc/class/tflite/interpreter", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47395\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47395\">No</a>\n"]}, {"number": 47394, "title": "Simple Example with CIFAR-10. ImageDataGenerator + 'sparse_categorical_crossentropy'", "body": "**System information**\r\n- TensorFlow version (use command below): 2.4\r\n\r\nI try example CIFAR-10 with ImageDataGenerator. But it doesn't works. \r\n\r\nMy custom CNN Model is not training when I use **ImageDataGenerator + sparse_categorical_crossentropy**.\r\nHowever, when I use **ImageDataGenerator + categorical_crossentropy**, it works well.\r\n\r\nwhat happen in this code?\r\n\r\nThank you and my code is below.\r\n\r\n------------------------------------------\r\n\r\n```\r\nfrom tensorflow.keras.datasets import cifar10\r\nimport numpy as np\r\n\r\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\r\n\r\nx_mean = np.mean(x_train, axis = (0, 1, 2))\r\nx_std = np.std(x_train, axis = (0, 1, 2))\r\n\r\nx_train = (x_train - x_mean) / x_std\r\nx_test = (x_test - x_mean) / x_std\r\n\r\nfrom sklearn.model_selection import train_test_split\r\n\r\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, \r\n                                                  test_size = 0.3, random_state = 777)\r\n\r\nprint('data ready~')\r\n\r\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n\r\ntrain_datagen = ImageDataGenerator(horizontal_flip = True,\r\n                                   zoom_range = 0.2,\r\n                                   width_shift_range = 0.1,\r\n                                   height_shift_range = 0.1,\r\n                                   rotation_range = 30,\r\n                                   fill_mode = 'nearest'\r\n                                  )\r\nval_datagen = ImageDataGenerator()\r\n\r\nbatch_size = 32\r\n\r\ntrain_generator = train_datagen.flow(x_train, y_train,\r\n                                    batch_size = batch_size)\r\nval_generator = val_datagen.flow(x_val, y_val,\r\n                                batch_size = batch_size)\r\n\r\n\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Dense, Flatten, Activation, BatchNormalization\r\nfrom tensorflow.keras.optimizers import Adam\r\n\r\nmodel = Sequential()\r\n\r\nmodel.add(Conv2D(filters = 32, kernel_size = 3, padding = 'same', input_shape = (32, 32, 3)))\r\nmodel.add(BatchNormalization())\r\nmodel.add(Activation('relu'))\r\nmodel.add(Conv2D(filters = 32, kernel_size = 3, padding = 'same'))\r\nmodel.add(BatchNormalization())\r\nmodel.add(Activation('relu'))\r\nmodel.add(MaxPool2D(pool_size = (2, 2), strides = 2, padding = 'same'))\r\n\r\nmodel.add(Conv2D(filters = 64, kernel_size = 3, padding = 'same'))\r\nmodel.add(BatchNormalization())\r\nmodel.add(Activation('relu'))\r\nmodel.add(Conv2D(filters = 64, kernel_size = 3, padding = 'same'))\r\nmodel.add(BatchNormalization())\r\nmodel.add(Activation('relu'))\r\nmodel.add(MaxPool2D(pool_size = (2, 2), strides = 2, padding = 'same'))\r\n\r\nmodel.add(Conv2D(filters = 128, kernel_size = 3, padding = 'same'))\r\nmodel.add(BatchNormalization())\r\nmodel.add(Activation('relu'))\r\nmodel.add(Conv2D(filters = 128, kernel_size = 3, padding = 'same'))\r\nmodel.add(BatchNormalization())\r\nmodel.add(Activation('relu'))\r\nmodel.add(MaxPool2D(pool_size = (2, 2), strides = 2, padding = 'same'))\r\n\r\nmodel.add(Flatten())\r\nmodel.add(Dense(256))\r\nmodel.add(Activation('relu'))\r\nmodel.add(Dense(10, activation = 'softmax'))\r\n\r\nmodel.compile(optimizer = Adam(1e-4),\r\n             loss = 'sparse_categorical_crossentropy',\r\n             metrics = ['acc'])\r\n\r\ndef get_step(train_len, batch_size):\r\n    if(train_len % batch_size > 0):\r\n        return train_len // batch_size + 1\r\n    else:\r\n        return train_len // batch_size\r\n\r\nhistory = model.fit(train_generator,\r\n                    epochs = 100,\r\n                    steps_per_epoch = get_step(len(x_train), batch_size),\r\n                    validation_data = val_generator,\r\n                    validation_steps = get_step(len(x_val), batch_size))\r\n```\r\n", "comments": ["To begin with, when replicating this code in a Google Colab runtime, it seemed to function properly, so the bug is likely with your system or for a different reason. The code does not seem to have any *runtime* issues.\r\n\r\nIn general, `sparse_categorical_crossentropy` should be used when prediction classes are mutually exclusive, i.e. each training example belongs to one single class, and `categorical_crossentropy` should be used when one sample may have multiple labels or you need the *probability* for each output.\r\n\r\nFor example, if you have a label of `2`, from the range 0-3, then you should use `sparse_categorical_crossentropy`. However, if your label vector is `[0.1, 0.05, 0.75, 0.1]`, then you should use `categorical_crossentropy` since you are finding the prediction *confidence* for each class.\r\n\r\nFor the Cifar-10 example that you've given, the labels are each contained in a 1-dimensional label vector, i.e. `[[0], [1], [2], [5]]` (with a shape of (35000, 1). This means that it will not throw an error with `sparse_categorical_crossentropy` *or* `categorical_crossentropy`. However, since it is still a vector without class probabilities, it actually will not perform best on *any* of these two loss functions. If you want to use `sparse_categorical_crossentropy`, the best option here since there are **mutually exclusive class values**, then call either `np.squeeze` or `tf.squeeze` on the data to get rid of the last dimension.", "Firstly, Thank you for your answer And I understand it.\r\n\r\nAdditional, I check that it works well using np.squeeze on y_train.\r\n\r\nBut, I don't understand below.\r\n\r\n+ x_train = same\r\n+ y_train = (35000, 1)\r\n+ compile loss = sparse_categorical_crossentropy\r\n\r\nIn model.fit(), \r\nA.\r\nmodel.fit(x_train, y_train, ...) --> good\r\n\r\nB.\r\nmodel.fit(train_generator, ...) --> Bad\r\n\r\nIn SparseCategoricalCrossentropy(y_true, y_pred), I think that Loss function uses the same thing below.\r\n+ y_true = (batch_size, 1)\r\n+ y_pred = (batch_size, 10)\r\n\r\nwhat is difference between A and B example?\r\nIs the difference due to the way y_train is handled inside the fit function?", "Could you please elaborate on the issues you are facing with the `ImageDataGenerator`? I rarely encounter any issues when working with it, and it in fact is supposed to *help* with training, since it performs spatial augmentation on the images. This allows it to generate more diverse data. \r\n\r\nThe clearcut difference between the way X_train and y_train are handled inside of the training function is essentially due to the fact that alongside the spatial augmentation, the `ImageDataGenerator` creates image batches beforehand.\r\n\r\nFurthermore, I seem to encounter no issues using either of them when testing in Google Colab, so I'm not sure what the problem is.", "Definitely, No error in code.\r\n\r\nwhen using ImageDatagenerator, I got about 10% accuracy.\r\nBut, I use y_train on fit function directly, I got about 80% accuracy.\r\nThe problem is that performance is not good.\r\n\r\nLiterally, I think No difference between the two.\r\n\r\nBecause,\r\nWith ImageDataGenerator gives us the shape of y_train like below.\r\n\r\n```\r\ntest = train_generator.next()\r\ntest[1].shape # output's shape: (32, 1)\r\n\r\nAnd, With just using y_train,\r\ny_train.shape # output's shape: (35000, 1)\r\n\r\nBut in fit function, I think that the shape of y_train turns into (32, 1)\r\n```\r\n\r\nHowever, when using ImageDataGenerator, performance is good with suqeeze, and when y_train is used directly, performance is good without squeeze.\r\n\r\nI don't understand this... why?\r\n", "The explanation for the different shapes, as I mentioned previously, is because the `ImageDataGenerator` converts the data into **image batches**. This means that the data will be converted into smaller sets of the same data, which will then be passed through the model in sequence.\r\n\r\nFurthermore, there *is* a difference, because the `ImageDataGenerator` **spatially augments** the images, so it might rotate, or horizontally/vertically flip the image.\r\n\r\nAs for your description of accuracies between the `ImageDataGenerator` and the `X_train`/`y_train`, I can't seem to replicate that; I get similar accuracies with both.\r\n\r\nI suggest you recheck your code and if your questions have been answered, please be sure to close the issue.", "Thank you and Rechecking Now.\r\n\r\nFinally, I close this issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47394\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47394\">No</a>\n", "I ran into the same issue. \r\nSystem information: Win 10 21h1, python 3.9, TensorFlow 2.6.0\r\nWhen I use CIFAR10 + ImageDataGenerator + sparse_categorical_crossentropy in TF2.6, I got 10% acc. \r\nUsing MNIST + ImageDataGenerator + sparse_categorical_crossentropy, 99% acc, it works well.\r\nUsing Fruits114 + ImageDataGenerator + sparse_categorical_crossentropy, 99% acc, it works well too.\r\nUsing CIFAR10 without ImageDataGenerator, it works well too.\r\nUsing CIFAR10 + ImageDataGenerator + sparse_categorical_crossentropy in TF2.1, I got 90% acc, it works well too.\r\nThis is very strange to me. I am guessing whether some changes made by ImageDataGenerator caused this strange phenomenon.\r\n"]}, {"number": 47393, "title": "EagerTensor implements `__len__` but not `len()`.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `Linux merry 5.8.0-43-generic #49~20.04.1-Ubuntu SMP Fri Feb 5 09:57:56 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux`\r\n- TensorFlow installed from (source or binary): `pip install tensorflow`\r\n- TensorFlow version (use command below): `v2.4.0-49-g85c8b2a817f 2.4.1`\r\n- Python version: `3.8.5 (default, Jul 28 2020, 12:59:40) [GCC 9.3.0]`\r\n\r\n**Describe the current behavior**\r\nThe EagerTensor implements `__len__` but does not provide the `len(.)` function.\r\n\r\n**Describe the expected behavior**\r\nIf `__len__` is a attribute, the `len(.)` function should work.\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport sys\r\n\r\nprint(tf.version.GIT_VERSION, tf.version.VERSION) # v2.4.0-49-g85c8b2a817f 2.4.1\r\nprint(sys.version) # 3.8.5 (default, Jul 28 2020, 12:59:40) [GCC 9.3.0]\r\nx = np.dtype('float32').type(3.0)\r\n\r\nsigmoid = tf.keras.layers.Activation(activation=\"sigmoid\")\r\nactX = sigmoid(x)\r\n\r\nprint(type(x)) # <class 'numpy.float32'>\r\nprint(type(actX)) # <class 'tensorflow.python.framework.ops.EagerTensor'>\r\n\r\nif hasattr(actX, \"__len__\"):\r\n    print(len(actX))\r\nelse:\r\n    print(\"Has no length\")\r\n```\r\nyield the following error:\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-5-a34ef039f8c4> in <module>\r\n      9 \r\n     10 if hasattr(actX, \"__len__\"):\r\n---> 11     print(len(actX))\r\n     12 else:\r\n     13     print(\"Has no length\")\r\n\r\n~/Projects/NotebooksEnvs/py38Env/lib/python3.8/site-packages/tensorflow/python/framework/ops.py in __len__(self)\r\n   1020     \"\"\"Returns the length of the first dimension in the Tensor.\"\"\"\r\n   1021     if not self.shape.ndims:\r\n-> 1022       raise TypeError(\"Scalar tensor has no `len()`\")\r\n   1023     # pylint: disable=protected-access\r\n   1024     try:\r\n\r\nTypeError: Scalar tensor has no `len()`\r\n```\r\n\r\n\r\n", "comments": ["I am able to replicate the issue reported on tf 2.4 and nightly, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/a61b1be61641de145afc27ff46e02b7d/untitled552.ipynb)", "@noppelmax Looks like this throws an error when the object has single element. When I have list object as shown below, then there is no issue.  Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/be4093be730a116a6a1046fe7dbad607/untitled552.ipynb)\r\n\r\n`x = np.dtype('float32').type([3.0, 4.0, 5.0])`\r\n\r\nI am not sure whether it is intended or not. We will look into it. Thanks!", "This is an expected behavior. As the trace shows, the tensor is a scalar. As a result len() does not really apply here.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47393\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47393\">No</a>\n", "So the only possibility to check whether a tensor is a scalar or not is a `try-except`? ", "Hi @noppelmax, can you please specify what is your usage scenario? What about attribute 'shape'?\r\n\r\n```\r\nx = tf.constant(1)\r\ny = tf.constant([1,2,3])\r\n\r\nprint(x.shape) # ()\r\nprint(y.shape) # (3,)\r\n```"]}, {"number": 47392, "title": "Did not open image after detecting object using tensorflow2", "body": "I am learning object [detetction with tensorflow2](https://gilberttanner.com/blog/tensorflow-object-detection-with-tensorflow-2-creating-a-custom-model) and my model trained successfully.\r\n\r\nBut whenever I trying to [Test trained model on test images](https://colab.research.google.com/github/TannerGilbert/Tensorflow-Object-Detection-API-Train-Model/blob/master/Tensorflow_2_Object_Detection_Train_model.ipynb#scrollTo=5tGVwzpLxvSv) in my _VScode_, image doesn't open.\r\n\r\n### Here is my code:\r\n\r\n```\r\nimport io\r\nimport os\r\nimport cv2\r\nimport scipy.misc\r\nimport numpy as np\r\nimport six\r\nimport time\r\nimport glob\r\nfrom IPython.display import display\r\n\r\nfrom six import BytesIO\r\n\r\nimport matplotlib\r\nimport matplotlib.pyplot as plt\r\nfrom PIL import Image, ImageDraw, ImageFont\r\n\r\nimport tensorflow as tf\r\nfrom object_detection.utils import ops as utils_ops\r\nfrom object_detection.utils import label_map_util\r\nfrom object_detection.utils import visualization_utils as vis_util\r\n\r\ndef load_image_into_numpy_array(path):\r\n  \"\"\"Load an image from file into a numpy array.\r\n\r\n  Puts image into numpy array to feed into tensorflow graph.\r\n  Note that by convention we put it into a numpy array with shape\r\n  (height, width, channels), where channels=3 for RGB.\r\n\r\n  Args:\r\n    path: a file path (this can be local or on colossus)\r\n\r\n  Returns:\r\n    uint8 numpy array with shape (img_height, img_width, 3)\r\n  \"\"\"\r\n  img_data = tf.io.gfile.GFile(path, 'rb').read()\r\n  image = Image.open(BytesIO(img_data))\r\n  (im_width, im_height) = image.size\r\n  return np.array(image.getdata()).reshape(\r\n      (im_height, im_width, 3)).astype(np.uint8)\r\n\r\ncategory_index = label_map_util.create_category_index_from_labelmap('training/label_map.pbtxt', use_display_name=True)\r\n\r\ntf.keras.backend.clear_session()\r\nmodel = tf.saved_model.load(f'inference_graph/saved_model')\r\n\r\ndef run_inference_for_single_image(model, image):\r\n  image = np.asarray(image)\r\n  # The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\r\n  input_tensor = tf.convert_to_tensor(image)\r\n  # The model expects a batch of images, so add an axis with `tf.newaxis`.\r\n  input_tensor = input_tensor[tf.newaxis,...]\r\n\r\n  # Run inference\r\n  model_fn = model.signatures['serving_default']\r\n  output_dict = model_fn(input_tensor)\r\n\r\n  # All outputs are batches tensors.\r\n  # Convert to numpy arrays, and take index [0] to remove the batch dimension.\r\n  # We're only interested in the first num_detections.\r\n  num_detections = int(output_dict.pop('num_detections'))\r\n  output_dict = {key:value[0, :num_detections].numpy() \r\n                 for key,value in output_dict.items()}\r\n  output_dict['num_detections'] = num_detections\r\n\r\n  # detection_classes should be ints.\r\n  output_dict['detection_classes'] = output_dict['detection_classes'].astype(np.int64)\r\n   \r\n  # Handle models with masks:\r\n  if 'detection_masks' in output_dict:\r\n    # Reframe the the bbox mask to the image size.\r\n    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\r\n              output_dict['detection_masks'], output_dict['detection_boxes'],\r\n               image.shape[0], image.shape[1])      \r\n    detection_masks_reframed = tf.cast(detection_masks_reframed > 0.5,\r\n                                       tf.uint8)\r\n    output_dict['detection_masks_reframed'] = detection_masks_reframed.numpy()\r\n    \r\n  return output_dict\r\n  \r\nfor image_path in glob.glob('images/test/*.jpg'):\r\n  image_np = load_image_into_numpy_array(image_path)\r\n  output_dict = run_inference_for_single_image(model, image_np)\r\n  vis_util.visualize_boxes_and_labels_on_image_array(\r\n      image_np,\r\n      output_dict['detection_boxes'],\r\n      output_dict['detection_classes'],\r\n      output_dict['detection_scores'],\r\n      category_index,\r\n      instance_masks=output_dict.get('detection_masks_reframed', None),\r\n      use_normalized_coordinates=True,\r\n      line_thickness=8)\r\n  display(Image.fromarray(image_np))\r\n```\r\n\r\n### After run the python file I got below output in cmd:\r\n\r\n> <PIL.Image.Image image mode=RGB size=500x625 at 0x2090689B040>\r\n> <PIL.Image.Image image mode=RGB size=242x239 at 0x2090689B040>\r\n> <PIL.Image.Image image mode=RGB size=238x238 at 0x2090689B040>\r\n> <PIL.Image.Image image mode=RGB size=489x368 at 0x2090689B040>\r\n> <PIL.Image.Image image mode=RGB size=433x358 at 0x2090689B040>\r\n> <PIL.Image.Image image mode=RGB size=486x486 at 0x2090689B040>\r\n> <PIL.Image.Image image mode=RGB size=492x487 at 0x2090689B040>\r\n> <PIL.Image.Image image mode=RGB size=155x357 at 0x2090689B040>\r\n\r\n**_I didn't get expected output which is shown [here](https://colab.research.google.com/github/TannerGilbert/Tensorflow-Object-Detection-API-Train-Model/blob/master/Tensorflow_2_Object_Detection_Train_model.ipynb#scrollTo=EEX-m3P1yp4y&line=5&uniqifier=1)._** Please help me to solve this.", "comments": ["@rutvi1462 \r\nIf you run this code with a normal Python interpreter, this output is expected. To resolve this, you have two options. One, you can save these images to disk and view them as normal images. Secondly, you can try with `cv2.imshow()` method. This works when calling through interpreter and shell. \r\nSometimes Jupyter or Colab notebooks face similar issues, so it's best to avoid them for this case.", "@AdityaKane2001 \r\nThanks for your answer. Images are already saved in my drive. But its give me same output. And I tried `cv2.imshow()`. I wrote this above `display(Image.fromarray(image_np))`. But it would show me only image. This is not detect at least wrong object. Is this right place to write  `cv2.imshow()`. If not do you have any solution?", "So, if you are accessing from a script, IPython module will not help you. Please try with `cv2.imshow()` . Secondly, when using cv2, don't forget to manually draw the boxes using `cv2.rectangle()`  . I think using this method, you will get your results.\r\n\r\nIn case the issue gets resolved, don't forget to close this issue.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n"]}, {"number": 47390, "title": "TypeError: tensor_equals() missing 1 required positional argument: 'other'", "body": "\r\n![image](https://user-images.githubusercontent.com/18486587/109113616-895ce900-7762-11eb-9882-5f86a866d871.png)\r\n\r\nOn loading the saved model, it gives an error. \r\nTensorflow version is 2.4.1\r\n[Notebook to reproduce it. ](https://colab.research.google.com/drive/1w5QAIeG6rUpSWUbHEJJjNLfp1FYzCwff?usp=sharing)", "comments": ["@coreqode \r\nI ran the code shared in the notebook but face a different error,please find [gist here](https://colab.research.google.com/gist/Saduf2019/d13f1ed2de788bb037e69d7eeb7c7d6b/untitled.ipynb).\r\nPlease share all dependencies for us to replicate the issue reported.", "@Saduf2019 \r\nCan you download and upload the model file from the link mentioned in\r\nnotebook?\r\n\r\nOn Thu, 25 Feb 2021 at 1:15 PM, Saduf2019 <notifications@github.com> wrote:\r\n\r\n> @coreqode <https://github.com/coreqode>\r\n> I ran the code shared in the notebook but face a different error,please\r\n> find gist here\r\n> <https://colab.research.google.com/gist/Saduf2019/d13f1ed2de788bb037e69d7eeb7c7d6b/untitled.ipynb>\r\n>\r\n> \u2014\r\n> You are receiving this because you were mentioned.\r\n> Reply to this email directly, view it on GitHub\r\n> <https://github.com/tensorflow/tensorflow/issues/47390#issuecomment-785692206>,\r\n> or unsubscribe\r\n> <https://github.com/notifications/unsubscribe-auth/AENBKO3JOB47WZYSVNDJPX3TAX5Z5ANCNFSM4YF5J45A>\r\n> .\r\n>\r\n", "I am able to replicate the issue reported on tf 2.3,2.4 and nightly, please find [gist here](https://colab.research.google.com/gist/Saduf2019/41277ef17882a989fe5f29c3f5061fbd/untitled.ipynb)", "@coreqode,\r\nCan you please share the complete code i.e., code for building your model and code for saving it? Thanks! ", "@rmothukuru Here is a complete code for reproducing the error. [Link to Colab Notebook](https://colab.research.google.com/drive/1zsLXYiBEOGGf2-ljKeNe1LbWqwMS0vQv?usp=sharing)\r\n\r\nI also think, that most probably error lies in this line, `input_5, input_4 = model_reposition(input_1, input_4, input_4, input_4)` in the `build_model` function. Because, without this, I was able to restore the model. \r\nPlease have a look at this code. Thanks!!", "Was able to reproduce the issue in TF v2.6.0-dev20210526,please check the gist [here](https://colab.research.google.com/gist/sushreebarsa/90064818d55409d022a923b9554a224b/untitled143.ipynb?authuser=1#scrollTo=52cnFkQCmcOf)..Thanks !", "I had the same issue. Changing a line `tensor == 0` to `tf.equal(tensor, 0)` fixed the problem. I used TF2.5.0.", "I had the same problem, and @salmituukka s solution to change a `tensor != 0` to `tf.not_equal(tensor, 0)` worked like a charm.", "An interesting side note is that Vertex AI Models & Endpoint could load the model just fine, so I'm guessing they do something else than `tf.keras.models.load_model` internally.", "@coreqode Could you please update as per the [comment ](https://github.com/tensorflow/tensorflow/issues/47390#issuecomment-905396213) using TF v2.6.0 and let us know if it helps?Thank you!", "(I'm using tf 2.6.0 btw)", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47390\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47390\">No</a>\n", "> I had the same issue. Changing a line `tensor == 0` to `tf.equal(tensor, 0)` fixed the problem. I used TF2.5.0.\r\n\r\nChanging the operator to a function does solve the problem. However, there's two outstanding issues that require solutions.\r\n\r\n(1) You can still save the model, without receiving any warning. This issue only shows up when loading the model with load_model()\r\n\r\n(2) Recovering the model from this state is challenging. Suppose you trained a model for a long time, and went to recover it. All the information about the parameters is there. However, it cannot be loaded.  Passing {\"other\": ....} to load_model(custom_object=...) does nothing. How can the model be recovered?"]}]