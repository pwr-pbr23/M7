[{"number": 636, "title": "Implementation for GPU depthwise max pooling", "body": "I have this code:\n\n```\n    sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True,\n                                        log_device_placement=True))\n    with tf.device(\"/gpu:0\"):\n        s, readout, h_fc1 = createNetwork()\n    with sess:\n            trainNetwork(s, readout, h_fc1, sess)\n```\n\nThis fails with this error:\n\n```\nW tensorflow/core/common_runtime/executor.cc:1076] 0x28d7890 Compute status: Unimplemented: Depthwise max pooling is currently only implemented for CPU devices.\n     [[Node: MaxPool = MaxPool[ksize=[1, 1, 1, 512], padding=\"SAME\", strides=[1, 1, 1, 512], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Relu_2)]]\nW tensorflow/core/common_runtime/executor.cc:1076] 0x2a693f0 Compute status: Unimplemented: Depthwise max pooling is currently only implemented for CPU devices.\n     [[Node: MaxPool = MaxPool[ksize=[1, 1, 1, 512], padding=\"SAME\", strides=[1, 1, 1, 512], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Relu_2)]]\n     [[Node: add_4/_3 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1039_add_4\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nTraceback (most recent call last):\n  File \"/mnt/data1/PREZ/PROGRAMMING/2015/12/BOB_learning_0/gpu/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 428, in _do_run\n    target_list)\ntensorflow.python.pywrap_tensorflow.StatusNotOK: Unimplemented: Depthwise max pooling is currently only implemented for CPU devices.\n     [[Node: MaxPool = MaxPool[ksize=[1, 1, 1, 512], padding=\"SAME\", strides=[1, 1, 1, 512], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Relu_2)]]\n     [[Node: add_4/_3 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1039_add_4\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"bob_learning.py\", line 222, in <module>\n    main()\n  File \"bob_learning.py\", line 219, in main\n    playGame()\n  File \"bob_learning.py\", line 216, in playGame\n    trainNetwork(s, readout, h_fc1, sess)\n  File \"bob_learning.py\", line 141, in trainNetwork\n    readout_t = readout.eval(feed_dict = {s : [s_t]})[0]\n  File \"/mnt/data1/PREZ/PROGRAMMING/2015/12/BOB_learning_0/gpu/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 460, in eval\n    return _eval_using_default_session(self, feed_dict, self.graph, session)\n  File \"/mnt/data1/PREZ/PROGRAMMING/2015/12/BOB_learning_0/gpu/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 2910, in _eval_using_default_session\n    return session.run(tensors, feed_dict)\n  File \"/mnt/data1/PREZ/PROGRAMMING/2015/12/BOB_learning_0/gpu/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 368, in run\n    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)\n  File \"/mnt/data1/PREZ/PROGRAMMING/2015/12/BOB_learning_0/gpu/lib/python3.4/site-packages/tensorflow/python/client/session.py\", line 444, in _do_run\n    e.code)\ntensorflow.python.framework.errors.UnimplementedError: Depthwise max pooling is currently only implemented for CPU devices.\n     [[Node: MaxPool = MaxPool[ksize=[1, 1, 1, 512], padding=\"SAME\", strides=[1, 1, 1, 512], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Relu_2)]]\n     [[Node: add_4/_3 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device_incarnation=1, tensor_name=\"edge_1039_add_4\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nCaused by op 'MaxPool', defined at:\n  File \"bob_learning.py\", line 222, in <module>\n    main()\n  File \"bob_learning.py\", line 219, in main\n    playGame()\n  File \"bob_learning.py\", line 214, in playGame\n    s, readout, h_fc1 = createNetwork()\n  File \"bob_learning.py\", line 98, in createNetwork\n    h_pool3_flat = tf.reshape(max_pool_featurewise(h_conv3, old_num_filters), [-1, IMSIZE * IMSIZE])\n  File \"bob_learning.py\", line 52, in max_pool_featurewise\n    return tf.nn.max_pool(x, ksize = [1, 1, 1, num_filters], strides = [1, 1, 1, num_filters], padding = \"SAME\")\n  File \"/mnt/data1/PREZ/PROGRAMMING/2015/12/BOB_learning_0/gpu/lib/python3.4/site-packages/tensorflow/python/ops/nn_ops.py\", line 235, in max_pool\n    name=name)\n  File \"/mnt/data1/PREZ/PROGRAMMING/2015/12/BOB_learning_0/gpu/lib/python3.4/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 449, in _max_pool\n    strides=strides, padding=padding, name=name)\n  File \"/mnt/data1/PREZ/PROGRAMMING/2015/12/BOB_learning_0/gpu/lib/python3.4/site-packages/tensorflow/python/ops/op_def_library.py\", line 664, in apply_op\n    op_def=op_def)\n  File \"/mnt/data1/PREZ/PROGRAMMING/2015/12/BOB_learning_0/gpu/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 1834, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/mnt/data1/PREZ/PROGRAMMING/2015/12/BOB_learning_0/gpu/lib/python3.4/site-packages/tensorflow/python/framework/ops.py\", line 1043, in __init__\n    self._traceback = _extract_stack()\n```\n\nAs far as I understand, it should just place that single op on the CPU and everything else on the GPU.\n", "comments": ["This is a subtly different issue: as far as the placer is concerned MaxPool is defined to run on GPU, so it will be placed on a GPU device if available (using hard or soft placement). However, for certain input values (in this case, where the kernel size in the depth dimension is greater than 1) it will raise an error at runtime if the op tries to execute on GPU.\n\n**TL;DR:** For now it's necessary to annotate any depthwise max-pooling ops with a `with tf.device(\"/cpu:0\"):` block.\n", "Yes, this is more about an unsupported configuration of an op, not soft placement.  Retitling this.\n", "@vrv I looked into this issue, as far as I can tell adding a `DepthwiseMaxPool` [here](https://github.com/tensorflow/tensorflow/blob/master/third_party/eigen3/unsupported/Eigen/CXX11/src/NeuralNetworks/Pooling.h) will solve the issue. Am I on the right track?\n", "We have to remove those header files actually, we moved them into core/kernels/eigen_*\n\nBut yes, that's probably where you would have to implement it (thankfully, just once for both CPU and GPU).  I don't know if there's a way to get MaxPool for CuDNN to do depth-pooling, but if so, that should be part of this.\n", "@kerokeroloid, is this still an issue for you, or could I close this?\r\n", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 635, "title": "Fix small typo: python/training/moving_averages.py", "body": "Quick fix to typos in comments:\ntensorflow/python/training/moving_averages.py\n", "comments": []}, {"number": 634, "title": "AdamOptimizer + checkpoints", "body": "When using the AdamOptimizer, does the checkpoint save the state of the AdamOptimizer? If yes, how do you clear the state (i.e., restart the AdamOptimizer but keep the model weights from the checkpoint); if no, how do you maintain the Adam state. Question can be applied to AdaGrad as well.\n", "comments": ["This kind of question should be asked on stackoverflow, since it is not about a bug or feature request for tensorflow.  However, the answer is yes: the state of optimizers is stored in `tf.Variable` objects just like normal state, and these are saved to checkpoints.\n", "Can this be reopened as a feature request to create an API call to reset the state of an optimizer?\n\nThere doesn't seem to be a nice way to do it as far as I know. \n", "You could \"reset\" state of optimizer by creating new optimizer over the\nsame parameter variable\n\nOn Tue, Sep 20, 2016 at 10:23 PM, Steven Basart notifications@github.com\nwrote:\n\n> Can this be reopened as a feature request to create an API call to reset\n> the state of an optimizer?\n> \n> There doesn't seem to be a nice way to do it as far as I know.\n> \n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/634#issuecomment-248514658,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AABaHMt3mME5XOahc81xRZZbU8OqkbWqks5qsL9YgaJpZM4G7spa\n> .\n", "That seems more like a \"hack\" in the sense that when I save my new model now I'll need to find a way to find and exclude the old optimizer variables and only save the old variables except the old optimizer and new optimizer. This starts to break the code.    I was interested in experimenting with this technique [here](http://arxiv.org/abs/1608.03983) but other optimization schemes. However I don't see a nice way to do this once the model has been saved and I need to restart it.  \n\nUnless I'm misunderstanding how you intend to code it up?\n\nI was imagining I have my graph:\n\n```\ndef train():\n  with tf.Session() as sess:\n    inputs = get_inputs()\n    model_out = infer(inputs)\n    loss = (model_out, targets)\n    train_op = (loss)\n    saver = tf.train.Saver()\n    sess.run(tf.initialize_all_variables())\n    saver.restore(sess, checkpoint)\n```\n\nThat's the old model then I imagine the change your suggesting is to add the one below?\n\n```\n    .... (same as above)\n    saver.restore(sess, checkpoint)\n    train_op = (loss)\n    sess.run(tf.initialize_variables(tf.report_uninitialized_variables(tf.all_variables)))\n```\n", "You could also load checkpoint in a regular way, and then run initialize on all the variables you want to reset `sess.run([v.initialize for v in variables_to_reset])`\n", "@xksteven did that method work for you? simply overwriting the `train_op` variable after restoring the checkpoint?", "@dylanbfox \r\n\r\nIf you're using the tensorflow built in saver then if you \"reset\" the adam optimizer by simply creating a new adam optimizer then it will create an entire extra set of parameters for each variable in the graph while maintaining the old unused ones.  This process will not work as a long term solution as you're almost doubling the size of graph every time you reset it in this way.  \r\n\r\nIt is not a viable solution.  \r\n\r\nI honestly still don't have a good way to do this as one would need to iterate through all of the variables and reset all of the \"slot\" variables.  I do not know of a way that works to accomplish this.\r\n\r\nI would suggest keeping this issue open.", "To solve this problem, you need to simply pass a list of variables to restore to the Saver object. I had this problem before, and after experimenting, I have posted my finding on saving and restoring variables along with the code on a stack overflow post. Here is the link:\r\n\r\nhttps://stackoverflow.com/questions/48161147/error-restoring-model-in-tensorflow-after-changing-the-optimizer-paramter/48212514#48212514"]}, {"number": 633, "title": "tf.decode_csv works with \\n but not with \\r\\n for new lines", "body": "I copied the example for reading CSV files from [here](https://www.tensorflow.org/versions/master/how_tos/reading_data/index.html#reading-from-files) and used it with csv files that I generated (5 columns, comma seperated) which used **\\r\\n** as line breaks which resulted in the following error:\n\n> W tensorflow/core/common_runtime/executor.cc:1076] 0x1659ea0 Compute status: Invalid argument: Unquoted fields cannot have quotes/CRLFs inside\n\nUsing only **\\n** worked as expected. According to the [standard](https://tools.ietf.org/html/rfc4180#section-2) using **\\r\\n** is also valid.\n\nI'm using docker for windows and used the latest docker image, I haven't tried it on other machines.\n", "comments": ["Looks like the issue is in `TextLineReader`, which only recognizes `'\\n'` when splitting a text file into lines. I'll prepare a patch.\n", "Should be fixed at HEAD now.\n"]}, {"number": 632, "title": "Added info about how to run TensorBoard for the Deep CNN example.", "body": "The CIFAR tutorial talks a bit about the TensorBoard and I think it'd be nice if the command to run it was mentioned explicitly in the tutorial. Otherwise you have to look the documentation for the TensorBoard and open `cifar10_train.py` to see where the log files are being saved.\n", "comments": ["Thanks for the fast review! I've changed the command to `tensorboard` as you suggested. :)\n", "Sorry for the delay, can you update this to handle the conflicts?\n", "Can one of the admins verify this patch?\n", "Merged upstream and handled the conflicts.\n", "Sorry -- can you merge (again) and make sure to squash the commits into one?\n", "Closing since it looks like you've given up :(.  Feel free to ping this thread / rebase and we'll re-open and merge.\n"]}, {"number": 631, "title": "Provide sugar for insuring gradient computation of an op is put on the desired device", "body": "Currently, it is somewhat involved to insure that a set of ops are put on the desired device for both the forward and backward (gradient) computations. For example if I have a function that defines its own scope like:\n\n```\ndef my_op(inputs, name=None):\n    with tf.op_scope([inputs], name, 'my_op') as scope:\n        ...\n```\n\nSimply using the following code would not place its gradient calculations on the specified device:\n\n```\nwith tf.device('/gpu:0'):\n    my_op(...)\n```\n\nInstead, the only way I got the above to really work is to define a device function that not only checks the name of the op but also all incoming nodes (because TF adds a lot of additional operations that are not explicitly named under the scope), like this:\n\n```\ndef _device_function(op):\n    if ('my_op' in op.name) or any('my_op' in node.name for node in op.inputs):\n        return \"/gpu:0\"\n    else:\n        return None\n```\n\nThis is unnecessarily involved and may very well be error-prone. Something like a boolean `grad` option for `tf.device` so that the user can simply specify `tf.device(..., grad=True)` would be far cleaner.\n", "comments": ["@benoitsteiner , is this necessary with the new device placement optimizers? I'd like to close this if it is not needed anymore. @alquraishi, is this still an issue for you?\r\n", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?"]}, {"number": 630, "title": "ADB Install Instructions for Android Example (tiny fix)", "body": "The ADB installation command in the documentation for the Android app threw this error when I tried it:\n\n``` bash\n$ adb install -r -g bazel-bin/tensorflow/examples/android/tensorflow_demo.apk\n2918 KB/s (58599654 bytes in 19.605s)\nError: Unknown option: -g\n```\n\nThe option flags have to be supplied together for it to work:\n\n``` bash\n$ adb install -rg bazel-bin/tensorflow/examples/android/tensorflow_demo.apk\n```\n\nWhich resulted in successfully installing the app:\n\n``` bash\n$ adb install -rg bazel-bin/tensorflow/examples/android/tensorflow_demo.apk\n2683 KB/s (58599654 bytes in 21.322s)\n    pkg: /data/local/tmp/tensorflow_demo.apk\nSuccess\n```\n", "comments": ["The command is fine as-is, it just requires a recent version of adb -- I can verify that it works with ADB 1.0.32 Revision 09a0d98bebce-android (although it did not with another 1.0.32 adb binary). If you don't see \"-g\" listed as an install option when you type \"adb\" then you are not using a recent enough version.\n\nThis only seems to work here because adb ignores all but the first character after '-'. Additionally, \"-g\" should not be necessary unless you are using an Android 6.0 or higher device.\n\nIf you would like to to modify your PR to clarify the instructions please do so, otherwise I'll update them internally.\n", "Aha! Makes sense!\n\nCertainly. I'll modify it today. Thanks for clarifying.\n", "How does this sound?\n", "Should be good now\n"]}, {"number": 629, "title": "How to print or see the value of Tensor? ", "body": "Variable\nTensor\n...\n", "comments": ["This is a better question for stackoverflow: github is for issues with tensorflow that require code changes to fix.  However, the answer is `tf.Print`, or to use Tensorboard.\n", "How to get the value of variable?\r\nNo print or see."]}, {"number": 628, "title": "Bazel can't build anymore?", "body": "Was a BUILD file or something recently changed?\n\nThis works perfectly fine:\nbazel build -c opt --config=cuda //tensorflow/core:tensorflow --verbose_failures || exit 1\n\nThis fails (gets stuck):\nbazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures || exit 1\n\nand gets stuck on:\nbazel build --config=cuda //tensorflow/tools/pip_package:build_pip_package\nINFO: Reading 'startup' options from /home/wchan/.bazelrc: --install_base /dev/shm/wchan/bazel/install_base --output_base /dev/shm/wchan/bazel/output_base\nExtracting Bazel installation...\n......\nINFO: (12-26 18:02:26.076) Loading package: \n\nstuck on \"Loading package\", can't find anything in the logs. Tried the whole shebang of bazel clean and another server, doesn't work on different machines as well... any ideas?\n", "comments": ["This is not supposed to happen right?\n\nrm -rf /tmp/wchan\nbazel build -c opt --config=cuda //tensorflow/python:all\nINFO: Reading 'startup' options from /home/wchan/.bazelrc: --install_base /tmp/wchan/bazel/install_base --output_base /tmp/wchan/bazel/output_base\nExtracting Bazel installation...\n......\nINFO: (12-26 18:21:09.192) Found 236 targets...\nINFO: (12-26 18:21:11.017) From Executing genrule @six_archive//:copy_six:\nsrc/main/tools/namespace-sandbox.c:361: mkdir(\"tmp\", 0755): File exists\nERROR: (12-26 18:21:11.018) /tmp/wchan/bazel/output_base/external/six_archive/BUILD:1:1: Executing genrule @six_archive//:copy_six failed: bash failed: error executing command /bin/bash -c 'source tools/genrule/genrule-setup.sh; cp external/six_archive/six-1.10.0/six.py bazel-out/local_linux-opt/genfiles/external/six_archive/six.py'.\nINFO: (12-26 18:21:11.088) Elapsed time: 9.932s, Critical Path: 0.74s\n\n(confirmed I have python six installed btw).\n", "FYI, if I remove tensorboard out of the BUILD file, it builds fine again -- as soon as I add it back it, it gets stuck on the \"Loading package\", so Im guessing something must have changed in the last few days.\n", "wchan@, I was able to build successfully by following the \"Installing from sources\" instructions. This seems more like a Bazel issue than a TF issue. Make sure you have Bazel 0.1.1. Perhaps try a `bazel clean` and try building again.\n", "The latest supported version is 0.1.2, I think.  But yes, maybe file this bug with the bazel team.\n\n(If you want, you could try bisecting the git commits to see where this problem started happening).\n", "@wchan, did you find a solution to this, did it disappear, or is it still a problem? I've not been able to reproduce.\n", "I've experienced the same problem. I found that cleaning out the ~/.cache/bazel directory fixed it. I think this is an issue with the cache getting corrupted. I was using bazel version 0.1.5.\n", "@joshuastrock's advice solved my issue"]}, {"number": 627, "title": "Recommend to add search box in tensorflow API page", "body": "I think the user experience would be better if we could have a search box in tensor API webpage. \n", "comments": ["Agreed. Out of the box solutions require searchable things to live on\nseparate pages, which isn't the case for our docs right now. We'll have to\ndo some restructuring to make this work (well, a badly working search box\nis simple, but I'd rather do it right if I'm doing it at all). It's on our\nlist of todos. Thanks for the report!\nOn Sat, Dec 26, 2015 at 14:38 Jacob Israel notifications@github.com wrote:\n\n> I think the user experience would be better if we could have a search box\n> in tensor API webpage\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/627.\n", "@martinwicke: Should @xmbrst be assigned for this kind of doc bug?\n", "Yes, but this specific one will be made obsolete by our move to different infrastructure for tensorflow.org. We can leave it open and close it later, but nobody will work on this before the move happens.\n", "Reassigning for the honor of closing.\n", "+1 for this feature request. For now many search results of tensorflow doc in google are dead links."]}, {"number": 626, "title": "Cannot restore large model", "body": "I'm using tf.train.save.Saver to save my model parameters which come out to be ~1.5GB on disk. When I try to reload the model I get a segmentation fault (this is on a machine with 60GB memory). This also happens when using the option restore_sequentially=True. I found an option to shard the save, but it saves one file per device -- surprisingly there are two files, one is virtually nothing and the other is ~1.5GB for a CPU-only machine, so this didn't help. How can I save my model in such a way that I can get it back into memory?\n\nUpdate:\nI tried saving/loading a smaller model. Surprising the save came out to be ~2GB, which is a larger than the save file of the original model; and this 2GB file loaded fine when restoring the model. So perhaps my original model is really larger than 1.5GB and failed to save properly.\n", "comments": ["Oh no!  Looks like this bug got dropped through the cracks.  Regardless of whether the initial save was valid, the load should not segfault.  Do you still have code that can reproduce this problem?\n", "No worries! Actually, once I found the work-around, I just settled with the smaller model and made that work. I don't think I have the code or models lying around anymore. This was for a competition which has since ended I didn't think I needed those files anymore. Sorry about that!\n", "Alas!  Sorry we didn't get notice this earlier.  I think we're getting better at not dropping bugs, but there's still a ways to improve.\n"]}, {"number": 625, "title": "Update index.md", "body": "[Pro tutorial](https://www.tensorflow.org/versions/master/tutorials/mnist/pros/index.html) edit - Updating `import input_data` to full tensorflow path `from tensorflow.examples.tutorials.mnist import input_data`\n", "comments": []}, {"number": 624, "title": "Android Tensorflow demo crash", "body": "I tried the tensorflow demo for android and it looks really promising, but there is a big problem, every time I completely cover the camera my cellphone will horribly crash and reboot, which has never happened to me, I have never encountered an error in an application that will reboot my phone completely, so in order to take this into production I have to find the reason for this, and try to fix it, I hope someone here can provide some guidance or feedback as to why this is happening, it might be that the app is working too hard, but still it would be weird for the whole phone to crash, the scenario is like this, the app is working fine and then when I cover the camera with my finger it will recognize a nematode and immediately crash, any comments would be appreciated, I wonder if anybody else has run into this issue, my cellphone is a samsung galaxy s6 by the way.\n", "comments": ["Nematode is a common classification for very dark images by the default model, so that part is not surprising.\n\nIt definitely shouldn't be crashing your phone, however. What phone/Android version are you using? Could you try repeating this with \"adb logcat\" running on an attached computer and attach a log, please?\n\nAlso, if you modify https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/android/src/org/tensorflow/demo/TensorflowImageListener.java#L41, you can set it to save the bitmaps it's actually sending to the classifier (it overwrites so only the last image is ever saved). It could be helpful to see this image as well to diagnose the problem.\n", "Just to note, it's actually already set to save preview bitmaps (but probably shouldn't be). This means that currently you don't need to do anything other than \"adb pull /sdcard/data/data/saved_images/preview.png\" to grab the latest classified preview image.\n", "Hey thanks for the reply, I'm running android 5.0.2 on a samsung galaxy s6, the last image saved by the demo app is a completely black 224x224 png image, and here I attached the last part of the log from my cellphone, I included all the logs but the last 2 lines coming from the tensorflow demo are this:\n12-29 13:09:42.086 13566-13609/org.tensorflow.demo I/native: tensorflow/examples/android/jni/tensorflow_jni.cc:222 Predictions: \n12-29 13:09:42.086 13566-13609/org.tensorflow.demo I/TensorflowClassifier: Parsing []\n\nan empty predictions array which it tries to parse, maybe because it is running in native code the exception doesn\u2019t get caught and crashes? anyway here is the rest of he log\n\n12-29 13:09:41.546 13566-13609/org.tensorflow.demo I/native: tensorflow/examples/android/jni/tensorflow_jni.cc:188 End computing.\n12-29 13:09:41.546 13566-13609/org.tensorflow.demo I/native: tensorflow/examples/android/jni/tensorflow_jni.cc:195 Reading from layer output:0\n12-29 13:09:41.546 13566-13609/org.tensorflow.demo I/native: tensorflow/examples/android/jni/tensorflow_jni.cc:222 Predictions: 984 0.101 matchstick\n12-29 13:09:41.546 13566-13609/org.tensorflow.demo I/TensorflowClassifier: Parsing [984 0.101 matchstick]\n12-29 13:09:41.546 13566-13609/org.tensorflow.demo D/gralloc: gralloc_lock_ycbcr success. usage: 3, ycbcr.y: 0xddc8e000, .cb: 0xddcb3801, .cr: 0xddcb3800, .ystride: 480 , .cstride: 480, .chroma_step: 2\n12-29 13:09:41.546 13566-13609/org.tensorflow.demo D/gralloc: gralloc_lock_ycbcr success. usage: 3, ycbcr.y: 0xddc55000, .cb: 0xddc7a801, .cr: 0xddc7a800, .ystride: 480 , .cstride: 480, .chroma_step: 2\n12-29 13:09:41.556 13566-13609/org.tensorflow.demo D/gralloc: gralloc_lock_ycbcr success. usage: 3, ycbcr.y: 0xf3ec3000, .cb: 0xf3ee8801, .cr: 0xf3ee8800, .ystride: 480 , .cstride: 480, .chroma_step: 2\n12-29 13:09:41.566 13566-13609/org.tensorflow.demo I/tensorflow: ImageUtils: Saving 224x224 bitmap to /storage/emulated/0/tensorflow.\n12-29 13:09:41.566 13566-13609/org.tensorflow.demo I/tensorflow: ImageUtils: Make dir failed\n12-29 13:09:41.576 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:35)\n12-29 13:09:41.596 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:41.606 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:41.616 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:41.616 13566-13609/org.tensorflow.demo I/native: tensorflow/examples/android/jni/tensorflow_jni.cc:251 Height: 224\n12-29 13:09:41.616 13566-13609/org.tensorflow.demo I/native: tensorflow/examples/android/jni/tensorflow_jni.cc:252 Width: 224\n12-29 13:09:41.616 13566-13609/org.tensorflow.demo I/native: tensorflow/examples/android/jni/tensorflow_jni.cc:253 Stride: 896\n12-29 13:09:41.616 13566-13609/org.tensorflow.demo I/native: tensorflow/examples/android/jni/tensorflow_jni.cc:164 Tensorflow: Copying Data.\n12-29 13:09:41.616 13566-13609/org.tensorflow.demo I/native: tensorflow/examples/android/jni/tensorflow_jni.cc:182 Start computing.\n12-29 13:09:41.636 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:34)\n12-29 13:09:41.646 2971-13863/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_putBuffer[1332]):inputFrameQ wait timeout\n12-29 13:09:41.646 2971-13863/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_putBufferThreadFunc[1288]):m_putbuffer fail, ret(-110)\n12-29 13:09:41.656 2971-13864/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_getBuffer[1636]):requestFrameQ wait timeout\n12-29 13:09:41.656 2971-13864/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_getBufferThreadFunc[1304]):m_getBuffer fail, ret(-110)\n12-29 13:09:41.696 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:33)\n12-29 13:09:41.716 2971-13861/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_3AA]-WARN(m_putBuffer[1332]):inputFrameQ wait timeout\n12-29 13:09:41.716 2971-13861/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_3AA]-WARN(m_putBufferThreadFunc[1288]):m_putbuffer fail, ret(-110)\n12-29 13:09:41.746 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:41.756 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:41.756 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:32)\n12-29 13:09:41.766 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:41.796 3996-3996/? D/StatusBar.NetworkController: refreshViews connected={ wifi } level=4 combinedSignalIconId=0x7f02054e/com.android.systemui:drawable/stat_sys_wifi_signal_4 mobileLabel=TW Mobile wifiLabel=\"Y155413\" emergencyOnly=false combinedLabel=\"Y155413\" mAirplaneMode=false mDataActivity=0 mPhoneSignalIconId=0x7f0204e5/com.android.systemui:drawable/stat_sys_signal_4_auto_rotate mQSPhoneSignalIconId=0x7f020123/com.android.systemui:drawable/ic_qs_signal_4 mDataDirectionIconId=0x0/(null) mDataSignalIconId=0x7f0204e5/com.android.systemui:drawable/stat_sys_signal_4_auto_rotate mDataTypeIconId=0x7f020327/com.android.systemui:drawable/stat_sys_data_connected_4g mQSDataTypeIconId=0x0/(null) mNoSimIconId=0x0/(null) mWifiIconId=0x7f02054e/com.android.systemui:drawable/stat_sys_wifi_signal_4 mQSWifiIconId=0x7f020139/com.android.systemui:drawable/ic_qs_wifi_4 mWifiActivityIconId=0x7f02051b/com.android.systemui:drawable/stat_sys_signal_no_inout mBluetoothTetherIconId=0x7f02052b/com.android.systemui:drawable/stat_sys_tether_bluetooth\n12-29 13:09:41.796 3996-3996/? D/STATUSBAR-WifiQuickSettingButton: onWifiSignalChanged enabled=true enabledDesc:\"Y155413\"\n12-29 13:09:41.796 3996-3996/? D/StatusBar.NetworkController: refreshNwBoosterIndicator - setNWBoosterIndicators(false)\n12-29 13:09:41.796 3996-3996/? D/StatusBar.NetworkController: refreshNwBoosterIndicator - setNWBoosterIndicators(false)\n12-29 13:09:41.806 3996-3996/? D/StatusBar.NetworkController: refreshNwBoosterIndicator - setNWBoosterIndicators(false)\n12-29 13:09:41.806 3996-3996/? D/StatusBar.NetworkController: refreshNwBoosterIndicator - setNWBoosterIndicators(false)\n12-29 13:09:41.816 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:31)\n12-29 13:09:41.876 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:30)\n12-29 13:09:41.896 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:41.906 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:41.916 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:41.936 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:29)\n12-29 13:09:41.996 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:28)\n12-29 13:09:42.046 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:42.056 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:42.056 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:27)\n12-29 13:09:42.066 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:42.086 13566-13609/org.tensorflow.demo I/native: tensorflow/examples/android/jni/tensorflow_jni.cc:188 End computing.\n12-29 13:09:42.086 13566-13609/org.tensorflow.demo I/native: tensorflow/examples/android/jni/tensorflow_jni.cc:195 Reading from layer output:0\n12-29 13:09:42.086 13566-13609/org.tensorflow.demo I/native: tensorflow/examples/android/jni/tensorflow_jni.cc:222 Predictions: \n12-29 13:09:42.086 13566-13609/org.tensorflow.demo I/TensorflowClassifier: Parsing []\n12-29 13:09:42.116 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:26)\n12-29 13:09:42.146 2971-13863/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_putBuffer[1332]):inputFrameQ wait timeout\n12-29 13:09:42.146 2971-13863/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_putBufferThreadFunc[1288]):m_putbuffer fail, ret(-110)\n12-29 13:09:42.156 2971-13864/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_getBuffer[1636]):requestFrameQ wait timeout\n12-29 13:09:42.156 2971-13864/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_getBufferThreadFunc[1304]):m_getBuffer fail, ret(-110)\n12-29 13:09:42.176 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:25)\n12-29 13:09:42.196 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:42.206 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:42.216 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:42.216 2971-13861/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_3AA]-WARN(m_putBuffer[1332]):inputFrameQ wait timeout\n12-29 13:09:42.216 2971-13861/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_3AA]-WARN(m_putBufferThreadFunc[1288]):m_putbuffer fail, ret(-110)\n12-29 13:09:42.246 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:24)\n12-29 13:09:42.306 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:23)\n12-29 13:09:42.346 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:42.356 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:42.366 16494-16494/? E/SMD: smd Interface open failed errno is 2 -1\n12-29 13:09:42.366 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:22)\n12-29 13:09:42.366 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:42.426 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:21)\n12-29 13:09:42.486 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:20)\n12-29 13:09:42.496 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:42.506 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:42.516 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:42.546 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:19)\n12-29 13:09:42.576 3938-3938/? I/wpa_supplicant: set true handover condition [-52 dBm], wpa_s->handover_scan_cnt[1]\n12-29 13:09:42.576 3938-3938/? I/wpa_supplicant: wlan0: Setting scan request: 0 sec 0 usec\n12-29 13:09:42.576 3938-3938/? I/wpa_supplicant: P2P: Current p2p state = IDLE\n12-29 13:09:42.586 3938-3938/? I/wpa_supplicant: Scan requested (ret=0) - scan timeout 30 seconds\n12-29 13:09:42.606 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:18)\n12-29 13:09:42.646 2971-13863/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_putBuffer[1332]):inputFrameQ wait timeout\n12-29 13:09:42.646 2971-13863/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_putBufferThreadFunc[1288]):m_putbuffer fail, ret(-110)\n12-29 13:09:42.646 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:42.656 2971-13864/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_getBuffer[1636]):requestFrameQ wait timeout\n12-29 13:09:42.656 2971-13864/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_getBufferThreadFunc[1304]):m_getBuffer fail, ret(-110)\n12-29 13:09:42.656 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:42.666 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:42.666 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:17)\n12-29 13:09:42.716 2971-13861/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_3AA]-WARN(m_putBuffer[1332]):inputFrameQ wait timeout\n12-29 13:09:42.716 2971-13861/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_3AA]-WARN(m_putBufferThreadFunc[1288]):m_putbuffer fail, ret(-110)\n12-29 13:09:42.726 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:16)\n12-29 13:09:42.786 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:15)\n12-29 13:09:42.796 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:42.806 3996-3996/? D/StatusBar.NetworkController: refreshViews connected={ wifi } level=4 combinedSignalIconId=0x7f02054e/com.android.systemui:drawable/stat_sys_wifi_signal_4 mobileLabel=TW Mobile wifiLabel=\"Y155413\" emergencyOnly=false combinedLabel=\"Y155413\" mAirplaneMode=false mDataActivity=0 mPhoneSignalIconId=0x7f0204e5/com.android.systemui:drawable/stat_sys_signal_4_auto_rotate mQSPhoneSignalIconId=0x7f020123/com.android.systemui:drawable/ic_qs_signal_4 mDataDirectionIconId=0x0/(null) mDataSignalIconId=0x7f0204e5/com.android.systemui:drawable/stat_sys_signal_4_auto_rotate mDataTypeIconId=0x7f020327/com.android.systemui:drawable/stat_sys_data_connected_4g mQSDataTypeIconId=0x0/(null) mNoSimIconId=0x0/(null) mWifiIconId=0x7f02054e/com.android.systemui:drawable/stat_sys_wifi_signal_4 mQSWifiIconId=0x7f020139/com.android.systemui:drawable/ic_qs_wifi_4 mWifiActivityIconId=0x7f020516/com.android.systemui:drawable/stat_sys_signal_in mBluetoothTetherIconId=0x7f02052b/com.android.systemui:drawable/stat_sys_tether_bluetooth\n12-29 13:09:42.806 3996-3996/? D/STATUSBAR-WifiQuickSettingButton: onWifiSignalChanged enabled=true enabledDesc:\"Y155413\"\n12-29 13:09:42.806 3996-3996/? D/StatusBar.NetworkController: refreshNwBoosterIndicator - setNWBoosterIndicators(false)\n12-29 13:09:42.806 3996-3996/? D/StatusBar.NetworkController: refreshNwBoosterIndicator - setNWBoosterIndicators(false)\n12-29 13:09:42.806 3996-3996/? D/StatusBar.NetworkController: refreshNwBoosterIndicator - setNWBoosterIndicators(false)\n12-29 13:09:42.806 3996-3996/? D/StatusBar.NetworkController: refreshNwBoosterIndicator - setNWBoosterIndicators(false)\n12-29 13:09:42.806 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:42.816 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:42.846 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:14)\n12-29 13:09:42.906 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:13)\n12-29 13:09:42.946 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:42.956 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:42.966 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:42.966 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:12)\n12-29 13:09:43.026 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:11)\n12-29 13:09:43.086 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:10)\n12-29 13:09:43.096 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:43.106 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:43.116 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:43.146 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:9)\n12-29 13:09:43.146 2971-13863/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_putBuffer[1332]):inputFrameQ wait timeout\n12-29 13:09:43.146 2971-13863/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_putBufferThreadFunc[1288]):m_putbuffer fail, ret(-110)\n12-29 13:09:43.156 2971-13864/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_getBuffer[1636]):requestFrameQ wait timeout\n12-29 13:09:43.156 2971-13864/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_getBufferThreadFunc[1304]):m_getBuffer fail, ret(-110)\n12-29 13:09:43.206 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:8)\n12-29 13:09:43.216 2971-13861/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_3AA]-WARN(m_putBuffer[1332]):inputFrameQ wait timeout\n12-29 13:09:43.216 2971-13861/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_3AA]-WARN(m_putBufferThreadFunc[1288]):m_putbuffer fail, ret(-110)\n12-29 13:09:43.246 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:43.256 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:43.266 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:43.266 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:7)\n12-29 13:09:43.326 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:6)\n12-29 13:09:43.366 16494-16494/? E/SMD: smd Interface open failed errno is 2 -1\n12-29 13:09:43.386 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:5)\n12-29 13:09:43.396 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:43.406 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:43.416 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:43.446 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:4)\n12-29 13:09:43.506 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:3)\n12-29 13:09:43.546 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:43.556 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:43.566 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:43.566 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:2)\n12-29 13:09:43.626 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:5 / totalRequestCnt:5 / blockReqCount = min:4, max:9 / waitcnt:1)\n12-29 13:09:43.646 2971-13863/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_putBuffer[1332]):inputFrameQ wait timeout\n12-29 13:09:43.646 2971-13863/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_putBufferThreadFunc[1288]):m_putbuffer fail, ret(-110)\n12-29 13:09:43.656 2971-13864/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_getBuffer[1636]):requestFrameQ wait timeout\n12-29 13:09:43.656 2971-13864/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_getBufferThreadFunc[1304]):m_getBuffer fail, ret(-110)\n12-29 13:09:43.686 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:40)\n12-29 13:09:43.696 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:43.706 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:43.716 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:43.726 3996-3996/? D/StatusBar.NetworkController: onSignalStrengthsChanged signalStrength=SignalStrength: 99 99 -120 -160 -120 -1 -1 29 -88 -10 228 -1 2147483647 0x4000 gsm|lte level=4\n12-29 13:09:43.726 3996-3996/? D/StatusBar.NetworkController: updateTelephonySignalStrength: hasService=true ss=SignalStrength: 99 99 -120 -160 -120 -1 -1 29 -88 -10 228 -1 2147483647 0x4000 gsm|lte\n12-29 13:09:43.726 3996-3996/? D/StatusBar.NetworkController: updateTelephonySignalStrength: iconLevel=4\n12-29 13:09:43.726 3996-3996/? D/StatusBar.NetworkController: updateTelephonySignalStrength, No signal level. mPhoneSignalIconId = com.android.systemui:drawable/stat_sys_signal_4_auto_rotate mDataSignalIconId = com.android.systemui:drawable/stat_sys_signal_4_auto_rotate mQSPhoneSignalIconId = com.android.systemui:drawable/ic_qs_signal_4 mContentDescriptionPhoneSignal = Full phone signal\n12-29 13:09:43.726 3996-3996/? D/StatusBar.NetworkController: refreshViews connected={ wifi } level=4 combinedSignalIconId=0x7f02054e/com.android.systemui:drawable/stat_sys_wifi_signal_4 mobileLabel=TW Mobile wifiLabel=\"Y155413\" emergencyOnly=false combinedLabel=\"Y155413\" mAirplaneMode=false mDataActivity=0 mPhoneSignalIconId=0x7f0204e5/com.android.systemui:drawable/stat_sys_signal_4_auto_rotate mQSPhoneSignalIconId=0x7f020123/com.android.systemui:drawable/ic_qs_signal_4 mDataDirectionIconId=0x0/(null) mDataSignalIconId=0x7f0204e5/com.android.systemui:drawable/stat_sys_signal_4_auto_rotate mDataTypeIconId=0x7f020327/com.android.systemui:drawable/stat_sys_data_connected_4g mQSDataTypeIconId=0x0/(null) mNoSimIconId=0x0/(null) mWifiIconId=0x7f02054e/com.android.systemui:drawable/stat_sys_wifi_signal_4 mQSWifiIconId=0x7f020139/com.android.systemui:drawable/ic_qs_wifi_4 mWifiActivityIconId=0x7f020516/com.android.systemui:drawable/stat_sys_signal_in mBluetoothTetherIconId=0x7f02052b/com.android.systemui:drawable/stat_sys_tether_bluetooth\n12-29 13:09:43.726 3996-3996/? D/STATUSBAR-WifiQuickSettingButton: onWifiSignalChanged enabled=true enabledDesc:\"Y155413\"\n12-29 13:09:43.726 3996-3996/? D/StatusBar.NetworkController: refreshNwBoosterIndicator - setNWBoosterIndicators(false)\n12-29 13:09:43.726 3996-3996/? D/StatusBar.NetworkController: refreshNwBoosterIndicator - setNWBoosterIndicators(false)\n12-29 13:09:43.726 3996-3996/? D/StatusBar.NetworkController: refreshNwBoosterIndicator - setNWBoosterIndicators(false)\n12-29 13:09:43.726 3996-3996/? D/StatusBar.NetworkController: refreshNwBoosterIndicator - setNWBoosterIndicators(false)\n12-29 13:09:43.746 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:39)\n12-29 13:09:43.806 3996-3996/? D/StatusBar.NetworkController: refreshViews connected={ wifi } level=4 combinedSignalIconId=0x7f02054e/com.android.systemui:drawable/stat_sys_wifi_signal_4 mobileLabel=TW Mobile wifiLabel=\"Y155413\" emergencyOnly=false combinedLabel=\"Y155413\" mAirplaneMode=false mDataActivity=0 mPhoneSignalIconId=0x7f0204e5/com.android.systemui:drawable/stat_sys_signal_4_auto_rotate mQSPhoneSignalIconId=0x7f020123/com.android.systemui:drawable/ic_qs_signal_4 mDataDirectionIconId=0x0/(null) mDataSignalIconId=0x7f0204e5/com.android.systemui:drawable/stat_sys_signal_4_auto_rotate mDataTypeIconId=0x7f020327/com.android.systemui:drawable/stat_sys_data_connected_4g mQSDataTypeIconId=0x0/(null) mNoSimIconId=0x0/(null) mWifiIconId=0x7f02054e/com.android.systemui:drawable/stat_sys_wifi_signal_4 mQSWifiIconId=0x7f020139/com.android.systemui:drawable/ic_qs_wifi_4 mWifiActivityIconId=0x7f02051b/com.android.systemui:drawable/stat_sys_signal_no_inout mBluetoothTetherIconId=0x7f02052b/com.android.systemui:drawable/stat_sys_tether_bluetooth\n12-29 13:09:43.806 3996-3996/? D/STATUSBAR-WifiQuickSettingButton: onWifiSignalChanged enabled=true enabledDesc:\"Y155413\"\n12-29 13:09:43.806 3996-3996/? D/StatusBar.NetworkController: refreshNwBoosterIndicator - setNWBoosterIndicators(false)\n12-29 13:09:43.806 3996-3996/? D/StatusBar.NetworkController: refreshNwBoosterIndicator - setNWBoosterIndicators(false)\n12-29 13:09:43.806 3996-3996/? D/StatusBar.NetworkController: refreshNwBoosterIndicator - setNWBoosterIndicators(false)\n12-29 13:09:43.806 3996-3996/? D/StatusBar.NetworkController: refreshNwBoosterIndicator - setNWBoosterIndicators(false)\n12-29 13:09:43.806 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:38)\n12-29 13:09:43.846 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:43.856 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:43.866 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:43.876 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:37)\n12-29 13:09:43.936 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:36)\n12-29 13:09:43.996 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:35)\n12-29 13:09:43.996 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:44.006 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:44.016 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:44.056 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:34)\n12-29 13:09:44.066 3522-3691/? I/ActivityManager: Waited long enough for: ServiceRecord{152586a8 u0 com.samsung.android.MtpApplication/.MtpService}\n12-29 13:09:44.116 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:33)\n12-29 13:09:44.126 2971-13861/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_3AA]-WARN(m_putBuffer[1332]):inputFrameQ wait timeout\n12-29 13:09:44.126 2971-13861/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_3AA]-WARN(m_putBufferThreadFunc[1288]):m_putbuffer fail, ret(-110)\n12-29 13:09:44.146 2971-13863/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_putBuffer[1332]):inputFrameQ wait timeout\n12-29 13:09:44.146 2971-13863/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_putBufferThreadFunc[1288]):m_putbuffer fail, ret(-110)\n12-29 13:09:44.156 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:44.156 2971-13864/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_getBuffer[1636]):requestFrameQ wait timeout\n12-29 13:09:44.156 2971-13864/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_getBufferThreadFunc[1304]):m_getBuffer fail, ret(-110)\n12-29 13:09:44.156 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:44.166 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:44.176 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:32)\n12-29 13:09:44.236 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:31)\n12-29 13:09:44.296 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:30)\n12-29 13:09:44.306 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:44.316 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:44.316 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:44.356 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:29)\n12-29 13:09:44.366 16494-16494/? E/SMD: smd Interface open failed errno is 2 -1\n12-29 13:09:44.416 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:28)\n12-29 13:09:44.456 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:44.466 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:44.466 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:44.476 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:27)\n12-29 13:09:44.526 3522-4714/? D/BatteryService: !@BatteryListener : batteryPropertiesChanged!\n12-29 13:09:44.526 3522-4714/? D/BatteryService: level:98, scale:100, status:2, health:2, present:true, voltage: 4015, temperature: 287, technology: Li-ion, AC powered:false, USB powered:true, POGO powered:false, Wireless powered:false, icon:17303396, invalid charger:0\n12-29 13:09:44.526 3522-4714/? D/BatteryService: online:4, current avg:-882, charge type:2, power sharing:false, high voltage charger:false, capacity:280000, current_now:-432\n12-29 13:09:44.526 3522-3522/? D/BatteryService: Sending ACTION_BATTERY_CHANGED.\n12-29 13:09:44.536 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:26)\n12-29 13:09:44.536 3522-3522/? I/MotionRecognitionService: Plugged\n12-29 13:09:44.536 3522-3522/? I/MotionRecognitionService: mGripSensorEnabled= false\n12-29 13:09:44.536 3996-3996/? D/KeyguardUpdateMonitor: received broadcast android.intent.action.BATTERY_CHANGED\n12-29 13:09:44.536 3996-3996/? D/KeyguardUpdateMonitor: handleBatteryUpdate\n12-29 13:09:44.546 4355-4355/? V/EmergencyMode: [EmergencyStateReceiver] onReceive : android.intent.action.BATTERY_CHANGED\n12-29 13:09:44.546 4355-4355/? V/EmergencyMode: [EmergencyStateReceiver] ACTION_BATTERY_CHANGED mBatteryLevelForLogging = 98\n12-29 13:09:44.546 3996-3996/? D/PowerUI.Notification: showChargingNotice chargingType : 1 oldChargingTime : 1794000 mChargingTime : 1819000\n12-29 13:09:44.556 3522-4322/? D/ApplicationPolicy: isStatusBarNotificationAllowedAsUser: packageName = com.android.systemui,userId = -2\n12-29 13:09:44.556 3522-4322/? V/ApplicationPolicy: isApplicationStateBlocked userId -2 pkgname com.android.systemui\n12-29 13:09:44.566 3996-3996/? D/QSTile.TorchLightTile: ACTION_BATTERY_CHANGED - Level :: 98, Status :: 2\n12-29 13:09:44.566 3996-3996/? D/BatteryMeterView: ACTION_BATTERY_CHANGED : level:98 status:2 health:2\n12-29 13:09:44.566 3996-3996/? D/BatteryMeterView: ACTION_BATTERY_CHANGED : level:98 status:2 health:2\n12-29 13:09:44.566 3996-3996/? D/BatteryMeterView: ACTION_BATTERY_CHANGED : level:98 status:2 health:2\n12-29 13:09:44.566 3996-4010/? D/LoadedApk: getResources for android.app.ActivityThread@19681ada forcing ? false needsResourceUpdate ?false\n12-29 13:09:44.566 3996-4749/? D/LoadedApk: getResources for android.app.ActivityThread@19681ada forcing ? false needsResourceUpdate ?false\n12-29 13:09:44.576 3996-3996/? D/StatusBar: ----- contentsUnchanged : true, bigContentsUnchanged - true, headsUpContentsUnchanged - true , publicUnchanged true\n12-29 13:09:44.576 3996-3996/? D/NotificationContentView: AH:256, SH:256\n12-29 13:09:44.576 3996-3996/? D/NotificationContentView: AH:256, SH:256\n12-29 13:09:44.576 3996-3996/? D/PersonaManager: isKioskContainerExistOnDevice\n12-29 13:09:44.576 3996-3996/? D/PersonaManager: isKioskContainerExistOnDevice\n12-29 13:09:44.586 3996-3996/? D/PanelView: There is/are notification(s) \n12-29 13:09:44.586 3996-3996/? D/PanelView: kidsfalse mQsExpansionEnabled:true\n12-29 13:09:44.586 3996-3996/? D/PersonaManager: isKioskContainerExistOnDevice\n12-29 13:09:44.586 3996-3996/? D/PanelView: There is/are notification(s) \n12-29 13:09:44.586 3996-3996/? D/PanelView: kidsfalse mQsExpansionEnabled:true\n12-29 13:09:44.596 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:25)\n12-29 13:09:44.606 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:44.616 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:44.616 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:44.626 2971-13861/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_3AA]-WARN(m_putBuffer[1332]):inputFrameQ wait timeout\n12-29 13:09:44.626 2971-13861/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_3AA]-WARN(m_putBufferThreadFunc[1288]):m_putbuffer fail, ret(-110)\n12-29 13:09:44.646 2971-13863/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_putBuffer[1332]):inputFrameQ wait timeout\n12-29 13:09:44.646 2971-13863/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_putBufferThreadFunc[1288]):m_putbuffer fail, ret(-110)\n12-29 13:09:44.656 3996-3996/? D/PanelView: mClearAll.setVisibility - mIsFullyOpened : false isShade : true mHasNotification : true mIsUpwardFling : false mQsFullyExpanded : false isShadeLocked : false mClearAllVisible : true\n12-29 13:09:44.656 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:24)\n12-29 13:09:44.656 2971-13864/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_getBuffer[1636]):requestFrameQ wait timeout\n12-29 13:09:44.656 2971-13864/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_getBufferThreadFunc[1304]):m_getBuffer fail, ret(-110)\n12-29 13:09:44.676 3522-6996/? D/SSRM:n: SIOP:: AP = 530, PST = 496, CP = 291, CUR = -882\n12-29 13:09:44.716 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:23)\n12-29 13:09:44.756 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:44.766 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:44.766 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:44.776 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:22)\n12-29 13:09:44.806 3996-3996/? D/StatusBar.NetworkController: refreshViews connected={ wifi } level=4 combinedSignalIconId=0x7f02054e/com.android.systemui:drawable/stat_sys_wifi_signal_4 mobileLabel=TW Mobile wifiLabel=\"Y155413\" emergencyOnly=false combinedLabel=\"Y155413\" mAirplaneMode=false mDataActivity=0 mPhoneSignalIconId=0x7f0204e5/com.android.systemui:drawable/stat_sys_signal_4_auto_rotate mQSPhoneSignalIconId=0x7f020123/com.android.systemui:drawable/ic_qs_signal_4 mDataDirectionIconId=0x0/(null) mDataSignalIconId=0x7f0204e5/com.android.systemui:drawable/stat_sys_signal_4_auto_rotate mDataTypeIconId=0x7f020327/com.android.systemui:drawable/stat_sys_data_connected_4g mQSDataTypeIconId=0x0/(null) mNoSimIconId=0x0/(null) mWifiIconId=0x7f02054e/com.android.systemui:drawable/stat_sys_wifi_signal_4 mQSWifiIconId=0x7f020139/com.android.systemui:drawable/ic_qs_wifi_4 mWifiActivityIconId=0x7f020516/com.android.systemui:drawable/stat_sys_signal_in mBluetoothTetherIconId=0x7f02052b/com.android.systemui:drawable/stat_sys_tether_bluetooth\n12-29 13:09:44.806 3996-3996/? D/STATUSBAR-WifiQuickSettingButton: onWifiSignalChanged enabled=true enabledDesc:\"Y155413\"\n12-29 13:09:44.816 3996-3996/? D/StatusBar.NetworkController: refreshNwBoosterIndicator - setNWBoosterIndicators(false)\n12-29 13:09:44.816 3996-3996/? D/StatusBar.NetworkController: refreshNwBoosterIndicator - setNWBoosterIndicators(false)\n12-29 13:09:44.816 3996-3996/? D/StatusBar.NetworkController: refreshNwBoosterIndicator - setNWBoosterIndicators(false)\n12-29 13:09:44.816 3996-3996/? D/StatusBar.NetworkController: refreshNwBoosterIndicator - setNWBoosterIndicators(false)\n12-29 13:09:44.836 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:21)\n12-29 13:09:44.896 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:20)\n12-29 13:09:44.906 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:44.906 3996-3996/? D/StatusBar.NetworkController: onSignalStrengthsChanged signalStrength=SignalStrength: 99 99 -120 -160 -120 -1 -1 29 -88 -10 174 -1 2147483647 0x4000 gsm|lte level=4\n12-29 13:09:44.906 3996-3996/? D/StatusBar.NetworkController: updateTelephonySignalStrength: hasService=true ss=SignalStrength: 99 99 -120 -160 -120 -1 -1 29 -88 -10 174 -1 2147483647 0x4000 gsm|lte\n12-29 13:09:44.906 3996-3996/? D/StatusBar.NetworkController: updateTelephonySignalStrength: iconLevel=4\n12-29 13:09:44.906 3996-3996/? D/StatusBar.NetworkController: updateTelephonySignalStrength, No signal level. mPhoneSignalIconId = com.android.systemui:drawable/stat_sys_signal_4_auto_rotate mDataSignalIconId = com.android.systemui:drawable/stat_sys_signal_4_auto_rotate mQSPhoneSignalIconId = com.android.systemui:drawable/ic_qs_signal_4 mContentDescriptionPhoneSignal = Full phone signal\n12-29 13:09:44.906 3996-3996/? D/StatusBar.NetworkController: refreshViews connected={ wifi } level=4 combinedSignalIconId=0x7f02054e/com.android.systemui:drawable/stat_sys_wifi_signal_4 mobileLabel=TW Mobile wifiLabel=\"Y155413\" emergencyOnly=false combinedLabel=\"Y155413\" mAirplaneMode=false mDataActivity=0 mPhoneSignalIconId=0x7f0204e5/com.android.systemui:drawable/stat_sys_signal_4_auto_rotate mQSPhoneSignalIconId=0x7f020123/com.android.systemui:drawable/ic_qs_signal_4 mDataDirectionIconId=0x0/(null) mDataSignalIconId=0x7f0204e5/com.android.systemui:drawable/stat_sys_signal_4_auto_rotate mDataTypeIconId=0x7f020327/com.android.systemui:drawable/stat_sys_data_connected_4g mQSDataTypeIconId=0x0/(null) mNoSimIconId=0x0/(null) mWifiIconId=0x7f02054e/com.android.systemui:drawable/stat_sys_wifi_signal_4 mQSWifiIconId=0x7f020139/com.android.systemui:drawable/ic_qs_wifi_4 mWifiActivityIconId=0x7f020516/com.android.systemui:drawable/stat_sys_signal_in mBluetoothTetherIconId=0x7f02052b/com.android.systemui:drawable/stat_sys_tether_bluetooth\n12-29 13:09:44.906 3996-3996/? D/STATUSBAR-WifiQuickSettingButton: onWifiSignalChanged enabled=true enabledDesc:\"Y155413\"\n12-29 13:09:44.906 3996-3996/? D/StatusBar.NetworkController: refreshNwBoosterIndicator - setNWBoosterIndicators(false)\n12-29 13:09:44.906 3996-3996/? D/StatusBar.NetworkController: refreshNwBoosterIndicator - setNWBoosterIndicators(false)\n12-29 13:09:44.906 3996-3996/? D/StatusBar.NetworkController: refreshNwBoosterIndicator - setNWBoosterIndicators(false)\n12-29 13:09:44.906 3996-3996/? D/StatusBar.NetworkController: refreshNwBoosterIndicator - setNWBoosterIndicators(false)\n12-29 13:09:44.916 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:44.916 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:44.956 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:19)\n12-29 13:09:45.016 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:18)\n12-29 13:09:45.056 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:45.066 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:45.066 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:45.076 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:17)\n12-29 13:09:45.136 2971-13861/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_3AA]-WARN(m_putBuffer[1332]):inputFrameQ wait timeout\n12-29 13:09:45.136 2971-13861/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_3AA]-WARN(m_putBufferThreadFunc[1288]):m_putbuffer fail, ret(-110)\n12-29 13:09:45.136 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:16)\n12-29 13:09:45.146 2971-13863/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_putBuffer[1332]):inputFrameQ wait timeout\n12-29 13:09:45.146 2971-13863/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_putBufferThreadFunc[1288]):m_putbuffer fail, ret(-110)\n12-29 13:09:45.156 2971-13864/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_getBuffer[1636]):requestFrameQ wait timeout\n12-29 13:09:45.156 2971-13864/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_getBufferThreadFunc[1304]):m_getBuffer fail, ret(-110)\n12-29 13:09:45.196 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:15)\n12-29 13:09:45.206 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:45.216 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:45.216 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:45.256 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:14)\n12-29 13:09:45.316 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:13)\n12-29 13:09:45.356 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:45.366 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:45.366 16494-16494/? E/SMD: smd Interface open failed errno is 2 -1\n12-29 13:09:45.366 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:45.376 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:12)\n12-29 13:09:45.436 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:11)\n12-29 13:09:45.496 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:10)\n12-29 13:09:45.496 2971-13868/? E/ExynosCamera3: [CAM_ID(0)][]-[m_monitorThreadFunc](7716) (0)\n12-29 13:09:45.496 2971-13868/? E/ExynosCamera3: [CAM_ID(0)][]-[m_monitorThreadFunc](7718) ERROR_DQ_BLOCKED) ; ERROR_DQ_BLOCKED_COUNT =20\n12-29 13:09:45.496 2971-13868/? D/ExynosCamera3: DEBUG(dump[1791])\n12-29 13:09:45.506 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:45.516 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:45.516 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:45.556 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:9)\n12-29 13:09:45.616 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:8)\n12-29 13:09:45.636 2971-13861/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_3AA]-WARN(m_putBuffer[1332]):inputFrameQ wait timeout\n12-29 13:09:45.636 2971-13861/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_3AA]-WARN(m_putBufferThreadFunc[1288]):m_putbuffer fail, ret(-110)\n12-29 13:09:45.646 2971-13863/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_putBuffer[1332]):inputFrameQ wait timeout\n12-29 13:09:45.646 2971-13863/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_putBufferThreadFunc[1288]):m_putbuffer fail, ret(-110)\n12-29 13:09:45.656 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:45.656 2971-13864/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_getBuffer[1636]):requestFrameQ wait timeout\n12-29 13:09:45.656 2971-13864/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_getBufferThreadFunc[1304]):m_getBuffer fail, ret(-110)\n12-29 13:09:45.666 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:45.666 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:45.666 3522-3878/? V/AlarmManager: waitForAlarm result :4\n12-29 13:09:45.676 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:7)\n12-29 13:09:45.736 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:6)\n12-29 13:09:45.806 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:5)\n12-29 13:09:45.806 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:45.816 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:45.816 3996-3996/? D/StatusBar.NetworkController: refreshViews connected={ wifi } level=4 combinedSignalIconId=0x7f02054e/com.android.systemui:drawable/stat_sys_wifi_signal_4 mobileLabel=TW Mobile wifiLabel=\"Y155413\" emergencyOnly=false combinedLabel=\"Y155413\" mAirplaneMode=false mDataActivity=0 mPhoneSignalIconId=0x7f0204e5/com.android.systemui:drawable/stat_sys_signal_4_auto_rotate mQSPhoneSignalIconId=0x7f020123/com.android.systemui:drawable/ic_qs_signal_4 mDataDirectionIconId=0x0/(null) mDataSignalIconId=0x7f0204e5/com.android.systemui:drawable/stat_sys_signal_4_auto_rotate mDataTypeIconId=0x7f020327/com.android.systemui:drawable/stat_sys_data_connected_4g mQSDataTypeIconId=0x0/(null) mNoSimIconId=0x0/(null) mWifiIconId=0x7f02054e/com.android.systemui:drawable/stat_sys_wifi_signal_4 mQSWifiIconId=0x7f020139/com.android.systemui:drawable/ic_qs_wifi_4 mWifiActivityIconId=0x7f02051b/com.android.systemui:drawable/stat_sys_signal_no_inout mBluetoothTetherIconId=0x7f02052b/com.android.systemui:drawable/stat_sys_tether_bluetooth\n12-29 13:09:45.816 3996-3996/? D/STATUSBAR-WifiQuickSettingButton: onWifiSignalChanged enabled=true enabledDesc:\"Y155413\"\n12-29 13:09:45.816 3996-3996/? D/StatusBar.NetworkController: refreshNwBoosterIndicator - setNWBoosterIndicators(false)\n12-29 13:09:45.816 3996-3996/? D/StatusBar.NetworkController: refreshNwBoosterIndicator - setNWBoosterIndicators(false)\n12-29 13:09:45.816 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:45.816 3996-3996/? D/StatusBar.NetworkController: refreshNwBoosterIndicator - setNWBoosterIndicators(false)\n12-29 13:09:45.816 3996-3996/? D/StatusBar.NetworkController: refreshNwBoosterIndicator - setNWBoosterIndicators(false)\n12-29 13:09:45.866 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:4)\n12-29 13:09:45.926 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:3)\n12-29 13:09:45.956 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:45.966 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:45.966 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:45.986 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:2)\n12-29 13:09:46.046 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:6 / totalRequestCnt:6 / blockReqCount = min:4, max:9 / waitcnt:1)\n12-29 13:09:46.046 2971-13727/? D/ExynosCameraBufferManager: [CAM_ID(0)][PREVIEW_STREAM_BUF]-DEBUG(getIndexByHandle[2818]): assigned new buffer handle(0x0) Index(3)\n12-29 13:09:46.106 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:46.106 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:40)\n12-29 13:09:46.116 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:46.116 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:46.146 2971-13863/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_putBuffer[1332]):inputFrameQ wait timeout\n12-29 13:09:46.146 2971-13863/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_putBufferThreadFunc[1288]):m_putbuffer fail, ret(-110)\n12-29 13:09:46.156 2971-13864/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_getBuffer[1636]):requestFrameQ wait timeout\n12-29 13:09:46.156 2971-13864/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_getBufferThreadFunc[1304]):m_getBuffer fail, ret(-110)\n12-29 13:09:46.166 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:39)\n12-29 13:09:46.226 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:38)\n12-29 13:09:46.256 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:46.266 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:46.266 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:46.286 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:37)\n12-29 13:09:46.316 3938-3938/? I/wpa_supplicant: nl80211: Received scan results (15 BSSes)\n12-29 13:09:46.316 3522-3693/? I/Nat464Xlat: interfaceLinkStateChanged wlan0, true\n12-29 13:09:46.316 3522-3693/? D/Tethering: interfaceLinkStateChanged wlan0, true\n12-29 13:09:46.316 3522-3693/? D/Tethering: interfaceStatusChanged wlan0, true\n12-29 13:09:46.316 3938-3938/? I/wpa_supplicant: same, connected : D8.E0.90, current : D8.E0.90\n12-29 13:09:46.316 3522-3912/? D/WifiP2pService: InactiveState{ what=147461 }\n12-29 13:09:46.316 3522-3912/? D/WifiP2pService: P2pEnabledState{ what=147461 }\n12-29 13:09:46.316 3522-3912/? D/WifiP2pService: DefaultState{ what=147461 }\n12-29 13:09:46.346 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:36)\n12-29 13:09:46.356 3522-3522/? I/CLocInfoService: External Intent Received android.net.wifi.SCAN_RESULTS\n12-29 13:09:46.356 3522-3522/? I/CLocInfoCtrl: isAllWifiGathering\n12-29 13:09:46.356 3522-3522/? I/CLocInfoCtrl: wifigathering result : 0\n12-29 13:09:46.366 3996-3996/? I/LoadedApk: getClassLoader :dalvik.system.PathClassLoader[DexPathList[[zip file \"/system/framework/secvisualeffect.jar\", zip file \"/system/priv-app/SystemUI/SystemUI.apk\"],nativeLibraryDirectories=[/vendor/lib64, /system/lib64]]]\n12-29 13:09:46.366 16494-16494/? E/SMD: smd Interface open failed errno is 2 -1\n12-29 13:09:46.366 6556-6556/? I/LoadedApk: getClassLoader :dalvik.system.PathClassLoader[DexPathList[[zip file \"/system/framework/com.google.android.maps.jar\", zip file \"/data/app/com.facebook.orca-1/base.apk\"],nativeLibraryDirectories=[/data/app/com.facebook.orca-1/lib/arm, /vendor/lib, /system/lib]]]\n12-29 13:09:46.406 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:46.406 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:35)\n12-29 13:09:46.416 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:46.416 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:46.466 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:34)\n12-29 13:09:46.526 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:33)\n12-29 13:09:46.546 2971-13861/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_3AA]-WARN(m_putBuffer[1332]):inputFrameQ wait timeout\n12-29 13:09:46.546 2971-13861/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_3AA]-WARN(m_putBufferThreadFunc[1288]):m_putbuffer fail, ret(-110)\n12-29 13:09:46.556 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:46.566 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:46.566 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:46.586 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:32)\n12-29 13:09:46.646 2971-13863/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_putBuffer[1332]):inputFrameQ wait timeout\n12-29 13:09:46.646 2971-13863/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_putBufferThreadFunc[1288]):m_putbuffer fail, ret(-110)\n12-29 13:09:46.646 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:31)\n12-29 13:09:46.656 2971-13864/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_getBuffer[1636]):requestFrameQ wait timeout\n12-29 13:09:46.656 2971-13864/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_getBufferThreadFunc[1304]):m_getBuffer fail, ret(-110)\n12-29 13:09:46.706 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:46.706 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:30)\n12-29 13:09:46.716 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:46.716 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:46.766 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:29)\n12-29 13:09:46.826 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:28)\n12-29 13:09:46.856 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:46.866 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:46.866 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:46.886 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:27)\n12-29 13:09:46.956 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:26)\n12-29 13:09:47.006 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:47.016 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:25)\n12-29 13:09:47.016 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:47.016 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:47.046 2971-13861/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_3AA]-WARN(m_putBuffer[1332]):inputFrameQ wait timeout\n12-29 13:09:47.046 2971-13861/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_3AA]-WARN(m_putBufferThreadFunc[1288]):m_putbuffer fail, ret(-110)\n12-29 13:09:47.076 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:24)\n12-29 13:09:47.136 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:23)\n12-29 13:09:47.146 2971-13863/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_putBuffer[1332]):inputFrameQ wait timeout\n12-29 13:09:47.146 2971-13863/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_putBufferThreadFunc[1288]):m_putbuffer fail, ret(-110)\n12-29 13:09:47.156 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:47.156 2971-13864/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_getBuffer[1636]):requestFrameQ wait timeout\n12-29 13:09:47.156 2971-13864/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_getBufferThreadFunc[1304]):m_getBuffer fail, ret(-110)\n12-29 13:09:47.166 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:47.166 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:47.196 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:22)\n12-29 13:09:47.256 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:21)\n12-29 13:09:47.306 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:47.316 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:20)\n12-29 13:09:47.316 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:47.316 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:47.366 16494-16494/? E/SMD: smd Interface open failed errno is 2 -1\n12-29 13:09:47.376 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:19)\n12-29 13:09:47.376 3522-3878/? V/AlarmManager: waitForAlarm result :4\n12-29 13:09:47.376 3522-3691/? E/ActivityManager: checkUser: useridlist=null, currentuser=0\n12-29 13:09:47.376 3522-3691/? E/ActivityManager: checkUser: useridlist=null, currentuser=0\n12-29 13:09:47.376 3522-3691/? E/ActivityManager: checkUser: useridlist=null, currentuser=0\n12-29 13:09:47.376 3522-3691/? E/ActivityManager: checkUser: useridlist=null, currentuser=0\n12-29 13:09:47.396 17959-17959/? E/Zygote: MountEmulatedStorage()\n12-29 13:09:47.396 17959-17959/? E/Zygote: v2\n12-29 13:09:47.396 17959-17959/? I/libpersona: KNOX_SDCARD checking this for 10126\n12-29 13:09:47.396 17959-17959/? I/libpersona: KNOX_SDCARD not a persona\n12-29 13:09:47.396 17959-17959/? I/SELinux: Function: selinux_compare_spd_ram, SPD-policy is existed. and_ver=SEPF_SM-G9208_5.0.2 ver=27\n12-29 13:09:47.396 3522-3691/? I/ActivityManager: Start proc com.skype.raider for broadcast com.skype.raider/com.skype.android.push.RegisterReceiver: pid=17959 uid=10126 gids={50126, 9997, 3003, 3002, 1028, 1015} abi=armeabi-v7a\n12-29 13:09:47.396 17959-17959/? I/SELinux: Function: selinux_compare_spd_ram , priority [1] , priority version is VE=SEPF_SM-G9208_5.0.2_0027\n12-29 13:09:47.396 17959-17959/? E/SELinux: [DEBUG] get_category: variable seinfo: default sensitivity: NULL, cateogry: NULL\n12-29 13:09:47.426 17959-17959/? D/TimaKeyStoreProvider: TimaSignature is unavailable\n12-29 13:09:47.426 17959-17959/? D/ActivityThread: Added TimaKeyStore provider\n12-29 13:09:47.436 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:18)\n12-29 13:09:47.436 17959-17959/? D/LoadedApk: getResources for android.app.ActivityThread@19681ada forcing ? false needsResourceUpdate ?false\n12-29 13:09:47.446 17959-17959/? D/LoadedApk: getResources for android.app.ActivityThread@19681ada forcing ? false needsResourceUpdate ?false\n12-29 13:09:47.456 3522-4456/? I/InjectionManagerService\u00a0-AppFeature: getCoreFeaturePkgList :[]\n12-29 13:09:47.456 17959-17959/? I/InjectionManager: Inside getClassLibPath + mLibMap{0=, 1=}\n12-29 13:09:47.456 17959-17959/? D/AssetManager: addAssetPath path =/data/app/com.skype.raider-2/base.apkmapset is 0\n12-29 13:09:47.456 17959-17959/? D/AssetManager: addAssetPath path =/data/app/com.skype.raider-2/base.apk, mapOffset =0\n12-29 13:09:47.456 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:47.456 17959-17959/? D/AssetManager: addAssetPath path =/data/app/com.skype.raider-2/base.apk,elasticAppCookieOffset ={3=0}\n12-29 13:09:47.466 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:47.466 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:47.476 17959-17959/? I/LoadedApk: getClassLoader :null\n12-29 13:09:47.476 17959-17959/? I/InjectionManager: Inside getClassLibPath caller \n12-29 13:09:47.476 17959-17959/? I/LoadedApk: classLibPath :, mActivityThread.mCoreFeatureClassLoader :null\n12-29 13:09:47.496 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:17)\n12-29 13:09:47.546 2971-13861/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_3AA]-WARN(m_putBuffer[1332]):inputFrameQ wait timeout\n12-29 13:09:47.546 2971-13861/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_3AA]-WARN(m_putBufferThreadFunc[1288]):m_putbuffer fail, ret(-110)\n12-29 13:09:47.556 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:16)\n12-29 13:09:47.606 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:47.616 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:15)\n12-29 13:09:47.616 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:47.616 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:47.646 2971-13863/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_putBuffer[1332]):inputFrameQ wait timeout\n12-29 13:09:47.646 2971-13863/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_putBufferThreadFunc[1288]):m_putbuffer fail, ret(-110)\n12-29 13:09:47.656 2971-13864/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_getBuffer[1636]):requestFrameQ wait timeout\n12-29 13:09:47.656 2971-13864/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_getBufferThreadFunc[1304]):m_getBuffer fail, ret(-110)\n12-29 13:09:47.676 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:14)\n12-29 13:09:47.736 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:13)\n12-29 13:09:47.756 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:47.766 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:47.776 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:47.796 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:12)\n12-29 13:09:47.856 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:11)\n12-29 13:09:47.906 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:47.916 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:10)\n12-29 13:09:47.916 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:47.926 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:47.976 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:9)\n12-29 13:09:48.036 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:8)\n12-29 13:09:48.046 2971-13861/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_3AA]-WARN(m_putBuffer[1332]):inputFrameQ wait timeout\n12-29 13:09:48.046 2971-13861/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_3AA]-WARN(m_putBufferThreadFunc[1288]):m_putbuffer fail, ret(-110)\n12-29 13:09:48.056 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:48.066 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:48.076 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:48.096 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:7)\n12-29 13:09:48.146 2971-13863/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_putBuffer[1332]):inputFrameQ wait timeout\n12-29 13:09:48.146 2971-13863/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_putBufferThreadFunc[1288]):m_putbuffer fail, ret(-110)\n12-29 13:09:48.156 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:6)\n12-29 13:09:48.156 2971-13864/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_getBuffer[1636]):requestFrameQ wait timeout\n12-29 13:09:48.156 2971-13864/? W/ExynosCameraMCPipe: [CAM_ID(0)][PIPE_ISP]-WARN(m_getBufferThreadFunc[1304]):m_getBuffer fail, ret(-110)\n12-29 13:09:48.206 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:48.216 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:5)\n12-29 13:09:48.216 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:48.226 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:48.276 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:4)\n12-29 13:09:48.336 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:3)\n12-29 13:09:48.356 2971-13865/? W/ExynosCamera3: WARN(m_previewStream3AAPipeThreadFunc):wait timeout\n12-29 13:09:48.366 16494-16494/? E/SMD: smd Interface open failed errno is 2 -1\n12-29 13:09:48.366 2971-13866/? W/ExynosCamera3: WARN(m_previewStreamISPPipeThreadFunc):wait timeout\n12-29 13:09:48.376 2971-13867/? W/ExynosCamera3: WARN(m_duplicateBufferThreadFunc):wait timeout\n12-29 13:09:48.396 2971-13727/? D/ExynosCamera3: DEBUG(processCaptureRequest[1393]):time out (m_processList:7 / totalRequestCnt:7 / blockReqCount = min:4, max:9 / waitcnt:2)\n", "I've tried duplicating this on a T-Mobile Samsung Galaxy S6 running Android 5.1.1, but am unable to cause any unexpected behavior. I've also tried clearing the bitmap to be completely black before recognition just to try and rule out a numerical issue in Tensorflow.\n\nIf you change the entirety of onImageAvailable() to be:\n\n```\n  @Override\n  public void onImageAvailable(final ImageReader reader) {\n    Image image = null;\n    try {\n      image = reader.acquireLatestImage();\n    } catch (final Exception e) {\n      LOGGER.e(e, \"Exception!\");\n    }\n    if (image != null) {\n      image.close();\n    }\n  }\n```\n\ndoes the problem still occur? I'm just trying to completely rule out any of the native code (image processing or TF) contained in the app as the cause.\n\nWhat provider is your phone from?\n\nAlso, does the image just look black, or have you verified that the RGB value of every single pixel is actually 0,0,0?\n", "Hey sorry for the late reply, I was testing it in other devices, I tested it in a 5.1.1 Samsung galaxy s6 edge and the error did not occur, I then thought it was something wrong with my configuration or some other factor affecting my cellphone so I performed a factory reset but the problem still occurs, as for the black image it is not entirely black pixels, you can see some light colors, so basically it is mostly black, I tested the demo with the code above and now there is no recognition of course but the error persists\n", "Sorry for late response, just got back from vacation.\n\nSo this problem occurs on a Samsung Galaxy S6 running Android 5.0.2, but not on Samsung Galaxy S6 Edge running 5.1.1, is that correct? Which mobile providers are the respective phones from?\n\nIf so, I'm guessing it has more to do with the particular camera drivers on your phone than Tensorflow, especially since you tested with the null code above. \n", "Closing due to lack of activity, reopen if still occurring.\n"]}, {"number": 623, "title": "Fix apk path in the doc", "body": "When following the instructions build rule doesn't produce that incremental APK\n", "comments": []}, {"number": 622, "title": "Cannot remove entries from nonexistent ", "body": "Hello everyone\n\nI am using Anaconda on Mac OS 10.11\n\nI created a new environment with anaconda\n\n``` bash\nconda create -n tensorflow python\n```\n\nThen tried to install tensorflow\n\n``` bash\npip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.6.0-py2-none-any.whl\n```\n\nbut I faced an error\n\n``` bash\nInstalling collected packages: six, setuptools, protobuf, numpy, tensorflow\n  Found existing installation: setuptools 19.1.1\n**Cannot remove entries from nonexistent file /Users/qdang/anaconda/envs/tensorflow/lib/python2.7/site-packages/easy-install.pth**\n```\n\nHow could I install tensorflow with anaconda python 2.7?\n\nBtw, I have CUDA 3.0 (Nvidia 750M) with my Macbook? How could I utilize its power other than running only on CPU mode?\n\nThanks,\n", "comments": ["The solution is posted here\n\nhttps://github.com/tensorflow/tensorflow/issues/135\n\nIt is for tensorflow 0.5.0 but still works with version 0.6.0\n", "Hi, I followed the solution in the provided linking by downloading .whl file manually ( https://storage.googleapis.com/tensorflow/mac/tensorflow-0.6.0-py2-none-any.whl ) and run $pip install tensorflow-0.6.0-py2-none-any.whl.\n\nAnd install the latest tensorflow by $  pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.6.0-cp27-none-linux_x86_64.whl\n\nHowever, the issue still comes out:\nFound existing installation: setuptools 19.1.1\nCannot remove entries from nonexistent file...\n\nCould you please give more detailed solution when you solved the 'nonexistent' issue? Thanks a lot!\n", "Hi\n\nIt works for me (in Mac OS 10.11). Hope it helps\n\nhttp://vinhdq.blogspot.com/2015/12/installing-tensorflow-on-mac-os-1011.html http://vinhdq.blogspot.com/2015/12/installing-tensorflow-on-mac-os-1011.html\n\u2014\nBest Regards\n\nVinh DANG\n\n> On 30 Dec 2015, at 07:14, Zhuotun Zhu notifications@github.com wrote:\n> \n> Hi, I followed the solution in the provided linking by downloading .whl file manually ( https://storage.googleapis.com/tensorflow/mac/tensorflow-0.6.0-py2-none-any.whl https://storage.googleapis.com/tensorflow/mac/tensorflow-0.6.0-py2-none-any.whl ) and run $pip install tensorflow-0.6.0-py2-none-any.whl.\n> \n> And install the latest tensorflow by $ pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.6.0-cp27-none-linux_x86_64.whl https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.6.0-cp27-none-linux_x86_64.whl\n> However, the issue still comes out:\n> Found existing installation: setuptools 19.1.1\n> Cannot remove entries from nonexistent file...\n> \n> Could you please give more detailed solution when you solved the 'nonexistent' issue? Thanks a lot!\n> \n> \u2014\n> Reply to this email directly or view it on GitHub https://github.com/tensorflow/tensorflow/issues/622#issuecomment-167943977.\n", "I actually have installed Tensorflow 0.6.0 successfully on Ubuntu 14.04.\nI am wondering how to solve the  \"Found existing installation: setuptools 19.1.1 Cannot remove entries from nonexistent file\" issue. Maybe it worked for you but not me due to the different OS?\n", "Hi\n\nHow did you install tensor flow?\n\nI faced a same problem when I installed with pip, but after I created a totally new environment there is no issue.\n\u2014\nBest Regards\n\nVinh DANG\n\n> On 30 Dec 2015, at 07:31, Zhuotun Zhu notifications@github.com wrote:\n> \n> I actually have installed Tensorflow 0.6.0 successfully on Ubuntu 14.04.\n> I am wondering how to solve the \"Found existing installation: setuptools 19.1.1 Cannot remove entries from nonexistent file\" issue. Maybe it worked for you but not me due to the different OS?\n> \n> \u2014\n> Reply to this email directly or view it on GitHub https://github.com/tensorflow/tensorflow/issues/622#issuecomment-167945086.\n", "Hi, I installed the tensorflow on Ubuntu 14.04 as following:\n\n$ conda install virtualenv\n$ conda create --name=tensorflow_env python=2.7\n$ source activate tensorflow_env\n$ pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.5.0-cp27-none-linux_x86_64.whl\n\nThen I updated to the 0.6.0 version. Although there is still the nonexistent issue, I tested the tensorflow successfully on MNIST demo. I think the issue is just somehow a warning that may not affect the use of tensorflow at present. However, it's better to solve it. \n", "Why do you need to install version 0.5.0 then upgrade. Maybe it\u2019s better to install 0.6.0 directly?\n\n\u2014\nBest Regards\n\nVinh DANG\n\n> On 30 Dec 2015, at 08:06, Zhuotun Zhu notifications@github.com wrote:\n> \n> Hi, I installed the tensorflow on Ubuntu 14.04 as following:\n> \n> $ conda install virtualenv\n> $ conda create --name=tensorflow_env python=2.7\n> $ source activate tensorflow_env\n> $ pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.5.0-cp27-none-linux_x86_64.whl https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.5.0-cp27-none-linux_x86_64.whl\n> Then I updated to the 0.6.0 version. Although there is still the nonexistent issue, I tested the tensorflow successfully on MNIST demo. I think the issue is just somehow a warning that may not affect the use of tensorflow at present. However, it's better to solve it.\n> \n> \u2014\n> Reply to this email directly or view it on GitHub https://github.com/tensorflow/tensorflow/issues/622#issuecomment-167948239.\n", "Hi,\nCause the instruction on homepage of Virtualenv installation is the 0.5.0 version. I didn't notice the latest 0.6.0 version. After I installed, I was informed from other source that maybe I could update to the 0.6.0 version. However, the nonexistent issue comes out both on my installation of 0.5.0 and 0.6.0.\n", "Well\n\nI have no idea about Ubuntu environment.\n\nHowever, I could suggest you try (nothing to lose LOL):\n- create a new environment with conda (using sklearn environment instead of pure python)\n- install tensor flow 0.6.0 offline.\n  \u2014\n  Best Regards\n\nVinh DANG\n\n> On 30 Dec 2015, at 08:31, Zhuotun Zhu notifications@github.com wrote:\n> \n> Hi,\n> Cause the instruction on homepage of Virtualenv installation is the 0.5.0 version. I didn't notice the latest 0.6.0 version. After I installed, I was informed from other source that maybe I could update to the 0.6.0 version. However, the nonexistent issue comes out both on my installation of 0.5.0 and 0.6.0.\n> \n> \u2014\n> Reply to this email directly or view it on GitHub https://github.com/tensorflow/tensorflow/issues/622#issuecomment-167951149.\n", "See here: https://github.com/pypa/pip/issues/2751.\nPossible work-around: `pip install --upgrade --I setuptools`\n", "@osdf - yeah I hit this too. Used the following to solve it when using conda (after I already successfully installed using the ubuntu pip directly) so that I had iPython notebook (Jupyter) installed.\n\nList conda environments\n`$ conda env list`\n\nEnable a conda environment..\n`$ source activate [your env or root]`\n\ncheck python..\n`$ which python`\n.. this should be something like ~/anaconda2/bin/python\n\n`$ pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.6.0-cp27-none-linux_x86_64.whl`\n\n.. got the error above, so added the  --ignore-installed flag per https://github.com/pypa/pip/issues/2751\n\n`$  pip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.6.0-cp27-none-linux_x86_64.whl --ignore-installed`\n\n.. everything was successful..\n\n`$ python`\n`>>> import tensorflow`\n\n.. success and back in business!\n", "Thanks @frankcarey for posting your workaround.\n", "Had same error with Python 3.4 version, solution by @frankcarey worked, thanks!\n", "@frankcarey \nI use your workaround and successfully installed tensorflow\nBut when I import it, there is something wrong.\n\n```\n---------------------------------------------------------------------------\nImportError                               Traceback (most recent call last)\n<ipython-input-1-a649b509054f> in <module>()\n----> 1 import tensorflow\n\n/public/home/kli/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/__init__.py in <module>()\n     21 from __future__ import print_function\n     22\n---> 23 from tensorflow.python import *\n\n/public/home/kli/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/__init__.py in <module>()\n     39 please exit the tensorflow source tree, and relaunch your python interpreter\n     40 from there.\"\"\" % traceback.format_exc()\n---> 41   raise ImportError(msg)\n     42\n     43 from tensorflow.core.framework.summary_pb2 import *\n\nImportError: Traceback (most recent call last):\n  File \"/public/home/kli/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 35, in <module>\n    from tensorflow.core.framework.graph_pb2 import *\n  File \"/public/home/kli/anaconda/envs/tensorflow/lib/python2.7/site-packages/tensorflow/core/framework/graph_pb2.py\", line 6, in <module>\n    from google.protobuf import descriptor as _descriptor\n  File \"/public/home/kli/anaconda/envs/tensorflow/lib/python2.7/site-packages/google/protobuf/descriptor.py\", line 46, in <module>\n    from google.protobuf.pyext import _message\nImportError: /lib64/libc.so.6: version `GLIBC_2.14' not found (required by /public/home/kli/anaconda/envs/tensorflow/lib/python2.7/site-packages/google/protobuf/pyext/_message.so)\n\n\nError importing tensorflow.  Unless you are using bazel,\nyou should not try to import tensorflow from its source directory;\nplease exit the tensorflow source tree, and relaunch your python interpreter\nfrom there.\n\n```\n", "@kli-nlpr Did you figure out the GLIBC_2.14 problem?\n", "@StevenHuang4321  \nI use centos6 when encounter this problem.\nWhen I use Ubuntu14.04, the problem goes away.\n", "Since our server use Centos 6, it is not possible for me to change to\nubuntu. Thanks.\n\nOn Tue, Mar 8, 2016 at 5:28 PM, Kai Li notifications@github.com wrote:\n\n> @StevenHuang4321 https://github.com/StevenHuang4321\n> \n> I use centos6 when encounter this problem.\n> When I use Ubuntu14.04, the problem goes away.\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/622#issuecomment-194055591\n> .\n", "@StevenHuang4321 \nThe possible solution is to update your glibc version.\nBut I think this is a complicated task and dangerous...\n\nIn fact I encounter a lot of problem when I use centos6 while doing deep learning research.\nAfter change to Ubuntu, life becomes much easier.\n", "Our system is CentOS 6.7, but it seems that only CentOS 7 supprot glib_2.14\nor higher version.\n\nApparently, CentOS is not a good linux distribution to do develop and\nresearch.\n\nI already suggest my advisor to migrate our server from CentOS6.7 to Ubuntu\nserver.\n\nOn Tue, Mar 8, 2016 at 5:41 PM, Kai Li notifications@github.com wrote:\n\n> @StevenHuang4321 https://github.com/StevenHuang4321\n> The possible solution is to update your glibc version.\n> But I think this is a complicated task and dangerous...\n> \n> In fact I encounter a lot of problem when I use centos6 while doing deep\n> learning research.\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/622#issuecomment-194058962\n> .\n", "solution works, thanks!\n", "Another solution \n\n```\npip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl\n```\n", "Observed on Ubuntu 15.10 Server in Anaconda 4.0.0 with python 3.4, tensorflow-0.7.1-cp34-none-linux_x86_64.whl GPU. Downloading and installing from local file works!\n", "@osdf \nthanks for your solution!\nit works\npip install --upgrade -I setuptools\n", "Both solutions worked for me:\n1. \n\n``` shell\npip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl\n```\n\n2.\n\n``` shell\npip install --upgrade -I setuptools\n\nexport TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow-0.10.0rc0-py3-none-any.whl\nsudo pip3 install --upgrade $TF_BINARY_URL\n\nsudo python3 -m pip install --upgrade https://storage.googleapis.com/tensorflow/mac/protobuf-3.0.0b2.post2-cp35-none-any.whl \n```\n", "just as a comment...I accidentally downloaded the MAC version in linux because the `--ignore-installed` allowed me. So if it still doesn't work that might be it.\n", "1.download [ez_setup.py](https://bootstrap.pypa.io/ez_setup.py)\n2.run script >python ez_setup.py\nIt works for me (in windows 7)\n"]}, {"number": 621, "title": "word2vec_optimized.py fails with large training files", "body": "Here is the relevant part of the error for a 2400000000 byte file:\n\n```\nexternal/re2/re2/re2.cc:571: RE2: invalid startpos, endpos pair. [startpos: 0, endpos: -1894967296, text size: -1894967296]\nW tensorflow/models/embedding/word2vec_kernels.cc:38] Invalid argument: The text file _train.txt contains too little data: 0 words\nE tensorflow/core/framework/op_segment.cc:52] Create kernel failed: Invalid argument: The text file _train.txt contains too little data: 0 words\nE tensorflow/core/common_runtime/executor.cc:262] Executor failed to create kernel. Invalid argument: The text file _train.txt contains too little data: 0 words\n```\n\nThis doesn't happen for a 1000000000 byte file. I suppose there might be an overflow somewhere.\n\nAs an aside, how do I dump the embeddings from the final checkpoint?\n", "comments": ["See https://github.com/tensorflow/tensorflow/issues/531 for the first part -- feel free to send us a change to fix this if you'd like.\n\nSee https://www.tensorflow.org/versions/master/how_tos/variables/index.html#saving-and-restoring for the second.\n", "Thanks, vrv. I see in the bug report you linked that a fix is pending code review. Is another fix needed?\n", "We're waiting for the author to repost to github -- feel free to send a similar change soon if the original author doesn't.\n"]}, {"number": 620, "title": "Question about MNIST For ML Beginners, the model definition?", "body": "https://www.tensorflow.org/versions/master/tutorials/mnist/beginners/index.html#mnist-for-ml-beginners\nIn the tutorial for beginner, the model definition flipped from original equation, as say it is a small trick to deal with x being a 2D tensor. \n\n> First, we multiply x by W with the expression tf.matmul(x, W). This is flipped from when we multiplied them in our equation, where we had Wx, as a small trick to deal with x being a 2D tensor with multiple inputs. We then add b, and finally apply tf.nn.softmax.\n\nWhy say it is a small trick ?  Both definition should be equivalent right?\nAs below\nModel definition: \n(1) $y = Wx + b$  \nShape: (10, n) = (10, 784) x (784, n) + (10, n)  \n(2) $y = xW + b$  \nShape: (n, 10) = (n, 784) x (784, 10) + (n, 10)\n\nI change the downloaded code `mnist_softmax.py` code to model (1) version and run it, I found that the accuracy is lower than model (2)?\nAnyone could tell me the reason? \n", "comments": ["Hi Jacob,\n\nThe 'small trick' refers to the fact that the image tensor returned by `mnist.train.next_batch(100)` has the shape `[100, 784]`. Note that the batch is the innermost dimension. To use it directly, we shape the `W` tensor as `[784, 10]` to use it directly in `tf.matmul(x, W)` to produce `10` activations. So if you transposed the output of `mnist.train.next_batch(100)` to `[784, 100]` and shaped your `W` as `[10, 784]`, then indeed you can call `tf.matmul(W, x)`. Is that what you were trying and were seeing a different accuracy?\n", "Hello Keveman, \n         Thanks for your reply. My understanding is exactly the same with you. This is what I am trying and seeing that the tensorflow version is always higher than the flipped version, which is very strange.\n\nCould you also have a try and take a look? The attachment is my modification of tensorflow code(mnist_softmax.py), which averages the result of n iterations. \n\n[mnist_softmax_flip.txt](https://github.com/tensorflow/tensorflow/files/75367/mnist_softmax_flip.txt)\n[mnist_softmax.txt](https://github.com/tensorflow/tensorflow/files/75368/mnist_softmax.txt)\n", "This is a question for stackoverflow, not an issue with TensorFlow.  If the activations have shape `[batch, input]` and the weight matrix has shape `[input, output]`, only `tf.matmul(activations, weights)` makes sense.  The other way around would be a size error.  You're correct that transposing the entire graph should produce something with the same semantics, but note that _every_ part of the graph needs to be transposed, including the input pipeline, loss ops, etc.\n"]}, {"number": 619, "title": "TENSOR-566: Fix for verbose messaging", "body": "After doing a bit of digging on various logging.h used in tensorflow, while some provide facility of silencing logs via LogSilencer and some use re2 package with flags like FLAGS_minlogLevel, the flow for local_device.cc and direct_session.cc only hit the core platform default logging (tensorflow/core/platform/default/logging.h) which neither has facility to silence log nor is capable of interpreting command line flag setting. One way is to make it verbose logging at level 1 for these messages are truly not messages a user needs to know  every time, but only if interested.Please review and let me know if this is ok.Also long term if there is log suppressing on this flow.thanks.\n", "comments": ["Thanks @vrv for the review.updated.please check.thanks.\n", "ok, looks good, please squash the commit into one\n", "Done.thanks @vrv \n", "If I actually want to see these log messages, how can I un-suppress them? (logging.basicConfig(level=logging.DEBUG) made no difference)\n", "@omasoud You could add the following to `tensorflow/core/platform/logging.h` and recompile:\n\n`#define VLOG_IS_ON(lvl) ((lvl) <= 1)`\n"]}, {"number": 618, "title": "Strongly suggest to improve Tensorflow API document by adding examples", "body": "Dear contributors, \n        I think the document of tensorflow is not good enough overall. \n        I really like Python and Numpy's official document, since they are give very **detailed explanation** and **importantly each concept has simple code example to illustrate the meaning, which helps a lot for easier understanding**. \n       However, tensorflow's document does not contains such example for illustration and the explanation is not in detail. \n       For example, the document for \n      `tf.nn.in_top_k(predictions, targets, k, name=None)` \n       spend me much time to guess what does it mean. The formula in it is not trivial to understand. \n       We could see in the **issue post** in this project that many of them are regarding the specific use of some method/function. \n       To once for all resolve this problem, please consider to improve the the overall document in the Python document fashion, it is very important for the popularity of tensorflow among all other similar tools. \n       Thank you all for your contribution for this project. \n", "comments": ["We have tried to include examples for complicated functions but more examples certainly wouldn't hurt. We'll gladly accept PRs for example code in function documentation.\n", "And there is no document or api on tf.nn.rnncell\n", "Closing for now since this isn't specific enough as a Github issue.  We're still happy accept PRs improving the documentation, and please file more specific documentation issues as separate bugs.\n"]}, {"number": 617, "title": "Docs for tf.device should point to tf.Graph.device", "body": "Currently the docs for `tf.device` located here:\n\nhttps://www.tensorflow.org/versions/master/api_docs/python/framework.html#device\n\npoint to `tf.Graph.name_scope()` for more details, when it would be a lot more helpful if they pointed instead to `tf.Graph.device()`, i.e. here:\n\nhttps://www.tensorflow.org/versions/master/api_docs/python/framework.html#Graph.device\n\nThis would be more consistent with the rest of the docs as well.\n", "comments": ["Should be fixed at HEAD now.\n"]}, {"number": 616, "title": "How  to use tf.train.write_graph() and tf.import_graph_def()? It seems that it does not work.", "body": "How  to use tf.train.write_graph() and tf.import_graph_def()? It seems that it does not work.\n\nPlease refer the following codes and prints, the final result is None, but it is expected to be [101 102 103 104 105 106 107 108 109 110].\n\ncode\uff1a\n\nimport tensorflow as tf\nimport os\nimport numpy as np\nfrom tensorflow.python.platform import gfile\n\ninput1= tf.placeholder(tf.int32, [10], name=\"input\")\ndata = np.arange(10)\noutput1= tf.add(input1, tf.constant(1), name=\"output\")\n\nwith tf.Session() as sess:\n    os.system(\"rm -rf /tmp/load\")\n    tf.train.write_graph(sess.graph_def, \"/tmp/load\", \"test.pb\", False)\n    print sess.run(output1,{input1:data})\nprint \"Done\"\n# load graph\n\nwith gfile.FastGFile(\"/tmp/load/test.pb\",'rb') as f:\n    graph_def = tf.GraphDef()\n    graph_def.ParseFromString(f.read())\n    tf.import_graph_def(graph_def, name='')\n# run\n\nwith tf.Session() as sess:\n    input_x = sess.graph.get_tensor_by_name(\"input:0\")\n    print input_x\n    Const = sess.graph.get_tensor_by_name(\"Const:0\")\n    print Const  \n    output = sess.graph.get_operation_by_name(\"output\")\n    print output\n\n```\ndata1 = np.arange(10)+100\nprint \"data1:\", data1\nresult = sess.run(output, {input_x: data1})\nprint \"result:\",result\n```\n\nprints\uff1a\n[ 1  2  3  4  5  6  7  8  9 10]\nDone\nTensor(\"input:0\", shape=TensorShape([Dimension(10)]), dtype=int32)\nTensor(\"Const:0\", shape=TensorShape([]), dtype=int32)\nname: \"output\"\nop: \"Add\"\ninput: \"input\"\ninput: \"Const\"\nattr {\n  key: \"T\"\n  value {\n    type: DT_INT32\n  }\n}\n\ndata1: [100 101 102 103 104 105 106 107 108 109]\nresult: None\n", "comments": ["see https://stackoverflow.com/questions/33759623/tensorflow-how-to-restore-a-previously-saved-model-python\n\nHere is a complete example for your convenience:\n\n```\nimport tensorflow as tf\nimport os\nimport numpy as np\nfrom tensorflow.python.platform import gfile\n\ndata = np.arange(10,dtype=np.int32)\nwith tf.Session() as sess:\n  print(\"# build graph and run\")\n  input1= tf.placeholder(tf.int32, [10], name=\"input\")\n  output1= tf.add(input1, tf.constant(100,dtype=tf.int32), name=\"output\") #  data depends on the input data\n  saved_result= tf.Variable(data, name=\"saved_result\")\n  do_save=tf.assign(saved_result,output1)\n  tf.initialize_all_variables()\n  os.system(\"rm -rf /tmp/load\")\n  tf.train.write_graph(sess.graph_def, \"/tmp/load\", \"test.pb\", False) #proto\n  # now set the data:\n  result,_=sess.run([output1,do_save], {input1: data}) # calculate output1 and assign to 'saved_result'\n  saver = tf.train.Saver(tf.all_variables())\n  saver.save(sess,\"checkpoint.data\")\n\nwith tf.Session() as persisted_sess:\n  print(\"load graph\")\n  with gfile.FastGFile(\"/tmp/load/test.pb\",'rb') as f:\n    graph_def = tf.GraphDef()\n    graph_def.ParseFromString(f.read())\n    persisted_sess.graph.as_default()\n    tf.import_graph_def(graph_def, name='')\n  print(\"map variables\")\n  persisted_result = persisted_sess.graph.get_tensor_by_name(\"saved_result:0\")\n  tf.add_to_collection(tf.GraphKeys.VARIABLES,persisted_result)\n  try:\n    saver = tf.train.Saver(tf.all_variables()) # 'Saver' misnomer! Better: Persister!\n  except:pass\n  print(\"load data\")\n  saver.restore(persisted_sess, \"checkpoint.data\")  # now OK\n  print(persisted_result.eval())\n  print(\"DONE\")\n```\n", "fyi, there is a bug in write_graph, I'll send in a patch \"shortly\", the quick fix is this:\n\nindex 6f4589a..2428c66 100644\n--- a/tensorflow/python/training/training_util.py\n+++ b/tensorflow/python/training/training_util.py\n@@ -66,8 +66,9 @@ def write_graph(graph_def, logdir, name, as_text=True):\n     name: Filename for the graph.\n     as_text: If `True`, writes the graph as an ASCII proto.\n   \"\"\"\n-  if not gfile.IsDirectory(logdir):\n-    gfile.MakeDirs(logdir)\n  path = os.path.join(logdir, name)\n-  gfile.MakeDirs(os.path.dirname(path))\n  f = gfile.FastGFile(path, \"w\")\n  if as_text:\n   f.write(str(graph_def))\n", "edit: ^ formatting above screw up:\n\nBasically you have to do this:\n  if not gfile.IsDirectory(logdir):\n    gfile.MakeDirs(logdir)\n  path = os.path.join(logdir, name)\n\n(MakeDirs expect the path to not exist, if the path exists it will fail)\n", "Oh yeah, also my version needed to have an explicit binary flag \"wb\"\n\n```\n+++ b/tensorflow/python/training/training_util.py\n@@ -67,10 +67,13 @@ def write_graph(graph_def, logdir, name, as_text=True):\n\n   if as_text:\n+    f = gfile.FastGFile(path, \"w\")\n     f.write(str(graph_def))\n   else:\n+    f = gfile.FastGFile(path, \"wb\")\n     f.write(graph_def.SerializeToString())\n   f.close()\n```\n", "Thank  @pannous  and @wchan  very much.\n\nI want to acheive the effect same with classify_image.py in path of tensorflow/tensorflow/models/image/imagenet. The file just use classify_image_graph_def.pb as model files, which seems to have contained trained variables. Do you have any idea about how to generate the .pb file with trained variables?\n", "I have the same problem. How to save the trained variables? I trained the model by python, and I want to predict on Android devices, but the trained variables did not save in .pb file. there is no C++ API to restore variables which saved by python API \"saver\"\n", "I have the same issue, I can't seem to figure out how to save the trained variables into a .pb file, if somebody could shed some light to this issue I would be really grateful.\n", "It seem that tensorflow can not support this mode now. They are still working for it.\nhttp://stackoverflow.com/questions/34353160/how-can-i-execute-a-tensorflow-graph-from-a-protobuf-in-c\n", "It is possible, the answer is in the above link's answers, the trick is to use tf.constant instead of variables\n", "@jonathanponce it sounds like you have an idea of how to do this, but I saw no reference to tf.constant in the above links. Can you explain? I'm guessing you mean that `graph_def.SerializeToString()` stores constants? I would very much like to store my entire trained model in a serialized graph_def - which seems entirely possible since Google is distributing Inception v3 as a .pb file.\n", "Yeah, I was able to export a trained graph and use it my android application, I followed some of the instructions here http://stackoverflow.com/questions/34343259/is-there-an-example-on-how-to-generate-protobuf-files-holding-trained-tensorflow/34343517#34343517 by using tf.constant when saving the trained graph def\n", "I follow the steps in http://stackoverflow.com/questions/34343259/is-there-an-example-on-how-to-generate-protobuf-files-holding-trained-tensorflow/34343517#34343517 \nbut in step4 when import_graph_def is called, I got an error\n\n> ValueError: graph_def is invalid at node u'conv1/weights/Assign': Input tensor u'conv1/weights:0' Cannot convert a tensor of type float32 to an input of type float32_ref\n\nAnything I missed? \nmy source code is \n\n```\n  for v in g1.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES):\n    with g2.as_default():\n      const_var[v.name] = tf.constant(v.eval(),name=v.name)\n  with g2.as_default():\n    tf.import_graph_def(graph_def=g1.as_graph_def(),input_map=const_var)\n```\n", "Looks like this fell through the cracks.  Anyone know if it's still an issue?\n", "This is also an issue for me. \n", "@sherrym: Can you take a look?\n", "I'm facing the same problem as @yutachen when I call import_graph_def\n\nMy function that saves the graph looks like:\n\n```\ndef save_graph(inference_func,checkpoint_path,image_size,dest_path):\n    \"\"\" Saves a computation graph with all it's variables.\n    :param inference_func: the function that builds the graph and gets image input\n    :param checkpoint_path: the path to a checkpoint containing values of variables\n    :param image_size: the image input size\n    :param dest_path: file path to save the graph definition protocol buffer\n    :return:\n    \"\"\"\n\n    g = tf.Graph()\n    vars = {}\n    with g.as_default():\n        with tf.Session() as sess:\n            d = np.ones([1,conf.parts_avg_size[5][1],conf.parts_avg_size[5][0],3],dtype=np.float32)\n\n            input_data = tf.placeholder(tf.float32,shape=[1,image_size[1],image_size[0],3], name=\"input_placeholder\")\n            logits = inference_func(input_data)\n\n            init = tf.initialize_all_variables()\n            sess.run(init) #TODO for testing, remove later\n            saver = tf.train.Saver(tf.trainable_variables(),max_to_keep=0)\n            saver.restore(sess,checkpoint_path)\n\n            print sess.run(logits,{input_data:d})\n            for v in tf.trainable_variables():\n                vars[v.name] = sess.run(v)\n\n\n    g2 = tf.Graph()\n    consts = {}\n    with g2.as_default():\n        with tf.Session() as sess:\n            for k in vars.keys():\n                consts[k] = tf.constant(vars[k])\n            tf.import_graph_def(g.as_graph_def(),input_map={name:consts[name] for name in consts.keys()})\n\n            tf.train.write_graph(sess.graph_def,dest_path,'graph.pbtxt',False)\n\n    return os.path.join(dest_path,'graph.pbtxt')\n```\n\nand I'm getting\n`ValueError: graph_def is invalid at node u'conv1/weigths/Assign': Input tensor 'conv1/weigths:0' Cannot convert a tensor of type float32 to an input of type float32_ref.`\n\n@jonathanponce can you take a look?\n", "I also get the similar error trying to restore graph with `tf.train.ExponentalMovingAverage`.  The error is `ValueError: graph_def is invalid at node u'conv1_1/bn/ExponentialMovingAverage/AssignMovingAvg': Input tensor 'conv1_1/bn/conv1_1/bn/moments/moments_1/mean/ExponentialMovingAverage:0' Cannot convert a tensor of type float32 to an input of type float32_ref.`\n", "In general, please make sure that when you use import_graph_def(), you are in a fresh new graph, not the same graph. Something like this:\n\nfirst_graph = tf.Graph()\nwith tf.Session(graph=first_graph) as sess:\n   # build you graph\n   # write your graph\n\nsecond_graph = tf.Graph()\nwith tf.Session(graph=second_graph) as sess:\n  # import from the written graph\n  # run compute, etc\n\nI will take a closer look at each failure case and respond separately.\n\nSherry\n", "For Pouya's problem:\n\nWhen you constructed your input_map, consts() is a map of Tensors (if you print it out, you will see that your consts() are tensors):\n\n<tf.Tensor 'Const:0' shape=() dtype=float32>\n\nAssign Op requires that the first input be a ref type:\n\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/ops/state_ops.cc#L95\n\nTo make it work, just remove your input_map.\n", "@yutachen's problem has the same root cause.\n\n@ingwar, if you are passing in input_map as well, you problem probably has the same root case as well.\n\nSherry\n", "If your problem is different from the ones encountered by @po0ya, @yutachen, and @ingwar, and you have followed my instructions, please include your complete program.\n\nThanks,\nSherry\n", "@sherrym Thanks. No, I don't use `input_map`, I am trying to restore graph passed through `convert_variables_to_constants`. I'll try to post the script to reproduce the issue.\n", "@sherrym First thank you for helping on this. \nI'm a little bit confused. By removing the input map do you mean I change that line to just `tf.import_graph_def(g.as_graph_def())` ?\n\nBut in here  http://stackoverflow.com/questions/34343259/is-there-an-example-on-how-to-generate-protobuf-files-holding-trained-tensorflow/34343517#34343517 in step 4 @mrry says \"use the input_map argument to replace each variable in g_1 with the corresponding tf.constant() tensors created in step 3. \" \n\nHow do they get assigned to the variables in graph without an input map argument?\n", "Assigned to @mrry since he wrote the instructions. :)\n", "I think the appropriate fix is to change the tensors that you're remapping in `input_map` from the (names of the) variables themselves to (names of) the _values_ of the variables. I think you can achieve it by replacing the following loop:\n\n``` python\nfor v in tf.trainable_variables():\n    vars[v.name] = sess.run(v)\n```\n\n...with this code:\n\n``` python\nfor v in tf.trainable_variables():\n    vars[v.value().name] = sess.run(v)\n```\n", "Sorry for delay, here is the gist that reproduce my issue: https://gist.github.com/Ingwar/3b8a7232f4cb906ff1f0. I can open separate issue, if needed.\n", "@mrry Thanks, this solved the issue. I tested the function and it gives consistent results after loading the model that is saved this way.\n", "This fundamental functionality should really be one call in core tensorflow. It should not be reinvented painfully in dozens lines of code by every developer.\n", "@pannous Please feel free to open a new issue with a feature request. You might also find the [`freeze_graph.py`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py) script useful for this purpose.\n", "my workaround, in case helpful:\n\n(1) Train\n(2) Create nodes to freeze trained weights/biases\n\n```\ndef _freeze(self):\n    regex = re.compile('^[^:]*')\n    with tf.name_scope('assign_ops'):\n       for tvar in tf.trainable_variables():\n           tf.assign(tvar, tvar.eval(),\n                     name = re.match(regex, tvar.name).group(0))\n```\n\n(3) Save graph\n\n```\nwith open(outfile, 'wb') as f:\n    f.write(sesh.graph_def.SerializeToString())\n```\n\n(4) (Later) restore graph and get handles for desired nodes\n\n```\nwith open(graph_def, 'rb') as f:\n    graph_def = tf.GraphDef()\n    graph_def.ParseFromString(f.read())\n\nself.x, self.dropout, self.predictions = tf.import_graph_def(\n    graph_def, return_elements = ['x:0', 'dropout:0', 'predictions:0'],\n    name = '')\n```\n\n(5) Re-assign stored values\n\n```\nwith tf.Session(config = config) as sesh:\n    assign_ops = [op for op in tf.Graph.get_operations(sesh.graph)\n                          if 'assign_ops' in op.name]\n    sesh.run(assign_ops)\n```\n\nNow you can get predictions, etc by feeding test data to `x` placeholder with sesh.run, as per the usj\n", "I encountered the same issue as reported by @Ingwar which is reproducible using the [gist](https://gist.github.com/Ingwar/3b8a7232f4cb906ff1f0)\n\nThe pattern is that both of our graphs use the op `tf.train.ExponentialMovingAverage`.\nAny workaround for this problem?\n", "I have the same problem as http://stackoverflow.com/questions/34343259/is-there-an-example-on-how-to-generate-protobuf-files-holding-trained-tensorflow/34343517#34343517 \n\nI followed some of the instructions of @mrry and @po0ya 's code, and get the .pb file. \nThen I replace the tensorflow_inception_graph.pb, whice is from https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip and used in tensorflow_android_camera, with the new .pb file from the cifar10 model of tensorflow. \n\nI run the tensorflow_android_camera app but there is no output. The error in log is: \n Error during inference: Not found: FeedInputs: unable to find feed output input:0\n\nHere is my code:\ndef save_graph():\ng = tf.Graph()\nvars = {}\nwith g.as_default():\n    with tf.Session() as sess:\n        d = np.ones([1,24,24,3],dtype=np.float32)\n        images, labels = cifar10.distorted_inputs()\n        logits = cifar10.inference(images)\n        init = tf.initialize_all_variables()\n        sess.run(init)\n        saver = tf.train.Saver(tf.trainable_variables(),max_to_keep=0)\n        saver.restore(sess,os.path.join(FLAGS.train_dir, 'model.ckpt'))\n        print (sess.run(logits,{images:d}))\n        for v in tf.trainable_variables():\n            vars[v.value().name] = sess.run(v)\n\ng2 = tf.Graph()\nconsts = {}\nwith g2.as_default():\n    with tf.Session() as sess:\n        for k in vars.keys():\n            consts[k] = tf.constant(vars[k])\n        tf.import_graph_def(g.as_graph_def(),input_map={name:consts[name] for name in consts.keys()})\n        tf.train.write_graph(sess.graph_def,'/home/eli/Documents/TensorflowProjetos/ProtobufFiles','graph.pb',False)\n\nreturn os.path.join('/home/eli/Documents/TensorflowProjetos/ProtobufFiles','graph.pb')\n\nPlease help me ,thank you!\n", "Use keras, they wrap this basic functionality in one line\n", "@lilac I see a similar error when saving a graph that has a batch normalization layer. Tried this with both `0.9` and  `0.10.0rc0`. When loading the saved graph, I get an error: \n\n```\nValueError: graph_def is invalid at node u'BatchNorm/cond/AssignMovingAvg/Switch': Input tensor 'BatchNorm/moving_mean:0' Cannot convert a tensor of type float32 to an input of type float32_ref.\n```\n\nWithout the batch normalization layer (i.e. `tensorflow.contrib.layers.python.layers.batch_norm`) this error is not thrown. Seems related to your problem, as this also contains a moving average.\n", "@axeltidemann Also fighting with this issue right now with. Generated the graph with tensorflow/tensorflow/python/tools/freeze_graph.py and get the following error using my own Batch Norm layer that uses moving average. Running 0.9\n\n```\nInput tensor 'root/cond/root/moments/moments_1/mean/ExponentialMovingAverage:0' Cannot convert a tensor of type float32 to an input of type float32_ref\n```\n\nAnyone figure out a workaround? \n", "Thanks everyone for sharing their experiences and code here. It helped me a lot with my little experiment. I've decided to take this implementation for converting the caffe AlexNet to TensorFlow https://github.com/guerzh/tf_weights . I adapted his implementation to save the graph as pb-file (my modified file can be found here https://github.com/isabel-schwende/TensorFlowCode/blob/master/alexNetSave.py ) It writes a protobuf file to the location that I've specified and the size of the file is as I expected. I verified that the graph looks fine with the Tensorboard tool. However, when I try to use this saved graph I always get the same error about my Variables not being initialised - FailedPreconditionError: Attempting to use uninitialized value Variable_1 -  I've also uploaded a python script that I've used for testing here https://github.com/isabel-schwende/TensorFlowCode/blob/master/alexNetLoad.py . I understand that variables have to be constants to save them but how do I use them later on then? Any help or hints would be highly appreciated, thanks. \n", "Is there a way to solve this issue (unable to import frozen graph with batchnorm) https://github.com/tensorflow/tensorflow/issues/616#issuecomment-235999726\n", "@axeltidemann @bcaine @pavelgonchar The original issue is now closed: please create a new issue for the problem with freezing and batchnorm, and we will assign it appropriately.\n", "raised a new issue https://github.com/tensorflow/tensorflow/issues/3628 for the freezing batchnorm\n", "im sure this is a complex issue,  but there seems to be a lot of problems around  saving/loading models. isnt this one of the fundamental things tensorflow and not the developer should take care of?\n", "I'm having an issue using `freeze_graph.py` on a modified version of the cifar10 example. In short, I get all the root nodes of the graph using `[n.name for n in sess.graph_def.node if '/' not in n.name and n.name != 'init']`, and use that as the `output_node_names` parameter of `freeze_graph`. The freezing appears to work; 30 variables are converted to const ops, with ~100k ops in the final graph. However, upon examining the final protobuf final, there are a bunch of assign ops in the graph. This then leads to a similar problem as @po0ya, where I get\r\n\r\n    ValueError: graph_def is invalid at node u'conv_1/W/Assign': Input tensor 'conv_1/W:0' Cannot convert a tensor of type float32 to an input of type float32_ref.\r\n\r\nupon attempting to import the frozen graph (with no input_map). It seems to me like there are some issues in `convert_variables_to_constants`, specifically the call to `extract_sub_graph`. Going by the comments, these functions should be stripping the graph of assignment nodes; however, judging by my protobuf file and the import call, this is not the case. @mrry, any thoughts?\r\n", "@arcticmatt At a guess you're probably including too many nodes with that list comprehension. Without seeing the whole graph, it's hard to say what node is causing the assign to appear in the extracted subgraph, but I'd recommend being much more selective in your choice of output nodes if possible. If there's still a problem, feel free to open a new issue!", "Why is something that should be so simple, so incredibly complex and failure prone? These are supposed to be checkpoints to protect against failures, not to provoke failures. There should be a simple call to checkpoint everything and another to restore it. The restore should wipe out whatever was in memory before. I've spent hours trying to untangle this mess because I was hoping it would save me re-running a model that crashed. Now I see it is just easier to rerun the model and go see a movie than to make checkpoints work. If it is good, I'll post a movie review - that way you have a backup plan ready when checkpoint recovery fails. :)\r\n", "@codeisnotcode It'd be great if you could share more details of your problem in a Stack Overflow question (if you have questions about how to do something specific) or a new issue (if you think it's a bug, or have a specific feature request). Thanks!\r\n\r\nPS. I'm going to lock this issue to avoid the conversation drifting off-topic. "]}, {"number": 615, "title": "please share a total example from training in python and prediction in C++.", "body": "Hi, TFs\n\nCurrent I'm trying prediction in C++ following the tutorial in tensorflow/tensorflow/g3doc/tutorials/image_recognition/index.md.\n\nI want to train the mode in python, using interface tf.train.write_graph() to write the graph to a file, and then loading it in the C++ for predition, just like the above tutorial. Because there is no python codes in the tutorial and no guides to create the file of \"tensorflow_inception_graph.pb\".\n\nI've tried several times, but failed. Could you share a total example in both sides in pyhton and c++?\n", "comments": ["I tried to evaluate the graph file which is generated by tf.train.write_graph()  in python, fed the required data, then run in session, finally encountered the followng error, the error shows use not initialized value. How to write the initialized value to file by tf.train.write_graph() ?\n\nW tensorflow/core/common_runtime/executor.cc:1076] 0x2672cc0 Compute status: Failed precondition: Attempting to use uninitialized value embedding/W\n     [[Node: embedding/W/read = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](embedding/W)]]\n     [[Node: _recv_dropout_keep_prob_0 = _Recv[client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=4326657343305820101, tensor_name=\"dropout_keep_prob:0\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\nTraceback (most recent call last):\n  File \"/data/wmjiang/tf_workspace/tf/test/20_news_load.py\", line 38, in <module>\n    predictions = sess.run(output, {input_x: data, input_y:label,dropout_prob:1.0})\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 368, in run\n    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 444, in _do_run\n    e.code)\ntensorflow.python.framework.errors.FailedPreconditionError: Attempting to use uninitialized value embedding/W\n     [[Node: embedding/W/read = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](embedding/W)]]\nCaused by op u'embedding/W/read', defined at:\n  File \"/data/wmjiang/tf_workspace/tf/test/20_news_load.py\", line 29, in <module>\n    create_graph()\n  File \"/data/wmjiang/tf_workspace/tf/test/20_news_load.py\", line 26, in create_graph\n    _ = tf.import_graph_def(graph_def, name='')\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/importer.py\", line 232, in import_graph_def\n    compute_shapes=False)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1834, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1043, in __init__\n    self._traceback = _extract_stack()\n", "same problem, please someone tell me how to restore weights from the checkpoint file via c++ \n", "This is probably a question better suited for stackoverflow. Short version: `write_graph` only writes the graph, not the variable content. You need a `Saver`, see for instance:  http://stackoverflow.com/questions/33689598/how-to-pause-resume-training-in-tensorflow/33690809#33690809\n", "@martinwicke I run the loader.cc example and it's okay,\nBut I have one question which enables me to use c++ with my own model.\n\nAfter I load the graph and run the session with inputs I get following error:\n\n```\nAttempting to use uninitialized value Variable_1\n     [[Node: Variable_1/read = Identity[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](Variable_1)]]\n```\n\nAnd the number of variable is changing, 1, 2, 3,...\nI used \n\n```\nstatus = session->Run(inputs, {\"prediction\"}, {\"init_all_vars_op\"}, &outputs);\n```\n\nAs [the tutorial](https://www.tensorflow.org/versions/v0.6.0/api_docs/cc/index.html) I wrote the graph and have the file, but in your previous comment you are saying that the write_graph only saves the architecture, but not the trained model, so:\n1. If this is the case, so how your [Inception model](https://www.tensorflow.org/versions/v0.6.0/tutorials/image_recognition/index.html) tutorial works?? There you only load the graph to the model + labels and the test image. Where is the saved wights there?\n2. If not and you should load the model, then how? \n", "Take a look at python/tools/freeze_graph.py, which takes the contents of\nvariables and saves them to the graph as constants. Then when the graph is\nloaded it comes with all the data.\n\nOn Sun, Feb 14, 2016 at 10:00 AM Hamed notifications@github.com wrote:\n\n> @martinwicke https://github.com/martinwicke I run the loader.cc example\n> and it's okay,\n> But I have one question which enables me to use c++ with my own model.\n> \n> As the tutorial\n> https://www.tensorflow.org/versions/v0.6.0/api_docs/cc/index.html I\n> wrote the graph and have the file, but in your previous comment you are\n> saying that the write_graph only saves the architecture, but not the\n> trained model, so:\n> \n>    1.\n> \n>    If this is the case, so how your Inception model\n>    https://www.tensorflow.org/versions/v0.6.0/tutorials/image_recognition/index.html\n>    tutorial works?? There you only load the graph to the model + labels and\n>    the test image. Where is the saved wights there?\n>    2.\n> \n>    If not and you should load the model, then how?\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/615#issuecomment-183938907\n> .\n", "Thank you very much @martinwicke \n\nAfter looking into documentations, I found that there are few similar methods, can you tell what is the difference between `freeze_graph()` and:\n `tf.train.export_meta_graph` as it has similar parameters, but it seems it can also be used for importing models to C++ (I just guess the difference is that for using the file output by this method you can only use `import_graph_def()` or it's something else?)\n\n Also one question about how to use `write_graph()`:\nIn documentations the `graph_def` is given by `sess.graph_def` but in examples in `freeze_graph()` it is `sess.graph.as_graph_def()`. What is the difference between these two? \n\nThank you!\n", "I think we should take this discussion to stackoverflow. Can you post there and add a link here? We shouldn't abuse the issue tracker for questions. I'll leave this issue open as a feature request for a tutorial on graph import/export.\n", "Yes, of course, here you are @martinwicke : http://stackoverflow.com/questions/35508866/tensorflow-different-ways-to-export-and-run-graph-in-c \n\nBtw, I want to inform you that the `freeze_graph()` didn't work because of lacking `graph_util.convert_variables_to_constants()` method in the wheel installation by pip for Mac. I managed to run it by cloning and building binary. May be I need to open a new issue but I think you will update the wheel soon so I didn't pile a new issue on top of them now :)  \n", "I think a new issue would be good, I don't think we have a fix for this yet.\n\nOn Fri, Feb 19, 2016 at 7:30 AM Hamed notifications@github.com wrote:\n\n> Yes, of course, here you are @martinwicke https://github.com/martinwicke\n> :\n> http://stackoverflow.com/questions/35508866/tensorflow-different-ways-to-export-and-run-graph-in-c\n> \n> Btw, I want to inform you that the freeze_graph() didn't work because of\n> lacking graph_util.convert_variables_to_constants() method in the wheel\n> installation by pip for Mac. I managed to run it by cloning and building\n> binary. May be I need to open a new issue but I think you will update the\n> wheel soon so I didn't pile a new issue on top of them now :)\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/615#issuecomment-186260605\n> .\n", "Which issue you mean? \nAs @vrv said in #1199 he will look for the `graph_util.convert_variables_to_constants()`.\nThe other problem about the difference I think it's only a matter of documentation. \n", "\ud83d\udc4d\nOn Sat, Feb 20, 2016 at 03:17 Hamed notifications@github.com wrote:\n\n> Which issue you mean?\n> As @vrv https://github.com/vrv said in #1199\n> https://github.com/tensorflow/tensorflow/issues/1199 he will look for\n> the graph_util.convert_variables_to_constants().\n> The other problem about the difference I think it's only a matter of\n> documentation.\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/615#issuecomment-186574996\n> .\n", "I've written a (hopefully) self-contained example today: http://stackoverflow.com/a/43639305/1076564", "Hi @peci1, thanks for your helpful post on stackoverflow. However, I tried your solution but it complains\r\n\r\n```\r\nError creating graph: Invalid argument: No OpKernel was registered to support Op 'Const' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n\t [[Node: save/RestoreV2_8/shape_and_slices = Const[_output_shapes=[[1]], dtype=DT_STRING, value=Tensor<type: string shape: [1] values: >]()]]\r\n```\r\n\r\nHow you compile all necessary ops and kernels into the lib?", "@xumengwei Check out my other answer :) https://stackoverflow.com/a/43526252/1076564 . And I'm not sure if it still works with TF 1.4, I had some problems with it. But 1.3 is working for me.", "any recent(improved) methods to train models in Python and make predictions with C++? as now, what is the best method to achieve this? @martinwicke @HamedMP "]}, {"number": 614, "title": "fix wrong variable reference error description", "body": "", "comments": ["Thanks!\n"]}, {"number": 613, "title": "fix typo", "body": "", "comments": []}, {"number": 612, "title": "Keep screen on during camera preview.", "body": "Prevent display off during the demonstration.\n", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I updated my CLA Information.\n", "CLAs look good, thanks!\n\n<!-- ok -->\n"]}, {"number": 611, "title": "A time saving mode to extract the MNIST data", "body": "[tensorflow/tensorflow/examples/tutorials/mnist]\nSince now it takes time to extract gz files even if they are already download on a local machine, why don't we consider an additional mode which saves extract data as binary data? \n\nI submitted the update code of input_data.py and the update first line in run_training(), which is\ndata_sets = input_data.read_data_sets(FLAGS.train_dir, FLAGS.fake_data, fastload = True)\n\nAny opinion?\n\n(James) Sung-Jin Kim\nsungjinkim@fas.harvard.edu\n", "comments": ["Sorry for my sudden proposal. Actually, I am talking about how to improve compatibility with Python and its existing libraries such as Sklearn, Pandas and Pylab family (Numpy/Scipy/Matplotlib). I agree that the recent version of tensorflow python wrapping is so much great. However, if it becomes more compatible with recent machine learning and data processing tools in Python, the solution becomes more familiar with current python users including me. So, the addition of pickle mode in input_data.py is made based on this ideology. \n\nMoreover, I am wondering where my contribution is gone. I updated input_data.py here and submitted it a few days ago but I couldn't find it. Please advice me if there is any mistake I made in code contribution. \n\n(James) Sung-Jin Kim\nsungjinkim@fas.harvard.edu\n", "Looks like this fell through the cracks.  When you say you submitted a contribution, did you make a PR?  There doesn't seem to be any programmatic mention of a contribution here.\n", "@jskDr: Closing for now due to lack of response, but please open if you still have a contribution! \n"]}, {"number": 610, "title": "Issues with running transpose on GPU", "body": "I\u2019m running into a couple of issues with `transpose` on GPUs. First, even the forward computation can\u2019t be registered on a GPU unless I explicitly set the `perm` option. For example this fails (I\u2019m setting `allow_soft_placement=False` in the session `Config`):\n\n```\nwith tf.device('/gpu:0'):\n    a = tf.constant(npr.rand(5, 3).astype('float32'))\n    b = tf.transpose(a)\n```\n\nwith the following error:\n\n```\nInvalidArgumentError: Cannot assign a device to node 'transpose/Reverse': Could not satisfy explicit device specification '/gpu:0'\n[[Node: transpose/Reverse = Reverse[T=DT_INT32, _device=\"/gpu:0\"](transpose/Range, transpose/Reverse/dims)]]\n```\n\nIf however I set `perm=(1, 0)` in the `transpose` operation above, it works. But that\u2019s not the only problem, as the backward computation doesn\u2019t work either way. For example this fails:\n\n```\nwith tf.device('/gpu:0'):\n    a = tf.Variable(tf.random_uniform([5, 3]))\n    b = tf.transpose(a, perm=(1, 0))\n    l = tf.reduce_sum(b)\n    o = tf.train.AdamOptimizer().minimize(l)\n    i = tf.initialize_all_variables()\n\nsess = tf.Session(config=tf.ConfigProto(allow_soft_placement=False))\nsess.run(i)\nsess.run(o)\n```\n\nwith the following error:\n\n```\nInvalidArgumentError: Cannot assign a device to node 'gradients/transpose_grad/InvertPermutation': Could not satisfy explicit device specification '/gpu:0'\n[[Node: gradients/transpose_grad/InvertPermutation = InvertPermutation[_device=\"/gpu:0\"](transpose/perm)]]\n```\n", "comments": ["I think we're just missing some declarations of the GPU kernel of Reverse for int32 here:\n\nhttps://github.com/tensorflow/tensorflow/blob/9c3043ff3bf31a6a81810b4ce9e87ef936f1f529/tensorflow/core/kernels/reverse_op.cc#L148\n\nWhoever fixes this should probably add tests for all supported types here:\n\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/kernel_tests/array_ops_test.py#L45\n", "`Reverse` is not the only thing causing the problem though. In fact the problem with `Reverse` could be circumvented with an explicit `perm`. What can't be circumvented is the `InvertPermutation` error.\n", "InvertPermutation does not currently have a GPU kernel at all. We may be\nable to cheat our way to one with an appropriate HostMemory declaration, or\nwe have to properly implement a GPU kernel. Either way, it would be in\ntranspose_op.cc.\nOn Sat, Dec 26, 2015 at 17:41 Mohammed AlQuraishi notifications@github.com\nwrote:\n\n> Reverse is not the only thing causing the problem though. In fact the\n> problem with Reverse could be circumvented with an explicit term. What\n> can't be circumvented is the InvertPermutation error.\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/610#issuecomment-167374746\n> .\n", "Except for error checking, it's much easier to implement `InvertPermutation` on GPU now that we have code for `tf.scatter` on GPU.  A bit of refactoring would probably let `InvertPermutation` reuse the functors for scatter.\n", "Just had a look at `InvertPermutation` and noticed that a GPU version based on `HostMemory` has been added by now.\nI like the idea of re-using `ScatterFunctor` for this, but it wouldn't check whether there are duplicate permutation indices in the input (which the current version of the code does).\n", "This issue is quite old and hasn't had recent activity. "]}, {"number": 609, "title": "'convolutional.py' considered harmful?", "body": "The [get started page](https://www.tensorflow.org/versions/master/get_started/os_setup.html#source) recommends to run [convolutional.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/mnist/convolutional.py) as the first tensorflow neural net model:\n\n```\n$ cd tensorflow/models/image/mnist\n$ python convolutional.py\n```\n\nHowever, running it brought my machine down. After bringing it up again, the NVIDIA driver didn't work properly anymore (the boot messages showed nvidia-related errors and nvidia-smi became slow). I fixed it by booting into single-user mode and reinstalling the NVIDIA/CUDA drivers.\n\nMy desktop has two GPUs of type GeForce GTX 780 Ti with 3GB memory each.\n\nI assume that `convolutional.py` uses too much GPU memory. Maybe a gentler script should be used in the getting-started manual.\n", "comments": ["A simple way to shave off memory is to replace the giant testset loaded in a constant with a placeholder that gets fed with a small loop at evaluation time. I didn't do that to keep the code as simple as possible, but since several people have commented on having this issue, it might be worth changing it. I'd like confirmation that this would actually fix the problem however; @markusdr would you be able to hack that together and let me know if that solves your problem?\n", "Yes, using fewer images for the validation set and the test set solves the issue. I tested with 500 images for each of the two data sets, and it worked well.\n", "@markusdr  can you share how did you change in the convolutional.py?  \nI run it encounter resource exhausted: OOM\n thanks.\n", "@gotope Here is the diff:\n\n```\n--- a/tensorflow/models/image/mnist/convolutional.py\n+++ b/tensorflow/models/image/mnist/convolutional.py\n@@ -40,7 +40,7 @@ IMAGE_SIZE = 28\n NUM_CHANNELS = 1\n PIXEL_DEPTH = 255\n NUM_LABELS = 10\n-VALIDATION_SIZE = 5000  # Size of the validation set.\n+VALIDATION_SIZE = 500  # Size of the validation set.\n SEED = 66478  # Set to None for random seed.\n BATCH_SIZE = 64\n NUM_EPOCHS = 10\n@@ -126,8 +126,8 @@ def main(argv=None):  # pylint: disable=unused-argument\n     # Extract it into numpy arrays.\n     train_data = extract_data(train_data_filename, 60000)\n     train_labels = extract_labels(train_labels_filename, 60000)\n-    test_data = extract_data(test_data_filename, 10000)\n-    test_labels = extract_labels(test_labels_filename, 10000)\n+    test_data = extract_data(test_data_filename, 500)\n+    test_labels = extract_labels(test_labels_filename, 500)\n\n     # Generate a validation set.\n     validation_data = train_data[:VALIDATION_SIZE, :, :, :]\n```\n", "@markusdr  thanks for share it, it works .\n", "Evals should now be batched, pending propagation of the changes.\nFeel free to reopen if you see more memory issues.\n", "I don't think it's been pushed yet -- will leave it open until it is.\n", "Ok, pushed.\n", "I also had this error, but with a GeForce GTX 660 with 2GB memory. I experimented and was able to successfully test up to 7850 images in the test set. However, after about 5000 images, it would come up with a warning:\n\n```\nW tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 705.73MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\nW tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 2.60GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\n```\n\nI've added this comment just for info, in case there was something more fundamentally wrong. As the GTX 660 nearly processed (7900 images is the  failure point) the test set, I'm not sure why the GTX780 couldn't process the whole 10000 images as it has half again as much memory\n"]}, {"number": 608, "title": "Rescale weights (not gradients) column norms to 1", "body": "How is this possible in TensorFlow, I feel like it should be trivial, but I can't find anything in the API to do this =\\\n\nThis is to rescale the columns of the weight matrix (i.e., input connections).\n\nThanks!\n", "comments": ["I implemented this using a slightly modified version of `clip_by_norm`, which I applied to each weights variable. I then computed these normed weights variables at each update and then ran a loop across the variables calling `assign`. Unfortunately, calling `assign` within a Python loop at each step was a major performance bottleneck and I can't see any op in the API that would allow me to move this update into the graph.\n", "https://www.tensorflow.org/versions/master/api_docs/python/nn.html#l2_normalize , or an equivalent construct? (You should be able to compute the appropriate norm and scale using reductions / elementwise ops, right?)\n", "My apologies, I didn't make it clear, what we usually do is we only normalize if the weight column is > some threshold, i.e., if column norm > threshold, normalize, else do noop. so I dont think that Op will help, or am I mistaken?\n", "There may be a better way to do it, but if I understand correctly, you may be able to use tf.select to do what you want (may not be the most efficient thing to do memory wise).\n\nAssuming:\nw_gradient is the matrix representing the gradients of shape [m, n]\nw_gradient_column is whatever reduction function along the column dimension (shape [1, n])\nw_tensor is the original weight matrix\nw_scaled_tensor is w_tensor with the normalization applied for all columns\n\nFirst you compute which columns to apply the rescaling to\ncondition_per_column = tf.greater(w_gradient_column, threshold)\n\nNext you replicate that value along every row to make a boolean tensor of the same shape as w_tensor\ncondition_tiled = tf.tile(condition_per_column, [m, 1])\n\nLastly, you create a resulting tensor that applies a mask to select the right value from each tensor.\nresult = tf.select(condition_tiled, w_scaled_tensor, w_tensor)\n\nMaybe this still isn't what you want, but hopefully you get the point: you can use tf.select and comparison operators to select/mask results conditionally.\n", "I am going to write a TensorOp for this; in the TensorOp, is it legal to have the .Input() and the .Output() tensor point to the same memory? i.e., I want to do this in-place.\n", "fyi, wrote a kernel for this:\nhttps://github.com/wchan/tensorflow/blob/master/tensorflow/core/kernels/training_ops.cc\n\nsee: \"ApplyMaxWeightColNorm\"\n\ncode needs to be refactored, generalized and tests added before patch can be submitted \"soon\".\n", "I think a custom op for this is overkill.  Just do `matrix * tf.expand_dims(threshold / tf.maximum(threshold, norms), 1)`.  Hmm.  I guess for norms one has to do `tf.sqrt(tf.reduce_sum(tf.square(matrix), 1)` which isn't pretty, but if any new op is added here it should be an L2 norm op (or possibly some extra arguments the existing `L2Loss` op), not a normalization op.\n"]}, {"number": 607, "title": "Fix TensorBoard not displaying any images", "body": "The Convolutional Neural Networks/CIFAR-10 tutorial describes how TensorBoard is able to display preprocessed images that have been output through tf.image_summary. However, when viewing the resulting TensorBoard site, the 'Images' tab displays no images at all, and Chrome reports invalid javascript.\n\nMaking _getRuns a proper function definition as in this commit fixes the syntax error, and results in TensorBoard actually displaying some images in that tutorial.\n", "comments": ["@danmane, @dsmilkov: let us know if this is okay to merge\n", "Can one of the admins verify this patch?\n", "At present this pull request only changes a compiled file (dist/tf-tensorboard.html) but not the corresponding source file (components/tf-image-dashboard/tf-image-grid.html).\n\nPlease change the source as well and then this will be good to merge.\n", "I've updated the pull request's commit so that now components/tf-image-dashboard/tf-image-grid.html is updated in addition to dist/tf-tensorboard.html\n", "@danmane: still looks good?  if so i'll merge\n", "Looks good. Thanks! :)\n"]}]