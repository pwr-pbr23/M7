[{"number": 31645, "title": "i try to run a python code using tensorflow and Mask RCNN but i get that error", "body": "check failed status == cudnn_status_success (7 vs. 0)failed to set cudnn stream\r\n\r\ni am using \r\n\r\ntensorflow  1.14.0\r\ncuda  10.0", "comments": ["Did you download the CUDNN files and place them in the appropriate files in the CUDA folders?", "> Did you download the CUDNN files and place them in the appropriate files in the CUDA folders?\r\nyes, but i got this error\r\n\r\n![Capture](https://user-images.githubusercontent.com/23197541/63125269-8ac62680-bfad-11e9-8a7a-ea7625aeb359.PNG)\r\n\r\n![Capture1](https://user-images.githubusercontent.com/23197541/63125379-d082ef00-bfad-11e9-9182-cf9591f7c59c.PNG)\r\n", "@mhmedeng, \r\nPlease provide details about what platform you are using (operating system, architecture).\r\n\r\nMake sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n", "> @mhmedeng,\r\n> Please provide details about what platform you are using (operating system, architecture).\r\n> \r\n> Make sure you also include the exact command if possible to produce the output included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n> \r\n> We ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n\r\nwindows 7  64 bit\r\nnvidia quadro k1100\r\nprocessor : Intel Core i7 CPU 2.8 GHz\r\ni installed tensorflow-gpu 1.14.0 and cuda 10.0\r\ni am trying to run demo file in samples folder of Mask_RCNN\r\n\r\n![Capture](https://user-images.githubusercontent.com/23197541/63166261-2ac39480-c02e-11e9-9a4b-c5d41f50c17e.PNG)\r\n\r\n", "@mhmedeng,\r\nPlease provide the minimal code to reproduce the issue. Thanks! ", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31645\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31645\">No</a>\n"]}, {"number": 31644, "title": "tf.keras.models.load_model takes forever to load", "body": "**System information**\r\n- Have I written custom code: yes\r\n- OS Platform and Distribution: Windows 10 Version 1607\r\n- TensorFlow installed from: pip\r\n- TensorFlow version:\r\n   - Git-Version: v1.12.1-8794-ge36271a61d\r\n   - version: 1.15.0-dev20190814\r\n- CUDA/cuDNN version: 10.0/7\r\n- GPU model and memory: NVIDIA GTX 1050 Ti, 4096 MB\r\n\r\n**Describe the current behavior**\r\nThe code below produces this output:\r\n```\r\nSave successfull\r\nloading ...\r\nW0815 15:02:11.705600 17844 deprecation.py:506] From C:\\tensorflow_anduin\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCall initializer instance with the dtype argument instead of passing it to the constructor\r\nW0815 15:02:11.706604 17844 deprecation.py:506] From C:\\tensorflow_anduin\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will\r\nbe removed in a future version.\r\nInstructions for updating:\r\nCall initializer instance with the dtype argument instead of passing it to the constructor\r\n```\r\neven after 30 mins it doesn't print the expected output `Load successfull`\r\n\r\n**Describe the expected behavior**\r\nSuccesful loading in under 1 min\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import (Dense, Input, Lambda)\r\nfrom tensorflow.keras.models import Model, Sequential\r\nfrom scipy import sparse\r\nimport numpy as np\r\n\r\n\r\ndef layer_lambda(input_x):\r\n    sparse = input_x[0]\r\n    dense = input_x[1]\r\n    dense = tf.transpose(dense)\r\n    y = tf.sparse.sparse_dense_matmul(sparse, dense)\r\n    return tf.transpose(y)\r\n\r\n\r\ndense_mat = np.eye(30, 30, dtype=np.float32)\r\nsparse_mat = sparse.coo_matrix(dense_mat)\r\nsparse_indices = np.mat([sparse_mat.row, sparse_mat.col]).transpose()\r\nsparse_tensor = tf.SparseTensor(sparse_indices, sparse_mat.data, sparse_mat.shape)\r\n\r\nmodel = Sequential()\r\nmodel_input = Input(shape=(20,))\r\nx = Dense(20)(model_input)\r\nx = Dense(30)(x)\r\nx = Lambda(layer_lambda, output_shape=(None, 30, 30))([sparse_tensor, x])\r\nmodel = Model(model_input, x)\r\n\r\nmodel.predict([[np.ones(20)]])\r\n\r\nmodel.save(\"model.h5\")\r\n\r\nprint(\"Save successfull\")\r\nprint(\"loading ...\")\r\nmodel_load = tf.keras.models.load_model(\"model.h5\", custom_objects={'layer_lambda': layer_lambda})\r\n\r\nprint(\"Load successfull\")\r\n\r\n```\r\n\r\nThis error occurred after fixing [issue 31607](https://github.com/tensorflow/tensorflow/issues/31607).\r\n", "comments": ["I was able to replicate the issue with TF nightly version,kindly find the [gist](https://colab.research.google.com/drive/1sk__Ztrp8qI6YTvgCm2cjgUzv1_veHaP) of colab.Thanks", "Is there a possible fix to this bug?", "Moving all of the sparse ops into the lambda solves this issue:\r\n\r\n```\r\ndef layer_lambda(input_x):\r\n  dense_mat = np.eye(30, 30, dtype=np.float32)\r\n  sparse_mat = sparse.coo_matrix(dense_mat)\r\n  sparse_indices = np.mat([sparse_mat.row, sparse_mat.col]).transpose()\r\n  sparse_tensor = tf.SparseTensor(sparse_indices, sparse_mat.data, sparse_mat.shape)\r\n  dense = input_x\r\n  dense = tf.transpose(dense)\r\n  y = tf.sparse.sparse_dense_matmul(sparse_tensor, dense)\r\n  return tf.transpose(y)\r\n\r\nmodel = Sequential()\r\nmodel_input = Input(shape=(20,))\r\nx = Dense(20)(model_input)\r\nx = Dense(30)(x)\r\nx = Lambda(layer_lambda, output_shape=(None, 30, 30))(x)\r\nmodel = Model(model_input, x)\r\n```\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31644\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31644\">No</a>\n"]}, {"number": 31643, "title": "ImportError: DLL load failed: The specified module could not be found.", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Microsoft Windows 10 Pro\r\n10.0.18362 Build 18362\r\n\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 1.14.0\r\n- Python version: 3.6.6 virtual interpreter\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: 9.0\r\n- GPU model and memory: NVIDIA GeForce GTX 1050 Ti\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n- Note: The usage of -> short for linked to.\r\n- Downloaded and installed CUDA/cuDNN 9.0\r\n- Downloaded and installed 10.0 (needed 10 for cudart64_100.dll) as per error message PyCharm 2019.1.3 (Professional Edition) 'cudart64_100.dll was not found' along those lines.\r\n- Downloaded a copy of cudnn64_7.dll from the cuDNN Library and pasted into ../v9.0/bin folder\r\n- Update windows environment paths as per recommendation https://www.tensorflow.org/install/gpu and as per issue/10033\r\n- Found the issue where a user was recommended to run Scratch.py file via PyCharm \r\n[stratch-py.txt](https://github.com/tensorflow/tensorflow/files/3504373/stratch-py.txt)\r\n- Installed protobuf 3.6.0 as per issues/28389 -> issues/28389 -> issues/25072\r\n- Unsure if I have non-avx cpu and require non-avx built wheel as per issues/28389 -> issues/28389 -> issues/25072\r\n    - Processor\tIntel(R) Core(TM) i7-7700HQ CPU @ 2.80GHz, 2801 Mhz, 4 Core(s), 8 LogPro's\r\n- Removed CUDA/cuDNN version 10.0 (see log file removed-cuda-10-0) as per issues/22872\r\n    - Copied cudart64_100.dll to ../v9.0/bin folder\r\n    - Re-updated environment paths:\r\n        - C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\bin\r\n        - C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\extras\\CUPTI\\libx64\r\n        - C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\include\r\n        - C:\\tools\\cuda\\bin\r\n- Upgraded from 3.6.6 to 3.6.8 as per issues/29575\r\n- Removed tensorflow-gpu and tensorflow-gpu-graphics from pycharm project interpreter settings. \r\n    - [output-scratch-py-minus-gpu.txt](https://github.com/tensorflow/tensorflow/files/3505544/output-scratch-py-minus-gpu.txt)\r\n    - pip install tensorflow==1.14.0\r\n- Updated the project interpreter to 3.6.8 non virtual interpret via pycharm\r\n    - See output post-updated-pycharm-interp-3.6.8\r\n    - Also current-project-interp-pkgs\r\n\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n[pycharm-project-interpreter-pkgs.txt](https://github.com/tensorflow/tensorflow/files/3505376/pycharm-project-interpreter-pkgs.txt)\r\n[cli-python-import-tensorflow.txt](https://github.com/tensorflow/tensorflow/files/3504377/cli-python-import-tensorflow.txt)\r\n[tensorflow-log.txt](https://github.com/tensorflow/tensorflow/files/3504340/tensorflow-log.txt)\r\n[pydev-debugger.txt](https://github.com/tensorflow/tensorflow/files/3504349/pydev-debugger.txt)\r\n[removed-cuda-10-0.txt](https://github.com/tensorflow/tensorflow/files/3505369/removed-cuda-10-0.txt)\r\n[stack-trace.pdf](https://github.com/tensorflow/tensorflow/files/3505474/stack-trace.pdf)\r\n[stack-trace-with-debug.pdf](https://github.com/tensorflow/tensorflow/files/3505483/stack-trace-with-debug.pdf)\r\n[post-updated-pycharm-interp-3.6.8.pdf](https://github.com/tensorflow/tensorflow/files/3505572/post-updated-pycharm-interp-3.6.8.pdf)\r\n[current-project-interp-pkgs.txt](https://github.com/tensorflow/tensorflow/files/3505581/current-project-interp-pkgs.txt)\r\n\r\n\r\n", "comments": ["@tcratius In reference to GitHub issue https://github.com/tensorflow/tensorflow/issues/22872, The user was installing TF 1.11 thus asked to switch to cuda 9 and not cuda 10.0\r\nHowever in your case you should install cuda 10.0 and not cuda 9.0.\r\nTF 1.13 and above support cuda 10.0\r\nSee https://www.tensorflow.org/install/gpu#software_requirements\r\nPlease update your environment paths to cuda 10", "Sorry about that @ymodak, tried to be thorough, but totally missed that.  I have installed cuda_10.0.130_win10_network.exe and ran the scratch file both in PyCharm and Command-Line both produce:\r\n\r\nThe installed version of TensorFlow includes GPU support.\r\n- Python version is 3.6.\r\n- TensorFlow is installed at: C:\\Users\\Two_Oriel\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\r\n- msvcp140.dll Found at C:\\Windows\\System32\\msvcp140.dll\r\n- Could not load 'cudart64_90.dll'. Download and install CUDA 9.0 from\r\n  this URL: https://developer.nvidia.com/cuda-toolkit\r\n- nvcuda.dll found at C:\\Windows\\System32\\nvcuda.dll\r\n- cuDNN Found at C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\bin\\cudnn64_7.dll\r\nProcess finished with exit code -1\r\n", "Looks like that fixed it, only warnings now and can handle that. Now just have to remember what it was that I was trying to learn. Such is life.\r\n[app-py.txt](https://github.com/tensorflow/tensorflow/files/3508771/app-py.txt)\r\n[app-py-log.txt](https://github.com/tensorflow/tensorflow/files/3508787/app-py-log.txt)\r\n", "Are you satisfied with the resolution of your issue?\r\n[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)\r\n[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)"]}, {"number": 31642, "title": "How can I use tensorflow2.0 beta1 multiple GPUs one computer to write a GAN code?", "body": "def main():\r\n    def G_D_fn(train_data):  \r\n        with tf.GradientTape() as tape:\r\n            generates = G(train_data)  \r\n            print(generates) \r\n            print(\"!!!!!!!!!!!!!!!!!\")\r\n            logits_fake = D(generates)   #error here, but if I do not use multiple GPUs, the program is normal.\r\n\r\n with strategy.scope():\r\n      # obtain models\r\n      G = get_G((batch_size, None, None, 3)) #(batch_size, 128, 128, 3)\r\n      D = get_D((batch_size, None, None, 3)) \r\n      train_dataset = get_data()\r\n      train_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\r\n     for epoch in range(10):\r\n          for one_batch in train_dist_dataset:\r\n              per_loss = strategy.experimental_run_v2(G_D_fn, args=(epoch, batch_data, ))\r\n\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 680, in <module>\r\n    train()\r\n  File \"train.py\", line 319, in train\r\n    per_d_loss, per_g_loss, per_d_loss1, per_d_loss2, per_g_gan_loss, per_mse_loss, per_vgg_loss, per_style_loss = strategy.experimental_run_v2(G_D_fn, args=(epoch, batch_data, ))\r\n  File \"/home/dongwen/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 708, in experimental_run_v2\r\n    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n  File \"/home/dongwen/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 1710, in call_for_each_replica\r\n    return self._call_for_each_replica(fn, args, kwargs)\r\n  File \"/home/dongwen/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/distribute/mirrored_strategy.py\", line 708, in _call_for_each_replica\r\n    fn, args, kwargs)\r\n  File \"/home/dongwen/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/distribute/mirrored_strategy.py\", line 195, in _call_for_each_replica\r\n    coord.join(threads)\r\n  File \"/home/dongwen/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/training/coordinator.py\", line 389, in join\r\n    six.reraise(*self._exc_info_to_raise)\r\n  File \"/home/dongwen/anaconda3/envs/tf2/lib/python3.7/site-packages/six.py\", line 693, in reraise\r\n    raise value\r\n  File \"/home/dongwen/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\r\n    yield\r\n  File \"/home/dongwen/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/distribute/mirrored_strategy.py\", line 189, in _call_for_each_replica\r\n    **merge_kwargs)\r\n  File \"/home/dongwen/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/training/moving_averages.py\", line 105, in merge_fn\r\n    return update(strategy, v, value)\r\n  File \"/home/dongwen/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/training/moving_averages.py\", line 96, in update\r\n    return strategy.extended.update(v, update_fn, args=(value,))\r\n  File \"/home/dongwen/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py\", line 1458, in update\r\n    return self._update(var, fn, args, kwargs, group)\r\n  File \"/home/dongwen/anaconda3/envs/tf2/lib/python3.7/site-packages/tensorflow/python/distribute/mirrored_strategy.py\", line 758, in _update\r\n    assert isinstance(var, values.DistributedVariable)\r\nAssertionError\r\n\r\n", "comments": ["In reference to the gpu tutorial found [here](https://www.tensorflow.org/beta/guide/using_gpu#using_multiple_gpus) you can run multiple gpus by wrapping each individual model call in their own tf.device('gpu:x'): setup. For example:\r\n```\r\nwith tf.device('gpu:0'):\r\n    generator(noise)\r\nwith tf.device('gpu:1'):\r\n    discriminator(images)\r\n```\r\nThis is a rough example, but is how you would do it. I don't know if mirrored strategy works right now with a custom loop, but also take a look at that. ", "I just tried it. The error is as follows:\r\n        with tf.GradientTape(persistent=True) as tape:\r\n            with tf.device('/gpu:0'):\r\n                generates = G(train_data) \r\n            with tf.device('/gpu:1'): \r\n                logits_fake = D(generates) \r\n2019-08-16 10:55:59.977308: W tensorflow/core/framework/op_kernel.cc:1546] OP_REQUIRES failed at nccl_ops.cc:100 : Unknown: Error invoking NCCL: unhandled cuda error\r\n2019-08-16 10:55:59.977378: W tensorflow/core/common_runtime/base_collective_executor.cc:216] BaseCollectiveExecutor::StartAbort Unknown: Error invoking NCCL: unhandled cuda error\r\n\t [[{{node NcclAllReduce}}]]\r\n\r\nMy code as follows:\r\n    def G_D_fn(epoch, batch_data):\r\n       train_data = batch_data   \r\n        with tf.GradientTape(persistent=True) as tape:\r\n            with tf.device('/gpu:0'):\r\n                generates = G( train_data) \r\n            with tf.device('/gpu:1'): \r\n                logits_fake = D(generates) \r\n       ##logits_fake = D(generates)\r\n            feature_fake = VGG((generates+1)/2.)   #If I use vgg, it works normal. If I use D, it has error.\r\n            d_loss = tl.cost.sigmoid_cross_entropy(logits, tf.ones_like(logits_fake))\r\n            g_gan_loss = 1e-3 * tl.cost.sigmoid_cross_entropy(logits_fake, tf.ones_like(logits_fake))\r\n        grad = tape.gradient(g_loss, G.trainable_weights)\r\n        g_optimizer.apply_gradients(zip(grad, G.trainable_weights))\r\n     \r\n        grad = tape.gradient(d_loss, D.trainable_weights)\r\n        d_optimizer.apply_gradients(zip(grad, D.trainable_weights))\r\n        return d_loss, g_gan_loss\r\n\r\n\r\n    print(\"Begin training...\")\r\n    devices = ['/device:GPU:{}'.format(i) for i in range(num_gpu)] \r\n    strategy = tf.distribute.MirroredStrategy(devices)\r\n    with strategy.scope():\r\n        train_log_dir = 'logs/gradient_tape/train'\r\n        train_summary_writer = tf.summary.create_file_writer(train_log_dir)\r\n        # obtain models\r\n        G = get_G((batch_size, None, None, 3))\r\n        D = get_D((batch_size, None, None, 3)) \r\n        VGG = tl.models.vgg19(pretrained=True, mode='static') \r\n        lr_v = tf.Variable(lr_init)\r\n        g_optimizer_init = tf.optimizers.Adam(lr_v, beta_1=beta1)\r\n        g_optimizer = tf.optimizers.Adam(lr_v, beta_1=beta1)\r\n        d_optimizer = tf.optimizers.Adam(lr_v, beta_1=beta1)\r\n    \r\n        G.train()\r\n        D.train()\r\n        VGG.train()\r\n    \r\n        train_ds = get_train_data()\r\n        dist_train_ds = strategy.experimental_distribute_dataset(train_ds)\r\n\r\n        n_batch_epoch = round(n_epoch // batch_size)  \r\n        for epoch in range(n_epoch):    \r\n            total_mse_loss = 0.0\r\n            batch = 0\r\n            for batch_data in dist_train_ds:\r\n                batch += 1                 \r\n                per_d_loss, per_g_gan_loss = strategy.experimental_run_v2(G_D_fn, args=(epoch, batch_data, ))\r\n                total_d_loss += strategy.reduce(tf.distribute.ReduceOp.SUM, per_d_loss, axis = 0)\r\n                total_g_gan_loss += strategy.reduce(tf.distribute.ReduceOp.SUM, per_g_gan_loss, axis = 0)\r\n    \r\n            d_loss = total_d_loss/batch\r\n            g_gan_loss = total_g_gan_loss/batch\r\n\r\n            print(\"g_gan:{:.6f}, d_loss: {:.9f}\".format(g_gan_loss, d_loss))\r\n\r\n", "@YonghuiXu Will it be possible to provide the complete and proper indent code to reproduce the reported issue. Thanks! ", "Is it not possible to calculate the logits_fake and logits_real here for Tensorflow 2.0 beta?\r\n\r\n\r\n\r\n\r\n------------------ \u539f\u59cb\u90ae\u4ef6 ------------------\r\n\u53d1\u4ef6\u4eba: \"gadagashwini\"<notifications@github.com>; \r\n\u53d1\u9001\u65f6\u95f4: 2019\u5e748\u670816\u65e5(\u661f\u671f\u4e94) \u4e0b\u53485:28\r\n\u6536\u4ef6\u4eba: \"tensorflow/tensorflow\"<tensorflow@noreply.github.com>; \r\n\u6284\u9001: \"\u59d0\u59b9\u7684\u6d77\u6d0b\"<2259949930@qq.com>; \"Mention\"<mention@noreply.github.com>; \r\n\u4e3b\u9898: Re: [tensorflow/tensorflow] How can I use tensorflow2.0 beta1multiple GPUs one computer to write a GAN code? (#31642)\r\n\r\n\r\n\r\n\r\n@YonghuiXu Will it be possible to provide the complete and proper indent code to reproduce the reported issue. Thanks!\r\n \r\n\u2014\r\nYou are receiving this because you were mentioned.\r\nReply to this email directly, view it on GitHub, or mute the thread.", "Hi,@gadagashwini @Slushy. I have find the problem.There are BatchNorm layers in my discriminator. When I delete them, the program can work. Or when I didn't use tf.distribute.MirroredStrategy, the program can work. Do tf.distribute.MirroredStrategy permit batch norm ?", "@YonghuiXu Please Provide us the reproducible code. It will indeed help us to move faster.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31642\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31642\">No</a>\n"]}, {"number": 31641, "title": "How can I use multiple GPUs one computer to write a GAN code?", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": []}, {"number": 31640, "title": "Update serialization.py", "body": "import dense_attention  to void \"ValueError: Unknown layer: Attention\"", "comments": ["Can one of the admins verify this patch?", "I think the same code has been already added in head now. Closing this PR since is no longer needed."]}, {"number": 31639, "title": "There is a patch in the Eigen dir. Any plan to update it to a new commit?", "body": "I'm compiling a project with TensorFlow and Eigen and I need to use the same version Eigen source code as TensorFlow. But I found there is a git patch in the TensorFlow's Eigen dir.  I don't know which commit of Eigen I should use Bazel to download. Any plan to update the Eigen to a new commit?\r\nThanks!\r\n", "comments": ["Does it seem like the official Eigen commits don't have already merged this patch?", "We track Eigen head pretty close, current revision is `8071cda5714d` https://github.com/tensorflow/tensorflow/blob/master/tensorflow/workspace.bzl#L178.\r\n\r\nAre you talking about https://github.com/tensorflow/tensorflow/blob/master/third_party/eigen3/gpu_packet_math.patch? That one should probably go into Eigen main repo, if you can prepare a PR to Eigen bitbucket, you can assign it to http://bitbucket.org/rmlarsen and TF will pick it up this or next week.", "Based https://bitbucket.org/eigen/eigen/commits/ on we are just 1 commit away from head", "Thanks for your reply!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31639\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31639\">No</a>\n"]}, {"number": 31638, "title": "Mask is not propagated into Sequential keras layers", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS\r\n- TensorFlow installed from (source or binary): docker, pip\r\n- TensorFlow version (use command below): 1.14.0, 2.0.0b\r\n- Python version: 3.6.8\r\n\r\n**Describe the current behavior**\r\n\r\nWhen a masked input is fed to a `tf.keras.models.Sequential`, the mask is ignored\r\n\r\n**Describe the expected behavior**\r\n\r\nI would expect the mask to be propagated as if the inner layers were not in a `Sequential` layer.\r\n\r\n**Code to reproduce the issue**\r\n\r\nThis works:\r\n```\r\nimport tensorflow as tf\r\n\r\ndef check_mask(inputs, mask=None):\r\n    assert mask is not None\r\n    return inputs\r\n\r\nmodel = tf.keras.models.Sequential([\r\n    tf.keras.layers.Masking(0, input_shape=[1]),\r\n    tf.keras.layers.Lambda(check_mask)\r\n])\r\n```\r\n\r\nThis fails due to failed assert:\r\n```\r\nimport tensorflow as tf\r\n\r\ndef check_mask(inputs, mask=None):\r\n    assert mask is not None\r\n    return inputs\r\n\r\nmodel = tf.keras.models.Sequential([\r\n    tf.keras.layers.Masking(0, input_shape=[1]),\r\n    tf.keras.models.Sequential([\r\n        tf.keras.layers.Lambda(check_mask),\r\n    ]),\r\n])\r\n```\r\n\r\n**Other info / logs**\r\nI think I have narrowed this down to a cache invalidation issue in `tf.keras.layers.Layer._should_compute_mask`: https://github.com/tensorflow/tensorflow/blob/e19c354920c3b246dda6598229210a582caaa1a9/tensorflow/python/keras/engine/base_layer.py#L2055-L2059\r\n\r\nFrom my debugging, it seems that whenever the issue above appears `_should_compute_mask` is cached as false even though evaluating the actual property expression results in true.\r\n\r\nSince this problem is in a base layer, this issue might be affecting other layers as well.", "comments": ["I was able to replicate the issue for given code in both TF versions- 1.14 and 2.0beta. Thanks", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31638\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31638\">No</a>\n", "Was able to reproduce the issue with [TF v2.1](https://colab.research.google.com/gist/amahendrakar/19fd10326257085b09f137049681b6be/2-1-template.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/bbd1ef55fd48d1851f0b984a5513429c/tf-nightly.ipynb#scrollTo=ieAW-NK5iqpf) i.e. v2.2.0-dev20200327. Please find the attached gist. Thanks!", "@mpdn Closing this issue as it is fixed in TF 2.x. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31638\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31638\">No</a>\n"]}, {"number": 31637, "title": "gradient accumulation for very large embeddings", "body": "**System information**\r\n- TensorFlow version (you are using): 1.12\r\n- Are you willing to contribute it (Yes/No): yes, but don't know how.\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\n**Will this change the current api? How?**\r\nIt certainly will add some new apis. Currently, in a distributed environment, we can use `tf.contrib.opt.AGNOptimizer` class to do gradient accumulation. However this optimizer converts all gradients (Tensor or IndexedSlices) to dense types which consumes quite large memory. In certain scenarios, say we've got some very large embedding variables which can't fit into one single machine, this would cause OOM on workers.\r\n\r\n**Who will benefit with this feature?**\r\nAnyone who has some very large variables in their models, and want to use gradient accumulation to accelerate training.\r\n\r\n**Any Other info.**\r\nNone.", "comments": ["Do you have any use case that requires the feature you are interested in? Please feel free to submit a PR if you have use cases that supports that feature.Thanks!", "@AdrianYu Can you try recent TF versions and see whether the OOM issues persists. There were lot of improvements more recently. Please let us know what you think? Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 31636, "title": "Masked GlobalAveragePooling1D fails when size of step axis is not known statically", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 1.14.0, 2.0.0b\r\n- Python version: 3.6.8\r\n\r\n**Code to reproduce the issue**\r\n\r\nThis code:\r\n```\r\nimport tensorflow as tf\r\ninput = tf.keras.layers.Input([None, 32])\r\nmask = tf.keras.layers.Input([None], dtype=tf.bool)\r\ntf.keras.layers.GlobalAveragePooling1D()(input, mask)\r\n```\r\n\r\nFails with this exception:\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 662, in __call__\r\n    outputs = call_fn(inputs, *args, **kwargs)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/keras/layers/pooling.py\", line 643, in call\r\n    mask = array_ops.reshape(mask, broadcast_shape)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 7715, in reshape\r\n    \"Reshape\", tensor=tensor, shape=shape, name=name)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 530, in _apply_op_helper\r\n    raise err\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 527, in _apply_op_helper\r\n    preferred_dtype=default_dtype)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1237, in internal_convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 305, in _constant_tensor_conversion_function\r\n    return constant(v, dtype=dtype, name=name)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 246, in constant\r\n    allow_broadcast=True)\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 284, in _constant_impl\r\n    allow_broadcast=allow_broadcast))\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/tensor_util.py\", line 563, in make_tensor_proto\r\n    \"supported type.\" % (type(values), values))\r\nTypeError: Failed to convert object of type <class 'list'> to Tensor. Contents: [-1, None, 1]. Consider casting elements to a supported type.\r\n```\r\n\r\nI would expect masked global average pooling to be no different than regular global average pooling (where unknown step axis is supported) \r\n\r\nI think this is caused by the two lines here: https://github.com/tensorflow/tensorflow/blob/e19c354920c3b246dda6598229210a582caaa1a9/tensorflow/python/keras/layers/pooling.py#L641-L642\r\n\r\nInstead of finding the broadcast shape using `as_list` it should use the shape tensor directly and `tf.concat` them together (or whatever is an appropriate equivalent in the keras library).", "comments": ["Was able to replicate the issue on Colab with Tensorflow 2.0.0.beta1. Please see the gist [here](https://colab.sandbox.google.com/drive/1AijetZx2ofPuBztdlKovFiC7ZpiT2QFs#scrollTo=l9gPx9dqn4Uu). Thanks!", "Had the same issue when using masking and `GlobalAveragePooling1D` with the Keras `Sequential`. \r\n\r\nFor anyone else running into this - it is fixed in `v2.1.0-rc0` and later versions.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/9837eceb39171aba9e28dc1f120f53271b6b1ef0/tensorflow/python/keras/layers/pooling.py#L642-L643", "@mpdn As mentioned by @vsimkus, this issue was resolved in latest version. Please take a look at the [gist](https://colab.sandbox.google.com/gist/jvishnuvardhan/42a3edc1d4fc4e771b0417e5f2b2675c/tf31636.ipynb) for your reference. Thanks!\r\n\r\nI am closing this issue as it was resolved. Please feel free to open if the issue persists again. thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31636\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31636\">No</a>\n", "Yes, it is fixed in 2.1, while the issue still persists in 2.0.1.\r\n\r\nAnd if I upgrade to 2.1, my model cannot predict since 'Error when checking model input'.\r\n\r\nThe issue can be reproduced with tf 2.1 by \r\nhttps://colab.research.google.com/drive/1hMLd5-r82FrnFnBub-B-fVW78Px4KPX1\r\n\r\nAnyone can fix it?\r\n\r\nThanks"]}, {"number": 31635, "title": "Make it easier to build the dataset pipeline in Dataset C++ tests", "body": "This PR aims to simplify the code of making the dataset pipeline in Dataset C++ tests using the following style:\r\n```C++\r\nauto* source_dataset_params = new RangeDatasetParams(...);\r\nauto* target_dataset_params = source_dataset_params->Batch(...)->Map(...)->...->...;\r\n// Handles all the allocated dataset_params (source_dataset_params, batch_dataset_params, map_dataset_params, ... , target_dataset_params)\r\ncore::ScopedUnref scoped_unref(target_dataset_params); \r\nTensor target_dataset;\r\nMakeDatasetTensor(target_dataset_params, &target_dataset);\r\n...\r\n...\r\n\r\n```\r\nOne example is as below\r\n```C++\r\n// The ownership is transferred to the caller.\r\nMapDatasetParams* MapDatasetParams() {\r\n  auto* range_dataset_params = new RangeDatasetParams(10, 0, -3);\r\n  return range_dataset_params\r\n      ->Batch(\r\n          /*batch_size=*/2,\r\n          /*drop_remainder=*/false,\r\n          /*parallel_copy=*/true,\r\n          /*output_dtypes=*/{DT_INT64},\r\n          /*output_shapes=*/{PartialTensorShape({2})},\r\n          /*node_name=*/\"batch_node\")\r\n      ->Map(\r\n          /*other_arguments=*/{},\r\n          /*func=*/\r\n          FunctionDefHelper::FunctionRef(\"XAddX\", {{\"T\", DT_INT64}}),\r\n          /*func_lib=*/{test::function::XAddX()},\r\n          /*type_arguments=*/{},\r\n          /*output_dtypes=*/{DT_INT64},\r\n          /*output_shapes=*/{PartialTensorShape({1})},\r\n          /*use_inter_op_parallelism=*/true,\r\n          /*preserve_cardinality=*/false,\r\n          /*node_name=*/kNodeName);\r\n}\r\n```", "comments": ["@jsimsa The first commit (https://github.com/tensorflow/tensorflow/pull/31635/commits/79b55fd17b055c4a17737de87db6e0667685e2e5) is as same as #31592, which you have reviewed and is pending for merge. You can just review the second commit (https://github.com/tensorflow/tensorflow/pull/31635/commits/08ebb28d857e425134485487e3c65aeb38f0631c).", "@jsimsa Thanks for your suggestion! Now `RefCounted` is replaced by the smart pointer and the static factory methods are added as below. Could you please have a look at the changes (https://github.com/tensorflow/tensorflow/pull/31635/commits/50624183a1e6c92546c268687afc6c6c817f8777) when you get a chance?\r\n```C++\r\nstatic std::shared_ptr<BatchDatasetParams> Batch(\r\n    std::shared_ptr<DatasetParams> input_dataset_params, ...);\r\n\r\nstatic std::shared_ptr<MapDatasetParams> Map(\r\n    std::shared_ptr<DatasetParams> input_dataset_params, ...) ;\r\n\r\nstatic std::shared_ptr<RangeDatasetParams> Range(int64 start, int64 stop, int64 step);\r\n```\r\n------------------------------------------------\r\n\r\n**Updates:**\r\n\r\n[class DatasetParamsBuilder](https://github.com/tensorflow/tensorflow/pull/31635/commits/53dcdf7da81d6715567047f72466268146e9d4ae#diff-a4a3b8bfea4ac6f0185c2a132dadbb8bR181) is added to simplify the building of the dataset pipeline. Compared with the static factory methods, the builder class brings a few benefits:\r\n1. easy to chain multiple dataset params like Python API;\r\n2. no need to explicitly create the DatasetParams objects one by one;\r\n3. do not use the smart pointer type in the public APIs.  \r\n4. automatically generate the node name for each dataset op in the pipeline without worrying about the name conflicts.\r\n\r\nOne example:\r\n```C++\r\nauto batch_dataset_params =\r\n      DatasetParamsBuilder()\r\n          .Range(/*start=*/0,\r\n                 /*stop=*/12,\r\n                 /*step=*/1)\r\n          .Batch(/*batch_size=*/4,\r\n                 /*drop_remainder=*/false,\r\n                 /*parallel_copy=*/true,\r\n                 /*output_dtypes=*/{DT_INT64},\r\n                 /*output_shapes=*/{PartialTensorShape({4})})\r\n          .GetDatasetParams<BatchDatasetParams>();\r\n```\r\n@jsimsa Which style do you think is better (the static factory methods v.s. DatasetParamsBuilder)?\r\n", "Can one of the admins verify this patch?", "@jsimsa Thanks for your review! The smart pointers are removed and all the members in DatasetParams are changed to be private. Could you please have a loot at the changes (https://github.com/tensorflow/tensorflow/pull/31635/commits/55afc02a147669a25e462abfafa684b9103476fa) when you get a chance?", "@jsimsa Thanks for your suggestions! The comments are addressed here(https://github.com/tensorflow/tensorflow/commit/26d82644d52001f3d49246baa9094606688f2096). Also, clean up `DatasetOpsTestBaseV2` a little bit so that the derived test classes do not need to override any functions, e.g. `Initialize()` and `MakeDatasetOpKernel`. Could you please have another look when you have time?", "Thanks @rachellim for your review and help! Most of the comments are addressed here (https://github.com/tensorflow/tensorflow/pull/31635/commits/015b45e95dac3047060f698b959083a4dcc6e2b4) except this one (https://github.com/tensorflow/tensorflow/pull/31635#discussion_r320406144). Will do it once we get the answer from @jsimsa. ", "@rachellim All the comments are addressed now (https://github.com/tensorflow/tensorflow/pull/31635/commits/321e8cdf098d6a5b5645a9e3bbff0e0f6f223caf). Could you please take another look when you get a chance?", "> I'd suggest making everything consistent to _have_ a space after the colon, not removing the space from everything.\r\n\r\nGotcha. Will change them\r\n", "Thanks for your changes!", "Thanks for the very prompt review, @rachellim! This commit (https://github.com/tensorflow/tensorflow/pull/31635/commits/2bf79a761656e3c64fbaeead39e63e41fd492255) is submitted to address the comments. Please take a look!\r\n\r\n-------------------------------------------\r\nAlso, `MapAndBatchDatasetOpTest` and `SamplingDatasetOpTest` (which are using `DatasetOpsTestBaseV2`) are refactored to be the latest format (https://github.com/tensorflow/tensorflow/pull/31635/commits/3d62a7b90f497813589864b8f8ef30fb5de6e40e).\r\n", "The internal checks failed. Could you help check the logs and paste them here?", "internal tests are still running", "@jsimsa The internal checks are in the failed status. Could you please help check the logs?", "```\r\n./third_party/tensorflow/core/kernels/data/dataset_test_base.h:132:3: error: 'tensorflow::data::DatasetParams' has virtual functions but non-virtual destructor [-Werror,-Wnon-virtual-dtor]\r\n  ~DatasetParams() {}\r\n  ^\r\n./third_party/tensorflow/core/kernels/data/dataset_test_base.h:184:7: error: 'tensorflow::data::RangeDatasetParams' has virtual functions but non-virtual destructor [-Werror,-Wnon-virtual-dtor]\r\nclass RangeDatasetParams : public DatasetParams {\r\n      ^\r\n./third_party/tensorflow/core/kernels/data/dataset_test_base.h:208:7: error: 'tensorflow::data::BatchDatasetParams' has virtual functions but non-virtual destructor [-Werror,-Wnon-virtual-dtor]\r\nclass BatchDatasetParams : public DatasetParams {\r\n      ^\r\n./third_party/tensorflow/core/kernels/data/dataset_test_base.h:245:7: error: 'tensorflow::data::MapDatasetParams' has virtual functions but non-virtual destructor [-Werror,-Wnon-virtual-dtor]\r\nclass MapDatasetParams : public DatasetParams {\r\n```", "@jsimsa The virtual destructor is added [here](https://github.com/tensorflow/tensorflow/pull/31635/commits/b0040a837c27bbd81e5f0033b4cd493a8f2513a9) and also update some places to use the named constant. Could you please take another look when you get a chance?", "@rthadur An error happed while migrating the change to the internal checks. Could you help retrigger the internal checks? Thanks!", "done", "Thanks very much for your help on this PR, @jsimsa @rachellim @rthadur !"]}, {"number": 31634, "title": "Custom OP using eigen matrix", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Win 10 pro\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 1.13.1\r\n- Python version: 3.6.7\r\n- Installed using virtualenv? pip? conda?: from source\r\n- Bazel version (if compiling from source): 0.21.0\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: cuda 10.0 cudnn 7.6.2\r\n- GPU model and memory:ROG strix geforce gtx 1080Ti, 11G\r\n\r\n\r\n\r\n**Describe the problem**\r\nI'm trying to develop a Tensorflow custom op using cuda. And inside the op, I need to use Eigen to run some matrix operations, but when I try to calculate the inverse of a size 8*8 matrix, I've encountered several problems.\r\n\r\nThis function is written in CUDA kernel.\r\nIn cuda kernel function file (.cu.cc), I have included\r\n```c++\r\n#include <Eigen\\Dense>\r\n#include <Eigen/LU>\r\n#include \"third_party/eigen3/unsupported/Eigen/CXX11/Tensor\"\r\n#include \"tensorflow/core/framework/op.h\"\r\n#include \"tensorflow/core/framework/op_kernel.h\"\r\n#include <stdio.h>\r\n#include <math.h>\r\n```\r\nAnd in the kernel function, I just tried a simple test:\r\n```c++\r\ntypedef Eigen::Matrix<float, 8, 8> Matrix8f;\r\n\r\n__global__ void CsmToRcmKernel(Eigen::Map<const Eigen::MatrixXcf> csm_map, Eigen::Map<const Eigen::VectorXf> reg_vec,\r\n    Eigen::Map<const MatrixXi16> offset8,       // (12160, 8, 3)\r\n    Eigen::Map<const MatrixXi16> offset3,       // (9728, 3, 3)\r\n    Eigen::Map<const MatrixXi16> offset4,       // (12160, 4, 3)\r\n    Eigen::Map<const MatrixXi16> offset6,       // (9728, 6, 3)\r\n    Eigen::Map<Eigen::MatrixXcf> rcm_map) {\r\n\r\n    Matrix8f A = MatrixXf::Identity(8, 8);\r\n    A(0, 0) = 2;\r\n\r\n    // inv_A = inv(A);\r\n    Matrix8f inv_A = A.inverse();\r\n}\r\n```\r\n(You can ignore the input parameters, they aren't used in this test program.)\r\n\r\nAnd when I try to build this op with bazel, I got following errors:\r\n```\r\nc:\\users\\administrator\\_bazel_zhaozixiao\\sr6amwum\\execroot\\org_tensorflow\\external\\eigen_archive\\eigen\\src/Core/SolveTriangular.h(185): \r\nerror: function \"Eigen::Block<XprType, BlockRows, BlockCols, InnerPanel>::operator=(const Eigen::Block<Eigen::Block<Eigen::Map<Eigen::Matrix<float, -1, -1, 0, -1, -1>, 0, Eigen::Stride<0, 0>>, -1, -1, false>, -1, -1, false> &) [with XprType=Eigen::Block<Eigen::Map<Eigen::Matrix<float, -1, -1, 0, -1, -1>, 0,Eigen::Stride<0, 0>>, -1, -1, false>, BlockRows=-1, BlockCols=-1, InnerPanel=false]\" (declared implicitly) cannot be referenced -- it is a deleted function\r\n\r\nc:\\users\\administrator\\_bazel_zhaozixiao\\sr6amwum\\execroot\\org_tensorflow\\external\\eigen_archive\\eigen\\src/Core/GenericPacketMath.h(368): \r\nerror: asm operand type size(8) does not match type/size implied by constraint 'r'\r\n```\r\nAnd if I try to calculate the inverse of a size 4 * 4(or below) matrix, there isn't any problem. \r\nIn fact I found that tensorflow itself can realise big size matrix operation, matrix inverse for example, but it seems like they don't use eigen structure. So I'd like to know if cuda kernel supports big size(bigger than 4 * 4) matrix operations based on eigen? Thank you!\r\n\r\n", "comments": ["@SeanCho1996 could you please file a bug for the Eigen maintainers with a pure Eigen + cuda repro?\r\n\r\nhttp://eigen.tuxfamily.org/bz/", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31634\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31634\">No</a>\n"]}, {"number": 31633, "title": "Expand documentation for RandomDataset", "body": "This PR adds a `description` field to the API spec for `RandomDataset`. I included some additional details on the type of random numbers the dataset generates, as well as how to create instances of the dataset.", "comments": []}, {"number": 31632, "title": "r2.0-CherryPick: Fixes for failing tests on windows builds", "body": "", "comments": []}, {"number": 31631, "title": "Unbundle LLVM", "body": "cc @perfinion, @timokau", "comments": ["@sanjoy could you take a look?\r\nthis PR tries to use system LLVM for TF.\r\nOne potential issue I see is, TF always uses cutting edge version for LLVM, so you can almost never use TF at head if you use system LLVM.", "> One potential issue I see is, TF always uses cutting edge version for LLVM, so you can almost never use TF at head if you use system LLVM.\r\n\r\nThis is not a huge issue for me as LLVM releases are fairly frequent (major release every 6 months), that I can wait a few months for a LLVM release to use it.", "While I understand that this is not a problem for your use case, when it is checked in, everyone can use it for their own use case. And once it does not work, TF team will be receiving issues and support requests.\r\nTherefore, I want XLA team's review on this.", "XLA uses the C++ LLVM API which has **no** compatibility guarantees.  This plus the fact that internally google uses a monorepo means we have to live very close to LLVM head.\r\n\r\nSo this change is okay if it is clearly documented that the TF and XLA teams will not take (or create!) any PRs solely to make a non HEAD version of LLVM work with XLA.  I.e. I'm okay with this PR if it saves someone a fork, but we can't commit to keeping it working.\r\n\r\n> This is not a huge issue for me as LLVM releases are fairly frequent (major release every 6 months), that I can wait a few months for a LLVM release to use it.\r\n\r\nCan you elaborate a little bit on this?  Let's say XLA in TF head today gets adapted to an LLVM API change that made on 14 August.  Do you have a plan to deal with that?  That API change may have been reverted before the next release so we may not have *any* LLVM release that works with TF.", "> Do you have a plan to deal with that? That API change may have been reverted before the next release so we may not have any LLVM release that works with TF.\r\n\r\nIf that happens, then yes, we can't use system LLVM. Let me know what you decide.", "Sorry for my interruption. I'm wondering could this PR be improved so it be enabled conditionally perhaps via a bazel configure-time option?\r\n\r\nWorking on XLA it's pretty important to closely follow LLVM tip, but I do see some good use cases where going back to system LLVM be beneficial to check interop with IRs coming from other frontends.", "> I'm wondering could this PR be improved so it be enabled conditionally perhaps via a bazel configure-time option?\r\n\r\nIt is there. `TF_SYSTEM_LIBS=llvm` for just `llvm` or `TF_SYSTEM_LIBS=llvm,png,and,other,libs`", "> If that happens, then yes, we can't use system LLVM. Let me know what you decide.\r\n\r\nGiven that:\r\n\r\n - Using a system LLVM won't reliably work.\r\n - Gunan says (rightly I think) that even if we document this as \"unsupported\", in practice we will get bugs / PRs.\r\n\r\nI think we should drop this PR.\r\n", "Thanks for the review."]}, {"number": 31630, "title": "cannot import tensorflow ", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Home 64 bit\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 1.14.0\r\n- Python version: 3.7.0\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 9.0 / 6.0 *\r\n- GPU model and memory: GeForce 940M (can't seem to find the memory of this card)\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nimportError is raised when I attempt to import tensorflow\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n>>>import tensorflow as tf\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\venv\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\venv\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: \u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6a21\u5757\u3002\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 28, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\venv\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\venv\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: \u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6a21\u5757\u3002\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\n*: I can't install CUDA 8.0 on my computer, because most of the modules failed to install, so I used 9.0 instead\r\n", "comments": ["From the template it looks like you are installing **TensorFlow-GPU** (TF) prebuilt binaries.\n\n **TF Version >= 1.13 requires CUDA 10.0 and TF Version < 1.13 (till TF 1.5) requires CUDA 9.0.** \n\n* If you have above configuration and using _**Windows**_ platform -\n     * Try adding the CUDA, CUPTI, and cuDNNinstallation directories to the %PATH% environment variable. \n     * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\n* If you have above configuration and using _**Ubuntu/Linux**_ platform -\n     * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\n     * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\n\nPlease let us know if this helps.", "I tried to install CUDA 10.0 but failed to install most files", "@ongoing0217 Tensorflow version >=1.13 requires CUDA 10.0. Can you downgrade the Tensorflow version to 1.12 and check the import tensorflow. Thanks!", "How do you downgrade the version of tensorflow? Sorry for being a big noob :/", "@ongoing0217 Try the `pip install tensorflow-gpu==1.12.0`. Let us know how it progresses. Thanks!", "@gadagashwini the command prompt windows pops up from pip, saying \"collecting tensorflow-gpu==1.12.0\" then just closes, as if tensorflow is already installed--which is true, I still have 1.14.0 tf installed.\r\nbtw, I should be the one thanking you :P", "@ongoing0217 Try uninstalling the already installed Tensorflow by `pip uninstall tensorflow-gpu` . Later install tensorflow-gpu==1.12.0. Let us know if this helps. Thanks!", "@gadagashwini I tried uninstalling then reinstalling. Initially, pip started uninstalling tf and everything seemed fine, but when I install tf 1.12.0 the situation with the previous comment happened again. I tried installing tf 1.14.0 again and it said \"requirements already installed\" and repeated many times. I think pip didn't uninstall all the things, and so trying to install another tf won't work? is there any other way to get around this problem?", "@ongoing0217, Did you try creating virtual environment and install Tf there. If not try\r\n`pip install virtualenv`. Thanks!\r\n", "@ongoing0217, Other option you can use conda. Please follow the instructions mentioned in this [link](https://github.com/jvishnuvardhan/Installing-TensorFlow-GPU-on-Windows-10-TF1.12). Let us know if that solves your problem. Thanks!", "@gadagashwini I was busy and could not respond, sorry\r\nIn this period, I downgraded tensorflow-gpu to 1.12.0 and reapplied my previous setup with CUDA 9.0, reinstalled cuDNN 7.5, and I can actually import tensorflow and error messages won't be raised. However, when I tried to test if the package was actually working using tf.Session(), my command prompt just stops working.\r\n\r\n>>> hello=tf.constant('hello world')\r\n>>> sess=tf.Session()\r\n2019-08-24 13:26:29.884962: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2019-08-24 13:26:30.375610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties:\r\nname: GeForce 940M major: 5 minor: 0 memoryClockRate(GHz): 1.176\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 2.00GiB freeMemory: 1.65GiB\r\n2019-08-24 13:26:30.376042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0", "@gadagashwini seems like the issue somehow sorted itself out, so all my problems are solved. Thanks for answering my questions :D", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31630\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31630\">No</a>\n"]}, {"number": 31629, "title": "Go: allow larger C array backed slices on 64 bit machines", "body": "See the discussion on https://github.com/golang/go/issues/13656\r\n\r\nIn particular, https://github.com/golang/go/issues/13656#issuecomment-291957684", "comments": ["Can one of the admins verify this patch?"]}, {"number": 31628, "title": "fft2d on CPUs", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Red Hat 7.6\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0.0-beta1\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nIt seems like there is a performance issue when running fft2d on data with dimension > 2 (CPU only).\r\nWhen running fft2d on an array of (40,40,256,256), the function correctly computes fft2d on the inner most 2 dimensions as expected. But it only uses 1 CPU core which results in poor performance.\r\n\r\n\r\n**Describe the expected behavior**\r\nBecause it is equivalent to simultaneously computing 40x40 fft2d, I would expect parallel computation across multiple CPU cores to boost the performance.\r\n\r\n**Code to reproduce the issue**\r\na=tf.cast(tf.Variable(tf.random.uniform([40,40,256,256],dtype=tf.float32)), dtype=tf.complex64)\r\nb=tf.signal.fft2d(a)\r\n\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Please refer to this snippet of code\r\nhttps://github.com/tensorflow/tensorflow/blob/dcdca11bcbab4b2474e7bf4d21d1806e6c2790a3/tensorflow/core/kernels/fft_ops.cc#L132-L141\r\n\r\nThere is no for loop. And tensorflow seems is calling \"Eigen fft\" to calculate the result.\r\n ", "@danielzt12\r\nYou could do the parallel computation by appropriate use of the tensorflow APIs.\r\nPlease refer to this snippet of code:\r\n```\r\nimport tensorflow as tf\r\na=tf.cast(tf.Variable(tf.random.uniform([40,40,256,256],dtype=tf.float32)), dtype=tf.complex64)\r\nres = None\r\nfor i in range(40):\r\n    temp_out = tf.signal.fft2d(tf.slice(a,[i,0,0,0],[1,40,256,256]))\r\n    if res is None:\r\n        res = temp_out\r\n    else:\r\n        tf.concat([res,temp_out],0)\r\nconfig = tf.ConfigProto(intra_op_parallelism_threads=4)\r\nwith tf.Session(config=config) as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    sess.run(res)\r\n```\r\n @Leslie-Fang ", "> @danielzt12\r\n> You could do the parallel computation by appropriate use of the tensorflow APIs.\r\n> Please refer to this snippet of code:\r\n> \r\n> ```\r\n> import tensorflow as tf\r\n> a=tf.cast(tf.Variable(tf.random.uniform([40,40,256,256],dtype=tf.float32)), dtype=tf.complex64)\r\n> res = None\r\n> for i in range(40):\r\n>     temp_out = tf.signal.fft2d(tf.slice(a,[i,0,0,0],[1,40,256,256]))\r\n>     if res is None:\r\n>         res = temp_out\r\n>     else:\r\n>         tf.concat([res,temp_out],0)\r\n> config = tf.ConfigProto(intra_op_parallelism_threads=4)\r\n> with tf.Session(config=config) as sess:\r\n>     sess.run(tf.global_variables_initializer())\r\n>     sess.run(res)\r\n> ```\r\n> \r\n> @Leslie-Fang\r\n\r\nHi Leslie, \r\nThanks for helping out. I tried your code but because I am using tf 2.0 the for loop is executed in eager mode, it was only slightly faster (not even 10% I think).\r\n\r\nDo I need to use @tf.function for this? The whole tf thing is still all very new to me, do you have a solution for tf 2.0?  Thanks\r\n\r\nEdit: I think I figured it out with tf.function\r\n\r\nimport tensorflow as tf\r\nimport time\r\na=tf.cast(tf.Variable(tf.random.uniform([40,40,256,256],dtype=tf.float32)), dtype=tf.complex64)\r\n@tf.function\r\ndef test(a):\r\n    res = None\r\n    for i in range(40):\r\n        tmp_out = tf.signal.fft2d(a[i])\r\n        if res is None:\r\n            res = tmp_out\r\n        else:\r\n            res=tf.concat([res,tmp_out],0)\r\n    return res\r\nc=test(a)\r\n\r\nt0=time.time()\r\nc=test(a)\r\nprint(time.time()-t0)\r\n\r\nit is now 15 times faster, thanks Leslie", "Can we close this issue since the query is been resolved. Thanks!"]}, {"number": 31627, "title": "Encountered error while reading extension file 'protobuf.bzl': ", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version: \r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nFollowed these installation instruction\r\nhttps://www.tensorflow.org/install/source_windows\r\n\r\n**Describe the problem**\r\n**Encountered error while reading extension file 'protobuf.bzl': no such package '@com_google_protobuf//': Traceback (most recent call last):\r\nerror loading package 'tensorflow': in C:/temp/tensorflow-master/tensorflow/core/platform/default/build_config.bzl: Encountered error while reading extension file** \r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n\r\n> C:\\Temp\\tensorflow-master>bazel build --config=opt //tensorflow:tensorflow.dll\r\n> WARNING: Ignoring JAVA_HOME, because it must point to a JDK, not a JRE.\r\n> INFO: Options provided by the client:\r\n>   Inherited 'common' options: --isatty=1 --terminal_columns=120\r\n> INFO: Options provided by the client:\r\n>   'build' options: --python_path=C:/ProgramData/Anaconda3/python.exe\r\n> INFO: Reading rc options for 'build' from c:\\temp\\tensorflow-master\\.bazelrc:\r\n>   'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone --strategy=Genrule=standalone -c opt --announce_rc --define=grpc_no_ares=true --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include\r\n> INFO: Reading rc options for 'build' from c:\\temp\\tensorflow-master\\.tf_configure.bazelrc:\r\n>   'build' options: --action_env PYTHON_BIN_PATH=C:/ProgramData/Anaconda3/python.exe --action_env PYTHON_LIB_PATH=C:/ProgramData/Anaconda3/lib/site-packages --python_path=C:/ProgramData/Anaconda3/python.exe --config monolithic --copt=-w --host_copt=-w --copt=-DWIN32_LEAN_AND_MEAN --host_copt=-DWIN32_LEAN_AND_MEAN --copt=-DNOGDI --host_copt=-DNOGDI --verbose_failures --distinct_host_configuration=false --action_env TF_CONFIGURE_IOS=0\r\n> INFO: Found applicable config definition build:monolithic in file c:\\temp\\tensorflow-master\\.bazelrc: --define framework_shared_object=false\r\n> INFO: Found applicable config definition build:opt in file c:\\temp\\tensorflow-master\\.tf_configure.bazelrc: --copt=/arch:AVX --define with_default_optimizations=true\r\n> INFO: An error occurred during the fetch of repository 'com_google_protobuf'\r\n> INFO: Call stack for the definition of repository 'com_google_protobuf':\r\n>  - C:/temp/tensorflow-master/tensorflow/workspace.bzl:432:5\r\n>  - C:/temp/tensorflow-master/WORKSPACE:26:1\r\n> ERROR: Skipping '//tensorflow:tensorflow.dll': error loading package 'tensorflow': in C:/temp/tensorflow-master/tensorflow/core/platform/default/build_config.bzl: Encountered error while reading extension file 'protobuf.bzl': no such package '@com_google_protobuf//': Traceback (most recent call last):\r\n>         File \"C:/temp/tensorflow-master/third_party/repo.bzl\", line 104\r\n>                 _apply_patch(ctx, ctx.attr.patch_file)\r\n>         File \"C:/temp/tensorflow-master/third_party/repo.bzl\", line 70, in _apply_patch\r\n>                 _wrap_bash_cmd(ctx, patch_command)\r\n>         File \"C:/temp/tensorflow-master/third_party/repo.bzl\", line 28, in _wrap_bash_cmd\r\n>                 fail(\"BAZEL_SH environment variable i...\")\r\n> BAZEL_SH environment variable is not set\r\n> WARNING: Target pattern parsing failed.\r\n> ERROR: error loading package 'tensorflow': in C:/temp/tensorflow-master/tensorflow/core/platform/default/build_config.bzl: Encountered error while reading extension file 'protobuf.bzl': no such package '@com_google_protobuf//': Traceback (most recent call last):\r\n>         File \"C:/temp/tensorflow-master/third_party/repo.bzl\", line 104\r\n>                 _apply_patch(ctx, ctx.attr.patch_file)\r\n>         File \"C:/temp/tensorflow-master/third_party/repo.bzl\", line 70, in _apply_patch\r\n>                 _wrap_bash_cmd(ctx, patch_command)\r\n>         File \"C:/temp/tensorflow-master/third_party/repo.bzl\", line 28, in _wrap_bash_cmd\r\n>                 fail(\"BAZEL_SH environment variable i...\")\r\n> BAZEL_SH environment variable is not set\r\n> INFO: Elapsed time: 21.498s\r\n> INFO: 0 processes.\r\n> FAILED: Build did NOT complete successfully (0 packages loaded)\r\n>     currently loading: tensorflow\r\n\r\n```", "comments": ["@dmitryponv, Which Protobuf version are you using? ", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31627\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31627\">No</a>\n"]}, {"number": 31626, "title": "Exception handling fix in `math_ops.div_no_nan()`", "body": "Currently `div_no_nan()` does not raise a `TypeError` if the inputs are of different types. Although the code for that exists, it is never executed as in one of the lines above that, the code fails with a different error. This is fixed in the first [commit](https://github.com/tensorflow/tensorflow/commit/25ffbdfccc02b7f8c2e05f76c066ddef2503af39). \r\n\r\nCode to execute:\r\n\r\n```python\r\nimport tensorflow as tf\r\na = tf.constant(1, dtype=tf.float32)\r\nb = tf.constant(2, dtype=tf.float64)\r\nc = tf.div_no_nan(a,b)\r\n```\r\nEarlier:\r\n```python\r\n\r\nValueError: Tensor conversion requested dtype float32 for Tensor with dtype float64: 'tf.Tensor(2.0, shape=(), dtype=float64)'\r\n\r\n```\r\nNow:\r\n```python\r\n\r\nTypeError: x and y must have the same dtype, got tf.float32 != tf.float64\r\n```\r\n", "comments": ["Can one of the admins verify this patch?"]}, {"number": 31625, "title": "Strange result when fetching variables under a distributed strategy", "body": "**System information**\r\n- Have I written custom code: yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Mojave 10.14.5\r\n- TensorFlow installed from (source or binary): binary (tf-nightly)\r\n- TensorFlow version (use command below): 1.15.0-dev20190729\r\n- Python version: 3.7.4\r\n\r\n**Describe the current behavior**\r\nWhen I am using any distributed strategy, and I fetch a `tf.Variable`, I get a result that looks like: `[array([( 10,), ( 44,), ( 47,),  ...], dtype=[('resource', 'u1')])]`. Instead, I have to wrap the variable in a `tf.identity` call in order to get its value properly.\r\n\r\n**Describe the expected behavior**\r\nThe fetched result should be the value of the variable.\r\n\r\n**Code to reproduce the issue**\r\n```Python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport sys\r\n\r\nclass RunHook(tf.train.SessionRunHook):\r\n  def before_run(self, run_context):\r\n    return tf.train.SessionRunArgs(fetches=['var:0'])\r\n\r\n  def after_run(self, run_context, run_values):\r\n    print(run_values.results)\r\n    sys.exit(0)\r\n\r\ndef model_fn(features, labels, mode, params):\r\n  var = tf.get_variable(\r\n    initializer=tf.constant([1.0], dtype=tf.float32),\r\n    name=\"var\",\r\n    dtype=tf.float32,\r\n    trainable=True,\r\n  )\r\n  loss = tf.identity(var)\r\n  opt = tf.train.AdamOptimizer(0.001)\r\n  global_step = tf.train.get_or_create_global_step()\r\n  train_op = opt.minimize(loss, global_step=global_step)\r\n  return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\r\n\r\nstrategy = tf.distribute.MirroredStrategy()\r\nsession_config = tf.ConfigProto()\r\nconfig = tf.estimator.RunConfig(train_distribute=strategy, session_config=session_config,\r\n                                log_step_count_steps=1, save_checkpoints_steps=float('inf'))\r\nclassifier = tf.estimator.Estimator(model_fn=model_fn, config=config)\r\n\r\n\r\nx = np.array([1, 2, 3, 4])\r\ny = np.array([5, 6, 7, 8])\r\ntrain_input_fn = tf.estimator.inputs.numpy_input_fn(x, y, batch_size=1, num_epochs=None, shuffle=True)\r\n\r\ntf.estimator.train_and_evaluate(\r\n  classifier,\r\n  train_spec=tf.estimator.TrainSpec(input_fn=lambda: train_input_fn, hooks=[RunHook()]),\r\n  eval_spec=tf.estimator.EvalSpec(input_fn=lambda: train_input_fn)\r\n)\r\n```\r\n", "comments": ["I have tried on colab with TF version 1.15.0-dev20190729 and i was getting the below error`ImportError: cannot import name 'dense_features' .Please, find the [gist ](https://colab.research.google.com/drive/1EWycvv6DE-xDmvzhzNKkudeEjMcmrKDz)here.However i tried with latest nightly version and was able to reproduce the issue.Please, find the [gist ](https://colab.research.google.com/drive/1cJ61uL5_cnJU-AGAurpaQgmGkTo2bbC7)here.Thanks!", "This shouldn't affect correctness.\r\n\r\nIt is caused by the variable becoming a resource variable.  Your current code leave use_resource=None, yet the distribution strategy force use_resource=True on the variable.  That's why it looks like the behavior is different between the case without distribution strategy and the case with distribution strategy.   You can also see that if you remove distribution strategy, but add use_resource=True to your variable you will get the confusing print out.\r\n\r\nFetching the resource variables by python reference works, however.  You can accept the references in the constructor argument of `RunHook()` and return the hook using EstimatorSpec.training_hooks.\r\n\r\nHope this helps.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=31625\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=31625\">No</a>\n"]}, {"number": 31624, "title": "r2.0 CherryPick: Fix arg typo.", "body": "PiperOrigin-RevId: 262395899", "comments": []}, {"number": 31623, "title": "[INTEL MKL] Fix for Batchmatmul regression", "body": "BatchMatmul now uses the BatchMatMulV2 operator, however TF+MKL hadn't been updated accordingly. Fixed this issue and also added missing unit tests. ", "comments": []}, {"number": 31622, "title": "GPU docker images and pip package have mismatched CuDNN versions", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16\r\n- TensorFlow installed from (source or binary): Docker image\r\n- TensorFlow version: Nightly\r\n- CUDA/cuDNN version: Docker is cudnn 7.5 or 7.4 & pip package is cudnn 7.6\r\n\r\n**Describe the problem**\r\nThe available GPU docker images (tensorflow/tensorflow:nightly-gpu ; tensorflow/tensorflow:gpu & the others) will fail to intialize cuDNN since TF-nightly is compiled with a higher minor version\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\ndocker run --rm -it --runtime=nvidia tensorflow/tensorflow:nightly-gpu-py3 /bin/bash\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nx = tf.placeholder(tf.float32, shape=(2,4,4,3))\r\nlayer = tf.keras.layers.Conv2D(5, (2,2), input_shape=(4,4,3))\r\nout = layer(x)\r\n\r\ndata = np.random.random((2, 4, 4, 3))\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    print(sess.run(out, feed_dict={x: data}))\r\n\r\n```\r\n\r\nFails with:\r\n```\r\nLoaded runtime CuDNN library: 7.4.1 but source was compiled with: 7.6.0.\r\nFailed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n```\r\n\r\n**Any other info / logs**\r\nRelated issue: https://github.com/tensorflow/addons/issues/418\r\n\r\ncc @yifeif @av8ramit . As discussed this applies to custom-op repos as well.\r\n", "comments": ["On it.  Sorry I missed this, the change happened in a bit of a weird way.  There is still not excuse to be honest.  ", "I checked the this docker `tensorflow/tensorflow:nightly-gpu-py3` and we look good for tf-nightly:  \r\n\r\nlibcudnn7/unknown,now 7.6.2.24-1+cuda10.0 amd64 [installed,upgradable to: 7.6.2.24-1+cuda10.1]\r\nlibnvinfer5/unknown,now 5.1.5-1+cuda10.0 amd64 [installed,upgradable to: 5.1.5-1+cuda10.1"]}, {"number": 31621, "title": "Support a dictionary of tensors as a CompositeTensor", "body": "- TensorFlow version (you are using): 2.0.0b1\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n**Describe the feature and the current behavior/state.**\r\nThe CompositeTensor base class offers a unified way of handling various types of tensors that are themselves composed of tensors. Currently, dictionaries of tensors are not supported; it would be useful if they were.\r\n\r\n**Will this change the current api? How?**\r\nYes, by adding to the types of structures that can be treated as a CompositeTensor.\r\n\r\n**Who will benefit with this feature?**\r\nDictionaries are one of the more convenient ways to manage collections of heterogeneous features. In issue #27679 (Passing a dictionary of tensors to py_function), it was stated that in that case, creating a subclass of CompositeTensor that can represent a dictionary would be one path to ultimately supporting dictionaries of tensors in py_function.", "comments": ["Most APIs that support composite tensors also support nested structures (as defined by [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest).  In particular, the tf.nest functions include an \"expand_composites\" argument that tells tf.nest that it should treat composite tensors as nested structures.\r\n\r\nTherefore, we don't need a CompositeTensor for dictionaries -- we can just use dictionaries as is.  But what we do ned is to extend py_function to use tf.nest to do appropriate flattening and repacking of tensors at the input & output boundaries.  (Using \"expand_composites=True\" will ensure that this supports both \"normal\" nested structures and composite tensors.)\r\n\r\nClosing this issue, but adding a similar comment to issue #27679."]}, {"number": 31620, "title": "r2.0-Cherrypick: TensorEquality related changes", "body": "", "comments": []}, {"number": 31619, "title": "Incorrect value in results when using tf.math.log()", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No idea\r\n- TensorFlow installed from (source or binary): binary using pip3 install\r\n- TensorFlow version (use command below): 1.14\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: cuda9.0, cudnn 7.6\r\n- GPU model and memory: RTX 2080Ti\r\n\r\nWhen I run the following code using CPU:\r\n`result= tf.math.log(tf.constant([280.41303540865516]*100, dtype=tf.float32)).numpy()`\r\nI got:\r\n`\r\n[5.6362634 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634\r\n 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634\r\n 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634\r\n 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634\r\n 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634\r\n 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634\r\n 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634\r\n 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634\r\n 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634\r\n 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634\r\n 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634\r\n 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634\r\n 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634\r\n 5.6362634 5.6362634 5.6362634 5.6362634 5.6362634 5.636264  5.636264\r\n 5.636264  5.636264 ]`\r\n\r\nI found result[0] is not equal to result[-1]. the first one is \r\n5.636263370513916 while the latter one is equal to 5.636263847351074.\r\n\r\nI believe it is a bug.\r\n\r\n\r\n**Code to reproduce the issue**\r\n`\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\nimport tensorflow as tf\r\nfrom random import *\r\ntf.enable_eager_execution()\r\nwith tf.device(\"/cpu:0\"):\r\n    result = tf.math.log(tf.constant([ 280.41303540865516]*100, dtype=tf.float32)).numpy()\r\nprint(\"{} vs {}\".format(result[0], result[-1]))`\r\n\r\n\r\nSeems GPU has no such issues.", "comments": ["Well, this issue could be related to #31408 ", "I think they are related, but don't know if the fix to one will also fix the other one, so better to not mark them as duplicates", "@yqtianust I tried to reproduce the issue on [Colab](https://colab.sandbox.google.com/gist/gowthamkpr/b512cc2618fd02ca1c3b65cf5d7398e3/untitled93.ipynb) but was not able to reproduce it. Can you please provide a github gist of the issue. Thanks!", "@gowthamkpr I found that it is ok if using number 280.41303540865516 in Colab. However, if you change the number to 774.726039560185 and run it on colab, the issue appear again. \r\n\r\nSee here [colab](https://colab.research.google.com/drive/1Z4KvcoYXLwNoOwSaAO4p3nVDsJyjiVZI)", "@mihaimaruseac @yqtianust \r\nI suspect it's a bug of eigen.\r\nWith GDB to debug, I set the break point at\r\nhttps://github.com/tensorflow/tensorflow/blob/aac18a3ffb2b9744f026eda4970369d2cf548980/tensorflow/core/common_runtime/eager/kernel_and_device.cc#L169-L179\r\nAnd print the results in memory:\r\n```\r\nx/1fw 0x401e100\r\n0x401e100:  5.63626337\r\n\r\nx/1fw 0x401e28c\r\n0x401e28c:  5.63626385\r\n```\r\n\r\n\r\n", "My understand is it's calling\r\nhttps://github.com/tensorflow/tensorflow/blob/aac18a3ffb2b9744f026eda4970369d2cf548980/tensorflow/core/kernels/cwise_ops.h#L837-L838\r\nto calculate the result.\r\n\r\nPlease correct me if I am wrong.\r\n", "In that case, let's also open an issue on Eigen and crossreference to here", " I have write a sample code to do the test of Eigen:\r\n```\r\n  #include <iostream>\r\n  #include <Eigen/Core>\r\n  #include \"Eigen/src/Core/functors/UnaryFunctors.h\"\r\n  #include <iomanip>\r\n  using namespace Eigen;\r\n  using namespace std;\r\n  int main()\r\n  {\r\n    Eigen::Matrix<float, 100, 1> tmp = Eigen::Matrix<float, 100, 1>::Constant(100, 1, 280.41303540865516);\r\n    cout << setprecision(8) << tmp << endl << \"becomes: \" << endl << tmp.unaryExpr(internal::scalar_log_op<float>()) << endl;\r\n  }\r\n```\r\nWhen I build it, I link to the Eigen lib which tensorflow use. \r\nHowever, this code didn't happens the problem.\r\nI mean all of the output is same.\r\n\r\nMoreover, I narrow down this issue to the code snippet:\r\nhttps://github.com/tensorflow/tensorflow/blob/69b1feac62276edcc509ac88af229c6236e645fe/tensorflow/core/kernels/cwise_ops_common.h#L537-L543\r\n", "@Leslie-Fang Have you tried other data type? like double? I am not familiar with Eigen.\r\nIt seems this issue will not occurs when using dtype float16, but it will occur when using float32 in tensorflow.\r\n\r\nAlos, have you tried GDB on the issue #31408?\r\n\r\nOr it is possible the problem is due to the connection between Eigen and TensorFlow? \r\n", "@yqtianust I suspect the problem may happen in the tensor copy process. But I don't have any clue now.", "@yqtianust \r\nIs this still an issue.", "@Saduf2019 I think so. \r\nHowever, according to #31408. \r\n\r\n> Both numbers are correct to within 1 ulp (unit in last place). The inconsistency is due to the difference between the vectorized and scalar path in the underlying Eigen code. In short, please don't rely on exact equality of floating point numbers.", "based on the last comment, closing this bug as of now. Please let me know if this is still a problem.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31619\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31619\">No</a>\n"]}, {"number": 31618, "title": "CUDA installation link leads to 9.0 instead of 10", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 64bit\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: none tested\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.14\r\n- **Python version**: 3.7\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: None installed\r\n- **GPU model and memory**: NVIDIA GeForce GTX 1060 6GB with 16GB RAM\r\n- **Exact command to reproduce**: import tensorflow\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nThe CUDA download link that appears when `tensorflow-gpu` is installed but CUDA is missing leads to 9.0\r\n\r\n### Source code / logs\r\n```Traceback (most recent call last):\r\n  File \"H:/C33F/Programmieren 4.0/HelloWorldProject/DeepLearning/dqn_main.py\", line 1, in <module>\r\n    from openaigym_cartrack_deeplearning_custom_environments import CarTrackDeepLearningEnvironment\r\n  File \"H:\\C33F\\Programmieren 4.0\\HelloWorldProject\\DeepLearning\\openaigym_cartrack_deeplearning_custom_environments.py\", line 7, in <module>\r\n    import brains\r\n  File \"H:\\C33F\\Programmieren 4.0\\HelloWorldProject\\DeepLearning\\brains.py\", line 10, in <module>\r\n    from keras.layers import Dense, Flatten, Input\r\n  File \"C:\\Python37\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\r\n    from . import utils\r\n  File \"C:\\Python37\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\r\n    from . import conv_utils\r\n  File \"C:\\Python37\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\r\n    from .. import backend as K\r\n  File \"C:\\Python37\\lib\\site-packages\\keras\\backend\\__init__.py\", line 89, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"C:\\Python37\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 28, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Python37\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 30, in <module>\r\n    self_check.preload_check()\r\n  File \"C:\\Python37\\lib\\site-packages\\tensorflow\\python\\platform\\self_check.py\", line 82, in preload_check\r\n    % (build_info.cudart_dll_name, build_info.cuda_version_number))\r\nImportError: Could not find 'cudart64_100.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 10.0 from this URL: https://developer.nvidia.com/cuda-90-download-archive\r\n```\r\n", "comments": ["Thanks. This is captured by #31143"]}, {"number": 31617, "title": "Accuracy metric not consistent between training and evaluation when using same dataset for both train and test", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES, I made changes based on a script provided by TF\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): PIP install\r\n- TensorFlow version (use command below): 1.14.0\r\n- Python version: 3.6\r\n\r\n**Intro**\r\n\r\nIn order to sanity check a code for custom estimator I wrote, I trained and evaluated it on the same dataset (training set = evaluation set), expecting to get the same metrics. I also set the batch size to the dataset size to avoid having discrepancies due to calculations based on the batch instead of the whole dataset.\r\n\r\nWhile I could verify that the loss was consistent, I haven't managed to get consistent accuracies. Because of that, I grabbed code provided by tensorflow (https://github.com/tensorflow/models/tree/master/samples/core/get_started) and tried to replicate the behavior. I needed to make some changes in order to 1)run it with batch size = whole dataset, 2) run it with training set = test set, and 3) save data to disk so I could inspect it with Tensorboard. The whole pieces of code are shown below.\r\n\r\n**Describe the current behavior**\r\n\r\nThe accuracy calculated during training is different from the one calculated during evaluation, even if training and test set are exactly the same.\r\n\r\n**Describe the expected behavior**\r\n\r\nI would expect to be able to get the same accuracy both for training and for evaluation, if the same dataset is being used for both phases.\r\n\r\n**Code to reproduce the issue**\r\n\r\nScripts based on [custom_estimator.py](https://github.com/tensorflow/models/blob/master/samples/core/get_started/custom_estimator.py) and [iris_data.py](https://github.com/tensorflow/models/blob/master/samples/core/get_started/iris_data.py).\r\n\r\nMy custom_estimator.py:\r\n\r\n```\r\n#  Copyright 2016 The TensorFlow Authors. All Rights Reserved.\r\n#\r\n#  Licensed under the Apache License, Version 2.0 (the \"License\");\r\n#  you may not use this file except in compliance with the License.\r\n#  You may obtain a copy of the License at\r\n#\r\n#   http://www.apache.org/licenses/LICENSE-2.0\r\n#\r\n#  Unless required by applicable law or agreed to in writing, software\r\n#  distributed under the License is distributed on an \"AS IS\" BASIS,\r\n#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\r\n#  See the License for the specific language governing permissions and\r\n#  limitations under the License.\r\n\"\"\"An Example of a custom Estimator for the Iris dataset.\"\"\"\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport os\r\nimport argparse\r\nimport tensorflow as tf\r\nfrom tensorflow_estimator import estimator\r\n\r\nimport iris_data\r\n\r\nparser = argparse.ArgumentParser()\r\nparser.add_argument('--batch_size', default=120, type=int, help='batch size')\r\nparser.add_argument('--train_steps', default=10, type=int,\r\n                    help='number of training steps')\r\n\r\ndef my_model(features, labels, mode, params):\r\n    \"\"\"DNN with three hidden layers and learning_rate=0.1.\"\"\"\r\n    # Create three fully connected layers.\r\n    net = tf.feature_column.input_layer(features, params['feature_columns'])\r\n    for units in params['hidden_units']:\r\n        net = tf.layers.dense(net, units=units, activation=tf.nn.relu)\r\n\r\n    # Compute logits (1 per class).\r\n    logits = tf.layers.dense(net, params['n_classes'], activation=None)\r\n\r\n    # Compute predictions.\r\n    predicted_classes = tf.argmax(logits, 1)\r\n    if mode == tf.estimator.ModeKeys.PREDICT:\r\n        predictions = {\r\n            'class_ids': predicted_classes[:, tf.newaxis],\r\n            'probabilities': tf.nn.softmax(logits),\r\n            'logits': logits,\r\n        }\r\n        return tf.estimator.EstimatorSpec(mode, predictions=predictions)\r\n\r\n    # Compute loss.\r\n    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\r\n\r\n    # Compute evaluation metrics.\r\n    accuracy = tf.metrics.accuracy(labels=labels,\r\n                                   predictions=predicted_classes,\r\n                                   name='acc_op')\r\n    metrics = {'accuracy': accuracy}\r\n    tf.summary.scalar('accuracy', accuracy[1])\r\n\r\n    if mode == tf.estimator.ModeKeys.EVAL:\r\n        return tf.estimator.EstimatorSpec(\r\n            mode, loss=loss, eval_metric_ops=metrics)\r\n\r\n    # Create training op.\r\n    assert mode == tf.estimator.ModeKeys.TRAIN\r\n\r\n    optimizer = tf.train.AdagradOptimizer(learning_rate=0.1)\r\n    train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\r\n    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\r\n\r\n\r\ndef main(argv):\r\n    args = parser.parse_args(argv[1:])\r\n\r\n    # Fetch the data\r\n    (train_x, train_y), (test_x, test_y) = iris_data.load_data()\r\n\r\n    # Feature columns describe how to use the input.\r\n    my_feature_columns = []\r\n    for key in train_x.keys():\r\n        my_feature_columns.append(tf.feature_column.numeric_column(key=key))\r\n\r\n    # Build 2 hidden layer DNN with 10, 10 units respectively.\r\n    classifier = tf.estimator.Estimator(\r\n        model_fn=my_model,\r\n        params={\r\n            'feature_columns': my_feature_columns,\r\n            # Two hidden layers of 10 nodes each.\r\n            'hidden_units': [10, 10],\r\n            # The model must choose between 3 classes.\r\n            'n_classes': 3,\r\n        },\r\n        config=estimator.RunConfig(\r\n            keep_checkpoint_max=1,\r\n            save_checkpoints_steps=1,\r\n            save_summary_steps=1,\r\n            model_dir=os.path.join(\".\", \"model_dir\")))\r\n\r\n    # Train the Model.\r\n    estimator.train_and_evaluate(\r\n        estimator=classifier,\r\n        train_spec=estimator.TrainSpec(input_fn=lambda: iris_data.train_input_fn(train_x, train_y, args.batch_size),\r\n                                       max_steps=args.train_steps),\r\n        eval_spec=estimator.EvalSpec(input_fn=lambda: iris_data.eval_input_fn(test_x, test_y, args.batch_size),\r\n                                     start_delay_secs=0,\r\n                                     throttle_secs=0,\r\n                                     steps=None),\r\n\r\n    )\r\n    #classifier.train(\r\n    #    input_fn=lambda:iris_data.train_input_fn(train_x, train_y, args.batch_size),\r\n    #    steps=args.train_steps)\r\n\r\n    # Evaluate the model.\r\n    #eval_result = classifier.evaluate(\r\n    #    input_fn=lambda:iris_data.eval_input_fn(test_x, test_y, args.batch_size))\r\n\r\n    #print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))\r\n\r\n    # Generate predictions from the model\r\n    expected = ['Setosa', 'Versicolor', 'Virginica']\r\n    predict_x = {\r\n        'SepalLength': [5.1, 5.9, 6.9],\r\n        'SepalWidth': [3.3, 3.0, 3.1],\r\n        'PetalLength': [1.7, 4.2, 5.4],\r\n        'PetalWidth': [0.5, 1.5, 2.1],\r\n    }\r\n\r\n    predictions = classifier.predict(\r\n        input_fn=lambda:iris_data.eval_input_fn(predict_x,\r\n                                                labels=None,\r\n                                                batch_size=args.batch_size))\r\n\r\n    for pred_dict, expec in zip(predictions, expected):\r\n        template = ('\\nPrediction is \"{}\" ({:.1f}%), expected \"{}\"')\r\n\r\n        class_id = pred_dict['class_ids'][0]\r\n        probability = pred_dict['probabilities'][class_id]\r\n\r\n        print(template.format(iris_data.SPECIES[class_id],\r\n                              100 * probability, expec))\r\n\r\n\r\nif __name__ == '__main__':\r\n    tf.logging.set_verbosity(tf.logging.INFO)\r\n    tf.app.run(main)\r\n```\r\n\r\nMy iris_data.py:\r\n\r\n```\r\nimport pandas as pd\r\nimport tensorflow as tf\r\n\r\nTRAIN_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\r\nTEST_URL = TRAIN_URL#\"http://download.tensorflow.org/data/iris_test.csv\"\r\n\r\nCSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth',\r\n                    'PetalLength', 'PetalWidth', 'Species']\r\nSPECIES = ['Setosa', 'Versicolor', 'Virginica']\r\n\r\ndef maybe_download():\r\n    train_path = tf.keras.utils.get_file(TRAIN_URL.split('/')[-1], TRAIN_URL)\r\n    test_path = tf.keras.utils.get_file(TEST_URL.split('/')[-1], TEST_URL)\r\n\r\n    return train_path, test_path\r\n\r\ndef load_data(y_name='Species'):\r\n    \"\"\"Returns the iris dataset as (train_x, train_y), (test_x, test_y).\"\"\"\r\n    train_path, test_path = maybe_download()\r\n\r\n    train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\r\n    train_x, train_y = train, train.pop(y_name)\r\n\r\n    test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\r\n    test_x, test_y = test, test.pop(y_name)\r\n\r\n    return (train_x, train_y), (test_x, test_y)\r\n\r\n\r\ndef train_input_fn(features, labels, batch_size):\r\n    \"\"\"An input function for training\"\"\"\r\n    # Convert the inputs to a Dataset.\r\n    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\r\n\r\n    # Shuffle, repeat, and batch the examples.\r\n    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\r\n\r\n    # Return the dataset.\r\n    return dataset\r\n\r\n\r\ndef eval_input_fn(features, labels, batch_size):\r\n    \"\"\"An input function for evaluation or prediction\"\"\"\r\n    features=dict(features)\r\n    if labels is None:\r\n        # No labels, use only features.\r\n        inputs = features\r\n    else:\r\n        inputs = (features, labels)\r\n\r\n    # Convert the inputs to a Dataset.\r\n    dataset = tf.data.Dataset.from_tensor_slices(inputs)\r\n\r\n    # Batch the examples\r\n    assert batch_size is not None, \"batch_size must not be None\"\r\n    dataset = dataset.batch(batch_size)\r\n\r\n    # Return the dataset.\r\n    return dataset\r\n\r\n\r\n# The remainder of this file contains a simple example of a csv parser,\r\n#     implemented using the `Dataset` class.\r\n\r\n# `tf.parse_csv` sets the types of the outputs to match the examples given in\r\n#     the `record_defaults` argument.\r\nCSV_TYPES = [[0.0], [0.0], [0.0], [0.0], [0]]\r\n\r\ndef _parse_line(line):\r\n    # Decode the line into its fields\r\n    fields = tf.decode_csv(line, record_defaults=CSV_TYPES)\r\n\r\n    # Pack the result into a dictionary\r\n    features = dict(zip(CSV_COLUMN_NAMES, fields))\r\n\r\n    # Separate the label from the features\r\n    label = features.pop('Species')\r\n\r\n    return features, label\r\n\r\n\r\ndef csv_input_fn(csv_path, batch_size):\r\n    # Create a dataset containing the text lines.\r\n    dataset = tf.data.TextLineDataset(csv_path).skip(1)\r\n\r\n    # Parse each line.\r\n    dataset = dataset.map(_parse_line)\r\n\r\n    # Shuffle, repeat, and batch the examples.\r\n    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\r\n\r\n    # Return the dataset.\r\n    return dataset\r\n```\r\n\r\n**Other info / logs**\r\n\r\nSome tensorboard images. First, I can always get a consistent loss (loss in step x for eval is equal to loss in step x+1 for training). Example:\r\n\r\n![image](https://user-images.githubusercontent.com/42271354/63022114-7d704580-bea2-11e9-9873-19ed0bf715e0.png)\r\n\r\n![image](https://user-images.githubusercontent.com/42271354/63022154-8e20bb80-bea2-11e9-8c96-dc2a45d79f76.png)\r\n\r\nBut the accuracies don't match in any apparent way. I could verify that the evaluation accuracy is indeed correct, when looking at the labels and predicted values, but the accuracy during training is different.\r\n\r\n![image](https://user-images.githubusercontent.com/42271354/63022282-d7710b00-bea2-11e9-965b-f59bbf45a4e1.png)\r\n\r\nI might be missing some obvious detail here, so please do let me know if you can spot something.\r\n", "comments": ["Is this still an issue? Can you test with a latest version of TensorFlow (2.2) and check? Thanks!", "I won't be able to test, so I'm closing it.\r\n\r\nThanks!"]}, {"number": 31616, "title": "Dataset prefetch not working as expected, not storing data in memory", "body": "**System information**\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04 LTS\r\n- **TensorFlow installed from (source or binary)**: conda-forge\r\n- **TensorFlow version (use command below)**: unknown 1.14.0\r\n- **Python version**: Python 3.7.3\r\n- **CUDA/cuDNN version**: NVIDIA-SMI 418.67, Driver Version: 418.67, CUDA Version: 10.1\r\n- **GPU model and memory**: Quadro RTX 6000, 24190MiB\r\n- **Exact command to reproduce**:\r\n\r\n**Describe the current behavior**\r\n\r\nI am training a small LSTM model and until recently, I could use `Dataset.from_tensor_slices()` reading numpy arrays directly because all training data fits into memory. Unfortunately, after adding some new data, I ran into the 2 GB graph memory limitation and was forced to switch to using `TFRecord` and `TFRecordDataset`. However, the actual training data still fits into RAM and I want to make sure it is prefetched even when using the `TFRecordDataset`. Therefore, I tried to use the `Dataset.prefetch()` methodology to achieve this, assuming a buffer will be created and (constantly) filled with data. However, it does not work - in fact, there seems to be little to no difference comparing a version with and without a final `.prefetch(x)` in the data pipeline. See the animated gif below:\r\n\r\n![tf_prefetch](https://user-images.githubusercontent.com/53339396/63017447-a985c980-be96-11e9-91ce-0ea3cd23945f.gif)\r\n\r\nThe actual dataset is filtered in the pipeline and the training stalls whenever a sequence of values that is filtered out is occurring in the data. Only a few values in each data/tfrecord file (of which many exist) are relevant. To illustrate this further, the data layout is similar to this:\r\n\r\n    file 1: [---------#####----------------####------]\r\n    file 2: [--------######----------------###-------]\r\n    file 3: [----------####----------------####------]\r\n    file 4: ...\r\n    ...\r\n\r\nwhere `-` denotes irrelevant and `#` denotes relevant data points in a time series. When holding all values in memory (as previously was the case), the filter is rather fast and irrelevant values are skipped unnoticeable.\r\n\r\nThe data pipeline is set up like this:\r\n\r\n    feature_description = { \"features\": tf.FixedLenFeature([132], tf.float32),  \"label\": tf.FixedLenFeature([1], tf.float32) }\r\n    def _parse_function(example_proto):\r\n        return tf.parse_single_example(example_proto, feature_description)\r\n    \r\n    ds = tf.data.TFRecordDataset([f.as_posix() for f in fs_train])\r\n    ds = ds.map(_parse_function)\r\n    ds = ds.flat_map(lambda v: tf.data.Dataset.from_tensors((v[\"features\"][2:], v[\"label\"])))\r\n    # filter data, only allow Ls[0] and Ls[1]\r\n    ds = ds.filter(\r\n        lambda _, y: tf.reshape(tf.logical_or(\r\n            tf.equal(y, Ls[0]),\r\n            tf.equal(y, Ls[1])\r\n        ), [])\r\n    )\r\n    # relabel and re-map labels to 0 and 1\r\n    ds = ds.flat_map(lambda x, y: tf.data.Dataset.from_tensors((x, tf_relabel(y) - base_label.value)))\r\n    # create sliding window for LSTM\r\n    ds = ds.window(size=window_size, shift=shift, stride=stride, drop_remainder=True)\r\n    ds = ds.flat_map(lambda x, y: tf.data.Dataset.zip((x.batch(window_size), y.batch(window_size))))\r\n    \r\n    # batch and prefetch\r\n    ds = ds.batch(batch_size, drop_remainder=True)\r\n    ds = ds.prefetch(1000000000000000) # tried many values, nothing works\r\n\r\n**Describe the expected behavior**\r\nI expect to find some value for `Dataset.prefetch()` that reads all or enough data to memory to allow for fast training without stalling.\r\n\r\n**Code to reproduce the issue**\r\nSee data pipeline above. I cannot provide the data as it is proprietary.\r\n", "comments": ["@mimxrt try using the\r\n`tf.data.Dataset.cache` method\r\n```\r\n**Args**:\r\nfilename: A tf.string scalar tf.Tensor, representing the \r\nname of a directory on the filesystem to use for caching \r\ntensors in this Dataset. If a filename is not provided, \r\nthe dataset will be cached in memory.\r\n```\r\nNote : Its is good practice to cache the dataset before performing any non deterministic operations on it, (like random augmentations)", "Thank you for your response. From my understanding, while the `cache()` method would work from the second epoch forward, it does not change the behavior for the first epoch at all. So while I will certainly make use of `cache()` in future, my expectation is still that `prefetch()` reads data to memory _before_ any operation is done on the data. My reason for this is that before switching to `TFRecordDataset` (i.e. when using `.from_tensor_slices()` on Numpy arrays), the first epoch was running as fast as it can get and the whole training of 50 epochs was finished in under one hour. Now it takes over one hour just for the first epoch. The difference was that previously the raw data was sequentially read into memory as-is, without any operation on it.\r\n\r\nIt seems there should be a way to cache the dataset before any further processing; if not `preprocess()` then what else? NB: I also tried to put `preprocess()` to an earlier stage of the data pipeline.", "@mimxrt if you are purely aiming for throughput, you might be better off doing offline filtering.\r\nAlso there are a couple of low hanging fruits viz.\r\n - `num_parallel_calls` arg in `map` for parallel processing of dataset elements\r\n-  `tf.data.experimental.parallel_interleave` or `tf.data.Dataset.interleave `when processing tfrecords. However parallel_interleave is deprecated.\r\n- `tf.data.experimental.AUTOTUNE` for `buffer_size ` in `prefetch` and `num_parallel_calls` in `map`\r\n- Tune the pipeline according to your needs using `tf.data.Options`", "I understand, thank you for your kind help. I will try your suggestions and then decide to do offline filtering if necessary.", "I'm sorry to re-open this but it seems again that both `cache()` and `num_parallel_calls` have no effect. See the screenshot below for the second epoch when using `cache()` after pre-processing, i.e. before windowing with `window()`.\r\n\r\n![2019-08-15-123156_1920x1080_scrot](https://user-images.githubusercontent.com/53339396/63089655-dac6ce00-bf58-11e9-8a46-ba62b8e4291e.png)\r\n\r\nBefore, when using Numpy array input, the very same network was trained like this:\r\n\r\n![2019-08-15-124847_1920x1080_scrot](https://user-images.githubusercontent.com/53339396/63090289-1e223c00-bf5b-11e9-8e9d-add9756feb5a.png)\r\n\r\nFor comparison: 145 s / 27485 items = 5.28 ms per item, versus now ~81 ms per item.\r\n\r\nSo for the run above, the pipeline looks like this:\r\n\r\n```\r\nds_train = tf.data.TFRecordDataset([f.as_posix() for f in fs_train])\r\n#ds_train = ds_train.cache()\r\n\r\nds_train = ds_train.map(lambda x: tf.parse_single_example(x, {\r\n    \"features\": tf.FixedLenFeature([132], tf.float32),\r\n    \"label\": tf.FixedLenFeature([1], tf.float32),\r\n}))\r\n\r\nds_train = ds_train.flat_map(lambda v: tf.data.Dataset.from_tensors((v[\"features\"][2:], v[\"label\"])))\r\n\r\nds_train = ds_train.filter(\r\n    lambda _, y: tf.reshape(tf.logical_or(\r\n        tf.equal(y, Ls[0]),\r\n        tf.equal(y, Ls[1])\r\n    ), [])\r\n)\r\n\r\nds_train = ds_train.flat_map(lambda x, y: tf.data.Dataset.from_tensors((x, y - base_label.value)))\r\n\r\nds_train = ds_train.cache()\r\n\r\nds_train = ds_train.window(size=num_tsteps, shift=1, stride=1, drop_remainder=True)\r\nds_train = ds_train.flat_map(lambda x, y: tf.data.Dataset.zip((x.batch(num_tsteps), y.batch(num_tsteps))))\r\n\r\nds_train = ds_train.batch(batch_size, drop_remainder=True)\r\nds_train = ds_train.prefetch(1)\r\n```\r\n\r\nI tried to add the suggested optimizations with this pipeline:\r\n```\r\nds_train = tf.data.TFRecordDataset([f.as_posix() for f in fs_train])\r\n#ds_train = ds_train.cache()\r\n\r\nds_train = ds_train.map(lambda x: tf.parse_single_example(x, {\r\n    \"features\": tf.FixedLenFeature([132], tf.float32),\r\n    \"label\": tf.FixedLenFeature([1], tf.float32),\r\n}), num_parallel_calls=num_cores)\r\n\r\nds_train = ds_train.interleave(lambda v: tf.data.Dataset.from_tensors((v[\"features\"][2:], v[\"label\"])),\r\n                               cycle_length=num_cores, block_length=1,\r\n                               num_parallel_calls=num_cores)\r\n\r\nds_train = ds_train.filter(\r\n    lambda _, y: tf.reshape(tf.logical_or(\r\n        tf.equal(y, Ls[0]),\r\n        tf.equal(y, Ls[1])\r\n    ), [])\r\n)\r\n\r\nds_train = ds_train.interleave(lambda x, y: tf.data.Dataset.from_tensors((x, y - base_label.value)),\r\n                               cycle_length=num_cores, block_length=1,\r\n                               num_parallel_calls=num_cores)\r\n\r\nds_train = ds_train.window(size=num_tsteps, shift=1, stride=1, drop_remainder=True)\r\nds_train = ds_train.interleave(lambda x, y: tf.data.Dataset.zip((x.batch(num_tsteps), y.batch(num_tsteps))),\r\n                               cycle_length=num_cores, block_length=1,\r\n                               num_parallel_calls=num_cores)\r\n\r\nds_train = ds_train.batch(batch_size, drop_remainder=True)\r\n\r\nds_train = ds_train.cache()\r\nds_train = ds_train.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\r\n```\r\n\r\nRunning result:\r\n![2019-08-15-122121_1920x1080_scrot](https://user-images.githubusercontent.com/53339396/63089956-f8486780-bf59-11e9-8a97-7f2e9f8c15b9.png)\r\n\r\nNB: I put `cache()` more towards the end as it had no effect when putting it before `window()` even though it seems redundant to store windowed results...", "`prefetch` works as expected. It decouples the producer from consumer, using an internal buffer. What I suspect is going on is that your input pipeline is running slower than your training step, which means that you get little benefits from preprocessing.\r\n\r\nYou could confirm this hypothesis by separately benchmarking a) the latency of your input pipeline and b) the latency of your model with synthetic data. If a) is much higher than b) you will get little benefits from prefetching and you should instead focus on optimizing the performance of you input pipeline through parallelization. My recommendation would be to use [Tensorboard Keras profiler](https://www.tensorflow.org/tensorboard/r2/tensorboard_profiling_keras) to understand what is going on in your input pipeline. If you share a link to your trace, I would be happy to provide insights.", "Thank you for your comment. I understand and I am currently (hopefully) profiling the model fitting to confirm your hypothesis. Until now I am struggling to get TensorBoard to visualize the profile. Anyway, I wanted to let you know that I am still looking into this.\r\n\r\nAs a side note: `Dataset.cache()` seems to work when using a hard disk file instead of RAM. The second epoch forward is now as fast as I would expect which further supports your hypothesis.\r\n\r\n**EDIT**: I also want to stress, that _something_ is still amiss with the data pipeline even if `prefetch()` turns out to work as expected. The performance of epoch 0 (i.e. empty cache) is extremely slow compared to reading and pre-processing the data with Dask/Pandas and feeding plain numpy arrays to the Dataset API. It could be that the pipeline does not read/process data in parallel but I am unsure how to enable this feature. `num_parallel_calls` and `tf.data.Dataset.interleave` had no effect for me so far. I can confirm that the CPU usage is small compared to the Dask pipeline when using the TF Dataset API.", "@jsimsa Thanks again for your comment. I attached ([log_20190904150036.tar.gz](https://github.com/tensorflow/tensorflow/files/3575133/log_20190904150036.tar.gz)) a trace from the following pipeline:\r\n\r\n    ds = tf.data.TFRecordDataset([f.as_posix() for f in files])\r\n    ds = ds.map(lambda x: tf.parse_single_example(x, {\r\n        \"features\": tf.FixedLenFeature([132], tf.float32),\r\n        \"label\": tf.FixedLenFeature([1], tf.float32),\r\n    }), num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\n    ds = ds.flat_map(lambda v: tf.data.Dataset.from_tensors((v[\"features\"][2:], v[\"label\"])))\r\n\r\n    # only allow two labels\r\n    ds = ds.filter(\r\n        lambda _, y: tf.reshape(tf.logical_or(\r\n            tf.equal(y, Ls[0]),\r\n            tf.equal(y, Ls[1])\r\n        ), [])\r\n    )\r\n\r\n    ds = ds.flat_map(lambda x, y: tf.data.Dataset.from_tensors((x, y - base_label.value)))\r\n    ds = ds.cache(cachefile)\r\n    ds = ds.window(size=num_tsteps, shift=1, stride=1, drop_remainder=True)\r\n    ds = ds.flat_map(lambda x, y: tf.data.Dataset.zip((x.batch(num_tsteps), y.batch(num_tsteps))))\r\n    ds = ds.batch(batch_size, drop_remainder=True)\r\n    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\r\n\r\nI am looking forward to your insights regarding the performance. \r\n\r\nAdditionally, I am currently running another training with a modified pipeline that (hopefully) is functionally equivalent but should be fully parallelized. However, the performance seems not to increase at all (also the CPU usage does not increase, no matter the amount of `num_cores`). Here is the trace:  [log_20190904151101.tar.gz](https://github.com/tensorflow/tensorflow/files/3575226/log_20190904151101.tar.gz)\r\n\r\n    num_cores = 20\r\n    ds = tf.data.TFRecordDataset([f.as_posix() for f in files])\r\n    ds = ds.map(lambda x: tf.io.parse_single_example(x, {\r\n        \"features\": tf.io.FixedLenFeature([132], tf.float32),\r\n        \"label\": tf.io.FixedLenFeature([1], tf.float32),\r\n    }), num_parallel_calls=num_cores)\r\n    ds = ds.map(lambda v: (v[\"features\"][2:], v[\"label\"]), num_parallel_calls=num_cores)\r\n\r\n    def flt(x, y):\r\n        c = tf.cond(tf.reshape(tf.logical_or(tf.equal(y, Ls[0]), tf.equal(y, Ls[1])), []),\r\n                    lambda: tf.constant(1, dtype=tf.int64),\r\n                    lambda: tf.constant(0, dtype=tf.int64))\r\n        return tf.data.Dataset.from_tensors((x, y)).repeat(c)\r\n    ds = ds.interleave(flt, cycle_length=num_cores, block_length=1,\r\n                      num_parallel_calls=num_cores)\r\n\r\n    ds = ds.map(lambda x, y: (x, y - base_label.value), num_parallel_calls=num_cores)\r\n    ds = ds.cache(cachefile)\r\n    ds = ds.window(size=num_tsteps, shift=1, stride=1, drop_remainder=True)\r\n    ds = ds.interleave(lambda x, y: tf.data.Dataset.zip((x.batch(num_tsteps), y.batch(num_tsteps))),\r\n                       cycle_length=num_cores, block_length=1,\r\n                       num_parallel_calls=num_cores)\r\n    ds = ds.batch(batch_size, drop_remainder=True)\r\n    ds = ds.prefetch(1)", "I looked at your trace but in the five second window it captures only see one tf.data \"get_next\" event, which takes <40us. This suggests you are not input pipeline bound. Have you tried benchmarking the latency of your input pipeline (i.e. how long it takes to extra an element running in tight loop):\r\n\r\n```\r\nimport timeit\r\n\r\nstart = timeit.default_timer()\r\ni = 0\r\nfor elem in dataset:\r\n  i += 1\r\nend = timeit.default_timer()\r\nprint(\"Average latency {}\".format((end - start) / i))\r\n```\r\nSeparately from the above, try collecting a longer trace (e.g. 30 seconds).\r\n", "~When running your code snipped my workstation does run out of memory (128 GB RAM). For some reason, iterating the dataset like this occupies all memory after approximately 9920000 iterations (i added a `print(i)` every 10000 rounds to see some progress). After that the execution stalls and nothing happens further. However, I can confirm that the execution takes a long time (similar to running the actual training) and it seems even without further processing the generated elements (i.e. training), the pipeline is slow.~\r\n\r\nI tried to do a longer trace as well but unfortunately, the documentation you posted does only really show how to trace exactly one batch (which is probably what you see in the traces above):\r\n\r\n```\r\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, profile_batch = 3)\r\nmodel.fit(train_data,\r\n          steps_per_epoch=20,\r\n          epochs=5, \r\n          callbacks=[tensorboard_callback])\r\n```\r\n\r\nFurther down the [profiler service is briefly introduced](https://www.tensorflow.org/tensorboard/r2/tensorboard_profiling_keras#profiler_service) but `tf.python.eager.profiler.start_profiler_server()` does neither exist in TensorFlow 1.14 nor in TensorFlow 2.0.0-rc0. It seems to be the only \"documented\" way to use the Keras API for training (as opposed to using `session.run()` directly) and creating traces of specific length. Could you provide further instructions on how to create the trace you suggested collecting?\r\n\r\n~~**EDIT:** Note that because of `ds.filter()` there should only be 203698 elements in the dataset, judging from the trainings, e.g.~~\r\n```\r\n# ...\r\nEpoch 2/50\r\n203698/203698 - 1259s - loss: 0.0876 - acc: 0.9680\r\nEpoch 3/50\r\n203698/203698 - 1258s - loss: 0.0800 - acc: 0.9704\r\n# ...\r\n```\r\n~~I guess simply iterating the dataset does not batch, and it does not create a cache file even though `ds.cache(cachefile)` is given.~~\r\n\r\n**EDIT2:** I realized that the issue is caused by not running in eager execution mode and after enabling it, I got this result:\r\n```\r\nAverage latency 0.05543092633988548\r\nstart: 246634.557416572\r\nend: 257925.726250154\r\ni: 203698\r\n```\r\n", "Have you tried using the [Profiler Service](https://www.tensorflow.org/tensorboard/r2/tensorboard_profiling_keras#profiler_service)?", "Yes, sorry, I got some errors before. I now captured 60 seconds to ensure getting multiple phases of valid and invalid samples (see https://github.com/tensorflow/tensorflow/issues/31616#issue-480636359, data is only partially valid in one time series file). \r\n\r\nHere is the trace: [log_20190906075644.tar.gz](https://github.com/tensorflow/tensorflow/files/3582909/log_20190906075644.tar.gz)\r\n\r\n**EDIT:** I created a few more traces because they look all so different to my untrained eye. I hope I could capture some relevant parts.\r\n[log_20190906082335_1.tar.gz](https://github.com/tensorflow/tensorflow/files/3583581/log_20190906082335_1.tar.gz)\r\n[log_20190906082335_2.tar.gz](https://github.com/tensorflow/tensorflow/files/3583582/log_20190906082335_2.tar.gz)\r\n[log_20190906082335_3.tar.gz](https://github.com/tensorflow/tensorflow/files/3583583/log_20190906082335_3.tar.gz)", "Hrm, it is odd that the different samples look different (and the information in the trace does not seem coherent). I could try running your input pipeline myself and analyze it for you but for that, I would need end-to-end reproducible example (include the data).", "Thank you for your kind offer, that's really nice. However, due to project deadlines, I had to switch to pre-processing the data in Dask and storing already the pre-processed data to tfrecord files. Doing this, the Tensorflow Dataset-pipeline is reduced to merely reading the files and the training is accelerated. Of course, I am still interested in using the more elegant way of pre-processing the data in parallel on-the-fly, but I would feel bad if you invested a lot of your time into this while there is no emergency.\r\n\r\nAdditionally, the data is proprietary, although, of course, I could provide you with fake data of the same shape and size. So, if you are interested in this as well, let me know and I will create a minimal working example including fake data. In either case, thank you very much for your kind support!", "Makes sense. I would be happy to take a look at your MRE. I will leave it up to you if you wish to close this issue, or follow up with MRE.", "It seems I cannot find the time to create a MRE as I continue to run into different issues that need to be resolved asap. As this issues is mitigated by preprocessing the data before training time, I am going to close it. Thanks again for your offer and your help!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31616\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/31616\">No</a>\n", "@jsimsa @srihari-humbarwadi @jvishnuvardhan @ravikyram \r\nHi , I'm not familiar with tf.data api\uff0cin my case, I found the IO is a problem: GPU uti is low, about 15%. I use a generator function to read local multiple pickle files(about 200K), examples are bellow: \r\n```\r\ndef train_data():\r\n    while True:\r\n        for i in shuffle(train_id):\r\n            df = pd.read_pickle(df_train_val['file_name'].iloc[i],\r\n                                compression='gzip')\r\n            feature = df.to_numpy().reshape(df.shape[0], -1)\r\n            yield feature.reshape(-1, 56),feature.reshape(-1, 56)\r\n```\r\nThen\r\n```\r\ngn = tf.data.Dataset.from_generator(train_data, output_types=(tf.float32, tf.float32),\r\n                                          output_shapes=((None, 56),(None, 56))\r\n                                         ).prefetch(tf.data.experimental.AUTOTUNE)\r\n```\r\nI found prefetch not work and IO bottleneck is very high, so any advice for this case, how can I speed up the training process?", "@Anhaoxu Please create a new issue and provide a simple standalone code to reproduce the issue. Thanks!", "Please see https://github.com/tensorflow/tensorflow/issues/43905#issuecomment-823675760"]}]