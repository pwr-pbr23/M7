[{"number": 426, "title": "problem about session.run", "body": "Hi guys, I am very new to tensorflow. Now I am implementing a pairwise cnn model. While I got the error:\n\nFile \"Train.py\", line 72, in <module>\n    train()\n  File \"Train.py\", line 48, in train\n    feature1,feature2,train_loss,_=sess.run([model.feature1,model.feature2,model.cost,model.train_op],feed)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 345, in run\n    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)\n  File \"/usr/lib/python2.7/site-packages/tensorflow/python/client/session.py\", line 404, in _do_run\n    target_list)\ntensorflow.python.pywrap_tensorflow.StatusNotOK: Not found: FeedInputs: unable to find feed output Placeholder:0\n\nHere in the sess.run function, feed is a dictionary containing input data and corresponding labels. feature1 and feature2 are the output of the same neural networks and finally I would like to compare feature1 and feature2.\n\nAny help are more than welcome. Thanks!\n", "comments": ["This is a better question for stackoverflow, since if we answer it there it'll be easy for future users to find the answer via search.  Can you repost and add the question link here?\n", "hi girving, thanks for your advice. You can find the same question in stack flow with the link http://stackoverflow.com/questions/34150921/session-run-error-when-implement-a-pairwise-cnn-with-tensorflow\n\nLook forward to your answer :0\n"]}, {"number": 425, "title": "Cannot install tensorflow via pip", "body": "## 1) If I install directly\n\n(I already have pip in my machine):\n\n``` sh\nsudo pip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.5.0-py2-none-any.whl\nsudo easy_install --upgrade six\n```\n\nI receive the following errors: \n\n```\nDownloading/unpacking https://storage.googleapis.com/tensorflow/mac/tensorflow-0.5.0-py2-none-any.whl\n  Downloading tensorflow-0.5.0-py2-none-any.whl (9.8MB): 9.8MB downloaded\n  Running setup.py egg_info for package from https://storage.googleapis.com/tensorflow/mac/tensorflow-0.5.0-py2-none-any.whl\n    Traceback (most recent call last):\n      File \"<string>\", line 16, in <module>\n    IOError: [Errno 2] No such file or directory: '/tmp/pip-Kf4UD9-build/setup.py'\n    Complete output from command python setup.py egg_info:\n    Traceback (most recent call last):\n\n  File \"<string>\", line 16, in <module>\n\nIOError: [Errno 2] No such file or directory: '/tmp/pip-Kf4UD9-build/setup.py'\n\n----------------------------------------\nCommand python setup.py egg_info failed with error code 1 in /tmp/pip-Kf4UD9-build\nStoring complete log in /Users/kanitw/.pip/pip.log\n```\n## 2) If I install via virtualenv\n\n``` sh\nvirtualenv --system-site-packages ~/tensorflow\nsource ~/tensorflow/bin/activate\npip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.5.0-py2-none-any.whl\n```\n\nI receive the following errors: \n\n```\nDownloading/unpacking https://storage.googleapis.com/tensorflow/mac/tensorflow-0.5.0-py2-none-any.whl\n  Downloading tensorflow-0.5.0-py2-none-any.whl (9.8MB): 9.8MB downloaded\n  Running setup.py egg_info for package from https://storage.googleapis.com/tensorflow/mac/tensorflow-0.5.0-py2-none-any.whl\n    Traceback (most recent call last):\n      File \"<string>\", line 16, in <module>\n    IOError: [Errno 2] No such file or directory: '/var/folders/h3/9m4gf8ln7yngtp_36k84d9hm0000gn/T/pip-Wy0s9g-build/setup.py'\n    Complete output from command python setup.py egg_info:\n    Traceback (most recent call last):\n\n  File \"<string>\", line 16, in <module>\n\nIOError: [Errno 2] No such file or directory: '/var/folders/h3/9m4gf8ln7yngtp_36k84d9hm0000gn/T/pip-Wy0s9g-build/setup.py'\n\n----------------------------------------\nCommand python setup.py egg_info failed with error code 1 in /var/folders/h3/9m4gf8ln7yngtp_36k84d9hm0000gn/T/pip-Wy0s9g-build\nStoring complete log in /Users/kanitw/.pip/pip.log\n```\n", "comments": ["https://www.tensorflow.org/install/install_linux#common_installation_problems ?\r\n", "That works, thank you for super-fast reply!\n", "@vrv \r\nthe link you have shared is broken", "https://www.tensorflow.org/install/install_linux#common_installation_problems", "good it work for me   \r\n"]}, {"number": 424, "title": "Using Linear Algebraic Functions In TensorFlow Python", "body": "Hey TF, \n\nMatrix norm in python, it doesn't appear the documentation. However, in your Eigen section, there is a matrix norm function. \n\nIs it possible to use these eigen functions via python and ensure that it is performed on the gpu? These linear algebraic functions are very easy to do in theano, but I'm having difficulty figuring out how to do this in python. \n\nMy ultimate goal is to perform a [euclidean norm](http://mathworld.wolfram.com/FrobeniusNorm.html).  I just don't know what is the best way to do this in python would be. Thanks!\n", "comments": ["Oh wow...I'm pretty dumb...You can just make them from tensorflow's functions. In case anyone needs them:\n\n``` python\ndef euclidean_norm(tensor, reduction_indicies = None):\n    squareroot_tensor = tf.sqrt(tensor)\n    euclidean_norm = tf.sum(squareroot_tensor, reduction_indicies =  reduction_indicies)\n    return euclidean_norm\n\ndef frobenius_norm(tensor, reduction_indicies = None):\n    squareroot_tensor = tf.sqrt(tensor)\n    tensor_sum = tf.sum(squareroot_tensor, reduction_indicies =  reduction_indicies)\n    frobenius_norm = tf.sqrt(tensor_sum)\n    return frobenius_norm\n```\n", "For your norms, I think you want to square before the sum instead of sqrt.\n", "@ebrevdo Thanks for the correction! Here are they corrected:\n\n``` python\ndef euclidean_norm(tensor, reduction_indicies = None, name = None):\n    with tf.op_scope(tensor + reduction_indicies, name, \"euclidean_norm\"): #need to have this for tf to work\n        squareroot_tensor = tf.square(tensor)\n        euclidean_norm = tf.sum(squareroot_tensor, reduction_indicies =  reduction_indicies)\n        return euclidean_norm\n\ndef frobenius_norm(tensor, reduction_indicies = None, name = None):\n    with tf.op_scope(tensor + reduction_indicies, name, \"frobenius_norm\"): #need to have this for tf to work\n        squareroot_tensor = tf.square(tensor)\n        tensor_sum = tf.sum(squareroot_tensor, reduction_indicies =  reduction_indicies)\n        frobenius_norm = tf.sqrt(tensor_sum)\n        return frobenius_norm\n\n```\n"]}, {"number": 423, "title": "Add targets to build libtensorflow.so and libtensorflow.dylib", "body": "Using these build targets to build libtensorflow for use with node.js.\n\nHoping these don't have to live in my fork, and can be merged.\n\nThanks, Nikhil\n", "comments": []}, {"number": 422, "title": "Sigaction invalid argument error while running the translate example.", "body": "I am running the translate example (installed from the source using the CPU only mode on Ubuntu running in VMware) using this command from the tutorial:\n\n```\nbazel run -c opt tensorflow/models/rnn/translate:translate -- \n--data_dir [your_data_directory] --train_dir [checkpoints_directory] --en_vocab_size=40000 --fr_vocab_size=40000\n```\n\nThe data downloads fine and runs for a few hours. It creates the vocabulary and tokenizes giga-fren.release2.fr and giga-fren.release2.en. However it throws an error in the \"Reading development and training data (limit: 0).\" step. Here are the last couple of log lines:\n\n```\n  reading data line 13300000\n  reading data line 13400000\n  reading data line 13500000\n  reading data line 13600000\n  reading data line 13700000\nsrc/main/tools/process-tools.c:88: sigaction(sig, &sa, NULL): Invalid argument\nERROR: Non-zero return code '1' from command: Process exited with status 1.\n```\n\nAny idea why I get this error?\n", "comments": ["Hmm, this one is confusing, especially since process-tools.c is a part of bazel, not tensorflow.  I'm not sure why bazel would be doing anything of significance after the job is launched.  @vrv?\n", "@davidzchen, if he knows more\n", "Appreciate the help. I have attached the execution log file in case it helps. Ubuntu 14.04 64bit on VMware workstation 12. \n[log.txt](https://github.com/tensorflow/tensorflow/files/55295/log.txt)\n", "Sorry for the delay.\n\nI haven't seen this before. @philwo Do you know what might be causing this?\n", "Hi @roostapour,\n\nit looks like the binary receives a signal that kills it while it processes your data. I think the process-tools.c part of Bazel is just reporting that, though the logging could surely be improved here!\n\nCould you please run your binary directly (not via bazel run) and see if it then works fine, or if it crashes at the same point in time?\n\nIt should work simply like this:\n\n # Step 1: Build\nbazel build -c opt //tensorflow/models/rnn/translate:translate\n\nNote that this prints the path to the binary after a successful build, like this:\n____Building complete.\nTarget //tensorflow/models/rnn/translate:translate up-to-date:\n  bazel-bin/tensorflow/models/rnn/translate/translate\n\n # Step 2: Just run the binary from the path printed there:\nbazel-bin/tensorflow/models/rnn/translate/translate --data_dir [your_data_directory] --train_dir [checkpoints_directory] --en_vocab_size=40000 --fr_vocab_size=40000\n", "Others have had the same error after they were out of memory. Could this be the problem? Is this still a problem in the latest release?\n", "Thanks everyone. I tried the latest release with @philwo's steps and here are the last lines of the log:\n\n```\n  reading data line 16600000\n  reading data line 16700000\n  reading data line 16800000\nKilled\n```\n\nI think it is a memory limitation problem. I set up the TensorFlow on another VM machine with a bit more RAM and ran the translate example again. The error happened after several thousands more lines were processed.\n", "This error generally seems to be a memory issue. There are a few other\npeople that have seen this and it was always OOM.\n\nOn Tue, Dec 15, 2015 at 11:59 AM roostapour notifications@github.com\nwrote:\n\n> Thanks everyone. I tried the latest release with @philwo\n> https://github.com/philwo's steps and here are the last lines of the\n> log:\n> \n>   reading data line 16600000\n>   reading data line 16700000\n>   reading data line 16800000\n> Killed\n> \n> I think it is a memory limitation problem. I set up the TensorFlow on\n> another VM machine with a bit more RAM and ran the translate example again.\n> The error happened after several thousands more lines were processed.\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/422#issuecomment-164877742\n> .\n", "Is this OOM issue in TensorFlow or in Bazel?\n", "The OOM issue is in TensorFlow.\n", "Closing due to inactivity.  Probably can better be addressed by running the example via binary install than through bazel.\n"]}, {"number": 421, "title": "Use __all__ to restrict exported Python symbols to the public API", "body": "As part of semantic versioning, our public Python API is (about to be) defined as the symbols documented at https://www.tensorflow.org/api_docs/python.  This is a good definition, but it makes it easy for users to accidentally depend on the non-public API.  To fix this, we should add `__all__` to our Python modules and make sure `__all__` matches the documented public API exactly.\n\nSince we already declare the public symbols via '@@' references in the module docstring, we may be able to do this programmatically.  Indeed,\n\n```\n__all__ = [m.group(1) for m in re.finditer(r'^@@(\\w+)$', sys.modules[__name__].__doc__)]\n```\n\nFor Google folk, see b/25561952.\n", "comments": ["I like that **all** solution, then we only have to worry about the top-level tf module.\n", "We can build the toplevel `__all__` by concatenating the submodule `__all__`s.\n", "This will not work for classes and class members, correct? I suppose we can rely on _ for members, but classes may be trickier.\n", "It should work fine for classes, and class members aren't part of either `__all__` or the module docstring. \n", "Internal note: Once this is done, we should test that all exposed symbols are documented.\n", "@cwhipkey has made progress on this.\n", "@cwhipkey: What's the recent status of this?  Are we still in large whitelist stage? \n", "Yes, still in the large whitelist stage for the modules that have **all** added.  There are also some modules that don't have **all** added, like 'flags'.\n", "This is now done. Thanks!"]}, {"number": 420, "title": "SparseCrossEntropy in TensorFlow", "body": "Hey TF, \n\nIn your Translate, seq2seq example, there is a part where you require conversion from a sparse to dense matrix to do a softmax. \n\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/seq2seq.py#L670\n\nThe comment there states that tensorflow needs a sparsecrossentropy function in order for this computation to be done on the gpu (and more efficiently overall). I was wondering: was this implementation planned to happen soon? Thanks!\n", "comments": ["It's on our list of things to do, yes, the sooner the better. Meanwhile the one in seq2seq seems to be reasonably efficient, at least it's not a bottleneck - check it out.\n", "thanks @lukaszkaiser -- I have been using the one in seq2seq since its release. The biggest problem though is that you are forced to used a cpu for the softmax, meaning you can't take advantage of using another gpu to do the softmax. As a result, it does lead to longer training times. \n\nI'll close this issue. But I wouldn't mind trying to help out to get this done on the gpu! Thanks! \n"]}, {"number": 419, "title": "Failed to run Android demo targeting API < 20", "body": "I tried to build the demo application for Android for KitKat device (API 20). I was able to modify the app not to use new `hardware.camera2` and it worked on Android Lollipops successfully. However there is an issue targeting older Android device. \nIt turned out that the app crashes right after trying to load the native shared library, `tensorflow_demo` in my case.\nAnd that's due to dependency of `libpthread.so` to `libmediandk.so` that is not supported for API older than 21. See the following logcat message:\n\nError: `..dlopen failed: could not load library \"libmediandk.so\" needed by \"libtensorflow_demo.so\"; caused by library \"libmediandk.so\" not found`\n\nI also desperately tried to replace the cloned `libpthread.so` with the same file from my  `/usr/arm-linux-gnueabi/lib/` directory with no success.\nI am using:\n    1- android-ndk-r10c\n    2- api_level=20\n    3- build_tools_version = \"20.0.0\"\n\nDid I missed anything in that process? \n", "comments": ["Hi Hamid,\n\nThe libpthread.so target is just a kludge to get around the fact that the\nprotobuf library attempts to link it in, despite this not being necessary\n(or possible) on Android.\n\nA cleaner workaround for you is to edit google/protobuf/BUILD and change\nthe line:\n\nLINK_OPTS = [\"-lpthread\"]\nto:\nLINK_OPTS = [\"\"]\n\nIdeally the protobuf linkopts would be dependent on build target, or the\ndummy libpthread.so file could be generated at compile-time so that it\nwould match the target architecture (will look into it).\n\nOn Sat, Dec 5, 2015 at 5:19 PM, Hamid Bazargani notifications@github.com\nwrote:\n\n> I tried to build the demo application for Android for KitKat device (API\n> 20). I was able to modify the app not to use new hardware.camera2 and it\n> worked on Android Lollipops successfully. However there is an issue\n> targeting older Android device.\n> It turned out that the app crashes right after trying to load the native\n> shared library, tensorflow_demo in my case.\n> And that's due to dependency of libpthread.so to libmediandk.so that is\n> not supported for API older than 21. See the following logcat message:\n> \n> Error: ..dlopen failed: could not load library \"libmediandk.so\" needed by\n> \"libtensorflow_demo.so\"; caused by library \"libmediandk.so\" not found\n> \n> I also desperately tried to replace the cloned libpthread.so with the\n> same file from my /usr/arm-linux-gnueabi/lib/ directory with no success.\n> I am using:\n> 1- android-ndk-r10c\n> 2- api_level=20\n> 3- build_tools_version = \"20.0.0\"\n> \n> Did I missed anything in that process?\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/419.\n", "Hi Andrew,\nI think `pthread` also resolves some POSIX symbols like `getPageSize`,  `strtof`, ... that are used elsewhere.\nBy removing `-lpthread`, I still get unresolved reference errors.\nHow should I resolve them by removing pthread ?\nThanks,\nHamid\n", "The libpthread.so in the TF repo is not actually a copy of libpthead.so\n(it's actually arbitrarily cloned from libmediandk.so, which could explain\nyour earlier link errors), so it's not possible that it could be providing\nanything. Those functions are found in other libraries on Android.\n-DHAVE_PTHREAD still applies, it just doesn't need to actually link in\npthread.\n\nIf you:\n1. remove the \"-lpthread\" from google/protobuf/BUILD,\n2. delete the \":dummy_pthread\" dep in tensorflow/examples/android/BUILD\n3. build with:\n   bazel build tensorflow/examples/android:tensorflow_demo\n   --config=android_arm\n\nwith no other changes do you still get the same errors? Please attach a log\nif so.\n\nOn Sat, Dec 5, 2015 at 8:13 PM, Hamid Bazargani notifications@github.com\nwrote:\n\n> Hi Andrew,\n> I think pthread also resolves some POSIX symbols like getPageSize, strtof,\n> ... that are used elsewhere.\n> By removing -lpthread, I still get unresolved reference errors.\n> How should I resolve them by removing pthread ?\n> Thanks,\n> Hamid\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/419#issuecomment-162261581\n> .\n", "First I should  mention that there is no issue when trying the app on a Android 5.0 device. The problem happens when using KitKat device.\nI followed your instruction. Still no success.\nFollowing is my steps:\n\n### 1- changed google/protobuf/BUILD\n\n```\n// [\"\"] returns bazel error\nLINK_OPTS = []\n```\n\n### 2- changed tensorflow/examples/android/BUILD\n\n```\ncc_library(\n    name = \"tensorflow_native_libs\",\n    srcs = glob([\"jni/**/*.cc\"]),\n    hdrs = glob([\"jni/**/*.h\"]),\n    copts = [\n        \"-std=c++11\",\n        \"-mfpu=neon\",\n        \"-O2\",\n    ],\n    linkopts = [\"-llog -landroid -lm -ljnigraphics\"],\n    tags = [\n        \"manual\",\n        \"notap\",\n    ],\n    deps = [\n    #    \":dummy_pthread\", // commented\n        \"//tensorflow/core:android_tensorflow_lib\",\n    ],\n)\n```\n\n### 3- My workspace looks:\n\n```\nandroid_sdk_repository(\n    name = \"androidsdk\",\n    api_level = 20,\n    build_tools_version = \"20.0.0\",\n    # Replace with path to Android SDK on your system\n    path = \"/hamidb/software/TADP/android-sdk-linux\",\n)\nandroid_ndk_repository(\n    name=\"androidndk\",\n    path=\"/hamidb/software/TADP/android-ndk-r10c\",\n    api_level=21)\n```\n\n### 4- I issued (I also tried without android_arm)\n\nbazel build --verbose_failures //tensorflow/examples/android:tensorflow_demo --config=android_arm\n\n### After running the apk file my logcat logs:\n\n> --------- beginning of /dev/log/main\n> D/Raydium_ts_main(  242): ## Report rate in 10 seconds =1213 \n> I/art     ( 1219): GcCauseBackground partial concurrent mark sweep GC freed 6011(335KB) AllocSpace objects, 27(1351KB) LOS objects, 12% free, 6MB/7MB, paused 5.823ms total 48.435ms\n> --------- beginning of /dev/log/system\n> I/ActivityManager(  904): START u0 {act=android.intent.action.MAIN cat=[android.intent.category.LAUNCHER] flg=0x10200000 cmp=org.tensorflow.demo/.CameraActivity bnds=[984,1381][1176,1573]} from pid 1219\n> W/art     (  166): Could not get current activity\n> I/ActivityManager(  904): Start proc org.tensorflow.demo for activity org.tensorflow.demo/.CameraActivity: pid=11918 uid=10073 gids={50073, 1028, 1015}\n> W/NvAppProfileService(  904): App Profiles: Enabled\n> I/PowerServiceCient(  904): Successfully bound to service\n> **_`E/art     (11918): dlopen(\"/data/app-lib/org.tensorflow.demo-1/libtensorflow_demo.so\", RTLD_LAZY) failed: dlopen failed: cannot locate symbol \"getpagesize\" referenced by \"libtensorflow_demo.so\"...`**_\n> D/AndroidRuntime(11918): Shutting down VM\n> E/AndroidRuntime(11918): FATAL EXCEPTION: main\n> E/AndroidRuntime(11918): Process: org.tensorflow.demo, PID: 11918\n> **`E/AndroidRuntime(11918): java.lang.UnsatisfiedLinkError: dlopen failed: cannot locate symbol \"getpagesize\" referenced by \"libtensorflow_demo.so\"...`**\n> E/AndroidRuntime(11918):    at java.lang.Runtime.loadLibrary(Runtime.java:364)\n> E/AndroidRuntime(11918):    at java.lang.System.loadLibrary(System.java:526)\n> E/AndroidRuntime(11918):    at org.tensorflow.demo.TensorflowClassifier.<clinit>(TensorflowClassifier.java:46)\n> E/AndroidRuntime(11918):    at org.tensorflow.demo.TensorflowImageListener.<init>(TensorflowImageListener.java:51)\n> E/AndroidRuntime(11918):    at org.tensorflow.demo.CameraConnectionFragment.<init>(CameraConnectionFragment.java:212)\n> E/AndroidRuntime(11918):    at org.tensorflow.demo.CameraConnectionFragment.newInstance(CameraConnectionFragment.java:91)\n> E/AndroidRuntime(11918):    at org.tensorflow.demo.CameraActivity.onCreate(CameraActivity.java:30)\n> E/AndroidRuntime(11918):    at android.app.Activity.performCreate(Activity.java:5231)\n> E/AndroidRuntime(11918):    at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1087)\n> E/AndroidRuntime(11918):    at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2160)\n> E/AndroidRuntime(11918):    at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2246)\n> E/AndroidRuntime(11918):    at android.app.ActivityThread.access$800(ActivityThread.java:136)\n> E/AndroidRuntime(11918):    at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1197)\n> E/AndroidRuntime(11918):    at android.os.Handler.dispatchMessage(Handler.java:102)\n> E/AndroidRuntime(11918):    at android.os.Looper.loop(Looper.java:136)\n> E/AndroidRuntime(11918):    at android.app.ActivityThread.main(ActivityThread.java:5030)\n> E/AndroidRuntime(11918):    at java.lang.reflect.Method.invoke(Native Method)\n> E/AndroidRuntime(11918):    at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:793)\n> E/AndroidRuntime(11918):    at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:609)\n> W/ActivityManager(  904):   Force finishing activity org.tensorflow.demo/.CameraActivity\n> W/ActivityManager(  904): Activity pause timeout for ActivityRecord{65595fd8 u0 org.tensorflow.demo/.CameraActivity t73 f}\n> I/Process (11918): Sending signal. PID: 11918 SIG: 9\n> W/InputMethodManagerService(  904): Window already focused, ignoring focus gain of: com.android.internal.view.IInputMethodClient$Stub$Proxy@65367aa0 attribute=null, token = android.os.BinderProxy@651cfa98\n> I/ActivityManager(  904): Process org.tensorflow.demo (pid 11918) has died.\n> D/Raydium_ts_main(  242): ## Report rate in 10 seconds =1038 \n", "Thanks Hamid. I'm guessing this might be a discrepancy between what the\ncompiler expects of API level 21 and what the device provides at level 20.\n\nI've just tried setting my WORKSPACE ndk api_level to 20 and found that the\nAndroid demo still builds. Could you try the same and see if that corrects\nthe issue?\n\nOn Sat, Dec 5, 2015 at 9:33 PM, Hamid Bazargani notifications@github.com\nwrote:\n\n> I followed your instruction. Still no success.\n> Following is my steps:\n> 1- changed google/protobuf/BUILD\n> \n> // [\"\"] returns bazel error\n> LINK_OPTS = []\n> \n> 2- changed tensorflow/examples/android/BUILD\n> \n> cc_library(\n>     name = \"tensorflow_native_libs\",\n>     srcs = glob([\"jni/**/*.cc\"]),\n>     hdrs = glob([\"jni/**/*.h\"]),\n>     copts = [\n>         \"-std=c++11\",\n>         \"-mfpu=neon\",\n>         \"-O2\",\n>     ],\n>     linkopts = [\"-llog -landroid -lm -ljnigraphics\"],\n>     tags = [\n>         \"manual\",\n>         \"notap\",\n>     ],\n>     deps = [\n>     #    \":dummy_pthread\", // commented\n>         \"//tensorflow/core:android_tensorflow_lib\",\n>     ],\n> )\n> \n> 3- My workspace looks:\n> \n> android_sdk_repository(\n>     name = \"androidsdk\",\n>     api_level = 20,\n>     build_tools_version = \"20.0.0\",\n>     # Replace with path to Android SDK on your system\n>     path = \"/hamidb/software/TADP/android-sdk-linux\",\n> )\n> android_ndk_repository(\n>     name=\"androidndk\",\n>     path=\"/hamidb/software/TADP/android-ndk-r10c\",\n>     api_level=21)\n> \n> 4- I issued (I also tried without android_arm)\n> \n> bazel build --verbose_failures\n> //tensorflow/examples/android:tensorflow_demo --config=android_arm\n> After running the apk file my logcat logs:\n> \n> --------- beginning of /dev/log/main\n> D/Raydium_ts_main( 242): ## Report rate in 10 seconds =1213\n> I/art ( 1219): GcCauseBackground partial concurrent mark sweep GC freed\n> 6011(335KB) AllocSpace objects, 27(1351KB) LOS objects, 12% free, 6MB/7MB,\n> paused 5.823ms total 48.435ms\n> --------- beginning of /dev/log/system\n> I/ActivityManager( 904): START u0 {act=android.intent.action.MAIN\n> cat=[android.intent.category.LAUNCHER] flg=0x10200000\n> cmp=org.tensorflow.demo/.CameraActivity bnds=[984,1381][1176,1573]} from\n> pid 1219\n> W/art ( 166): Could not get current activity\n> I/ActivityManager( 904): Start proc org.tensorflow.demo for activity\n> org.tensorflow.demo/.CameraActivity: pid=11918 uid=10073 gids={50073, 1028,\n> 1015}\n> W/NvAppProfileService( 904): App Profiles: Enabled\n> I/PowerServiceCient( 904): Successfully bound to service\n> _E/art (11918):\n> dlopen(\"/data/app-lib/org.tensorflow.demo-1/libtensorflow_demo.so\",\n> RTLD_LAZY) failed: dlopen failed: cannot locate symbol \"getpagesize\"\n> referenced by \"libtensorflow_demo.so\"..._\n> D/AndroidRuntime(11918): Shutting down VM\n> E/AndroidRuntime(11918): FATAL EXCEPTION: main\n> E/AndroidRuntime(11918): Process: org.tensorflow.demo, PID: 11918\n> _E/AndroidRuntime(11918): java.lang.UnsatisfiedLinkError: dlopen failed:\n> cannot locate symbol \"getpagesize\" referenced by \"libtensorflow_demo.so\"..._\n> E/AndroidRuntime(11918): at java.lang.Runtime.loadLibrary(Runtime.java:364)\n> E/AndroidRuntime(11918): at java.lang.System.loadLibrary(System.java:526)\n> E/AndroidRuntime(11918): at\n> org.tensorflow.demo.TensorflowClassifier.(TensorflowClassifier.java:46)\n> E/AndroidRuntime(11918): at\n> org.tensorflow.demo.TensorflowImageListener.(TensorflowImageListener.java:51)\n> E/AndroidRuntime(11918): at\n> org.tensorflow.demo.CameraConnectionFragment.(CameraConnectionFragment.java:212)\n> E/AndroidRuntime(11918): at\n> org.tensorflow.demo.CameraConnectionFragment.newInstance(CameraConnectionFragment.java:91)\n> E/AndroidRuntime(11918): at\n> org.tensorflow.demo.CameraActivity.onCreate(CameraActivity.java:30)\n> E/AndroidRuntime(11918): at\n> android.app.Activity.performCreate(Activity.java:5231)\n> E/AndroidRuntime(11918): at\n> android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1087)\n> E/AndroidRuntime(11918): at\n> android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2160)\n> E/AndroidRuntime(11918): at\n> android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2246)\n> E/AndroidRuntime(11918): at\n> android.app.ActivityThread.access$800(ActivityThread.java:136)\n> E/AndroidRuntime(11918): at\n> android.app.ActivityThread$H.handleMessage(ActivityThread.java:1197)\n> E/AndroidRuntime(11918): at\n> android.os.Handler.dispatchMessage(Handler.java:102)\n> E/AndroidRuntime(11918): at android.os.Looper.loop(Looper.java:136)\n> E/AndroidRuntime(11918): at\n> android.app.ActivityThread.main(ActivityThread.java:5030)\n> E/AndroidRuntime(11918): at java.lang.reflect.Method.invoke(Native Method)\n> E/AndroidRuntime(11918): at\n> com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:793)\n> E/AndroidRuntime(11918): at\n> com.android.internal.os.ZygoteInit.main(ZygoteInit.java:609)\n> W/ActivityManager( 904): Force finishing activity\n> org.tensorflow.demo/.CameraActivity\n> W/ActivityManager( 904): Activity pause timeout for\n> ActivityRecord{65595fd8 u0 org.tensorflow.demo/.CameraActivity t73 f}\n> I/Process (11918): Sending signal. PID: 11918 SIG: 9\n> W/InputMethodManagerService( 904): Window already focused, ignoring focus\n> gain of: com.android.internal.view.IInputMethodClient$Stub$Proxy@65367aa0\n> attribute=null, token = android.os.BinderProxy@651cfa9\n> https://github.com/android.os.BinderProxy/tensorflow/commit/651cfa98\n> I/ActivityManager( 904): Process org.tensorflow.demo (pid 11918) has died.\n> D/Raydium_ts_main( 242): ## Report rate in 10 seconds =1038\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/419#issuecomment-162264595\n> .\n", "Thank you Andrew.\nI guessed that before and built the demo but never tried after removing pthread from protobus.\nNow I confirm that changing to API=20 and removing pthread from both protobus and demo application solved the issue (even without --config=android_arm).\n\nThanks again for your guidelines.\n", "Great, glad that worked!\n\nI have a patch for the original libpthread.so issue coming, so that it will\ngenerate the dummy lib at compile-time and make things more portable.\n\nOn Sun, Dec 6, 2015 at 10:03 AM, Vincent Vanhoucke <notifications@github.com\n\n> wrote:\n> \n> Closed #419 https://github.com/tensorflow/tensorflow/issues/419.\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/419#event-483728500.\n", "Thanks Andrew,\nThe patch can be absolutely useful, especially when POSIX is really needed in an application.\n", "Is this procedure even works for API 19?\n", "It should, if you follow these steps:\n1. patch CameraConnectionFragment.java to remove the use of the camera2 API and use android.hardware.Camera instead\n2. change the API level defined by AndroidManifest.xml\n3. set the API level of your NDK appropriately in WORKSPACE\n\nNote that \"--config=android_arm\" is not necessary or beneficial, and was only included by mistake in earlier comments.\n", "@CalmWaves \nYou can checkout my fork from [here](https://github.com/hamidb/tensorflow/tree/api20) enabling API<20. \n", "Hi, thanks for the instructions on how to build the library for API < 20. \n\nThe steps outlined by @andrewharp don't seem to work with the latest TF code though.\n\nI've modified the Android demo to remove dependencies on APIs lower than 21, modified AndroidManifest.xml, and configured the WORKSPACE file, all that to make the build target API 19.\n\nHowever, the build fails with the following error:\n\nERROR: /home/bruno/tensorflow/tensorflow/contrib/android/BUILD:36:1: C++ compilation of rule '//tensorflow/contrib/android:android_tensorflow_inference_jni' failed: linux-sandbox failed: error executing command /home/bruno/.cache/bazel/_bazel_bruno/fc8ca368ddd99b1148acfb9b362d6174/execroot/tensorflow/_bin/linux-sandbox ... (remaining 65 argument(s) skipped).\nIn file included from tensorflow/contrib/android/jni/jni_utils.cc:32:0:\n./tensorflow/contrib/android/jni/limiting_file_input_stream.h: In member function 'virtual int tensorflow::android::LimitingFileInputStream::Read(void*, int)':\n./tensorflow/contrib/android/jni/limiting_file_input_stream.h:39:28: error: 'errno' was not declared in this scope\n     } while (result < 0 && errno == EINTR);\n                            ^\n./tensorflow/contrib/android/jni/limiting_file_input_stream.h:39:37: error: 'EINTR' was not declared in this scope\n     } while (result < 0 && errno == EINTR);\n                                     ^\nTarget //tensorflow/examples/android:tensorflow_demo failed to build\nUse --verbose_failures to see the command lines of failed build steps.\nINFO: Elapsed time: 1615.615s, Critical Path: 1600.63s\n\nAny advice? \n\nThanks.\n", "@barantes If you add `#include <errno.h>` to the includes list for `tensorflow/contrib/android/jni/limiting_file_input_stream.h`, does the build error go away?\n", "The include tree for the newer NDK APIs must be including errno.h implicitly. Adding it explicitly fixes the build error on older APIs. Fix incoming.\n", "Hi Andrew. Thanks for the quick response. The library was successfully built after adding the #include &lt;errno.h&gt; to limiting_file_input_stream.h.\n"]}, {"number": 418, "title": "Tensor slice or indexing with tensor i, j ", "body": "What I want to do is retrieving(or slicing 1-element) from tensor with tensor indices.\n\nfor example, \n\n```\ndata = tf.constant( [ [1,2,3], [4,5,6] ] )\ni = tf.constant(2)\nj = tf.constant(1)\n\nk = data[i,j]    # error\nl = tf.gather( tf.gather(data, i) , j) # ok. but generate errors when gradient optimization process..\n```\n\n<code>sess.run(k, ...)</code> generates bad slice errors. \n\n```\n data[i,j]\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 129, in _SliceHelper\n    raise TypeError(\"Bad slice index %s of type %s\" % (s, type(s)))\n```\n\n<code>tf.gather</code> is ok to slice element, but it yields errors when training time (<code>tf.train.GradientDescentOptimizer.minimize</code>)\n\nAny tips to work-around this problem?\n", "comments": ["We're tracking our current lack of indexing fanciness here: #206.\n\nHowever, I'm less clear on the second part.  What errors are you seeing?  `tf.gather` can't yet take multiple index arguments (that's also part of #206); is that what you mean?\n", "Here I put some toy codes to re-generate errors. \n( The loss calculation doesn't make sense, It's just for re-generating errors)\n\nThere are two problems.\n- case I : using method_1() for slicing ( direct element slicing with tensor)\n  - error when graph construction time \n- case II : using method_2() for slicing (gather approach)\n  - ok when graph construction, but can't back-propagate \n  - also using gpu:0 and cpu:0 options show different error messages. \n- case III : using mehthod_3() for slicing ( using python INT for indexing)\n  - OK.\n\nErrors can be re-generated by switching \n<code>scores = method_1()</code>, <code>scores = method_2()</code>, <code>scores = method_3()</code>\n\n```\nimport tensorflow as tf\nimport numpy as np\nimport math\n\nwith tf.Graph().as_default():\n  with tf.device(\"/cpu:0\"):\n\n    # NxN matrix for weights\n    size = 3\n    w_init = tf.truncated_normal_initializer(stddev=1.0/ math.sqrt(float(size)) )\n    mat    = tf.get_variable(\"weight_matrix\", [size, size], initializer=w_init )\n\n    # Indices to retrieve weight\n    length = 3\n    x = tf.placeholder(tf.int32, shape=(length) ) \n    y = tf.placeholder(tf.int32, shape=(length) ) \n\n    # score\n    def method_1():   # <-- graph construction error!\n      scores = []\n      for i in xrange(length):\n        v = mat[x[i], y[i]] # slice error \n        scores.append( v ) \n      return scores\n\n    def method_2():  # <-- graph is ok. error when training time\n      scores = []\n      for i in xrange(length):\n        v = tf.gather( tf.gather(mat, x[i]), y[i] ) # ok. but can't minimize\n        scores.append( v ) \n      return scores\n\n    def method_3(): # <-- graph is ok. train ok. \n      scores = []\n      scores.append( mat[0,0] )\n      scores.append( mat[1,1] )\n      scores.append( mat[2,2] )\n      return scores\n\n    # loss to minimize\n    # switch method_1, method_2 and method 3 to generate errors\n    scores = method_1()\n    loss = tf.reduce_sum( tf.pack(scores) )\n\n    # optmizer\n    optimizer   = tf.train.GradientDescentOptimizer(0.01)\n    global_step = tf.Variable(0, name='global_step', trainable=False)\n    train_op    = optimizer.minimize(loss, global_step=global_step)\n\n  with tf.Session() as sess:\n    init  = tf.initialize_all_variables()\n    sess.run(init)\n\n    feed_data = {}\n    feed_data[x] = np.array([2,1,0])\n    feed_data[y] = np.array([0,1,1])\n\n    l = sess.run(loss, feed_dict=feed_data)\n    print(l)\n\n    print(\"!!! Training Time !!!\")\n    _ = sess.run(train_op, feed_dict=feed_data) # <-- error!\n```\n", "Method 1 won't work until we fix #206.  I don't know why method 2 doesn't work, since you didn't include the error message.\n", "method 2 - errors (with /cpu:0 option)\n\n```\n...\nI tensorflow/core/common_runtime/local_session.cc:45] Local session inter op parallelism threads: 24\n-0.196204\n!!! Training Time !!!\nW tensorflow/core/common_runtime/executor.cc:1027] 0x3ae60b0 Compute status: Invalid argument: ConcatOp : Expected concatenating dimensions in the range [0, 0), but got 0\n         [[Node: gradients/concat_7 = Concat[N=3, T=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](gradients/concat_7/concat_dim, Squeeze, Squeeze_2, Squeeze_4)]]\nTraceback (most recent call last):\n  File \"tf_gather_test.py\", line 76, in <module>\n    _ = sess.run(train_op, feed_dict=feed_data) # <-- error!\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 345, in run\n    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 419, in _do_run\n    e.code)\ntensorflow.python.framework.errors.InvalidArgumentError: ConcatOp : Expected concatenating dimensions in the range [0, 0), but got 0\n         [[Node: gradients/concat_7 = Concat[N=3, T=DT_INT32, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](gradients/concat_7/concat_dim, Squeeze, Squeeze_2, Squeeze_4)]]\nCaused by op u'gradients/concat_7', defined at:\n  File \"tf_gather_test.py\", line 62, in <module>\n    train_op    = optimizer.minimize(loss, global_step=global_step)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 165, in minimize\n    gate_gradients=gate_gradients)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/optimizer.py\", line 205, in compute_gradients\n    loss, var_list, gate_gradients=(gate_gradients == Optimizer.GATE_OP))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients.py\", line 385, in gradients\n    aggregation_method)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients.py\", line 605, in _AggregatedGrads\n    array_ops.concat(0, [x.indices for x in out_grad]),\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 290, in concat\n    name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 70, in _concat\n    name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 633, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1710, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 988, in __init__\n    self._traceback = _extract_stack()\n```\n\nmethod 2 errors - with /gpu:0 option\n\n```\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:643] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K80, pci bus id: 0000:85:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:47] Setting region size to 284540928\nI tensorflow/core/common_runtime/gpu/gpu_region_allocator.cc:47] Setting region size to 11286332212\nI tensorflow/core/common_runtime/local_session.cc:45] Local session inter op parallelism threads: 24\nTraceback (most recent call last):\n  File \"tf_gather_test.py\", line 66, in <module>\n    sess.run(init)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 345, in run\n    results = self._do_run(target_list, unique_fetch_targets, feed_dict_string)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 419, in _do_run\n    e.code)\ntensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'global_step': Could not satisfy explicit device specification '/gpu:0'\n         [[Node: global_step = Variable[container=\"\", dtype=DT_INT32, shape=[], shared_name=\"\", _device=\"/gpu:0\"]()]]\nCaused by op u'global_step', defined at:\n  File \"tf_gather_test.py\", line 61, in <module>\n    global_step = tf.Variable(0, name='global_step', trainable=False)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variables.py\", line 187, in __init__\n    name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/state_ops.py\", line 96, in variable_op\n    container=container, shared_name=shared_name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_state_ops.py\", line 334, in _variable\n    name=name)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/op_def_library.py\", line 633, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1710, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 988, in __init__\n    self._traceback = _extract_stack()\n```\n", "Thanks!  The `cpu` case is a bug in the gradient of `tf.gather`, which wasn't correctly updated when I made `gather` handle arbitrary rank indices (including scalars).  I'll fix that.\n\nI'm not sure about the `gpu` case, but it's possible that we don't yet allow scalars in some places on the GPU for Eigen-related reasons.  @benoitsteiner: Is that possible?\n", "Upon further investigation, fixing (2) in an efficient way seems tricky.  The problem is that an optimizer step for two nested calls to `tf.gather` can't be efficient unless `tf.scatter` handles multiple index arguments.  Specifically, we'd need to make `IndexedSlices` accept multiple index arguments so that the gradient of `tf.gather` could build one `IndexedSlices` and then build a deeper one for the next `tf.gather` call.\n\nI'm going to leave this open as a bug and reference it from #206.  Apologies that I won't have a fix for you soon.\n", "Here is a small failing test case for when someone gets to this.\n\n```\ndef testNestedGather(self):\n  \"\"\"Catch https://github.com/tensorflow/tensorflow/issues/418.\"\"\"\n  with self.test_session() as sess:\n    init = np.arange(6).reshape(2, 3).astype(np.float32)\n    var = tf.Variable(init)\n    i = tf.constant(1)\n    j = tf.constant(2)\n    loss = tf.gather(tf.gather(var, i), j)\n    sess.run(tf.initialize_all_variables())\n    self.assertEqual(loss.eval(), init[1, 2])\n    # Run one step of optimization\n    optimizer = tf.train.GradientDescentOptimizer(0.01)\n    train = optimizer.minimize(loss)\n    sess.run(train)\n```\n", "@girving Any progress or plan on this?\n\nI'm working on sequence wise custom loss function which requires confusion matrix indexing. \n\nlike <code> matrix[ i , j] </code> where <code>matrix = tensor [num_classes x num_classes]</code>\n", "Unfortunately no.  As a workaround until it gets fixed, does this work for you?\n\n```\ntf.gather(tf.reshape(matrix, [-1]), i * tf.shape(matrix)[1] + j)\n```\n", "@girving  Thanks. It works for indexing, and gradient descent updates too. \nMaybe we need temporary smart walkaround-wrappers. \n\nAlso following tips are really very helpful to implement numpy like indexing. \nThe trick is using sparse tensor multiplication for slicing. \n\nhttp://stackoverflow.com/questions/34685947/adjust-single-value-within-tensor-tensorflow/34686952#34686952\n", "Will try to work on an efficient multi-index gather this week.  No promises on timelines though.\n", "I made a `ravel_multi_index` . From a multi-index, it produces an tensor suitable for indexing a flattened tensor. See the [numpy](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.ravel_multi_index.html) documentation for instance.\n\n``` python\nimport tensorflow as tf\nimport numpy as np\n\ndef __cumprod(l):\n    # Get the length and make a copy\n    ll = len(l)\n    l = [v for v in l]\n\n    # Reverse cumulative product\n    for i in range(ll-1):\n        l[ll-i-2] *= l[ll-i-1]\n\n    return l\n\ndef ravel_multi_index(tensor, multi_idx):\n    \"\"\"\n    Returns a tensor suitable for use as the index\n    on a gather operation on argument tensor.\n    \"\"\"\n\n    if not isinstance(tensor, (tf.Variable, tf.Tensor)):\n        raise TypeError('tensor should be a tf.Variable')\n\n    if not isinstance(multi_idx, list):\n        multi_idx = [multi_idx]\n\n    # Shape of the tensor in ints\n    shape = [i.value for i in tensor.get_shape()]\n\n    if len(shape) != len(multi_idx):\n        raise ValueError(\"Tensor rank is different \"\n                        \"from the multi_idx length.\")\n\n    # Work out the shape of each tensor in the multi_idx\n    idx_shape = [tuple(j.value for j in i.get_shape()) for i in multi_idx]\n    # Ensure that each multi_idx tensor is length 1\n    assert all(len(i) == 1 for i in idx_shape)\n\n    # Create a list of reshaped indices. New shape will be\n    # [1, 1, dim[0], 1] for the 3rd index in multi_idx\n    # for example.\n    reshaped_idx = [tf.reshape(idx, [1 if i !=j else dim[0]\n                    for j in range(len(shape))])\n                for i, (idx, dim)\n                in enumerate(zip(multi_idx, idx_shape))]\n\n    # Figure out the base indices for each dimension\n    base = __cumprod(shape)\n\n    # Now multiply base indices by each reshaped index\n    # to produce the flat index\n    return (sum(b*s for b, s in zip(base[1:], reshaped_idx[:-1]))\n        + reshaped_idx[-1])\n\n# Shape and slice starts and sizes\nshape = (Z, Y, X) = 4, 5, 6\nZ0, Y0, X0 = 1, 1, 1\nZS, YS, XS = 3, 3, 4\n\n# Numpy matrix and index\nM = np.random.random(size=shape)\nidx = [\n    np.arange(Z0, Z0+ZS).reshape(ZS,1,1),\n    np.arange(Y0, Y0+YS).reshape(1,YS,1),\n    np.arange(X0, X0+XS).reshape(1,1,XS),\n]\n\n# Tensorflow matrix and indices\nTM = tf.Variable(M)\nTF_flat_idx = ravel_multi_index(TM, [\n    tf.range(Z0, Z0+ZS),\n    tf.range(Y0, Y0+YS),\n    tf.range(X0, X0+XS)])\nTF_data = tf.gather(tf.reshape(TM,[-1]), TF_flat_idx)\n\nwith tf.Session() as S:\n    S.run(tf.initialize_all_variables())\n\n    # Obtain data via flat indexing\n    data = S.run(TF_data)\n\n    # Check that it agrees with data obtained\n    # by numpy smart indexing\n    assert np.all(data == M[idx])\n```\n", "@girving @ebrevdo @sjperkins @hugman \nI need to slice a tensor this way:\n`matrix[row_indices, col_indices]` where `matrix` is a `mxn` tensor and `row_indices` and `col_indices` are int32 vectors of sizes `k` such that k is less than m and n respectively. I want to slice and obtain a length `k` vector eventually i.e. vectorized operation of `matrix[i,j]`\nWhat would be an optimized way of doing this? `tf.gather(matrix,indices)` takes only a vector `indices` and can return all the rows corresponding to the vector `indices`\n", "@tejaskhot `ravel_multi_index` above should do it\n\n``` python\nmatrix = tf.random_normal([M,N])\nrow_indices = tf.Variable([1,5,8,9])\ncol_indices = tf.Variable([5,3,8,2])\nflat_index = ravel_multi_index(matrix, [row_indices, col_indices])\ndata = rf.gather(tf.reshape(matrix, [-1]), flat_index)\n```\n\nNote that `ravel_multi_index` only works with the static tensor shape inferred prior to running the expression tree. If your tensor shape is dynamic, `ravel_multi_index` will need to be updated to use `tf.shape()` during expression tree execution. [This](http://stackoverflow.com/questions/36035092/multi-dimensional-gather-in-tensorflow) StackOverflow question would be a good place to answer that. However, the indices (`row_indices` and `col_indices`) are currently evaluated at run-time.\n", "@sjperkins \nIt doesn't seem to work with `tf.placeholder`. An example to reproduce the issue:\n\n```\ndef train():\n    mat1 = np.ones((75000,50)).astype(np.float32)\n    idx = np.arange(100).astype(np.int32)\n    wts = np.ones((50,50)).astype(np.float32)\n\n    mat_1 = tf.Variable(mat1, name=\"mat_1\")\n    indices = tf.Variable(idx, name=\"indices\")\n    dot_1 = tf.gather(mat_1, indices)\n\n    W = tf.Variable(wts, name=\"W\")\n    dot_2 = tf.matmul(dot_1, W)\n\n    activation = tf.nn.softmax(dot_2)\n    output = -tf.log(activation)\n\n    row_indices = tf.placeholder(\"int32\", name=\"row_indices\")\n    col_indices = tf.placeholder(\"int32\", name=\"col_indices\")\n    flat_index = ravel_multi_index(output, [row_indices, col_indices])\n    data = tf.gather(tf.reshape(output, [-1]), flat_index)\n    return data\n\n\nrow_idx = np.arange(10).astype(np.int32)\ncol_idx = np.arange(15).astype(np.int32)\n\nsess = tf.Session()\ndata = train()\nsess.run(tf.initialize_all_variables())\nresult = sess.run(data, feed_dict={row_indices:row_idx, col_indices:col_idx})\nprint type(result), result.shape\n\n```\n\nAny ideas on how to adapt this if the indices are placeholders and not variables?\nIt gets stuck on the call to `ravel_multi_index`\n", "@tejaskhot Ah rats, the following line:\n\n``` python\n# Work out the shape of each tensor in the multi_idx\nidx_shape = [tuple(j.value for j in i.get_shape()) for i in multi_idx]\n```\n\nis dealing with the static (`get_shape()`) rather than the  dynamic ('tf.shape(...)`) shape. I don't ahve time to improve it now, but it gives you the clue to continue the investigation. Update the stackoverflow question if you figure it out. ;-)\n", "Please see the new op gather_nd in array ops at HEAD/ in the nightly build.\n", "@ebrevdo Shiny :-)\n\nI gather it'll be used to implement #206?\n", "Closing as a duplicate of part of #206.\n", "I like add some functions in deep MNIST but I get the error as tensorflow.python.pywrap_tensorflow.StatusNotOK: Invalid argument: Node 'multiplelayer error/initial_value': Node name contains invalid characters\n     [[Node: multiplelayer error = Variable[container=\"\", dtype=DT_INT32, shape=[], shared_name=\"\"]()]]?\n", "I have matrices of different shape, I want to use them as an input in Tensorflow or Keras, any suggestions how to proceed on this?"]}, {"number": 417, "title": "Explanation of the constants in the tutorials for TensorFlow", "body": "Hi,\n\nWould you be able to provide more explanation in the comments for the code (or at least the papers that are relevant to the underlying theory) for the TensorFlow tutorials?\n\nThanks!\n\nShyamal\n", "comments": ["I think the udacity course materials are the right place to put these types of docs, since they're more geared towards teaching the theory behind the practice.\n", "@vrv The Udacity course is nonlinear and doesn't have a rich, drill-down vocabulary that is required for pedogogical purposes.  Thus, it doesn't, by itself, suffice for the purposes of providing documentation for Tensorflow.  The theory that is presented is half-baked and too abstract to convert to code from some high-level graphics.  \n"]}, {"number": 416, "title": "small typo for BiRNN comment", "body": "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn.py#L193\n\ndo you mean with shape [batch_size x input_size] ?\n", "comments": ["Thanks for the report, fixed now.\n"]}, {"number": 415, "title": "'import cifar10' bug", "body": "I have inserted simple print('xxx') in cifar10.py and run cifar10_train.py but no 'xxx' is printed.\nExamining cifar10_train.py find out 'import cifar10' from different source:\n    from tensorflow.models.image.cifar10 import cifar10\nI changed it to:\n   import cifar10\nand run again, get 'xxx' but crashed the program at the function loss() in cifar10.py saying:\n\nTraceback (most recent call last):\n  File \"cifar10_train.py\", line 139, in <module>\n    tf.app.run()\n  File \"/home/ooky/tensorflow/local/lib/python2.7/site-packages/tensorflow/python/platform/default/_app.py\", line 11, in run\n    sys.exit(main(sys.argv))\n  File \"cifar10_train.py\", line 135, in main\n    train()\n  File \"cifar10_train.py\", line 77, in train\n    loss = cifar10.loss(logits, labels)\n  File \"/home/ooky/work/cifar10/cifar10.py\", line 401, in loss\n    indices = tf.reshape(tf.range(FLAGS.batch_size), [FLAGS.batch_size, 1])\nTypeError: range() takes at least 2 arguments (1 given)\n\nWhat's wrong?\n", "comments": ["I recently fixed `tf.range` to accept between 1 and 3 arguments (like Python's `range`).  This change will be part of the upcoming 0.6.0 release, but you're using the 0.5.0 release, and a version of cifar10 from git.  Quick fix: use `tf.range(0, FLAGS.batch_size)` instead of `tf.range(FLAGS.batch_size)`.\n", "Thanks much for prompt reply!\n2015. 12. 6. \uc624\uc804 7:09\uc5d0 \"Geoffrey Irving\" notifications@github.com\ub2d8\uc774 \uc791\uc131:\n\n> I recently fixed tf.range to accept between 1 and 3 arguments (like\n> Python's range). This change will be part of the upcoming 0.6.0 release,\n> but you're using the 0.5.0 release, and a version of cifar10 from git.\n> Quick fix: use tf.range(0, FLAGS.batch_size) instead of\n> tf.range(FLAGS.batch_size).\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/415#issuecomment-162252409\n> .\n"]}, {"number": 414, "title": "crosstool_wrapper_driver_is_not_gcc cannot find libpython2.7.so.1.0", "body": "I encountered error\npython2: error while loading shared libraries: libpython2.7.so.1.0: cannot open shared object file: No such file or directory\nwhile trying to install tensorflow from source with GPU-enabled.\n\nI can see the error command is\n (cd /home/xxx/.cache/bazel/_bazel_xxx/d568262eb4464bf011ab3d998aff21ac/tensorflow && \\\n  exec env - \\\n    INTERCEPT_LOCALLY_EXECUTABLE=1 \\\n    PATH=/share/software/python/2.7.10/Python-2.7.10/release/bin:/share/software/java/jdk1.8.0_66/bin:/share/software/NLP/bazel/output:/usr/local/cuda/bin:/opt/attila/:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/sbin:/opt/ibutils/bin:/usr/local/MATLAB/R2014a/bin \\\n  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-std=c++11' -iquote . -iquote bazel-out/local_linux-opt/genfiles -isystem tools/cpp/gcc3 -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' '-frandom-seed=bazel-out/local_linux-opt/bin/external/gemmlowp/_objs/eight_bit_int_gemm/external/gemmlowp/eight_bit_int_gemm/eight_bit_int_gemm.o' -MD -MF bazel-out/local_linux-opt/bin/external/gemmlowp/_objs/eight_bit_int_gemm/external/gemmlowp/eight_bit_int_gemm/eight_bit_int_gemm.d -c external/gemmlowp/eight_bit_int_gemm/eight_bit_int_gemm.cc -o bazel-out/local_linux-opt/bin/external/gemmlowp/_objs/eight_bit_int_gemm/external/gemmlowp/eight_bit_int_gemm/eight_bit_int_gemm.o)\n\nI guess the problem is I'm using a local python version, which is installed under\n/share/software/python/2.7.10/Python-2.7.10/release/bin\nand path to libpython2.7.so.1.0 is not accessible. \nIf I add LD_LIBRARY_PATH=/share/software/python/2.7.10/Python-2.7.10/release/lib to the error command, I would be able to get rid of the error.\n\nIt seems to me bazel does not allow user to add ld_library_path(?), so what should I do in this case..?\n\nThis error has bothered me for days and I still cannot get over it.... Thank you in advance for your help and suggestions!\n", "comments": ["If building from HEAD, you should be able to use ./configure to specify the path of the python you want to use -- let us know if that works.\n", "Hi vrv,\nI have pulled the most recent version, and configure python with the local installation. However, the error is still there.\nactually the lib link points to the site-package, which I assume will resolve numpy errors.\n\npython_include -> /share/software/python/2.7.10/Python-2.7.10/release/include/python2.7\npython_lib -> /share/software/python/2.7.10/Python-2.7.10/release/lib/python2.7/site-packages\n\nI have created softlink to libpython2.7.so.1.0 under /share/software/python/2.7.10/Python-\n2.7.10/release/lib/python2.7/site-packages, which doesn't help either... \n\nthanks!\n", "where is your libpython2.7.so.1.0?  what directory is it in?\n\nhave you tried using a virtualenv with that python, and pointing configure at that virtualenv?\n", "Can you do something for me?  Load up the version of python you set up with config, and run:\n\nfrom distutils import sysconfig\nprint sysconfig.get_config_vars('LIBPL')\n\nit should return a path.  can you reply with that path?  also, for the path, type: ls -l THAT_PATH  (and paste the results here as well)\n", "@girving  we may need to point the pythonX_path to a script (copied from a template via e.g. sed) which sets the LD_LIBRARY_PATH correctly based on e.g. LIBPL output, and calls the python interpreter.\n", "Hi ebrevdo,\nlibpython2.7.so.1.0 is under /share/software/python/2.7.10/Python-2.7.10/release/lib\n\nHere is the output.\nprint sysconfig.get_config_vars('LIBPL')\n['/share/software/python/2.7.10/Python-2.7.10/release/lib/python2.7/config']\n\nls -l /share/software/python/2.7.10/Python-2.7.10/release/lib/python2.7/config\ntotal 9768\n-rw-rw-r--. 1 xxxx    2200 Oct  2 15:44 config.c\n-rw-rw-r--. 1 xxxx    1507 Oct  2 15:44 config.c.in\n-rwxrwxr-x. 1 xxxx    7122 Oct  2 15:44 install-sh\n-rw-rw-r--. 1 xxxx 9883714 Oct  2 15:44 libpython2.7.a\n-rw-rw-r--. 1 xxxx   49734 Oct  2 15:44 Makefile\n-rwxrwxr-x. 1 xxxx    7431 Oct  2 15:44 makesetup\n-rw-rw-r--. 1 xxxx    6256 Oct  2 15:44 python.o\n-rw-rw-r--. 1 xxxx   18479 Oct  2 15:44 Setup\n-rw-rw-r--. 1 xxxx     368 Oct  2 15:44 Setup.config\n-rw-rw-r--. 1 xxxx      41 Oct  2 15:44 Setup.local\n", "Interesting.  Can you run the python-config associated with that python\nbin?  i imagine it's something like:\n\n/share/software/python/2.7.10/Python-2.7.10/release/python-config\n\ncan you run it separately with each of: --ldflags, --cflags, --includes,\n--libs, --prefix, --exec-prefix?\n\nthanks!\n\nOn Sat, Dec 5, 2015 at 9:40 PM, Luzy notifications@github.com wrote:\n\n> Hi ebrevdo,\n> libpython2.7.so.1.0 is under\n> /share/software/python/2.7.10/Python-2.7.10/release/lib\n> \n> Here is the output.\n> print sysconfig.get_config_vars('LIBPL')\n> \n> ['/share/software/python/2.7.10/Python-2.7.10/release/lib/python2.7/config']\n> \n> ls -l\n> /share/software/python/2.7.10/Python-2.7.10/release/lib/python2.7/config\n> total 9768\n> -rw-rw-r--. 1 xxxx 2200 Oct 2 15:44 config.c\n> -rw-rw-r--. 1 xxxx 1507 Oct 2 15:44 config.c.in\n> -rwxrwxr-x. 1 xxxx 7122 Oct 2 15:44 install-sh\n> -rw-rw-r--. 1 xxxx 9883714 Oct 2 15:44 libpython2.7.a\n> -rw-rw-r--. 1 xxxx 49734 Oct 2 15:44 Makefile\n> -rwxrwxr-x. 1 xxxx 7431 Oct 2 15:44 makesetup\n> -rw-rw-r--. 1 xxxx 6256 Oct 2 15:44 python.o\n> -rw-rw-r--. 1 xxxx 18479 Oct 2 15:44 Setup\n> -rw-rw-r--. 1 xxxx 368 Oct 2 15:44 Setup.config\n> -rw-rw-r--. 1 xxxx 41 Oct 2 15:44 Setup.local\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/414#issuecomment-162272677\n> .\n", "Here is the result (your comment was folded previously, and did not get the flags the first time)\n/share/software/python/2.7.10/Python-2.7.10/release/bin/python-config --ldflags\n-lpython2.7 -lpthread -ldl -lutil -lm -Xlinker -export-dynamic\n\n/share/software/python/2.7.10/Python-2.7.10/release/bin/python-config --cflags\n-I/share/software/python/2.7.10/Python-2.7.10/release/include/python2.7 -I/share/software/python/2.7.10/Python-2.7.10/release/include/python2.7 -fno-strict-aliasing -g -O2 -DNDEBUG -g -fwrapv -O3 -Wall -Wstrict-prototypes\n\n/share/software/python/2.7.10/Python-2.7.10/release/bin/python-config --includes\n-I/share/software/python/2.7.10/Python-2.7.10/release/include/python2.7 -I/share/software/python/2.7.10/Python-2.7.10/release/include/python2.7\n\n/share/software/python/2.7.10/Python-2.7.10/release/bin/python-config --libs\n-lpython2.7 -lpthread -ldl -lutil -lm\n\n/share/software/python/2.7.10/Python-2.7.10/release/bin/python-config --prefix\n/share/software/python/2.7.10/Python-2.7.10/release\n\n/share/software/python/2.7.10/Python-2.7.10/release/bin/python-config --exec-prefix\n/share/software/python/2.7.10/Python-2.7.10/release\n", "On my machine, libpython...so is in\n  /usr/lib/python2.7/config-x86_64-linux-gnu\nand my python-config --ldflags adds this line:\n  -L/usr/lib/python2.7/config-x86_64-linux-gnu -L/usr/lib\n\nin contrast, on your system we can't use python-config to get the location of the so file.\n\nIn addition, while on my system I can find a copy of the .so file in my LIBPL directory, on your system it isn't there.  It's very strange.\n\nYou seem to have a fairly nonstandard installation of python 2.7.  Are you an administrator of this machine?  Perhaps you could reinstall python?  Or install a version of python in your home directory, where you have write permissions and can install a properly built version?\n", "@vrv: Reassigning since Eugene is out.\n", "Hi,\nHere is an update. Unfortunately I don't have admin access to the machine.\nI installed another python with config\n./configure --prefix=$PWD/release/ --enable-shared LDFLAGS=\"-L$PWD/release/lib/python2.7/config -Wl,--rpath=$PWD/release/lib/python2.7/config -L$PWD/release/lib/ -Wl,--rpath=$PWD/release/lib/\" CPPFLAGS=\"-I$PWD/release/include\"\n(I found these from some stackoverflow answers, though I don't fully understand how it works yet)\n\nthough libpython...so is still not under lib/python2.7/config/, nor does python-config --ldflags\n-lpython2.7 -lpthread -ldl -lutil -lm -Xlinker -export-dynamic return -L....\n\nI was able to get pass that libpython2.7.so.1.0 not found error building tensorflow.\n\nBut I encountered error\n/usr/bin/env: python2.7: No such file or directory\nERROR: /share/software/tensorflow/google/protobuf/BUILD:270:1: Linking of rule '//google/protobuf:protoc' failed: crosstool_wrapper_driver_is_not_gcc failed: ....\n\nbecause the command generated by bazel seems not to set the PATH variable (I do not understand why)\n(cd /home/zhiyunlu/.cache/bazel/_bazel_zhiyunlu/d568262eb4464bf011ab3d998aff21ac/tensorflow && \\\n  exec env - \\\n  third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc....)\n\nSo I fixed the problem by changing the first line of crosstool_wrapper_driver_is_not_gcc to be\n#!/share/software/python/2.7.10/Python-2.7.10-tf/release/bin/python2\nto run with specific python I installed.\n\nWith some other modifications to use local gcc installation version ([issue649](https://github.com/bazelbuild/bazel/issues/649)), I am able to build tensorflow successfully.\n\nI saw many warnings, for example\nwarning: calling a __host__ function from a __host__ __device__ function is not allowed.\nBut I assume it is okay...?\n\nSo I think the libpython...so problem is fixed now. Thanks a lot for helping this out!\n", "The warnings are fine. The underlying Eigen library doesn't always mark\nfunctions as OK to run on a gpu, even if they are. That results in many of\nthe warnings.\nOn Dec 8, 2015 7:25 PM, \"Luzy\" notifications@github.com wrote:\n\n> Hi,\n> Here is an update. Unfortunately I don't have admin access to the machine.\n> I installed another python with config\n> ./configure --prefix=$PWD/release/ --enable-shared\n> LDFLAGS=\"-L$PWD/release/lib/python2.7/config\n> -Wl,--rpath=$PWD/release/lib/python2.7/config -L$PWD/release/lib/\n> -Wl,--rpath=$PWD/release/lib/\" CPPFLAGS=\"-I$PWD/release/include\"\n> (I found these from some stackoverflow answers, though I don't fully\n> understand how it works yet)\n> \n> though libpython...so is still not under lib/python2.7/config/, nor does\n> python-config --ldflags\n> -lpython2.7 -lpthread -ldl -lutil -lm -Xlinker -export-dynamic return\n> -L....\n> \n> I was able to get pass that libpython2.7.so.1.0 not found error building\n> tensorflow.\n> \n> But I encountered error\n> /usr/bin/env: python2.7: No such file or directory\n> ERROR: /share/software/tensorflow/google/protobuf/BUILD:270:1: Linking of\n> rule '//google/protobuf:protoc' failed: crosstool_wrapper_driver_is_not_gcc\n> failed: ....\n> \n> because the command generated by bazel seems not to set the PATH variable\n> (I do not understand why)\n> (cd\n> /home/zhiyunlu/.cache/bazel/_bazel_zhiyunlu/d568262eb4464bf011ab3d998aff21ac/tensorflow\n> && \\\n> exec env - \\\n> \n> third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc....)\n> \n> So I fixed the problem by changing the first line of\n> crosstool_wrapper_driver_is_not_gcc to be\n> #!/share/software/python/2.7.10/Python-2.7.10-tf/release/bin/python2\n> to run with specific python I installed.\n> \n> With some other modifications to use local gcc installation version (\n> issue649 https://github.com/bazelbuild/bazel/issues/649), I am able to\n> build tensorflow successfully.\n> \n> I saw many warnings, for example\n> warning: calling a _host_ function from a _host_ _device_ function is not\n> allowed.\n> But I assume it is okay...?\n> \n> So I think the libpython...so problem is fixed now. Thanks a lot for\n> helping this out!\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/414#issuecomment-163113984\n> .\n"]}, {"number": 413, "title": "How to use tensorflow python API from the source tree?", "body": "I am trying to setup an efficient development environment for new code inside tensorflow source tree and an external library. Therefore, I am trying to avoid the pip installation process (after every code change) and use the output of bazel build directly in the source tree. In particular, I need access to the Python API from the external library. Can that be accomplished? \n", "comments": ["I'm not entirely sure, this might be a better question for the bazel team at https://github.com/bazelbuild/bazel.  Hopefully the use of 'bazel' isn't viral.\n", "Can you set up your binary similar to any of the checked-in model? \n\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/alexnet/BUILD\n\nYou can run either as: \nbazel run -c opt --config=cuda third_party/tensorflow/models/image/alexnet:alexnet_benchmark\n\nOr \nbazel build -c opt --config=cuda third_party/tensorflow/models/image/alexnet:alexnet_benchmark\nbazel-bin/third_party/tensorflow/models/image/alexnet/alexnet_benchmark\n", "That sounds like a good suggestion. Will check it out.\n", "@pronobis - Did that work well for you?\n", "I was wondering if running the following after building would do the trick (while in tensorflow root folder):\n\npython ./tensorflow/tools/pip_package/setup.py develop\n", "Ok it doesn't work, but something that would do the trick would be so useful...\n", "I think I have a setup for development without rebuilding the wheel / re-installing it after every change. It does, however, require re-running the bazel build every time the C++ file change, or if any python files are added or deleted.\n\nFrom the tensorflow repo root:\n\n``` sh\nbazel build -c opt //tensorflow/tools/pip_package:build_pip_package\nmkdir _python_build\ncd _python_build\n\nln -s ../bazel-bin/tensorflow/tools/pip_package/build_pip_package.runfiles/* .\nln -s ../tensorflow/tools/pip_package/* .\npython setup.py develop\n```\n", "This is great! I'll make this part of os_setup.md if you don't mind (or you can)?\n", "@martinwicke You can go ahead and do that\n"]}, {"number": 412, "title": "Adding operations after gradient are applied screws with the optimizer", "body": "I'm currently trying to add an operation after I apply the gradients. Essentially I have a row of some variables that I don't to change via gradients so I would ideally reset it after gradients are applied (I could also set that part of the gradient to 0 but w/e). I currently have this done after my forward inference pass as putting it after apply_gradients doesn't seem to work.\n\nEven adding an op like tf.Print seems to completely screw with the optimizer. What I gather from my debugging is no variables are updated.\n\n```\ntrain_op = self._opt.apply_gradients(...)\ntrain_op = tf.Print(train_op, ....)\n```\n\nIf I understand Print correctly it just prints stuff and then returns have the op that was passed in, so the returned op should work the same. tf.Print works as expected it prints out what I wanted it to print.\n", "comments": ["How are you using `train_op` downstream?  What you're doing seems like it should work as you expect from what you've written, so I think we need to see the rest of the context.\n", "Closing due to lack of activity / follow up.  Feel free to comment and we'll re-open.\n", "I think I am having a similar problem to this. Gradients are apparently computed, but the weight matrix associated with the gradient does not change (i.e., they are exactly the same across mini-batches and iterations). Interestingly, this happens only with one dataset. I use the same code for two other (MNIST and an artificially generated dataset) datasets, and it works fine. \n\n```\noptimizer = tf.train.GradientDescentOptimizer(0.1)\npredict_op = tf.argmax(py_x,1)\n\ntvars = tf.trainable_variables()\ngrads = tf.gradients(cost, tvars)\ntrain_op = optimizer.apply_gradients(zip(grads, tvars))\n```\n\nSo this is my optimization code. I used this explicit way of computing to see the values of the gradients. Otherwise I used\n\n`train_op = tf.train.GradientDescentOptimizer(0.1).minimize(cost)`\n\nand other optimization techniques TensorFlow offers as well. As I said, although gradients are computed(And they are non-zero), they are not applied to the weight matrix, and the weight matrix remains the same. As a result, because of the random initialization of the weights, the classifier I trained (Which is an LSTM + a softmax layer) keeps predicting with random guess (i.e., 1/n accuracy, where n is the number of classes). \n\nNot sure if this is the right place to post, but I guess the problem is similar. I can open a new issue if you want. The code is very long (and messy because of everything I tried to make it work in the last few days), so I did not post here the whole thing. If you need the other parts, I can clean them and post here. \n", "Are you running the `train_op`?\n", "My bad. I deleted it at some point, and only for the code that runs with that particular dataset. Thanks a lot. You saved my future few days. \n"]}, {"number": 411, "title": "image_ops.per_image_whitening returns NaN", "body": "It computes a negative variance for certain uniform values.\n\n```\nimport tensorflow as tf\nimport numpy as np\n\nim = tf.Variable(np.ones([19,19,3]).astype(np.float32)) * 249\nw = tf.image.per_image_whitening(im)\ns = tf.Session()\nwith s.as_default():\n  s.run(tf.initialize_all_variables())\n  assert not s.run(w).any(), 'NaN'\n```\n", "comments": ["I was able to reproduce the error. Working on a fix. \n"]}, {"number": 410, "title": "Batching from two string_input_producers does that don't preserve order.", "body": "I'm trying to read in multiple files (one file consists of the input, the other is the label). I assembled a pipeline using `tf.train.string_input_producer`, some custom decoder and `tf.train.batch` to put them together to batches. Unfortunately, the order does somehow get mixed up in this process. I extracted a minimal example that uses randomly generated strings instead of filenames (and also skips the decoding step), [see my gist here](https://gist.github.com/panmari/6bf13e06c21493d08c75)\n\nIn this example, all shuffling was disabled. But the error also occurs if I enabled shuffle and set the same seed for both string input producers. \n\nAm I using these classes not as intended? Or is there an actual bug?\n", "comments": ["I just realized that my test succeeds if I set `num_threads=1` in the `tf.train.batch` call. So the strange behavior seems to originate from there.\n", "I'm not sure exactly how you are trying to read the two files in parallel.  Doing that correctly can be a bit awkward, especially if you want to use multiple threads.  What reader(s) are you using?  Can you show the code you are using for your input pipeline?  The most robust approach would be a custom reader.\n", "Well, one of them is my 'label image', the other the 'input image'. I don't have access to the code right now, but it's quite similar to the gist I posted in my initial post, just with some png.decode thrown inbetween.\n", "Looks like this fell through the cracks.  @panmari: Is this still an issue, and do you have code if so?  For better or worse, tensorflow exposes a lot of the complexity of asynchronous programming to users, so it may be that this is intended behavior.\n", "I ended up going a completely different route, since the non-sequential nature of reading (rather small) png files this way ended up being the bottle neck of my learning pipeline. Starting from [this example](https://github.com/tensorflow/tensorflow/blob/r0.7/tensorflow/examples/how_tos/reading_data/convert_to_records.py), I wrote a small script that dumps multiple images into one `example` under different keys. That way, the two images are always read by the same reader, so I don't have to care about concurrency issues anymore. And since I dump 2000 examples into one file (which can be read sequentially), this way of reading data proved to be much faster (at least on traditional hard drives). \n\nI'll close this issue, since I feel this is the proper way to tackle this problem, not the one outlined in the original issue.\n", "I'm also having this issue: I have a file listing input images, and another file listing output targets. I might also have to start using TFRecords instead, but it would be nice to just have a way to use two string_input_producers in conjunction.", "I also went with TFRecords in the end. I simply joined the files in when\ngenerating the TFRecords.\n\nOn Sun, May 21, 2017, 12:44 Chris Watts <notifications@github.com> wrote:\n\n> I'm also having this issue. I might also have to start using TFRecords\n> instead, but it would be nice to just have a way to ues two\n> string_input_producers in conjunction.\n>\n> \u2014\n> You are receiving this because you modified the open/close state.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/410#issuecomment-302928752>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAr4rOXXJlo4BrRcswXK98Vay-E7hEayks5r8BWGgaJpZM4Gu-QQ>\n> .\n>\n", "@CJxD It's possible that the new `tf.contrib.data` module could solve your problem. It's available in TensorFlow 1.2rc0, and there is some preliminary documentation here:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/data/README.md\r\n\r\nAssuming you have two text files, line delimited, I think the solution would look something like this:\r\n\r\n```python\r\nimage_filenames = tf.contrib.data.TextLineDataset(\"image_index.txt\")\r\nimages = image_filenames.map(lambda filename: tf.image.decode_image(tf.read_file(filename)))\r\noutput_target_strings = tf.contrib.data.TextLineDataset(\"output_targets.txt\")\r\noutput_target_values = output_target_strings.map(lambda target: ...)  # Insert type conversion code here.\r\n\r\ncombined = tf.contrib.data.Dataset.zip((images, output_targets)).repeat().batch(BATCH_SIZE)\r\niterator = combined.make_one_shot_iterator()\r\nnext_element = iterator.get_next()\r\n# ...\r\n```\r\n\r\nNote that building everything into a TFRecord file would have better I/O characteristics as @panmari notes, but this might work well for initial experimentation."]}, {"number": 409, "title": "fix typo in doc", "body": "", "comments": []}, {"number": 408, "title": "Can't find pngwutil.c building tensorflow", "body": "I am getting this error when compiling tensorflow on RHEL 6.6. \n\n```\n[<user>@blah tensorflow]$ ../bazel/output/bazel --output_base=/lvol/<user> build --genrule_strategy=standalone --spawn_strategy=standalone --verbose_failures -j 1 -c opt //tensorflow/cc:tutorials_example_trainer 2>&1|tee compile0.log\n......\nWARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.io/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.\n____Loading package: tensorflow/cc\n____Loading...\n____Loading package: @bazel_tools//tools/cpp\n____Loading package: @local-jdk//\n____Loading package: tensorflow/core/platform/default/build_config\n____Loading package: @png_archive//\n____Loading package: @jpeg_archive//\n____Loading complete.  Analyzing...\n____Found 1 target...\n____Building...\n____[0 / 1] BazelWorkspaceStatusAction stable-status.txt\n____[3 / 28] Compiling google/protobuf/src/google/protobuf/arena.cc\n____[27 / 82] Compiling google/protobuf/src/google/protobuf/any.cc\n____[108 / 169] Compiling google/protobuf/src/google/protobuf/any.cc [for host]\n____[161 / 260] Compiling google/protobuf/src/google/protobuf/compiler/code_generator.cc [for host]\n____[252 / 330] Compiling external/re2/re2/bitstate.cc\nERROR: missing input file '@png_archive//:libpng-1.2.53/pngwutil.c'.\nERROR: /lvol/<user>/external/png_archive/BUILD:33:1: @png_archive//:png: missing input file '@png_archive//:libpng-1.2.53/pngwutil.c'.\n____Building complete.\nTarget //tensorflow/cc:tutorials_example_trainer failed to build\nERROR: /lvol/<user>/external/png_archive/BUILD:33:1 1 input file(s) do not exist.\n____Elapsed time: 277.881s, Critical Path: 6.96s\n```\n\nHere is what the tree looks like. All the soft-links point to valid files.\n\n```\n[<user>@atl4-05 tensorflow]$ ls /lvol/<user>/external/png_archive/\naclocal.m4      config.guess  example.c          LICENSE        pngbar.jpg  png.h       pngrutil.c   pngwrite.c   test-pngtest.sh\nANNOUNCE        config.h.in   INSTALL            ltmain.sh      pngbar.png  pngmem.c    pngset.c     pngwtran.c   TODO\nautogen.sh      config.sub    install-sh         Makefile.am    png.c       pngnow.png  pngtest.c    pngwutil.c   WORKSPACE\nBUILD           configure     KNOWNBUG           Makefile.in    pngconf.h   pngpread.c  pngtest.png  projects     Y2KINFO\nCHANGES         configure.ac  libpng-1.2.53.txt  missing        pngerror.c  pngread.c   pngtrans.c   README\nCMakeLists.txt  contrib       libpng.3           mkinstalldirs  pnggccrd.c  pngrio.c    pngvcrd.c    scripts\ncompile         depcomp       libpngpf.3         png.5          pngget.c    pngrtran.c  pngwio.c     test-driver\n```\n\nHere is what the /lvol/<user>/external/png_archive/BUILD file looks like.\n\n```\npackage(default_visibility = [\"//visibility:public\"])\n\nprefix_dir = \"libpng-1.2.53\"\n\nPNG_SOURCES = [\n    \"png.c\",\n    \"pngerror.c\",\n    \"pngget.c\",\n    \"pngmem.c\",\n    \"pngpread.c\",\n    \"pngread.c\",\n    \"pngrio.c\",\n    \"pngrtran.c\",\n    \"pngrutil.c\",\n    \"pngset.c\",\n    \"pngtrans.c\",\n    \"pngwio.c\",\n    \"pngwrite.c\",\n    \"pngwtran.c\",\n    \"pngwutil.c\",\n]\n\ngenrule(\n    name = \"configure\",\n    srcs = glob(\n        [\"**/*\"],\n        exclude = [prefix_dir + \"/config.h\", \"configure\"],\n    ),\n    outs = [prefix_dir + \"/config.h\"],\n    cmd = \"pushd external/png_archive/%s; workdir=$$(mktemp -d -t tmp.XXXXXXXXXX); cp -a * $$workdir; pushd $$workdir; ./configure --enable-shared=no --with-pic=no; popd; popd; cp $$workdir/config.h $(@D); rm -rf $$workdir;\" % prefix_dir,\n)\n\ncc_library(\n    name = \"png\",\n    srcs = [prefix_dir + \"/\" + source for source in PNG_SOURCES],\n    hdrs = glob([\"**/*.h\"]) + [\":configure\"],\n    includes = [prefix_dir],\n    linkopts = [\"-lz\"],\n    visibility = [\"//visibility:public\"],\n)\n```\n", "comments": ["What version of bazel do you happen to be running?\n\n@davidzchen, in case he knows :)\n", "I checked out bazel from github and built it myself 2 days ago. So HEAD ?\n", "This does seem like a bazel bug, btw -- this doesn't even hit the tensorflow side of things before it fails.  Can you report a bug there and then come back to us if it turns out that it's a problem on our end?\n", "Sorry for the delay. I don't see anything obviously wrong with the BUILD file either. Can you open a bug at bazelbuild/bazel?\n", "Closing for now until there's more evidence there's something the TF team can help with.\n", "I am using bazel 0.3.0 and ran into the same problem as well. \n", "forgot to mention some important details in the previous post : I downloaded the dependency packages and transfer to a server without internet access. I have to uncompress them and load from the uncompressed directories when I put tar.gz and zip files on the local. Not sure but It seems the reported missing files are random and all of them from the repositories corresponding to tar.gz and zip files. \n"]}, {"number": 407, "title": "Adding new op, no c++ wrapper gen and user_ops.h not found", "body": "I followed wiki of adding new op\nhttps://github.com/jikexueyuanwiki/tensorflow-zh/blob/master/SOURCE/how_tos/adding_an_op/index.md\n\nBut after rebuild successfully using \nbazel build -c opt //tensorflow/tools/pip_package:build_pip_package\npip install /tmp/tensorflow_pkg/tensorflow-0.5.0-py2-none-any.whl\n\nNo user_op.zero_out found.\n\nIt seems python wrapper automatically generated ok,\n ./bazel-genfiles/tensorflow/python/ops/gen_user_ops.py \n\nBut c++ wrapper not generated,\nI can not find ./bazel-genfiles/tensorflow/cc/ops/user_ops.{h,cc}., though tensorflow/core/user_ops/zero_out.cc exists.\n\n\"The C++ Op wrapper\n\nC++ op wrappers are created automatically for all ops placed in the tensorflow/core/user_ops directory, when you build Tensorflow. For example, ops in tensorflow/core/user_ops/zero_out.cc will generate wrappers in bazel-genfiles/tensorflow/cc/ops/user_ops.{h,cc}.\"\n", "comments": ["It's due to indentation problem of user_op.py, and after fixing identation, I forget to pip uninstall first.\nAfter pip uninstall and re generate wll and  reinstall now  I can find tensorflow.user_ops.zero_out.\nSo now no problem, but still no  ./bazel-genfiles/tensorflow/cc/ops/user_ops.{h,cc}(no dir cc under ./bazel-genfiles/tensorflow/) as the wiki said, may be not a problem, if so please close this issue @josh11b \n"]}, {"number": 406, "title": "How to do a Bilinear Tensor Product? Or generally multiply 3D tensor by a vector?", "body": "Seems like there are only two multiplication operations available, tf.mul which is element-wise and tf.matmul which performs regular 2d matrix multiplication. Am I missing something? \n", "comments": ["There is also http://www.tensorflow.org/api_docs/python/math_ops.html#batch_matmul\n\nYou can compute a bilinear form just using matmul of course.\n", "What I'm trying to do is multiply each 2d slice of a 3d tensor by the same vector. There seems to be no way to perform this operation that I can see. It's the key operation in this paper: [Reasoning With Neural Tensor Networks for Knowledge Base Completion](http://papers.nips.cc/paper/5028-reasoning-with-neural-tensor-networks-for-knowledge-base-completion.pdf)\n", "Matrix-vector can be done via a reshape of the vector, though #216 is the feature request to make a 'numpy.dot' equivalent that automatically broadcasts.\n\nI'm not an expert, but if bilinear tensor product is roughly equivalent to tensor contraction, then it should be somewhat straightforward to add tensor contraction as an operation: our CPU matmul is actually using eigen's tensor contraction underneath.\n", "I've [posted to stackoverflow](http://stackoverflow.com/questions/34110502/bilinear-tensor-product-in-tensorflow). That's probably where this question belongs. Nevertheless, I feel like there should be an operation defined by tensorflow for multipying a 3D tensor by a vector. Unless I'm overlooking it, it doesn't seem to exist. matmul won't work with a 3D tensor and batch_matmul won't accept the vector. \n", "I think that the best way to solve this would be to solve #216 and/or #175. But in the meantime, doing some clever reshaping seems sufficient. Thanks guys!\n", "Has anyone added this functionality to TensorFlow since 2015? I have a similar need.", "@zfrenchee I had a similar problem to solve so I came up with a solution that uses tensor product and tensor contraction as mentioned by @vrv. I have replied to your [stackoverflow question](https://stackoverflow.com/questions/34110502/bilinear-tensor-product-in-tensorflow/49095661#49095661)."]}, {"number": 405, "title": "gcc-4.8.1 wouldn't compile matrix_inverse_op.cc", "body": "gcc-4.8.1 didn't like the way 'using' was used. This patch fixed the issue for me.\n\n[using_typename.txt](https://github.com/tensorflow/tensorflow/files/51293/using_typename.txt)\n", "comments": ["Do you want to follow our [contributing](https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md) guidelines and send us a request via Gerrit, or would you rather us make the change for you?\n", "Since it's a simple change, if you guys can do it it would be awesome. Meanwhile I'll check on the guidelines for further contribution. Thanks!\n", "I'll apply it now.  Thanks!\n", "@azzolini: To satisfy my curiosity, what was the error message?  It's useful to include the full error message for this kind of issue.\n", "In review.\n"]}, {"number": 404, "title": "gcc-4.8.1 is unhappy with usage of auto* in conv_grad_ops.cc", "body": "Seems like gcc-4.8.1 can't resolve the type of some of the instances of auto. This diff fixed it for me:\n\n[remove_auto.txt](https://github.com/tensorflow/tensorflow/files/51290/remove_auto.txt)\n", "comments": ["Do you want to follow our [contributing](https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md) guidelines and send us a request via Gerrit, or would you rather us make the change for you?\n", "Since it's a simple change, if you guys can do it it would be awesome. Meanwhile I'll check on the guidelines for further contribution. Thanks!\n", "What error message do you get?  I'd like to understand why auto is problematic.\n", "@azzolini: we now accept PRs, so if you want to make the fix and also let us know what the error you were getting was, please do!\n", "Closing due to lack of activity.  Please reopen if this is still an issue!  If so, please include the error messages that result.\n"]}, {"number": 403, "title": "Bidirectional RNNs", "body": "I'd like to request support for bidirectional RNNs, as these are rather canonical architectures. I realize it's possible to do using the existing rnn API, but given all the intricacies of padding and such (especially in the reverse direction), it would be nice if this had builtin support.\n", "comments": ["Good request! Bidirectional RNN code is checked in internally, will go out some time soon with the next release (within a few weeks).\n", "Is the code within github now? or is it still to come as you said in the next release?\n", "Our policy is that until it is documented, assume it is private and not ready to be used.\n\n@ludimagister: let's reopen this until it's actually done and public\n", "Okay great! That's a pretty smart policy. Thanks @vrv \n", "Will it have builtin supporting for padding sequences of different length? This is easy to do in the one-directional case but the bidirectional case has to flip the padding and align the activations of the shorter sequences.\n", "Yes, for the backward RNN it will internally reverse the input sequences up to a specified length (per sequence for the given batch) and reverse then this output to produce the backward output which is then concatenated with the forward output, so the padding will be correct. The unit test should make this clear once the code is pushed.\n", "@ludimagister \n\nSeems like the BiRNN has merged. A question: Does it support padding on the front? For example, if a sequence with length 3 is padded to length 5, the layout is like this:\n\nPAD, PAD, TOKEN1, TOKEN2, TOKEN3\n\nIf I understand correctly, the backward RNN is not expecting input like this. Please correct me, if I am wrong.\n", "No, it doesn't support padding at the front, it only supports to pass in the lengths of each individual sequence in the batch, and will do the correct forward/backward pass on them, up to the specified length. Since every sequence is independent so I am not sure why it would make sense to support aligning them on the right (we picked to align them on the left).\n", "@ludimagister Padding on the front (aligning on the right) is usually used for the inputs of the sequence to sequence model.\n", "I plan to add support for this but it won't happen until at least January.\nOn Dec 9, 2015 5:37 PM, \"Raingo\" notifications@github.com wrote:\n\n> @ludimagister https://github.com/ludimagister Padding on the front\n> (aligning on the right) is usually used for the inputs of the sequence to\n> sequence model.\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/403#issuecomment-163477316\n> .\n", "Even though this is not yet public / documented I have a small note. Sequence length should not be required for `bidirectional_rnn` as `_reverse_seq` simply reverses the input if `lengths` is not given. This trivially covers cases where the input is already padded or where the input is a static number of time steps.\n\n```\n   if not isinstance(inputs, list):\n     raise TypeError(\"inputs must be a list\")\n-  if not sequence_length:\n-    raise ValueError(\"sequence_length has to be defined\")\n   if not inputs:\n     raise ValueError(\"inputs must not be empty\")\n```\n", "Yes we should remove this.  +ludigmaster@\nOn Dec 16, 2015 5:17 PM, \"Stephen Merity\" notifications@github.com wrote:\n\nEven though this is not yet public / documented I have a small note.\nSequence length should not be required for bidirectional_rnn as _reverse_seq\nsimply reverses the input if lengths is not given. This trivially covers\ncases where the input is already padded or where the input is a static\nnumber of time steps.\n\n   if not isinstance(inputs, list):\n     raise TypeError(\"inputs must be a list\")\n-  if not sequence_length:\n-    raise ValueError(\"sequence_length has to be defined\")\n  if not inputs:\n   raise ValueError(\"inputs must not be empty\")\n\n\u2014\nReply to this email directly or view it on GitHub\nhttps://github.com/tensorflow/tensorflow/issues/403#issuecomment-165325888\n.\n", "@Smerity Yes, very good point, will fix tomorrow.\n", "It has been quite a long time since we have been waiting for the Bidirectional RNN. When will it be made available to public?\n", "@shoaibahmed even though they haven't been officially made public yet, bidirectional RNNs are available in rnn.py, along with the other preliminary RNN architectures.\n", "Yes, I have checked that out @alquraishi. I want to use it for sequence classification purposes i.e. assigning a single label to a whole sequence. I am not sure how to use it for that purpose. An example like this: \nhttps://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3%20-%20Neural%20Networks/recurrent_network.py\nwill surely help a lot in understanding.\n", "Any good paper that you would recommend explaining bi-directional RNN ? \n", "On Tue, Dec 29, 2015 at 10:37 AM, Fabrizio Milo notifications@github.com\nwrote:\n\n> Any good paper that you would recommend explaining bi-directional RNN ?\n> \n> http://lmgtfy.com/?q=bidirectional+recurrent+neural+networks\n> \n> \u2014\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/403#issuecomment-167849917\n> .\n", "The example I'd love to see is how to use BiRNN to compute a sequence with one element per input sequence, with an architecture like this:\n\n```\n      /-- F_0..t --\\\nX_0..t              -- fullyConnected_0..t --> Y_0..t\n      \\-- R_0..t --/\n```\n\nSo to predict each element Y_i, an instance of a fully connected network FC_i is attached to F_i and R_i, with all FC sharing all weights.\n", "I am wondering what is going on with the bidirectional RNN function in TF. I am currently working with bidirectional RNN but asking for different batch_size in training and testing. Following https://github.com/aymericdamien/TensorFlow-Examples/blob/master/notebooks/3%20-%20Neural%20Networks/bidirectional_rnn.ipynb, I am now facing the problem to set seq_len = batch_size. Any suggestions?\n", "RNNs are available in python code. How can we create an RNN using C++ API in TensorFlow?\n", "@ludimagister, @ebrevdo: What's the status of bidirectional RNNs?  \n", "Hi , A small doubt . In Bi - directional RNN if the input is [ w1 , w2 , w3 , w4 , PAD , PAD ] , while its reversing internally , will it reverse like [ PAD , PAD , w4 , w3 , w2 , w1 ] . The doubt is because , while concatenating the forward hidden state and backward hidden state ( reversed ) , if the hidden state computes in the backward RNN is starting from left to right , we will lose the information . ( hidden state fw(w1) + hidden state bw(PAD) ) . This is not what we expect I guess . I have not seen the implementation , just want to know if it is processing correctly or not . \n", "Provide sequence_lengths and it will reverse correctly, keeping padding on\nthe right.\n\nOn Jul 28, 2016 1:58 AM, \"s4sarath\" notifications@github.com wrote:\n\n> Hi , A small doubt . In Bi - directional RNN if the input is [ w1 , w2 ,\n> w3 , w4 , PAD , PAD ] , while its reversing internally , will it reverse\n> like [ PAD , PAD , w4 , w3 , w2 , w1 ] . The doubt is because , while\n> concatenating the forward hidden state and backward hidden state ( reversed\n> ) , if the hidden state computes in the backward RNN is starting from left\n> to right , we will lose the information . ( hidden state fw(w1) + hidden\n> state bw(PAD) ) . This is not what we expect I guess . I have not seen the\n> implementation , just want to know if it is processing correctly or not .\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/403#issuecomment-235838856,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ABtim0eaZk0UdYKoZHr__Bs7ZMwiL38Lks5qaG87gaJpZM4GuHp8\n> .\n", "You can also compute them dynamically if your sequences are zero-padded (more details [on my blog](https://danijar.com/variable-sequence-lengths-in-tensorflow/)):\n\n``` python\nmask = tf.sign(tf.reduce_max(tf.abs(sequence), 2))\nlength = tf.reduce_sum(mask, 1)\n```\n", "@danijar . Yeah I am following your blog for variable length sequence classification. \n@ebrevdo  - Thanks . \n", "@danlijar you should change the following line on your blog:\n\nmax_length = int(output.get_shape()[1])\n\nto:\n\nmax_length = tf.shape(output)[1]\n\nsince in general max_length can vary from run to run.\n\nOn Thu, Jul 28, 2016 at 8:04 AM, s4sarath notifications@github.com wrote:\n\n> @danijar https://github.com/danijar . Yeah I am following your blog for\n> variable length sequence classification.\n> @ebrevdo https://github.com/ebrevdo - Thanks .\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/403#issuecomment-235922547,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ABtim-kOPYGFIwB3298NPD8l4GUyJ6z8ks5qaMTtgaJpZM4GuHp8\n> .\n", "@ebrevdo Thanks for your feedback :)\n", "@danijar @ebrevdo is this still an open feature request? If the code is now out I will close and move usage discussions to StackOverflow.\n", "Do we get an RNN using C++ API in TensorFlow?"]}, {"number": 402, "title": "More details of Inception model?", "body": "Please include the following details for the inception model included in the android and label-image example:\n1. training dataset\n2. testing dataset and what's the top-1 and top-5 performance\n3. training parameters, number of iterations, learning rate, optimization algorithm\n", "comments": ["I believe that the currently released model corresponds to: http://arxiv.org/abs/1409.4842\n@Yangqing would know exactly.\nWe don't have more details to release about that particular model beyond what's published.\nA more recent version with lots of details about the training process is described here: http://arxiv.org/abs/1512.00567\n", "Thanks for the information. Is it possible to release the inception-v3 model?\n"]}, {"number": 401, "title": "Tutorial TensorBoard: Visualizing Learning, path error", "body": "In the following tutorial about visualizing TensorBoard is an error: http://www.tensorflow.org/how_tos/summaries_and_tensorboard/index.html\n\nThe tutorial says the code to run the visualization of the mnist data is:\n\n```\ntensorboard --logdir=/tmp/mnist_data\n```\n\nHowever in the code you provide, you put:\n\n```\nwriter = tf.train.SummaryWriter(\"/tmp/mnist_logs\", sess.graph_def)\n```\n\nmnist_data =/= mnist_logs. The right code is:\n\n```\ntensorboard --logdir=/tmp/mnist_logs\n```\n\n---\n\nAdditionally would it be possible to explain how TensorBoard takes it current path?\nFor example, if I change `--logdir=/tmp/mnist_logs` to `--logdir=mnist_logs` (to put it in the current directory I'm working in), it correctly makes a new folder `mnist_logs`. However if I run the following code in the current directory:\n\n```\n tensorboard --logdir=mnist_logs\n```\n\nTensorBoard cannot find the log file. How would I run `tensorboard` from the current directory?\n\n---\n\nOn the subject of path clarity, could you add an output which states where TensorBoard looks for the log file? Currently:\n\n```\nStarting TensorBoard on port 6006\n(You can navigate to http://localhost:6006)\n```\n\nCould you add:\n\n```\nTensorBoard looks for the log files in: /path/to/folder/\nand found a file / didn't find a file\n```\n", "comments": ["I think https://github.com/tensorflow/tensorflow/pull/337 might have fixed this -- this will be in the next release but you can probably build from sources to get the fix now.\n", "@NumesSanguis As well as relative paths being fixed, I believe it now prints the path right before the line `Starting TensorBoard on port 6006` (although I'm not sure when that change was made).\n<img width=\"730\" alt=\"screen shot 2015-12-23 at 2 11 09 pm\" src=\"https://cloud.githubusercontent.com/assets/511499/11983846/bca15cf8-a984-11e5-946d-5291ca41021d.PNG\">\n"]}, {"number": 400, "title": "Tutorial: Visual Object Recognition", "body": "When will the 'Visual Object Recognition' part of the tutorial be released?\n", "comments": ["The tutorial has been released.\nhttps://www.tensorflow.org/versions/master/tutorials/image_recognition/index.html\n\nBelow is a cut-and-paste from a recent announcement sent to discuss@tensorflow.org.\n\n# \n\nDear TensorFlow community,\n\nToday we are releasing our best image classifier trained on ImageNet data. As described in our recent Arxiv preprint at http://arxiv.org/abs/1512.00567, an ensemble of four of these models achieves 3.46% top-5 error on the validation set of the ImageNet whole image ILSVRC2012 classification task (compared with our ensemble from last year that won the 2014 ImageNet classification challenge with a 6.66% top-5 error rate).\n\nIn this release, we are supplying code and data files containing the trained model parameters for running the image classifier on:\nBoth desktop and mobile environments\nEmploying either a C++ or Python API.\n\nIn addition, we are providing a tutorial that describes how to use the image recognition system for a variety of use-cases.\n    http://www.tensorflow.org/tutorials/image_recognition/index.html\n\nThis release allows one to compute higher-level visual features and/or perform image recognition on the ImageNet 1000 object label set*. We are actively working on refactoring our code so that we can open-source a complete training system for this model so that others can train on their own data or fine-tune it for other purposes (Some custom training operations for this model rely on code that is shared between our non-open-sourced DistBelief system and TensorFlow and we are actively working on disentangling this).\n\nWe wish to especially acknowledge Christian Szegedy, Sergey Ioffe and Vincent Vanhoucke for developing this network and helping make this happen.\n\nHappy Holidays-\nSherry, Pete, Chris, Jon with contributions from many team members\n- The 1000 object labels are listed at:\n  http://image-net.org/challenges/LSVRC/2014/browse-synsets\n"]}, {"number": 399, "title": "connection refused", "body": "Hello all,\nI have a problem when running: python tensorflow/models/image/mnist/convolutional.py\nAn error evoked :  IOError: [Errno socket error] [Errno 111] Connection refused\n\nCan it be related to proxy settings problem? \n", "comments": ["Probably a dup of https://github.com/tensorflow/tensorflow/issues/209 -- Yann's website is probably getting taken down by all of these downloads occasionally.  We haven't put up a mirror since I don't think we (yet) have the rights to - de-duping with 209 for now.\n", "Thnx for the comment..But can it be related to some socket configuration also? since i tired to make connection through socket to other websites and it returned my the same error\n", "It's possible - it's probably worth you instrumenting https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/mnist/convolutional.py#L59 to figure out what you need to get access.\n", "I had the problem of setting the proxy of the netowrk..Thnx!\n"]}, {"number": 398, "title": "GPU ran-out-of-memory problem", "body": "I've got a GPU ran-out-of-memory problem.\n\nMy single GPU Card has about 11GB memory. As the nvidia-smi shows below:\n## N/A   48C    P0   129W / 235W |  10985MiB / 11519MiB |     99%      Default\n\nI define a big CNN models, it is like this:\n## My CNN Models Start...\n\nLayer 1.\ninput: one batch 35 pics, with 1024x1024x3:\n(35,1024,1024,3)\n\nLayer 2.\n2D conv-layer and 2D max-pool layer:\nconv-kernel (3,3,3), 16 feature maps, stride=1, and using \"SAME\" padding,\nmax-pool-kernel (2,2), stride=2, so the output should be\n(35,512,512,16)\nand the parameters of the layer should be:\nW: 3x3x3x16+b: 16=448\n\nLayer3, 4, 5, 6:\nThe same as Layer2, 2D Conv and 2D Max Pool,\nconv-kernel (3,3,16), 16 feature maps, stride=1, and using \"SAME\" padding,\nmax-pool-kernel (2,2), strides=2, \nthe output of the layers is:\n(35,256,256,16)\n(35,128,128,16)\n(35,64,64,16)\n(35,32,32,16)\nThe total parameters is:\n4x(3x3x16x16)+4x16=9280\n\nLayer7:\ndense layer with 2048 hidden nodes,\nthe parameters:\n32x32x16x2048+2048=33556480\n\nLayer8:\ndense layer with 600 hidden nodes,\nthe parameters:\n600x2048+600=1229400\n## END.\n\nSo all together, the model has 448+9280+33556480+1229400=34795608 float32 parameters, it is  34795608x4/1024/1024=132MB parameters.\n\nMaybe I should also add the memory cost by the outputs, so it is\n(35x1024x1024x3)+(35x512x512x16)+(35x256x256x16)+(35x128x128x16)+(35x64x64x16)+(35x32x32x16)=305643520 float32\n=305643520x4/1024/1024=1164MB\n## All together, no more than 2GB. Far from 11GB.\n\nBut I got the following:\n## Ran out of memory trying to allocate 512.00MiB.  See logs for memory state\n\nHowever,  once I changed the number of output feature-maps for each layer from 16 to 8 (or less), the model just trained well.\n\nI use the latest tensor-flow codes (20151202), the following session configs:\n## Code start\n\n```\n### start session\nconfig=tf.ConfigProto()\n# config.gpu_options.per_process_gpu_memory_fraction=0.98\nconfig.gpu_options.allocator_type=\"BFC\"\nconfig.log_device_placement=True\nsess=tf.Session(config=config)\n```\n## Code end\n\nBut it doesn't solve my problems.\n## So, help....\n", "comments": ["If you include the full logs of the output when the GPU runs out of memory, we might be able to help.\n\nWe are also working on user tools to diagnose memory problems, so look out for that in the future\n", "Hi, @vrv \nDoes ' full logs' means the following (seems to be a little too full ...):\n\n## err\n\n<blockquote>\nI tensorflow/core/common_runtime/local_device.cc:40] Local device intra op parallelism threads: 32\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:103] Found device 0 with properties: \nname: Tesla K40m\nmajor: 3 minor: 5 memoryClockRate (GHz) 0.745\npciBusID 0000:83:00.0\nTotal memory: 11.25GiB\nFree memory: 11.12GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:127] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:137] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:702] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40m, pci bus id: 0000:83:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Allocating 10.57GiB bytes.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:52] GPU 0 memory begins at 0x2047a0000 extends to 0x4a8ab8e67\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 32.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 64.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 128.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 256.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 512.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 1.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 2.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 4.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 8.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:66] Creating bin of max chunk size 16.00GiB\nI tensorflow/core/common_runtime/direct_session.cc:60] Direct session inter op parallelism threads: 32\nI tensorflow/core/common_runtime/direct_session.cc:126] Device mapping:\n/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: Tesla K40m, pci bus id: 0000:83:00.0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_15/Momentum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] zeros_15: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_15/Momentum/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_14/Momentum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] zeros_14: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_14/Momentum/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_13/Momentum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] zeros_13: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_13/Momentum/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_12/Momentum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] zeros_12: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_12/Momentum/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_11/Momentum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] zeros_11: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_11/Momentum/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_10/Momentum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] zeros_10: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_10/Momentum/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_9/Momentum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] zeros_9: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_9/Momentum/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_8/Momentum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] zeros_8: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_8/Momentum/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_7/Momentum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] zeros_7: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_7/Momentum/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_6/Momentum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] zeros_6: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_6/Momentum/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_5/Momentum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] zeros_5: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_5/Momentum/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_4/Momentum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] zeros_4: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_4/Momentum/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_3/Momentum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] zeros_3: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_3/Momentum/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_2/Momentum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] zeros_2: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_2/Momentum/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_1/Momentum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] zeros_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_1/Momentum/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable/Momentum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] zeros: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable/Momentum/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_15: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Const_7: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_15/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_14: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_7/stddev: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_7/mean: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_7/shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_7/TruncatedNormal: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_7/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_7: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_14/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_13: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Const_6: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_13/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_12: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_6/stddev: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_6/mean: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_6/shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_6/TruncatedNormal: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_6/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_6: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_12/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_11: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Const_5: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_11/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_10: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_5/stddev: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_5/mean: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_5/shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_5/TruncatedNormal: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_5/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_5: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_10/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_9: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Const_4: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_9/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_8: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_4/stddev: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_4/mean: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_4/shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_4/TruncatedNormal: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_4/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_4: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_8/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_7: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Const_3: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_7/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_6: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_3/stddev: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_3/mean: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_3/shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_3/TruncatedNormal: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_3/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_3: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_6/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_5: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Const_2: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_5/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_4: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_2/stddev: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_2/mean: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_2/shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_2/TruncatedNormal: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_2/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_2: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_4/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_3: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Const_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_3/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_2: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_1/stddev: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_1/mean: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_1/shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_1/TruncatedNormal: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_1/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_2/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Const: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_1/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal/stddev: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal/mean: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal/shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal/TruncatedNormal: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] truncated_normal: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable/Assign: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] init: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Momentum/momentum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_grad/zeros/Const: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_1_grad/zeros/Const: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_2_grad/zeros/Const: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_3_grad/zeros/Const: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_4_grad/zeros/Const: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_5_grad/zeros/Const: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_6_grad/zeros/Const: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/SoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Mean_grad/range_2/delta: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Mean_grad/range_2/start: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Mean_grad/range_1/delta: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Mean_grad/range_1/start: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Mean_grad/Fill/value: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Mean_grad/range/delta: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Mean_grad/range/start: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Const: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] range/delta: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] range/start: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_15/read: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_7_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_14/read: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] dropout_1/random_uniform/max: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] dropout_1/random_uniform/min: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] dropout_1/random_uniform/sub: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] dropout_1/keep_prob: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] dropout_1/Inv: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout_1/mul_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] mul_6/x: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_6_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_13/read: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_6_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_12/read: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] dropout/random_uniform/max: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] dropout/random_uniform/min: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] dropout/random_uniform/sub: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] dropout/keep_prob: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] dropout/Inv: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout/mul_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] mul_5/x: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_5_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_11/read: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_5_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_10/read: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Reshape/shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] mul_4/x: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_4_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_9/read: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_4_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_8/read: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Conv2D_4_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] mul_3/x: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_3_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_7/read: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_3_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_6/read: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Conv2D_3_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] mul_2/x: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_2_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_5/read: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_2_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_4/read: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Conv2D_2_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] mul_1/x: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_1_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_3/read: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_1_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_2/read: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Conv2D_1_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] mul/x: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable_1/read: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Variable/read: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Conv2D_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Conv2D_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Conv2D: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] add: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_grad/GreaterEqual: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_grad/LogicalNot: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Maximum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] MaxPool: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Conv2D_1_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Conv2D_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_1_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_1_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] add_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_1_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_1_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_1_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] mul_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_1_grad/GreaterEqual: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_1_grad/LogicalNot: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_1_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_1_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Maximum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] MaxPool_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Conv2D_2_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Conv2D_2: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_2_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_2_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] add_2: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_2_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_2_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_2_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] mul_2: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_2_grad/GreaterEqual: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_2_grad/LogicalNot: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_2_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_2_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Maximum_2: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] MaxPool_2: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Conv2D_3_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Conv2D_3: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_3_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_3_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] add_3: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_3_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_3_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_3_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] mul_3: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_3_grad/GreaterEqual: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_3_grad/LogicalNot: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_3_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_3_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Maximum_3: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] MaxPool_3: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Conv2D_4_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Conv2D_4: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_4_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_4_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] add_4: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_4_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_4_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_4_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] mul_4: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_4_grad/GreaterEqual: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_4_grad/LogicalNot: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_4_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_4_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Maximum_4: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] MaxPool_4: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Reshape_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] MatMul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_5_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_5_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] add_5: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_5_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_5_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_5_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] mul_5: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_5_grad/GreaterEqual: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_5_grad/LogicalNot: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_5_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_5_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Maximum_5: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout/mul_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout/mul_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] dropout/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout/mul_1_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] dropout/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] dropout/random_uniform/RandomUniform: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] dropout/random_uniform/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] dropout/random_uniform: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] dropout/add: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] dropout/Floor: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout/mul_1_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout/mul_1_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] dropout/mul_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] MatMul_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_6_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_6_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] add_6: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_6_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_6_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_6_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] mul_6: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_6_grad/GreaterEqual: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_6_grad/LogicalNot: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_6_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_6_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Maximum_6: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout_1/mul_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout_1/mul_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] dropout_1/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout_1/mul_1_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] dropout_1/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] dropout_1/random_uniform/RandomUniform: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] dropout_1/random_uniform/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] dropout_1/random_uniform: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] dropout_1/add: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] dropout_1/Floor: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout_1/mul_1_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout_1/mul_1_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] dropout_1/mul_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] MatMul_2: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_7_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_7_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] add_7: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] SoftmaxCrossEntropyWithLogits: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Mean_grad/Shape_2: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Mean_grad/Rank_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Mean_grad/range_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Mean_grad/Prod: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Mean_grad/Rank: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Mean_grad/range: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Mean_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Rank: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] range: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Mean_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Mean_grad/Fill: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Mean_grad/DynamicStitch: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Mean_grad/floordiv: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Mean: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Mean_grad/Shape_3: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Mean_grad/Rank_2: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Mean_grad/range_2: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Mean_grad/Prod_1: /job:localhost/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Mean_grad/floordiv_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Mean_grad/Cast: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Shape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Fill: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Mean_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Mean_grad/Tile: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Mean_grad/truediv: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Mean_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Mean_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/SoftmaxCrossEntropyWithLogits_grad/ExpandDims: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/SoftmaxCrossEntropyWithLogits_grad/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/SoftmaxCrossEntropyWithLogits_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/SoftmaxCrossEntropyWithLogits_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_7_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_7_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_7_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_7_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_7_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_7_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Momentum/update_Variable_15/ApplyMomentum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_7_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/MatMul_2_grad/MatMul_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/MatMul_2_grad/MatMul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/MatMul_2_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/MatMul_2_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Momentum/update_Variable_14/ApplyMomentum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/MatMul_2_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout_1/mul_1_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout_1/mul_1_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout_1/mul_1_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout_1/mul_1_grad/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout_1/mul_1_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout_1/mul_1_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout_1/mul_1_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout_1/mul_1_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout_1/mul_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout_1/mul_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout_1/mul_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout_1/mul_grad/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout_1/mul_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout_1/mul_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout_1/mul_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout_1/mul_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_6_grad/Shape_2: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_6_grad/zeros: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_6_grad/Select_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_6_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_6_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_6_grad/Select: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_6_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_6_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_6_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_6_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_6_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_6_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_6_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_6_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_6_grad/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_6_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_6_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_6_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_6_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/AddN: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_6_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_6_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_6_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_6_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_6_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_6_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Momentum/update_Variable_13/ApplyMomentum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_6_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/MatMul_1_grad/MatMul_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/MatMul_1_grad/MatMul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/MatMul_1_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/MatMul_1_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Momentum/update_Variable_12/ApplyMomentum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/MatMul_1_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout/mul_1_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout/mul_1_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout/mul_1_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout/mul_1_grad/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout/mul_1_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout/mul_1_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout/mul_1_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout/mul_1_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout/mul_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout/mul_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout/mul_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout/mul_grad/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout/mul_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout/mul_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout/mul_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/dropout/mul_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_5_grad/Shape_2: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_5_grad/zeros: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_5_grad/Select_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_5_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_5_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_5_grad/Select: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_5_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_5_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_5_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_5_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_5_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_5_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_5_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_5_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_5_grad/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_5_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_5_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_5_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_5_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/AddN_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_5_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_5_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_5_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_5_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_5_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_5_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Momentum/update_Variable_11/ApplyMomentum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_5_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/MatMul_grad/MatMul_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/MatMul_grad/MatMul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/MatMul_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/MatMul_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Momentum/update_Variable_10/ApplyMomentum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/MatMul_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Reshape_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Reshape_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Reshape_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/MaxPool_4_grad/MaxPoolGrad: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_4_grad/Shape_2: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_4_grad/zeros: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_4_grad/Select_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_4_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_4_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_4_grad/Select: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_4_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_4_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_4_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_4_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_4_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_4_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_4_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_4_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_4_grad/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_4_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_4_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_4_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_4_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/AddN_2: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_4_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_4_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_4_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_4_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_4_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_4_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Momentum/update_Variable_9/ApplyMomentum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_4_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Conv2D_4_grad/Conv2DBackpropFilter: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Conv2D_4_grad/Conv2DBackpropInput: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Conv2D_4_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Conv2D_4_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Momentum/update_Variable_8/ApplyMomentum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Conv2D_4_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/MaxPool_3_grad/MaxPoolGrad: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_3_grad/Shape_2: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_3_grad/zeros: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_3_grad/Select_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_3_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_3_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_3_grad/Select: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_3_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_3_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_3_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_3_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_3_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_3_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_3_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_3_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_3_grad/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_3_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_3_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_3_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_3_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/AddN_3: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_3_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_3_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_3_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_3_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_3_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_3_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Momentum/update_Variable_7/ApplyMomentum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_3_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Conv2D_3_grad/Conv2DBackpropFilter: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Conv2D_3_grad/Conv2DBackpropInput: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Conv2D_3_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Conv2D_3_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Momentum/update_Variable_6/ApplyMomentum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Conv2D_3_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/MaxPool_2_grad/MaxPoolGrad: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_2_grad/Shape_2: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_2_grad/zeros: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_2_grad/Select_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_2_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_2_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_2_grad/Select: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_2_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_2_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_2_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_2_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_2_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_2_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_2_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_2_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_2_grad/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_2_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_2_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_2_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_2_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/AddN_4: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_2_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_2_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_2_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_2_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_2_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_2_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Momentum/update_Variable_5/ApplyMomentum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_2_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Conv2D_2_grad/Conv2DBackpropFilter: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Conv2D_2_grad/Conv2DBackpropInput: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Conv2D_2_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Conv2D_2_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Momentum/update_Variable_4/ApplyMomentum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Conv2D_2_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/MaxPool_1_grad/MaxPoolGrad: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_1_grad/Shape_2: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_1_grad/zeros: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_1_grad/Select_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_1_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_1_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_1_grad/Select: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_1_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_1_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_1_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_1_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_1_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_1_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_1_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_1_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_1_grad/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_1_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_1_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_1_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_1_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/AddN_5: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_1_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_1_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_1_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_1_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_1_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_1_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Momentum/update_Variable_3/ApplyMomentum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_1_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Conv2D_1_grad/Conv2DBackpropFilter: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Conv2D_1_grad/Conv2DBackpropInput: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Conv2D_1_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Conv2D_1_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Momentum/update_Variable_2/ApplyMomentum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Conv2D_1_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/MaxPool_grad/MaxPoolGrad: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_grad/Shape_2: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_grad/zeros: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_grad/Select_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_grad/Select: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Maximum_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_grad/mul: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/mul_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/AddN_6: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Momentum/update_Variable_1/ApplyMomentum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/add_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Conv2D_grad/Conv2DBackpropFilter: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Conv2D_grad/Conv2DBackpropInput: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Conv2D_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] gradients/Conv2D_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Momentum/update_Variable/ApplyMomentum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:304] Momentum: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:366] Bin (256):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:366] Bin (1024):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:366] Bin (2048):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:366] Bin (4096):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:366] Bin (8192):  Total Chunks: 1, Chunks in use: 0 5.0KiB allocated for chunks. 4B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:366] Bin (16384):     Total Chunks: 5, Chunks in use: 0 46.8KiB allocated for chunks. 45.0KiB client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:366] Bin (32768):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:366] Bin (65536):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:366] Bin (131072):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:366] Bin (262144):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:366] Bin (524288):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:366] Bin (1048576):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:366] Bin (2097152):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:366] Bin (4194304):   Total Chunks: 1, Chunks in use: 0 3.49MiB allocated for chunks. 9.0KiB client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:366] Bin (8388608):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:366] Bin (16777216):  Total Chunks: 1, Chunks in use: 0 16.00MiB allocated for chunks. 8.00MiB client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:366] Bin (33554432):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:366] Bin (67108864):  Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:366] Bin (134217728):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:366] Bin (268435456):     Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:366] Bin (536870912):     Total Chunks: 1, Chunks in use: 0 288.00MiB allocated for chunks. 128.00MiB client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:366] Bin (1073741824):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:366] Bin (2147483648):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:366] Bin (4294967296):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:366] Bin (8589934592):    Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:366] Bin (17179869184):   Total Chunks: 0, Chunks in use: 0 0B allocated for chunks. 0B client-requested for chunks. 0B in use in bin. 0B client-requested in use in bin.\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:385] Bin for 512.00MiB was 512.00MiB, Chunk State: \nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:390]   Size: 288.00MiB | Requested Size: 128.00MiB | in_use: 0, prev:   Size: 512.00MiB | Requested Size: 512.00MiB | in_use: 1, next:   Size: 129.01MiB | Requested Size: 128.00MiB | in_use: 1\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x3a60e2a00 of size 135274496\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x3940e2a00 of size 301989888\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2b3ce0a00 of size 536870912\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x273ce0a00 of size 536870912\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2d3ce0a00 of size 2147483648\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20db33700 of size 5120\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x253ce0a00 of size 536870912\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20db33600 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x353ce0a00 of size 541073408\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20db33500 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20db33400 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20db33300 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20db33200 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20db33100 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20db32d00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20db32c00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20db32b00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x3740e2a00 of size 536870912\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20db32a00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20db32900 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20db32500 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20db32400 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20db32300 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20db32200 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20db32100 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20db34c00 of size 9216\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20db33000 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20d7b3800 of size 3661824\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x216ebe200 of size 1792\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20db34b00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20db32600 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x3ae1e4a00 of size 632274944\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x216ec7e00 of size 134217728\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x22994fc00 of size 3661824\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047a8900 of size 9216\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20db31800 of size 1792\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20db32800 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x216b3fb00 of size 3661824\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x216ec0f00 of size 9216\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x3d3ce0a00 of size 3571287143\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x22024a500 of size 158357248\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047af700 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047a1100 of size 8192\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047a1000 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x232cd7300 of size 1792\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047aae00 of size 9216\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047aad00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047a8800 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20db32700 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047a5c00 of size 1792\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x229ccdc00 of size 11008\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047a0900 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x216ec5800 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047a0700 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20db32f00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047a6400 of size 9216\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047a0600 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20db32e00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047a6300 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047a0200 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20db3bb00 of size 134217728\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047a0500 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x293ce0a00 of size 536870912\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x215b3bb00 of size 8192\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047a3200 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x21eec7e00 of size 8192\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047a0100 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20db3ba00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047a0000 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047ad200 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047a0b00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047ad300 of size 9216\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047a0c00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047a3100 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047af800 of size 134217728\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047a0800 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047a0d00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047a3300 of size 8192\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20db37000 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047a0e00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x216ebe900 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047a5300 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20db37100 of size 9216\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047a0300 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20db39500 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047a0400 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20c7b1800 of size 16777216\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20db39600 of size 9216\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x216ec5900 of size 9216\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x215b3db00 of size 16777216\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x23acde600 of size 16777216\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20d7b1800 of size 8192\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x216ebdb00 of size 1792\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20db32000 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047a5500 of size 1792\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x21fecbe00 of size 3661824\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047a5400 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20db31f00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x216ebea00 of size 9216\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x216ec0e00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x216ec3300 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x216ec3400 of size 9216\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x216ec7d00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x21fec9e00 of size 8192\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x21eec9e00 of size 16777216\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x216b3db00 of size 8192\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x220249e00 of size 1792\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x20c7af800 of size 8192\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x23bcde600 of size 9216\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x229cd0700 of size 9216\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x23bce0a00 of size 402653184\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047a0f00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x229cd2b00 of size 151013376\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x2047a0a00 of size 256\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x232cd7a00 of size 9216\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x232cd9e00 of size 9216\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x232cdc200 of size 9216\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:400] Chunk at 0x232cde600 of size 134217728\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:403]      Summary of in-use Chunks by size: \nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 59 Chunks of size 256 totalling 14.8KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 7 Chunks of size 1792 totalling 12.2KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 1 Chunks of size 5120 totalling 5.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 8 Chunks of size 8192 totalling 64.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 16 Chunks of size 9216 totalling 144.0KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 1 Chunks of size 11008 totalling 10.8KiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 4 Chunks of size 3661824 totalling 13.97MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 4 Chunks of size 16777216 totalling 64.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 4 Chunks of size 134217728 totalling 512.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 1 Chunks of size 135274496 totalling 129.01MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 1 Chunks of size 151013376 totalling 144.02MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 1 Chunks of size 158357248 totalling 151.02MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 1 Chunks of size 301989888 totalling 288.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 1 Chunks of size 402653184 totalling 384.00MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 5 Chunks of size 536870912 totalling 2.50GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 1 Chunks of size 541073408 totalling 516.01MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 1 Chunks of size 632274944 totalling 602.98MiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 1 Chunks of size 2147483648 totalling 2.00GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:406] 1 Chunks of size 3571287143 totalling 3.33GiB\nI tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:410] Sum Total of in-use chunks: 10.57GiB\nW tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:166] Ran out of memory trying to allocate 512.00MiB.  See logs for memory state\nW tensorflow/core/kernels/pooling_ops_common.cc:167] Resource exhausted: OOM when allocating tensor with shapedim { size: 32 } dim { size: 16 } dim { size: 512 } dim { size: 512 }\nW tensorflow/core/common_runtime/executor.cc:1071] 0x4a442a0 Compute status: Resource exhausted: OOM when allocating tensor with shapedim { size: 32 } dim { size: 16 } dim { size: 512 } dim { size: 512 }\n     [[Node: gradients/MaxPool_1_grad/MaxPoolGrad = MaxPoolGrad[ksize=[1, 2, 2, 1], padding=\"SAME\", strides=[1, 2, 2, 1], _device=\"/job:localhost/replica:0/task:0/gpu:0\"](Maximum_1, MaxPool_1, gradients/Conv2D_2_grad/tuple/control_dependency)]]\n</blockquote>\n\n## log\n\n<blockquote>\nDevice mapping:\n/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: Tesla K40m, pci bus id: 0000:83:00.0\nVariable_15/Momentum: /job:localhost/replica:0/task:0/gpu:0\nzeros_15: /job:localhost/replica:0/task:0/gpu:0\nVariable_15/Momentum/Assign: /job:localhost/replica:0/task:0/gpu:0\nVariable_14/Momentum: /job:localhost/replica:0/task:0/gpu:0\nzeros_14: /job:localhost/replica:0/task:0/gpu:0\nVariable_14/Momentum/Assign: /job:localhost/replica:0/task:0/gpu:0\nVariable_13/Momentum: /job:localhost/replica:0/task:0/gpu:0\nzeros_13: /job:localhost/replica:0/task:0/gpu:0\nVariable_13/Momentum/Assign: /job:localhost/replica:0/task:0/gpu:0\nVariable_12/Momentum: /job:localhost/replica:0/task:0/gpu:0\nzeros_12: /job:localhost/replica:0/task:0/gpu:0\nVariable_12/Momentum/Assign: /job:localhost/replica:0/task:0/gpu:0\nVariable_11/Momentum: /job:localhost/replica:0/task:0/gpu:0\nzeros_11: /job:localhost/replica:0/task:0/gpu:0\nVariable_11/Momentum/Assign: /job:localhost/replica:0/task:0/gpu:0\nVariable_10/Momentum: /job:localhost/replica:0/task:0/gpu:0\nzeros_10: /job:localhost/replica:0/task:0/gpu:0\nVariable_10/Momentum/Assign: /job:localhost/replica:0/task:0/gpu:0\nVariable_9/Momentum: /job:localhost/replica:0/task:0/gpu:0\nzeros_9: /job:localhost/replica:0/task:0/gpu:0\nVariable_9/Momentum/Assign: /job:localhost/replica:0/task:0/gpu:0\nVariable_8/Momentum: /job:localhost/replica:0/task:0/gpu:0\nzeros_8: /job:localhost/replica:0/task:0/gpu:0\nVariable_8/Momentum/Assign: /job:localhost/replica:0/task:0/gpu:0\nVariable_7/Momentum: /job:localhost/replica:0/task:0/gpu:0\nzeros_7: /job:localhost/replica:0/task:0/gpu:0\nVariable_7/Momentum/Assign: /job:localhost/replica:0/task:0/gpu:0\nVariable_6/Momentum: /job:localhost/replica:0/task:0/gpu:0\nzeros_6: /job:localhost/replica:0/task:0/gpu:0\nVariable_6/Momentum/Assign: /job:localhost/replica:0/task:0/gpu:0\nVariable_5/Momentum: /job:localhost/replica:0/task:0/gpu:0\nzeros_5: /job:localhost/replica:0/task:0/gpu:0\nVariable_5/Momentum/Assign: /job:localhost/replica:0/task:0/gpu:0\nVariable_4/Momentum: /job:localhost/replica:0/task:0/gpu:0\nzeros_4: /job:localhost/replica:0/task:0/gpu:0\nVariable_4/Momentum/Assign: /job:localhost/replica:0/task:0/gpu:0\nVariable_3/Momentum: /job:localhost/replica:0/task:0/gpu:0\nzeros_3: /job:localhost/replica:0/task:0/gpu:0\nVariable_3/Momentum/Assign: /job:localhost/replica:0/task:0/gpu:0\nVariable_2/Momentum: /job:localhost/replica:0/task:0/gpu:0\nzeros_2: /job:localhost/replica:0/task:0/gpu:0\nVariable_2/Momentum/Assign: /job:localhost/replica:0/task:0/gpu:0\nVariable_1/Momentum: /job:localhost/replica:0/task:0/gpu:0\nzeros_1: /job:localhost/replica:0/task:0/gpu:0\nVariable_1/Momentum/Assign: /job:localhost/replica:0/task:0/gpu:0\nVariable/Momentum: /job:localhost/replica:0/task:0/gpu:0\nzeros: /job:localhost/replica:0/task:0/gpu:0\nVariable/Momentum/Assign: /job:localhost/replica:0/task:0/gpu:0\nVariable_15: /job:localhost/replica:0/task:0/gpu:0\nConst_7: /job:localhost/replica:0/task:0/gpu:0\nVariable_15/Assign: /job:localhost/replica:0/task:0/gpu:0\nVariable_14: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_7/stddev: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_7/mean: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_7/shape: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_7/TruncatedNormal: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_7/mul: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_7: /job:localhost/replica:0/task:0/gpu:0\nVariable_14/Assign: /job:localhost/replica:0/task:0/gpu:0\nVariable_13: /job:localhost/replica:0/task:0/gpu:0\nConst_6: /job:localhost/replica:0/task:0/gpu:0\nVariable_13/Assign: /job:localhost/replica:0/task:0/gpu:0\nVariable_12: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_6/stddev: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_6/mean: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_6/shape: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_6/TruncatedNormal: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_6/mul: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_6: /job:localhost/replica:0/task:0/gpu:0\nVariable_12/Assign: /job:localhost/replica:0/task:0/gpu:0\nVariable_11: /job:localhost/replica:0/task:0/gpu:0\nConst_5: /job:localhost/replica:0/task:0/gpu:0\nVariable_11/Assign: /job:localhost/replica:0/task:0/gpu:0\nVariable_10: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_5/stddev: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_5/mean: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_5/shape: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_5/TruncatedNormal: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_5/mul: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_5: /job:localhost/replica:0/task:0/gpu:0\nVariable_10/Assign: /job:localhost/replica:0/task:0/gpu:0\nVariable_9: /job:localhost/replica:0/task:0/gpu:0\nConst_4: /job:localhost/replica:0/task:0/gpu:0\nVariable_9/Assign: /job:localhost/replica:0/task:0/gpu:0\nVariable_8: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_4/stddev: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_4/mean: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_4/shape: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_4/TruncatedNormal: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_4/mul: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_4: /job:localhost/replica:0/task:0/gpu:0\nVariable_8/Assign: /job:localhost/replica:0/task:0/gpu:0\nVariable_7: /job:localhost/replica:0/task:0/gpu:0\nConst_3: /job:localhost/replica:0/task:0/gpu:0\nVariable_7/Assign: /job:localhost/replica:0/task:0/gpu:0\nVariable_6: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_3/stddev: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_3/mean: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_3/shape: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_3/TruncatedNormal: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_3/mul: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_3: /job:localhost/replica:0/task:0/gpu:0\nVariable_6/Assign: /job:localhost/replica:0/task:0/gpu:0\nVariable_5: /job:localhost/replica:0/task:0/gpu:0\nConst_2: /job:localhost/replica:0/task:0/gpu:0\nVariable_5/Assign: /job:localhost/replica:0/task:0/gpu:0\nVariable_4: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_2/stddev: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_2/mean: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_2/shape: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_2/TruncatedNormal: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_2/mul: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_2: /job:localhost/replica:0/task:0/gpu:0\nVariable_4/Assign: /job:localhost/replica:0/task:0/gpu:0\nVariable_3: /job:localhost/replica:0/task:0/gpu:0\nConst_1: /job:localhost/replica:0/task:0/gpu:0\nVariable_3/Assign: /job:localhost/replica:0/task:0/gpu:0\nVariable_2: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_1/stddev: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_1/mean: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_1/shape: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_1/TruncatedNormal: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_1/mul: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal_1: /job:localhost/replica:0/task:0/gpu:0\nVariable_2/Assign: /job:localhost/replica:0/task:0/gpu:0\nVariable_1: /job:localhost/replica:0/task:0/gpu:0\nConst: /job:localhost/replica:0/task:0/gpu:0\nVariable_1/Assign: /job:localhost/replica:0/task:0/gpu:0\nVariable: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal/stddev: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal/mean: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal/shape: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal/TruncatedNormal: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal/mul: /job:localhost/replica:0/task:0/gpu:0\ntruncated_normal: /job:localhost/replica:0/task:0/gpu:0\nVariable/Assign: /job:localhost/replica:0/task:0/gpu:0\ninit: /job:localhost/replica:0/task:0/gpu:0\n<<<ITER>>> 0\nMomentum/momentum: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_grad/zeros/Const: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_1_grad/zeros/Const: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_2_grad/zeros/Const: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_3_grad/zeros/Const: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_4_grad/zeros/Const: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_5_grad/zeros/Const: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_6_grad/zeros/Const: /job:localhost/replica:0/task:0/gpu:0\ngradients/SoftmaxCrossEntropyWithLogits_grad/ExpandDims/dim: /job:localhost/replica:0/task:0/gpu:0\ngradients/Mean_grad/range_2/delta: /job:localhost/replica:0/task:0/gpu:0\ngradients/Mean_grad/range_2/start: /job:localhost/replica:0/task:0/gpu:0\ngradients/Mean_grad/range_1/delta: /job:localhost/replica:0/task:0/gpu:0\ngradients/Mean_grad/range_1/start: /job:localhost/replica:0/task:0/gpu:0\ngradients/Mean_grad/Fill/value: /job:localhost/replica:0/task:0/gpu:0\ngradients/Mean_grad/range/delta: /job:localhost/replica:0/task:0/gpu:0\ngradients/Mean_grad/range/start: /job:localhost/replica:0/task:0/gpu:0\ngradients/Const: /job:localhost/replica:0/task:0/gpu:0\nrange/delta: /job:localhost/replica:0/task:0/gpu:0\nrange/start: /job:localhost/replica:0/task:0/gpu:0\nVariable_15/read: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_7_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nVariable_14/read: /job:localhost/replica:0/task:0/gpu:0\ndropout_1/random_uniform/max: /job:localhost/replica:0/task:0/gpu:0\ndropout_1/random_uniform/min: /job:localhost/replica:0/task:0/gpu:0\ndropout_1/random_uniform/sub: /job:localhost/replica:0/task:0/gpu:0\ndropout_1/keep_prob: /job:localhost/replica:0/task:0/gpu:0\ndropout_1/Inv: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout_1/mul_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nmul_6/x: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_6_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nVariable_13/read: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_6_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nVariable_12/read: /job:localhost/replica:0/task:0/gpu:0\ndropout/random_uniform/max: /job:localhost/replica:0/task:0/gpu:0\ndropout/random_uniform/min: /job:localhost/replica:0/task:0/gpu:0\ndropout/random_uniform/sub: /job:localhost/replica:0/task:0/gpu:0\ndropout/keep_prob: /job:localhost/replica:0/task:0/gpu:0\ndropout/Inv: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout/mul_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nmul_5/x: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_5_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nVariable_11/read: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_5_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nVariable_10/read: /job:localhost/replica:0/task:0/gpu:0\nReshape/shape: /job:localhost/replica:0/task:0/gpu:0\nmul_4/x: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_4_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nVariable_9/read: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_4_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nVariable_8/read: /job:localhost/replica:0/task:0/gpu:0\ngradients/Conv2D_4_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nmul_3/x: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_3_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nVariable_7/read: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_3_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nVariable_6/read: /job:localhost/replica:0/task:0/gpu:0\ngradients/Conv2D_3_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nmul_2/x: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_2_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nVariable_5/read: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_2_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nVariable_4/read: /job:localhost/replica:0/task:0/gpu:0\ngradients/Conv2D_2_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nmul_1/x: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_1_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nVariable_3/read: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_1_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nVariable_2/read: /job:localhost/replica:0/task:0/gpu:0\ngradients/Conv2D_1_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nmul/x: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nVariable_1/read: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nVariable/read: /job:localhost/replica:0/task:0/gpu:0\ngradients/Conv2D_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Conv2D_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nConv2D: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nadd: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nmul: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_grad/GreaterEqual: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_grad/LogicalNot: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nMaximum: /job:localhost/replica:0/task:0/gpu:0\nMaxPool: /job:localhost/replica:0/task:0/gpu:0\ngradients/Conv2D_1_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nConv2D_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_1_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_1_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nadd_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_1_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_1_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_1_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nmul_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_1_grad/GreaterEqual: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_1_grad/LogicalNot: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_1_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_1_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nMaximum_1: /job:localhost/replica:0/task:0/gpu:0\nMaxPool_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Conv2D_2_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nConv2D_2: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_2_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_2_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nadd_2: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_2_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_2_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_2_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nmul_2: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_2_grad/GreaterEqual: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_2_grad/LogicalNot: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_2_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_2_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nMaximum_2: /job:localhost/replica:0/task:0/gpu:0\nMaxPool_2: /job:localhost/replica:0/task:0/gpu:0\ngradients/Conv2D_3_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nConv2D_3: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_3_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_3_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nadd_3: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_3_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_3_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_3_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nmul_3: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_3_grad/GreaterEqual: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_3_grad/LogicalNot: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_3_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_3_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nMaximum_3: /job:localhost/replica:0/task:0/gpu:0\nMaxPool_3: /job:localhost/replica:0/task:0/gpu:0\ngradients/Conv2D_4_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nConv2D_4: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_4_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_4_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nadd_4: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_4_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_4_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_4_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nmul_4: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_4_grad/GreaterEqual: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_4_grad/LogicalNot: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_4_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_4_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nMaximum_4: /job:localhost/replica:0/task:0/gpu:0\nMaxPool_4: /job:localhost/replica:0/task:0/gpu:0\ngradients/Reshape_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nReshape: /job:localhost/replica:0/task:0/gpu:0\nMatMul: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_5_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_5_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nadd_5: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_5_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_5_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_5_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nmul_5: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_5_grad/GreaterEqual: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_5_grad/LogicalNot: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_5_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_5_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nMaximum_5: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout/mul_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout/mul_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\ndropout/mul: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout/mul_1_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\ndropout/Shape: /job:localhost/replica:0/task:0/gpu:0\ndropout/random_uniform/RandomUniform: /job:localhost/replica:0/task:0/gpu:0\ndropout/random_uniform/mul: /job:localhost/replica:0/task:0/gpu:0\ndropout/random_uniform: /job:localhost/replica:0/task:0/gpu:0\ndropout/add: /job:localhost/replica:0/task:0/gpu:0\ndropout/Floor: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout/mul_1_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout/mul_1_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\ndropout/mul_1: /job:localhost/replica:0/task:0/gpu:0\nMatMul_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_6_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_6_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nadd_6: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_6_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_6_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_6_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\nmul_6: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_6_grad/GreaterEqual: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_6_grad/LogicalNot: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_6_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_6_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nMaximum_6: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout_1/mul_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout_1/mul_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\ndropout_1/mul: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout_1/mul_1_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\ndropout_1/Shape: /job:localhost/replica:0/task:0/gpu:0\ndropout_1/random_uniform/RandomUniform: /job:localhost/replica:0/task:0/gpu:0\ndropout_1/random_uniform/mul: /job:localhost/replica:0/task:0/gpu:0\ndropout_1/random_uniform: /job:localhost/replica:0/task:0/gpu:0\ndropout_1/add: /job:localhost/replica:0/task:0/gpu:0\ndropout_1/Floor: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout_1/mul_1_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout_1/mul_1_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\ndropout_1/mul_1: /job:localhost/replica:0/task:0/gpu:0\nMatMul_2: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_7_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_7_grad/BroadcastGradientArgs: /job:localhost/replica:0/task:0/gpu:0\nadd_7: /job:localhost/replica:0/task:0/gpu:0\nSoftmaxCrossEntropyWithLogits: /job:localhost/replica:0/task:0/gpu:0\ngradients/Mean_grad/Shape_2: /job:localhost/replica:0/task:0/gpu:0\ngradients/Mean_grad/Rank_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Mean_grad/range_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Mean_grad/Prod: /job:localhost/replica:0/task:0/cpu:0\ngradients/Mean_grad/Rank: /job:localhost/replica:0/task:0/gpu:0\ngradients/Mean_grad/range: /job:localhost/replica:0/task:0/gpu:0\ngradients/Mean_grad/Shape: /job:localhost/replica:0/task:0/gpu:0\nRank: /job:localhost/replica:0/task:0/gpu:0\nrange: /job:localhost/replica:0/task:0/gpu:0\ngradients/Mean_grad/Shape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Mean_grad/Fill: /job:localhost/replica:0/task:0/gpu:0\ngradients/Mean_grad/DynamicStitch: /job:localhost/replica:0/task:0/gpu:0\ngradients/Mean_grad/floordiv: /job:localhost/replica:0/task:0/gpu:0\nMean: /job:localhost/replica:0/task:0/cpu:0\ngradients/Mean_grad/Shape_3: /job:localhost/replica:0/task:0/gpu:0\ngradients/Mean_grad/Rank_2: /job:localhost/replica:0/task:0/gpu:0\ngradients/Mean_grad/range_2: /job:localhost/replica:0/task:0/gpu:0\ngradients/Mean_grad/Prod_1: /job:localhost/replica:0/task:0/cpu:0\ngradients/Mean_grad/floordiv_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Mean_grad/Cast: /job:localhost/replica:0/task:0/gpu:0\ngradients/Shape: /job:localhost/replica:0/task:0/gpu:0\ngradients/Fill: /job:localhost/replica:0/task:0/gpu:0\ngradients/Mean_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\ngradients/Mean_grad/Tile: /job:localhost/replica:0/task:0/gpu:0\ngradients/Mean_grad/truediv: /job:localhost/replica:0/task:0/gpu:0\ngradients/Mean_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/Mean_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ngradients/SoftmaxCrossEntropyWithLogits_grad/ExpandDims: /job:localhost/replica:0/task:0/gpu:0\ngradients/SoftmaxCrossEntropyWithLogits_grad/mul: /job:localhost/replica:0/task:0/gpu:0\ngradients/SoftmaxCrossEntropyWithLogits_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/SoftmaxCrossEntropyWithLogits_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_7_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_7_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_7_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_7_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_7_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_7_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nMomentum/update_Variable_15/ApplyMomentum: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_7_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ngradients/MatMul_2_grad/MatMul_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/MatMul_2_grad/MatMul: /job:localhost/replica:0/task:0/gpu:0\ngradients/MatMul_2_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/MatMul_2_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nMomentum/update_Variable_14/ApplyMomentum: /job:localhost/replica:0/task:0/gpu:0\ngradients/MatMul_2_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout_1/mul_1_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout_1/mul_1_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout_1/mul_1_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout_1/mul_1_grad/mul: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout_1/mul_1_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout_1/mul_1_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout_1/mul_1_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout_1/mul_1_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout_1/mul_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout_1/mul_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout_1/mul_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout_1/mul_grad/mul: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout_1/mul_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout_1/mul_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout_1/mul_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout_1/mul_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_6_grad/Shape_2: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_6_grad/zeros: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_6_grad/Select_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_6_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_6_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_6_grad/Select: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_6_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_6_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_6_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_6_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_6_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_6_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_6_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_6_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_6_grad/mul: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_6_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_6_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_6_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_6_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/AddN: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_6_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_6_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_6_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_6_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_6_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_6_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nMomentum/update_Variable_13/ApplyMomentum: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_6_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ngradients/MatMul_1_grad/MatMul_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/MatMul_1_grad/MatMul: /job:localhost/replica:0/task:0/gpu:0\ngradients/MatMul_1_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/MatMul_1_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nMomentum/update_Variable_12/ApplyMomentum: /job:localhost/replica:0/task:0/gpu:0\ngradients/MatMul_1_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout/mul_1_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout/mul_1_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout/mul_1_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout/mul_1_grad/mul: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout/mul_1_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout/mul_1_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout/mul_1_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout/mul_1_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout/mul_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout/mul_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout/mul_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout/mul_grad/mul: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout/mul_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout/mul_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout/mul_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/dropout/mul_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_5_grad/Shape_2: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_5_grad/zeros: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_5_grad/Select_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_5_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_5_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_5_grad/Select: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_5_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_5_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_5_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_5_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_5_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_5_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_5_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_5_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_5_grad/mul: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_5_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_5_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_5_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_5_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/AddN_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_5_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_5_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_5_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_5_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_5_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_5_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nMomentum/update_Variable_11/ApplyMomentum: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_5_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ngradients/MatMul_grad/MatMul_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/MatMul_grad/MatMul: /job:localhost/replica:0/task:0/gpu:0\ngradients/MatMul_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/MatMul_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nMomentum/update_Variable_10/ApplyMomentum: /job:localhost/replica:0/task:0/gpu:0\ngradients/MatMul_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ngradients/Reshape_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\ngradients/Reshape_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/Reshape_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ngradients/MaxPool_4_grad/MaxPoolGrad: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_4_grad/Shape_2: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_4_grad/zeros: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_4_grad/Select_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_4_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_4_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_4_grad/Select: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_4_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_4_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_4_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_4_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_4_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_4_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_4_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_4_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_4_grad/mul: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_4_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_4_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_4_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_4_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/AddN_2: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_4_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_4_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_4_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_4_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_4_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_4_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nMomentum/update_Variable_9/ApplyMomentum: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_4_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ngradients/Conv2D_4_grad/Conv2DBackpropFilter: /job:localhost/replica:0/task:0/gpu:0\ngradients/Conv2D_4_grad/Conv2DBackpropInput: /job:localhost/replica:0/task:0/gpu:0\ngradients/Conv2D_4_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/Conv2D_4_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nMomentum/update_Variable_8/ApplyMomentum: /job:localhost/replica:0/task:0/gpu:0\ngradients/Conv2D_4_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ngradients/MaxPool_3_grad/MaxPoolGrad: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_3_grad/Shape_2: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_3_grad/zeros: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_3_grad/Select_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_3_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_3_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_3_grad/Select: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_3_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_3_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_3_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_3_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_3_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_3_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_3_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_3_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_3_grad/mul: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_3_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_3_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_3_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_3_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/AddN_3: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_3_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_3_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_3_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_3_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_3_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_3_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nMomentum/update_Variable_7/ApplyMomentum: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_3_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ngradients/Conv2D_3_grad/Conv2DBackpropFilter: /job:localhost/replica:0/task:0/gpu:0\ngradients/Conv2D_3_grad/Conv2DBackpropInput: /job:localhost/replica:0/task:0/gpu:0\ngradients/Conv2D_3_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/Conv2D_3_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nMomentum/update_Variable_6/ApplyMomentum: /job:localhost/replica:0/task:0/gpu:0\ngradients/Conv2D_3_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ngradients/MaxPool_2_grad/MaxPoolGrad: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_2_grad/Shape_2: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_2_grad/zeros: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_2_grad/Select_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_2_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_2_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_2_grad/Select: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_2_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_2_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_2_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_2_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_2_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_2_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_2_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_2_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_2_grad/mul: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_2_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_2_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_2_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_2_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/AddN_4: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_2_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_2_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_2_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_2_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_2_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_2_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nMomentum/update_Variable_5/ApplyMomentum: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_2_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ngradients/Conv2D_2_grad/Conv2DBackpropFilter: /job:localhost/replica:0/task:0/gpu:0\ngradients/Conv2D_2_grad/Conv2DBackpropInput: /job:localhost/replica:0/task:0/gpu:0\ngradients/Conv2D_2_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/Conv2D_2_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nMomentum/update_Variable_4/ApplyMomentum: /job:localhost/replica:0/task:0/gpu:0\ngradients/Conv2D_2_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ngradients/MaxPool_1_grad/MaxPoolGrad: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_1_grad/Shape_2: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_1_grad/zeros: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_1_grad/Select_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_1_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_1_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_1_grad/Select: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_1_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_1_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_1_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_1_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_1_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_1_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_1_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_1_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_1_grad/mul: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_1_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_1_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_1_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_1_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/AddN_5: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_1_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_1_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_1_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_1_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_1_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_1_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nMomentum/update_Variable_3/ApplyMomentum: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_1_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ngradients/Conv2D_1_grad/Conv2DBackpropFilter: /job:localhost/replica:0/task:0/gpu:0\ngradients/Conv2D_1_grad/Conv2DBackpropInput: /job:localhost/replica:0/task:0/gpu:0\ngradients/Conv2D_1_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/Conv2D_1_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nMomentum/update_Variable_2/ApplyMomentum: /job:localhost/replica:0/task:0/gpu:0\ngradients/Conv2D_1_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ngradients/MaxPool_grad/MaxPoolGrad: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_grad/Shape_2: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_grad/zeros: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_grad/Select_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_grad/Select: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/Maximum_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_grad/mul_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_grad/mul: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/mul_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/AddN_6: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_grad/Sum_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_grad/Reshape_1: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_grad/Sum: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_grad/Reshape: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nMomentum/update_Variable_1/ApplyMomentum: /job:localhost/replica:0/task:0/gpu:0\ngradients/add_grad/tuple/control_dependency: /job:localhost/replica:0/task:0/gpu:0\ngradients/Conv2D_grad/Conv2DBackpropFilter: /job:localhost/replica:0/task:0/gpu:0\ngradients/Conv2D_grad/Conv2DBackpropInput: /job:localhost/replica:0/task:0/gpu:0\ngradients/Conv2D_grad/tuple/group_deps: /job:localhost/replica:0/task:0/gpu:0\ngradients/Conv2D_grad/tuple/control_dependency_1: /job:localhost/replica:0/task:0/gpu:0\nMomentum/update_Variable/ApplyMomentum: /job:localhost/replica:0/task:0/gpu:0\nMomentum: /job:localhost/replica:0/task:0/gpu:0\n</blockquote>\n", "Going to de-dupe with the more general 'memory issue' here: https://github.com/tensorflow/tensorflow/issues/492 since I think there's a lot of stuff we need to improve.\n", "A blast from the future: don't forget to make sure you don't have a job ctl-Z'd and using all the memory.", "fixed this probleb by setting the batchsize as the power of 2 such as  32  64 128  256  512  1024", "Similar problem I had to assign 16 to the batch size. \r\nDoes the h5 file generation has to do something with this issue. Maybe using some compression options within create_dataset method would fixe the problem (didn't try it yet):\r\nex: h5_fout.create_dataset( 'data', data=data,compression='gzip', compression_opts=4,       dtype=data_dtype)", "I encountered this problem for inference.\r\nWhen using tf with jetson nano for inference on different sized models (VGG 16/19/resnet50), an OOM accures with the bfc_alllocator warnning repeats until memory is freed.\r\nWhen using the config option \"allow growth\". the OOM disappears but inference is done on any image with the bfc allocator warnings appear at first and continues till the model is loaded. \r\nHow can I avoid these warnings and use just the right amount of memory needed for tf?, \r\n\r\nknowing that I used per process gpu memory fraction at different values and each one allocates different memory spaces (proportionnaly increasing) but the actual memory used by the model stays the same(Using memory stats (MaxByteInUse and BytesInUse ))."]}, {"number": 397, "title": "Add auc calculation operator ?", "body": "Any plans for adding this ?  Like in sklearn   roc_auc_score(teY, predicts)\n", "comments": ["Is it that hard to add AUC calc and optimize by hand, I wonder?\nIn my opinion, making a continuous approximation of the AUC function will just do.\n\nWhen I was using Theano, I tried to add the AUC loss with something related to some Mann Whitney Kernel, but I haven't tried that using TF yet. \n", "@zhangchen-qinyinghua  Yes, seems for tensorflow it is very convenient to implement user_op of this kind, closing this issue.\n", "`AUC` is commonly used in LR or DNN models and I don't think everyone need to implement the user op again.\n\nNow TF learn has implemented the `streaming_auc` in `tensorflow/tensorflow/contrib/metrics/python/ops/metric_ops.py`. We will test and hope it could be used out of the scope of TF learn API.\n", "The auc for binary is implemented, but for multi-label isn't. I am doing a multi-label classification task and need to compute the acpr, but no method to slove it ."]}]