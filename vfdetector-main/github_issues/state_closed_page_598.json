[{"number": 35732, "title": "A strange numerical computation bug for the simple dense layer", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS 10.14.5\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.1.0\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory:  N/A\r\n\r\n**Describe the current behavior**\r\n\r\nSee the code:\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nm = 3\r\nn = 3\r\nx = tf.cast(np.random.randn(1, m, 32), tf.float32)\r\nz = tf.tile(x, [n, 1, 1])\r\n\r\nlayer = tf.keras.layers.Dense(32)\r\nw = layer(z)\r\n\r\ntf.print(tf.norm(z[0, :, :] - z[1, :, :]), tf.norm(z[1, :, :] - z[n-1, :, :]))\r\ntf.print(tf.norm(w[0, :, :] - w[1, :, :]), tf.norm(w[1, :, :] - w[n-1, :, :]))\r\n```\r\nIn the code we replicate the input `x` 3 times and apply a dense layer upon it. We expect to get the same results for the 3 replicates. In fact the 1st and 2nd results are indeed same, while the 3rd result is different. Here is the results of the script above:\r\n\r\n```\r\n0 0\r\n0 1.0617149e-06 # this error is not fixed for each run\r\n```\r\nwhere we expect all results to be 0.\r\n\r\nStrangely enough, this bug only appears for some `(m,n)` pairs (in the example above `m=n=3`). I ran the code for all `m` and `n` from 1 to 100 and found that there are ~40% combinations that will cause a bug, but I didn't find any obvious pattern...", "comments": ["Was able to reproduce the issue. Please find the Gist [here](https://colab.sandbox.google.com/gist/amahendrakar/88a98b7c3174e2385686af597ae1c8ca/35732.ipynb). Thanks!", "@David-Mao \r\nCan you please try with `!pip install tf-nightly` version. I am not seeing any issue in nightly version.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/7d8c3704f0b378a3f95509587f4064ea/untitled608.ipynb).Thanks!", "@ravikyram I tried with '2.2.0-dev20200208' version, and the bug shows again. Now the result is \r\n<img width=\"749\" alt=\"image\" src=\"https://user-images.githubusercontent.com/12476624/74125470-7d16e580-4b79-11ea-9cc0-ecfa01fe07ac.png\">\r\n\r\n", "Ping. This bug has still not been fixed in the most recent nightly build.\r\n\r\n", "Gentle bump.\r\n\r\nI noticed that for the latest nightly version, this bug has disappeared in Linux version. However, for the Mac version (I'm using Mac OS 10.14.5 with Python 3.7, the file is `tf_nightly-2.3.0.dev20200617-cp37-cp37m-macosx_10_9_x86_64.whl`), the bug still persists.\r\n\r\n", "I have tried in TF nightly version (`2.5.0-dev20201029`) and was able to reproduce the issue. Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/5e03737641cca4a4ff20e39abf25b4a7/untitled97.ipynb?authuser=1).Thanks!", "Ping. This is a computation bug and it has been a year. Is there any progress? Thanks", "Was able to reproduce your issue, please find the gist [here](https://colab.research.google.com/gist/sachinprasadhs/a52280b0b292bb071ea4be33de0e9625/35650.ipynb). Thank you.", "Issue still persists in `2.6.0` and also on nightly `2.8.0-dev20211020`. Please take a look at the [gist here](https://colab.research.google.com/gist/sanatmpa1/c4b3824c9e86cfc72a075c130dd1b0fa/35650.ipynb)", "Hi There,\n\n This is a stale issue. As you are using an older version of tensorflow, we are checking to see if you still need help on this issue. Please test the issue with the latest TensorFlow (TF2.7 and tf-nightly). If the issue still persists with the newer versions of TF, please feel free to open it in [keras-team/keras](https://github.com/keras-team/keras/issues) repository by providing details about the issue and a standalone code to reproduce the issue. Thanks! \n\n Please note that Keras development has moved to a separate Keras-team/keras repository to focus entirely on only Keras. Thanks! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35732\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35732\">No</a>\n"]}, {"number": 35731, "title": "RuntimeError when saving Keras model with stacked RNN cells in HDF5 format", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS Mojave 10.14.6\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de410 2.1.0\r\n- Python version: 3.7.4\r\n\r\n**Describe the current behavior**\r\nWhen I try to save a Keras model in HDF5 format with `model.save()`, if a model includes RNN layer with stacked cells, a `RuntimeError` occurs because of non-unique trainable weight `tf.Variable` names.\r\n\r\n**Describe the expected behavior**\r\nI should be able to save Keras model to HDF5 file without issues.\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\n\r\nX = tf.keras.Input([10, 91], name=\"train_input\")\r\nrnn_layers = [\r\n    tf.keras.layers.LSTMCell(size, recurrent_dropout=0, name=\"rnn_cell%d\" % i)\r\n    for i, size in enumerate([512, 512])\r\n]\r\nrnn_output = tf.keras.layers.RNN(rnn_layers, return_sequences=True, name=\"rnn_layer\")(X)\r\npred_feat = tf.keras.layers.Dense(91, name=\"prediction_features\")(rnn_output)\r\npred = tf.keras.layers.Softmax()(pred_feat)\r\nmodel = tf.keras.Model(inputs=[X], outputs=[pred, pred_feat])\r\nmodel.save(\"test.h5\")\r\n```\r\n\r\n**Other info / logs**\r\nTraceback:\r\n```\r\n  File \"/Users/dimitrijer/git/mlai/footpy/footpy/train_keras.py\", line 41, in train\r\n    model.save()\r\n  File \"/Users/dimitrijer/git/mlai/footpy/footpy/model_keras.py\", line 246, in save\r\n    self.model.save(os.path.join(model_path, filename), overwrite=True)\r\n  File \"/Users/dimitrijer/.pyenv/versions/footpy/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\", line 1035, in save\r\n    signatures, options)\r\n  File \"/Users/dimitrijer/.pyenv/versions/footpy/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py\", line 118, in save_model\r\n    model, filepath, overwrite, include_optimizer)\r\n  File \"/Users/dimitrijer/.pyenv/versions/footpy/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\", line 109, in save_model_to_hdf5\r\n    save_weights_to_hdf5_group(model_weights_group, model_layers)\r\n  File \"/Users/dimitrijer/.pyenv/versions/footpy/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\", line 631, in save_weights_to_hdf5_group\r\n    param_dset = g.create_dataset(name, val.shape, dtype=val.dtype)\r\n  File \"/Users/dimitrijer/.pyenv/versions/footpy/lib/python3.7/site-packages/h5py/_hl/group.py\", line 139, in create_dataset\r\n    self[name] = dset\r\n  File \"/Users/dimitrijer/.pyenv/versions/footpy/lib/python3.7/site-packages/h5py/_hl/group.py\", line 373, in __setitem__\r\n    h5o.link(obj.id, self.id, name, lcpl=lcpl, lapl=self._lapl)\r\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\r\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\r\n  File \"h5py/h5o.pyx\", line 202, in h5py.h5o.link\r\nRuntimeError: Unable to create link (name already exists)\r\n```\r\nThis occurs because there is a repeating set of TF variables for each RNN cell:\r\n- `<tf.Variable 'rnn_layer/kernel:0'...>`\r\n- `<tf.Variable 'rnn_layer/recurrent_kernel:0'...>`\r\n- `<tf.Variable 'rnn_layer/bias:0'...>`\r\n\r\nThese three variables have the same name across stacked RNN cells.\u00a0This causes conflict when HDF5 model is saved - when a group is formed for RNN layer, list at `hdf5_format.py:628` contains triplets with repeating names, which causes the error when dataset is created for each weight at line 635.", "comments": ["Was able to reproduce the issue. Please find the Gist [here](https://colab.sandbox.google.com/gist/amahendrakar/90b21c7f45eeba9c81a6bf36b6b9a3ca/35731.ipynb). Thanks!", "I am able to reproduce the issue with 'save_format = h5' but `save_format = 'tf'` is working as expected. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35731\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35731\">No</a>\n"]}, {"number": 35730, "title": "micro: Fix typo in missing op code error message", "body": "From '% d' to '%d' to correct message", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F35730) for more info**.\n\n<!-- need_sender_cla -->"]}, {"number": 35729, "title": "tensorflow.python.framework.errors_impl.InvalidArgumentError: indices = -1 is not in [0, 4) [Op:GatherV2]", "body": "I am getting InvalidArgumentError while running below code:\r\n\r\n![Code](https://user-images.githubusercontent.com/59674741/72132628-b47a5280-337f-11ea-9dfb-f60609156f4f.jpeg)\r\n\r\n### System information\r\n- **OS Platform:Ubuntu 18.04\r\n- **TensorFlow version: v2.0.0-rc2-26-g64c3d38 and tensorflow2.0.0\r\n- **Python version**: Python 3.7.4\r\n\r\nThis code is failing while running for first epoch. It has to run for 400 steps in first epoch but getting failed at 256, 300 or sometimes any no of iteration.\r\nBelow is the error i am getting:\r\n256/400 [==================>...........] - ETA: 3:40 - loss: 0.6932 - accuracy: 0.4968Traceback (most recent call last):\r\n  File \"train_model_latest.py\", line 196, in <module>\r\n    train_model()\r\n  File \"train_model_latest.py\", line 168, in train_model\r\n    callbacks=callbacks)\r\n  File \"/u/s/shalinis/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 1297, in fit_generator\r\n    steps_name='steps_per_epoch')\r\n  File \"/u/s/shalinis/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_generator.py\", line 265, in model_iteration\r\n    batch_outs = batch_function(*batch_data)\r\n  File \"/u/s/shalinis/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 973, in train_on_batch\r\n    class_weight=class_weight, reset_metrics=reset_metrics)\r\n  File \"/u/s/shalinis/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\", line 264, in train_on_batch\r\n    output_loss_metrics=model._output_loss_metrics)\r\n  File \"/u/s/shalinis/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\", line 311, in train_on_batch\r\n    output_loss_metrics=output_loss_metrics))\r\n  File \"/u/s/shalinis/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\", line 252, in _process_single_batch\r\n    training=training))\r\n  File \"/u/s/shalinis/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_eager.py\", line 127, in _model_loss\r\n    outs = model(inputs, **kwargs)\r\n  File \"/u/s/shalinis/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 891, in __call__\r\n    outputs = self.call(cast_inputs, *args, **kwargs)\r\n  File \"/u/s/shalinis/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/sequential.py\", line 256, in call\r\n    return super(Sequential, self).call(inputs, training=training, mask=mask)\r\n  File \"/u/s/shalinis/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\", line 708, in call\r\n    convert_kwargs_to_constants=base_layer_utils.call_context().saving)\r\n  File \"/u/s/shalinis/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\", line 860, in _run_internal_graph\r\n    output_tensors = layer(computed_tensors, **kwargs)\r\n  File \"/u/s/shalinis/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 891, in __call__\r\n    outputs = self.call(cast_inputs, *args, **kwargs)\r\n  File \"/u/s/shalinis/.local/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py\", line 233, in call\r\n    update_op = tf_utils.smart_cond(training, add_update, no_op)\r\n  File \"/u/s/shalinis/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/tf_utils.py\", line 59, in smart_cond\r\n    pred, true_fn=true_fn, false_fn=false_fn, name=name)\r\n  File \"/u/s/shalinis/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/smart_cond.py\", line 54, in smart_cond\r\n    return true_fn()\r\n  File \"/u/s/shalinis/.local/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py\", line 227, in add_update\r\n    [self.pruning_obj.conditional_mask_update()]):\r\n  File \"/u/s/shalinis/.local/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_impl.py\", line 245, in conditional_mask_update\r\n    mask_update_distributed)\r\n  File \"/u/s/shalinis/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 1917, in merge_call\r\n    return self._merge_call(merge_fn, args, kwargs)\r\n  File \"/u/s/shalinis/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 1924, in _merge_call\r\n    return merge_fn(self._strategy, *args, **kwargs)\r\n  File \"/u/s/shalinis/.local/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_impl.py\", line 241, in mask_update_distributed\r\n    no_update)\r\n  File \"/u/s/shalinis/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/u/s/shalinis/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/control_flow_ops.py\", line 1202, in cond\r\n    result = true_fn()\r\n  File \"/u/s/shalinis/.local/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_impl.py\", line 232, in update_distributed\r\n    new_threshold, new_mask = self._maybe_update_block_mask(weight)\r\n  File \"/u/s/shalinis/.local/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_impl.py\", line 128, in _maybe_update_block_mask\r\n    return self._update_mask(weights)\r\n  File \"/u/s/shalinis/.local/lib/python3.7/site-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_impl.py\", line 102, in _update_mask\r\n    current_threshold = array_ops.gather(values, k - 1)\r\n  File \"/u/s/shalinis/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py\", line 180, in wrapper\r\n    return target(*args, **kwargs)\r\n  File \"/u/s/shalinis/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\", line 3967, in gather\r\n    return gen_array_ops.gather_v2(params, indices, axis, name=name)\r\n  File \"/u/s/shalinis/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py\", line 4075, in gather_v2\r\n    _six.raise_from(_core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: indices = -1 is not in [0, 4) [Op:GatherV2]\r\n", "comments": ["@tomshalini,\r\nIn order to expedite the trouble-shooting process, could you please copy the complete code and paste it here (instead of the screenshot), so that it would be easy for us to reproduce it. Also, can you provide the saved model (Model_9Jan11AM.h5) you are using in your code. Thanks!", "Please find below code for your reference:\r\n\r\nfrom os import path, makedirs\r\nfrom utility_files import model_utils\r\nimport local_configuration as config\r\nfrom utility_files import tfrecords_utils as tfutils\r\nimport numpy as np\r\nimport tempfile\r\nimport zipfile\r\nimport os\r\nfrom tensorflow_model_optimization.sparsity import keras as sparsity\r\nfrom tensorflow import keras\r\n\r\n'''\r\nThis file prunes the pre-trained model and save the pruned model to the location specified in the configuration file and \r\nvalidates the model on the complete validation data set.\r\nPlease set the pretrained model name along with its path to the variable - \"keras_file\" .\r\n'''\r\n\r\n################################ Hyper parameters of the model #################################\r\n\r\nsequence_length = 60000                      # Number of samples per channel. A predetermined number.\r\ntraining_examples = 12800                       # Number of files to be used for training. Maximum allowed number is the combined number in Sinus and AF folder\r\nvalidation_examples = 3200                     # Number of files to be used for testing. Maximum allowed number is the combined number in Sinus and AF testing folder\r\nbatch_size = 32                              # Batch size for training and testing\r\nbatch_size_to_write_or_read_value = 2 * (1600)  # Number of examples to read from TF record for \"tests\" for final evaluation. (Max = validation_examples = 2 * (validation_examples/2))\r\nlr = 1e-4                                    # Learning rate for the model\r\ndecay = 1e-3                                 # Decay rate for the model\r\nnumber_of_channels = 2                       # Number of channels\r\n\r\ndef prune_model():\r\n\r\n    tf_record_train = config.tf_record_file_base_path + \"ecg_data_tf_CNN_float_60000.tfrecord\"\r\n    tf_record_test = config.tf_record_file_base_path + \"ecg_data_tf_CNN_test_float_60000.tfrecord\"\r\n    tf_reader_train = tfutils.TFrecords(tf_record_train)                        # tfutils instance for training\r\n    tf_reader_test = tfutils.TFrecords(tf_record_test)                          # tfutils instance for testing\r\n    opt = keras.optimizers.Adam(lr=lr, decay=decay)\r\n\r\n    validation_steps = int(validation_examples // batch_size)\r\n    steps_per_epoch = int(training_examples // batch_size)\r\n\r\n    keras_file = \"/u/s/shalinis/PycharmProjects/half/Model_26_Nov_10AM_lr_0_0001_decay_0_001_sparse_dense_layers_epoch_15.h5\"   #Path of Pre-trained model.\r\n    model = keras.models.load_model(keras_file)\r\n    print('Original Model Summary:')\r\n    model.summary()\r\n\r\n    end_step = np.ceil(1.0 * training_examples / batch_size).astype(np.int32) * 2\r\n    pruning_params = {\r\n        'pruning_schedule': sparsity.PolynomialDecay(initial_sparsity=0.50,\r\n                                                     final_sparsity=0.90,\r\n                                                     begin_step=0,\r\n                                                     end_step=end_step,\r\n                                                     frequency=100)\r\n    }\r\n    model = sparsity.prune_low_magnitude(model, **pruning_params)\r\n    model.compile(optimizer=opt,  # Compile the model\r\n                  loss='binary_crossentropy',\r\n                  metrics=['accuracy'])\r\n    model.summary()\r\n    logdir = \"/m/scratch/hive/shalini/logs/\"\r\n    print('Writing training logs to ' + logdir)\r\n    callbacks = [\r\n        sparsity.UpdatePruningStep(),\r\n        sparsity.PruningSummaries(log_dir=logdir)\r\n    ]\r\n    model.fit_generator(\r\n        model_utils._data_generator(tf_reader_train, batch_size=batch_size, sequence_length=sequence_length),\r\n        validation_data=model_utils._data_generator(tf_reader_test, batch_size=batch_size,\r\n                                                    sequence_length=sequence_length),\r\n        validation_steps=validation_steps,\r\n        steps_per_epoch=steps_per_epoch,\r\n        epochs=2, verbose=1, shuffle=str,\r\n        callbacks=callbacks,\r\n        use_multiprocessing=False, workers=0)\r\n\r\n    model_utils.final_model_validation(model, tf_record_test, batch_size_to_write_or_read_value)\r\n    pruned_keras_file = \"/m/scratch/hive/shalini/Model CheckPoints/SparPrunedModel_10Jan1730PM.h5\"\r\n    print('Saving model to: ', pruned_keras_file)\r\n    keras.models.save_model(model, pruned_keras_file,\r\n                            include_optimizer=False)\r\n\r\n    final_model = sparsity.strip_pruning(model)\r\n    final_model.summary()\r\n    Finalpruned_keras_file = \"/m/scratch/hive/shalini/Model CheckPoints/FinPrunedModel_10Jan1730PM.h5\"\r\n    print('Saving model to: ', Finalpruned_keras_file)\r\n    keras.models.save_model(model, Finalpruned_keras_file,\r\n                            include_optimizer=False)\r\n\r\n\r\n\r\n\r\n    _, zip3 = tempfile.mkstemp('.zip')\r\n    with zipfile.ZipFile(zip3, 'w', compression=zipfile.ZIP_DEFLATED) as f:\r\n        f.write(keras_file)\r\n    print(\"Size of the original model before compression: %.2f Mb\"\r\n          % (os.path.getsize(keras_file) / float(2 ** 20)))\r\n    print(\"Size of the original model after compression: %.2f Mb\"\r\n          % (os.path.getsize(zip3) / float(2 ** 20)))\r\n\r\n    _, zip3 = tempfile.mkstemp('.zip')\r\n    with zipfile.ZipFile(zip3, 'w', compression=zipfile.ZIP_DEFLATED) as f:\r\n        f.write(Finalpruned_keras_file)\r\n    print(\"Size of the pruned model before compression: %.2f Mb\"\r\n          % (os.path.getsize(Finalpruned_keras_file) / float(2 ** 20)))\r\n    print(\"Size of the pruned model after compression: %.2f Mb\"\r\n          % (os.path.getsize(zip3) / float(2 ** 20)))\r\n\r\nif __name__ == \"__main__\":\r\n    prune_model()\r\n\r\n--------------------------------------------------------------------------------------------\r\nAttached is the pretrained model. Please unzip this file first before using.\r\n\r\n[Model_26_Nov_10AM_lr_0_0001_decay_0_001_sparse_dense_layers_epoch_15.h5.tar.gz](https://github.com/tensorflow/tensorflow/files/4047358/Model_26_Nov_10AM_lr_0_0001_decay_0_001_sparse_dense_layers_epoch_15.h5.tar.gz)\r\n\r\n", "@tomshalini,\r\nSeems like you are importing user-defined/custom modules and config files in your code, hence I am facing [an error](https://colab.sandbox.google.com/gist/amahendrakar/5bc10431993d2cfd40774de21cd8fcd1/35729.ipynb) while reproducing the issue.\r\n\r\nI'd suggest you to use [this](https://colab.sandbox.google.com/notebook#create=true&language=python3) link to run the code and share the Gist (File -> Save a copy as Github gist) with us. Thanks!", "Any updates regarding this issue? Thanks!", "Could you please tell me reason of increasing model's parameter by prunning wrapper? ", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\nThanks!\r\n"]}, {"number": 35728, "title": "Wrong Window Size while training the model", "body": "## URL(s) with the issue:\r\n\r\nhttps://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l08c05_forecasting_with_machine_learning.ipynb\r\n\r\n## Description of issue (what needs changing):\r\n\r\nWindow size should be 30 instead of 20 in the description under \"Forecasting With Machine Learning\".\r\n\r\n### Clear description\r\n\r\n![Screenshot from 2020-01-10 12-05-13](https://user-images.githubusercontent.com/29497701/72131252-b1905980-33a1-11ea-8cf5-11d089d5316e.png)\r\n\r\n--------------------\r\nAs we can see under \"Linear Model\", `window_size=30` while in description it is mentioned as model forecasts, given previous 20 steps.\r\n\r\n### Submit a pull request?\r\n\r\nYes...", "comments": ["This is already resolved. In the updated docs, the window size is mentioned correctly. Please check [here](https://github.com/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l08c05_forecasting_with_machine_learning.ipynb).\r\n\r\n> First, we will train a model to forecast the next step given the previous 30 steps, therefore, we need to create a dataset of 30-step windows for training.\r\n\r\nI am closing this issue as this was already resolved. Thanks!"]}, {"number": 35727, "title": "GOOGLE CODE IN 2019 : TASK \"Add a usage example to TensorFlow 2.0 API documentation. \"", "body": "", "comments": ["Check out this pull request on&nbsp; <a href=\"https://app.reviewnb.com/tensorflow/tensorflow/pull/35727\"><img align=\"absmiddle\"  alt=\"ReviewNB\" height=\"28\" class=\"BotMessageButtonImage\" src=\"https://raw.githubusercontent.com/ReviewNB/support/master/images/button_reviewnb.png\"/></a> \n\n You'll be able to see Jupyter notebook diff and discuss changes. Powered by <a href='https://www.reviewnb.com'>ReviewNB</a>.", "Hello, good work. Apparently, this example uses Tensorflow 1.0, not 2.0. It's nice to see another code-in participant, good luck on this task btw!\r\n\r\nJuanC", "Thanks for your appreciation, I love to contribute here. Let's see what can be done next. The mentors are very helpful by giving us many suggestions. ", "https://colab.research.google.com/drive/1a8B3_w_u70c1WyI4vO4gWN1hBtQpKyKL\r\nin Tf 2.0", "Hi! Unfortunately you can't add Google Colab notebooks as usage examples, you need to make it a doctest as seen [here ](https://www.tensorflow.org/community/contribute/docs_ref#testable_docstrings). Also please make sure to make the changes in the correct file.", "Hi , i have added the doctest ", "Sorry, this is not how the doctests should be. You can take a look at @msteknoadam's examples here #35388"]}, {"number": 35726, "title": "ERROR:root:Internal Python error in the inspect module.", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-5-df9a78134369>\", line 1, in <module>\r\n    from keras.models import Model\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\r\n    from . import utils\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\r\n    from . import conv_utils\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\r\n    from .. import backend as K\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\r\n    from .load_backend import epsilon\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\r\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\r\n    return f(*args, **kwargs)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\r\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\r\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\r\n    filename = getsourcefile(frame) or getfile(frame)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\r\n    if getattr(getmodule(object, filename), '__loader__', None) is not None:\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\inspect.py\", line 733, in getmodule\r\n    if ismodule(module) and hasattr(module, '__file__'):\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-5-df9a78134369>\", line 1, in <module>\r\n    from keras.models import Model\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\r\n    from . import utils\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\r\n    from . import conv_utils\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\r\n    from .. import backend as K\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\r\n    from .load_backend import epsilon\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-5-df9a78134369>\", line 1, in <module>\r\n    from keras.models import Model\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\r\n    from . import utils\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\r\n    from . import conv_utils\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\r\n    from .. import backend as K\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\r\n    from .load_backend import epsilon\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\r\n    if (await self.run_code(code, result,  async_=asy)):\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\r\n    self.showtraceback(running_compiled_code=True)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2043, in showtraceback\r\n    value, tb, tb_offset=tb_offset)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1385, in structured_traceback\r\n    self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1288, in structured_traceback\r\n    self, etype, value, tb, tb_offset, number_of_lines_of_context\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in structured_traceback\r\n    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\r\nTypeError: can only concatenate str (not \"list\") to str\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'TypeError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1101, in get_records\r\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\r\n    return f(*args, **kwargs)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\r\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\r\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\r\n    filename = getsourcefile(frame) or getfile(frame)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\r\n    if getattr(getmodule(object, filename), '__loader__', None) is not None:\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\inspect.py\", line 733, in getmodule\r\n    if ismodule(module) and hasattr(module, '__file__'):\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3326, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-5-df9a78134369>\", line 1, in <module>\r\n    from keras.models import Model\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\r\n    from . import utils\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\r\n    from . import conv_utils\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\r\n    from .. import backend as K\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\r\n    from .load_backend import epsilon\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3249, in run_ast_nodes\r\n    if (await self.run_code(code, result,  async_=asy)):\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\r\n    self.showtraceback(running_compiled_code=True)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2043, in showtraceback\r\n    value, tb, tb_offset=tb_offset)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1385, in structured_traceback\r\n    self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1288, in structured_traceback\r\n    self, etype, value, tb, tb_offset, number_of_lines_of_context\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1150, in structured_traceback\r\n    formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\r\nTypeError: can only concatenate str (not \"list\") to str\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2040, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'TypeError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\KRISHNA PRASAD P\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py in <module>\r\n     57 \r\n---> 58   from tensorflow.python.pywrap_tensorflow_internal import *\r\n     59   from tensorflow.python.pywrap_tensorflow_internal import __version__\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py in <module>\r\n     27             return _mod\r\n---> 28     _pywrap_tensorflow_internal = swig_import_helper()\r\n     29     del swig_import_helper\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py in swig_import_helper()\r\n     23             try:\r\n---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n     25             finally:\r\n\r\n~\\Anaconda3\\lib\\imp.py in load_module(name, file, filename, details)\r\n    241         else:\r\n--> 242             return load_dynamic(name, filename, file)\r\n    243     elif type_ == PKG_DIRECTORY:\r\n\r\n~\\Anaconda3\\lib\\imp.py in load_dynamic(name, path, file)\r\n    341             name=name, loader=loader, origin=path)\r\n--> 342         return _load(spec)\r\n    343 \r\n\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nAttributeError                            Traceback (most recent call last)\r\n~\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in showtraceback(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\r\n   2039                         # in the engines. This should return a list of strings.\r\n-> 2040                         stb = value._render_traceback_()\r\n   2041                     except Exception:\r\n\r\nAttributeError: 'ImportError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n~\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self, code_obj, result, async_)\r\n   3341             if result is not None:\r\n   3342                 result.error_in_exec = sys.exc_info()[1]\r\n-> 3343             self.showtraceback(running_compiled_code=True)\r\n   3344         else:\r\n   3345             outflag = False\r\n\r\n~\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in showtraceback(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\r\n   2041                     except Exception:\r\n   2042                         stb = self.InteractiveTB.structured_traceback(etype,\r\n-> 2043                                             value, tb, tb_offset=tb_offset)\r\n   2044 \r\n   2045                     self._showtraceback(etype, value, stb)\r\n\r\n~\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py in structured_traceback(self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n   1383         self.tb = tb\r\n   1384         return FormattedTB.structured_traceback(\r\n-> 1385             self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n   1386 \r\n   1387 \r\n\r\n~\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py in structured_traceback(self, etype, value, tb, tb_offset, number_of_lines_of_context)\r\n   1286             # Verbose modes need a full traceback\r\n   1287             return VerboseTB.structured_traceback(\r\n-> 1288                 self, etype, value, tb, tb_offset, number_of_lines_of_context\r\n   1289             )\r\n   1290         elif mode == 'Minimal':\r\n\r\n~\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py in structured_traceback(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\r\n   1148         exception = self.get_parts_of_chained_exception(evalue)\r\n   1149         if exception:\r\n-> 1150             formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\r\n   1151             etype, evalue, etb = exception\r\n   1152         else:\r\n\r\nTypeError: can only concatenate str (not \"list\") to str\r\n", "comments": ["@prasad03kp,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the TensorFlow version you are using. Thanks!", "@amahendrakar  I got this error when i am using tensorflow 2.1. I just tried to print the version of tensorflow using tf.__version__ . I resolved the problem by downgrading tensorflow into 2.0 beta version.\r\nThank you\r\n", "I got same error.To overcome this situation use google colab instead of jupyter notebook", "> \r\n> \r\n> I got same error.To overcome this situation use google colab instead of jupyter notebook\r\n\r\nI got same error from colab"]}, {"number": 35725, "title": "How to print tensor within GradientTape scope in TF2?", "body": "How to print tensor within GradientTape scope in TF2? i.e.\r\n\r\n```\r\nwith tf.GradientTape() as tape: \r\n    ...\r\n    print(x)\r\n\r\n```\r\n\r\nCurrently it gives me output like this:\r\n\r\n> Tensor(\"Identity_1:0\", shape=(), dtype=float32)\r\n\r\nThis is very needed for debugging. Shouldn't the concept of computational graph already be discarded in TF2, such that it should work very much like PyTorch? Why is it still behaving like TF1 in GradientTape?", "comments": ["@yxchng try tf.print() insted of print", "@NLP-ZY Great. Thanks!"]}, {"number": 35724, "title": "Recurrent Dropout is Wrong", "body": "I've reviewed one design in-depth, and two others superficially, but Keras/TF's `recurrent_dropout` does not implement _any_ of them; publication links below.\r\n\r\n 1. I see some potentially severe problems with TF's implementation in light of the papers I've read, which explicitly advocate against the used scheme. This said - what is TensorFlow / Keras's justification / rationale  of its own implementation?\r\n\r\n 2. The implementation is inconsistent - see below; the docstring only mentions a performance difference, but there's also a _reproducibility_ and _design_ difference; `==1` uses _different masks_ per gate, whereas `==2` uses a _shared mask_. The two are neither theoretically nor practically identical. \r\n\r\nSecond's fixable via a docstring, but first involves significant changes to recurrent dropout logic for `LSTM`, `GRU`, and maybe other RNNs. This said: **is TensorFlow / Keras open to changing its base implementations of recurrent dropout?** If so, I can go ahead and clarify **(1)** in detail, and maybe even do the re-implementing myself in a PR, per paper 1.\r\n\r\n<hr>\r\n\r\n**Inconsistency**: `implementation==1` vs. `implementation==2`\r\n\r\n```python\r\nif 0. < self.recurrent_dropout < 1.:  # implementation==1\r\n    h_tm1_i = h_tm1 * rec_dp_mask[0]\r\n    h_tm1_f = h_tm1 * rec_dp_mask[1]\r\n    h_tm1_c = h_tm1 * rec_dp_mask[2]\r\n    h_tm1_o = h_tm1 * rec_dp_mask[3]\r\n```\r\n```python\r\nif 0. < self.recurrent_dropout < 1.:  # implementation==2\r\n    h_tm1 *= rec_dp_mask[0]\r\n```\r\nSource codes: [keras](https://github.com/keras-team/keras/blob/master/keras/layers/recurrent.py#L2014) -- [tf.keras](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/recurrent.py#L2391)\r\n\r\n<hr>\r\n\r\n**Publications**:\r\n\r\n 1. [Recurrent Dropout without Memory Loss](https://arxiv.org/abs/1603.05118)\r\n 2. [A Theoretically Grounded Application of Dropout in Recurrent Neural Networks](https://arxiv.org/abs/1512.05287)\r\n 3. [RNNDrop: A novel dropout for RNNs](https://sci-hub.se/10.1109/ASRU.2015.7404775)", "comments": ["Hi @OverLordGoldDragon. Thanks for reporting the issue.\r\n\r\n1. For point 1, can you be more specific about the difference between the paper and the keras implementation? eg the math formula in the paper vs the code in keras.\r\n\r\n2. For point 2, I have previously also notice the difference, and added a patch to force use implementation 1 when the recurrent_dropout is enabled. The code is in 9002ff156ef173e91822a9ad9ba51f260e4a2223.", "@qlzh727 2: I see, so TF's ahead of Keras in this; nicely done.\r\n\r\n1: sure. Upon closer inspection of the second paper, I realize TF's implementation is probably based on it - but is still off:\r\n\r\n 1. `tf.nn.dropout` is _inverted dropout_, whereas the authors don't apply any scaling; their code on the paper's last page generates masks via [`srng.binomial()`](https://github.com/Theano/Theano/blob/master/theano/sandbox/rng_mrg.py#L896) - no scaling here, nor in the formulas.\r\n 2. The paper applies a _single_ dropout mask for the entire sequence; I couldn't really determine from the code whether this is the case, or masks are generated per-timestep. I'm fairly sure, however, that a new set of masks is generated with a new input to the model, _even with_ `stateful=True`.\r\n\r\nImplications:\r\n\r\n 1. **Dampened gradient**: upscaling preactivations drives the recurrent sigmoid into saturation sooner, exacerbating gradient vanishing.\r\n 2. **Stateful** is mainly for fitting a _single sequence_ in separate consecutive fits; that is, inputs are assumed to _causally continue_ from their predecessors. The paper's central design element is dropping the _same features per_ (entire) _sequence_ (see f1).\r\n\r\nThere may be more as I haven't read the paper in full, but the idea is, TF's implementation concretely differs from the paper's in at least these two regards.\r\n\r\n<hr>\r\n\r\n**Footnotes**:  f1 - pg. 6: \r\n\r\n> we drop the same words throughout the sequence - i.e. we drop word types at random rather than word tokens (e.g. the sentence \"the dog and the cat\" might become \"__ dog and __ cat\" or \"the __ and the cat\", but never \"__ dog and the cat\")\r\n\r\nIn context of signals, this'd mean dropping the same _channels_ for the entire sequence. (In my application, the signal is 240,000 timesteps per sequence, requiring stateful even post dim-reduction)\r\n", "@qlzh727 More importantly, I find paper 1's implementation more viable than 2's from my reviews so far - and 1 does present empirically better-or-equal results than 2. It seems to offer superior gradient dynamics for long timeseries, _and_ is `implementation=2`-friendly. Further, 2 accounts for train vs. interence-time scaling, whereas 1 seems to not use any scaling (which may not be best). \r\n\r\nThere's more to be argued in favor of paper 1, but before I do I should ask - **is TensorFlow open to changing its base implementation of recurrent dropout, OR enabling a settable alternative?** I.e. e.g. `recurrent_dropout_implementation=2`. I can see it implemented with a relatively small change to the overall source code.\r\n\r\nI'm aware the answer to above is a \"yes\" if offering it as a \"custom add-on\" - hence my asking on _base_. If TF is open to this end, I can detail further as to why 1 is better than 2, or is as good as, and hence should be in the base implementation.", "Thanks for the details.\r\n\r\n1. We are generally open for change of the layer behavior if there is a mis-interpretation for the concept in the paper.\r\n\r\n2. For those 2 paper referred, I can see first paper is quite clear that not scaling up when dropout is applied (sample code at last page). On the other hand, the second paper is explicitly scaling up the value when dropout (formula 18). It's unclear to me that which one is the \"correct\" approach. If one approach is generically better than the other, then we should change to that, otherwise, we have to allow user control this behavior.\r\n\r\n3. Reusing the same mask for the whole sequence. Keras is using same mask for the whole sequence (variational dropout). The mask will be reset for every batch, but stays the same for all the timesteps within the batch. You can find more details in 9650c977e3b3ca73a0249a08f703960f478b3ea9.", "@qlzh727 Thanks for the feedback; glad to hear TF is open to change given sufficient reason. \r\n\r\n 2. Second paper max formula number is 9, pg. 5; which is \"formula 18\"? \r\n\r\n 3. Right, so then it _changes_ between batches even with stateful, which may be undesirable per paper 2\r\n\r\nI have more to say, but will relay it after clarification; awaiting your response.", "Sorry, I think I made the typo between paper 1 and 2 in my previous message. I was referring to paper \"Recurrent Dropout without Memory Loss\", on page 4,  formula 18, with content\r\n```\r\nmask \u2217 x/p, if train phase\r\nx otherwise\r\n```\r\nNote here p is the probably for dropout, dividing p means scale up for the value.", "@qlzh727 Indeed, it is from paper 1, whereas Keras' implementation is based on _2_. As noted in my previous reply, 2's source code at the last page uses no scaling, as confirmed with a lookup to [`srng.binomial()`](https://github.com/Theano/Theano/blob/master/theano/sandbox/rng_mrg.py#L896). i.e., Keras' implementation _conradicts the authors'_.\r\n\r\nRegarding formula 18, authors mention it as an example of a _problem_ they're fixing right underneath:\r\n\r\n> In this case the above argument holds as well, but instead of observing exponentially decreasing hidden states during testing, we will observe exponentially increasing values of hidden states during\r\ntraining.\r\n\r\n > Our approach **addresses the problem** discussed previously by ...\r\n\r\nFrom the source code linked in the paper, we can see that [no scaling](https://github.com/stas-semeniuta/drop-rnn/blob/master/layers.py#L99) occurs on train time, but it does at [test time](https://github.com/stas-semeniuta/drop-rnn/blob/master/layers.py#L143) (`drop_candidates` is for 1's implementation, which they compare against paper 3's implementation via `=False`).\r\n\r\n", "@qlzh727 It should now be clear that `recurrent_dropout` is indeed off in regards to scaling, and possibly in regards to `stateful` dropout masking - but I'd like to make a stronger claim that paper 1's implementation should _replace_ the current one, or at least be added as an option to the base implementation. To this end, I present a case in favor of 1 in this post:\r\n\r\n<hr>\r\n\r\n**THEORETICAL**:\r\n\r\n 1. **Improved gradient persistence along time**; with a bounded activation like `sigmoid` or `tanh` in the hidden-to-hidden transformation, inverted dropout upscales pre-activations, which drives _activations_ closer to saturation, diminishing the gradient. The effect is amplified upon recurrence - especially for long sequences, _inhibiting learning long-term dependencies_. (My observation)\r\n\r\n 2. **Improved inference-time performance**; for `t` timesteps, assuming a favorable case of all gates being equal to 1 to preserve the hidden state, the hidden state vector at time t, `h_t`, under paper 2's recurrent transformation, is \r\n\r\n![image](https://user-images.githubusercontent.com/16495490/72905379-e4dfca80-3d49-11ea-9c68-8b0af3caacbe.png)\r\n\r\n> Since `p` is a value between zero and one, sum components that are far away in the past are multiplied by a very low value and are effectively removed from the summation. Thus, even though the network is able to learn long-term dependencies, it is **not capable of exploiting them during test phase**.\r\n\r\n> Our approach addresses the problem discussed previously by dropping the update vectors **g**. Since we drop only candidates, we do not scale the hidden state directly. This allows for solving the scaling issue, as Eq. 17 becomes:\r\n\r\n![image](https://user-images.githubusercontent.com/16495490/72905828-941ca180-3d4a-11ea-835f-32946a4f984e.png)\r\n\r\n\r\n 3. **Improved stability**, relative to paper 2 w/ inverted dropout, not just due to gradients, but train-time activations, which are upscaled, easing divergence. In fact, I observed this directly, as in [this SO](https://stackoverflow.com/questions/57516678/lstm-recurrent-dropout-with-relu-yields-nans); furthermore, also reproduced it with `tanh` activations. Higher `recurrent_dropout` accelerated divergence.\r\n\r\n<hr> \r\n\r\n**EMPIRICAL**:\r\n\r\nAuthors demonstrate equal or better performance to 2's implementation in a number of applications, including word-level language modeling, character-level language modeling, named entity recognition, Twitter sentiment analysis, and a demonstrative synthetic task. Some distinguishing findings are:\r\n\r\n 1. (iv) applying dropout to hidden state _updates_ rather than hidden states in some cases leads to a perplexity decrease by more than 30 points; (v) our approach is effective even when combined with the forward dropout - for LSTMs we are able to bring down perplexity on validation set from 130 to 91.6 -- pg. 6, Word-level Language Modeling\r\n 2. Per-step mask sampling was shown to work better or as well as per-sequence sampling across all tasks, and _even for_ 2's implementation on word-level language embedding.\r\n\r\n 3. \r\n\r\n> While our experimental results show that recurrent dropout leads to significant improvements across various NLP benchmarks ..., its benefits for other tasks, e.g. sequence-to-sequence prediction, speech recognition, or other domains, remains unexplored.\r\n\r\nWhile all presented so far should be sufficient, I offer to take it a step further; I can fill the missing gap in the sequence-to-sequence domain. I'm working on a seizure EEG classification task, containing 16-channel recordings w/ 240,000 timesteps, totaling 65+ GB of data. My work has been extensive, and I have a massive database of hundreds of tested architectures, majority CNN + RNN. The stacked RNNs are typically fed ~1500 timesteps post dim-reduction in a stateful manner - which is far more than what's been tested in any of the papers. \r\n\r\nI can compare the current dropout scheme against 1's, and report results; I'll also be using my [visualization package](https://github.com/OverLordGoldDragon/see-rnn) to inspect the gradients directly.", "Thank you for the very detailed explanation and sorry for the late reply.\r\n\r\n1. I agree with you that the recurrent dropout should not scale up the undroped value, wrt to all the referred paper.\r\n2. Wrt to stateful RNN, currently generate new masks for each of the mini batch, but we can update that to handle the stateful case. Within each of the batch, the masks are the same.\r\n3. If we going to change the recurrent dropout to be not scaling, probably we will add a new flag for this since its changing the existing behavior. Even through it might not be correct in the first place, but people relied on it. ", "@qlzh727 All of that sounds good, and I agree with 3 also. Further, I've changed my position since last time: I no longer advocate for _replacing_ current recurrent dropout, as I just achieved remarkable performance with current dropout, which wouldn't be possible if it did more harm than good. 1's authors do also note that performance was close to 2's on multiple benchmarks.\r\n\r\nThis said, and my case considered, is TF open to a PR on paper 1's implementation of `recurrent_dropout`? (as an option, e.g. via `recurrent_dropout_implementation=2`)", "Yes, I think we are open for that. Also adding @fchollet  as the API owner to confirm this.\r\n\r\nWe can have a more descriptive naming for the new param, but we can decide it later.", "@qlzh727 Wonderful. To clarify, did fchollet confirm it, or are you requesting a confirmation?\r\n\r\nIf it's a green light, I'll go ahead and cook up a PR - though unsure when exactly, I'd say within a few weeks. As for correcting the current implementation, I'll leave that to the devs.", "@OverLordGoldDragon, I would like to have @fchollet to confirm this is ok to proceed as the API owner.", "I confirmed numerous times again, that `recurrent_dropout` promotes exploding gradients (`nan` loss & weights) - but this time, with an insight: `recurrent_dropout` + _large weight norms_, or `recurrent_dropout` + _large uncentered inputs_ (e.g. ReLU). While both can cause divergence without `recurrent_dropout`, `recurrent_dropout` significantly lowers the required threshold.\r\n\r\nTo test my hypothesis on scaling, edited `_recurrent_mask *= (1 - self.recurrent_dropout)` - and indeed, explosions no more, and training proceeds in a stable manner.", "Has this been fixed by any chance in version 2.4.1? \r\nThanks!", "@marioskef TensorFlow 4 will happen sooner.\r\n\r\nI'd look for third-party implementations.", "@OverLordGoldDragon thanks for your reply! \r\nI am asking because here https://github.com/yaringal/BayesianRNN/issues/5#issuecomment-354255980 the author of the _A Theoretically Grounded Application of Dropout in Recurrent Neural Networks_ said he implemented it for keras. So I am a bit confused tbh what is what.\r\nAny advice? :)\r\n", "@MariosKef Don't recall the details, but these bits seem relevant (Ctrl + F):\r\n\r\n> Upon closer inspection of the second paper, I realize TF's implementation is probably based on it - but is still off:\r\n\r\n> More importantly, I find paper 1's implementation more viable than 2's from my reviews so far\r\n\r\nSo I've concluded it's not based on paper 2 (you could ask the author directly, point to this thread), and even if it was, it's not the best approach. ", "@OverLordGoldDragon \r\n\r\nThanks for your answer. So basically what is currently implemented in TF is a type of variational dropout but not the one suggested from the paper, if got it correctly.\r\n\r\nAny advice for 3rd implementations or other libraries?", "@MariosKef Right, it _partly_ implements 2. I don't know of such libraries.", "Hi There,\n\n This is a stale issue. As you are using an older version of tensorflow, we are checking to see if you still need help on this issue. Please test the issue with the latest TensorFlow (TF2.7 and tf-nightly). If the issue still persists with the newer versions of TF, please feel free to open it in [keras-team/keras](https://github.com/keras-team/keras/issues) repository by providing details about the issue and a standalone code to reproduce the issue. Thanks! \n\n Please note that Keras development has moved to a separate Keras-team/keras repository to focus entirely on only Keras. Thanks! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35724\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35724\">No</a>\n"]}, {"number": 35723, "title": "[Intel MKL] Updating MKL layout pass unit test with bfloat16 support - 3", "body": "This PR enables some more operators with bfloat16 graph rewrite tests.", "comments": ["> Thank you for the quick fixes!\r\n\r\nThanks for quick review!"]}, {"number": 35722, "title": "fixed tf-lite-micro test's boolean evaluation macro", "body": "the raw form ' if(!x) ' causes errors when used with expressions such as ' is_active && is_ok ' which will evaluate to ' !is_active && is_ok ' instead of ' !(is_active && is_ok) '", "comments": []}, {"number": 35721, "title": "import tensorflow as tf fail", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 2.1 (with pip)\r\n- **Python version**: 3.7 (anaconda)\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: cuda 10.1 cudnn 7.6\r\n- **GPU model and memory**: RTX 2080\r\n- **Exact command to reproduce**: import tensorflow as tf \r\n\r\n\r\n### Describe the problem\r\nHi, I install tf 2.1 with pip.\r\nWhen I write inside Spyder :\r\nimport tensorflow as tf\r\n\r\nI get the error \r\n\r\n\r\nError in callback <bound method AutoreloadMagics.post_execute_hook of <autoreload.AutoreloadMagics object at 0x000002944E042978>> (for post_execute):\r\n\r\n\r\nTraceback (most recent call last):\r\n\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 578, in post_execute_hook\r\n    _, pymtime = self._reloader.filename_and_mtime(sys.modules[modname])\r\n\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 184, in filename_and_mtime\r\n    if not hasattr(module, '__file__') or module.__file__ is None:\r\n\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: \r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nThanks for your help !", "comments": ["@moi35 ,\r\nWhat is make/model of your cpu being used ?\r\nCan you please check if the system supports AVX instructions sets? that might be causing the issue.\r\nAlso see [Hardware Requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements).\r\nThanks!", "Hi,\r\nYes, the system supports AVX instruction. The CPU is an intel i5 and i  I use the last driver available for the GPU. I have the good version of cuda/cudnn requirements for TF 2.1.\r\nI have used before tensorflow 1.12 without issue on this computer (with older version of cuda/cudnn).\r\nThanks\r\nHave a nice day", "I think you have the same issue as I do in #35618. ", "I think you're right. Sorry, I didn't see it.\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35721\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35721\">No</a>\n", "I am having the same issue when I pip install tensorflow. I do not have an nvidia graphics card and want to use a CPU tensorflow, NOT GPU. I get:\r\n\r\nImportError: DLL load failed: The specified module could not be found.\r\nFailed to load the native TensorFlow runtime."]}, {"number": 35720, "title": "Decorating a function with tf.function leads to slower execution", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): None\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): v1.12.1-21967-gd80fda0 2.1.0-dev20200109\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: CUDA Version 10.1.243 / cuDNN 7.6.4.38-1\r\n- GPU model and memory: TITAN V, 12GB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nWhen decorating a function with tf.function leads to slower execution, even though the function accepts only tf Tensors.\r\n\r\n**Describe the expected behavior**\r\nI expect the function to execute as fast or faster with tf.function decoration.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n`\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport time\r\n\r\nassert tf.executing_eagerly()\r\n\r\ngpus_p = tf.config.experimental.list_physical_devices('GPU')\r\nif gpus_p:\r\n    try:\r\n        # Currently, memory growth needs to be the same across GPUs\r\n        for gpu in gpus_p:\r\n            tf.config.experimental.set_memory_growth(gpu, True)\r\n    except RuntimeError as e:\r\n        # Memory growth must be set before GPUs have been initialized\r\n        print(e)\r\n\r\n@tf.function\r\ndef sony_forward_tf_function(x,d,xmax):\r\n    return d * tf.round(tf.clip_by_value(x , -xmax , xmax ) / d)\r\n\r\n\r\ndef sony_forward(x,d,xmax):\r\n    return d * tf.round(tf.clip_by_value(x , -xmax , xmax ) / d)\r\n\r\n\r\nx = tf.random.uniform(shape=[10000,1000])\r\ntimes = {'tf':[],'tf_function':[],'sony':[],'sony_function':[]}\r\nxmax = tf.Variable(0.5)\r\nstep_size = xmax / (tf.pow(2.0, tf.cast(8,dtype=tf.float32) - 1.0) - 1.0)\r\n\r\nsony_forward(x,-xmax,xmax)\r\nsony_forward_tf_function(x,-xmax,xmax)\r\n\r\nfor n in range(1000):\r\n    start = time.time()\r\n    x = sony_forward(x,step_size,xmax)\r\n    stop = time.time()\r\n    times['sony'].append(stop-start)\r\n\r\nfor n in range(1000):\r\n    start = time.time()\r\n    x = sony_forward_tf_function(x,step_size,xmax)\r\n    stop = time.time()\r\n    times['sony_function'].append(stop-start)\r\n    \r\nprint('Sony forward ' + str(1000 * np.mean(times['sony'])) + ' ms')\r\nprint('Sony forward w/ tf.function ' + str(1000 * np.mean(times['sony_function'])) + ' ms')\r\n`\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@ifed-ucsd,\r\nI tried to reproduce the issue with TF- 2.1.0-dev20200109 and did not observe much difference in the execution time. Please find the attached Gist [here](https://colab.sandbox.google.com/gist/amahendrakar/7f86b6ea4efcaa5184803e1ddbed96c8/35720.ipynb).", "@amahendrakar But there is still a difference in runtime, with tf.function decoration leading to slower code. It seems to me that this is not the intended behavior. At the least tf.function decoration should produce functions that run as fast as ones not decorated with tf.function (if not faster)", "Unfortunately, `tf.function` is not always faster for small computations. The reason is quite simple: calling an empty `tf.function` is more expensive than calling an empty Python function. This is especially true when the computations involve scalars, when the speed gained inside the function is too small to recover the cost of calling it.\r\n\r\nThis can sometimes be avoided by one of the following:\r\n * vectorizing the computation (e.g. instead of operating on one example at a time, operate on an entire batch); [here](https://www.tensorflow.org/guide/function#batching) is such an example\r\n * adding `experimental_compile=True`, which can greatly speed up complex scalar computations when XLA support is available\r\n * you may also speed things up by moving more computation inside the `tf.function` iself\r\n\r\nThis is something that we're addressing, as there are a few inefficiencies in the current implementation.", "That makes sense. When I add `experimental_compile=True`, I do see the decorated function running faster than the un-decorated one. "]}, {"number": 35719, "title": "parallel_for: No converter defined for MatrixSolve", "body": "I need to calculate the Jacobian of a function, where `tf.linalg.solve` is part of the function. I can usually use `parallel_for` but `pfor` does not support the `MatrixSolve` op, requiring a fallback to a slow while loop. It would be great to add a converter for `MatrixSolve` to `parallel_for.` Note that below, my example can be easily mathematically simplified, but in my actually use case it cannot be.\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.14.0\r\n- Python version: 3.7.3\r\n\r\n**Code to reproduce the issue**\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.python.ops.parallel_for.gradients import jacobian\r\nimport numpy as np\r\n\r\nsess = tf.InteractiveSession()\r\nprint(tf.__version__)\r\n\r\nx = tf.compat.v1.placeholder(tf.float64, shape = [3])\r\ny = tf.compat.v1.placeholder(tf.float64, shape = [3])\r\nz = tf.reshape(tf.linalg.solve(tf.linalg.diag(x), tf.reshape(y, [-1, 1])), [-1])\r\n\r\njac = jacobian(z, x)\r\n\r\nprint(sess.run(jac, feed_dict = {x: np.array([1., 1., 1.]), y: np.array([1., 2., 3.])}))\r\n```\r\n\r\n**Describe the current behavior**\r\n\r\n```python\r\nValueError: No converter defined for MatrixSolve\r\nname: \"loop_body/gradients/MatrixSolve_grad/MatrixSolve\"\r\nop: \"MatrixSolve\"\r\ninput: \"MatrixDiag\"\r\ninput: \"loop_body/gradients/Reshape_1_grad/Reshape\"\r\nattr {\r\n  key: \"T\"\r\n  value {\r\n    type: DT_DOUBLE\r\n  }\r\n}\r\nattr {\r\n  key: \"adjoint\"\r\n  value {\r\n    b: true\r\n  }\r\n}\r\n\r\ninputs: [WrappedTensor(t=<tf.Tensor 'MatrixDiag:0' shape=(3, 3) dtype=float64>, is_stacked=False, is_sparse_stacked=False), WrappedTensor(t=<tf.Tensor 'loop_body/gradients/Reshape_1_grad/Reshape/pfor/Reshape:0' shape=(3, 3, 1) dtype=float64>, is_stacked=True, is_sparse_stacked=False)]. \r\nEither add a converter or set --op_conversion_fallback_to_while_loop=True, which may run slower\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nI should get\r\n```\r\narray([[-1.,  0.,  0.],\r\n       [ 0., -2.,  0.],\r\n       [ 0.,  0., -3.]])\r\n```\r\n", "comments": ["I notice from the `pfor` [code](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/parallel_for/pfor.py) that both `tf.linalg.cholesky` and `tf.linalg.triangular_solve` are supported. I'll use this as a work around until this is fixed (since I'm solving with a symmetric positive definite matrix):\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.python.ops.parallel_for.gradients import jacobian\r\nimport numpy as np\r\n\r\n### work around because there is no converter for MatrixSolve in pfor\r\n### I can change this just to tf.linalg.solve() when tensorflow fixes this\r\ndef chol_triangular_solve(a, b):\r\n    chol_a = tf.linalg.cholesky(a)\r\n    return tf.linalg.triangular_solve(tf.transpose(chol_a), tf.linalg.triangular_solve(chol_a, b, lower = True), lower = False)\r\n\r\nsess = tf.InteractiveSession()\r\nprint(tf.__version__)\r\n\r\nx = tf.compat.v1.placeholder(tf.float64, shape = [3])\r\ny = tf.compat.v1.placeholder(tf.float64, shape = [3])\r\nz = tf.reshape(chol_triangular_solve(tf.linalg.diag(x), tf.reshape(y, [-1, 1])), [-1])\r\n\r\njac = jacobian(z, x)\r\n\r\nprint(sess.run(jac, feed_dict = {x: np.array([1., 1., 1.]), y: np.array([1., 2., 3.])}))\r\n```\r\n\r\nThis is not very elegant, but I get the desired output:\r\n```python\r\n[[-1.  0.  0.]\r\n [ 0. -2.  0.]\r\n [ 0.  0. -3.]]\r\n```", "I have tried on colab with TF version 1.14, 1.15 and was able to reproduce the issue.Please,find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/6e311c0490f217bb66e00bfb1aa047ee/untitled546.ipynb). Thanks!", "MatrixSolve is supported at head but not in 1.15. Can you use a more recent version of TF, using compat.v1 if needed.? ", "Yes, I noticed a bit ago this has been updated since my original post, but I forgot to close this. Sorry about that, and thank you! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35719\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35719\">No</a>\n"]}, {"number": 35718, "title": "Fake quantization is much slower when decorated with tf.function", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.3\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): v1.12.1-21967-gd80fda0 2.1.0-dev20200109\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: CUDA Version 10.1.243 / cuDNN 7.6.4.38-1\r\n- GPU model and memory: TITAN V, 12GB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nExecuting `tf.quantization.fake_quant_with_min_max_vars` within a `tf.function` decorator is much slower than executing without the decorator. On my system, the code below prints:\r\n\r\nTF forward 0.27578210830688477 ms\r\nTF forward w/ tf.function 0.4100463390350342 ms\r\n\r\n**Describe the expected behavior**\r\nI expect the speed to be the same.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n`\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport time\r\n\r\nassert tf.executing_eagerly()\r\n\r\ngpus_p = tf.config.experimental.list_physical_devices('GPU')\r\nif gpus_p:\r\n    try:\r\n        # Currently, memory growth needs to be the same across GPUs\r\n        for gpu in gpus_p:\r\n            tf.config.experimental.set_memory_growth(gpu, True)\r\n    except RuntimeError as e:\r\n        # Memory growth must be set before GPUs have been initialized\r\n        print(e)\r\n\r\n@tf.function\r\ndef tf_forward_tf_function(x,xmin,xmax):\r\n    return tf.quantization.fake_quant_with_min_max_vars(inputs=x,\r\n                                                        min=xmin,\r\n                                                        max=xmax,\r\n                                                        num_bits=8)\r\n\r\ndef tf_forward(x,xmin,xmax):\r\n    return tf.quantization.fake_quant_with_min_max_vars(inputs=x,\r\n                                                        min=xmin,\r\n                                                        max=xmax,\r\n                                                        num_bits=8)\r\n\r\nx = tf.random.uniform(shape=[10000,1000])\r\ntimes = {'tf':[],'tf_function':[]}\r\nxmax = tf.Variable(0.5)\r\n\r\ntf_forward(x,-xmax,xmax)\r\ntf_forward_tf_function(x,-xmax,xmax)\r\n\r\nfor n in range(1000):\r\n    start = time.time()\r\n    tf_forward(x,-xmax,xmax)\r\n    stop = time.time()\r\n    times['tf'].append(stop-start)\r\n\r\n    start = time.time()\r\n    tf_forward_tf_function(x,-xmax,xmax)\r\n    stop = time.time()\r\n    times['tf_function'].append(stop-start)\r\n    \r\nprint('TF forward ' + str(1000 * np.mean(times['tf'])) + ' ms')\r\nprint('TF forward w/ tf.function ' + str(1000 * np.mean(times['tf_function'])) + ' ms')   \r\n\r\n`\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@ifed-ucsd,\r\nI have observed that this issue is similar to [#35720](https://github.com/tensorflow/tensorflow/issues/35720). Please confirm if I can close this issue as it is already being tracked there.", "I would like to keep this open because this issue highlights that decorating a single call to a TF function with tf.function leads to slower execution, whereas #35720 is about decorating a sequence of TF function calls. Moreover, this issue is about the tf.quantization API specifically, whereas #35720 is not.", "Was able to reproduce the issue. Please find the Gist [here](https://colab.sandbox.google.com/gist/amahendrakar/556336666ea4fed9d12d0e22da535879/35718.ipynb). Thanks!", "I think this highlights the same fundamental issue as #35720, that is, `tf.function` does not yield a speed gain for small computations.\r\n\r\nSince `tf.fake_quant_with_min_max_vars` is a single op kernel, this is a particular case. Conceptually, it is similar e.g. to how in Python, `x + y` is faster when executed directly, compared to executing it in a function.\r\n\r\nLet's use the other thread to capture both cases."]}, {"number": 35717, "title": "TensorFlow<1.15 documentation redirects to GitHub", "body": "## URL(s) with the issue:\r\n\r\nFor example,\r\nhttps://www.tensorflow.org/versions/r1.14/api_docs/python/tf/train\r\nhttps://www.tensorflow.org/versions/r1.14/api_docs/python/tf/estimator/Estimator\r\nhttps://www.tensorflow.org/versions/r1.14/api_docs/python/tf/keras/Model\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe links above currently redirect to GitHub. The 1.15 links work:\r\n\r\nhttps://www.tensorflow.org/versions/r1.15/api_docs/python/tf/train\r\nhttps://www.tensorflow.org/versions/r1.15/api_docs/python/tf/estimator/Estimator\r\nhttps://www.tensorflow.org/versions/r1.15/api_docs/python/tf/keras/Model\r\n\r\nI have projects using TensorFlow 1.14, so I would like to use the 1.14 docs for reference.\r\n\r\nWill the 1.14 docs be back up?\r\n", "comments": ["@artemmavrin Where did you find those links on Tensorflow website? Thanks!", "@jvishnuvardhan The links are similar to links I've been using as recently as earlier this week to access TensorFlow 1.14 documentation.\r\n\r\nThe last such working link in by browser history is https://www.tensorflow.org/versions/r1.14/api_docs/python/ from January 9, which currently redirects to https://github.com/tensorflow/docs/tree/r1.14/site/en/api_docs/python.\r\n\r\nI've been using the 1.15 documentation and 1.14 source code for reference in the meantime, but it would be very convenient for my projects that use 1.14 if I had the 1.14 documentation at my disposal.\r\n\r\nThanks!", "HI @artemmavrin, this is works-as-intended.\r\n\r\ntensorflow.org is focused on TF2 now, but we'll continue to host the latest 1.x version on the site (1.15). We're archiving older versions in the tensorflow/docs GitHub repo under the version branch: https://github.com/tensorflow/docs/tree/r1.14/site/en\r\nThese docs can be navigated and previewed using the GitHub previewer.\r\n"]}, {"number": 35716, "title": "fixed tf-lite-micro test's boolean evaluation macro", "body": "the raw form 'if(!x)' causes errors when used with expressions such as 'is_active && is_ok' which will evaluate to '!is_active && is_ok' instead of '!(is_active && is_ok)'", "comments": []}, {"number": 35715, "title": "Add usage example to Dropout", "body": "Added a usage example to tf.keras.layers.Dropout", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F35715) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F35715) for more info**.\n\n<!-- ok -->", "Please move the Usage Examples section above the Arguments section", "Hi, I've moved it above the Arguments section.", "@Joseph-Rance Can you please resolve conflicts? Thanks!", "Hi, they should be fixed now"]}, {"number": 35714, "title": "fixed static sized arrays with variable length", "body": "using const int or int for the size of an array implies that it has variable length (ill-formed, https://en.cppreference.com/w/cpp/language/ub), static arrays' lengths should be constexpr or a macro constant", "comments": []}, {"number": 35713, "title": "No gradient in custom loss function", "body": "I tried to create a custom loss function using spearman correlation in tensorflow 2.1.0-rc1. However, I've encountered \"no gradient\" error. I have multiple targets. Here is my code:\r\n```\r\nimport tensorflow as tf\r\nfrom scipy.stats import rankdata\r\nBATCH_SIZE = 4\r\n\r\ndef custom_loss(num_targets):\r\n    def custom_rhos(y_true, y_pred):\r\n        rhos = []\r\n        for ind in range(num_targets):\r\n            a = tf.squeeze(tf.slice(y_true, [0, ind], [-1, 1]))\r\n            b = tf.squeeze(tf.slice(y_pred, [0, ind], [-1, 1]))\r\n            rank_a, rank_b = tf.numpy_function(rankdata, [a],  Tout=tf.float32), tf.numpy_function(rankdata, [b],  Tout=tf.float32)\r\n            rho = 1 - 6 * tf.reduce_sum((rank_a - rank_b) ** 2) / (BATCH_SIZE ** 3 - BATCH_SIZE)\r\n            rhos.append(rho)\r\n        return -tf.reduce_sum(rhos)\r\n    return custom_rhos\r\n```\r\n\r\nIt keeps giving the erros as following:\r\n\r\n```\r\n/tensorflow-2.1.0/python3.6/tensorflow_core/python/keras/optimizer_v2/optimizer_v2.py in _filter_grads(grads_and_vars)\r\n   1037   if not filtered:\r\n   1038     raise ValueError(\"No gradients provided for any variable: %s.\" %\r\n-> 1039                      ([v.name for _, v in grads_and_vars],))\r\n   1040   if vars_with_empty_grads:\r\n   1041     logging.warning(\r\n\r\nValueError: No gradients provided for any variable:\r\n```\r\n", "comments": ["@acmilannesta,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here. Thanks!", "Here is my model structure\r\n```\r\ndef custom_loss(num_targets):\r\n    def custom_rhos(y_true, y_pred):\r\n        rhos = []\r\n        for ind in range(num_targets):\r\n            a = tf.slice(y_true, [0, ind], [-1, 1])\r\n            a = tf.reshape(a, [-1])\r\n            b = tf.slice(y_pred, [0, ind], [-1, 1])\r\n            b = tf.reshape(b, [-1])\r\n            rank_a, rank_b = tf.py_function(rankdata, [a],  Tout=tf.float32), tf.py_function(rankdata, [b],  Tout=tf.float32)\r\n            rho = 1 - 6 * tf.reduce_sum((rank_a - rank_b) ** 2) / (BATCH_SIZE ** 3 - BATCH_SIZE)\r\n            rhos.append(rho)\r\n        return -tf.reduce_sum(rhos)\r\n    return custom_rhos\r\n\r\n\r\ndef model_build(len_train, num_targets, dropout=0.2, lr=LR, epochs=NUM_EPOCHS, bert_trainable=True, multi_target=True):\r\n    global NUM_CLASSES\r\n    global BATCH_SIZE\r\n    global NUM_EPOCHS\r\n    global MIN_LR\r\n    # global LR\r\n    global MAXLEN\r\n    global model_path\r\n    global NUM_AUX\r\n \r\n    q_in = keras.layers.Input(shape=(None,), dtype=tf.int32, name=\"q_input_word_ids\")\r\n    q2_in = keras.layers.Input(shape=(None,), dtype=tf.int32, name=\"q_input_masks\")\r\n    q3_in = keras.layers.Input(shape=(None,), dtype=tf.int32, name=\"q_segment_ids\")\r\n    input_category = keras.layers.Input((1,), dtype=tf.int32, name='input_category')\r\n    input_host = tf.keras.layers.Input((1,), dtype=tf.int32, name='input_host')\r\n\r\n    bert_layer = hub.KerasLayer(model_path, trainable=bert_trainable)\r\n    _, q_inputs  = bert_layer([q_in, q2_in, q3_in])\r\n    q_outputs1 = keras.layers.GlobalAveragePooling1D()(q_inputs)\r\n    q_outputs1 = keras.layers.Dropout(dropout)(q_outputs1)\r\n\r\n    category_emb = keras.layers.Embedding(input_dim=len(category_encoder.mapper)+1, output_dim=32)(input_category)\r\n    category_emb = keras.layers.SpatialDropout1D(0.1)(category_emb)\r\n\r\n    host_emb = keras.layers.Embedding(input_dim=len(host_encoder.mapper)+2, output_dim=32)(input_host)\r\n    host_emb = keras.layers.SpatialDropout1D(0.1)(host_emb)\r\n\r\n    features_dense = keras.layers.concatenate([category_emb, host_emb], axis=1)\r\n    features_dense = keras.layers.Flatten()(features_dense)\r\n\r\n    dense = keras.layers.concatenate([q_outputs1, features_dense])\r\n\r\n    if multi_target:\r\n        outputs = [keras.layers.Dense(1, activation='sigmoid')(dense) for _ in range(num_targets)]\r\n        loss_func = [custom_loss]*num_targets\r\n\r\n    else:\r\n        outputs = keras.layers.Dense(num_targets, activation='sigmoid')(dense)\r\n        loss_func = [custom_loss(num_targets=num_targets)]\r\n    # model = keras.Model([q_in, q2_in, q3_in], outputs)\r\n    model = keras.Model([q_in, q2_in, q3_in, input_category, input_host], outputs)\r\n\r\n\r\n    decay_steps, warmup_steps = calc_train_steps(\r\n        len_train,\r\n        batch_size=BATCH_SIZE,\r\n        epochs=epochs,\r\n    )\r\n\r\n    model.compile(\r\n        loss=loss_func,\r\n        optimizer=AdamWarmup(\r\n            decay_steps=decay_steps,\r\n            warmup_steps=warmup_steps,\r\n            lr=lr,\r\n            min_lr=MIN_LR,\r\n            ),\r\n        )\r\n\r\n\r\n    return model\r\n```\r\nI could compile the model, but when I try to train it. The error occurs. I think maybe this is because I didn't pass a gradient to tf.py_function?\r\n", "@acmilannesta,\r\nLooks like the given code is incomplete. I was unable to reproduce the issue. Please find the Gist [here](https://colab.sandbox.google.com/gist/amahendrakar/64b36d06eec11982d3d832166fcb5195/35713.ipynb). \r\nCould you provide the complete code to reproduce the reported issue. Thanks!", "Any updates regarding this issue? Thanks!"]}, {"number": 35712, "title": "tf.distribute.experimental.TPUStrategy doesn't render Stable correctly", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/api_docs/python/tf/distribute/experimental/TPUStrategy?version=stable\r\n\r\n## Description of issue (what needs changing):\r\n\r\nOn the documentation page for tf.distribute.experimental.TPUStrategy, the Stable documentation is shown as the raw text of the documentation (looks like it's a combination of HTML and Markdown?).\r\n\r\nExample below:\r\n\r\n<img width=\"1664\" alt=\"Screen Shot 2020-01-09 at 1 22 11 PM\" src=\"https://user-images.githubusercontent.com/11432284/72094036-87786200-32e3-11ea-89ca-253b45a5ad7b.png\">\r\n\r\nClicking \"See Nightly\" it renders correctly, but clicking \"See Stable\" again it still shows the raw text again.\r\n", "comments": ["@uchua \r\n\r\nLooks like browser issue.Can you please check again. I am not seeing any issue with the documentation.Thanks!", "Yup looks like it loads correctly now. I tried it on Chrome on a couple computers yesterday and they all were doing the same thing, so I'm not sure what would've changed."]}, {"number": 35711, "title": "unknown option '--proto-format' when make a TensorFlow Lite AAR", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nI nearly finished the build \uff01but finally met this error\r\n\r\n```\r\nERROR: /Users/norly/Documents/github/android/tensorflow-r1.15/tensorflow/lite/java/BUILD:28:1: Processing Android resources for //tensorflow/lite/java:tensorflow-lite-with-select-tf-ops_dummy_app_for_so failed (Exit 1): ResourceProcessorBusyBox failed: error executing command \r\n  (cd /private/var/tmp/_bazel_root/c472abc5e7a3fc0cf3c1a120192310f1/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    ANDROID_BUILD_TOOLS_VERSION=26.0.2 \\\r\n    ANDROID_NDK_API_LEVEL=18 \\\r\n    ANDROID_NDK_HOME=/Users/norly/Documents/github/android/android-ndk-r17c \\\r\n    ANDROID_SDK_API_LEVEL=26 \\\r\n    ANDROID_SDK_HOME=/Users/norly/library/Android/Sdk \\\r\n    PATH='/Applications/anaconda3/envs/android/bin:/Users/norly/opt/anaconda3/condabin:/anaconda3/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Applications/VMware Fusion.app/Contents/Public:/Library/TeX/texbin:usr/bin:/Library/Java/JavaVirtualMachines/jdk1.8.0_171.jdk/Contents/Home/bin:Users/daredos/Swig/bin:/Users/norly/bin' \\\r\n    PYTHON_BIN_PATH=/Applications/anaconda3/envs/android/bin/python \\\r\n    PYTHON_LIB_PATH=/Applications/anaconda3/envs/android/lib/python3.6/site-packages \\\r\n    TF_CONFIGURE_IOS=0 \\\r\n  bazel-out/host/bin/external/bazel_tools/src/tools/android/java/com/google/devtools/build/android/ResourceProcessorBusyBox --tool AAPT2_PACKAGE -- --aapt2 bazel-out/host/bin/external/androidsdk/aapt2_binary --directData ::bazel-out/android-armeabi-v7a-opt/bin/tensorflow/lite/java/tensorflowlite_flex_processed_manifest/AndroidManifest.xml:bazel-out/android-armeabi-v7a-opt/bin/tensorflow/lite/java/tensorflowlite_flex_symbols/R.aapt2.txt:bazel-out/android-armeabi-v7a-opt/bin/tensorflow/lite/java/tensorflowlite_flex_symbols/symbols.zip --useCompiledResourcesForMerge --primaryData ::bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/java/_merged/tensorflow-lite-with-select-tf-ops_dummy_app_for_so/AndroidManifest.xml --buildToolsVersion 26.0.2 --androidJar external/androidsdk/platforms/android-26/android.jar --rOutput bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/java/tensorflow-lite-with-select-tf-ops_dummy_app_for_so_symbols/R.txt --symbolsOut bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/java/tensorflow-lite-with-select-tf-ops_dummy_app_for_so_symbols/merged.bin --srcJarOutput bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/java/tensorflow-lite-with-select-tf-ops_dummy_app_for_so.srcjar --proguardOutput bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/java/proguard/tensorflow-lite-with-select-tf-ops_dummy_app_for_so/_tensorflow-lite-with-select-tf-ops_dummy_app_for_so_proguard.cfg --mainDexProguardOutput bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/java/proguard/tensorflow-lite-with-select-tf-ops_dummy_app_for_so/main_dex_tensorflow-lite-with-select-tf-ops_dummy_app_for_so_proguard.cfg --manifestOutput bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/java/tensorflow-lite-with-select-tf-ops_dummy_app_for_so_processed_manifest/AndroidManifest.xml --resourcesOutput bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/java/tensorflow-lite-with-select-tf-ops_dummy_app_for_so_files/resource_files.zip --packagePath bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/java/tensorflow-lite-with-select-tf-ops_dummy_app_for_so.ap_ --packageForR dummy.package.for.so)\r\nExecution platform: @bazel_tools//platforms:host_platform\r\n1\u6708 10, 2020 2:04:41 \u4e0a\u5348 com.google.devtools.build.android.ResourceProcessorBusyBox processRequest\r\n\u4e25\u91cd: Error during processing\r\njava.lang.RuntimeException: Error during Linking bazel-out/armeabi-v7a-opt/bin/tensorflow/lite/java/_merged/tensorflow-lite-with-select-tf-ops_dummy_app_for_so/AndroidManifest.xml:\r\nCommand: bazel-out/host/bin/external/androidsdk/aapt2_binary\\\r\n\tlink\\\r\n\t--no-version-vectors\\\r\n\t--no-static-lib-packages\\\r\n\t--manifest\\\r\n\tbazel-out/armeabi-v7a-opt/bin/tensorflow/lite/java/_merged/tensorflow-lite-with-select-tf-ops_dummy_app_for_so/AndroidManifest.xml\\\r\n\t--auto-add-overlay\\\r\n\t--proto-format\\\r\n\t--custom-package\\\r\n\tdummy.package.for.so\\\r\n\t-I\\\r\n\texternal/androidsdk/platforms/android-26/android.jar\\\r\n\t-R\\\r\n\t/var/folders/zz/zyxvpxvq6csfxvn_n0000000000000/T/android_resources_tmp17238626937439459235/linked/filtered/bazel-out/android-armeabi-v7a-opt/bin/tensorflow/lite/java/tensorflowlite_flex_symbols/symbols.zip\\\r\n\t-R\\\r\n\t/var/folders/zz/zyxvpxvq6csfxvn_n0000000000000/T/android_resources_tmp17238626937439459235/linked/filtered/folders/zz/zyxvpxvq6csfxvn_n0000000000000/T/android_resources_tmp17238626937439459235/compiled/compiled.zip\\\r\n\t-0\\\r\n\t.apk\\\r\n\t--output-text-symbols\\\r\n\t/var/folders/zz/zyxvpxvq6csfxvn_n0000000000000/T/android_resources_tmp17238626937439459235/linked/R.txt\\\r\n\t--emit-ids\\\r\n\t/var/folders/zz/zyxvpxvq6csfxvn_n0000000000000/T/android_resources_tmp17238626937439459235/linked/ids.txt\\\r\n\t--java\\\r\n\t/var/folders/zz/zyxvpxvq6csfxvn_n0000000000000/T/android_resources_tmp17238626937439459235/linked/java\\\r\n\t--proguard\\\r\n\t/var/folders/zz/zyxvpxvq6csfxvn_n0000000000000/T/android_resources_tmp17238626937439459235/linked/proguard.cfg\\\r\n\t--proguard-main-dex\\\r\n\t/var/folders/zz/zyxvpxvq6csfxvn_n0000000000000/T/android_resources_tmp17238626937439459235/linked/proguard.maindex.cfg\\\r\n\t-o\\\r\n\t/var/folders/zz/zyxvpxvq6csfxvn_n0000000000000/T/android_resources_tmp17238626937439459235/linked/bin.-pb.apk\r\nOutput:\r\nunknown option '--proto-format'.\r\n\r\naapt2 link [options] -o arg --manifest arg files...\r\n\r\nOptions:\r\n -o arg                                            Output path.\r\n --manifest arg                                    Path to the Android manifest to build.\r\n -I arg                                            Adds an Android APK to link against.\r\n -A arg                                            An assets directory to include in the APK. These are unprocessed.\r\n -R arg                                            Compilation unit to link, using `overlay` semantics.\r\n                                                   The last conflicting resource given takes precedence.\r\n --package-id arg                                  Specify the package ID to use for this app. Must be greater or equal to\r\n                                                   0x7f and can't be used with --static-lib or --shared-lib.\r\n --java arg                                        Directory in which to generate R.java.\r\n --proguard arg                                    Output file for generated Proguard rules.\r\n --proguard-main-dex arg                           Output file for generated Proguard rules for the main dex.\r\n --no-auto-version                                 Disables automatic style and layout SDK versioning.\r\n --no-version-vectors                              Disables automatic versioning of vector drawables. Use this only\r\n                                                   when building with vector drawable support library.\r\n --no-version-transitions                          Disables automatic versioning of transition resources. Use this only\r\n                                                   when building with transition support library.\r\n --no-resource-deduping                            Disables automatic deduping of resources with\r\n                                                   identical values across compatible configurations.\r\n --enable-sparse-encoding                          Enables encoding sparse entries using a binary search tree.\r\n                                                   This decreases APK size at the cost of resource retrieval performance.\r\n -x                                                Legacy flag that specifies to use the package identifier 0x01.\r\n -z                                                Require localization of strings marked 'suggested'.\r\n -c arg                                            Comma separated list of configurations to include. The default\r\n                                                   is all configurations.\r\n --preferred-density arg                           Selects the closest matching density and strips out all others.\r\n --product arg                                     Comma separated list of product names to keep\r\n --output-to-dir                                   Outputs the APK contents to a directory specified by -o.\r\n --no-xml-namespaces                               Removes XML namespace prefix and URI information from\r\n                                                   AndroidManifest.xml and XML binaries in res/*.\r\n --min-sdk-version arg                             Default minimum SDK version to use for AndroidManifest.xml.\r\n --target-sdk-version arg                          Default target SDK version to use for AndroidManifest.xml.\r\n --version-code arg                                Version code (integer) to inject into the AndroidManifest.xml if none is\r\n                                                   present.\r\n --version-name arg                                Version name to inject into the AndroidManifest.xml if none is present.\r\n --shared-lib                                      Generates a shared Android runtime library.\r\n --static-lib                                      Generate a static Android library.\r\n --no-static-lib-packages                          Merge all library resources under the app's package.\r\n --non-final-ids                                   Generates R.java without the final modifier. This is implied when\r\n                                                   --static-lib is specified.\r\n --stable-ids arg                                  File containing a list of name to ID mapping.\r\n --emit-ids arg                                    Emit a file at the given path with a list of name to ID mappings,\r\n                                                   suitable for use with --stable-ids.\r\n --private-symbols arg                             Package name to use when generating R.java for private symbols.\r\n                                                   If not specified, public and private symbols will use the application's\r\n                                                   package name.\r\n --custom-package arg                              Custom Java package under which to generate R.java.\r\n --extra-packages arg                              Generate the same R.java but with different package names.\r\n --add-javadoc-annotation arg                      Adds a JavaDoc annotation to all generated Java classes.\r\n --output-text-symbols arg                         Generates a text file containing the resource symbols of the R class in\r\n                                                   the specified folder.\r\n --auto-add-overlay                                Allows the addition of new resources in overlays without\r\n                                                   <add-resource> tags.\r\n --rename-manifest-package arg                     Renames the package in AndroidManifest.xml.\r\n --rename-instrumentation-target-package arg       Changes the name of the target package for instrumentation. Most useful\r\n                                                   when used in conjunction with --rename-manifest-package.\r\n -0 arg                                            File extensions not to compress.\r\n --split arg                                       Split resources matching a set of configs out to a Split APK.\r\n                                                   Syntax: path/to/output.apk:<config>[,<config>[...]].\r\n                                                   On Windows, use a semicolon ';' separator instead.\r\n -v                                                Enables verbose logging.\r\n -h                                                Displays this help menu\r\n\r\n\tat com.google.devtools.build.android.AaptCommandBuilder.execute(AaptCommandBuilder.java:318)\r\n\tat com.google.devtools.build.android.aapt2.ResourceLinker.linkProtoApk(ResourceLinker.java:423)\r\n\tat com.google.devtools.build.android.aapt2.ResourceLinker.link(ResourceLinker.java:531)\r\n\tat com.google.devtools.build.android.Aapt2ResourcePackagingAction.main(Aapt2ResourcePackagingAction.java:185)\r\n\tat com.google.devtools.build.android.ResourceProcessorBusyBox$Tool$14.call(ResourceProcessorBusyBox.java:144)\r\n\tat com.google.devtools.build.android.ResourceProcessorBusyBox.processRequest(ResourceProcessorBusyBox.java:240)\r\n\tat com.google.devtools.build.android.ResourceProcessorBusyBox.main(ResourceProcessorBusyBox.java:203)\r\n```\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n.tf_configure.bazelrc\r\n```\r\nbuild --action_env PYTHON_BIN_PATH=\"/Applications/anaconda3/envs/android/bin/python\"\r\nbuild --action_env PYTHON_LIB_PATH=\"/Applications/anaconda3/envs/android/lib/python3.6/site-packages\"\r\nbuild --python_path=\"/Applications/anaconda3/envs/android/bin/python\"\r\nbuild:xla --define with_xla_support=true\r\nbuild:opt --copt=-march=native\r\nbuild:opt --copt=-Wno-sign-compare\r\nbuild:opt --host_copt=-march=native\r\nbuild:opt --define with_default_optimizations=true\r\nbuild:v2 --define=tf_api_version=2\r\nbuild --action_env ANDROID_NDK_HOME=\"/Users/norly/Documents/github/android/android-ndk-r17c\"\r\nbuild --action_env ANDROID_NDK_API_LEVEL=\"18\"\r\nbuild --action_env ANDROID_BUILD_TOOLS_VERSION=\"26.0.2\"\r\nbuild --action_env ANDROID_SDK_API_LEVEL=\"26\"\r\nbuild --action_env ANDROID_SDK_HOME=\"/Users/norly/library/Android/Sdk\"\r\ntest --flaky_test_attempts=3\r\ntest --test_size_filters=small,medium\r\ntest --test_tag_filters=-benchmark-test,-no_oss,-oss_serial\r\ntest --build_tag_filters=-benchmark-test,-no_oss\r\ntest --test_tag_filters=-gpu,-nomac,-no_mac\r\ntest --build_tag_filters=-gpu,-nomac,-no_mac\r\nbuild --action_env TF_CONFIGURE_IOS=\"0\"\r\n```\r\n\r\n`sudo bazel build --cxxopt='--std=c++11' -c opt --config=android_arm --config=monolithic //tensorflow/lite/java:tensorflow-lite-with-select-tf-ops`\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["aapt2 tool of SDK level 26 doesn't look support the \"--proto-format\" option.\r\nCould you try it again with SDK tool 28+ version?", "> aapt2 tool of SDK level 26 doesn't look support the \"--proto-format\" option.\r\n> Could you try it again with SDK tool 28+ version?\r\n\r\nYes , I noticed yesterday.  It is supported from 28, Thanks"]}, {"number": 35710, "title": "tf.range fails when `limit` is type of `tf.int32` and `dtype` is `tf.int64`", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macos Catalina\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: n/a\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): `2.1.0`\r\n- Python version: `3.7`\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n**Describe the current behavior**\r\nThe behavior of `tf.range` changed between `2.0.0` and `2.1.0`, such that `tf.range(limit, dtype=dtype)` fails when `limit` is type of `tf.int32` and `dtype` is `tf.int64`. Not sure if this is a bug or a feature but I would expect this to still work.\r\n\r\nThe documentation nor the `2.1.0` release notes don't explicitly mention anything about this.\r\n\r\n**Describe the expected behavior**\r\nThe behavior as it was in `2.0.0`, i.e. no exception is raised.\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\ntf.range(tf.constant(4, dtype=tf.int32), dtype=tf.int64)\r\n```\r\n\r\n**Other info / logs**\r\n\r\nWith `tensorflow == 2.1.0`:\r\n```bash\r\n$ python -c \"import tensorflow as tf; print(tf.__version__); print(tf.range(tf.constant(4, dtype=tf.int32), dtype=tf.int64))\"\r\n2.1.0\r\n2020-01-09 16:45:39.137901: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-01-09 16:45:39.151651: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fa652c190b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-01-09 16:45:39.151667: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"/Users/hartikainen/conda/envs/bae/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py\", line 1430, in range\r\n    limit = ops.convert_to_tensor(limit, dtype=dtype, name=\"limit\")\r\n  File \"/Users/hartikainen/conda/envs/bae/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1290, in convert_to_tensor\r\n    (dtype.name, value.dtype.name, value))\r\nValueError: Tensor conversion requested dtype int64 for Tensor with dtype int32: <tf.Tensor: shape=(), dtype=int32, numpy=4>\r\n```\r\n\r\nWith `tensorflow==2.0.0`\r\n```bash\r\n$ python -c \"import tensorflow as tf; print(tf.__version__); print(tf.range(tf.constant(4, dtype=tf.int32), dtype=tf.int64))\"\r\n2.0.0\r\n2020-01-09 16:40:11.425955: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-01-09 16:40:11.439063: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8c6ccdfd00 executing computations on platform Host. Devices:\r\n2020-01-09 16:40:11.439079: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\r\ntf.Tensor([0 1 2 3], shape=(4,), dtype=int64)\r\n```\r\n", "comments": ["https://github.com/tensorflow/tensorflow/issues/29867 seems related but it's from time before this feature worked.", "@hartikainen \r\nI have tried on colab with TF version 2.1 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/99ab8383b4ad24661d44b476fd4a903e/untitled545.ipynb).However i am not seeing any issue with TF 2.0. Thanks!", "@ravikyram Yeah, my point was that this seems like a regression from 2.0 to 2.1, since it behaves as I would expect on 2.0. What I'm not sure is if the \"regression\" is expected or not.", "Added a PR #35821 for the fix.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35710\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35710\">No</a>\n", "Thanks for fixing this!\r\n\r\nAs a side note, the @tensorflow-bot's survey messages are completely useless, since once you have answered it once in another issue, you always just get a message saying \"You've already responded\". Is there a way to fix that?", "@hartikainen Thanks for bringing this @tensorflow-bot's survey issue. We will work on it soon. Thanks!"]}, {"number": 35709, "title": "TensorFlow 2.1.0 requires scipy", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.1.0\r\n- Python version: 3.6.10\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nTensorFlow 2.1.0 added `scipy` as a required dependency.  However, as far as I can tell TensorFlow doesn't actually need scipy. Judging from this PR https://github.com/tensorflow/tensorflow/pull/35278 (which introduced the requirement), the intention was just to avoid a bug with scipy==1.4.0. But it seems that simply not having scipy installed would be another way to avoid that bug, and adding scipy as a requirement to every tensorflow installation seems like kind of a drastic solution. It also wasn't mentioned in the release notes at all, so I'm wondering whether this was an intentional change or not.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n`pip install tensorflow`\r\n", "comments": ["It was an intentional change but we might revisit by the time we release TF 2.2", "By the way, `scipy` dep already existed for `TEST_PACKAGES` included by tests_require at https://github.com/tensorflow/tensorflow/blob/ca2b3d0f9b7e0e5a5701f9175e63a320a3148d4d/tensorflow/tools/pip_package/setup.py#L129\r\n\r\nMight be worth moving that version to scipy >= 1.4.1 as well or just getting rid of it, as it's now duplicated with `INSTALL_PACKAGES`?\r\n\r\nLess relevant if `scipy` dep is reverted for TF 2.2.\r\n\r\nIn general, these gcc version differences that segfault pybind11 between different wheels are possibly not a battle for tensorflow scope as long as manylinux-related PEP xxx gcc etc build-related versions are followed?", "Trying to get a build of Tensorflow 2.1.0 onto Raspberry Pi Zero and having a _terrible_ time building scipy 1.4.1 locally. First, it doesn't automatically enforce pybind11 is installed - a hard dependency. Secondly, it causes an internal compiler error when building scipy/fft/_pocketfft/pypocketfft.cxx file.", "It's unfortunate that pip does not support any kind of \"conflicts with\" declaration. I think given this, the only better solution available now is to detect whether an incompatible version of scipy is installed early on and issue a warning, rather than adding a spurious dependency.", "Should be solved by  @tensorflow-copybara  in 78026d6 "]}, {"number": 35708, "title": "tf2.0 & 2.1 in colab tpu get 'Compilation failure: Asked to propagate a dynamic dimension from..' error", "body": "def simple_residual_block(input, weight_decay=1e-4):\r\n\r\n    input_channels = input.get_shape().as_list()[-1]\r\n\r\n    x = BatchNormalization()(input)\r\n    x = Activation('relu')(x)\r\n    x = Convolution2D(input_channels// 4, 1, 1, kernel_regularizer=l2(weight_decay))(x)\r\n\r\n    x = BatchNormalization()(x)\r\n    x = Activation('relu')(x)\r\n    x = Convolution2D(input_channels // 4, 3, 1, padding='same', kernel_regularizer=l2(weight_decay))(x)\r\n\r\n    x = BatchNormalization()(x)\r\n    x = Activation('relu')(x)\r\n    x = Convolution2D(input_channels, 1, 1, kernel_regularizer=l2(weight_decay))(x)\r\n\r\n    x = add([x, input])\r\n    return x\r\n\r\ndef attention_block(input, encoder_depth, weight_decay=1e-4):\r\n\r\n    assert input.get_shape().as_list()[-2]>=math.pow(2,encoder_depth)*8, 'input width should >= pow(2,encoder_depth)*8'\r\n\r\n    input_channels = input.get_shape().as_list()[-1]\r\n    input = simple_residual_block(input, weight_decay)\r\n    output_trunk = simple_residual_block(input, weight_decay)\r\n    output_trunk = simple_residual_block(output_trunk, weight_decay)\r\n    output_soft_mask = MaxPooling2D(padding='same')(input)\r\n    output_soft_mask = simple_residual_block(output_soft_mask, weight_decay)\r\n\r\n    skip_connections = []\r\n\r\n    for i in range(encoder_depth):\r\n        output_skip_connection = simple_residual_block(output_soft_mask, weight_decay)\r\n        skip_connections.append(output_skip_connection)\r\n        output_soft_mask = MaxPooling2D(padding='same')(output_soft_mask)\r\n        output_soft_mask = simple_residual_block(output_soft_mask, weight_decay)\r\n\r\n    skip_connections = list(reversed(skip_connections))\r\n\r\n    for i in range(encoder_depth):\r\n        output_soft_mask = simple_residual_block(output_soft_mask, weight_decay)\r\n        output_soft_mask = UpSampling2D()(output_soft_mask)\r\n        output_soft_mask = add([output_soft_mask, skip_connections[i]])\r\n\r\n    output_soft_mask = simple_residual_block(output_soft_mask, weight_decay)\r\n    output_soft_mask = UpSampling2D()(output_soft_mask)\r\n\r\n    output_soft_mask = Convolution2D(input_channels, 1, 1)(output_soft_mask)\r\n    output_soft_mask = Convolution2D(input_channels, 1, 1)(output_soft_mask)\r\n    output_soft_mask = Activation('sigmoid')(output_soft_mask)\r\n\r\n    output = Lambda(lambda x: x + 1)(output_soft_mask)\r\n    output = Multiply()([output, output_trunk])\r\n    output = simple_residual_block(output, weight_decay)\r\n\r\n    return output\r\n\r\n\r\n call attention_block with encoder_depth >1 get this err, \r\n\r\nand setting 'strategy.experimental_enable_dynamic_batch_size = False' do not work\r\n\r\n\r\n\r\n\r\n\r\nEpoch 1/200\r\n496/497 [============================>.] - ETA: 0s - loss: 4.5875 - accuracy: 0.2602\r\n---------------------------------------------------------------------------\r\nUnimplementedError                        Traceback (most recent call last)\r\n<ipython-input-1-db2f1c8a2097> in <module>()\r\n    188                                 validation_data=(x_validation, y_validation),\r\n    189                                 validation_steps=x_validation.shape[0] // batch_size,\r\n--> 190                                 shuffle=True)\r\n    191             show_train_history(history, 'accuracy', 'val_accuracy')\r\n    192             show_train_history(history, 'loss', 'val_los')\r\n\r\n11 frames\r\n/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)\r\n\r\nUnimplementedError:  Compilation failure: Asked to propagate a dynamic dimension from hlo %add.5706 = f32[128,8,8,64]{3,2,1,0} add(f32[128,8,8,64]{3,2,1,0} %add.5705, f32[128,8,8,64]{3,2,1,0} %add.5678), metadata={op_type=\"AddV2\" op_name=\"model/add_8/add\"}@{}@0 to hlo %custom-call.5725 = f32[128,16,16,64]{3,2,1,0} custom-call(f32[128,8,8,64]{3,2,1,0} %add.5706), custom_call_target=\"ResizeNearest\", metadata={op_type=\"ResizeNearestNeighbor\" op_name=\"model/up_sampling2d/resize/ResizeNearestNeighbor\"}, backend_config=\"\\\"01\\\"\", which is not implemented.\r\n\tTPU compilation failed\r\n\t [[{{node tpu_compile_succeeded_assert/_8555495338583930365/_5}}]]\r\nAdditional GRPC error information:\r\n{\"created\":\"@1578578190.016458329\",\"description\":\"Error received from peer\",\"file\":\"external/grpc/src/core/lib/surface/call.cc\",\"file_line\":1039,\"grpc_message\":\" Compilation failure: Asked to propagate a dynamic dimension from hlo %add.5706 = f32[128,8,8,64]{3,2,1,0} add(f32[128,8,8,64]{3,2,1,0} %add.5705, f32[128,8,8,64]{3,2,1,0} %add.5678), metadata={op_type=\"AddV2\" op_name=\"model/add_8/add\"}@{}@0 to hlo %custom-call.5725 = f32[128,16,16,64]{3,2,1,0} custom-call(f32[128,8,8,64]{3,2,1,0} %add.5706), custom_call_target=\"ResizeNearest\", metadata={op_type=\"ResizeNearestNeighbor\" op_name=\"model/up_sampling2d/resize/ResizeNearestNeighbor\"}, backend_config=\"\\\"01\\\"\", which is not implemented.\\n\\tTPU compilation failed\\n\\t [[{{node tpu_compile_succeeded_assert/_8555495338583930365/_5}}]]\",\"grpc_status\":12} [Op:__inference_distributed_function_203353]\r\n\r\nFunction call stack:\r\ndistributed_function -> distributed_function\r\n", "comments": ["UpSampling2D  cause this problem, but do not know why and how to fix it , i tested tf v2.1  have same error too but  appears at the epoch start", "Hi,\r\nHow did you solve this? I am facing the same error in model.fit at the beginning of the training.", "Why is the issue closed?\r\n\r\nI too face this issue.", "I did get the same problem when I was trying to train unet with TPU. Just like @ofpppppppdbfjs said, the problem is caused by upsampling2D layer. Once I replaced the upsampling2D layer with conv2d_transpose layer, the problem sloved. \r\nBut I still don't know why Upsampling2D will cause this problem, and maybe there are some other layers might cause this problem either. I suggest that you can replace some of your layers in model with similar function layers to find out what cause this issue, until the real issue is solved by Tensorflow team.", "> I did get the same problem when I was trying to train unet with TPU. Just like @ofpppppppdbfjs said, the problem is caused by upsampling2D layer. Once I replaced the upsampling2D layer with conv2d_transpose layer, the problem sloved.\r\n> But I still don't know why Upsampling2D will cause this problem, and maybe there are some other layers might cause this problem either. I suggest that you can replace some of your layers in model with similar function layers to find out what cause this issue, until the real issue is solved by Tensorflow team.\r\n\r\nIn cases where your UpSampling2D layers could be substituted with UpSampling1D, doing that also seems to make the problem go away."]}, {"number": 35707, "title": "Failed to load model from file:///android_asset/frozen_inference_graph.pb'", "body": "Hi guys, \r\n\r\nI am trying to run the trained model on my android device, but it's crashing on opening. \r\n\r\nWhen i checked my logcat, i have the following screenshot:\r\n<img width=\"1364\" alt=\"Screen Shot 2020-01-09 at 5 47 51 PM\" src=\"https://user-images.githubusercontent.com/22390818/72073182-d7b5eb00-3308-11ea-996d-b508710f75c4.png\">\r\nProcess: org.tensorflow.demo, PID: 3797 java.lang.RuntimeException: Failed to load model from 'file:///android_asset/frozen_inference_graph.pb'.\r\n\r\nI have tried so many things like changing my TF version to match the tensorflow android build version but all to no avail. \r\n\r\nAnd also, sometimes the logcat will log an error message relating to something like `Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary`. \r\n\r\nI would have matched my android build.gradle dependencies with my current TF version but the latest tensorflow-android is 1.13.1.\r\n\r\nMy model was trained on TF 1.15.0\r\nmacOS Mojave 10.14\r\nTF Version: 1.15.0\r\nModel used: ssd_mobilenet_v2_quantized_300*300_coco and ssd_inception_v2_coco\r\n\r\nPlease help, I have used more than 24 hours in looking for the solution. \r\n", "comments": ["TF Mobile is deprecated, so if you need updated support you would have to build the libraries manually from source.\r\n\r\nAlternatively, TensorFlow Lite supports both ssd_mobilenet_v2 and ssd_inception, and should offer much better performance and a much smaller binary size. Is there a reason you cannot use TensorFlow Lite?", "Aha, Okay.\r\n\r\nNo reason, actually. I just followed a tutorial. \r\n\r\nI'll definitely try out TensorFlow Lite and see how it goes. \r\n\r\nThank you!", "Sounds good, let us know if you run into any issues!", "Hi @jdduke, I am trying to run the command to convert .pb to tflite format using this code\r\n `toco --graph_def_file=trained-inference-graphs/output_tflite/tflite_graph.pb  --output_format=TFLITE --output_file=trained-inference-graphs/output_tflite/detect.tflite --inference_type=QUANTIZED_UINT8 --inference_input_type=QUANTIZED_UINT8 --input_arrays=input --output_arrays=TFLite_Detection_PostProcess --input_shapes=1,60,80,3 --mean_values=128 --std_dev_values=128 --default_ranges_min=0 --default_ranges_max=6\r\n` \r\n\r\nbut it's returning the error `F tensorflow/lite/toco/graph_transformations/quantize.cc:614] Check failed: is_rnn_state_array`. When i change the output_arrays, it returns `Specified output array is not produced by any op in this graph`. I have tried different input_arrays values as well as output_arrays values and input_shapes values ut all to no avail. How can i know the correct appropriate values for my case, please?", "@srjoglekar246 can help in offering guidance for detection model conversion.", "@SirPhemmiey Please follow the instructions on [this page](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tensorflowlite.md) for conversion. You will probably need to follow instructions for float models, since the models mentioned above aren't quantized. The command to convert, in particular, is this:\r\n\r\n```\r\nbazel run --config=opt tensorflow/lite/toco:toco -- \\\r\n--input_file=$OUTPUT_DIR/tflite_graph.pb \\\r\n--output_file=$OUTPUT_DIR/detect.tflite \\\r\n--input_shapes=1,300,300,3 \\\r\n--input_arrays=normalized_input_image_tensor \\\r\n--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'  \\\r\n--inference_type=FLOAT \\\r\n--allow_custom_ops\r\n```", "I'm getting the same error when deploying frozenModel.pb to android \r\nMy tensorflow model contains LSTM layers. Is it because of this?\r\nThanks in advance", "@Adeesh2411 you can't run a .pb on Android with TFLite. What API are you using?", "> @Adeesh2411 you can't run a .pb on Android with TFLite. What API are you using?\r\n\r\n**This is my tensor flow model information:** \r\n![image](https://user-images.githubusercontent.com/35789683/110511461-428bcd80-812a-11eb-985a-ca901dc3c37e.png)\r\n\r\n\r\n\r\nI'm not using tflite file . I Converted above model to  .pb file and I want to run this .pb file in android \r\n**API used in android :** \r\nModule used :  import org.tensorflow.contrib.android.TensorFlowInferenceInterface;\r\ninferenceInterface = new TensorFlowInferenceInterface(getAssets(), MODEL_FILE); // here MODEL_FILE is path to .pb file\r\n\r\nMy issue is it fails to load the module itself .It provides Java Runtime exception\r\n\r\nThe reason I'm using this approach is because I need to deploy LSTM Model into android \r\n**To put this in another way is it possible to run LSTM model in android by any means?**\r\n", "You need to convert it to tflite. ", "Currently we cannot convert LSTM model to tflite file . so then we cannot deploy LSTM model to android?", "What errors do you encounter during conversion? Can you file a new Github issue for those? LSTMs should be supported for conversion to TFLite with our new converter.\r\nThere is no good way to run Protobuf models on Android AFAIK.", "Ok I will raise new Issue. \r\nMy error is same as the This issue title \r\n"]}, {"number": 35706, "title": "Init operations did not make model ready. When import form .pbtxt", "body": "**System information**\r\n- Ubuntu 16.04:\r\n- TensorFlow installed from (source or binary): pip binary\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: 3.5.2\r\n- CUDA/cuDNN version: 10.0 / 7.5\r\n- GPU model and memory: NVIDIA RTX 2080TI\r\n\r\nI am trying the tf.io.write_graph() and tf.import_graph_def API to implement model saving and re-building. And I encountered \"Init operations did not make model ready\" when importing the graph_def into MonitoredSession()\r\n\r\n**Here is the importing related source code:**\r\n\r\n```\r\n# Some code to load graph_def from .pbtxt file\r\ntf.reset_default_graph()\r\ntf.import_graph_def(graph_def, name='')\r\nwith tf.train.MonitoredTrainingSession() as sess:\r\n```\r\n\r\n**The bug information is:**\r\nRuntimeError: Init operations did not make model ready.  Init op: group_deps, init fn: None, local_init_op: name: \"group_deps_1\"\r\nop: \"NoOp\"\r\ninput: \"^init_2\"\r\ninput: \"^init_all_tables\"\r\ninput: \"^init_3\"\r\n, error: Variables not initialized: global_step, ......", "comments": ["@HongmingHUANG,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here. Thanks!", "@amahendrakar \r\nThanks for your response, Here is the complete code to reproduce the issue:\r\nThe input file is a .pbtxt file exported using \r\ntf.io.write_graph(sess.graph_def, '.', \u2018validation.pbtxt')\r\n\r\nHere is the code to reproduce the bug (I just reproduced it now)\r\n```\r\nimport tensorflow as tf\r\nfrom google.protobuf import text_format\r\nwith open('validation.pbtxt', 'r') as fdin:\r\n    file_content = fdin.read()\r\n    try:\r\n        graph_def = text_format.Parse(file_content, tf.GraphDef())\r\n    except text_format.ParseError as e:\r\n        raise IOError(\"Cannot parse file %s: %s.\"\r\n                        % (filename, str(e)))\r\ntf.reset_default_graph()\r\ntf.import_graph_def(graph_def, name='')\r\nwith tf.train.MonitoredTrainingSession() as sess:\r\n        sess.graph.as_default()\r\n# Report error\r\n```", "Was able to reproduce the issue. Please find the Gist [here](https://colab.sandbox.google.com/gist/amahendrakar/8514be1f6f1d7d5322617c413ec417fa/35706.ipynb). Thanks!", "You may refer https://github.com/tensorflow/tensorflow/issues/14391", "> You may refer #14391\r\n\r\nHi ymodak, I tried the solution in #14391 that add a new checkpoint folder in the session parameter like this:\r\n`\r\nwith tf.train.MonitoredTrainingSession(checkpoint_dir = '/tmp/new_checkpoint') as sess:\r\n    sess.run(target_node)\r\n`\r\nHowever, I still meet the same bug.\r\nIt seems that just change the checkpoint is not enough. Do we also need to write the init function by ourselves?", "Apologies for the delay in response. Is this still an issue? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35706\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35706\">No</a>\n"]}, {"number": 35705, "title": "AttributeError: _ckpt_saved_epoch when using MultiWorkerMirroredStrategy TF2.0", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nyes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nWindows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\npip\r\n- TensorFlow version (use command below):\r\nv2.0.0-rc2-26-g64c3d382ca 2.0.0\r\n- Python version: \r\n3.6.9\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n10.0, 7.6.2\r\n- GPU model and memory:\r\nGeForce GTX 1070 and GeForce GTX 1080\r\n\r\n**Describe the current behavior**\r\nCrash when writing Checkpoint (or stuck when writing log for tensorboard)\r\n\r\n**Describe the expected behavior**\r\nWrite a checkpoint and a Tensorboardlog\r\n\r\n**Code to reproduce the issue**\r\n```\r\nos.environ['TF_CONFIG'] = json.dumps({\r\n    'cluster': {\r\n        \"worker\": [\"10.10.1.168:1234\"],\r\n        'chief': [\"10.10.1.60:2345\"]\r\n    },\r\n    'task': {'type': 'chief', 'index': 0}\r\n})\r\nstrategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\r\n\r\ndef get_label(file_path, class_names):\r\n  parts = tf.strings.split(file_path, os.path.sep)\r\n  return parts[-2] == class_names\r\n\r\ndef parse_image(filename):\r\n    parts = tf.strings.split(filename, \"\\\\\")\r\n    label = get_label(filename, CLASS_NAMES)\r\n    image = tf.io.read_file(filename)\r\n    image = tf.image.decode_png(image, channels=3)\r\n    image = tf.image.convert_image_dtype(image, tf.float32)\r\n    image = tf.image.resize(image, [299,299])\r\n    return image, label\r\n\r\ndef make_dataset_unbatched():\r\n    images_ds = list_ds.map(parse_image, num_parallel_calls=AUTOTUNE)\r\n    images_ds = images_ds.shuffle(BATCH_SIZE)\r\n    images_ds = images_ds.repeat(epochs)\r\n    images_ds = images_ds.prefetch(BUFFER_SIZE)\r\n    return images_ds\r\n\r\ndatasetFilePath = \"D:\\TrainData\\BalancedData\"\r\nIMAGESIZE = 299\r\nAUTOTUNE = tf.data.experimental.AUTOTUNE\r\ndatasetPath = pathlib.Path(datasetFilePath)\r\nlist_ds = tf.data.Dataset.list_files(str(datasetPath/\"*/*\"))\r\nnum_elements = tf.data.experimental.cardinality(list_ds).numpy()\r\n\r\nCLASS_NAMES = np.array([item.name for item in datasetPath.glob('*')])\r\n\r\nepochs = 2\r\ndef build_and_compile_model():\r\n    base_model =tf.keras.applications.InceptionV3(include_top=False, weights = \"imagenet\", input_shape=(299,299,3))\r\n\r\n    base_model.trainable = True\r\n    x = base_model.output\r\n    x = tf.keras.layers.GlobalAveragePooling2D(name=\"avg_pool\")(x)\r\n    x = tf.keras.layers.Dense(256, activation=\"relu\")(x)\r\n    predictions = tf.keras.layers.Dense(2, activation=\"softmax\")(x)\r\n    model = tf.keras.models.Model(inputs=base_model.input, outputs=predictions)\r\n\r\n    base_learning_rate = 0.00001\r\n    model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\r\n                 loss=\"categorical_crossentropy\",\r\n                 metrics=[\"accuracy\"])\r\n    return model\r\nlogdir = os.path.join(\"Z:\\Tensorflow\\TensorboardLogs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\r\ncallbacks = [tf.keras.callbacks.ModelCheckpoint(filepath=\"Z:\\Tensorflow\\Checkpoints\"), \r\n             tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)]\r\n\r\nwith strategy.scope():\r\n    dataset = make_dataset_unbatched().batch(BATCH_SIZE, drop_remainder=True)\r\n    multi_worker_model = build_and_compile_model()\r\n\r\nhistory = multi_worker_model.fit(dataset, epochs=epochs, steps_per_epoch=50, callbacks=callbacks)\r\n``` \r\n\r\n**Other info / logs**\r\n[ckpt_error.txt](https://github.com/tensorflow/tensorflow/files/4040557/ckpt_error.txt)\r\n\r\nThis log happens with the checkpoint in the code, and with only the tensorboard-log as checkpoint the chief stops right at the end of the first epoch and nothing else happens.\r\n\r\nI hope someone can help me with this.\r\n", "comments": ["have you solve this problem?  i also met it ", "> have you solve this problem? i also met it\r\n\r\nUnfortunatly not, \r\nbecause its just a side project i put it on ice for now", "> > have you solve this problem? i also met it\r\n> \r\n> Unfortunatly not,\r\n> because its just a side project i put it on ice for now\r\n\r\ni solved it by chaging tf save format to hdf5. \r\n\r\nfilepath = 'weights.{epoch:02d}-{val_loss:.2f}.hdf5'\r\ncallbacks = [tf.keras.callbacks.ModelCheckpoint(filepath=filepath, verbose=1)]\r\n", "> i solved it by chaging tf save format to hdf5.\r\n> \r\n> filepath = 'weights.{epoch:02d}-{val_loss:.2f}.hdf5'\r\n> callbacks = [tf.keras.callbacks.ModelCheckpoint(filepath=filepath, verbose=1)]\r\n\r\nThanks for the hint, i will try that as soon as i have time to work on that project again!\r\n", "Hi - we believe this should be fixed in the TF nightly (or you can also try with https://pypi.org/project/tensorflow/2.2.0rc3/) . Please re-open if not fixed. "]}, {"number": 35704, "title": " fixed static sized arrays with variable length", "body": "using const int or int for the size of an array implies that it has variable length (ill-formed, https://en.cppreference.com/w/cpp/language/ub), static arrays' lengths should be constexpr or a macro constant", "comments": []}, {"number": 35703, "title": "Problem on building tensorflow optimized for AVX2  CPU", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution : **Debian GNU/Linux 10 (buster)**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): **source**\r\n- TensorFlow version: **2.1**\r\n- Python version: **3.6.9**\r\n- Installed using virtualenv? pip? conda?: **N/A**\r\n- Bazel version (if compiling from source): **1.2.1**\r\n- GCC/Compiler version (if compiling from source): **8.3.0**\r\n- CUDA/cuDNN version: **N/A**\r\n- GPU model and memory: **N/A**\r\n\r\n**Describe the problem**\r\n\r\nHi everybody,\r\n\r\nI tried to build Tensorflow from the source as the way to deal with problem **Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2** since the existing installation of tensorflow by pip install does not allow the optimization for using in my laptop that use CPU that use AVX2.\r\n\r\nHowever, the bazel compiler keeps giving me a headache of Fatal Failed to sync ... Permission denied. as shown in the command and  jpeg file I attached\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n> FATAL: failed to sync '/root/.cache/bazel/_bazel_root/install/84defa6eb1e9416bf92d6f89ab2d4f31.tmp.10122/A-server.jar': (error: 13): Permission denied\r\n\r\nHow can I deal with this kind of troubles on building and installing tensorflow optimized for my CPU? Please help me out. \r\n\r\nBTW, I run tensorflow through docker container since my Laptop OS is Windows 10 though. \r\n![ProblemonCompilingTensorFlowfromSource](https://user-images.githubusercontent.com/58510558/72069742-6d0dab00-331a-11ea-8a5f-6e0b02b09572.jpg)\r\n\r\n\r\n\r\n\r\n\r\n", "comments": ["@WisarutBholsithi,\r\nProvide the exact sequence of commands / steps that you executed before running into the problem.", "@WisarutBholsithi, Did you check the read and execute permission on the file. Thanks", "@WisarutBholsithi, Looks like the read and execute permission on the file is disabled. Navigate to the folder and change the file permission,\r\n`chmod 777 *`. Thanks", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35703\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35703\">No</a>\n"]}]