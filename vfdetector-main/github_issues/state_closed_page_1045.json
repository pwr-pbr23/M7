[{"number": 21952, "title": "Failed to load the native TensorFlow runtime.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 x64 1803 \r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: TensorFlow 1.10.0\r\n- **Python version**: Python 3.6.3\r\n- **Bazel version (if compiling from source)**: 0.16.1\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: ?\r\n- **GPU model and memory**: I'm not using tensoflow GPU version i'm using CPU Ver\r\n- **Exact command to reproduce**: python decensor.py\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\n== cat /etc/issue ===============================================\r\nMINGW64_NT-10.0 DESKTOP-PC1D4GE 2.10.0(0.325/5/3) 2018-06-13 23:34 x86_64 Msys\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nbash: c++: command not found\r\n\r\n== uname -a =====================================================\r\nMINGW64_NT-10.0 DESKTOP-PC1D4GE 2.10.0(0.325/5/3) 2018-06-13 23:34 x86_64 Msys\r\n\r\n== check pips ===================================================\r\nnumpy                 1.14.5             \r\nprotobuf              3.6.1              \r\ntensorflow            1.10.0             \r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\minat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\minat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\minat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\minat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\minat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"C:\\Users\\minat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 22, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\minat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\minat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\minat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\minat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\minat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\minat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\minat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nbash: nvidia-smi: command not found\r\n\r\n== cuda libs  ===================================================\r\n\r\n\r\n\r\n\r\n### Describe the problem\r\nC:\\Users\\minat\\Desktop\\Respo\\DeepMindBreak>python decensor.py\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\minat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 14, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\minat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 658, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 571, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\minat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\minat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 17, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\minat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 16, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\minat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"decensor.py\", line 2, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\minat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 22, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\minat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\minat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\minat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 14, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\minat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 658, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 571, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\minat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\minat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 17, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\minat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 16, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\minat\\AppData\\Local\\Programs\\Python\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\n### Source code\r\nimport tensorflow as tf\r\nhello = tf.constant('Hello, TensorFlow!')\r\nsess = tf.Session()\r\nprint(sess.run(hello))\r\n\r\n", "comments": ["### Edit : \r\n\r\n I fix it from this [https://github.com/tensorflow/tensorflow/issues/18503](url)\r\n\r\nThank's to @sirjo66"]}, {"number": 21951, "title": "[DOC]: minor typo in docstring of make_callable method.", "body": null, "comments": []}, {"number": 21950, "title": "Fix possible memory leak", "body": "`ExecutorState` is used in the following code\r\n```c++\r\nvoid ExecutorImpl::RunAsync(const Args& args, DoneCallback done) {\r\n  (new ExecutorState(args, this))->RunAsync(std::move(done));\r\n}\r\n```\r\nso `RunAsync` should `delete this` if exception occurs before `ScheduleReady` is reached, although this rarely happens.", "comments": ["Thanks @mrry !"]}, {"number": 21949, "title": "'''\\]['p", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": []}, {"number": 21948, "title": "'", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": []}, {"number": 21947, "title": "Where can i find tensorflow 0,12 version?", "body": "It seems that i can't find tensorflow versio 0,12.. Can anyone help me to find it?", "comments": ["If you mean the source code, it's under branch `r0.12`: https://github.com/tensorflow/tensorflow/tree/r0.12", "https://github.com/tensorflow/tensorflow/releases/tag/v0.12.0\r\n\r\nhttps://pypi.org/project/tensorflow/0.12.1/", "We do not support documentation for that version on the site, but those are the best resources if you must use it."]}, {"number": 21946, "title": "[feature request] specify subgraphs to route to TensorRT in tf.contrib.tensorrt", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: 1.10.1\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**: 0.15.1\r\n- **GCC/Compiler version (if compiling from source)**: 5\r\n- **CUDA/cuDNN version**: 9.0, 7.0\r\n- **GPU model and memory**: \r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nBased on the examples provided in tf.contrib.tensorrt as well as on the internet, it seems that the following:\r\n```\r\nimport tensorflow.contrib.tensorrt as trt\r\nwith gfile.FastGFile(protobuf_file, 'rb') as f:\r\n    graph_def = tf.GraphDef()\r\n    graph_def.ParseFromString(f.read())\r\n    trt_graph = trt.create_inference_graph(graph_def, trt_nodes,\r\n                                           max_batch_size=batch_size,\r\n                                           max_workspace_size_bytes=memory_allocation,\r\n                                           minimum_segment_size=minimum_segment_size,\r\n                                           precision_mode=\"FP32\")  # Get optimized graph\r\n```\r\nis enough to make the parts that are recognized by TensorRT into trt_ops. The only control you have of what to send to TensorRT within the graph is \"minimum_segment_size\" which excludes sections of the graph below this number of compatible ops.\r\nHowever, it would be helpful to be able to define sections (either explicit ops, or input/output pairs in the subgraph).\r\nFor example, at the moment, I am struggling to convert into a hybrid TF/TRT graph a Fast-RCNN architecture. TensorRT will convert for example all convolution operations, however the encoder part will have convolutions with a batch size equal to the number of images provided, while the proposal classification part of the network will have convolutions with batch size equal to the number of proposals. I have everything as a single Tensorflow graph with dynamic batch for the 2nd stage, however TensorRT expects a max batch size. If I set the max batch size to the max number of proposals, I run out of memory since it will also assign this max batch to the encoder part.\r\nAt the moment I've set the minimum_segment_size high enough for TensorRT to ignore the proposal part of the network and convert only the encoder. However, it would be helpful to be convert both sections, and leave the unsupported operations (like `tf.image.crop_and_resize`, or `tf.image.non_max_suppression` in Tensorflow).\r\nAny advice? Thanks\r\n", "comments": ["This is on our roadmap and we'll start working on it maybe next month.", "Thank you , I believe this has been added but the contrib folder is deprecated in latest versions . please check tensorflow/addons for further details."]}, {"number": 21945, "title": "Make tf.transpose emit simpler graph when possible", "body": "If not given an explicit 'perm' parameter, tf.transpose currently\r\nemits a graph that dynamically calculates it from the rank of the\r\ninput tensor. This is completely unnecessary when the rank of the\r\ninput can be statically determined at graph construction time.\r\n\r\nModify tf.transpose to emit 'perm' as a single Const node whenever\r\npossible.", "comments": ["EDIT: It looks like //tensorflow/contrib/learn:dnn_test fails with the patch in addition to the other pre-existing failures under contrib. Need to debug this further, since I can't figure out the root cause.", "It looks like there are a few tests where this patch causes a test to fail. They all raise an exception in the same place:\r\n\r\ntensorflow/contrib/learn/python/learn/estimators/head.py\", line 1924, in _centered_bias_step\r\n\r\nWhat's strange is that the code that builds the graph doesn't fail when tf.transpose is called, i.e. the graph node is created just as expected, so its input parameters seem validated. Having gone through every such call with some good old print debugging, the parameters don't look like anything strange. The exception in the test is raised when the optimizer is creating the backprop graph for the bias computation and at this point it looks like some variable and it's grad have different shapes:\r\n\r\n```\r\nFile \"/home/efagerholm/.cache/bazel/_bazel_efagerholm/3bd66cc293ffd5c1e1b6be4e441d09f4/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/contrib/learn/dnn_test.runfiles/org_tensorflow/tensorflow/contrib/learn/python/learn/estimators/dnn_test.py\", line 1562, in testEnableCenteredBias\r\n    regressor.fit(input_fn=_input_fn, steps=5)\r\n  File \"/home/efagerholm/.cache/bazel/_bazel_efagerholm/3bd66cc293ffd5c1e1b6be4e441d09f4/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/contrib/learn/dnn_test.runfiles/org_tensorflow/tensorflow/python/util/deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/efagerholm/.cache/bazel/_bazel_efagerholm/3bd66cc293ffd5c1e1b6be4e441d09f4/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/contrib/learn/dnn_test.runfiles/org_tensorflow/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 525, in fit\r\n    loss = self._train_model(input_fn=input_fn, hooks=hooks)\r\n  File \"/home/efagerholm/.cache/bazel/_bazel_efagerholm/3bd66cc293ffd5c1e1b6be4e441d09f4/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/contrib/learn/dnn_test.runfiles/org_tensorflow/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 1042, in _train_model\r\n    model_fn_ops = self._get_train_ops(features, labels)\r\n  File \"/home/efagerholm/.cache/bazel/_bazel_efagerholm/3bd66cc293ffd5c1e1b6be4e441d09f4/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/contrib/learn/dnn_test.runfiles/org_tensorflow/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 1265, in _get_train_ops\r\n    return self._call_model_fn(features, labels, model_fn_lib.ModeKeys.TRAIN)\r\n  File \"/home/efagerholm/.cache/bazel/_bazel_efagerholm/3bd66cc293ffd5c1e1b6be4e441d09f4/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/contrib/learn/dnn_test.runfiles/org_tensorflow/tensorflow/contrib/learn/python/learn/estimators/estimator.py\", line 1228, in _call_model_fn\r\n    model_fn_results = self._model_fn(features, labels, **kwargs)\r\n  File \"/home/efagerholm/.cache/bazel/_bazel_efagerholm/3bd66cc293ffd5c1e1b6be4e441d09f4/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/contrib/learn/dnn_test.runfiles/org_tensorflow/tensorflow/contrib/learn/python/learn/estimators/dnn.py\", line 214, in _dnn_model_fn\r\n    logits=logits)\r\n  File \"/home/efagerholm/.cache/bazel/_bazel_efagerholm/3bd66cc293ffd5c1e1b6be4e441d09f4/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/contrib/learn/dnn_test.runfiles/org_tensorflow/tensorflow/contrib/learn/python/learn/estimators/head.py\", line 758, in create_model_fn_ops\r\n    enable_centered_bias=self._enable_centered_bias)\r\n  File \"/home/efagerholm/.cache/bazel/_bazel_efagerholm/3bd66cc293ffd5c1e1b6be4e441d09f4/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/contrib/learn/dnn_test.runfiles/org_tensorflow/tensorflow/contrib/learn/python/learn/estimators/head.py\", line 669, in _create_model_fn_ops\r\n    batch_size, loss_fn, weight_tensor)\r\n  File \"/home/efagerholm/.cache/bazel/_bazel_efagerholm/3bd66cc293ffd5c1e1b6be4e441d09f4/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/contrib/learn/dnn_test.runfiles/org_tensorflow/tensorflow/contrib/learn/python/learn/estimators/head.py\", line 1940, in _train_op\r\n    weights=weights)\r\n  File \"/home/efagerholm/.cache/bazel/_bazel_efagerholm/3bd66cc293ffd5c1e1b6be4e441d09f4/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/contrib/learn/dnn_test.runfiles/org_tensorflow/tensorflow/contrib/learn/python/learn/estimators/head.py\", line 1924, in _centered_bias_step\r\n    centered_bias_loss, var_list=(centered_bias,), name=name)\r\n  File \"/home/efagerholm/.cache/bazel/_bazel_efagerholm/3bd66cc293ffd5c1e1b6be4e441d09f4/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/contrib/learn/dnn_test.runfiles/org_tensorflow/tensorflow/python/training/optimizer.py\", line 410, in minimize\r\n    name=name)\r\n  File \"/home/efagerholm/.cache/bazel/_bazel_efagerholm/3bd66cc293ffd5c1e1b6be4e441d09f4/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/contrib/learn/dnn_test.runfiles/org_tensorflow/tensorflow/python/training/optimizer.py\", line 607, in apply_gradients\r\n    update_ops.append(processor.update_op(self, grad))\r\n  File \"/home/efagerholm/.cache/bazel/_bazel_efagerholm/3bd66cc293ffd5c1e1b6be4e441d09f4/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/contrib/learn/dnn_test.runfiles/org_tensorflow/tensorflow/python/training/optimizer.py\", line 115, in update_op\r\n    update_op = optimizer._apply_dense(g, self._v)  # pylint: disable=protected-access\r\n  File \"/home/efagerholm/.cache/bazel/_bazel_efagerholm/3bd66cc293ffd5c1e1b6be4e441d09f4/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/contrib/learn/dnn_test.runfiles/org_tensorflow/tensorflow/python/training/adagrad.py\", line 103, in _apply_dense\r\n    use_locking=self._use_locking)\r\n  File \"/home/efagerholm/.cache/bazel/_bazel_efagerholm/3bd66cc293ffd5c1e1b6be4e441d09f4/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/contrib/learn/dnn_test.runfiles/org_tensorflow/tensorflow/python/training/gen_training_ops.py\", line 174, in apply_adagrad\r\n    use_locking=use_locking, update_slots=update_slots, name=name)\r\n  File \"/home/efagerholm/.cache/bazel/_bazel_efagerholm/3bd66cc293ffd5c1e1b6be4e441d09f4/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/contrib/learn/dnn_test.runfiles/org_tensorflow/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/efagerholm/.cache/bazel/_bazel_efagerholm/3bd66cc293ffd5c1e1b6be4e441d09f4/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/contrib/learn/dnn_test.runfiles/org_tensorflow/tensorflow/python/util/deprecation.py\", line 488, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/efagerholm/.cache/bazel/_bazel_efagerholm/3bd66cc293ffd5c1e1b6be4e441d09f4/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/contrib/learn/dnn_test.runfiles/org_tensorflow/tensorflow/python/framework/ops.py\", line 3274, in create_op\r\n    op_def=op_def)\r\n  File \"/home/efagerholm/.cache/bazel/_bazel_efagerholm/3bd66cc293ffd5c1e1b6be4e441d09f4/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/contrib/learn/dnn_test.runfiles/org_tensorflow/tensorflow/python/framework/ops.py\", line 1770, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): var and grad do not have the same shape[1] []\r\n         [[node dnn/regression_head/centered_bias_step/update_dnn/regression_head/centered_bias_weight/ApplyAdagrad (defined at /home/efagerholm/.cache/bazel/_bazel_efagerholm/3bd66cc293ffd5c1e1b6be4e441d09f4/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/contrib/learn/dnn_test.runfiles/org_tensorflow/tensorflow/contrib/learn/python/learn/estimators/head.py:1924)  = ApplyAdagrad[T=DT_FLOAT, _class=[\"loc:@dnn/r...plyAdagrad\"], update_slots=true, use_locking=false, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dnn/regression_head/centered_bias_weight, dnn/regression_head/dnn/regression_head/centered_bias_weight/Adagrad, dnn/regression_head/centered_bias_step/learning_rate, dnn/regression_head/gradients/dnn/regression_head/centered_bias_step/Tile_grad/Sum)]]\r\n```\r\n\r\nI don't quite understand how it would be possible to have a valid forward graph and then have the optimizer end up with different sizes for variables during backprop. I'll look closer into this later this week.", "It looks like I've triggered a bug in TensorFlow (probably the grappler optimizer). The following code fails with the error in the message above:\r\n\r\n```\r\n      a = ops.convert_to_tensor(a, name=\"a\") \r\n      if not a.get_shape().ndims: \r\n        rank = gen_array_ops.rank(a) \r\n        perm = (rank - 1) - gen_math_ops._range(0, rank, 1) \r\n      else: \r\n        rank = a.get_shape().ndims \r\n        perm = (rank - 1) - np.arange(rank, dtype=np.int32) \r\n```\r\n\r\nHowever, if I simply add a tf.Print on the perm parameter it works, i.e. the following code passes unit tests:\r\n\r\n```\r\n      a = ops.convert_to_tensor(a, name=\"a\") \r\n      if not a.get_shape().ndims: \r\n        rank = gen_array_ops.rank(a) \r\n        perm = (rank - 1) - gen_math_ops._range(0, rank, 1) \r\n      else: \r\n        rank = a.get_shape().ndims \r\n        perm = (rank - 1) - np.arange(rank, dtype=np.int32) \r\n        from tensorflow.python.ops import logging_ops \r\n        perm = logging_ops.Print(perm, [perm], \"sdfsdf\") \r\n```\r\n\r\n", "Can you fix this by doing perm = ops.convert_to_tensor((rank - 1) -\nnp.arange(rank, dtype=np.int32))?\n\nOn Mon, Sep 17, 2018 at 5:53 AM Edvard Fagerholm <notifications@github.com>\nwrote:\n\n> It looks like I've triggered a bug in TensorFlow (probably the grappler\n> optimizer). The following code fails with the error in the message above:\n>\n>       a = ops.convert_to_tensor(a, name=\"a\")\n>       if not a.get_shape().ndims:\n>         rank = gen_array_ops.rank(a)\n>         perm = (rank - 1) - gen_math_ops._range(0, rank, 1)\n>       else:\n>         rank = a.get_shape().ndims\n>         perm = (rank - 1) - np.arange(rank, dtype=np.int32)\n>\n> However, if I simply add a tf.Print on the perm parameter it works, i.e.\n> the following code passes unit tests:\n>\n>       a = ops.convert_to_tensor(a, name=\"a\")\n>       if not a.get_shape().ndims:\n>         rank = gen_array_ops.rank(a)\n>         perm = (rank - 1) - gen_math_ops._range(0, rank, 1)\n>       else:\n>         rank = a.get_shape().ndims\n>         perm = (rank - 1) - np.arange(rank, dtype=np.int32)\n>         from tensorflow.python.ops import logging_ops\n>         perm = logging_ops.Print(perm, [perm], \"sdfsdf\")\n>\n> \u2014\n> You are receiving this because your review was requested.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/21945#issuecomment-422000334>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxfHBtfO86QL9m4uClIzk828SluZRks5ub5tGgaJpZM4WRYE2>\n> .\n>\n\n\n-- \n - Alex\n", "I suggest this because I think it's not a grappler-related bug but instead an issue where some piece of code downstream behaves differently whether perm is a tensor or not, and print makes it a tensor.", "> Can you fix this by doing perm = ops.convert_to_tensor((rank - 1) - np.arange(rank, dtype=np.int32))?\r\n\r\nShould have mentioned that I already tried this and it doesn't help. In fact, I tried the following things:\r\n\r\n```\r\n1. perm = logging_ops.Print(perm, [perm], \"sdfsdf\")\r\n2. perm = constant(perm)\r\n3. perm = identity(perm)\r\n4. perm = ops.convert_to_tensor(perm)\r\n```\r\n\r\nUnit tests only pass with (1), the others all fail.", "Since tf.Print() is basically tf.identity(), I'm not sure if there could be some strange device placement issues going on here? However, I'm running tests with \"--config=opt\", so there's really only the CPU to choose from, so I can't see how this could factor in either.", "@rmlarsen is there someone on the grappler side who can help investigate this failure?", "@efagerho thanks for the PR and sorry for the delay. Let me take a look.\r\n", "This does appear to be a Grappler bug. The tests pass when I disable all Grappler optimizations. I will hunt down and squash the bug now.", "I believe this was caused by a bug in the shape function of Transpose. I will submit a fix shortly. Then we should be able to proceed with this PR.", "> I believe this was caused by a bug in the shape function of Transpose. I will submit a fix shortly. Then we should be able to proceed with this PR.\r\n\r\nThat's quite unexpected. Would have assumed that code to have been fairly well exercised. Thanks for figuring it out!", "@efagerho indeed!", "@efagerho @alextp it looks like fixing the shape function was not enough, and that there is a separate bug in the Grappler shape inference or constant folding.  :-( \r\nI'll keep digging.", "@efagerho @alextp OK found the second bug in reduction index materialization (a part of Grappler constant folding).", "@efagerho @alextp I have submitted the bugfix for Grappler and we can proceed. I have verified that this change now works, but let's keep it as a PR so you get credited for it.", "@efagerho your PR has now been merged. Thanks for the contribution!", "Seems like the patch got rolled back. Were the Grappler fixes checked in before the CI ran?", "We're working on resubmitting it; there were some obscure test failures triggered by this."]}, {"number": 21943, "title": "Can't include no_op in input_map when i import graph_def", "body": "### System information\r\n- **TensorFlow version (use command below)**: current master\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nWhen i pass no_op  into input_map, it makes an error.\r\ni tracebacked some codes and \r\nthe function _PopulateTFImportGraphDefOptions() in tensorflow/tensorflow/python/framework/importer.py can't support no_op as a control dependency.\r\n\r\nunder the first loop, it registers the input map operation into `options` when the `input_src` starts with '^'.\r\nHowever, `no_op` doesn't have `_as_tf_output()` and the line\r\n`dst_op = input_dst._as_tf_output().oper` occurs an exception.\r\nTemporarily, i add the lines\r\n`      src_name, src_idx = _ParseTensorName(input_src[1:])`\r\n`      src_name = compat.as_str(src_name)`\r\n`      dst_output = c_api_util.tf_output(input_dst._c_op, -1)`\r\n`      c_api.TF_ImportGraphDefOptionsAddInputMapping(options, src_name, -1,`\r\n`                                                    dst_output)`\r\ninstead of the lines\r\n`      src_name = compat.as_bytes(input_src[1:])`\r\n`      dst_op = input_dst._as_tf_output().oper  # pylint: disable=protected-access`\r\n`      c_api.TF_ImportGraphDefOptionsRemapControlDependency(`\r\n`          options, src_name, dst_op)`\r\nHowever, I hope this problem to be fixed in the next version.\r\n\r\nThank you\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "It has been 17 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 21942, "title": "why we have kernel argument here?  How can I get my custom op kernel depends on a tf_kernel_library", "body": "https://github.com/tensorflow/tensorflow/blob/3d35a07179d4d38d0cabac4415c550f1cbce00c0/tensorflow/tensorflow.bzl#L1497", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "It has been 17 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 21941, "title": " CUDNN_STATUS_INTERNAL_ERROR   CUDNN_STATUS_BAD_PARAM  TypeError: 'NoneType' object is not callable", "body": "2018-08-29 07:55:25.813715: E tensorflow/stream_executor/cuda/cuda_dnn.cc:403] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\r\n2018-08-29 07:55:25.813773: E tensorflow/stream_executor/cuda/cuda_dnn.cc:370] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM\r\n2018-08-29 07:55:25.813787: F tensorflow/core/kernels/conv_ops.cc:712] Check failed: stream->parent()->GetConvolveAlgorithms( conv_parameters.ShouldIncludeWinogradNonfusedAlgo<T>(), &algorithms) \r\nException ignored in: <bound method BaseSession.__del__ of <tensorflow.python.client.session.Session object at 0x7fa2b1fed588>>\r\nTraceback (most recent call last):\r\n  File \"/root/anaconda3/lib/python3.5/site-packages/tensorflow/python/client/session.py\", line 712, in __del__\r\nTypeError: 'NoneType' object is not callable", "comments": ["\u89e3\u51b3\u529e\u6cd5\uff1a\r\nSolved:\r\n\r\nclass FaceRecognition(object):\r\n\r\n    def __init__(self, model_path, img_path_base='', test_image_file='', file_log_dir='', gpu_memory_fraction=0.3):\r\n\r\nwhen the option gpu_memory_fraction = 0.5 , this error occured , I changed it into  gpu_memory_fraction = 0.3 , this error disappear\r\n\r\n"]}, {"number": 21940, "title": "Add `contains` op to lookup table", "body": "", "comments": []}, {"number": 21939, "title": "Tensorflow 1.10.1 incompatible with latest numpy version 1.15.1 ", "body": "Installed TF with following command `pip3 install tensorflow`. The installation is successful but gave me this error.\r\n`tensorflow 1.10.1 has requirement numpy<=1.14.5,>=1.13.3, but you'll have numpy 1.15.1 which is incompatible.`\r\n\r\nDo I need to downgrade my numpy version?", "comments": ["Yeah if the given error shows \"numpy<=1.14.5,>=1.13.3, but you'll have numpy 1.15.1\" this then  i think you should downgrade it once and check if it works successfully if not then try to update by the command \" conda update --all", "duplicate of #21866", "I was able to solve this with :\r\n sudo pip3 uninstall numpy\r\n pip install numpy==1.14.5\r\n", "If i have to use numpy 1.11.0 what version of tensorflow  should i use ?", "how can I solve this problem ?\r\ndistributed 1.21.8 requires msgpack, which is not installed.\r\ntensorflow 1.14.0 has requirement numpy<2.0,>=1.14.5, but you'll have numpy 1.14.3 which is incompatible.\r\nInstalling collected packages: wrapt, tensorflow, deephyp, setuptools\r\n  Found existing installation: wrapt 1.10.11\r\nCannot uninstall 'wrapt'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\r\nYou are using pip version 10.0.1, however version 19.2.3 is available.\r\n"]}, {"number": 21938, "title": "MKL build failing at tensorflow/core/kernels/mkl_input_conversion_op.cc", "body": "I'm trying to build TF with the MKL option, and it looks like `tensorflow/core/kernels/mkl_input_conversion_op.cc` is failing to build, with the following error:\r\n(building off of the master branch)\r\n```\r\n\u001b\u001b\r\n\u001b[0m\u001b[91mERROR: /opt/tensorflow/tensorflow/core/kernels/BUILD:6217:1: C++ compilation of rule '//tensorflow/core/kernels:mkl_input_conversion_op' failed (Exit 1)\r\n\u001b[0m\u001b[91mIn file included from ./tensorflow/core/kernels/mkl_tfconv_op.h:39,\r\n                 from tensorflow/core/kernels/mkl_input_conversion_op.cc:32:\r\n./tensorflow/core/util/mkl_util.h: In member function 'void tensorflow::FactoryKeyCreator::Append(tensorflow::StringPiece)':\r\n./tensorflow/core/util/mkl_util.h:2057:19: error: 'class tensorflow::StringPiece' has no member named 'ToString'\r\n     key_.append(s.ToString());\r\n                   ^~~~~~~~\r\n\u001b[0m\u001b[91mTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n```", "comments": ["Note that I have used a `sed` to replace the MKL-DNN versions to use the latest release. I'm currently building without that manual update; I'll close this issue if that fixes things right away (since it looks like a header issue now)\r\n\r\nEDIT: Still breaking on master branch. I can however confirm that `r1.10` branch builds successfully with MKL.", "@sadatnfs There is a PR https://github.com/tensorflow/tensorflow/pull/21956 that fixes this error. ", "Nagging Assignee @bignamehyp: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 21937, "title": "Update ops.h -- Eliminating a Warning Message of Type Inconsistency", "body": "In this source code file, the type of t.NumElements() is a signed integer, while the type of v.size() is unsigned. For the \"!=\" operator between them, a warning message appears when TensorFlow is compiled with a C++ application.", "comments": []}, {"number": 21936, "title": "add `bucketize_v2` op to support tensor type `boundaries`", "body": "fix #21934, and ping @yongtang ", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "CLAs look good, thanks!\n\n<!-- ok -->"]}, {"number": 21935, "title": "import tensorflow.contrib fails on arm32", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No. running \"tensorflow/examples/learn/resnet.py\"\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: custom embedded linux\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: Yes, rpi class device\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.10.1 / 4dcfddc5d12018a5a0fdca652b9221ed95e9eb23\r\n- **Python version**: 2.7.15\r\n- **Bazel version (if compiling from source)**:  0.16.0\r\n- **GCC/Compiler version (if compiling from source)**: gcc 6.3\r\n- **CUDA/cuDNN version**: None\r\n- **GPU model and memory**: None\r\n- **Exact command to reproduce**: \"import tensorflow.contrib\"\r\n\r\n### Describe the problem\r\nI am cross-compiling tensorflow to work on a 32-bit armhf system. My build system is x86-64. sample apps seem to work ok. but I am having difficulty in the python environment. \"import tensorflow\" works ok. But \"import tensorflow.contrib\" fails with this error:\r\n\r\n```\r\n>>> import tensorflow.contrib\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/mnt/nfs/baseline/obj.32/target/usr/local/lib/python2.7/site-packages/tensorflow/contrib/__init__.py\", line 69, in <module>\r\n    from tensorflow.contrib import periodic_resample\r\n  File \"/mnt/nfs/baseline/obj.32/target/usr/local/lib/python2.7/site-packages/tensorflow/contrib/periodic_resample/__init__.py\", line 22, in <module>\r\n    from tensorflow.contrib.periodic_resample.python.ops.periodic_resample_op import periodic_resample\r\n  File \"/mnt/nfs/baseline/obj.32/target/usr/local/lib/python2.7/site-packages/tensorflow/contrib/periodic_resample/python/ops/periodic_resample_op.py\", line 32, in <module>\r\n    resource_loader.get_path_to_datafile('_periodic_resample_op.so'))\r\n  File \"/mnt/nfs/baseline/obj.32/target/usr/local/lib/python2.7/site-packages/tensorflow/contrib/util/loader.py\", line 56, in load_op_library\r\n    ret = load_library.load_op_library(path)\r\n  File \"/mnt/nfs/baseline/obj.32/target/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/load_library.py\", line 73, in load_op_library\r\n    exec(wrappers, module.__dict__)\r\n  File \"<string>\", line 293, in <module>\r\n  File \"<string>\", line 229, in _InitOpDefLibrary\r\n  File \"/mnt/nfs/baseline/obj.32/target/usr/local/lib/python2.7/site-packages/tensorflow/python/framework/op_def_registry.py\", line 35, in register_op_list\r\n    assert _registered_ops[op_def.name] == op_def\r\nAssertionError\r\n```\r\n\r\nI have tried combinations of bazel 0.12/0.16, tensorflow 1.8/1.10 and python 2.7.10/2.7.15. I get the same result every time. Issue seems to be related to only PeriodicResample & PeriodicResampleOpGrad. Other modules do not assert.\r\n\r\n", "comments": ["Hi @hododoy ! \r\nIt seems you are using older versions(1.x versions) of Tensorflow which is not supported any more. Have you referred this [document ](https://www.tensorflow.org/lite/guide/build_arm)from TF 2.7 version yet? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 21934, "title": "[feature request] tensor type `boundaries` in `bucketize` op", "body": "ping @yongtang and refer to https://github.com/tensorflow/tensorflow/pull/14774#issuecomment-416726581 \r\n\r\nCurrently, `boundaries` has to be `list` type. It is not convenience for the dynamic `boundaries` .\r\nIt would be great if`boundaries` could be `tensor` type. ", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device"]}, {"number": 21933, "title": "Added axis parameter to tf.losses.softmax_cross_entropy", "body": "The internal implementation of `tf.losses.softmax_cross_entropy`, uses `nn.softmax_cross_entropy_with_logits_v2` which has a dim argument with a default value of -1. The new argument `axis=-1` wraps the `dim` argument of `nn.softmax_cross_entropy_with_logits_v2`. Documentations also updated.\r\nThis will fix #20866", "comments": []}, {"number": 21932, "title": "x86/ppc64le //tensorflow/contrib/lite/delegates/eager:kernel_test and delegate_test core dump", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ppc64le Linux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: master branch from 8/27 (Last commit 514f65a)\r\n- **Python version**: both 2.7 and 3.6\r\n- **Bazel version (if compiling from source)**: 0.15.0\r\n- **GCC/Compiler version (if compiling from source)**: 5.4.0\r\n- **CUDA/cuDNN version**: 9.0, 7\r\n- **GPU model and memory**: 4 V100 GPUs with 16 GB of memory each\r\n- **Exact command to reproduce**:\r\nbazel test --config=cuda --test_tag_filters=-no_oss,-oss_serial,-no_gpu,-benchmark-test --test_timeout 300,450,1200,3600 --local_test_jobs=4 --test_output=errors --build_tests_only //tensorflow/tools/ci_build/gpu_build:parallel_gpu_execute //tensorflow/contrib/lite/delegates/eager:kernel_test //tensorflow/contrib/lite/delegates/eager:delegate_test \r\n\r\n### Describe the problem\r\non x86 and ppc64le when running the Tensorflow Unit Test against contrib, both contrib/lite/delegates/eager:kernel_test and delegate_test core dump. Maybe 'contrib/lite' since it was meant for mobile should be excluded from unit test for x86 and ppc64le?\r\n\r\n\r\n```\r\n==================== Test output for //tensorflow/contrib/lite/delegates/eager:kernel_test:\r\nRunning test /home/wdirons/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_wdirons/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/lite/delegates/eager/kernel_test.runfiles/org_tensorflow/tensorflow/contrib/lite/delegates/eager/kernel_test  on GPU 0\r\n[==========] Running 7 tests from 1 test case.\r\n[----------] Global test environment set-up.\r\n[----------] 7 tests from KernelTest\r\n[ RUN      ] KernelTest.FullGraph\r\n2018-08-28 22:14:43.578155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Found device 0 with properties:\r\nname: Tesla V100-SXM2-16GB major: 7 minor: 0 memoryClockRate(GHz): 1.53\r\npciBusID: 0004:04:00.0\r\ntotalMemory: 15.75GiB freeMemory: 15.34GiB\r\n2018-08-28 22:14:43.578223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1485] Adding visible gpu devices: 0\r\n2018-08-28 22:18:23.446411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:966] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-08-28 22:18:23.446445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:972]      0\r\n2018-08-28 22:18:23.446454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:985] 0:   N\r\n2018-08-28 22:18:23.447047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1098] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14846 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0004:04:00.0, compute capability: 7.0)\r\n/home/wdirons/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_wdirons/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/lite/delegates/eager/kernel_test.runfiles/org_tensorflow/tensorflow/tools/ci_build/gpu_build/parallel_gpu_execute: line 64: 61525 Segmentation fault      (core dumped) \"$TEST_BINARY\" $@\r\n================================================================================\r\n\r\n```\r\n\r\n### Source code / logs\r\ngdb where ran on the core dump for kernel_test on ppc64le\r\n\r\n```\r\n(gdb) where\r\n#0  __memcpy_power7 () at ../sysdeps/powerpc/powerpc64/power7/memcpy.S:277\r\n#1  0x00000001118dd344 in void tflite::eager::(anonymous namespace)::KernelTest::ConfigureDelegate<tflite::eager::(anonymous namespace)::KernelTest_FullGraph_Test::TestBody()::{lambda(                       TfLiteContext*, _TfLiteDelegate*)#1}>(tflite::eager::(anonymous namespace)::KernelTest_FullGraph_Test::TestBody()::{lambda(TfLiteContext*, _TfLiteDelegate*)#1})::{lambda(TfLiteContext*                       , _TfLiteDelegate*, int, void*, unsigned long)#1}::_FUN ()\r\n#2  0x00007fffa4afd9d0 in tflite::Interpreter::Invoke() ()\r\n   from /home/wdirons/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_wdirons/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/lite                       /delegates/eager/../../../../../_solib_local/libtensorflow_Scontrib_Slite_Slibframework.so\r\n#3  0x00007fffa6773b14 in tflite::eager::testing::EagerModelTest::Invoke() ()\r\n   from /home/wdirons/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_wdirons/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/lite                       /delegates/eager/../../../../../_solib_local/libtensorflow_Scontrib_Slite_Sdelegates_Seager_Slibtest_Uutil.so\r\n#4  0x00000001118e8444 in tflite::eager::(anonymous namespace)::KernelTest_FullGraph_Test::TestBody() ()\r\n#5  0x00007fffa47f272c in void testing::internal::HandleExceptionsInMethodIfSupported<testing::Test, void>(testing::Test*, void (testing::Test::*)(), char const*) ()\r\n   from /home/wdirons/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_wdirons/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/lite                       /delegates/eager/../../../../../_solib_local/libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest.so\r\n#6  0x00007fffa47f2ab4 in testing::Test::Run() ()\r\n   from /home/wdirons/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_wdirons/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/lite                       /delegates/eager/../../../../../_solib_local/libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest.so\r\n#7  0x00007fffa47f2f98 in testing::TestInfo::Run() ()\r\n   from /home/wdirons/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_wdirons/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/lite                       /delegates/eager/../../../../../_solib_local/libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest.so\r\n#8  0x00007fffa47f33a4 in testing::TestCase::Run() ()\r\n   from /home/wdirons/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_wdirons/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/lite                       /delegates/eager/../../../../../_solib_local/libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest.so\r\n#9  0x00007fffa47f387c in testing::internal::UnitTestImpl::RunAllTests() ()\r\n   from /home/wdirons/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_wdirons/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/lite                       /delegates/eager/../../../../../_solib_local/libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest.so\r\n#10 0x00007fffa47f3c5c in bool testing::internal::HandleExceptionsInMethodIfSupported<testing::internal::UnitTestImpl, bool>(testing::internal::UnitTestImpl*, bool (testing::internal::                       UnitTestImpl::*)(), char const*) ()\r\n   from /home/wdirons/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_wdirons/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/lite                       /delegates/eager/../../../../../_solib_local/libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest.so\r\n#11 0x00007fffa47f3f60 in testing::UnitTest::Run() ()\r\n   from /home/wdirons/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_wdirons/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/lite                       /delegates/eager/../../../../../_solib_local/libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest.so\r\n#12 0x00000001117950fc in main ()\r\n(gdb)\r\n```\r\n\r\ngdb where ran on the core dump for delegate_test on ppc64le\r\n\r\n```\r\n(gdb) where\r\n#0  __memcpy_power7 () at ../sysdeps/powerpc/powerpc64/power7/memcpy.S:277\r\n#1  0x00007fffaabc2b24 in tflite::eager::delegate::CopyFromBufferHandle(TfLiteContext*, _TfLiteDelegate*, int, void*, unsigned long) ()\r\n   from /home/wdirons/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_wdirons/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/lite/delegates/eager/../../../../../_solib_local/libtensorflow_Scontrib_Slite_Sdelegates_Seager_Slibdelegate.so\r\n#2  0x00007fff9716d9d0 in tflite::Interpreter::Invoke() ()\r\n   from /home/wdirons/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_wdirons/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/lite/delegates/eager/../../../../../_solib_local/libtensorflow_Scontrib_Slite_Slibframework.so\r\n#3  0x00007fff98ec3b14 in tflite::eager::testing::EagerModelTest::Invoke() ()\r\n   from /home/wdirons/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_wdirons/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/lite/delegates/eager/../../../../../_solib_local/libtensorflow_Scontrib_Slite_Sdelegates_Seager_Slibtest_Uutil.so\r\n#4  0x0000000105bf182c in tflite::eager::(anonymous namespace)::DelegateTest_FullGraph_Test::TestBody() ()\r\n#5  0x00007fff96f4272c in void testing::internal::HandleExceptionsInMethodIfSupported<testing::Test, void>(testing::Test*, void (testing::Test::*)(), char const*) ()\r\n   from /home/wdirons/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_wdirons/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/lite/delegates/eager/../../../../../_solib_local/libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest.so\r\n#6  0x00007fff96f42ab4 in testing::Test::Run() ()\r\n   from /home/wdirons/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_wdirons/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/lite/delegates/eager/../../../../../_solib_local/libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest.so\r\n#7  0x00007fff96f42f98 in testing::TestInfo::Run() ()\r\n   from /home/wdirons/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_wdirons/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/lite/delegates/eager/../../../../../_solib_local/libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest.so\r\n#8  0x00007fff96f433a4 in testing::TestCase::Run() ()\r\n   from /home/wdirons/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_wdirons/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/lite/delegates/eager/../../../../../_solib_local/libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest.so\r\n#9  0x00007fff96f4387c in testing::internal::UnitTestImpl::RunAllTests() ()\r\n   from /home/wdirons/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_wdirons/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/lite/delegates/eager/../../../../../_solib_local/libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest.so\r\n#10 0x00007fff96f43c5c in bool testing::internal::HandleExceptionsInMethodIfSupported<testing::internal::UnitTestImpl, bool>(testing::internal::UnitTestImpl*, bool (testing::internal::UnitTestImpl::*)(), char const*) ()\r\n   from /home/wdirons/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_wdirons/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/lite/delegates/eager/../../../../../_solib_local/libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest.so\r\n#11 0x00007fff96f43f60 in testing::UnitTest::Run() ()\r\n   from /home/wdirons/tensorflow/bazel-ci_build-cache/.cache/bazel/_bazel_wdirons/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/lite/delegates/eager/../../../../../_solib_local/libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest.so\r\n#12 0x0000000105aa3f7c in main ()\r\n```\r\n\r\nOn my x86 container I was unable to determine the location of the core that was generated.", "comments": ["In theory these tests should succeed on desktop platforms. We'll take a look.", "Nagging Assignee @jdduke: It has been 44 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 21931, "title": "Added axis parameter to tf.losses.softmax_cross_entropy. fixes #20866", "body": "The internal implementation of `tf.losses.softmax_cross_entropy`, uses `nn.softmax_cross_entropy_with_logits_v2` which has a dim argument with a default value of -1. The new argument `axis=-1` wraps the `dim` argument of `nn.softmax_cross_entropy_with_logits_v2`. Documentations updated too.", "comments": ["Code formatting Issues. Will put another PR"]}, {"number": 21930, "title": "TF logging should support \"exception()\"", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: np\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: all\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**:1.8\r\n- **Python version**:2.7\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:N/A\r\n- **GPU model and memory**:N/A\r\n- **Exact command to reproduce**:N/A\r\n\r\n### Describe the problem\r\nFeature request:\r\nTensorflow logging library should support \"exception()\" function  - and forward it to the underlying logger.\r\n", "comments": ["Maybe hijacking this for a slightly bigger discussion: Should tf expose logging at all? Clearly we need something for TF itself to use, but is there an actual use case for tf.logging being part of the public API? Or should we simply remove it, and users who also want logging facilities should simply use python's logging module. A wrapper makes little sense if it doesn't add useful features.", "Yes. Let's remove tf.logging from the public API (in 2.0). Users should switch to Python's logging module (or any logging facility of their choice).\r\n\r\nI will close this issue. "]}, {"number": 21929, "title": "Poor performance of the model when enabling layer normalization with tf.contrib.rnn.LayerNormBasicLSTMCell", "body": "-------------------------------------------------------------------------------------------------------\r\n\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: \r\n\r\nVERSION=\"16.04.4 LTS (Xenial Xerus)\"\r\nVERSION_ID=\"16.04\"\r\nVERSION_CODENAME=xenial\r\n\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: \r\nNo\r\n- **TensorFlow installed from (source or binary)**:\r\n source\r\n- **TensorFlow version (use command below)**:  \r\ntf.VERSION = 1.9.0\r\n\r\n- **Python version**: python 2.7\r\n\r\n- **Bazel version (if compiling from source)**:  \r\n0.11.1\r\n\r\n- **GCC/Compiler version (if compiling from source)**:  \r\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\n\r\n- **CUDA/cuDNN version**: \r\n 9.1\r\n- **GPU model and memory**:  \r\nTesla K80\r\n- **Exact command to reproduce**:\r\n( No command)\r\n\r\n-------------------------------------------------------------------------------------------------------\r\nBefore writing my issue here,  I found a similar question on  [stackoverflow]( https://stackoverflow.com/questions/45150101/why-is-layernormbasiclstmcell-much-slower-and-less-accurate-than-lstmcell) where the author described the same problem I have but there were no valid answer and most of the comments where wrongly referring to technique related to batch_normalization which are non-applicable since we are talking about layer_normalization. \r\n( [Difference between layer_normalzation and batch_normalization](https://theneuralperspective.com/2016/10/27/gradient-topics/) )\r\nI was trying to do some layer normalization with my model, and I have chosen the \r\n`tf.contrib.rnn.LayerNormBasicLSTMCell` where `layer_norm` is set to True.\r\nI started training the model and as unexpected the training/validation losses are decreasing slowly.\r\nThe paper of layer normalization ( https://arxiv.org/pdf/1607.06450.pdf ) showed that this technique makes the training time much faster but the Tensorflow implementation showed the inverse case.\r\nAre there please any hints on how to solve this problem? Any further explications on why the implementation makes the training slower? ", "comments": ["Here I added some results of the experiment I have done using the MNIST dataset.\r\n\r\n\r\n\r\n\r\n\r\n       def RNN(x,weights,biaises):\r\n            x = tf.unstack(x,timesteps,1)\r\n            lstm_cell = rnn.LayerNormBasicLSTMCell(num_hidden, forget_bias=1.0,layer_norm=True)\r\n            outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\r\n            return tf.matmul(outputs[-1], weights['out']) + biases['out']\r\n\r\n\r\n\r\n\r\nThe output of the model was the following.   \r\n\r\n\r\n> Step 1, Minibatch Loss= nan, Training Accuracy= 0.070\r\nStep 200, Minibatch Loss= nan, Training Accuracy= 0.117\r\nStep 400, Minibatch Loss= nan, Training Accuracy= 0.195\r\nStep 600, Minibatch Loss= nan, Training Accuracy= 0.117\r\nStep 800, Minibatch Loss= nan, Training Accuracy= 0.086\r\nStep 1000, Minibatch Loss= nan, Training Accuracy= 0.102\r\nStep 1200, Minibatch Loss= nan, Training Accuracy= 0.109\r\nStep 1400, Minibatch Loss= nan, Training Accuracy= 0.148\r\nStep 1600, Minibatch Loss= nan, Training Accuracy= 0.133\r\nStep 1800, Minibatch Loss= nan, Training Accuracy= 0.102\r\nStep 2000, Minibatch Loss= nan, Training Accuracy= 0.086\r\nStep 2200, Minibatch Loss= nan, Training Accuracy= 0.094\r\nStep 2400, Minibatch Loss= nan, Training Accuracy= 0.062\r\nStep 2600, Minibatch Loss= nan, Training Accuracy= 0.094\r\nStep 2800, Minibatch Loss= nan, Training Accuracy= 0.094\r\nStep 3000, Minibatch Loss= nan, Training Accuracy= 0.109\r\nStep 3200, Minibatch Loss= nan, Training Accuracy= 0.086\r\nStep 3400, Minibatch Loss= nan, Training Accuracy= 0.109\r\nStep 3600, Minibatch Loss= nan, Training Accuracy= 0.148\r\nStep 3800, Minibatch Loss= nan, Training Accuracy= 0.102\r\nStep 4000, Minibatch Loss= nan, Training Accuracy= 0.117\r\nStep 4200, Minibatch Loss= nan, Training Accuracy= 0.078\r\nStep 4400, Minibatch Loss= nan, Training Accuracy= 0.102\r\nStep 4600, Minibatch Loss= nan, Training Accuracy= 0.062\r\nStep 4800, Minibatch Loss= nan, Training Accuracy= 0.078\r\nStep 5000, Minibatch Loss= nan, Training Accuracy= 0.070\r\nStep 5200, Minibatch Loss= nan, Training Accuracy= 0.062\r\nStep 5400, Minibatch Loss= nan, Training Accuracy= 0.125\r\nStep 5600, Minibatch Loss= nan, Training Accuracy= 0.109\r\nStep 5800, Minibatch Loss= nan, Training Accuracy= 0.125\r\nStep 6000, Minibatch Loss= nan, Training Accuracy= 0.062\r\nStep 6200, Minibatch Loss= nan, Training Accuracy= 0.102\r\nStep 6400, Minibatch Loss= nan, Training Accuracy= 0.094\r\nStep 6600, Minibatch Loss= nan, Training Accuracy= 0.094\r\nStep 6800, Minibatch Loss= nan, Training Accuracy= 0.102\r\nStep 7000, Minibatch Loss= nan, Training Accuracy= 0.078\r\nStep 7200, Minibatch Loss= nan, Training Accuracy= 0.148\r\nStep 7400, Minibatch Loss= nan, Training Accuracy= 0.117\r\nStep 7600, Minibatch Loss= nan, Training Accuracy= 0.125\r\nStep 7800, Minibatch Loss= nan, Training Accuracy= 0.117\r\nStep 8000, Minibatch Loss= nan, Training Accuracy= 0.102\r\nStep 8200, Minibatch Loss= nan, Training Accuracy= 0.125\r\nStep 8400, Minibatch Loss= nan, Training Accuracy= 0.062\r\nStep 8600, Minibatch Loss= nan, Training Accuracy= 0.055\r\nStep 8800, Minibatch Loss= nan, Training Accuracy= 0.094\r\nStep 9000, Minibatch Loss= nan, Training Accuracy= 0.172\r\nStep 9200, Minibatch Loss= nan, Training Accuracy= 0.078\r\nStep 9400, Minibatch Loss= nan, Training Accuracy= 0.148\r\nStep 9600, Minibatch Loss= nan, Training Accuracy= 0.086\r\nStep 9800, Minibatch Loss= nan, Training Accuracy= 0.094\r\nStep 10000, Minibatch Loss= nan, Training Accuracy= 0.078\r\nOptimization Finished!\r\nelapsed time is 6732.706034\r\nTesting Accuracy: 0.078125\r\n\r\nNow working with the BasicLSTM implementation : \r\n\r\n     def RNN(x,weights,biaises):\r\n            x = tf.unstack(x,timesteps,1)\r\n            lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\r\n            outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\r\n            return tf.matmul(outputs[-1], weights['out']) + biases['out']\r\n\r\n\r\nThe results were like the following:\r\n \r\n\r\n> Step 1, Minibatch Loss= 2.5853, Training Accuracy= 0.055\r\n> Step 200, Minibatch Loss= 2.0630, Training Accuracy= 0.344\r\n> Step 400, Minibatch Loss= 1.9385, Training Accuracy= 0.359\r\n> Step 600, Minibatch Loss= 1.8311, Training Accuracy= 0.398\r\n> Step 800, Minibatch Loss= 1.7100, Training Accuracy= 0.492\r\n> Step 1000, Minibatch Loss= 1.6623, Training Accuracy= 0.398\r\n> Step 1200, Minibatch Loss= 1.4859, Training Accuracy= 0.469\r\n> Step 1400, Minibatch Loss= 1.3768, Training Accuracy= 0.555\r\n> Step 1600, Minibatch Loss= 1.2733, Training Accuracy= 0.609\r\n> Step 1800, Minibatch Loss= 1.1450, Training Accuracy= 0.633\r\n> Step 2000, Minibatch Loss= 1.2749, Training Accuracy= 0.562\r\n> Step 2200, Minibatch Loss= 1.2194, Training Accuracy= 0.633\r\n> Step 2400, Minibatch Loss= 1.2644, Training Accuracy= 0.586\r\n> Step 2600, Minibatch Loss= 1.1235, Training Accuracy= 0.664\r\n> Step 2800, Minibatch Loss= 1.0690, Training Accuracy= 0.688\r\n> Step 3000, Minibatch Loss= 0.9766, Training Accuracy= 0.664\r\n> Step 3200, Minibatch Loss= 0.9989, Training Accuracy= 0.648\r\n> Step 3400, Minibatch Loss= 1.0919, Training Accuracy= 0.648\r\n> Step 3600, Minibatch Loss= 0.9082, Training Accuracy= 0.711\r\n> Step 3800, Minibatch Loss= 0.9113, Training Accuracy= 0.727\r\n> Step 4000, Minibatch Loss= 0.9754, Training Accuracy= 0.703\r\n> Step 4200, Minibatch Loss= 0.9138, Training Accuracy= 0.719\r\n> Step 4400, Minibatch Loss= 0.9403, Training Accuracy= 0.688\r\n> Step 4600, Minibatch Loss= 0.7376, Training Accuracy= 0.797\r\n> Step 4800, Minibatch Loss= 0.8453, Training Accuracy= 0.688\r\n> Step 5000, Minibatch Loss= 0.8530, Training Accuracy= 0.781\r\n> Step 5200, Minibatch Loss= 0.6303, Training Accuracy= 0.797\r\n> Step 5400, Minibatch Loss= 0.7195, Training Accuracy= 0.781\r\n> Step 5600, Minibatch Loss= 0.6891, Training Accuracy= 0.805\r\n> Step 5800, Minibatch Loss= 0.6978, Training Accuracy= 0.805\r\n> Step 6000, Minibatch Loss= 0.7251, Training Accuracy= 0.766\r\n> Step 6200, Minibatch Loss= 0.6651, Training Accuracy= 0.773\r\n> Step 6400, Minibatch Loss= 0.6404, Training Accuracy= 0.789\r\n> Step 6600, Minibatch Loss= 0.6093, Training Accuracy= 0.805\r\n> Step 6800, Minibatch Loss= 0.5060, Training Accuracy= 0.844\r\n> Step 7000, Minibatch Loss= 0.6833, Training Accuracy= 0.805\r\n> Step 7200, Minibatch Loss= 0.5854, Training Accuracy= 0.844\r\n> Step 7400, Minibatch Loss= 0.4906, Training Accuracy= 0.836\r\n> Step 7600, Minibatch Loss= 0.5958, Training Accuracy= 0.820\r\n> Step 7800, Minibatch Loss= 0.4900, Training Accuracy= 0.828\r\n> Step 8000, Minibatch Loss= 0.4880, Training Accuracy= 0.867\r\n> Step 8200, Minibatch Loss= 0.4877, Training Accuracy= 0.836\r\n> Step 8400, Minibatch Loss= 0.4955, Training Accuracy= 0.867\r\n> Step 8600, Minibatch Loss= 0.5071, Training Accuracy= 0.820\r\n> Step 8800, Minibatch Loss= 0.5158, Training Accuracy= 0.805\r\n> Step 9000, Minibatch Loss= 0.3802, Training Accuracy= 0.898\r\n> Step 9200, Minibatch Loss= 0.5845, Training Accuracy= 0.859\r\n> Step 9400, Minibatch Loss= 0.3615, Training Accuracy= 0.898\r\n> Step 9600, Minibatch Loss= 0.5044, Training Accuracy= 0.867\r\n> Step 9800, Minibatch Loss= 0.4280, Training Accuracy= 0.883\r\n> Step 10000, Minibatch Loss= 0.4171, Training Accuracy= 0.875\r\n> Optimization Finished!\r\n> elapsed time is 0.03865504264831543\r\n> Testing Accuracy: 0.8828125\r\n> \r\n\r\n\r\n", "@asimshankar any updates about this issue?", "here is the full code \r\n```python\r\n\"\"\" Recurrent Neural Network.\r\n\r\nA Recurrent Neural Network (LSTM) implementation example using TensorFlow library.\r\nThis example is using the MNIST database of handwritten digits (http://yann.lecun.com/exdb/mnist/)\r\n\r\nLinks:\r\n    [Long Short Term Memory](http://deeplearning.cs.cmu.edu/pdfs/Hochreiter97_lstm.pdf)\r\n    [MNIST Dataset](http://yann.lecun.com/exdb/mnist/).\r\n\r\nAuthor: Aymeric Damien\r\nProject: https://github.com/aymericdamien/TensorFlow-Examples/\r\n\"\"\"\r\n\r\nfrom __future__ import print_function\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib import rnn\r\n\r\n# Import MNIST data\r\nfrom tensorflow.examples.tutorials.mnist import input_data\r\nmnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\r\n\r\n'''\r\nTo classify images using a recurrent neural network, we consider every image\r\nrow as a sequence of pixels. Because MNIST image shape is 28*28px, we will then\r\nhandle 28 sequences of 28 steps for every sample.\r\n'''\r\n\r\n# Training Parameters\r\nlearning_rate = 0.001\r\ntraining_steps = 10000\r\nbatch_size = 128\r\ndisplay_step = 200\r\n\r\n# Network Parameters\r\nnum_input = 28 # MNIST data input (img shape: 28*28)\r\ntimesteps = 28 # timesteps\r\nnum_hidden = 128 # hidden layer num of features\r\nnum_classes = 10 # MNIST total classes (0-9 digits)\r\n\r\n# tf Graph input\r\nX = tf.placeholder(\"float\", [None, timesteps, num_input])\r\nY = tf.placeholder(\"float\", [None, num_classes])\r\n\r\n# Define weights\r\nweights = {\r\n    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\r\n}\r\nbiases = {\r\n    'out': tf.Variable(tf.random_normal([num_classes]))\r\n}\r\n\r\n\r\ndef RNN(x, weights, biases):\r\n\r\n    # Prepare data shape to match `rnn` function requirements\r\n    # Current data input shape: (batch_size, timesteps, n_input)\r\n    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\r\n\r\n    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\r\n    x = tf.unstack(x, timesteps, 1)\r\n\r\n    # Define a lstm cell with tensorflow\r\n    lstm_cell = rnn.LayerNormBasicLSTMCell(num_hidden, forget_bias=1.0)\r\n\r\n    # Get lstm cell output\r\n    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\r\n\r\n    # Linear activation, using rnn inner loop last output\r\n    return tf.matmul(outputs[-1], weights['out']) + biases['out']\r\n\r\nlogits = RNN(X, weights, biases)\r\nprediction = tf.nn.softmax(logits)\r\n\r\n# Define loss and optimizer\r\nloss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\r\n    logits=logits, labels=Y))\r\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\r\ntrain_op = optimizer.minimize(loss_op)\r\n\r\n# Evaluate model (with test logits, for dropout to be disabled)\r\ncorrect_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\r\naccuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\r\n\r\n# Initialize the variables (i.e. assign their default value)\r\ninit = tf.global_variables_initializer()\r\n\r\n# Start training\r\nwith tf.Session() as sess:\r\n\r\n    # Run the initializer\r\n    sess.run(init)\r\n\r\n    for step in range(1, training_steps+1):\r\n        batch_x, batch_y = mnist.train.next_batch(batch_size)\r\n        # Reshape data to get 28 seq of 28 elements\r\n        batch_x = batch_x.reshape((batch_size, timesteps, num_input))\r\n        # Run optimization op (backprop)\r\n        sess.run(train_op, feed_dict={X: batch_x, Y: batch_y})\r\n        if step % display_step == 0 or step == 1:\r\n            # Calculate batch loss and accuracy\r\n            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_x,\r\n                                                                 Y: batch_y})\r\n            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\r\n                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\r\n                  \"{:.3f}\".format(acc))\r\n\r\n    print(\"Optimization Finished!\")\r\n\r\n    # Calculate accuracy for 128 mnist test images\r\n    test_len = 128\r\n    test_data = mnist.test.images[:test_len].reshape((-1, timesteps, num_input))\r\n    test_label = mnist.test.labels[:test_len]\r\n    print(\"Testing Accuracy:\", \\\r\n        sess.run(accuracy, feed_dict={X: test_data, Y: test_label}))```", "@petrux @ebrevdo : Any advice here?\r\n\r\n(Marking as \"Community Support\" since most things in `tf.contrib` are an experimental playground and often not written/maintained by the TensorFlow maintainers. Perhaps @petrux , who originally contributed `LayerNormBasicLSTMCell` would have some advice).", "@asimshankar thanks for pointing it out! Unfortunately, I haven't been working on this piece of code since 2016. Anyway, on top of my head:\r\n1. the `nan` value for the loss means that there could be something fishy in general. \r\n2. even assuming that point 1 is not a real problem, could be that layer normalization doesn't fit this particular problem---by the way, note that in the original paper the MNIST problem is not tackled using RNNs but just layer-normalizing a FF network.", "@petrux , thank you for your answer. I have also done the layer normalization using the tf.contrib.rnn.LayerNormBasicLSTMCell in a speech-recogntition task and the model was slow, converges so early to a high loss and the accuracy decreases by the end.\r\n", "Here is [the encoder implementation ](https://github.com/vrenkens/nabu/blob/master/nabu/neuralnetworks/models/ed_encoders/listener.py)\r\nin [this line ](https://github.com/vrenkens/nabu/blob/19404f2453f43721d20ee234aeefb77801614208/nabu/neuralnetworks/models/ed_encoders/listener.py#L50) I have used a pblstm layer where the `tf.contrib.rnn.LayerNormBasicLSTMCell` cell  with `layer_norm = True`. \r\n\r\n", "I think that being slower is somehow intended, since you have more parameters to optimize and more calculation to perform. The fact that it converges faster is intended as well. At that point, you could lower you learning rate to avoid the loss in accuracy (always, just on top of my head).", "Thank you for pointing that out. Actually, I'm using a validation to tune the training learning rate. If the next two validation losses are worse than the actual validation loss, the training rate will be divided by two.\r\nSo, even taking this in account the accuracy is still way worse than the one I have without layer_normlaization.", "Another point I'm thinking of is to not use the `tf.contrib.rnn.LayerNormBasicLSTMCell`  but instead use `tf.contrib.layers.layer_norm` in the level of layer's output of my encoder/decoder. Would that make a sense?", "See also:\n\nhttps://github.com/tensorflow/tensorflow/pull/15861\n\nOn Thu, Sep 6, 2018, 1:05 AM Aziz <notifications@github.com> wrote:\n\n> Another point I'm thinking of is to not use the\n> tf.contrib.rnn.LayerNormBasicLSTMCell in my layers but instead use\n> tf.contrib.layers.layer_norm in the layers of my encoder/decoder. Would\n> that make a sense?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/21929#issuecomment-419003278>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim6FsQeakl1Jj5AnUtnBk9K8dLFzrks5uYNdKgaJpZM4WQAIm>\n> .\n>\n", "Yes, I have considered his pull request and I got the same performance as the one we have.", "Looks like we're getting into the black magic of nn tweaking. It's not\nclear that there's a bug in the layer itself but rather likely that\ntweaking hyperparams or using layer norm elsewhere is the right approach.\nIf you set the learning rrate to 0 or very small, do you still get\ninstabilities?  If not, then it's unlikely to be caused by the layer.\n\nOn Thu, Sep 6, 2018, 7:41 AM Aziz <notifications@github.com> wrote:\n\n> Yes, I have considered his pull request and I got the same performance as\n> the one we have.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/21929#issuecomment-419119012>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim8VoD7vfbzF6aGvUKGCLUB1IfNSSks5uYTQjgaJpZM4WQAIm>\n> .\n>\n", "I have set the learning rate to `0.000001` and the results were the same with the `tf.contrib.rnn.LayerNormBasicLSTMCell`. \r\nThe model (using the MNIST dataset ) terminates with an accuracy of `0.078125`.\r\nThe idea of using the layer norm elsewhere seems to be working pretty good in the case of the speech-recognition task ( the model is much faster and the accuracy are good, still training!!!)\r\n", "Probably because speech recognition is an actual _recurrent_ problem. Maybe you might want to train a FF network on MNIST data and try to layer normalize?---like in the original paper.", "I will try it and let you updated.\r\nthank you ", "This is a simple neural network with 5 layers on the MNIST dataset.\r\nAt each layer I applied layer normalization using `tf.contrib.layers.layer_norm`\r\n\r\n```python\r\nfrom tensorflow.examples.tutorials.mnist import input_data\r\nimport tensorflow as tf\r\n\r\nbatch_size = 100\r\nlearning_rate = 0.003\r\ntraining_epoch = 10\r\n\r\nmnist = input_data.read_data_sets('data', one_hot=True)\r\n\r\nX_ = tf.placeholder(tf.float32, [None, 784])\r\nY_ = tf.placeholder(tf.float32, [None, 10])\r\n\r\nL = 200\r\nM = 100\r\nN = 60\r\nO = 30\r\n\r\nX = tf.reshape(X_, [-1, 784])\r\nW1 = tf.Variable(tf.truncated_normal([784, L], stddev=0.1))\r\nB1 = tf.Variable(tf.ones([L])/10)\r\nW2 = tf.Variable(tf.truncated_normal([L, M], stddev=0.1))\r\nB2 = tf.Variable(tf.ones([M])/10)\r\nW3 = tf.Variable(tf.truncated_normal([M, N], stddev=0.1))\r\nB3 = tf.Variable(tf.ones([N])/10)\r\nW4 = tf.Variable(tf.truncated_normal([N, O], stddev=0.1))\r\nB4 = tf.Variable(tf.ones(O)/10)\r\nW5 = tf.Variable(tf.truncated_normal([O, 10], stddev=0.1))\r\nB5 = tf.Variable(tf.zeros(10))\r\n\r\nY1 = tf.nn.relu(tf.matmul(X, W1) + B1)\r\nY1 = tf.contrib.layers.layer_norm(Y1)\r\nY2 = tf.nn.relu(tf.matmul(Y1, W2) + B2)\r\nY2 = tf.contrib.layers.layer_norm(Y2)\r\nY3 = tf.nn.relu(tf.matmul(Y2, W3) + B3)\r\nY3 = tf.contrib.layers.layer_norm(Y3)\r\nY4 = tf.nn.relu(tf.matmul(Y3, W4) + B4)\r\nY4 = tf.contrib.layers.layer_norm(Y4)\r\nYlogits = tf.matmul(Y4, W5) + B5\r\nY = tf.nn.softmax(Ylogits)\r\n\r\n\r\ncross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=Y_, logits=Ylogits))\r\ncorrect_prediction = tf.equal(tf.argmax(Y, 1), tf.argmax(Y_, 1))\r\naccuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\r\ntrain_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy)\r\n\r\nwith tf.Session() as sess:\r\n\tsess.run(tf.global_variables_initializer())\r\n\tfor epoch in range(training_epoch):\r\n\t\tbatch_count = int(mnist.train.num_examples/batch_size)\r\n\t\tfor i in range(batch_count):\r\n\t\t\tbatch_x, batch_y = mnist.train.next_batch(batch_size)\r\n\t\t\tsess.run([train_step], feed_dict= {X: batch_x, Y_: batch_y})\r\n\t\tprint(\"Epoch: \", epoch, \", Accuracy: \", accuracy.eval(feed_dict={X: mnist.test.images, Y_: mnist.test.labels}))\r\n\r\n```\r\nand the results were like this \r\n\r\n```\r\nEpoch:  0 , Accuracy:  0.9589\r\nEpoch:  1 , Accuracy:  0.9631\r\nEpoch:  2 , Accuracy:  0.9721\r\nEpoch:  3 , Accuracy:  0.9659\r\nEpoch:  4 , Accuracy:  0.9718\r\nEpoch:  5 , Accuracy:  0.9729\r\nEpoch:  6 , Accuracy:  0.9729\r\nEpoch:  7 , Accuracy:  0.9779\r\nEpoch:  8 , Accuracy:  0.9796\r\nEpoch:  9 , Accuracy:  0.9763\r\n```\r\nso applying the  `tf.contrib.layers.layer_norm`  works fine but applying the `tf.contrib.rnn.LayerNormBasicLSTMCell` to the MNIST dataset didn't work and maybe this is due to the nature of the problem. ", "Indeed. Please note that you were tackling the same problem with two radical different solutions. thanks for sharing the result of this latest experiment.", "The tensor2tensor team has had success with layer norm in sequential models\nbut they use it in a very different way.  It probably depends on the\nproblem domain to see where it will work.\n\nOn Fri, Sep 7, 2018, 1:50 PM Aziz <notifications@github.com> wrote:\n\n> Closed #21929 <https://github.com/tensorflow/tensorflow/issues/21929>.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/21929#event-1833724144>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim-jJnvjQeSJwXyexSuSsNYHYjEsRks5uYtwBgaJpZM4WQAIm>\n> .\n>\n", "Well, I tuned my code and now with layer normalization i have the following output  \r\n\r\n> Step 1, Minibatch Loss= 4.9653, Training Accuracy= 0.086\r\nStep 200, Minibatch Loss= 0.4167, Training Accuracy= 0.859\r\nStep 400, Minibatch Loss= 0.1636, Training Accuracy= 0.969\r\n\r\nI used instead the AdamOptimizer gradient and of course a whole different implementation of layer normalization", "> Well, I tuned my code and now with layer normalization i have the following output\r\n> \r\n> > Step 1, Minibatch Loss= 4.9653, Training Accuracy= 0.086\r\n> > Step 200, Minibatch Loss= 0.4167, Training Accuracy= 0.859\r\n> > Step 400, Minibatch Loss= 0.1636, Training Accuracy= 0.969\r\n> \r\n> I used instead the AdamOptimizer gradient and of course a whole different implementation of layer normalization\r\n\r\nHi, if you don't mind can you point to which implementation of layer norm you used? Thanks!", "I had the same issue with tf.contrib.layers.layer_norm, getting NaNs during training. Here is how I solved it: change the variance epsilon from 1e-12 to 1e-3. There seems to be some numerical instability during gradient computation when there are many layer norms in a row and the input has zero variance. In that case there will be direct division by epsilon. Unfortunately currently variance epsilon is not exposed as an argument to the tf.contrib.layer_norm, however I made a pull request to expose it recently: https://github.com/tensorflow/tensorflow/pull/25813", "If anyone is still looking for a fast LayerNorm LSTM implementation, there's one at https://github.com/lmnt-com/haste. It's much faster than `LayerNormBasicLSTMCell` because it's a single fused op."]}, {"number": 21928, "title": "Rot90ND for rotating image tensors with general shapes", "body": "This request addresses the feature request raised in [#21104](https://github.com/tensorflow/tensorflow/issues/21104)\r\n\r\nThe original feature request suggested \"a 5D [batch, height, width, depth, channels] version of tf.image.rot90.\" Rather than modify the existing rot90 function, I opted to create a more general rot90ND function which can handle image tensors with the following shapes:\r\n\r\n-   [height, width, channels]\r\n-   [height, width, depth, channels]\r\n-   [batch, height, width, channels]\r\n-   [batch, height, width, depth, channels]", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I have now signed the CLA!", "@JimBoonie could you comment exactly with `I signed it!` to retrigger the CLA check bot?", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "I have made several commits with the changes requested by @asimshankar . I believe that these changes address all of your concerns. However, if you have any more concerns, please let me know.\r\n\r\nAlso, I have an informal set of test cases to provide, but wasn't sure about how to include them into the project. Is there a formal process for including tests?", "@JimBoonie : There are unittests in `image_ops_test.py` that you can add to. https://github.com/tensorflow/tensorflow/blob/28eeda839f124cf5ba648576e86214b38141e4ab/tensorflow/python/ops/image_ops_test.py#L1300", "Thanks for your help, @asimshankar . I added a few unittests to `image_ops_test.py`, basing them off of the existing unittests for Rot90 with a few additions for this case. ", "Hi, I have been traveling but I am still working on this pull request. I will update this pull request with some changes as soon as I can.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "It has been 43 days that this pull-request has stalled. Please create a new pull-request with the requested changes."]}, {"number": 21927, "title": "AttributeError: module 'tensorflow.python.keras' has no attribute 'Model'", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: not custom code / object_detection\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary \r\n- **TensorFlow version (use command below)**: 1.4.0\r\n- **Python version**:  3.5\r\n- **CUDA/cuDNN version**: 8.0\r\n- **GPU model and memory**: \r\nArchitecture:          x86_64\r\nCPU op-mode(s):        32-bit, 64-bit\r\nByte Order:            Little Endian\r\nCPU(s):                56\r\nOn-line CPU(s) list:   0-55\r\nThread(s) per core:    2\r\nCore(s) per socket:    14\r\nSocket(s):             2\r\nNUMA node(s):          2\r\nVendor ID:             GenuineIntel\r\nCPU family:            6\r\nModel:                 79\r\nModel name:            Intel(R) Xeon(R) CPU E5-2690 v4 @ 2.60GHz\r\nStepping:              1\r\nCPU MHz:               2599.695\r\nCPU max MHz:           3500.0000\r\nCPU min MHz:           1200.0000\r\nBogoMIPS:              5189.84\r\nVirtualization:        VT-x\r\nL1d cache:             32K\r\nL1i cache:             32K\r\nL2 cache:              256K\r\nL3 cache:              35840K\r\nNUMA node0 CPU(s):     0-13,28-41\r\nNUMA node1 CPU(s):     14-27,42-55\r\nFlags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush dts acpi mmx fxsr sse sse2 ss ht tm pbe syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon pebs bts rep_good nopl xtopology nonstop_tsc aperfmperf eagerfpu pni pclmulqdq dtes64 ds_cpl vmx smx est tm2 ssse3 sdbg fma cx16 xtpr pdcm pcid dca sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch epb invpcid_single intel_pt ibrs ibpb stibp kaiser tpr_shadow vnmi flexpriority ept vpid fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm cqm rdseed adx smap xsaveopt cqm_llc cqm_occup_llc cqm_mbm_total cqm_mbm_local dtherm arat pln pts\r\n\r\n- **Exact command to reproduce**:\r\npython3 object_detection/legacy/train.py --logtostderr --train_dir=object_detection/training/ --pipeline_config_path=object_detection/training/ssd_mobilenet_v1_pets.config\r\n\r\nWhen i wanted to start training object detector i get this error even if tensorflow has valid installation. With the same configuration on tf 1.10. its working well. Is this a problem of version? was the \"Model attribute\" released after tf 1.4 version?\r\n\r\nERROR LOG:\r\nTraceback (most recent call last):\r\n  File \"object_detection/legacy/train.py\", line 51, in <module>\r\n    from object_detection.builders import model_builder\r\n  File \"/home/klapajar/cone_detection/tensorflow/models/research/object_detection/builders/model_builder.py\", line 20, in <module>\r\n    from object_detection.builders import box_predictor_builder\r\n  File \"/home/klapajar/cone_detection/tensorflow/models/research/object_detection/builders/box_predictor_builder.py\", line 18, in <module>\r\n    from object_detection.predictors import convolutional_box_predictor\r\n  File \"/home/klapajar/cone_detection/tensorflow/models/research/object_detection/predictors/convolutional_box_predictor.py\", line 18, in <module>\r\n    from object_detection.core import box_predictor\r\n  File \"/home/klapajar/cone_detection/tensorflow/models/research/object_detection/core/box_predictor.py\", line 137, in <module>\r\n    class KerasBoxPredictor(tf.keras.Model):\r\nAttributeError: module 'tensorflow.python.keras' has no attribute 'Model'", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nBazel version\nMobile device", "@kopecdav - I faced the same issue. upgrading the tensorflow version to 1.7.0 helped me. Thanks.", "I encountered the same problem when deploying a training on ml engine on google cloud platform. Any updates on this issue?", "@kopecdav Does this issue still persist ?\r\n@ViktorPot Hi, can you provide the tensorflow version you're using ?", "`pip install -U tensorflow`\r\n\r\nworked for me. It updated tensorflow to v1.11", "worked for me too.", "Feel free to close this issue if it no longer persists. Thanks !", "It has been 44 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It appears that was added in 4aef7dde40a3ffb1871d9a58aafec20711e7131f Nov 29 2018 which I think is more recently that 1.12 release. Probably means need 1.13 or something like this.", "still not resolved, my Tensorflow version is 2.0.0a0", "Here the same problem, my Tensorflow version is 2.0.0a0\r\n", "Here the same problem, my Tensorflow version is 1.4. Any responses???", "> I encountered the same problem when deploying a training on ml engine on google cloud platform. Any updates on this issue?\r\n\r\nHey @ViktorPot  \r\ndid you solve this problem?", "import tensorflow as tf\r\ntf.keras.models.Model() solves the issue", "ERROR:\r\n(tensorflow) C:\\tensorflow\\models\\research\\object_detection>python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/faster_rcnn_inception_v2_pets.config\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 54, in <module>\r\n    from object_detection.builders import model_builder\r\n  File \"C:\\tensorflow\\models\\research\\object_detection\\builders\\model_builder.py\", line 66, in <module>\r\n    from object_detection.models import ssd_efficientnet_bifpn_feature_extractor as ssd_efficientnet_bifpn\r\n  File \"C:\\tensorflow\\models\\research\\object_detection\\models\\ssd_efficientnet_bifpn_feature_extractor.py\", line 33, in <module>\r\n    from official.vision.image_classification.efficientnet import efficientnet_model\r\n  File \"C:\\tensorflow\\models\\official\\vision\\image_classification\\efficientnet\\efficientnet_model.py\", line 35, in <module>\r\n    from official.modeling import tf_utils\r\n  File \"C:\\tensorflow\\models\\official\\modeling\\tf_utils.py\", line 25, in <module>\r\n    from official.modeling import activations\r\n  File \"C:\\tensorflow\\models\\official\\modeling\\activations\\__init__.py\", line 16, in <module>\r\n    from official.modeling.activations.gelu import gelu\r\n  File \"C:\\tensorflow\\models\\official\\modeling\\activations\\gelu.py\", line 20, in <module>\r\n    @tf.keras.utils.register_keras_serializable(package='Text')\r\nAttributeError: module 'tensorflow_core.keras.utils' has no attribute 'register_keras_serializable'\r\n\r\n(tensorflow) C:\\tensorflow\\models\\research\\object_detection>"]}, {"number": 21926, "title": "got a bus error on raspberry pi", "body": "I trained my network on my mac, and predict something on my raspberry pi with keras, but I got a bus error.\r\n\r\nOS: Raspbian GNU/Linux 9\r\ntensorflow: 1.9.0\r\nkeras: 2.2.2\r\n\r\nlog info:\r\n\r\nUsing TensorFlow backend.\r\n/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.4 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\r\n  return f(*args, **kwds)\r\n/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: builtins.type size changed, may indicate binary incompatibility. Expected 432, got 412\r\n  return f(*args, **kwds)\r\n2018-08-28 14:31:25.554008: W tensorflow/core/framework/allocator.cc:108] Allocation of 63539200 exceeds 10% of system memory.\r\n2018-08-28 14:31:26.177700: W tensorflow/core/framework/allocator.cc:108] Allocation of 63539200 exceeds 10% of system memory.\r\n2018-08-28 14:31:26.345901: W tensorflow/core/framework/allocator.cc:108] Allocation of 63539200 exceeds 10% of system memory.\r\n2018-08-28 14:31:36.619646: W tensorflow/core/framework/allocator.cc:108] Allocation of 63539200 exceeds 10% of system memory.\r\n2018-08-28 14:31:36.850119: W tensorflow/core/framework/allocator.cc:108] Allocation of 63539200 exceeds 10% of system memory.\r\nBus error", "comments": ["Hello, I am having the same problem. Has anyone found a solution?\r\nI am using another network on raspberry and it works fine, but not this one.\r\nIn my case the error looks like this:\r\n\r\n\r\n2018-08-14 09:56:59.250458: W tensorflow/core/framework/allocator.cc:108] Allocation of 5677056 exceeds 10% of system memory.\r\n2018-08-14 09:56:59.288605: W tensorflow/core/framework/allocator.cc:108] Allocation of 5677056 exceeds 10% of system memory.\r\nBus error\r\n", "@Anto95 Are you using keras? Maybe it's an error about keras.", "I'm sorry I didn't  specify.\r\nI'm using tensorflow. The model which works is a 2D Cnn in pure tensorflow 1.9.0, the one which gives  the error is a 3D Cnn implemented with tensorflow but using Slim. Maybe that could be the problem.\r\n", "have the same issue @Anto95 ", "@aselle - who can address Raspberry Pi issues?", "I also had this issue, using keras and tensorflow. The problem for me was that I trained my model with tensorflow 1.10 but had 1.9 on my raspberry. I only had the \"Bus error\" log, though\r\nYou can get a prebuilt 1.10 version for raspbian stretch from https://github.com/lhelontra/tensorflow-on-arm/releases, which fixed the issue for me ", "Nagging Assignee @aselle: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 21925, "title": "tf.scatter_update gradients silently failing in eager mode", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: 1.10\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**: 0.16.0\r\n- **GCC/Compiler version (if compiling from source)**: 5.4.0\r\n- **CUDA/cuDNN version**: 8.0/6.0\r\n- **GPU model and memory**: GTX 980 4GB\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nWhen I use `tf.scatter_update` in `eager` mode, I get `None` gradients for variables that are involved in the update (not for the updated variable).   \r\nThe same code in graph mode produces an error.   \r\nThe behaviour I expect is either for the gradients to be properly computed (not sure why tensorflow can't do this), or to give the same kind of error as in graph mode.\r\n\r\n### Source code / logs\r\n```\r\nfrom __future__ import print_function\r\nimport tensorflow as tf\r\ntf.enable_eager_execution()\r\n\r\nv = tf.Variable(13.0)\r\nalpha = tf.Variable([1, 2, 3], dtype=tf.float32)\r\nidx = 1\r\nwith tf.GradientTape() as tape:\r\n    alpha = tf.scatter_update(alpha, idx, v)\r\n    loss = tf.reduce_sum(tf.square(alpha))\r\ngrads = tape.gradient(loss, [v, alpha])\r\nprint(grads)\r\n```\r\nThe output of `print(grads)` is `[None, <tf.Tensor: id=31, shape=(3,), dtype=float32, numpy=array([ 2., 26.,  6.], dtype=float32)>]`, so the gradient is not computed for `v`.\r\n\r\nIn graph mode\r\n```\r\nfrom __future__ import print_function\r\nimport tensorflow as tf\r\n\r\nv = tf.Variable(13.0)\r\nalpha = tf.Variable([1, 2, 3], dtype=tf.float32)\r\nidx = 1\r\nalpha = tf.scatter_update(alpha, idx, v)\r\nloss = tf.reduce_sum(tf.square(alpha))\r\ngrads = tf.gradients(loss, [v, alpha])\r\nprint(grads)\r\n\r\n```\r\nThe error I get: `LookupError: No gradient defined for operation 'ScatterUpdate' (op type: ScatterUpdate)`", "comments": ["@francisr Hi, for the second scenario, i.e when executed in graph mode the behavior is as expected. Please refer #2770 for more information on it.", "@tatatodd Hi, did you get a chance to look into this ?", "@francisr,\r\nSorry for the delayed response. Your code gives Expected Results when **`tf.scatter_update`** is replaced with **`tf.tensor_scatter_nd_update`**, in the Tensorflow Version, 2.4.1. Please find [the Gist](https://colab.research.google.com/gist/rmothukuru/979d9a1425d9f58db7ad9a16734ca487/gh_21925.ipynb) of the working code. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/21925\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/21925\">No</a>\n"]}, {"number": 21924, "title": "toco runs into flatbuffer 2GB limit when converting 181MB frozen graph_def", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: KDE Neon\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: master branch, rev 57919740bf151cb6395aa60e30404ee9caa066d6\r\n- **Python version**: 3.6.4\r\n- **Bazel version (if compiling from source)**: 0.16.1\r\n- **GCC/Compiler version (if compiling from source)**: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.10) 5.4.0 20160609\r\n- **CUDA/cuDNN version**: CPU-only build\r\n- **GPU model and memory**: N/A\r\n- **Mobile device**: N/A\r\n- **Exact command to reproduce**: bazel run --compilation_mode=dbg tensorflow/contrib/lite/toco:toco -- --input_file=/path/to/output_graph.pb --inference_type=FLOAT --input_arrays=input_node --input_shapes=1,16,494 --output_array=logits --output_file=/tmp/graph.tflite\r\n\r\n### Describe the problem\r\n\r\nWhen trying to convert my GraphDef file to a TFLite file using TOCO I run into the 2GB limit for flatbuffers. The frozen graph protobuf is 181MB. I've uploaded the frozen graph protobuf as well as an unfrozen pbtxt here: https://github.com/reuben/silly_hacks/releases/tag/github_as_file_hosting_service\r\n\r\n```\r\n$ bazel run --compilation_mode=dbg tensorflow/contrib/lite/toco:toco -- --input_file=/home/reuben/output_graph.pb --inference_type=FLOAT --input_arrays=input_node --input_shapes=1,16,494 --output_array=logits --output_file=/home/reuben/graph.tflite\r\nINFO: Analysed target //tensorflow/contrib/lite/toco:toco (0 packages loaded).\r\nINFO: Found 1 target...\r\nTarget //tensorflow/contrib/lite/toco:toco up-to-date:\r\n  bazel-bin/tensorflow/contrib/lite/toco/toco\r\nINFO: Elapsed time: 0.213s, Critical Path: 0.00s\r\nINFO: 0 processes.\r\nINFO: Build completed successfully, 1 total action\r\nINFO: Running command line: bazel-bin/tensorflow/contrib/lite/toco/toco '--input_file=/home/reuben/output_graph.pb' '--inference_type=FLOAT' '--input_arrays=input_node' '--input_shapes=1,16,494' '--output_INFO: Build completed successfully, 1 total action\r\n2018-08-28 10:42:03.161524: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 262 operators, 398 arrays (0 quantized)\r\n2018-08-28 10:42:03.170762: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 262 operators, 398 arrays (0 quantized)\r\n2018-08-28 10:42:11.384607: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 225 operators, 373 arrays (0 quantized)\r\n2018-08-28 10:42:11.454370: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 223 operators, 371 arrays (0 quantized)\r\n2018-08-28 10:42:11.472062: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 3: 221 operators, 367 arrays (0 quantized)\r\n2018-08-28 10:42:11.487687: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 221 operators, 367 arrays (0 quantized)\r\n2018-08-28 10:42:11.493166: I tensorflow/contrib/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 278528 bytes, theoretical optimal value: 262144 bytes.\r\n2018-08-28 10:42:11.496319: I tensorflow/contrib/lite/toco/toco_tooling.cc:394] Estimated count of arithmetic ops: 1.52158 billion (note that a multiply-add is counted as 2 ops).\r\ntoco: external/flatbuffers/include/flatbuffers/flatbuffers.h:590: size_t flatbuffers::vector_downward::ensure_space(size_t): Assertion `size() < FLATBUFFERS_MAX_BUFFER_SIZE' failed.\r\nAborted\r\n```\r\n\r\n### Source code / logs\r\n\r\nTraceback:\r\n\r\n```\r\n(gdb) bt\r\n#0  0x00007ffff46a9428 in __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:54\r\n#1  0x00007ffff46ab02a in __GI_abort () at abort.c:89\r\n#2  0x00007ffff46a1bd7 in __assert_fail_base (fmt=<optimized out>, assertion=assertion@entry=0x73cdf0 \"size() < FLATBUFFERS_MAX_BUFFER_SIZE\", file=file@entry=0x73cd28 \"external/flatbuffers/include/flatbuffers/flatbuffers.h\",\r\n    line=line@entry=590, function=function@entry=0x73d640 <flatbuffers::vector_downward::ensure_space(unsigned long)::__PRETTY_FUNCTION__> \"size_t flatbuffers::vector_downward::ensure_space(size_t)\") at assert.c:92\r\n#3  0x00007ffff46a1c82 in __GI___assert_fail (assertion=0x73cdf0 \"size() < FLATBUFFERS_MAX_BUFFER_SIZE\", file=0x73cd28 \"external/flatbuffers/include/flatbuffers/flatbuffers.h\", line=590,\r\n    function=0x73d640 <flatbuffers::vector_downward::ensure_space(unsigned long)::__PRETTY_FUNCTION__> \"size_t flatbuffers::vector_downward::ensure_space(size_t)\") at assert.c:101\r\n#4  0x00000000005baac8 in flatbuffers::vector_downward::ensure_space (this=0x7fffffffc8e0, len=0) at external/flatbuffers/include/flatbuffers/flatbuffers.h:590\r\n#5  0x00000000005baaf1 in flatbuffers::vector_downward::make_space (this=0x7fffffffc8e0, len=0) at external/flatbuffers/include/flatbuffers/flatbuffers.h:595\r\n#6  0x00000000005bacb9 in flatbuffers::vector_downward::fill (this=0x7fffffffc8e0, zero_pad_bytes=0) at external/flatbuffers/include/flatbuffers/flatbuffers.h:647\r\n#7  0x00000000005bb12e in flatbuffers::FlatBufferBuilder::Align (this=0x7fffffffc8e0, elem_size=4) at external/flatbuffers/include/flatbuffers/flatbuffers.h:840\r\n#8  0x00000000005bd1ad in flatbuffers::FlatBufferBuilder::PushElement<unsigned int> (this=0x7fffffffc8e0, element=134217728) at external/flatbuffers/include/flatbuffers/flatbuffers.h:861\r\n#9  0x00000000005bb831 in flatbuffers::FlatBufferBuilder::EndVector (this=0x7fffffffc8e0, len=134217728) at external/flatbuffers/include/flatbuffers/flatbuffers.h:1148\r\n#10 0x00000000005f6fce in flatbuffers::FlatBufferBuilder::CreateVector<unsigned char> (this=0x7fffffffc8e0,\r\n    v=0x7fff645ea010 \"\u01a2\\256<\\355\\212#\\274\\v\\261w<_\\\"\\016\\275(\\371\\254\\275\\314I\\274\\274\\206\\032\\300<\\232\\037B=~8\\236\\274\\213\\366\\036<\\020\\254\\251<\\314\\363\\360;2\\262\\360\\274\\345\\252}=\", len=134217728)\r\n    at external/flatbuffers/include/flatbuffers/flatbuffers.h:1194\r\n#11 0x00000000006af292 in toco::tflite::(anonymous namespace)::CopyBuffer<(toco::ArrayDataType)2> (array=..., builder=0x7fffffffc8e0) at tensorflow/contrib/lite/toco/tflite/types.cc:56\r\n#12 0x00000000006aec36 in toco::tflite::DataBuffer::Serialize (array=..., builder=0x7fffffffc8e0) at tensorflow/contrib/lite/toco/tflite/types.cc:141\r\n#13 0x00000000005b9a88 in toco::tflite::ExportBuffers (model=..., buffers_to_write=std::vector of length 368, capacity 512 = {...}, builder=0x7fffffffc8e0) at tensorflow/contrib/lite/toco/tflite/export.cc:307\r\n#14 0x00000000005ba1b2 in toco::tflite::Export (model=..., allow_custom_ops=false, output_file_contents=0x7fffffffd070, ops_by_type=std::map with 80 elements = {...}) at tensorflow/contrib/lite/toco/tflite/export.cc:387\r\n#15 0x00000000005b9b5c in toco::tflite::Export (model=..., allow_custom_ops=false, output_file_contents=0x7fffffffd070) at tensorflow/contrib/lite/toco/tflite/export.cc:317\r\n#16 0x000000000052eae2 in toco::Export (toco_flags=..., model=..., allow_custom_ops=false, output_file_contents=0x7fffffffd070) at tensorflow/contrib/lite/toco/toco_tooling.cc:407\r\n#17 0x00000000005135fa in toco::(anonymous namespace)::ToolMain (parsed_toco_flags=..., parsed_model_flags=...) at tensorflow/contrib/lite/toco/toco.cc:90\r\n#18 0x00000000005138fe in main (argc=1, argv=0x7fffffffd9e8) at tensorflow/contrib/lite/toco/toco.cc:127\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nGPU model and memory\nMobile device", "I've updated the issue.", "Thanks for the report @reuben . There was a similar issue reported internally that turned out to be related to some conflicting flatbuffer symbols (see also [this patch](https://github.com/tensorflow/tensorflow/commit/22e855159462b502dc3af138d254214bd02cf68b#diff-12251921ed1d6cc4b14367cfba47de82)). It's not clear if the issues are related, will take a look.", "Also, just to confirm, do you also hit this issue if you use `--compilation_mode=opt` instead of `--compilation_mode=dbg`?", "Hey @jdduke. Thanks, I'll try with the patch. Yes, it also happens with an optimized build, except then it's just a segfault.", "I'm able to repro locally with the latest builds, so this appears to be a separate (and definitely legit) issue.", "Reassigning as this looks like it could be an issue with LSTM conversion.", "Thanks @jdduke @miaout17, would you know how we might be able to help on that ?", "We are still investigating the best fixes internally, but as an immediate work-around, you can pass:\r\n\r\n--dedupe_array_min_size_bytes=1000\r\n\r\nthis allows your command to complete and the resulting .tflite file size is 188939536 bytes.\r\n\r\n", "Oh, neat, thanks! I'll give it a try.", "Fixes are going through integration at the moment so expect them soon in this repository. Once they land, the default behavior will be equivalent to --dedupe_array_min_size_bytes=64, and your command line should work as-is.", "The problem should be closed after commit 5330ede39fa2f1f7b3302bc316061baf180fab44. \r\nDo you mind to try this again? Thanks!", "Thanks, we'll keep you posted, but so far I know that @reuben was able to properly generate the model :)", "@miaout17 It seems that this issue is indeed properly fixed, but we'll likely have to open new ones :)"]}, {"number": 21922, "title": "TF_GraphImportGraphDef fails with no input mapping on existing nodes", "body": "### System information\r\n\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: linux, ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.10\r\n- **Python version**:  3.5.2\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n\r\n### Describe the problem\r\n\r\nUsing `TF_GraphImportGraphDef` to incrementally build a graph (using NodeDefs instead of the extensive `TF_OperationDescription* ` API) returns a `TF_Status` error code (3) with message  **Unknown input node** when a node currently being imported has an input node who is  not in the current import call, but already in the graph.\r\n\r\n\r\n### Source code / logs\r\n\r\nI would assume that it would be okay to import a node whose inputs are already in the graph.\r\n\r\nIf this assumption is correct the problem arises from line 529 In [graph_constructor.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/graph/graph_constructor.cc):\r\n\r\n```\r\nfor (int i = 0; i < node_def.input_size(); ++i) {\r\n      StringPiece input_name = node_def.input(i);\r\n      TensorId id(ParseTensorName(input_name));\r\n      if (opts_.input_map.count(id) == 0) {\r\n        // If an input is not mapped, then the input should appear in the graph\r\n        // being imported.\r\n        auto iter = gdef_nodes_.find(id.first);\r\n        if (iter == gdef_nodes_.end()) {\r\n          return errors::InvalidArgument(\"Node '\", node_def.name(),\r\n                                         \"': Unknown input node '\",\r\n                                         node_def.input(i), \"'\");\r\n        }\r\n        outputs_[iter->second.gdef_index].push_back(n);\r\n      } else {\r\n        // This input is mapped to an existing edge. Therefore this input is\r\n        // as good as being already processed.\r\n        --pending_count;\r\n        DCHECK_GE(pending_count, 0);\r\n      }\r\n    }\r\n```\r\n\r\nWhere if no mapping was supplied using `TF_ImportGraphDefOptionsAddInputMapping`, the validation check assumes the input nodes exist in the current import call, along side the node being imported itself, without bothering to check if the graph might already contain these nodes (which is the assumption when a mapping IS supplied).\r\n\r\nThis means that when importing a graph, unnecessary input mappings have to be supplied.\r\n\r\n", "comments": ["We see that you are using old version of Tensorflow which is officially considered as end of life, We recommend that you upgrade to 2.4 or later version and let us know if the issue still persists in newer versions .Please open a new issue in case you face any errors, we will get you the right help .Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 21921, "title": " Tensorflow lite model gives very different accuracy value compared to python model", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: No\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.10\r\n- **Python version**:3.6\r\n- **Bazel version (if compiling from source)**: 0.16.0\r\n- **CUDA/cuDNN version**:N/A\r\n- **GPU model and memory**:N/A\r\n- **Exact command to reproduce**: See Source Code\r\n\r\n### Describe the problem\r\nI am using tensorflow 1.10 Python 3.6\r\n\r\nMy code is based in the premade iris classification model provided by TensorFlow. This means, I am using a Tensorflow DNN premade classifier, with the difference following difference:\r\n\r\n10 features instead 4.\r\n5 classes instead 3.\r\nThe test and training files can be downloaded from the following link: https://www.dropbox.com/sh/nmu8i2i8xe6hvfq/AADQEOIHH8e-kUHQf8zmmDMDa?dl=0\r\n\r\nI have made a code to export this classifier to a tflite format, however the accuracy in the python model is higher than 75% but when exported the accuracy decrease approximately to 45% this means approximately 30% Accuracy is lost (This is too much). I have tried the code with different set of data and in all of them the accuracy after exporting decrease a lot! This made me think that something is going wrong with the TocoConverter function or that maybe I am exporting to tflite incorrectly, missing a parameter or something like that.\r\n\r\nI share the code in which I calculate also the accuracy of the .tflite file.\r\n\r\nI hope some of you can identify the error, or give a possible solution\r\n\r\n### Source code / logs\r\n\r\n```\r\nimport argparse\r\nimport tensorflow as tf\r\n\r\nimport pandas as pd\r\nimport csv\r\n\r\nfrom tensorflow.python.tools import freeze_graph\r\nfrom tensorflow.python.tools import optimize_for_inference_lib\r\nimport numpy as np\r\n\r\n\r\nparser = argparse.ArgumentParser()\r\nparser.add_argument('--batch_size', default=100, type=int, help='batch size')\r\nparser.add_argument('--train_steps', default=1000, type=int,\r\n                    help='number of training steps')\r\n\r\nfeatures_global = None\r\nfeature_spec = None\r\n\r\nMODEL_NAME = 'myModel'\r\n\r\ndef load_data(train_path, test_path):\r\n    \"\"\"Returns the iris dataset as (train_x, train_y), (test_x, test_y).\"\"\"\r\n\r\n    with open(train_path, newline='') as f:\r\n        reader = csv.reader(f)\r\n        column_names = next(reader)\r\n\r\n    y_name = column_names[-1]\r\n\r\n    train = pd.read_csv(train_path, names=column_names, header=0)\r\n    train_x, train_y = train, train.pop(y_name)\r\n\r\n    test = pd.read_csv(test_path, names=column_names, header=0)\r\n    test_x, test_y = test, test.pop(y_name)\r\n\r\n    return (train_x, train_y), (test_x, test_y)\r\n\r\n\r\ndef train_input_fn(features, labels, batch_size):\r\n    \"\"\"An input function for training\"\"\"\r\n    # Convert the inputs to a Dataset.\r\n    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\r\n\r\n    # Shuffle, repeat, and batch the examples.\r\n    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\r\n\r\n    # Return the dataset.\r\n    return dataset\r\n\r\n\r\ndef eval_input_fn(features, labels, batch_size):\r\n    \"\"\"An input function for evaluation or prediction\"\"\"\r\n    features=dict(features)\r\n    if labels is None:\r\n        # No labels, use only features.\r\n        inputs = features\r\n    else:\r\n        inputs = (features, labels)\r\n\r\n    # Convert the inputs to a Dataset.\r\n    dataset = tf.data.Dataset.from_tensor_slices(inputs)\r\n\r\n    # Batch the examples\r\n    assert batch_size is not None, \"batch_size must not be None\"\r\n    dataset = dataset.batch(batch_size)\r\n\r\n    # Return the dataset.\r\n    return dataset\r\n\r\n\r\ndef main(argv):\r\n    args = parser.parse_args(argv[1:])\r\n\r\n    train_path = \"trainData.csv\"\r\n    test_path = \"testData.csv\"\r\n\r\n    # Fetch the data\r\n    (train_x, train_y), (test_x, test_y) = load_data(train_path, test_path)\r\n\r\n    # Load labels\r\n    num_labels = 5\r\n\r\n    # Feature columns describe how to use the input.\r\n    my_feature_columns = []\r\n    for key in train_x.keys():\r\n        my_feature_columns.append(tf.feature_column.numeric_column(key=key))\r\n\r\n    # Build 2 hidden layer DNN\r\n    classifier = tf.estimator.DNNClassifier(\r\n        feature_columns=my_feature_columns,\r\n        # Two hidden layers of 10 nodes each.\r\n        hidden_units=[100, 500],\r\n        # The model must choose between 'num_labels' classes.\r\n        optimizer=tf.train.AdagradOptimizer(learning_rate=0.003),\r\n        n_classes=num_labels,\r\n        model_dir=\"myModel\")\r\n\r\n    # Train the Model\r\n    classifier.train(\r\n        input_fn=lambda:train_input_fn(train_x, train_y,\r\n                                                args.batch_size),\r\n        steps=args.train_steps)\r\n\r\n    # Evaluate the model.\r\n    eval_result = classifier.evaluate(\r\n        input_fn=lambda:eval_input_fn(test_x, test_y,\r\n                                                args.batch_size))\r\n\r\n    print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))\r\n\r\n    # Export model\r\n    feature_spec = tf.feature_column.make_parse_example_spec(my_feature_columns)\r\n    serve_input_fun = tf.estimator.export.build_parsing_serving_input_receiver_fn(feature_spec)\r\n    saved_model_path = classifier.export_savedmodel(\r\n            export_dir_base=\"out\",\r\n            serving_input_receiver_fn=serve_input_fun,\r\n            as_text=True,\r\n            checkpoint_path=classifier.latest_checkpoint(),\r\n        )\r\n    tf.reset_default_graph()\r\n    var = tf.Variable(0)\r\n    with tf.Session() as sess:\r\n        # First let's load meta graph and restore weights\r\n        sess.run(tf.global_variables_initializer())\r\n        latest_checkpoint_path = classifier.latest_checkpoint()\r\n        saver = tf.train.import_meta_graph(latest_checkpoint_path + '.meta')\r\n        saver.restore(sess, latest_checkpoint_path)\r\n\r\n        input_arrays = [\"dnn/input_from_feature_columns/input_layer/concat\"]\r\n        output_arrays = [\"dnn/logits/BiasAdd\"]\r\n\r\n        frozen_graph_def = tf.graph_util.convert_variables_to_constants(\r\n            sess, sess.graph_def,\r\n            output_node_names=[\"dnn/logits/BiasAdd\"])\r\n\r\n        frozen_graph = \"out/frozen_graph.pb\"\r\n\r\n        with tf.gfile.FastGFile(frozen_graph, \"wb\") as f:\r\n                f.write(frozen_graph_def.SerializeToString())\r\n\r\n        # save original graphdef to text file\r\n        with open(\"estimator_graph.pbtxt\", \"w\") as fp:\r\n            fp.write(str(sess.graph_def))\r\n        # save frozen graph def to text file\r\n        with open(\"estimator_frozen_graph.pbtxt\", \"w\") as fp:\r\n            fp.write(str(frozen_graph_def))\r\n\r\n        input_node_names = input_arrays\r\n        output_node_name = output_arrays\r\n        output_graph_def = optimize_for_inference_lib.optimize_for_inference(\r\n                frozen_graph_def, input_node_names, output_node_name,\r\n                tf.float32.as_datatype_enum)\r\n\r\n        final_model_path = 'out/opt_' + MODEL_NAME + '.pb'\r\n        with tf.gfile.FastGFile(final_model_path, \"wb\") as f:\r\n            f.write(output_graph_def.SerializeToString())\r\n\r\n        tflite_file = \"out/iris.tflite\"\r\n\r\n        converter = tf.contrib.lite.TocoConverter.from_frozen_graph(final_model_path, input_arrays, output_arrays, input_shapes={\"dnn/input_from_feature_columns/input_layer/concat\": [1, 10]})\r\n        tflite_model = converter.convert()\r\n        open(tflite_file, \"wb\").write(tflite_model)\r\n\r\n        interpreter = tf.contrib.lite.Interpreter(model_path=tflite_file)\r\n        interpreter.allocate_tensors()\r\n\r\n        # Get input and output tensors.\r\n        input_details = interpreter.get_input_details()\r\n        output_details = interpreter.get_output_details()\r\n\r\n        # Test model on random input data.\r\n        input_shape = input_details[0]['shape']\r\n        # change the following line to feed into your own data.\r\n        input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\r\n        resultlist = list()\r\n        df = pd.read_csv(test_path)\r\n        expected = df.iloc[:, -1].values.tolist()\r\n        with open(test_path, newline='') as f:\r\n            reader = csv.reader(f)\r\n            column_names = next(reader)\r\n            for x in range(1, len(expected)):\r\n                linea = next(reader)\r\n                linea = linea[:len(linea) - 1]\r\n                input_data2 = np.array(linea, dtype=np.float32)\r\n                interpreter.set_tensor(input_details[0]['index'], [input_data2])\r\n                interpreter.invoke()\r\n                output_data = interpreter.get_tensor(output_details[0]['index'])\r\n                #print(output_data)\r\n                max = 0;\r\n                longitud = len(output_data[0])\r\n\r\n                for k in range(0, longitud):\r\n                    if (output_data[0][k] > output_data[0][max]):\r\n                        max = k\r\n                resultlist.append(max)\r\n            print(resultlist)\r\n\r\n        coincidences = 0\r\n        for pred_dict, expec in zip(resultlist, expected):\r\n            if pred_dict == expec:\r\n                coincidences = coincidences + 1\r\n\r\n        print(\"tflite Accuracy: \" + str(coincidences / len(expected)))\r\n\r\n\r\nif __name__ == '__main__':\r\n    tf.logging.set_verbosity(tf.logging.INFO)\r\n    tf.app.run(main)\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Fields Updated", "I also noticed that tflite produces worse results. I am not sure it's that huge (75 VS 45) though.\r\nThe commands I used to convert to tflite are:\r\n\r\ntf_models/research/object_detection/export_tflite_ssd_graph.py \\\r\n    --pipeline_config_path=data/gen/coco/ssdlite_mobilenet_v2.config \\\r\n    --trained_checkpoint_prefix=data/gen/coco/ssdlite_mobilenet_v2/model.ckpt-66366 \\\r\n    --output_directory=data/gen/coco/ssdlite_mobilenet_v2_exported --add_postprocessing_op=true\r\n\r\nbazel run --config=opt tensorflow/contrib/lite/toco:toco -- --input_file=/home/chao/projects/tf-object-detect/train/data/gen/coco/ssdlite_mobilenet_v2_exported/tflite_graph.pb --output_file=/home/chao/projects/tf-object-detect/train/data/gen/coco/ssdlite_mobilenet_v2_exported/detect.tflite --input_shapes=1,300,300,3 --input_arrays=normalized_input_image_tensor --output_arrays=TFLite_Detection_PostProcess,TFLite_Detection_PostProcess:1,TFLite_Detection_PostProcess:2,TFLite_Detection_PostProcess:3 --inference_type=FLOAT --allow_custom_ops\r\n", "@YijinLiu I am encountered with it, too.  I selected ssdlite_mobilenet_v2.config  to train and eval the model, then converted the ckpt to pb and pb to tflite step by step according to the doc, but at last it gave the worse results compared to the pb that was generated by export_inference_graph.py\r\npython 3.6.6\r\ntensorflow 1.10.0\r\nbazel 0.15.2", "Hi, guys @YijinLiu @jimenisimo I solved my problem by adding the std and mean to the input data though I did not give the  \"--mean_values=128     --std_values=128\" when using bazel compile.\r\nWhen inferring the image, 'input_data = np.expand_dims((input_data - args.input_mean) / args.input_std, axis=0)' should be given , and the input_mean is 128/ std is 128.\r\n---------------------------------------------------------------------------------------------------------------\r\nerrrrrrr, finally I check the source code and find the comment first:\r\n\"In floating point Mobilenet model, 'normalized_image_tensor' has values\r\nbetween [-1,1). This typically means mapping each pixel (linearly)\r\nto a value between [-1, 1]. Input image\r\nvalues between 0 and 255 are scaled by (1/128.0) and then a value of\r\n-1 is added to them to ensure the range is [-1,1).\r\nIn quantized Mobilenet model, 'normalized_image_tensor' has values between [0,\r\n255].\"\r\nIn the \r\n1\u3001\"export_tflite_graph.py->predicted_tensors = detection_model.predict(image, true_image_shapes=None)\"\r\n2\u3001\"model_builder.py->'ssd_mobilenet_v2': SSDMobileNetV2FeatureExtractor,\"\r\n3\u3001\"SSDMobileNetV2FeatureExtractor.py->def preprocess(self, resized_inputs):return (2.0 / 255.0) * resized_inputs - 1.0\"\r\nWhere the normalization was done, but not for tflite, it is for \"export_inference_graph.py\". So careless I am, sorry guys.", "+Suharsh for additional guidance.", "@hequn I have no idea how to implement your solution in my code, could you help me, have you tried my code?", "@jimenisimo These codes mentioned above are not my codes, they are in the research module 'object_detection', you may go into that and check the source codes. \r\nSorry, I haven't tried you code, but it seems the acc from 75% to 45% is not similar with the situation in my test.  ", "Once resolved, see [jimenisimo's stackoverflow post](https://stackoverflow.com/questions/52057552/tensorflow-lite-model-gives-very-different-accuracy-value-compared-to-python-mod ) for closing also. There are a number of people who have upvoted it.", "It seems to me that tflite is not able to detect objects overlap with other objects. I hope this is a bug instead of a fundamental problem of tensorflow lite's object detection postprocess implementation.", "I haven't tried to change the code to verify my story yet. Still struggling to understand it. However, it looks like a bad implementation. See https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/kernels/detection_postprocess.cc#L574", "After playing with detection_postprocess.cc a bit, I don't think these missing overlapped objects are caused by Detection_PostProcess. They don't even exist in Detection_PostProcess's input.", "@YijinLiu : @achowdhery is most familiar with export_ssd script and the conversion process. \r\n\r\nCan we move the ssd discussion to a separate thread since it's unrelated to the issue that @jimenisimo has?", "Nagging Assignees @suharshs, @achowdhery: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@YijinLiu Please file a new issue. Thanks.\r\n\r\n@jimenisimo: Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "@suharshs  @achowdhery Has there been any update about this issue? I see the same issue with tensorflow 1.10. The accuracy drops significantly (> 10%) when a frozen graph (50k steps with quantized-aware training kicking in at 48k steps) is converted to tflite using toco. The model is ssd_mobilenetv2 and it was trained with TF Object Detection API."]}]