[{"number": 22460, "title": "Feature Request: GRUBlockFusedCell in tf.contrib.rnn", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: /  \r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.10.0\r\n- **Python version**: 3.6.0\r\n- **Bazel version (if compiling from source)**: /\r\n- **GCC/Compiler version (if compiling from source)**: /\r\n- **CUDA/cuDNN version**: /  \r\n- **GPU model and memory**: /  \r\n- **Exact command to reproduce**: /  \r\n\r\n### Describe the problem\r\nFused RNN cells provide much better performance. Currently only tf.contrib.rnn.LSTMBlockFusedCell is provided. More, tf.contrib.cudnn_rnn.CudnnGRU, which has similar performance with typical FusedCell, is incompatible with normal GRUCell due to differences in computing mechanisms, hence pretrained GRU parameters cannot be used by CudnnGRU. So I wonder if a fused version of GRUCell could be implemented.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nBazel version", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 22459, "title": "[bazel] Unrecoverable error while evaluating node '//tensorflow/cc:ops/io_ops_gen_cc", "body": "I am running bazel  0.17.2 on Windows 7, with the following command:\r\nbazel build tensorflow/examples/wav_to_spectrogram/...\r\n\r\nThe output:\r\n\r\nc:\\tensorflow-master>bazel build tensorflow/examples/wav_to_spectrogram/...\r\nLoading:\r\nLoading: 0 packages loaded\r\nDEBUG: C:/users/me/_bazel_me/cxy76ymx/external/bazel_tools/tools/cpp/lib_cc_conf\r\nigure.bzl:115:5:\r\nAuto-Configuration Warning: 'BAZEL_VC' is not set, start looking for the latest\r\nVisual C++ installed.\r\nDEBUG: C:/users/me/_bazel_me/cxy76ymx/external/bazel_tools/tools/cpp/lib_cc_conf\r\nigure.bzl:115:5:\r\nAuto-Configuration Warning: Looking for VS%VERSION%COMNTOOLS environment variabl\r\nes, eg. VS140COMNTOOLS\r\nDEBUG: C:/users/me/_bazel_me/cxy76ymx/external/bazel_tools/tools/cpp/lib_cc_conf\r\nigure.bzl:115:5:\r\nAuto-Configuration Warning: Visual C++ build tools found at C:\\Program Files (x8\r\n6)\\Microsoft Visual Studio 12.0\\VC\\\r\nAnalyzing: 3 targets (0 packages loaded)\r\nAnalyzing: 3 targets (0 packages loaded)\r\nAnalyzing: 3 targets (1 packages loaded)\r\nWARNING: C:/tensorflow-master/tensorflow/core/BUILD:2501:1: in includes attribut\r\ne of cc_library rule //tensorflow/core:framework_internal_headers_lib: '../../ex\r\nternal/com_google_absl' resolves to 'external/com_google_absl' not below the rel\r\native path of its package 'tensorflow/core'. This will be an error in the future\r\n. Since this rule was created by the macro 'cc_header_only_library', the error m\r\night have been caused by the macro implementation in C:/tensorflow-master/tensor\r\nflow/tensorflow.bzl:1376:20\r\nWARNING: C:/tensorflow-master/tensorflow/core/BUILD:2587:1: in includes attribut\r\ne of cc_library rule //tensorflow/core:framework_headers_lib: '../../external/co\r\nm_google_absl' resolves to 'external/com_google_absl' not below the relative pat\r\nh of its package 'tensorflow/core'. This will be an error in the future. Since t\r\nhis rule was created by the macro 'cc_header_only_library', the error might have\r\n been caused by the macro implementation in C:/tensorflow-master/tensorflow/tens\r\norflow.bzl:1376:20\r\nUnhandled exception thrown during build; message: Unrecoverable error while eval\r\nuating node '//tensorflow/cc:ops/io_ops_gen_cc BuildConfigurationValue.Key[ac98f\r\n5975123fd6eeb07a7415b6161fb] true' (requested by nodes '//tensorflow/cc:io_ops_g\r\nenrule BuildConfigurationValue.Key[6a75becf8194103d260d4e5a345be2c2] false')\r\nINFO: Elapsed time: 31.631s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (2 packages loaded)\r\njava.lang.RuntimeException: Unrecoverable error while evaluating node '//tensorf\r\nlow/cc:ops/io_ops_gen_cc BuildConfigurationValue.Key[ac98f5975123fd6eeb07a7415b6\r\n161fb] true' (requested by nodes '//tensorflow/cc:io_ops_genrule BuildConfigurat\r\nionValue.Key[6a75becf8194103d260d4e5a345be2c2] false')\r\n        at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate\r\n.run(AbstractParallelEvaluator.java:497)\r\n        at com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$Wrapped\r\nRunnable.run(AbstractQueueVisitor.java:368)\r\n        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown S\r\nource)\r\n        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown\r\nSource)\r\n        at java.base/java.lang.Thread.run(Unknown Source)\r\nCaused by: java.lang.IllegalStateException\r\n        at com.google.common.base.Preconditions.checkState(Preconditions.java:49\r\n1)\r\n        at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.addD\r\nynamicInputLinkOptions(LibrariesToLinkCollector.java:290)\r\n        at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.addL\r\ninkerInputs(LibrariesToLinkCollector.java:258)\r\n        at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.coll\r\nectLibrariesToLink(LibrariesToLinkCollector.java:203)\r\n        at com.google.devtools.build.lib.rules.cpp.CppLinkActionBuilder.build(Cp\r\npLinkActionBuilder.java:916)\r\n        at com.google.devtools.build.lib.rules.cpp.CcBinary.init(CcBinary.java:4\r\n13)\r\n        at com.google.devtools.build.lib.rules.cpp.CcBinary.create(CcBinary.java\r\n:179)\r\n        at com.google.devtools.build.lib.rules.cpp.CcBinary.create(CcBinary.java\r\n:71)\r\n        at com.google.devtools.build.lib.analysis.ConfiguredTargetFactory.create\r\nRule(ConfiguredTargetFactory.java:320)\r\n        at com.google.devtools.build.lib.analysis.ConfiguredTargetFactory.create\r\nConfiguredTarget(ConfiguredTargetFactory.java:205)\r\n        at com.google.devtools.build.lib.skyframe.SkyframeBuildView.createConfig\r\nuredTarget(SkyframeBuildView.java:631)\r\n        at com.google.devtools.build.lib.skyframe.ConfiguredTargetFunction.creat\r\neConfiguredTarget(ConfiguredTargetFunction.java:770)\r\n        at com.google.devtools.build.lib.skyframe.ConfiguredTargetFunction.compu\r\nte(ConfiguredTargetFunction.java:320)\r\n        at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate\r\n.run(AbstractParallelEvaluator.java:420)\r\n        ... 4 more\r\njava.lang.RuntimeException: Unrecoverable error while evaluating node '//tensorf\r\nlow/cc:ops/io_ops_gen_cc BuildConfigurationValue.Key[ac98f5975123fd6eeb07a7415b6\r\n161fb] true' (requested by nodes '//tensorflow/cc:io_ops_genrule BuildConfigurat\r\nionValue.Key[6a75becf8194103d260d4e5a345be2c2] false')\r\n        at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate\r\n.run(AbstractParallelEvaluator.java:497)\r\n        at com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$Wrapped\r\nRunnable.run(AbstractQueueVisitor.java:368)\r\n        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown S\r\nource)\r\n        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown\r\nSource)\r\n        at java.base/java.lang.Thread.run(Unknown Source)\r\nCaused by: java.lang.IllegalStateException\r\n        at com.google.common.base.Preconditions.checkState(Preconditions.java:49\r\n1)\r\n        at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.addD\r\nynamicInputLinkOptions(LibrariesToLinkCollector.java:290)\r\n        at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.addL\r\ninkerInputs(LibrariesToLinkCollector.java:258)\r\n        at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.coll\r\nectLibrariesToLink(LibrariesToLinkCollector.java:203)\r\n        at com.google.devtools.build.lib.rules.cpp.CppLinkActionBuilder.build(Cp\r\npLinkActionBuilder.java:916)\r\n        at com.google.devtools.build.lib.rules.cpp.CcBinary.init(CcBinary.java:4\r\n13)\r\n        at com.google.devtools.build.lib.rules.cpp.CcBinary.create(CcBinary.java\r\n:179)\r\n        at com.google.devtools.build.lib.rules.cpp.CcBinary.create(CcBinary.java\r\n:71)\r\n        at com.google.devtools.build.lib.analysis.ConfiguredTargetFactory.create\r\nRule(ConfiguredTargetFactory.java:320)\r\n        at com.google.devtools.build.lib.analysis.ConfiguredTargetFactory.create\r\nConfiguredTarget(ConfiguredTargetFactory.java:205)\r\n        at com.google.devtools.build.lib.skyframe.SkyframeBuildView.createConfig\r\nuredTarget(SkyframeBuildView.java:631)\r\n        at com.google.devtools.build.lib.skyframe.ConfiguredTargetFunction.creat\r\neConfiguredTarget(ConfiguredTargetFunction.java:770)\r\n        at com.google.devtools.build.lib.skyframe.ConfiguredTargetFunction.compu\r\nte(ConfiguredTargetFunction.java:320)\r\n        at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate\r\n.run(AbstractParallelEvaluator.java:420)\r\n        ... 4 more\r\nFAILED: Build did NOT complete successfully (2 packages loaded)\r\n\r\nServer terminated abruptly (error code: 14, error message: '', log file: 'c:\\use\r\nrs\\me\\_bazel_me\\cxy76ymx/server/jvm.out')\r\n\r\n\r\nc:\\tensorflow-master>", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Have I written custom code:  No\r\nOS Platform and Distribution: Windows 7, 64 bit\r\nTensorFlow installed from: windows build\r\nTensorFlow version: 1.5, newer versions would not import\r\nBazel version: 0.17.2\r\nCUDA/cuDNN version: NA\r\nGPU model and memory: NA\r\nExact command to reproduce: bazel build tensorflow/examples/wav_to_spectrogram/...\r\nMobile device: NA", "I'm also seeing similar issue with below command line . I did try different TF version (1.9, 1.10, 1.11) but all gives similar error\r\nbazel test -c opt -- //tensorflow/... -//tensorflow/compiler/... -//tensorflow/contrib/lite/... \r\n\r\n", "Here maybe a related problem. What is //tensorflow/cc:ops/math_ops_gen_cc? I can see a folder /tensorflow/cc/ops but what is cc:ops?\r\n\r\nMicrosoft Windows [Version 6.1.7601]\r\nCopyright (c) 2009 Microsoft Corporation.  All rights reserved.\r\n\r\nC:\\tensorflow-master>bazel run tensorflow/examples/wav_to_spectrogram:wav_to_spe\r\nctrogram -- ^\r\nMore? --input_wav=/tmp/speech_dataset/happy/ab00c4b2_nohash_0.wav ^\r\nMore? --output_image=/tmp/spectrogram.png\r\nStarting local Bazel server and connecting to it...\r\nLoading:\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\n    currently loading: tensorflow/examples/wav_to_spectrogram\r\nAnalyzing: target //tensorflow/examples/wav_to_spectrogram:wav_to_spectrogram (3\r\n packages loaded)\r\nAnalyzing: target //tensorflow/examples/wav_to_spectrogram:wav_to_spectrogram (8\r\n packages loaded)\r\nAnalyzing: target //tensorflow/examples/wav_to_spectrogram:wav_to_spectrogram (1\r\n0 packages loaded)\r\nAnalyzing: target //tensorflow/examples/wav_to_spectrogram:wav_to_spectrogram (1\r\n1 packages loaded)\r\nAnalyzing: target //tensorflow/examples/wav_to_spectrogram:wav_to_spectrogram (1\r\n9 packages loaded)\r\nAnalyzing: target //tensorflow/examples/wav_to_spectrogram:wav_to_spectrogram (3\r\n0 packages loaded)\r\nAnalyzing: target //tensorflow/examples/wav_to_spectrogram:wav_to_spectrogram (4\r\n3 packages loaded)\r\nAnalyzing: target //tensorflow/examples/wav_to_spectrogram:wav_to_spectrogram (5\r\n0 packages loaded)\r\nAnalyzing: target //tensorflow/examples/wav_to_spectrogram:wav_to_spectrogram (5\r\n2 packages loaded)\r\nWARNING: C:/tensorflow-master/tensorflow/core/BUILD:2501:1: in includes attribut\r\ne of cc_library rule //tensorflow/core:framework_internal_headers_lib: '../../ex\r\nternal/com_google_absl' resolves to 'external/com_google_absl' not below the rel\r\native path of its package 'tensorflow/core'. This will be an error in the future\r\n. Since this rule was created by the macro 'cc_header_only_library', the error m\r\night have been caused by the macro implementation in C:/tensorflow-master/tensor\r\nflow/tensorflow.bzl:1376:20\r\nWARNING: C:/tensorflow-master/tensorflow/core/BUILD:2587:1: in includes attribut\r\ne of cc_library rule //tensorflow/core:framework_headers_lib: '../../external/co\r\nm_google_absl' resolves to 'external/com_google_absl' not below the relative pat\r\nh of its package 'tensorflow/core'. This will be an error in the future. Since t\r\nhis rule was created by the macro 'cc_header_only_library', the error might have\r\n been caused by the macro implementation in C:/tensorflow-master/tensorflow/tens\r\norflow.bzl:1376:20\r\nAnalyzing: target //tensorflow/examples/wav_to_spectrogram:wav_to_spectrogram (6\r\n9 packages loaded)\r\nUnhandled exception thrown during build; message: Unrecoverable error while eval\r\nuating node '//tensorflow/cc:ops/math_ops_gen_cc BuildConfigurationValue.Key[ac9\r\n8f5975123fd6eeb07a7415b6161fb] true' (requested by nodes '//tensorflow/cc:math_o\r\nps_genrule BuildConfigurationValue.Key[6a75becf8194103d260d4e5a345be2c2] false')\r\n\r\nINFO: Elapsed time: 24.494s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (72 packages loaded)\r\njava.lang.RuntimeException: Unrecoverable error while evaluating node '//tensorf\r\nlow/cc:ops/math_ops_gen_cc BuildConfigurationValue.Key[ac98f5975123fd6eeb07a7415\r\nb6161fb] true' (requested by nodes '//tensorflow/cc:math_ops_genrule BuildConfig\r\nurationValue.Key[6a75becf8194103d260d4e5a345be2c2] false')\r\n        at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate\r\n.run(AbstractParallelEvaluator.java:497)\r\n        at com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$Wrapped\r\nRunnable.run(AbstractQueueVisitor.java:368)\r\n        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown S\r\nource)\r\n        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown\r\nSource)\r\n        at java.base/java.lang.Thread.run(Unknown Source)\r\nCaused by: java.lang.IllegalStateException\r\n        at com.google.common.base.Preconditions.checkState(Preconditions.java:49\r\n1)\r\n        at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.addD\r\nynamicInputLinkOptions(LibrariesToLinkCollector.java:290)\r\n        at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.addL\r\ninkerInputs(LibrariesToLinkCollector.java:258)\r\n        at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.coll\r\nectLibrariesToLink(LibrariesToLinkCollector.java:203)\r\n        at com.google.devtools.build.lib.rules.cpp.CppLinkActionBuilder.build(Cp\r\npLinkActionBuilder.java:916)\r\n        at com.google.devtools.build.lib.rules.cpp.CcBinary.init(CcBinary.java:4\r\n13)\r\n        at com.google.devtools.build.lib.rules.cpp.CcBinary.create(CcBinary.java\r\n:179)\r\n        at com.google.devtools.build.lib.rules.cpp.CcBinary.create(CcBinary.java\r\n:71)\r\n        at com.google.devtools.build.lib.analysis.ConfiguredTargetFactory.create\r\nRule(ConfiguredTargetFactory.java:320)\r\n        at com.google.devtools.build.lib.analysis.ConfiguredTargetFactory.create\r\nConfiguredTarget(ConfiguredTargetFactory.java:205)\r\n        at com.google.devtools.build.lib.skyframe.SkyframeBuildView.createConfig\r\nuredTarget(SkyframeBuildView.java:631)\r\n        at com.google.devtools.build.lib.skyframe.ConfiguredTargetFunction.creat\r\neConfiguredTarget(ConfiguredTargetFunction.java:770)\r\n        at com.google.devtools.build.lib.skyframe.ConfiguredTargetFunction.compu\r\nte(ConfiguredTargetFunction.java:320)\r\n        at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate\r\n.run(AbstractParallelEvaluator.java:420)\r\n        ... 4 more\r\njava.lang.RuntimeException: Unrecoverable error while evaluating node '//tensorf\r\nlow/cc:ops/math_ops_gen_cc BuildConfigurationValue.Key[ac98f5975123fd6eeb07a7415\r\nb6161fb] true' (requested by nodes '//tensorflow/cc:math_ops_genrule BuildConfig\r\nurationValue.Key[6a75becf8194103d260d4e5a345be2c2] false')\r\n        at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate\r\n.run(AbstractParallelEvaluator.java:497)\r\n        at com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$Wrapped\r\nRunnable.run(AbstractQueueVisitor.java:368)\r\n        at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown S\r\nource)\r\n        at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown\r\nSource)\r\n        at java.base/java.lang.Thread.run(Unknown Source)\r\nCaused by: java.lang.IllegalStateException\r\n        at com.google.common.base.Preconditions.checkState(Preconditions.java:49\r\n1)\r\n        at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.addD\r\nynamicInputLinkOptions(LibrariesToLinkCollector.java:290)\r\n        at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.addL\r\ninkerInputs(LibrariesToLinkCollector.java:258)\r\n        at com.google.devtools.build.lib.rules.cpp.LibrariesToLinkCollector.coll\r\nectLibrariesToLink(LibrariesToLinkCollector.java:203)\r\n        at com.google.devtools.build.lib.rules.cpp.CppLinkActionBuilder.build(Cp\r\npLinkActionBuilder.java:916)\r\n        at com.google.devtools.build.lib.rules.cpp.CcBinary.init(CcBinary.java:4\r\n13)\r\n        at com.google.devtools.build.lib.rules.cpp.CcBinary.create(CcBinary.java\r\n:179)\r\n        at com.google.devtools.build.lib.rules.cpp.CcBinary.create(CcBinary.java\r\n:71)\r\n        at com.google.devtools.build.lib.analysis.ConfiguredTargetFactory.create\r\nRule(ConfiguredTargetFactory.java:320)\r\n        at com.google.devtools.build.lib.analysis.ConfiguredTargetFactory.create\r\nConfiguredTarget(ConfiguredTargetFactory.java:205)\r\n        at com.google.devtools.build.lib.skyframe.SkyframeBuildView.createConfig\r\nuredTarget(SkyframeBuildView.java:631)\r\n        at com.google.devtools.build.lib.skyframe.ConfiguredTargetFunction.creat\r\neConfiguredTarget(ConfiguredTargetFunction.java:770)\r\n        at com.google.devtools.build.lib.skyframe.ConfiguredTargetFunction.compu\r\nte(ConfiguredTargetFunction.java:320)\r\n        at com.google.devtools.build.skyframe.AbstractParallelEvaluator$Evaluate\r\n.run(AbstractParallelEvaluator.java:420)\r\n        ... 4 more\r\nFAILED: Build did NOT complete successfully (72 packages loaded)\r\n\r\nC:\\tensorflow-master>", "I have the same problem on Windows7/64 when running:\r\nbazel build tensorflow/contrib/lite/toco:tocoFAILED: Build did NOT complete successfully (443 packages loaded)\r\n\r\nServer terminated abruptly (error code: 14, error message: '', log file: 'c:\\users\\brm738\\_bazel_brm738\\cxmuuzyy/server/jvm.out').\r\n\r\nPython 3.6.2\r\nVS 2017\r\nTF1.11.0\r\n\r\n", "Hi @pauldelmusica ! The above example on wave_to_spectrogram has depreciated now. Attaching [audio recognition ](https://www.tensorflow.org/tutorials/audio/simple_audio)documentation from the 2.8 version for reference. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 22458, "title": "ImportError: _pywrap_tensorflow_internal.so: undefined symbol: _ZN10tensorflow20UnaryDatasetOpKernel11MakeDatasetEPNS_15OpKernelContextEPPNS_11DatasetBaseE", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["Hi There:\r\n\r\nI am on ubuntu 18.04. use conda environment to run python and tensorflow.\r\n\r\nthe stuff works fine before and today during the pycharm debugging, the next run pops up the\r\n\r\nImportError: /home/jxu/anaconda3/envs/tf-cpu/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN10tensorflow20UnaryDatasetOpKernel11MakeDatasetEPNS_15OpKernelContextEPPNS_11DatasetBaseE\r\n\r\ntried to remove the conda environment and recreate a new conda environment\r\ninstall the tensorflow via pip install tensorflow==1.10.0 or 1.10.1\r\nnone of them works.\r\n\r\nafter installation, run python. the python is version\r\n\r\nPython 3.6.6 |Anaconda, Inc.| (default, Jun 28 2018, 17:14:51)\r\n[GCC 7.2.0] on linux\r\n\r\ntry to import tensorflow as tf\r\n\r\nget following error message:\r\n\r\nTraceback (most recent call last):\r\nFile \"/home/jxu/anaconda3/envs/tf-cpu/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in \r\nfrom tensorflow.python.pywrap_tensorflow_internal import *\r\nFile \"/home/jxu/anaconda3/envs/tf-cpu/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in \r\n_pywrap_tensorflow_internal = swig_import_helper()\r\nFile \"/home/jxu/anaconda3/envs/tf-cpu/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n_mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\nFile \"/home/jxu/anaconda3/envs/tf-cpu/lib/python3.6/imp.py\", line 243, in load_module\r\nreturn load_dynamic(name, filename, file)\r\nFile \"/home/jxu/anaconda3/envs/tf-cpu/lib/python3.6/imp.py\", line 343, in load_dynamic\r\nreturn _load(spec)\r\nImportError: /home/jxu/anaconda3/envs/tf-cpu/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN10tensorflow20UnaryDatasetOpKernel11MakeDatasetEPNS_15OpKernelContextEPPNS_11DatasetBaseE\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\nFile \"\", line 1, in \r\nFile \"/home/jxu/anaconda3/envs/tf-cpu/lib/python3.6/site-packages/tensorflow/init.py\", line 22, in \r\nfrom tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import\r\nFile \"/home/jxu/anaconda3/envs/tf-cpu/lib/python3.6/site-packages/tensorflow/python/init.py\", line 49, in \r\nfrom tensorflow.python import pywrap_tensorflow\r\nFile \"/home/jxu/anaconda3/envs/tf-cpu/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 74, in \r\nraise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\nFile \"/home/jxu/anaconda3/envs/tf-cpu/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in \r\nfrom tensorflow.python.pywrap_tensorflow_internal import *\r\nFile \"/home/jxu/anaconda3/envs/tf-cpu/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in \r\n_pywrap_tensorflow_internal = swig_import_helper()\r\nFile \"/home/jxu/anaconda3/envs/tf-cpu/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n_mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\nFile \"/home/jxu/anaconda3/envs/tf-cpu/lib/python3.6/imp.py\", line 243, in load_module\r\nreturn load_dynamic(name, filename, file)\r\nFile \"/home/jxu/anaconda3/envs/tf-cpu/lib/python3.6/imp.py\", line 343, in load_dynamic\r\nreturn _load(spec)\r\nImportError: /home/jxu/anaconda3/envs/tf-cpu/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZN10tensorflow20UnaryDatasetOpKernel11MakeDatasetEPNS_15OpKernelContextEPPNS_11DatasetBaseE\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions. Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nplease kindly help to suggest to fix the problem.\r\n\r\nthis happens suddenly on my computer. it was working perfectly.\r\n\r\nRegards,\r\n\r\nJian Xu", "Why did you close the issue @jianxucsm ?"]}, {"number": 22457, "title": "Fix tflite Makefile so it can find absl includes", "body": "", "comments": []}, {"number": 22456, "title": "Workaround a Notebook bug in in c.NotebookApp.ip", "body": "See https://github.com/jupyter/notebook/issues/3946. I found this by\r\nchecking package version differences and hunting for recent issues on\r\nNotebook's github page.", "comments": []}, {"number": 22455, "title": "V1.11.0-rc2 still build fail with VERBS", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NO\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04 and CentOS 7.5\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: build from source\r\n- **TensorFlow version (use command below)**: Master and v1.11-rc2\r\n- **Python version**: 2.7 and 3.5\r\n- **Bazel version (if compiling from source)**: 0.16\r\n- **GCC/Compiler version (if compiling from source)**: 4.8.5\r\n- **CUDA/cuDNN version**: CUDA 9.1 and 9.2, cuDNN 7.2\r\n- **GPU model and memory**: P100, Titan V\r\n- **Exact command to reproduce**: Enable VERBS in config\r\nThen, bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\nIn latest master (9/26), used following to compile:\r\nbazel build --config=opt --config=cuda --config=verbs  //tensorflow/tools/pip_package:build_pip_package\r\nSame error message as described blow.\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\nSame environment can build 1.10 successfully, but failed on 1.11\r\n\r\nIt seems this static member functions (static void tensorflow::RdmaMgr::RegMemVisitors()) try to directly access non-static member (RdmaAdapter* rdma_adapter_;)\r\n\r\n> ERROR: /home/ai/tensorflow/tensorflow/contrib/verbs/BUILD:105:1: C++ compilation of rule '//tensorflow/contrib/verbs:rdma_mgr' failed (Exit 1)\r\nIn file included from tensorflow/contrib/verbs/rdma_mgr.cc:18:0:\r\n./tensorflow/contrib/verbs/rdma_mgr.h: In static member function 'static void tensorflow::RdmaMgr::RegMemVisitors()':\r\n./tensorflow/contrib/verbs/rdma_mgr.h:50:16: error: invalid use of member 'tensorflow::RdmaMgr::rdma_adapter_' in static member function\r\n   RdmaAdapter* rdma_adapter_;\r\n                ^\r\ntensorflow/contrib/verbs/rdma_mgr.cc:282:40: error: from this location\r\n     int32_t bus_id = TryToReadNumaNode(rdma_adapter_->context_->device) + 1;\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.", "comments": ["While this is not pretty, We will be cutting 1.12 in one week, so we wont have time to fix this in 1.11.\r\n\r\n@jhseu do you know who supports libverbs?\r\nWho can fix this for us, from our side or theirs?", "@snuzxj @gunan The PR #22415 will fix the issue I think.", "Actually, #22003 fixed the error mentioned in this issue. However, there were another compilation error with verbs that was introduced later (33170cc661f3838aa7d0d7fc19bb0c6ba4812a3c). The other compilation error will be fixed by #22415.", "@snuzxj The PR #22415 has been merged in the master. It is unlikely to be in r1.11 given the timeline though. I think maybe we could consider this issue fixed now?", "@yongtang just tried the new master. Got an Error:\r\n\r\n> ERROR: /home/ai/tensorflow/tensorflow/contrib/verbs/BUILD:105:1: C++ compilation of rule '//tensorflow/contrib/verbs:rdma_mgr' failed (Exit 1)\r\nIn file included from tensorflow/contrib/verbs/rdma_mgr.cc:18:0:\r\n./tensorflow/contrib/verbs/rdma_mgr.h: In static member function 'static void tensorflow::RdmaMgr::RegMemVisitors()':\r\n./tensorflow/contrib/verbs/rdma_mgr.h:50:16: error: invalid use of member 'tensorflow::RdmaMgr::rdma_adapter_' in static member function\r\n   RdmaAdapter* rdma_adapter_;\r\n                ^\r\ntensorflow/contrib/verbs/rdma_mgr.cc:282:40: error: from this location\r\n     int32_t bus_id = TryToReadNumaNode(rdma_adapter_->context_->device) + 1;", "@snuzxj I tried with the latest master and it works fine. Could it be that the dependency libraries are not properly installed on your machine?", "@yongtang Thank you for the prompt feedback! I just tried again with latest master, but it still failed with the same error message. However, when I use 1.10, it built successfully. So, I don't think it related to dependency libraries on my machine. By the way, I am using mellanox driver for my RDMA device.", "@snuzxj Can you share your system information (Ubuntu, gcc version, etc), as was requested when you opened the issue?", "@yongtang Just tried with today's master, but failed again. Updated the original post to include system information. I tried on several systems, all failed.", "I just checked the code, it seems that \"static void tensorflow::RdmaMgr::RegMemVisitors()\" are newly introduced in https://github.com/tensorflow/tensorflow/commit/33170cc661f3838aa7d0d7fc19bb0c6ba4812a3c\r\nJust wonder if it is the cause.\r\nIt seems this static member functions try to directly access non-static member (RdmaAdapter* rdma_adapter_;)", "@snuzxj Thanks. The issue could be reproduced. The issue is similar to #22559. Not very familiar with this area so will need to take another look into how to fix it.", "the problem exists with the latest source code. I checked the commit history, someone added a static function RdmaMgr::RegMemVisitors, but used a data member rdma_adapter_, could this be fixed?\r\n\r\nThe commiter is A. Tensorflow Unique...", "The problem itself is easy to fix, but doing so uncovers some additional problems, also from the same patch. I think I am close to a fix (Shouldn't be much different from the problems with GDR).", "Sorry, Seems like I was a bit hasty to talk, as I did not yet resolve all issues, and it may be a while longer (1-2weeks) before I can find the time to properly address and fix them.", "I can confirm that the issue still exists in the current master.", "I confirm that the issue exists in the current master as well as 1.12 branch", "That issue still appears in v1.12.0 when compiling TF from the source.\r\n", "#24250 should fix this. @snuzxj could you confirm?", "I just tried to compile r1.13 rc0 with --config=verbs and I still get the error below. Is there any update ? \r\n\r\nERROR: /home/an/gits/tensorflow/tensorflow/contrib/verbs/BUILD:105:1: C++ compilation of rule '//tensorflow/contrib/verbs:rdma_mgr' failed (Exit 1)\r\ntensorflow/contrib/verbs/rdma_mgr.cc: In static member function 'static void tensorflow::RdmaMgr::RegMemVisitors()':\r\ntensorflow/contrib/verbs/rdma_mgr.cc:282:40: error: invalid use of member 'tensorflow::RdmaMgr::rdma_adapter_' in static member function\r\n     int32_t bus_id = TryToReadNumaNode(rdma_adapter_->context_->device) + 1;\r\n                                        ^~~~~~~~~~~~~\r\nIn file included from tensorflow/contrib/verbs/rdma_mgr.cc:18:0:\r\n./tensorflow/contrib/verbs/rdma_mgr.h:50:16: note: declared here\r\n   RdmaAdapter* rdma_adapter_;\r\n                ^~~~~~~~~~~~~\r\n", "@axeln31459 r1.13 branch does not include #24250. You could patch that manually:\r\n\r\n```bash\r\ncurl https://patch-diff.githubusercontent.com/raw/tensorflow/tensorflow/pull/24250.patch | git apply\r\n```\r\n\r\nand then compile again.", "@hgadig I believe this has been fixed. Could you close this issue?", "@byronyi Thanks! Close the issue as it has been fixed."]}, {"number": 22454, "title": "Dynamic loading of CUDA libraries", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: N/A\r\n- **TensorFlow version (use command below)**: N/A\r\n- **Python version**: N/A\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\n\r\nCurrently, the TensorFlow Python library is released in two flavours: CPU-only and CPU/GPU. The latter is dynamically linked with CUDA libraries and fails to load if they are not available in the linker path.\r\n\r\n```python\r\nImportError: dlopen([...]/tensorflow/python/_pywrap_tensorflow_internal.so, 10): Library not loaded: @rpath/libcublas.8.0.dylib\r\n  Referenced from: [...]/tensorflow/python/_pywrap_tensorflow_internal.so\r\n  Reason: image not found\r\n```\r\n\r\nI suspect that it might be possible to load CUDA libraries dynamically at runtime. This would allow having a single TensorFlow build which attempts to load CUDA, and if it is not available, falls back to CPU-only ops. \r\n\r\nIt hard for me to estimate the feasibility of the proposal for the current TensorFlow runtime implementation, so it might as well be the case, that the proposed change is too big/intrusive to be practical. ", "comments": ["Apart from having a single package, TF used to operate like this.\r\nI do not remember why we switched.\r\n\r\nThe above means this is feasible. But it will definitely be an intrusive change. And I also remember multiple github issues about this.\r\n\r\nThis is eventually in our plans to implement, but if someone from the community is willing to take a stab, I would be happy to review the change.", "A-ha, found the duplicate #16184"]}, {"number": 22453, "title": "Ordering for configurable and non-configurable optimizers", "body": "This PR enables mixing and ordering of non-configurable default optimizers and custom-optimizers, allowing expert users to fine tune the optimizer ordering and injecting custom optimizers between default optimizers. Before this patch, custom optimizers were always executed last.", "comments": []}, {"number": 22452, "title": "Documentation for tf.train.init_from_checkpoint doesn't say what it does when", "body": "Base on the code, [`tf.train.init_from_checkpoint`](https://www.tensorflow.org/api_docs/python/tf/train/init_from_checkpoint) seems to overwrite the initializers of variables to load from the given checkpoint.  The actual initialization will then occur when `tf.global_variables_initializer()` or similar is executed.\r\n\r\nHowever, the documentation makes no mention of this.  It's written as if the initialization happens *now*.  I suppose it does happen now for eager mode, but for Graph mode the initialization is delayed.\r\n\r\nThis is particularly confusing in a TPU context where code is executing in all sorts of places, so it took me a while reading through the underlying source code before I understood what was going on.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "@vihanjain: could you take a look?", "Thank you!"]}, {"number": 22451, "title": "Workaround a Notebook bug in in c.NotebookApp.ip", "body": "See https://github.com/jupyter/notebook/issues/3946. I found this by checking package version differences and hunting for recent issues on Notebook's github page.", "comments": []}, {"number": 22450, "title": " Intel  GPU Support ", "body": "Support Intel GPU alongside with NVIDIA, not sure if that is possible but it may help achieve better performance\r\ncheck intel deep leaning kit\r\nhttps://software.intel.com/en-us/openvino-toolkit/", "comments": ["@abdelrahmanmohamed Fyi. Please check [this](https://www.tensorflow.org/performance/performance_guide#tensorflow_with_intel%C2%AE_mkl_dnn).", "You may also check the following github rep \r\n[Intel-TF](https://github.com/Intel-tensorflow)\r\n[Intel/MKL-DNN](https://github.com/intel/mkl-dnn)\r\n[OpenCL support](https://github.com/tensorflow/tensorflow/issues/22)", "I do not think there are promising project which demonstrate good performance on Intel GPUs.\r\nI know that OpenCL can work on these GPUs, but I am not sure about the performance.\r\nThis will  definitely need to be a community contribution, as we have no plans for this.\r\n\r\n@claynerobison any resources on Intel GPUs you can point us to?", "Hi @abdelrahmanmohamed. There are a couple of community supported OpenCL efforts, but nothing officially supported:\r\n\r\n- https://jonnoftw.github.io/2018/04/04/building-tensorflow-with-opencl-support-on-ubuntu-1604\r\n\r\n- https://github.com/hughperkins/tf-coriander\r\n\r\n- https://www.codeplay.com/portal/tensorflow%E2%84%A2-for-opencl%E2%84%A2-using-sycl%E2%84%A2", "Does TensorFlow support Intel GPUs in its latest releases?"]}, {"number": 22449, "title": "[bazel] Update bazel to 0.17.1", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: PR #19461\r\n- **Python version**: 2.7.12\r\n- **Bazel version (if compiling from source)**: 0.17.1/0.17.2\r\n- **GCC/Compiler version (if compiling from source)**: 5.4.0 20160609\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: build of PR #19461\r\n\r\n### Describe the problem\r\n\r\nThis is a placeholder for updating bazel to 0.17.1 so that PR #19461 could pass CI tests. Before bazel 0.17.1, bazel had some issues with fetching http_archive (See https://github.com/bazelbuild/bazel/issues/5932). The issue has been fixed in 0.17.1.\r\n\r\nThe update of bazel 0.17.1 requires additional efforts than bumping versions in the repo (See https://github.com/tensorflow/tensorflow/pull/22281#issuecomment-421414201). Pushing bleeding edge bazel immediately caused some issues before, so it is preferred to wait until a full release cycle before making the change.\r\n\r\nAt the moment, bazel 0.17.2 has been released (See https://github.com/bazelbuild/bazel/issues/6164#issuecomment-423524449) which is a minor release increment to 0.17.1.\r\n\r\n/cc @gunan \r\n\r\nNote The bazel 0.18.0 release is not far away (See https://github.com/bazelbuild/bazel/issues/5963), as far as I could see. so wait until 0.18.0 is rebased, then update to 0.17.1 is also reasonable I think.", "comments": ["@av8ramit is currently updating the CI images to use bazel 0.17.", "This will be done after the 1.11 release.", "@gunan @av8ramit Any update with bazel 0.17.1?", "@yongtang We have not made the update yet due to some incompatibilities we are still working through.", "@av8ramit Thanks for the update! \ud83d\udc4d \u2764\ufe0f ", "Looks like bazel 0.20 has been in place for tf repo: https://github.com/tensorflow/tensorflow/commit/55bbb4c92567732ee6712c0201b94bef50df6083\r\n\r\nSo this issue could be closed. Thanks all for the work!"]}, {"number": 22448, "title": "Issue with gradients computation when using stop_gradient on a map_fn output", "body": "\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOs\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.10.0-rc1-19-g656e7a2b34\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\n\r\nWhen training the model, the error with the stack trace below occurs randomly.\r\nOriginal exception is thrown from there:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/tensor_array.h#L571\r\n\r\nThe error disappears if I remove the `stop_gradient`.\r\n\r\n### Code\r\n\r\nUnfortunately, I haven't managed to replicate the issue with a small piece of code.\r\nBasically, I have a model where a layer forward pass is based on `map_fn`. Inside the function called by `map_fn`, there is a `tf.cond`.\r\nDownstream this layer, there is another layer with a `stop_gradient` on one of the outputs of the previous layer.\r\n\r\n\r\n### Error stack\r\n\r\n```\r\n2018-09-21 20:54:20.894525: W tensorflow/core/framework/op_kernel.cc:1275] OP_REQUIRES failed at tensor_array_ops.cc:527 : Invalid argument: TensorArray scene_model/roi_filter_layer/map/TensorArray_3_8140@gradients: Could not read from TensorArray index 0.  Furthermore, the element shape is not fully defined: <unknown>.  It is possible you are working with a resizeable TensorArray and stop_gradients is not allowing the gradients to be written.  If you set the full element_shape property on the forward TensorArray, the proper all-zeros tensor will be returned instead of incurring this error.\r\nTraceback (most recent call last):\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1278, in _do_call\r\n    return fn(*args)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1263, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1350, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: TensorArray scene_model/roi_filter_layer/map/TensorArray_3_8140@gradients: Could not read from TensorArray index 0.  Furthermore, the element shape is not fully defined: <unknown>.  It is possible you are working with a resizeable TensorArray and stop_gradients is not allowing the gradients to be written.  If you set the full element_shape property on the forward TensorArray, the proper all-zeros tensor will be returned instead of incurring this error.\r\n\t [[Node: gradients/scene_model/roi_filter_layer/map/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3 = TensorArrayReadV3[dtype=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](gradients/scene_model/roi_filter_layer/map/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3, gradients/scene_model/roi_filter_layer/map/while/TensorArrayWrite_2/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPopV2, gradients/scene_model/roi_filter_layer/map/while/Merge_2_grad/Switch:1)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/Users/jnd/dev/mask_rcnn/scripts/train_eval_export/new_train.py\", line 55, in <module>\r\n    train(config_path)\r\n  File \"/Users/jnd/dev/mask_rcnn/scripts/train_eval_export/new_train.py\", line 48, in train\r\n    training_schedule=training_program, epoch_offset=0)\r\n  File \"/Users/jnd/dev/mask_rcnn/libs/models/scene/helpers/model_trainer.py\", line 91, in train\r\n    estimator.train(input_fn=input_fn_train, steps=self.config.STEPS_PER_EPOCH)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 376, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1145, in _train_model\r\n    return self._train_model_default(input_fn, hooks, saving_listeners)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1173, in _train_model_default\r\n    saving_listeners)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1451, in _train_with_estimator_spec\r\n    _, loss = mon_sess.run([estimator_spec.train_op, estimator_spec.loss])\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 583, in run\r\n    run_metadata=run_metadata)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 1059, in run\r\n    run_metadata=run_metadata)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 1150, in run\r\n    raise six.reraise(*original_exc_info)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/six.py\", line 693, in reraise\r\n    raise value\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 1135, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 1207, in run\r\n    run_metadata=run_metadata)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\", line 987, in run\r\n    return self._sess.run(*args, **kwargs)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 877, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1100, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1272, in _do_run\r\n    run_metadata)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1291, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: TensorArray scene_model/roi_filter_layer/map/TensorArray_3_8140@gradients: Could not read from TensorArray index 0.  Furthermore, the element shape is not fully defined: <unknown>.  It is possible you are working with a resizeable TensorArray and stop_gradients is not allowing the gradients to be written.  If you set the full element_shape property on the forward TensorArray, the proper all-zeros tensor will be returned instead of incurring this error.\r\n\t [[Node: gradients/scene_model/roi_filter_layer/map/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3 = TensorArrayReadV3[dtype=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](gradients/scene_model/roi_filter_layer/map/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3, gradients/scene_model/roi_filter_layer/map/while/TensorArrayWrite_2/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPopV2, gradients/scene_model/roi_filter_layer/map/while/Merge_2_grad/Switch:1)]]\r\n\r\nCaused by op 'gradients/scene_model/roi_filter_layer/map/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3', defined at:\r\n  File \"/Users/jnd/dev/mask_rcnn/scripts/train_eval_export/new_train.py\", line 55, in <module>\r\n    train(config_path)\r\n  File \"/Users/jnd/dev/mask_rcnn/scripts/train_eval_export/new_train.py\", line 48, in train\r\n    training_schedule=training_program, epoch_offset=0)\r\n  File \"/Users/jnd/dev/mask_rcnn/libs/models/scene/helpers/model_trainer.py\", line 91, in train\r\n    estimator.train(input_fn=input_fn_train, steps=self.config.STEPS_PER_EPOCH)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 376, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1145, in _train_model\r\n    return self._train_model_default(input_fn, hooks, saving_listeners)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1170, in _train_model_default\r\n    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1133, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)\r\n  File \"/Users/jnd/dev/mask_rcnn/libs/models/scene/helpers/estimator.py\", line 84, in model_fn\r\n    grad_vars = optimizer.compute_gradients(loss, var_list=trainable_variables)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\", line 514, in compute_gradients\r\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 596, in gradients\r\n    gate_gradients, aggregation_method, stop_gradients)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 779, in _GradientsHelper\r\n    lambda: grad_fn(op, *out_grads))\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 398, in _MaybeCompile\r\n    return grad_fn()  # Exit early\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py\", line 779, in <lambda>\r\n    lambda: grad_fn(op, *out_grads))\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_grad.py\", line 132, in _TensorArrayWriteGrad\r\n    grad = g.read(index)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py\", line 824, in read\r\n    return self._implementation.read(index, name=name)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/ops/tensor_array_ops.py\", line 258, in read\r\n    name=name)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/ops/gen_data_flow_ops.py\", line 6515, in tensor_array_read_v3\r\n    dtype=dtype, name=name)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\r\n    op_def=op_def)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\n...which was originally created as op 'scene_model/roi_filter_layer/map/while/TensorArrayWrite/TensorArrayWriteV3', defined at:\r\n  File \"/Users/jnd/dev/mask_rcnn/scripts/train_eval_export/new_train.py\", line 55, in <module>\r\n    train(config_path)\r\n[elided 5 identical lines from previous traceback]\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 1133, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)\r\n  File \"/Users/jnd/dev/mask_rcnn/libs/models/scene/helpers/estimator.py\", line 56, in model_fn\r\n    outputs = model(features, training=(mode == tf.estimator.ModeKeys.TRAIN), train_bn=train_bn)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 736, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"/Users/jnd/dev/mask_rcnn/libs/models/scene/model.py\", line 197, in call\r\n    rcnn_outputs = self.object_rcnn_model.call(inputs, **kwargs)\r\n  File \"/Users/jnd/dev/mask_rcnn/libs/models/scene/head/rcnn/object_rcnn.py\", line 160, in call\r\n    filter_outputs = self.roi_filter_layer(filter_inputs, **kwargs)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 736, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"/Users/jnd/dev/mask_rcnn/libs/models/scene/head/rcnn/roi_filter_layer.py\", line 77, in call\r\n    (tf.float32, tf.int32, tf.float32))\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/ops/functional_ops.py\", line 459, in map_fn\r\n    maximum_iterations=n)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3232, in while_loop\r\n    return_same_structure)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2952, in BuildLoop\r\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2887, in _BuildLoop\r\n    body_result = body(*packed_vars_for_body)\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3201, in <lambda>\r\n    body = lambda i, lv: (i + 1, orig_body(*lv))\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/ops/functional_ops.py\", line 451, in compute\r\n    tas = [ta.write(i, value) for (ta, value) in zip(tas, flat_fn_values)]\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/ops/functional_ops.py\", line 451, in <listcomp>\r\n    tas = [ta.write(i, value) for (ta, value) in zip(tas, flat_fn_values)]\r\n  File \"/usr/local/anaconda3/envs/mask_rcnn_cpu/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 118, in wrapped\r\n    return _add_should_use_warning(fn(*args, **kwargs))\r\n\r\nInvalidArgumentError (see above for traceback): TensorArray scene_model/roi_filter_layer/map/TensorArray_3_8140@gradients: Could not read from TensorArray index 0.  Furthermore, the element shape is not fully defined: <unknown>.  It is possible you are working with a resizeable TensorArray and stop_gradients is not allowing the gradients to be written.  If you set the full element_shape property on the forward TensorArray, the proper all-zeros tensor will be returned instead of incurring this error.\r\n\t [[Node: gradients/scene_model/roi_filter_layer/map/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayReadV3 = TensorArrayReadV3[dtype=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](gradients/scene_model/roi_filter_layer/map/while/TensorArrayWrite/TensorArrayWriteV3_grad/TensorArrayGrad/TensorArrayGradV3, gradients/scene_model/roi_filter_layer/map/while/TensorArrayWrite_2/TensorArrayWriteV3_grad/TensorArrayReadV3/StackPopV2, gradients/scene_model/roi_filter_layer/map/while/Merge_2_grad/Switch:1)]]\r\n\r\n```", "comments": ["Hi @jnd77 . It is difficult to figure out what is breaking your code without a code snippet / small repro example. Can you please try to build one?", "Hi @ymodak. Sorry for the late reply, I was out of office. Let me see what I can do. Tricky to reproduce race conditions issues ...", "Sorry, haven't managed to do a repro with a simple code. Will close it for now ...", "```python\r\ninput_placeholer = tf.placeholder(tf.float32, shape=(None, None, 3))\r\nsizes = [2, 3]\r\nresult = tf.TensorArray(tf.float32, size=1, dynamic_size=True, infer_shape=False)\r\nfor i in sizes:\r\n    tensor_arr = tf.TensorArray(tf.float32, size=1, dynamic_size=True)\r\n    for j in range(i):\r\n        tensor_arr = tensor_arr.write(j, input_placeholer)\r\n    result = result.write(i, tensor_arr.stack())\r\n\r\nresult = result.concat()\r\n\r\ninit = tf.global_variables_initializer()\r\nwith tf.Session() as sess:\r\n    sess.run(init)\r\n    print(sess.run([tf.shape(result)], feed_dict={input_placeholer: np.random.randn(10, 10, 3)}))\r\n```\r\n\r\nThis code can reproduce this issue."]}, {"number": 22447, "title": "tf.keras.utils.multi_gpu_model  just ingore loaded weights from template model", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: no\r\n- **TensorFlow installed from (source or binary)**: binary prebuilt\r\n- **TensorFlow version (use command below)**: 1.9.0\r\n- **Python version**: 3.6.4\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 9.0/7.2.1\r\n- **GPU model and memory**: Tesla K80 12GB\r\n- **Exact command to reproduce**:\r\n\r\nactually, when i call tf.keras.utils.multi_gpu_model on a template model that load_weights,  but result show that the multi_gpu_model just ingore the loaded weights on the template model.\r\n", "comments": ["@jasstionzyf Hi, Could you please describe the issue clearly. Also request you to provide a sample code snippet to reproduce the issue.", "@harshini-gadige \r\ncurrently i can not reproduce the  issues, so will close it !\r\n"]}, {"number": 22446, "title": "tf.data.Dataset run after loading  whole data without using shuffle method", "body": "Does have any method to load sub of data then running model, without using `shuffle`,  I want the data order not changed.", "comments": ["@zh794390558 Please correct me if I am wrong: You are looking to run your model on a subset of whole data and not the whole dataset. Am I right?", "@zh794390558  Will [tf.data.Dataset.list_files](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#list_files) work for your case? You can specify a file_pattern for the data subset.", "@ymodak @feihugis   when is using dataset api without `shuflle`, tf will load all data into memory, then do own processing. If using `shuffle`, then tf will load `buffer_size` data into memory and do processing, but will shuffle the dataset. I want an interface to load `buffer_size` data into memory and do processing order by oder.", "@zh794390558 There is a similar [issue](https://github.com/tensorflow/tensorflow/issues/17810) reported. Is that what you mean? A [PR](https://github.com/tensorflow/tensorflow/pull/22429) is proposed to avoid loading all data into memory.", "@feihugis The issue is not same to me, I using `tf.data.Dataset.from_generater` to load data.", "@zh794390558 Could you post your code here for reproducing the problem?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 22445, "title": "No functions or submodules are installed in 1.11.0rc1 when compiled from source", "body": "### System information\r\n- **OS**: `uname -a`: Linux pnode1.cluster 3.10.0-514.el7.ppc64le #1 SMP Sat Nov 5 15:08:14 GMT 2016 ppc64le ppc64le ppc64le GNU/Linux\r\n- **TensorFlow installed from**: source\r\n- **TensorFlow version**: 1.11.0rc1\r\n- **Python version**: 3.5.6\r\n- **Bazel version**: 0.17.1\r\n- **GCC/Compiler version**: gcc (GCC) 4.8.5 20150623 (Red Hat 4.8.5-11)\r\n- **CUDA/cuDNN version**: 9.1\r\n- **GPU model and memory**: NVIDIA Tesla P100\r\n- **Exact command to reproduce**: `python3.5 -c \"import tensorflow.keras\"`\r\n\r\n### Reproduction steps\r\nCompile and install Tensorflow from source:\r\n```\r\ngit clone https://github.com/tensorflow/tensorflow.git\r\ncd tensorflow\r\n./configure\r\n# Leave everything as default except for cuda options which I chose 9.1 and the correct cuda path\r\nbazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\nbazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\r\ncp /tmp/tensorflow_pkg/tensorflow-1.11.0rc1-cp35-cp35m-linux_ppc64le.whl ../\r\ncd ..\r\npip3.5 install tensorflow-1.11.0rc1-cp35-cp35m-linux_ppc64le.whl\r\n```\r\nTest `tensorflow.keras`:\r\n```\r\npython3.5 -c \"import tensorflow.keras\"\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nImportError: No module named 'tensorflow.keras'\r\n```\r\nTest other functions:\r\n```\r\n$ python3.5\r\n>>> x = tf.constant([[-2.25 + 4.75j], [-3.25 + 5.75j]])\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nAttributeError: module 'tensorflow' has no attribute 'constant'\r\n```\r\n\r\n### Pip packages\r\n`pip3.5 list`:\r\n```\r\nabsl-py                  0.5.0\r\nalabaster                0.7.11\r\nappdirs                  1.4.3\r\nastor                    0.7.1\r\natomicwrites             1.2.1\r\nattrs                    18.2.0\r\nBabel                    2.6.0\r\ncertifi                  2018.8.24\r\nchardet                  3.0.4\r\nCython                   0.28.5\r\ndecorator                4.3.0\r\ndocutils                 0.14\r\ngast                     0.2.0\r\ngrpcio                   1.15.0\r\nh5py                     2.8.0\r\nidna                     2.7\r\nimagesize                1.1.0\r\nJinja2                   2.10\r\nKeras                    2.2.2\r\nKeras-Applications       1.0.5\r\nKeras-Preprocessing      1.0.3\r\nMako                     1.0.7\r\nMarkdown                 2.6.11\r\nMarkupSafe               1.0\r\nmock                     2.0.0\r\nmore-itertools           4.3.0\r\nnose                     1.3.7\r\nnumpy                    1.15.1\r\npackaging                17.1\r\npathlib2                 2.3.2\r\npbr                      4.2.0\r\npip                      18.0\r\npluggy                   0.7.1\r\nprotobuf                 3.6.1\r\npy                       1.6.0\r\npydot                    1.2.4\r\npydot-ng                 1.0.0\r\nPygments                 2.2.0\r\nPyGraph                  0.2.1\r\npygraphviz               1.5\r\npyparsing                2.2.1\r\npytest                   3.8.0\r\npytools                  2018.5.2\r\npytz                     2018.5\r\nPyYAML                   3.13\r\nrequests                 2.19.1\r\nscipy                    1.1.0\r\nsetuptools               28.8.0\r\nsix                      1.11.0\r\nsnowballstemmer          1.2.1\r\nSphinx                   1.8.0\r\nsphinxcontrib-websupport 1.1.0\r\ntensorboard              1.10.0\r\ntensorflow               1.11.0rc1\r\ntermcolor                1.1.0\r\nurllib3                  1.23\r\nWerkzeug                 0.14.1\r\nwheel                    0.31.1\r\n```", "comments": ["@nelsyeung Can you try : import tensorflow.python.keras ?\r\nThis should solve your import problem.\r\n", "`import tensorflow.python.keras` also would not work:\r\n```\r\npython3.5 -c \"import tensorflow.python.keras\"\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nImportError: No module named 'tensorflow.python'\r\n```\r\n@ymodak I'd recommend you to familiarize yourself with the [Tensorflow documentation](https://www.tensorflow.org/api_docs/python/tf). Ever since v1.9 `tensorflow.python.keras` is moved to `tensorflow.keras`.\r\n\r\n### Some further information:\r\n- I cleaned up the system and recompiled everything from scratch, but that didn't help.\r\n\r\n- I just realized that nothing from Tensorflow is actually working, even though it took around 3 hours to compile. Did I miss some installation steps that's not documented? For example:\r\n```\r\n>>> x = tf.constant([[-2.25 + 4.75j], [-3.25 + 5.75j]])\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nAttributeError: module 'tensorflow' has no attribute 'constant'\r\n```\r\n- On my cluster, v1.10 and v1.9 branch simply gives too many compilation errors for me to solve them all, that's why I'm doing it on the master branch since it actually compiles.\r\n\r\n- I only know for a fact that the below commit from v1.6 would work perfectly for Python 2.7 on my system. I will try to compile that for Python 3.5 later:\r\n```\r\ngit checkout `git rev-list -n 1 --before=\"2018-02-23 18:00\" master`\r\n```", "When using TF, you should always use `import tensorflow as tf`\r\nThen use `tf.keras`.\r\nYou may define shortcuts such as `keras = tf.keras`\r\n\r\nTF public API guarantees only apply when you do `import tensorflow`.\r\nAny other import statements are outside of TF public python API guarantees.", "@gunan I apologize that I didn't rename the title after my discovery that *nothing from Tensorflow is actually working*.\r\n\r\nI'd recommend you to also familiarize yourself with the [Tensorflow Guide](https://www.tensorflow.org/guide/keras). Ever since v1.10, it **is** possible to import `tensorflow.keras` using, and I quote from the above link,\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n```\r\nThere was an issue sometime ago discussing `tf.keras` is simply too frustrating to use.\r\n\r\nFurthermore, just test this before you recommend anything, I can see that the below works fine on macOS with pip (I'm using pyenv to isolate all my Python packages and versions):\r\n```\r\npip install tensorflow==1.11.0rc1\r\npython3.5 -c \"import tensorflow.keras\"\r\n```\r\n\r\nHave a read on my [further information comment](https://github.com/tensorflow/tensorflow/issues/22445#issuecomment-423619601) just above yours.", "I just tried building and installing from head. The only difference is that I built a CPU-only package.\r\n```\r\npython3 -m venv venv/\r\nsource venv/bin/activate\r\n\r\ngit clone https://github.com/tensorflow/tensorflow.git\r\ncd tensorflow\r\n\r\npip install keras_applications==1.0.4\r\npip install keras_preprocessing==1.0.2\r\npip install --upgrade six mock portpicker scipy sklearn grpcio\r\npip install numpy==1.14.5\r\npip install h5py==2.8.0\r\n\r\n# Here I picked default for everything\r\n./configure\r\n\r\nbazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\n\r\nMove out of tensorflow directory before installing tensorflow pip package.\r\ncd ..\r\npip install /tmp/tensorflow_pkg/tensorflow-1.11.0rc1-cp35-cp35m-linux_x86_64.whl\r\n```\r\n\"from tensorflow import keras\" worked fine after this step. I don't know if we want to support this type of import long term, however.\r\nI might try GPU build later today, but for now you can check if anything is missing.\r\n\r\nEdit: fixed formatting\r\n", "@nelsyeung You are right. I apologize for the misleading information I provided.\r\nLooks like the top level modules under tensorflow are expected to work like that, at least for now.\r\nHowever, we have no tests that verify these work. Therefore, any breakages on this has been invisible to us.\r\n", "I just tried GPU build (with Python 2.7 this time). \"from tensorflow import keras\" works fine.\r\n\r\nFor GPU build, I also had to set nccl and cudnn, but the other steps were the same.", "I feel like that I must be missing some sort of environment variables, since this is a cluster a lot of the paths has to be set myself, can someone please check whether I'm missing anything:\r\n```sh\r\nexport PNODE=/home/user/pnode\r\nexport PATH=$PNODE/bin:$PATH\r\nexport LD_LIBRARY_PATH=$PNODE/lib:$LD_LIBRARY_PATH\r\nexport LD_LIBRARY_PATH=$PNODE/lib64:$LD_LIBRARY_PATH\r\nexport PYTHONPATH=$PNODE/lib/python3.5\r\nexport CPATH=$PNODE/include:$CPATH\r\nexport PKG_CONFIG_PATH=$PNODE/lib/pkgconfig:$PKG_CONFIG_PATH\r\nexport CUDA_HOME=$PNODE/cuda-9.1\r\nexport PATH=$CUDA_HOME/bin:$PATH\r\nexport CPATH=$CUDA_HOME/include:$CPATH\r\nexport LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH\r\n```\r\nThe only real clue to what's wrong is that I can import Tensorflow with no errors, but just that none of its functions or sub-modules work.\r\n\r\nI'll recompile everything later and give my full reproduction steps that includes building Python, cmake, OpenBlas, HDF5, Bazel and finally Tensorflow.", "Nagging Assignee @ymodak: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "No time to recompile everything and deal with this, decided to just revert Python 2.7 and Tensorflow 1.6."]}, {"number": 22444, "title": "tflite interpreter get different output for same input", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Debian 4.5.5\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**:  v1.10.1\r\n- **Python version**: 3.5.5\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\ngive data to a tflite model\r\ndata shape = (2, 28, 28, 1) and data[0] == data[1]\r\nuse tf.contrib.lite.Interpreter to run the model\r\nget the output, but output[0] != output[1]\r\n\r\n### Source code / [logs](url)\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ndef test_same():\r\n    data = np.random.random((1,28,28,1)).astype(np.float32)\r\n    data = np.concatenate([data, data])\r\n    print('input[0] == input[1]: ', equal(data[0], data[1]))\r\n    model = tf.contrib.lite.Interpreter(\r\n        model_path='resnet18_finetuned_batch2.tflite')\r\n    model.allocate_tensors()\r\n    model.set_tensor(0, data)\r\n    model.invoke()\r\n    output = model.get_tensor(model.get_output_details()[0]['index'])\r\n    print('output[0] == output[1]: ', equal(output[0], output[1]))\r\n\r\ndef equal(tensor1, tensor2):\r\n    for i, j in zip(tensor1.reshape(-1), tensor2.reshape(-1)):\r\n        if abs(i - j) > 0.001:\r\n            return False\r\n    return True\r\n\r\nif __name__ == \"__main__\":\r\n    test_same()\r\n```\r\nOUTPUT:\r\n```\r\ninput[0] == input[1]:  True\r\noutput[0] == output[1]:  False\r\n```", "comments": ["@lcxywfe I compared tflite outputs from identical inputs using a simple model without getting any error. Make sure your model.set_tensor has the correct index and tensor from input details. ", "@wt-huang Simple model is OK, I suspect it is related to memory reuse, how can i provide my model to you? ", "@lcxywfe You can post a link to your model.", "@wt-huang https://github.com/lcxywfe/model-zoom/raw/master/resnet18_finetuned_batch2.tflite", "@lcxywfe Thanks for sharing the model. The reason that you didn't get identical results for the same input is because the tensor shape for input and output needs to be identical here. You can feed `data` separately into the tflite model, i.e. `model.set_tensor(input_details[0]['index'], data[0])` and `model.set_tensor(input_details[0]['index'], data[1])`, then you will get identical results. ", "@wt-huang  Sorry, what the \"the tensor shape for input and output needs to be identical here\" means?\r\nAnd I try\r\n```\r\nmodel.set_tensor(model.get_input_details()[0]['index'], data[0])\r\n```\r\nbut get\r\n```\r\nValueError: Cannot set tensor: Dimension mismatch\r\n```", "@lcxywfe The tensor shape for model input and output should be identical. To avoid `Dimension mismatch` error, you would need to convert `data[0]` and `data[1]` to np.array. Below is an example to get input from your model then do the same and feed `data[1]` to a separate tflite model, then you will see identical outputs.\r\n\r\n```\r\n    model = tf.contrib.lite.Interpreter(model_path=\"resnet18_finetuned_batch2.tflite\")\r\n\r\n    input_details = model.get_input_details()\r\n    output_details = model.get_output_details()\r\n\r\n    data = np.array(np.random.random_sample(input_details[0]['shape']), dtype=np.float32)\r\n    model.allocate_tensors()\r\n    model.set_tensor(input_details[0]['index'], data)\r\n\r\n    model.invoke()\r\n    output = model.get_tensor(output_details[0]['index'])\r\n```", "@wt-huang I'm sorry, but why the input and output shape should be identical? If this is a classification model, then it can not work?", "@lcxywfe Yes, it works on classification or most models for that matter. What I meant was the input and output to the model conversion and their shapes should be the same.", "Hi, what the 'the input and output to the model conversion' means?, i used \"Flatbuffers\" to create the tflite model instread of \"toco\".", "@lcxywfe I guess tflite does not support changing input shape, so the original TF model used to create the tflite model must have identical shapes with tensors loaded at runtime in tflite.", "Closing this now, feel free to ask any additional questions."]}, {"number": 22443, "title": "ValueError: The passed save_path is not a valid checkpoint: modeltest.ckpt", "body": "\r\nI run this code\r\n```\r\ntf.reset_default_graph()\r\nv1 = tf.Variable(tf.constant(0.1, shape = [2]), name=\"v1\")\r\nv2 = tf.Variable(tf.constant(0.2, shape = [2]), name=\"v2\")\r\nsaver = tf.train.Saver()\r\nwith tf.Session() as sess:\r\n    saver.restore(sess, \"/tmp/model/model.ckpt\")\r\n```\r\nand then this error is occured:ValueError: The passed save_path is not a valid checkpoint: modeltest.ckpt\r\n\r\nthis is my env:\r\n\r\ntensorflow (1.10.1)\r\n\r\ntensorboard (1.10.0)\r\n\r\nh5py (2.8.0)\r\n\r\nPython 3.6.5\r\n\r\nCould you please advice how to solve out this error\r\n\r\nThank you", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Basically the error conveys that the checkpoint file is absent and therefore it is not a valid checkpoint.\r\nYou need to save the model before executing *saver.restore ( ) method * as it loads the file from the disk.\r\nPlease refer [saver.save ( ) method](https://www.tensorflow.org/guide/saved_model#save_variables) and\r\n[saver.restore ( ) method](https://www.tensorflow.org/guide/saved_model#restore_variables)\r\n", "Are you satisfied with the resolution of your issue?\r\n[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)\r\n[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)", "If the model name is \"modeltest.ckpt\", then you probably have the model in a zip file. Then you need to extract the model into a folder (\"model\\\" for example) and it will include 3 files. Now you can use the name as follows: \"model\\modeltest.ckpt\"", "Hello.\r\n\r\nI'm having problems resuming training from a checkpoint using Tensor2Tensor on Google Colab. The only way I've found is to delete all checkpoints and start again, which of course isn't a good idea after training for hours.\r\n\r\nI'm using TF and t2t version 1.14.0 and Ubuntu 18.04 on normal runtime. I tried posting first on t2t's issues [here](https://github.com/tensorflow/tensor2tensor/issues/1683) but I haven't got an answer in 9 days, and since this is a TF error I've decided to post here too.\r\n\r\nThis is the code :\r\n```\r\n!t2t-trainer \\\r\n    --tmp_dir='/content/gdrive/My Drive/TCC/T2T LibriSpeech/tmp/' \\\r\n    --problem='librispeech_clean_small' \\\r\n    --model='transformer' \\\r\n    --eval_steps=3 \\\r\n    --hparams_set='transformer_librispeech' \\\r\n    --data_dir='/content/gdrive/My Drive/TCC/T2T LibriSpeech/data/' \\\r\n    --output_dir='/content/gdrive/My Drive/TCC/T2T LibriSpeech/output/' \r\n```\r\n\r\nAnd this is the prompt output:\r\n```\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0828 15:46:33.243587 139684777486208 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/expert_utils.py:68: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\r\n\r\nW0828 15:46:34.237717 139684777486208 lazy_loader.py:50] \r\nThe TensorFlow contrib module will not be included in TensorFlow 2.0.\r\nFor more information, please see:\r\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\r\n  * https://github.com/tensorflow/addons\r\n  * https://github.com/tensorflow/io (for I/O related ops)\r\nIf you depend on functionality not listed there, please file an issue.\r\n\r\nW0828 15:46:36.218165 139684777486208 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/adafactor.py:27: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\r\n\r\nW0828 15:46:36.218689 139684777486208 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/multistep_optimizer.py:32: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\r\n\r\nW0828 15:46:36.231890 139684777486208 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/mesh_tensorflow/ops.py:4237: The name tf.train.CheckpointSaverListener is deprecated. Please use tf.estimator.CheckpointSaverListener instead.\r\n\r\nW0828 15:46:36.232139 139684777486208 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/mesh_tensorflow/ops.py:4260: The name tf.train.SessionRunHook is deprecated. Please use tf.estimator.SessionRunHook instead.\r\n\r\nW0828 15:46:36.251127 139684777486208 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/models/research/neural_stack.py:38: The name tf.nn.rnn_cell.RNNCell is deprecated. Please use tf.compat.v1.nn.rnn_cell.RNNCell instead.\r\n\r\nW0828 15:46:36.288087 139684777486208 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/rl/gym_utils.py:235: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\r\n\r\nW0828 15:46:36.311170 139684777486208 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/trainer_lib.py:111: The name tf.OptimizerOptions is deprecated. Please use tf.compat.v1.OptimizerOptions instead.\r\n\r\nW0828 15:46:36.326797 139684777486208 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensorflow_gan/python/contrib_utils.py:305: The name tf.estimator.tpu.TPUEstimator is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimator instead.\r\n\r\nW0828 15:46:36.327040 139684777486208 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensorflow_gan/python/contrib_utils.py:310: The name tf.estimator.tpu.TPUEstimatorSpec is deprecated. Please use tf.compat.v1.estimator.tpu.TPUEstimatorSpec instead.\r\n\r\nW0828 15:46:37.165019 139684777486208 deprecation_wrapper.py:119] From /usr/local/bin/t2t-trainer:32: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\r\n\r\nW0828 15:46:37.165243 139684777486208 deprecation_wrapper.py:119] From /usr/local/bin/t2t-trainer:32: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\r\n\r\nW0828 15:46:37.165358 139684777486208 deprecation_wrapper.py:119] From /usr/local/bin/t2t-trainer:33: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\r\n\r\nW0828 15:46:37.166135 139684777486208 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/hparams_lib.py:49: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\r\n\r\nI0828 15:46:37.167073 139684777486208 hparams_lib.py:64] Loading hparams from existing json /content/gdrive/My Drive/TCC/T2T LibriSpeech/output/hparams.json\r\nW0828 15:46:37.167232 139684777486208 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/hparams_lib.py:65: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\r\n\r\nW0828 15:46:37.169995 139684777486208 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/trainer_lib.py:839: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\r\n\r\nW0828 15:46:37.170993 139684777486208 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/trainer_lib.py:123: The name tf.GraphOptions is deprecated. Please use tf.compat.v1.GraphOptions instead.\r\n\r\nW0828 15:46:37.171175 139684777486208 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/trainer_lib.py:129: The name tf.GPUOptions is deprecated. Please use tf.compat.v1.GPUOptions instead.\r\n\r\nW0828 15:46:37.171345 139684777486208 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/trainer_lib.py:242: RunConfig.__init__ (from tensorflow.contrib.learn.python.learn.estimators.run_config) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nWhen switching to tf.estimator.Estimator, use tf.estimator.RunConfig instead.\r\nI0828 15:46:37.171534 139684777486208 trainer_lib.py:265] Configuring DataParallelism to replicate the model.\r\nI0828 15:46:37.171617 139684777486208 devices.py:76] schedule=continuous_train_and_eval\r\nI0828 15:46:37.171699 139684777486208 devices.py:77] worker_gpu=1\r\nI0828 15:46:37.171761 139684777486208 devices.py:78] sync=False\r\nW0828 15:46:37.171855 139684777486208 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/devices.py:139: The name tf.logging.warn is deprecated. Please use tf.compat.v1.logging.warn instead.\r\n\r\nW0828 15:46:37.171929 139684777486208 devices.py:141] Schedule=continuous_train_and_eval. Assuming that training is running on a single machine.\r\nI0828 15:46:37.172624 139684777486208 devices.py:170] datashard_devices: ['gpu:0']\r\nI0828 15:46:37.172721 139684777486208 devices.py:171] caching_devices: None\r\nI0828 15:46:37.173149 139684777486208 devices.py:172] ps_devices: ['gpu:0']\r\nI0828 15:46:37.173902 139684777486208 estimator.py:209] Using config: {'_task_type': None, '_task_id': 0, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0aa908abe0>, '_master': '', '_num_ps_replicas': 0, '_num_worker_replicas': 0, '_environment': 'local', '_is_chief': True, '_evaluation_master': '', '_train_distribute': None, '_eval_distribute': None, '_experimental_max_worker_delay_secs': None, '_device_fn': None, '_tf_config': gpu_options {\r\n  per_process_gpu_memory_fraction: 1.0\r\n}\r\n, '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_secs': None, '_log_step_count_steps': 100, '_protocol': None, '_session_config': gpu_options {\r\n  per_process_gpu_memory_fraction: 0.95\r\n}\r\nallow_soft_placement: true\r\ngraph_options {\r\n  optimizer_options {\r\n    global_jit_level: OFF\r\n  }\r\n}\r\nisolate_session_state: true\r\n, '_save_checkpoints_steps': 1000, '_keep_checkpoint_max': 20, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/content/gdrive/My Drive/TCC/T2T LibriSpeech/output/', 'use_tpu': False, 't2t_device_info': {'num_async_replicas': 1}, 'data_parallelism': <tensor2tensor.utils.expert_utils.Parallelism object at 0x7f0aa908af28>}\r\nW0828 15:46:37.174193 139684777486208 model_fn.py:630] Estimator's model_fn (<function T2TModel.make_estimator_model_fn.<locals>.wrapping_model_fn at 0x7f0aa9087ae8>) includes params argument, but params are not passed to Estimator.\r\nW0828 15:46:37.174434 139684777486208 trainer_lib.py:783] ValidationMonitor only works with --schedule=train_and_evaluate\r\nI0828 15:46:37.185815 139684777486208 estimator_training.py:186] Not using Distribute Coordinator.\r\nI0828 15:46:37.186260 139684777486208 training.py:612] Running training and evaluation locally (non-distributed).\r\nI0828 15:46:37.186565 139684777486208 training.py:700] Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 1000 or save_checkpoints_secs None.\r\nE0828 15:46:37.192399 139684777486208 checkpoint_management.py:348] Couldn't match files for checkpoint /content/gdrive/My Drive/TCC/T2T LibriSpeech/output/model.ckpt-13000\r\nW0828 15:46:37.197599 139684777486208 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\r\nI0828 15:46:37.208258 139684777486208 problem.py:644] Reading data files from /content/gdrive/My Drive/TCC/T2T LibriSpeech/data/librispeech_clean_small-train*\r\nI0828 15:46:37.229276 139684777486208 problem.py:670] partition: 0 num_data_files: 100\r\nW0828 15:46:37.232276 139684777486208 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/data_generators/problem.py:680: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\r\nW0828 15:46:37.275019 139684777486208 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/common_audio.py:92: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.cast` instead.\r\nW0828 15:46:37.562360 139684777486208 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/common_audio.py:115: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.cast` instead.\r\nW0828 15:46:37.750620 139684777486208 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/data_reader.py:275: tf_record_iterator (from tensorflow.python.lib.io.tf_record) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse eager execution and: \r\n`tf.data.TFRecordDataset(path)`\r\nW0828 15:46:38.267626 139684777486208 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/data_reader.py:395: DatasetV1.output_shapes (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.compat.v1.data.get_output_shapes(dataset)`.\r\nW0828 15:46:38.267972 139684777486208 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/data_reader.py:398: The name tf.logging.warning is deprecated. Please use tf.compat.v1.logging.warning instead.\r\n\r\nW0828 15:46:38.268058 139684777486208 data_reader.py:399] Shapes are not fully defined. Assuming batch_size means tokens.\r\nW0828 15:46:38.323740 139684777486208 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/data/experimental/ops/grouping.py:193: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.where in 2.0, which has the same broadcast rule as np.where\r\nW0828 15:46:38.372743 139684777486208 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/data_reader.py:231: The name tf.summary.scalar is deprecated. Please use tf.compat.v1.summary.scalar instead.\r\n\r\nI0828 15:46:38.437698 139684777486208 estimator.py:1145] Calling model_fn.\r\nI0828 15:46:38.450161 139684777486208 t2t_model.py:2248] Setting T2TModel mode to 'train'\r\nW0828 15:46:38.529374 139684777486208 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/t2t_model.py:244: The name tf.summary.text is deprecated. Please use tf.compat.v1.summary.text instead.\r\n\r\nI0828 15:46:39.269068 139684777486208 api.py:255] Using variable initializer: uniform_unit_scaling\r\nI0828 15:46:39.718456 139684777486208 t2t_model.py:2248] Transforming feature 'inputs' with speech_recognition_modality.bottom\r\nW0828 15:46:39.720613 139684777486208 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/modalities.py:439: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.keras.layers.Conv2D` instead.\r\nI0828 15:46:40.186799 139684777486208 t2t_model.py:2248] Transforming feature 'targets' with symbol_modality_256_384.targets_bottom\r\nI0828 15:46:40.323158 139684777486208 t2t_model.py:2248] Building model body\r\nW0828 15:46:40.388057 139684777486208 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/models/transformer.py:96: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\r\nW0828 15:46:40.435504 139684777486208 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/common_layers.py:3077: The name tf.layers.Dense is deprecated. Please use tf.compat.v1.layers.Dense instead.\r\n\r\nW0828 15:46:40.844527 139684777486208 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/layers/common_attention.py:1249: The name tf.summary.image is deprecated. Please use tf.compat.v1.summary.image instead.\r\n\r\nI0828 15:46:48.565067 139684777486208 t2t_model.py:2248] Transforming body output with symbol_modality_256_384.top\r\nW0828 15:46:48.689695 139684777486208 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/learning_rate.py:120: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\r\n\r\nI0828 15:46:48.691083 139684777486208 learning_rate.py:29] Base learning rate: 2.000000\r\nI0828 15:46:48.704310 139684777486208 optimize.py:338] Trainable Variables Total size: 70343552\r\nI0828 15:46:48.704722 139684777486208 optimize.py:338] Non-trainable variables Total size: 5\r\nI0828 15:46:48.705073 139684777486208 optimize.py:193] Using optimizer adam\r\nI0828 15:47:00.715373 139684777486208 estimator.py:1147] Done calling model_fn.\r\nI0828 15:47:00.717198 139684777486208 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\r\nI0828 15:47:05.476253 139684777486208 monitored_session.py:240] Graph was finalized.\r\n2019-08-28 15:47:05.480538: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200000000 Hz\r\n2019-08-28 15:47:05.480819: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x22a5640 executing computations on platform Host. Devices:\r\n2019-08-28 15:47:05.480857: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\r\nW0828 15:47:05.483572 139684777486208 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse standard file APIs to check for files with this prefix.\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/t2t-trainer\", line 33, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/usr/local/bin/t2t-trainer\", line 28, in main\r\n    t2t_trainer.main(argv)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensor2tensor/bin/t2t_trainer.py\", line 412, in main\r\n    execute_schedule(exp)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensor2tensor/bin/t2t_trainer.py\", line 367, in execute_schedule\r\n    getattr(exp, FLAGS.schedule)()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensor2tensor/utils/trainer_lib.py\", line 456, in continuous_train_and_eval\r\n    self._eval_spec)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 473, in train_and_evaluate\r\n    return executor.run()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 613, in run\r\n    return self.run_local()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/training.py\", line 714, in run_local\r\n    saving_listeners=saving_listeners)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 367, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1158, in _train_model\r\n    return self._train_model_default(input_fn, hooks, saving_listeners)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1192, in _train_model_default\r\n    saving_listeners)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/estimator.py\", line 1480, in _train_with_estimator_spec\r\n    log_step_count_steps=log_step_count_steps) as mon_sess:\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 584, in MonitoredTrainingSession\r\n    stop_grace_period_secs=stop_grace_period_secs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1007, in __init__\r\n    stop_grace_period_secs=stop_grace_period_secs)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 725, in __init__\r\n    self._sess = _RecoverableSession(self._coordinated_creator)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1200, in __init__\r\n    _WrappedSession.__init__(self, self._create_session())\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 1205, in _create_session\r\n    return self._sess_creator.create_session()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 871, in create_session\r\n    self.tf_sess = self._session_creator.create_session()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py\", line 647, in create_session\r\n    init_fn=self._scaffold.init_fn)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/session_manager.py\", line 290, in prepare_session\r\n    config=config)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/session_manager.py\", line 220, in _restore_checkpoint\r\n    saver.restore(sess, ckpt.model_checkpoint_path)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py\", line 1278, in restore\r\n    compat.as_text(save_path))\r\nValueError: The passed save_path is not a valid checkpoint: /content/gdrive/My Drive/TCC/T2T LibriSpeech/output/model.ckpt-13000\r\n```", "If you take the file model.ckpt outside of train folder, you will get this problem. You should export the inference_graph with de data wich was trained your model.", "> Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\r\n> Have I written custom code\r\n> OS Platform and Distribution\r\n> TensorFlow installed from\r\n> TensorFlow version\r\n> Bazel version\r\n> CUDA/cuDNN version\r\n> GPU model and memory\r\n> Exact command to reproduce\r\n> Mobile device\r\n\r\nNo taken code from tech with Tim chatbot video\r\nOs : Windows 10 and distribution anaconda\r\ntensorflow installed from anaconda\r\ntensorflow versions = 1.14.0\r\n.\r\ncuda 10.1\r\ngpu Nvidia gtx 2060 ti\r\n.\r\n.\r\nMy error is same", "I am using google colab with tensorflow 2.3.0 on Ubuntu. I have also tried working with tensroflow 1.15 and come to a similar error (possibly for same reason???)\r\n\r\nCode is from here [https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#exporting-a-trained-model](url)\r\n\r\nError is here\r\n`2020-09-06 08:03:23.830447: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-09-06 08:03:25.844063: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\r\n2020-09-06 08:03:25.879149: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-09-06 08:03:25.879813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\r\ncoreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\r\n2020-09-06 08:03:25.879853: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-09-06 08:03:25.881273: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-09-06 08:03:25.882999: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-09-06 08:03:25.883384: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-09-06 08:03:25.885102: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-09-06 08:03:25.886330: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-09-06 08:03:25.889988: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-09-06 08:03:25.890105: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-09-06 08:03:25.891047: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-09-06 08:03:25.891854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-09-06 08:03:25.901457: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz\r\n2020-09-06 08:03:25.901653: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2cdd480 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-09-06 08:03:25.901678: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-09-06 08:03:26.012959: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-09-06 08:03:26.013665: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x2cdd640 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-09-06 08:03:26.013697: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\r\n2020-09-06 08:03:26.013935: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-09-06 08:03:26.014510: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:00:04.0 name: Tesla T4 computeCapability: 7.5\r\ncoreClock: 1.59GHz coreCount: 40 deviceMemorySize: 14.73GiB deviceMemoryBandwidth: 298.08GiB/s\r\n2020-09-06 08:03:26.014556: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-09-06 08:03:26.014600: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-09-06 08:03:26.014625: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-09-06 08:03:26.014647: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-09-06 08:03:26.014667: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-09-06 08:03:26.014689: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-09-06 08:03:26.014712: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-09-06 08:03:26.014784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-09-06 08:03:26.015364: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-09-06 08:03:26.015875: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n2020-09-06 08:03:26.015919: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-09-06 08:03:26.651590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1257] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-09-06 08:03:26.651650: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1263]      0 \r\n2020-09-06 08:03:26.651663: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1276] 0:   N \r\n2020-09-06 08:03:26.651874: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-09-06 08:03:26.652564: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-09-06 08:03:26.653153: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\r\n2020-09-06 08:03:26.653195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1402] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13962 MB memory) -> physical GPU (device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5)\r\nTraceback (most recent call last):\r\n  File \"exporter_main_v2.py\", line 159, in <module>\r\n    app.run(main)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"exporter_main_v2.py\", line 155, in main\r\n    FLAGS.side_input_types, FLAGS.side_input_names)\r\n  File \"/usr/local/lib/python3.6/dist-packages/object_detection-0.1-py3.6.egg/object_detection/exporter_lib_v2.py\", line 260, in export_inference_graph\r\n    status.assert_existing_objects_matched()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/util.py\", line 885, in assert_existing_objects_matched\r\n    \"No checkpoint specified (save_path=None); nothing is being restored.\")\r\nAssertionError: No checkpoint specified (save_path=None); nothing is being restored.`\r\n\r\nThere are multiple .ckpt files in the directory as training seemed to run smoothly"]}, {"number": 22442, "title": "get error run simple_estimator_example.py", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Just example from tensorflow.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:macOS High Sierra 10.13.6\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:None\r\n- **TensorFlow installed from (source or binary)**:Ananconda3\r\n- **TensorFlow version (use command below)**:Tensorflow 1.10\r\n- **Python version**: Python 3.65\r\n- **Bazel version (if compiling from source)**:NaN\r\n- **GCC/Compiler version (if compiling from source)**:NaN\r\n- **CUDA/cuDNN version**:NaN\r\n- **GPU model and memory**:NaN\r\n- **Exact command to reproduce**:  config = tf.estimator.RunConfig(train_distribute=distribution,\r\n eval_distribute=distribution)\r\n\r\n### Describe the problem\r\nI just download the official example-\"simple_estimator_example.py\" and run it in my own computer. But I just get this error `  config = tf.estimator.RunConfig(train_distribute=distribution,eval_distribute=distribution)`. \r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["@AmberCheng Hi, Could you please post the source code/logs which you are getting.", "> @AmberCheng Hi, Could you please post the source code/logs which you are getting.\r\n\r\nThe logs are like that:\r\n```\r\n/Users/amber/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\r\n  return f(*args, **kwds)\r\n/Users/amber/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\ndense (Dense)                (None, 16)                176       \r\n_________________________________________________________________\r\ndense_1 (Dense)              (None, 16)                272       \r\n_________________________________________________________________\r\ndense_2 (Dense)              (None, 1)                 17        \r\n=================================================================\r\nTotal params: 465\r\nTrainable params: 465\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\nTraceback (most recent call last):\r\n  File \"/Users/amber/Documents/dstf/test_1.11.py\", line 74, in <module>\r\n    tf.app.run(argv=sys.argv)\r\n  File \"/Users/amber/anaconda3/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"/Users/amber/Documents/dstf/test_1.11.py\", line 62, in main\r\n    train_distribute=strategy, eval_distribute=strategy)\r\nTypeError: __init__() got an unexpected keyword argument 'eval_distribute'\r\n[Finished in 5.8s with exit code 1] \r\n```", "This problem is fixed in tensorflow 1.11.Thank you so much~~"]}, {"number": 22441, "title": "[Request] Please make version-compatible table among them: \"python/tensorflow/tensorflow-gpu/tflearn/cuDNN/CUDA\"", "body": "Request: Version-Compatible Table\r\n\r\nThere are a lot of people using Tensorflow, and I'm sure that those people at least have tried to use tflearn, tensorflow-gpu, cuDNN CUDA, etc. And again, I'm very sure we have had the problem of version incompatibility many many many... times. We've done a lot of research to resolve this incompatibility. We tried all kinds of version combinations. And something came to mind:\r\n\"Why there wasn't a Version-Compatible table?\"\r\n\r\nLike: https://www.tensorflow.org/install/source_windows (Tested build configurations)\r\n\r\nExample:\r\n\r\nWhich version tensorflow-gpu (X version) want at least (also MAX.) Python version?\r\nWhich version tensorflow-gpu (X version) want at least (also MAX.) cuDNN version?\r\nWhich version tensorflow-gpu (X version) want at least (also MAX.) CUDA version?\r\n\r\nWhich tflearn versions are compatible with which tensorflow (X) versions?\r\nWhich tflearn versions are compatible with which tensorflow-gpu (X) versions?\r\n\r\nWhich CUDA versions are compatible (at least and MAX) with which tensorflow-gpu versions?\r\n\r\netc... It could be an Exel table that clears all of these questions from our minds. Wouldn't that be good? You need to enter individual wiki pages and investigate version compatible each time. (I mean that waste of time)\r\n\r\nThanks in advance...\r\n", "comments": ["I tried installing the newest Tensorflow (1.11.0-rc1) with the newest Python (3.7.0), newest CUDA (9.2) and the newest cuDNN (7.2). It failed miserably.\r\n\r\nNow with CUDA 10.0 and cuDNN 7.3 it will be an even bigger mess. A compatibility table would help very much! ", "@Dentrax Please find \"Tested build configurations\" table in this [link.](https://www.tensorflow.org/install/source#tested_build_configurations)", "@harshini-gadige Nice! Could a table for Windows be added and minor CUDA revisions? CUDA 9.2 didn't work for me on 1.10, only 9.0 did.", "@EwoutH  Here is the link for [Windows](https://www.tensorflow.org/install/source_windows#tested_build_configurations). Please find \"Tested build configurations\". Windows supports only Python3(not Python2). Currently there is no low level table containing minor CUDA revisions. Will keep posted if there is any such table in future."]}, {"number": 22440, "title": "Import tensorflow ,Kernel died,restarting ", "body": "### System information\r\n- **OS Platform and Distribution (Windows 10)**:\r\n- **TensorFlow installed from :pip3\r\n- **TensorFlow version :1.5\r\n- **Python version: 2.7.14\r\n- **GPU model and memory: Nvidia GT540M 1GB\r\n\r\n### Describe the problem\r\nOn importing tensorflow i get this error. Downgraded to 1.5 still the same error as on the lastest version.\r\n1) Spyder and Jupyter both result in the same error\r\n", "comments": ["@yaskh Hi, try restarting the kernel and run \"pip install ipykernel\". ", "Install a lower version of tensorflow, It works for me.", " Got this error when i run the command: \r\nCollecting ipykernal\r\n  Could not find a version that satisfies the requirement ipykernal (from versions: )\r\nNo matching distribution found for ipykernal", "@yaskh Have you tried with a lower version of tensorflow ?", "@yaskh There is also a possibility that the firewall/internet security is blocking the kernel to start. So can you stop the firewall and try it again. Please post your observation once done. Thank you !", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "I have a version 1.5 of tensorflow(have downgraded it) and 3.3.1 of spyder. \r\nI have tried updating the wait time to more than 60 seconds and also installed ipykernel and still the problem persists.\r\nI am running anaconda on a 16GB DDR4 ram with i7-7500u processor machine and still the error says:-kernel died, restarting", "apple m1, when import tensorflow: dead kernel\r\n", "same issue not able to solve it after 3 dayss                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              "]}, {"number": 22439, "title": "Import tensorflow Kernel died,restarting ", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nOn imp\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["Duplicate of #22440 "]}, {"number": 22438, "title": "InvalidArgumentError when SparseTensorValue is not ordered by row then col", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS 10.13.6\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: no\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: v1.10.0-rc1-19-g656e7a2b34 1.10.0\r\n- **Python version**: 3.6.5\r\n- **Bazel version (if compiling from source)**: no\r\n- **GCC/Compiler version (if compiling from source)**: no\r\n- **CUDA/cuDNN version**: no\r\n- **GPU model and memory**: no\r\n- **Exact command to reproduce**: `python bug.py`\r\n\r\n### Describe the problem\r\n\r\nIf we feed a `SparseTensorValue` to `tf.data.Dataset.from_tensor_slices` such that its indices are not lexicographically sorted by row then col, then we will get a `InvalidArgumentError`.\r\n\r\nMaybe it could be said in the docs, or the error should provide a clearer message. It was hard to guess that `indices[2] = [1,0] is out of order` meant the indices were not provided in lexicographic order.\r\n\r\nI finally saw that it was explained in the [`SparseTensor` docs](https://www.tensorflow.org/api_docs/python/tf/SparseTensor), but I feel it should be said in the [`SparseTensorValue` docs](https://www.tensorflow.org/api_docs/python/tf/SparseTensorValue) as well.\r\n\r\n### Source code / logs\r\n\r\n```python\r\nfrom scipy.sparse import csr_matrix\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n\r\nM = np.array([[0, 1, 1], [1, 0, 0], [1, 0, 2], [0, 1, 1]])\r\n\r\n# First observation: these two slicing operations provide different orderings\r\nS = csr_matrix(M)[1:3].tocoo()\r\nprint('1:3', S.row, S.col)\r\nS = csr_matrix(M)[[1, 2]].tocoo()\r\nprint('1,2', S.row, S.col)\r\n\r\nentries = np.column_stack((S.row, S.col, S.data))\r\nordering = np.arange(len(S.data))\r\n\r\n# Uncomment the following line to fix the error\r\n# ordering = np.lexsort((S.col, S.row))  # Sort by row then col\r\n\r\nX_train = tf.SparseTensorValue(indices=entries[ordering, :2],\r\n                               values=entries[ordering, 2],\r\n                               dense_shape=S.shape)\r\n\r\ndataset = tf.data.Dataset.from_tensor_slices(X_train)\r\niterator = dataset.make_initializable_iterator()\r\nX_sample = iterator.get_next()\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(iterator.initializer)\r\n    print(sess.run(X_sample))\r\n```\r\n\r\n    Traceback (most recent call last):\r\n      File \"/Users/jilljenn/code/vae/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1278, in _do_call\r\n        return fn(*args)\r\n      File \"/Users/jilljenn/code/vae/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1263, in _run_fn\r\n        options, feed_dict, fetch_list, target_list, run_metadata)\r\n      File \"/Users/jilljenn/code/vae/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1350, in _call_tf_sessionrun\r\n        run_metadata)\r\n    tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[2] = [1,0] is out of order\r\n         [[Node: SerializeManySparse = SerializeManySparse[T=DT_INT64, out_type=DT_VARIANT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](tensors/SparseTensor/indices, tensors/SparseTensor/values, tensors/SparseTensor/dense_shape)]]\r\n\r\n    During handling of the above exception, another exception occurred:\r\n\r\n    Traceback (most recent call last):\r\n      File \"bug.py\", line 27, in <module>\r\n        sess.run(iterator.initializer)\r\n      File \"/Users/jilljenn/code/vae/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 877, in run\r\n        run_metadata_ptr)\r\n      File \"/Users/jilljenn/code/vae/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1100, in _run\r\n        feed_dict_tensor, options, run_metadata)\r\n      File \"/Users/jilljenn/code/vae/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1272, in _do_run\r\n        run_metadata)\r\n      File \"/Users/jilljenn/code/vae/venv/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1291, in _do_call\r\n        raise type(e)(node_def, op, message)\r\n    tensorflow.python.framework.errors_impl.InvalidArgumentError: indices[2] = [1,0] is out of order\r\n         [[Node: SerializeManySparse = SerializeManySparse[T=DT_INT64, out_type=DT_VARIANT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](tensors/SparseTensor/indices, tensors/SparseTensor/values, tensors/SparseTensor/dense_shape)]]\r\n\r\n    Caused by op 'SerializeManySparse', defined at:\r\n      File \"bug.py\", line 22, in <module>\r\n        dataset = tf.data.Dataset.from_tensor_slices(X_train)\r\n      File \"/Users/jilljenn/code/vae/venv/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 254, in from_tensor_slices\r\n        return TensorSliceDataset(tensors)\r\n      File \"/Users/jilljenn/code/vae/venv/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1173, in __init__\r\n        self._tensors = sparse.serialize_many_sparse_tensors(tensors)\r\n      File \"/Users/jilljenn/code/vae/venv/lib/python3.6/site-packages/tensorflow/python/data/util/sparse.py\", line 132, in serialize_many_sparse_tensors\r\n        for tensor in nest.flatten(tensors)\r\n      File \"/Users/jilljenn/code/vae/venv/lib/python3.6/site-packages/tensorflow/python/data/util/sparse.py\", line 132, in <listcomp>\r\n        for tensor in nest.flatten(tensors)\r\n      File \"/Users/jilljenn/code/vae/venv/lib/python3.6/site-packages/tensorflow/python/ops/sparse_ops.py\", line 1469, in serialize_many_sparse\r\n        out_type=out_type)\r\n      File \"/Users/jilljenn/code/vae/venv/lib/python3.6/site-packages/tensorflow/python/ops/gen_sparse_ops.py\", line 502, in serialize_many_sparse\r\n        out_type=out_type, name=name)\r\n      File \"/Users/jilljenn/code/vae/venv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n        op_def=op_def)\r\n      File \"/Users/jilljenn/code/vae/venv/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 454, in new_func\r\n        return func(*args, **kwargs)\r\n      File \"/Users/jilljenn/code/vae/venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3155, in create_op\r\n        op_def=op_def)\r\n      File \"/Users/jilljenn/code/vae/venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1717, in __init__\r\n        self._traceback = tf_stack.extract_stack()\r\n\r\n    InvalidArgumentError (see above for traceback): indices[2] = [1,0] is out of order\r\n         [[Node: SerializeManySparse = SerializeManySparse[T=DT_INT64, out_type=DT_VARIANT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](tensors/SparseTensor/indices, tensors/SparseTensor/values, tensors/SparseTensor/dense_shape)]]", "comments": ["@jilljenn Good catch and agreed that more clarity on SparseTensorValue would help. \r\n\r\n@MarkDaoust Can you take a look at this?", "Closing this issue, we will add this to the future release.", "I've also met this error and been confused this message.\r\n~I hope you to implement some sorting function to avoid this error~ as well as to update the error message.\r\n\r\n- Environment: \r\n    - macOS: 10.14.4\r\n    - docker: 19.03.1\r\n    - docker image: tensorflow/tensorflow:latest-py3\r\n\r\nSorry, I missed to find the description and the function.\r\n- https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor\r\n- https://www.tensorflow.org/api_docs/python/tf/sparse/reorder", "@hiro-o918 thanks for pinging this bug, \r\n\r\nI've improved the error message to point people in the right direction:\r\n\r\n```\r\n InvalidArgumentError (see above for traceback): indices[2] = [1,0] is out of order. Many sparse ops require sorted indices.\r\n    Use `tf.sparse.reorder` to create a correctly ordered copy.\r\n```\r\n\r\n"]}, {"number": 22437, "title": "tensorflow-1.11.0-rc1 fails to build", "body": "\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nNo\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 16.04.5 LTS\r\n\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: \r\nNo\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\nsource\r\n\r\n- **TensorFlow version (use command below)**:\r\n1.11.0-rc1\r\n\r\n- **Python version**:\r\n3.5\r\n\r\n- **Bazel version (if compiling from source)**:\r\n0.17.1\r\n\r\n- **GCC/Compiler version (if compiling from source)**:cc \r\n5.4.0\r\n\r\n- **CUDA/cuDNN version**:\r\nCUDA10.0 \r\ncuDNN 7.2\r\n\r\n- **GPU model and memory**:\r\nGTX1070\r\n\r\nTried to build tensorflow-1.11.0-rc1 but it failed with\r\n\r\n> ERROR: /home/bernard/opt/cuda_test/cuda10/tensorflow-1.11.0-rc1/tensorflow/contrib/verbs/BUILD:90:1: C++ compilation of rule '//tensorflow/contrib/verbs:rdma_rendezvous_mgr' failed (Exit 1)\r\n\r\nTo be sure that it is not  because cuda is too new I tried also build tensorflow-1.10.1 and it built without problem\r\n\r\nI tried googling and dug up this old bug https://github.com/tensorflow/tensorflow/issues/9752", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nExact command to reproduce", "Updated\r\n\r\nExact command to reproduce\r\n\r\nNA", "Someone just reported exactly the same error\r\nhttps://github.com/tensorflow/tensorflow/issues/22455", "The other issue articulates the problem better.\r\nTF 1.11 builds fine, the problem is verbs support.\r\nI will close this issue and continue on the other one."]}, {"number": 22436, "title": "freeze.py OP_REQUIRES failed at save_restore_tensor.cc", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nNo\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows 7 \r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary\r\n- **TensorFlow version (use command below)**:\r\n1.5\r\n- **Python version**:\r\n3.6\r\n- **Bazel version (if compiling from source)**:\r\nNA\r\n- **GCC/Compiler version (if compiling from source)**:\r\nNA\r\n- **CUDA/cuDNN version**:\r\nNA\r\n- **GPU model and memory**:\r\nNA\r\n- **Exact command to reproduce**:\r\n(tensorflow) C:\\tensorflow-master> python tensorflow/examples/speech_commands/freeze.py \\\r\n--start_checkpoint=C:/tmp/speech_commands_train/conv.ckpt-1400 \\\r\n--output_file=c:/tmp/my_frozen_graph.pb\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nI ran the command from https://www.tensorflow.org/tutorials/sequences/audio_recognition and got the following error\r\n\r\n### Source code / logs\r\n(tensorflow) C:\\tensorflow-master>python tensorflow/examples/speech_commands/fre\r\neze.py \\\r\n2018-09-20 17:13:42.678960: W tensorflow/core/framework/op_kernel.cc:1318] OP_RE\r\nQUIRES failed at save_restore_tensor.cc:170 : Not found: Unsuccessful TensorSlic\r\neReader constructor: Failed to find any matching files for\r\nTraceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\client\\session.py\", line 1322, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\client\\session.py\", line 1307, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\client\\session.py\", line 1409, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceR\r\neader constructor: Failed to find any matching files for\r\n         [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT\r\n, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device\r\n:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_\r\nand_slices)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"tensorflow/examples/speech_commands/freeze.py\", line 208, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\platform\\app.py\", line 126, in run\r\n    _sys.exit(main(argv))\r\n  File \"tensorflow/examples/speech_commands/freeze.py\", line 134, in main\r\n    models.load_variables_from_checkpoint(sess, FLAGS.start_checkpoint)\r\n  File \"C:\\tensorflow-master\\tensorflow\\examples\\speech_commands\\models.py\", lin\r\ne 155, in load_variables_from_checkpoint\r\n    saver.restore(sess, start_checkpoint)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\training\\saver.py\", line 1802, in restore\r\n    {self.saver_def.filename_tensor_name: save_path})\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\client\\session.py\", line 900, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\client\\session.py\", line 1135, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\client\\session.py\", line 1316, in _do_run\r\n    run_metadata)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\client\\session.py\", line 1335, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceR\r\neader constructor: Failed to find any matching files for\r\n         [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT\r\n, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device\r\n:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_\r\nand_slices)]]\r\n\r\nCaused by op 'save/RestoreV2', defined at:\r\n  File \"tensorflow/examples/speech_commands/freeze.py\", line 208, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\platform\\app.py\", line 126, in run\r\n    _sys.exit(main(argv))\r\n  File \"tensorflow/examples/speech_commands/freeze.py\", line 134, in main\r\n    models.load_variables_from_checkpoint(sess, FLAGS.start_checkpoint)\r\n  File \"C:\\tensorflow-master\\tensorflow\\examples\\speech_commands\\models.py\", lin\r\ne 154, in load_variables_from_checkpoint\r\n    saver = tf.train.Saver(tf.global_variables())\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\training\\saver.py\", line 1338, in __init__\r\n    self.build()\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\training\\saver.py\", line 1347, in build\r\n    self._build(self._filename, build_save=True, build_restore=True)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\training\\saver.py\", line 1384, in _build\r\n    build_save=build_save, build_restore=build_restore)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\training\\saver.py\", line 835, in _build_internal\r\n    restore_sequentially, reshape)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\training\\saver.py\", line 472, in _AddRestoreOps\r\n    restore_sequentially)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\training\\saver.py\", line 886, in bulk_restore\r\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\ops\\gen_io_ops.py\", line 1462, in restore_v2\r\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\framework\\ops.py\", line 3392, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\framework\\ops.py\", line 1718, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-\r\naccess\r\n\r\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader construc\r\ntor: Failed to find any matching files for\r\n         [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT\r\n, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device\r\n:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_\r\nand_slices)]]\r\n\r\n\r\n(tensorflow) C:\\tensorflow-master>--start_checkpoint=C:/tmp/speech_commands_trai\r\nn/conv.ckpt-1400 \\\r\n'--start_checkpoint' is not recognized as an internal or external command,\r\noperable program or batch file.\r\n\r\n(tensorflow) C:\\tensorflow-master>--output_file=c:/tmp/my_frozen_graph.pb\r\n'--output_file' is not recognized as an internal or external command,\r\noperable program or batch file.\r\n\r\n(tensorflow) C:\\tensorflow-master>1a\r\n\r\n(tensorflow) C:\\tensorflow-master>python tensorflow/examples/speech_commands/fre\r\neze.py \\\r\n2018-09-20 17:28:18.766069: W tensorflow/core/framework/op_kernel.cc:1318] OP_RE\r\nQUIRES failed at save_restore_tensor.cc:170 : Not found: Unsuccessful TensorSlic\r\neReader constructor: Failed to find any matching files for\r\nTraceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\client\\session.py\", line 1322, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\client\\session.py\", line 1307, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\client\\session.py\", line 1409, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceR\r\neader constructor: Failed to find any matching files for\r\n         [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT\r\n, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device\r\n:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_\r\nand_slices)]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"tensorflow/examples/speech_commands/freeze.py\", line 208, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\platform\\app.py\", line 126, in run\r\n    _sys.exit(main(argv))\r\n  File \"tensorflow/examples/speech_commands/freeze.py\", line 134, in main\r\n    models.load_variables_from_checkpoint(sess, FLAGS.start_checkpoint)\r\n  File \"C:\\tensorflow-master\\tensorflow\\examples\\speech_commands\\models.py\", lin\r\ne 155, in load_variables_from_checkpoint\r\n    saver.restore(sess, start_checkpoint)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\training\\saver.py\", line 1802, in restore\r\n    {self.saver_def.filename_tensor_name: save_path})\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\client\\session.py\", line 900, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\client\\session.py\", line 1135, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\client\\session.py\", line 1316, in _do_run\r\n    run_metadata)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\client\\session.py\", line 1335, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceR\r\neader constructor: Failed to find any matching files for\r\n         [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT\r\n, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device\r\n:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_\r\nand_slices)]]\r\n\r\nCaused by op 'save/RestoreV2', defined at:\r\n  File \"tensorflow/examples/speech_commands/freeze.py\", line 208, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\platform\\app.py\", line 126, in run\r\n    _sys.exit(main(argv))\r\n  File \"tensorflow/examples/speech_commands/freeze.py\", line 134, in main\r\n    models.load_variables_from_checkpoint(sess, FLAGS.start_checkpoint)\r\n  File \"C:\\tensorflow-master\\tensorflow\\examples\\speech_commands\\models.py\", lin\r\ne 154, in load_variables_from_checkpoint\r\n    saver = tf.train.Saver(tf.global_variables())\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\training\\saver.py\", line 1338, in __init__\r\n    self.build()\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\training\\saver.py\", line 1347, in build\r\n    self._build(self._filename, build_save=True, build_restore=True)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\training\\saver.py\", line 1384, in _build\r\n    build_save=build_save, build_restore=build_restore)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\training\\saver.py\", line 835, in _build_internal\r\n    restore_sequentially, reshape)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\training\\saver.py\", line 472, in _AddRestoreOps\r\n    restore_sequentially)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\training\\saver.py\", line 886, in bulk_restore\r\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\ops\\gen_io_ops.py\", line 1462, in restore_v2\r\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\framework\\ops.py\", line 3392, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\py\r\nthon\\framework\\ops.py\", line 1718, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-\r\naccess\r\n\r\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader construc\r\ntor: Failed to find any matching files for\r\n         [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT\r\n, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device\r\n:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_\r\nand_slices)]]\r\n\r\n\r\n(tensorflow) C:\\tensorflow-master>--start_checkpoint=C:\\\\tmp\\\\speech_commands_tr\r\nain\\\\conv.ckpt-1400 \\\r\n'--start_checkpoint' is not recognized as an internal or external command,\r\noperable program or batch file.\r\n\r\n(tensorflow) C:\\tensorflow-master>--output_file=c:\\\\tmp\\\\my_frozen_graph.pb\r\n'--output_file' is not recognized as an internal or external command,\r\noperable program or batch file.\r\n\r\n(tensorflow) C:\\tensorflow-master>", "comments": ["@pauldelmusica Hi, could you please precise the error you are getting.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 22435, "title": "Fix control edge issue while constructing TRTEngineOp nodes", "body": "This PR fixes an issue with control edges when constructing TRTEngineOp nodes. Duplicate addition of control edges both to the NodeDef and to the graph was breaking schema.\r\n\r\nAdditionally extra configuration parameters are added to the TRTOptimization pass to help better understanding the conversion process and help with similar issues in the future.", "comments": ["It has been 23 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "It has been 55 days that this pull-request has stalled. Please create a new pull-request with the requested changes."]}, {"number": 22434, "title": "kernel dying, after import.", "body": "Python 3.6.6 (default, Jul 19 2018, 14:25:17) \r\n[GCC 8.1.1 20180712 (Red Hat 8.1.1-5)] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow\r\nIllegal instruction (core dumped)\r\n", "comments": ["pytorch  works well, why not tensorflow.", "Duplicate of #22440. "]}, {"number": 22433, "title": "train_op given in estimator spec raising error while given with distribution strategy", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 7\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.9\r\n- **Python version**: 3.5.2\r\n- **CUDA/cuDNN version**: CuDA 9 and CuDNN 7\r\n- **GPU model and memory**: K1100M Quadro, 2 GB\r\n\r\n### Describe the problem\r\nWhile training simple mnist model with estimator, if the loss function is given to the optimiser for minimisation, the following error is reproduced.\r\n\r\n### Source code / logs\r\nFile \"D:/Userdata/Software/FullModelSeparate/train.py\", line 62, in <module>\r\n    tf.estimator.train_and_evaluate(mnist_est,train_spec=train_spec,eval_spec=eval_spec)\r\n  File \"C:\\Program Files\\Python 3.5\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\", line 447, in train_and_evaluate\r\n    return executor.run()\r\n  File \"C:\\Program Files\\Python 3.5\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\", line 531, in run\r\n    return self.run_local()\r\n  File \"C:\\Program Files\\Python 3.5\\lib\\site-packages\\tensorflow\\python\\estimator\\training.py\", line 669, in run_local\r\n    hooks=train_hooks)\r\n  File \"C:\\Program Files\\Python 3.5\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 366, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"C:\\Program Files\\Python 3.5\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 1117, in _train_model\r\n    return self._train_model_distributed(input_fn, hooks, saving_listeners)\r\n  File \"C:\\Program Files\\Python 3.5\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 1160, in _train_model_distributed\r\n    self.config)\r\n  File \"C:\\Program Files\\Python 3.5\\lib\\site-packages\\tensorflow\\python\\training\\distribute.py\", line 794, in call_for_each_tower\r\n    return self._call_for_each_tower(fn, *args, **kwargs)\r\n  File \"C:\\Program Files\\Python 3.5\\lib\\site-packages\\tensorflow\\contrib\\distribute\\python\\one_device_strategy.py\", line 77, in _call_for_each_tower\r\n    return fn(*args, **kwargs)\r\n  File \"C:\\Program Files\\Python 3.5\\lib\\site-packages\\tensorflow\\python\\estimator\\estimator.py\", line 1107, in _call_model_fn\r\n    model_fn_results = self._model_fn(features=features, **kwargs)\r\n  File \"D:\\Userdata\\Software\\FullModelSeparate\\ModelToEstimator.py\", line 110, in convert\r\n    return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=apply_gradient_op)\r\n  File \"C:\\Program Files\\Python 3.5\\lib\\site-packages\\tensorflow\\python\\estimator\\model_fn.py\", line 184, in __new__\r\n    _check_is_tensor_or_operation(train_op, 'train_op')\r\n  File \"C:\\Program Files\\Python 3.5\\lib\\site-packages\\tensorflow\\python\\estimator\\model_fn.py\", line 390, in _check_is_tensor_or_operation\r\n    raise TypeError('{} must be Operation or Tensor, given: {}'.format(name, x))\r\nTypeError: train_op must be Operation or Tensor, given: <tf.Variable 'global_step:0' shape=() dtype=int64>\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nBazel version\nExact command to reproduce\nMobile device", "I would like to encourage you take a look at [Fashion MNIST tutorial](https://www.tensorflow.org/tutorials/keras/basic_classification) and [custom estimator's](https://www.tensorflow.org/guide/custom_estimators), if you haven't already.\r\nThis question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 22432, "title": "tensorflow.python.framework.errors_impl.NotFoundError: /home/selena/pcn-master/pc_distance/tf_nndistance_so.so: undefined symbol: _ZN10tensorflow15OpKernelContext10CtxFailureEPKciRKNS_6StatusE", "body": "Error Message:\r\nTraceback (most recent call last):\r\n  File \"demo.py\", line 29, in <module>\r\n    model_module = importlib.import_module('.%s' % args.model_type, 'models')\r\n  File \"/home/selena/miniconda2/envs/tensorflow/lib/python3.5/importlib/__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 985, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 968, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 957, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 673, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 697, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\n  File \"/home/selena/pcn-master/models/pcn_cd.py\", line 2, in <module>\r\n    from tf_util import mlp, mlp_conv, chamfer, add_train_summary, add_valid_summary\r\n  File \"/home/selena/pcn-master/tf_util.py\", line 2, in <module>\r\n    from pc_distance import tf_nndistance, tf_approxmatch\r\n  File \"/home/selena/pcn-master/pc_distance/tf_nndistance.py\", line 5, in <module>\r\n    nn_distance_module=tf.load_op_library(os.path.join(BASE_DIR, 'tf_nndistance_so.so'))\r\n  File \"/home/selena/.local/lib/python3.5/site-packages/tensorflow/python/framework/load_library.py\", line 56, in load_op_library\r\n    lib_handle = py_tf.TF_LoadLibrary(library_filename, status)\r\n  File \"/home/selena/.local/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\", line 473, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.NotFoundError: /home/selena/pcn-master/pc_distance/tf_nndistance_so.so: undefined symbol: _ZN10tensorflow15OpKernelContext10CtxFailureEPKciRKNS_6StatusE\r\n\r\n\r\nMakeFile:\r\n cuda_inc = /usr/local/cuda-9.0/include/\r\ncuda_lib = /usr/local/cuda-9.0/lib64/\r\nnsync = /home/selena/miniconda2/envs/tensorflow/lib/python3.5/site-packages/external/nsync/public\r\nnvcc = /usr/local/cuda-9.0/bin/nvcc\r\ntf_inc = /home/selena/miniconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow/include\r\ntf_lib = /home/selena/miniconda2/envs/tensorflow/lib/python3.5/site-packages/tensorflow\r\n\r\nall: tf_nndistance_so.so tf_approxmatch_so.so\r\n\r\ntf_nndistance.cu.o: tf_nndistance.cu\r\n\t$(nvcc) tf_nndistance.cu -o tf_nndistance.cu.o -c -O2 -DGOOGLE_CUDA=1 -x cu -Xcompiler -fPIC\r\n\r\ntf_nndistance_so.so: tf_nndistance.cpp tf_nndistance.cu.o\r\n\tg++ tf_nndistance.cpp tf_nndistance.cu.o -o tf_nndistance_so.so \\\r\n\t-I $(cuda_inc) -I $(tf_inc) -I $(nsync) \\\r\n\t-L $(cuda_lib) -lcudart -L $(tf_lib) -ltensorflow_framework \\\r\n    -shared -std=c++11 -fPIC -O2\r\n\r\ntf_approxmatch.cu.o: tf_approxmatch.cu\r\n\t$(nvcc) tf_approxmatch.cu -o tf_approxmatch.cu.o -c -O2 -DGOOGLE_CUDA=1 -x cu -Xcompiler -fPIC\r\n\r\ntf_approxmatch_so.so: tf_approxmatch.cpp tf_approxmatch.cu.o\r\n\tg++ -shared $(CPPFLAGS) tf_approxmatch.cpp tf_approxmatch.cu.o -o tf_approxmatch_so.so \\\r\n\t-I $(cuda_inc) -I $(tf_inc) -I $(nsync) \\\r\n\t-L $(cuda_lib) -lcudart -L $(tf_lib) -ltensorflow_framework \\\r\n    -shared -std=c++11 -fPIC -O2\r\n\r\nclean:\r\n\trm -rf *.o *.so\r\n\r\n\r\nCuda:9.0\r\nTensorFlow: 1.5.0", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "@HappySelena Hi, could you please describe the issue clearly.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 22431, "title": "pip official package compiled differently with package in docker image?", "body": "I am working on filesystem plugin, a .so file, which works fine with official tensorflow pip package, but with tensorflow in tensorflow/tensorflow:1.7.0, i got error  `_ZN10tensorflow10FileSystem10FilesExistERKSt6vectorISsSaISsEEPS1_INS_6StatusESaIS6_EE`\r\n\r\n\r\nSeems tensorflow from pypi package is different from package in docker image?\r\nI checked docker hub image history `tensorflow/tensorflow:1.7.0` with docker history\r\n```\r\n/bin/sh -c pip --no-cache-dir install /tensorflow-1.7.0-cp27-cp27mu-manylinux1_x86_64.whl\r\n``` \r\nseems tensorflow is install from local wal, and tensorflow size is `16533200` and symbol i want to find missing\r\n\r\n```\r\n-rwxr-xr-x  1 root staff 16533200 Mar 29 17:04 libtensorflow_framework.so*\r\n\r\nnm libtensorflow_framework.so|grep _ZN10tensorflow10FileSystem10FilesExistERKSt6vectorISsSaISsEEPS1_INS_6StatusESaIS6_EE\r\n```\r\nBut if i uninstall tensorflow an reinstall in again\r\n```\r\npip uninstall -y tensorflow\r\npip install tensorflow==1.7.0\r\n```\r\n\r\ni get different tensorflow library with size `16337456`, and symbol i want to find  appears\r\n````\r\n16337456 Sep 20 02:45 libtensorflow_framework.so*\r\n\r\n nm libtensorflow_framework.so|grep _ZN10tensorflow10FileSystem10FilesExistERKSt6vectorISsSaISsEEPS1_INS_6StatusESaIS6_EE\r\n0000000000553240 T _ZN10tensorflow10FileSystem10FilesExistERKSt6vectorISsSaISsEEPS1_INS_6StatusESaIS6_EE\r\n```\r\n\r\nSo why and how to solve this? How can i compile a filesystem plugin compatible to tensorflow/tensorflow:1.7.0\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "@u2takey Could you try TensorFlow 1.10? Also make sure you completely uninstall TensorFlow before reinstalling. Please provide more information by filling out the above template .\r\n\r\n", "duplicate: https://github.com/tensorflow/tensorflow/issues/22339, closed"]}]