[{"number": 28413, "title": "tensorflow installation error", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution :windows 10\r\n- TensorFlow installed from :tensorflow.org\r\n- TensorFlow version:1.12.0\r\n- Python version:3.6\r\n- Installed using virtualenv? pip? conda?:pip\r\n- CUDA/cuDNN version:10.1\r\n- GPU model and memory: nVidia GeForce GTX 1060 6 GB \r\n\r\n\r\n\r\n**Describe the problem**\r\nWhile checking the installation of tensorflow in python idle i found the importerror?\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n>>> import tensorflow as tf\r\n\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\parek\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\parek\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\parek\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\parek\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\parek\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<pyshell#0>\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\parek\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\parek\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\parek\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\parek\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\parek\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\parek\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\parek\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\parek\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.", "comments": ["The tensorflow gpu 1.12 installed via pip requires CUDA9.0, 1.13 requires CUDA10.0.Please install the correct version of CUDA and the corresponding cuDNN.", "Please have a look on this [link](https://www.tensorflow.org/install/source) for reference. TensorFlow 1.12 is compatible with  CUDA 9 cuDNN 7. Let us know if that helps. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 28412, "title": "Threadpool created by SingleThreadedCpuDevice ", "body": "Here we have a question about the threadpool created by SingleThreadedCpuDevice which could make sense on performance.\r\nEach time the constructor of SingleThreadedCpuDevice is called, a threadpool with only one thread will be created.\r\n \r\n  (single_threaded_cpu_device.cc:44)\r\n```\r\n  explicit SingleThreadedCpuDevice(Env* env)\r\n      : Device(env, Device::BuildDeviceAttributes(\"/device:CPU:0\", DEVICE_CPU,\r\n                                                  Bytes(256 << 20),\r\n                                                  DeviceLocality())) {\r\n    eigen_worker_threads_.num_threads = kNumThreads;\r\n    eigen_worker_threads_.workers = GraphRunnerThreadPool();\r\n    eigen_device_.reset(new Eigen::ThreadPoolDevice(\r\n        eigen_worker_threads_.workers->AsEigenThreadPool(),\r\n        eigen_worker_threads_.num_threads));\r\n    set_tensorflow_cpu_worker_threads(&eigen_worker_threads_);\r\n    set_eigen_cpu_device(eigen_device_.get());\r\n  }\r\n```\r\n \r\nAs far as we know, a threadpool cost more than a thread, so why a SingleThreadedCpuDevice create a threadpoll instead of a thread?", "comments": ["@snowpeakz It looks like you haven't used a template to create this issue. Please resubmit your issue using a template from [here](https://github.com/tensorflow/tensorflow/issues/new/choose). We ask users to use the template because it reduces overall time to resolve a new issue by avoiding extra communication to get to the root of the issue. We will close this issue in lieu of the new one you will create from the template. Thank you for your cooperation.\r\n\r\n", "@snowpeakz Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 28411, "title": "Eigen version bump breaks nightly AVX512 build with gcc 6.3", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 9.9\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy): N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: e432bf03931f4062f7c5e3a1553aff61a7294751\r\n- Python version: 2.7.13\r\n- Installed using virtualenv? pip? conda?: virtualenv\r\n- Bazel version (if compiling from source): 0.24.1\r\n- GCC/Compiler version (if compiling from source): (Debian 6.3.0-18+deb9u1) 6.3.0 20170516\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the problem**\r\n\r\nIn a GCE VM with AVX512 supported CPU:\r\n\r\n```\r\nbazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\n**Any other info / logs**\r\n\r\n```\r\nIn file included from /usr/lib/gcc/x86_64-linux-gnu/6/include/immintrin.h:59:0,\r\n                 from external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/util/ConfigureVectorization.h:318,\r\n                 from external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/Core:22,\r\n                 from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:14,\r\n                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                 from ./tensorflow/core/framework/tensor_shape.h:21,\r\n                 from ./tensorflow/core/kernels/conv_grad_ops.h:164,\r\n                 from tensorflow/core/kernels/conv_grad_filter_ops.cc:21:\r\n/usr/lib/gcc/x86_64-linux-gnu/6/include/avx512vlbwintrin.h: In function 'typename Eigen::internal::enable_if<Eigen::internal::unpacket_traits<T>::masked_load_available, Packet>::type Eigen::internal::ploadu(const typename Eigen::internal::unpacket_traits<Packet>::type*, typename Eigen::internal::unpacket_traits<Packet>::mask_t) [with Packet = Eigen::internal::Packet16h]':\r\n/usr/lib/gcc/x86_64-linux-gnu/6/include/avx512vlbwintrin.h:105:1: error: inlining failed in call to always_inline '__m256i _mm256_maskz_loadu_epi16(__mmask16, const void*)': target specific option mismatch\r\n _mm256_maskz_loadu_epi16 (__mmask16 __U, void const *__P)\r\n ^~~~~~~~~~~~~~~~~~~~~~~~\r\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/Core:202:0,\r\n                 from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:14,\r\n                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\r\n                 from ./tensorflow/core/framework/tensor_shape.h:21,\r\n                 from ./tensorflow/core/kernels/conv_grad_ops.h:164,\r\n                 from tensorflow/core/kernels/conv_grad_filter_ops.cc:21:\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/arch/GPU/PacketMathHalf.h:598:38: note: called from here\r\n   result.x = _mm256_maskz_loadu_epi16(mask, from);\r\n              ~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 387.379s, Critical Path: 200.24s\r\nINFO: 763 processes: 763 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\nBisect to b53fd7648b5ca7eaeceb602617433be6e9a4abec reports the following error:\r\n\r\n```\r\nIn file included from /usr/lib/gcc/x86_64-linux-gnu/6/include/immintrin.h:59:0,\r\n                 from external/eigen_archive/Eigen/src/Core/util/ConfigureVectorization.h:318,\r\n                 from external/eigen_archive/Eigen/Core:22,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_conv2d.h:19,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_conv2d.cc:16:\r\n/usr/lib/gcc/x86_64-linux-gnu/6/include/avx512vlbwintrin.h: In function 'typename Eigen::internal::enable_if<Eigen::internal::unpacket_traits<T>::masked_load_available, Packet>::type Eigen::internal::ploadu(const typename Eigen::internal::unpacket_traits<Packet>::type*, typename Eigen::internal::unpacket_traits<Packet>::mask_t) [with Packet = Eigen::internal::Packet16h]':\r\n/usr/lib/gcc/x86_64-linux-gnu/6/include/avx512vlbwintrin.h:105:1: error: inlining failed in call to always_inline '__m256i _mm256_maskz_loadu_epi16(__mmask16, const void*)': target specific option mismatch\r\n _mm256_maskz_loadu_epi16 (__mmask16 __U, void const *__P)\r\n ^~~~~~~~~~~~~~~~~~~~~~~~\r\nIn file included from external/eigen_archive/Eigen/Core:202:0,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_conv2d.h:19,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_conv2d.cc:16:\r\nexternal/eigen_archive/Eigen/src/Core/arch/GPU/PacketMathHalf.h:598:38: note: called from here\r\n   result.x = _mm256_maskz_loadu_epi16(mask, from);\r\n              ~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 639.500s, Critical Path: 90.25s\r\nINFO: 4690 processes: 4690 local.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\nReverting b53fd7648b5ca7eaeceb602617433be6e9a4abec resolves the issue.", "comments": ["Gentle ping @ezhulenev ", "I guess `from` pointer has to be reinterpret_casted similar to the method above: https://bitbucket.org/eigen/eigen/src/1984a10c33ea299487e6492602076cccc56a97be/Eigen/src/Core/arch/GPU/PacketMathHalf.h#lines-588:600\r\n\r\nI'll submit this change to Eigen and will bump the version.", "Eigen PR is out: https://bitbucket.org/eigen/eigen/pull-requests/639/fix-avx512-gcc-63-compilation/diff", "Should be fixed by c9e93a1bbfb7041e9f86c6c73ec617afc5bbcb51, but got the following error:\r\n\r\n```\r\nIn file included from /usr/lib/gcc/x86_64-linux-gnu/6/include/immintrin.h:59:0,\r\n                 from external/eigen_archive/Eigen/src/Core/util/ConfigureVectorization.h:318,\r\n                 from external/eigen_archive/Eigen/Core:22,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.h:19,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:16:\r\n/usr/lib/gcc/x86_64-linux-gnu/6/include/avx512vlbwintrin.h: In function 'typename Eigen::internal::enable_if<Eigen::internal::unpacket_traits<T>::masked_load_available, Packet>::type Eigen::internal::ploadu(const typename Eigen::internal::unpacket_traits<Packet>::type*, typename Eigen::internal::unpacket_traits<Packet>::mask_t) [with Packet = Eigen::internal::Packet16h]':\r\n/usr/lib/gcc/x86_64-linux-gnu/6/include/avx512vlbwintrin.h:105:1: error: inlining failed in call to always_inline '__m256i _mm256_maskz_loadu_epi16(__mmask16, const void*)': target specific option mismatch\r\n _mm256_maskz_loadu_epi16 (__mmask16 __U, void const *__P)\r\n ^~~~~~~~~~~~~~~~~~~~~~~~\r\nIn file included from external/eigen_archive/Eigen/Core:202:0,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.h:19,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:16:\r\nexternal/eigen_archive/Eigen/src/Core/arch/GPU/PacketMathHalf.h:598:38: note: called from here\r\n   result.x = _mm256_maskz_loadu_epi16(mask, reinterpret_cast<const __m256i*>(from));\r\n              ~~~~~~~~~~~~~~~~~~~~~~~~^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 736.417s, Critical Path: 111.79s\r\nINFO: 3870 processes: 3870 local.\r\nFAILED: Build did NOT complete successfully\r\n```", "@anuj-rawat any ideas what's the problem here?\r\n\r\n@byronyi what bazel command are you trying to run? It seems that this problem might be coming from wrong combination of compiler flags. Something similar: https://github.com/xianyi/OpenBLAS/issues/1797", "I think the problem might be that `_mm256_maskz_loadu_epi16` requires AVX512VL and AVX512BW. I will update the API similar to what you did in AVX/PacketMath.h to only use AVX512F intrinsics. If I am unable to do that, I will add a guard.", "I could recreate the build failure. I am sure it is because of `_mm256_maskz_loadu_epi16` requiring AVX512VL and AVX512BW. Since currently this API is not used anywhere, I will remove it for now and create an Eigen PR.", "The change is now merged in Eigen. The next EIgen bump in TensorFlow should pull it in.", "Closing this out since I understand it to be resolved, but please let me know if I'm mistaken. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28411\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28411\">No</a>\n", "System information\uff1a\r\nubuntu 16.04\r\ngcc 5.4.0 20160609 \r\npython 3.6\r\nbazel: 0.26.1\r\ncuda 10\r\ncudnn 7.6.5\r\ntensorflow:  [r1.14]https://github.com/tensorflow/tensorflow/tree/r1.14\r\ndocker image build by using  [dockerfiles](https://github.com/tensorflow/tensorflow/tree/r1.14/tensorflow/tools/dockerfiles),  change python version to python3.6\r\n\r\nbuild command\r\n`bazel build --config=opt --config=cuda  --verbose_failures //tensorflow/tools/pip_package:build_pip_package`\r\n\r\n\r\nFirstly, I build a docker image, then I build tensorflow in the image. And encountered the same problem.\r\n\r\nAny other info / logs:\r\n\r\n`/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlbwintrin.h: In function 'typename Eigen::internal::enable_if<Eigen::internal::unpacket_traits<T>::masked_load_available, Packet>::type Eigen::internal::ploadu(const typename Eigen::internal::unpacket_traits<Packet>::type*, typename Eigen::internal::unpacket_traits<Packet>::mask_t) [with Packet = Eigen::internal::Packet16h; typename Eigen::internal::enable_if<Eigen::internal::unpacket_traits<T>::masked_load_available, Packet>::type = Eigen::internal::Packet16h; typename Eigen::internal::unpacket_traits<Packet>::type = Eigen::half; typename Eigen::internal::unpacket_traits<Packet>::mask_t = short unsigned int]':\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlbwintrin.h:105:1: error: inlining failed in call to always_inline '__m256i _mm256_maskz_loadu_epi16(__mmask16, const void*)': target specific option mismatch\r\n _mm256_maskz_loadu_epi16 (__mmask16 __U, void const *__P)\r\n ^\r\nIn file included from external/eigen_archive/Eigen/Core:202:0,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.h:19,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_single_threaded_conv2d.cc:16:\r\nexternal/eigen_archive/Eigen/src/Core/arch/GPU/PacketMathHalf.h:598:38: error: called from here\r\n   result.x = _mm256_maskz_loadu_epi16(mask, reinterpret_cast<const __m256i*>(from));\r\n`\r\n\r\nother information\uff1a\r\n\r\n-  I can build successfully with docker image that ubuntu 18.04 gcc 7.4.0 with the same other config above.\r\n\r\n-  I have change workspace.bzl \"eigen_archive\" with [b53fd7648b](https://github.com/tensorflow/tensorflow/commit/b53fd7648b5ca7eaeceb602617433be6e9a4abec) \r\n\r\ngett error:\r\n\r\n`./tensorflow/core/kernels/eigen_spatial_convolutions.h:108:61: error: 'masked_store_available' is not a member of 'Eigen::internal::unpacket_traits<__vector(16) float>'\r\nIn file included from ./tensorflow/core/util/padding.h:26:0,\r\n                 from ./tensorflow/core/framework/common_shape_fns.h:21,\r\n                 from ./tensorflow/core/framework/resource_mgr.h:25,\r\n                 from ./tensorflow/core/kernels/conv_ops.h:20,\r\n                 from tensorflow/core/kernels/conv_ops.cc:25:\r\n./tensorflow/core/util/tensor_format.h: In function 'int tensorflow::GetTensorSpatialDims(int, tensorflow::TensorFormat)':\r\n./tensorflow/core/util/tensor_format.h:127:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\n./tensorflow/core/util/tensor_format.h: In function 'int tensorflow::GetTensorDimsFromSpatialDims(int, tensorflow::TensorFormat)':\r\n./tensorflow/core/util/tensor_format.h:151:1: warning: control reaches end of non-void function [-Wreturn-type]\r\n }\r\n ^\r\n`\r\n\r\nand [e432bf0393](https://github.com/tensorflow/tensorflow/commit/e432bf03931f4062f7c5e3a1553aff61a7294751), \r\nget error:\r\n`/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlbwintrin.h:105:1: error: inlining failed in call to always_inline '__m256i _mm256_maskz_loadu_epi16(__mmask16, const void*)': target specific option mismatch\r\n _mm256_maskz_loadu_epi16 (__mmask16 __U, void const *__P)\r\n ^\r\nIn file included from external/eigen_archive/Eigen/Core:202:0,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from ./tensorflow/compiler/xla/service/cpu/runtime_conv2d.h:19,\r\n                 from tensorflow/compiler/xla/service/cpu/runtime_conv2d.cc:16:\r\nexternal/eigen_archive/Eigen/src/Core/arch/GPU/PacketMathHalf.h:598:38: error: called from here\r\n   result.x = _mm256_maskz_loadu_epi16(mask, from);\r\n`\r\n\r\nHow can I solve this problem? @anuj-rawat @ezhulenev \r\n\r\n", "@xieyi4650 , What is the eigen in your original build with the problem? Is it at [c85345](https://github.com/tensorflow/tensorflow/commit/c853459a0a88187a3a4e8adc6dd1eea6bbd566bc#diff-455a4c7f8e22d7c514e8c2caa27506c5)? - this should have the fix already. The API was removed from  `Eigen/src/Core/arch/GPU/PacketMathHalf.h`", "@anuj-rawat  my workspace.bzl  is\uff1a\r\n\r\n\r\n`name = \"eigen_archive\",\r\n        sha256 = \"74845ea27e19a1bcf63f3f271de62e06798f23e0467bb9d45b83a94918941b23\",\r\n        strip_prefix = \"eigen-eigen-20cbc6576426\",\r\n        urls = [\r\n            \"http://mirror.tensorflow.org/bitbucket.org/eigen/eigen/get/20cbc6576426.tar.gz\",\r\n            \"https://bitbucket.org/eigen/eigen/get/20cbc6576426.tar.gz\",\r\n        ],\r\n`\r\n\r\n\r\nif update urls flowing [c85345](https://github.com/tensorflow/tensorflow/commit/c853459a0a88187a3a4e8adc6dd1eea6bbd566bc#diff-455a4c7f8e22d7c514e8c2caa27506c5) then \r\n\r\n\r\n`\r\nERROR: An error occurred during the fetch of repository 'eigen_archive':\r\n   java.io.IOException: Error downloading [http://mirror.tensorflow.org/bitbucket.org/eigen/eigen/get/a0d250e79c79.tar.gz, https://bitbucket.org/eigen/eigen/get/a0d250e79c79.tar.gz] to /root/.cache/bazel/_bazel_root/b9065c75c7fa26a9c046c3c10662a85c/external/eigen_archive/a0d250e79c79.tar.gz: All mirrors are down: [Connection reset, GET returned 404 Not Found]\r\nERROR: /tensorflow_1_14_ubuntu16/third_party/eigen3/BUILD:30:1: no such package '@eigen_archive//': java.io.IOException: Error downloading [http://mirror.tensorflow.org/bitbucket.org/eigen/eigen/get/a0d250e79c79.tar.gz, https://bitbucket.org/eigen/eigen/get/a0d250e79c79.tar.gz] to /root/.cache/bazel/_bazel_root/b9065c75c7fa26a9c046c3c10662a85c/external/eigen_archive/a0d250e79c79.tar.gz: All mirrors are down: [Connection reset, GET returned 404 Not Found] and referenced by '//third_party/eigen3:eigen3'\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: no such package '@eigen_archive//': java.io.IOException: Error downloading [http://mirror.tensorflow.org/bitbucket.org/eigen/eigen/get/a0d250e79c79.tar.gz, https://bitbucket.org/eigen/eigen/get/a0d250e79c79.tar.gz] to /root/.cache/bazel/_bazel_root/b9065c75c7fa26a9c046c3c10662a85c/external/eigen_archive/a0d250e79c79.tar.gz: All mirrors are down: [Connection reset, GET returned 404 Not Found]\r\n`\r\n\r\n\r\nand when I go to `http://mirror.tensorflow.org/bitbucket.org/eigen/eigen/get/a0d250e79c79.tar.gz` there nothing on it", "The fix is not in the Eigen version that you are using.\r\n\r\nI am also unable to access `http://mirror.tensorflow.org/bitbucket.org/eigen/eigen/get/a0d250e79c79.tar.gz`, but I can still access the other mirror `https://bitbucket.org/eigen/eigen/get/a0d250e79c79.tar.gz`. Could you try to edit the `workspace.bzl` to remove the mirror that is down and only keep the one that works?", "@anuj-rawat  \r\nYes, I have tried to remove the mirror that is down, and get error below. Seems that tensorflow url must be the first.\r\n`\r\nERROR: An error occurred during the fetch of repository 'eigen_archive':\r\n   tf_http_archive(urls) must have redundant URLs. The mirror.tensorflow.org URL must be present and it must come first. Even if you don't have permission to mirror the file, please put the correctly formatted mirror URL there anyway, because someone will come along shortly thereafter and mirror the file.\r\nERROR: /tensorflow_1_14_ubuntu16/tensorflow/tools/pip_package/BUILD:155:1: no such package '@eigen_archive//': tf_http_archive(urls) must have redundant URLs. The mirror.tensorflow.org URL must be present and it must come first. Even if you don't have permission to mirror the file, please put the correctly formatted mirror URL there anyway, because someone will come along shortly thereafter and mirror the file. and referenced by '//tensorflow/tools/pip_package:licenses'\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: no such package '@eigen_archive//': tf_http_archive(urls) must have redundant URLs. The mirror.tensorflow.org URL must be present and it must come first. Even if you don't have permission to mirror the file, please put the correctly formatted mirror URL there anyway, because someone will come along shortly thereafter and mirror the file.\r\nINFO: Elapsed time: 2.693s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (95 packages loaded, 7580 targets configured)\r\n    currently loading: @llvm// ... (2 packages)\r\n`", "I've just mirrored Eigen to http://mirror.tensorflow.org/bitbucket.org/eigen/eigen/get/a0d250e79c79.tar.gz, either we never mirrored it before, or lost it."]}, {"number": 28410, "title": "ResolveDilatedConv bug fix", "body": "Missing scenario to detect dilated Conv is added.\r\n\r\nRef: #22146", "comments": ["@alanchiao : Gentle reminder!", "Hello. Does this fix resolve as well the issue with conversion of models created with keras-TCN to TFLite? If yes, that would be great. Best regards.", "@alanchiao : Gentle reminder!", "Can one of the admins verify this patch?", "@alanchiao Can you please take a look on this PR? Thanks!", "@ANSHUMAN87 Can you please check reviewer comments and keep us posted. Thanks!", "> generate_examples_lib\r\n\r\n@jdduke : I am trying to run the generate_examples_lib, but it throws so many compilation error in my workspace. Can you please help me how to run this in my local. May be i am doing some mistake. \r\nNOTE: I am running on latest code.\r\nTIA!", "@gbaned , @jdduke : Could you please help on the issue i posted above. Thanks!", "Looks like we don't have good test coverage for this transformation yet, so that's not on you. Just confirming that you were able to run the mode in issue #22146 and you validated the output as being correct?"]}, {"number": 28409, "title": "Mac os tensorflow website gets wrong", "body": "when i open the website with my macbook air, the website gets wrong results like following:\r\n![Screen Shot 2019-05-05 at 3 54 53 PM](https://user-images.githubusercontent.com/25492462/57190612-ab162c00-6f4e-11e9-82f4-835830952fb8.png)\r\n![Screen Shot 2019-05-05 at 3 54 53 PM](https://user-images.githubusercontent.com/25492462/57190645-12cc7700-6f4f-11e9-9df3-b05ccb829555.png)\r\n", "comments": ["@WuChannn Can you please check with different browsers like Google Chrome, firefox etc. Also there could be network fluctuations due to which the page would not have loaded properly.", "Thanks. I use google chrome already, but the problem appeared. Maybe the website isn\u2019t suitable for 13 inches screen?------------------ Original ------------------From: muddham  <notifications@github.com>Date: Mon,May 6,2019 7:15 PMTo: tensorflow/tensorflow <tensorflow@noreply.github.com>Cc: WuChannn <wuzchng@gmail.com>, Mention <mention@noreply.github.com>Subject: Re: [tensorflow/tensorflow] Mac os tensorflow website gets wrong(#28409)@WuChannn Can you please check with different browsers like Google Chrome, firefox etc. Also there could be network fluctuations due to which the page would not have loaded properly.\n\n\u2014You are receiving this because you were mentioned.Reply to this email directly, view it on GitHub, or mute the thread.\n[\n{\n\"@context\": \"http://schema.org\",\n\"@type\": \"EmailMessage\",\n\"potentialAction\": {\n\"@type\": \"ViewAction\",\n\"target\": \"https://github.com/tensorflow/tensorflow/issues/28409#issuecomment-489583759\",\n\"url\": \"https://github.com/tensorflow/tensorflow/issues/28409#issuecomment-489583759\",\n\"name\": \"View Issue\"\n},\n\"description\": \"View this Issue on GitHub\",\n\"publisher\": {\n\"@type\": \"Organization\",\n\"name\": \"GitHub\",\n\"url\": \"https://github.com\"\n}\n}\n]", "@WuChannn This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.If you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose). Thanks!\r\n\r\n"]}, {"number": 28408, "title": "fix nccl build bug", "body": "fix bug: nccl build fail as below:\r\n\r\nERROR: /root/.cache/bazel/_bazel_root/xxxxx/external/local_config_nccl/BUILD:8:12: in srcs attribute of cc_library rule @local_config_nccl//:nccl: generated file '@local_config_nccl//:libnccl.so.%{2}' is misplaced here (expected .cc, .cpp, .cxx, .c++, .C, .c, .h, .hh, .hpp, .ipp, .hxx, .inc, .inl, .H, .S, .s, .asm, .a, .lib, .pic.a, .lo, .lo.lib, .pic.lo, .so, .dylib, .dll, .o, .obj or .pic.o)\r\nERROR: /root/.cache/bazel/_bazel_root/xxxxx/external/local_config_nccl/BUILD:8:12: in srcs attribute of cc_library rule @local_config_nccl//:nccl: '@local_config_nccl//:libnccl.so.%{2}' does not produce any cc_library srcs files (expected .cc, .cpp, .cxx, .c++, .C, .c, .h, .hh, .hpp, .ipp, .hxx, .inc, .inl, .H, .S, .s, .asm, .a, .lib, .pic.a, .lo, .lo.lib, .pic.lo, .so, .dylib, .dll, .o, .obj or .pic.o)", "comments": ["@annarev it's a small bug fix for nccl build fail", "@xinan-jiang I\u2019ve never met this error before. Could you post the details of your  environment so we make sure it\u2019s a bug? Thanks!", "@chsigg Christian, can you take a look?  You are more familiar with nccl config.", "I've encountered the same error, if you use the your own nccl install and not the default configure selection of http://github.com/nvidia/nccl.\r\n\r\nI'll setup an environment to recreate error.", "I recreated using the container: docker.io/nvidia/cuda:10.0-cudnn7-devel-ubuntu18.04\r\n\r\n```\r\n# apt install libnccl2 libnccl-dev\r\n[other setup like python bazel....]\r\n\r\n# export TF_NCCL_VERSION=2\r\n# ./configure\r\n\r\nit will say:\r\nFound NCCL 2 in:\r\n    /usr/lib/x86_64-linux-gnu\r\n    /usr/include\r\n\r\n\r\n# cat .tf_configure.bazelrc | grep -i nccl\r\nbuild --action_env TF_NCCL_VERSION=\"2\"\r\n\r\n\r\n# bazel build //tensorflow/tools/pip_package:build_pip_package\r\n\r\n# cat /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/local_config_nccl/BUILD\r\nfilegroup(\r\n    name = \"LICENSE\",\r\n    visibility = [\"//visibility:public\"],\r\n)\r\n\r\ncc_library(\r\n    name = \"nccl\",\r\n    srcs = [\"libnccl.so.%{2}\"],\r\n    hdrs = [\"nccl.h\"],\r\n    include_prefix = \"third_party/nccl\",\r\n    visibility = [\"//visibility:public\"],\r\n    deps = [\r\n        \"@local_config_cuda//cuda:cuda_headers\",\r\n    ],\r\n)\r\n\r\ngenrule(\r\n    name = \"nccl-files\",\r\n    outs = [\r\n        libnccl.so.%{2},\r\n        \"nccl.h\",\r\n    ],\r\n    cmd = \"\"\"\r\ncp \"%{nccl_header_dir}/nccl.h\" \"$(@D)/nccl.h\" &&\r\ncp \"%{/usr/lib/x86_64-linux-gnu}/libnccl.so.%{2}\" \\\r\n  \"$(@D)/libnccl.so.%{2}\"\r\n\"\"\",\r\n)\r\n```\r\n\r\nThis problem was caused by commit: https://github.com/tensorflow/tensorflow/commit/8e9ca6617b4637d759da395ad89e783a38ccd5ad\r\n\r\nNotice how above \"%{nccl_header_dir}/nccl.h\" was not replaced with the actual path, this is because find_cuda_config.py returns the directory as nccl_include_dir. (See\r\nhttps://github.com/tensorflow/tensorflow/blob/master/third_party/gpus/find_cuda_config.py#L374)\r\n\r\nThe patch includes: `\"%{nccl_header_dir}\": config[\"nccl_include_dir\"],` to fix the name mismatch. (Other possible fixes would be changing in the template or find_cuda_config.py to use the same name for the variable.\r\n\r\nThe other problem is \"libnccl.so.%{2}\" should be \"libnccl.so.2\", this is because the '%{' and '}' did not get replaced. Adding the %{ } to the string to be replaced solves that issue.\r\n\r\n"]}, {"number": 28407, "title": "Performance issue with the C API", "body": "I'm currently working on a project that requires deep learning inference with Tensorflow's C API. I have a trained neural net (format: frozen graph) to do this. We use the inference for Computational Fluid Dynamics, which makes performance a key aspect for me. For example, one single simulation includes thousands of timesteps. In each timestep, the inference must be carried out for thousands of sets of input data. In my current case, I have a computational domain including 33400 cells and 880 boundary patches. That means, for each single of these thousands of timesteps I have to do the inference 34280 times. We use 3 input and 15 output values.\r\n\r\nThe whole inference process (from providing the input values to receiving the output values) requires a total of 91 milliseconds on my GPU. The actual inference step: TF_SessionRun(...) makes up for 98% of the computation time.\r\n\r\n`TF_CAPI_EXPORT extern void TF_SessionRun(TF_Session* session, const TF_Buffer* run_options, const TF_Output* inputs, TF_Tensor* const* input_values, int ninputs, const TF_Output* outputs, TF_Tensor** output_values, int noutputs, const TF_Operation* const* target_opers, int ntargets, TF_Buffer* run_metadata, TF_Status*);`\r\n\r\nThe problem now is that I need to do the inference 34280 times in every timestep, which then takes approximately 52 minutes. That means for thousands of timesteps, the computation time is extensive.\r\n\r\nSurprisingly, if I convert the frozen graph to a uff-model and do the inference using TensorRT, it only takes me 90 milliseconds for all 34280 input sets. That means the speed-up of TensorRT vs. the C API would be about 35000. As we want to do the inference on a CPU-only architecture, later on, TensorRT is no option for me.\r\n\r\nMy question: do you know a way to use Tensorflow's C API in a way, that drastically reduces the computation time for multiple inferences? The bottleneck definitely is the TF_SessionRun(...) command, but I can not see a way to run 34280 inferences by only calling the command once. Moreover, the command provides several options (run options, run metadata, target operations, number of targets - see code above) that aren't used in a single example of those I found on the internet. Maybe these can be used to improve the performance?", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version and if possible provide us the code snippet to reproduce the issue at hand. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose). Thanks!", "Platform & OS: Ubuntu 16.04 LTS\r\nTensorflow version: no local installation, only using C API version 1.13.1 (https://www.tensorflow.org/install/lang_c) - CPU only version\r\n\r\n\r\nCode, neural net and executable:\r\n[inference.zip](https://github.com/tensorflow/tensorflow/files/3151575/inference.zip)\r\n\r\n\r\n", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged//tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there and can provide help. Thanks!\r\n"]}, {"number": 28406, "title": "[tflite doc] CONV_2D_TRANSPOSE -> TRANSPOSE_CONV", "body": "## Existing URLs containing the issue:\r\n\r\nhttps://www.tensorflow.org/lite/guide/ops_compatibility\r\n\r\n## Description of issue (what needs changing):\r\n\r\nTensorFlow `r1.13`.\r\n\r\n`CONV_2D_TRANSPOSE` op is not present in TensorFlow Lite schema.\r\nAfter glimpsed `toco` source code,  `tf.nn.conv2d_transpose`(`Conv2DBackpropInput`) is converted to `TRANSPOSE_CONV`.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.13/tensorflow/lite/toco/import_tensorflow.cc#L1778 \r\n\r\nSo updating tflite documentation(replace `CONV_2D_TRANSPOSE` with `TRANSPOSE_CONV`  ) would be nice.\r\n\r\n", "comments": ["@syoyo Can you please elaborate the above information, cause CONV_2D_TRANSPOSE method is visible . Please see attached.\r\n![image](https://user-images.githubusercontent.com/48215502/57302011-dee08580-70f7-11e9-8df4-66881b712aa7.png)\r\n", "@muddaham Yes that's what I found. Documentation should be updated by syncing with the implementation(or tflite schema).", "I'm preparing a fix for this."]}, {"number": 28405, "title": " GPU utilization of these two Epoch is very low", "body": "I run https://www.tensorflow.org/alpha/tutorials/text/transformer in Calab with GPU.\r\nThe result is a strange phenomenon. The first two Epoch are very slow. I tried to run on my local machine and the result was the same. According to observations, the GPU utilization of these two Epoch is very low, almost zero. What happened to these two Epoch?\r\n\r\n```\r\nEpoch 1 Batch 0 Loss 4.4497 Accuracy 0.0000\r\nEpoch 1 Batch 500 Loss 3.6058 Accuracy 0.0401\r\nEpoch 1 Loss 3.3683 Accuracy 0.0538\r\nTime taken for 1 epoch: 1175.7783224582672 secs\r\n\r\nEpoch 2 Batch 0 Loss 2.8402 Accuracy 0.0966\r\nEpoch 2 Batch 500 Loss 2.4239 Accuracy 0.1189\r\nEpoch 2 Loss 2.3728 Accuracy 0.1240\r\nTime taken for 1 epoch: 1116.1639959812164 secs\r\n\r\nEpoch 3 Batch 0 Loss 2.4180 Accuracy 0.1410\r\nEpoch 3 Batch 500 Loss 2.1358 Accuracy 0.1484\r\nEpoch 3 Loss 2.1007 Accuracy 0.1518\r\nTime taken for 1 epoch: 235.27584767341614 secs\r\n\r\nEpoch 4 Batch 0 Loss 2.2033 Accuracy 0.1632\r\nEpoch 4 Batch 500 Loss 1.8985 Accuracy 0.1763\r\nEpoch 4 Loss 1.8629 Accuracy 0.1806\r\nTime taken for 1 epoch: 154.04113721847534 secs\r\n\r\nEpoch 5 Batch 0 Loss 1.9665 Accuracy 0.1941\r\nEpoch 5 Batch 500 Loss 1.6708 Accuracy 0.2037\r\nSaving checkpoint for epoch 5 at ./checkpoints/train/ckpt-1\r\nEpoch 5 Loss 1.6434 Accuracy 0.2066\r\nTime taken for 1 epoch: 118.84977173805237 secs\r\n\r\nEpoch 6 Batch 0 Loss 1.7504 Accuracy 0.2196\r\nEpoch 6 Batch 500 Loss 1.4882 Accuracy 0.2233\r\nEpoch 6 Loss 1.4662 Accuracy 0.2257\r\nTime taken for 1 epoch: 183.19546270370483 secs\r\n\r\nEpoch 7 Batch 0 Loss 1.5731 Accuracy 0.2368\r\nEpoch 7 Batch 500 Loss 1.3058 Accuracy 0.2438\r\nEpoch 7 Loss 1.2844 Accuracy 0.2462\r\nTime taken for 1 epoch: 134.03554582595825 secs\r\n\r\nEpoch 8 Batch 0 Loss 1.3853 Accuracy 0.2504\r\nEpoch 8 Batch 500 Loss 1.1468 Accuracy 0.2625\r\nEpoch 8 Loss 1.1327 Accuracy 0.2643\r\nTime taken for 1 epoch: 147.67497181892395 secs\r\n\r\nEpoch 9 Batch 0 Loss 1.2550 Accuracy 0.2759\r\nEpoch 9 Batch 500 Loss 1.0325 Accuracy 0.2769\r\nEpoch 9 Loss 1.0226 Accuracy 0.2780\r\nTime taken for 1 epoch: 99.68828344345093 secs\r\n\r\nEpoch 10 Batch 0 Loss 1.1568 Accuracy 0.2833\r\nEpoch 10 Batch 500 Loss 0.9410 Accuracy 0.2888\r\nSaving checkpoint for epoch 10 at ./checkpoints/train/ckpt-2\r\nEpoch 10 Loss 0.9350 Accuracy 0.2891\r\nTime taken for 1 epoch: 132.47828769683838 secs\r\n```\r\n", "comments": ["Notice that such information appears when running locally, I don't know if it is related.\r\n```\r\n> 2019-05-05 09:14:47.113549: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [10]\r\n> \t [[{{node Placeholder/_0}}]]\r\n> 2019-05-05 09:14:47.114102: W tensorflow/core/common_runtime/executor.cc:2237] [/device:CPU:0] Executor start aborting: Invalid argument: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [10]\r\n> \t [[{{node Placeholder/_0}}]]\r\n```", "@soloice Can you please take a look at this issue? Thanks!", "Probably the same as [this one](https://github.com/tensorflow/tensorflow/issues/13114#issuecomment-330381682).", "I tried the code on my local environment (GTX 1080 Ti + CUDA 10.0.0 + TF 1.13.1) and it runs normally (the very first epoch is slightly longer 154s vs. ~110s of subsequent epoches):\r\n```\r\n2019-05-17 14:21:46.428676: W ./tensorflow/core/framework/model.h:202] Encountered a stop event that was not preceded by a start event.\r\n2019-05-17 14:21:56.422792: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:103] Filling up shuffle buffer (this may take a while): 11737 of 20000\r\n2019-05-17 14:22:02.903131: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:150] Shuffle buffer filled.\r\nEpoch 1 Batch 0 Loss 4.4382 Accuracy 0.0000\r\nEpoch 1 Batch 500 Loss 3.4579 Accuracy 0.0389\r\nEpoch 1 Loss 3.2365 Accuracy 0.0530\r\nTime taken for 1 epoch: 154.54717898368835 secs\r\n\r\n2019-05-17 14:24:21.745880: W ./tensorflow/core/framework/model.h:202] Encountered a stop event that was not preceded by a start event.\r\n2019-05-17 14:24:31.740729: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:103] Filling up shuffle buffer (this may take a while): 12293 of 20000\r\n2019-05-17 14:24:38.427798: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:150] Shuffle buffer filled.\r\nEpoch 2 Batch 0 Loss 2.6457 Accuracy 0.1018\r\nEpoch 2 Batch 500 Loss 2.3402 Accuracy 0.1217\r\nEpoch 2 Loss 2.2758 Accuracy 0.1303\r\nTime taken for 1 epoch: 114.29197025299072 secs\r\n\r\n2019-05-17 14:26:16.247264: W ./tensorflow/core/framework/model.h:202] Encountered a stop event that was not preceded by a start event.\r\n2019-05-17 14:26:26.241918: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:103] Filling up shuffle buffer (this may take a while): 13094 of 20000\r\n2019-05-17 14:26:31.618235: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:150] Shuffle buffer filled.\r\nEpoch 3 Batch 0 Loss 2.1175 Accuracy 0.1672\r\nEpoch 3 Batch 500 Loss 1.9352 Accuracy 0.1706\r\nEpoch 3 Loss 1.9053 Accuracy 0.1748\r\nTime taken for 1 epoch: 112.49538898468018 secs\r\n\r\n2019-05-17 14:28:08.755016: W ./tensorflow/core/framework/model.h:202] Encountered a stop event that was not preceded by a start event.\r\n2019-05-17 14:28:18.749417: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:103] Filling up shuffle buffer (this may take a while): 13690 of 20000\r\n2019-05-17 14:28:23.495135: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:150] Shuffle buffer filled.\r\nEpoch 4 Batch 0 Loss 1.8739 Accuracy 0.1959\r\nEpoch 4 Batch 500 Loss 1.7347 Accuracy 0.1924\r\nEpoch 4 Loss 1.7185 Accuracy 0.1950\r\nTime taken for 1 epoch: 108.57341289520264 secs\r\n\r\n2019-05-17 14:29:57.784247: W ./tensorflow/core/framework/model.h:202] Encountered a stop event that was not preceded by a start event.\r\n2019-05-17 14:30:07.778153: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:103] Filling up shuffle buffer (this may take a while): 12566 of 20000\r\n2019-05-17 14:30:13.554589: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:150] Shuffle buffer filled.\r\nEpoch 5 Batch 0 Loss 1.7317 Accuracy 0.2044\r\nEpoch 5 Batch 500 Loss 1.6061 Accuracy 0.2057\r\nSaving checkpoint for epoch 5 at ./checkpoints/train/ckpt-1\r\nEpoch 5 Loss 1.5919 Accuracy 0.2081\r\nTime taken for 1 epoch: 117.97101092338562 secs\r\n```", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "I am seeing the same issue regularly, not every run though. My input data are images of the same size. This happens with all kinds of network sizes. It happens on both my machines. It seems to always happen after a reboot. "]}, {"number": 28404, "title": "Missing tensorflow.compiler.xla.service import hlo_pb2 ", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\nI\r\n\r\n\r\nI am trying to build a TensorRT file to run on my jetson nano.\r\nI am running tensorflow 1.13. \r\nWhen I run this code:\r\n\r\ntrt_graph = trt.create_inference_graph(\r\n    input_graph_def=['input_1'],\r\n    outputs=['Logits/Softmax'],\r\n    max_batch_size=1,\r\n    max_workspace_size_bytes=1 << 25,\r\n    precision_mode='FP16',\r\n    minimum_segment_size=50\r\n)\r\nI get this error :\r\nImportError: cannot import name 'hlo_pb2'\r\n\r\nIt says its looking here for it:\r\n from tensorflow.compiler.xla.service import hlo_pb2 \r\n\r\nIt dosent exist?\r\n\r\n", "comments": ["In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 28403, "title": "dataset in tf2.0 lack of key properties and methods which already in tf1.13", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):mac\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip install\r\n- TensorFlow version (use command below):2.0 alpha\r\n- Python version:3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\ndataset in tf2.0 lack of key properties and methods which already in tf1.13, for example:\r\nproperties: output_shapes, output_types\r\nmethods: make_one_shot_iterator\r\n\r\n**Describe the expected behavior**\r\nthese key properties and methods should in dataset of tf2.0\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@gandalflee Can you please refer the TF2.0 release notes [link](https://github.com/tensorflow/tensorflow/blob/r2.0/RELEASE.md). It includes all the new features added and  deprecated details.", "@gandalflee Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 28402, "title": "Update dataset_ops.py", "body": "Added a couple of periods at the end of 'Args' and 'Raises' sentences in tf.data.Options.merge.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28402) for more info**.\n\n<!-- need_sender_cla -->", "> Thanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\r\n> \r\n> \ud83d\udcdd **Please visit https://cla.developers.google.com/ to sign.**\r\n> \r\n> Once you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\r\n> \r\n> #### What to do if you already signed the CLA\r\n> ##### Individual signers\r\n> * It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\r\n> \r\n> ##### Corporate signers\r\n> * Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\r\n> * The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\r\n> * The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\r\n> \r\n> \u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28402) for more info**.\r\n\r\nI have signed it.", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28402) for more info**.\n\n<!-- ok -->", "Closing this PR as this not against `master`, please open a new PR against `master` \r\nCC @mihaimaruseac"]}, {"number": 28401, "title": "Capitalize docstring on input_layer.py", "body": "Capitalized argument descriptions on line 174 and 184.\r\n174 - optional -> Optional\r\n184 - deprecated -> Deprecated", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28401) for more info**.\n\n<!-- need_sender_cla -->", "> Thanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\r\n> \r\n> \ud83d\udcdd **Please visit https://cla.developers.google.com/ to sign.**\r\n> \r\n> Once you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\r\n> \r\n> #### What to do if you already signed the CLA\r\n> ##### Individual signers\r\n> * It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\r\n> \r\n> ##### Corporate signers\r\n> * Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\r\n> * The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\r\n> * The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\r\n> \r\n> \u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28401) for more info**.\r\n\r\nI have signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28401) for more info**.\n\n<!-- ok -->", "@yifeif can you please help merge this PR.", "Closing this PR as this not against `master`, please open a new PR against `master` \r\nCC @mihaimaruseac"]}, {"number": 28400, "title": "[Regression] Conv1D output shape is lost when dilation_rate != 1.", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Custom simple Keras sequential model with Conv1D dilated layers.\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): Works in tf-nightly-gpu-2.0-preview==2.0.0.dev20190410 but fails in tf-nightly-gpu-2.0-preview==2.0.0.dev20190504.\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.0 (installed via conda)\r\n- GPU model and memory: Turing (2080 Ti)\r\n\r\n**Describe the current behavior**\r\nThe output shape is not inferred correctly anymore for a Keras Conv1D with dilation_rate != 1 (it is ok when dilation_rate = 1). Shape inference used to work as expected in tf-nightly-gpu-2.0-preview==2.0.0.dev20190410. \r\n\r\n**Describe the expected behavior**\r\nPlease revert to the behaviour available in tf-nightly-gpu-2.0-preview==2.0.0.dev20190410\r\n\r\n**Code to reproduce the issue**\r\nCORRECT behaviour with a dilation_rate=1:\r\n\r\n```\r\nmodel = tf.keras.models.Sequential([\r\n    tf.keras.layers.Conv1D(24, kernel_size = 2, dilation_rate = 1, padding='causal',\r\n                           kernel_regularizer=tfk.regularizers.l2(0.01), input_shape=(2560, 8)),\r\n    tf.keras.layers.ReLU(),\r\n    tf.keras.layers.Dense(10),\r\n    tf.keras.layers.Softmax(),\r\n])\r\n\r\nmodel.summary()\r\nModel: \"sequential_2\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nconv1d_26 (Conv1D)           (None, 2560, 24)          408       \r\n_________________________________________________________________\r\nre_lu_23 (ReLU)              (None, 2560, 24)          0         \r\n_________________________________________________________________\r\ndense_3 (Dense)              (None, 2560, 10)          250       \r\n_________________________________________________________________\r\nsoftmax_2 (Softmax)          (None, 2560, 10)          0         \r\n=================================================================\r\nTotal params: 658\r\nTrainable params: 658\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\n```\r\n\r\nShape inference FAILS with a dilation_rate=2 (or >1): The second dimension of the output shape's is lost,\r\n\r\n```\r\nmodel = tf.keras.models.Sequential([\r\n    tf.keras.layers.Conv1D(24, kernel_size = 2, dilation_rate = 2, padding='causal',\r\n                           kernel_regularizer=tfk.regularizers.l2(0.01), input_shape=(2560, 8)),\r\n    tf.keras.layers.ReLU(),\r\n    tf.keras.layers.Dense(10),\r\n    tf.keras.layers.Softmax(),\r\n])\r\n\r\nmodel.summary()\r\nModel: \"sequential_3\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nconv1d_27 (Conv1D)           (None, None, 24)          408       \r\n_________________________________________________________________\r\nre_lu_24 (ReLU)              (None, None, 24)          0         \r\n_________________________________________________________________\r\ndense_4 (Dense)              (None, None, 10)          250       \r\n_________________________________________________________________\r\nsoftmax_3 (Softmax)          (None, None, 10)          0         \r\n=================================================================\r\nTotal params: 658\r\nTrainable params: 658\r\nNon-trainable params: 0\r\n```\r\n\r\nPlease note that the behaviour in 20190410 was correct independently of the dilation_rate.\r\n\r\n**Other info / logs**\r\nThis causes more issues downstream as one can't concatenate or sum outputs w.r.t the axis with the unknown shape.\r\n", "comments": ["@Madder In order to expedite the trouble-shooting process, please provide whole code snippet to reproduce the issue reported here. Thanks!\r\n", "Hi @muddham : Complete code snipped to reproduce the issue:\r\n\r\n```\r\nimport tensorflow as tf\r\nmodel = tf.keras.models.Sequential([\r\n    tf.keras.layers.Conv1D(24, kernel_size = 2, dilation_rate = 2, padding='causal',\r\n                           kernel_regularizer=tf.keras.regularizers.l2(0.01), input_shape=(2560, 8)),\r\n    tf.keras.layers.ReLU(),\r\n    tf.keras.layers.Dense(10),\r\n    tf.keras.layers.Softmax(),\r\n])\r\n\r\nmodel.summary()\r\n```\r\nOutput in  tf-nightly-gpu-2.0-preview==2.0.0.dev20190504 (and  tf-nightly-gpu-2.0-preview==2.0.0.dev20190505):\r\n```\r\nModel: \"sequential_1\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nconv1d_1 (Conv1D)            (None, None, 24)          408       \r\n_________________________________________________________________\r\nre_lu_1 (ReLU)               (None, None, 24)          0         \r\n_________________________________________________________________\r\ndense_1 (Dense)              (None, None, 10)          250       \r\n_________________________________________________________________\r\nsoftmax_1 (Softmax)          (None, None, 10)          0         \r\n=================================================================\r\nTotal params: 658\r\nTrainable params: 658\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\n```\r\nOutput in  tf-nightly-gpu-2.0-preview==2.0.0.dev20190410 (output shape inferred correctly):\r\n\r\n```\r\nModel: \"sequential\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nconv1d (Conv1D)              (None, 2560, 24)          408       \r\n_________________________________________________________________\r\nre_lu (ReLU)                 (None, 2560, 24)          0         \r\n_________________________________________________________________\r\ndense (Dense)                (None, 2560, 10)          250       \r\n_________________________________________________________________\r\nsoftmax (Softmax)            (None, 2560, 10)          0         \r\n=================================================================\r\nTotal params: 658\r\nTrainable params: 658\r\nNon-trainable params: 0\r\n_________________________________________________________________\r\n```", "@Madder Able to reproduce the issue in in tf-nightly-gpu-2.0-preview==2.0.0.dev20190504 and tf-nightly-gpu-2.0-preview==2.0.0.dev20190505.\r\n\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nconv1d (Conv1D)              (None, None, 24)          408       \r\n_________________________________________________________________\r\nre_lu (ReLU)                 (None, None, 24)          0         \r\n_________________________________________________________________\r\ndense (Dense)                (None, None, 10)          250       \r\n_________________________________________________________________\r\nsoftmax (Softmax)            (None, None, 10)          0         \r\n=================================================================\r\nTotal params: 658\r\nTrainable params: 658\r\nNon-trainable params: 0", "Please note that this bug is also reproduced in the just released Tensorflow 1.14 rc0 when eager execution is enabled:\r\n\r\n```\r\nimport tensorflow as tf\r\ntf.enable_eager_execution()\r\n\r\nmodel = tf.keras.models.Sequential([\r\n    tf.keras.layers.Conv1D(24, kernel_size = 2, dilation_rate = 2, padding='causal',\r\n                           kernel_regularizer=tf.keras.regularizers.l2(0.01), input_shape=(2560, 8)),\r\n    tf.keras.layers.ReLU(),\r\n    tf.keras.layers.Dense(10),\r\n    tf.keras.layers.Softmax(),\r\n])\r\n\r\nmodel.summary()\r\n```\r\n\r\nThe axis=1 length is lost again similarly to the issue in tf2 nightly: \r\n```\r\nModel: \"sequential_1\"\r\n_________________________________________________________________\r\nLayer (type)                 Output Shape              Param #   \r\n=================================================================\r\nconv1d_1 (Conv1D)            (None, None, 24)          408       \r\n_________________________________________________________________\r\nre_lu_1 (ReLU)               (None, None, 24)          0         \r\n_________________________________________________________________\r\ndense_1 (Dense)              (None, None, 10)          250       \r\n_________________________________________________________________\r\nsoftmax_1 (Softmax)          (None, None, 10)          0         \r\n=================================================================\r\nTotal params: 658\r\nTrainable params: 658\r\nNon-trainable params: 0\r\n```", "Please note that this bug is still present in Tensorflow 2.0 Beta0\r\n", "Able to reproduce the issue in tensorflow==2.0.0-beta0", "This affects all conv layers, I believe. This is probably a duplicate of #29843. That issue has some debugging I've done, the error seems to be in `BaseLayer.__call__`.", "I'm closing this as a duplicate of #29542", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28400\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28400\">No</a>\n"]}, {"number": 28399, "title": "gpu_fusible refactoring change: Create methods to check if two instructions are fusible", "body": "Current PR handles producer-consumer and producer-consumer multi-output fusion", "comments": ["Hi Justin,\r\n\r\nThis PR is a refactoring change and should not change functionality. I plan on using these methods for a project that implements a new kind of fusion. I don't really have anyone that can do an internal review at school and was hoping that Thomas could review it instead because I have already discussed the changes with him.", "Oh no, @sana-damani, I confused you with someone with a similar username who works at nvidia!  I'm really sorry about that.\r\n\r\nIf you are willing, I think it would still be helpful to do the following.\r\n\r\n - update the PR description here to say what you said in the comment above.  The PR description is what ends up becoming the commit description, so it is important to write down what is going on so others can understand.\r\n\r\n - read the diff yourself and find things like empty lines being added for no reason and code that's commented out that should have been removed.  This will save you back-and-forth time with Thomas.", "_> * Testing: Non-trivial functions extracted into gpu_fusible should be tested in gpu_fusible_test. These tests would look somewhat similar to existing tests that operate on the fusion pass level, but test functions in isolation._\r\nShall I add positive and negative tests for both functions? Should I be testing multiple operator combinations?\r\n\r\n_> * The FusionMerger pass does not take advantage of IsProducerConsumerFusible yet. In principle this should work. Have you tried this?_\r\nFusion merger seems to have a limited legality check in that it only checks for fusion nodes. I could create a separate IsProducerConsumerFusionMergerFusible for this if you like.\r\n\r\n_> * Pass-specific restrictions: For instance, the GpuMultiOutputFusion pass chooses not to fuse constants, since this \"should be handled by the regular fusion pass\". Let's not extract pass-specific things into gpu_fusible, but keep them where they are. This will make it easier to understand the code and re-consider pass-specific logic (with the goal of eliminating unnecessary differences) going forward._\r\nI agree, that makes sense.\r\n", "Hi Sana, please always include @thomasjoerg in your replies to help me stay on top of things.\r\n\r\n> _> * Testing: Non-trivial functions extracted into gpu_fusible should be tested in gpu_fusible_test. These tests would look somewhat similar to existing tests that operate on the fusion pass level, but test functions in isolation._\r\n> Shall I add positive and negative tests for both functions? Should I be testing multiple operator combinations?\r\n> \r\nYes and yes. Ideally tests exercise each branch at least once.\r\n\r\n> _> * The FusionMerger pass does not take advantage of IsProducerConsumerFusible yet. In principle this should work. Have you tried this?_\r\n> Fusion merger seems to have a limited legality check in that it only checks for fusion nodes. I could create a separate IsProducerConsumerFusionMergerFusible for this if you like.\r\n> \r\nAt a conceptual level, it's all producer-consumer fusion. At present the instruction_fusion and fusion_merger passes look at unfused and fused ops, respectively. However, these restrictions are arbitrary. Since you are looking into a different approach to fusion, I'd expect a generalized legality check is what you want.\r\n\r\n> _> * Pass-specific restrictions: For instance, the GpuMultiOutputFusion pass chooses not to fuse constants, since this \"should be handled by the regular fusion pass\". Let's not extract pass-specific things into gpu_fusible, but keep them where they are. This will make it easier to understand the code and re-consider pass-specific logic (with the goal of eliminating unnecessary differences) going forward._\r\n> I agree, that makes sense.\r\n\r\n", "Hi @thomasjoerg,\r\nI've made the code changes. I am now looking into the unit tests and I can't see how these tests would be different from those written in instruction_fusion_test.cc etc. Are the cases for legal/illegal fusion not tested there already?\r\n\r\n", "Hi @sanadamani , thanks for resolving my review comments. I'd love to see tests added to gpu_fusible_test.cc for non-trivial code moved there. IIUC, this part hasn't been done yet. Let me know if you have further questions. Thanks, Thomas", "> Hi @sanadamani , thanks for resolving my review comments. I'd love to see tests added to gpu_fusible_test.cc for non-trivial code moved there. IIUC, this part hasn't been done yet. Let me know if you have further questions. Thanks, Thomas\r\n\r\nYes, I'm still working on the unit tests.", "Hi @thomasjoerg, I have added some unit tests for the new methods. ", "@thomasjoerg I have addressed your comments in my latest commit.", "@sana-damani \r\nHeads-up: This PR breaks a number of tests in https://github.com/tensorflow/tensorflow/tree/master/tensorflow/compiler/tests\r\nand elsewhere. I haven't had time to investigate this, but I thought I'll let you know in case you have some cycles.", "@thomasjoerg, I was unable to reproduce these failures locally: https://source.cloud.google.com/results/invocations/6a0ab204-91ee-472b-aeed-10f7aff0cd60/targets\r\nI tried merging upstream but my local branch appears to be up to date. I'm not quite sure how to reproduce the failures so I can debug them.\r\n", "> @thomasjoerg, I was unable to reproduce these failures locally: \r\n\r\nThanks for taking another look. I should have some time to look into it this week.\r\n\r\n", "I made the following changes to un-break tests:\r\n\r\n-  instruction_fusion.cc 125:129\r\n  Keep checking that producers are unfused. Otherwise this will create nested fusions.\r\n- multi_output_fusion.cc 129:133\r\n  Keep checking IsInputFusibleReduction. Dropping this restriction is possible in principle, however, we run into a phase ordering issue similar to the one I described in the FusionFusion doc. This isn't hard to fix, but is worth a separate patch.\r\n- gpu_fusible.cc 241:242\r\n  The producer in a multi-output fusion needs to be loop-fusible.\r\n\r\n@sana-damani We should investigate why you were unable to reproduce locally.", "@thomasjoerg Thank you for fixing this! Why are nested fusions illegal?", "> Why are nested fusions illegal?\r\n\r\nIn XLA:GPU fusions correspond the GPU kernels. CUDA supports nested kernel launches with certain restrictions referred to as Dynamic Parallelism. However, XLA:GPU does not use this feature though."]}, {"number": 28398, "title": "Passing tf.data.Dataset to model.predict raises \"ValueError: The `batch_size` argument must not be specified when using dataset as an input.\"", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution: 19.04\r\n- TensorFlow installed from (source or binary): pip install tensorflow==2.0.0-alpha0 \r\n- TensorFlow version (use command below): 2.0.0-alpha\r\n- Python version: 3.7.3\r\n\r\n**Describe the current behavior**\r\nRunning simple classification example with Keras interface\r\n**Describe the expected behavior**\r\nPredict results of fitted model with tf.data.Dataset using model.predict\r\n\r\n**Code to reproduce the issue**\r\n```\r\nfrom sklearn import datasets\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\r\nimport tensorflow as tf\r\nfrom tensorflow.python import keras\r\n\r\niris = datasets.load_iris()\r\n\r\nscl = StandardScaler()\r\nohe = OneHotEncoder(categories='auto')\r\ndata_norm = scl.fit_transform(iris.data)\r\ndata_target = ohe.fit_transform(iris.target.reshape(-1,1)).toarray()\r\ntrain_data, val_data, train_target, val_target = train_test_split(data_norm, data_target, test_size=0.1)\r\ntrain_data, test_data, train_target, test_target = train_test_split(train_data, train_target, test_size=0.2)\r\n\r\n\r\ntrain_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_target))\r\ntrain_dataset = train_dataset.batch(32).repeat()\r\n\r\ntest_dataset = tf.data.Dataset.from_tensor_slices((test_data, test_target))\r\ntest_dataset = test_dataset.batch(32).repeat()\r\n\r\nval_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_target))\r\nval_dataset = val_dataset.batch(12).repeat()\r\n\r\nmdl = keras.Sequential([\r\n    keras.layers.Dense(16, input_dim=4, activation='relu'),\r\n    keras.layers.Dense(8, activation='relu'),\r\n    keras.layers.Dense(8, activation='relu'),\r\n    keras.layers.Dense(3, activation='softmax')]\r\n)\r\n\r\nmdl.compile(\r\n    optimizer=keras.optimizers.Adam(0.01),\r\n    loss=keras.losses.categorical_crossentropy,\r\n    metrics=[keras.metrics.categorical_accuracy]\r\n    )\r\n\r\nhistory = mdl.fit(train_dataset, epochs=10, steps_per_epoch=15, validation_data=val_dataset, validation_steps=12)\r\nresults = mdl.evaluate(test_dataset, steps=15)\r\ncomparison = mdl.predict_classes(test_dataset)\r\n```\r\n\r\n**Other info / logs**\r\n```\r\nE0504 15:10:24.153471 139666315605824 ultratb.py:149] Internal Python error in the inspect module.\r\nBelow is the traceback from this internal error.\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/ispmarin/lib/venvs/dl/lib/python3.7/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-15-848835f9eab8>\", line 41, in <module>\r\n    comparison = mdl.predict_classes(test_dataset)\r\n  File \"/home/ispmarin/lib/venvs/dl/lib/python3.7/site-packages/tensorflow/python/keras/engine/sequential.py\", line 313, in predict_classes\r\n    proba = self.predict(x, batch_size=batch_size, verbose=verbose)\r\n  File \"/home/ispmarin/lib/venvs/dl/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 1122, in predict\r\n    batch_size = self._validate_or_infer_batch_size(batch_size, steps, x)\r\n  File \"/home/ispmarin/lib/venvs/dl/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\", line 1780, in _validate_or_infer_batch_size\r\n    raise ValueError('The `batch_size` argument must not be specified when'\r\nValueError: The `batch_size` argument must not be specified when using dataset as an input.\r\n\r\n\r\n```", "comments": ["@ispmarin : I am able to reproduce the issue on colab with TensorFlow version 2.0.0-alpha0", "@jvishnuvardhan as far as I can tell, this is an error in Keras, not tf.data ... please re-assign this problem to someone familiar with Keras, thank you", "@ispmarin I think this was resolved in `tf-nightly-gpu-2.0-preview==2.0.0.dev20190723`. Please check the [gist here](https://colab.sandbox.google.com/gist/jvishnuvardhan/e68b76451dd49bf282fb35d2f78faca7/tf_28398.ipynb).\r\n\r\nLast line in your code `mdl.predict_classes` is expecting a numpy array where as your are providing a `dataset`.\r\n\r\nI am closing this issue as it was resolved. Please feel free to reopen the issue if the issue persists again. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28398\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28398\">No</a>\n", "The error persists, and now the [documentation](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/Sequential#predict_classes) says that predict can use tf.data besides other kinds of data, but predict_classes can only use numpy arrays. Is there a reason for `predict_classes` only accepts numpy arrays? This seems to break what is expected from the library."]}, {"number": 28397, "title": "Tensorflow does not build with \"--config=monolithic\": \"multiple definition\"", "body": "**System information**\r\n- OS Platform and Distribution: Ubuntu 19.04 64bit on Digital Ocean\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: r1.13 branch\r\n- Python version: 3.7.3 (/usr/bin/python3)\r\n- Bazel version (if compiling from source): 0.21.0\r\n- GCC/Compiler version (if compiling from source): 8.3.0\r\n- CUDA/cuDNN version: disabled\r\n\r\nCompiling tensorflow from source gives linking errors on the end, all of which are related to \"multiple definition\".\r\n\r\n```bash\r\nbazel build --define=grpc_no_ares=true --config=opt --config=monolithic --config=ngraph --config=mkl --config=noaws //tensorflow/tools/pip_package:build_pip_package --local_resources 6000,.5,1.0 &> log.txt\r\n```\r\n\r\n[log.txt](https://github.com/tensorflow/tensorflow/files/3144670/log.txt)\r\n", "comments": ["The problem is solved by removing the \"--config=monolithic\" option.", "@Binero As this is resolved, closing this issue. Thanks!", "@muddham Is it not supposed to build regardless? "]}, {"number": 28396, "title": "Build did NOT complete successfully; ERROR: expression must have a constant value", "body": "**System information**\r\n- OS Platform and Distribution: Windows10\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 1.12\r\n- Python version: 3.36\r\n- Bazel version: 0.15.0\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 9.0/7.5.1\r\n- GPU model and memory: Quadro K1100m\r\n\r\n**Describe problem**\r\n\r\nHello guys, I have been trying to build tf-gpu on source with bazel but continuously getting errors. Got success so far but now it is giving me following errors on matching instances of overload func & also saying expression must have constant value while giving me list of hex strings of whose I can't find any solution to resolve. Please guide.. TIA\r\n\r\n**Error I got after executing command:**\r\n\r\n> $ bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\n\r\n```\r\n....\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (142 packages loaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (143 packages loaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (144 packages loaded)\r\nWARNING: C:/users/lenovo/_bazel_lenovo/6kwxios2/external/grpc/BUILD:1992:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_common.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in C:/users/lenovo/_bazel_lenovo/6kwxios2/external/grpc/bazel/grpc_build_system.bzl:172:12\r\nWARNING: C:/users/lenovo/_bazel_lenovo/6kwxios2/external/grpc/BUILD:1992:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_decode.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in C:/users/lenovo/_bazel_lenovo/6kwxios2/external/grpc/bazel/grpc_build_system.bzl:172:12\r\nWARNING: C:/users/lenovo/_bazel_lenovo/6kwxios2/external/grpc/BUILD:1992:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_encode.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in C:/users/lenovo/_bazel_lenovo/6kwxios2/external/grpc/bazel/grpc_build_system.bzl:172:12\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (147 packages loaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (147 packages loaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (148 packages loaded)\r\nAnalyzing: target //tensorflow/tools/pip_package:build_pip_package (148 packages loaded)\r\nWARNING: C:/users/lenovo/tensorflow-build/tensorflow/tensorflow/contrib/learn/BUILD:17:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': No longer supported. Switch to SavedModel immediately.\r\nWARNING: C:/users/lenovo/tensorflow-build/tensorflow/tensorflow/contrib/learn/BUILD:17:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': No longer supported. Switch to SavedModel immediately.\r\nWARNING: C:/users/lenovo/tensorflow-build/tensorflow/tensorflow/contrib/timeseries/python/timeseries/state_space_models/BUILD:230:1: in py_library rule //tensorflow/contrib/timeseries/python/timeseries/state_space_models:filtering_postprocessor: target '//tensorflow/contrib/timeseries/python/timeseries/state_space_models:filtering_postprocessor' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: C:/users/lenovo/tensorflow-build/tensorflow/tensorflow/contrib/timeseries/python/timeseries/BUILD:354:1: in py_library rule //tensorflow/contrib/timeseries/python/timeseries:ar_model: target '//tensorflow/contrib/timeseries/python/timeseries:ar_model' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: C:/users/lenovo/tensorflow-build/tensorflow/tensorflow/contrib/timeseries/python/timeseries/state_space_models/BUILD:73:1: in py_library rule //tensorflow/contrib/timeseries/python/timeseries/state_space_models:kalman_filter: target '//tensorflow/contrib/timeseries/python/timeseries/state_space_models:kalman_filter' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: C:/users/lenovo/tensorflow-build/tensorflow/tensorflow/contrib/bayesflow/BUILD:17:1: in py_library rule //tensorflow/contrib/bayesflow:bayesflow_py: target '//tensorflow/contrib/bayesflow:bayesflow_py' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: C:/users/lenovo/tensorflow-build/tensorflow/tensorflow/contrib/seq2seq/BUILD:23:1: in py_library rule //tensorflow/contrib/seq2seq:seq2seq_py: target '//tensorflow/contrib/seq2seq:seq2seq_py' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: C:/users/lenovo/tensorflow-build/tensorflow/tensorflow/contrib/BUILD:13:1: in py_library rule //tensorflow/contrib:contrib_py: target '//tensorflow/contrib:contrib_py' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nINFO: Analysed target //tensorflow/tools/pip_package:build_pip_package (155 packages loaded).\r\nINFO: Found 1 target...\r\n[0 / 9] [-----] BazelWorkspaceStatusAction stable-status.txt\r\nINFO: From Compiling external/grpc/third_party/address_sorting/address_sorting_posix.c:\r\ncl : Command line warning D9002 : ignoring unknown option '-std=c99'\r\nINFO: From Compiling external/grpc/third_party/address_sorting/address_sorting_windows.c:\r\ncl : Command line warning D9002 : ignoring unknown option '-std=c99'\r\nINFO: From Compiling external/grpc/third_party/address_sorting/address_sorting.c:\r\ncl : Command line warning D9002 : ignoring unknown option '-std=c99'\r\nINFO: From Compiling external/com_google_absl/absl/base/dynamic_annotations.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Compiling external/com_google_absl/absl/strings/internal/utf8.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Compiling external/com_google_absl/absl/strings/internal/ostringstream.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Compiling external/com_google_absl/absl/numeric/int128.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Compiling external/com_google_absl/absl/base/internal/spinlock_wait.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\n[2,314 / 5,397] Compiling external/pcre/pcre_exec.c; 128s local ... (7 actions running)\r\nINFO: From Linking external/grpc/libgrpc++_base.a:\r\nserver_posix.o : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\nrpc_method.o : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\ncreate_channel_posix.o : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\nINFO: From Compiling external/com_google_absl/absl/base/internal/unscaledcycleclock.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Compiling external/com_google_absl/absl/base/internal/cycleclock.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Compiling external/com_google_absl/absl/types/bad_variant_access.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Compiling external/com_google_absl/absl/types/optional.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Compiling external/com_google_absl/absl/base/internal/thread_identity.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Compiling external/com_google_absl/absl/base/internal/spinlock.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Compiling external/com_google_absl/absl/base/internal/raw_logging.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Compiling external/com_google_absl/absl/types/bad_optional_access.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Compiling external/com_google_absl/absl/strings/string_view.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Compiling external/com_google_absl/absl/base/internal/sysinfo.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Compiling external/com_google_absl/absl/strings/internal/charconv_parse.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Compiling external/com_google_absl/absl/strings/internal/charconv_bigint.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Compiling external/com_google_absl/absl/base/internal/throw_delegate.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Compiling external/com_google_absl/absl/strings/ascii.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Compiling external/com_google_absl/absl/strings/numbers.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Compiling external/com_google_absl/absl/strings/internal/memutil.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Compiling external/com_google_absl/absl/strings/match.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Compiling external/com_google_absl/absl/strings/substitute.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Compiling external/com_google_absl/absl/strings/charconv.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Compiling external/com_google_absl/absl/strings/str_cat.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Compiling external/com_google_absl/absl/strings/str_replace.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Compiling external/com_google_absl/absl/strings/escaping.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Compiling external/com_google_absl/absl/strings/internal/str_format/extension.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Compiling external/com_google_absl/absl/strings/internal/str_format/output.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Compiling external/com_google_absl/absl/strings/str_split.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Compiling external/com_google_absl/absl/strings/internal/str_format/float_conversion.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Compiling external/com_google_absl/absl/strings/internal/str_format/parser.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Compiling external/com_google_absl/absl/strings/internal/str_format/arg.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Compiling external/com_google_absl/absl/strings/internal/str_format/bind.cc:\r\ncl : Command line warning D9025 : overriding '/w' with '/W3'\r\nINFO: From Linking external/protobuf_archive/libprotobuf_lite.a:\r\narenastring.o : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\nINFO: From Linking external/protobuf_archive/libprotobuf.a:\r\nerror_listener.o : warning LNK4221: This object file does not define any previously undefined public symbols, so it will not be used by any link operation that consumes this library\r\nINFO: From ProtoCompile tensorflow/core/protobuf/replay_log.pb.cc:\r\ntensorflow/core/protobuf/replay_log.proto: warning: Import tensorflow/core/framework/graph.proto but not used.\r\ntensorflow/core/protobuf/replay_log.proto: warning: Import tensorflow/core/protobuf/cluster.proto but not used.\r\n[2,860 / 5,406] Compiling tensorflow/core/framework/api_def.pb.cc; 6s local ... (7 actions running)\r\nERROR: C:/users/lenovo/tensorflow-build/tensorflow/tensorflow/contrib/rnn/BUILD:218:1: C++ compilation of rule '//tensorflow/contrib/rnn:python/ops/_lstm_ops_gpu' failed (Exit 5): msvc_wrapper_for_nvcc.bat failed: error executing command\r\n  cd C:/users/lenovo/_bazel_lenovo/6kwxios2/execroot/org_tensorflow\r\n  SET CUDA_TOOLKIT_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v9.0\r\n    SET CUDNN_INSTALL_PATH=C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v9.0\r\n    SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\ATLMFC\\include;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\include\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\winrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.17763.0\\cppwinrt\r\n    SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\ATLMFC\\lib\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\lib\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\lib\\um\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.17763.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.17763.0\\um\\x64;\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\bin\\HostX64\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\VC\\VCPackages;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\TeamFoundation\\Team Explorer;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\MSBuild\\15.0\\bin\\Roslyn;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Team Tools\\Performance Tools\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Team Tools\\Performance Tools;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Common\\VSPerfCollectionTools\\;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.6.1 Tools\\x64\\;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\10.0.17763.0\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\\\MSBuild\\15.0\\bin;C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\Tools\\;;C:\\Windows\\system32;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\CMake\\bin;C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\CMake\\Ninja\r\n    SET PWD=/proc/self/cwd\r\n    SET PYTHON_BIN_PATH=C:/Users/Lenovo/Python/Python36/python.exe\r\n    SET PYTHON_LIB_PATH=C:/Users/Lenovo/Python/Python36/lib/site-packages\r\n    SET TEMP=C:\\Users\\Lenovo\\AppData\\Local\\Temp\r\n    SET TF_CUDA_CLANG=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=3.0\r\n    SET TF_CUDA_VERSION=9.0\r\n    SET TF_CUDNN_VERSION=7\r\n    SET TF_NEED_CUDA=1\r\n    SET TF_NEED_OPENCL_SYCL=0\r\n    SET TF_NEED_ROCM=0\r\n    SET TMP=C:\\Users\\Lenovo\\AppData\\Local\\Temp\r\n  external/local_config_cuda/crosstool/windows/msvc_wrapper_for_nvcc.bat /nologo /DCOMPILER_MSVC /DNOMINMAX /D_WIN32_WINNT=0x0600 /D_CRT_SECURE_NO_DEPRECATE /D_CRT_SECURE_NO_WARNINGS /D_SILENCE_STDEXT_HASH_DEPRECATION_WARNINGS /bigobj /Zm500 /J /Gy /GF /EHsc /wd4351 /wd4291 /wd4250 /wd4996 /I. /Ibazel-out/x64_windows-opt/genfiles /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Iexternal/bazel_tools /Ibazel-out/x64_windows-opt/genfiles/external/bazel_tools /Iexternal/local_config_sycl /Ibazel-out/x64_windows-opt/genfiles/external/local_config_sycl /Iexternal/protobuf_archive /Ibazel-out/x64_windows-opt/genfiles/external/protobuf_archive /Iexternal/com_google_absl /Ibazel-out/x64_windows-opt/genfiles/external/com_google_absl /Iexternal/local_config_cuda /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda /Iexternal/eigen_archive /Ibazel-out/x64_windows-opt/genfiles/external/eigen_archive /Ibazel-out/x64_windows-opt/bin/external/eigen_archive /Iexternal/protobuf_archive/src /Ibazel-out/x64_windows-opt/genfiles/external/protobuf_archive/src /Ibazel-out/x64_windows-opt/bin/external/protobuf_archive/src /Iexternal/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda /Iexternal/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda/cuda/include /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/include /Iexternal/local_config_cuda/cuda/cuda/include/crt /Ibazel-out/x64_windows-opt/genfiles/external/local_config_cuda/cuda/cuda/include/crt /Ibazel-out/x64_windows-opt/bin/external/local_config_cuda/cuda/cuda/include/crt /DEIGEN_MPL2_ONLY /DEIGEN_MAX_ALIGN_BYTES=64 /D__CLANG_SUPPORT_DYN_ANNOTATION__ /showIncludes /MD /O2 /DNDEBUG -w /arch:AVX -x cuda -DGOOGLE_CUDA=1 -nvcc_options=relaxed-constexpr -nvcc_options=ftz=true /Fobazel-out/x64_windows-opt/bin/tensorflow/contrib/rnn/_objs/python/ops/_lstm_ops_gpu/lstm_ops_gpu.cu.o /c tensorflow/contrib/rnn/kernels/lstm_ops_gpu.cu.cc\r\nnvcc error   : 'cicc' died with status 0xC0000005 (ACCESS_VIOLATION)\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\type_traits(603): error: expression must have a constant value\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\type_traits(604): error: expression must have a constant value\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\type_traits(605): error: expression must have a constant value\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\type_traits(637): error: expression must have a constant value\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\type_traits(1148): error: expression must have a constant value\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\type_traits(1594): error: expression must have a constant value\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\type_traits(2428): error: expression must have a constant value\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\type_traits(2428): error: expression must have a constant value\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\xutility(385): error: expression must have a constant value\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\xtr1common(59): error: class \"std::enable_if<<error-constant>, int>\" has no member \"type\"\r\n          detected during instantiation of type \"std::enable_if_t<<error-constant>, int>\"\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\xutility(385): here\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\xutility(647): error: expression must have a constant value\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\xutility(654): error: expression must have a constant value\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\xutility(698): error: expression must have a constant value\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\xutility(705): error: expression must have a constant value\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\xutility(777): error: expression must have a constant value\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\xutility(786): error: expression must have a constant value\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\xutility(787): error: expression must have a constant value\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\xutility(796): error: expression must have a constant value\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\xutility(797): error: expression must have a constant value\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\xutility(862): error: expression must have a constant value\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\xmemory0(353): error: expression must have a constant value\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\xmemory0(943): error: expression must have a constant value\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\xmemory0(1217): error: expression must have a constant value\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\xstring(1914): error: expression must have a constant value\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\xtr1common(59): error: class \"std::enable_if<<error-constant>, void>\" has no member \"type\"\r\n          detected during instantiation of type \"std::enable_if_t<<error-constant>, void>\"\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\xstring(1914): here\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\xutility(264): error: expression must have a constant value\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\type_traits(1562): error: expected a \">\"\r\n          detected during:\r\n            instantiation of \"const __nv_bool std::_Is_specialization_v [with _Type=std::char_traits<char>, _Template=std::char_traits]\"\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\xstring(2108): here\r\n            instantiation of class \"std::basic_string<_Elem, _Traits, _Alloc> [with _Elem=char, _Traits=std::char_traits<char>, _Alloc=std::allocator<char>]\"\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\stdexcept(24): here\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\memory(1483): error: expression must have a constant value\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\memory(1490): error: expression must have a constant value\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\memory(2536): error: expression must have a constant value\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\type_traits(1562): error: expected a \">\"\r\n          detected during:\r\n            instantiation of \"const __nv_bool std::_Is_specialization_v [with _Type=std::char_traits<__wchar_t>, _Template=std::char_traits]\"\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\xstring(2108): here\r\n            instantiation of class \"std::basic_string<_Elem, _Traits, _Alloc> [with _Elem=__wchar_t, _Traits=std::char_traits<__wchar_t>, _Alloc=std::allocator<__wchar_t>]\"\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\string(325): here\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\type_traits(1562): error: expected a \">\"\r\n          detected during:\r\n            instantiation of \"const __nv_bool std::_Is_specialization_v [with _Type=std::char_traits<char16_t>, _Template=std::char_traits]\"\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\xstring(2108): here\r\n            instantiation of class \"std::basic_string<_Elem, _Traits, _Alloc> [with _Elem=char16_t, _Traits=std::char_traits<char16_t>, _Alloc=std::allocator<char16_t>]\"\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\string(656): here\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\type_traits(1562): error: expected a \">\"\r\n          detected during:\r\n            instantiation of \"const __nv_bool std::_Is_specialization_v [with _Type=std::char_traits<char32_t>, _Template=std::char_traits]\"\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\xstring(2108): here\r\n            instantiation of class \"std::basic_string<_Elem, _Traits, _Alloc> [with _Elem=char32_t, _Traits=std::char_traits<char32_t>, _Alloc=std::allocator<char32_t>]\"\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\string(661): here\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\tuple(172): error: expression must have a constant value\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\tuple(190): error: expression must have a constant value\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\tuple(209): error: expression must have a constant value\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\tuple(242): error: expression must have a constant value\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\tuple(1034): error: no instance of overloaded function \"std::tuple<_This, _Rest...>::tuple\" matches the specified type\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\tuple(1046): error: no instance of overloaded function \"std::tuple<_This, _Rest...>::tuple\" matches the specified type\r\n\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Community\\VC\\Tools\\MSVC\\14.16.27023\\include\\functional(1193): error: expression must have a constant value\r\n\r\n0x00007FF703B12395 (0x0000000000000000 0x0000021243C9C370 0x000002123D7334A8 0x0000000000000000)\r\n0x00007FF703B0F0D1 (0x0000000000000000 0x0000021200000000 0x0000000000000000 0x0000000000000000)\r\n0x00007FF703B0FE73 (0x000002123DFFDD90 0x0000000000000000 0x0000000000000000 0x0000021243C9D480)\r\n0x00007FF703B4413F (0x0000021200000001 0x0000000000000001 0x0000021200000001 0x0000000000000001)\r\n0x00007FF703B3E650 (0x0000021200000001 0x000000E605BFB478 0x000000E605BFBB20 0x0000000000000001)\r\n0x00007FF7039C2E4A (0x000000E600000000 0x0000000000000000 0x000000E605BFB560 0x0000021243C9C188)\r\n0x00007FF7039C81D1 (0x000000E605BFBAC0 0x00007FF703A01712 0x000000E605BFBD30 0x0000000000000011)\r\n0x00007FF7039C7ED0 (0x0000000000003901 0x0000000000000001 0x0000000000000000 0x0000000000000000)\r\n0x00007FF703A2AB15 (0x00000212413E8EA0 0x0000021243C9A598 0x00000212413F12E8 0x000002123BD79990)\r\n0x00007FF703A2BAD9 (0x000002123BD79990 0x000000E605BFC340 0x00000212413F12E8 0x0000000900000000)\r\n0x00007FF703A2A94E (0x0000021243C9C448 0x0000000000000000 0x0000000000000080 0x0000021243C37790)\r\n0x00007FF703B4FCCF (0x0000000000000000 0x0000000000000001 0x00000212413E9138 0x000002123DD59A78)\r\n0x00007FF703B37262 (0x000002123DD5A4B0 0x00000212413E9138 0x000002123DD59A78 0x0000000000000000)\r\n0x00007FF703B36D22 (0x0000000000000000 0x000000E605BFC1A1 0x000000E605BFC340 0x000000260002FE91)\r\n0x00007FF703B37CE4 (0x0000000000000000 0x0000021243C9A598 0x00000212413F12E8 0x00000212413F2D38)\r\n0x00007FF703B4FC0C (0x0000021243C9C6B8 0x0000000000000000 0x0000021243C9A598 0x00000212413F12E8)\r\n0x00007FF703B30B10 (0x0000021243C9A598 0x00000212413F2D08 0x0000021200000000 0x00000212413F2D08)\r\n0x00007FF703B553EA (0x0000000000000000 0x000000E605BFC520 0x00000212413EA140 0x0000000000000000)\r\n0x00007FF703B552A8 (0x00000212413F2D08 0x00000212413F2D80 0x0000000000000000 0x000002123D6C4CE0)\r\n0x00007FF703AEFA96 (0x0000000000000000 0x000002123EA26D68 0x0000021243A3D968 0x0000000000000000)\r\n0x00007FF703AED063 (0x00000212413F2D08 0x0000021240866400 0x0000021200000000 0x00000212413F2D08)\r\n0x00007FF703AFCBAF (0x0000021240866400 0x0000021200000000 0x0000000000000000 0x0000021243A3D968)\r\n0x00007FF703AE57D2 (0x000000E605BFD3E0 0x0000000000000000 0x000000E605BFD3E0 0x000000000000000B)\r\n0x00007FF7039E51A8 (0x0000000000000024 0x00007FF7038E0000 0x0000000000000000 0x0000000000000000)\r\n0x00007FF7039D6C0C (0x000000E605BFD660 0x0000000000000000 0x0000000000000000 0x000000E605BFD978)\r\n0x00007FF7039E9D80 (0x000000E605BFDA08 0x0000021243CB1768 0x0000000000000000 0x0000000000000000)\r\n0x00007FF703B1744A (0x0000000000000001 0x0000000000000000 0x0000000000000000 0x0000000000000000)\r\n0x00007FF703B1B26E (0x0000000000000001 0x0000000000000001 0x0000000000000001 0x000000030003939C)\r\n0x00007FF703B16423 (0x0000000000000001 0x0000000000000000 0x0000000000000000 0x0000021200000000)\r\n0x00007FF703A1BF31 (0x0000021243C9A3F0 0x0000021243C9A3F0 0x0000000000000000 0x0000021243C9A3F0)\r\n0x00007FF703A1AAC3 (0x000000E605BFDCE0 0x0000000000000002 0x0000021243C9A038 0x000000E605BFDDB0)\r\n0x00007FF7039946FA (0x0000000000000001 0x000000E600000000 0x0000000000000000 0x000000E605BFDDB0)\r\n0x00007FF70399B216 (0x0000021243C3ECB8 0x000002123BD804B0 0x0000000000000000 0x0000000000000000)\r\n0x00007FF703992EE0 (0x0000001500039256 0x000000E605BFE0F9 0x0000021243C21A88 0x000000E605BFE0F9)\r\n0x00007FF703997AA4 (0x000000E605BFE1F0 0x0000021200000000 0x000000E605BFE3B0 0x000000E605BFE1D0)\r\n0x00007FF70398BB84 (0x0000000000000001 0x0000000000000000 0x0000000000000000 0x000000E605BFE2C0)\r\n0x00007FF70399ADCC (0x0000351A402BF60C 0x00007FF703C6989A 0x0000000000000000 0x000000E605BFE638)\r\n0x00007FF703992EE0 (0x0000001100039254 0x000000E605BFE629 0x000002123F111940 0x000000E605BFE629)\r\n0x00007FF703997AA4 (0x000000E605BFE720 0x0000021200000000 0x000000E605BFE8E0 0x000000E605BFE700)\r\n0x00007FF70398BB84 (0x0000000000000001 0x0000000000000000 0x0000000000000000 0x000000E605BFE7F0)\r\n0x00007FF70399ADCC (0x000002123BD7D890 0x0000021200000000 0x0000000000000000 0x0000000000000006)\r\n0x00007FF70399C58A (0x0000000000000000 0x0000021200000000 0x0000000000000000 0x0000000000000000)\r\n0x00007FF703B641F4 (0xTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 1322.663s, Critical Path: 133.82s\r\nINFO: 1644 processes: 1644 local.\r\nFAILED: Build did NOT complete successfully\r\nFAILED: Build did NOT complete successfully\r\n```\r\n", "comments": ["i have the same problem", "@SabahKarim Looks like your cuDNN library version is not compatible with CUDA version.\r\nAlso take a look at tested build configurations for tensorflow_gpu-1.12. Thanks!", "I changed to MSBuild Tools 2015 Update 3 and it solved my problem. Thanks. \r\nClosing the issue."]}, {"number": 28395, "title": "keras_to_tpu_model error \"No OpKernel was registered to support Op ConfigureDistributedTPU\"", "body": "Running GCP VM (made for TPU) with TPU v2-8, running ML code in **Jupyter**, trying to **convert keras model to TPU** gives error\r\n**No OpKernel was registered to support Op 'ConfigureDistributedTPU'**\r\n\r\n**System information**\r\nGCP VM build from image \"debian-9-tf-1-13-v20190504\"\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 9\r\n- TensorFlow installed from (source or binary): preinstalled\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: 3.5.3\r\n- TPU model and memory: v2-8\r\n\r\n**Describe the current behavior**\r\nError running code below : **InvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU'** \r\n\r\n**Describe the expected behavior**\r\nno error\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\n\r\nfrom tensorflow.python.keras.models import Sequential\r\nfrom tensorflow.python.keras.layers import Dense\r\n\r\nwindow_size = 1024 #900\r\ninputs_n = 7\r\noutputs_n = 8\r\nepochs_n = 1\r\nepochs =  range(epochs_n)\r\n\r\nTPU_ADDRESS = 'grpc://10.240.1.2:8470'\r\n\r\nfrom keras.layers import Dense, Activation, Dropout, LSTM\r\nfrom keras.models import Sequential, load_model\r\n\r\nmodel = Sequential()\r\nmodel.add(LSTM(128, batch_input_shape=(1, window_size, inputs_n), return_sequences=True, stateful=True))\r\nmodel.add(Dropout(0.2))\r\nmodel.add(LSTM(128, return_sequences=True, stateful=True))\r\nmodel.add(Dropout(0.2))\r\nmodel.add(Dense(8, activation='linear'))\r\n\r\nopt = tf.train.AdamOptimizer(0.01)\r\n\r\nmodel.compile(loss='mse', optimizer=opt)\r\n\r\ntpu_model = tf.contrib.tpu.keras_to_tpu_model(\r\n    model,\r\n    strategy=tf.contrib.tpu.TPUDistributionStrategy(\r\n        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)))\r\n```\r\n\r\n**output**\r\n```\r\nINFO:tensorflow:Querying Tensorflow master (grpc://10.240.1.2:8470) for TPU system metadata.\r\nINFO:tensorflow:Found TPU system:\r\nINFO:tensorflow:*** Num TPU Cores: 8\r\nINFO:tensorflow:*** Num TPU Workers: 1\r\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 6098867428625386983)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 3944999252280507086)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 11439376241675220217)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 6679858096061465067)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 17112049907098627726)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 8235536748600333881)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 11246969246948913311)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 18093998721829044871)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2543676904778409938)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 16455517362176252302)\r\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 522461249528463037)\r\nWARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1333     try:\r\n-> 1334       return fn(*args)\r\n   1335     except errors.OpError as e:\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _run_fn(feed_dict, fetch_list, target_list, options, run_metadata)\r\n   1316       # Ensure any changes to the graph are reflected in the runtime.\r\n-> 1317       self._extend_graph()\r\n   1318       return self._call_tf_sessionrun(\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _extend_graph(self)\r\n   1351     with self._graph._session_run_lock():  # pylint: disable=protected-access\r\n-> 1352       tf_session.ExtendSession(self._session)\r\n   1353 \r\n\r\nInvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}}with these attrs: [tpu_embedding_config=\"\", is_global_init=false, embedding_config=\"\"]\r\nRegistered devices: [CPU, XLA_CPU]\r\nRegistered kernels:\r\n  <no registered kernels>\r\n\r\n\t [[{{node ConfigureDistributedTPU}}]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-15-454c38059ada> in <module>\r\n     36     model,\r\n     37     strategy=tf.contrib.tpu.TPUDistributionStrategy(\r\n---> 38         tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)))\r\n     39 #\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/framework/experimental.py in new_func(*args, **kwargs)\r\n     62         'any time, and without warning.',\r\n     63         decorator_utils.get_qualified_name(func), func.__module__)\r\n---> 64     return func(*args, **kwargs)\r\n     65   new_func.__doc__ = _add_experimental_function_notice_to_docstring(\r\n     66       func.__doc__)\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py in tpu_model(model, strategy)\r\n   2219     else:\r\n   2220       optimizer_config = None\r\n-> 2221     model_weights = model.get_weights()\r\n   2222   else:\r\n   2223     model_weights = None\r\n\r\n~/.local/lib/python3.5/site-packages/keras/engine/network.py in get_weights(self)\r\n    490         for layer in self.layers:\r\n    491             weights += layer.weights\r\n--> 492         return K.batch_get_value(weights)\r\n    493 \r\n    494     def set_weights(self, weights):\r\n\r\n~/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py in batch_get_value(ops)\r\n   2418     \"\"\"\r\n   2419     if ops:\r\n-> 2420         return get_session().run(ops)\r\n   2421     else:\r\n   2422         return []\r\n\r\n~/.local/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py in get_session()\r\n    197                 # not already marked as initialized.\r\n    198                 is_initialized = session.run(\r\n--> 199                     [tf.is_variable_initialized(v) for v in candidate_vars])\r\n    200                 uninitialized_vars = []\r\n    201                 for flag, v in zip(is_initialized, candidate_vars):\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\r\n    927     try:\r\n    928       result = self._run(None, fetches, feed_dict, options_ptr,\r\n--> 929                          run_metadata_ptr)\r\n    930       if run_metadata:\r\n    931         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\r\n   1150     if final_fetches or final_targets or (handle and feed_dict_tensor):\r\n   1151       results = self._do_run(handle, final_targets, final_fetches,\r\n-> 1152                              feed_dict_tensor, options, run_metadata)\r\n   1153     else:\r\n   1154       results = []\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\r\n   1326     if handle is None:\r\n   1327       return self._do_call(_run_fn, feeds, fetches, targets, options,\r\n-> 1328                            run_metadata)\r\n   1329     else:\r\n   1330       return self._do_call(_prun_fn, handle, feeds, fetches)\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\r\n   1346           pass\r\n   1347       message = error_interpolation.interpolate(message, self._graph)\r\n-> 1348       raise type(e)(node_def, op, message)\r\n   1349 \r\n   1350   def _extend_graph(self):\r\n\r\nInvalidArgumentError: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by node ConfigureDistributedTPU (defined at <ipython-input-12-37d2eadc5b71>:35) with these attrs: [tpu_embedding_config=\"\", is_global_init=false, embedding_config=\"\"]\r\nRegistered devices: [CPU, XLA_CPU]\r\nRegistered kernels:\r\n  <no registered kernels>\r\n\r\n\t [[node ConfigureDistributedTPU (defined at <ipython-input-12-37d2eadc5b71>:35) ]]\r\n\r\nCaused by op 'ConfigureDistributedTPU', defined at:\r\n  File \"/usr/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\r\n    \"__main__\", mod_spec)\r\n  File \"/usr/lib/python3.5/runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py\", line 16, in <module>\r\n    app.launch_new_instance()\r\n  File \"/usr/local/lib/python3.5/dist-packages/traitlets/config/application.py\", line 658, in launch_instance\r\n    app.start()\r\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelapp.py\", line 505, in start\r\n    self.io_loop.start()\r\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/platform/asyncio.py\", line 148, in start\r\n    self.asyncio_loop.run_forever()\r\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 421, in run_forever\r\n    self._run_once()\r\n  File \"/usr/lib/python3.5/asyncio/base_events.py\", line 1424, in _run_once\r\n    handle._run()\r\n  File \"/usr/lib/python3.5/asyncio/events.py\", line 126, in _run\r\n    self._callback(*self._args)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 690, in <lambda>\r\n    lambda f: self._run_callback(functools.partial(callback, future))\r\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/ioloop.py\", line 743, in _run_callback\r\n    ret = callback()\r\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 781, in inner\r\n    self.run()\r\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 742, in run\r\n    yielded = self.gen.send(value)\r\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 357, in process_one\r\n    yield gen.maybe_future(dispatch(*args))\r\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\r\n    yielded = next(result)\r\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\r\n    yield gen.maybe_future(handler(stream, idents, msg))\r\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\r\n    yielded = next(result)\r\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/kernelbase.py\", line 534, in execute_request\r\n    user_expressions, allow_stdin,\r\n  File \"/usr/local/lib/python3.5/dist-packages/tornado/gen.py\", line 209, in wrapper\r\n    yielded = next(result)\r\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/ipkernel.py\", line 294, in do_execute\r\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\r\n  File \"/usr/local/lib/python3.5/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\r\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2848, in run_cell\r\n    raw_cell, store_history, silent, shell_futures)\r\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2874, in _run_cell\r\n    return runner(coro)\r\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\r\n    coro.send(None)\r\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3049, in run_cell_async\r\n    interactivity=interactivity, compiler=compiler, result=result)\r\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3214, in run_ast_nodes\r\n    if (yield from self.run_code(code, result)):\r\n  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-12-37d2eadc5b71>\", line 35, in <module>\r\n    tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)))\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/framework/python/framework/experimental.py\", line 64, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py\", line 2225, in tpu_model\r\n    setup_tpu_session(strategy._tpu_cluster_resolver)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/tpu/python/tpu/keras_support.py\", line 161, in setup_tpu_session\r\n    tpu_session.run(tpu.initialize_system())\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/tpu/python/tpu/tpu.py\", line 94, in initialize_system\r\n    return tpu_ops.configure_distributed_tpu(embedding_config=config_string)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/contrib/tpu/ops/gen_tpu_ops.py\", line 315, in configure_distributed_tpu\r\n    is_global_init=is_global_init, name=name)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nInvalidArgumentError (see above for traceback): No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by node ConfigureDistributedTPU (defined at <ipython-input-12-37d2eadc5b71>:35) with these attrs: [tpu_embedding_config=\"\", is_global_init=false, embedding_config=\"\"]\r\nRegistered devices: [CPU, XLA_CPU]\r\nRegistered kernels:\r\n  <no registered kernels>\r\n\r\n\t [[node ConfigureDistributedTPU (defined at <ipython-input-12-37d2eadc5b71>:35) ]]\r\n```", "comments": ["it seems mix of keras and tf.keras isn't working", "Could you please tell me how you resolved this? That is how did you consolidate keras and tensorflow.keras?", "I think this one where I used Keras `model` variable instead of `tpu_model` calling `fit`.. \r\nSimple coding mistake. nothing sinister. "]}, {"number": 28394, "title": "Custom TF 2.0 training loop performing considerably worse than keras fit_generator - can't understand why", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04.2 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v1.12.0-9492-g2c319fb415 2.0.0-alpha0\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: 10.1/V10.1.105\r\n- GPU model and memory: RTX 2080 ti 11gb\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nCurrently trying to reproduce the results from keras model.fit_generator with a custom training loop in TF2.0. Code runs without any issue, but the MAE loss for the custom training loop is ~3.0, whereas the MAE loss for the keras model.fit_generator is significantly better, at ~2.0.\r\n\r\n**Describe the expected behavior**\r\nI would expect the losses to be roughly equivalent.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\nThe data set is extremely large, but each sample consists of 4 fields of length 14,995. Target is a single value, in seconds.\r\n\r\n`\r\n         import tensorflow as tf\r\n         import numpy as np\r\n         import os\r\n        import pandas as pd\r\n         import time\r\n         from sklearn import preprocessing\r\n         import shutil\r\n         import my_classes_tf\r\n    \r\n    # Import data and massage\r\n    os.chdir('/home/aj/Data/LANL-Earthquake-Prediction')\r\n    # cv_indices = pd.read_csv('./Current Data/cv_assignments.csv', delimiter=',', header=None).values.astype('int16')\r\n    evaluation_indices = pd.read_csv('./Current Data/Validation Indices Original.csv', delimiter=',', header=None).values.astype('int64')\r\n    eval_index, cv_index = np.hsplit(evaluation_indices, 2)\r\n    train = pd.read_csv('./Current Data/NewFeatures.csv', delimiter=',', header=None).values.astype('float32')\r\n    train_data, other_info = np.hsplit(train, 2)\r\n    targets, OG_row, EQ_ind, CV_ind = np.hsplit(other_info, 4)\r\n    targets = targets.astype('float16')\r\n    OG_row = OG_row.astype('int64')\r\n    EQ_ind = EQ_ind.astype('int64')\r\n    CV_ind = CV_ind.astype('int64')\r\n    mod_eval = pd.read_csv('./Current Data/Validation Indices Modified.csv', delimiter=',', header=None).values.astype('int64')\r\n    mod_eval_index, mod_cv_index, _, _ = np.hsplit(mod_eval, 4)\r\n    \r\n    logtrain = pd.read_csv('./Current Data/NewFeatures_logtransformed.csv', delimiter=',', header=None).values.astype('float32')\r\n    \r\n    log_std, log_skew, log_kurt, log_sixth, _, _, _ = np.hsplit(logtrain, 7)\r\n    train_data_logs = np.concatenate((log_std, log_skew, log_kurt, log_sixth), axis=1)\r\n    \r\n    del logtrain, log_std, log_skew, log_kurt, log_sixth, other_info\r\n    \r\n    \r\n    def safe_mkdir(path):\r\n        \"\"\" Create a directory if there isn't one already. \"\"\"\r\n        try:\r\n            os.mkdir(path)\r\n        except OSError:\r\n            pass\r\n    \r\n    \r\n    def del_dir(name):\r\n        if os.path.isdir('./Saved Models/{}'.format(name)):\r\n            shutil.rmtree('./Saved Models/{}'.format(name))\r\n        if os.path.isdir('./Error Plots/{}'.format(name)):\r\n            shutil.rmtree('./Error Plots/{}'.format(name))\r\n        if os.path.isdir('./Train and Test Losses/{}'.format(name)):\r\n            shutil.rmtree('./Train and Test Losses/{}'.format(name))\r\n    \r\n    \r\n    fold = 1\r\n    boolz = CV_ind != fold\r\n    cv_train = train_data_logs[boolz.reshape(-1)]\r\n    cv_targets = targets[boolz.reshape(-1)]\r\n    cv_eqs = EQ_ind[boolz.reshape(-1)]\r\n    \r\n    scaler = preprocessing.StandardScaler().fit(cv_train)\r\n    cv_train = scaler.transform(cv_train)\r\n    cv_val = scaler.transform(train_data_logs)\r\n    \r\n    batch_size = 64\r\n    lookback = 14995\r\n    offset = 15000\r\n    \r\n    if np.max(mod_eval_index) > len(train_data_logs):  # Prevents from dividing twice on accident when re-running code\r\n        mod_eval_index = mod_eval_index // 10\r\n    train_gen = my_classes_tf.DataGenerator(data=cv_train,\r\n                                            targets=cv_targets,\r\n                                            indices=cv_eqs,\r\n                                            min_index=0,\r\n                                            max_index=None,\r\n                                            batch_size=batch_size,\r\n                                            lookback=lookback,\r\n                                            offset=offset,\r\n                                            shuffle_start=True,\r\n                                            shuffle_feed=True)\r\n    \r\n    val_gen = my_classes_tf.ValDataGenerator(data=cv_val,\r\n                                             targets=targets,\r\n                                             eval_index=mod_eval_index,\r\n                                             cv_index=mod_cv_index,\r\n                                             cv=fold,\r\n                                             batch_size=batch_size,\r\n                                             lookback=lookback)\r\n    \r\n    \r\n    class CRNN(tf.keras.Model):\r\n        def __init__(self):\r\n            super(CRNN, self).__init__()\r\n            # Consider LocallyConnected1D\r\n            self.conv1 = tf.keras.layers.Conv1D(filters=32, kernel_size=50, strides=1, padding='same',\r\n                                                activation=None, kernel_initializer='he_uniform', name='conv1a')\r\n            self.pool1 = tf.keras.layers.MaxPool1D(pool_size=100, strides=None, name='pool1')\r\n            self.gru1 = tf.keras.layers.GRU(units=32, name='gru1')\r\n            self.dense1 = tf.keras.layers.Dense(units=16, activation=None, name='dense1')\r\n            self.output1 = tf.keras.layers.Dense(units=1, activation='relu', name='output1')\r\n            self.lrelu = tf.keras.layers.LeakyReLU(alpha=0.1)\r\n            self.mae = tf.keras.losses.MeanAbsoluteError()\r\n            self.optimizer = tf.keras.optimizers.SGD(lr=1e-3, momentum=0, nesterov=True)\r\n    \r\n        def call(self, inputs):\r\n            x = self.conv1(inputs)\r\n            x = self.lrelu(x)\r\n            x = self.pool1(x)\r\n            x = self.gru1(x)\r\n            x = self.dense1(x)\r\n            x = self.lrelu(x)\r\n            return self.output1(x)\r\n    \r\n        def train_step(self, sample, label):\r\n            with tf.GradientTape() as tape:\r\n                predictions = self.call(sample)\r\n                loss = self.mae(label, predictions)\r\n            gradients = tape.gradient(loss, self.trainable_variables)\r\n            self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\r\n            self.train_loss(loss)\r\n    \r\n        def eval_once(self, sample, label):\r\n            predictions = self.call(sample)\r\n            loss = self.mae(label, predictions)\r\n            self.eval_loss(loss)\r\n    \r\n        def train(self, num_epochs):\r\n            self.train_loss = tf.keras.metrics.Mean(name='train_loss')\r\n            self.eval_loss = tf.keras.metrics.Mean(name='eval_loss')\r\n            self.store_gradients = np.empty((num_epochs, ))\r\n            for epoch in range(num_epochs):\r\n                start_time = time.time()\r\n                self.train_loss.reset_states()\r\n                self.eval_loss.reset_states()\r\n                for samples, labels in train_gen:\r\n                    self.train_step(samples, labels)\r\n                train_gen.on_epoch_end()\r\n                for samples, labels in val_gen:\r\n                    self.eval_once(samples, labels)\r\n                print('Epoch: {0}, Time: {1:.2f}, Train Loss: {2:.2f}, Test Loss: {3:.2f}'.format(epoch + 1,\r\n                                                                                                  time.time() - start_time,\r\n                                                                                                  self.train_loss.result(),\r\n                                                                                                  self.eval_loss.result()))\r\n    \r\n    \r\n    tf.keras.backend.clear_session()\r\n    model = CRNN()\r\n    model.train(20)\r\n    \r\n    model2 = CRNN()\r\n    model2.compile(optimizer=tf.keras.optimizers.SGD(lr=1e-3, momentum=0, nesterov=True),\r\n                   loss='mae')\r\n    \r\n    history = model2.fit_generator(generator=train_gen,\r\n                                   validation_data=val_gen,\r\n                                   epochs=20,\r\n                                   workers=1,\r\n                                   use_multiprocessing=False,\r\n                                   verbose=2,\r\n                                   callbacks=[])\r\n    \r\n    # https://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/engine/training_eager.py\r\n    # Check this ^ to see what is different between keras fit_generator and your fit\r\n    model3 = CRNN()\r\n    model3.compile(optimizer=model3.optimizer,\r\n                   loss=model3.mae)\r\n    history3 = model3.fit_generator(generator=train_gen,\r\n                                    validation_data=val_gen,\r\n                                    epochs=20,\r\n                                    workers=1,\r\n                                    use_multiprocessing=False,\r\n                                    verbose=2,\r\n                                    callbacks=[])\r\n\r\n`\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\nI have tested to see that this model can overfit by training it on only a single sample, and it is able to overfit in both scenarios. I am using custom generators of the class tf.keras.utils.Sequence, but they work equivalently under each training scenario. Let me know if you need any additional information in order to help me out with this issue! Thanks!\r\n\r\nAttached the custom generators as well as some of the data in text file format (the larger files are too large to upload, but you can use the data from here: https://www.kaggle.com/c/LANL-Earthquake-Prediction/data along with the Build_Features R script I uploaded).\r\n[Build_Features.txt](https://github.com/tensorflow/tensorflow/files/3152705/Build_Features.txt)\r\n\r\n[Validation Indices Original.txt](https://github.com/tensorflow/tensorflow/files/3152692/Validation.Indices.Original.txt)\r\n[Validation Indices Modified.txt](https://github.com/tensorflow/tensorflow/files/3152693/Validation.Indices.Modified.txt)\r\n\r\n\r\n\r\n\r\n[my_classes.txt](https://github.com/tensorflow/tensorflow/files/3152664/my_classes.txt)\r\n", "comments": ["@Atrus619 Please provide the whole set libraries included in this attached code. We request the complete code to reproduce the issue.", "Updated with the requested information - let me know if you have any additional questions, thanks!", "@Atrus619 I ran the code, it says ModuleNotFoundError: No module named 'my_classes_tf'. As this is custom written code, This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.If you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose). Thanks!\r\n", "To the best of my knowledge, this issue is independent of the custom generator (and the generator has been provided as an attachment, see my_classes.txt). I'm sure this could be replicated if the custom generator was replaced with a native tensorflow/keras generator or even something simpler. Would it be helpful to you if I pulled that together and reposted on here?", "@Atrus619 Please provide a smaller reproducible code so that it will be easy to debug. Thanks!", "@muddham Here is one standalone script that replicates this issue. I am leaving the original code at the top for the time being for reference (to demonstrate the analogy at play), but if you would prefer I completely replace it, I have no problem doing just that.\r\n\r\nShort description of analogy:\r\nI wrote a very simple generator to replicate the tf.keras.utils.Sequence class I am using for my custom generator. The data set is MNIST for ease of use, since it is a tensorflow data set. Interestingly enough, I set up two modes for the CRNN class, one for mae and one for sparse categorical crossentropy, and it seems like this issue only occurs for mae. The results of a run I just did:\r\nCustom loop and MAE error: 2.518\r\nKeras loop and MAE error: 1.307\r\nCustom loop and SCC error: 1.468\r\nKeras loop and SCC error: 1.593\r\n\r\nEssentially the custom loop with MAE error ceased to train after only an epoch or two. I realize that MNIST is technically a multilabel classification problem, but it seemed like a good example you will be more familiar with. Feel free to recommend an alternate data set to demonstrate this issue. Also, it is possible the initialization fails and the model ceases to train at all, but as long as you re-run it once it should be fine.\r\n\r\nCode - This standalone script should run just fine as long as you are running tf 2.0:\r\n    import time\r\n    import numpy as np\r\n    import tensorflow_datasets as tfds\r\n    import tensorflow as tf\r\n    \r\n    # Construct a tf.data.Dataset\r\n    ds_train, ds_test = tfds.load(name=\"mnist\", split=[\"train\", \"test\"])\r\n    \r\n    \r\n    # Generator\r\n    class SampleGenerator(tf.keras.utils.Sequence):\r\n        def __init__(self, data, epoch_len, batch_size, shuffle=False):\r\n            self.data = data\r\n            self.epoch_len = epoch_len\r\n            self.batch_size = batch_size\r\n            self.shuffle = shuffle\r\n            self.this_isnt_efficient_images = np.empty([self.epoch_len, self.batch_size, 28, 28, 1])\r\n            self.this_isnt_efficient_labels = np.empty([self.epoch_len, self.batch_size])\r\n            self.on_epoch_end()\r\n    \r\n        def __len__(self):\r\n            return self.epoch_len\r\n    \r\n        def on_epoch_end(self):\r\n            data_temp = self.data\r\n            if self.shuffle:\r\n                data_temp = self.data.shuffle(60000)\r\n            data_temp_batched = data_temp.batch(self.batch_size)\r\n            i = 0\r\n            for features in data_temp_batched:\r\n                if i < self.epoch_len:\r\n                    self.this_isnt_efficient_images[i], self.this_isnt_efficient_labels[i] = features['image'], features['label']\r\n                    i += 1\r\n    \r\n        def __getitem__(self, index):\r\n            return tf.convert_to_tensor(self.this_isnt_efficient_images[index], dtype=tf.float32), \\\r\n                   tf.convert_to_tensor(self.this_isnt_efficient_labels[index], dtype=tf.int16)\r\n    \r\n    \r\n    train_gen = SampleGenerator(ds_train, 400, 128, shuffle=True)\r\n    val_gen = SampleGenerator(ds_test, 20, 128)\r\n    \r\n    \r\n    # Build CRNN class\r\n    class CRNN(tf.keras.Model):\r\n        def __init__(self, mode):\r\n            super(CRNN, self).__init__()\r\n            # Consider LocallyConnected1D\r\n            self.conv1 = tf.keras.layers.Conv1D(filters=32, kernel_size=50, strides=1, padding='same',\r\n                                                activation=None, kernel_initializer='he_uniform', name='conv1a')\r\n            self.pool1 = tf.keras.layers.MaxPool1D(pool_size=100, strides=None, name='pool1')\r\n            self.gru1 = tf.keras.layers.GRU(units=32, name='gru1')\r\n            self.dense1 = tf.keras.layers.Dense(units=16, activation=None, name='dense1')\r\n    \r\n            self.lrelu = tf.keras.layers.LeakyReLU(alpha=0.1)\r\n            self.flatten = tf.keras.layers.Flatten()\r\n            if mode == \"mae\":\r\n                self.output1 = tf.keras.layers.Dense(units=1, activation=tf.keras.activations.relu, name='output1')\r\n                self.loss = tf.keras.losses.MeanAbsoluteError()\r\n            elif mode == \"scc\":\r\n                self.output1 = tf.keras.layers.Dense(units=10, activation=tf.keras.activations.softmax, name='output1')\r\n                self.loss = tf.keras.losses.SparseCategoricalCrossentropy()\r\n            self.optimizer = tf.optimizers.SGD(lr=1e-3, momentum=0, nesterov=True)\r\n    \r\n        def call(self, inputs):\r\n            x = tf.reshape(self.flatten(inputs), [128, 784, 1])\r\n            x = self.conv1(x)\r\n            x = self.lrelu(x)\r\n            x = self.pool1(x)\r\n            x = self.gru1(x)\r\n            x = self.dense1(x)\r\n            x = self.lrelu(x)\r\n            return self.output1(x)\r\n    \r\n        def train_step(self, sample, label):\r\n            with tf.GradientTape() as tape:\r\n                predictions = self.call(sample)\r\n                loss = self.loss(label, predictions)\r\n            gradients = tape.gradient(loss, self.trainable_variables)\r\n            self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\r\n            self.train_loss(loss)\r\n    \r\n        def eval_once(self, sample, label):\r\n            predictions = self.call(sample)\r\n            loss = self.loss(label, predictions)\r\n            self.eval_loss(loss)\r\n    \r\n        def train(self, num_epochs):\r\n            self.train_loss = tf.metrics.Mean(name='train_loss')\r\n            self.eval_loss = tf.metrics.Mean(name='eval_loss')\r\n            self.store_gradients = np.empty((num_epochs,))\r\n            for epoch in range(num_epochs):\r\n                start_time = time.time()\r\n                self.train_loss.reset_states()\r\n                self.eval_loss.reset_states()\r\n                for samples, labels in train_gen:\r\n                    self.train_step(samples, labels)\r\n                train_gen.on_epoch_end()\r\n                for samples, labels in val_gen:\r\n                    self.eval_once(samples, labels)\r\n                print('Epoch: {0}, Time: {1:.2f}, Train Loss: {2:.2f}, Test Loss: {3:.2f}'.format(epoch + 1,\r\n                                                                                                  time.time() - start_time,\r\n                                                                                                  self.train_loss.result(),\r\n                                                                                                  self.eval_loss.result()))\r\n    \r\n    \r\n    # Train\r\n    # Custom loop and MAE error - 2.52\r\n    tf.keras.backend.clear_session()\r\n    model_custom_mae = CRNN(mode='mae')\r\n    model_custom_mae.train(20)\r\n    # Keras fit_generator and MAE error - 1.307\r\n    tf.keras.backend.clear_session()\r\n    model_keras_mae = CRNN(mode='mae')\r\n    model_keras_mae.compile(optimizer=tf.optimizers.SGD(lr=1e-3, momentum=0, nesterov=True),\r\n                            loss='mae')\r\n    history1 = model_keras_mae.fit_generator(generator=train_gen,\r\n                                             validation_data=val_gen,\r\n                                             epochs=20,\r\n                                             workers=1,\r\n                                             use_multiprocessing=False,\r\n                                             verbose=2,\r\n                                             callbacks=[])\r\n    # Custom loop and SCC error - 1.468\r\n    tf.keras.backend.clear_session()\r\n    model_custom_scc = CRNN(mode='scc')\r\n    model_custom_scc.train(20)\r\n    # Keras fit_generator and SCC error - 1.593\r\n    tf.keras.backend.clear_session()\r\n    model_keras_scc = CRNN(mode='scc')\r\n    model_keras_scc.compile(optimizer=tf.optimizers.SGD(lr=1e-3, momentum=0, nesterov=True),\r\n                            loss='sparse_categorical_crossentropy')\r\n    history2 = model_keras_scc.fit_generator(generator=train_gen,\r\n                                             validation_data=val_gen,\r\n                                             epochs=20,\r\n                                             workers=1,\r\n                                             use_multiprocessing=False,\r\n                                             verbose=2,\r\n                                             callbacks=[])\r\n    # Print outputs\r\n    print(\"Custom loop and MAE error: {0:.3f}\".format(model_custom_mae.eval_loss.result().numpy()))\r\n    print(\"Keras loop and MAE error: {0:.3f}\".format(history1.history['val_loss'][len(history1.history['val_loss'])-1]))\r\n    print(\"Custom loop and SCC error: {0:.3f}\".format(model_custom_scc.eval_loss.result().numpy()))\r\n    print(\"Keras loop and SCC error: {0:.3f}\".format(history2.history['val_loss'][len(history2.history['val_loss'])-1]))", "@Atrus619 Able to reproduce the issue with the provided code in TF\r\nCustom loop and MAE error: 2.516\r\nKeras loop and MAE error: 1.274\r\nCustom loop and SCC error: 1.518\r\nKeras loop and SCC error: 1.240", "Hi @Atrus619, \r\nmaybe the problem is caused by broadcasting in your loss function in the custom loop. Make sure that the dimensions of `predictions` and `label` is equal. At the moment (for MAE) they are `[128,1]` and `[128]`. Just make use  of `tf.squeeze` or `tf.expand_dims`. \r\n\r\nI've tested it with `predictions = tf.squeeze(predictions)` in the `train_step` and `eval_once` only for MAE. Results are after 20 epochs now: \r\n\r\nCustom loop and MAE error: 1.413\r\nKeras loop and MAE error: 1.261\r\nCustom loop and SCC error: 1.327\r\nKeras loop and SCC error: 1.390\r\n\r\nHope I could help, \r\nAlex", "Closing this out since I understand it to be resolved by @AlexanderBartler suggestion, but please let me know if I'm mistaken.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28394\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28394\">No</a>\n", "Yes, I guess I didn't notice the response 15 days ago, but this was totally the issue, guess I learned a valuable lesson about broadcasting, thanks @AlexanderBartler!"]}, {"number": 28393, "title": "Error: Chunk at .... - Custom object detection train.py", "body": "Hey,\r\nI am quite new to tensorflow object detection.\r\nCurrently running the newest version 1.13.1. My CUDA is version 10.0, cudnn version is also corresponding. I have set the model settings properly, labelmap is fine. But when I start training it shows this instead of the training progress. This is the command I use for training: \r\npython train.py --logtostderr --train_dir=Training_dir/ --pipeline_config_path=Training/faster_rcnn_inception_v2_pets.config\r\n\r\n\r\n2019-05-04 15:49:49.681406: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0000000715B7F200 of size 256\r\n2019-05-04 15:49:49.685276: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0000000715B7F300 of size 256\r\n2019-05-04 15:49:49.687901: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0000000715B7F400 of size 256\r\n2019-05-04 15:49:49.690789: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0000000715B7F500 of size 256\r\n2019-05-04 15:49:49.695108: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0000000715B7F600 of size 256\r\n2019-05-04 15:49:49.697040: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0000000715B7F700 of size 256\r\n2019-05-04 15:49:49.699036: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0000000715B7F800 of size 256\r\n2019-05-04 15:49:49.701121: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0000000715B7F900 of size 256\r\n2019-05-04 15:49:49.704656: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0000000715B7FA00 of size 256\r\n2019-05-04 15:49:49.707688: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0000000715B7FB00 of size 256\r\n2019-05-04 15:49:49.710263: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0000000715B7FC00 of size 256\r\n2019-05-04 15:49:49.712346: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0000000715B7FD00 of size 256\r\n2019-05-04 15:49:49.716165: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0000000715B7FE00 of size 256\r\n2019-05-04 15:49:49.718124: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0000000715B7FF00 of size 256\r\n2019-05-04 15:49:49.720099: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0000000715B80000 of size 256\r\n2019-05-04 15:49:49.722046: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0000000715B80100 of size 256\r\n2019-05-04 15:49:49.726579: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0000000715B80200 of size 256\r\n2019-05-04 15:49:49.728682: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0000000715B80300 of size 256\r\n2019-05-04 15:49:49.731296: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0000000715B80400 of size 256\r\n2019-05-04 15:49:49.734722: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0000000715B80500 of size 256\r\n2019-05-04 15:49:49.737321: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0000000715B80600 of size 256\r\n2019-05-04 15:49:49.739445: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0000000715B80700 of size 256\r\n2019-05-04 15:49:49.741584: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0000000715B80800 of size 256\r\n2019-05-04 15:49:49.745590: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0000000715B80900 of size 256\r\n2019-05-04 15:49:49.747562: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0000000715B80A00 of size 256\r\n2019-05-04 15:49:49.749507: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0000000715B80B00 of size 256\r\n2019-05-04 15:49:49.752000: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0000000715B80C00 of size 256\r\n2019-05-04 15:49:49.756087: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0000000715B80D00 of size 256\r\n2019-05-04 15:49:49.758338: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0000000715B80E00 of size 256\r\n2019-05-04 15:49:49.761321: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0000000715B80F00 of size 256\r\n2019-05-04 15:49:49.764796: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0000000715B81000 of size 256\r\n2019-05-04 15:49:49.766885: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Free  at 0000000715B81100 of size 359440128\r\n2019-05-04 15:49:49.768987: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 000000072B24B000 of size 718848000\r\n2019-05-04 15:49:49.771072: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 0000000755FD7000 of size 359424000\r\n2019-05-04 15:49:49.774803: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Chunk at 000000076B69D000 of size 718848000\r\n2019-05-04 15:49:49.776925: I tensorflow/core/common_runtime/bfc_allocator.cc:632] Free  at 0000000796429000 of size 548053760\r\n2019-05-04 15:49:49.779391: I tensorflow/core/common_runtime/bfc_allocator.cc:638]      Summary of in-use Chunks by size:\r\n2019-05-04 15:49:49.781397: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 6634 Chunks of size 256 totalling 1.62MiB\r\n2019-05-04 15:49:49.785476: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 224 Chunks of size 512 totalling 112.0KiB\r\n2019-05-04 15:49:49.788136: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 136 Chunks of size 768 totalling 102.0KiB\r\n2019-05-04 15:49:49.790378: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 160 Chunks of size 1024 totalling 160.0KiB\r\n2019-05-04 15:49:49.794349: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 19 Chunks of size 1280 totalling 23.8KiB\r\n2019-05-04 15:49:49.796678: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 16 Chunks of size 1536 totalling 24.0KiB\r\n2019-05-04 15:49:49.799443: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 2 Chunks of size 2048 totalling 4.0KiB\r\n2019-05-04 15:49:49.802687: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 2 Chunks of size 6144 totalling 12.0KiB\r\n2019-05-04 15:49:49.807143: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 2 Chunks of size 8192 totalling 16.0KiB\r\n2019-05-04 15:49:49.809723: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 3 Chunks of size 13312 totalling 39.0KiB\r\n2019-05-04 15:49:49.812037: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 4 Chunks of size 16384 totalling 64.0KiB\r\n2019-05-04 15:49:49.816472: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 2 Chunks of size 24576 totalling 48.0KiB\r\n2019-05-04 15:49:49.818742: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 8 Chunks of size 49152 totalling 384.0KiB\r\n2019-05-04 15:49:49.824086: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 1 Chunks of size 53248 totalling 52.0KiB\r\n2019-05-04 15:49:49.828020: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 8 Chunks of size 65536 totalling 512.0KiB\r\n2019-05-04 15:49:49.831981: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 2 Chunks of size 81920 totalling 160.0KiB\r\n2019-05-04 15:49:49.836604: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 2 Chunks of size 98304 totalling 192.0KiB\r\n2019-05-04 15:49:49.839664: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 4 Chunks of size 147456 totalling 576.0KiB\r\n2019-05-04 15:49:49.844910: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 2 Chunks of size 163840 totalling 320.0KiB\r\n2019-05-04 15:49:49.847864: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 22 Chunks of size 221184 totalling 4.64MiB\r\n2019-05-04 15:49:49.850899: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 12 Chunks of size 294912 totalling 3.38MiB\r\n2019-05-04 15:49:49.855669: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 6 Chunks of size 331776 totalling 1.90MiB\r\n2019-05-04 15:49:49.857862: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 4 Chunks of size 368640 totalling 1.41MiB\r\n2019-05-04 15:49:49.860496: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 12 Chunks of size 442368 totalling 5.06MiB\r\n2019-05-04 15:49:49.862624: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 2 Chunks of size 516096 totalling 1008.0KiB\r\n2019-05-04 15:49:49.866863: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 4 Chunks of size 524288 totalling 2.00MiB\r\n2019-05-04 15:49:49.869060: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 4 Chunks of size 589824 totalling 2.25MiB\r\n2019-05-04 15:49:49.871650: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 2 Chunks of size 655360 totalling 1.25MiB\r\n2019-05-04 15:49:49.876124: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 6 Chunks of size 737280 totalling 4.22MiB\r\n2019-05-04 15:49:49.878282: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 6 Chunks of size 786432 totalling 4.50MiB\r\n2019-05-04 15:49:49.880396: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 4 Chunks of size 884736 totalling 3.38MiB\r\n2019-05-04 15:49:49.882433: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 2 Chunks of size 921600 totalling 1.76MiB\r\n2019-05-04 15:49:49.886079: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 2 Chunks of size 1105920 totalling 2.11MiB\r\n2019-05-04 15:49:49.888123: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 2 Chunks of size 1290240 totalling 2.46MiB\r\n2019-05-04 15:49:49.890219: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 2 Chunks of size 1327104 totalling 2.53MiB\r\n2019-05-04 15:49:49.892502: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 4 Chunks of size 1441792 totalling 5.50MiB\r\n2019-05-04 15:49:49.896264: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 2 Chunks of size 1548288 totalling 2.95MiB\r\n2019-05-04 15:49:49.898314: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 2 Chunks of size 1769472 totalling 3.38MiB\r\n2019-05-04 15:49:49.900343: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 4 Chunks of size 1806336 totalling 6.89MiB\r\n2019-05-04 15:49:49.902344: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 4 Chunks of size 2211840 totalling 8.44MiB\r\n2019-05-04 15:49:49.906552: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 2 Chunks of size 2359296 totalling 4.50MiB\r\n2019-05-04 15:49:49.909086: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 2 Chunks of size 10616832 totalling 20.25MiB\r\n2019-05-04 15:49:49.911765: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 1 Chunks of size 359424000 totalling 342.77MiB\r\n2019-05-04 15:49:49.915674: I tensorflow/core/common_runtime/bfc_allocator.cc:641] 2 Chunks of size 718848000 totalling 1.34GiB\r\n2019-05-04 15:49:49.918760: I tensorflow/core/common_runtime/bfc_allocator.cc:645] Sum Total of in-use chunks: 1.77GiB\r\n2019-05-04 15:49:49.921284: I tensorflow/core/common_runtime/bfc_allocator.cc:647] Stats:\r\nLimit:                  3006477107\r\nInUse:                  1902062848\r\nMaxInUse:               1902062848\r\nNumAllocs:                   12819\r\nMaxAllocSize:            718848000\r\n\r\n2019-05-04 15:49:49.928506: W tensorflow/core/common_runtime/bfc_allocator.cc:271] ****______*__________*************************************************************__________________\r\n2019-05-04 15:49:49.931977: W tensorflow/core/framework/op_kernel.cc:1401] OP_REQUIRES failed at conv_ops.cc:446 : Resource exhausted: OOM when allocating tensor with shape[52,64,480,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\nINFO:tensorflow:Error reported to Coordinator: OOM when allocating tensor with shape[52,64,480,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n         [[node FirstStageFeatureExtractor/InceptionV2/InceptionV2/Conv2d_1a_7x7/separable_conv2d (defined at D:\\tensorflow\\models-master\\research\\slim\\nets\\inception_v2.py:117) ]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n         [[node BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Reshape (defined at D:\\tensorflow\\models-master\\research\\object_detection\\core\\post_processing.py:136) ]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\r\nCaused by op 'FirstStageFeatureExtractor/InceptionV2/InceptionV2/Conv2d_1a_7x7/separable_conv2d', defined at:\r\n  File \"train.py\", line 184, in <module>\r\n    tf.app.run()\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 324, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"train.py\", line 180, in main\r\n    graph_hook_fn=graph_rewriter_fn)\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\legacy\\trainer.py\", line 291, in train\r\n    clones = model_deploy.create_clones(deploy_config, model_fn, [input_queue])\r\n  File \"D:\\tensorflow\\models-master\\research\\slim\\deployment\\model_deploy.py\", line 193, in create_clones\r\n    outputs = model_fn(*args, **kwargs)\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\legacy\\trainer.py\", line 204, in _create_losses\r\n    prediction_dict = detection_model.predict(images, true_image_shapes)\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\meta_architectures\\faster_rcnn_meta_arch.py\", line 647, in predict\r\n    image_shape) = self._extract_rpn_feature_maps(preprocessed_inputs)\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\meta_architectures\\faster_rcnn_meta_arch.py\", line 978, in _extract_rpn_feature_maps\r\n    scope=self.first_stage_feature_extractor_scope))\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\meta_architectures\\faster_rcnn_meta_arch.py\", line 163, in extract_proposal_features\r\n    return self._extract_proposal_features(preprocessed_inputs, scope)\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\models\\faster_rcnn_inception_v2_feature_extractor.py\", line 138, in _extract_proposal_features\r\n    scope=scope)\r\n  File \"D:\\tensorflow\\models-master\\research\\slim\\nets\\inception_v2.py\", line 117, in inception_v2_base\r\n    scope=end_point)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\arg_scope.py\", line 182, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py\", line 2778, in separable_convolution2d\r\n    outputs = layer.apply(inputs)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1227, in apply\r\n    return self.__call__(inputs, *args, **kwargs)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 530, in __call__\r\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 554, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\", line 1691, in call\r\n    data_format=conv_utils.convert_data_format(self.data_format, ndim=4))\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py\", line 681, in separable_conv2d\r\n    name=name)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1113, in conv2d\r\n    data_format=data_format, dilations=dilations, name=name)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\r\n    op_def=op_def)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[52,64,480,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n         [[node FirstStageFeatureExtractor/InceptionV2/InceptionV2/Conv2d_1a_7x7/separable_conv2d (defined at D:\\tensorflow\\models-master\\research\\slim\\nets\\inception_v2.py:117) ]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n         [[node BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Reshape (defined at D:\\tensorflow\\models-master\\research\\object_detection\\core\\post_processing.py:136) ]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1334, in _do_call\r\n    return fn(*args)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1319, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1407, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[52,64,480,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n         [[{{node FirstStageFeatureExtractor/InceptionV2/InceptionV2/Conv2d_1a_7x7/separable_conv2d}}]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n         [[{{node BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Reshape}}]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\coordinator.py\", line 297, in stop_on_exception\r\n    yield\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\coordinator.py\", line 495, in run\r\n    self.run_loop()\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\supervisor.py\", line 1034, in run_loop\r\n    self._sv.global_step])\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 929, in run\r\n    run_metadata_ptr)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1152, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1328, in _do_run\r\n    run_metadata)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1348, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[52,64,480,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n         [[node FirstStageFeatureExtractor/InceptionV2/InceptionV2/Conv2d_1a_7x7/separable_conv2d (defined at D:\\tensorflow\\models-master\\research\\slim\\nets\\inception_v2.py:117) ]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n         [[node BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Reshape (defined at D:\\tensorflow\\models-master\\research\\object_detection\\core\\post_processing.py:136) ]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\r\nCaused by op 'FirstStageFeatureExtractor/InceptionV2/InceptionV2/Conv2d_1a_7x7/separable_conv2d', defined at:\r\n  File \"train.py\", line 184, in <module>\r\n    tf.app.run()\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 324, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"train.py\", line 180, in main\r\n    graph_hook_fn=graph_rewriter_fn)\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\legacy\\trainer.py\", line 291, in train\r\n    clones = model_deploy.create_clones(deploy_config, model_fn, [input_queue])\r\n  File \"D:\\tensorflow\\models-master\\research\\slim\\deployment\\model_deploy.py\", line 193, in create_clones\r\n    outputs = model_fn(*args, **kwargs)\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\legacy\\trainer.py\", line 204, in _create_losses\r\n    prediction_dict = detection_model.predict(images, true_image_shapes)\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\meta_architectures\\faster_rcnn_meta_arch.py\", line 647, in predict\r\n    image_shape) = self._extract_rpn_feature_maps(preprocessed_inputs)\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\meta_architectures\\faster_rcnn_meta_arch.py\", line 978, in _extract_rpn_feature_maps\r\n    scope=self.first_stage_feature_extractor_scope))\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\meta_architectures\\faster_rcnn_meta_arch.py\", line 163, in extract_proposal_features\r\n    return self._extract_proposal_features(preprocessed_inputs, scope)\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\models\\faster_rcnn_inception_v2_feature_extractor.py\", line 138, in _extract_proposal_features\r\n    scope=scope)\r\n  File \"D:\\tensorflow\\models-master\\research\\slim\\nets\\inception_v2.py\", line 117, in inception_v2_base\r\n    scope=end_point)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\arg_scope.py\", line 182, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py\", line 2778, in separable_convolution2d\r\n    outputs = layer.apply(inputs)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1227, in apply\r\n    return self.__call__(inputs, *args, **kwargs)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 530, in __call__\r\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 554, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\", line 1691, in call\r\n    data_format=conv_utils.convert_data_format(self.data_format, ndim=4))\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py\", line 681, in separable_conv2d\r\n    name=name)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1113, in conv2d\r\n    data_format=data_format, dilations=dilations, name=name)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\r\n    op_def=op_def)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[52,64,480,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n         [[node FirstStageFeatureExtractor/InceptionV2/InceptionV2/Conv2d_1a_7x7/separable_conv2d (defined at D:\\tensorflow\\models-master\\research\\slim\\nets\\inception_v2.py:117) ]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n         [[node BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Reshape (defined at D:\\tensorflow\\models-master\\research\\object_detection\\core\\post_processing.py:136) ]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\r\nINFO:tensorflow:Error reported to Coordinator: OOM when allocating tensor with shape[52,64,480,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n         [[node FirstStageFeatureExtractor/InceptionV2/InceptionV2/Conv2d_1a_7x7/separable_conv2d (defined at D:\\tensorflow\\models-master\\research\\slim\\nets\\inception_v2.py:117) ]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n         [[node BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Reshape (defined at D:\\tensorflow\\models-master\\research\\object_detection\\core\\post_processing.py:136) ]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\r\nCaused by op 'FirstStageFeatureExtractor/InceptionV2/InceptionV2/Conv2d_1a_7x7/separable_conv2d', defined at:\r\n  File \"train.py\", line 184, in <module>\r\n    tf.app.run()\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 324, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"train.py\", line 180, in main\r\n    graph_hook_fn=graph_rewriter_fn)\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\legacy\\trainer.py\", line 291, in train\r\n    clones = model_deploy.create_clones(deploy_config, model_fn, [input_queue])\r\n  File \"D:\\tensorflow\\models-master\\research\\slim\\deployment\\model_deploy.py\", line 193, in create_clones\r\n    outputs = model_fn(*args, **kwargs)\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\legacy\\trainer.py\", line 204, in _create_losses\r\n    prediction_dict = detection_model.predict(images, true_image_shapes)\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\meta_architectures\\faster_rcnn_meta_arch.py\", line 647, in predict\r\n    image_shape) = self._extract_rpn_feature_maps(preprocessed_inputs)\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\meta_architectures\\faster_rcnn_meta_arch.py\", line 978, in _extract_rpn_feature_maps\r\n    scope=self.first_stage_feature_extractor_scope))\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\meta_architectures\\faster_rcnn_meta_arch.py\", line 163, in extract_proposal_features\r\n    return self._extract_proposal_features(preprocessed_inputs, scope)\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\models\\faster_rcnn_inception_v2_feature_extractor.py\", line 138, in _extract_proposal_features\r\n    scope=scope)\r\n  File \"D:\\tensorflow\\models-master\\research\\slim\\nets\\inception_v2.py\", line 117, in inception_v2_base\r\n    scope=end_point)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\arg_scope.py\", line 182, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py\", line 2778, in separable_convolution2d\r\n    outputs = layer.apply(inputs)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1227, in apply\r\n    return self.__call__(inputs, *args, **kwargs)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 530, in __call__\r\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 554, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\", line 1691, in call\r\n    data_format=conv_utils.convert_data_format(self.data_format, ndim=4))\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py\", line 681, in separable_conv2d\r\n    name=name)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1113, in conv2d\r\n    data_format=data_format, dilations=dilations, name=name)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\r\n    op_def=op_def)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[52,64,480,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n         [[node FirstStageFeatureExtractor/InceptionV2/InceptionV2/Conv2d_1a_7x7/separable_conv2d (defined at D:\\tensorflow\\models-master\\research\\slim\\nets\\inception_v2.py:117) ]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n         [[node BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Reshape (defined at D:\\tensorflow\\models-master\\research\\object_detection\\core\\post_processing.py:136) ]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1334, in _do_call\r\n    return fn(*args)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1319, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1407, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[52,64,480,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n         [[{{node FirstStageFeatureExtractor/InceptionV2/InceptionV2/Conv2d_1a_7x7/separable_conv2d}}]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n         [[{{node BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Reshape}}]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\coordinator.py\", line 297, in stop_on_exception\r\n    yield\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\coordinator.py\", line 495, in run\r\n    self.run_loop()\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\supervisor.py\", line 1034, in run_loop\r\n    self._sv.global_step])\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 929, in run\r\n    run_metadata_ptr)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1152, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1328, in _do_run\r\n    run_metadata)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1348, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[52,64,480,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n         [[node FirstStageFeatureExtractor/InceptionV2/InceptionV2/Conv2d_1a_7x7/separable_conv2d (defined at D:\\tensorflow\\models-master\\research\\slim\\nets\\inception_v2.py:117) ]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n         [[node BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Reshape (defined at D:\\tensorflow\\models-master\\research\\object_detection\\core\\post_processing.py:136) ]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\r\nCaused by op 'FirstStageFeatureExtractor/InceptionV2/InceptionV2/Conv2d_1a_7x7/separable_conv2d', defined at:\r\n  File \"train.py\", line 184, in <module>\r\n    tf.app.run()\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 324, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"train.py\", line 180, in main\r\n    graph_hook_fn=graph_rewriter_fn)\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\legacy\\trainer.py\", line 291, in train\r\n    clones = model_deploy.create_clones(deploy_config, model_fn, [input_queue])\r\n  File \"D:\\tensorflow\\models-master\\research\\slim\\deployment\\model_deploy.py\", line 193, in create_clones\r\n    outputs = model_fn(*args, **kwargs)\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\legacy\\trainer.py\", line 204, in _create_losses\r\n    prediction_dict = detection_model.predict(images, true_image_shapes)\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\meta_architectures\\faster_rcnn_meta_arch.py\", line 647, in predict\r\n    image_shape) = self._extract_rpn_feature_maps(preprocessed_inputs)\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\meta_architectures\\faster_rcnn_meta_arch.py\", line 978, in _extract_rpn_feature_maps\r\n    scope=self.first_stage_feature_extractor_scope))\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\meta_architectures\\faster_rcnn_meta_arch.py\", line 163, in extract_proposal_features\r\n    return self._extract_proposal_features(preprocessed_inputs, scope)\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\models\\faster_rcnn_inception_v2_feature_extractor.py\", line 138, in _extract_proposal_features\r\n    scope=scope)\r\n  File \"D:\\tensorflow\\models-master\\research\\slim\\nets\\inception_v2.py\", line 117, in inception_v2_base\r\n    scope=end_point)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\arg_scope.py\", line 182, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py\", line 2778, in separable_convolution2d\r\n    outputs = layer.apply(inputs)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1227, in apply\r\n    return self.__call__(inputs, *args, **kwargs)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 530, in __call__\r\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 554, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\", line 1691, in call\r\n    data_format=conv_utils.convert_data_format(self.data_format, ndim=4))\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py\", line 681, in separable_conv2d\r\n    name=name)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1113, in conv2d\r\n    data_format=data_format, dilations=dilations, name=name)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\r\n    op_def=op_def)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[52,64,480,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n         [[node FirstStageFeatureExtractor/InceptionV2/InceptionV2/Conv2d_1a_7x7/separable_conv2d (defined at D:\\tensorflow\\models-master\\research\\slim\\nets\\inception_v2.py:117) ]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n         [[node BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Reshape (defined at D:\\tensorflow\\models-master\\research\\object_detection\\core\\post_processing.py:136) ]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1334, in _do_call\r\n    return fn(*args)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1319, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1407, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[52,64,480,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n         [[{{node FirstStageFeatureExtractor/InceptionV2/InceptionV2/Conv2d_1a_7x7/separable_conv2d}}]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n         [[{{node gradients/FirstStageFeatureExtractor/InceptionV2/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/BatchNorm/FusedBatchNorm_grad/FusedBatchNormGrad}}]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\supervisor.py\", line 994, in managed_session\r\n    yield sess\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\slim\\python\\slim\\learning.py\", line 770, in train\r\n    sess, train_op, global_step, train_step_kwargs)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\slim\\python\\slim\\learning.py\", line 487, in train_step\r\n    run_metadata=run_metadata)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 929, in run\r\n    run_metadata_ptr)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1152, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1328, in _do_run\r\n    run_metadata)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1348, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[52,64,480,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n         [[node FirstStageFeatureExtractor/InceptionV2/InceptionV2/Conv2d_1a_7x7/separable_conv2d (defined at D:\\tensorflow\\models-master\\research\\slim\\nets\\inception_v2.py:117) ]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n         [[node gradients/FirstStageFeatureExtractor/InceptionV2/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/BatchNorm/FusedBatchNorm_grad/FusedBatchNormGrad (defined at D:\\tensorflow\\models-master\\research\\slim\\deployment\\model_deploy.py:263) ]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\r\nCaused by op 'FirstStageFeatureExtractor/InceptionV2/InceptionV2/Conv2d_1a_7x7/separable_conv2d', defined at:\r\n  File \"train.py\", line 184, in <module>\r\n    tf.app.run()\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 324, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"train.py\", line 180, in main\r\n    graph_hook_fn=graph_rewriter_fn)\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\legacy\\trainer.py\", line 291, in train\r\n    clones = model_deploy.create_clones(deploy_config, model_fn, [input_queue])\r\n  File \"D:\\tensorflow\\models-master\\research\\slim\\deployment\\model_deploy.py\", line 193, in create_clones\r\n    outputs = model_fn(*args, **kwargs)\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\legacy\\trainer.py\", line 204, in _create_losses\r\n    prediction_dict = detection_model.predict(images, true_image_shapes)\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\meta_architectures\\faster_rcnn_meta_arch.py\", line 647, in predict\r\n    image_shape) = self._extract_rpn_feature_maps(preprocessed_inputs)\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\meta_architectures\\faster_rcnn_meta_arch.py\", line 978, in _extract_rpn_feature_maps\r\n    scope=self.first_stage_feature_extractor_scope))\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\meta_architectures\\faster_rcnn_meta_arch.py\", line 163, in extract_proposal_features\r\n    return self._extract_proposal_features(preprocessed_inputs, scope)\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\models\\faster_rcnn_inception_v2_feature_extractor.py\", line 138, in _extract_proposal_features\r\n    scope=scope)\r\n  File \"D:\\tensorflow\\models-master\\research\\slim\\nets\\inception_v2.py\", line 117, in inception_v2_base\r\n    scope=end_point)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\arg_scope.py\", line 182, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py\", line 2778, in separable_convolution2d\r\n    outputs = layer.apply(inputs)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1227, in apply\r\n    return self.__call__(inputs, *args, **kwargs)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 530, in __call__\r\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 554, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\", line 1691, in call\r\n    data_format=conv_utils.convert_data_format(self.data_format, ndim=4))\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py\", line 681, in separable_conv2d\r\n    name=name)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1113, in conv2d\r\n    data_format=data_format, dilations=dilations, name=name)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\r\n    op_def=op_def)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[52,64,480,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n         [[node FirstStageFeatureExtractor/InceptionV2/InceptionV2/Conv2d_1a_7x7/separable_conv2d (defined at D:\\tensorflow\\models-master\\research\\slim\\nets\\inception_v2.py:117) ]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n         [[node gradients/FirstStageFeatureExtractor/InceptionV2/InceptionV2/Mixed_4d/Branch_1/Conv2d_0b_3x3/BatchNorm/FusedBatchNorm_grad/FusedBatchNormGrad (defined at D:\\tensorflow\\models-master\\research\\slim\\deployment\\model_deploy.py:263) ]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 184, in <module>\r\n    tf.app.run()\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 324, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"train.py\", line 180, in main\r\n    graph_hook_fn=graph_rewriter_fn)\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\legacy\\trainer.py\", line 418, in train\r\n    saver=saver)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\slim\\python\\slim\\learning.py\", line 785, in train\r\n    ignore_live_threads=ignore_live_threads)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\contextlib.py\", line 99, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\supervisor.py\", line 1004, in managed_session\r\n    self.stop(close_summary_writer=close_summary_writer)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\supervisor.py\", line 832, in stop\r\n    ignore_live_threads=ignore_live_threads)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\coordinator.py\", line 389, in join\r\n    six.reraise(*self._exc_info_to_raise)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\six.py\", line 693, in reraise\r\n    raise value\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\coordinator.py\", line 297, in stop_on_exception\r\n    yield\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\coordinator.py\", line 495, in run\r\n    self.run_loop()\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\supervisor.py\", line 1034, in run_loop\r\n    self._sv.global_step])\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 929, in run\r\n    run_metadata_ptr)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1152, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1328, in _do_run\r\n    run_metadata)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1348, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.ResourceExhaustedError: OOM when allocating tensor with shape[52,64,480,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n         [[node FirstStageFeatureExtractor/InceptionV2/InceptionV2/Conv2d_1a_7x7/separable_conv2d (defined at D:\\tensorflow\\models-master\\research\\slim\\nets\\inception_v2.py:117) ]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n         [[node BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Reshape (defined at D:\\tensorflow\\models-master\\research\\object_detection\\core\\post_processing.py:136) ]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\r\nCaused by op 'FirstStageFeatureExtractor/InceptionV2/InceptionV2/Conv2d_1a_7x7/separable_conv2d', defined at:\r\n  File \"train.py\", line 184, in <module>\r\n    tf.app.run()\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 324, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"train.py\", line 180, in main\r\n    graph_hook_fn=graph_rewriter_fn)\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\legacy\\trainer.py\", line 291, in train\r\n    clones = model_deploy.create_clones(deploy_config, model_fn, [input_queue])\r\n  File \"D:\\tensorflow\\models-master\\research\\slim\\deployment\\model_deploy.py\", line 193, in create_clones\r\n    outputs = model_fn(*args, **kwargs)\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\legacy\\trainer.py\", line 204, in _create_losses\r\n    prediction_dict = detection_model.predict(images, true_image_shapes)\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\meta_architectures\\faster_rcnn_meta_arch.py\", line 647, in predict\r\n    image_shape) = self._extract_rpn_feature_maps(preprocessed_inputs)\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\meta_architectures\\faster_rcnn_meta_arch.py\", line 978, in _extract_rpn_feature_maps\r\n    scope=self.first_stage_feature_extractor_scope))\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\meta_architectures\\faster_rcnn_meta_arch.py\", line 163, in extract_proposal_features\r\n    return self._extract_proposal_features(preprocessed_inputs, scope)\r\n  File \"D:\\tensorflow\\models-master\\research\\object_detection\\models\\faster_rcnn_inception_v2_feature_extractor.py\", line 138, in _extract_proposal_features\r\n    scope=scope)\r\n  File \"D:\\tensorflow\\models-master\\research\\slim\\nets\\inception_v2.py\", line 117, in inception_v2_base\r\n    scope=end_point)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\framework\\python\\ops\\arg_scope.py\", line 182, in func_with_args\r\n    return func(*args, **current_args)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\layers\\python\\layers\\layers.py\", line 2778, in separable_convolution2d\r\n    outputs = layer.apply(inputs)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 1227, in apply\r\n    return self.__call__(inputs, *args, **kwargs)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 530, in __call__\r\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\", line 554, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\convolutional.py\", line 1691, in call\r\n    data_format=conv_utils.convert_data_format(self.data_format, ndim=4))\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\nn_impl.py\", line 681, in separable_conv2d\r\n    name=name)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1113, in conv2d\r\n    data_format=data_format, dilations=dilations, name=name)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\r\n    op_def=op_def)\r\n  File \"D:\\Program Files\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[52,64,480,300] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n         [[node FirstStageFeatureExtractor/InceptionV2/InceptionV2/Conv2d_1a_7x7/separable_conv2d (defined at D:\\tensorflow\\models-master\\research\\slim\\nets\\inception_v2.py:117) ]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n         [[node BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Reshape (defined at D:\\tensorflow\\models-master\\research\\object_detection\\core\\post_processing.py:136) ]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n", "comments": ["Obviously this is because of memory overflow.The batch size or input size you set is too large.For more information, you need to provide configuration files and device information. Please follow the template for the issue.", "This is the .config File: \r\n\r\n```\r\nmodel {\r\n  ssd {\r\n    num_classes: 1\r\n    box_coder {\r\n      faster_rcnn_box_coder {\r\n        y_scale: 10.0\r\n        x_scale: 10.0\r\n        height_scale: 5.0\r\n        width_scale: 5.0\r\n      }\r\n    }\r\n    matcher {\r\n      argmax_matcher {\r\n        matched_threshold: 0.5\r\n        unmatched_threshold: 0.5\r\n        ignore_thresholds: false\r\n        negatives_lower_than_unmatched: true\r\n        force_match_for_each_row: true\r\n      }\r\n    }\r\n    similarity_calculator {\r\n      iou_similarity {\r\n      }\r\n    }\r\n    anchor_generator {\r\n      ssd_anchor_generator {\r\n        num_layers: 6\r\n        min_scale: 0.2\r\n        max_scale: 0.95\r\n        aspect_ratios: 1.0\r\n        aspect_ratios: 2.0\r\n        aspect_ratios: 0.5\r\n        aspect_ratios: 3.0\r\n        aspect_ratios: 0.3333\r\n      }\r\n    }\r\n    image_resizer {\r\n      fixed_shape_resizer {\r\n        height: 300\r\n        width: 300\r\n      }\r\n    }\r\n    box_predictor {\r\n      convolutional_box_predictor {\r\n        min_depth: 0\r\n        max_depth: 0\r\n        num_layers_before_predictor: 0\r\n        use_dropout: false\r\n        dropout_keep_probability: 0.8\r\n        kernel_size: 1\r\n        box_code_size: 4\r\n        apply_sigmoid_to_scores: false\r\n        conv_hyperparams {\r\n          activation: RELU_6,\r\n          regularizer {\r\n            l2_regularizer {\r\n              weight: 0.00004\r\n            }\r\n          }\r\n          initializer {\r\n            truncated_normal_initializer {\r\n              stddev: 0.03\r\n              mean: 0.0\r\n            }\r\n          }\r\n          batch_norm {\r\n            train: true,\r\n            scale: true,\r\n            center: true,\r\n            decay: 0.9997,\r\n            epsilon: 0.001,\r\n          }\r\n        }\r\n      }\r\n    }\r\n    feature_extractor {\r\n      type: 'ssd_mobilenet_v2'\r\n      min_depth: 16\r\n      depth_multiplier: 1.0\r\n      conv_hyperparams {\r\n        activation: RELU_6,\r\n        regularizer {\r\n          l2_regularizer {\r\n            weight: 0.00004\r\n          }\r\n        }\r\n        initializer {\r\n          truncated_normal_initializer {\r\n            stddev: 0.03\r\n            mean: 0.0\r\n          }\r\n        }\r\n        batch_norm {\r\n          train: true,\r\n          scale: true,\r\n          center: true,\r\n          decay: 0.9997,\r\n          epsilon: 0.001,\r\n        }\r\n      }\r\n    }\r\n    loss {\r\n      classification_loss {\r\n        weighted_sigmoid {\r\n        }\r\n      }\r\n      localization_loss {\r\n        weighted_smooth_l1 {\r\n        }\r\n      }\r\n      hard_example_miner {\r\n        num_hard_examples: 3000\r\n        iou_threshold: 0.99\r\n        loss_type: CLASSIFICATION\r\n        max_negatives_per_positive: 3\r\n        min_negatives_per_image: 3\r\n      }\r\n      classification_weight: 1.0\r\n      localization_weight: 1.0\r\n    }\r\n    normalize_loss_by_num_matches: true\r\n    post_processing {\r\n      batch_non_max_suppression {\r\n        score_threshold: 1e-8\r\n        iou_threshold: 0.6\r\n        max_detections_per_class: 100\r\n        max_total_detections: 100\r\n      }\r\n      score_converter: SIGMOID\r\n    }\r\n  }\r\n}\r\n\r\ntrain_config: {\r\n  batch_size: 1\r\n  optimizer {\r\n    rms_prop_optimizer: {\r\n      learning_rate: {\r\n        exponential_decay_learning_rate {\r\n          initial_learning_rate: 0.004\r\n          decay_steps: 800720\r\n          decay_factor: 0.95\r\n        }\r\n      }\r\n      momentum_optimizer_value: 0.9\r\n      decay: 0.9\r\n      epsilon: 1.0\r\n    }\r\n  }\r\n  fine_tune_checkpoint: \"D:/tensorflow/models-master/research/object_detection/ssd_mobilenet_v2_coco_2018_03_29/model.ckpt\"\r\n  fine_tune_checkpoint_type:  \"detection\"\r\n  num_steps: 200000\r\n  data_augmentation_options {\r\n    random_horizontal_flip {\r\n    }\r\n  }\r\n  data_augmentation_options {\r\n    ssd_random_crop {\r\n    }\r\n  }\r\n}\r\n\r\ntrain_input_reader: {\r\n  tf_record_input_reader {\r\n    input_path: \"D:/tensorflow/models-master/research/object_detection/Images/train.record\"\r\n  }\r\n  label_map_path: \"D:/tensorflow/models-master/research/object_detection/Training/labelmap.pbtxt\"\r\n}\r\n\r\neval_config: {\r\n  num_examples: 8000\r\n\r\n  max_evals: 10\r\n}\r\n\r\neval_input_reader: {\r\n  tf_record_input_reader {\r\n    input_path: \"D:/tensorflow/models-master/research/object_detection/Images/test.record\"\r\n  }\r\n  label_map_path: \"D:/tensorflow/models-master/research/object_detection/Training/labelmap.pbtxt\"\r\n  shuffle: false\r\n  num_readers: 1\r\n}\r\n```", "This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will open a new issue. Thanks!", "Try adding these lines of code immediately after importing tensorflow in train.py \r\n\r\nfrom tensorflow.compat.v1 import ConfigProto\r\nfrom tensorflow.compat.v1 import InteractiveSession\r\n\r\nconfig = ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\nsession = InteractiveSession(config=config)"]}, {"number": 28392, "title": "[aarch64] make TensorFlow build for aarch64 linux natively with bazel", "body": "Tested on Coral Dev Board running Mendel Linux chef release\r\n```\r\nbazel --host_jvm_args=-Xms128m --host_jvm_args=-Xmx2048m \\\r\nbuild --config opt --local_resources 1024,1,1 \\\r\n//tensorflow/tools/pip_package/build_pip_package\r\n```", "comments": []}, {"number": 28391, "title": "Update backprop.py", "body": "I tried the example in the docs of GradientTape.jacobian method. However, I got an error like so:\r\n\r\n    with tf.GradientTape() as g:\r\n      x  = tf.constant([1.0, 2.0])\r\n      g.watch(x)\r\n      y = x * x\r\n    jacobian = g.jacobian(y, x)\r\n    # jacobian value is [[2., 0.], [0., 4.]]\r\n\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-1-98cbf513a095> in <module>\r\n      4       g.watch(x)\r\n      5       y = x * x\r\n----> 6       jacobian = g.jacobian(y, x)\r\n      7 \r\n\r\n/anaconda3/envs/ml4u/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py in jacobian(self, target, sources, unconnected_gradients, parallel_iterations, experimental_use_pfor)\r\n   1015     # need gradients through the enclosed operations.\r\n   1016     #self._recording = False\r\n-> 1017     self._push_tape()\r\n   1018     target = array_ops.reshape(target, [-1])\r\n   1019     self._pop_tape()\r\n\r\n/anaconda3/envs/ml4u/lib/python3.7/site-packages/tensorflow/python/eager/backprop.py in _push_tape(self)\r\n    778   def _push_tape(self):\r\n    779     if self._recording:\r\n--> 780       raise ValueError(\"Tape is already recording.\")\r\n    781     if self._tape is None:\r\n    782       self._tape = tape.push_new_tape(\r\n\r\nValueError: Tape is already recording.\r\n\r\nI checked the source code and found that when calling method '_push_tape', it check for flag \"self._recording\". If 'self._recording' == True,  generate the error message as above. So I have to manually add \"self._recording = False' to line 1016.  I have tested and found no more errors.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28391) for more info**.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F28391) for more info**.\n\n<!-- ok -->", "Closing this PR as this not against `master`, please open a new PR against `master` \r\nCC @mihaimaruseac"]}, {"number": 28390, "title": "different results on different machine", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): win10(10.0 17134  10.0 15063)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: unclear\r\n- TensorFlow installed from (source or binary): anaconda navigator\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: 3.7.0\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source): spyder 3.3.1\r\n- CUDA/cuDNN version: CPU\r\n- GPU model and memory: CPU\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\ndifferent results on different machine\r\n**Describe the expected behavior**\r\nsame results on different machine\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\nimport numpy as np\r\nimport csv\r\nimport matplotlib.pyplot as plt\r\nimport tensorflow as tf\r\nfrom sklearn.utils import shuffle\r\nfrom batch import Dataset\r\n\r\n\r\n\r\n\r\ndef generate(sample_size,mean,cov,diff,regression):\r\n    num_classes = 2\r\n    samples_per_class = int(sample_size/2)\r\n    np.random.seed(1)\r\n    X0 = np.random.multivariate_normal(mean,cov,samples_per_class)\r\n    Y0 = np.zeros(samples_per_class)\r\n    \r\n    for ci,d in enumerate(diff):\r\n        X1 = np.random.multivariate_normal(mean+d,cov,samples_per_class)\r\n        Y1 = (ci+1)*np.ones(samples_per_class)\r\n        \r\n        X0 = np.concatenate((X0,X1))\r\n        Y0 = np.concatenate((Y0,Y1))\r\n    \r\n    if regression==False:\r\n        class_ind = [Y0==class_number for class_number in range(num_classes)]\r\n        Y0 = np.asarray(np.hstack(class_ind),dtype=np.float32)\r\n        \r\n    X,Y = shuffle(X0,Y0,random_state=1)\r\n    \r\n    return X,Y\r\n\r\n\r\n\r\nnp.random.seed(10)\r\nnum_classes = 2\r\nmean = np.random.randn(num_classes)\r\ncov = np.eye(num_classes)\r\nX,Y = generate(100,mean,cov,[3.0],True)\r\ncolors = ['r' if l==0 else 'b' for l in Y[:]]\r\nplt.scatter(X[:,0],X[:,1],c=colors)\r\nplt.xlabel('Scaled age (in yrs)')\r\nplt.ylabel('Tumor size (in cm)')\r\nplt.show()\r\nlab_dim =1\r\n\r\n\r\npath = 'F:\\\\\u5b9e\u9a8c\u5ba4\u4ee3\u7801\\\\python\\\\autoencoder\\\\testData\\\\\u7ebf\u6027\u903b\u8f91\u56de\u5f52\u8bad\u7ec3\u96c6.csv'\r\nf = open(path ,'w',newline='',encoding='utf-8') \r\nwriter = csv.writer(f)\r\nfor item in X :\r\n   writer.writerow(item)  \r\nf.close()\r\n\r\ninput_dim = X.shape[1]\r\nlab_dim = 1\r\ninput_features = tf.placeholder(tf.float32,[None,input_dim])\r\ninput_labels = tf.placeholder(tf.float32,[None,lab_dim])\r\nW = tf.Variable(tf.random_normal([input_dim,lab_dim],seed=1),name='weight')\r\nb = tf.Variable(tf.zeros([lab_dim]),name='bias')\r\n\r\noutput = tf.nn.sigmoid(tf.matmul(input_features,W)+b)\r\ncross_entropy = -(input_labels*tf.log(output)+(1-input_labels)*tf.log(1-output))\r\nser = tf.square(input_labels-output)\r\n\r\nloss = tf.reduce_mean(cross_entropy)\r\nerr = tf.reduce_mean(ser)\r\noptimizer = tf.train.AdamOptimizer(0.04)\r\ntrain = optimizer.minimize(loss)\r\n\r\nmaxEpochs = 51\r\nminibatchSize = 25\r\n\r\n\r\npath = 'F:\\\\\u5b9e\u9a8c\u5ba4\u4ee3\u7801\\\\python\\\\autoencoder\\\\testData\\\\\u7ebf\u6027\u903b\u8f91\u56de\u5f52\u4f18\u5316\u524d\u6743\u91cd.csv'\r\nf_1 = open(path ,'w',newline='',encoding='utf-8') \r\nwriter_1 = csv.writer(f_1)\r\n\r\npath = 'F:\\\\\u5b9e\u9a8c\u5ba4\u4ee3\u7801\\\\python\\\\autoencoder\\\\testData\\\\\u7ebf\u6027\u903b\u8f91\u56de\u5f52\u4f18\u5316\u540e\u6743\u91cd.csv'\r\nf_2 = open(path ,'w',newline='',encoding='utf-8') \r\nwriter_2 = csv.writer(f_2)\r\n\r\npath = 'F:\\\\\u5b9e\u9a8c\u5ba4\u4ee3\u7801\\\\python\\\\autoencoder\\\\testData\\\\\u6240\u6709epoch\u7684index.csv'\r\nf_3 = open(path ,'w',newline='',encoding='utf-8') \r\nwriter_3 = csv.writer(f_3)\r\n\r\n\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(tf.global_variables_initializer())\r\n    \r\n    w_1 = sess.run(W)  #\u4f18\u5316\u524d\u7684\u6743\u91cd\r\n    for item in w_1 :\r\n        writer_1.writerow(item)  \r\n    f_1.close()\r\n\r\n    index_all_epoch = []  #\u6240\u6709epoch\r\n    for epoch in range(maxEpochs):\r\n        sumerr=0\r\n        index = Dataset(np.arange(0, 100))  #index\u4e3a\u4e0b\u6807\u6570\u7ec4\uff0c\u4ece0\u5230n_examples-1\u7684\u6574\u6570\r\n        index_whole = np.array([]) #\u4e00\u6b21epoch \r\n        seed = epoch\r\n        for i in range(np.int32(len(Y)/minibatchSize)):\r\n            \r\n            tempindex = index.next_batch(minibatchSize,seed)  #\u5c06\u4e0b\u6807\u6570\u7ec4\u6253\u4e71\uff0c\u53d6\u51fa\u524d\u9762\u7684\u4e0b\u6807\r\n            \r\n            index_whole = np.append(index_whole,tempindex)\r\n            \r\n            x1 = X[tempindex]\r\n            y1 = np.reshape(Y[tempindex],[-1,1])\r\n            tf.reshape(y1,[-1,1])\r\n            _,lossval,outputval,errval = sess.run([train,loss,output,err],feed_dict = {input_features:x1,input_labels:y1})\r\n            sumerr = sumerr + errval\r\n        print('Epoch:','%04d' %(epoch+1),'cost=','{:.9f}'.format(lossval),'err=',sumerr/np.int32(len(Y)/minibatchSize))\r\n        index_all_epoch.append(index_whole)\r\n    \r\n    w_2 = sess.run(W)  #\u4f18\u5316\u540e\u7684\u6743\u91cd\r\n    for item in w_2 :\r\n        writer_2.writerow(item)  \r\n    f_2.close()\r\n    \r\n    for item in index_all_epoch:#\u6240\u6709epoch\r\n        writer_3.writerow(item)\r\n    f_3.close()\r\n        \r\n        \r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@jiayeah9508 please provide a minimum code snippet to reproduce the issue reported here. Thanks!", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 28389, "title": "DLL load failed: The specified module could not be found.", "body": "Exception has occurred: ImportError\r\nDLL load failed: The specified module could not be found.\r\n  File \"C:\\Users\\hanna\\Anaconda3\\Lib\\site-packages\\numpy\\_distributor_init.py\", line 34, in <module>\r\n    from . import _mklinit\r\n  File \"C:\\Users\\hanna\\Anaconda3\\Lib\\site-packages\\numpy\\__init__.py\", line 140, in <module>\r\n    from . import _distributor_init\r\n  File \"C:\\Users\\hanna\\Anaconda3\\Lib\\site-packages\\tensorflow\\python\\__init__.py\", line 47, in <module>\r\n    import numpy as np\r\n  File \"C:\\Users\\hanna\\Anaconda3\\Lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\hanna\\Google Drive\\hannannussbaum\\Data Science\\TensorFlowTest.py\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\hanna\\Anaconda3\\Lib\\runpy.py\", line 85, in _run_code\r\n    exec(code, run_globals)\r\n  File \"C:\\Users\\hanna\\Anaconda3\\Lib\\runpy.py\", line 96, in _run_module_code\r\n    mod_name, mod_spec, pkg_name, script_name)\r\n  File \"C:\\Users\\hanna\\Anaconda3\\Lib\\runpy.py\", line 263, in run_path\r\n    pkg_name=pkg_name, script_name=fname)\r\n\r\ntensorboard                        1.13.1\r\ntensorflow                         1.13.1\r\ntensorflow-estimator               1.13.0\r\ntensorflow-gpu                     1.13.1\r\ntermcolor                          1.1.0", "comments": ["\r\n\r\nDuring testing of installation of tensorflow 1.12.0 ,tensorflow-gpu 1.12.0, tensorboard 1.12.0 I found this error in python idle 3.6\r\n`>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\parek\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\parek\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\parek\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\parek\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\parek\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<pyshell#0>\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\parek\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\parek\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\parek\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\parek\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\parek\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\parek\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\parek\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\parek\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n`", "Please have a look on #28095 . Let us know if that helps. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 28388, "title": "How to build static libtensorflow_cc.a and libtensorflow_framework.a for Linux and MacOS", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 10.13\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: v1.13.1\r\n- Python version: 3.6.7\r\n- Installed using virtualenv? pip? conda?: conda\r\n- Bazel version (if compiling from source): 0.19.2\r\n- GCC/Compiler version (if compiling from source): Apple LLVM version 9.1.0 (clang-902.0.39.2)\r\n- CUDA/cuDNN version: 10/7.4.2.24\r\n- GPU model and memory: GTX 1060\r\n\r\n\r\n\r\n**Describe the problem**\r\nI am unable to build a static version of tensorflow as described for a solution to:\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/22810#issuecomment-433225466\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nTrying to use tensorflow/contrib/cmake results in a number of errors\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nCan you describe the approach to creating a static version of the libraries needed for the following headers:\r\n\r\n#include <tensorflow/core/platform/init_main.h>\r\n#include <tensorflow/core/public/session.h>\r\n#include <tensorflow/core/framework/tensor_shape.h>\r\n\r\nTo link against my software?\r\n\r\nOr alternatively solve this issue:\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/22810\r\n\r\nDated in October of last year.\r\n\r\nStatic linking seems to be doable.", "comments": ["@samhodge This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.If you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose). Thanks!\r\n", "The feature I am requesting is to build a static library under OSX the makefile contrib does not work", "Maybe this is  a better link\r\n\r\nhttps://stackoverflow.com/questions/56013508/libtensorflow-core-a-missing-symbols-tensorflowportinitmainchar-const-in", "I do not think we ever explored building static libtensorflow libraries.\r\n@martinwicke to confirm if that's the case\r\n@meteorcloudy to check how we can do this with bazel\r\n\r\nMartin, also who would be the new owners of libtensorflow?", "I have attempted this for OSSFuzz integration and got into issues with Bazel", "I sorted the issues on the Linux side of things and can get everything statically linked with libtensorflow-core.a nsync.a and libprotobuf.a I was missing some of the -W,l directives which I shamelessly stole from the benchmark example that came as part of contrib/makefile\r\n\r\nEDIT:\r\n\r\nhere is the info\r\n```\r\n-Wall -L$(TENSORFLOW)/tensorflow/contrib/makefile/gen/protobuf-host/lib -Wl,--allow-multiple-definition -Wl,--whole-archive  $(TENSORFLOW)/tensorflow/contrib/makefile/gen/lib/libtensorflow-core.a -Wl,--no-whole-archive $(TENSORFLOW)/tensorflow/contrib/makefile/downloads/nsync/builds/default.linux.c++11/nsync.a -lstdc++ -l:libprotobuf.a -lz -lm -ldl -lpthread -lrt \r\n```", "@hlopko Is it possible to write a cc_static_library in Starlark now?", "@oquenchil will know for sure :)\r\n", "OK I can build the static libraries under OSX from the makefile method also, but I dont have CUDA support yet.\r\n\r\nI might submit a new Makefile if I figure it out.", "> @hlopko Is it possible to write a cc_static_library in Starlark now?\r\n\r\nWith help from the toolchain API but yes it can be done now. There is no cc_common.link() or cc_common.archive() method in the API that will create a static library with dependencies.", "Is there a recipe for doing it now?", "OK here is the link command for using the libtensorflow-core.a nsync.a and libprotobuf.a on OSX\r\n\r\n```\r\n    TENSORFLOW_LIBS = -Wl,-force_load,$(TENSORFLOW)/tensorflow/contrib/makefile/gen/lib/libtensorflow-core.a -Wl,-force_load,$(TENSORFLOW)/tensorflow/contrib/makefile/downloads/nsync/builds/default.macos.c++11/nsync.a  -Wl,-force_load,$(TENSORFLOW)/tensorflow/contrib/makefile/gen/protobuf-host/lib/libprotobuf.a -lstdc++ -lz -lpthread \r\n```", "OK people I can see that under contrib/makefile \r\n\r\nThere are CUDA build possibilities for Tegra \r\n\r\nIs there any history of people makeing the tf_gpu.a for Linux and OSX?\r\n\r\nI am not sure if my users will buy a CPU only interence because it can take 5 minutes per frame of video.\r\n\r\nGPU can be as little as 0.2fps.\r\n\r\nI have tested with libtensorflow_cc.so and libtensorflow_framework.so\r\n\r\nSam\r\nsam", "> Is there a recipe for doing it now?\r\n\r\nNot exactly. We have this example:\r\nhttps://github.com/bazelbuild/rules_cc/blob/master/examples/my_c_compile/my_c_compile.bzl\r\n\r\nYou could use that with CPP_LINK_STATIC_LIBRARY_ACTION_NAME instead from https://github.com/bazelbuild/bazel/blob/master/tools/build_defs/cc/action_names.bzl", "There is also this example which is closer to what is needed: https://github.com/bazelbuild/rules_cc/blob/master/examples/my_c_archive/my_c_archive.bzl.\r\n\r\nNow you have 2 options:\r\n\r\n1) Wait until we add accessors for objects to LibraryToLink\r\n2) Collect transitive static libraries, unpack them, and repack again in one big static library.", "@hlopko \r\n\r\nI think option 2 would be suitable.\r\n\r\nSam", "Any progress on this, I tried hacking up the Tegra gpu/cuda libtfcuda.a target to work on Linux and I didn't get very far:\r\n\r\nsee:\r\nhttps://github.com/tensorflow/tensorflow/blob/v1.13.1/tensorflow/contrib/makefile/Makefile#L833\r\n\r\nHas anybody attempted such a thing before?\r\n\r\nSeems possible.\r\n\r\nSam\r\n\r\nThe kind of issues I ran into were missing dnn.pb.h and other conversions of .proto files to .pb.h and other derived file formats.\r\n\r\nI felt like I was stabbing around in the dark somewhat. I feel that using Bazel would be a much smoother ride than flat Makefile, even though it is very direct.", "The other problem I am having one of my models uses contributed Ops which are not part of the current Makefile so that doesn't run using libtensorflow-core.a but works fine with libtensorflow_cc.so and libtensorflow_framework.so\r\n\r\nI hope I am not the only person who needs static linking.\r\n\r\nSam", "@samhodge hi,Dears,,i have got a problem with build a static library and run error ,could u can help me? thanks.", "the detail info is [here ](https://stackoverflow.com/questions/56249350/how-to-build-a-static-library-with-libtensorflow-core-a-and-how-to-use-it)", "Adding related issue \r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/28942", "Adding related issue\r\nhttps://github.com/tensorflow/tensorflow/issues/29042", "This issue has been reported 2 years ago\r\n\r\nhttps://github.com/bazelbuild/bazel/issues/1920\r\n\r\n", "Adding solution to issue reported 2 years ago\r\n\r\nhttps://github.com/bazelbuild/bazel/issues/5200", "Where are the best resources to start to learn how to do this myself in Skylark?", "@hlopko @meteorcloudy to help with starlark documentation.", "I might add that Tensorflow/contrib/cmake is very broken under Linux for v1.12.0 and v1.13.1 the abseil-cpp dependency is missing from v1.12.0 and in addition v1.12.1+ has a dnn.proto file that should get converted to a dnn.pb.h but is not included in any dependency. @gunan Do you know if there is a maintainer of contrib/cmake they seem like relatively easy fixes for someone with good cmake skills. The other issue were some files in v1.12.0 had been renamed or moved or missing from lists.", "We have dropped official support for cmake long ago. To the best of my\nknowledge, noone stepped up to claim ownership of the cmake folder. That\nsaid, I am still happy to accept fixes for the cmake files.\n\nOn Wed, May 29, 2019, 2:50 PM Sam Hodge <notifications@github.com> wrote:\n\n> I might add that Tensorflow/contrib/cmake is very broken under Linux for\n> v1.12.0 and v1.13.1 the abseil-cpp dependency is missing from v1.12.0 and\n> in addition v1.12.1+ has a dnn.proto file that should get converted to a\n> dnn.pb.h but is not included in any dependency. @gunan\n> <https://github.com/gunan> Do you know if there is a maintainer of\n> contrib/cmake they seem like relatively easy fixes for someone with good\n> cmake skills. The other issue were some files in v1.12.0 had been renamed\n> or moved or missing from lists.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/28388?email_source=notifications&email_token=AB4UEOICMI4BQEX4YSHRKYLPX33DJA5CNFSM4HKYE5FKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODWQXPDY#issuecomment-497121167>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AB4UEOMNRHOLXDJXTYPXCXTPX33DJANCNFSM4HKYE5FA>\n> .\n>\n", "@gunan \r\n\r\nThanks for your response, my own CMake skills are limited to a number of files in a folder and linking to a library or two, rather than checking out whole projects and linking them together from a single CMake parent file.\r\n\r\nThat being said at some stage in my life I didn't know how to walk or talk, and I learned that too. My choice now is if to make the small number of changes via CMake or the other changes via bazel and Skylark. I really need static linking with CUDA support to satisfy the use case for Tensorflow as a plugin to a parent package already using Tensorflow where computations are in the minutes per frame CPU only but are seconds a frame with GPU support.\r\n\r\n But there is plenty of example code and tutorials at least for CMake. So I may make those contributions.", "@hlopko\r\n\r\nOk CMake seems like a lost cause.\r\n\r\nAlthough in October 2018 I did build a static version of Tensorflow 1.8(?) on Windows with CUDA 9 but that is not suitable to current RTX hardware \r\n\r\nSo looking into Bazel and Starlark\r\n\r\nI found this\r\n\r\nhttps://docs.bazel.build/versions/0.26.0/be/c-cpp.html\r\n\r\nWith reference to link static \r\n\r\nWith a bit of graph introspection of libtensorflow_cc.so\r\n\r\nI can probably expand out the transitive libraries \r\n\r\nBut I don\u2019t know how to make an archive from an existing statically linked archive, are there any tips on how this is done?\r\n\r\nSam\r\n\r\n\r\n", "You'll have to unarchive all archives and then re-archive all objects back into 1 giant archive. Or use ar script (https://stackoverflow.com/questions/3821916/how-to-merge-two-ar-static-libraries-into-one).", "@hlopko\r\n\r\nIs there a way to do the ar unpack repack trick in Starlark?\r\n\r\nOr would it be easier to do some graph walking and just stuff all of the .o files for recursive upstream dependencies to libtensorflow_cc.so?\r\n\r\nI am hoping to have time to tackle this today.", "I found how to get the ar executable \r\n\r\nhttps://docs.bazel.build/versions/master/skylark/lib/CcToolchainInfo.html\r\n\r\nBut not sure how to call it\r\n\r\n@hlopko is there an example in the docs or could you paste a snippet ", "Seems the ar actions take flags\r\n\r\nhttps://docs.bazel.build/versions/master/cc-toolchain-config-reference.html#ar-actions\r\n\r\nSo you could call ar -x on each .a file initially\r\n\r\nBut where will the .o files end up? Also what if the names of the object files overlap?\r\n\r\n@hlopko Any references?", "So the journey begins\r\n\r\n```\r\nKognats-Mac-Pro:tensorflow kognat$ bazel query 'deps(//tensorflow:libtensorflow_cc.so)' --output graph > graph.in\r\nStarting local Bazel server and connecting to it...\r\nERROR: /Users/kognat/dev/tensorflow-v1.13.1-static-gpu/tensorflow/tensorflow/cc/saved_model/BUILD:36:1: no such target '//tensorflow/core:saved_model_portable_proto': target 'saved_model_portable_proto' not declared in package 'tensorflow/core' defined by /Users/kognat/dev/tensorflow-v1.13.1-static-gpu/tensorflow/tensorflow/core/BUILD and referenced by '//tensorflow/cc/saved_model:reader'\r\nERROR: Evaluation of query \"deps(//tensorflow:libtensorflow_cc.so)\" failed: errors were encountered while computing transitive closure\r\n```\r\n\r\nJust trying\r\n\r\nbazel build --config=opt //tensorflow:libtensorflow_cc.so\r\n\r\nto be sure it can actually still be built, will know more in an hour or two\r\n\r\nhere is my .tf_configure.bazelrc\r\n\r\n```\r\nKognats-Mac-Pro:tensorflow kognat$ cat .tf_configure.bazelrc \r\nbuild --action_env PYTHON_BIN_PATH=\"/Users/kognat/anaconda3/envs/tensorflow/bin/python\"\r\nbuild --action_env PYTHON_LIB_PATH=\"/Users/kognat/anaconda3/envs/tensorflow/lib/python3.6/site-packages\"\r\nbuild --python_path=\"/Users/kognat/anaconda3/envs/tensorflow/bin/python\"\r\nbuild:xla --define with_xla_support=true\r\nbuild --action_env TF_NEED_OPENCL_SYCL=\"0\"\r\nbuild --action_env TF_NEED_ROCM=\"0\"\r\nbuild --action_env TF_NEED_CUDA=\"1\"\r\nbuild --action_env CUDA_TOOLKIT_PATH=\"/usr/local/cuda\"\r\nbuild --action_env TF_CUDA_VERSION=\"10.0\"\r\nbuild --action_env CUDNN_INSTALL_PATH=\"/usr/local/cuda\"\r\nbuild --action_env TF_CUDNN_VERSION=\"7\"\r\nbuild --action_env TF_CUDA_COMPUTE_CAPABILITIES=\"6.1\"\r\nbuild --action_env TF_CUDA_CLANG=\"0\"\r\nbuild --action_env GCC_HOST_COMPILER_PATH=\"/usr/bin/gcc\"\r\nbuild --config=cuda\r\ntest --config=cuda\r\nbuild:opt --copt=-march=native\r\nbuild:opt --copt=-Wno-sign-compare\r\nbuild:opt --host_copt=-march=native\r\nbuild:opt --define with_default_optimizations=true\r\nbuild:v2 --define=tf_api_version=2\r\n```\r\n\r\nNote MacOS 10.13 build is swapping but seems to be active.\r\n\r\nWill power cycle the machine and use smaller jvm stack size.", "compile fails\r\n\r\ntrying again with \r\n```\r\nbazel build --config=opt --config=nonccl //tensorflow:libtensorflow_cc.so\r\n```", "Also building on CentOS 7.4 from v1.14.0\r\n\r\nWith the following config\r\n\r\n```\r\n[kognat@vxfhost tensorflow]$ more .tf_configure.bazelrc \r\nbuild --action_env PYTHON_BIN_PATH=\"/usr/bin/python3\"\r\nbuild --action_env PYTHON_LIB_PATH=\"/usr/lib64/python3.6/site-packages\"\r\nbuild --python_path=\"/usr/bin/python3\"\r\nbuild:xla --define with_xla_support=true\r\nbuild --action_env TF_CUDA_VERSION=\"10\"\r\nbuild --action_env TF_CUDNN_VERSION=\"7\"\r\nbuild --action_env TF_CUDA_PATHS=\"/usr/local/cuda-10.0,/usr/local/cudnn-7.4.2.24/cuda,/usr/local/cuda-10.0/extras\r\n/CUPTI/\"\r\nbuild --action_env CUDA_TOOLKIT_PATH=\"/usr/local/cuda-10.0\"\r\nbuild --action_env TF_CUDA_COMPUTE_CAPABILITIES=\"6.1\"\r\nbuild --action_env LD_LIBRARY_PATH=\"/usr/local/cuda-10.0/lib64/:/usr/local/cuda-10.0/extras/CUPTI/lib64/:/usr/local/cudnn-7.4.2.24/cuda/lib64/\"\r\nbuild --action_env GCC_HOST_COMPILER_PATH=\"/usr/lib64/ccache/gcc\"\r\nbuild --config=cuda\r\nbuild:opt --copt=-march=native\r\nbuild:opt --copt=-Wno-sign-compare\r\nbuild:opt --host_copt=-march=native\r\nbuild:opt --define with_default_optimizations=true\r\nbuild:v2 --define=tf_api_version=2\r\ntest --flaky_test_attempts=3\r\ntest --test_size_filters=small,medium\r\ntest --test_tag_filters=-benchmark-test,-no_oss,-oss_serial\r\ntest --build_tag_filters=-benchmark-test,-no_oss\r\ntest --test_tag_filters=-no_gpu\r\ntest --build_tag_filters=-no_gpu\r\ntest --test_env=LD_LIBRARY_PATH\r\nbuild --action_env TF_CONFIGURE_IOS=\"0\"\r\n```\r\n\r\nusing\r\nbazel build --config=opt --action_env=LD_LIBRARY_PATH --config=cuda //tensorflow:libtensorflow_cc.so\r\n\r\nwhere CUDNN, CUDA TOOLKIT and CUPTI extra are all put on the LD_LIBRARY_PATH\r\n\r\nwith updated git 2.16\r\ngcc/4.8.5\r\n\r\nCuda Toolkit 10.0\r\nCUDNN 7.4.2.24\r\n\r\nOnce that is complete I will be able to start messing with repacking the symbols with edits to the tensorflow.bzl\r\n\r\nbut\r\n\r\ninitially the query above did not work.  \r\n\r\nEDIT: with bazel 0.25.3 and tensorflow 1.14.0 on CentOS 7.4 it cannot find CUDA and CUDNN with the above configuration \r\n\r\nending with\r\n```\r\nERROR: /home/kognat/dev/tensorflow-1.14.0-static-gpu/tensorflow/tensorflow/stream_executor/platform/default/BUILD:16:1: undeclared inclusion(s) in rule '//tensorflow/stream_executor/platform/default:dso_loader':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/stream_executor/platform/default/dso_loader.cc':\r\n  'third_party/gpus/cuda/cuda_config.h'\r\nTarget //tensorflow:libtensorflow_cc.so failed to build\r\nINFO: Elapsed time: 44.305s, Critical Path: 29.68s\r\nINFO: 261 processes: 261 local.\r\n```\r\n\r\nSo I am giving up to bazel 0.15.2 and TF v1.12.0", "Adding to the list of things that dont work, doing \r\n```\r\nfind bazel-out -iname \\*.o\r\n```\r\n\r\nmashing that though\r\n```\r\nar -r libtfgpu.a lots.pic.o of.pic.o things.o\r\n```\r\n\r\nExpecting to use \r\n```\r\n-Wl,whole_archive -Wl,--whole-archive $FOLDER/libtfgpu.a -Wl,--no-whole-archive\r\n```\r\n\r\n  and expect  everything to be OK\r\n\r\nBut it was worth a shot.", "I have attached the graph that resolves with the query\r\n\r\n bazel query --noimplicit_deps 'deps(//tensorflow:libtensorflow_cc.so)' --output graph > graph.in\r\n\r\nafter deleting a few lines from \r\n```\r\ntensorflow/cc/saved_model/BUILD\r\n```\r\n\r\n[graph.txt](https://github.com/tensorflow/tensorflow/files/3268055/graph.txt)\r\n\r\nIt is pretty big.\r\n", "I gave up and used the Golidlocks method with the .o files making a .a file that was just right.\r\n\r\nBasically you play Goldilock with the intermediate archive.\r\n\r\nGo to link and it says \"Symbol Missing\" you add more .o files, too little\r\n\r\nAdd too many .o files and you get \"Duplicate Symbol\", too much\r\n\r\nUntil like Goldilocks you find a list of symbols that is \"Just Right\"\r\n\r\nJust using the linker as a heuristic and a little patience you get there.\r\n\r\nThen you program will run the same as being Dynamically Linked.\r\n\r\nAs a result I still don't know much Starlark Language.\r\n\r\nOn OSX and Linux a list of those object files for CUDA and v1.12.0 and my configuration is \r\n\r\n[Linux_object.txt](https://github.com/tensorflow/tensorflow/files/3269863/Linux_object.txt)\r\n[OSX_objs.txt](https://github.com/tensorflow/tensorflow/files/3269864/OSX_objs.txt)\r\n\r\n@hlopko  Is there a less direct way of doing this with Starlark?", "https://www.tensorflow.org/lite/guide/build_arm64\r\nthis is documentation for tensorflow arm64 static compilation.", "@samhodge Did you find a less direct method to build a static library? If not could you explain your approach a bit more in detail? which tools did you use exactly?  \r\nI am currently struggling with creating a static library for windows. ", "I am still struggling with it for Arm, it worked well with CMake on Linux x86, but the arch in Arm static lib is not fine for the cross compilers.  The next approach will be compiling everything with bazel.", "I recently revisited this as part of the bazel process in bazel-bin directory there are _obj folders with the .o files\r\n\r\nRunning a \r\n\r\nfind bazel-bin -name \u201c*.o\u201d | grep -v \u201cnot these\u201d > list.txt\r\n\r\nWill get you a list of all of the .o files to make the bazel target you chose like libtensorflow_cc.so\r\n\r\nThen you can write a short Python command to turn that list into a sub process to pack those .o files into a .a via ar with the appropriate flags.\r\n\r\nLater when you are linking your application you might need so other symbols: absl, protobuf, nsync.\r\n\r\nBut that is the gist of my approach.\r\n\r\nSam", "> Any progress on this, I tried hacking up the Tegra gpu/cuda libtfcuda.a target to work on Linux and I didn't get very far:\r\n\r\n@samhodge \r\nDid you compile libtfcuda.a  successfully \uff1f", "> I recently revisited this as part of the bazel process in bazel-bin directory there are _obj folders with the .o files\r\n> \r\n> Running a\r\n> \r\n> find bazel-bin -name \u201c*.o\u201d | grep -v \u201cnot these\u201d > list.txt\r\n> \r\n> Will get you a list of all of the .o files to make the bazel target you chose like libtensorflow_cc.so\r\n> \r\n> Then you can write a short Python command to turn that list into a sub process to pack those .o files into a .a via ar with the appropriate flags.\r\n> \r\n> Later when you are linking your application you might need so other symbols: absl, protobuf, nsync.\r\n> \r\n> But that is the gist of my approach.\r\n> \r\n> Sam\r\n\r\nDoes the .a file  depend on libcuda.so and other .so\uff1f", "> > I recently revisited this as part of the bazel process in bazel-bin directory there are _obj folders with the .o files\r\n> > Running a\r\n> > find bazel-bin -name \u201c*.o\u201d | grep -v \u201cnot these\u201d > list.txt\r\n> > Will get you a list of all of the .o files to make the bazel target you chose like libtensorflow_cc.so\r\n> > Then you can write a short Python command to turn that list into a sub process to pack those .o files into a .a via ar with the appropriate flags.\r\n> > Later when you are linking your application you might need so other symbols: absl, protobuf, nsync.\r\n> > But that is the gist of my approach.\r\n> > Sam\r\n> \r\n> Does the .a file depend on libcuda.so and other .so\uff1f\r\n\r\nyes it does, if you compile with CUDA support.", "I was able to make some things work by using the object files reported in the `*.params`:\r\n```\r\nar -cr libtensorflow.a $(cat bazel-bin/tensorflow/libtensorflow_*.so.*.params | grep '\\.o$')\r\n````\r\n... and then link with `-Wl,--allow-multiple-definition -Wl,--whole-archive libtensorflow.a`\r\n\r\nNote: I first tried creating separate static libraries corresponding to the shared libraries, `libtensorflow_cc.a` and `libtensorflow_framework.a` as noted in this issue's title, but encountered a lot of problems with that approach (e.g. duplicate registrations).  Putting it all in one archive seemed to magically resolve that.\r\n\r\nHope this helps someone!", "Actually, it's better with `bazel build --config=monolithic`, which seems intended for static linking and enables:\r\n`ar -cr libtensorflow_cc.a $(cat bazel-bin/tensorflow/libtensorflow_cc.so.*.params | grep '\\.o$')`", "We see that you are using old version of tensorflow 1.x which is out of support window, We recommend that you upgrade to 2.6.0 and let us know if the issue still persists in newer versions .please check https://github.com/tensorflow/tensorflow/issues/28388#issuecomment-733962842 , https://github.com/tensorflow/tensorflow/issues/28388#issuecomment-734028952 it will help in resolving your issue. Please open a new issue in case you face any errors, Hence moving this to closed status.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28388\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/28388\">No</a>\n"]}, {"number": 28387, "title": "This is to workaround a problem in XLA's clustering, related to handling resources.", "body": "    Workaround a problem in XLA's clustering, with the following code pattern,\r\n\r\n     op0 : VarHandleOp\r\n     op1 : Switch op0, pred\r\n     op2 : ReadVariableOp op0\r\n     op3 : ReadVariableOp op1\r\n\r\n    If op2 and op3 are clustered, the op0 and op1 are inputs,\r\n    and they are both considered as resources, and\r\n    op1 and op0 happen to point to the same resource, and\r\n    this will cause an execution error since the resource is\r\n    not allowed to be initialized (locked) twice.\r\n\r\n    The workaround here is to place contraint on clustering candidates to avoid such cases.\r\n", "comments": ["On your following comments, \r\n\r\n\"I have some minor comments inline, but I'm wondering if this scheme is too broad and would break up legitimate clusters. How much work would it be to do the following:\r\n\r\nRun an analysis over the TF graph creating a set, S, of Switch nodes that produce resources.\r\nFor every Switch in S, find all the users of the switch (call this set SU) and all the users of the data input of the switch (call this set DU). Two nodes, x and y, cannot be in the same cluster if x is in SU and y is in DU.\r\nRun a nested loop like we do for resource variable operations 0 to avoid clustering decisions that would place x and y in the same cluster, where x is in some SU and y is in some DU.\"\r\n\r\nI believe it may be a better and more complete fix to the problem.  I would think it should not be too difficult to implement the algorithm.  \r\n  \r\n", "@gbaned Looks like @xykong58 is currently working on addressing  https://github.com/tensorflow/tensorflow/pull/28387#issuecomment-490649220 ?", "@xykong58 Did you get a chance to look on reviewer comments? Please let us know on the update. Thanks!", "@gbaned  I thought I post an update which addressed all the feedback, and I haven't heard back from sanjoy, which is the reviewer.", "Unfortunately there has been a miscommunication here.  I interpreted\r\n\r\n> I believe it may be a better and more complete fix to the problem. I would think it should not be too difficult to implement the algorithm.\r\n\r\nAs suggesting that you are going to implement the less conservative algorithm.  Though on a second reading it seems that you were only suggesting that doing this would be a good idea, but did not volunteer to do it?\r\n\r\nGiven that the more precise algorithm is not difficult, I think we should implement that more precise algorithm instead of the current less precise algorithm implemented in this PR.  Usually it takes a large amount of annoying work to identify why the TF/XLA bridge does not auto-cluster a graph as effectively, and if we can reduce the chance of needing to do that, I think we should.", "Sorry, I did not make it clear I am not volunteer myself for the implementation. As my priority does not allow me working on the proposed solution, I would leave you to decide how to handle the PR. ", "@xykong58 Is this bug blocking you?  If not, I'd prefer closing the PR for now and revisit later if this ends up being a common problem.\r\n\r\n(Speculatively closing the PR.)"]}, {"number": 28386, "title": "Fix a minor issue in FilterDataset with tests", "body": "This PR fixes a minor issue in `FilterDataset` and add tests:\r\n* https://github.com/tensorflow/tensorflow/commit/a1702b366db532c5280ce264fbae691dd0f660f1: clear the out tensors if the output of filter func is invalid.\r\n\r\n*  https://github.com/tensorflow/tensorflow/commit/b3b934ce549772260dad9f24d25ee46656764a23: add tests for `FilterDataset`.\r\n\r\ncc: @jsimsa ", "comments": []}, {"number": 28384, "title": "Update saver.py", "body": "tf.mul was removed that was there in this saver example. Along with it, tf.compat.v1.initialize_all_variables() ops is going to be deprecated so updated it with tf.compat.v1.global_variables_initializer().", "comments": ["@dynamicwebpaige could you please review new changes", "Thanks @mihaimaruseac "]}, {"number": 28383, "title": "Change doc issue formatting for plain text display", "body": "Issue templates are displayed in a text input box so shouldn't use Markdown formatting.\r\nb/131912565\r\n", "comments": []}]