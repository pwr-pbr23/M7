[{"number": 3738, "title": "Bidirectional_dynamic_rnn in while_loop results in: AttributeError: 'GradLoopState' object has no attribute 'forward_ctxt'", "body": "I'm attempting to recreate this [model](https://github.com/bplank/bilstm-aux) in TensorFlow but I can not seem to get anywhere close to the speed of the original code. On average the TensorFlow implementation is taking 60 ms per document on a GPU, while the pycnn is taking 12 ms per document on a CPU.\n\nWhat appears to be the issue is that _rnn_step will call the LSTM cell on every time step regardless of whether the input at that position is padding or not and then simply fill those values with zeros after the fact using sequence_length. This seems like a lot of unnecessary calculations. \n\nProcessing the tokens sequentially in multiple session.run calls with one token per batch in a similar performance to the original code but the embeddings do not update as the flow is broken.\n\nCurrent working (but slow) code is below.\n\n```\ndef char_encoding(config, graph, doc_len):\n    \"\"\"Create graph nodes for character encoding\"\"\"\n\n    c2i = config[\"c2i\"]\n    max_tokens = config[\"max_tokens\"]\n\n    with graph.as_default():\n\n        # Character Embedding\n        word_lengths = tf.placeholder(tf.int64, [None], name=\"word_lengths\")\n        word_lengths = tf.gather(word_lengths, tf.range(tf.to_int32(doc_len)))\n        char_inputs = tf.placeholder(tf.int32, [None, max_tokens], name=\"char_inputs\")\n        cembed_matrix = tf.Variable(tf.random_uniform([len(c2i.keys()), config[\"ce_dim\"]], -0.25, 0.25), name=\"cembeds\")\n\n        char_inputs = tf.transpose(char_inputs, perm=[1,0])\n        cembeds = tf.nn.embedding_lookup(cembed_matrix, char_inputs, name=\"ce_lookup\")\n        cembeds = tf.gather(cembeds, tf.range(tf.to_int32(doc_len)))\n        cembeds = tf.transpose(cembeds, perm=[1,0,2])\n\n        # Create LSTM for Character Encoding\n        fw_lstm = tf.nn.rnn_cell.BasicLSTMCell(config[\"ce_dim\"], state_is_tuple=True)\n        bw_lstm = tf.nn.rnn_cell.BasicLSTMCell(config[\"ce_dim\"], state_is_tuple=True)\n\n        # Encode Characters with LSTM\n        options = {\n            \"dtype\": tf.float32,\n            \"sequence_length\": word_lengths,\n            \"time_major\": True\n        }\n\n        (output_fw, output_bw), output_states = tf.nn.bidirectional_dynamic_rnn(fw_lstm, bw_lstm, cembeds, **options)\n        output_fw = tf.transpose(output_fw, perm=[1,0,2])\n        output_bw = tf.transpose(output_bw, perm=[1,0,2])\n\n        return output_fw, output_bw, word_lengths\n\n```\n\nAn alternate approach where I loop through the tokens in the graph itself seems like it should be faster but is throwing an odd error: \n\nCode:\n\n```\ndef char_encoding(config, graph, doc_len):\n    \"\"\"Create graph nodes for character encoding\"\"\"\n\n    c2i = config[\"c2i\"]\n    max_tokens = config[\"max_tokens\"]\n\n    with graph.as_default():\n\n        # Character Embedding\n        word_lengths = tf.placeholder(tf.int64, [None], name=\"word_lengths\")\n        word_lengths = tf.gather(word_lengths, tf.range(tf.to_int32(doc_len)))\n        char_inputs = tf.placeholder(tf.int32, [None, max_tokens], name=\"char_inputs\")\n        char_inputs = tf.transpose(char_inputs, perm=[1, 0])\n        cembed_matrix = tf.Variable(tf.random_uniform([len(c2i.keys()), config[\"ce_dim\"]], -0.25, 0.25), name=\"cembeds\")\n\n        # Create LSTM for Character Encoding\n        fw_lstm = tf.nn.rnn_cell.BasicLSTMCell(config[\"ce_dim\"], state_is_tuple=True)\n        bw_lstm = tf.nn.rnn_cell.BasicLSTMCell(config[\"ce_dim\"], state_is_tuple=True)\n\n        def one_pass(i, o_fw, o_bw):\n\n            int_i = tf.to_int32(i)\n\n            options = {\n                \"dtype\": tf.float32,\n                \"sequence_length\": tf.expand_dims(tf.gather(word_lengths, int_i), 0),\n                \"time_major\": True\n            }\n\n            cembeds_invert = tf.nn.embedding_lookup(cembed_matrix, tf.gather(char_inputs, int_i))\n            cembeds_invert = tf.transpose(tf.expand_dims(cembeds_invert, 0), perm=[1,0,2])\n\n            (output_fw, output_bw), output_states = tf.nn.bidirectional_dynamic_rnn(fw_lstm, bw_lstm, cembeds_invert, **options)\n\n            # Get Last Relevant\n            output_fw = tf.gather(output_fw, tf.gather(word_lengths, int_i) - 1)\n            output_bw = tf.gather(output_bw, tf.gather(word_lengths, int_i) - 1)\n\n            # Append to Previous Token Encodings\n            o_fw = o_fw.write(int_i, tf.squeeze(output_fw))\n            o_bw = o_bw.write(int_i, tf.squeeze(output_bw))\n\n            return tf.add(i, 1), o_fw, o_bw\n\n        # Build Loop in Graph\n        i = tf.constant(0.0)\n        float_doc_len = tf.to_float(doc_len)\n        o_fw = tensor_array_ops.TensorArray(dtype=tf.float32, size=tf.to_int32(doc_len))\n        o_bw = tensor_array_ops.TensorArray(dtype=tf.float32, size=tf.to_int32(doc_len))\n        cond = lambda i, *_: tf.less(i, float_doc_len)\n        i, char_embeds, rev_char_embeds = tf.while_loop(cond, one_pass, [i, o_fw, o_bw])\n\n        return char_embeds.pack(), rev_char_embeds.pack()\n```\n\nError:\n\n```\nTraceback (most recent call last):\n  File \"/usr/lib/python3.4/runpy.py\", line 170, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.4/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/git/Meerkat/meerkat/longtail/bilstm_tagger.py\", line 445, in <module>\n    run_from_command_line()\n  File \"/home/ubuntu/git/Meerkat/meerkat/longtail/bilstm_tagger.py\", line 441, in run_from_command_line\n    graph, saver = build_graph(config)\n  File \"/home/ubuntu/git/Meerkat/meerkat/longtail/bilstm_tagger.py\", line 311, in build_graph\n    optimizer = tf.train.GradientDescentOptimizer(config[\"learning_rate\"]).minimize(loss, name=\"optimizer\")\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/optimizer.py\", line 196, in minimize\n    grad_loss=grad_loss)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/optimizer.py\", line 253, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/gradients.py\", line 478, in gradients\n    in_grads = _AsList(grad_fn(op, *out_grads))\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/control_flow_grad.py\", line 202, in _EnterGrad\n    result = grad_ctxt.AddBackPropAccumulator(op, grad)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1646, in AddBackPropAccumulator\n    forward_ctxt = self.grad_state.forward_ctxt\nAttributeError: 'GradLoopState' object has no attribute 'forward_ctxt'\n```\n\nLet me know if seeing the full graph will help at all. Right now that higher level LSTM isn't causing issues because I can just run one document at a time.\n", "comments": ["This seems related but it doesn't seem it was ever resolved:\n\nhttps://github.com/tensorflow/tensorflow/issues/511\n", "Whats most frustrating is that if one token is 50 characters long and 10 other tokens in that batch are 3 characters long it essentially takes the same time to process as if every token was 50 characters long. There must be a better way to approach this. \n", "Yes, the RNN code always runs up to the maximum length.  This is usually solved at a higher level by bucketing by input size.\n", "@girving\n\nI don't think bucketing by input size works in this case. A sub-LSTM is encoding each token in the each sentence. There's only a limited number of tokens in each document. At each step a LSTM encoding of each token is concatenated with work a word embedding before fed into a higher level LSTM for tagging. \n\nI've attempted to not call the cell at ever step like this\n\n```\nflat_state = nest.flatten(state)\n    flat_zero_output = nest.flatten(zero_output)\n\n    def select_relevant_state(state, mask):\n        c = tf.boolean_mask(state[0], mask)\n        h = tf.boolean_mask(state[1], mask)\n        return (c, h)\n\n    # Function to Perform at Each Time Step\n    def time_step(time, output_ta, state):\n\n        mask = (time < sequence_length)\n        indices = tf.squeeze(tf.to_int32(tf.where(mask)))\n        invert_indices = tf.squeeze(tf.to_int32(tf.where(invert_mask)))\n        invert_indices = tf.to_int32(tf.where(invert_mask))\n        input_t = tuple(ta.read(time) for ta in input_ta)\n\n        # Restore Shape Information\n        for input_, shape in zip(input_t, inputs_got_shape):\n            input_.set_shape(shape[1:])\n\n        input_t = nest.pack_sequence_as(structure=inputs, flat_sequence=input_t)\n\n        # Select Only Relevant at This Time Step\n        input_t = tf.boolean_mask(input_t, mask)\n        state = select_relevant_state(state, mask)\n        call_cell = lambda: cell(input_t, state)\n\n        # Call Cell\n        (output, new_state) = call_cell()\n\n        # Fill Unprocessed Steps\n        filler_output = tf.boolean_mask(zero_output, invert_mask)\n        filler_state = select_relevant_state(state, invert_mask)\n\n        output = tf.dynamic_stitch([indices, invert_indices], [output, filler_output])\n        new_state_c = tf.dynamic_stitch([indices, invert_indices], [new_state[0], filler_state[0]])\n        new_state_h = tf.dynamic_stitch([indices, invert_indices], [new_state[1], filler_state[1]])\n        new_state = tf.pack([new_state_c, new_state_h], axis=0)\n\n        # Pack State if Using State Tuples\n        output = nest.flatten(output)\n\n        output_ta = tuple(ta.write(time, out) for ta, out in zip(output_ta, output))\n\n        return (time + 1, output_ta, new_state)\n```\n\nBut this seems to make no difference. It appears that the majority of time is being taken up by back propagation. Is there a means to intervene at this level?\n\nIs there no way to use the same approach as pycnn and get the same performance? The difference is huge. \n", "You mention that pycnn does something better.  Can you describe the approach?\n", "Pycnn isn't documented as well, but the original code at https://github.com/bplank/bilstm-aux simply iterates through each token and then concats the output to the word embeddings. \n\n```\nclass RNNSequencePredictor(SequencePredictor):\n    def __init__(self, rnn_builder):\n        \"\"\"\n        rnn_builder: a LSTMBuilder or SimpleRNNBuilder object.\n        \"\"\"\n        self.builder = rnn_builder\n\n    def predict_sequence(self, inputs):\n        s_init = self.builder.initial_state()\n        return [x.output() for x in s_init.add_inputs(inputs)] #quicker version\n\nchar_rnn = RNNSequencePredictor(pycnn.LSTMBuilder(1, self.c_in_dim, self.c_in_dim, self.model))\n```\n\n```\nfor chars_of_token in char_indices:\n            # use last state as word representation\n            last_state = self.char_rnn.predict_sequence([self.cembeds[c] for c in chars_of_token])[-1]\n            rev_last_state = self.char_rnn.predict_sequence([self.cembeds[c] for c in reversed(chars_of_token)])[-1]\n            char_emb.append(last_state)\n            rev_char_emb.append(rev_last_state)\n\n        wfeatures = [self.wembeds[w] for w in word_indices]\n        features = [pycnn.concatenate([w,c,rev_c]) for w,c,rev_c in zip(wfeatures,char_emb,reversed(rev_char_emb))]\n```\n\nI posted a similar approach in TensorFlow above but got the following error:\n\n```\nTraceback (most recent call last):\n  File \"/usr/lib/python3.4/runpy.py\", line 170, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/lib/python3.4/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ubuntu/git/Meerkat/meerkat/longtail/bilstm_tagger.py\", line 445, in <module>\n    run_from_command_line()\n  File \"/home/ubuntu/git/Meerkat/meerkat/longtail/bilstm_tagger.py\", line 441, in run_from_command_line\n    graph, saver = build_graph(config)\n  File \"/home/ubuntu/git/Meerkat/meerkat/longtail/bilstm_tagger.py\", line 311, in build_graph\n    optimizer = tf.train.GradientDescentOptimizer(config[\"learning_rate\"]).minimize(loss, name=\"optimizer\")\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/optimizer.py\", line 196, in minimize\n    grad_loss=grad_loss)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/training/optimizer.py\", line 253, in compute_gradients\n    colocate_gradients_with_ops=colocate_gradients_with_ops)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/gradients.py\", line 478, in gradients\n    in_grads = _AsList(grad_fn(op, *out_grads))\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/control_flow_grad.py\", line 202, in _EnterGrad\n    result = grad_ctxt.AddBackPropAccumulator(op, grad)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1646, in AddBackPropAccumulator\n    forward_ctxt = self.grad_state.forward_ctxt\nAttributeError: 'GradLoopState' object has no attribute 'forward_ctxt'\n```\n\nI've solved on how to run the RNN while only calling the cell on the relevant characters (can post code if necessary) but the issue persists so it seems the fundamental issue is the time that back propagation takes rather than the time it takes to do the forward pass.\n", "@yuanbyu He's trying to do a two dimensional while loop, and the code looks reasonable to me at first glance.  Could you take a look?\n", "@msevrens I somewhat doubt we have good documentation for while loop differentiation, but @yuanbyu can correct me if we have it.\n", "Same issue here. I've implemented 2d RNN using `tf.while` but got only `AttributeError: 'GradLoopState' object has no attribute 'forward_ctxt'` error. \ud83d\ude1e \n", "This seems relevant: https://github.com/tensorflow/tensorflow/issues/593\n", "@msevrens I forgot to verify: what version of TensorFlow are you using?\n", "@girving \n0.9.0\n\nI'll try to update now and see if that makes a difference\n", "Could you provide a complete running program that can reproduce the problem? \n", "@girving: I've confirmed that the issue still exists on 0.10.0rc0\n\n@yuanbyu: I've attached a stripped down version that isolates the issue.\n[bilstm_tagger.txt](https://github.com/tensorflow/tensorflow/files/416855/bilstm_tagger.txt)\n\nNote that the main issue is still the slowness of running every token to max length regardless of the length of each token. This looping approach is just my attempt to get around it, but I'm running into this GradLoopState error. \n", "I think GradLoopState error is occured by this [commit](https://github.com/tensorflow/tensorflow/commit/0ab76c2cf2b3a34f4cb985875512830aadea9afd). This code makes no sense - because i think there's a lot of syntax error (ex: `forward_ctxt` is nowhere (did you meant `forward_context`?), `grad_state` and `outer_grad_state` is not defined.)\n", "@therne\n\nPerhaps you could provide @yuanbyu another sample of code that results in this error such that it's easier for him to debug?\n", "@msevrens Unfortunately I can't share my code because it has too many local dependency \ud83d\ude22 Instead, i'm trying to reproduce the error using simpler code.\n", "@girving Please keep in mind, if your max sequence_length is less than the total number of inputs to `rnn`, then the calculation is exited early (however, anything past the max sequence length _must_ be filled with zeros because TensorFlow requires all outputs to be filled by _something_).\n\nIf your minibatch sizes vary from iteration to iteration, you could try using `tf.nn.dynamic_rnn`, and make sure that for your LSTM inputs (now tensors of shape `batch_size, max_time_per_batch, depth`) have a `max_time_per_batch` which is exactly equal to the maximum number of frames for that minibatch (and no larger).\n", "(when i say minibatch sizes, i mean minibatch maximum time step counts)\n", "@ebrevdo I think maybe you should take a little more time reading through the previous posts\n", "@ebrevdo \nIn reality if you look at _dynamic_rnn_loop all values at each time step are passed to the LSTM cell. The forward pass is then applied to everything regardless of the sequence_length provided.\n\n```\ninput_t = tuple(ta.read(time) for ta in input_ta)\ncall_cell = lambda: cell(input_t, state)\n```\n\nTherefore, a max_time_step of 100 with all documents having 100 length with take the same amount of time as a max_time_step of 100 with all documents having a length of 20. The only thing sequence_length is used for is to copy in filler zeros AFTER calculation has already occurred.\n\nSeeing as pycnn does the same task on the CPU five times faster than TF does on the GPU shows there's definitely room from improvement here. And I would imagine actually having the \"computation exit early\" would be the first step. Though as I showed above, simply not calling the cell at every step during the forward pass does little to help. The gradient calculation and application is still a bit spaghetti to me so I can't comment on that yet.\n", "@girving @yuanbyu \n\nSo I've discovered that training on the CPU only and clocked at 70ms per training step versus 180ms per training step.\n\nIs this expected behavior? Are LSTMs inherently faster on a CPU?\n\nNote that the GradLoopState is still an issue and this is still half the speed that pycnn trains the same model.\n", "Matt: how large are your hidden states and inputs and batch sizes?  The\nlarger each of these parameters is, the faster that GPU training will be\nrelative to CPU training.\n\nAre you using the sequence_lengths input parameter?  How fast does training\nbecome if you don't use it?\n\nOn Wed, Aug 17, 2016 at 2:23 PM, Matt Sevrens notifications@github.com\nwrote:\n\n> @girving https://github.com/girving @yuanbyu\n> https://github.com/yuanbyu\n> \n> So I've discovered that training on the CPU only and clocked at 70ms per\n> training step versus 180ms per training step.\n> \n> Is this expected behavior? Are LSTMs inherently faster on a CPU?\n> \n> Note that the GradLoopState is still an issue and this is still half the\n> speed that pycnn trains the same model.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3738#issuecomment-240552898,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ABtim08QhHEDV4jviZly9jnBxscqyclOks5qg3u1gaJpZM4Jhn6r\n> .\n", "@ebrevdo Those comments are helpful, but someone should also investigate why his attempt to make it faster throws an obscure error.\n", "@ebrevdo \n\nThe primary speed drain is the inner LSTM which does character encoding. Both the batch size and the max_sequence_length of this inner LSTM are variable. This helps speed it up quite a bit.\n\nOuter LSTM doesn't use batching, same as original paper.\n\nRemoving sequence lengths throws an error. Hidden dims are 100. Running on CPU is fine though as long as long as it matches the speed of pycnn code. As of now on CPU it's about half the speed.\n\nI'm mainly interested now in the nested loop issue as this would seem to solve the fundamental problem of unnecessary calculation. In pycnn time scales relative to number of characters in the sentence. In TensorFlow time scales to `max_token_length * num_tokens`. As token length can be extremely variable in my dataset, until that issue is solved everything seems negligible.\n\n@girving \nI'm working on a more stripped down bare bones version of the issue to help debugging. \n", "With a batch size of 1 and 100 dims, you generally don't get enough data\ngoing through to saturate the GPU's matmul powers; and copying data to/from\nthe GPU becomes the bottleneck.\n\ndynamic_rnn accepts a tensor with a shape of max_time_for_this_minibatch\nand does not perform early stopping for two reasons:\n1. you can provide an inputs tensor where max_time_for_this_minibatch is\ntruly the maximum time _for this minibatch_\n2. having a bunch of cond ops (which must run on CPU) will add additional\nslowdown to the computation, especially if most of the computation is on a\nGPU.  and because of #1 it's unnecessary since the length of the\ncomputation can be variable and is determined by the input tensor\ndimensions.  if you are using placeholders, simply use\nplaceholder(shape=(batch_size, None, input_depth), dtype=...) and feed in\nproperly sized inputs.\n\nIn contrast, with tf.nn.rnn, you always have a fixed graph and using cond()\nto reduce the number of calls to the LSTM cell (especially the matmuls) is\nextremely important.  In this case, sequence_lengths is used to replace\nthis computation past max(sequence_lengths) with just symbolically copying\nsome zero values through (this is essentially free).\n\nOn Wed, Aug 17, 2016 at 4:24 PM, Matt Sevrens notifications@github.com\nwrote:\n\n> @ebrevdo https://github.com/ebrevdo\n> \n> The primary speed drain is the inner LSTM which does character encoding.\n> Both the batch size and the max_sequence_length of this inner LSTM are\n> variable. This helps speed it up quite a bit.\n> \n> Outer LSTM doesn't use batching, same as original paper.\n> \n> Removing sequence lengths throws an error. Hidden dims are 100. Running on\n> CPU is fine though as long as long as it matches the speed of pycnn code.\n> As of now on CPU it's about half the speed.\n> \n> I'm mainly interested now in the nested loop issue as this would seem to\n> solve the fundamental problem of unnecessary calculation. In pycnn time\n> scales relative to number of characters in the sentence. In TensorFlow time\n> scales to max_token_length \\* num_tokens. As token length can be extremely\n> variable in my dataset, until that issue is solved everything seems\n> negligible.\n> \n> @girving https://github.com/girving\n> I'm working on a more stripped down bare bones version of the issue to\n> help debugging.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3738#issuecomment-240579474,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ABtimzvOS5_V9atNeVWXVHP-pKl9Y5rMks5qg5gcgaJpZM4Jhn6r\n> .\n", "@ebrevdo \nI don't think this really solves my fundamental issue. If one token in the batch to the inner LSTM has a length of 100 and the rest have a length of 3 there will always be a huge performance deficit if they are batched. Either the tokens are batched together, or they're looped over. The output of this is fed into a higher LSTM which only has a batch size of 1.\n\nThe batching approach is unreasonably slow when one token is far longer than the rest, the nested loop approach is throwing an obscure error.\n", "@ebrevdo, regarding #1, would it make sense to include convenience functionality in dynamic_rnn that trims the input tensor to the max_time_for_this_minibatch based on `sequence_length`? I _think_ this is easy to do, no?\n", "@alquraishi since this is equivalent to doing a simple `slice` or `gather`, and would bloat the already bloated interface of `dynamic_rnn`, i'd prefer not to do it there.\n", "@msevrens now you are really at the fundamental core of how to deal with RNNs and minibatches.  unfortunately this is out of the hands of e.g. `dynamic_rnn` and has to be handled by the preprocessing technique.\n\nthere are two ways to solve this problem.  one is called truncated back propagation through time, and works on models where you have a loss at every time step (e.g. cross entropy loss).  for this we just added a contrib method called `tf.contrib.training.batch_sequence_with_states`.  You will have to look at truncated BPTT literature and the documentation for that algorithm in depth to understand what it's doing.\n\nThe other approach is called bucketing, and the idea there is, when you read your examples in, group them according to similar lengths and put them in the appropriate queue.  The training step reads off the next available queue and processes the minibatch accordingly.  Each minibatch will contain sequences of approximately the same length.  I plan to make something like this available in contrib very soon.  Keep in mind this approach breaks the `independent` part of `i.i.d.` when training SGD minibatches; but in practice it works pretty well!\n", "My understanding of this bug is that you are running into several issues; one of which is that your batch sizes are too small to effectively take advantage of GPU; and when they do grow large you have too large a variance in the sequence lengths to properly avoid unnecessary unrolls.  I've proposed two solutions above to do this (one already in, one called bucketing which is coming soon).  I'll keep this issue open until bucketing is available in contrib.\n", "I'm also renaming the issue to better reflect the true problem.\n", "@ebrevdo The new title ignores the while-loop related obscure error, though I suppose the other one does too.  I think @msevrens understands the issues involved, and believes he has a fix except for the obscure error.  It might be better to rename the issue to reflect that error, and then debug it.\n", "@ebrevdo \nThe original paper is not using truncated back propagation through time. The final outputs from the forward and backward passes of the inner LSTM on each token are concatenated to a word embedding and fed into the higher level LSTM. There is no loss at every step as the loss comes from the higher level LSTM. \n\nWe also discussed bucketing above and that will not work either as the mini batch itself is the sentence input. Both the inner and outer LSTM are optimized together using the loss from the higher level LSTM. So the batch for the inner LSTM will always be the tokens from the sentence being tagged. \n\nThis architecture seems pretty tied to what is causing the performance issue. At this point, barring a major change to how LSTM's are handled by TensorFlow I believe the best solution is this while loop approach. \n\n@girving \nI agree, I'm going to change the title\n", "One way to handle this might be to combine multiple shorter examples into a\nsingle long example, with state reset indicators in between, and minibatch\nthese longer examples. This kind of bookkeeping is not impossible in a Tf\ngraph, but it's also not easy. I've never seen it done.\n\nOn Aug 19, 2016 2:03 PM, \"Matt Sevrens\" notifications@github.com wrote:\n\n> @ebrevdo https://github.com/ebrevdo\n> The original paper is not using truncated back propagation through time.\n> The final outputs from the forward and backward passes of the inner LSTM on\n> each token are concatenated to a word embedding and fed into the higher\n> level LSTM. There is no loss at every step as the loss comes from the\n> higher level LSTM.\n> \n> We also discussed bucketing above and that will not work either as the\n> mini batch itself is the sentence input. Both the inner and outer LSTM are\n> optimized together using the loss from the higher level LSTM. So the batch\n> for the inner LSTM will always be the tokens from the sentence being\n> tagged.\n> \n> This architecture seems pretty tied to what is causing the performance\n> issue. At this point, barring a major change to how LSTM's are handled by\n> TensorFlow I believe the best solution is this while loop approach.\n> \n> @girving https://github.com/girving\n> I agree, I'm going to change the title\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3738#issuecomment-241134499,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ABtim_O2pakgJmEw5xRYHpoCb5ToCe_dks5qhhomgaJpZM4Jhn6r\n> .\n", "@ebrevdo That's a wonderful idea!  It would reduce the slowdown to at most a factor of 2 (or maybe 3?).  If some tricky bookkeeping is required, maybe an organizational C++ op is worth it?\n", "@girving @ebrevdo @yuanbyu \n\nI've put together a much shorter and simpler code sample that replicates the bug. Hopefully this will be helpful in debugging:\n\n```\nimport tensorflow as tf\nimport numpy as np\n\nfrom tensorflow.python.ops import tensor_array_ops\n\n# Prepare Input\n\ntokens = [\"the\", \"fox\", \"jumps\", \"over\", \"the\", \"erroneous\", \"dog\"]\ntags = [\"other\", \"noun\", \"other\", \"other\", \"other\", \"other\", \"noun\"]\n\ntag_map = {\n    \"noun\": 0,\n    \"other\": 1\n}\n\ntags = np.array([int(tag_map[tag]) for tag in tags])\nencoded_tags = (np.arange(len(tag_map)) == tags[:, None]).astype(np.float32)\n\nalphabet = \"abcdefghijklmnopqrstuvwxyz0\"\nc2i = {a : i for i, a in enumerate(alphabet)}\n\nchar_inputs = []\ntoken_lengths = [len(t) for t in tokens]\nmax_token_length = max(token_lengths)\nnum_tokens = len(tokens)\n\nfor token in tokens:\n    char_ind = [c2i[token[c]] if c < len(token) else c2i[\"0\"] for c in range(max_token_length)]\n    char_inputs.append(char_ind)\n\n# Build Graph\n\ngraph = tf.Graph()\n\nwith graph.as_default():\n\n    # Character Embeddings\n    character_indices = tf.placeholder(tf.int32, [len(tokens), max_token_length])\n    word_lengths = tf.placeholder(tf.int32, [None])\n\n    cembed_matrix = tf.Variable(tf.random_uniform([len(c2i), 100]))\n    inner_lstm = tf.nn.rnn_cell.BasicLSTMCell(100, state_is_tuple=True)\n\n    # Outer Loop Body\n    def outer_body(i, s_out):\n\n        token_input = tf.nn.embedding_lookup(cembed_matrix, tf.gather(character_indices, i))\n        token_input = tf.expand_dims(token_input, 0)\n        token_input = tf.transpose(token_input, perm=[1,0,2])\n\n        options = {\n            \"dtype\": tf.float32,\n            \"sequence_length\": tf.expand_dims(tf.gather(word_lengths, i), 0),\n            \"time_major\": True,\n            \"scope\": \"inner\"\n        }\n\n        output, state = tf.nn.dynamic_rnn(inner_lstm, token_input, **options)\n        last_output = tf.gather(output, tf.gather(word_lengths - 1, i))\n        s_out = s_out.write(i, tf.squeeze(last_output))\n\n        return tf.add(i, 1), s_out\n\n    # Build Loop in Graph\n    i = tf.constant(0)\n    sentence_output = tensor_array_ops.TensorArray(dtype=tf.float32, size=num_tokens)\n    outer_cond = lambda i, *_: tf.less(i, num_tokens)\n    _, encoded_chars = tf.while_loop(outer_cond, outer_body, [i, sentence_output])\n    encoded_chars = encoded_chars.pack()\n\n    # Outer LSTM\n    outer_lstm = tf.nn.rnn_cell.BasicLSTMCell(100, state_is_tuple=True)\n    weight = tf.Variable(tf.random_uniform([100, len(tag_map)]))\n    batched_input = tf.expand_dims(encoded_chars, 0)\n\n    options = {\n        \"dtype\": tf.float32,\n        \"sequence_length\": tf.expand_dims(num_tokens, 0),\n        \"scope\": \"outer\"\n    }\n\n    output, state = tf.nn.dynamic_rnn(outer_lstm, batched_input, **options)\n    prediction = tf.log(tf.nn.softmax(tf.matmul(tf.gather(output, num_tokens), weight)))\n\n    # Calculate Loss and Optimize\n    labels = tf.placeholder(tf.float32, shape=[None, len(tag_map)])\n    loss = tf.neg(tf.reduce_sum(prediction * labels))\n    optimizer = tf.train.GradientDescentOptimizer(0.1).minimize(loss)\n\n# Run Session\n\nwith tf.Session(graph=graph) as sess:\n\n    tf.initialize_all_variables().run()\n\n    feed_dict = {\n        character_indices : char_inputs,\n        word_lengths : token_lengths,\n        labels: encoded_tags\n    }\n\n    sess.run(optimizer, feed_dict=feed_dict)\n```\n", "@ebrevdo\n\nThat's a pretty good idea. I'll take a shot at it.\n\nIn the meantime can you take a look at the code I posted at https://github.com/tensorflow/tensorflow/issues/3738#issuecomment-241531134 and let me know if can see any issue with this looping approach?\n\nI'm really interested in debugging this error, but at this point the TensorFlow internals are still a bit confusing to me.\n", "@yuanbyu \n\nI got the most recent version of tensorFlow with your fix to a related nested looping issue here: https://github.com/tensorflow/tensorflow/commit/096069687c52e16eaa18c1db6e7bbf2737639257  however the GradLoopState issue persists. Any thoughts?\n", "@girving @yuanbyu @ebrevdo \n\nIs this dead? Is there any progress on this? Do I just need to give up on nested looping? I still would like to see this fixed.\n", "It was fixed on our side, and should be in HEAD very soon.\n", "@yuanbyu \nAwesome, looking forward to testing it out.\n", "@yuanbyu \nThe current code in github actually does fix the simpler nested loop example I provided above. Unfortunately, the same error appears when I run the more complex version of the nested loop I'm using for the tagger. I'm not sure what the key difference is.\n\nExample here: \n[nested_loop.txt](https://github.com/tensorflow/tensorflow/files/464999/nested_loop.txt)\n\nI'm not sure whether the full fix is in git yet or if what's in currently is a partial fix. \n", "Running your code gave the following error:\n\nFile \"/usr/local/google/_blaze_yuanbyu/4e574b920d97309ebaf8003010ddff1b/execroot/google3/blaze-out/gcc-4.X.Y-crosstool-v18-hybrid-grtev4-k8-opt/bin/experimental/users/yuanbyu/python/dynamic_rnn1.runfiles/google3/experimental/users/yuanbyu/python/dynamic_rnn1.py\", line 284, in train_model\n    optimizer_out, loss = sess.run([get_op(graph, \"optimizer\"), get_tensor(graph, \"loss:0\")], feed_dict=feed_dict)\n  File \"/usr/local/google/_blaze_yuanbyu/4e574b920d97309ebaf8003010ddff1b/execroot/google3/blaze-out/gcc-4.X.Y-crosstool-v18-hybrid-grtev4-k8-opt/bin/experimental/users/yuanbyu/python/dynamic_rnn1.runfiles/google3/experimental/users/yuanbyu/python/dynamic_rnn1.py\", line 54, in get_op\n    return graph.get_operation_by_name(name)\n  File \"/usr/local/google/_blaze_yuanbyu/4e574b920d97309ebaf8003010ddff1b/execroot/google3/blaze-out/gcc-4.X.Y-crosstool-v18-hybrid-grtev4-k8-opt/bin/experimental/users/yuanbyu/python/dynamic_rnn1.runfiles/google3/third_party/tensorflow/python/framework/ops.py\", line 2579, in get_operation_by_name\n    return self.as_graph_element(name, allow_tensor=False, allow_operation=True)\n  File \"/usr/local/google/_blaze_yuanbyu/4e574b920d97309ebaf8003010ddff1b/execroot/google3/blaze-out/gcc-4.X.Y-crosstool-v18-hybrid-grtev4-k8-opt/bin/experimental/users/yuanbyu/python/dynamic_rnn1.runfiles/google3/third_party/tensorflow/python/framework/ops.py\", line 2451, in as_graph_element\n    return self._as_graph_element_locked(obj, allow_tensor, allow_operation)\n  File \"/usr/local/google/_blaze_yuanbyu/4e574b920d97309ebaf8003010ddff1b/execroot/google3/blaze-out/gcc-4.X.Y-crosstool-v18-hybrid-grtev4-k8-opt/bin/experimental/users/yuanbyu/python/dynamic_rnn1.runfiles/google3/third_party/tensorflow/python/framework/ops.py\", line 2511, in _as_graph_element_locked\n    \"graph.\" % repr(name))\nKeyError: \"The name 'optimizer' refers to an Operation not in the graph.\"\n", "By the way, if you got exactly the same error as before:\n\n```\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/control_flow_grad.py\", line 202, in _EnterGrad\n    result = grad_ctxt.AddBackPropAccumulator(op, grad)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1646, in AddBackPropAccumulator\n    forward_ctxt = self.grad_state.forward_ctxt\nAttributeError: 'GradLoopState' object has no attribute 'forward_ctxt'\n```\n\nIt is very likely that you were using an older version that doesn't include the fix.\n", "@yuanbyu\n\nThe GradLoopState error should occur before the error you're seeing so it appears to be solved on your system.\n\nUnfortunately I no longer seem to be able to build from scratch using the most recent code so I'll need to debug that before I can confirm. \n", "@yuanbyu \n\nSo I got TF to build and it appears the issue with nested looping is solved. Thanks for your effort on this.\n\nUnfortunately the looping approach I was attempting did not speed up the training or execution of the model I'm working with but as far as this issue goes it can be closed.\n"]}, {"number": 3737, "title": "Rename TF_Node to TF_Operation in C API.", "body": "Change: 129673736\n", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n"]}, {"number": 3736, "title": "Fix typo in TensorFlow Linear Model Tutorial", "body": "Hi team!\n\nFixed a small typo in the TensorFlow Linear Model tutorial.\n", "comments": ["Can one of the admins verify this patch?\n", "Test this please\n"]}, {"number": 3735, "title": "Giving `name` attributes to `Graph` and `Session`", "body": "I wanted to gauge thoughts on adding a string `name` attribute to `Graph` and `Session` objects. Currently, there's no programmatic way to identify specific Graphs or Sessions from a generic handle. \n\nThere's no mechanism to ensure unique graph/session names (unless I'm mistaken), but it should still be beneficial even without guaranteeing unique names. In a larger system that may be tossing around multiple sessions and graphs, it would be good to have a way to know what graph is being handled (or what family of graphs, if multiple graphs have the same name). The uses for this could also be extended out to TensorBoard, exporting graphs/models, etc.\n\nPerhaps it would be better off being called `tag`, but I went with `name` to keep it consistent with current code.\n\nGood idea, terrible idea, somewhere in the middle?\n", "comments": ["I would suggest storing a dictionary mapping names to graphs.  Adding name attributes to `Graph` or `Session` would be poor coding style.\n"]}, {"number": 3734, "title": "Update the TensorBoard README link on r0.9.", "body": "Cherrypicked from master.\n", "comments": ["Can one of the admins verify this patch?\n"]}, {"number": 3733, "title": "Update the TensorBoard README link on r0.10.", "body": "Cherrypicked from master.\n", "comments": ["Can one of the admins verify this patch?\n"]}, {"number": 3732, "title": "partial_run, feed placeholder already been fed", "body": "The following code gives this error: 'InvalidArgumentError: The feed Placeholder:0 had already been fed.' I'm not sure if it is expected behaviour. \n\n```\nimport tensorflow as tf\n\nsess = tf.Session()\n\na = tf.placeholder(tf.float32)\nb = tf.placeholder(tf.float32)\nc = tf.placeholder(tf.float32)\nr1 = tf.add(a, b)\nr2 = tf.mul(a, c)\nr3 = tf.sub(r1, r2)\n\nh = sess.partial_run_setup([r1, r2, r3], [a, b, c])\nres1 = sess.partial_run(h, r1, feed_dict={a: 1, b: 2})\nres2 = sess.partial_run(h, r2, feed_dict={a: 2, c: 3})\nres3 = sess.partial_run(h, r3)\n```\n\nI get the error both on version '0.9.0' and on a yesterday's GitHub snapshot.\n", "comments": ["Please ask questions like this on StackOverflow.  In this case, the problem is caused by feeding the same placeholder twice, as the error message indicates.\n"]}, {"number": 3731, "title": "0.10.0rc0: tf.pack uses the wrong negative axis", "body": "When supplied a negative axis, tf.pack() actually operates on `(axis - 1)`. For example, providing `axis=-1` operates on the second-to-last axis, not the last axis.\n\nThis code illustrates the issue:\n\n``` python\nimport tensorflow as tf\nimport numpy as np\n\n#10 tensors with shape 2, 3, 4, 5\nx = [tf.convert_to_tensor(np.zeros((2, 3, 4, 5)))] * 10\n\n# pack along last axis explicitly\ntf.pack(x, 4).get_shape().as_list() # [2, 3, 4, 5, 10]\n\n# pack along last axis with negative axis, doesn't work\ntf.pack(x, -1).get_shape().as_list() # [2, 3, 4, 10, 5]\n\n# this doesn't match the behavior of unpack(), so packing/unpacking \n# along the same negative axis fails\nlen(tf.unpack(tf.pack(x, axis=-1), axis=-1)) == 10 # False\n\n```\n### Environment info\n\nOperating System: \nmacOS 10.11\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`): \nN/A\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\n   https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.10.0rc0-py3-none-any.whl\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n   0.10.0rc0\n", "comments": ["This looks like a bug in shape inference, actually.  What happens if you evaluate the tensors?\n", "@girving Yep, I think you're right:\n\n``` python\nIn [163]: tf.pack(x, 4).eval().shape\nOut[163]: (2, 3, 4, 5, 10)\n\nIn [164]: tf.pack(x, -1).eval().shape\nOut[164]: (2, 3, 4, 5, 10)\n\nIn [165]: tf.pack(x, -1)\nOut[165]: <tf.Tensor 'pack_105:0' shape=(2, 3, 4, 10, 5) dtype=float64>\n```\n\nAnd indeed, trying to `eval` the first result from the pack/unpack combination at the end of my snippet raises a shape mismatch  error.\n", "Shape inference there\nhttps://github.com/tensorflow/tensorflow/blob/2a10e469d70827ede21c0bb5d0a46aac97404d4c/tensorflow/python/ops/array_ops.py#L772\ndoesn't have special logic for negative axis\ninput_shape.insert(op.get_attr(\"axis\"), len(op.inputs))\n\nSo if axis is \"-1\", it just does \"shapelist.insert(-1, stuff)\"\nIt should probably mirror the logic from the C++ implementation\nGetAxisForPackAndUnpack\nhttps://github.com/tensorflow/tensorflow/blob/2a10e469d70827ede21c0bb5d0a46aac97404d4c/tensorflow/core/ops/array_ops.cc#L30\n\nOn Wed, Aug 10, 2016 at 12:19 PM, Jeremiah Lowin notifications@github.com\nwrote:\n\n> @girving https://github.com/girving Yep, I think you're right:\n> \n> In [163]: tf.pack(x, 4).eval().shape\n> Out[163]: (2, 3, 4, 5, 10)\n> \n> In [164]: tf.pack(x, -1).eval().shape\n> Out[164]: (2, 3, 4, 5, 10)\n> \n> In [165]: tf.pack(x, -1)\n> Out[165]: <tf.Tensor 'pack_105:0' shape=(2, 3, 4, 10, 5) dtype=float64>\n> \n> And indeed, trying to eval the unpack/pack combination at the end of my\n> snippet raises a shape mismatch error.\n> \n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3731#issuecomment-238974490,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AABaHJt2-3N-yWkNjx9a7qr_LRmkQV4Yks5qeiQygaJpZM4JhRBe\n> .\n", "I'm in the process of locating the Github account of the axis attr's author.\n\nOn the other hand, @cwhipkey: Are we far enough along that Python shape inference routines can go away?\n", "On Wed, Aug 10, 2016 at 1:12 PM, Geoffrey Irving notifications@github.com\nwrote:\n\n> I'm in the process of locating the Github account of the axis attr's\n> author.\n> \n> On the other hand, @cwhipkey https://github.com/cwhipkey: Are we far\n> enough along that Python shape inference routines can go away?\n\nI think we are still several weeks away from removing the python shape\ninference ones.\n\n(@vrv fyi)\n\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3731#issuecomment-238988438,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AQw4wby3EsDCcv9qgvIfMsLkmKp-g7wFks5qejCYgaJpZM4JhRBe\n> .\n", "Looks like the author is on vacation, so I'll fix it.\n", "Fixed internally, should push out soon.\n", "@jlowin Thank you for reporting!\n", "@girving thanks for fixing!\n"]}, {"number": 3730, "title": "tf.round != np.round", "body": "Looks like tensorflow and numpy use different tie-breaking rules:\n\n```\ntf.round(0.5) => 1\nnp.round(0.5) => 0\n```\n\nBoth are sound, so actually there's no bug, however since tf and np are tightly coupled is worth considering to uniform them or at least to explictly mention it in the doc.\nEspecially because np is often used as ground truth for tf tests.\n### Environment info\n- Operating System: Mac OS X\n- TensorFlow: 0.10.0rc0 \n- https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.10.0rc0-py2-none-any.whl\n### Steps to reproduce\n\n```\nimport tensorflow as tf\nimport numpy as np\n\nwith tf.Session() as S:\n    tf_round = S.run(tf.round(0.5))\n\nnp_round = np.round(0.5)\n\nprint \"round(0.5) => tf: {:.2f}\\t np:{:.2}\".format(tf_round, np_round)\n\nassert np_round == tf_round\n```\n", "comments": ["@martinwicke What's the status of native round?  We currently just use `floor`.\n", "Never reinstated it. We should.\nOn Wed, Aug 10, 2016 at 09:23 Geoffrey Irving notifications@github.com\nwrote:\n\n> @martinwicke https://github.com/martinwicke What's the status of native\n> round? We currently just use floor.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3730#issuecomment-238921203,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AAjO_UFL86WZW6cyRj0_ry_jBaGE34CRks5qefrsgaJpZM4JhOP5\n> .\n", "on tensorflow the function rounds the value to the nearest integer, wherein numpy specify the decimal to return the ground truth.  print np.round(0.5, decimals=1)\n\ne.g,\n\n> > > import tensorflow as tf\n> > > import numpy as np\n> > > with tf.Session() as S:\n> > > ...     tf_round = S.run(tf.round(1.5))\n> > > ... \n> > > np_round = np.round(1.5,1)\n> > > \n> > > print \"round(1.5) => tf: {:.2f}\\t np:{:.2}\".format(tf_round, np_round)\n> > > round(1.5) => tf: 2.00   np:1.5\n", "@apmanikandan The decimals monstrosity is unfortunate but unrelated to the current discussion; @m-colombo's concern is with tie breaking behavior.\n", "NumPy seems to be using an unusual rounding mode by default called _Round half to even_. See https://en.wikipedia.org/wiki/Rounding#Tie-breaking \n\nTensorFlow uses the same standard rounding as all other scientific tools I have available (Octave, Silverfrost Fortran and Gnu Fortran) called _Round half away from zero_\n\nEdit: No _tests_ should ever use `round` due to the 6 or so different ways to do it. Use `floor` or `ceil` (round to -inf and +inf) which offers no ambiguity.\n", "Even if unusual it's the default mode in IEEE754, while _Round half away from zero_ is the optional one added in IEEE754-2008. I tried R and Matlab, the first use _Round half to even_ while Matlab _Round half away from zero_ .\nMore over I did a brief search on low level rounding operation support and both [Cuda](http://docs.nvidia.com/cuda/parallel-thread-execution/index.html#rounding-modifiers) and [Intel architectures](http://www.intel.com/content/www/us/en/architecture-and-technology/64-ia-32-architectures-software-developer-manual-325462.html) (pg.104) do not natively support _Round half away from zero_ \n\nWondering why so many scientific tools adopted that mode, which before 2008 wasn't even standard.\n", "If someone wants to reinstate #1288, I'd be very excited.\n", "@martinwicke seems the rint operator was merged and then unmerged? you want a rebased PR of that PR? \n", "That would be great. Last time we had to revert because it failed some\npostsubmits and I never got around to fixing it. The root cause was\nsomeplace else and fixed I believe so this should work now.\nOn Sun, Aug 28, 2016 at 12:01 Fabrizio Milo notifications@github.com\nwrote:\n\n> @martinwicke https://github.com/martinwicke seems the rint operator was\n> merged and then unmerged? you want a rebased PR of that PR?\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> \n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3730#issuecomment-242992567,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AAjO_R9R05P_BpKGHqEZb801ab2rCKsiks5qkdsngaJpZM4JhOP5\n> .\n", "@martinwicke I took a look at this and updated to work for float32 and float64. But seems that the `round` operation for Eigen::half is not supported on Eigen. I think is a simple declaration of the round function, but how to proceed? Wait for Eigen? commit only the float32 and float64 version?\n", "I think we should commit the float 32 and 64 version and we'll try to get the declaration into Eigen as soon as we can and then update tensorflow. \n", "@martinwicke see #4113 \n", "Andrew, assigning to you to eventually close once all the new code is in.\n", "We have implemented fast vectorized rounding in Eigen equivalent to std::round's round-half-away from zero. I wish we could make it the default. ", "Is there a reason we cannot make it the default?\r\n\r\nI think this is a bug. @tensorflow/api-owners ", "It is a bug. I'm all for making it the default if we can agree on that.", "Context: https://gitlab.com/libeigen/eigen/commit/06e99aaf409eff4693c4256e59bb58313052818d", "As @aselle points out, round-to-even is used in numpy.ndrray.round, so perhaps we should keep it this way. We should provide a fast implementation of that however.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/3730\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/3730\">No</a>\n"]}, {"number": 3729, "title": "[started] convert to records example in tutorial?", "body": "As far as i know, the started document only provide a example with mnist example, however, really confused about how tensorflow handle an sparse example.\nwhen it comes to linear model, the libsvm format always be a popular format in research and industry. But how to convert libsvm format entries to tensorflow records? How will an entry represent in tensorflow? in column ways or in row ways?\n\ne.g.\n\n```\nlabel, key:value, key:value, ....\n\n```\n\nwhereas the key is index, value is the feature value in sparse format. \nCan anyone kindly to add such an example to tutorial ? Thanks\n", "comments": ["I think these questions would be better on StackOverflow.  You're welcome to submit a tutorial yourself, but otherwise I'll close this issue for now, since Github issues are more for code bugs and feature requests.\n", "@dzhwinter \nThis is an self contained example of parsing libsvm format\nWrite to tf record and read and train using mlp classifier.\nhttps://github.com/chenghuige/tensorflow-exp/tree/master/examples/tf-record/sparse\nhttps://github.com/chenghuige/tensorflow-exp/tree/master/examples/sparse-tensor-classification\n", "@chenghuige \r\nhttps://github.com/chenghuige/tensorflow-exp/tree/master/examples/tf-record/sparse  404 error\r\nwhat's happen?"]}, {"number": 3728, "title": "contrib.learn.DNNRegressor not compatible for e.g. GridSearchCV", "body": "Imho the new architecture of contrib.learn.DNNRegressor (compared to the old contrib.learn.TensorflowDNNRegressor) makes it impossible to properly use things like GridSearchCV from sklearn. To use GridSearchCV I have to pass all parameters to be tuned to the constructor. In the new architecture of DNNRegressor some parameters are passed to the fit-method which is quite untypical for sklearns architecture usually expecting only X and y as parameters of the fit-method. For example I can no longer tune steps and batch_size (now part of the fit-method) with GridSearchCV. I can only pass them as fixed fit_params. Or am I getting something wrong?\n", "comments": ["@ilblackdragon Can you comment?\n", "You can see the same issue detailed at http://stackoverflow.com/questions/38968249/cannot-run-tflearn-with-sklearns-gridsearchcv\n", "Looks like this was answered on stackoverflow."]}, {"number": 3727, "title": "distributed seq2seq: too much device placement logs", "body": "I'm trying the distributed seq2seq model. But when I run the program, there are too much device placement logs. Just like this below:\n\n```\nsync_replicas/fifo_queue_4_enqueue/component_0: /job:ps/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] sync_replicas/fifo_queue_4_enqueue/component_0: /job:ps/replica:0/task:0/cpu:0\nsync_replicas/fifo_queue_2_enqueue/component_0: /job:ps/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] sync_replicas/fifo_queue_2_enqueue/component_0: /job:ps/replica:0/task:0/cpu:0\nScatterUpdate_3/indices: /job:ps/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] ScatterUpdate_3/indices: /job:ps/replica:0/task:0/cpu:0\nScatterUpdate_2/indices: /job:ps/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] ScatterUpdate_2/indices: /job:ps/replica:0/task:0/cpu:0\nScatterUpdate_1/indices: /job:ps/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] ScatterUpdate_1/indices: /job:ps/replica:0/task:0/cpu:0\nScatterUpdate/indices: /job:ps/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] ScatterUpdate/indices: /job:ps/replica:0/task:0/cpu:0\nVariable_1/initial_value: /job:ps/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] Variable_1/initial_value: /job:ps/replica:0/task:0/cpu:0\nmul/y: /job:worker/replica:0/task:1/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] mul/y: /job:worker/replica:0/task:1/gpu:0\nGradientDescent_3/value: /job:ps/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] GradientDescent_3/value: /job:ps/replica:0/task:0/cpu:0\nFill_3/dims: /job:ps/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] Fill_3/dims: /job:ps/replica:0/task:0/gpu:0\nGradientDescent_2/value: /job:ps/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] GradientDescent_2/value: /job:ps/replica:0/task:0/cpu:0\nFill_2/dims: /job:ps/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] Fill_2/dims: /job:ps/replica:0/task:0/gpu:0\nGradientDescent_1/value: /job:ps/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] GradientDescent_1/value: /job:ps/replica:0/task:0/cpu:0\nFill_1/dims: /job:ps/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] Fill_1/dims: /job:ps/replica:0/task:0/gpu:0\nGradientDescent/value: /job:ps/replica:0/task:0/cpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] GradientDescent/value: /job:ps/replica:0/task:0/cpu:0\nFill/dims: /job:ps/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] Fill/dims: /job:ps/replica:0/task:0/gpu:0\nVariable/initial_value: /job:ps/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:818] Variable/initial_value: /job:ps/replica:0/task:0/gpu:0\n```\n\nWhile when I run the original seq2seq model in single machine, I don't have the problem. I locate the `simple_placer.cc:818`, finding they are really log ouputs. \n## Why does it output in the distributed model?\n\nsimple_placer.cc\n\n```\nvoid SimplePlacer::AssignAndLog(const string& assigned_device,\n                                Node* node) const {\n  node->set_assigned_device_name(assigned_device);\n  // Log placement if log_device_placement is set.\n  if (options_ && options_->config.log_device_placement()) {\n    printf(\"%s: %s\\n\", node->name().c_str(),\n           node->assigned_device_name().c_str());\n    LOG(INFO) << node->name() << \": \" << node->assigned_device_name();\n  }\n}\n```\n", "comments": ["What is the bug here?  The logs can be turned off by setting `log_device_placement=false` in the config.\n", "@girving thx, it works. But it's still hanging on the `sess.run()` . As the [issue](https://github.com/tensorflow/tensorflow/issues/3705)\n", "@DjangoPeng Did you fixed the sess.run hang problem? I also get this problem\n"]}, {"number": 3726, "title": "nested scan functions break in gradient calculation, bug?", "body": "I tried to produce some code to read out the values at multiple locations from a vector of results. To do this I used two nested scan functions to go through the batches and the vector of the multiple locations. \nThis function correctly calculates the values when used alone, but when I want to calculate gradients, the code breaks at initialisation of the variables in the session with a error message I do not feel responsible for.\n## Environment info\n\nOperating System: iOS 10.11.5 \n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n-rwxr-xr-x  1 root  wheel  8280 Aug  9 18:11 /usr/local/cuda/lib/libcuda.1.dylib\n-rwxr-xr-x  1 root  wheel  8280 Apr 13 08:02 /usr/local/cuda/lib/libcuda.dylib\nlrwxr-xr-x  1 root  wheel    45 Apr 13 08:03 /usr/local/cuda/lib/libcudadevrt.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudadevrt.a\nlrwxr-xr-x  1 root  wheel    50 Apr 13 08:03 /usr/local/cuda/lib/libcudart.7.5.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.7.5.dylib\nlrwxr-xr-x  1 root  wheel    46 Apr 13 08:03 /usr/local/cuda/lib/libcudart.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.dylib\nlrwxr-xr-x  1 root  wheel    49 Apr 13 08:03 /usr/local/cuda/lib/libcudart_static.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart_static.a\nlrwxr-xr-x  1 root  wheel    47 Aug  9 18:38 /usr/local/cuda/lib/libcudnn.5.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudnn.5.dylib\nlrwxr-xr-x  1 root  wheel    45 Aug  9 18:38 /usr/local/cuda/lib/libcudnn.dylib -> /Developer/NVIDIA/CUDA-7.5/lib/libcudnn.dylib\nlrwxr-xr-x  1 root  wheel    48 Aug  9 18:38 /usr/local/cuda/lib/libcudnn_static.a -> /Developer/NVIDIA/CUDA-7.5/lib/libcudnn_static.a\n\nIf installed from source, provide \n1. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n   '0.10.0rc0'\n2. The commit hash (`git rev-parse HEAD`)\n   056db850614e0a06ce6f65b30f877c5789ab74f5\n3. The output of `bazel version`\n   Build label: 0.3.1-homebrew\n   Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\n   Build time: Thu Aug 4 09:58:27 2016 (1470304707)\n   Build timestamp: 1470304707\n   Build timestamp as int: 1470304707\n## Steps to reproduce\n1. run code \n\n```\nimport tensorflow as tf\nimport numpy \n\ndef saliency_loss(y_true, y_pred):\n    def saliency_loss_1(oldL,y):\n        select = tf.slice(tf.squeeze(y),[5],[-1])\n        def subindex(old,select1):\n            return tf.slice(y,tf.reshape(tf.cast(select1,dtype='int32'),(1,)),tf.reshape(tf.constant(1),(1,))) \n        prob = tf.scan(subindex,select,initializer = tf.reshape(tf.constant(0.0),(1,)))\n        return -tf.reshape(tf.reduce_sum(tf.log(prob)),(1,))\n    y = tf.concat(1,(y_pred,y_true),name = 'y')\n    L = tf.scan(saliency_loss_1,y,initializer = tf.reshape(tf.constant(0.0),(1,)))\n    return tf.reduce_mean(L)\n\ny_true = tf.Variable([[0.0,0.0,0.0],[1.0,4.0,1.0],[0.0,0.0,0.0],[1.0,4.0,1.0]])\ny_pred = tf.Variable([[1.0,2.0,3.0,4.0,5.0],[11.0,12.0,13.0,14.0,15.0],[1.0,2.0,3.0,4.0,5.0],[11.0,12.0,13.0,14.0,15.0]])\ny = tf.concat(1,(y_pred,y_true),name = 'y')\nprint(-(numpy.log(12.0)+numpy.log(15.0)+numpy.log(12.0))/2.0)\n\n\nwith tf.Session() as sess:\n    sess.run(tf.initialize_all_variables())\n    print(sess.run(saliency_loss(y_true, y_pred)))\n\nloss = saliency_loss(y_true, y_pred)\ngrad = tf.gradients(loss,y_pred)\n\nprint(grad)\n\nwith tf.Session() as sess:\n    sess.run(tf.initialize_all_variables())\n    #print(sess.run(grad))\n\n```\n## What have you tried?\n1. all orders of initialisation and running only gradient calculation\n## Logs or other output that would be helpful\n### Errortrace:\n\n---\n\nInvalidArgumentError                      Traceback (most recent call last)\n/Users/heiko/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, _args)\n    964     try:\n--> 965       return fn(_args)\n    966     except errors.OpError as e:\n\n/Users/heiko/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run_fn(session, feed_dict, fetch_list, target_list, options, run_metadata)\n    946                                  feed_dict, fetch_list, target_list,\n--> 947                                  status, run_metadata)\n    948 \n\n/Users/heiko/anaconda/lib/python3.5/contextlib.py in **exit**(self, type, value, traceback)\n     65             try:\n---> 66                 next(self.gen)\n     67             except StopIteration:\n\n/Users/heiko/anaconda/lib/python3.5/site-packages/tensorflow/python/framework/errors.py in raise_exception_on_not_ok_status()\n    449           compat.as_text(pywrap_tensorflow.TF_Message(status)),\n--> 450           pywrap_tensorflow.TF_GetCode(status))\n    451   finally:\n\nInvalidArgumentError: Input 0 of node gradients/scan_1/while/scan/TensorArrayPack_grad/TensorArrayGrad/TensorArrayGrad was passed string from gradients/scan_1/while/scan/TensorArrayPack_grad/TensorArrayGrad/TensorArrayGrad/StackPop:0 incompatible with expected string_ref.\n\nDuring handling of the above exception, another exception occurred:\n\nInvalidArgumentError                      Traceback (most recent call last)\n<ipython-input-1-d5cce368f52a> in <module>()\n     29 \n     30 with tf.Session() as sess:\n---> 31     sess.run(tf.initialize_all_variables())\n     32     #print(sess.run(grad))\n\n/Users/heiko/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py in run(self, fetches, feed_dict, options, run_metadata)\n    708     try:\n    709       result = self._run(None, fetches, feed_dict, options_ptr,\n--> 710                          run_metadata_ptr)\n    711       if run_metadata:\n    712         proto_data = tf_session.TF_GetBuffer(run_metadata_ptr)\n\n/Users/heiko/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py in _run(self, handle, fetches, feed_dict, options, run_metadata)\n    906     if final_fetches or final_targets:\n    907       results = self._do_run(handle, final_targets, final_fetches,\n--> 908                              feed_dict_string, options, run_metadata)\n    909     else:\n    910       results = []\n\n/Users/heiko/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_run(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\n    956     if handle is None:\n    957       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n--> 958                            target_list, options, run_metadata)\n    959     else:\n    960       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n\n/Users/heiko/anaconda/lib/python3.5/site-packages/tensorflow/python/client/session.py in _do_call(self, fn, *args)\n    976         except KeyError:\n    977           pass\n--> 978       raise type(e)(node_def, op, message)\n    979 \n    980   def _extend_graph(self):\n\nInvalidArgumentError: Input 0 of node gradients/scan_1/while/scan/TensorArrayPack_grad/TensorArrayGrad/TensorArrayGrad was passed string from gradients/scan_1/while/scan/TensorArrayPack_grad/TensorArrayGrad/TensorArrayGrad/StackPop:0 incompatible with expected string_ref.\n", "comments": ["@ebrevdo Should this be fixed after https://github.com/tensorflow/tensorflow/issues/593?\n", "Though it's not a related error, yuan is pushing the fix for this approximately on Monday.\n", "This has already been fixed, so wait for the next push.  The problem is that we need to use non-ref for the handle input of TensorArrayGrad op.\n", "Well, the ref handle fix doesn't fix the problem completely. I think we are back to the problem with nested scan (#593). \n", "A possible fix should be available in the next push.\n", "I still have this issue in r0.11.\n\nI have a nested scan, and [line 197 in control_flow_grad.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/control_flow_grad.py#L197):\n\n'''grad_ctxt = graph._get_control_flow_context()'''\n\nresults in a None value for grad_ctxt.\n", "Does the problem still presist with latest versions?", "Closing due to lack of response.  Please reopen if necessary."]}, {"number": 3725, "title": "FTRL implementation in tensorflow V.S. FTRL in Google's research paper", "body": "Hello, every one! \n\nI am interested in digging the details how FTRL is implemented in tensorflow. I find some information in the file \"gen_training_ops.py\" in the folder /tensorflow/python/training. In this file, the formula of FTRL algorithm is described as follows:\n\n```\ndef apply_ftrl(var, accum, linear, grad, lr, l1, l2, lr_power,\nuse_locking=None, name=None):\nr\"\"\"Update '*var' according to the Ftrl-proximal scheme\naccum_new = accum + grad * grad      ------ (1)\nlinear += grad + (accum_new^(-lr_power) - accum^(-lr_power)) / lr * var        ------ (2)\nquadratic = 1.0 / (accum_new^(lr_power) * lr) + 2 * l2              ------ (3)\nvar = (sign(linear) * l1 - linear) / quadratic if |linear| > l1 else 0.0           ------(4)\naccum = accum_new        ------(5)\n```\n\nI am also reading the paper \"Ad Click Prediction: a View from the Trenches\" by Google in KDD'13. The formula of FTRL algorithm is given in page 2 of this paper. Comparing this two implementations, we find some connections:\nvar is w_{t,i} in the paper; l1 is lambda1 in the paper; linear is zi in the paper; lr is alpha in the paper; grad is gi in the paper; accum is ni in the paper.\n\nBut also, there are some inconsistent points:\naccording to the paper, the Equation (2) above should be \n`linear += grad - (accum_new^(-lr_power) - accum^(-lr_power)) / lr * var`\nalso we can get the following equation by comparing the two implementations:\n`2l2  *alpha = beta + alpha * lambda2`\n\nFor any expert who is familiar with the FTRL implementation in the tensorflow, can you help us to clarify the meaning the parameters given in tensorflow, and the connections with the FTRL code in Google's research paper \"Ad Click Prediction: a View from the Trenches\".\n\nThanks!\n", "comments": ["Unless you think there is a bug, this question would be better asked on StackOverflow.  Github issues are for code bugs and feature requests, not requests for clarification.\n", "I think there is a bug in it.\n", "The FTRL implementation in Tensorflow was exactly coming from that paper. I think the meaning of parameters is quite consistent with the notation in the paper. Where do you think the bug is?\n", "Hi, will001:\n\nThanks for your attention!\n\nTo our understanding, we can establish the following connections:\nvar is w_{t,i} in the paper; l1 is lambda1 in the paper; linear is zi in the paper; lr is alpha in the paper; grad is gi in the paper; accum is ni in the paper.\n\nHowever, we found that  the notation \"beta\" is the paper is missing from the Tensorflow implementation.\n\nFurthermore, we guess that l2 is lambda2 in the paper, however, we are not able to get this conclusion by comparing the two implementations. Instead, we can only get this equation: \n2l2 *alpha = beta + alpha \\* lambda2\n\nCan you clarify these two points a little bit?\n\nThanks again.\n", "I have same confusion. It seems that the optimizer force `beta = l2 * alpha`.\nIs there any reason behind that ?\n", "I do have the same question with @yanyachen \n", "Although the documentation points to the right paper, it was unclear to me (until I dug into the code) whether the TensorFlow class implemented Nesterov's dual averaging (ie. FTRL) or the FTRL-Proximal variant proposed in the Ad Click Prediction paper.\n\nIt would be good to clarify this in the documentation, along with the meaning of the hyperparameters. Thanks!\n", "Thanks tangruiming@ for pointing out, the comments 2) in get_training_ops.py is not accurate, which should be:\nlinear += grad - (accum_new^(-lr_power) - accum^(-lr_power)) / lr \\* var.\nI will fix this very soon.\n\nFor the missing parameter 'beta' in the implementation, which actually comes from the initial_accumulator_value for the 'accum', where accum = initial_accumulator_value + sigma{g(i)^2}. So, you can think of it as  _beta + sqrt(n^i)_ == sqrt((initial_accumulator_value + sigma(g(i)^2))). \n\nTo ageron@, the implementation in Tensorflow as FTRL-Proximal, proposed in the Ad Click Prediction paper.\n", "Hi, will001@:\n\nThank you very much for your clarification. \n\nI found another place in the comments in the get_training_ops.py  that may be wrong:\n`quadratic = 1.0 / (accum_new^(lr_power) * lr) + 2 * l2              ------ (3)`\nI think it should be \n`quadratic = 1.0 / (accum_new^(lr_power) * lr) + l2              ------ (3)`\nAm I right?\n\nSecondly, I want to confirm sth about \"beta\":\nI can have the similar equation as you stated:\nbeta + sqrt(n_i) = sqrt(accum_new) = sqrt(initial_accumulator_value + sigma(g(i)^2)).\n**Approximately**, we can have beta + sqrt(n_i)  = sqrt(beta + n_i), so based on these two equations, it can be concluded that beta is approximately the same as initial_accumulator_value. Am I right?\n\nThanks again.\n\nRuiming\n", "To tangruiming@, you are right. Thanks for pointing it out.\n", "To will001, thank you very much. My doubts are clear. \n", "by the way, where is the bias of logistic regression?", "Closing after reading latest comment from @tangruiming.", "@will001 , seems points (2) and (3) @tangruiming mentioned aren't fixed yet.", "hey, sorry to dig the old issue, but go into the implementation, still have some question here.\r\n\r\ntensorflow/core/kernel/training_ops.cc\r\n\r\nclass SparseApplyFtrlOp\r\n```\r\n          T updated_a = a + g * g;\r\n          using Eigen::numext::pow;\r\n          T sigma = pow(updated_a, -lr_power_scalar) - pow(a, -lr_power_scalar);\r\n          sigma /= lr_scalar;\r\n          T updated_l = l + g - sigma * v;\r\n          v = FtrlCompute(updated_a, updated_l, lr_scalar, l1_scalar, l2_scalar,\r\n                          lr_power_scalar);\r\n          a = updated_a;\r\n          l = updated_l;\r\n```\r\na/updated_a  -> n\r\nl/updated_l    ->  z\r\nv                    ->  w\r\nlr_scalar        ->  alpha\r\nl1_scalar        ->  lambda1\r\nl2_scalar       ->  lambda2\r\n\r\n\r\nFtrlCompute\r\n```\r\ntemplate <typename T>\r\ninline T FtrlCompute(const T& accum, const T& linear, const T& lr, const T& l1,\r\n                     const T& l2, const T& lr_power) {\r\n  T quadratic;\r\n  if (lr_power == static_cast<T>(-0.5)) {\r\n    quadratic = Eigen::numext::sqrt(accum) / lr + static_cast<T>(2) * l2;\r\n  } else {\r\n    quadratic =\r\n        Eigen::numext::pow(accum, -lr_power) / lr + static_cast<T>(2) * l2;\r\n  }\r\n  if (Eigen::numext::abs(linear) > l1) {\r\n    return (l1 * sgn(linear) - linear) / quadratic;\r\n  } else {\r\n    return static_cast<T>(0.0);\r\n  }\r\n}\r\n```\r\nlinear        ->   z\r\nl1               ->   lambda1\r\nl2              ->   lambda2\r\nlr               ->   alpha\r\naccum      ->   n\r\n\r\nso , the problem is here\r\n```\r\nquadratic = Eigen::numext::sqrt(accum) / lr + static_cast<T>(2) * l2;\r\n```\r\nwhy there is `a static_cast<T>(2)`?  according paper, it is only lambda2.\r\n", "@ydp still in this SparseApplyFtrlOp I cannot find where the var is set to zero if var = (sign(linear) * l1 - linear) / quadratic if |linear| <= l1 , so where is the sparse solution", "I agree. Seems like an issue we should fix.", "@tanzhenyu @will001 \r\nHas this bug been fixed? I see that the comment has not changed."]}, {"number": 3724, "title": "Source-compiled .whl package is much slower in training", "body": "Recently, from my experiment, I found that running inception model using the .whl file generated by myself is much slower than using .whl file downloaded directly from the $TF_BINARY_URL.\n### Environment info\n\nOperating System: ubuntu14.04\nCUDA: cuda7.5\nCUDNN: cudnn 5\n\nI followed the instructions\n./configure\nbazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\nbazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\nAnd I got tensorflow-0.9.0-py2-none-any.whl to install using:\npip install /home/dl/bxl/tensorflow/tensorflow_pkg/tensorflow-0.9.0-py2-none-any.whl\n (the name of this .whl file is automatically generated )\n\nThen I downloaded the inception model related files to train following the instructions:\ncd ~/models/inception\nbazel build inception/imagenet_train\nbazel-bin/inception/imagenet_train --num_gpus=1 --batch_size=64 --train_dir=/tmp/imagenet_train --data_dir=/data1/ImageNet\n\nFrom the information printed out, I found that the speed is 8.5 samples/sec. (In the first several lines printed out, it says\uff1a\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.7.5 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.7.5 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.7.5 locally,\nfrom which I guess CUDA/CuDNN are automatically loaded)\n\nHowever, if I replace the .whl file by that directly downloaded from the $TF_BINARY_URL provided in www.tensorflow.org ( tensorflow-0.9.0-cp27-none-linux_x86_64.whl, which uses CuDNN4 and cuda7.5), and reinstall it using pip, and restart a new process to train the inception model using the same code. \n\nI got that the training speed was 20.2 samples/sec, which is nearly 2.5x faster than my first training using the .whl package generated by myself. \n\nSo it is very difficult to explain. Because I use CUDNN5, I expect my version is faster, but in fact, it is 2.5x slower....\n\nDoes anyone know why??\n\nThanks in advance.\n", "comments": ["To expand on Yaroslav's comment: you need to give options to bazel every time you run it.  If you run it twice with different options, it will discard anything built with the older options.\n", "I have tried this:\ncd ~/models/inception\nbazel build -c opt inception/imagenet_train\nbazel-bin/inception/imagenet_train --num_gpus=1 --batch_size=64 --train_dir=/tmp/imagenet_train --data_dir=/data1/ImageNet\n\nUnfortunately, the performance is still the same as my previous results.\n", "It seems that it is not the problem of \"bazel build -c opt inception/imagenet_train\", because I use the same build option with self-complied .whl package and the downloaded one. \n", "Some debugging ideas:\n1. Use strace to see which \"_pywrap_tensorflow.so\" each run is opening, and\n   check that their sizes are similar\n2. Configure built-from-source version with CuDNN version 4.0 and see how\n   fast it is\n3. Look at how the version is built in the \"pip.sh\" script\n   https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/ci_build/builds/pip.sh\n\nOn Wed, Aug 10, 2016 at 6:25 PM, gclouding notifications@github.com wrote:\n\n> It seems that it is not the problem of \"bazel build -c opt\n> inception/imagenet_train\", because I use the same build option with\n> self-complied .whl package and the downloaded one.\n> \n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3724#issuecomment-239052018,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AABaHKrn-szPHLP7vy62etSZBl6gGaTEks5qenn_gaJpZM4Jg4cH\n> .\n", "This is a known bug. #3603\n"]}, {"number": 3723, "title": "_pywrap_tensorflow module not found on OS X 10.11.6 after compiling and building a package", "body": "I compiled tensorflow from the source with CUDA support. After installing the wheel I was greeted with an error(listed below). The compilation without CUDA support is successful.\n\nI cant figure out what the problem is.\n\n**All of this was done in a Virtualenv Python version: 2.7.12**\n### Environment info\n\nOperating System:\nMac OS X(10.11.6)\nInstalled version of CUDA and cuDNN: \n`-rwxr-xr-x  1 root  wheel   8.1K Jun 10 01:58 /usr/local/cuda/lib/libcuda.dylib*\nlrwxr-xr-x  1 root  wheel    45B Sep 25  2015 /usr/local/cuda/lib/libcudadevrt.a@ -> /Developer/NVIDIA/CUDA-7.5/lib/libcudadevrt.a\nlrwxr-xr-x  1 root  wheel    50B Sep 25  2015 /usr/local/cuda/lib/libcudart.7.5.dylib@ -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.7.5.dylib\nlrwxr-xr-x  1 root  wheel    46B Sep 25  2015 /usr/local/cuda/lib/libcudart.dylib@ -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart.dylib\nlrwxr-xr-x  1 root  wheel    49B Sep 25  2015 /usr/local/cuda/lib/libcudart_static.a@ -> /Developer/NVIDIA/CUDA-7.5/lib/libcudart_static.a\nlrwxr-xr-x  1 root  wheel    47B Aug  9 21:51 /usr/local/cuda/lib/libcudnn.5.dylib@ -> /Developer/NVIDIA/CUDA-7.5/lib/libcudnn.5.dylib\nlrwxr-xr-x  1 root  wheel    45B Aug  9 21:51 /usr/local/cuda/lib/libcudnn.dylib@ -> /Developer/NVIDIA/CUDA-7.5/lib/libcudnn.dylib\nlrwxr-xr-x  1 root  wheel    48B Aug  9 21:51 /usr/local/cuda/lib/libcudnn_static.a@ -> /Developer/NVIDIA/CUDA-7.5/lib/libcudnn_static.a`\n\nIf installed from source, provide \n1. 32bd3d024f33e920a67a1081bc0ae0048350fdee\n2. The output of `bazel version`:\n   `Build label: 0.3.1-homebrew\n   Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\n   Build time: Thu Aug 4 09:58:27 2016 (1470304707)\n   Build timestamp: 1470304707\n   Build timestamp as int: 1470304707`\n### Steps to reproduce\n1. Configure with CUDA v7.5 and Cudnn v5.1 \n2. Compile with CUDA support enabled.\n3. Build pip package and then install.\n### What have you tried?\n1. Tried installing the binary, but I was then greeted with a different error. \n### Logs or other output that would be helpful\n\n`Traceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/Users/ojas/.pyenv/versions/ve2/lib/python2.7/site-packages/tensorflow/__init__.py\", line 23, in <module>\n    from tensorflow.python import *\n  File \"/Users/ojas/.pyenv/versions/ve2/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 48, in <module>\n    from tensorflow.python import pywrap_tensorflow\n  File \"/Users/ojas/.pyenv/versions/ve2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 21, in <module>\n    _pywrap_tensorflow = swig_import_helper()\n  File \"/Users/ojas/.pyenv/versions/ve2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 20, in swig_import_helper\n    return importlib.import_module('_pywrap_tensorflow')\n  File \"/Users/ojas/.pyenv/versions/2.7.12/Python.framework/Versions/2.7/lib/python2.7/importlib/__init__.py\", line 37, in import_module\n    __import__(name)\nImportError: No module named _pywrap_tensorflow`\n", "comments": ["Can you try in a different shell? I hit this error when I am using bash. But, with fish shell I get a SEGMENTATION FAULT on Python. \n\nI had not set some paths on the SHELL. CUDA_HOME, DYLD_LIBRARY_PATH. I set those and now I am getting a SEGFAULT. \n", "Tried that. Still the same error.\n\nAnother thing I did was installed the TF binary with GPU support. Tried importing in a different shell(fish).\nGot this error:\n\n```\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/Users/ojas/.pyenv/versions/ve2/lib/python2.7/site-packages/tensorflow/__init__.py\", line 23, in <module>\n    from tensorflow.python import *\n  File \"/Users/ojas/.pyenv/versions/ve2/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 48, in <module>\n    from tensorflow.python import pywrap_tensorflow\n  File \"/Users/ojas/.pyenv/versions/ve2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 28, in <module>\n    _pywrap_tensorflow = swig_import_helper()\n  File \"/Users/ojas/.pyenv/versions/ve2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)\nImportError: dlopen(/Users/ojas/.pyenv/versions/ve2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so, 10): Library not loaded: @rpath/libcudart.7.5.dylib\n  Referenced from: /Users/ojas/.pyenv/versions/ve2/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow.so\n  Reason: image not found\n```\n\n> On 10-Aug-2016, at 1:06 PM, ashvsdata notifications@github.com wrote:\n> \n> Can you try in a different shell? I hit this error when I am using bash. But, with fish shell I get a SEGMENTATION FAULT on Python\n> \n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub https://github.com/tensorflow/tensorflow/issues/3723#issuecomment-238788613, or mute the thread https://github.com/notifications/unsubscribe-auth/AKL6AXViBeO1QJwlOEmy-qUhtoWcEkA0ks5qeX-RgaJpZM4Jg1CN.\n", "The `libcudart.7.5.dylib not found` error happens when you don't set `DYLD_LIBRARY_PATH` correctly\n", "I have set that correctly.\nVerified by running deviceQuery, unless thats not the point of deviceQuery.\n\n> On 10-Aug-2016, at 9:59 PM, Yaroslav Bulatov notifications@github.com wrote:\n> \n> The libcudart.7.5.dylib not found error happens when you don't set DYLD_LIBRARY_PATH correctly\n> \n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub https://github.com/tensorflow/tensorflow/issues/3723#issuecomment-238922621, or mute the thread https://github.com/notifications/unsubscribe-auth/AKL6AWG5ow1YkV92KMUTt6oaY3tPN1eaks5qefxwgaJpZM4Jg1CN.\n", "You could run it under `sudo dtruss` to see where it's trying to look for the `dylib`. Also, I've had to disable SIP (system integrity protection) for it to work, although that had extra `dyld: warning` messages in error log\n", "I shall try disabling SIP soon.\nhere is the exports:\n`export CUDA_HOME=/usr/local/cuda\nexport DYLD_LIBRARY_PATH=\"$DYLD_LIBRARY_PATH:$CUDA_HOME/lib:/Developer/NVIDIA/CUDA-7.5/lib\"\nexport DYLD_LIBRARY_PATH=\"$CUDA_HOME/lib:$DYLD_LIBRARY_PATH\"\nexport PATH=\"$CUDA_HOME/bin:$PATH\"\n`\n\nAlso dtruss is saying this:\n\n> dtrace: failed to execute python: dtrace cannot control executables signed with restricted entitlements\n", "Okay I did what you said @yaroslavvb. Disabled SIP, now I get this:\n`import tensorflow\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.7.5.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.5.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.7.5.dylib locally\nSegmentation fault: 11`\n", "Can you get a stack trace?\nYou should have a crash report file created in a file like below during\ncrash\n\n~/Library/Logs/DiagnosticReports/Python_2016-07-21-144526_Yaroslavs-MacBook-Pro.crash\n(Also viewable under User Diagnostic reports in Console App)\n\nAlso you get a stack trace for crashing script.py on Mac by running under\nlldb, ie\n\nlldb python\n(lldb) r script.py\n....\n(lldb) up\n...\n(lldb) up\n\nOptionally compile with \"bazel build -c dbg --config=cuda\" to get actual\nline numbers in stack trace\n\nOn Thu, Aug 11, 2016 at 2:49 AM, Ojas Shirekar notifications@github.com\nwrote:\n\n> Okay I did what you said @yaroslavvb https://github.com/yaroslavvb.\n> Disabled SIP, now I get this:\n> import tensorflow\n> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA\n> library libcublas.7.5.dylib locally\n> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA\n> library libcudnn.5.dylib locally\n> I tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA\n> library libcufft.7.5.dylib locally\n> Segmentation fault: 11\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3723#issuecomment-239117523,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AABaHFjRGTIRj4khKcTtOqawrorljwF2ks5qevAtgaJpZM4Jg1CN\n> .\n", "Have you tried importing _pywrap_tensorflow.so in python directly? That will give you a good demarcation point between what could be the problem. It often gives you a better description of the problem.\n", "I did have the same issue. I believe this is cause by `DYLD_LIBRARY_PATH` not working in OS X El Capitan due to SIP.\n\nhttps://github.com/oracle/node-oracledb/issues/231\n\nI'm looking to workaround though.\n", "@lxcid I disabled SIP now atleast the library loads and segfaults :/\n@yaroslavvb here is the trace from lldb\n`'(lldb) r test.py\nProcess 2728 launched: '/Users/ojas/.pyenv/versions/ve2/bin/python' (x86_64)\nProcess 2728 stopped\n- thread #1: tid = 0x47b7, 0x0000000100009000 dyld`_dyld_start, stop reason = exec\n  frame #0: 0x0000000100009000 dyld`_dyld_start\n  dyld`_dyld_start:\n  ->  0x100009000 <+0>: popq   %rdi\n  0x100009001 <+1>: pushq  $0x0\n  0x100009003 <+3>: movq   %rsp, %rbp\n  0x100009006 <+6>: andq   $-0x10, %rsp\n  (lldb) up\n  `\n\n@yaroslavvb I will try recompiling it with your options soon.\n", "Woooo!  Thanks for this help everyone.\r\n\r\n@ojss So I got to the same place as you.  The final thing I needed to do to do in order to get things working was to create a symbolic link: ln -sf /usr/local/cuda/lib/libcuda.dylib /usr/local/cuda/lib/libcuda.1.dylib\r\n\r\nAs referenced at the very bottom of the documentation: https://www.tensorflow.org/versions/r0.11/get_started/os_setup.html.\r\n\r\n@yaroslavvb It would be nice to add a hint suggesting that SIP might need to be disabled to the documentation - took a whole morning of poking around and reinstalling things for me to find this thread.  ", "@the13fools pretty sure I did that. Anyway I shall try it once again.", "okay I updated CUDA and Cudnn and here is the stack trace from lldb\r\n\r\n```\r\n* thread #1: tid = 0x1d1246, 0x00007fffc1ebfb52 libsystem_c.dylib`strlen + 18, queue = 'com.apple.main-thread', stop reason = EXC_BAD_ACCESS (code=1, address=0x0)\r\n    frame #0: 0x00007fffc1ebfb52 libsystem_c.dylib`strlen + 18\r\nlibsystem_c.dylib`strlen:\r\n->  0x7fffc1ebfb52 <+18>: pcmpeqb (%rdi), %xmm0\r\n    0x7fffc1ebfb56 <+22>: pmovmskb %xmm0, %esi\r\n    0x7fffc1ebfb5a <+26>: andq   $0xf, %rcx\r\n    0x7fffc1ebfb5e <+30>: orq    $-0x1, %rax\r\n```", "okay fixed it. Applied this:\r\n```\r\nexport CUDA_HOME=/usr/local/cuda\r\nexport DYLD_LIBRARY_PATH=\"$CUDA_HOME/lib:$CUDA_HOME:$CUDA_HOME/extras/CUPTI/lib\"\r\nexport LD_LIBRARY_PATH=$DYLD_LIBRARY_PATH\r\n```\r\n\r\n**instead of:**\r\n```\r\nexport CUDA_HOME=/usr/local/cuda\r\nexport DYLD_LIBRARY_PATH=\"$DYLD_LIBRARY_PATH:$CUDA_HOME/lib\"\r\nexport PATH=\"$CUDA_HOME/bin:$PATH\"\r\n```\r\nwould love an explanation for the above solution\r\nand had to do this hack in #2910\r\n", "I believe the instructions were updated to reflect this in version 1.1.\r\nWe dropped support for macOS with NVIDIA GPUs, therefore I am closing this issue."]}, {"number": 3722, "title": "Tensorflow build fails due to farmhash build failure on ppc64le", "body": "Tensorflow's external dependency named farmhash fails to build on Ubuntu 14.04 linux ppc64le. If I manually edit the config.guess of farmhash to add a case for ppc64le, then it works. So, I wanted to know how can I contribute this fix back to repo as farmhash is not git cloned by tensorflow, rather a zip archive is downloaded from [farmhash download url](https://github.com/google/farmhash/archive/34c13ddfab0e35422f4c3979f360635a8c050260.zip.)\nEven if I generate the a pull request for google/farmhash, how tensorflow will fetch that?\n### Environment info\n\nOperating System: Ubuntu 14.04 linux ppc64le\n\nInstalled version of CUDA and cuDNN: 7.5\n$ ls -l /usr/local/cuda-7.5/lib64/libcud*\n-rw-r--r-- 1 root root   326744 Nov  9  2015 /usr/local/cuda-7.5/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Nov  5  2015 /usr/local/cuda-7.5/lib64/libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx 1 root root       19 Nov  5  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5 -> libcudart.so.7.5.23\n-rwxr-xr-x 1 root root   445192 Nov  5  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5.23\n-rw-r--r-- 1 root root   902750 Nov  9  2015 /usr/local/cuda-7.5/lib64/libcudart_static.a\nlrwxrwxrwx 1 root root       13 Apr 24 20:17 /usr/local/cuda-7.5/lib64/libcudnn.so -> libcudnn.so.5\n-rwxr-xr-x 1 root root 60068392 Apr 22 19:18 /usr/local/cuda-7.5/lib64/libcudnn.so.5.0.5\n-rw-r--r-- 1 root root 59436124 Apr 22 19:30 /usr/local/cuda-7.5/lib64/libcudnn_static.a\n\n**1. The commit hash (`git rev-parse HEAD`)** - v0.9.0 (problem also seen in the latest master branch)\n**2. The output of `bazel version`** \nBuild label: head (@f7d9417)\nBuild target: bazel-out/local_linux-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Tue Aug 9 13:56:57 2016 (1470751017)\nBuild timestamp: 1470751017\nBuild timestamp as int: 1470751017\n### Steps to reproduce\n1. git clone https://github.com/tensorflow/tensorflow\n2. cd  tensorflow && git checkout v0.9.0\n3. ./configure && bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\n### What have you tried?\n1. Manually modifying config.guess of farmhash to add a case of ppc64le fixes the problem.\n### Logs or other output that would be helpful\n\nERROR: /home/user/.cache/bazel/_bazel_user/9138b14b59b57ff6760f108ab5f6a562/external/farmhash_archive/BUILD:5:1: Executing genrule @farmhash_archive//:configure failed: bash failed: error executing command /bin/bash -c ... (remaining 1 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\n/home/user/.cache/bazel/_bazel_user/9138b14b59b57ff6760f108ab5f6a562/tensorflow_upstream/external/farmhash_archive/farmhash-34c13ddfab0e35422f4c3979f360635a8c050260 /home/user/.cache/bazel/_bazel_user/9138b14b59b57ff6760f108ab5f6a562/tensorflow_upstream\n/tmp/tmp.um0vY1ktLs /home/user/.cache/bazel/_bazel_user/9138b14b59b57ff6760f108ab5f6a562/tensorflow_upstream/external/farmhash_archive/farmhash-34c13ddfab0e35422f4c3979f360635a8c050260 /home/user/.cache/bazel/_bazel_user/9138b14b59b57ff6760f108ab5f6a562/tensorflow_upstream\nchecking for a BSD-compatible install... /usr/bin/install -c\nchecking whether build environment is sane... yes\nchecking for a thread-safe mkdir -p... /bin/mkdir -p\nchecking for gawk... no\nchecking for mawk... mawk\nchecking whether make sets $(MAKE)... yes\nchecking whether make supports nested variables... yes\nchecking build system type... /tmp/tmp.um0vY1ktLs/missing: Unknown `--is-lightweight' option\nTry`/tmp/tmp.um0vY1ktLs/missing --help' for more information\nconfigure: WARNING: 'missing' script is too old or missing\n./config.guess: unable to guess system type\n\nThis script, last modified 2010-08-21, has failed to recognize\nthe operating system you are using. It is advised that you\ndownload the most up to date version of the config scripts from\n\n  http://git.savannah.gnu.org/gitweb/?p=config.git;a=blob_plain;f=config.guess;hb=HEAD\nand\n  http://git.savannah.gnu.org/gitweb/?p=config.git;a=blob_plain;f=config.sub;hb=HEAD\n\nIf the version you run (./config.guess) is already up to date, please\nsend the following data and any information you think might be\npertinent to config-patches@gnu.org in order to provide the needed\ninformation to handle your system.\n\nconfig.guess timestamp = 2010-08-21\n\nuname -m = ppc64le\nuname -r = 3.19.0-58-generic\nuname -s = Linux\nuname -v = #64~14.04.1-Ubuntu SMP Fri Mar 18 19:05:01 UTC 2016\n\n/usr/bin/uname -p =\n/bin/uname -X     =\n\nhostinfo               =\n/bin/universe          =\n/usr/bin/arch -k       =\n/bin/arch              =\n/usr/bin/oslevel       =\n/usr/convex/getsysinfo =\n\nUNAME_MACHINE = ppc64le\nUNAME_RELEASE = 3.19.0-58-generic\nUNAME_SYSTEM  = Linux\nUNAME_VERSION = #64~14.04.1-Ubuntu SMP Fri Mar 18 19:05:01 UTC 2016\nconfigure: error: cannot guess build type; you must specify one\n", "comments": ["We download by git hash: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/workspace.bzl#L35\n\nSo if you make a PR to farmhash, and it gets merged, we can update the hash in workspace.bzl and farmhash.BUILD to point to the version that has your commit.\n", "Okay. Thanks a lot!\n", "I am seeing this as well on what should be amd64:\n\n```\nFarmHash Version 1.1.0\n\nPrefix: '/usr/local'.\nCompiler: 'g++ -g -O2'\n\nNow type 'make [<target>]'\n  where the optional <target> is:\n    all                - build everything\n    check              - build and run tests\n    install            - install everything\n\n--------------------------------------------------\n/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/tensorflow/external/farmhash_archive/farmhash-34c13ddfab0e35422f4c3979f360635a8c050260 /root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/tensorflow\n/root/.cache/bazel/_bazel_root/68a62076e91007a7908bc42a32e4cff9/execroot/tensorflow\n/tmp/tmp.0swBa9mWmx/missing: Unknown `--is-lightweight' option\nTry `/tmp/tmp.0swBa9mWmx/missing --help' for more information\nconfigure: WARNING: 'missing' script is too old or missing\n```\n", "Farmhash already has a pending pull request https://github.com/google/farmhash/pull/7 to address this problem. Not sure about the reason for it not yet merged.\n", "Farmhash's pull request https://github.com/google/farmhash/pull/8 to detect the ppc64le has been merged to google/farmhash repo.\nBut looks like the latest tensorflow does not build farmhash as it used to do earlier. So, config.guess and config.sub are not used at all. However, I think it is worth updating farmhash commit hash in the tensorflow/workspace.bzl. \n\nI have generated a pull request updating the farmhash commit hash in tensorflow https://github.com/tensorflow/tensorflow/pull/4597. \n", "Closing the issue as the pull request #4597 has been merged. Thanks all.\n"]}, {"number": 3721, "title": "contrib outputs_collections bug", "body": "# Problem description\n\nTensorFlow version r0.10\n\nIt seems to me that there is a bug with the outputs_collections in tensorflow/tensorflow/contrib/layers. When trying to add the outputs of the layers (say, conv2d) to the tf.GraphKeys.ACTIVATIONS collection, I run into errors with NamedOutputs such as the following:\n\n```\n...\nRun summarize_activations() from tensorflow/tensorflow/contrib/layers/python/layers/summaries.py\n...\n/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/summaries.pyc in summarize_collection(collection, name_filter, summarizer)\n    160     if name_filter is None or re.match(name_filter, op.op.name):\n    161       tensors.append(op)\n--> 162   return summarize_tensors(tensors, summarizer)\n    163\n    164\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/summaries.pyc in summarize_tensors(tensors, summarizer)\n    150 def summarize_tensors(tensors, summarizer=summarize_tensor):\n    151   \"\"\"Summarize a set of tensors.\"\"\"\n--> 152   return [summarizer(tensor) for tensor in tensors]\n    153\n    154\n\n/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/summaries.pyc in summarize_tensor(tensor, tag)\n    135   \"\"\"\n    136   # Skips string tensors and boolean tensors (not handled by the summaries).\n--> 137   if (tensor.dtype.is_compatible_with(dtypes.string) or\n    138       tensor.dtype.base_dtype == dtypes.bool):\n    139     return None\n\nAttributeError: 'NamedOutputs' object has no attribute 'dtype'\n```\n# Root of problem\n## README and code are not consistent\n\nThe readme (located at tensorflow/tensorflow/contrib/layers/README.md) indicates that \"weights, biases, and activations (i.e., outputs) are, by default, added to the specified collections.\" They even show a piece of code such as `output_collections=(tf.GraphKeys.ACTIVATIONS,)`. However, looking into the code in tensorflow/tensorflow/contrib/layers/python/layers/layers.py it seems to me that there is nothing adding activations to the tf.GraphKeys.ACTIVATIONS collection. I believe one solution to this problem is to use the `_apply_activation` function already written in the file:\n\n```\ndef _apply_activation(y, activation_fn, output_collections):\n  if activation_fn:\n    y = activation_fn(y)\n  ops.add_to_collections(list(output_collections or []) +\n                         [ops.GraphKeys.ACTIVATIONS], y)\n  return y\n```\n\ninstead of using only\n\n```\nif activation_fn:\n      outputs = activation_fn(outputs)\nreturn utils.collect_named_outputs(outputs_collections, sc.name, outputs)\n```\n## Code walkthrough\n\ntensorflow/tensorflow/contrib/layers/python/layers/layers.py uses this line several times (such as in conv2d):\n`utils.collect_named_outputs(outputs_collections, sc, outputs)`\n\nOpening tensorflow/tensorflow/contrib/layers/python/layers/utils.py we see that this ultimately calls:\n`ops.add_to_collections(collections, NamedOutputs(name, outputs))`\n\nHowever, it seems to me that when using the summarize_activations function in https://github.com/tensorflow/tensorflow/blob/r0.10/tensorflow/contrib/layers/python/layers/summaries.py, it expects the value to be `outputs` rather than `NamedOutputs(name, outputs)`. In other words, the summarize_activations function seems to expect something along the lines of:\n`ops.add_to_collections(collections, outputs)`\nrather than\n`ops.add_to_collections(collections, NamedOutputs(name, outputs))`\n### Further description (not particularly informative if you are already familiar with the tensorflow repo)\n\nIf we look into what `ops.add_to_collections` is doing, we see that in tensorflow/tensorflow/python/framework/ops.py this ultimately calls:\n`self.add_to_collection(name, value)`\n\n`add_to_collection(...)` is described in the same file as:\n\n```\n  def add_to_collection(self, name, value):\n    \"\"\"Stores `value` in the collection with the given `name`.\n    Note that collections are not sets, so it is possible to add a value to\n    a collection several times.\n    Args:\n      name: The key for the collection. The `GraphKeys` class\n        contains many standard names for collections.\n      value: The value to add to the collection.\n```\n\nSo, our `value` here is `value = NamedOutputs(name, outputs)` from earlier.\n\nHowever, if we look at the summarize_activations in tensorflow/tensorflow/contrib/layers/python/layers/summaries.py, we see that:\n\n```\ndef summarize_activations(name_filter=None, summarizer=summarize_activation):\n  \"\"\"Summarize activations, using `summarize_activation` to summarize.\"\"\"\n  return summarize_collection(ops.GraphKeys.ACTIVATIONS, name_filter,\n                              summarizer)\n\ndef summarize_collection(collection, name_filter=None,\n                         summarizer=summarize_tensor):\n  \"\"\"Summarize a graph collection of tensors, possibly filtered by name.\"\"\"\n  tensors = []\n  for op in ops.get_collection(collection):\n    if name_filter is None or re.match(name_filter, op.op.name):\n      tensors.append(op)\n  return summarize_tensors(tensors, summarizer)\n```\n\nIn other words, `summarize_collection(...)` expects the collection to contain tensors instead of NamedOutputs(name, outputs).\n", "comments": ["@martinwicke Is this a `tf.learn` API inconsistency?\n", "Yes, thanks. @sguada: I hadn't noticed the commit that introduced these. As a general rule, we always only had tensors in the collections, and rely on this in several places. \n\nI recall a conversation where we discussed this type of change and decided that the tensor names themselves would be enough. We should revisit that decision and talk about what we want and make it consistent, or we should revert that change.\n", "This also seems to have broken `layers.summarize_activations()`. When I use it I get:\n\n```\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/summaries.py\", line 181, in summarize_activations\n    summarizer)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/summaries.py\", line 162, in summarize_collection\n    return summarize_tensors(tensors, summarizer)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/summaries.py\", line 152, in summarize_tensors\n    return [summarizer(tensor) for tensor in tensors]\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/layers/python/layers/summaries.py\", line 108, in summarize_activation\n    if op.op.type in ('Relu', 'Softplus', 'Relu6'):\nAttributeError: 'NamedOutputs' object has no attribute 'op'\n```\n\nA temporary workaround/fix would be nice.\n", "Yes, I might have changed a few things in my code before getting the output that I showed in the issue.\n\nA temporary workaround is to manually add each activation into the tf.GraphKeys.ACTIVATIONS collection.\n\nEdit: just to clarify, `summarize_activations()` itself is not broken (as far as I know).\n", "working in a fix.\n"]}, {"number": 3720, "title": "Merge internal changes: Branch 129809238", "body": "Bringing internal changes to GitHub.\n", "comments": ["@tensorflow-jenkins Test this please.\n", "Merging because the failures are all pre-existing.\n"]}, {"number": 3719, "title": "Log sigmoid", "body": "It would be nice to have a numerically stable log_sigmoid similar to the existing log_softmax.\n", "comments": ["Do you mean `-tf.softplus`?\n", "I changed my mind, after accidentally writing `log_sigmoid(x) = -tf.nn.softplus(x)` instead of the correct `-tf.nn.softplus(-x)`.  We should have `tf.log_sigmoid`, though it should be implemented as pure Python."]}, {"number": 3718, "title": "Add complex dtype support to cast", "body": "This PR enables the `tf.cast` op to convert from/to complex numbers.\nThis is something that users might expect to work, as it's possible in numpy.\nI've also extended the tests and gradient code.\n\nI didn't quite know what to put as the cost for the cast operation, so I picked `NumTraits<To>::AddCost`, which is similar to what's used by `bfloat16`.\n\nThis fixes #3346.\n", "comments": ["Can one of the admins verify this patch?\n", "@benoitsteiner Can you review?\n", "Jenkins, test this please.\n", "The test failures so far (image_retrain_test) are known issues; they don't appear related to this PR. \n", "I've pushed a new commit that uses partial specialization instead of macros.\n", "Jenkins, test this please.\n", "The test failures appear unrelated, and the CPU tests were already failing when Jenkins started to test this PR (http://ci.tensorflow.org/job/tensorflow-master-cpu/926/). However to be on the safe side I'll wait until TensorFlow tests turn green again and trigger the tests again.\n", "Jenkins, test this please.\n", "Jenkins, test this please.\n"]}, {"number": 3717, "title": "Undefined Inputs on MatMul in Trace File (GPU Only)", "body": "I am still working on solving my performance issue with a Reinforcement Learning system as stated in #3320 and have a question about reading the trace files in Chrome with \"chrome:trace\".\n\nI am trying to debug and speed up my graph.  I am seeing multiple copies of some of the graph ops with \"undefined\" for both inputs for MatMul when GPU is in use, but not for CPU.  This seems to be the only Op I see this \"undefined\" input value.\n\nFor example, \"taking_action/mydnn/DNNLayer_1/MatMul\" has 3 MatMul.  1 with the appropriate inputs and 2 copies with \"undefined\" inputs.  Is this expected or do I have a problem with my graph?  Are the 2 \"undefined\" some optimization of the original \"MatMul\"?\n\n![screenshot 2016-08-09 15 30 21](https://cloud.githubusercontent.com/assets/18412448/17531049/41bc30ca-5e48-11e6-8de4-2ace42ebd192.png)\n\nEDIT: Using the latest HEAD, 0.10.0 RC\n", "comments": ["@prb12 What does undefined mean here?  If this is expected behavior, more details would be better sought on StackOverflow.\n", "Just a ping to keep this alive.  I can upload something if that speeds up the answer.  Still very suspicious that MatMul seems to be the only Op on the GPU I found that has these 2 additional MatMul's spawned with the \"undefined\" inputs.\n", "One way to narrow down this issue is to look at run_metadata.step_stats, to\nsee if the \"Unknown\" are also seen there, in which case it's problem with\ntracing. Otherwise it's a problem in Timeline generation.\n\nOn Mon, Aug 15, 2016 at 12:33 PM, Mazecreator notifications@github.com\nwrote:\n\n> Just a ping to keep this alive. I can upload something if that speeds up\n> the answer. Still very suspicious that MatMul seems to be the only Op on\n> the GPU I found that has these 2 additional MatMul's spawned with the\n> \"undefined\" inputs.\n> \n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3717#issuecomment-239853157,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AABaHNAkbsLj4Po73eENUlEjOZG27ngyks5qgJTvgaJpZM4Jgcsg\n> .\n", "I looked at the raw JSON data and did find that file was not created properly, so the problem is deeper in TensorFlow as there is no \"input0/1\" added to the file for the GPU version (2nd copy of OP):\n\nHere is the proper entry:\n\n> ```\n>     {\n>         \"name\": \"MatMul\",\n>         \"args\": {\n>             \"input0\": \"_recv_taking_action/observation_0/_12\",\n>             \"input1\": \"mydnn/l1_weight/read\",\n>             \"name\": \"taking_action/mydnn/DNNLayer_1/MatMul\",\n>             \"op\": \"MatMul\"\n>         },\n>         \"pid\": 3,\n>         \"ts\": 1470766531877123,\n>         \"cat\": \"Op\",\n>         \"tid\": 0,\n>         \"ph\": \"X\",\n>         \"dur\": 52\n>     },\n> ```\n\nHere is what I think is the bad entry in the JSON with no inputs defined:\n\n> ```\n>     {\n>         \"name\": \"MatMul\",\n>         \"args\": {\n>             \"name\": \"taking_action/mydnn/DNNLayer_1/MatMul\",\n>             \"op\": \"MatMul\"\n>         },\n>         \"pid\": 5,\n>         \"ts\": 1470766531877204,\n>         \"cat\": \"Op\",\n>         \"tid\": 0,\n>         \"ph\": \"X\",\n>         \"dur\": 23\n>     },\n> ```\n\nNot sure where to go from here.  I am uploading the raw JSON file.\n[timeline_gpu.ctf.json.txt](https://github.com/tensorflow/tensorflow/files/419025/timeline_gpu.ctf.json.txt)\n", "Here's a bit of digging -- toy program that generates matmul\n\n```\nrun_metadata = tf.RunMetadata()\na = tf.placeholder(dtype=np.float32)\nb = tf.placeholder(dtype=np.float32)\nc = tf.matmul(a, b)\nsess = tf.InteractiveSession()\na0 = np.ones((3,3), dtype=np.float32)\nfeed_dict = {a: a0, b: a0}\nsess.run([c], feed_dict=feed_dict,\n         options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE),\n         run_metadata=run_metadata)\nprint run_metadata.step_stats\n\n...\n\ntimeline_label: \"MatMul = MatMul(_recv_Placeholder_0, _recv_Placeholder_1_0)\"\n\n```\n\nThe result in shows no mention of inputs, that definition is in [step_stats.proto](https://github.com/tensorflow/tensorflow/blob/2a06837336bc29cb797c5be5605cb6188857768c/tensorflow/core/framework/step_stats.proto) so there are no inputs in proto but they are present in label\n\nAnd it looks like `timeline.py` has `_parse_op_label` which extracts inputs from op label. So one thing to check would be to look at your `run_metadata.step_stats` and see what `timeline_label` is for the node in question and then check the label generating logic if it's missing inputs\n", "It is unfortunate, but expected, to have some 'undefined' tensors/ops in the current Timeline view.\nThe reasons for this are due to some internal implementation details of the tracing framework. \n\nIn particular, the `timeline_label` field in the `StepStats` proto is generated from the `NodeDef`s in the **original** `GraphDef`, and the code which does this currently has no way to know about the ever-increasing amount of graph rewriting which happens before execution.  \n\nQuite often the original input nodes of the graph are simply no longer present at execution time and so do not appear in the `StepStats`.  The `tf.Timeline` code uses an extremely simple heuristic to parse this `timeline_label` and _attempt_ to find the input nodes elsewhere in the trace (i.e. the `StepStats`)...  but this heuristic is increasingly fragile.\n\nSome examples of rewriting which can cause input nodes to 'disappear' from the graph are:\n- Partitioning of the graph across 'devices' (e.g. CPU vs CPU) which turns an edge in the original graph into `_Send` and `_Recv` nodes with freshly generated names (usually ending with a numeric suffix)\n- Constant folding (if running with optimizations enabled) can frequently reduce non-trivial subgraphs to constant nodes with names ending in `__cf_[digits]` \n- Device-specific graph rewrites (see `Device::MaybeRewriteGraphDef`)\n- Any `OptimizationPass` which may have been registered. \n\nMost of the time, the only places where people will encounter this problem are when tensors cross device boundaries or when there has been some constant folding...  if the former is happening a lot then you have probably found your performance problem ;-)  \n\nIt's arguably overdue to refactor some of these APIs, but there are other changes in progress which will need to happen first.\n\nThe most likely solution is to add some additional metadata APIs (e.g. to `Session`) to allow the collection of the optimized and partitioned `GraphDefs` which actually get executed.  (e.g. `RunMetadata` could be extended to return the _actual_ `GraphDefs` and this information could be provided to `tf.Timeline`).  This would probably save a _lot_ of wasted debugging time and help people understand what is going on under the hood.\n", "Close due to no activity. Feel free to reopen! :)"]}, {"number": 3716, "title": "Seq2Seq - Place different LSTM layers on separate GPUs", "body": "Dears \n\nBased on the discussion on https://github.com/tensorflow/tensorflow/issues/600, I would like to place different LSTM layers on separate GPUs to improve the accuracy and speed. \nCan someone help me?\n\nWith Best Wishes,\nSiamak\n", "comments": ["Please ask questions about how to use TensorFlow on StackOverflow, not as Github issues.\n"]}, {"number": 3715, "title": "convert_to_records meet a bug", "body": "When I run the convert_to_records in how_to demo, show me the message. \nI just trash the reshape parameter and meet other bugs, it seems simple to fix.\n\n```\nTraceback (most recent call last):\n  File \"convert_to_records.py\", line 91, in <module>\n    tf.app.run()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"convert_to_records.py\", line 82, in main\n    reshape=False)\nTypeError: read_data_sets() got an unexpected keyword argument 'reshape'\n```\n", "comments": ["We'll need more information:\n1. Which tutorial code are you copying from?\n2. Which `read_data_sets` function doesn't have a reshape argument?\n\nThe only tutorial which I see using a `reshape` argument calls a `read_data_sets` function that does take that argument.\n", "I get the same error. I'm using the code found here:\nhttps://github.com/tensorflow/tensorflow/blob/r0.10/tensorflow/examples/how_tos/reading_data/convert_to_records.py\n\nedit: I've confirmed that I get the same error when using the code found here as well:\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/how_tos/reading_data/convert_to_records.py\n\nLike dzhwinter mentioned, removing reshape leads to other errors in the code.\n\nAlso, to clarify dzhwinter's original bug report, it's not that the function doesn't take the argument, it's that the argument isn't recognized by the function. If you remove the reshape=False there are other problems.\n", "I did some digging and it looks like for me, this might be related to the version of the code available from conda-forge. I checked the file:\n~/tensorflow/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py \n\nWhich is where that function comes from and indeed it does not have a reshape argument like the later version do. I'll try reinstalling with pip.\n", "Closing as stale. Feel free to reopen if this is a relevant issue today."]}, {"number": 3714, "title": "Tensorflow fails to install with python 2 (CPU-only) on MacOS 10.11.6.  What to do?", "body": "### Environment info\n\nOperating System: MacOS 10.11.6\n\nInstalled version of CUDA and cuDNN: \nn/a -- I chose the non-GPU edition of TensorFlow\n\nIf installed from binary pip package, provide:\n\nSee below...\n\nIf installed from source, provide \n\nn/a\n### Steps to reproduce\n1. Try to install tensorflow with python 2 on MacOSX 10.11.6.\n\n```\nShyamals-iMac-174:~ shyamalchandra$ export TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.10.0rc0-py2-none-any.whl\nShyamals-iMac-174:~ shyamalchandra$ \nShyamals-iMac-174:~ shyamalchandra$ sudo pip install --upgrade $TF_BINARY_URL\nPassword:\nSorry, try again.\nPassword:\nThe directory '/Users/shyamalchandra/Library/Caches/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\nThe directory '/Users/shyamalchandra/Library/Caches/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\nCollecting tensorflow==0.10.0rc0 from https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.10.0rc0-py2-none-any.whl\n  Downloading https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.10.0rc0-py2-none-any.whl (30.6MB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 30.6MB 45kB/s \nCollecting mock>=2.0.0 (from tensorflow==0.10.0rc0)\n  Downloading mock-2.0.0-py2.py3-none-any.whl (56kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 61kB 905kB/s \nCollecting protobuf==3.0.0b2 (from tensorflow==0.10.0rc0)\n  Downloading protobuf-3.0.0b2-py2.py3-none-any.whl (326kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 327kB 2.1MB/s \nRequirement already up-to-date: six>=1.10.0 in /Library/Python/2.7/site-packages/six-1.10.0-py2.7.egg (from tensorflow==0.10.0rc0)\nCollecting wheel (from tensorflow==0.10.0rc0)\n  Downloading wheel-0.29.0-py2.py3-none-any.whl (66kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 71kB 5.6MB/s \nCollecting numpy>=1.10.1 (from tensorflow==0.10.0rc0)\n  Downloading numpy-1.11.1-cp27-cp27m-macosx_10_6_intel.macosx_10_9_intel.macosx_10_9_x86_64.macosx_10_10_intel.macosx_10_10_x86_64.whl (3.9MB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3.9MB 324kB/s \nCollecting funcsigs>=1; python_version < \"3.3\" (from mock>=2.0.0->tensorflow==0.10.0rc0)\n  Downloading funcsigs-1.0.2-py2.py3-none-any.whl\nCollecting pbr>=0.11 (from mock>=2.0.0->tensorflow==0.10.0rc0)\n  Downloading pbr-1.10.0-py2.py3-none-any.whl (96kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 102kB 5.2MB/s \nCollecting setuptools (from protobuf==3.0.0b2->tensorflow==0.10.0rc0)\n  Downloading setuptools-25.1.6-py2.py3-none-any.whl (442kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 450kB 960kB/s \nInstalling collected packages: funcsigs, pbr, mock, setuptools, protobuf, wheel, numpy, tensorflow\n  Found existing installation: setuptools 1.1.6\n    Uninstalling setuptools-1.1.6:\nException:\nTraceback (most recent call last):\n  File \"/Library/Python/2.7/site-packages/pip/basecommand.py\", line 215, in main\n    status = self.run(options, args)\n  File \"/Library/Python/2.7/site-packages/pip/commands/install.py\", line 317, in run\n    prefix=options.prefix_path,\n  File \"/Library/Python/2.7/site-packages/pip/req/req_set.py\", line 736, in install\n    requirement.uninstall(auto_confirm=True)\n  File \"/Library/Python/2.7/site-packages/pip/req/req_install.py\", line 742, in uninstall\n    paths_to_remove.remove(auto_confirm)\n  File \"/Library/Python/2.7/site-packages/pip/req/req_uninstall.py\", line 115, in remove\n    renames(path, new_path)\n  File \"/Library/Python/2.7/site-packages/pip/utils/__init__.py\", line 267, in renames\n    shutil.move(old, new)\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py\", line 299, in move\n    copytree(src, real_dst, symlinks=True)\n  File \"/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/shutil.py\", line 208, in copytree\n    raise Error, errors\nError: [('/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/__init__.py', '/tmp/pip-iSKbnn-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/__init__.py', \"[Errno 1] Operation not permitted: '/tmp/pip-iSKbnn-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/__init__.py'\"), ('/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/__init__.pyc', '/tmp/pip-iSKbnn-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/__init__.pyc', \"[Errno 1] Operation not permitted: '/tmp/pip-iSKbnn-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/__init__.pyc'\"), ('/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/markers.py', '/tmp/pip-iSKbnn-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/markers.py', \"[Errno 1] Operation not permitted: '/tmp/pip-iSKbnn-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/markers.py'\"), ('/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/markers.pyc', '/tmp/pip-iSKbnn-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/markers.pyc', \"[Errno 1] Operation not permitted: '/tmp/pip-iSKbnn-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib/markers.pyc'\"), ('/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib', '/tmp/pip-iSKbnn-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib', \"[Errno 1] Operation not permitted: '/tmp/pip-iSKbnn-uninstall/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/_markerlib'\")]\n```\n### What have you tried?\n\nNothing yet; what should I do?\n### Logs or other output that would be helpful\n\nn/a\n", "comments": ["Do not use sudo pip on Mac. use `pip install --user <package_name>` \n", "El Capitan has a protection feature built-in that prevents overwriting some\npython dirs even with sudo\n\nOn Tue, Aug 9, 2016 at 8:55 PM, ashvsdata notifications@github.com wrote:\n\n> Do not use sudo pip on Mac. use pip install --user <package_name>\n> \n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3714#issuecomment-238759533,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AABaHOntzDbmcDoxXL2fn6ox0TAHJw-Gks5qeUvMgaJpZM4JgUCC\n> .\n"]}, {"number": 3713, "title": "Explanation of blank label in ctc_loss", "body": "The doc string of ctc_loss is lacking of several details. I tried to explain a little better of what is needed to get it working, but english is not my native language, so I'm sure that you can do much better!\n", "comments": ["Can one of the admins verify this patch?\n", "@ebrevdo can you review?\n", "@tensorflow-jenkins test this please\n"]}, {"number": 3712, "title": "gather_nd not working with API examples", "body": "### Environment info\n\nOperating System: Ubuntu 14.04\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\ncuda 7.5\ncudnn 4.0\n\npython3\ntensorflow version 0.9\n#### Code:\n\n```\nimport tensorflow as tf\nx = tf.constant([[1,1,1,1],[1,2,3,4]],shape=(2,4))\nindices = [[0],[0]]\ny = tf.gather_nd(x,indices)\n```\n#### Error log messages\n\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 814, in gather_nd\n    name=name)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/op_def_library.py\", line 704, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\", line 2262, in create_op\n    set_shapes_for_outputs(ret)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/ops.py\", line 1702, in set_shapes_for_outputs\n    shapes = shape_func(op)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/ops/array_ops.py\", line 1090, in _GatherNdShape\n    indices_shape[-1].merge_with(params_shape.ndims)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/tensor_shape.py\", line 133, in merge_with\n    self.assert_is_compatible_with(other)\n  File \"/usr/local/lib/python3.4/dist-packages/tensorflow/python/framework/tensor_shape.py\", line 108, in assert_is_compatible_with\n    % (self, other))\n#### Error\n\nValueError: Dimensions 1 and 2 are not compatible\n", "comments": ["Support for partial indices in `gather_nd` (fewer indices than dimensions) was added quite recently.  You are you using a version of TensorFlow where each index tensor must have exactly the number of tensor dimensions.  The code should work at HEAD.\n"]}, {"number": 3711, "title": "mnist_with_summaries.py error 'module' object has no attribute 'DT_HALF'", "body": "when $python mnist_with_summaries.py\nFile \"mnist_with_summaries.py\", line 29, in <module>\n    from tensorflow.examples.tutorials.mnist import input_data\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/examples/tutorials/mnist/**init**.py\", line 21, in <module>\n    from tensorflow.examples.tutorials.mnist import input_data\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/examples/tutorials/mnist/input_data.py\", line 29, in <module>\n    from tensorflow.contrib.learn.python.learn.datasets.mnist import read_data_sets\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/**init**.py\", line 23, in <module>\n    from tensorflow.contrib import distributions\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/distributions/**init**.py\", line 25, in <module>\n    from tensorflow.contrib.distributions.python.ops import gaussian_conjugate_posteriors\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/distributions/python/ops/gaussian_conjugate_posteriors.py\", line 25, in <module>\n    from tensorflow.contrib.distributions.python.ops.gaussian import Gaussian  # pylint: disable=line-too-long\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/distributions/python/ops/gaussian.py\", line 26, in <module>\n    from tensorflow.contrib.framework.python.framework import tensor_util as contrib_tensor_util  # pylint: disable=line-too-long\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/framework/**init**.py\", line 43, in <module>\n    from tensorflow.contrib.framework.python.framework import *\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/framework/python/framework/**init**.py\", line 22, in <module>\n    from tensorflow.contrib.framework.python.framework.tensor_util import *\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/framework/python/framework/tensor_util.py\", line 40, in <module>\n    from tensorflow.python.framework import dtypes\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/dtypes.py\", line 274, in <module>\n    float16 = DType(types_pb2.DT_HALF)\nAttributeError: 'module' object has no attribute 'DT_HALF'\n", "comments": ["Wrong version   solved it now\n"]}, {"number": 3710, "title": "function.Defun can't be applied to tf.Variable", "body": "I need to specify a custom gradient for my custom_op() function. I've written the following example.\n\n```\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.python.framework import function\n\ndef custom_op_grad(op, grad):\n    return grad\n\n@function.Defun(x=tf.float32, python_grad_func=custom_op_grad)\ndef custom_op(x):\n    exp = tf.exp(x)\n    constant = tf.constant(1., dtype=tf.float32)\n    add1 = tf.add(constant, exp)\n    log = tf.log(add1)\n    return log\n\nx = tf.Variable(np.array(np.arange(6)).reshape(3, 2), dtype=tf.float32)\n\nsess = tf.Session()\nsess.run(tf.initialize_all_variables())\n\nx = tf.identity(x)\n\ngrad = tf.gradients(custom_op(x), [x])[0]\n\nres = sess.run(grad)\n\nprint(res)\n\nsess.close()\n```\n\nIf I run the above example as it is I get the following result:\n\n```\n[[ 1.  1.]\n [ 1.  1.]\n [ 1.  1.]]\n```\n\nIf I comment out the @function.Defun(...) decorator (with I use to specify a custom gradient function) I get a different result:\n\n```\n[[ 0.5         0.7310586 ]\n [ 0.88079709  0.95257413]\n [ 0.98201376  0.99330717]]\n```\n\nThat is strange because custom_op_grad(op, grad) just returns grad, which I guess should be the same as the gradient calculated in the second case.\n\nMoreover, if I keep the decorator I also need to do this: x = tf.identity(x). If I comment out this line, I get the following error and I don't understand why:\n\n```\nTraceback (most recent call last):\n  File \"custom_op3.py\", line 42, in <module>\n    grad = tf.gradients(custom_op(x), [x])[0]\n  File \"/Users/zeis/tfm/lib/python3.5/site-packages/tensorflow/python/framework/function.py\", line 528, in __call__\n    return call_function(self._definition, *args, **kwargs)\n  File \"/Users/zeis/tfm/lib/python3.5/site-packages/tensorflow/python/framework/function.py\", line 267, in call_function\n    compute_shapes=False)\n  File \"/Users/zeis/tfm/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2285, in create_op\n    raise TypeError(\"Input #%d is not a tensor: %s\" % (idx, a))\nTypeError: Input #0 is not a tensor: <tensorflow.python.ops.variables.Variable object at 0x10eb7d710>\n```\n\nI'm using the GitHub version of TensofFlow.\n", "comments": ["If you comment out the `Defun`, it's computing the gradient of softplus correctly.  Your gradient function is wrong, since softplus isn't the identity function and doesn't have derivative 1, but computes what I'd expect given its implementation.\n\nThe fact that you can't apply a Defun to a variable is a bug.  @andydavis1: Could you take a look?\n", "Sorry that you are having this issue. We are working on a fix, after which you will be able to pass a Variable as a function argument (without using the Identify).\n", "Your custom_op(x) is effectively computing element-wise y = log(1+e^x) for x in the inputs. By definition, tf.gradients(y, x) computes, since grad_ys=None by default, dy_i/dx_i = e^x / (1 + e^x)  = sigmoid(x). Since your test is giving x = [0, 1, 2, 3, 4, 5]. So, \n[[ 0.5         0.7310586 ]\n [ 0.88079709  0.95257413]\n [ 0.98201376  0.99330717]]\nis correct.\n\nWhen you specify custom_op_grad(x, grad) = grad, effectively, you are telling the backprop algorithm to pass through the error. Since grad_ys=None, effectively, these are 1.0.\n", "If I run that sample code, I get\r\n\r\n    ValueError: Unknown keyword arguments: ['x']\r\n\r\nWhen I remove `x=` in the `Defun` call, this exception is gone.\r\n\r\nBut then I get:\r\n\r\n    tensorflow.python.framework.errors_impl.NotFoundError: Op type not registered 'custom_op_d6da5a2c'\r\n\r\nIs there something broken again?\r\n"]}, {"number": 3709, "title": "random_uniform for int32 broken on GPU", "body": "`tf.random_uniform` with `dtype=tf.int32` always produces `106199773` on GPU.\n\n```\nIn [3]: with tf.device('/cpu'): print(tf.random_uniform([], 0, 10, dtype=tf.int32).eval())\n6\n\nIn [4]: with tf.device('/gpu'): print(tf.random_uniform([], 0, 10, dtype=tf.int32).eval())\n1061997773\n```\n\nEnvironment:\nCentOS 7\nTensorFlow 0.9.0\nGTX TITAN X\nCUDA 7.5\nNVIDIA 367.27\n", "comments": ["This is likely caused by conversion between float and int.\n\n```\nIn [15]: tf.cast(0.0, 'int32').eval()\nOut[15]: 1056964608\n```\n", "That does seem like a bug, but it will be hard for us to reproduce since we don't have CentOS machines, and it doesn't seem to happen on what we do have.  Would you be up for investigating further?\n", "Yes, I would like to.\n", "Have you had a chance to do any more experiments, to try to isolate the problem? \n", "A system reboot seems to fix the problem, for a few days. I will make more investigation the next time I have a chance.\n", "Thanks for the update, let us know if you find anything else.\n"]}]