[{"number": 44504, "title": "Replace the COMPUTE_FTRL macro with a templated function; NFC", "body": "", "comments": []}, {"number": 44503, "title": "IOS: TensorFlow Lite Error: Didn't find op for builtin opcode 'RESIZE_BILINEAR' version '3'", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No - It's the TensorFlow Lite IOS Object Detection example...I just tried to use my own converted Darknet Tiny Yolo v4 to TFLite\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  NA\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: IOS 13.7\r\n- TensorFlow installed from (source or binary): I ran the POD install command on my mac\r\n- TensorFlow version (use command below): unknown...whatever POD install installed \r\n- Python version: NA\r\n- Bazel version (if compiling from source) NA:\r\n- GCC/Compiler version (if compiling from source) NA:\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nFrom XCODE -> Play the solution to deploy to my IOS IPhone device.  Fails on the following line:\r\n interpreter = try Interpretor(modelPath: modelPath, options: options)  \r\n\r\n**Describe the expected behavior**\r\nI expected it to run the normal TFLite IOS object detection example program on my phone but with my model\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@kaublezw \r\nPlease share complete stand alone code for us to replicate the issue faced, and the tf version.", "Here's the source code:  https://github.com/kaublezw/tflite_ios_example/tree/main/ObjectDetection\r\nIt is the tensorflow lite object detection ios example program. All I did was change the labels to be my own and added my own model, yolo4-tiny-416.tflite.  It fails on line 110 in ModelDataHandler.swift when it tries to load the Interpreter.", "@kaublezw Can you provide some more details on what error you see? Also, how did you obtain the yolo model? The example app supports models with a specific input/output signature, and possibly requires edits based on the input size & quantization of the model.", "I don't have any more details other than the error message that's in the title that was shown in xcode...  IOS: TensorFlow Lite Error: Didn't find op for builtin opcode 'RESIZE_BILINEAR' version '3'   The yolo v4 tiny model was trained via darknet installed on a Linux machine.  It was tested thoroughly.  I converted the yolo weights to tflite using this code: https://github.com/hunglc007/tensorflow-yolov4-tflite/blob/master/save_model.py  \r\n\r\nI tested the tflite model and it worked nearly identical to the original yolo tiny model.   I would expect an input/output error to occur at the point when I actually call the model...not when I try to simply instantiate the model using the out-of-box tf lite sample program.", "@yyoon Could you take a look at this? Looks like the YOLO model requires ResizeBilinear v3 which was added in a more recent TFLite version. Is there some issue with the pod installed?", "would it work if I tried training a yolo tiny v3 model and use that instead?", "@kaublezw Based on the `Podfile.lock` file in your repository, seems like you are using TFLite version 2.1.0, which is not the most recent version. Can you try running `pod update` from your project directory and build the project again? This will update your TFLite dependency to 2.3.0.\r\n\r\n@srjoglekar246 Do you know which exact stable version is this op available? If this was not available in 2.1.0, I think a simple version update above would probably solve the issue.", "That did it.  Thanks!", "Thanks for confirming @kaublezw !", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44503\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44503\">No</a>\n"]}, {"number": 44502, "title": "Jacobian fails on gradient of tf.function with if-elif-else or nested tf.cond", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): binary (pip)\r\n- TensorFlow version (use command below): v2.3.0-54-gfcc4b966f1 2.3.1\r\n- Python version: 3.8.5\r\n- CUDA/cuDNN version: executing on CPU\r\n- GPU model and memory: executing on CPU\r\n\r\n**Describe the current behavior**\r\n\r\nComputing the `GradientTape.jacobian` of the gradient (i.e. the Hessian) of a `tf.function` with either an if-elif-else construct or nested `tf.cond` results in a crash:\r\n\r\n```\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError:  Trying to add unsupported dtype 10\r\n         [[node gradients/AddN_2 (defined at debug.py:44) ]] [Op:__inference___backward___backward_f_bad_373_1158_1489]\r\n```\r\nSee full trace attached as [trace_without_pfor.txt](https://github.com/tensorflow/tensorflow/files/5471053/trace_without_pfor.txt).\r\n\r\nThe computation works fine when disabling  `tf.functions`.\r\n\r\nFirst-order derivatives (gradient or jacobian) work fine too.\r\n\r\n**Describe the expected behavior**\r\n\r\nHessian evaluates to `tf.Tensor([[2.]], shape=(1, 1), dtype=float32)`.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nThe following works if `use_function = False`, but fails for both `f_bad` and `f_bad_cond` when using `use_function = True`. Both `f_good` and `f_good_const` always work fine.\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nuse_function = True\r\nuse_pfor = False\r\n\r\ntf.config.run_functions_eagerly(not use_function)\r\n\r\n@tf.function\r\ndef f_bad(x):\r\n    if x < -1.:\r\n        return tf.pow(x, 2)\r\n    elif x <= 1.:\r\n        return tf.pow(x, 2)\r\n    else:\r\n        return tf.pow(x, 2)\r\n\r\n@tf.function\r\ndef f_bad_cond(x):\r\n    return tf.cond(x < -1.,\r\n                   lambda: tf.pow(x, 2),\r\n                   lambda: tf.cond(x <= 1.,\r\n                                   lambda: tf.pow(x, 2),\r\n                                   lambda: tf.pow(x, 2)))\r\n\r\n@tf.function\r\ndef f_good(x):\r\n    if x < -1.:\r\n        return tf.pow(x, 2)\r\n    else:\r\n        return tf.pow(x, 2)\r\n\r\n@tf.function\r\ndef f_good_cond(x):\r\n    return tf.cond(x < -1.,\r\n                   lambda: tf.pow(x, 2),\r\n                   lambda: tf.pow(x, 2))\r\n\r\nf = f_bad\r\n\r\nx = tf.Variable([0.])\r\nwith tf.GradientTape(persistent=not use_pfor) as t2:\r\n    with tf.GradientTape() as t1:\r\n        y = f(x)\r\n    g_y = t1.gradient(y, x)\r\nhess = t2.jacobian(g_y, x, experimental_use_pfor=use_pfor)\r\nprint(hess)\r\n```\r\n\r\nNote that using `use_pfor = True` with `use_function = True` crashes for all four functions (see the attached [trace_with_pfor.txt](https://github.com/tensorflow/tensorflow/files/5471052/trace_with_pfor.txt)), but that is probably an entirely different issue...\r\n", "comments": ["I have tried on colab with TF version 2.3.1, nightly version(`2.5.0-dev20201029`) and was able to reproduce the issue. Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/cf8df22c346976e418fde3edd82057b2/untitled481.ipynb). Thanks!", "In nightly, seems even before `hess` the code is failing. The error message is `LookupError: No gradient defined for operation 'gradients/cond_grad/gradients/cond/cond/StatefulPartitionedCall_grad/SymbolicGradient' (op type: SymbolicGradient)` Seems to be [from tf.gradients](https://www.tensorflow.org/api_docs/python/tf/gradients), which raises a lookup error 'if one of the operations between x and y does not have a registered gradient function.'", "The latest nightly is a bit out of date (it's from last Thursday). I verified that the non-pfor issues have been fixed, likely by https://github.com/tensorflow/tensorflow/commit/07b75ffa453b1ec9189371244d21b6684503340b.\r\n\r\nI'll look into adding vectorization for optionals.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44502\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44502\">No</a>\n", "That should handle the pfor case. Please let me know if anything related to this bug is still broken.", "Should be fixed, thanks a lot!!", "The pfor part of the fix was rolled back. Should get back in soon. But the non-pfor bit will still work."]}, {"number": 44501, "title": "Image artifact with tf.keras data augmentation", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): RUN pip install --upgrade tensorflow tensorflow-gpu\r\n- TensorFlow version (use command below): v2.3.0-54-gfcc4b966f1 2.3.1\r\n- Python version: Python 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: V10.1.243\r\n- GPU model and memory: GeForce GTX 108 / 261MiB / 11178MiB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nWhen using the following code: \r\n```\r\ndata_augmentation = tf.keras.Sequential([\r\n  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\r\n  tf.keras.layers.experimental.preprocessing.RandomRotation(90),\r\n])\r\n```\r\nI see black lines around the edges of the augmented images. I do not see this when I use plain Keras:\r\n\r\n```\r\ndatagen = ImageDataGenerator(\r\n    rotation_range=model_params['rotation_range'],  # randomly rotate images in the range (degrees, 0 to 180)  \r\n    horizontal_flip=model_params['horizontal_flip'],  # randomly flip images\r\n    vertical_flip=model_params['vertical_flip'],\r\n\r\n)  \r\n```\r\n\r\nAlso, when I upgrade to tf-nightly it goes away. \r\n\r\n**Describe the expected behavior**\r\nI would expect the black lines to not be there. \r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nhttps://colab.research.google.com/drive/1nRpmyMrXkV43W82nI2fP2F05JndeGdg0?usp=sharing\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nI guess my question is whether or not these black lines are truly being fed into the network when using data augmentation.", "comments": ["Was able to reproduce the issue with [TF v2.3](https://colab.research.google.com/gist/amahendrakar/32d1f447194b885ef65cbeb2ece787af/44501.ipynb#scrollTo=boucrfpl-SrX) and as mentioned issue seems to be resolved in the latest [TF-nightly](https://colab.research.google.com/gist/amahendrakar/2c65092d39820454d5f73e58dd6d63dc/44501-tf-nightly.ipynb#scrollTo=boucrfpl-SrX). \r\n\r\nPlease find the attached gist. Thanks!", "The fix is available in newly released TF 2.4.0-rc0 as well. Hence we can expect it in TF 2.4 final version as well.\r\nThanks!\r\n", "> The fix is available in newly released TF 2.4.0-rc0 as well. Hence we can expect it in TF 2.4 final version as well.\r\n> Thanks!\r\n\r\nThank you @ymodak. And just to clarify, TF 2.4.0 isn't released yet, correct? So should I use tf-nightly in the interim?", "That's correct, 2.4.0 is yet to be released. For now you can use 2.4.0-rc0 or latest nightly version (2.5.XXXX)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44501\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44501\">No</a>\n"]}, {"number": 44500, "title": "FAILED: Build did NOT complete successfully", "body": "Hello ,\r\n\r\n\r\n- OS : pc windows 10\r\n- CPU : i7-5820K\r\n- RAM: 16G\r\n- TensorFlow installed from (source or binary): source git master\r\n- TensorFlow version: git Master\r\n- Python version: 3.8.6\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): [bazel release 3.7.0]\r\n- GCC/Compiler version (if compiling from source): Visual Studio Build Tools 2019 and Visual Studio Community 2019\r\n- CUDA/cuDNN version: cuda_10.1.105_418.96_win10/ cudnn-10.1-windows10-x64-v7.6.5.32\r\n- GPU model and memory: Nvidia getforce GTX1070Ti / 8192 MB\r\n\r\n\r\n\r\nin build verbose :\r\n`\r\nWARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/llvm/llvm-project/archive/9bb9b737c5573cf3850230bc4db8dac7be0e1e85.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\n`\r\nand\r\n\r\n\r\n`ERROR: C:/tf/tensorflow/tensorflow/core/kernels/BUILD:1157:18: C++ compilation of rule '//tensorflow/core/kernels:reverse_op_gpu' failed (Exit 2): python.exe failed: error executing command`\r\n\r\n[Full log.txt](https://github.com/tensorflow/tensorflow/files/5470759/Full.log.txt)\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\ni search to build tensorflow-gpu with support AVX2\r\nbuild command in MSYS :\r\n\r\n bazel build --define=no_tensorflow_py_deps=true --local_ram_resources=12288 //tensorflow/tools/pip_package:build_pip_package\r\n\r\n", "comments": ["@project2501a \r\nCould you please try with CUDA 11 and cuDNN 8 and let us know if you still face issues.", "@Saduf2019 \r\nHello,\r\ni have build with :\r\n                          bazel-3.7.0-windows-x86_64\r\n                          msys2-x86_64-20200903 (and update with : pacman -Syu\r\n                                                                    pacman -Su)\r\n                          python 3.8.6\r\n                          cuda_11.1.1_win10_network\r\n                          cudnn-11.1-windows-x64-v8.0.4.30\r\nwith this command :   bazel build --define=no_tensorflow_py_deps=true --local_ram_resources=12288 //tensorflow/tools\r\n                                  /pip_package:build_pip_package\r\n\r\nand have 2 other error : \r\n\r\n1) ERROR: C:/tf/tensorflow/tensorflow/BUILD:1018:19: Executing genrule //tensorflow:tf_python_api_gen_v2 failed (Exit 1): bash.exe failed: error executing command\r\n\r\n2) RuntimeError: The current Numpy installation ('C:\\\\Users\\\\dinonornis\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python38\\\\lib\\\\site-packages\\\\numpy\\\\__init__.py') fails to pass a sanity check due to a bug in the windows runtime. See this issue for more information: https://tinyurl.com/y3dm3h86\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n\r\n\r\n[Full log-2.txt](https://github.com/tensorflow/tensorflow/files/5482100/Full.log-2.txt)\r\n\r\n\r\nThx for your help :)\r\n", "@project2501a \r\nPlease install all the dependencies listed ex numpy. [[link](https://www.tensorflow.org/install/source_windows#setup_for_windows)]", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44500\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44500\">No</a>\n", "I'm experiencing this same 404 error on Ubuntu with CUDA 11.1 and CUDNN 8.0.5", "@tomweingarten \r\nCan you please try with CUDA 11.0? TF 2.4 (and nightly) is built and tested against CUDA 11.0, not 11.1.", "This is now resolved, thank you!\r\n\r\nTo clarify: I'm still compiling with 11.1 but it works now", "Same issue here. I am trying to build TF 2.4 with CUDA 11.0.3 and CUDNN 8.0.5. Some downloads are not working:\r\n\r\n```\r\nWARNING: Download from https://mirror.bazel.build/github.com/aws/aws-sdk-cpp/archive/1.7.336.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nWARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/llvm/llvm-project/archive/f402e682d0ef5598eeffc9a21a691b03e602ff58.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\n```\r\n", "INFO: Found applicable config definition build:dynamic_kernels in file /home/hortor/Desktop/data1/work/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS\r\nDEBUG: Rule 'io_bazel_rules_go' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = \"1557349968 -0400\"\r\nDEBUG: Repository io_bazel_rules_go instantiated at:\r\n  no stack (--record_rule_instantiation_callstack not enabled)\r\nRepository rule git_repository defined at:\r\n  /home/hortor/.cache/bazel/_bazel_hortor/c4d98c77c9b8b7dcb6bae627296ef8a4/external/bazel_tools/tools/build_defs/repo/git.bzl:195:18: in <toplevel>\r\nDEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = \"1556410077 -0400\"\r\nDEBUG: Repository io_bazel_rules_docker instantiated at:\r\n  no stack (--record_rule_instantiation_callstack not enabled)\r\nRepository rule git_repository defined at:\r\n  /home/hortor/.cache/bazel/_bazel_hortor/c4d98c77c9b8b7dcb6bae627296ef8a4/external/bazel_tools/tools/build_defs/repo/git.bzl:195:18: in <toplevel>\r\nWARNING: Download from https://mirror.bazel.build/github.com/aws/aws-sdk-cpp/archive/1.7.336.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nWARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/llvm/llvm-project/archive/f402e682d0ef5598eeffc9a21a691b03e602ff58.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nINFO: Analyzed target //tensorflow/tools/lib_package:libtensorflow (190 packages loaded, 20055 targets configured).\r\n", "> \r\n> \r\n> Same issue here. I am trying to build TF 2.4 with CUDA 11.0.3 and CUDNN 8.0.5. Some downloads are not working:\r\n> \r\n> ```\r\n> WARNING: Download from https://mirror.bazel.build/github.com/aws/aws-sdk-cpp/archive/1.7.336.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\n> WARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/llvm/llvm-project/archive/f402e682d0ef5598eeffc9a21a691b03e602ff58.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\n> ```\r\n\r\n@samfux84 Have you found the solution for downloading llvm ?\r\nI have the same issue with tensorflow 2.4.1", "@redradist : Please have a look at #45739"]}, {"number": 44499, "title": "Add missing dep on MLIRMhloPassIncGen target", "body": "The file `sink_constants_to_control_flow.cc` includes the header\r\n`PassDetail.h`, which itself includes `mhlo_passes.h.inc`. The latter is\r\nnot guaranteed to be already generated since there was no dependency set\r\nto MLIRMhloPassIncGen.", "comments": ["This was identified during working on the integration of mlir-hlo into iree, because it broke the parallel build.\r\n\r\n@GMNGeoffrey Required for https://github.com/google/iree/issues/3312."]}, {"number": 44498, "title": "Module of the same name was imported twice.", "body": "Imported python `logging` module was redefined several lines afterwards as `from tensorflow.python.platform import tf_logging`.\r\nThe module `loggin` is also used extensively by itself `tf_logging`.", "comments": []}, {"number": 44497, "title": "the tf.repeat function can not be converted to tflite?", "body": "I tested the newest tf-nightly==2.5.0-dev20201029,\r\nthe tf.repeat function would cause the errors below:\r\n\r\ntensorflow.lite.python.convert.ConverterError: ...../lib/python3.6/site-packages/tensorflow/python/saved_model/load.py:890:0: error: 'tf.Reshape' op requires 'shape' to have at most one dynamic dimension, but got multiple dynamic dimensions at indices 1 and 2\r\n\r\n........\r\n\r\nException ignored in: <bound method Buckets.del of <tensorflow.python.eager.monitoring.ExponentialBuckets object at 0x7f6e852aa4c8>>\r\nTraceback (most recent call last):\r\nFile \"......./lib/python3.6/site-packages/tensorflow/python/eager/monitoring.py\", line 407, in del\r\nAttributeError: 'NoneType' object has no attribute 'TFE_MonitoringDeleteBuckets'\r\n\r\n\r\nThe code has been shown in https://github.com/tensorflow/tensorflow/issues/40504\r\n\r\nAt the same time, according to the colab(https://colab.research.google.com/drive/1HudLLpT9CQdh2k04c06bHUwLubhGTWxA?usp=sharing)\r\nwhen using tf-nightly==2.4.0-dev20200630, tf.repeat can be converted. ", "comments": ["The above TensorTTS colab works fine with tf-nightly version, 2.5.0-dev20201029.\r\n\r\nCould you share a minimal example for reproducing your problem via colab?", "I just found that the problem is not caused by tf.repeat and the code can be converted. thanks", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44497\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44497\">No</a>\n"]}, {"number": 44496, "title": "Minor Update: Sample Code on Convert Section ", "body": "**Whats New:**\r\n\r\n- [ ] Update missing comma on sample code (Section: Create a model using high-level tf.keras.* APIs)", "comments": ["Thank you for the change!", "Thank you for your review @lintian06 @rthadur "]}, {"number": 44495, "title": "Screen freezes when jupyter starts loading keras and tensorflow", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1.  It must be a bug, a feature request, or a significant problem with the\r\n    documentation (for small docs fixes please send a PR instead).\r\n2.  The form below must be filled out.\r\n3.  It shouldn't be a TensorBoard issue. Those go\r\n    [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**:\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**:\r\n-   **TensorFlow installed from (source or binary)**:\r\n-   **TensorFlow version (use command below)**:\r\n-   **Python version**:\r\n-   **Bazel version (if compiling from source)**:\r\n-   **GCC/Compiler version (if compiling from source)**:\r\n-   **CUDA/cuDNN version**:\r\n-   **GPU model and memory**:\r\n-   **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": []}, {"number": 44494, "title": "TensorBoard say Launching TensorBoard..., but nothing show", "body": "![9DAroMg0xc](https://user-images.githubusercontent.com/4510984/97798399-a116db80-1c60-11eb-8f2f-05a6bb148e39.gif)\r\n\r\n![image](https://user-images.githubusercontent.com/4510984/97798449-269a8b80-1c61-11eb-95d1-b4f872a6d570.png)\r\n", "comments": ["@GF-Huang \r\nplease open this issue in the tensorboard repo, and move this to closed status.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44494\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44494\">No</a>\n"]}, {"number": 44493, "title": "Error while setting serial port parameters: 9,600 N 8 1: when run the \"tensorflow/tensorflow/lite/micro/examples/person_detection/\" example on Arduino Nano 33 BLE sense", "body": "### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**: tensorflow/tensorflow/lite/micro/examples/person_detection/\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**:\r\n-   **TensorFlow installed from (source or binary)**: \r\n-   **TensorFlow version (use command below)**: 1.14\r\n-   **Python version**:3.6\r\n-   **Bazel version (if compiling from source)**:\r\n-   **GCC/Compiler version (if compiling from source)**:\r\n-   **CUDA/cuDNN version**:\r\n-   **GPU model and memory**:\r\n-   **Exact command to reproduce**:\r\n\r\n\r\n### Describe the problem\r\nWhen I load the person detection example code in Arduino IDE, it works perfectly. \r\nBut, for my custom dog detection model, I re-implement all steps as defined in [this ](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/person_detection/training_a_model.md)article. This custom dog detection model trained successfully and also able to generate .cc model file. But, when I replace person_detect_model_data.cpp file with my dog_model, it throw the below error message when I click on serial monitor.\r\n\r\nCan someone help me to solve my issue?\r\n\r\nThanks a lot,\r\nBhavika\r\n\r\n### Source code / logs\r\nSketch uses 428728 bytes (43%) of program storage space. Maximum is 983040 bytes.\r\nGlobal variables use 127600 bytes (48%) of dynamic memory, leaving 134544 bytes for local variables. Maximum is 262144 bytes.\r\nDevice       : nRF52840-QIAA\r\nVersion      : Arduino Bootloader (SAM-BA extended) 2.0 [Arduino:IKXYZ]\r\nAddress      : 0x0\r\nPages        : 256\r\nPage Size    : 4096 bytes\r\nTotal Size   : 1024KB\r\nPlanes       : 1\r\nLock Regions : 0\r\nLocked       : none\r\nSecurity     : false\r\nErase flash\r\n\r\nDone in 0.000 seconds\r\nWrite 428736 bytes to flash (105 pages)\r\n[==============================] 100% (105/105 pages)\r\nDone in 17.794 seconds\r\nError while setting serial port parameters: 9,600 N 8 1\r\n\r\n", "comments": ["Hey @bhavikapanara, I'm getting compilation error just while trying out the person_detection example code. Any idea what would be causing that? I installed all the libraries and boards. ", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44493\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44493\">No</a>\n"]}, {"number": 44492, "title": "optimize all_reduce_indexed_slices for better performance", "body": "the original implementation convert sparse to reduce before all reduce, it is not efficient.", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F44492) for more info**.\n\n<!-- need_author_cla -->", "@googlebot I fixed it.", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F44492) for more info**.\n\n<!-- need_author_cla -->", "@chengmengli06  Can you please sign CLA. Thanks!", "@chengmengli06  Can you please check @crccw's comments and keep us posted ? Thanks!", "@chengmengli06 Any update on this PR? Please. Thanks!", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!", "I still want this to be merged, but I could not find self.gather @crccw @gbaned", "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/distribute/cross_device_utils.py#L495"]}, {"number": 44491, "title": "deterministic `Dataset.map`s aren't", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution: default colab\r\n\r\n**Describe the current behavior**\r\n`tf.data.Dataset.map` has a `determinstic` argument which is documented as allowing performance to be traded for determinism. Behaviour is not deterministic when `num_parallel_calls != 1` if `map_func` uses `tf.random` ops or methods from `tf.random.Generator` instances, even when `deterministic=True`.\r\n\r\n**Describe the expected behavior**\r\nDatasets mapped with `deterministic=True` should be deterministic, even with `num_parallel_calls != 1`. If this is not possible, documentation should not say that it is.\r\n\r\n**Standalone code to reproduce the issue**\r\nSee [colab](https://colab.research.google.com/drive/1u9N87y5BsFFGXvTO23pIjRTjheQekPEJ?usp=sharing) (code reproduced below).\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nimport time\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nseed = 0\r\ntf.random.set_seed(seed)\r\n\r\n\r\ndef map_fn(x):\r\n  return tf.random.uniform((100,),)\r\n\r\n\r\nds = tf.data.Dataset.range(10).map(\r\n    map_fn, num_parallel_calls=2, deterministic=True)\r\n\r\ntf.random.set_seed(seed)\r\nvals0 = [el.numpy() for el in ds]\r\ntf.random.set_seed(seed)\r\nvals1 = [el.numpy() for el in ds]\r\n\r\nnp.testing.assert_equal(vals0, vals1)\r\nprint(\"Passed\")\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\n```txt\r\n---------------------------------------------------------------------------\r\nAssertionError                            Traceback (most recent call last)\r\n<ipython-input-3-9c92a75ab4eb> in <module>()\r\n     18 vals1 = [el.numpy() for el in ds]\r\n     19 \r\n---> 20 np.testing.assert_equal(vals0, vals1)\r\n     21 print(\"Passed\")\r\n     22 \r\n\r\n3 frames\r\n/usr/local/lib/python3.6/dist-packages/numpy/testing/_private/utils.py in assert_array_compare(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)\r\n    844                                 verbose=verbose, header=header,\r\n    845                                 names=('x', 'y'), precision=precision)\r\n--> 846             raise AssertionError(msg)\r\n    847     except ValueError:\r\n    848         import traceback\r\n\r\nAssertionError: \r\nArrays are not equal\r\nitem=3\r\n\r\nMismatched elements: 100 / 100 (100%)\r\nMax absolute difference: 0.8390552\r\nMax relative difference: 70.61441\r\n x: array([0.839809, 0.390264, 0.704193, 0.916514, 0.008297, 0.778485,\r\n       0.316561, 0.052142, 0.876872, 0.176245, 0.275351, 0.204759,\r\n       0.999374, 0.40232 , 0.895112, 0.604971, 0.688866, 0.333363,...\r\n y: array([0.595369, 0.867852, 0.033959, 0.962069, 0.560696, 0.772698,\r\n       0.060957, 0.602406, 0.495115, 0.442416, 0.500883, 0.282592,\r\n       0.324962, 0.593064, 0.731267, 0.349757, 0.635136, 0.251549,...\r\n```", "comments": ["@jackd,\r\nOn setting the `experimental_deterministic` to `True` as per the [tf.data.Options](https://www.tensorflow.org/api_docs/python/tf/data/Options) documentation, I was able to run the code without any issues. \r\n\r\nPlease find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/91238870723615bd21222d4b07cd7552/44491-with-options.ipynb#scrollTo=JJetXPbVagy1). Thanks!", "@amahendrakar ~~So I opened my original colab, added `with_options` and it still failed. I then opened your colab, and it also failed. I re-opened my colab with the `with_options` changes and it passed. I've refreshed my colab and re-run the results a few times now, and sometimes it passes, sometimes it fails. I've also removed the `with_options` component and observe the same behaviour - sometimes it passes, sometimes it fails.~~\r\n\r\nI thought this might be to do with the machines colab was allocating, but I saw the same behaviour locally. Having increased the size of the dataset and `num_parallel_calls` I get this consistently failing both with and without `Options`. I suspect there's a non-deterministic race condition that occasionally behaves consistently with a small number of parallel calls. Original colab has been updated.\r\n\r\n```python\r\nds = tf.data.Dataset.range(1000).map(\r\n    map_fn, num_parallel_calls=8, deterministic=True)\r\n```\r\n\r\n", "Was able to reproduce the issue with [TF v2.3](https://colab.research.google.com/gist/amahendrakar/e98e3ea465b600027e82e9a8ede43c0a/44491.ipynb#scrollTo=RTif7JClak4R) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/911a3f8c74182713ed033559ce2f5775/44491-tf-nightly.ipynb#scrollTo=JkGrJapiaSqf). Please find the attached gist. Thanks!", "The documentation talks about the order in which the elements are produced, which is what the `deterministic` option controls. When `num_parallel_calls > 1` the order in which parallel map transformation access any state of stateful map transformations is not deterministic.\r\n\r\nTo guarantee that your code is deterministic in the presence of `num_parallel_calls > 1`, the map transformation should be stateless (and you can for instance use stateless RNG instead of the stateful one).\r\n\r\nI would be happy to review a PR with your suggestion for how to improve the documentation of tf.data.Dataset map.", "@jsimsa in this context does  \"produced\" mean the same as \"returned\"? I read that part of the documentation but assumed any stateful operations would be called during production. Happy to put in a PR.", "\"returned\" is indeed more accurate.\r\n\r\nTo be more precise: when `map` executes deterministically, then assuming its inputs are `x_1, ..., x_n`, it will produce as output `f(x_1), ..., f(x_n)`. If `num_parallel_calls > 1`, the application of `f` on different `x_i` can happen in parallel (and possibly out-of-order). As a consequence, if the output of `f` depends on external state that `f` modifies (such as RNG), the produced values `f(x_1), ..., f(x_n)` are not guaranteed to be identical across different executions (even though the \"order\" in which they are returned is).", "@jackd,\r\nCan you please respond to @jsimsa's comment. Thanks!  ", "Doc change merged.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44491\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44491\">No</a>\n"]}, {"number": 44490, "title": "tf-nightly2.4  run error", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu18.04\r\n- TensorFlow version (use command below):tf-nightly2.4\r\n- Python version:3.7.4\r\n- CUDA/cuDNN version:CUDA11.1\r\n- GPU model and memory:RTX3090\r\n\r\n\r\n**Describe the current behavior**\r\nIn my current environment, I use tf-nightly2.4 to run the bert model. After I run an epoch, I reported an error.\r\n  value error: layer model expects 3 input(s), but it received 4 input tensors.\r\nIt seems that the output layer of the model is also regarded as the input layer.\r\nBut there is no problem with my code, it can run completely on CUDA10.1, so what is going on?\r\n\r\n", "comments": ["I think the tf-nightly2.4 can't support RTX 3090 very well. we need to wait new version. I have the same question about that.", "@wwww666 \r\nPlease refer to [this comment](https://github.com/tensorflow/tensorflow/issues/43947#issuecomment-715295153) and use version 11 instead of 11.1 let us know, also[lease refer to this issue with respect to the configuration mentioned :#43718 #43588 #44251", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44490\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44490\">No</a>\n"]}, {"number": 44489, "title": "systemlib cherrypicks for r2.4", "body": "This cherry-picks a few fixes into r2.4 to make systemlib builds work.\r\n\r\nThis cherry-picks from:\r\nhttps://github.com/tensorflow/tensorflow/pull/44144\r\nhttps://github.com/tensorflow/tensorflow/pull/44222\r\nhttps://github.com/tensorflow/tensorflow/pull/44488\r\n\r\nThe first two are already merged into master and the last is a tiny fix for the merge conflict which was squashed into the protobuf commit", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F44489) for more info**.\n\n<!-- need_author_consent -->", "@Flamefire Can you add the consent to cherry-pick the first two commits into r2.4\r\nthanks!", "@googlebot I consent.\r\n\r\n@perfinion Why are the headers required for protobuf? Haven't been required on our system and having them (actually the copy of them) caused problems if the protobuf version didn't fully match and headers were missing or added", "> @perfinion Why are the headers required for protobuf? Haven't been required on our system and having them (actually the copy of them) caused problems if the protobuf version didn't fully match and headers were missing or added\r\n\r\n@Flamefire I get errors like this if i remove the `hdrs = HEADERS,` line from protobuf.BUILD\r\n\r\n```\r\nERROR: /home/jason/code/tf/tensorflow/tensorflow/tools/proto_text/BUILD:31:10: undeclared inclusion(s) in rule '//tensorflow/tools/proto_text:gen_proto_text_functions':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/tools/proto_text/gen_proto_text_functions.cc':\r\n  'bazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/google/protobuf/io/coded_stream.h'\r\n  'bazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/google/protobuf/io/zero_copy_stream.h'\r\n  'bazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/google/protobuf/io/zero_copy_stream_impl_lite.h'\r\n  'bazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/google/protobuf/descriptor.pb.h'\r\n  'bazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/google/protobuf/arena.h'\r\n  'bazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/google/protobuf/descriptor.h'\r\n  'bazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/google/protobuf/map.h'\r\n  'bazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/google/protobuf/repeated_field.h'\r\n  'bazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/google/protobuf/text_format.h'\r\n  'bazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/google/protobuf/util/json_util.h'\r\n  'bazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/google/protobuf/util/type_resolver_util.h'\r\n  'bazel-out/k8-opt-exec-50AE0418/bin/external/com_google_protobuf/google/protobuf/compiler/importer.h'\r\n```\r\n\r\nmy headers are in eg `/usr/include/google/protobuf/io/coded_stream.h`  so they _should_ just be automatically available because my compiler by default looks in /usr/include. Have you seen anything like this? I dont need it for any other deps it only happens for protobuf headers. I also really dislike needing to hardcode headers, the jsoncpp headers were a massive headache before you fixed them too but i'm not sure how cuz these arent a different include path :( .\r\n", "This very much looks like there are headers still there. I removed the copy here (same as for jsoncpp) so the system location should be used instead. Is it possible you are doing a \"dirty\" build? I.e. those headers are still there and were copied before my PR removed the copy and hence are used due to Bazel auto-adding those as include paths? If so simply deleting those headers is very much recommended as they might even be from an outdated protobuf installation.\r\n\r\nI'd recommend resolving that first before merging", "Waiting on #44522 ", "I finally figured out the protobuf issues, the culprit was `--disk_cache=` I have enabled. Even with `bazel clean --expunge` the old stuff was still being pulled out of the cache and re-used. I unreliably managed to make it work even with keeping the cache around. Doing a clean --expunge and changing some stuff in the protobuf.BUILD file would get it to work. Strangely adding `tags = [\"no-cache\"],` did not always work. The most reliably way to fix it was to just nuke my --disk_cache= dir.\r\n\r\nI dropped the protobuf commit from the top of this series (and rebased on top of the r2.4 branch). It should be okay to merge \r\ninto r2.4 now. I also approved https://github.com/tensorflow/tensorflow/pull/44522 which should go into master \r\n\r\n"]}, {"number": 44488, "title": "systemlibs: protobuf: fix merge conflict", "body": "The merge of PR 44222 ended up with duplicate keys in the bazel rule\r\n\r\nSigned-off-by: Jason Zaman <jason@perfinion.com>", "comments": ["Oh, I just realized this was on master, not on the release branch. Should not have merged manually.", "Reverting and reverting forward to fix my mistake, sorry.", "Should be fixed now. Sorry for the loops."]}, {"number": 44486, "title": "Fixed incorrect ptxas usage affecting performance when using CUDA", "body": "This PR fixes #40036 issue. Now unsuccessful `ptxas` invocation attempts are being cached as well. This helps to avoid a lot of unnecessary actions and IO operations if `ptxas` is not found or is incompatible.", "comments": ["hi, TF2.3 still have the problem\"incorrect ptxas usage affecting performance when using CUDA\". Which version will solve this? Thanks!", "@TiantianZhang This fix is applicable for the TF 2.3 codebase, however it's up to TF maintainers whether to release patches for TF 2.2 and 2.3 or not.", "> @TiantianZhang This fix is applicable for the TF 2.3 codebase, however it's up to TF maintainers whether to release patches for TF 2.2 and 2.3 or not.\r\n\r\nThank you very much! I think everyone who have this problem can just changed the code like your commit to avoid this problem.", "After approving, you can try patching the other branches (and mention that you are cherrypicking). if we do a patch release (for security reasons) we might consider taking in the cherrypick, depending on complexity and timeline.", "Multiple tests are failing after this\r\n\r\nErrors look like\r\n\r\n```\r\ntensorflow.python.framework.errors_impl.InternalError: 2 root error(s) found.\r\n  (0) Internal: Failed to load in-memory CUBIN: CUDA_ERROR_INVALID_IMAGE: device kernel image is invalid\r\n\t [[{{node Qr}}]]\r\n  (1) Internal: Failed to load in-memory CUBIN: CUDA_ERROR_INVALID_IMAGE: device kernel image is invalid\r\n\t [[{{node Qr}}]]\r\n\t [[Qr/_5]]\r\n```\r\n\r\nProbably caused by\r\n\r\n```\r\n2020-11-30 16:52:46.015358: W tensorflow/core/framework/op_kernel.cc:1763] OP_REQUIRES failed at xla_compile_on_demand_op.cc:173 : Internal: Failed to load in-memory CUBIN: CUDA_ERROR_INVALID_IMAGE: device kernel image is invalid\r\n```\r\n\r\nCan you fix please? For example, `bazel test //tensorflow/compiler/xla/tests:dot_operation_test_gpu` should pass.", "@mihaimaruseac I've fixed the failing tests. Seems like `TF_ASSIGN_OR_RETURN` was silently moving PTX compilation result instead of returning it by reference.\r\nSorry for letting this happen, I thought these tests are failing for some other reason, not because of my changes. Could you rerun the CI pipeline to validate the fix? Thank you in advance!"]}, {"number": 44485, "title": "Support Python 3.9", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.3.1\r\n- Are you willing to contribute it (Yes/No): No (willing to do trivial patches)\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nTensorFlow should be supported on Python 3.9.\r\n\r\n**Will this change the current api? How?** Significant changes will likely need to be made.\r\n\r\n**Who will benefit with this feature?**\r\nAnyone on Python 3.9\r\n\r\n**Any Other info.**\r\n", "comments": ["We have not released anything for python3.9.\r\n\r\nRelease process is as follows:\r\n\r\n1. Ensure all of our dependencies support python3.9 (not yet there)\r\n2. Ensure our code works with all these dependencies on all supported versions of python (at the moment, at least `gast` needs additional support work).\r\n3. Release nightly version supporting the new python version\r\n4. Release a full release.\r\n\r\nAs we are already doing the 2.4 release, python3.9 support for TF will come in 2.5 release at the earliest.\r\n\r\n@ravikyram, @amahendrakar, @rmothukuru  let's deduplicate to this issue all py39 requests/issues. I'll monitor this one and provide updates as we start adding support.", "@mihaimaruseac,\r\nSure ", "> I may be wrong, but I believe this is the case:\r\n> \r\n> ```\r\n> python3.8 -m pipdeptree -p tensorflow | grep \"^  -\" | sed \"s/  - //\" | sed \"s/ \\[.*]//\" | xargs python3.9 -m pip install\r\n> ```\r\n> \r\n> which is essentially\r\n> \r\n> ```\r\n> python3.9 -m pip install absl-py astunparse flatbuffers gast google-pasta grpcio h5py keras-preprocessing numpy opt-einsum protobuf six tensorboard tensorflow-estimator termcolor typing-extensions wheel wrapt\r\n> ```\r\n> \r\n> works fine for me. Am I missing anything?\r\n\r\n(from https://github.com/tensorflow/tensorflow/issues/40840#issuecomment-728760033)\r\n\r\nThe main issue is that we also have C++ code and we need the needed dependencies to also upgrade for their C++ code. By this time, likely most are solved, so 2.5 release will have py3.9 support.\r\n\r\nWe should get py3.9 in nightly soon.", "So, all of our depdencies have a release for py3.9 but our `setup.py` upper bounds to versions which are below that release. We will need to increase these bounds while making sure we don't break existing usecases/tests. Will slowly happen over December.", "> So, all of our depdencies have a release for py3.9 but our `setup.py` upper bounds to versions which are below that release. We will need to increase these bounds while making sure we don't break existing usecases/tests. Will slowly happen over December.\r\n\r\n@mihaimaruseac Any update? (Quite concerned here as we did an upgrade to 3.9 for some various reasons such Python's core enhancements but totally zapped out the TensorFlow's upper bound T_T)\r\n\r\nOh, and why limiting on upper bound nightly releases if they are for testing?\r\nI tried `pip install tf-nightly 2.5.0.dev20201211` but it ended up as the stable version:\r\n```\r\nERROR: Could not find a version that satisfies the requirement tf-nightly\r\nERROR: No matching distribution found for tf-nightly\r\n```", "I've built tf 2.4 for python 3.9.1 on windows 10 and ubuntu 18.04 and they work fine, no problem at all", "> I've built tf 2.4 for python 3.9.1 on windows 10 and ubuntu 18.04 and they work fine, no problem at all\r\n\r\nCurious to know how you did that since you cannot use it because of this \u201cstupid\u201d dependency check. Oh you mean you built it from source? If that\u2019s so, would you mind sharing the commands/options you used?\r\n\r\nthanks!", "@willemavjc I can share my build from source setup. Win 10 and works with python 3.9.1, TF 2.4.\r\nPython 3.9 installed in c:\\python39\\ dir.\r\n```\r\n# Copy https://github.com/bazelbuild/bazel/releases/download/3.7.2/bazel-3.7.2-windows-x86_64.exe to somewhere in PATH and rename to bazel.exe \r\n# Make sure you have Visual Studio 2019 Build Tools installed (located under C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC)\r\n# Make sure cudnn-8.0.5.39 is unpacked into C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.0 respective dirs.\r\n# Ensure your env vars contain something like this:\r\n# CUDA_PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.0\r\n# CUDA_TOOLKIT_PATH=%CUDA_PATH%\r\n# PATH=%CUDA_PATH%\\bin;%PATH%\r\n# PATH=%CUDA_PATH%\\extras\\CUPTI\\libx64;%PATH%\r\n\r\n# Using PowerShell 7.1.0\r\ngit clone https://github.com/tensorflow/tensorflow.git tf24build\r\ncd tf24build\r\ngit checkout v2.4.0\r\n\\python39\\python -m venv .venv\r\n.\\.venv\\Scripts\\Activate.ps1\r\npip install -U pip\r\n\r\n# Now, depending on how fresh is your Windows installation, you need either numpy==1.19.3 or or 1.19.4.\r\n# See https://github.com/numpy/numpy/issues/16744 for details\r\npip install six numpy==1.19.4 wheel keras_applications keras_preprocessing --no-deps\r\n\r\n$Env:BAZEL_VC = \"C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\BuildTools\\VC\"\r\n# Adjust the Compute Capabilities to match your target GPU!\r\n$Env:TF_CUDA_COMPUTE_CAPABILITIES = \"7.5\"\r\n$Env:CC_OPT_FLAGS = \"/arch:AVX2\"\r\n$Env:TF_NEED_CUDA = \"1\"\r\n\r\n# Check the prompts but should be just enter for everything\r\n.\\configure.cmd\r\n\r\nbazel build --config=opt --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package\r\n\r\n# Generates tensorflow_2_4_py39.whl\r\nbazel-bin\\tensorflow\\tools\\pip_package\\build_pip_package tensorflow_2_4_py39\r\n\r\n# Create a new venv and install the new wheel, test it's health with\r\n# python -c \"import tensorflow as tf;print(tf.reduce_sum(tf.random.normal([1000, 1000])));print(tf.config.list_physical_devices('GPU'))\" \r\n", "Sorry but AFAIK protobuf does not support Python 3.9 properly with their Linux wheels. See https://github.com/protocolbuffers/protobuf/issues/7978.", "Ah, I think I also left out a few bits here...\r\nBecause grpcio version that tensorflow depends on is not having the python 3.9 wheels (but newer version has), my setup to install the wheels is twofold:\r\n```\r\n# Requirements from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/pip_package/setup.py\r\npip install \"grpcio==1.34.0\" \"absl-py~=0.10\" \"astunparse~=1.6.3\" \"flatbuffers~=1.12.0\" \"google_pasta~=0.2\" \"h5py~=3.1.0\" \"keras_preprocessing~=1.1.2\" \"numpy~=1.19.2\" \"opt_einsum~=3.3.0\" \"protobuf>=3.9.2\" \"six~=1.15.0\" \"termcolor~=1.1.0\" \"typing_extensions~=3.7.4\" \"wheel~=0.35\" \"wrapt~=1.12.1\" \"gast==0.3.3\"\r\n\r\npip install --no-deps C:\\tmp\\tensorflow-2.4.0-cp39-cp39-win_amd64.whl\r\n```\r\n\r\nThis makes it easier to also manage the protobuf installation separately. At least for Windows there is an unofficial Python 3.9 protobuf wheel at https://www.lfd.uci.edu/~gohlke/pythonlibs/#protobuf (not the latest but good enough, 3.12.3, ).", "protobuf and gast are current blockers to have 100% tests passing", "> protobuf and gast are current blockers to have 100% tests passing\r\n\r\n[gast 0.4.0](https://github.com/serge-sans-paille/gast/releases/tag/0.4.0) seems to support Python 3.9. Haven't tested it yet though.", "@willemavjc \r\nonly problem blocked me was grpcio 1.32.0, which I ignored using --no-dependency option\r\n\r\n\r\nI've built tensorflow from source of course\r\n\r\ncuda 11.2\r\ncudnn 8.0.5\r\nbranch - r2.4", "> > protobuf and gast are current blockers to have 100% tests passing\r\n> \r\n> [gast 0.4.0](https://github.com/serge-sans-paille/gast/releases/tag/0.4.0) seems to support Python 3.9. Haven't tested it yet though.\r\n\r\nIt does, but I think @mdanatg has a change to update and there are a few things that need to change to make all tests pass.", "The change to upgrade to 0.4 is ready and just needs one final approval. We should be able to resolve this shortly after the approver is back in office, on Jan 5.", "> The change to upgrade to 0.4 is ready and just needs one final approval. We should be able to resolve this shortly after the approver is back in office, on Jan 5.\r\n\r\nThis kind of info is related, more in general, to a quite old open topic (since 2016) as you can see https://github.com/tensorflow/tensorflow/pull/46039#issuecomment-752087368\r\n\r\nAnd this specific issue was exposed from October (https://github.com/tensorflow/tensorflow/issues/44146) so we had two months to be exposed to concurrent contributions conflicts.", "https://github.com/protocolbuffers/protobuf/pull/8121", "can you share the generated tensorflow-2.4.0-cp39-cp39-win_amd64.whl file?", "When building for mac Big Sur it seems that you need to rename the whl from tensorflow-2.4.0-cp39-cp39-macosx_11_0_x86_64.whl to tensorflow-2.4.0-cp39-cp39-macosx_10_16_x86_64.whl, but after installing gast==0.4, hypy==3.1.0 and grpcio==1.34.0 everything is working perfectly (so far ;))", "Any progress here? I would really appreciate being able to use Python 3.9.", "Not yet. We should support py3.9 in nightly in about a few weeks.", "Python 3.9.2 release is scheduled to happen in two weeks according to https://www.python.org/dev/peps/pep-0596\r\n\r\nPerhaps work should start now on testing against [Python 3.10a4](https://www.python.org/downloads/release/python-3100a4) so the community does not face yet another 7-month delay.", "> Python 3.9.2 release is scheduled to happen in two weeks according to https://www.python.org/dev/peps/pep-0596\r\n> \r\n> Perhaps work should start now on testing against [Python 3.10a4](https://www.python.org/downloads/release/python-3100a4) so the community does not face yet another 7-month delay.\r\n\r\nPython 3.9 is released at October 5th, 2020. Or are you referring to something else by \u201c7-month delay\u201d?", "TF has a large number of dependencies. We cannot make progress until all dependencies are updated.\r\n\r\nRight now protobuf is still lacking a [`py39` wheel](https://pypi.org/project/protobuf/#files). This means TF is unable to make real progress anyway (as we need the `py39` wheel due to the C++ protobuf interface)", "We have to wait until https://github.com/protocolbuffers/protobuf/pull/8121 lands and a new protobuf containing it (or similar) is released.", "Now that protocolbuffers/protobuf#8121 landed, we just need to wait for the release.", "Hi, any updates yet? Has it been released?", "When will tensorflow support python 3.9?", "Not until after there is a [protobuf release](https://github.com/protocolbuffers/protobuf/releases) that contains the protocolbuffers/protobuf#8121 mods.", "@cclauss are you implying that it will not happen until the _next_ release, since there was a release 5 days ago that did not include it?", "5 days ago was a ___pre___-release", "@cclauss Can you share any links for web pages with more details about the pre-release? I can't seem to find anything. \r\nThanks!", "@amay428 https://pypi.org/project/protobuf/3.15.0rc1/#files", "@ahtik I meant TensorFlow, not protobuf, but thanks", "TensorFlow **will** suport Python 3.9 **first** in **nightly** and then in **Tensorflow 2.5**. But this will happen **only** after all dependencies are available.", "Hi\r\n\r\nAny estimation date when TensorFlow will support Python 3.9 in nightly? \r\nAnd any estimation of release date of Tensorflow 2.5?\r\nIs it stable to use the nightly until Tensorflow 2.5 is released?\r\n\r\nThanks", "`nightly` is for non-production use so `nightly` != `stable` by definition.", "Currently blocked on Windows by #46902 caused by MSVC / Python 3.9 defines (https://www.gitmemory.com/issue/OpenImageIO/oiio/2799/752372181). As long as upstream projects are not working properly we cannot do anything. ", "< Had the exactly same problems >\r\nI can\u2019t wait when TF support to Python 3.9. \r\nLooking for reasonable ways to use TF without downloading Anaconda, Eventually, Decide to download lower version Python 3.5.8 and Use different Interpreter by Pycharm. ", "A bit of a drag that [Python 3.9.2 is shipping](https://www.python.org/downloads/release/python-392/) but TF still does not support Py39.\r\nHowever, If you need to run TF now, I would recommend looking at [Python 3.8](https://www.python.org/downloads/release/python-388/) instead of 3.5 which is already [end of life](https://devguide.python.org/devcycle/#end-of-life-branches).", "The [`copysign` issue](https://bugs.python.org/issue42120) got fixed by Python 3.9.1 by [removing it](https://github.com/python/cpython/pull/23326)\r\n\r\nhttps://docs.python.org/3/whatsnew/changelog.html\r\n![image](https://user-images.githubusercontent.com/140952/108675415-0f6cfb80-74e7-11eb-9ad3-e1af8b4f149f.png)\r\n\r\nhttps://github.com/microsoft/vcpkg/pull/16315 is getting this fix in by https://github.com/microsoft/vcpkg/issues/15369, if anyone wants to track one of the remaining upstream deps preventing the Python 3.9 upgrade.\r\n\r\nprotobuf got the 3.15.1 out with Python 3.9 a few days ago (unfortunately without the Windows build, but that was already the case with Python 3.8).", "Hi, any updates yet? Has it been released?", "Waiting for https://github.com/tensorflow/tensorflow/pull/44282", "Hi, looking forward to TF on Python 3.9.", "microsoft/vcpkg#16315 has been merged", "We have py39 wheels in recent `tf-nightly` and `tf-nightly-cpu` projects. Pending `tf-nightly-gpu`.\r\n\r\nMacOS is not yet supported. Only Linux and Windows for now, not all of them are in all of the above projects yet due to other unrelated failures. Please test nightly before the 2.5 release so we can get 2.5 release with good py39 support.", "I do get a build failure when trying to build the latest master (1627cd9e368) Windows wheel for Python 3.9.2.\r\n\r\nI wonder if the following error is one of the known unrelated failures or worth reporting? CUDA 11.2, compute capabilities 7.5, 8.6.\r\n\r\n```\r\n.\\tensorflow/core/platform/ram_file_system.h(197): error C2039: 'lstrcatA': is not a member of 'absl'\r\nexternal/com_google_absl\\absl/strings/str_split.h(51): note: see declaration of 'absl'\r\n.\\tensorflow/core/platform/ram_file_system.h(197): error C2664: 'LPSTR lstrcatA(LPSTR,LPCSTR)': cannot convert argument 2 from '_Ty1' to 'LPCSTR'\r\n        with\r\n        [\r\n            _Ty1=const std::string\r\n        ]\r\n.\\tensorflow/core/platform/ram_file_system.h(197): note: No user-defined-conversion operator available that can perform this conversion, or the operator cannot be called\r\nC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.18362.0\\um\\winbase.h(2794): note: see declaration of 'lstrcatA'\r\n```\r\n", "> We have py39 wheels in recent `tf-nightly` and `tf-nightly-cpu` projects. Pending `tf-nightly-gpu`.\r\n> \r\n> MacOS is not yet supported. Only Linux and Windows for now, not all of them are in all of the above projects yet due to other unrelated failures. Please test nightly before the 2.5 release so we can get 2.5 release with good py39 support.\r\n\r\nStill does not work for me (windows - py39)!", "@ahtik It seems you cloned exactly when the repo was failing :( Cloning at de4bc85341d4ffb3e0e8a2f40267459b04c1f2a1 should guarantee a passing Windows build (at least on our infra it was passing).\r\n\r\n@samanemami: what where you trying to do and what was the error?\r\n\r\nAll: All windows and Linux wheels for Py3.9 have been updated. If nothing breaks, over the weekend we should get these wheels updated daily.", "@mihaimaruseac The problem has solved.\r\nI finally decided to downgrade my python version and installed the TF for py38.\r\nLooking forward to having TF for py39.\r\nThanks", "@samanemami: tf-nightly works with py39 on Windows now. TF proper needs to wait for the next release as we cannot just patch old releases for new Python versions.\r\n\r\n", " How did you install it @mihaimaruseac ? \r\n Thanks for feedbacks,..\r\n\r\n```shell \r\n ~ sw_vers\r\nProductName:\tmacOS\r\nProductVersion:\t11.2.2\r\nBuildVersion:\t20D80\r\n\r\n ~ python --version\r\nPython 3.9.1\r\n \r\n~ pip install tensorflow\r\nERROR: Could not find a version that satisfies the requirement tensorflow\r\nERROR: No matching distribution found for tensorflow\r\n\r\n ~ pip install tf-nightly\r\nERROR: Could not find a version that satisfies the requirement tf-nightly\r\nERROR: No matching distribution found for tf-nightly\r\n\r\n~ python -c \"import sys; print(sys.version)\"\r\n3.9.1 (default, Feb 27 2021, 16:03:12)\r\n[Clang 12.0.0 (clang-1200.0.32.29)]\r\n\r\n~ python -c \"import struct; print(struct.calcsize('P')*8)\"\r\n64\r\n\r\n ~ pyenv versions\r\n  system\r\n  3.5.8\r\n  3.6.13\r\n  3.7.10\r\n  3.8.7\r\n* 3.9.1 (set by .pyenv/version)\r\n\r\n ~ pyenv global 3.8.7\r\n ~ python --version\r\nPython 3.8.7\r\n\r\n ~ pip install tensorflow\r\nERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\r\nERROR: No matching distribution found for tensorflow\r\n\r\n ~ pyenv global 3.7.10\r\n ~ python --version\r\nPython 3.7.10\r\n\r\n ~ pip install tensorflow\r\nERROR: Could not find a version that satisfies the requirement tensorflow\r\nERROR: No matching distribution found for tensorflow\r\n```\r\n\r\n", "Use python -m pip install instead of pip when you have multiple installations", "> python -m pip\r\n\r\nDear @byronyi  already tried that, the same result:\r\n\r\n```shell\r\n ~ python --version\r\nPython 3.9.1\r\n\r\n ~ python -m pip install tensorflow\r\nERROR: Could not find a version that satisfies the requirement tensorflow\r\nERROR: No matching distribution found for tensorflow\r\n```", "> @webia1 You are on a Mac and [macOS is not yet supported](https://github.com/tensorflow/tensorflow/issues/44485#issuecomment-786086270).\r\n\r\n:sob:", "API compatibility test fails:\r\n\r\n```\r\n==================== Test output for //tensorflow/tools/api/tests:api_compatibility_test:\r\nRunning tests under Python 3.9.2: /usr/local/bin/python3.9\r\n[ RUN      ] ApiCompatibilityTest.testAPIBackwardsCompatibility\r\nERROR:tensorflow:TensorFlow API backwards compatibility test\r\nThis test ensures all changes to the public API of TensorFlow are intended.\r\n\r\nIf this test fails, it means a change has been made to the public API. Backwards\r\nincompatible changes are not allowed. You can run the test as follows to update\r\ntest goldens and package them with your change.\r\n\r\n    $ bazel run tensorflow/tools/api/tests:api_compatibility_test \\\r\n    #     -- --update_goldens True\r\n\r\nYou will need an API approval to make changes to the public TensorFlow API. This\r\nincludes additions to the API.\r\n\r\nE0301 10:14:53.017408 140661472663360 api_compatibility_test.py:293] TensorFlow API backwards compatibility test\r\nThis test ensures all changes to the public API of TensorFlow are intended.\r\n\r\nIf this test fails, it means a change has been made to the public API. Backwards\r\nincompatible changes are not allowed. You can run the test as follows to update\r\ntest goldens and package them with your change.\r\n\r\n    $ bazel run tensorflow/tools/api/tests:api_compatibility_test \\\r\n    #     -- --update_goldens True\r\n\r\nYou will need an API approval to make changes to the public TensorFlow API. This\r\nincludes additions to the API.\r\n\r\nERROR:tensorflow:1 differences found between API and golden.\r\nE0301 10:14:53.017659 140661472663360 api_compatibility_test.py:294] 1 differences found between API and golden.\r\nERROR:tensorflow:    Change detected in python object: tensorflow.types.experimental.\r\nE0301 10:14:53.017725 140661472663360 api_compatibility_test.py:315]     Change detected in python object: tensorflow.types.experimental.\r\nERROR:tensorflow:    \r\n  path: \"tensorflow.types.experimental\"\r\n  tf_module {\r\n    member {\r\n      name: \"TensorLike\"\r\n-     mtype: \"typing.Union\"\r\n+     mtype: \"<class \\'typing._UnionGenericAlias\\'>\"\r\n    }\r\n  }\r\n\r\nE0301 10:14:53.017775 140661472663360 api_compatibility_test.py:316]     \r\n  path: \"tensorflow.types.experimental\"\r\n  tf_module {\r\n    member {\r\n      name: \"TensorLike\"\r\n-     mtype: \"typing.Union\"\r\n+     mtype: \"<class \\'typing._UnionGenericAlias\\'>\"\r\n    }\r\n  }\r\n```\r\n\r\ncc @mihaimaruseac \r\n\r\nPatch: https://gist.github.com/99b57ba6c8777dcc958a822a2cd62f49", "The API compatibility tests are brittle around `typing` objects, especially across versions. We have some normalization for Python 3.7, and likely need to repeat it with 3.9. If that's the sole failure you see, you can safely ignore it until it's patched.", "Hi all, just an update FYI. \r\n\r\nI just loaded a TFBertModel in huggingface, and runned finetunning with tensorflow. \r\n- pip 21.0.1\r\n- python 3.9.2\r\n- tf-nightly 2.5.0.dev20210228\r\n- linux kernel zen 5.11.1 (Archlinux)\r\n\r\nHowever, I got errors with cuda but for some light operations on cpu it seems to be working. ", "> The API compatibility tests are brittle around `typing` objects, especially across versions. We have some normalization for Python 3.7, and likely need to repeat it with 3.9. If that's the sole failure you see, you can safely ignore it until it's patched.\r\n\r\n@mdanatg Thanks for the prompt fix! NIT: another test break lies in `//tensorflow/python/module:module_test`\r\n\r\n```\r\n================================================================================\r\n==================== Test output for //tensorflow/python/module:module_test:\r\nRunning tests under Python 3.9.2: /usr/local/bin/python3.9\r\n[ RUN      ] AbcTest.testAbstract\r\nINFO:tensorflow:time(__main__.AbcTest.testAbstract): 0.0s\r\nI0301 10:18:35.056211 140670264665920 test_util.py:2082] time(__main__.AbcTest.testAbstract): 0.0s\r\n[  FAILED  ] AbcTest.testAbstract\r\n[ RUN      ] AbcTest.testConcrete\r\nINFO:tensorflow:time(__main__.AbcTest.testConcrete): 0.0s\r\nI0301 10:18:35.057143 140670264665920 test_util.py:2082] time(__main__.AbcTest.testConcrete): 0.0s\r\n[       OK ] AbcTest.testConcrete\r\n[ RUN      ] AbcTest.test_session\r\n[  SKIPPED ] AbcTest.test_session\r\n[ RUN      ] FlattenTest.test_attribute_traversal_key\r\n2021-03-01 10:18:35.069777: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-03-01 10:18:35.079878: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\r\nINFO:tensorflow:time(__main__.FlattenTest.test_attribute_traversal_key): 0.02s\r\nI0301 10:18:35.080415 140670264665920 test_util.py:2082] time(__main__.FlattenTest.test_attribute_traversal_key): 0.02s\r\n[       OK ] FlattenTest.test_attribute_traversal_key\r\n[ RUN      ] FlattenTest.test_attributes_to_ignore\r\nINFO:tensorflow:time(__main__.FlattenTest.test_attributes_to_ignore): 0.03s\r\nI0301 10:18:35.108479 140670264665920 test_util.py:2082] time(__main__.FlattenTest.test_attributes_to_ignore): 0.03s\r\n[       OK ] FlattenTest.test_attributes_to_ignore\r\n[ RUN      ] FlattenTest.test_flatten(<function FlattenTest.<lambda> at 0x7fee25b8aa60>)\r\nINFO:tensorflow:time(__main__.FlattenTest.test_flatten(<function FlattenTest.<lambda> at 0x7fee25b8aa60>)): 0.0s\r\nI0301 10:18:35.109399 140670264665920 test_util.py:2082] time(__main__.FlattenTest.test_flatten(<function FlattenTest.<lambda> at 0x7fee25b8aa60>)): 0.0s\r\n[       OK ] FlattenTest.test_flatten(<function FlattenTest.<lambda> at 0x7fee25b8aa60>)\r\n[ RUN      ] FlattenTest.test_flatten(<class 'list'>)\r\nINFO:tensorflow:time(__main__.FlattenTest.test_flatten(<class 'list'>)): 0.0s\r\nI0301 10:18:35.110031 140670264665920 test_util.py:2082] time(__main__.FlattenTest.test_flatten(<class 'list'>)): 0.0s\r\n[       OK ] FlattenTest.test_flatten(<class 'list'>)\r\n[ RUN      ] FlattenTest.test_flatten(<class 'tuple'>)\r\nINFO:tensorflow:time(__main__.FlattenTest.test_flatten(<class 'tuple'>)): 0.0s\r\nI0301 10:18:35.110611 140670264665920 test_util.py:2082] time(__main__.FlattenTest.test_flatten(<class 'tuple'>)): 0.0s\r\n[       OK ] FlattenTest.test_flatten(<class 'tuple'>)\r\n[ RUN      ] FlattenTest.test_flatten(<function <lambda> at 0x7fee25b8a940>)\r\nINFO:tensorflow:time(__main__.FlattenTest.test_flatten(<function <lambda> at 0x7fee25b8a940>)): 0.0s\r\nI0301 10:18:35.111363 140670264665920 test_util.py:2082] time(__main__.FlattenTest.test_flatten(<function <lambda> at 0x7fee25b8a940>)): 0.0s\r\n[       OK ] FlattenTest.test_flatten(<function <lambda> at 0x7fee25b8a940>)\r\n[ RUN      ] FlattenTest.test_raises_error_with_path\r\nINFO:tensorflow:time(__main__.FlattenTest.test_raises_error_with_path): 0.0s\r\nI0301 10:18:35.112239 140670264665920 test_util.py:2082] time(__main__.FlattenTest.test_raises_error_with_path): 0.0s\r\n[       OK ] FlattenTest.test_raises_error_with_path\r\n[ RUN      ] FlattenTest.test_session\r\n[  SKIPPED ] FlattenTest.test_session\r\n[ RUN      ] FlattenTest.test_with_path\r\nINFO:tensorflow:time(__main__.FlattenTest.test_with_path): 0.0s\r\nI0301 10:18:35.114492 140670264665920 test_util.py:2082] time(__main__.FlattenTest.test_with_path): 0.0s\r\n[       OK ] FlattenTest.test_with_path\r\n[ RUN      ] ForwardMethodsTest.testEntersNameScope_call\r\n2021-03-01 10:18:35.124874: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\r\n2021-03-01 10:18:35.125344: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2400000000 Hz\r\nINFO:tensorflow:time(__main__.ForwardMethodsTest.testEntersNameScope_call): 0.02s\r\nI0301 10:18:35.132264 140670264665920 test_util.py:2082] time(__main__.ForwardMethodsTest.testEntersNameScope_call): 0.02s\r\n[       OK ] ForwardMethodsTest.testEntersNameScope_call\r\n[ RUN      ] ForwardMethodsTest.testEntersNameScope_concreteFunction\r\nINFO:tensorflow:time(__main__.ForwardMethodsTest.testEntersNameScope_concreteFunction): 0.01s\r\nI0301 10:18:35.138598 140670264665920 test_util.py:2082] time(__main__.ForwardMethodsTest.testEntersNameScope_concreteFunction): 0.01s\r\n[       OK ] ForwardMethodsTest.testEntersNameScope_concreteFunction\r\n[ RUN      ] ForwardMethodsTest.testFunctionType\r\nINFO:tensorflow:time(__main__.ForwardMethodsTest.testFunctionType): 0.0s\r\nI0301 10:18:35.139103 140670264665920 test_util.py:2082] time(__main__.ForwardMethodsTest.testFunctionType): 0.0s\r\n[       OK ] ForwardMethodsTest.testFunctionType\r\n[ RUN      ] ForwardMethodsTest.test_session\r\n[  SKIPPED ] ForwardMethodsTest.test_session\r\n[ RUN      ] ModuleTrackingTest.test_non_ctor_submodule\r\nINFO:tensorflow:time(__main__.ModuleTrackingTest.test_non_ctor_submodule): 0.0s\r\nI0301 10:18:35.140079 140670264665920 test_util.py:2082] time(__main__.ModuleTrackingTest.test_non_ctor_submodule): 0.0s\r\n[       OK ] ModuleTrackingTest.test_non_ctor_submodule\r\n[ RUN      ] ModuleTrackingTest.test_session\r\n[  SKIPPED ] ModuleTrackingTest.test_session\r\n[ RUN      ] ModuleTrackingTest.test_submodules\r\nINFO:tensorflow:time(__main__.ModuleTrackingTest.test_submodules): 0.0s\r\nI0301 10:18:35.141992 140670264665920 test_util.py:2082] time(__main__.ModuleTrackingTest.test_submodules): 0.0s\r\n[       OK ] ModuleTrackingTest.test_submodules\r\n[ RUN      ] NameScopeTest.test_memoized_in_tf2\r\nINFO:tensorflow:time(__main__.NameScopeTest.test_memoized_in_tf2): 0.0s\r\nI0301 10:18:35.142328 140670264665920 test_util.py:2082] time(__main__.NameScopeTest.test_memoized_in_tf2): 0.0s\r\n[       OK ] NameScopeTest.test_memoized_in_tf2\r\n[ RUN      ] NameScopeTest.test_not_memoized_in_tf1\r\nINFO:tensorflow:time(__main__.NameScopeTest.test_not_memoized_in_tf1): 0.0s\r\nI0301 10:18:35.142561 140670264665920 test_util.py:2082] time(__main__.NameScopeTest.test_not_memoized_in_tf1): 0.0s\r\n[  SKIPPED ] NameScopeTest.test_not_memoized_in_tf1\r\n[ RUN      ] NameScopeTest.test_session\r\n[  SKIPPED ] NameScopeTest.test_session\r\n[ RUN      ] TestModuleNaming.test_construct_in_scope\r\nINFO:tensorflow:time(__main__.TestModuleNaming.test_construct_in_scope): 0.0s\r\nI0301 10:18:35.142951 140670264665920 test_util.py:2082] time(__main__.TestModuleNaming.test_construct_in_scope): 0.0s\r\n[       OK ] TestModuleNaming.test_construct_in_scope\r\n[ RUN      ] TestModuleNaming.test_ctor_error_closes_name_scope\r\nINFO:tensorflow:time(__main__.TestModuleNaming.test_ctor_error_closes_name_scope): 0.0s\r\nI0301 10:18:35.143225 140670264665920 test_util.py:2082] time(__main__.TestModuleNaming.test_ctor_error_closes_name_scope): 0.0s\r\n[       OK ] TestModuleNaming.test_ctor_error_closes_name_scope\r\n[ RUN      ] TestModuleNaming.test_ctor_error_handles_ctor_not_opening_name_scope\r\nINFO:tensorflow:time(__main__.TestModuleNaming.test_ctor_error_handles_ctor_not_opening_name_scope): 0.0s\r\nI0301 10:18:35.143461 140670264665920 test_util.py:2082] time(__main__.TestModuleNaming.test_ctor_error_handles_ctor_not_opening_name_scope): 0.0s\r\n[       OK ] TestModuleNaming.test_ctor_error_handles_ctor_not_opening_name_scope\r\n[ RUN      ] TestModuleNaming.test_does_not_evaluate_property_methods\r\nINFO:tensorflow:time(__main__.TestModuleNaming.test_does_not_evaluate_property_methods): 0.0s\r\nI0301 10:18:35.143716 140670264665920 test_util.py:2082] time(__main__.TestModuleNaming.test_does_not_evaluate_property_methods): 0.0s\r\n[       OK ] TestModuleNaming.test_does_not_evaluate_property_methods\r\n[ RUN      ] TestModuleNaming.test_enters_name_scope_in_call\r\nINFO:tensorflow:time(__main__.TestModuleNaming.test_enters_name_scope_in_call): 0.0s\r\nI0301 10:18:35.144006 140670264665920 test_util.py:2082] time(__main__.TestModuleNaming.test_enters_name_scope_in_call): 0.0s\r\n[       OK ] TestModuleNaming.test_enters_name_scope_in_call\r\n[ RUN      ] TestModuleNaming.test_enters_name_scope_in_other_method\r\nINFO:tensorflow:time(__main__.TestModuleNaming.test_enters_name_scope_in_other_method): 0.0s\r\nI0301 10:18:35.144288 140670264665920 test_util.py:2082] time(__main__.TestModuleNaming.test_enters_name_scope_in_other_method): 0.0s\r\n[       OK ] TestModuleNaming.test_enters_name_scope_in_other_method\r\n[ RUN      ] TestModuleNaming.test_forward_method_closes_name_scope\r\nINFO:tensorflow:time(__main__.TestModuleNaming.test_forward_method_closes_name_scope): 0.0s\r\nI0301 10:18:35.144543 140670264665920 test_util.py:2082] time(__main__.TestModuleNaming.test_forward_method_closes_name_scope): 0.0s\r\n[       OK ] TestModuleNaming.test_forward_method_closes_name_scope\r\n[ RUN      ] TestModuleNaming.test_get_attr_doesnt_enter_name_scope\r\nINFO:tensorflow:time(__main__.TestModuleNaming.test_get_attr_doesnt_enter_name_scope): 0.0s\r\nI0301 10:18:35.144858 140670264665920 test_util.py:2082] time(__main__.TestModuleNaming.test_get_attr_doesnt_enter_name_scope): 0.0s\r\n[       OK ] TestModuleNaming.test_get_attr_doesnt_enter_name_scope\r\n[ RUN      ] TestModuleNaming.test_get_attribute_doesnt_enter_name_scope\r\nINFO:tensorflow:time(__main__.TestModuleNaming.test_get_attribute_doesnt_enter_name_scope): 0.0s\r\nI0301 10:18:35.145172 140670264665920 test_util.py:2082] time(__main__.TestModuleNaming.test_get_attribute_doesnt_enter_name_scope): 0.0s\r\n[       OK ] TestModuleNaming.test_get_attribute_doesnt_enter_name_scope\r\n[ RUN      ] TestModuleNaming.test_invalid_name\r\nINFO:tensorflow:time(__main__.TestModuleNaming.test_invalid_name): 0.0s\r\nI0301 10:18:35.145528 140670264665920 test_util.py:2082] time(__main__.TestModuleNaming.test_invalid_name): 0.0s\r\n[       OK ] TestModuleNaming.test_invalid_name\r\n[ RUN      ] TestModuleNaming.test_module_numbering_in_graph\r\nWARNING:tensorflow:From /usr/local/lib/python3.9/contextlib.py:87: TensorFlowTestCase.test_session (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `self.session()` or `self.cached_session()` instead.\r\nW0301 10:18:35.145755 140670264665920 deprecation.py:330] From /usr/local/lib/python3.9/contextlib.py:87: TensorFlowTestCase.test_session (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `self.session()` or `self.cached_session()` instead.\r\nINFO:tensorflow:time(__main__.TestModuleNaming.test_module_numbering_in_graph): 0.01s\r\nI0301 10:18:35.159946 140670264665920 test_util.py:2082] time(__main__.TestModuleNaming.test_module_numbering_in_graph): 0.01s\r\nINFO:tensorflow:time(__main__.TestModuleNaming.test_module_numbering_in_graph): 0.0s\r\nI0301 10:18:35.160279 140670264665920 test_util.py:2082] time(__main__.TestModuleNaming.test_module_numbering_in_graph): 0.0s\r\n[  SKIPPED ] TestModuleNaming.test_module_numbering_in_graph\r\n[ RUN      ] TestModuleNaming.test_modules_not_numbered_in_eager\r\nINFO:tensorflow:time(__main__.TestModuleNaming.test_modules_not_numbered_in_eager): 0.0s\r\nI0301 10:18:35.160827 140670264665920 test_util.py:2082] time(__main__.TestModuleNaming.test_modules_not_numbered_in_eager): 0.0s\r\nINFO:tensorflow:time(__main__.TestModuleNaming.test_modules_not_numbered_in_eager): 0.0s\r\nI0301 10:18:35.162637 140670264665920 test_util.py:2082] time(__main__.TestModuleNaming.test_modules_not_numbered_in_eager): 0.0s\r\n[       OK ] TestModuleNaming.test_modules_not_numbered_in_eager\r\n[ RUN      ] TestModuleNaming.test_overridden_name_scope\r\nINFO:tensorflow:time(__main__.TestModuleNaming.test_overridden_name_scope): 0.0s\r\nI0301 10:18:35.163025 140670264665920 test_util.py:2082] time(__main__.TestModuleNaming.test_overridden_name_scope): 0.0s\r\n[       OK ] TestModuleNaming.test_overridden_name_scope\r\n[ RUN      ] TestModuleNaming.test_patched_callable\r\nINFO:tensorflow:time(__main__.TestModuleNaming.test_patched_callable): 0.0s\r\nI0301 10:18:35.163293 140670264665920 test_util.py:2082] time(__main__.TestModuleNaming.test_patched_callable): 0.0s\r\n[       OK ] TestModuleNaming.test_patched_callable\r\n[ RUN      ] TestModuleNaming.test_property\r\nINFO:tensorflow:time(__main__.TestModuleNaming.test_property): 0.0s\r\nI0301 10:18:35.163604 140670264665920 test_util.py:2082] time(__main__.TestModuleNaming.test_property): 0.0s\r\n[       OK ] TestModuleNaming.test_property\r\n[ RUN      ] TestModuleNaming.test_property_no_name_scope\r\nINFO:tensorflow:time(__main__.TestModuleNaming.test_property_no_name_scope): 0.0s\r\nI0301 10:18:35.163878 140670264665920 test_util.py:2082] time(__main__.TestModuleNaming.test_property_no_name_scope): 0.0s\r\n[       OK ] TestModuleNaming.test_property_no_name_scope\r\n[ RUN      ] TestModuleNaming.test_session\r\n[  SKIPPED ] TestModuleNaming.test_session\r\n[ RUN      ] TestModuleNaming.test_single_name\r\nINFO:tensorflow:time(__main__.TestModuleNaming.test_single_name): 0.0s\r\nI0301 10:18:35.164222 140670264665920 test_util.py:2082] time(__main__.TestModuleNaming.test_single_name): 0.0s\r\n[       OK ] TestModuleNaming.test_single_name\r\n[ RUN      ] TestModuleNaming.test_subclassed_module\r\nINFO:tensorflow:time(__main__.TestModuleNaming.test_subclassed_module): 0.0s\r\nI0301 10:18:35.164546 140670264665920 test_util.py:2082] time(__main__.TestModuleNaming.test_subclassed_module): 0.0s\r\n[       OK ] TestModuleNaming.test_subclassed_module\r\n[ RUN      ] TestModuleNaming.test_submodule_created_late\r\nINFO:tensorflow:time(__main__.TestModuleNaming.test_submodule_created_late): 0.0s\r\nI0301 10:18:35.164953 140670264665920 test_util.py:2082] time(__main__.TestModuleNaming.test_submodule_created_late): 0.0s\r\n[       OK ] TestModuleNaming.test_submodule_created_late\r\n[ RUN      ] VariableNamingTest.test_session\r\n[  SKIPPED ] VariableNamingTest.test_session\r\n[ RUN      ] VariableNamingTest.test_variable_names\r\nINFO:tensorflow:time(__main__.VariableNamingTest.test_variable_names): 0.0s\r\nI0301 10:18:35.166484 140670264665920 test_util.py:2082] time(__main__.VariableNamingTest.test_variable_names): 0.0s\r\n[       OK ] VariableNamingTest.test_variable_names\r\n[ RUN      ] VariableTrackingTest.test_composite_variable\r\nINFO:tensorflow:time(__main__.VariableTrackingTest.test_composite_variable): 0.0s\r\nI0301 10:18:35.168788 140670264665920 test_util.py:2082] time(__main__.VariableTrackingTest.test_composite_variable): 0.0s\r\n[       OK ] VariableTrackingTest.test_composite_variable\r\n[ RUN      ] VariableTrackingTest.test_session\r\n[  SKIPPED ] VariableTrackingTest.test_session\r\n[ RUN      ] VariableTrackingTest.test_supports_distributed_variables\r\nINFO:tensorflow:time(__main__.VariableTrackingTest.test_supports_distributed_variables): 0.0s\r\nI0301 10:18:35.171150 140670264665920 test_util.py:2082] time(__main__.VariableTrackingTest.test_supports_distributed_variables): 0.0s\r\n[       OK ] VariableTrackingTest.test_supports_distributed_variables\r\n[ RUN      ] VariableTrackingTest.test_trainable_variables\r\nINFO:tensorflow:time(__main__.VariableTrackingTest.test_trainable_variables): 0.0s\r\nI0301 10:18:35.173183 140670264665920 test_util.py:2082] time(__main__.VariableTrackingTest.test_trainable_variables): 0.0s\r\n[       OK ] VariableTrackingTest.test_trainable_variables\r\n[ RUN      ] VariableTrackingTest.test_trainable_variables_ignores_non_trainable\r\nINFO:tensorflow:time(__main__.VariableTrackingTest.test_trainable_variables_ignores_non_trainable): 0.0s\r\nI0301 10:18:35.174891 140670264665920 test_util.py:2082] time(__main__.VariableTrackingTest.test_trainable_variables_ignores_non_trainable): 0.0s\r\n[       OK ] VariableTrackingTest.test_trainable_variables_ignores_non_trainable\r\n[ RUN      ] VariableTrackingTest.test_variables\r\nINFO:tensorflow:time(__main__.VariableTrackingTest.test_variables): 0.0s\r\nI0301 10:18:35.176566 140670264665920 test_util.py:2082] time(__main__.VariableTrackingTest.test_variables): 0.0s\r\n[       OK ] VariableTrackingTest.test_variables\r\n======================================================================\r\nFAIL: testAbstract (__main__.AbcTest)\r\ntestAbstract (__main__.AbcTest)\r\n----------------------------------------------------------------------\r\nTypeError: Can't instantiate abstract class AbstractModule with abstract method __call__\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/buildfarm/default/operations/52eafc82-3509-47a0-ad8a-d565ef4de86b/bazel-out/k8-opt/bin/tensorflow/python/module/module_test.runfiles/org_tensorflow/tensorflow/python/module/module_test.py\", line 340, in testAbstract\r\n    AbstractModule()  # pylint: disable=abstract-class-instantiated\r\nAssertionError: \"Can't instantiate .* abstract methods\" does not match \"Can't instantiate abstract class AbstractModule with abstract method __call__\"\r\n\r\n----------------------------------------------------------------------\r\nRan 50 tests in 0.121s\r\n\r\nFAILED (failures=1, skipped=10)\r\n```", "That one looks like a bad test - the check for the error message is too specific and breaks when the error message changes. If anyone is interested in sending t a patch, the fix is straightforward - just update the regex at line 339.", "@mdanatg I can open a PR for it", "@byronyi @mdanatg https://github.com/tensorflow/tensorflow/pull/47512 should fix the test failure", "```\r\n==================== Test output for //tensorflow/tools/api/tests:api_compatibility_test:\r\nRunning tests under Python 3.9.2: /usr/local/bin/python3.9\r\n[ RUN      ] ApiCompatibilityTest.testAPIBackwardsCompatibility\r\nINFO:tensorflow:No differences found between API and golden.\r\nI0303 01:00:03.331312 140083892332352 api_compatibility_test.py:321] No differences found between API and golden.\r\nINFO:tensorflow:time(__main__.ApiCompatibilityTest.testAPIBackwardsCompatibility): 2.64s\r\nI0303 01:00:03.337718 140083892332352 test_util.py:2082] time(__main__.ApiCompatibilityTest.testAPIBackwardsCompatibility): 2.64s\r\n[       OK ] ApiCompatibilityTest.testAPIBackwardsCompatibility\r\n[ RUN      ] ApiCompatibilityTest.testAPIBackwardsCompatibilityV1\r\n\r\nERROR:tensorflow:TensorFlow API backwards compatibility test\r\nThis test ensures all changes to the public API of TensorFlow are intended.\r\n\r\nIf this test fails, it means a change has been made to the public API. Backwards\r\nincompatible changes are not allowed. You can run the test as follows to update\r\ntest goldens and package them with your change.\r\n\r\n    $ bazel run tensorflow/tools/api/tests:api_compatibility_test \\\r\n    #     -- --update_goldens True\r\n\r\nYou will need an API approval to make changes to the public TensorFlow API. This\r\nincludes additions to the API.\r\n\r\nE0303 01:00:06.100362 140083892332352 api_compatibility_test.py:293] TensorFlow API backwards compatibility test\r\nThis test ensures all changes to the public API of TensorFlow are intended.\r\n\r\nIf this test fails, it means a change has been made to the public API. Backwards\r\nincompatible changes are not allowed. You can run the test as follows to update\r\ntest goldens and package them with your change.\r\n\r\n    $ bazel run tensorflow/tools/api/tests:api_compatibility_test \\\r\n    #     -- --update_goldens True\r\n\r\nYou will need an API approval to make changes to the public TensorFlow API. This\r\nincludes additions to the API.\r\n\r\nERROR:tensorflow:1 differences found between API and golden.\r\nE0303 01:00:06.100567 140083892332352 api_compatibility_test.py:294] 1 differences found between API and golden.\r\nERROR:tensorflow:    Change detected in python object: tensorflow.train.LooperThread.\r\nE0303 01:00:06.100632 140083892332352 api_compatibility_test.py:315]     Change detected in python object: tensorflow.train.LooperThread.\r\nERROR:tensorflow:    \r\n  path: \"tensorflow.train.LooperThread\"\r\n  tf_class {\r\n    is_instance: \"<class \\'tensorflow.python.training.coordinator.LooperThread\\'>\"\r\n    is_instance: \"<class \\'threading.Thread\\'>\"\r\n    member {\r\n      name: \"daemon\"\r\n      mtype: \"<type \\'property\\'>\"\r\n    }\r\n    member {\r\n      name: \"ident\"\r\n      mtype: \"<type \\'property\\'>\"\r\n    }\r\n    member {\r\n      name: \"name\"\r\n      mtype: \"<type \\'property\\'>\"\r\n    }\r\n    member_method {\r\n      name: \"__init__\"\r\n      argspec: \"args=[\\'self\\', \\'coord\\', \\'timer_interval_secs\\', \\'target\\', \\'args\\', \\'kwargs\\'], varargs=None, keywords=None, defaults=[\\'None\\', \\'None\\', \\'None\\'], \"\r\n    }\r\n    member_method {\r\n      name: \"getName\"\r\n-     argspec: \"args=[\\'self\\'], varargs=None, keywords=None, defaults=None\"\r\n-   }\r\n-   member_method {\r\n-     name: \"isAlive\"\r\n      argspec: \"args=[\\'self\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n    member_method {\r\n      name: \"isDaemon\"\r\n      argspec: \"args=[\\'self\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n    member_method {\r\n      name: \"is_alive\"\r\n      argspec: \"args=[\\'self\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n    member_method {\r\n      name: \"loop\"\r\n      argspec: \"args=[\\'coord\\', \\'timer_interval_secs\\', \\'target\\', \\'args\\', \\'kwargs\\'], varargs=None, keywords=None, defaults=[\\'None\\', \\'None\\'], \"\r\n    }\r\n    member_method {\r\n      name: \"run\"\r\n      argspec: \"args=[\\'self\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n    member_method {\r\n      name: \"run_loop\"\r\n      argspec: \"args=[\\'self\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n    member_method {\r\n      name: \"setDaemon\"\r\n      argspec: \"args=[\\'self\\', \\'daemonic\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n    member_method {\r\n      name: \"setName\"\r\n      argspec: \"args=[\\'self\\', \\'name\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n    member_method {\r\n      name: \"start\"\r\n      argspec: \"args=[\\'self\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n    member_method {\r\n      name: \"start_loop\"\r\n      argspec: \"args=[\\'self\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n    member_method {\r\n      name: \"stop_loop\"\r\n      argspec: \"args=[\\'self\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n  }\r\n\r\nE0303 01:00:06.100685 140083892332352 api_compatibility_test.py:316]     \r\n  path: \"tensorflow.train.LooperThread\"\r\n  tf_class {\r\n    is_instance: \"<class \\'tensorflow.python.training.coordinator.LooperThread\\'>\"\r\n    is_instance: \"<class \\'threading.Thread\\'>\"\r\n    member {\r\n      name: \"daemon\"\r\n      mtype: \"<type \\'property\\'>\"\r\n    }\r\n    member {\r\n      name: \"ident\"\r\n      mtype: \"<type \\'property\\'>\"\r\n    }\r\n    member {\r\n      name: \"name\"\r\n      mtype: \"<type \\'property\\'>\"\r\n    }\r\n    member_method {\r\n      name: \"__init__\"\r\n      argspec: \"args=[\\'self\\', \\'coord\\', \\'timer_interval_secs\\', \\'target\\', \\'args\\', \\'kwargs\\'], varargs=None, keywords=None, defaults=[\\'None\\', \\'None\\', \\'None\\'], \"\r\n    }\r\n    member_method {\r\n      name: \"getName\"\r\n-     argspec: \"args=[\\'self\\'], varargs=None, keywords=None, defaults=None\"\r\n-   }\r\n-   member_method {\r\n-     name: \"isAlive\"\r\n      argspec: \"args=[\\'self\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n    member_method {\r\n      name: \"isDaemon\"\r\n      argspec: \"args=[\\'self\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n    member_method {\r\n      name: \"is_alive\"\r\n      argspec: \"args=[\\'self\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n    member_method {\r\n      name: \"loop\"\r\n      argspec: \"args=[\\'coord\\', \\'timer_interval_secs\\', \\'target\\', \\'args\\', \\'kwargs\\'], varargs=None, keywords=None, defaults=[\\'None\\', \\'None\\'], \"\r\n    }\r\n    member_method {\r\n      name: \"run\"\r\n      argspec: \"args=[\\'self\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n    member_method {\r\n      name: \"run_loop\"\r\n      argspec: \"args=[\\'self\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n    member_method {\r\n      name: \"setDaemon\"\r\n      argspec: \"args=[\\'self\\', \\'daemonic\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n    member_method {\r\n      name: \"setName\"\r\n      argspec: \"args=[\\'self\\', \\'name\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n    member_method {\r\n      name: \"start\"\r\n      argspec: \"args=[\\'self\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n    member_method {\r\n      name: \"start_loop\"\r\n      argspec: \"args=[\\'self\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n    member_method {\r\n      name: \"stop_loop\"\r\n      argspec: \"args=[\\'self\\'], varargs=None, keywords=None, defaults=None\"\r\n    }\r\n  }\r\n\r\nINFO:tensorflow:time(__main__.ApiCompatibilityTest.testAPIBackwardsCompatibilityV1): 2.76s\r\nI0303 01:00:06.100801 140083892332352 test_util.py:2082] time(__main__.ApiCompatibilityTest.testAPIBackwardsCompatibilityV1): 2.76s\r\n[  FAILED  ] ApiCompatibilityTest.testAPIBackwardsCompatibilityV1\r\n[ RUN      ] ApiCompatibilityTest.testAPIBackwardsCompatibilityV2\r\nINFO:tensorflow:No differences found between API and golden.\r\nI0303 01:00:08.738246 140083892332352 api_compatibility_test.py:321] No differences found between API and golden.\r\nINFO:tensorflow:time(__main__.ApiCompatibilityTest.testAPIBackwardsCompatibilityV2): 2.64s\r\nI0303 01:00:08.744600 140083892332352 test_util.py:2082] time(__main__.ApiCompatibilityTest.testAPIBackwardsCompatibilityV2): 2.64s\r\n[       OK ] ApiCompatibilityTest.testAPIBackwardsCompatibilityV2\r\n[ RUN      ] ApiCompatibilityTest.testNoSubclassOfMessage\r\nINFO:tensorflow:time(__main__.ApiCompatibilityTest.testNoSubclassOfMessage): 0.34s\r\nI0303 01:00:09.094376 140083892332352 test_util.py:2082] time(__main__.ApiCompatibilityTest.testNoSubclassOfMessage): 0.34s\r\n[       OK ] ApiCompatibilityTest.testNoSubclassOfMessage\r\n[ RUN      ] ApiCompatibilityTest.testNoSubclassOfMessageV1\r\nINFO:tensorflow:time(__main__.ApiCompatibilityTest.testNoSubclassOfMessageV1): 0.34s\r\nI0303 01:00:09.430554 140083892332352 test_util.py:2082] time(__main__.ApiCompatibilityTest.testNoSubclassOfMessageV1): 0.34s\r\n[       OK ] ApiCompatibilityTest.testNoSubclassOfMessageV1\r\n[ RUN      ] ApiCompatibilityTest.testNoSubclassOfMessageV2\r\nINFO:tensorflow:time(__main__.ApiCompatibilityTest.testNoSubclassOfMessageV2): 0.32s\r\nI0303 01:00:09.751907 140083892332352 test_util.py:2082] time(__main__.ApiCompatibilityTest.testNoSubclassOfMessageV2): 0.32s\r\n[       OK ] ApiCompatibilityTest.testNoSubclassOfMessageV2\r\n[ RUN      ] ApiCompatibilityTest.test_session\r\n[  SKIPPED ] ApiCompatibilityTest.test_session\r\n======================================================================\r\nFAIL: testAPIBackwardsCompatibilityV1 (__main__.ApiCompatibilityTest)\r\ntestAPIBackwardsCompatibilityV1 (__main__.ApiCompatibilityTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/buildfarm/default/operations/7d0cf0f7-4e69-4535-a932-0a1eee6aad4f/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/tools/api/tests/api_compatibility_test.py\", line 440, in testAPIBackwardsCompatibilityV1\r\n    self._checkBackwardsCompatibility(\r\n  File \"/buildfarm/default/operations/7d0cf0f7-4e69-4535-a932-0a1eee6aad4f/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/tools/api/tests/api_compatibility_test.py\", line 400, in _checkBackwardsCompatibility\r\n    self._AssertProtoDictEquals(\r\n  File \"/buildfarm/default/operations/7d0cf0f7-4e69-4535-a932-0a1eee6aad4f/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/org_tensorflow/tensorflow/tools/api/tests/api_compatibility_test.py\", line 318, in _AssertProtoDictEquals\r\n    self.fail('%d differences found between API and golden.' % diff_count)\r\n  File \"/buildfarm/default/operations/7d0cf0f7-4e69-4535-a932-0a1eee6aad4f/bazel-out/k8-opt/bin/tensorflow/tools/api/tests/api_compatibility_test.runfiles/absl_py/absl/testing/absltest.py\", line 1704, in fail\r\n    return super(TestCase, self).fail(self._formatMessage(prefix, msg))\r\nAssertionError: 1 differences found between API and golden.\r\n\r\n----------------------------------------------------------------------\r\nRan 7 tests in 9.058s\r\n\r\nFAILED (failures=1, skipped=1)\r\n```\r\n\r\nI ran Python 3.6-3.8 tests prior to Python 3.9 and all passed.\r\n\r\n/cc @mdanatg ", "It's a v1 test so may not be that important. Context: https://bugs.python.org/issue37804", "Makes sene. Looks like that test is brittle, too. It seems that the symbol is already special-cased by the test: https://github.com/tensorflow/tensorflow/blob/27cb1e3e60d03be9262351795f46690ada5797e3/tensorflow/tools/api/lib/python_object_to_proto_visitor.py#L48\r\n\r\nPerhaps just adding isAlive in there will be sufficient.", "Any updates on this issue? I am unable to install Tensorflow in my windows py 3.9", "> Any updates on this issue? I am unable to install Tensorflow in my windows py 3.9\n\nHave you tried with tf-nightly?", "TF nightly now has support for python 3.9 on all 3 operating systems.\r\n\r\nPlease test it and report failures. We'll try to get them fixed before the next release.\r\n\r\nKeeping this open until next release. Branch cut is in 2 weeks and maybe 4 more weeks of RCs after that, so likely near the end of April.", "@mihaimaruseac As It is quite popular can we pin this issue in the meantime? What do you think?", "Great news!  Can we start testing on [Python 3.10.0 alpha 6](https://www.python.org/downloads/release/python-3100a6/)?  It would be good to have a shorter ramp up next time.", "The largest part of the ramp up is because of upstream dependencies. TF cannot build until they can build with the new version of Python. In particular, numpy, protobuf, grpc are the main delayers.", "But tf nightly is not getting imported . I am getting ModuleNotFoundError", "@ShyamSundhar1411 this looks like a different issue. Make sure you use the same python as the one used to do `pip install`. Recommendation is to use `python -m pip install` instead of `pip install`.\r\n\r\nIf the above does not fix, please open a new issue and fill in issue template and give a full description of the error you are seeing. Also, give output of both `python -m pip install`", "_Explicit is better than implicit..._`python3.9 -m pip install xyz`", "@mihaimaruseac this is marked for TF 2.5 but there is no mention of it on the current [release notes](https://github.com/tensorflow/tensorflow/blob/master/RELEASE.md).", "RC0 [files](https://pypi.org/project/tensorflow/2.5.0rc0/#files) already contain Py3.9 wheels.\r\n\r\nWe'll update the release notes, it seems we don't always mention support for new versions of Python in there.", "I think this is fixed now.", "Is Keras module that exists in tensorflow supported in python 3.9?", "@mihaimaruseac Seems like this issue can be closed.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44485\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44485\">No</a>\n"]}, {"number": 44484, "title": "Fix the absl module not found error", "body": "ToT workarounds the absl module not found error by using $CMAKE_MODULE_PATH,\r\nbut this is still likely to fail due to the fact that $CMAKE_MODULE_PATH is\r\na semicolon-separated list of directories specifying a search path for CMake\r\nmodules. In fact, if we set more than one path to $CMAKE_MODULE_PATH, the absl\r\nmodule not found error occurs. This patch solves the problem by give |absl_DIR|\r\nthe unique CMake module path in the source tree.", "comments": []}, {"number": 44483, "title": "Error after installing tensorflow", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1.  It must be a bug, a feature request, or a significant problem with the\r\n    documentation (for small docs fixes please send a PR instead).\r\n2.  The form below must be filled out.\r\n3.  It shouldn't be a TensorBoard issue. Those go\r\n    [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**:\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**:\r\n-   **TensorFlow installed from (source or binary)**: installed via pip3\r\n-   **TensorFlow version (use command below)**: tensorflow-2.3.1\r\n-   **Python version**: Python3.5\r\n-   **Bazel version (if compiling from source)**: -\r\n-   **GCC/Compiler version (if compiling from source)**: -\r\n-   **CUDA/cuDNN version**: -\r\n-   **GPU model and memory**: -\r\n-   **Exact command to reproduce**: import tensorflow as tf\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\n\r\n### Describe the problem\r\n\r\nHello,\r\nI have just installed tensorflow on my laptop which uses Ubuntu 16.04 and i installed it via pip3.\r\nI just wanted to test if its working properly but even just the import resulted in following error message:\r\n\r\n2020-10-31 18:31:40.413625: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/ros/kinetic/lib:/opt/ros/kinetic/lib/x86_64-linux-gnu\r\n2020-10-31 18:31:40.413651: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n\r\nHave i done something wrong when i installed it?\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["@Herminello \r\nPlease refer to [this comment](https://github.com/tensorflow/tensorflow/issues/38164#issuecomment-656767462) and let us know if this issue helps.\r\nPlease refer to [this comment](https://github.com/tensorflow/tensorflow/issues/44040#issuecomment-714817292) if you are using GeForce GTX.\r\nand #38578 , please refer to [this guide](https://github.com/tensorflow/tensorflow/issues/26182#issuecomment-469400322) and let us know.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44483\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44483\">No</a>\n"]}, {"number": 44482, "title": "tf.logging documentation leads to 404", "body": "## URL(s) with the issue:\r\nAs far as I can tell all articles describing tf.logging namespace. Such as:\r\n[https://www.tensorflow.org/api_docs/python/tf/logging/TaskLevelStatusMessage](https://www.tensorflow.org/api_docs/python/tf/logging/TaskLevelStatusMessage)\r\nor\r\n[https://www.tensorflow.org/api_docs/python/tf/logging](https://www.tensorflow.org/api_docs/python/tf/logging)\r\n\r\n## Description of issue (what needs changing):\r\nDespite showing up in search results these articles are not accessible. \r\n\r\n### Clear description\r\nSearch results for `logging` and related queries contain links to nonexistent articles. \r\nLeading to confusion and potentially avoidable issues. \r\n\r\n### Submit a pull request?\r\n\r\nNot at this time. \r\n", "comments": ["@jpodivin tf.logging doesn't exist in TF2.x. Please check [this issue](https://github.com/tensorflow/tensorflow/issues/26662#issuecomment-505913656) for more info.\r\n\r\nI think we need to update that page. Where did you find links to those two pages? \r\n\r\nIf someone wants to use it then import it from `tf.compat.v1.logging`. Thanks!\r\n\r\nWe will check this and update webpage accordingly. Thanks!", "@jvishnuvardhan I was looking into how logging works in Tensorflow. And if you search official docs it comes up among first results:\r\n![image](https://user-images.githubusercontent.com/66251151/97800813-96e0e700-1c38-11eb-86e2-9fa00458186e.png)\r\n\r\nI thought it might have been coincidence so I tried to find more about the module, only to run into more 404s and that's pretty much when I decided to post this issue. ", "@jpodivin Agree with you. I am seeing the same search results. I am not sure why those pages are picked up in the search.\r\n\r\n@MarkDaoust Any idea why search results are picking \"404\" error pages? Thanks!", "I'l often surprised how long 404s stick around in there. That's just google search.\r\nI've submitted a request to clear out those URLs, IDK how long that will take to activate."]}, {"number": 44480, "title": "[Documentation] Update missing comma on Sample Code (keras guideline) ", "body": "**Tensorflow Documentation**\r\n\r\n- Update missing comma on sample code (Section: Create a model using high-level tf.keras.* APIs)", "comments": []}, {"number": 44479, "title": "Update Documentation: missing comma (keras guideline)", "body": "**Tensorflow Documentation**\r\n\r\n- Update missing comma on sample code (Section: Create a model using high-level tf.keras.* APIs)", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F44479) for more info**.\n\n<!-- need_sender_cla -->", "@wdharmana  Can you please sign CLA. Thanks!", "@wdharmana  You have created another PR [#44496](https://github.com/tensorflow/tensorflow/pull/44496) with cla is yes. Hence closing this PR. ", "@gbaned thank you, please refer to PR #44496. "]}, {"number": 44478, "title": "I can't use tensorflow very well by using RTX 3090,When will you updata your new version to support the new RTX3090?", "body": "I can't use tensorflow very well by using RTX 3090,When will you updata your version to support the new RTX3090?\r\n![666](https://user-images.githubusercontent.com/73739019/97775960-a5f26700-1b5c-11eb-8cdd-f54eae8ee9d4.png)\r\n\r\n", "comments": ["I have the same problem.", "@lightlefter \r\nplease refer tot he issues in [this comment](https://github.com/tensorflow/tensorflow/issues/44490#issuecomment-720277302) regarding \"RTX 3090\" and let us know.", "> \u6211\u4e5f\u6709\u540c\u6837\u7684\u95ee\u9898\u3002\r\n\r\n\r\n\r\n> I have the same problem.\r\n\r\nI had deal with this problem,you need use tf2 command to restrain video memory", "@lightlefter \r\nPlease move the issue to closed status if resolved.", "> @lightlefter\r\n> Please move the issue to closed status if resolved.\r\n\r\nOK", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44478\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44478\">No</a>\n", "fine"]}, {"number": 44477, "title": "[TF-numpy] Add docstring in `np.random`", "body": "Thank you", "comments": ["@marload  Can you please check @wangpengmit's comments and keep us posted ? Thanks!", "@marload  Any update on this PR? Please. Thanks!", "This PR is probably safe to close, if @marload you don't object.", "@marload Can you please check @wangpengmit's comments and keep us posted ? Thanks!\r\n\r\n", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 44476, "title": "tensorflow.contrib.image import transform as H_transform", "body": "where is tensorflow.contrib.image import transform in tensorflow2.0?", "comments": ["@gpsherry \r\n\r\ntf.contrib.image.transform and tf.contrib.image.compose_transform are now part of the [tensorflow_addons.image](https://github.com/tensorflow/addons/blob/master/tensorflow_addons/image/README.md) module.\r\nPlease, refer #33335, [SO link](https://stackoverflow.com/questions/58288465/the-equivalent-of-tf-contrib-image-transform-in-tensorflow-2-0) and see if it helps you. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 44475, "title": "[TF-numpy] Implementation `np.random.poisson`", "body": "https://numpy.org/doc/stable/reference/random/generated/numpy.random.poisson.html?highlight=poisson#numpy.random.poisson", "comments": []}, {"number": 44474, "title": "[TF-numpy] Implementation `np.random.standard_normal`", "body": "https://numpy.org/doc/stable/reference/random/generated/numpy.random.standard_normal.html", "comments": ["Merged. Forgot to say, thanks for this PR!"]}, {"number": 44473, "title": "How can I clear GPU memory in tensorflow 2.2?", "body": "", "comments": ["@GF-Huang,\r\nBy default, TensorFlow maps nearly all of the GPU memory of all GPUs (subject to CUDA_VISIBLE_DEVICES) visible to the process. For more information, please take a look at this [guide](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth). \r\n\r\nTo clear GPU memory, you'll have to restart the Python interpreter. Please check similar issue [#17048](https://github.com/tensorflow/tensorflow/issues/17048) for reference. Thanks!"]}]