[{"number": 54832, "title": "Not able to cluster Conv1DTranspose layer", "body": "Hi, \r\n\r\nI am using this code for clustering the conv1d layers.\r\n\r\n```\r\n`# Create a base model\r\nbase_model = setup_model()\r\nbase_model.load_weights(pretrained_weights)\r\n\r\n\r\ndef apply_clustering_to_dense(layer):\r\n  if isinstance(layer, tf.keras.layers.Conv1D):\r\n    return cluster_weights(layer, **clustering_params)\r\n  return layer\r\n\r\nclustered_model = tf.keras.models.clone_model(\r\n    base_model,\r\n    clone_function=apply_clustering_to_dense,\r\n)`\r\n```\r\n\r\nI am getting below error. Is Conv1DTranspose clustering is possible or not? Can anyone suggest how to solve this.\r\n \r\n**`Please initialize `Cluster` with a supported layer. Layers should either be a `ClusterableLayer` instance, or should be supported by the ClusteringRegistry. You passed: <class 'keras.layers.convolutional.Conv1DTranspose'>`**\r\n\r\n\r\n--------------------------------------------------------------------------------------\r\n<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.6.0\r\n- Python version: 3.8.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"` : v2.6.0-rc2-32-g919f693420e 2.6.0\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): yes\r\n- Briefly describe your candidate solution(if contributing): \r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@rameshkunasi \r\nIn order to expedite the trouble-shooting process here,Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose),\r\nThanks!", "@sushreebarsa - Updated in the template format", "@rameshkunasi \r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!", "@sushreebarsa \r\n\r\nBelow is the code snippet to reproduce the issue.\r\n\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow_model_optimization as tfmot\r\n\r\ncluster_weights = tfmot.clustering.keras.cluster_weights\r\nCentroidInitialization = tfmot.clustering.keras.CentroidInitialization\r\n\r\ntime_dat = tf.keras.layers.Input(batch_shape=(1, 16000))\r\nx1 = tf.keras.layers.Conv1D(10, 256, 64, padding = \"valid\",use_bias=False)(tf.expand_dims(time_dat, axis=-1))\r\nx2 = tf.keras.layers.Conv1DTranspose(1, 256, 64, padding = \"valid\",use_bias=False)(x1)\r\nmodel = tf.keras.models.Model(inputs=time_dat, outputs=[x2])\r\n\r\nclustering_params = {\r\n  'number_of_clusters': 50,\r\n  'cluster_centroids_init': CentroidInitialization.LINEAR\r\n}\r\n\r\ndef apply_clustering_to_dense(layer):\r\n  if isinstance(layer, tf.keras.layers.Conv1D):\r\n    return cluster_weights(layer, **clustering_params)\r\n  return layer\r\n\r\nclustered_model = tf.keras.models.clone_model(\r\n    model,\r\n    clone_function=apply_clustering_to_dense,\r\n)\r\n```", "@rameshkunasi Sorry for the late response!\r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\nThanks!", "@sushreebarsa , Can you please add this as a serious issue?", "@rameshkunasi Could you please move this issue to close status as we are tracking the other ticket in keras-team/keras repo?\r\nThanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54832\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54832\">No</a>\n"]}, {"number": 54831, "title": "[mhlo] Phase II: Remove tuples from mhlo Infeed/Outfeed Ops.", "body": "[mhlo] Phase II: Remove tuples from mhlo Infeed/Outfeed Ops.\n\nThe CL does the following:\n1. Added mhlo verifiers to ascertain that the imported structure of the layout is as expected.\n2. Modified the tf lowering (new/old bridge) or jax lowering for infeed/outfeed op in this CL to generate the non-tuple variant of infeed op.\n", "comments": []}, {"number": 54830, "title": "Added support of short/ushort/char/uchar textures in MetalArguments.", "body": "Added support of short/ushort/char/uchar textures in MetalArguments.\n", "comments": []}, {"number": 54829, "title": "Add regression test demonstrating a codegen bug.", "body": "Add regression test demonstrating a codegen bug.\n", "comments": []}, {"number": 54828, "title": "How to arrange tensorboard's graphs horizontally in tensorflow 2.x?", "body": "I use the following code, the drawing is arranged vertically, how to change it to horizontal arrangement?\r\n\r\n```python\r\nwith self.summary_writer.as_default():\r\n    tf.summary.scalar(\"loss\", self.loss[-1], step=self.steps)\r\n    tf.summary.scalar(\"reward\", self.rewards[-1], step=self.steps)\r\n    tf.summary.scalar(\"average_rewards\", np.nanmean(self.rewards[-1000:]), step=self.steps)\r\n```\r\nI didn't find it in the homepage of tensorflow.\r\n[https://www.tensorflow.org/api_docs/python/tf/summary/scalar](https://www.tensorflow.org/api_docs/python/tf/summary/scalar)\r\n\r\n![1](https://user-images.githubusercontent.com/26672425/156324352-bc39cf12-fd50-4d16-881a-c92721920ffa.png)\r\n\r\n", "comments": ["I changed it this way:\r\n```python\r\nwith self.summary_writer.as_default():\r\n        tf.summary.scalar('status/loss', self.loss[-1], step=self.steps)\r\n        tf.summary.scalar('status/average_rewards', np.nanmean(self.rewards[-1000:]), step=self.steps,)\r\n        tf.summary.scalar('status/reward', self.rewards[-1], step=self.steps)\r\n```\r\nBut the name on the tag shows the same as the tag, how to make the name only show the part after '/'?\r\n![1](https://user-images.githubusercontent.com/26672425/156334133-65a51f78-cd4c-49cd-97bb-da69e7b7259f.png)\r\n\r\n", "@jaried ,\r\nCan you please take a look at this [link](https://github.com/tensorflow/tensorboard/issues/836) which delivers the similar information.It helps,Thanks!!", "Thanks for your answer."]}, {"number": 54827, "title": "Update pybind11_bazel from 26973c0ff320cb4b39e45bc3e4297b82bc3a6c09 to 72cbbf1fbc830e487e3012862b7b720001b70672.", "body": "Update pybind11_bazel from 26973c0ff320cb4b39e45bc3e4297b82bc3a6c09 to 72cbbf1fbc830e487e3012862b7b720001b70672.\n", "comments": []}, {"number": 54826, "title": "Update TensorRT-{commit} from 9ec6eb6db39188c9f3d25f49c8ee3a9721636b56 to 97c5b58092859ffe9c2353d09ca3eca461539cc6.", "body": "Update TensorRT-{commit} from 9ec6eb6db39188c9f3d25f49c8ee3a9721636b56 to 97c5b58092859ffe9c2353d09ca3eca461539cc6.\n", "comments": []}, {"number": 54825, "title": "Update libjpeg_turbo from 2.1.0 to 2.1.3.", "body": "Update libjpeg_turbo from 2.1.0 to 2.1.3.\n", "comments": []}, {"number": 54824, "title": "Update highwayhash from fd3d9af80465e4383162e4a7c5e2f406e82dd968 to 8e7cfe476f67e865b2be62b5a60a75014a631c9a.", "body": "Update highwayhash from fd3d9af80465e4383162e4a7c5e2f406e82dd968 to 8e7cfe476f67e865b2be62b5a60a75014a631c9a.\n", "comments": []}, {"number": 54823, "title": "[tf.data] Remove unused `ctx` parameter from `AsGraphDef`.", "body": "[tf.data] Remove unused `ctx` parameter from `AsGraphDef`.\n\nThis is unused as of cl/240419515 (then in third_party/tensorflow/core/kernels/data/dataset_utils.cc).\n", "comments": []}, {"number": 54822, "title": "cmake error: when build libtensorflow-lite.a for arm64.", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Big Sur 11.6.2\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: latest version 2.8.0 [master branch]\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\ngit clone latest master source, and use this CLI command in /tensorflow/lite dir:\r\n`cmake ../ -DCMAKE_TOOLCHAIN_FILE=${ANDROID_NDK}/build/cmake/android.toolchain.cmake \\\r\n        -DTFLITE_ENABLE_GPU=ON  \\\r\n        -DANDROID_ABI=arm64-v8a -DANDROID_PLATFORM=21 -DABSL_PROPAGATE_CXX_STD=ON\r\n`\r\n\r\nit's OK to build static library libtensorflow-lite.a \r\nBUT, when i include \"c_api.h\" and related header(e.g: c_api_types.h) and link libtensorflow-lite.a in my project.\r\nit comes compiling err.\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\ncmake err log: (so many same style errs. seems like absl lib is not linked in libtensorflow-lite.a\uff1f\uff1f)\r\n`/TFLite/TF_master/tensorflow/tensorflow/lite/delegates/gpu/common/model_builder_helper.cc:129:  undefined reference to absl::lts_20211102::OutOfRangeError(absl::lts_20211102::string_view)\r\n/TFLite/TF_master/tensorflow/tensorflow/lite/delegates/gpu/common/model_builder_helper.cc:150: undefined reference to absl::lts_20211102::UnavailableError(absl::lts_20211102::string_view)\r\n`\r\n\r\nand then i add this code in /tensorflow/lite/CMakeList.txt:\r\n\r\n`\r\nfind_package(absl REQUIRED)\r\nif(absl_FOUND)\r\n  message(\"absl found!\")\r\nendif()\r\n`\r\nBUT there is no \"absl found!\" log. so there is no absl lib found??? but it's really confused...", "comments": ["i see this doc:https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/guide/build_cmake_arm.md.\r\nbut i confused about that we must use gcc\\g++ to build tflite static lib for arm\uff1f\uff1f ndk toolchains seemed using clang\\clang++ by default.  Is this the reson of compiling errs? compiler err?", "Could you try with the 2.8.0 stable branch and let us know if you face the same error. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54822\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54822\">No</a>\n"]}, {"number": 54821, "title": "Convert async ToLiteral to return PjRtEvent instead of taking a callback lambda.", "body": "Convert async ToLiteral to return PjRtEvent instead of taking a callback lambda.\n", "comments": []}, {"number": 54820, "title": "Correct typo in documentation", "body": null, "comments": []}, {"number": 54819, "title": "nn.PixelShuffle\u7684pytorch\u5230tflite", "body": "How to convert nn.PixelShuffle from pytorch to tflite\uff1f\r\n", "comments": ["@douzaikongcheng \r\nIn order to expedite the trouble-shooting process here,Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose),\r\nThanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54819\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54819\">No</a>\n"]}, {"number": 54817, "title": "Custom LSTMCell has cell state gradients being zeros", "body": "<em>Please make sure that this is an issue related to performance of TensorFlow.\r\nAs per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:performance_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):  Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS Big Sur 11.3.1\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.6.0\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nLet c_t be the cell state at step t, c_0 the initial cell state of the same shape. I am trying to compute dc_t/dc_0 for every step as an indicative statistic for the extent of vanishing gradients in LSTM. On a text comment dataset, where each text sequence is labeled with a binary index as target, I have constructed an LSTM and computed and plotted the gradients over steps. \r\n\r\nFor the first 20 steps the gradients are decreasing drastically, demonstrating behaviour of vanishing gradients. For the last 20 steps they are completely zero. \r\n\r\nIn the reproducible example below I have used random uniform inputs. The same LSTM model and gradient computation process return me the exact SAME behaviour as it behaves on the text data. There is probably something wrong with my code that the LSTM is missing something when computing the gradients.\r\n\r\n**Describe the expected behavior**\r\nThe above-described gradients dc_t/dc_0 should stay away from zero, as theory of LSTM suggests that it is resistant against vanishing gradients. i.e. LSTM can capture (moderately) long-term dependencies, so dc_t/dc_0 with t being a few hundred steps should not vanish to zero so drastically. Of course longer temporal-dependency e.g. t = 1000 will cause this gradient to vanish. Models like transformers will do better.\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\nimport numpy as np\r\nfrom numpy import array, asarray, zeros\r\nimport pandas as pd \r\nfrom tqdm import tqdm\r\nfrom sklearn.model_selection import train_test_split\r\n\r\nimport tensorflow as tf\r\nfrom keras import Input, Model\r\nfrom keras.models import Sequential\r\nfrom keras.layers.recurrent import LSTM, GRU, SimpleRNN\r\nfrom keras.layers.core import Dense, Activation, Dropout, Flatten\r\nfrom keras.layers.embeddings import Embedding\r\nfrom sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\r\nfrom keras.layers import RNN, LSTMCell, Flatten, Bidirectional, SpatialDropout1D\r\nfrom keras.preprocessing import sequence, text\r\nfrom keras.callbacks import EarlyStopping, LambdaCallback, TensorBoard\r\nimport matplotlib.pyplot as plt\r\nimport seaborn as sns\r\n%matplotlib inline\r\nfrom keras import backend as k\r\nimport os \r\n\r\n\r\n# For each c_t, compute gradient dc_t/dc_0:\r\nbatch_size = 100; input_length_m = 20\r\nxtr_pad = tf.random.uniform((batch_size*2, input_length_m), maxval = 500, dtype=tf.int32)\r\nytr = tf.random.normal((batch_size*2, input_length_m, 200))\r\n\r\ninp= Input(batch_shape= (batch_size, input_length_m), name= 'input') \r\nemb_out= Embedding(500, 100, input_length= input_length_m, trainable= False, name= 'embedding')(inp)\r\n\r\nclass LSTMCellwithStates(LSTMCell):\r\n    def call(self, inputs, states, training=None):\r\n        real_inputs = inputs[:,:self.units] # decouple [h, c]\r\n        outputs, [h,c] = super().call(real_inputs, states, training=training)\r\n        return tf.concat([h, c], axis=1), [h,c]\r\n    \r\nrnn = RNN(LSTMCellwithStates(200), return_sequences= True, return_state= False, name= 'LSTM') \r\n\r\nh0 = tf.Variable(tf.random.uniform((batch_size, 200)))\r\nc0 = tf.Variable(tf.random.uniform((batch_size, 200)))\r\nrnn_allstates= rnn(emb_out, initial_state=[h0, c0])  \r\n\r\nmodel_lstm_mod = Model(inputs=inp, outputs= rnn_allstates[:, :, 200:], name= 'model_LSTMCell')\r\nmodel_lstm_mod.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\r\n\r\n### Compute gradients: \r\n\r\nds = tf.data.Dataset.from_tensor_slices((xtr_pad, ytr)).batch(100)\r\n\r\n@tf.function\r\n# Compute gradients\r\ndef compute_dct_dc0(t, x, c0):\r\n    return tf.gradients(model_lstm_mod(x)[:,t,:], c0)\r\n\r\nn_b = int(xtr_pad.shape[0]/ 100)  # 200 batches\r\nn_steps = 20   # look up only the first and last 20 steps\r\n\r\ndctdc0_all= tf.zeros([n_b, n_steps])\r\nfor b, (x_batch_train, y_batch_train) in enumerate(ds):  # batches 0,1\r\n    grad_batch= []   # a list of 1403 scalar gradients on the current batch\r\n    for t in range(n_steps):  \r\n        # steps 0,...,19\r\n        dctdc0_b_t = compute_dct_dc0(t, x_batch_train, c0)  # (batch_size, n_units)\r\n        grad_t = tf.reduce_mean(abs(dctdc0_b_t[0]), [0,1]) # Scalar dctdc0 at the current batch and step\r\n        print('step', t+1, 'of batch' ,b+1, 'done')\r\n        grad_batch.append(grad_t)\r\n    \r\n    dctdc0_all= tf.concat([dctdc0_all, [grad_batch]], axis = 0)   \r\n\r\ndctdc0_agg= tf.reduce_mean(dctdc0_all, 0)  # take rowmean to obtain a vector of shape (20,)\r\nprint(dctdc0_agg.shape)\r\n\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nThe LSTM gradient plot for the reproducible eg:\r\n\r\n<img width=\"647\" alt=\"Screen Shot 2022-03-02 at 4 31 31 pm\" src=\"https://user-images.githubusercontent.com/96099256/156301257-7df3a396-fe2a-4122-be3a-51f90a4a1774.png\">\r\n\r\nPlots for first and last 20 steps on text data:\r\n<img width=\"620\" alt=\"Screen Shot 2022-03-02 at 4 29 00 pm\" src=\"https://user-images.githubusercontent.com/96099256/156301342-370fb553-40c8-425a-9963-fd5da2d53199.png\">\r\n\r\n\r\n<img width=\"617\" alt=\"Screen Shot 2022-03-02 at 4 33 00 pm\" src=\"https://user-images.githubusercontent.com/96099256/156301388-7119d512-3333-4a84-b0a5-70a3710fbd97.png\">\r\n\r\n\r\n\r\n", "comments": ["@DagonArises ! It is replicating in [2.8](https://colab.sandbox.google.com/gist/mohantym/b5f6f9f1e220555fa8fe95c0808e8b44/untitled299.ipynb) version too.\r\n\r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999) . Thanks!", "@mohantym done it's [here](https://github.com/keras-team/keras/issues/16151)", "Ok! @DagonArises ! Moving this issue to closed status as it will be tracked down in Keras repo. Thanks!"]}, {"number": 54816, "title": "Update com_github_googlecloudplatform_google_cloud_cpp from v1.17.1 to v1.37.0.", "body": "Update com_github_googlecloudplatform_google_cloud_cpp from v1.17.1 to v1.37.0.\n", "comments": []}, {"number": 54815, "title": "Update png from v1.6.37 to v1.6.35.", "body": "Update png from v1.6.37 to v1.6.35.\n", "comments": []}, {"number": 54814, "title": "Update com_google_googleapis from 541b1ded4abadcc38e8178680b0677f65594ea6f to 513fc461bd5269a4aa5f475dd6d501b7b1312e33.", "body": "Update com_google_googleapis from 541b1ded4abadcc38e8178680b0677f65594ea6f to 513fc461bd5269a4aa5f475dd6d501b7b1312e33.\n", "comments": []}, {"number": 54813, "title": "Update com_github_google_crc32c from 1.0.6 to 1.1.2.", "body": "Update com_github_google_crc32c from 1.0.6 to 1.1.2.\n", "comments": []}, {"number": 54812, "title": "Fix Windows build", "body": "Fix Windows build\n", "comments": []}, {"number": 54811, "title": "Export missing pybind simbols from op_def_util for windows builds.", "body": "Export missing pybind simbols from op_def_util for windows builds.\n", "comments": []}, {"number": 54810, "title": "[MKL BUG fix]fix a minor bug of IsContractionWithAdd", "body": "fix a minor bug of IsContractionWithAdd, support Contraction + Add or Contraction + BiasAdd/BiasSemanticAdd + Add pattern shapes inferred.\r\nfor example :\r\nPattern Conv2D + BiasSemanticAdd ({1,} ADD) + Conv2D + BiasAdd.\r\n\r\nif do not has this fix, the result is  Conv2D + Add +  _FusedConv2D(Conv2D + BiasAdd).\r\nafter having this fix the result is _FusedConv2D + _FusedConv2D\r\n", "comments": []}, {"number": 54809, "title": "Make tf_distribute TypeSpecs compatible with Hierarchical TypeSpec", "body": "Make tf_distribute TypeSpecs compatible with Hierarchical TypeSpec\n", "comments": []}, {"number": 54808, "title": "Lower lmhlo.fft to tfrt_gpu", "body": "Lower lmhlo.fft to tfrt_gpu\n\nLowers the lmhlo fft op to the tfrt_gpu dialect. This involves splitting the fft op into a handle creation, plan creation and an fft execute op.\n", "comments": []}, {"number": 54807, "title": "Implement the `Trackable` interface for `ConcreteFunction`.", "body": "Implement the `Trackable` interface for `ConcreteFunction`.\n\nRemoves additional function special casing by moving to code for creating `TrackableConstants` and `_call_function_with_mapped_captures` to:\n* `ConcreteFunction._trackable_children` \n* `ConcreteFunction._export_to_saved_model_graph`\n\nThe `object_map` now contains copied concrete functions, so this also simplifies the code that does resource initialization in the SavedModel Graph.\n", "comments": []}, {"number": 54806, "title": "[mhlo]  Verifier for mhlo.bitcast_convert", "body": "[mhlo]  Verifier for mhlo.bitcast_convert\n", "comments": []}, {"number": 54805, "title": "Add tiling info in entry computation layout before XLA compilation, except", "body": "Add tiling info in entry computation layout before XLA compilation, except\nwhen layout is explicitly cleared in which case layout (including minor-to-major\norder) is completely decided by layout assignment.\n", "comments": []}, {"number": 54804, "title": "Avoid cached definition and signature in __init__ of eagerly created function", "body": "Avoid cached definition and signature in __init__ of eagerly created function\n\nWhen a concrete function is created but never called from Python, this change\nsaves us an extra copy of fdef. This tends to happen frequenctly in functions\nloaded from a saved model, where only the top-level 'inference' concrete\nfunctions are directly called from Python, whilst other supporting functions\nare called as part of the graph execution.\n", "comments": []}, {"number": 54803, "title": "Remove deleter for eagerly created resource variables.", "body": "Remove deleter for eagerly created resource variables.\n\nThey happen to be all ref-counting.\n", "comments": []}, {"number": 54802, "title": "removing [] bracket which masks the details next to it in () and hyperlinks it.", "body": "removing [] bracket which masks the details next to it in () and hyperlinks it.\n\nFUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/54486 from tensorflow:sachinprasadhs-patch-5 735efdca9a9d1fad35b0aa1b0dc834a2fa48106f\n", "comments": []}]