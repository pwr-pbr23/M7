[{"number": 20386, "title": "html5lib requirement ", "body": "Is there any way the html5lib version can be bumped to at least  0.99999999 (which supports 'html5lib[datrie]').\r\n\r\nThanks a lot\r\n\r\nCarlos", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "/CC @tatianashp", "Have I written custom code: N/A\r\nOS Platform and Distribution: macOSX\r\nTensorFlow installed from: N/A\r\nTensorFlow version: 1.8.0\r\nBazel version: N/A\r\nCUDA/cuDNN version: N/A\r\nGPU model and memory: N/A\r\nExact command to reproduce: N/A", "Are you using Bazel for your development?\r\n\r\nWhen TensorBoard builds its pip package, it vendors html5lib, so it's no longer a transitive dependency of TensorFlow on PyPi and won't conflict with anything you pip install.", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 20385, "title": "return ordered list of operations in Go API or provide sort Operation function", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: macOS 10.13.5\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: 2.7.14\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\n\r\nReading tensorflow Go APIs I see that there is no way to find which order of operations used in a graph. The current APIs only return list of Operations, and if I want to deduce the graph structure I need to know the order of operations. I can extract names, types but I don't know how to order operations. For instance, if I'll be given a model I want to see its structure. I can loop over graph operations and I'll get all operations, but I don't know their order and therefore can't reproduce the graph model structure.\r\n\r\n### Source code / logs\r\n```\r\n   // assume I'll be give a TF graph\r\n    sGraph := \"\"\r\n   // loop over graph operations and print them out\r\n    for _, op := range graph.Operations() {\r\n        fmt.Println(op.Name(), op.Type(), op.NumOutputs())\r\n        for i := 0; i < op.NumOutputs(); i++ {\r\n            if sGraph != \"\" {\r\n                sGraph = fmt.Sprintf(\"%s -> %s(%s)\", sGraph, op.Name(), op.Output(i).Shape())\r\n            } else {\r\n                sGraph = fmt.Sprintf(\"%s(%s)\", op.Name(), op.Output(i).Shape())\r\n            }\r\n        }\r\n    }\r\n```", "comments": ["Given any node in the graph (an `Output` object), you can traverse the graph by walking the edges via methods like [`Output.Consumers`](https://godoc.org/github.com/tensorflow/tensorflow/tensorflow/go#Output.Consumers).\r\n\r\nSo, starting from the input node (`graph.Operation(<node_name>).Output(<index>)`), you should be able to traverse the graph.\r\n\r\nDoes that suffice?", "I think that would work. I'll close ticket now and if I'll experience issues with traversing the graph I can re-open it and ask further questions."]}, {"number": 20384, "title": "Potential fix for how pip installs headers used for custom ops.", "body": "    Potential fix for how pip installs headers used for custom ops.\r\n    \r\n    These headers were recently moved from site-packages/external into\r\n    site-packages/tensorflow/include/external. Need to update setup.py\r\n    to reflect that.", "comments": ["No idea what Im doing really. The eigen headers seemed to get moved around a ton. They get copied into like tensorflow/include/external/eigen_archive/Eigen... by some build pip script. Then setup.py moves them again directly into tensorflow/include/Eigen?", "Anyways,  built the pip package locally and it looks good as far as I can tell.", "Looks like CMake build is completely broken, and need this for 1.9. So going ahead and merging."]}, {"number": 20382, "title": "TypeError: 'InvalidArgumentError' object is not iterable", "body": "Occasionally encounter   issues like the above during training.  Tensorflow does not provide any information about  where is it is happening. For example  take a look at the following ?  \r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"networks.py\", line 586, in <module>\r\n    main()\r\n  File \"networks.py\", line 572, in main\r\n    x, y, z = train_dataset_batch ()\r\n  File \"networks.py\", line 505, in train_dataset_batch\r\n    loss_f, train_op_f, summary_str = sess.run([ loss, train_op, summaries_op], feed_dict=fd)\r\nTypeError: 'InvalidArgumentError' object is not iterable\r\n```\r\n\r\n How can anyone debug this ?\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "OS Platform and Distribution : Ubuntu 16.04\r\nTensorFlow installed from : source \r\nTensorFlow version : 1.6\r\nBazel version\r\nCUDA/cuDNN version : 9.1\r\nGPU model and memory : quadros\r\nExact command to reproduce :   it is a complex network, and  the exceptions happens  unpredictably. ", "It  has certainly  something to do with tf.summary .  Probably  histogram and image.   It will save lot of time if TF print out specific   histogram op  in the traceback. ", "@whatdhack This is a stale issue. If this is still an issue for you, can you please share a simple standalone code to reproduce the issue? If it is not an issue any more for you, then bot will close this issue automatically. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/20382\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/20382\">No</a>\n"]}, {"number": 20381, "title": "Help......I just installed tf, i keep getting this error", "body": "ImportError                               Traceback (most recent call last)\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in swig_import_helper()\r\n     13         try:\r\n---> 14             return importlib.import_module(mname)\r\n     15         except ImportError:\r\n\r\n~\\Anaconda3\\lib\\importlib\\__init__.py in import_module(name, package)\r\n    125             level += 1\r\n--> 126     return _bootstrap._gcd_import(name[level:], package, level)\r\n    127 \r\n\r\n~\\Anaconda3\\lib\\importlib\\_bootstrap.py in _gcd_import(name, package, level)\r\n\r\n~\\Anaconda3\\lib\\importlib\\_bootstrap.py in _find_and_load(name, import_)\r\n\r\n~\\Anaconda3\\lib\\importlib\\_bootstrap.py in _find_and_load_unlocked(name, import_)\r\n\r\n~\\Anaconda3\\lib\\importlib\\_bootstrap.py in _load_unlocked(spec)\r\n\r\n~\\Anaconda3\\lib\\importlib\\_bootstrap.py in module_from_spec(spec)\r\n\r\n~\\Anaconda3\\lib\\importlib\\_bootstrap_external.py in create_module(self, spec)\r\n\r\n~\\Anaconda3\\lib\\importlib\\_bootstrap.py in _call_with_frames_removed(f, *args, **kwds)\r\n\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nModuleNotFoundError                       Traceback (most recent call last)\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>()\r\n     57 \r\n---> 58   from tensorflow.python.pywrap_tensorflow_internal import *\r\n     59   from tensorflow.python.pywrap_tensorflow_internal import __version__\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in <module>()\r\n     16             return importlib.import_module('_pywrap_tensorflow_internal')\r\n---> 17     _pywrap_tensorflow_internal = swig_import_helper()\r\n     18     del swig_import_helper\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in swig_import_helper()\r\n     15         except ImportError:\r\n---> 16             return importlib.import_module('_pywrap_tensorflow_internal')\r\n     17     _pywrap_tensorflow_internal = swig_import_helper()\r\n\r\n~\\Anaconda3\\lib\\importlib\\__init__.py in import_module(name, package)\r\n    125             level += 1\r\n--> 126     return _bootstrap._gcd_import(name[level:], package, level)\r\n    127 \r\n\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-1-6b7c506c9114> in <module>()\r\n      1 get_ipython().magic('matplotlib inline')\r\n      2 import matplotlib.pyplot as plt\r\n----> 3 import tensorflow as tf\r\n      4 import numpy as np\r\n      5 from sklearn.metrics import confusion_matrix\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py in <module>()\r\n     22 \r\n     23 # pylint: disable=g-bad-import-order\r\n---> 24 from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n     25 # pylint: disable=wildcard-import\r\n     26 from tensorflow.tools.api.generator.api import *  # pylint: disable=redefined-builtin\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py in <module>()\r\n     47 import numpy as np\r\n     48 \r\n---> 49 from tensorflow.python import pywrap_tensorflow\r\n     50 \r\n     51 # Protocol buffers\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>()\r\n     72 for some common reasons and solutions.  Include the entire stack trace\r\n     73 above this error message when asking for help.\"\"\" % traceback.format_exc()\r\n---> 74   raise ImportError(msg)\r\n     75 \r\n     76 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\mo.yosiwealth\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 14, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"C:\\Users\\mo.yosiwealth\\Anaconda3\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 658, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 571, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\mo.yosiwealth\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\mo.yosiwealth\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 17, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\mo.yosiwealth\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 16, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"C:\\Users\\mo.yosiwealth\\Anaconda3\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "This is a duplicate of #19584. Closing."]}, {"number": 20380, "title": "Dockerfile should assign LANG=C_ALL", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:official Dockerfile\r\n- **TensorFlow version (use command below)**:1.8.0\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**:from Docker\r\n- **GCC/Compiler version (if compiling from source)**:from Docker\r\n- **CUDA/cuDNN version**:not relevant\r\n- **GPU model and memory**:not relevant\r\n- **Exact command to reproduce**:see link\r\n\r\n### Describe the problem\r\n\r\nPython 3 has a serious issue on LANG=C environment as described in [Python Issue 19846](https://bugs.python.org/issue19846).\r\nIn fact, official python or Anaconda Dockerfile assigned LANG=C.UTF-8 like [Dockerfile](https://github.com/docker-library/python/blob/a652f35d6ce77f02ca268d67f39e7dfa24cf08c5/3.5/jessie/Dockerfile)\r\n\r\nCan this be fixed in future releases?\r\nThank you so much.\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Marking as contributions welcome -- this should be very easy to add.\r\n\r\nAlso, I've recently proposed a change to TensorFlow that obsoletes parameterized_docker_build.sh, which may help alleviate this issue (since the current Dockerfiles are very confusing). If anyone following this thread is interested in making TensorFlow's Dockerfile story better for everyone, [please take a look at the RFC](https://github.com/tensorflow/community/pull/8).", "Added a PR #21877 for the fix.", "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you."]}, {"number": 20379, "title": "tf.layers.conv3d throws an error when using 'channels_first' and 'None' size for the input shape", "body": "### System information\r\n- **Have I written custom code**: Yes\r\n- **OS Platform and Distribution**: Windows 10 Home version 1803\r\n- **TensorFlow installed from**: Installed by running \"pip install tensorflow-gpu\"\r\n- **TensorFlow version (use command below)**: b'v1.8.0-0-g93bc2e2072' 1.8.0\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: CUDA v9.0, cuDNN v7.1\r\n- **GPU model and memory**: GeForce GTX1080, 8GB\r\n- **Exact command to reproduce**: see the *Code To Reproduce The Bug* section\r\n\r\n\r\n### Bug Description\r\nWhen calling \"tf.layers.conv3d\" with \"data_format='channels_first'\" and the\r\ninput shape (None, 1, 3, None, None), tensorflow throws the error:\r\n\"TypeError(\"unsupported operand type(s) for *: 'int' and 'NoneType'\",)\"\r\n\r\nThis error appears to be thrown from [this line](https://github.com/tensorflow/tensorflow/blob/f202958ee2d5177a474e3d107fdbf0c83174d099/tensorflow/python/keras/layers/convolutional.py#L205) according to Visual Studio's python debugger.\r\n\r\n### Code To Reproduce The Bug\r\n```python\r\nimport tensorflow as tf\r\n\r\ndef WorkingCode():\r\n    InputTensor = tf.placeholder(dtype=tf.float32, shape=(None, 3, None, None, 1))\r\n    OutputTensor = tf.layers.conv3d(inputs=InputTensor, filters=16, kernel_size=(1, 3, 3), data_format='channels_last')\r\n\r\ndef BuggedCode():\r\n    InputTensor = tf.placeholder(dtype=tf.float32, shape=(None, 1, 3, None, None))\r\n    OutputTensor = tf.layers.conv3d(inputs=InputTensor, filters=16, kernel_size=(1, 3, 3), data_format='channels_first')\r\n```\r\nCalling the `BuggedCode` function will throw the error, while calling `WorkingCode` will work perfectly fine.\r\n\r\n### Full Traceback\r\n```\r\nTraceback (most recent call last):\r\n  File \".\\TensorflowBugTest.py\", line 11, in <module>\r\n    BuggedCode()\r\n  File \".\\TensorflowBugTest.py\", line 9, in BuggedCode\r\n    OutputTensor = tf.layers.conv3d(inputs=InputTensor, filters=16, kernel_size=(1, 3, 3), data_format='channels_first')\r\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\layers\\convolutional.py\", line 828, in conv3d\r\n    return layer.apply(inputs)\r\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 828, in apply\r\n    return self.__call__(inputs, *args, **kwargs)\r\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\layers\\base.py\", line 717, in __call__\r\n    outputs = self.call(inputs, *args, **kwargs)\r\n  File \"C:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\layers\\convolutional.py\", line 187, in call\r\n    outputs_shape[2] * outputs_shape[3],\r\nTypeError: unsupported operand type(s) for *: 'int' and 'NoneType'\r\n```", "comments": ["@fchollet it looks like you might have introduced the code that manipulates outputs_4d in the case where channels_first is True. Would you PTAL?", "I have a pull request for this in:\r\nhttps://github.com/tensorflow/tensorflow/pull/21610", "This is still a problem, also for 'channels_last\", where if I pass a data type with shape (None, 10, None, None, 1), line 1088 in /keras/layers/convolutional.py drops an error:\r\n\r\noutputs_4d = array_ops.reshape(outputs, [\r\n            outputs_shape[0], outputs_shape[1] * outputs_shape[2],\r\n            outputs_shape[3], outputs_shape[4]\r\n        ])\r\n\r\nTypeError: unsupported operand type(s) for *: 'int' and 'NoneType'", " Might be fixed upstream, but this is still a problem in `1.13.1`. \r\n\r\n```python\r\nimport tensorflow.keras as keras\r\ninp = keras.layers.Input([4, None, None, None])\r\nkeras.layers.Conv3D(16, 3, data_format='channels_first')(inp)\r\n```\r\n\r\nthrows \r\n\r\n```\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-9-97dcda7235cf> in <module>\r\n      1 import tensorflow.keras as keras\r\n      2 inp = keras.layers.Input([4, None, None, None])\r\n----> 3 keras.layers.Conv3D(16, 3, data_format='channels_first')(inp)\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/engine/base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    552             # In graph mode, failure to build the layer's graph\r\n    553             # implies a user-side bug. We don't catch exceptions.\r\n--> 554             outputs = self.call(inputs, *args, **kwargs)\r\n    555           else:\r\n    556             try:\r\n\r\n/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/convolutional.py in call(self, inputs)\r\n    211           outputs_4d = array_ops.reshape(outputs,\r\n    212                                          [outputs_shape[0], outputs_shape[1],\r\n--> 213                                           outputs_shape[2] * outputs_shape[3],\r\n    214                                           outputs_shape[4]])\r\n    215           outputs_4d = nn.bias_add(outputs_4d, self.bias, data_format='NCHW')\r\n\r\nTypeError: unsupported operand type(s) for *: 'NoneType' and 'NoneType'\r\n```", "This is fixed with tf-nightly version '1.15.0-dev20190726'. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=20379\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=20379\">No</a>\n"]}, {"number": 20378, "title": "Add int16 support for Pack on GPU", "body": "This fix tries to add int16 support for Pack on GPU, so that the issue raised in #20370 could be addressed.\r\n\r\nThis fix is related to #20370.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Ping @yifeif @zheng-xq, any chance to take a look at the PR?", "I'm not a good reviewer for this, I'm afraid. It looks like there are merge conflicts with head, too, by the way.", "Nagging Reviewer : You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 29 days with no activity and the `awaiting review` label has been applied.", "sorry, got lost."]}, {"number": 20377, "title": "keras model to estimator in eager mode gives ValueError", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: OSX 10.13.4\r\n- **TensorFlow installed from (source or binary)**: binary \r\n- **TensorFlow version (use command below)**:  1.9.0-rc1\r\n- **Python version**:  3.6\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\nAfter enabling eager mode with `tf.enable_eager_execution()` if I convert my `tf.keras.Model` to an estimator via: `tf.keras.estimator.model_to_estimator(model)` I get:\r\n\r\n```\r\nINFO:tensorflow:Using the Keras model provided.\r\nINFO:tensorflow:Using default config.\r\nWARNING:tensorflow:Using temporary folder as model directory: /var/folders/yg/t3pf0vds6c14zlhmq1jwwvtnsz8fsr/T/tmp197t8ju4\r\nINFO:tensorflow:Using config: {'_model_dir': '/var/folders/yg/t3pf0vds6c14zlhmq1jwwvtnsz8fsr/T/tmp197t8ju4', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1227bcdd8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-8-6cc0c716ca8a> in <module>()\r\n----> 1 estimator = tf.keras.estimator.model_to_estimator(model)\r\n\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/estimator/keras.py in model_to_estimator(keras_model, keras_model_path, custom_objects, model_dir, config)\r\n    512 \r\n    513   # Check if we need to call get_weights:\r\n--> 514   if _any_variable_initialized():\r\n    515     keras_weights = keras_model.get_weights()\r\n    516     # Warn if config passed to estimator tries to update GPUOptions. If a\r\n\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/estimator/keras.py in _any_variable_initialized()\r\n     77     boolean, True if at least one variable has been initialized, else False.\r\n     78   \"\"\"\r\n---> 79   variables = variables_module.global_variables()\r\n     80   for v in variables:\r\n     81     if getattr(v, '_keras_initialized', False):\r\n\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/variables.py in global_variables(scope)\r\n   1442     A list of `Variable` objects.\r\n   1443   \"\"\"\r\n-> 1444   return ops.get_collection(ops.GraphKeys.GLOBAL_VARIABLES, scope)\r\n   1445 \r\n   1446 \r\n\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in get_collection(key, scope)\r\n   5905   @end_compatibility\r\n   5906   \"\"\"\r\n-> 5907   return get_default_graph().get_collection(key, scope)\r\n   5908 \r\n   5909 \r\n\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in get_collection(self, name, scope)\r\n   3961       collected.\r\n   3962     \"\"\"  # pylint: disable=g-doc-exception\r\n-> 3963     _assert_collection_is_ok(name)\r\n   3964     with self._lock:\r\n   3965       collection = self._collections.get(name, None)\r\n\r\n/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in _assert_collection_is_ok(collection_name)\r\n   6146     if collection_name in GraphKeys._VARIABLE_COLLECTIONS:  # pylint: disable=protected-access\r\n   6147       raise ValueError(\r\n-> 6148           \"variable collections are not supported when eager execution is enabled.\"\r\n   6149       )\r\n   6150 \r\n\r\nValueError: variable collections are not supported when eager execution is enabled.\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "@anj-s @tanzhenyu : Mind taking a look?\r\n\r\n(CC @fchollet )", "Currently the tf.global_variables() function is not supported for eager execution.", "@tanzhenyu : Global collections in general aren't used with eager execution and that won't change going forward.\r\n\r\nThat said, why do we need to use them at all? Can we use `Model.variables` to get all the variables instead of using the collection?", "@asimshankar yes that's what I have in mind as well -- I have made one code change that takes in the keras model to search its own variables instead of searching global variables. (In the end there's no guarantee how many models exist in the graph by the way model_to_estimator works, so asking for global variables does not make sense here)", "@karmel add feature supporting eager execution in model_to_estimator?", "If that's the only delta, it seems pretty straightforward to resolve and make this compatible, which would be great.", "@karmel  probably more than that, one example I can think of is the optimizers compiled by Keras is not compatible with eager -- Currently keras is utilizing its own optimizer instead TF 'native' optimizers, that will likely cause a problem in the conversion. On the other hand, the metrics compiled by Keras (and losses) might not support eager as well as of today.", "Stateless metrics are supported in Eager but not stateful metrics. Sample weight mode and weighted metrics are also not supported. I believe loss functions are eager compatible.", "Got it. @tanzhenyu , care to add to the list of blocked features for now? We can readdress after some of the other issues are handled (ie, optimizers, stateful metrics in eager).", "@tanzhenyu It seems not only that metrics compiled by Keras might not support eager mode. \r\nBut seems that there is a general incompatibility between tf.keras and pure tf metrics. See https://github.com/tensorflow/tensorflow/issues/17168. As generally the metrics portfolio is not the same between tf.keras and tf (low level) users don't understand why they need to select what API to use (high level/low level) based on the metrics that they need inside the same framework (tensorflow).", "@bhack Regarding the existence of multiple metrics modules - we are working towards integrating them. After that you will be able to use any metric with any API.\r\n\r\n@tanzhenyu Stateful metrics are not supported in eager mode - this means irrespective of whether we convert keras model to estimator or not, this scenario is not supported today. This will be fixed as well when we integrate the metric modules. Having said that, this should not affect (and is independent) adding support for model_to_estimator in eager mode => should not cause a problem in conversion.", "@pavithrasv This is the only plausible route. I hope it can land soon in master.", "code shipped. Should be merged soon.", "@kashif it's already live. can you try it before we close the ticket?", "@tanzhenyu sure i'll compile up master and try it out asap!", "works! thanks! See: https://github.com/kashif/tf-keras-tutorial/blob/master/7-estimators-multi-gpus.ipynb\r\n"]}, {"number": 20376, "title": "tensorboard doesn't work well on Windows", "body": "Hey guys,\r\nI use TensorFlow on Windows. When I invoked this command:\r\n`tensorboard --logdir=output`\r\nThe **tensorboard** program didn't visualize my trained model as expected. Instead, it simply executed my model's python file.\r\nAnyway, I tried this fully-qualified version:\r\n`C:\\Python36\\Scripts\\tensorboard --logdir=output`\r\nIt did work, and I got my model visualized successfully.\r\nThis is very strange. Invoking the same program **tensorboard** in different ways produce totally different results.\r\nCan this be fixed in future releases?\r\nThank you so much.\r\n", "comments": ["Hi @iwmq. I'm not too familiar with Python or TensorFlow on Windows. However, by looking at the location you executed `tensorboard`, I would assume you do not have `C:\\Python36\\Scripts\\` added to your path. \r\n\r\nPlease ensure that the directory where you installed Python is added to your path environment variable. You can do this from My Computer > Properties > Advanced System Settings > Environment Variables. In your case, just add `C:\\Python36\\` and `C:\\Python36\\Scripts\\`. Close and relaunch your terminal and TensorBoard should work well now. \r\n\r\nLet me know if this resolves your issue.", "Hi @marshalhayes , thank you. I resolved this glitch of my code. \r\nIt's me to blame. I named the python program file as _tensorboard.py_, so the program I invoked is my own model script. \r\n"]}, {"number": 20375, "title": "Feature Request: CheckpointSaverHook should allow writing graph in binary mode", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: Binary\r\n- **TensorFlow version (use command below)**: 1.8.0\r\n- **Python version**:  3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nFirst, I found that the **MonitoredTrainingSession** is slow to start due to saving the `graph.pbtxt` file when the graph is huge. I could see that if it was saved in a binary format (`.pb`), it would be much faster (and also smaller).\r\n\r\nNow, I see that **MonitoredTrainingSession** utilizes the **CheckpointSaverHook** to save the graph. However, I see no way to make **CheckpointSaverHook** save in binary format. \r\n\r\nSee: https://github.com/tensorflow/tensorflow/blob/51ddb66cdf1444998827e03c4b5f592841ee6255/tensorflow/python/training/basic_session_run_hooks.py#L433\r\n\r\nShould **CheckpointSaverHook** has an option to save in binary format?\r\n\r\nPS. I also doubt the usefulness of `graph.pbtxt` file where the `.meta` file is also present.\r\n", "comments": ["@ispirmustafa Could you take a look at this feature request.", "Hi @phizaz \r\nCould you please verify the impact of saving in binary? If that creates a good gain for your case, adding this option will be a good contribution candidate.", "@ispirmustafa Saving in plain text is very slow in my case. Not that my network is huge but rather my dataset is included in the graph. This is unfortunate case for in-memory datasets like MNIST, Cifar10. When I use `tf.data.Dataset.from_tensor_slices(....)`, I guess, that whole dataset is included in the graph saved in the `graph.pbtxt` as well. Since, I cannot avoid this behavior saving in another format that is very much faster seems to be a good mitigation for me. Also, providing this support seems trivial to my naive eyes. ", "Thank you @phizaz \r\nI understand it's slow. Could you please verify the runtime improvement of all of your training? I mean how much effective it is. Do you have a comparison with and without binary format?\r\nthanks", "@ispirmustafa I wanted to give your numbers but I encounter some complications right now. I could only say that the difference is huge (out of my memory), saving in pbtxt took something like 15 seconds (it colud be wildly different) but with pb (binary mode) it took like 1-2 seconds.", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Closing this due to inactivity. Please do re-open if you need this."]}, {"number": 20374, "title": "Update beam_search_decoder.py", "body": "minor change in example", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", " I signed it!\n\nOn Thu, Jun 28, 2018 at 4:06 PM googlebot <notifications@github.com> wrote:\n\n> Thanks for your pull request. It looks like this may be your first\n> contribution to a Google open source project (if not, look below for help).\n> Before we can look at your pull request, you'll need to sign a Contributor\n> License Agreement (CLA).\n>\n> \ud83d\udcdd *Please visit https://cla.developers.google.com/\n> <https://cla.developers.google.com/> to sign.*\n>\n> Once you've signed (or fixed any issues), please reply here (e.g. I\n> signed it!) and we'll verify it.\n> ------------------------------\n> What to do if you already signed the CLA Individual signers\n>\n>    - It's possible we don't have your GitHub username or you're using a\n>    different email address on your commit. Check your existing CLA data\n>    <https://cla.developers.google.com/clas> and verify that your email is\n>    set on your git commits\n>    <https://help.github.com/articles/setting-your-email-in-git/>.\n>\n> Corporate signers\n>\n>    - Your company has a Point of Contact who decides which employees are\n>    authorized to participate. Ask your POC to be added to the group of\n>    authorized contributors. If you don't know who your Point of Contact is,\n>    direct the Google project maintainer to go/cla#troubleshoot (Public\n>    version <https://opensource.google.com/docs/cla/#troubleshoot>).\n>    - The email used to register you as an authorized contributor must be\n>    the email used for the Git commit. Check your existing CLA data\n>    <https://cla.developers.google.com/clas> and verify that your email is\n>    set on your git commits\n>    <https://help.github.com/articles/setting-your-email-in-git/>.\n>    - The email used to register you as an authorized contributor must\n>    also be attached to your GitHub account\n>    <https://github.com/settings/emails>.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/20374#issuecomment-400990609>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AIDgguoKlKzerVxpAIMimTBnMii6vUukks5uBLG0gaJpZM4U7JLb>\n> .\n>\n", "CLAs look good, thanks!\n\n<!-- ok -->"]}, {"number": 20373, "title": "kernel_tests:cwise_ops_test fails on AVX512 systems", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04 \r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: ('v1.8.0-4021-g4292085', '1.9.0-rc0')\r\n- **Python version**: Python 2.7.12\r\n- **Bazel version (if compiling from source)**:  0.15.0\r\n- **GCC/Compiler version (if compiling from source)**: gcc (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609\r\n- **CUDA/cuDNN version**: n/a\r\n- **GPU model and memory**: n/a\r\n- **Exact command to reproduce**: bazel test --config=opt -- //tensorflow/python/kernel_tests:cwise_ops_test\r\n\r\n### Describe the problem\r\n\r\nThe //tensorflow/python/kernel_tests:cwise_ops_test test fails on AVX512 machines.  Reproducing the problem is simple.  Just run the unit test.\r\n\r\n```\r\nbazel test --config=opt -- //tensorflow/python/kernel_tests:cwise_ops_test\r\n```\r\n\r\nThe test is failing as there's a bug in Eigen's AVX512 implementation of the psqrt functions, which incorrectly compute the sqrt of negative numbers as 0 instead of NaN.  There's a pull request pending on Eigen that fixes the issue.\r\n\r\nhttps://bitbucket.org/eigen/eigen/pull-requests/412/fix-avx512-implementations-of-psqrt/diff\r\n\r\nA similar issue was fixed in Eigen's AVX2 implementations of psqrt a couple of years ago.\r\n\r\n### Source code / logs\r\n\r\n```\r\ncwise_ops_test.py:1920: RuntimeWarning: invalid value encountered in sqrt\r\n  np_y = np.sqrt(x)\r\nF\r\n======================================================================\r\nFAIL: testSqrt (__main__.IsFiniteInfNanTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"$HOME/.cache/bazel/_bazel_markus/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/cwise_ops_test.runfiles/org_tensorflow/tensorflow/python/kernel_tests/cwise_ops_test.py\", line 1926, in testSqrt\r\n    self.assertAllEqual(np_nan, tf_nan.eval())\r\n  File \"$HOME/.cache/bazel/_bazel_markus/59a925eeb655b30b5c683f8317fe569e/execroot/org_tensorflow/bazel-out/k8-opt/bin/tensorflow/python/kernel_tests/cwise_ops_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py\", line 1401, in assertAllEqual\r\n    np.testing.assert_array_equal(a, b, err_msg=msg)\r\n  File \"$HOME/.local/lib/python2.7/site-packages/numpy/testing/nose_tools/utils.py\", line 855, in assert_array_equal\r\n    verbose=verbose, header='Arrays are not equal')\r\n  File \"$HOME/.local/lib/python2.7/site-packages/numpy/testing/nose_tools/utils.py\", line 779, in assert_array_compare\r\n    raise AssertionError(msg)\r\nAssertionError: \r\nArrays are not equal\r\n\r\n(mismatch 76.1904761905%)\r\n x: array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\r\n        True,  True,  True,  True,  True,  True,  True,  True,  True,\r\n        True,  True,  True,  True,  True,  True,  True,  True,  True,...\r\n y: array([False, False, False, False, False, False, False, False, False,\r\n       False, False, False, False, False, False, False, False, False,\r\n       False, False, False, False, False, False, False, False, False,...\r\n\r\n----------------------------------------------------------------------\r\nRan 3 tests in 4.787s\r\n\r\nFAILED (failures=1)\r\nnot equal where =  (array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\r\n       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\r\n       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47]),)\r\nnot equal lhs =  [ True  True  True  True  True  True  True  True  True  True  True  True\r\n  True  True  True  True  True  True  True  True  True  True  True  True\r\n  True  True  True  True  True  True  True  True  True  True  True  True\r\n  True  True  True  True  True  True  True  True  True  True  True  True]\r\nnot equal rhs =  [False False False False False False False False False False False False\r\n False False False False False False False False False False False False\r\n False False False False False False False False False False False False\r\n False False False False False False False False False False False False]\r\n```", "comments": ["Nagging Assignee @rohan100jain: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @rohan100jain: It has been 30 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Patch has been merged into Eigen.  The issue will be fixed when tensorflow updates the version of Eigen it uses.", "@rohan100jain This bug is still reproducible in tensorflow.  Fixing it requires an update to the version of Eigen used in tensorflow, so I think the bug should probably remain open."]}, {"number": 20372, "title": "Keras Tensorboard callback fails with tf.eager", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Custom code\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04\r\n- **TensorFlow installed from (source or binary)**: Via pip\r\n- **TensorFlow version (use command below)**: 1.9.0-rc1\r\n- **Python version**:  3.6.5\r\n- **Bazel version (if compiling from source)**: NA\r\n- **GCC/Compiler version (if compiling from source)**: NA\r\n- **CUDA/cuDNN version**: 9.0/7.0\r\n- **GPU model and memory**: GTX 1080Ti/11GB\r\n- **Exact command to reproduce**: Code given below\r\n\r\n### Describe the problem\r\nI'm using tf.eager, Keras model subclassing and tf.Dataset on TF 1.9.0-rc1. When I try to add the Tensorboard callback to the Keras `.fit` method I get the following error:\r\n```\r\n  File \"/home/ekami/workspace/src/main.py\", line 112, in <module>\r\n    main(args)\r\n  File \"/home/ekami/workspace/src/main.py\", line 63, in main\r\n    validation_steps=3)\r\n  File \"/home/ekami/workspace/src/models/base_model.py\", line 75, in fit\r\n    sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\r\n  File \"/home/ekami/Programs/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1328, in fit\r\n    validation_steps=validation_steps)\r\n  File \"/home/ekami/Programs/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_eager.py\", line 979, in fit_loop\r\n    callbacks.set_model(callback_model)\r\n  File \"/home/ekami/Programs/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/keras/callbacks.py\", line 70, in set_model\r\n    callback.set_model(model)\r\n  File \"/home/ekami/Programs/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/keras/callbacks.py\", line 763, in set_model\r\n    self.merged = tf_summary.merge_all()\r\n  File \"/home/ekami/Programs/anaconda3/envs/dl/lib/python3.6/site-packages/tensorflow/python/summary/summary.py\", line 311, in merge_all\r\n    'Merging tf.summary.* ops is not compatible with eager execution. '\r\nRuntimeError: Merging tf.summary.* ops is not compatible with eager execution. Use tf.contrib.summary instead.\r\n```\r\n\r\nHere is a pseudo code to reproduce the error:\r\n```\r\ntrain_ds, train_slides, val_ds, val_slides, lookup_table = Dataset(logger, input_dir, output_dir, crop_size,\r\n                                           cache_slide_size=cache_slide_size).get_dataset() # Returns a tf.Dataset object\r\n\r\npatches_len = len(train_slides[0].patches)\r\nmodel = SimpleCNNModel(num_classes=len(lookup_table))\r\nmodel.compile(optimizer=tf.train.AdamOptimizer(),\r\n                          loss='categorical_crossentropy',\r\n                          metrics=['accuracy'])\r\nmodel.fit(train_ds, epochs=args.epochs,\r\n                callbacks=[tf.keras.callbacks.TensorBoard()],  # Will fail with the above error\r\n                batch_size=batch_size,\r\n                steps_per_epoch=patches_len // batch_size,\r\n                shuffle=True,\r\n                validation_data=val_ds,\r\n                validation_steps=3)\r\nmodel.save_weights(weights_pth)\r\nlogger.info(\"Done training!\")\r\n```\r\n\r\n### Source code / logs\r\n\r\nGiven above\r\n", "comments": ["Assigning to @anj-s as she has a fix ready.", "The code provided should now work", "Perfect, thank you :)", "> The code provided should now work\r\n\r\nso should we just update ?\r\n", "@malikaltakrori yep, I think this should be in 1.11 if not you can `pip install tf-nightly` (or `pip install tf-nightly-gpu` for GPU support)", "Thanks for the reply @omalleyt12 .\r\nNote that I am working on Windows, not Linux. \r\nI did. Using Tensorflow version 1.10.0 and my callback is: \r\n\r\n```\r\ncallbacks = [\r\n        # Write TensorBoard logs to `./logs` directory\r\n        tf.keras.callbacks.TensorBoard() ]\r\n\r\nhistory = model.fit([X_train_seqs, masked_X_train_seqs], y=tf.keras.utils.to_categorical(YDocLevel_train, 13),\r\n              validation_data=([X_valid_seqs, masked_X_valid_seqs], tf.keras.utils.to_categorical(YDocLevel_valid, 13)),\r\n              batch_size=16, epochs=100, shuffle=True, callbacks= callbacks)\r\n```\r\n\r\nstill got the same error:\r\nFile \"D:\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\", line 71, in set_model\r\n    callback.set_model(model)\r\n  File \"D:\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\callbacks.py\", line 782, in set_model\r\n    self.merged = tf_summary.merge_all()\r\n  File \"D:\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\summary\\summary.py\", line 311, in merge_all\r\n    'Merging tf.summary.* ops is not compatible with eager execution. '\r\nRuntimeError: Merging tf.summary.* ops is not compatible with eager execution. Use tf.contrib.summary instead.", "@malikaltakrori 1.10 is too early, please try 1.11 or nightly", "I confirm it's now working on TF >= 1.11.0 ", "I see. \r\nMaybe there is something going on with my installation. I did I try to upgrade (with pip install --upgrade tensorflow)  I get: \r\n`Requirement already up-to-date: tensorflow in d:\\anaconda2\\envs\\tensorflow\\lib\\site-packages (1.11.0rc2)`\r\nWhen I print tf.__version__ I get 1.10\r\nand when I print tf.__file__ i get the correct location: \r\n`D:\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py`\r\n\r\n**Edit**: A rookie mistake, had two version of Tensorflow at the same time. Upgrading to 1.11.0rc2 solved it.\r\n\r\nThank you ", "Recently updated to `TensorFlow version:  2.0.0-beta1`\r\nI now get `ValueError: Session keyword arguments are not support during eager execution. You passed: {'callbacks': [<tensorflow.python.keras.callbacks.TensorBoard object at 0x1a473117f0>]}`", "I'm also experiencing this with TF 2.0.0-beta1\r\n\r\nValueError: Session keyword arguments are not support during eager execution. You passed: {'callbacks': [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x00000000498CB940>, <tensorflow.python.keras.callbacks.EarlyStopping object at 0x00000000498CB9E8>]}", "@MonsieurWave could you share a code snippet to repro?", "Make sure that the callbacks argument is inside the `fit` call, and not inside the `compile`."]}, {"number": 20371, "title": "fixed order: first create the config, then use it", "body": "", "comments": ["Thanks!"]}, {"number": 20370, "title": "MirroredStrategy fails with \"no supported kernel for GPU devices is available\"", "body": "- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: YES\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ML Engine default\r\n- **TensorFlow installed from (source or binary)**: ML Engine default\r\n- **TensorFlow version (use command below)**: 1.8\r\n- **Python version**: 2.6\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: ML Engine default\r\n- **GPU model and memory**: NVIDIA Tesla K80\r\n- **Exact command to reproduce**: N/A\r\n\r\nMirroredStrategy fails with \"no supported kernel for GPU devices is available\". The same code works on a single GPU.\r\n\r\nTraceback:\r\nTraceback (most recent call last): File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main \"__main__\", fname, loader, pkg_name) File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code exec code in run_globals File \"/root/.local/lib/python2.7/site-packages/trainer_yolo/main.py\", line 188, in <module> main(sys.argv) File \"/root/.local/lib/python2.7/site-packages/trainer_yolo/main.py\", line 184, in main start_training(output_dir, hparams, **otherargs) File \"/root/.local/lib/python2.7/site-packages/trainer_yolo/main.py\", line 131, in start_training tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 439, in train_and_evaluate executor.run() File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 546, in run getattr(self, task_to_run)() File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 601, in run_master self._start_distributed_training(saving_listeners=saving_listeners) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 739, in _start_distributed_training saving_listeners=saving_listeners) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 363, in train loss = self._train_model(input_fn, hooks, saving_listeners) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 841, in _train_model return self._train_model_distributed(input_fn, hooks, saving_listeners) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 977, in _train_model_distributed saving_listeners) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 1056, in _train_with_estimator_spec log_step_count_steps=self._config.log_step_count_steps) as mon_sess: File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 405, in MonitoredTrainingSession stop_grace_period_secs=stop_grace_period_secs) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 816, in __init__ stop_grace_period_secs=stop_grace_period_secs) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 539, in __init__ self._sess = _RecoverableSession(self._coordinated_creator) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 1002, in __init__ _WrappedSession.__init__(self, self._create_session()) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 1007, in _create_session return self._sess_creator.create_session() File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 696, in create_session self.tf_sess = self._session_creator.create_session() File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 467, in create_session init_fn=self._scaffold.init_fn) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py\", line 285, in prepare_session sess.run(init_op, feed_dict=init_feed_dict) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 900, in run run_metadata_ptr) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1135, in _run feed_dict_tensor, options, run_metadata) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1316, in _do_run run_metadata) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1335, in _do_call raise type(e)(node_def, op, message) InvalidArgumentError: Cannot assign a device for operation 'tower_3/Tile_7/input': Could not satisfy explicit device specification '/device:GPU:3' because **no supported kernel for GPU devices is available**. Registered kernels: device='CPU'; T in [DT_QINT32] device='CPU'; T in [DT_QUINT8] device='CPU'; T in [DT_QINT8] device='CPU'; T in [DT_VARIANT] device='CPU'; T in [DT_RESOURCE] device='CPU'; T in [DT_STRING] device='CPU'; T in [DT_BOOL] device='CPU'; T in [DT_COMPLEX128] device='CPU'; T in [DT_COMPLEX64] device='CPU'; T in [DT_DOUBLE] device='CPU'; T in [DT_FLOAT] device='CPU'; T in [DT_BFLOAT16] device='CPU'; T in [DT_HALF] device='CPU'; T in [DT_INT8] device='CPU'; T in [DT_UINT8] device='CPU'; T in [DT_INT16] device='CPU'; T in [DT_UINT16] device='CPU'; T in [DT_INT32] device='CPU'; T in [DT_INT64] device='GPU'; T in [DT_INT32] device='GPU'; T in [DT_BOOL] device='GPU'; T in [DT_INT64] device='GPU'; T in [DT_BFLOAT16] device='GPU'; T in [DT_DOUBLE] device='GPU'; T in [DT_FLOAT] device='GPU'; T in [DT_HALF] [[Node: tower_3/Tile_7/input = Pack[N=1, T=DT_INT16, axis=0, _device=\"/device:GPU:3\"](tower_3/Cast_4)]] Caused by op u'tower_3/Tile_7/input', defined at: File \"/usr/lib/python2.7/threading.py\", line 774, in __bootstrap self.__bootstrap_inner() File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner self.run() File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 465, in run self.main_result = self.main_fn(*self.main_args, **self.main_kwargs) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 831, in _call_model_fn model_fn_results = self._model_fn(features=features, **kwargs) File \"/root/.local/lib/python2.7/site-packages/trainer_yolo/model.py\", line 230, in model_fn iou_accuracy = box.compute_safe_IOU(target_rois, detected_rois, detected_rois_overflow, settings.TILE_SIZE) File \"/root/.local/lib/python2.7/site-packages/trainer_yolo/utils_box.py\", line 521, in compute_safe_IOU iou_accuracy = IOUCalculator.batch_intersection_over_union(detected_rois * tile_size, target_rois * tile_size, tile_size=tile_size) File \"/root/.local/lib/python2.7/site-packages/trainer_yolo/utils_box.py\", line 476, in batch_intersection_over_union linmap2 = cls.__iou_gen_linmap(batch, n2, tile_size) File \"/root/.local/lib/python2.7/site-packages/trainer_yolo/utils_box.py\", **line 428, in __iou_gen_linmap linmap = tf.tile([row], [tile_size, 1])** File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 8430, in tile \"Tile\", input=input, multiples=multiples, name=name) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 510, in _apply_op_helper preferred_dtype=default_dtype) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1104, in internal_convert_to_tensor ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 1034, in _autopacking_conversion_function return _autopacking_helper(v, inferred_dtype, name or \"packed\") File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 997, in _autopacking_helper return gen_array_ops.pack(elems_as_tensors, name=scope) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 4517, in pack \"Pack\", values=values, axis=axis, name=name) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper op_def=op_def) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op op_def=op_def) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__ self._traceback = self._graph._extract_stack() # pylint: disable=protected-access InvalidArgumentError (see above for traceback): Cannot assign a device for operation 'tower_3/Tile_7/input': Could not satisfy explicit device specification '/device:GPU:3' because **no supported kernel for GPU devices is available**. Registered kernels: device='CPU'; T in [DT_QINT32] device='CPU'; T in [DT_QUINT8] device='CPU'; T in [DT_QINT8] device='CPU'; T in [DT_VARIANT] device='CPU'; T in [DT_RESOURCE] device='CPU'; T in [DT_STRING] device='CPU'; T in [DT_BOOL] device='CPU'; T in [DT_COMPLEX128] device='CPU'; T in [DT_COMPLEX64] device='CPU'; T in [DT_DOUBLE] device='CPU'; T in [DT_FLOAT] device='CPU'; T in [DT_BFLOAT16] device='CPU'; T in [DT_HALF] device='CPU'; T in [DT_INT8] device='CPU'; T in [DT_UINT8] device='CPU'; T in [DT_INT16] device='CPU'; T in [DT_UINT16] device='CPU'; T in [DT_INT32] device='CPU'; T in [DT_INT64] device='GPU'; T in [DT_INT32] device='GPU'; T in [DT_BOOL] device='GPU'; T in [DT_INT64] device='GPU'; T in [DT_BFLOAT16] device='GPU'; T in [DT_DOUBLE] device='GPU'; T in [DT_FLOAT] device='GPU'; T in [DT_HALF] [[Node: tower_3/Tile_7/input = Pack[N=1, T=DT_INT16, axis=0, _device=\"/device:GPU:3\"](tower_3/Cast_4)]]\r\n", "comments": ["I managed to remove the offending instruction but the code failed in a different place:\r\n\r\nTraceback (most recent call last): File \"/usr/lib/python2.7/runpy.py\", line 174, in _run_module_as_main \"__main__\", fname, loader, pkg_name) File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code exec code in run_globals File \"/root/.local/lib/python2.7/site-packages/trainer_yolo/main.py\", line 188, in <module> main(sys.argv) File \"/root/.local/lib/python2.7/site-packages/trainer_yolo/main.py\", line 184, in main start_training(output_dir, hparams, **otherargs) File \"/root/.local/lib/python2.7/site-packages/trainer_yolo/main.py\", line 131, in start_training tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 439, in train_and_evaluate executor.run() File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 546, in run getattr(self, task_to_run)() File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 601, in run_master self._start_distributed_training(saving_listeners=saving_listeners) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/training.py\", line 739, in _start_distributed_training saving_listeners=saving_listeners) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 363, in train loss = self._train_model(input_fn, hooks, saving_listeners) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 841, in _train_model return self._train_model_distributed(input_fn, hooks, saving_listeners) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 977, in _train_model_distributed saving_listeners) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 1056, in _train_with_estimator_spec log_step_count_steps=self._config.log_step_count_steps) as mon_sess: File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 405, in MonitoredTrainingSession stop_grace_period_secs=stop_grace_period_secs) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 816, in __init__ stop_grace_period_secs=stop_grace_period_secs) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 539, in __init__ self._sess = _RecoverableSession(self._coordinated_creator) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 1002, in __init__ _WrappedSession.__init__(self, self._create_session()) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 1007, in _create_session return self._sess_creator.create_session() File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 696, in create_session self.tf_sess = self._session_creator.create_session() File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 467, in create_session init_fn=self._scaffold.init_fn) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py\", line 285, in prepare_session sess.run(init_op, feed_dict=init_feed_dict) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 900, in run run_metadata_ptr) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1135, in _run feed_dict_tensor, options, run_metadata) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1316, in _do_run run_metadata) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1335, in _do_call raise type(e)(node_def, op, message) InvalidArgumentError: Cannot assign a device for operation 'concat_97': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available. Registered kernels: device='GPU'; T in [DT_INT32] device='GPU'; T in [DT_BOOL] device='GPU'; T in [DT_INT64] device='GPU'; T in [DT_COMPLEX128] device='GPU'; T in [DT_COMPLEX64] device='GPU'; T in [DT_UINT8] device='GPU'; T in [DT_BFLOAT16] device='GPU'; T in [DT_DOUBLE] device='GPU'; T in [DT_FLOAT] device='GPU'; T in [DT_HALF] device='CPU'; T in [DT_QINT32] device='CPU'; T in [DT_QINT16] device='CPU'; T in [DT_QUINT16] device='CPU'; T in [DT_QINT8] device='CPU'; T in [DT_QUINT8] device='CPU'; T in [DT_STRING] device='CPU'; T in [DT_BOOL] device='CPU'; T in [DT_COMPLEX128] device='CPU'; T in [DT_COMPLEX64] device='CPU'; T in [DT_DOUBLE] device='CPU'; T in [DT_FLOAT] device='CPU'; T in [DT_BFLOAT16] device='CPU'; T in [DT_HALF] device='CPU'; T in [DT_INT8] device='CPU'; T in [DT_UINT8] device='CPU'; T in [DT_INT16] device='CPU'; T in [DT_UINT16] device='CPU'; T in [DT_INT32] device='CPU'; T in [DT_INT64] [[Node: concat_97 = ConcatV2[N=2, T=DT_STRING, Tidx=DT_INT32, _device=\"/device:GPU:0\"](report_uninitialized_variables/boolean_mask/GatherV2, report_uninitialized_resources/Const, concat_97/axis)]] Caused by op u'concat_97', defined at: File \"/usr/lib/python2.7/threading.py\", line 774, in __bootstrap self.__bootstrap_inner() File \"/usr/lib/python2.7/threading.py\", line 801, in __bootstrap_inner self.run() File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/distribute/python/mirrored_strategy.py\", line 465, in run self.main_result = self.main_fn(*self.main_args, **self.main_kwargs) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 1139, in create_per_tower_ready_op 'ready_op', ops.GraphKeys.READY_OP, default_ready_op) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/monitored_session.py\", line 264, in get_or_default op = default_constructor() File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/estimator/estimator.py\", line 1136, in default_ready_op ], 0) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/array_ops.py\", line 1189, in concat return gen_array_ops.concat_v2(values=values, axis=axis, name=name) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\", line 953, in concat_v2 \"ConcatV2\", values=values, axis=axis, name=name) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper op_def=op_def) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op op_def=op_def) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__ self._traceback = self._graph._extract_stack() # pylint: disable=protected-access InvalidArgumentError (see above for traceback): Cannot assign a device for operation 'concat_97': Could not satisfy explicit device specification '/device:GPU:0' because no supported kernel for GPU devices is available. Registered kernels: device='GPU'; T in [DT_INT32] device='GPU'; T in [DT_BOOL] device='GPU'; T in [DT_INT64] device='GPU'; T in [DT_COMPLEX128] device='GPU'; T in [DT_COMPLEX64] device='GPU'; T in [DT_UINT8] device='GPU'; T in [DT_BFLOAT16] device='GPU'; T in [DT_DOUBLE] device='GPU'; T in [DT_FLOAT] device='GPU'; T in [DT_HALF] device='CPU'; T in [DT_QINT32] device='CPU'; T in [DT_QINT16] device='CPU'; T in [DT_QUINT16] device='CPU'; T in [DT_QINT8] device='CPU'; T in [DT_QUINT8] device='CPU'; T in [DT_STRING] device='CPU'; T in [DT_BOOL] device='CPU'; T in [DT_COMPLEX128] device='CPU'; T in [DT_COMPLEX64] device='CPU'; T in [DT_DOUBLE] device='CPU'; T in [DT_FLOAT] device='CPU'; T in [DT_BFLOAT16] device='CPU'; T in [DT_HALF] device='CPU'; T in [DT_INT8] device='CPU'; T in [DT_UINT8] device='CPU'; T in [DT_INT16] device='CPU'; T in [DT_UINT16] device='CPU'; T in [DT_INT32] device='CPU'; T in [DT_INT64] [[Node: concat_97 = ConcatV2[N=2, T=DT_STRING, Tidx=DT_INT32, _device=\"/device:GPU:0\"](report_uninitialized_variables/boolean_mask/GatherV2, report_uninitialized_resources/Const, concat_97/axis)]]", "I got rid of the \"pack\" instruction. The code now fails in a different place (see trace above) and I am not able to identify where in my code it is. It looks like it is not in my code at all. What i do not understand is how can this work on a single GPU and fail with MirroredStrategy ?", "Added a PR #20378 to support int16 of Pack in GPU.", "@martin-gorner could you point me to your code? I think the failure doesn't happen on single GPU because the concat op that's failing wouldn't exist in that case (assuming you're running on one GPU without using any distribution strategy).\r\nFrom what i can tell from the stack trace, the concat is from there:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/estimator.py#L1456\r\nThis code in estimator is only reached when a distribution strategy like MirroredStrategy is present. \r\n\r\n\r\n\r\n", "OK, understood.\r\n@yongtang the second issue seems to be with \"concat\", not \"pack\"", "@guptapriya done\r\ncode sent through direct message", "Can you go back to the descriptions and format your log file?\r\n\r\nThank you.", "\"format your log file\" > I do not know what you mean ? ", "@martin-gorner If you use (three backticks):\r\n````\r\n```\r\nTraceback:\r\nTraceback (most recent call last): \r\n```\r\n````\r\n\r\nThe it will be formatted like the following:\r\n```\r\nTraceback:\r\nTraceback (most recent call last): \r\n```", "Yep, as @yongtang said. I tried this on your description, but it was pasted as a single line, so if you can paste by preserving the line endings and using the triple backticks, that would be great. Thank you!", "Don't use MirroredStrategy for between-graph replicated training for now. It doesn't work with \"worker\" and \"ps\" jobs. We'll have a strategy that works in this case.", "@yuefengz What strategy do you recommend for putting models on \"ps\" jobs?", "@ajbouh We'll have a ParameterServerStrategy soon which works both locally and on a cluster.", "Is this already in master?\r\n\r\nSearching the github repo for `ParameterServerStrategy` only returns this issue. :)", "It is still under review."]}, {"number": 20369, "title": "No registered 'NotEqual' OpKernel for GPU for INT32 type (but other types are fine).", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux 4.13.0-45-generic #50-Ubuntu SMP Wed May 30 08:23:18 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"17.10 (Artful Aardvark)\"\r\nVERSION_ID=\"17.10\"\r\nVERSION_CODENAME=artful\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary\r\n- **TensorFlow version (use command below)**:\r\n1.8\r\n- **Python version**: \r\n2.7\r\n- **Bazel version (if compiling from source)**:\r\nN/A\r\n- **GCC/Compiler version (if compiling from source)**:\r\nN/A\r\n- **CUDA/cuDNN version**:\r\nCUDA8.0 cuDNN9.0\r\n- **GPU model and memory**:\r\nTesla K80 10762 MB\r\n- **Exact command to reproduce**:\r\nSee below\r\n\r\n\r\n### Describe the problem\r\n------------------------\r\n\r\nWhen I run tf.not_equal under GPU, I got this error msg:\r\n\r\n> tensorflow.python.framework.errors_impl.NotFoundError: No registered 'NotEqual' OpKernel for GPU devices compatible with node NotEqual = NotEqual[T=DT_INT32](dummy_input, dummy_input)\r\n> \t (OpKernel was found, but attributes didn't match)\r\n> \t.  Registered:  device='CPU'; T in [DT_BOOL]\r\n>   device='CPU'; T in [DT_STRING]\r\n>   device='CPU'; T in [DT_COMPLEX128]\r\n>   device='CPU'; T in [DT_COMPLEX64]\r\n>   device='CPU'; T in [DT_INT64]\r\n>   device='CPU'; T in [DT_INT32]\r\n>   device='CPU'; T in [DT_INT16]\r\n>   device='CPU'; T in [DT_INT8]\r\n>   device='CPU'; T in [DT_UINT8]\r\n>   device='CPU'; T in [DT_DOUBLE]\r\n>   device='CPU'; T in [DT_HALF]\r\n>   device='CPU'; T in [DT_FLOAT]\r\n>   device='GPU'; T in [DT_BOOL]\r\n>   device='GPU'; T in [DT_COMPLEX128]\r\n>   device='GPU'; T in [DT_COMPLEX64]\r\n>   device='GPU'; T in [DT_INT64]\r\n>   device='GPU'; T in [DT_INT16]\r\n>   device='GPU'; T in [DT_INT8]\r\n>   device='GPU'; T in [DT_UINT8]\r\n>   device='GPU'; T in [DT_DOUBLE]\r\n>   device='GPU'; T in [DT_HALF]\r\n>   device='GPU'; T in [DT_FLOAT]\r\n>  [Op:NotEqual]\r\n>\r\nIt seems that INT32 is omitted forgetfully (jump from INT16 to INT64 directly)?", "comments": ["Sorry for the delay replying. I believe that INT32 ops are generally not registered on GPU. @zheng-xq may be able to give you the rationale and recommended workarounds.", "Yes, int32 is special in that all GPU kernels are actually CPU kernels. The reason behind it is that it is mostly used for shape arithmetic. The recommended workaround is to use either UINT32 or INT64. ", "@zheng-xq @robieta Updating our codebase, I'm hitting a similar issue with current tensorflow master:\r\n```\r\n         [[{{node lstm_fused_cell/SequenceMask/Range}} = Const[dtype=DT_INT32, value=Tensor<type: int32 shape: [16] values: 0 1 2...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\nError running session: Not found: No registered 'Const' OpKernel for GPU devices compatible with node {{node lstm_fused_cell/SequenceMask/Range}} = Const[dtype=DT_INT32, value=Tensor<type: int32 shape: [16] values: 0 1 2...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()\r\n         (OpKernel was found, but attributes didn't match)\r\n        .  Registered:  device='GPU'; dtype in [DT_VARIANT]\r\n  device='GPU'; dtype in [DT_BOOL]\r\n  device='GPU'; dtype in [DT_COMPLEX128]\r\n  device='GPU'; dtype in [DT_COMPLEX64]\r\n  device='GPU'; dtype in [DT_UINT64]\r\n  device='GPU'; dtype in [DT_INT64]\r\n  device='GPU'; dtype in [DT_QINT32]\r\n  device='GPU'; dtype in [DT_UINT32]\r\n  device='GPU'; dtype in [DT_QUINT16]\r\n  device='GPU'; dtype in [DT_QINT16]\r\n  device='GPU'; dtype in [DT_INT16]\r\n  device='GPU'; dtype in [DT_UINT16]\r\n  device='GPU'; dtype in [DT_QINT8]\r\n  device='GPU'; dtype in [DT_INT8]\r\n  device='GPU'; dtype in [DT_UINT8]\r\n  device='GPU'; dtype in [DT_DOUBLE]\r\n  device='GPU'; dtype in [DT_FLOAT]\r\n  device='GPU'; dtype in [DT_BFLOAT16]\r\n  device='GPU'; dtype in [DT_HALF]\r\n  device='CPU'\r\n         [[{{node lstm_fused_cell/SequenceMask/Range}} = Const[dtype=DT_INT32, value=Tensor<type: int32 shape: [16] values: 0 1 2...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n```\r\n\r\nThis is happening when trying to run inference from `libdeepspeech.so`, which links TensorFlow. However, the same code would work well with something based on TensorFlow r1.6. So it looks like something changed on that side, since. I could not find any evidence / documentation related.", "@zheng-xq @robieta Ok, my code works if I hack around `Const`:\r\n```\r\ndiff --git a/tensorflow/core/kernels/constant_op.cc b/tensorflow/core/kernels/constant_op.cc\r\nindex 426c404f43..d7973296ca 100644\r\n--- a/tensorflow/core/kernels/constant_op.cc\r\n+++ b/tensorflow/core/kernels/constant_op.cc\r\n@@ -108,6 +108,7 @@ REGISTER_KERNEL(GPU, int16);\r\n REGISTER_KERNEL(GPU, qint16);\r\n REGISTER_KERNEL(GPU, quint16);\r\n REGISTER_KERNEL(GPU, uint32);\r\n+REGISTER_KERNEL(GPU, int32);\r\n REGISTER_KERNEL(GPU, qint32);\r\n REGISTER_KERNEL(GPU, int64);\r\n REGISTER_KERNEL(GPU, uint64);\r\n```\r\n\r\nI am not convinced, however, that this is a viable solution. According to your comment earlier, I'm wondering if it's normal or not that we get a `int32`, it's within `LSTMBlockFusedCell`.", "@zheng-xq @robieta Can you provide more feedback ? Thanks.", "@zheng-xq @robieta ping ?", "Still no news on that ?", "> @zheng-xq @robieta Updating our codebase, I'm hitting a similar issue with current tensorflow master:\r\n> \r\n> ```\r\n>          [[{{node lstm_fused_cell/SequenceMask/Range}} = Const[dtype=DT_INT32, value=Tensor<type: int32 shape: [16] values: 0 1 2...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n> Error running session: Not found: No registered 'Const' OpKernel for GPU devices compatible with node {{node lstm_fused_cell/SequenceMask/Range}} = Const[dtype=DT_INT32, value=Tensor<type: int32 shape: [16] values: 0 1 2...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()\r\n>          (OpKernel was found, but attributes didn't match)\r\n>         .  Registered:  device='GPU'; dtype in [DT_VARIANT]\r\n>   device='GPU'; dtype in [DT_BOOL]\r\n>   device='GPU'; dtype in [DT_COMPLEX128]\r\n>   device='GPU'; dtype in [DT_COMPLEX64]\r\n>   device='GPU'; dtype in [DT_UINT64]\r\n>   device='GPU'; dtype in [DT_INT64]\r\n>   device='GPU'; dtype in [DT_QINT32]\r\n>   device='GPU'; dtype in [DT_UINT32]\r\n>   device='GPU'; dtype in [DT_QUINT16]\r\n>   device='GPU'; dtype in [DT_QINT16]\r\n>   device='GPU'; dtype in [DT_INT16]\r\n>   device='GPU'; dtype in [DT_UINT16]\r\n>   device='GPU'; dtype in [DT_QINT8]\r\n>   device='GPU'; dtype in [DT_INT8]\r\n>   device='GPU'; dtype in [DT_UINT8]\r\n>   device='GPU'; dtype in [DT_DOUBLE]\r\n>   device='GPU'; dtype in [DT_FLOAT]\r\n>   device='GPU'; dtype in [DT_BFLOAT16]\r\n>   device='GPU'; dtype in [DT_HALF]\r\n>   device='CPU'\r\n>          [[{{node lstm_fused_cell/SequenceMask/Range}} = Const[dtype=DT_INT32, value=Tensor<type: int32 shape: [16] values: 0 1 2...>, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n> ```\r\n> This is happening when trying to run inference from `libdeepspeech.so`, which links TensorFlow. However, the same code would work well with something based on TensorFlow r1.6. So it looks like something changed on that side, since. I could not find any evidence / documentation related.\r\n\r\nSame question with you. Any solutions ?", "@David-Mao \r\nCould you please try on latest stable version of tf and let us know if this is still an issue.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/20369\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/20369\">No</a>\n", "This is still a very relevant and difficult issue, please STOP closing issues just because they are hard to solve."]}, {"number": 20368, "title": "Using new tensorflow op for matrix exponential in a c++ library that already uses tensorflow as third party", "body": "### System information\r\n- **Have I written custom code**: I'm using ZeroOut CPU versionfrom https://github.com/MatteoRagni/tf.ZeroOut.gpu\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04 LTS\r\n- **TensorFlow installed from**: source\r\n- **TensorFlow version** : 1.8.0\r\n- **Python version**: Python 3.5.2\r\n- **Bazel version (if compiling from source)**: 0.14.1\r\n- **GCC/Compiler version (if compiling from source)**: gcc 5.4.0,  cmake 3.5.1\r\n- **CUDA/cuDNN version**: release 9.0, V9.0.176\r\n- **GPU model and memory**: GeForce GT 730/PCIe/SSE2\r\n- **Exact command to reproduce**: N/A\r\n\r\n\r\nHallo to everyone! That's my first time asking a question in tensorflow. I will try my best to formulate my question properly.\r\n\r\nMy plan is: \r\n\r\n - implement a new tensorflow GPU op for the matrix exponential,using Eigen unsupported MatrixFunctions or the already existing tensorflow matrix exponential op\r\n - add the gradient\r\n - use the new op in a c++ library, which already uses tensorflow as third party.\r\n\r\nI have started from the basics, and I realized that I don't know how to use my custom operation in c++. I registered the ZeroOut op for cpu from tensorflow c++ tutorial as in https://github.com/MatteoRagni/tf.ZeroOut.gpu but now I don't know how to use that in my c++ code. \r\n\r\nI tried to add the ZeroOut.so file to my lib as shared library, but it didn't work. Maybe I'm doing something wrong? My CMakeList.txt is attached. And including  ZeroOut.cpp in my c++ files hasn't make any difference until now.\r\nI looked in tensorflow documentation, stackoverflow and the internet but I couln't find an answer to my questions. Hopefully I didn't miss anything.\r\n\r\nCan you help me? Maybe giving an example of the required CMakeList.txt, even if not related to mine?\r\n\r\nSpeaking about my general plan, I would also like to have some advices from more experienced programmers. I know tensorflow has a matrix exponential op, but as far as I know it doesn't work for GPU (see #15465) and has no gradient implementation. Should I add this features to the existing op rather than registering a new one? And what about using Eigen unsupported MatrixFunctions in a new user op?\r\n\r\n### Source code / logs\r\nHere is my CMakeList.txt, which also creates the whole library I'm working with:\r\n\r\n    cmake_minimum_required(VERSION 2.8)\r\n    project(Project1)\r\n\r\n    set(CMAKE_BUILD_TYPE \"Release\") # Debug Release\r\n    set(CMAKE_CXX_FLAGS_RELEASE \"$ENV{CXXFLAGS} -std=c++14 -O3 -Wall                 -fopenmp\")\r\n    SET(CMAKE_MODULE_PATH ${PROJECT_SOURCE_DIR}/cmake)\r\n\r\n    #-------------path of 3rd party libraries-------------\r\n    # special libs.\r\n    find_package(Boost COMPONENTS filesystem iostreams regex)\r\n    find_package(FFTW)\r\n    find_package(NLopt)\r\n    find_package(HDF5 COMPONENTS CXX)\r\n\r\n    set(EXTERN_LIB_ROOT ${PROJECT_SOURCE_DIR}/3rd-party)\r\n\r\n    set(TENSORFLOW_ROOT /.../tensorflow)\r\n    set(TF_INCLUDE_DIRS \"${TENSORFLOW_ROOT}\" \"${TENSORFLOW_ROOT}/bazel-  genfiles\" \"${TENSORFLOW_ROOT}/bazel-tensorflow/external/protobuf_archive/src\")\r\n\r\n    # lib dirs.\r\n    set(LUA_LIBRARIES \"${EXTERN_LIB_ROOT}/lua/liblua53.so\") #5.3.4\r\n    set(LINENOISE_LIBRARIES \"${EXTERN_LIB_ROOT}/linenoise-ng/build/liblinenoise.so\")\r\n    set(YACAS_LIBRARIES \"${EXTERN_LIB_ROOT}/yacas/cyacas/libyacas/build/libyacas.so\")\r\n\r\n\r\n    set(TF_LIBRARIES ${TENSORFLOW_ROOT}/bazel-bin/tensorflow/libtensorflow_cc.so\r\n        ${TENSORFLOW_ROOT}/tensorflow/core/user_ops/tf.ZeroOut.gpu-master/zero_out.so) \r\n    #-------------ssl headers-------------\r\n    include_directories(${PROJECT_SOURCE_DIR}/src\r\n        ${EXTERN_LIB_ROOT}/eigen\r\n        ${EXTERN_LIB_ROOT}/gnuplot-iostream\r\n        ${EXTERN_LIB_ROOT}/\r\n        ${EXTERN_LIB_ROOT}/linenoise-ng/include\r\n        ${EXTERN_LIB_ROOT}/yacas/cyacas/libyacas/include\r\n        ${EXTERN_LIB_ROOT}/lua/src\r\n        ${NLOPT_INCLUDE_DIRS}\r\n        ${FFTW_INCLUDES}\r\n        ${TF_INCLUDE_DIRS}\r\n        ${Boost_INCLUDE_DIRS}\r\n        ${HDF5_INCLUDE_DIRS}\r\n        ${TENSORFLOW_ROOT}) \r\n\r\n    option(BUILD_SHARED_LIBS \"build shared library\" ON)\r\n    set(LIBRARY_OUTPUT_PATH ${PROJECT_BINARY_DIR}/lib)\r\n\r\n    #-------------ssl kernel lib-------------\r\n    file(GLOB_RECURSE _src_list\r\n        LIST_DIRECTORIES false\r\n        RELATIVE \"${CMAKE_CURRENT_SOURCE_DIR}\" \"${PROJECT_SOURCE_DIR}/src/*.h\" \"${PROJECT_SOURCE_DIR}/src/*.cpp\" \"\")\r\n\r\n    add_library(ssl SHARED ${_src_list})\r\n\r\n    set(SSL_LIBRARIES ${TF_LIBRARIES} ${LUA_LIBRARIES} ${Boost_LIBRARIES}     ${NLOPT_LIBRARIES} ${FFTW_LIBRARIES} ${LINENOISE_LIBRARIES} ${YACAS_LIBRARIES} ${HDF5_CXX_LIBRARIES}) #${TF_LIBRARIES}\r\n\r\n    target_link_libraries(ssl ${SSL_LIBRARIES} dl)\r\n\r\n    add_executable(Project1 main.cpp)\r\n    target_link_libraries(Project1 ssl)\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nExact command to reproduce", "I did, thank you for let me noticing this. I was wondering if maybe the best option is to build the graph in python at runtime, with data from my c++ library, and  then importing it to the library to run it.", "You can see existing ops in TensorFlow as an example. The best way is often through bazel. \r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/kernels/lstm_ops_gpu.cu.cc\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/BUILD\r\n", "Useful links! I compiled the op independently with bazel and it worked, I can use it in python. As far as I know I can't use it in c++. But how to add dependencies to other libraries in the bazel build file? I would like to use some Eigen functions in the op.", "@Ceveloper,\r\nSorry for the delayed response. Please refer [this Documentation](https://www.tensorflow.org/guide/create_op) which explains in detail, how to create **`New Tensorflow Op`** and then how to build it using **`Bazel`**. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/20368\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/20368\">No</a>\n"]}, {"number": 20367, "title": "Using new tensorflow op for matrix exponential in a c++ library that already uses tensorflow as third party", "body": "### System information\r\n- **Have I written custom code**: I'm using ZeroOut CPU versionfrom https://github.com/MatteoRagni/tf.ZeroOut.gpu\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04 LTS\r\n- **TensorFlow installed from**: source\r\n- **TensorFlow version** : 1.8.0\r\n- **Python version**: Python 3.5.2\r\n- **Bazel version (if compiling from source)**: 0.14.1\r\n- **GCC/Compiler version (if compiling from source)**: gcc 5.4.0,  cmake 3.5.1\r\n- **CUDA/cuDNN version**: release 9.0, V9.0.176\r\n- **GPU model and memory**: GeForce GT 730/PCIe/SSE2\r\n\r\n\r\nHallo to everyone! That's my first time asking a question in tensorflow. I will try my best to formulate my question properly.\r\n\r\nMy plan is: \r\n\r\n - implement a new tensorflow GPU op for the matrix exponential,using Eigen unsupported MatrixFunctions or the already existing tensorflow matrix exponential op\r\n - add the gradient\r\n - use the new op in a c++ library, which already uses tensorflow as third party.\r\n\r\nI have started from the basics, and I realized that I don't know how to use my custom operation in c++. I registered the ZeroOut op for cpu from tensorflow c++ tutorial as in https://github.com/MatteoRagni/tf.ZeroOut.gpu but now I don't know how to use that in my c++ code. \r\n\r\nI tried to add the ZeroOut.so file to my lib as shared library, but it didn't work. Maybe I'm doing something wrong? My CMakeList.txt is attached. And including  ZeroOut.cpp in my c++ files hasn't make any difference until now.\r\nI looked in tensorflow documentation, stackoverflow and the internet but I couln't find an answer to my questions. Hopefully I didn't miss anything.\r\n\r\nCan you help me? Maybe giving an example of the required CMakeList.txt, even if not related to mine?\r\n\r\nSpeaking about my general plan, I would also like to have some advices from more experienced programmers. I know tensorflow has a matrix exponential op, but as far as I know it doesn't work for GPU (see #15465) and has no gradient implementation. Should I add this features to the existing op rather than registering a new one? And what about using Eigen unsupported MatrixFunctions in a new user op?\r\n\r\n### Source code / logs\r\nHere is my CMakeList.txt, which also creates the whole library I'm working with:\r\n\r\n    cmake_minimum_required(VERSION 2.8)\r\n    project(Project1)\r\n\r\n    set(CMAKE_BUILD_TYPE \"Release\") # Debug Release\r\n    set(CMAKE_CXX_FLAGS_RELEASE \"$ENV{CXXFLAGS} -std=c++14 -O3 -Wall                 -fopenmp\")\r\n    SET(CMAKE_MODULE_PATH ${PROJECT_SOURCE_DIR}/cmake)\r\n\r\n    #-------------path of 3rd party libraries-------------\r\n    # special libs.\r\n    find_package(Boost COMPONENTS filesystem iostreams regex)\r\n    find_package(FFTW)\r\n    find_package(NLopt)\r\n    find_package(HDF5 COMPONENTS CXX)\r\n\r\n    set(EXTERN_LIB_ROOT ${PROJECT_SOURCE_DIR}/3rd-party)\r\n\r\n    set(TENSORFLOW_ROOT /.../tensorflow)\r\n    set(TF_INCLUDE_DIRS \"${TENSORFLOW_ROOT}\" \"${TENSORFLOW_ROOT}/bazel-  genfiles\" \"${TENSORFLOW_ROOT}/bazel-tensorflow/external/protobuf_archive/src\")\r\n\r\n    # lib dirs.\r\n    set(LUA_LIBRARIES \"${EXTERN_LIB_ROOT}/lua/liblua53.so\") #5.3.4\r\n    set(LINENOISE_LIBRARIES \"${EXTERN_LIB_ROOT}/linenoise-ng/build/liblinenoise.so\")\r\n    set(YACAS_LIBRARIES \"${EXTERN_LIB_ROOT}/yacas/cyacas/libyacas/build/libyacas.so\")\r\n\r\n\r\n    set(TF_LIBRARIES ${TENSORFLOW_ROOT}/bazel-bin/tensorflow/libtensorflow_cc.so\r\n        ${TENSORFLOW_ROOT}/tensorflow/core/user_ops/tf.ZeroOut.gpu-master/zero_out.so) \r\n    #-------------ssl headers-------------\r\n    include_directories(${PROJECT_SOURCE_DIR}/src\r\n        ${EXTERN_LIB_ROOT}/eigen\r\n        ${EXTERN_LIB_ROOT}/gnuplot-iostream\r\n        ${EXTERN_LIB_ROOT}/\r\n        ${EXTERN_LIB_ROOT}/linenoise-ng/include\r\n        ${EXTERN_LIB_ROOT}/yacas/cyacas/libyacas/include\r\n        ${EXTERN_LIB_ROOT}/lua/src\r\n        ${NLOPT_INCLUDE_DIRS}\r\n        ${FFTW_INCLUDES}\r\n        ${TF_INCLUDE_DIRS}\r\n        ${Boost_INCLUDE_DIRS}\r\n        ${HDF5_INCLUDE_DIRS}\r\n        ${TENSORFLOW_ROOT}) \r\n\r\n    option(BUILD_SHARED_LIBS \"build shared library\" ON)\r\n    set(LIBRARY_OUTPUT_PATH ${PROJECT_BINARY_DIR}/lib)\r\n\r\n    #-------------ssl kernel lib-------------\r\n    file(GLOB_RECURSE _src_list\r\n        LIST_DIRECTORIES false\r\n        RELATIVE \"${CMAKE_CURRENT_SOURCE_DIR}\" \"${PROJECT_SOURCE_DIR}/src/*.h\" \"${PROJECT_SOURCE_DIR}/src/*.cpp\" \"\")\r\n\r\n    add_library(ssl SHARED ${_src_list})\r\n\r\n    set(SSL_LIBRARIES ${TF_LIBRARIES} ${LUA_LIBRARIES} ${Boost_LIBRARIES}     ${NLOPT_LIBRARIES} ${FFTW_LIBRARIES} ${LINENOISE_LIBRARIES} ${YACAS_LIBRARIES} ${HDF5_CXX_LIBRARIES}) #${TF_LIBRARIES}\r\n\r\n    target_link_libraries(ssl ${SSL_LIBRARIES} dl)\r\n\r\n    add_executable(Project1 main.cpp)\r\n    target_link_libraries(Project1 ssl)\r\n", "comments": []}, {"number": 20366, "title": "Fix tf.contrib.ffmpeg.decode_video error", "body": "This fix tries to address the issue raised in #20348 where ffmpeg on Ubuntu 18.04 causes the error when decoding video. The reason was that different versions of ffmpeg may place `Input/Outpu/Stream mapping` sections in different orders in the stdout/stderr.\r\n\r\nThis fix address the issue by improve the parser of the dumped output.\r\n\r\nThis fix fixes #20348.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Thanks for the quick fix! According to [this](https://trac.ffmpeg.org/wiki/FFprobeTips#Getdurationbydecoding), the correct number of frames is always reported on the second-to-last line. Maybe that's a better heuristic?", "Created an alternative fix #20388.", "@yongtang should we proceed with #20388?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "It has been 43 days that this pull-request has stalled. Please create a new pull-request with the requested changes."]}, {"number": 20365, "title": "create platform for remote execution", "body": "* Platform target defines container to use for remote builds.\r\n* This PR is part of the process to deprecate use of\r\nexperimental_remote_platform_override which will consolidate the\r\ndefinition of the container to use for remote builds.\r\n* also update dockerfile for rbe to indicate base is Ubuntu 16-04", "comments": ["@erain @yifeif @gunan - could you please review? thanks!"]}, {"number": 20364, "title": "Add JavaScript to list of languages not covered by the backwards compatibility guarantee", "body": "JS should be listed at https://www.tensorflow.org/api_docs/ as well.", "comments": ["Nagging Assignee @yifeif: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 20363, "title": "'DNNBoostedTreeCombinedClassifier' default argument setting would lead to error", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.8.0\r\n- **Python version**: 2.7.14\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nIn `DNNBoostedTreeCombinedClassifier`, the default setting for `tree_feature_columns` is None and the default setting for `dnn_input_layer_to_tree` is True. In `dnn_tree_combined_estimator.py`:  https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/boosted_trees/estimator_batch/dnn_tree_combined_estimator.py#L228 there is an append operation for `tree_feature_columns` which would lead to a `AttributeError: 'NoneType' object has no attribute 'append'`. Current boston_combined example for `DNNBoostedTreeCombinedClassifier` also failed due to the same reason.\r\n\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "@tensorflowbutler Updated!", "Since this is in contrib this is not officially supported. Perhaps @taharafiq, one of the original authors could provide some help.", "@voe09 , DNNBoostedTreeCombinedClassifier has been depreciated, you can use something similar like [tf.estimator.DNNClassifier](https://www.tensorflow.org/api_docs/python/tf/estimator/DNNClassifier) or [tf.estimator.BoostedTreesClassifier](https://www.tensorflow.org/api_docs/python/tf/estimator/BoostedTreesClassifier)", "Hi There,\n\n We are checking to see if you still need help on this issue, as you are using an older version of tensorflow(1.x) which is officially considered as end of life. We recommend that you upgrade to 2.4 or later version and let us know if the issue still persists in newer versions. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, Please open a new issue for any help you need against 2.x, and we will get you the right help. ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/20363\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/20363\">No</a>\n"]}, {"number": 20362, "title": "Does Tensorflow install on 32-bit Windows 7 ? ", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nI could not install Tensorflow on my Win 7 32-bit machine through Anaconda or Pycharm, but I did\r\non my Win 7 64-bit machine.  \r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["Hi @paulgureghian. TensorFlow is [only tested and supported for 64-bit, x86 systems](https://www.tensorflow.org/install/install_windows). I don't believe you can install TensorFlow through `pip` or `conda` normally from a 32-bit system. If you take a look [here](https://pypi.org/project/tensorflow/#files), only 64-bit systems are listed for Windows.\r\n\r\nPerhaps you could try to [build and install TensorFlow from source instead](https://www.tensorflow.org/install/install_sources). But, to avoid the headache, maybe you could dual boot Linux :) ", "Or just use Theano as the backend to Keras ?  ", "Actually, I think I may be wrong. I believe TensorFlow will work on your 32-bit system as long as you are using 64-bit Python. Can you try that? \r\n\r\nBesides what I've already mentioned, I don't think I can help much more. I'll let someone else pickup from here.", "how to run python 64 on a 32 bit system ? ", "You cannot run 64 bit software on a 32 bit OS.\r\nSome users had success compiling TF on 32 bit systems, but we have not.\r\nUnfortunately, that is all I have about this issue. You may try searching for relevant issues or stackoverflow questions to see what people did to build TF on 32 bit systems.", "You're right. Sorry to cause confusion. I'm not sure what I was thinking.\r\n\r\nI hope you can get TensorFlow working for you, @paulgureghian ", "Using docker on 64-bit Linux to make tensorflow worked is a better way.\r\n\r\nIf you insist, you can help test this 32 bit built.\r\n\r\nhttps://github.com/fo40225/tensorflow-windows-wheel/tree/master/1.8.0/py36/CPU/sse2", "On windows, you cannot have linux docker container. Also, on an 32 bit OS you cannot run 64 bit docker containers.\r\nI think what you are proposing is this:\r\nhttps://stackoverflow.com/questions/56124/can-i-run-a-64-bit-vmware-image-on-a-32-bit-machine", "@gunan You CAN run a linux docker container thought [docker for windows](https://docs.docker.com/docker-for-windows/#switch-between-windows-and-linux-containers), but it is based on vm and it didn't support gpu.\r\n\r\nI have provided a 32 bit tensorflow built for windows, although it's not a helpful thing.\r\n\r\n32-bit process can use only 2GB memory; a complex model would not load.", "Yes, you are right, that is possible.\r\nAnd if you run a 64 bit VM with the help of the above stackoverflow question, you can run a 64 bit container in that VM.\r\n\r\n@paulgureghian please see the discussion above. You can try the 32 bit pip package keeping in mind the memory restriction @fo40225 pointed out.\r\nOr you can try running a 64 bit VM on your machine, if your CPU has the right extensions.", "As this issue has invited community support, please remove the assignee. Otherwise, remove the `community support` label. Thank you.", "if you use Anaconda, you can use  `conda install -c hesi_m tensorflow ` to install **tensorflow 1.9.0** for CPU \r\n\r\nif you specifically use Keras also, you can use  `conda install -c hesi_m keras` which installs **Keras 2.2.2** in accompany with everything including tensorflow 1.9.0\r\n\r\nIt is better to make a fresh anaconda environment for your experiments", "Hi \r\n\r\nI need to install and configure Tensorflow on my Windows-7 32-bit OS through Anaconda 5.3 Python 3.6 version and facing lot of issues. Please let me know steps to follow from scratch (and share if any specific installer I will start the process from scratch)\r\n\r\nThanks\r\n", "@arindam-mallik  Did you have any success building binaries for Windows 32-bit?\r\n\r\nI am looking for built binaries .dll  and .lib for 32bit machines.", "Since building 32-bit binaries from the source code seemed like it might be a bit over my head, I just use TF on my 64-bit machine instead through Anaconda. ", "Tensorflow does not work for 32 bit os.\n\nAlso in 64 bit OS, if Nvidia graphics not available GPU version of\ntensorflow we cannot but you can install CPU version.\n\nThanks & Regards\nArindam\n\nOn Sat, 30 Mar, 2019, 12:57 AM Paul Armen Gureghian, <\nnotifications@github.com> wrote:\n\n> Since building 32-bit binaries from the source code seemed like it might\n> be a bit over my head, I just use TF on my 64-bit machine instead through\n> Anaconda.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/20362#issuecomment-478120749>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/Aqf0vF1SZ3ZMY_Gp3-INtkhFVmbkZwaQks5vbmkxgaJpZM4U6hNd>\n> .\n>\n", "My use case is basic CPU operations only, though I do need 32 bit capabilities. I am looking into model conversion into another format that supports 32bit. ", "What about Keras, Pytorch, Caffe, Theano, or MXNet ? ", "Keras will not work in 32 bit OS too.\n\nI suggest you can utilize Google colaboratory lab and try your coding in\ncloud.\n\nThanks\nArindam\n\nOn Sat, 30 Mar, 2019, 9:59 PM Paul Armen Gureghian, <\nnotifications@github.com> wrote:\n\n> What about Keras, Pytorch, Caffe, Theano, or MXNet ?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/20362#issuecomment-478261505>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/Aqf0vKglsEpzMK1OzARYkaAFYdzUC7-Yks5vb5DtgaJpZM4U6hNd>\n> .\n>\n", "https://github.com/tensorflow/tensorflow/issues/32315", "Closing as #32315 duplicates it.", "https://github.com/tensorflow/tensorflow/issues/32627", "Hi, I have detailed instructions to compile and install Tensorflow in an 32 bits linux in this repository: [tensorflow-32-bits-linux](https://github.com/jahnog/tensorflow-32-bits-linux)", "> if you use Anaconda, you can use  `conda install -c hesi_m tensorflow ` to install **tensorflow 1.9.0** for CPU \n> \n> if you specifically use Keras also, you can use  `conda install -c hesi_m keras` which installs **Keras 2.2.2** in accompany with everything including tensorflow 1.9.0\n> \n> It is better to make a fresh anaconda environment for your experiments\n\nThis command worked when installing tensorflow"]}, {"number": 20361, "title": "ppc64le: //tensorflow/contrib/lite/kernels:resize_bilinear_test test fails CPU test", "body": "Please assign this issue to me and add the tag: stat:community support\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ppc64le Ubuntu 16.04.4\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: master from June 27th\r\n- **Python version**: 2.7.12\r\n- **Bazel version (if compiling from source)**: 0.11.0\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**:\r\nbazel test -c opt --cache_test_results=no //tensorflow/contrib/lite/kernels:resize_bilinear_test\r\n\r\n\r\n### Describe the problem\r\n```\r\nFAIL: //tensorflow/contrib/lite/kernels:resize_bilinear_test (see /root/.cache/bazel/_bazel_root/eab0d61a99b6696edb3d2aff87b585e8/execroot/org_tensorflow/bazel-out/ppc-opt/testlogs/tensorflow/contrib/lite/kernels/resize_bilinear_test/test.log)\r\nINFO: From Testing //tensorflow/contrib/lite/kernels:resize_bilinear_test:\r\n==================== Test output for //tensorflow/contrib/lite/kernels:resize_bilinear_test:\r\n[==========] Running 10 tests from 1 test case.\r\n[----------] Global test environment set-up.\r\n[----------] 10 tests from ResizeBilinearOpTest\r\n[ RUN      ] ResizeBilinearOpTest.HorizontalResize\r\n[       OK ] ResizeBilinearOpTest.HorizontalResize (0 ms)\r\n[ RUN      ] ResizeBilinearOpTest.HorizontalResize8Bit\r\n[       OK ] ResizeBilinearOpTest.HorizontalResize8Bit (0 ms)\r\n[ RUN      ] ResizeBilinearOpTest.VerticalResize\r\n[       OK ] ResizeBilinearOpTest.VerticalResize (0 ms)\r\n[ RUN      ] ResizeBilinearOpTest.VerticalResize8Bit\r\n[       OK ] ResizeBilinearOpTest.VerticalResize8Bit (0 ms)\r\n[ RUN      ] ResizeBilinearOpTest.TwoDimensionalResize\r\n[       OK ] ResizeBilinearOpTest.TwoDimensionalResize (0 ms)\r\n[ RUN      ] ResizeBilinearOpTest.TwoDimensionalResize8Bit\r\n[       OK ] ResizeBilinearOpTest.TwoDimensionalResize8Bit (1 ms)\r\n[ RUN      ] ResizeBilinearOpTest.TwoDimensionalResizeWithTwoBatches\r\n[       OK ] ResizeBilinearOpTest.TwoDimensionalResizeWithTwoBatches (0 ms)\r\n[ RUN      ] ResizeBilinearOpTest.ThreeDimensionalResize\r\n[       OK ] ResizeBilinearOpTest.ThreeDimensionalResize (0 ms)\r\n[ RUN      ] ResizeBilinearOpTest.TwoDimensionalResizeWithTwoBatches8Bit\r\ntensorflow/contrib/lite/kernels/resize_bilinear_test.cc:261: Failure\r\nValue of: m.GetOutput<uint8>()\r\nExpected: has 18 elements where\r\nelement #0 is approximately 3 (absolute error <= 9.9999997e-06),\r\nelement #1 is approximately 5 (absolute error <= 9.9999997e-06),\r\nelement #2 is approximately 6 (absolute error <= 9.9999997e-06),\r\nelement #3 is approximately 7 (absolute error <= 9.9999997e-06),\r\nelement #4 is approximately 9 (absolute error <= 9.9999997e-06),\r\nelement #5 is approximately 10 (absolute error <= 9.9999997e-06),\r\nelement #6 is approximately 9 (absolute error <= 9.9999997e-06),\r\nelement #7 is approximately 11 (absolute error <= 9.9999997e-06),\r\nelement #8 is approximately 12 (absolute error <= 9.9999997e-06),\r\nelement #9 is approximately 4 (absolute error <= 9.9999997e-06),\r\nelement #10 is approximately 8 (absolute error <= 9.9999997e-06),\r\nelement #11 is approximately 10 (absolute error <= 9.9999997e-06),\r\nelement #12 is approximately 8 (absolute error <= 9.9999997e-06),\r\nelement #13 is approximately 12 (absolute error <= 9.9999997e-06),\r\nelement #14 is approximately 14 (absolute error <= 9.9999997e-06),\r\nelement #15 is approximately 10 (absolute error <= 9.9999997e-06),\r\nelement #16 is approximately 13 (absolute error <= 9.9999997e-06),\r\nelement #17 is approximately 16 (absolute error <= 9.9999997e-06)\r\n  Actual: { '\\x3' (3), '\\x5' (5), '\\x6' (6), '\\a' (7), '\\t' (9), '\\n' (10, 0xA), '\\t' (9), '\\v' (11, 0xB), '\\f' (12, 0xC), '\\x4' (4), '\\b' (8), '\\n' (10, 0xA), '\\b' (8), '\\f' (12, 0xC), '\\xE' (14), '\\n' (10, 0xA), '\\xE' (14), '\\x10' (16) }, whose element #16 doesn't match, which is 1 from 13\r\ntensorflow/contrib/lite/kernels/resize_bilinear_test.cc:278: Failure\r\nValue of: const_m.GetOutput<uint8>()\r\nExpected: has 18 elements where\r\nelement #0 is approximately 3 (absolute error <= 9.9999997e-06),\r\nelement #1 is approximately 5 (absolute error <= 9.9999997e-06),\r\nelement #2 is approximately 6 (absolute error <= 9.9999997e-06),\r\nelement #3 is approximately 7 (absolute error <= 9.9999997e-06),\r\nelement #4 is approximately 9 (absolute error <= 9.9999997e-06),\r\nelement #5 is approximately 10 (absolute error <= 9.9999997e-06),\r\nelement #6 is approximately 9 (absolute error <= 9.9999997e-06),\r\nelement #7 is approximately 11 (absolute error <= 9.9999997e-06),\r\nelement #8 is approximately 12 (absolute error <= 9.9999997e-06),\r\nelement #9 is approximately 4 (absolute error <= 9.9999997e-06),\r\nelement #10 is approximately 8 (absolute error <= 9.9999997e-06),\r\nelement #11 is approximately 10 (absolute error <= 9.9999997e-06),\r\nelement #12 is approximately 8 (absolute error <= 9.9999997e-06),\r\nelement #13 is approximately 12 (absolute error <= 9.9999997e-06),\r\nelement #14 is approximately 14 (absolute error <= 9.9999997e-06),\r\nelement #15 is approximately 10 (absolute error <= 9.9999997e-06),\r\nelement #16 is approximately 13 (absolute error <= 9.9999997e-06),\r\nelement #17 is approximately 16 (absolute error <= 9.9999997e-06)\r\n  Actual: { '\\x3' (3), '\\x5' (5), '\\x6' (6), '\\a' (7), '\\t' (9), '\\n' (10, 0xA), '\\t' (9), '\\v' (11, 0xB), '\\f' (12, 0xC), '\\x4' (4), '\\b' (8), '\\n' (10, 0xA), '\\b' (8), '\\f' (12, 0xC), '\\xE' (14), '\\n' (10, 0xA), '\\xE' (14), '          \\x10' (16) }, whose element #16 doesn't match, which is 1 from 13\r\n[  FAILED  ] ResizeBilinearOpTest.TwoDimensionalResizeWithTwoBatches8Bit (0 ms)\r\n[ RUN      ] ResizeBilinearOpTest.ThreeDimensionalResize8Bit\r\ntensorflow/contrib/lite/kernels/resize_bilinear_test.cc:293: Failure\r\nValue of: m.GetOutput<uint8>()\r\nExpected: has 18 elements where\r\nelement #0 is approximately 3 (absolute error <= 9.9999997e-06),\r\nelement #1 is approximately 4 (absolute error <= 9.9999997e-06),\r\nelement #2 is approximately 5 (absolute error <= 9.9999997e-06),\r\nelement #3 is approximately 8 (absolute error <= 9.9999997e-06),\r\nelement #4 is approximately 6 (absolute error <= 9.9999997e-06),\r\nelement #5 is approximately 10 (absolute error <= 9.9999997e-06),\r\nelement #6 is approximately 7 (absolute error <= 9.9999997e-06),\r\nelement #7 is approximately 8 (absolute error <= 9.9999997e-06),\r\nelement #8 is approximately 9 (absolute error <= 9.9999997e-06),\r\nelement #9 is approximately 12 (absolute error <= 9.9999997e-06),\r\nelement #10 is approximately 10 (absolute error <= 9.9999997e-06),\r\nelement #11 is approximately 14 (absolute error <= 9.9999997e-06),\r\nelement #12 is approximately 9 (absolute error <= 9.9999997e-06),\r\nelement #13 is approximately 10 (absolute error <= 9.9999997e-06),\r\nelement #14 is approximately 11 (absolute error <= 9.9999997e-06),\r\nelement #15 is approximately 13 (absolute error <= 9.9999997e-06),\r\nelement #16 is approximately 12 (absolute error <= 9.9999997e-06),\r\nelement #17 is approximately 16 (absolute error <= 9.9999997e-06)\r\n  Actual: { '\\x3' (3), '\\x4' (4), '\\x5' (5), '\\b' (8), '\\x6' (6), '\\n' (10, 0xA), '\\a' (7), '\\b' (8), '\\t' (9), '\\f' (12, 0xC), '\\n' (10, 0xA), '\\xE' (14), '\\t' (9), '\\n' (10, 0xA), '\\v' (11, 0xB), '\\xE' (14), '\\f' (12, 0xC), '          \\x10' (16) }, whose element #15 doesn't match, which is 1 from 13\r\ntensorflow/contrib/lite/kernels/resize_bilinear_test.cc:305: Failure\r\nValue of: const_m.GetOutput<uint8>()\r\nExpected: has 18 elements where\r\nelement #0 is approximately 3 (absolute error <= 9.9999997e-06),\r\nelement #1 is approximately 4 (absolute error <= 9.9999997e-06),\r\nelement #2 is approximately 5 (absolute error <= 9.9999997e-06),\r\nelement #3 is approximately 8 (absolute error <= 9.9999997e-06),\r\nelement #4 is approximately 6 (absolute error <= 9.9999997e-06),\r\nelement #5 is approximately 10 (absolute error <= 9.9999997e-06),\r\nelement #6 is approximately 7 (absolute error <= 9.9999997e-06),\r\nelement #7 is approximately 8 (absolute error <= 9.9999997e-06),\r\nelement #8 is approximately 9 (absolute error <= 9.9999997e-06),\r\nelement #9 is approximately 12 (absolute error <= 9.9999997e-06),\r\nelement #10 is approximately 10 (absolute error <= 9.9999997e-06),\r\nelement #11 is approximately 14 (absolute error <= 9.9999997e-06),\r\nelement #12 is approximately 9 (absolute error <= 9.9999997e-06),\r\nelement #13 is approximately 10 (absolute error <= 9.9999997e-06),\r\nelement #14 is approximately 11 (absolute error <= 9.9999997e-06),\r\nelement #15 is approximately 13 (absolute error <= 9.9999997e-06),\r\nelement #16 is approximately 12 (absolute error <= 9.9999997e-06),\r\nelement #17 is approximately 16 (absolute error <= 9.9999997e-06)\r\n  Actual: { '\\x3' (3), '\\x4' (4), '\\x5' (5), '\\b' (8), '\\x6' (6), '\\n' (10, 0xA), '\\a' (7), '\\b' (8), '\\t' (9), '\\f' (12, 0xC), '\\n' (10, 0xA), '\\xE' (14), '\\t' (9), '\\n' (10, 0xA), '\\v' (11, 0xB), '\\xE' (14), '\\f' (12, 0xC), '          \\x10' (16) }, whose element #15 doesn't match, which is 1 from 13\r\n[  FAILED  ] ResizeBilinearOpTest.ThreeDimensionalResize8Bit (1 ms)\r\n[----------] 10 tests from ResizeBilinearOpTest (2 ms total)\r\n\r\n[----------] Global test environment tear-down\r\n[==========] 10 tests from 1 test case ran. (2 ms total)\r\n[  PASSED  ] 8 tests.\r\n[  FAILED  ] 2 tests, listed below:\r\n[  FAILED  ] ResizeBilinearOpTest.TwoDimensionalResizeWithTwoBatches8Bit\r\n[  FAILED  ] ResizeBilinearOpTest.ThreeDimensionalResize8Bit\r\n\r\n 2 FAILED TESTS\r\n================================================================================\r\n```\r\n\r\n### Source code / logs\r\nsee above\r\n", "comments": ["@wdirons , this test is not failing for me on ppc64le (CPU setup). I'm using community build mechanism and running the tests :\r\n\r\n```\r\n$  bazel test -c opt //tensorflow/contrib/lite/kernels:resize_bilinear_test \r\nINFO: Analysed target //tensorflow/contrib/lite/kernels:resize_bilinear_test (11 packages loaded).\r\nINFO: Found 1 test target...\r\nTarget //tensorflow/contrib/lite/kernels:resize_bilinear_test up-to-date:\r\n  bazel-bin/tensorflow/contrib/lite/kernels/resize_bilinear_test\r\nINFO: Elapsed time: 5.103s, Critical Path: 0.79s\r\nINFO: Build completed successfully, 1 total action\r\n//tensorflow/contrib/lite/kernels:resize_bilinear_test          (cached) PASSED in 0.8s\r\n```", "@sandipmgiri - The test passes if you use 1.9.0rc0 tag because it didn't have support for uint8_t datatype, moreover the test file resize_bilinear_test.cc itself didn't include any tests for uint8_t datatype. The support for generic datatype was added later in the commit https://github.com/tensorflow/tensorflow/commit/4f912021b04f5f82b0d1a6bba5b32a24d7cb9fca and so are the new tests in the resize_bilinear_test which are failing for me on ppc64le. ", "Found the cause of the issue. Working to fix the problem.\r\nThe way float value is type casted to uint8_t at https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h#L5506 is the root cause of the problem on ppc64le . If the calculated value is collected in a float datatype, it gives correct value.", "Further debugging this on both x86 and ppc64le, I found some weirdness on x86 and ppc64le behaving appropriately -\r\nBelow is the code snippet from optimized_ops.h which is executed when testcase \"ResizeBilinearOpTest.TwoDimensionalResizeWithTwoBatches8Bit\" is run.\r\n\r\n```\r\ntemplate <typename T>\r\ninline void ResizeBilinearGenericSmallChannel(\r\n    const T* input_data, const Dims<4>& input_dims, T* output_data,\r\n    const Dims<4>& output_dims, int32 batches, int32 input_height,\r\n    int32 input_width, int32 depth, int32 output_height, int32 output_width,\r\n    float height_scale, float width_scale) {\r\n          for (int32 d = 0; d < depth; d++) {\r\n          const T* input_ptr = &input_data[d];\r\n          float fOutput = input_ptr[input_offset[0]] * scale[0] +\r\n                                         input_ptr[input_offset[1]] * scale[1] +\r\n                                         input_ptr[input_offset[2]] * scale[2] +\r\n                                         input_ptr[input_offset[3]] * scale[3];\r\n          *output_ptr = static_cast<T>(fOutput);\r\n          LOG(INFO) << \"Uint8 Output:  \" << +*output_ptr;\r\n          LOG(INFO) << \"Float Output:  \" << fOutput;\r\n          output_ptr++;          \r\n        }\r\n    }\r\n```\r\n\r\nFor the mentioned  testcase, the above for loop runs for 18 times. For the 17th item, I get different values for uint8 and float on x86. Below are the logs I printed for the mentioned test case -\r\n\r\nOn ppc64le -\r\n```\r\n2018-07-03 12:32:46.008931: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5522] Uint8 Output:  3\r\n2018-07-03 12:32:46.008937: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5524] Float Output:  3\r\n2018-07-03 12:32:46.008942: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5522] Uint8 Output:  5\r\n2018-07-03 12:32:46.008948: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5524] Float Output:  5\r\n2018-07-03 12:32:46.008953: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5522] Uint8 Output:  6\r\n2018-07-03 12:32:46.008959: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5524] Float Output:  6\r\n2018-07-03 12:32:46.008964: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5522] Uint8 Output:  7\r\n2018-07-03 12:32:46.008969: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5524] Float Output:  7\r\n2018-07-03 12:32:46.008974: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5522] Uint8 Output:  9\r\n2018-07-03 12:32:46.008980: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5524] Float Output:  9\r\n2018-07-03 12:32:46.008985: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5522] Uint8 Output:  10\r\n2018-07-03 12:32:46.008992: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5524] Float Output:  10\r\n2018-07-03 12:32:46.008997: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5522] Uint8 Output:  9\r\n2018-07-03 12:32:46.009003: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5524] Float Output:  9\r\n2018-07-03 12:32:46.009008: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5522] Uint8 Output:  11\r\n2018-07-03 12:32:46.009013: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5524] Float Output:  11\r\n2018-07-03 12:32:46.009019: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5522] Uint8 Output:  12\r\n2018-07-03 12:32:46.009024: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5524] Float Output:  12\r\n2018-07-03 12:32:46.009029: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5522] Uint8 Output:  4\r\n2018-07-03 12:32:46.009035: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5524] Float Output:  4\r\n2018-07-03 12:32:46.009040: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5522] Uint8 Output:  8\r\n2018-07-03 12:32:46.009046: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5524] Float Output:  8\r\n2018-07-03 12:32:46.009051: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5522] Uint8 Output:  10\r\n2018-07-03 12:32:46.009057: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5524] Float Output:  10\r\n2018-07-03 12:32:46.009062: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5522] Uint8 Output:  8\r\n2018-07-03 12:32:46.009067: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5524] Float Output:  8\r\n2018-07-03 12:32:46.009072: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5522] Uint8 Output:  12\r\n2018-07-03 12:32:46.009078: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5524] Float Output:  12\r\n2018-07-03 12:32:46.009083: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5522] Uint8 Output:  14\r\n2018-07-03 12:32:46.009089: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5524] Float Output:  14\r\n2018-07-03 12:32:46.009096: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5522] Uint8 Output:  10\r\n2018-07-03 12:32:46.009101: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5524] Float Output:  10\r\n2018-07-03 12:32:46.009106: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5522] Uint8 Output:  14\r\n2018-07-03 12:32:46.009112: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5524] Float Output:  14\r\n2018-07-03 12:32:46.009117: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5522] Uint8 Output:  16\r\n2018-07-03 12:32:46.009123: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5524] Float Output:  16\r\n```\r\n\r\n\r\nOn x86 -\r\n```\r\n2018-07-03 12:32:33.869341: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5519] Uint8 Output:  3\r\n2018-07-03 12:32:33.869435: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5521] Float Output:  3\r\n2018-07-03 12:32:33.869449: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5519] Uint8 Output:  5\r\n2018-07-03 12:32:33.869458: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5521] Float Output:  5\r\n2018-07-03 12:32:33.869468: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5519] Uint8 Output:  6\r\n2018-07-03 12:32:33.869476: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5521] Float Output:  6\r\n2018-07-03 12:32:33.869484: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5519] Uint8 Output:  7\r\n2018-07-03 12:32:33.869492: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5521] Float Output:  7\r\n2018-07-03 12:32:33.869501: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5519] Uint8 Output:  9\r\n2018-07-03 12:32:33.869509: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5521] Float Output:  9\r\n2018-07-03 12:32:33.869518: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5519] Uint8 Output:  10\r\n2018-07-03 12:32:33.869527: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5521] Float Output:  10\r\n2018-07-03 12:32:33.869536: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5519] Uint8 Output:  9\r\n2018-07-03 12:32:33.869544: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5521] Float Output:  9\r\n2018-07-03 12:32:33.869553: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5519] Uint8 Output:  11\r\n2018-07-03 12:32:33.869561: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5521] Float Output:  11\r\n2018-07-03 12:32:33.869569: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5519] Uint8 Output:  12\r\n2018-07-03 12:32:33.869578: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5521] Float Output:  12\r\n2018-07-03 12:32:33.869587: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5519] Uint8 Output:  4\r\n2018-07-03 12:32:33.869595: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5521] Float Output:  4\r\n2018-07-03 12:32:33.869603: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5519] Uint8 Output:  8\r\n2018-07-03 12:32:33.869611: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5521] Float Output:  8\r\n2018-07-03 12:32:33.869620: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5519] Uint8 Output:  10\r\n2018-07-03 12:32:33.869628: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5521] Float Output:  10\r\n2018-07-03 12:32:33.869637: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5519] Uint8 Output:  8\r\n2018-07-03 12:32:33.869645: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5521] Float Output:  8\r\n2018-07-03 12:32:33.869653: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5519] Uint8 Output:  12\r\n2018-07-03 12:32:33.869661: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5521] Float Output:  12\r\n2018-07-03 12:32:33.869670: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5519] Uint8 Output:  14\r\n2018-07-03 12:32:33.869678: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5521] Float Output:  14\r\n2018-07-03 12:32:33.869687: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5519] Uint8 Output:  10\r\n2018-07-03 12:32:33.869695: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5521] Float Output:  10\r\n2018-07-03 12:32:33.869713: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5519] Uint8 Output:  13\r\n2018-07-03 12:32:33.869723: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5521] Float Output:  14\r\n2018-07-03 12:32:33.869732: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5519] Uint8 Output:  16\r\n2018-07-03 12:32:33.869740: I ./tensorflow/contrib/lite/kernels/internal/optimized/optimized_ops.h:5521] Float Output:  16\r\n```\r\n\r\nAnd the test case's expected output is designed as per uint8 value which is 13 at the index 17. However, the same test case with same inputs is also written for float datatype and it has 14 at the 17th index in the expected output. \r\nLooks like either it is some casting issue on x86 or I'm missing something here. Could anyone please help me?", "@npanpaliya , I'm not sure how the math worked in this case, but it does seem odd that the expected results are different if using float vs uint8. Maybe this is due to a rounding error. Perhaps you can attempt to change the input of the testcase to values where the results for float and uint8 are the same?", "@wdirons - I tried with different input values and fortunately for those values, I see x86 and ppc64le are giving same results. But not sure if Community can accept it as a fix.\r\n@rohan100jain and others from TF Community - Request you to provide the inputs on this. Will it be okay if we just change the input values to the testcase, such that the output is same on both the platforms?", "I think the question is more why for x86 are we expecting different results when casting to uint8 then when using float.", "@wdirons - Raised a PR for this by changing input/output for the failing tests - https://github.com/tensorflow/tensorflow/pull/20744", "Ah, the joy of floating-point numbers... Just to summarize, one of the errors happens because we are calculating:\r\n   `10*2/9+10*1/9+16*4/9+16*2/9`\r\nit should yield 126/9, which is exactly 14. However, we know the representations aren't exact ever, so sometimes we end up above 14, sometimes below. While doing uint8/quantized calculations the floating-point value is static_cast into uint8, which results in 13 or 14.", "The fix for this is now merged. I'm trying to verify but I'm having trouble right now running test on the master branch.", "Fixed with PR #20744"]}, {"number": 20360, "title": "Fix gradient of nccl_ops", "body": "In Python3, `op.get_attr` returns bytes, not str, which causes many failures.", "comments": ["@yifeif ping", "There are many unrelated failures."]}, {"number": 20359, "title": "Remove old get_started/index.md", "body": "Using _index.yaml instead", "comments": []}, {"number": 20358, "title": "Highlevel API do not well support float64 due to tf.feature_column.input_layer", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes. See the end.\r\n\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Debian 9.4.\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\nsource.\r\n\r\n- **TensorFlow version (use command below)**:\r\n1.9.0-rc1\r\n\r\n- **Python version**: \r\n3.5.3\r\n\r\n- **Bazel version (if compiling from source)**:\r\n0.11.1\r\n\r\n- **GCC/Compiler version (if compiling from source)**:\r\n6.3.0\r\n\r\n- **CUDA/cuDNN version**:\r\nNA (cpu only build)\r\n\r\n- **GPU model and memory**:\r\nNA (cpu only build)\r\n\r\n- **Exact command to reproduce**:\r\nSee the python script in the end. Just run it like:\r\n`python3 test_tf_float64.py`\r\n\r\n### The problem\r\nThe function `tf.feature_column.input_layer` return tensor in dtype=float32 for input dtype=float64.\r\n\r\nI know this is a [documented](https://github.com/tensorflow/tensorflow/blob/v1.9.0-rc1/tensorflow/python/feature_column/feature_column.py#L270) behavior, but this breaks things:\r\n\r\n1. When the training data is in float64 precision, the user is (I am) expecting a float64 output, especially when the DNN written in high level API is used as a regressor. However, it returns float32, see the script in the end.\r\n\r\n2. When building a custom estimator using high level API, seems that the input layer has to be created by `tf.feature_column.input_layer`. See the guide [here](https://www.tensorflow.org/get_started/custom_estimators#define_the_input_layer). This forbid the user from creating a network with dtype=float64 precision.\r\n\r\nOne may argue that dtype=float32 is already more than enough for DNN. But e.g. when doing theoretical work, the extra precision is desired.\r\n\r\nA possible fix is:\r\n\r\nChange line [2347](https://github.com/tensorflow/tensorflow/blob/v1.9.0-rc1/tensorflow/python/feature_column/feature_column.py#L2347) of function `_transform_feature` in file `tensorflow/python/feature_column/feature_column.py`, from\r\n\r\n```python3\r\n return math_ops.to_float(input_tensor)\r\n```\r\n\r\nto\r\n\r\n```python3\r\n    if not input_tensor.dtype.is_floating:\r\n      return math_ops.to_float(input_tensor)\r\n    return input_tensor\r\n```\r\n\r\nNote: this fix could breaks old code that has float32 assumption...\r\n\r\nIf this is considered as non-bug, then consider this as a feature request that make it possible to pass dtype=float64 through.\r\n\r\n### Source code\r\n```python3\r\n# Test tensorflow high level API.\r\n# dtype=float64 will be silently transformed to float32.\r\n\r\nimport sys\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ndef load_data(dtype):\r\n    l = 7\r\n    x1 = np.linspace(-1.0, 1.0, l, dtype=dtype)\r\n    z1 = np.sin(x1)\r\n    return ({'x':x1}, {'z':z1})\r\n\r\ndef train_input_fn(features, labels, batch_size):\r\n    dataset = tf.data.Dataset.from_tensor_slices((features, labels['z']))\r\n    dataset = dataset.repeat().batch(batch_size)\r\n    return dataset\r\n\r\ndef eval_input_fn(features):\r\n    dataset = tf.data.Dataset.from_tensor_slices(features)\r\n    dataset = dataset.batch(1)\r\n    return dataset\r\n\r\ndef main(argv):\r\n    dtype = np.float64   # specifies the data type\r\n\r\n    batch_size = 7\r\n    n_steps = 1\r\n\r\n    (train_x, train_y) = load_data(dtype)\r\n    my_feature_columns = [\r\n        tf.feature_column.numeric_column(\r\n            key   = 'x',\r\n            shape = (1,),\r\n            dtype = tf.as_dtype(train_x['x'].dtype))\r\n    ]\r\n\r\n    regressor = tf.estimator.DNNRegressor(   # or any other regressors\r\n        hidden_units    = [3],\r\n        feature_columns = my_feature_columns)\r\n\r\n    regressor.train(\r\n        input_fn = lambda:train_input_fn(train_x, train_y, batch_size),\r\n        steps    = n_steps)\r\n\r\n    predict_x = {'x': np.array([0.1, 0.2])}\r\n\r\n    predictions = regressor.predict(\r\n        input_fn=lambda:eval_input_fn(predict_x))\r\n\r\n    print([i for i in predictions]) # outputs are float32 instead of float64\r\n\r\nif __name__ == '__main__':\r\n    tf.app.run(main)\r\n```", "comments": ["After the switch from 1.X regressor to 2.X regressor we're seeing this as well. We're also getting terrible accuracy now and not sure if its related.", "@bewantbe It looks like you are using an older Version of Tensorflow (1.x). Many bugs have been fixed in the latest version. Can you please execute your code using Latest Version (2.6.0) and let us know if the issue still persists? Please refer to the [link](https://www.tensorflow.org/api_docs/python/tf/compat/v1/feature_column/input_layer) and let us know if it helps ? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/20358\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/20358\">No</a>\n"]}, {"number": 20357, "title": "Build OpenBLAS 0.3.0 on ppc64le for TF tests", "body": "Updates for TF tests on ppc64le.  Update to OpenBLAS 0.3.0 for ppc64le TF testing.  Also set OMP_NUM_THREADS=1 at runtime due to multi-threading issues.", "comments": ["Thank you @JonTriebenbach , I believe this will resolve issues #19697 and #19698 when merged, and maybe others. ", "@gunan - Could you please re-review this for the one line change Jon added. \r\n\r\nThank you!", "@yifeif any idea why this is still not merged internally?", "@yifeif any idea why this is still not merged internally?", "The internal change has been created. Should be merged once it is submitted!"]}, {"number": 20356, "title": "CUDA_ERROR_LAUNCH_FAILED", "body": "just wanna report this. it happened during the 60th call while I was calling a python script for about 100 times. (train 100 NNs).\r\n\r\nsystem: gtx950m\r\n\r\nat about the 30th call the neural network was not able to learn anymore. the accuracy and cost remained the same.\r\n\r\n2018-06-27 21:10:37.421165: E tensorflow/stream_executor/cuda/cuda_driver.cc:1110] could not synchronize on CUDA context: CUDA_ERROR_LAUNCH_FAILED :: No stack trace available\r\n2018-06-27 21:10:37.421173: E tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_LAUNCH_FAILED\r\n2018-06-27 21:10:37.421198: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:203] Unexpected Event status: 1\r\nAborted (core dumped)\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "I think this happens because I declare the model just once, even when I start the next training. \r\n\r\nAnyway just FYI, and I will close it now.", "I met the same issue. Anyone knows how to resolve it?"]}]