[{"number": 24384, "title": "tf.control_dependencies() not respected with Keras layers", "body": "**System information**\r\n- TensorFlow version: v1.12.0-0-ga6d8ffae09 1.12.0\r\n- Python version: 3.6.7\r\n\r\nI want to switch dropout on and off while processing one single batch of data (i.e., feeding data just once). For this I replace the _learning_phase_ placeholder used by Keras with a variable, which I can then assign dynamically, and use `tf.control_dependencies()` to control the order of operations. Order of execution does not seem to be respected, leading to random behavior.\r\nMore details: In the context of reinforcement learning, for each batch of data, I want to: (1) do a forward pass over my network with dropout disable to build targets; and (2) do a training step with those targets with dropout enabled.   \r\n\r\n**Code to reproduce the issue**\r\nThe code below is a toy example that resembles what I want to do. I would expect `o1` and `o3` to be equal and different than `o2`. I would also expect to run w/o crashing. \r\n\r\n```\r\nfrom tensorflow.keras.layers import Dropout, Dense, Input, Lambda, Layer, Add, RepeatVector, LSTM\r\nfrom tensorflow.python.keras import backend as K\r\nfrom tensorflow.keras import Model\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nlph = tf.Variable(False, dtype=tf.bool, name='lph')\r\ng = tf.get_default_graph()\r\nK._GRAPH_LEARNING_PHASES[g] = lph\r\n\r\nrepeat = RepeatVector(2)\r\nlstm = LSTM(1, dropout=0.5, recurrent_dropout=0.5)\r\n\r\nph1 = tf.placeholder(tf.float32, shape=(None, 1), name='ph1')\r\nh = repeat(ph1)\r\no1 = lstm(h)\r\n\r\nwith g.control_dependencies([lph.assign(True), tf.identity(o1)]):\r\n  target1 = tf.stop_gradient(o1)\r\n\r\n  ph2 = tf.placeholder(tf.float32, shape=(None, 1), name='ph2')\r\n  h = repeat(ph2)\r\n  o2 = lstm(h)\r\n  \r\n  with g.control_dependencies([lph.assign(False), tf.identity(o2)]):\r\n    target2 = tf.stop_gradient(o2)\r\n\r\n    ph3 = tf.placeholder(tf.float32, shape=(None, 1), name='ph3')\r\n    h = repeat(ph3)\r\n    o3 = lstm(h)\r\n    \r\n    loss = target1 + target2 - o2\r\n    opt = tf.train.GradientDescentOptimizer(0.1)\r\n    train = opt.minimize(loss)\r\n\r\nsess = tf.Session()\r\nK.set_session(sess)\r\nsess.run(tf.global_variables_initializer())\r\n\r\ndata = np.ones((1,1))\r\nsess.run([o1, o2, o3, train], feed_dict={ph1:data, ph2:data, ph3:data})\r\n```\r\n", "comments": ["Closing this since there is not a problem, actually. Splitting each of the `control_dependencies()` commands in two, as shown below, solves the issue.\r\n\r\n```\r\nwith g.control_dependencies([o1]):\r\n       with g.control_dependencies([lph.assign(True)]):\r\n               ....\r\n```\r\n "]}, {"number": 24383, "title": "Segmentation Fault running conv2d", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 1.12.0\r\n- Python version: 3.6.7\r\n- Installed using virtualenv? pip? conda?: conda\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source):N/A\r\n- CUDA/cuDNN version: CUDA 9.0 + cuDNN 7.3.1\r\n- GPU model and memory: RTX 2070 8GB\r\n\r\n\r\n\r\n**Running Example Convolutional Network Facing Segmentation Fault**\r\n\r\nI installed the latest 4.10 Nvidia drivers (earlier drivers does not support new RTX cards), and downloaded and installed CUDA 9.0 (runfile) and cuDNN 7.3.1 (tarball) from Nvidia's website. I then installed tensorflow on a brand new miniconda 3 environment. I tried to run the mnist [convolutional model](https://github.com/tensorflow/models/blob/master/tutorials/image/mnist/convolutional.py) from the tutorial, but gets segmentation fault. \r\n\r\n```\r\nExtracting data/train-images-idx3-ubyte.gz\r\nExtracting data/train-labels-idx1-ubyte.gz\r\nExtracting data/t10k-images-idx3-ubyte.gz\r\nExtracting data/t10k-labels-idx1-ubyte.gz\r\n2018-12-15 02:10:42.928599: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-12-15 02:10:43.065251: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-12-15 02:10:43.065776: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \r\nname: GeForce RTX 2070 major: 7 minor: 5 memoryClockRate(GHz): 1.71\r\npciBusID: 0000:1c:00.0\r\ntotalMemory: 7.76GiB freeMemory: 7.04GiB\r\n2018-12-15 02:10:43.065794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\r\n2018-12-15 02:10:43.293803: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-12-15 02:10:43.293835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \r\n2018-12-15 02:10:43.293843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \r\n2018-12-15 02:10:43.294030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 6768 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2070, pci bus id: 0000:1c:00.0, compute capability: 7.5)\r\nInitialized!\r\n[1]    29907 segmentation fault (core dumped)  python convolutional.py\r\n```\r\n", "comments": ["this may be related to https://github.com/tensorflow/tensorflow/issues/24376; \r\nConv2d seems to work incorrectly", "This should be the same issue with #24045. I will try to compile from source or use 1.10. ", "Compiling from source (r1.13 with CUDA 10 and cuDNN 7.4, Tensor RT 5) solves the issue. "]}, {"number": 24382, "title": "Upgrade to CUDA 10", "body": "Upgrades the docker files to CUDA 10 and lock Bazel to 0.19.2 (work done by Austin).\r\n\r\nList of changes to both gpu partials:\r\n-  CUDA 10\r\n- cuDNN 7.4\r\n- TensorRT 5.0.2 GA release\r\n- NCCL now from source\r\n\r\nRan the following tests:\r\n- Built all images\r\n- Did a build using the devel-gpu-py3 and executed tf_cnn_benchmarks causing NCCL to be used.", "comments": []}, {"number": 24381, "title": "TFTRT: Prevent segments with partially defined inputs for static mode", "body": "In static mode, If an input to a segment does not have a fully defined shape (exlcuding batch dim), we should prevent that segment from converting and fall back to native TF. TensorRT requires shapes to be defined in static mode. In some cases we would've caught the undefined shape by checks in certain ops but it was not reliable and the undefined shapes manifested in weird error messages.", "comments": ["I'm still not entirely sure about this. Do we expect partially defined input shapes to work in static mode?", "> I'm still not entirely sure about this. Do we expect partially defined input shapes to work in static mode?\r\n\r\nI am not sure about that as well. Adding Lambda for that. I could not figure that out by quick read of the code.\r\n\r\nI remember a discussion about the bucketing logic but not sure if that is already done and if that is part of TRTStatic orTRTDynamic.", "I don't think unknown shapes can work with static mode because the static mode requires building the TRT engine which includes all the optimizations that depend on shapes. But this requirement is for the inputs of the TRT engine, and not necessarily for the inputs of the whole graph; in other words, it's possible that there are unknown shapes in the graph inputs but not in the TRT engine inputs. I think Trevor's change checks the shape of TRT engine inputs which is the right thing.\r\n\r\n"]}, {"number": 24380, "title": "TensorFlow Tutorial. TensorFlowLite example app crashes: Tensor shape does not match.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Samsung Galaxy S6\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 1.9\r\n- Python version: 2.7\r\n- Bazel version (if compiling from source): 0.19.2\r\n- GCC/Compiler version (if compiling from source): 6\r\n- CUDA/cuDNN version: 9.0/7.14\r\n- GPU model and memory: GeForce GTX 1060 6GB\r\n\r\n\r\n**Describe the current behavior**\r\nI retrained a ssd_mobilenet_v1 as described in this [guide](https://medium.com/tensorflow/training-and-serving-a-realtime-mobile-object-detector-in-30-minutes-with-cloud-tpus-b78971cf1193).\r\nSo i converted my model to .tflite as shown under \"Running on mobile with TensorFlow Lite\"\r\nWhen i try to run it on my Phone, the App just crashes. So i installed Android Studio and tried to run it from there. Now i got following error:\r\n`Process: org.tensorflow.lite.demo, PID: 12449\r\n    java.lang.IllegalArgumentException: Cannot copy between a TensorFlowLite tensor with shape [1, 10, 4] and a Java object with shape [1, 4, 4].\r\n        at org.tensorflow.lite.Tensor.throwExceptionIfTypeIsIncompatible(Tensor.java:240)\r\n        at org.tensorflow.lite.Tensor.copyTo(Tensor.java:116)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:152)\r\n        at org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:216)\r\n        at org.tensorflow.demo.TFLiteObjectDetectionAPIModel.recognizeImage(TFLiteObjectDetectionAPIModel.java:194)\r\n        at org.tensorflow.demo.DetectorActivity$3.run(DetectorActivity.java:249)\r\n        at android.os.Handler.handleCallback(Handler.java:751)\r\n        at android.os.Handler.dispatchMessage(Handler.java:95)\r\n        at android.os.Looper.loop(Looper.java:154)\r\n        at android.os.HandlerThread.run(HandlerThread.java:61)`\r\n\r\nThe important line, i think, is **Cannot copy between a TensorFlowLite tensor with shape [1, 10, 4] and a Java object with shape [1, 4, 4].**\r\n\r\nHow do i know what tensor shape is needed? Can i change that in the app? Or do i need to change my model in some way?\r\n\r\n**Describe the expected behavior**\r\n\r\nRunning example app with retrained model as shown in the [guide](https://medium.com/tensorflow/training-and-serving-a-realtime-mobile-object-detector-in-30-minutes-with-cloud-tpus-b78971cf1193)\r\n\r\n**Code to reproduce the issue**\r\nconverted the model via:\r\n`bazel run -c opt tensorflow/contrib/lite/toco:toco -- \\`\r\n`--input_file=$OUTPUT_DIR/tflite_graph.pb \\`\r\n`--output_file=$OUTPUT_DIR/detect.tflite \\`\r\n`--input_shapes=1,300,300,3 \\`\r\n`--input_arrays=normalized_input_image_tensor \\`\r\n`--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3'  \\`\r\n`--inference_type=QUANTIZED_UINT8 \\`\r\n`--mean_values=128 \\`\r\n`--std_values=128 \\`\r\n`--change_concat_input_ranges=false \\`\r\n`--allow_custom_ops`\r\n\r\nChanges in **DetectorActivity.java** to match my model and labels:\r\n`private static final int TF_OD_API_INPUT_SIZE = 300;`\r\n  `private static final boolean TF_OD_API_IS_QUANTIZED = true;`\r\n  `private static final String TF_OD_API_MODEL_FILE = \"detectquant.tflite\";`\r\n  `private static final String TF_OD_API_LABELS_FILE = \"file:///android_asset/icons4cats.txt\";`\r\n\r\n\r\n", "comments": ["The error states your are copying [1, 10, 4] to  [1, 4, 4]. 1 fits in 1, but 10 doesn't fit in 4.. therefore you get the error. You could reshape your model or adjust the target object you are copying the tensors too.\r\n\r\nAre you trying to work with a custom model inside example software?\r\n\r\nLinks to the software would be helpful, as well as a description of the model if you cannot provide the code used to generate it.", "Hey, try increasing the number of detections in your java object. In your example app, change NUM_DETECTIONS or whatever it might be called. This will increase the java object shape from you current [1,4,4] to [1,10,4] matching the tensor shape. :)\r\n\r\nEdit: Change it from 4 to 10", "Did the abovementioned change resolve your issue regarding app crash?", "Closing this, feel free to re-open if the problem still exists.", "@StephanZmk I have the same problem, how did you solve it ?", "@ricardobnjunior i am not quiet sure anymore. I think using the tf-nightly build did the trick.", "@StephanZmk  what do you mean by tf-nightly build?\r\n", "> Hey, try increasing the number of detections in your java object. In your example app, change NUM_DETECTIONS or whatever it might be called. This will increase the java object shape from you current [1,4,4] to [1,10,4] matching the tensor shape. :)\r\n> \r\n> Edit: Change it from 4 to 10\r\n\r\n\u975e\u5e38\u8c22\u8c22\uff0c\u89e3\u51b3\u4e86\u6211\u7684\u95ee\u9898\uff01"]}, {"number": 24379, "title": "meta_graph_transform does not work with default checkpoint_path", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac OS High Sierra 10.13.4\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.10.1\r\n- Python version: 3.6.5\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.saved_model import simple_save\r\nfrom tensorflow.saved_model import tag_constants\r\nfrom tensorflow.contrib.meta_graph_transform.meta_graph_transform import (\r\n    meta_graph_transform)\r\n\r\nwith tf.Session() as sess:\r\n    meta_graph_def = tf.saved_model.loader.load(\r\n        sess,\r\n        [tag_constants.SERVING],\r\n        \"1544816647\")\r\n\r\n    new_meta_def = meta_graph_transform(\r\n        base_meta_graph_def=meta_graph_def,\r\n        input_names=[\"Placeholder\"],\r\n        output_names=[\"dnn/head/predictions/class_ids\", \"init_all_tables\"],\r\n        transforms=[\"freeze_graph\"],\r\n        tags=[tag_constants.SERVING],\r\n        checkpoint_path=None)\r\n\r\n    assert new_meta_def.graph_def\r\n    with tf.Graph().as_default() as graph:\r\n        tf.import_graph_def(new_meta_def.graph_def)\r\n\r\n        in_tensor = graph.get_tensor_by_name(\"import/Placeholder:0\")\r\n        out_tensor = graph.get_tensor_by_name(\"dnn/head/predictions/class_ids:0\")\r\n        simple_save(\r\n            sess,\r\n            \"./frozen\",\r\n            inputs={\"inputs\": in_tensor},\r\n            outputs={\"outputs\": out_tensor})\r\n```\r\nError:\r\nCan't load save_path when it is None.", "comments": ["@ashokramadass  Can you please check the path as the error says, it must be pointing to a wrong or non existing path. \r\nPlease verify the checkpoint path(when restoring the checkpoint) using\r\nsaver.restore(sess, tf.train.latest_checkpoint(cur_dir))", "@harshini-gadige as per the [docs](https://www.tensorflow.org/api_docs/python/tf/contrib/meta_graph_transform/meta_graph_transform/meta_graph_transform), checkpoint_path can take default as None but as you mentioned, it is verifying the path. I don't want to provide a checkpoint path as I am providing a valid base_meta_graph_def.", "@allenlavoie  Could you PTAL", "I don't know anything about contrib/meta_graph_transform. @suharshs are we keeping this, and if so do you know someone who should look at this bug?", "@ashokramadass Is this still an issue ? We see that you are using old version of tensorflow  1.x which is not actively supported, We recommend that you upgrade to 2.4 or later version and let us know if the issue still persists in newer versions .Please refer [this](https://www.tensorflow.org/guide/migrate) guide to migrate from TF v1.x to 2.x . Please open a new issue in case you face any errors using TF v2, we will get you the right help.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/24379\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/24379\">No</a>\n"]}, {"number": 24378, "title": "Hardcode Bazel installation version", "body": "The apt method of installing Bazel isn't very consistent, and we\nsometimes need to lock a specific version. This updates all of the devel\ndockerfiles to install Bazel directly from the installer instead.", "comments": ["This was included in another PR, already merged."]}, {"number": 24377, "title": "Error to flat the output of the session->Run C++", "body": "**System information**\r\n- Tensorflow version: 1.4\r\n- Programming Language: C++\r\n- Operational System: Windows 10\r\n- CPU implementation\r\n\r\n**Describe the current behavior**\r\n\r\nI am trying to run an .pb file on C++. The objective is to run and get the prediction result. However, after the `session->Run` is performed, I try to make an flat of the output: `outputs[0].flat<float>()`. When i try to do the flat, the system execution is interrupted, the error are:` Check failed: dtype() == expected_dtype (9 vs. 1).`\r\n\r\nTo understand the result of the output, I tried to print the content of my output, but I cannot.\r\n\r\nI hope that the estimation result is the tensor output, but I cannot read the result.\r\n\r\n_### **___________THE ERROR ARE AT THE LAST LINE IN THE CODE___________**_\r\n\r\n**Describe the expected behavior**\r\n\r\nThe expected behavior is Run the code and get the result of the estimation through of the `output `tensor.\r\n\r\n**Code to reproduce the issue**\r\n\r\n```\r\n#include \"TFUtils.h\"\r\n#include <cstdio>\r\n#include <cstdint>\r\n#include <string>\r\n\r\n#include \"tensorflow/cc/client/client_session.h\"\r\n#include \"tensorflow/cc/ops/standard_ops.h\"\r\n#include \"tensorflow/core/framework/tensor.h\"\r\n#include <tensorflow/core/public/session.h>\r\n#include <tensorflow/core/protobuf/meta_graph.pb.h>\r\n\r\nusing namespace std;\r\nusing namespace tensorflow;\r\nusing tensorflow::Flag;\r\nusing tensorflow::Tensor;\r\nusing tensorflow::Status;\r\nusing tensorflow::string;\r\nusing tensorflow::int32;\r\nusing namespace std;\r\n\r\nconst char __DSDL_OCR_LETTERS[] = { 'S', 'o', 'f', 'a', 'r', 'h', 'd', 'u', 't', 'i', 'n',\r\n'k', 'g', 'l', 'e', 's', 'm', '\"', 'W', 'w', 'v', 'c', 'p', 'y', '.', 'P', ',', 'b',\r\n'G', 'O', 'D', 'R', '!', 'T', 'F', 'H', 'j', '-', 'A', ':', 'I', '?', 'C', '2', ';',\r\n'B','\\'', 'Y', 'L', 'N', 'x', 'E', 'M', '1', '8', '3', '4', ' / ', '(', '9', '5', ')',\r\n'0','U', 'q', 'K', 'z', '6', 'J', '7', 'V', '&', '#', 'X', 'Q', '*', 'Z', ' + ', ' | ', ' ' };\r\n\r\n\r\nint main(int argc, char* argv[]) {\r\n\r\n\tstring image = \"D:\\\\IMAGE_FOR_TEST_IN_C\\\\imAux13.png\";\r\n\tstring graph =\"models\\\\Mode_epoch_269.pb\"; //D:\\svn\\image_thread\\engines\\dsir\\bin\\resources\\dll\\dl\\models\r\n\t\t\t\t\t\t\t\t\t\r\n\tstring labels =\t\"models\\\\ocr_model_labels.txt\";\r\n\r\n\tint32 input_width = 1940;\r\n\tstring out_fn = \"features\";\r\n\tint target_len_TAMANHO = 23;\r\n\tint seq_len_TAMANHO = 454;\r\n\tint32 input_height = 128;\r\n\tfloat input_mean = 0;\r\n\tfloat input_std = 255;\r\n\tstring input_layer = \"Inputs/inputs\";\r\n\tstring output_layer = \"predictions/CTCBeamSearchDecoder\";\r\n\r\n\tbool self_test = false;\r\n\tstring root_dir = \"D:\\\\svn\\\\image_thread\\\\engines\\\\dsir\\\\bin\\\\resources\\\\dll\\\\dl\";\r\n\tuint32_t sizeTransLenght = sizeof(__DSDL_OCR_LETTERS);\r\n\r\n\r\n\tstd::vector<Flag> flag_list = {\r\n\t\tFlag(\"inputs\", &image, \"image to be processed\"),\r\n\t\tFlag(\"out_fn\", &out_fn, \"name of the fn to save the features\"),\r\n\t\tFlag(\"graph\", &graph, \"graph to be executed\"),\r\n\t\tFlag(\"labels\", &labels, \"name of file containing labels\"),\r\n\t\tFlag(\"input_width\", &input_width, \"resize image to this width in pixels\"),\r\n\t\tFlag(\"input_height\", &input_height, \"resize image to this height in pixels\"),\r\n\t\tFlag(\"input_mean\", &input_mean, \"scale pixel values to this mean\"),\r\n\t\tFlag(\"input_std\", &input_std, \"scale pixel values to this std deviation\"),\r\n\t\tFlag(\"input_layer\", &input_layer, \"name of input layer\"),\r\n\t\tFlag(\"output_layer\", &output_layer, \"name of output layer\"),\r\n\t\tFlag(\"self_test\", &self_test, \"run a self test\"),\r\n\t\tFlag(\"root_dir\", &root_dir, \"interpret image and graph file names relative to this directory\"),\r\n\t};\r\n\r\n\tcout << \"\\n\" << argv[0] << \"\\n\";\r\n\tstring usage = tensorflow::Flags::Usage(argv[0], flag_list);\r\n\tconst bool parse_result = tensorflow::Flags::Parse(&argc, argv, flag_list);\r\n\r\n\tif (!parse_result) {\r\n\t\tLOG(ERROR) << usage;\r\n\t\treturn -1;\r\n\t}\r\n\r\n\t// We need to call this to set up global state for TensorFlow.\r\n\ttensorflow::port::InitMain(argv[0], &argc, &argv);\r\n\tif (argc > 1) {\r\n\t\tLOG(ERROR) << \"Unknown argument \" << argv[1] << \"\\n\" << usage;\r\n\t\treturn -1;\r\n\t}\r\n\r\n\t// First we load and initialize the model.\r\n\tstd::unique_ptr<tensorflow::Session> session;\r\n\tstring graph_path = tensorflow::io::JoinPath(root_dir, graph);\r\n\tStatus load_graph_status = LoadGraph(graph_path, &session);\r\n\tif (!load_graph_status.ok()) {\r\n\t\tLOG(ERROR) << load_graph_status;\r\n\t\treturn -1;\r\n\t}\r\n\r\n\t// Get the image from disk as a float array of numbers, resized and normalized\r\n\t// to the specifications the main graph expects.\r\n\tstd::vector<Tensor> resized_tensors;\r\n\tstring image_path = image; // tensorflow::io::JoinPath(root_dir, image);\r\n\tStatus read_tensor_status =\r\n\t\tReadTensorFromImageFile(image_path, input_height, input_width, input_mean,\r\n\t\t\tinput_std, &resized_tensors);\r\n\r\n\tif (!read_tensor_status.ok()) {\r\n\t\tLOG(ERROR) << read_tensor_status;\r\n\t\treturn -1;\r\n\t}\r\n\tconst Tensor& resized_tensor = resized_tensors[0];\r\n\r\n\tTensor targets_len(DT_INT32, TensorShape({}));\r\n\ttargets_len.scalar<int32>()() = target_len_TAMANHO;\r\n\r\n\tTensor seq_len(DT_INT32, TensorShape({1}));\r\n\tseq_len.scalar<int32>()() = seq_len_TAMANHO;\r\n\r\n\tint tamanho_batche = 16;\r\n\tTensor batche_size(DT_INT32, TensorShape({}));\r\n\tbatche_size.scalar<int32>()() = tamanho_batche;\r\n\r\n\t\r\n\t// Actually run the image through the model.\r\n\tstd::vector<Tensor> outputs;\r\n\tStatus run_status = session->Run({ { input_layer, resized_tensor },{ \"targets_len\", targets_len },{ \"seq_len\", seq_len } },\r\n\t{ output_layer }, {}, &outputs);\r\n\r\n\tif (!run_status.ok()) {\r\n\t\tLOG(ERROR) << \"Running model failed: \" << run_status;\r\n\t\treturn -1;\r\n\t}\r\n\r\n\tFILE *filePtr;\r\n\tfopen_s(&filePtr, out_fn.c_str(), \"w\");\r\n\tauto flat = outputs[0].flat<float>();\t//The error is here\r\n\r\n```\r\n\r\n**Other info / logs**\r\n\r\nThe erros are both bellow:\r\n\r\n`Check failed: dtype() == expected_dtype (9 vs. 1)`\r\n\r\n![image](https://user-images.githubusercontent.com/18532570/50023582-6fd68900-ffbe-11e8-8496-4e59a23006b6.png)\r\n\r\n", "comments": ["@ricardobnjunior  Could you try with the latest Tensorflow version  ?", "> @ricardobnjunior Could you try with the latest Tensorflow version ?\r\n\r\nNo, I cannot. Because the environment of the company which I work uses the 1.4 tensorflow version.\r\nWould there another way to solve my problem ? ", "@skye  Any inputs please?", "> @skye Any inputs please?\r\n\r\nI would like to thank you for the help!!\r\nI solved the problem.\r\n\r\nThe problem was because I make my flat with `float`, but I output format was `int64`. When I made this change from: `outputs[0].flat<float>();` to `outputs[0].flat<__int64>();`, the error did not happen again.\r\n\r\nThank you again!!", "Glad you figured it out, and thanks for sharing your solution!"]}, {"number": 24376, "title": "Conv2d causes Process finished with exit code 139 (interrupted by signal 11: SIGSEGV)", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.1 LTS\r\n- TensorFlow installed from (source or binary): source (conda)\r\n- TensorFlow version (use command below): 1.12.0 \r\n- Python version: 2.7\r\n- CUDA/cuDNN version: 9.2/ 7.2.1\r\n- GPU model and memory: RTX2070 8GB\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nProcess finished with exit code 139 (interrupted by signal 11: SIGSEGV);\r\n\r\n**Describe the expected behavior**\r\n\r\nRun a Convolutional Neural network with no error messages\r\n\r\n**Code to reproduce the issue**\r\n\t# simplified example\r\n\r\n\timport tensorflow as tf\r\n\tmnist = tf.keras.datasets.mnist\r\n\r\n\t(x_train, y_train),(x_test, y_test) = mnist.load_data()\r\n\tx_train, x_test = x_train / 255.0, x_test / 255.0\r\n\tw, h = 28, 28\r\n\r\n\t# Reshape input data from (28, 28) to (28, 28, 1)\r\n\tx_train = x_train.reshape(x_train.shape[0], w, h, 1)\r\n\tx_test = x_test.reshape(x_test.shape[0], w, h, 1)\r\n\r\n\t# buggy example -> what is going on with conv2d?\r\n\t#==========================================================================\r\n\tmodel = tf.keras.models.Sequential([\r\n\t    tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28,1)), # error\r\n\t    tf.keras.layers.Flatten(),\r\n\t    tf.keras.layers.Dense(512, activation=tf.nn.relu),\r\n\t    tf.keras.layers.Dropout(0.2),\r\n\t    tf.keras.layers.Dense(10, activation=tf.nn.softmax)\r\n\t])\r\n\t===========================================================================\r\n\tmodel.compile(optimizer='adam',\r\n\t\t      loss='sparse_categorical_crossentropy',\r\n\t\t      metrics=['accuracy'])\r\n\r\n\tmodel.fit(x_train, y_train, epochs=5)\r\n\tmodel.evaluate(x_test, y_test)\r\n\r\n\r\n**Other info / logs**\r\nThe error appears, when Conv2D layer is used; if i uncomment likeso:\r\n\r\n\t   #tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', \r\n\r\neverythink works. \r\n\r\nMore complicated examples like\r\nhttps://colab.research.google.com/github/margaretmz/deep-learning/blob/master/fashion_mnist_keras.ipynb\r\n\r\nfail with the same error message.", "comments": ["I was able to run your code snippet successfully. I suspect you are running into memory issues. You can try executing your script in [google colab](https://www.google.com/url?q=https://colab.sandbox.google.com&sa=D&source=hangouts&ust=1545167864524000&usg=AFQjCNEK4clc2sX5w9JnZ8OEsSOrM9WP2A) to confirm.", "@ymodak thanks for your reply. I don't think this is a memory issue:\r\n\r\nI was able to run the same code snippet (locally) using tensorflow-gpu==1.5.0 (conda). \r\n(i noticed that my CPU does not support AVX).\r\n\r\nI guess i need to build from source, to run the latest tensorflow version?", "Glad it worked for you. You can also use prebuilt binaries for latest tensorflow apart from installing from sources.", "okay, thank you very much", "Are you satisfied with the resolution of your issue?\r\n[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)\r\n[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)"]}, {"number": 24375, "title": "Set different activation in CuDNNLSTM", "body": "Can we add an \"activation\" input arg to CuDNNLSTM where uses can set different activation functions? Basically similar to \"activation\" input arg in LSTM. \r\nI see **[this](https://github.com/tensorflow/tensorflow/issues/23297)** but it has been closed (@harshini-gadige).", "comments": ["@saber7165  As I already mentioned in the previous issue, could you please post support related questions in [StackOverflow](http://stackoverflow.com/questions/tagged//tensorflow). We strictly encourage users to post only bug/feature request here. Thanks !", "@harshini-gadige, don't you consider this as feature request though? LSTM accepts different activation functions, but CuDNNLSM does not. I am asking if this feature can be added to CuDNNLSTM.", "@saber7165  Please submit [this](https://github.com/tensorflow/tensorflow/issues/new?template=30-feature-request.md) template. We will look into your feature request.", "**System information**\r\n- TensorFlow version (you are using): 1.12.0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nCurrently, CuDNNLSTM does not accept different activation functions as input. It would be useful to have this feature added similar to LSTM.\r\n\r\n**Will this change the current api? How?**\r\nYes. CuDNNLSTM should take an input named \"activation\" similar to LSTM. This is the description on LSTM layer:\r\nactivation: Activation function to use (see activations). Default: hyperbolic tangent (tanh). If you pass None, no activation is applied (ie. \"linear\" activation: a(x) = x).\r\n\r\n**Who will benefit with this feature?**\r\nAnyone developing LSTM models on GPU using CuDNNLSTM.\r\n", "@harshini-gadige,  please see above. Sorry, I should have done this from the beginning.", "It's not feasible to support this since the underlying cudnn API does not let us choose the activation function for LSTMS: https://docs.nvidia.com/deeplearning/sdk/cudnn-developer-guide/index.html#cudnnRNNMode_t"]}, {"number": 24374, "title": "tf.einsum doesn't compute the trace correctly", "body": "**System information**\r\n- Have I written custom code: yes\r\n- OS Platform and Distribution: MacOS Mojave 10.14.1\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.12\r\n- Python version: 3.6.6\r\n\r\n**Describe the current behavior**\r\nThe formula to compute the trace of a matrix with `einsum` computes instead the sum of all the elements of the matrix.\r\n\r\n**Describe the expected behavior**\r\nThe result should the the sum of the elements on the diagonal (compare with `np.einsum('ii', matrix)`)\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\n\r\nmatrix = tf.constant([[1, 2, 3],\r\n                      [4, 5, 6],\r\n                      [7, 8, 9]])\r\n\r\nwith tf.Session() as sess:\r\n    print(tf.einsum('ii',matrix).eval())\r\n\r\n# 45 (should be 15)\r\n```\r\n\r\n", "comments": ["@ziofil  You are right. I tried using np.einsum() and the result I see is 15.  tf.einsum should work similar to np.einsum but we see both the results are conflicting.\r\n@drpngx  -  It looks like a bug and a PR can be requested. WDYT ?\r\n", "That sounds like a serious bug. @ziofil Could you send a fix?\r\n\r\n/CC @av8ramit if we have a fix we might want to patch releases.\r\n\r\nFor this particular case, you can use [`tf.linalg.trace`](https://www.tensorflow.org/api_docs/python/tf/linalg/trace).", "I wish I was competent enough to send a fix, sorry. My specific need is different, I can't just use `tf.trace` (but thanks for the suggestion). I've boiled it down for this issue to the simplest example I could come up with, so possibly there are other cases that are buggy (like `'iijj'`, which is buggy as well)\r\n\r\nAnyways, I think [here](https://github.com/tensorflow/tensorflow/blob/fbc072b45d4a64e8fcc13783fa6047144a8ace2d/tensorflow/python/ops/special_math_ops.py#L270) is where the sum of all the elements takes place, because if the string is `'ii'`, `axis` is `[0,1]` and the contraction in this case shouldn't be performed with `reduce_sum`.\r\n\r\nThis case is [not tested](https://github.com/tensorflow/tensorflow/blob/24f578cd66bfc3ec35017fc77e136e43c4b74742/tensorflow/python/ops/special_math_ops_test.py#L204), by the way.", "Thanks for the information! I looked briefly into this. This is clearly not ideal, but note that the documentation states that this is not a supported [case](https://github.com/tensorflow/tensorflow/blob/fbc072b45d4a64e8fcc13783fa6047144a8ace2d/tensorflow/python/ops/special_math_ops.py#L182). It's a bug that it doesn't error out, and a feature request that it should work.", "Actually, I tried the latest version and it does error out correctly:\r\n```\r\nValueError: Subscript not supported: an axis appears more than once: ii\r\n```", "Hi, I have used Tensorflow for awhile, and was looking for a good place to start contributing.  This seems like a good feature for me to take a start at and I am looking into this", "Sounds good. Thank you!\n\nOn Sun, Dec 23, 2018, 8:15 PM lhendre <notifications@github.com wrote:\n\n> Hi, I have used Tensorflow for awhile, and was looking for a good place to\n> start contributing. This seems like a good feature for me to take a start\n> at and I am looking into this\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/24374#issuecomment-449683857>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_SbdQfVYUXpE9LCCDcgSA0hcxFw92Bks5u8FT4gaJpZM4ZTuho>\n> .\n>\n", "If the issue hasn't been solved yet, i'd like to contribute. Please update on status @lhendre .", "I am working on the issue and testing, things have slowed down a bit on my end due to the holidays but i have blocked time to wrap this up over the weekend.  Ill post and updated status on sunday/monday and if i havent made progress ill step back then", "@lhendre, could you update us? Thanks \ud83d\ude4f", "Hi, Sorry about that I had some family issues but thats been wrapped up and I have made some progress.  I have code that will handle trace correctly with base unit tests, I am right now testing and trying to make sure this is the appropriate way to do this/see if there is any more optimal way.  Ill be attaching this shortly", "#25079", "The PR has been merged and issue fixed."]}, {"number": 24373, "title": "Branch 1.13 build fails with undefined symbol: _ZNSaIPKN3xla14HloInstructionEEC1Ev", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Fedora 28\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): source \r\n- TensorFlow version: 1.13\r\n- Python version: 3.6.7\r\n- Installed using virtualenv? pip? conda?: conda\r\n- Bazel version (if compiling from source):  0.19.2\r\n- GCC/Compiler version (if compiling from source): 7.3.0\r\n- CUDA/cuDNN version: 9.2 / 7.1.4\r\n- GPU model and memory: Quadro M2200\r\n\r\n```\r\nbazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\nfails:\r\n\r\n```\r\n  File \"/home/key/.cache/bazel/_bazel_key/8de93c72df6c3fec3e289f10fadff72b/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/home/key/.cache/bazel/_bazel_key/8de93c72df6c3fec3e289f10fadff72b/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/home/key/.cache/bazel/_bazel_key/8de93c72df6c3fec3e289f10fadff72b/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/home/key/anaconda3/envs/tf-13-1213/lib/python3.6/imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/home/key/anaconda3/envs/tf-13-1213/lib/python3.6/imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: /home/key/.cache/bazel/_bazel_key/8de93c72df6c3fec3e289f10fadff72b/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZNSaIPKN3xla14HloInstructionEEC1Ev\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/key/.cache/bazel/_bazel_key/8de93c72df6c3fec3e289f10fadff72b/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py\", line 27, in <module>\r\n    from tensorflow.python.tools.api.generator import doc_srcs\r\n  File \"/home/key/.cache/bazel/_bazel_key/8de93c72df6c3fec3e289f10fadff72b/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/home/key/.cache/bazel/_bazel_key/8de93c72df6c3fec3e289f10fadff72b/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"/home/key/.cache/bazel/_bazel_key/8de93c72df6c3fec3e289f10fadff72b/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/home/key/.cache/bazel/_bazel_key/8de93c72df6c3fec3e289f10fadff72b/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/home/key/.cache/bazel/_bazel_key/8de93c72df6c3fec3e289f10fadff72b/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/home/key/anaconda3/envs/tf-13-1213/lib/python3.6/imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/home/key/anaconda3/envs/tf-13-1213/lib/python3.6/imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: /home/key/.cache/bazel/_bazel_key/8de93c72df6c3fec3e289f10fadff72b/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZNSaIPKN3xla14HloInstructionEEC1Ev\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 3986.489s, Critical Path: 241.90s, Remote (0.00% of the time): [queue: 0.00%, setup: 0.00%, process: 0.00%]\r\nINFO: 5801 processes: 5801 local.\r\nFAILED: Build did NOT complete successfully\r\n```", "comments": ["@aselle FYI\r\n1.13 branch is just cut last night. We will be going through such issues before we do the release.", "I get the same error trying to build current `master`:\r\n\r\n```\r\nERROR: /home/key/code/tensorflow/tensorflow/BUILD:582:1: Executing genrule //tensorflow:tf_python_api_gen_v1 failed (Exit 1)\r\nTraceback (most recent call last):\r\n  File \"/home/key/.cache/bazel/_bazel_key/8de93c72df6c3fec3e289f10fadff72b/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/home/key/.cache/bazel/_bazel_key/8de93c72df6c3fec3e289f10fadff72b/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/home/key/.cache/bazel/_bazel_key/8de93c72df6c3fec3e289f10fadff72b/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/home/key/anaconda3/envs/tf-13-1213/lib/python3.6/imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/home/key/anaconda3/envs/tf-13-1213/lib/python3.6/imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: /home/key/.cache/bazel/_bazel_key/8de93c72df6c3fec3e289f10fadff72b/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZNSaIPKN3xla14HloInstructionEEC1Ev\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/key/.cache/bazel/_bazel_key/8de93c72df6c3fec3e289f10fadff72b/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py\", line 27, in <module>\r\n    from tensorflow.python.tools.api.generator import doc_srcs\r\n  File \"/home/key/.cache/bazel/_bazel_key/8de93c72df6c3fec3e289f10fadff72b/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/home/key/.cache/bazel/_bazel_key/8de93c72df6c3fec3e289f10fadff72b/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"/home/key/.cache/bazel/_bazel_key/8de93c72df6c3fec3e289f10fadff72b/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/home/key/.cache/bazel/_bazel_key/8de93c72df6c3fec3e289f10fadff72b/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/home/key/.cache/bazel/_bazel_key/8de93c72df6c3fec3e289f10fadff72b/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"/home/key/anaconda3/envs/tf-13-1213/lib/python3.6/imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"/home/key/anaconda3/envs/tf-13-1213/lib/python3.6/imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: /home/key/.cache/bazel/_bazel_key/8de93c72df6c3fec3e289f10fadff72b/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1_tf_python_api_gen_v1.runfiles/org_tensorflow/tensorflow/python/_pywrap_tensorflow_internal.so: undefined symbol: _ZNSaIPKN3xla14HloInstructionEEC1Ev\r\n\r\n```", "I suggest you try a lower CUDA version (9.0) and a lower bazel version (0.15.0).I am not sure if this will solve the problem. But following the documentation suggested configuration may avoid some surprises", "```\r\n> c++filt _ZNSaIPKN3xla14HloInstructionEEC1Ev\r\nstd::allocator<xla::HloInstruction const*>::allocator()\r\n```\r\nit seems a XLA related problem.", "@freedomtan thanks! I've tried compiling again because I saw new updates to that file on master, but it still fails. Next I'll try without XLA support.\r\n\r\n@rootkitchao thanks, but these versions work when compiling other branches (1.10, 1.11, 1.12).", "Turns out it does indeed work when compiling without XLA!\r\nBut I guess I'll leave this open because it would be nice to be able to use XLA right?\r\n\r\nThx again @freedomtan!", "@skeydan I built 1.13 (b40aeb9c66a4b96536cca493906c2af461e72ad0) with XLA enabled successfully on Ubuntu 16.04+virtualenv+Python 3.5.2+Cuda 9.2+cudnn 7.1.4 just now.", "same error with or without XLA\r\n\r\npython 3.7.1, CUDA10, ubuntu 16.04.4", "having same issue, master branch\r\npython3.6.7 gcc7.3.0 cuda9.2 cudnn 7.2.1 ubuntu 18.04", "master branch, same error with XLA; ok without XLA.\r\nbazel master call:\r\nenv TMP=/tmp bazel build --config=opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --copt=-msse4.2 --cxxopt=-D_GLIBCXX_USE_CXX11_ABI=0 //tensorflow:libtensorflow.so //tensorflow/tools/pip_package:build_pip_package\r\n\r\nPackage versions: tensorflow1.13 bazel0.20 python2.7.15 gcc7.3.0 cuda10.0 cudnn7.4.2 fedora29", "Hi @alain54 - sorry for misusing this, but I plan to upgrade to F29 soon, and I see you have it working with cuda 10.\r\nMight I ask you what version of the nvidia driver you're using, and which is your kernel version? (I also take it, from what you write, that we still need to custom-compile gcc7 for cuda 10...?)\r\n\r\nThanks!", "Hi,\r\nSo, maybe this erreur comes from gcc 7.3.0-0, i.e the compiled source from https://gcc.gnu.org ?\r\nWith tensorflow Master, today, the 7.3.0-29 package from ubuntu 18.10 is OK; the compiled version 7.4.0 from gcc.gnu.org on my fedora 29 is also OK.\r\nPackage versions: tensorflowMaster bazel0.21 python2.7.15 gcc7.4.0 cuda10.0 cudnn7.4.2 fedora29 up to date.", "Thx @alain54! I was/am using gcc 7.3.0 (self-compiled). However, I'll be upgrading to F29 (including a newer kernel) this week. Would you mind indicating which is your kernel version, and the version of the nvidia driver? (The most \"destructive\" step in the whole procedure, for me, always being getting kernel and driver to match).", "Updating the original comment, as of 13/03/2019:\r\n\r\n@alain54 original idea was correct, this was/is due to using `gcc 7.3.0` in my case.\r\n\r\nAs of today, on Fedora 29 I can successfully compile TF master with `xla` with no tweaks to `bazel` configuration just by using `gcc 7.4.0`."]}, {"number": 24372, "title": "TF RPI build fails with AWS lib related linker errors", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nLinux rpi3-0 4.14.79-v7+ #1159 SMP Sun Nov 4 17:50:20 GMT 2018 armv7l GNU/Linux\r\n\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nn/a\r\n\r\n- TensorFlow installed from (source or binary):\r\nSource\r\n\r\n- TensorFlow version:\r\nv1.12.0\r\n\r\n- Python version:\r\nPython 2.7.13\r\n\r\n- Installed using virtualenv? pip? conda?:\r\nnope\r\n\r\n- Bazel version (if compiling from source):\r\n$ bazel version\r\nWARNING: The following rc files are no longer being read, please transfer their contents or import their path into one of the standard rc files:\r\n/home/pi/gocode/tensorflow/tools/bazel.rc\r\nINFO: Invocation ID: a32f1f82-b910-4312-b73c-335b3090412a\r\nBuild label: 0.20.0- (@non-git)\r\nBuild target: bazel-out/arm-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Thu Dec 13 03:56:33 2018 (1544673393)\r\nBuild timestamp: 1544673393\r\nBuild timestamp as int: 1544673393\r\n\r\n- GCC/Compiler version (if compiling from source):\r\ngcc (Raspbian 4.8.5-4) 4.8.5\r\n\r\n- CUDA/cuDNN version:\r\nn/a\r\n\r\n- GPU model and memory:\r\nn/a\r\n\r\n**Describe the problem**\r\nMy use case is running a binary, on Raspberry Pi, serving a TF model that has dynamic dependency on libtensorflow.so. Since I could not find pre-build TF C-library for RPI I tried to build it from source. After much pain and suffering I was able to get the code to compile, but saw linker errors related to AWS library. It would be great if users could download a pre-build library but in the mean time how can I resolve these errors. I do not need cloud support in TF, so if easier I would simply like to switch off such functionality.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n- Built proto (success)\r\n- Build bazel (success)\r\n- Check out v1.12.0 for TF code\r\n\r\nManually edit files with these commands:\r\n- grep -Rl 'lib64' | xargs sed -i 's/lib64/lib/g'\r\n- sed -i \"s|#define IS_MOBILE_PLATFORM|//#define IS_MOBILE_PLATFORM|g\" tensorflow/core/platform/platform.h\r\n\r\nInstall a few after seeing compile issues\r\n- sudo apt-get install gcc-4.8 g++-4.8\r\n- sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-4.8 100\r\n- sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-4.8 100\r\n- sudo apt-get install libc-ares-dev\r\n\r\nNo compile issues at this point after I added following flags to bazel command: `--copt=\"-std=gnu99\" --define=grpc_no_ares=true`. So I think `sudo apt-get install libc-ares-dev` is probably not required.\r\n\r\nAnyways, I then ran following command to build TF c-library:\r\n`bazel build -c opt --copt=\"-mfpu=neon-vfpv4\" --copt=\"-funsafe-math-optimizations\" --copt=\"-ftree-vectorize\" --copt=\"-fomit-frame-pointer\" --jobs 1 --local_resources 1024,1.0,1.0 --verbose_failures --genrule_strategy=standalone --spawn_strategy=standalone --incompatible_remove_native_http_archive=false --copt=\"-std=gnu99\" --define=grpc_no_ares=true //tensorflow:libtensorflow.so`\r\n\r\n\r\n**Any other info / logs**\r\nIt took 10 hours but all the code compiled fine, however, I ran into linker issues as follows:\r\n```\r\nERROR: /home/pi/gocode/tensorflow/tensorflow/BUILD:423:1: Linking of rule '//tensorflow:libtensorflow.so' failed (Exit 1): gcc failed: error executing command\r\n  (cd /home/pi/.cache/bazel/_bazel_pi/e36eb5edf9626338e60e5f0e9f0b5230/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PATH=/home/pi/go/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/local/games:/usr/games \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/usr/bin/python \\\r\n    PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \\\r\n    TF_DOWNLOAD_CLANG=0 \\\r\n    TF_NEED_CUDA=0 \\\r\n    TF_NEED_OPENCL_SYCL=0 \\\r\n    TF_NEED_ROCM=0 \\\r\n  /usr/bin/gcc -shared -o bazel-out/arm-opt/bin/tensorflow/libtensorflow.so -z defs -Wl,--version-script tensorflow/c/version_script.lds '-Wl,-rpath,$ORIGIN/' -Wl,-soname,libtensorflow.so -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread -pthread '-fuse-ld=gold' -Wl,-no-as-needed -Wl,-z,relro,-z,now -B/usr/bin -pass-exit-codes -Wl,--gc-sections -Wl,@bazel-out/arm-opt/bin/tensorflow/libtensorflow.so-2.params)\r\nExecution platform: @bazel_tools//platforms:host_platform\r\nbazel-out/arm-opt/bin/external/aws/_objs/aws/AWSCredentialsProvider.pic.o:AWSCredentialsProvider.cpp:function Aws::Auth::EnvironmentAWSCredentialsProvider::GetAWSCredentials(): error: undefined reference to 'Aws::Environment::GetEnv(char const*)'\r\nbazel-out/arm-opt/bin/external/aws/_objs/aws/AWSCredentialsProvider.pic.o:AWSCredentialsProvider.cpp:function Aws::Auth::EnvironmentAWSCredentialsProvider::GetAWSCredentials(): error: undefined reference to 'Aws::Environment::GetEnv(char const*)'\r\nbazel-out/arm-opt/bin/external/aws/_objs/aws/AWSCredentialsProvider.pic.o:AWSCredentialsProvider.cpp:function Aws::Auth::EnvironmentAWSCredentialsProvider::GetAWSCredentials(): error: undefined reference to 'Aws::Environment::GetEnv(char const*)'\r\nbazel-out/arm-opt/bin/external/aws/_objs/aws/AWSCredentialsProvider.pic.o:AWSCredentialsProvider.cpp:function Aws::Auth::ProfileConfigFileAWSCredentialsProvider::GetConfigProfileFilename(): error: undefined reference to 'Aws::FileSystem::GetHomeDirectory()'\r\nbazel-out/arm-opt/bin/external/aws/_objs/aws/AWSCredentialsProvider.pic.o:AWSCredentialsProvider.cpp:function Aws::Auth::ProfileConfigFileAWSCredentialsProvider::GetCredentialsProfileFilename(): error: undefined reference to 'Aws::Environment::GetEnv(char const*)'\r\nbazel-out/arm-opt/bin/external/aws/_objs/aws/AWSCredentialsProvider.pic.o:AWSCredentialsProvider.cpp:function Aws::Auth::ProfileConfigFileAWSCredentialsProvider::GetCredentialsProfileFilename(): error: undefined reference to 'Aws::FileSystem::GetHomeDirectory()'\r\nbazel-out/arm-opt/bin/external/aws/_objs/aws/ClientConfiguration.pic.o:ClientConfiguration.cpp:function Aws::Client::ClientConfiguration::ClientConfiguration(): error: undefined reference to 'Aws::OSVersionInfo::ComputeOSVersionString()'\r\nbazel-out/arm-opt/bin/external/aws/_objs/aws/DateTimeCommon.pic.o:DateTimeCommon.cpp:function Aws::Utils::DateTime::ConvertTimestampStringToTimePoint(char const*, Aws::Utils::DateFormat): error: undefined reference to 'Aws::Time::TimeGM(tm*)'\r\nbazel-out/arm-opt/bin/external/aws/_objs/aws/DateTimeCommon.pic.o:DateTimeCommon.cpp:function Aws::Utils::DateTime::ConvertTimestampToLocalTimeStruct() const: error: undefined reference to 'Aws::Time::LocalTime(tm*, long)'\r\nbazel-out/arm-opt/bin/external/aws/_objs/aws/DateTimeCommon.pic.o:DateTimeCommon.cpp:function Aws::Utils::DateTime::ConvertTimestampToGmtStruct() const: error: undefined reference to 'Aws::Time::GMTime(tm*, long)'\r\nbazel-out/arm-opt/bin/external/aws/_objs/aws/TempFile.pic.o:TempFile.cpp:function .LTHUNK5: error: undefined reference to 'Aws::FileSystem::RemoveFileIfExists(char const*)'\r\nbazel-out/arm-opt/bin/external/aws/_objs/aws/TempFile.pic.o:TempFile.cpp:function Aws::Utils::ComputeTempFileName(char const*, char const*): error: undefined reference to 'Aws::FileSystem::CreateTempFilePath()'\r\ncollect2: error: ld returned 1 exit status\r\nTarget //tensorflow:libtensorflow.so failed to build\r\nINFO: Elapsed time: 173.724s, Critical Path: 126.80s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@petewarden  Any thoughts on this ?", "also tried instructions [here](https://www.tensorflow.org/install/source_rpi), but ran into following errors with TF v1.12.0:\r\n\r\n```\r\nBuilding for the Pi Two/Three, with NEON acceleration\r\nWARNING: The following rc files are no longer being read, please transfer their contents or import their path into one of the standard rc files:\r\n/workspace/tools/bazel.rc\r\nWARNING: --batch mode is deprecated. Please instead explicitly shut down your Bazel server using the command \"bazel shutdown\".\r\nINFO: Invocation ID: 537ebdec-4670-44b7-8f27-b9d61f978791\r\nLoading:\r\nLoading: 0 packages loaded\r\nAnalyzing: 2 targets (1 packages loaded)\r\nERROR: cc_toolchain_suite '@local_config_arm_compiler//:toolchain' does not contain a toolchain for CPU 'armeabi', you may want to add an entry for 'armeabi|compiler' into toolchains and toolchain_identifier 'arm-linux-gnueabihf' into the corresponding cc_toolchain rule (see --incompatible_disable_cc_toolchain_label_from_crosstool_proto).\r\nINFO: Elapsed time: 1.550s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (2 packages loaded)\r\nFAILED: Build did NOT complete successfully (2 packages loaded)\r\n```", "The ability to disable AWS was removed in TF 1.12 but recently readded:\r\nhttps://github.com/tensorflow/tensorflow/commit/3437098ba5b111817ef6ac5906d86934168704b7\r\n\r\nApply those two patches: https://gist.github.com/fyhertz/4cef0b696b37d38964801d3ef21e8ce2 and restart your build with --config=noaws\r\n\r\nedit: One of the patch also moves the tools/bazel.rc, it has nothing to do with your issue, I needed it to build with bazel 0.19.2 :)", "> also tried instructions [here](https://www.tensorflow.org/install/source_rpi), but ran into following errors with TF v1.12.0:\r\n> \r\n\r\nI'm also facing this issue when cross-compiling for RPI, per docs. Seems to be another issue.\r\n\r\nAny ideas how solve that \"missing toolchain for armeabi\" issue?", "Closing this issue since RPI build is now working on master via cross-compiling workflow. Thank you TF team! ", "I got the same problem when compiling 2.0.0-alpha on FreeBSD.\r\n\r\nIs AWS support intended to be working at all?", "Fixed that by modifying the following switch: https://github.com/tensorflow/tensorflow/blob/master/third_party/aws/BUILD.bazel#L15"]}, {"number": 24371, "title": "FailedPreconditionError when using callbacks", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nThis is a modification of the MNIST tutorial. I have included callbacks for TensorBoard and also for a custom history callback, though that callback has been reduced to a no-op.\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nWindows 10 (Build 17134.471))\r\nSpyder 3.2.8\r\n\r\n- TensorFlow installed from (source or binary):  pip install TensorFlow\r\n\r\n- TensorFlow version (use command below):  1.12.0\r\n- Python version:  3.6.5; Qt 5.9.4, PyQt5 5.9.2 on Windows\r\n- GPU model and memory:  GeForce GTX 1070 Ti, 8G RAM\r\n\r\n**Describe the current behavior**\r\nWhen I include callbacks to TensorBoard and a custom History callback, I get a FailedPreconditionError.\r\n\r\nI was getting a similar error when just trying to use TensorBoard.  Changing the import statement to be more specific (from tensorflow.keras.callbacks import TensorBoard) fixed that one, but then I added the history callback, and it is unhappy again.\r\n\r\n**Describe the expected behavior**\r\nI include callbacks and do not get an error.\r\n\r\n**Code to reproduce the issue**\r\n\r\nimport os\r\n\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras.callbacks import TensorBoard\r\nfrom keras import backend as K\r\n\r\nclass LossLearningRateScheduler(keras.callbacks.History):\r\n    \"\"\"\r\n    *** By fergosuci on Kaggle.com ****\r\n    \r\n    A learning rate scheduler that relies on changes in loss function\r\n    \"\"\"\r\n    def __init__(self):\r\n        super(LossLearningRateScheduler, self).__init__()\r\n\r\n    def on_epoch_begin(self, epoch, logs=None):       \r\n        return K.get_value(self.model.optimizer.lr)\r\n\r\nfashion_mnist = keras.datasets.fashion_mnist\r\n\r\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\r\n\r\ntrain_images = train_images / 255.0\r\ntest_images = test_images / 255.0\r\n\r\nmodel = keras.Sequential([\r\n    keras.layers.Flatten(input_shape=(28, 28)),\r\n    keras.layers.Dense(128),\r\n    keras.layers.BatchNormalization(),\r\n    keras.layers.Activation('relu'),\r\n    keras.layers.Dense(10, activation=tf.nn.softmax)\r\n])\r\n\r\nmodel.compile(optimizer=keras.optimizers.SGD(), \r\n              loss='sparse_categorical_crossentropy',\r\n              metrics=['accuracy'])\r\n\r\nrunNumber = len(os.listdir('logs'))\r\ntensorboard = TensorBoard(log_dir=f\"logs/run_{runNumber}\", write_grads=True, write_graph=False)\r\nlearningRateScheduler = LossLearningRateScheduler()\r\n\r\nmodel.fit(train_images, train_labels, epochs=5, callbacks=[tensorboard, learningRateScheduler])\r\n\r\n\r\n**Other info / logs**\r\nTraceback (most recent call last):\r\n\r\n  File \"<ipython-input-7-52fc1b0c66af>\", line 1, in <module>\r\n    runfile('D:/Dev/Training/TensorFlow Tutorials/MNIST Fashion/ReproduceIssue.py', wdir='D:/Dev/Training/TensorFlow Tutorials/MNIST Fashion')\r\n\r\n  File \"D:\\dev\\Anaconda3\\lib\\site-packages\\spyder\\utils\\site\\sitecustomize.py\", line 705, in runfile\r\n    execfile(filename, namespace)\r\n\r\n  File \"D:\\dev\\Anaconda3\\lib\\site-packages\\spyder\\utils\\site\\sitecustomize.py\", line 102, in execfile\r\n    exec(compile(f.read(), filename, 'exec'), namespace)\r\n\r\n  File \"D:/Dev/Training/TensorFlow Tutorials/MNIST Fashion/ReproduceIssue.py\", line 44, in <module>\r\n    model.fit(train_images, train_labels, epochs=5, callbacks=[tensorboard, learningRateScheduler])\r\n\r\n  File \"D:\\dev\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1639, in fit\r\n    validation_steps=validation_steps)\r\n\r\n  File \"D:\\dev\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\", line 215, in fit_loop\r\n    outs = f(ins_batch)\r\n\r\n  File \"D:\\dev\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 2986, in __call__\r\n    run_metadata=self.run_metadata)\r\n\r\n  File \"D:\\dev\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1439, in __call__\r\n    run_metadata_ptr)\r\n\r\n  File \"D:\\dev\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 528, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\n\r\nFailedPreconditionError: Error while reading resource variable training_5/SGD/Variable_2 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/training_5/SGD/Variable_2/class tensorflow::Var does not exist.\r\n\t [[{{node training_5/SGD/mul_4/ReadVariableOp}} = ReadVariableOp[dtype=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training_5/SGD/Variable_2)]]", "comments": ["hi, i come across the same problem. have you sovled that?", "I never came up with a solution for that issue.", "any update on this i m facing the same issue \r\nBelow is my code followed with the error log \r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nfrom keras.callbacks import TensorBoard\r\nimport time\r\n#MODEL NAME\r\n\r\n# print(tf.__version__)\r\n\r\n\r\nNAME = \"fashion_mnist_28x28_{}\".format(int(time.time()))\r\n\r\ntensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\r\n\r\nfashion_mnist = keras.datasets.fashion_mnist\r\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\r\n\r\nclass_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\r\n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\r\n\r\nmodel_path=\"models/{}.h5\".format(NAME)\r\n\r\n# inspecting data for the fashion-mnist images \r\ndef inspect_data():\r\n    plt.figure()\r\n    plt.imshow(train_images[0])\r\n    plt.colorbar()\r\n    plt.grid(False)\r\n    plt.show()\r\n\r\ndef pre_process_data():\r\n    global train_images,test_images\r\n    train_images = train_images/255.0\r\n    test_images = test_images/255.0\r\n\r\ndef show25():\r\n    plt.figure(figsize=(10,10))\r\n    for i in range(25):\r\n        plt.subplot(5,5,i+1)\r\n        plt.xticks([])\r\n        plt.yticks([])\r\n        plt.grid(False)\r\n        plt.imshow(train_images[i],cmap=plt.cm.binary)\r\n        plt.xlabel(class_names[train_labels[i]])\r\n    plt.show()\r\n\r\n#pre_process_data()\r\n#show25()\r\n\r\ndef create_model():\r\n    model = keras.Sequential([\r\n        keras.layers.Flatten(input_shape=(28,28)),\r\n        keras.layers.Dense(128,activation=tf.nn.relu),\r\n        keras.layers.Dense(10,activation=tf.nn.softmax)\r\n    ])\r\n    model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\r\n    return model\r\n\r\n#model = create_model()\r\n#model.summary()\r\n\r\ndef train_model():\r\n    model = create_model()\r\n    pre_process_data()\r\n    model.fit(train_images,train_labels,batch_size=32,epochs=5)\r\n    return model\r\n\r\ndef train_and_save_as_whole():\r\n    # save the model in the HDF5\r\n    trained_model = train_model()\r\n    trained_model.save(model_path)\r\n\r\ndef read_model_as_whole(showsummary=False):\r\n    model = keras.models.load_model(model_path)\r\n    if showsummary:\r\n        model.summary()\r\n    return model\r\n\r\ndef read_whole_model_and_evaluate():\r\n    model=read_model_as_whole()\r\n    loss,acc = model.evaluate(test_images,test_labels)\r\n    print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))\r\n\r\n\r\ntrain_and_save_as_whole()\r\n\r\n```\r\nLog \r\n```\r\n2019-01-31 12:28:00.717309: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at resource_variable_ops.cc:420 : Not found: Container localhost does not exist. (Could not find resource: localhost/Adam/iterations)\r\nTraceback (most recent call last):\r\n  File \"fashion_mnist_keras_tf.py\", line 87, in <module>\r\n    train_and_save_as_whole()\r\n  File \"fashion_mnist_keras_tf.py\", line 72, in train_and_save_as_whole\r\n    trained_model = train_model()\r\n  File \"fashion_mnist_keras_tf.py\", line 67, in train_model\r\n    model.fit(train_images,train_labels,batch_size=32,epochs=5,callbacks=[tensorboard])\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1639, in fit\r\n    validation_steps=validation_steps)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\", line 215, in fit_loop\r\n    outs = f(ins_batch)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\", line 2986, in __call__\r\n    run_metadata=self.run_metadata)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1439, in __call__\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.FailedPreconditionError: Error while reading resource variable training/Adam/Variable_1 from Container: localhost.This could mean that the variable was uninitialized. Not found: Container localhost does not exist. (Could not find resource: localhost/training/Adam/Variable_1)\r\n         [[{{node training/Adam/mul_6/ReadVariableOp}} = ReadVariableOp[dtype=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training/Adam/Variable_1)]]\r\n\r\n```\r\n\r\n", "I still haven't heard of any fix for this one.\n\nOn Thu, Jan 31, 2019 at 2:28 AM divye1995 <notifications@github.com> wrote:\n\n> any update on this i m facing the same issue\n> Below is my code followed with the error log\n>\n> import tensorflow as tffrom tensorflow import keras\n> import numpy as npimport matplotlib.pyplot as pltfrom keras.callbacks import TensorBoardimport time#MODEL NAME\n> # print(tf.__version__)\n>\n> NAME = \"fashion_mnist_28x28_{}\".format(int(time.time()))\n>\n> tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n>\n> fashion_mnist = keras.datasets.fashion_mnist\n> (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n>\n> class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n>                'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n>\n> model_path=\"models/{}.h5\".format(NAME)\n> # inspecting data for the fashion-mnist images def inspect_data():\n>     plt.figure()\n>     plt.imshow(train_images[0])\n>     plt.colorbar()\n>     plt.grid(False)\n>     plt.show()\n> def pre_process_data():\n>     global train_images,test_images\n>     train_images = train_images/255.0\n>     test_images = test_images/255.0\n> def show25():\n>     plt.figure(figsize=(10,10))\n>     for i in range(25):\n>         plt.subplot(5,5,i+1)\n>         plt.xticks([])\n>         plt.yticks([])\n>         plt.grid(False)\n>         plt.imshow(train_images[i],cmap=plt.cm.binary)\n>         plt.xlabel(class_names[train_labels[i]])\n>     plt.show()\n> #pre_process_data()#show25()\n> def create_model():\n>     model = keras.Sequential([\n>         keras.layers.Flatten(input_shape=(28,28)),\n>         keras.layers.Dense(128,activation=tf.nn.relu),\n>         keras.layers.Dense(10,activation=tf.nn.softmax)\n>     ])\n>     model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n>     return model\n> #model = create_model()#model.summary()\n> def train_model():\n>     model = create_model()\n>     pre_process_data()\n>     model.fit(train_images,train_labels,batch_size=32,epochs=5)\n>     return model\n> def train_and_save_as_whole():\n>     # save the model in the HDF5\n>     trained_model = train_model()\n>     trained_model.save(model_path)\n> def read_model_as_whole(showsummary=False):\n>     model = keras.models.load_model(model_path)\n>     if showsummary:\n>         model.summary()\n>     return model\n> def read_whole_model_and_evaluate():\n>     model=read_model_as_whole()\n>     loss,acc = model.evaluate(test_images,test_labels)\n>     print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))\n>\n>\n> train_and_save_as_whole()\n>\n> Log\n>\n> 2019-01-31 12:28:00.717309: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at resource_variable_ops.cc:420 : Not found: Container localhost does not exist. (Could not find resource: localhost/Adam/iterations)\n> Traceback (most recent call last):\n>   File \"fashion_mnist_keras_tf.py\", line 87, in <module>\n>     train_and_save_as_whole()\n>   File \"fashion_mnist_keras_tf.py\", line 72, in train_and_save_as_whole\n>     trained_model = train_model()\n>   File \"fashion_mnist_keras_tf.py\", line 67, in train_model\n>     model.fit(train_images,train_labels,batch_size=32,epochs=5,callbacks=[tensorboard])\n>   File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1639, in fit\n>     validation_steps=validation_steps)\n>   File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\", line 215, in fit_loop\n>     outs = f(ins_batch)\n>   File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\", line 2986, in __call__\n>     run_metadata=self.run_metadata)\n>   File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1439, in __call__\n>     run_metadata_ptr)\n>   File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 528, in __exit__\n>     c_api.TF_GetCode(self.status.status))\n> tensorflow.python.framework.errors_impl.FailedPreconditionError: Error while reading resource variable training/Adam/Variable_1 from Container: localhost.This could mean that the variable was uninitialized. Not found: Container localhost does not exist. (Could not find resource: localhost/training/Adam/Variable_1)\n>          [[{{node training/Adam/mul_6/ReadVariableOp}} = ReadVariableOp[dtype=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training/Adam/Variable_1)]]\n>\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/24371#issuecomment-459242572>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AGGPELt-5f1-3l7fMA1bUZ4GmH_i6wEWks5vIpspgaJpZM4ZTiNS>\n> .\n>\n", "Me too facing this with TensorBoard", "the same problem\r\n\r\nMy model:\r\n```\r\n    model = tf.keras.models.Sequential()\r\n    model.add(tf.keras.layers.Embedding(len(sp), 10, input_length=max_sequence_len-1))\r\n    model.add(tf.keras.layers.Bidirectional(tf.keras.layers.CuDNNLSTM(500)))\r\n    model.add(tf.keras.layers.Dropout(0.4))\r\n    model.add(tf.keras.layers.Dense(len(sp), activation=tf.keras.activations.softmax))\r\n\r\n    model.compile(\r\n        optimizer=tf.keras.optimizers.Adam(),\r\n        loss=tf.keras.losses.categorical_crossentropy,\r\n        metrics=['mae', 'acc', 'accuracy', 'categorical_accuracy']\r\n    )\r\n```", "I'm unable to reproduce the original issue, could you please try with the latest nightly version of TensorFlow?", "> **System information**\r\n> \r\n> * Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n>   This is a modification of the MNIST tutorial. I have included callbacks for TensorBoard and also for a custom history callback, though that callback has been reduced to a no-op.\r\n> * OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n>   Windows 10 (Build 17134.471))\r\n>   Spyder 3.2.8\r\n> * TensorFlow installed from (source or binary):  pip install TensorFlow\r\n> * TensorFlow version (use command below):  1.12.0\r\n> * Python version:  3.6.5; Qt 5.9.4, PyQt5 5.9.2 on Windows\r\n> * GPU model and memory:  GeForce GTX 1070 Ti, 8G RAM\r\n> \r\n> **Describe the current behavior**\r\n> When I include callbacks to TensorBoard and a custom History callback, I get a FailedPreconditionError.\r\n> \r\n> I was getting a similar error when just trying to use TensorBoard. Changing the import statement to be more specific (from tensorflow.keras.callbacks import TensorBoard) fixed that one, but then I added the history callback, and it is unhappy again.\r\n> \r\n> **Describe the expected behavior**\r\n> I include callbacks and do not get an error.\r\n> \r\n> **Code to reproduce the issue**\r\n> \r\n> import os\r\n> \r\n> import tensorflow as tf\r\n> from tensorflow import keras\r\n> from tensorflow.keras.callbacks import TensorBoard\r\n> from keras import backend as K\r\n> \r\n> class LossLearningRateScheduler(keras.callbacks.History):\r\n> \"\"\"\r\n> *** By fergosuci on Kaggle.com ****\r\n> \r\n> ```\r\n> A learning rate scheduler that relies on changes in loss function\r\n> \"\"\"\r\n> def __init__(self):\r\n>     super(LossLearningRateScheduler, self).__init__()\r\n> \r\n> def on_epoch_begin(self, epoch, logs=None):       \r\n>     return K.get_value(self.model.optimizer.lr)\r\n> ```\r\n> \r\n> fashion_mnist = keras.datasets.fashion_mnist\r\n> \r\n> (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\r\n> \r\n> train_images = train_images / 255.0\r\n> test_images = test_images / 255.0\r\n> \r\n> model = keras.Sequential([\r\n> keras.layers.Flatten(input_shape=(28, 28)),\r\n> keras.layers.Dense(128),\r\n> keras.layers.BatchNormalization(),\r\n> keras.layers.Activation('relu'),\r\n> keras.layers.Dense(10, activation=tf.nn.softmax)\r\n> ])\r\n> \r\n> model.compile(optimizer=keras.optimizers.SGD(),\r\n> loss='sparse_categorical_crossentropy',\r\n> metrics=['accuracy'])\r\n> \r\n> runNumber = len(os.listdir('logs'))\r\n> tensorboard = TensorBoard(log_dir=f\"logs/run_{runNumber}\", write_grads=True, write_graph=False)\r\n> learningRateScheduler = LossLearningRateScheduler()\r\n> \r\n> model.fit(train_images, train_labels, epochs=5, callbacks=[tensorboard, learningRateScheduler])\r\n> \r\n> **Other info / logs**\r\n> Traceback (most recent call last):\r\n> \r\n> File \"\", line 1, in \r\n> runfile('D:/Dev/Training/TensorFlow Tutorials/MNIST Fashion/ReproduceIssue.py', wdir='D:/Dev/Training/TensorFlow Tutorials/MNIST Fashion')\r\n> \r\n> File \"D:\\dev\\Anaconda3\\lib\\site-packages\\spyder\\utils\\site\\sitecustomize.py\", line 705, in runfile\r\n> execfile(filename, namespace)\r\n> \r\n> File \"D:\\dev\\Anaconda3\\lib\\site-packages\\spyder\\utils\\site\\sitecustomize.py\", line 102, in execfile\r\n> exec(compile(f.read(), filename, 'exec'), namespace)\r\n> \r\n> File \"D:/Dev/Training/TensorFlow Tutorials/MNIST Fashion/ReproduceIssue.py\", line 44, in \r\n> model.fit(train_images, train_labels, epochs=5, callbacks=[tensorboard, learningRateScheduler])\r\n> \r\n> File \"D:\\dev\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\", line 1639, in fit\r\n> validation_steps=validation_steps)\r\n> \r\n> File \"D:\\dev\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\", line 215, in fit_loop\r\n> outs = f(ins_batch)\r\n> \r\n> File \"D:\\dev\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 2986, in **call**\r\n> run_metadata=self.run_metadata)\r\n> \r\n> File \"D:\\dev\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1439, in **call**\r\n> run_metadata_ptr)\r\n> \r\n> File \"D:\\dev\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\", line 528, in **exit**\r\n> c_api.TF_GetCode(self.status.status))\r\n> \r\n> FailedPreconditionError: Error while reading resource variable training_5/SGD/Variable_2 from Container: localhost. This could mean that the variable was uninitialized. Not found: Resource localhost/training_5/SGD/Variable_2/class tensorflow::Var does not exist.\r\n> [[{{node training_5/SGD/mul_4/ReadVariableOp}} = ReadVariableOp[dtype=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training_5/SGD/Variable_2)]]\r\n\r\nHi, have you solved the issue? I have same problem. Please help if you have solution."]}, {"number": 24370, "title": "Use retrained graph with tensorflow in C", "body": "Hi guys I'm trying to use retrained graph created with image retraining with C api. I retrainded with bitmap image with size 444x440. The C code that i wrote is the following:\r\n\r\n```\r\n#include \"neural_network.h\"\r\n\r\n#define GRAPH_NAME (\"retrained_graph.pb\")\r\n#define IN_NAME (\"Placeholder\")\r\n#define OUT_NAME (\"final_result\")\r\n\r\n// Change this or array data with less useless name\r\ntypedef unsigned int data_t;\r\n\r\nvoid free_buffer(void *data, size_t length) { free(data); }\r\n\r\n/* Read file containing the graph of the neural network and initialize the\r\n * TF_Buffer\r\n */\r\nTF_Buffer *read_file(const char *file) {\r\n    FILE *f = fopen(file, \"rb\");\r\n    fseek(f, 0, SEEK_END);\r\n    long fsize = ftell(f);\r\n    fseek(f, 0, SEEK_SET);\r\n\r\n    void *data = malloc(fsize);\r\n    fread(data, fsize, 1, f);\r\n    fclose(f);\r\n\r\n    TF_Buffer *buf = TF_NewBuffer();\r\n    buf->data = data;\r\n    buf->length = fsize;\r\n    buf->data_deallocator = free_buffer;\r\n    return buf;\r\n}\r\n\r\n// import the graph in the main graph\r\nvoid import_graph(TF_Graph *graph, TF_Status *status) {\r\n    TF_Buffer *graph_def = read_file(GRAPH_NAME);\r\n\r\n    TF_ImportGraphDefOptions *opts = TF_NewImportGraphDefOptions();\r\n    TF_GraphImportGraphDef(graph, graph_def, opts, status);\r\n    TF_DeleteImportGraphDefOptions(opts);\r\n    // check status\r\n    if (TF_GetCode(status) != TF_OK) {\r\n        fprintf(stderr, \"ERROR: Unable to import graph %s\", TF_Message(status));\r\n        return;\r\n    }\r\n\r\n    TF_DeleteBuffer(graph_def);\r\n}\r\n\r\nstatic void Deallocator(void *data, size_t length, void *arg) {}\r\n\r\nTF_Code run_session(TF_Graph *graph, TF_Status *status, data_t *data) {\r\n    float *result;\r\n\r\n    // Number of bytes of input\r\n    const int nb_in = EL_W * ACT_IMG_H * sizeof(data_t);\r\n\r\n    // Number of bytes of output\r\n    const int nb_out = 3 * sizeof(float);\r\n\r\n    // Input dimensions\r\n    int64_t in_dims[] = {1, EL_W, ACT_IMG_H, 0};\r\n    int n_in_dims = sizeof(in_dims) / sizeof(int64_t);\r\n\r\n    // Output dimensions\r\n    int64_t out_dims[] = {1, 3};\r\n    int n_out_dims = sizeof(out_dims) / sizeof(int64_t);\r\n\r\n    TF_Output input_op = {TF_GraphOperationByName(graph, IN_NAME), 0};\r\n\r\n    TF_Tensor *input_tensor = TF_NewTensor(TF_FLOAT, in_dims, n_in_dims, data,\r\n                                           nb_in, &Deallocator, 0);\r\n\r\n    TF_Output output = {TF_GraphOperationByName(graph, OUT_NAME), 0};\r\n\r\n    TF_Tensor *output_values =\r\n        TF_AllocateTensor(TF_FLOAT, out_dims, n_out_dims, nb_out);\r\n\r\n    TF_SessionOptions *sess_opts = TF_NewSessionOptions();\r\n    TF_Session *session = TF_NewSession(graph, sess_opts, status);\r\n\r\n    TF_SessionRun(session,\r\n                  NULL,                        // Run options\r\n                  &input_op, &input_tensor, 1, // in: tensor, values, number\r\n                  &output, &output_values, 1,  // out: tensor, vlaues, number\r\n                  NULL, 0,                     // target operation, num targets\r\n                  NULL,                        // metadata\r\n                  status                       // outputs status\r\n    );\r\n\r\n    // result = TF_TensorData(output_values);\r\n    // printf(\"%f %f %f\\n\", result[0], result[1], result[2]);\r\n\r\n    printf(\"%s\\n\", TF_Message(status));\r\n    return TF_GetCode(status);\r\n}\r\n\r\nvoid image_linearization(data_t *data) {\r\n    BITMAP *image;\r\n    acquire_screen();\r\n    image = create_sub_bitmap(screen, IMG_XT, IMG_YT, EL_W, ACT_IMG_H);\r\n\r\n    ssize_t x;\r\n    ssize_t line;\r\n\r\n    for (line = 0; line < image->h; ++line)\r\n        for (x = 0; x < image->w; ++x) {\r\n            data[line * image->h + x] = ((data_t *)image->line[line])[x];\r\n        }\r\n\r\n    destroy_bitmap(image);\r\n    release_screen();\r\n}\r\n\r\nvoid *neural_network_task(void *period) {\r\n    struct timespec t;\r\n    data_t data[EL_W * ACT_IMG_H];\r\n\r\n    TF_Graph *graph = TF_NewGraph();\r\n    TF_Status *status = TF_NewStatus();\r\n\r\n    import_graph(graph, status);\r\n\r\n    set_activation(&t, *(int *)period);\r\n\r\n    /*\r\n    TF_Operation *decode = TF_GraphOperationByName(graph, IN_NAME);\r\n    printf(\"P: %p\\n\", decode);\r\n    printf(\"NO: %i\\n\", TF_OperationNumOutputs(decode));\r\n    printf(\"NI: %i\\n\", TF_OperationNumInputs(decode));\r\n\r\n    decode = TF_GraphOperationByName(graph, OUT_NAME);\r\n    printf(\"P: %p\\n\", decode);\r\n    printf(\"NO: %i\\n\", TF_OperationNumOutputs(decode));\r\n    printf(\"NI: %i\\n\", TF_OperationNumInputs(decode));\r\n    */\r\n\r\n    while (1) {\r\n        image_linearization(data);\r\n\r\n        printf(\"%i %s\\n\", run_session(graph, status, data));\r\n        // TF_Message(status));\r\n        wait_for_activation(&t, *(int *)period);\r\n    }\r\n}\r\n```\r\n\r\nI had linearized the bitmap with the function and placed it into array with \"width*height\" element, then i following some example for creating tensor and run session but it didn't works. The tensor it's just one and the output tensor it's for 3 type of class.\r\n\r\nThe error that tensorflow gives me it's the following:\r\n\r\n```\r\nGeneric conv implementation does not support grouped convolutions for now.\r\n         [[{{node module_apply_default/InceptionV3/InceptionV3/Conv2d_1a_3x3/BatchNorm/FusedBatchNorm/Mul}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"VALID\", strides=[1, 2, 2, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](module_apply_default/hub_input/Sub, module_apply_default/InceptionV3/InceptionV3/Conv2d_1a_3x3/Conv2D/merged_input)]]\r\n```\r\n\r\nHow i can fix it?", "comments": ["Provide more details: what version of TF were your graphs using / made with? Just a hint, but maybe \"Generic conv implementation does not support grouped convolutions for now\".. maybe thats resolved in a newer version of TF/Inception?", "The graph was made with [image_retraining](https://www.tensorflow.org/hub/tutorials/image_retraining). The version of tensorflow is the lastone installed from the website, 1.12. ", "The error was introduced around 8 months ago according to git blame. It does not look like newer versions support this yet?.. So you may have to modify your code to not use this feature or you could try using an older version of Tensorflow.\r\n\r\nthis line of code may give you a hint: ` OP_REQUIRES(ctx, in_depth == filter.dim_size(2),` ctx is just your tf OpKernelContext.. which probably resolves to your whole tf instance, not sure...\r\n\r\nDoes `filter.dim_size(2)` mean anything to you?\r\n\r\nHopefully someone who can look at your code can suggest an alternative approach..\r\n\r\nDepthwise convolution and grouped convolutions seems to be good keywords to help you investigate an alternative.\r\n\r\nblame : https://github.com/tensorflow/tensorflow/blame/270acc07cc9c70e51e80956c032b5a264fb82dd8/tensorflow/core/kernels/conv_ops.cc#L133\r\nhttps://github.com/tensorflow/tensorflow/commit/a5a51ad3a1200e2e5ef46c140bab717422e41ca2\r\n\r\n\r\nEDIT:\r\n\r\n~~~\r\n    int64_t in_dims[] = {1, EL_W, ACT_IMG_H, 0};\r\n    int n_in_dims = sizeof(in_dims) / sizeof(int64_t);\r\n~~~\r\nSo `n_in_dims` is 4. and your then call `TF_NewTensor`.. Which I think will return the error when you call `TF_SessionRun`.. So why not create multiple tensors with only 2 input dims in each one? \r\nI guess 3D tensors aren't supported when you want to run convolutions on them..\r\n\r\nI hope I'm being helpful... Hopefully someone with more expertise can provide additional information.", "> \r\n> \r\n> The error was introduced around 8 months ago according to git blame. It does not look like newer versions support this yet?.. So you may have to modify your code to not use this feature or you could try using an older version of Tensorflow.\r\n> \r\n> this line of code may give you a hint: ` OP_REQUIRES(ctx, in_depth == filter.dim_size(2),` ctx is just your tf OpKernelContext.. which probably resolves to your whole tf instance, not sure...\r\n> \r\n> Does `filter.dim_size(2)` mean anything to you?\r\n> \r\n> Hopefully someone who can look at your code can suggest an alternative approach..\r\n> \r\n> Depthwise convolution and grouped convolutions seems to be good keywords to help you investigate an alternative.\r\n> \r\n> blame : https://github.com/tensorflow/tensorflow/blame/270acc07cc9c70e51e80956c032b5a264fb82dd8/tensorflow/core/kernels/conv_ops.cc#L133\r\n> [a5a51ad](https://github.com/tensorflow/tensorflow/commit/a5a51ad3a1200e2e5ef46c140bab717422e41ca2)\r\n> \r\n> EDIT:\r\n> \r\n> ```\r\n>     int64_t in_dims[] = {1, EL_W, ACT_IMG_H, 0};\r\n>     int n_in_dims = sizeof(in_dims) / sizeof(int64_t);\r\n> ```\r\n> \r\n> So `n_in_dims` is 4. and your then call `TF_NewTensor`.. Which I think will return the error when you call `TF_SessionRun`.. So why not create multiple tensors with only 2 input dims in each one?\r\n> I guess 3D tensors aren't supported when you want to run convolutions on them..\r\n> \r\n> I hope I'm being helpful... Hopefully someone with more expertise can provide additional information.\r\n\r\nI'm forced to use 4d dimension because if i use just {EL_W, ACT_IMG_H} I got other error that is the following:\r\n\r\n```\r\n2018-12-14 18:42:22.049577: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at conv_ops.cc:437 : Invalid argument: input must be 4-dimensional[1,444,440]\r\ninput must be 4-dimensional[1,444,440]\r\n```\r\n\r\nSo i'm forced to use different dims but it give me other error!\r\n\r\n**Edit:**\r\nI think that the problem is that the retrain script force size of image to specific size and then i use different size that C api doesn't resize at all.", "Just a quick summary: I'm trying to build graph with retrain script. I want use this graph into my C code for the recognition of an image that is rapresented by `array[WIDTH*HEIGHT]`. If some of you have some example that after retrain nn with own images with arbitrary size (WIDTH, HEIGHT) that use an array for store it and use as an input of `TF_NewTensor` used by session.", "So now the question is: it's possible to use retrained graph with C api or it's only possible with C++ and python, like the guide suggest? I'm in wrong?", "No I think it should be possible. I think you may have to look closely at the API / function definitions... Have you done so? Sorry I haven't got enough time this week to look closer..\r\n@harshini-gadige Do you know anyone you can include in on this problem with more knowledge?", "Update:\r\n```\r\n#include \"neural_network.h\"\r\n\r\nvoid free_buffer(void *data, size_t length) { free(data); }\r\n\r\n/* Read file containing the graph of the neural network and initialize the\r\n * TF_Buffer\r\n */\r\nTF_Buffer *read_file(const char *file) {\r\n    FILE *f = fopen(file, \"rb\");\r\n    fseek(f, 0, SEEK_END);\r\n    long fsize = ftell(f);\r\n    fseek(f, 0, SEEK_SET);\r\n\r\n    void *data = malloc(fsize);\r\n    fread(data, fsize, 1, f);\r\n    fclose(f);\r\n\r\n    TF_Buffer *buf = TF_NewBuffer();\r\n    buf->data = data;\r\n    buf->length = fsize;\r\n    buf->data_deallocator = free_buffer;\r\n    return buf;\r\n}\r\n\r\n// import the graph in the main graph\r\nvoid import_graph(TF_Graph *graph, TF_Status *status) {\r\n    TF_Buffer *graph_def = read_file(GRAPH_NAME);\r\n\r\n    TF_ImportGraphDefOptions *opts = TF_NewImportGraphDefOptions();\r\n    TF_GraphImportGraphDef(graph, graph_def, opts, status);\r\n    TF_DeleteImportGraphDefOptions(opts);\r\n    // check status\r\n    if (TF_GetCode(status) != TF_OK) {\r\n        fprintf(stderr, \"ERROR: Unable to import graph %s\", TF_Message(status));\r\n        return;\r\n    }\r\n\r\n    TF_DeleteBuffer(graph_def);\r\n}\r\n\r\nstatic void Deallocator(void *data, size_t length, void *arg) {}\r\n\r\nvoid run_session(TF_Graph *graph, TF_Status *status, tfdat_t *data) {\r\n    // Number of bytes of input\r\n    const unsigned int nb_in = ARRAY_SIZE * sizeof(tfdat_t);\r\n\r\n    // Number of bytes of output\r\n    const int nb_out = N_LAB * sizeof(float);\r\n\r\n    // Input dimensions\r\n    int64_t in_dims[] = {1, EL_W, ACT_IMG_H, CHANNELS};\r\n    int n_in_dims = sizeof(in_dims) / sizeof(int64_t);\r\n\r\n    // Output dimensions\r\n    int64_t out_dims[] = {1, N_LAB};\r\n    int n_out_dims = sizeof(out_dims) / sizeof(int64_t);\r\n\r\n    TF_Output input_op = {TF_GraphOperationByName(graph, IN_NAME), 0};\r\n\r\n    TF_Tensor *input_tensor = TF_NewTensor(TF_FLOAT, in_dims, n_in_dims, data,\r\n                                           nb_in, &Deallocator, 0);\r\n\r\n    TF_Output output = {TF_GraphOperationByName(graph, OUT_NAME), 0};\r\n\r\n    TF_Tensor *output_values =\r\n        TF_AllocateTensor(TF_FLOAT, out_dims, n_out_dims, nb_out);\r\n\r\n    TF_SessionOptions *sess_opts = TF_NewSessionOptions();\r\n    TF_Session *session = TF_NewSession(graph, sess_opts, status);\r\n\r\n    TF_SessionRun(session,\r\n                  NULL,                        // Run options\r\n                  &input_op, &input_tensor, 1, // in: tensor, values, number\r\n                  &output, &output_values, 1,  // out: tensor, vlaues, number\r\n                  NULL, 0,                     // target operation, num targets\r\n                  NULL,                        // metadata\r\n                  status                       // outputs status\r\n    );\r\n\r\n    if (TF_GetCode(status) == TF_OK) {\r\n        pthread_mutex_lock(&mutex_res);\r\n        result = TF_TensorData(output_values);\r\n        pthread_mutex_unlock(&mutex_res);\r\n    } else\r\n        fprintf(stderr, \"%s\\n\", TF_Message(status));\r\n}\r\n\r\nvoid image_linearization(tfdat_t *data) {\r\n    BITMAP *image;\r\n    acquire_screen();\r\n    image = create_sub_bitmap(screen, IMG_XT, IMG_YT, EL_W, ACT_IMG_H);\r\n\r\n    ssize_t x;\r\n    ssize_t line;\r\n\r\n    for (line = 0; line < image->h; ++line)\r\n        for (x = 0; x < image->w; ++x) {\r\n            int color = _getpixel16(image, x, line);\r\n            data[line * image->w + x] = (tfdat_t)getr16(color) / (1 << 8);\r\n            data[line * image->w + x + 1 * image->h * image->w] = (tfdat_t)getg16(color) / (1 << 8);\r\n            data[line * image->w + x + 2 * image->h * image->w] = (tfdat_t)getb16(color) / (1 << 8);\r\n        }\r\n\r\n    destroy_bitmap(image);\r\n    release_screen();\r\n}\r\n\r\nvoid *neural_network_task(void *period) {\r\n    struct timespec t;\r\n    tfdat_t data[EL_W * ACT_IMG_H * CHANNELS];\r\n\r\n    TF_Graph *graph = TF_NewGraph();\r\n    TF_Status *status = TF_NewStatus();\r\n\r\n    import_graph(graph, status);\r\n\r\n    set_activation(&t, *(int *)period);\r\n\r\n    while (1) {\r\n        image_linearization(data);\r\n\r\n        run_session(graph, status, data);\r\n        wait_for_activation(&t, *(int *)period);\r\n    }\r\n}\r\n```\r\n\r\nNow the code works but the result it's wrong. The problem is, in my honest opinion, that the script python resize the image with fix height and width (299,299) but my image is (444,440). In python there are `tf.image.resize_bilinear`, how i can do it in C? There are also other problem, tensorflow expect image divided into 3 color channels (RGB) how i have to convert this value for put it into array? All height*width elements are red then green and finally blue or it's R G B R G B and so on.", "This is quite a large question, and seems more appropriate for Stack Overflow (since it's about usage now rather than a bug). You can see an example of doing image resizing here:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/ios/simple/RunModelViewController.mm#L157"]}, {"number": 24369, "title": "ValueError: No variables to save", "body": "**System information**\r\n- Have I written custom code  : No\r\n- OS Platform and Distribution : Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.12\r\n- Python version: Python3.5\r\n- Bazel version (if compiling from source): Bazel-0.18.0\r\n\r\nI have used tf.keras to build a model and set keras backend session as sess where sess=tf.Session()\r\n\r\nSaved the graph_def file using below function \r\ntf.io.write_graph(sess.graph_def, '/tmp/model', 'model _graph.pbtxt')\r\n\r\nGenerated ckpt file using callbacks present in tensorflow as follows\r\ncp_callback=keras.callbacks.ModelCheckpoint(checkpoint_path, verbose=1, save_weights_only=True, period=1)\r\n\r\nWhen I am trying to generate frozen file using bazel I am getting below error\r\n\r\nTraceback (most recent call last):\r\n  File \"/root/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 491, in <module>\r\n    run_main()\r\n  File \"/root/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 488, in run_main\r\n    app.run(main=my_main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/root/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"/root/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 487, in <lambda>\r\n    my_main = lambda unused_args: main(unused_args, flags)\r\n  File \"/root/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 381, in main\r\n    flags.saved_model_tags, checkpoint_version)\r\n  File \"/root/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 363, in freeze_graph\r\n    checkpoint_version=checkpoint_version)\r\n  File \"/root/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 190, in freeze_graph_with_def_protos\r\n    var_list=var_list, write_version=checkpoint_version)\r\n  File \"/root/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/training/saver.py\", line 1123, in __init__\r\n    self.build()\r\n  File \"/root/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/training/saver.py\", line 1135, in build\r\n    self._build(self._filename, build_save=True, build_restore=True)\r\n  File \"/root/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/training/saver.py\", line 1160, in _build\r\n    raise ValueError(\"No variables to save\")\r\nValueError: No variables to save\r\n\r\n\r\nHow to solve this ValueError ? ", "comments": ["So your title is a little misleading... Where are your getting the attribute error? I dont see it in the stack trace.. if Object is an `int`... `int` is a primitive type so obviously it does not have object `node` in it...\r\n\r\nI have a hunch as to whats wrong... Can you provide the commands you're running around the area of freeze graph and save? It sounds like you are not providing proper arguments to the functions you are calling.. \r\n\r\nPython can be a bit tricky wrt objects because everything is an \"object\".. So its not going to give you an error necessarily .. like \"hey silly I want an array not an int\".. or \"hey silly I want a linked list of int with attribute node so I can traverse the list.\"\r\n\r\nYou probably are aware.. but errors are almost always terse and oblivious of implementation requirements.", "Exactly where I'm at right now and came here after Google (wow) \r\n\r\n`AttributeError: 'int' object has no attribute 'node'`\r\n\r\nAnyone know the solution to this?", "> So your title is a little misleading... Where are your getting the attribute error? I dont see it in the stack trace.. if Object is an `int`... `int` is a primitive type so obviously it does not have object `node` in it...\r\n> \r\n> I have a hunch as to whats wrong... Can you provide the commands you're running around the area of freeze graph and save? It sounds like you are not providing proper arguments to the functions you are calling..\r\n> \r\n> Python can be a bit tricky wrt objects because everything is an \"object\".. So its not going to give you an error necessarily .. like \"hey silly I want an array not an int\".. or \"hey silly I want a linked list of int with attribute node so I can traverse the list.\"\r\n> \r\n> You probably are aware.. but errors are almost always terse and oblivious of implementation requirements.\r\n\r\nUntil the OP replies here's my command which is resulting in the error above\r\n`python E:\\Documents\\Projects\\tensorflow\\tensorflow\\tensorflow\\python\\tools\\freeze_graph.py --input_graph=/model/frozen_inference_graph.pb --input_checkpoint=model/model.ckpt-50000 --input_binary=true --output_graph=model/frozen_mobilenet_graph.pb --output_node_names=MobilenetV2/Logits/output:0`", "> > So your title is a little misleading... Where are your getting the attribute error? I dont see it in the stack trace.. if Object is an `int`... `int` is a primitive type so obviously it does not have object `node` in it...\r\n> > I have a hunch as to whats wrong... Can you provide the commands you're running around the area of freeze graph and save? It sounds like you are not providing proper arguments to the functions you are calling..\r\n> > Python can be a bit tricky wrt objects because everything is an \"object\".. So its not going to give you an error necessarily .. like \"hey silly I want an array not an int\".. or \"hey silly I want a linked list of int with attribute node so I can traverse the list.\"\r\n> > You probably are aware.. but errors are almost always terse and oblivious of implementation requirements.\r\n> \r\n> Until the OP replies here's my command which is resulting in the error above\r\n> `python E:\\Documents\\Projects\\tensorflow\\tensorflow\\tensorflow\\python\\tools\\freeze_graph.py --input_graph=/model/frozen_inference_graph.pb --input_checkpoint=model/model.ckpt-50000 --input_binary=true --output_graph=model/frozen_mobilenet_graph.pb --output_node_names=MobilenetV2/Logits/output:0`\r\n\r\nCheck whether you have specified correct path to protobuf file and checkpoint file in the command.", "> So your title is a little misleading... Where are your getting the attribute error? I dont see it in the stack trace.. if Object is an `int`... `int` is a primitive type so obviously it does not have object `node` in it...\r\n> \r\n> I have a hunch as to whats wrong... Can you provide the commands you're running around the area of freeze graph and save? It sounds like you are not providing proper arguments to the functions you are calling..\r\n> \r\n> Python can be a bit tricky wrt objects because everything is an \"object\".. So its not going to give you an error necessarily .. like \"hey silly I want an array not an int\".. or \"hey silly I want a linked list of int with attribute node so I can traverse the list.\"\r\n> \r\n> You probably are aware.. but errors are almost always terse and oblivious of implementation requirements.\r\n\r\nI have forgot to change the title . When I have used the freeze graph first I got Attribute error, after resolving that error now I am encountering this issue.", "> > > So your title is a little misleading... Where are your getting the attribute error? I dont see it in the stack trace.. if Object is an `int`... `int` is a primitive type so obviously it does not have object `node` in it...\r\n> > > I have a hunch as to whats wrong... Can you provide the commands you're running around the area of freeze graph and save? It sounds like you are not providing proper arguments to the functions you are calling..\r\n> > > Python can be a bit tricky wrt objects because everything is an \"object\".. So its not going to give you an error necessarily .. like \"hey silly I want an array not an int\".. or \"hey silly I want a linked list of int with attribute node so I can traverse the list.\"\r\n> > > You probably are aware.. but errors are almost always terse and oblivious of implementation requirements.\r\n> > \r\n> > \r\n> > Until the OP replies here's my command which is resulting in the error above\r\n> > `python E:\\Documents\\Projects\\tensorflow\\tensorflow\\tensorflow\\python\\tools\\freeze_graph.py --input_graph=/model/frozen_inference_graph.pb --input_checkpoint=model/model.ckpt-50000 --input_binary=true --output_graph=model/frozen_mobilenet_graph.pb --output_node_names=MobilenetV2/Logits/output:0`\r\n> \r\n> Check whether you have specified correct path to protobuf file and checkpoint file in the command.\r\n\r\nYes I have checked\r\n\r\n> I have forgot to change the title . When I have used the freeze graph first I got Attribute error, after resolving that error now I am encountering this issue.\r\n\r\nWhats the latest error you're getting?\r\n\r\nAlso from the suggestion here https://github.com/tensorflow/tensorflow/issues/14580 I eliminated parameter `input_graph=/model/frozen_inference_graph.pb` from my command line and instead use the following\r\n\r\n`python E:\\Documents\\Projects\\tensorflow\\tensorflow\\tensorflow\\python\\tools\\freeze_graph.py --input_meta_graph=model/model.ckpt-50000.meta --input_checkpoint=\"model/model.ckpt-50000\" --input_binary=true --output_graph=\"model/frozen_mobilenet_graph.pb\" --output_node_names=\"MobilenetV2/Logits/output:0\"`\r\n\r\nnow I'm facing the issue exactly like the guy who posted this, [see his comments to the answer](https://stackoverflow.com/questions/52066621/how-to-find-the-output-node-names-for-a-specific-tensorflow-network)\r\n\r\n`AssertionError: MobilenetV2/Logits/output:0 is not in graph`", "@ramreddyy How did you find your output node, I found it very hard to find using Tensorboard so I used the script linked above in my answer?", "> @ramreddyy How did you find your output node, I found it very hard to find using Tensorboard so I used the script linked above in my answer?\r\n\r\n@zubairahmed-ai  I have checked output node name using tensorboard and we can also use below code to get the node names as a list \r\nnode_names=[n.name for n in tf.get_default_graph().as_graph_def().node]\r\n\r\nIterate over node_names and check the output name that you are providing to freeze_graph is present or not. \r\n\r\nIf you have a protobuf file then you can use summarize_graph of bazel \r\nTo use bazel tool go through below links\r\nhttps://docs.bazel.build/versions/master/install.html\r\nhttps://www.tensorflow.org/lite/tfmobile/prepare_models\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/README.md\r\n\r\nIf you are using tf.keras to build the model and gave a name to output layer as 'output' it may not be same as output but something like output/Softmax so please do check out your output node name using tensorboard or graph_def or summarize_graph ", "Thanks\r\nI will try out the script, my model is a custom trained SSD MobileNetv2 so TF.Keras won't work also I don't want to install Bazel just for doing this", "@ramreddyy \r\n\r\n>node_names=[n.name for n in tf.get_default_graph().as_graph_def().node]\r\n\r\nThis gives me a node name that is this `MobilenetV2/Predictions/Reshape_1`\r\n\r\nBut when I try this I still get a `AssertionError: MobilenetV2/Predictions/Reshape_1 is not in graph`\r\n\r\nVery confused right now ", "> \r\n> \r\n> @zubairahmed-ai\r\n> I had same problem.\r\n> I downloaded mobilenet_v2_1.4_224 from https://github.com/tensorflow/models/tree/master/research/slim/nets/mobilenet, and checked mobilenet_v2_1.4_224_info.txt.\r\n> \r\n> ```\r\n> Model: mobilenet_v2_1.4_224\r\n> Input: input\r\n> Output: MobilenetV2/Predictions/Reshape_1\r\n> ```\r\n> \r\n> However, `AssertionError: MobilenetV2/Predictions/Reshape_1 is not in graph` is occured.\r\n> Then, I inserted below code to line 219 of freeze_graph.py .\r\n> \r\n> ```\r\n> for v in sess.graph.get_operations():\r\n>     print(v.name)\r\n> ```\r\n> \r\n> Result is\r\n> \r\n> ```\r\n> \u2026\r\n> InceptionV3/Predictions/Softmax\r\n> InceptionV3/Predictions/Shape\r\n> InceptionV3/Predictions/Reshape_1\r\n> \u2026\r\n> ```\r\n> \r\n> In my case, pb file had mismatched node name to .pbtxt file and info.txt file.\r\n\r\n", "![image](https://user-images.githubusercontent.com/73299425/98220232-01b15b80-1f74-11eb-9006-24737f6d370e.png)\r\n", "Hi @ramreddyy!\r\nCould you please refer this[ link](https://www.tensorflow.org/guide/keras/custom_layers_and_models) to build your custom model in TF 2.x versions.\r\n\r\nIt also seems you are using older versions(1.x versions) of Tensorflow. We recommend that you upgrade  your code base to 2.x  versions as many features and bug fixes has been done in newer versions and let us know if the issue still persists in newer versions. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/24369\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/24369\">No</a>\n"]}, {"number": 24368, "title": "Advanced Tensorflow Neural Network visualization", "body": "I have gone through the beautiful tool given by Tensorflow. I am talking about the Playground. The tool is available at https://github.com/tensorflow/playground.\r\nEven though it an excellent tool but it doesn't help in analyzing the datasets given by the user. It takes its own 2D random numbers and let the people play with it. \r\nMy request for feature is that I want to have a similar tool but it should let the user use their datasets for analyzing the neural network offered by tensorflow.\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 1.12\r\n- Are you willing to contribute it (Yes/No): Yes ofcourse. if I get cleared with how the tool is working. I tried hard to understand but the tool has many hard coded values and is making is difficult to understand.\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\n**Will this change the current api? How?** Never.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nEveryone who is planning to create a machine learning model and want to start with Tensorflow. The newbie or even Researchers will be benefited by this tool. The visualization will give them a clear idea without any pain.\r\n\r\n**Any Other info.**\r\nThere isn't anything yet. If there is any in future I will add.", "comments": ["This issue is more suitable on tensorflow/playground repo. Please post this issue on https://github.com/tensorflow/playground/issues. Thanks!"]}, {"number": 24367, "title": "Exception ignored, Session closed", "body": "**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution: Arch Linux\r\n- TensorFlow installed from (source or binary): Official repository\r\n- TensorFlow version: v1.11.0-0-gc19e29306c 1.11.0\r\n- Python version: 3.6.6\r\n- GPU model: AMD Radeon HD 7850\r\n\r\n\r\n**Describe the current behavior (+ code)**\r\nCode: found in my second comment below.\r\nIt uses the environment `AcrobotForever-v1` which is really just a modification of the Acrobot env that never terminates. (additionally, I made it have 4 state variables: `(angle 1, angle 2, angle_vel 1, angle_vel 2)`. Code for the modified environment: https://github.com/Ploppz/gym-custom-envs\r\n\r\nMy code defines an agent acting in the Acrobot environment. It has one neural networks which it fits and uses to predict the next state.\r\n\r\nWhile training I get this error after some random amount of time:\r\n\r\n```\r\nException ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7f1ec3fcd9e8>>\r\nTraceback (most recent call last):\r\n  File \"/home/ploppz/.pyenv/versions/3.6.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1415, in __del__\r\n    self._session._session, self._handle, status)\r\n  File \"/home/ploppz/.pyenv/versions/3.6.6/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 526, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\r\nException ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7f1ec3497e10>>\r\nTraceback (most recent call last):\r\n  File \"/home/ploppz/.pyenv/versions/3.6.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1415, in __del__\r\n    self._session._session, self._handle, status)\r\n  File \"/home/ploppz/.pyenv/versions/3.6.6/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 526, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\r\nIter 5, timesteps=6000: coverage = 6.2595697434743025\r\nIter 6, timesteps=6000: coverage = 5.409617917650649\r\nException ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7f1ec3670da0>>\r\nTraceback (most recent call last):\r\n  File \"/home/ploppz/.pyenv/versions/3.6.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1415, in __del__\r\n    self._session._session, self._handle, status)\r\n  File \"/home/ploppz/.pyenv/versions/3.6.6/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 526, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\r\n```\r\n", "comments": ["We may be able to find more insight into your issue if you can figure out what the exception was. It looks like the exception is caught but the descriptions was not provided when handled (\"ignored\").", "How can I find the exception?", "@Ploppz  Could you give more details and the context to find root-cause of the issue. Could you test with a very simple models and provide the code and the error log? ", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Sorry for the delay. I have a more or less minimal example that should run if you have all the dependencies. It consists of two files:\r\n`experiment.py`:\r\n\r\n```\r\nfrom model_based import ModelBasedAgent\r\nimport gym\r\nimport numpy as np\r\nfrom types import MethodType\r\nimport random\r\nimport tensorflow as tf\r\nfrom matplotlib import pyplot as plt\r\nimport os\r\nimport datetime\r\nimport pickle\r\n\r\nsample_period = 100 # How often to look at coverage for plotting\r\ndef experiment(env, agent, timesteps, render=False):\r\n    global sample_period\r\n    ob_space_dim = env.observation_space.shape[0]\r\n    state = env.reset()\r\n    state = np.array([state])\r\n    scores =  []\r\n    for t in range(1, timesteps+1):\r\n        # Act\r\n        action, v_pred = agent.act(state)\r\n        # Step\r\n        state_next, _reward, _terminal, _info = env.step(action)\r\n        state_next = np.reshape(state_next, [1, ob_space_dim])\r\n        # Think\r\n        agent.think(state, action, state_next, v_pred)\r\n        # Render\r\n        if render:\r\n            env.render()\r\n        # Gather data\r\n        if t % sample_period == 0:\r\n            score = agent.covered_volume() * 100\r\n            scores.append(score)\r\n    return scores\r\n\r\n\r\n#  def several_experiments(env, agent, n_experiments=18, timesteps=7000, color='blue'):\r\ndef several_experiments(env, agent, n_experiments=3, timesteps=800, color='blue'):\r\n    global sample_period\r\n    scores = np.zeros((n_experiments, int(timesteps/sample_period)))\r\n    for i in range(n_experiments):\r\n        with tf.Session() as sess:\r\n            agent.reset()\r\n            sess.run(tf.global_variables_initializer())\r\n            # Scores\r\n            scores[i, :] = experiment(env, agent, timesteps)\r\n            print(\"Iter %s, timesteps=%s: coverage = %s\" % (i, timesteps, scores[i, -1]))\r\n        tf.reset_default_graph()\r\n\r\nif __name__ == '__main__':\r\n    ENV_NAME = \"AcrobotForever-v1\"\r\n    env = gym.make(ENV_NAME)\r\n\r\n    EPSILON = 0.1\r\n\r\n    agent = ModelBasedAgent(env)\r\n    agent.exploration_rate = EPSILON\r\n    several_experiments(env, agent)\r\n```\r\n\r\nand `model_based.py` which contains the agent, using tensorflow:\r\n```\r\nimport random\r\nimport gym\r\nimport acrobot_forever\r\nimport numpy as np\r\nfrom collections import deque\r\nfrom keras.models import Sequential\r\nfrom keras.layers import Dense\r\nfrom keras.optimizers import Adam\r\nfrom matplotlib import pyplot as plt\r\nfrom scipy.spatial import ConvexHull\r\nimport time\r\nimport tensorflow as tf\r\n\r\nclass ModelBasedAgent:\r\n    def __init__(self, env, act=None):\r\n        from types import MethodType\r\n        if not act is None:\r\n            self.act = MethodType(act, self)\r\n\r\n        # Custom initializer\r\n        from keras import backend as K\r\n        def network_init(shape, dtype=None):\r\n            return np.random.random(shape) * 10 - 5\r\n\r\n        self.advantage_learning = None\r\n        self.env = env\r\n        self.states = []\r\n        self.exploration_rate = 0.0\r\n        self.n_actions = env.action_space.n\r\n        self.ob_dim = env.observation_space.shape[0]\r\n\r\n        # Model network n: (s, a) -> ds\r\n        self.model_net = Sequential()\r\n        self.model_net.add(Dense(12, input_shape=(self.ob_dim + 1,), activation=\"relu\"))\r\n        self.model_net.add(Dense(12, activation=\"relu\"))\r\n        self.model_net.add(Dense(self.ob_dim, activation=\"linear\"))\r\n        self.model_net.compile(loss=\"mse\", optimizer=Adam(lr=0.001))\r\n\r\n    def reset(self):\r\n        self.__init__(self.env)\r\n\r\n    def _predict_ds(self, state, action):\r\n        sa = np.array([np.concatenate((state[0], [action]))])\r\n        return self.model_net.predict(sa, 1)[0]\r\n\r\n    def act(self, state):\r\n        if np.random.rand() < self.exploration_rate:\r\n            return random.randrange(self.n_actions), None\r\n\r\n        # Sample a desired ds (delta state)\r\n        target_dstate = np.random.normal(0.0, 1.0, self.ob_dim)\r\n        # Make predictions for each possible action\r\n        dstate = [self._predict_ds(state, a) for a in range(self.n_actions)]\r\n        # Find best action by measuring how close ds are to target_ds (angle)\r\n        def dist(ds1, ds2):\r\n            dot = np.dot(ds1, ds2) / (np.linalg.norm(ds1) * np.linalg.norm(ds2))\r\n            return 1 - dot    # from 0 (perfect match) to 2 (anti-parallel)\r\n        ds_distance = [dist(target_dstate, ds) for ds in dstate]\r\n\r\n        # Finally, return the action which results in a state change in a direction most similar to desired direction\r\n        return np.argmin(ds_distance), None\r\n\r\n\r\n    def think(self, state, action, state_next, _):\r\n        self.states.append(state_next[0])\r\n\r\n        # Train the model\r\n        sa = np.array([np.concatenate((state[0], [action]))])\r\n        self.model_net.fit(sa, state_next - state, verbose=0)\r\n\r\n    # Approximate the covered area by convex hull\r\n    def covered_volume(self):\r\n        states = np.array(self.states)\r\n        states = (states + self.env.observation_space.low)/(self.env.observation_space.high - self.env.observation_space.low)\r\n        return ConvexHull(states).volume\r\n```\r\n\r\nThe output I get when running `experiment.py`:\r\n```\r\nUsing TensorFlow backend.\r\nWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\r\n2019-02-14 17:06:11.273748: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\nIter 0, timesteps=800: coverage = 0.5695444808537892\r\nIter 1, timesteps=800: coverage = 0.8073160099913885\r\nIter 2, timesteps=800: coverage = 5.202966470958516\r\nException ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7f75287f8e10>>\r\nTraceback (most recent call last):\r\n  File \"/home/ploppz/.pyenv/versions/3.6.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1415, in __del__\r\n  File \"/home/ploppz/.pyenv/versions/3.6.6/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 526, in __exit__\r\ntensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\r\nException ignored in: <bound method BaseSession._Callable.__del__ of <tensorflow.python.client.session.BaseSession._Callable object at 0x7f75117d2e80>>\r\nTraceback (most recent call last):\r\n  File \"/home/ploppz/.pyenv/versions/3.6.6/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1415, in __del__\r\n  File \"/home/ploppz/.pyenv/versions/3.6.6/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 526, in __exit__\r\ntensorflow.python.framework.errors_impl.CancelledError: Session has been closed.\r\n```\r\n\r\nThis seems to always happen right after iteration 2.", "how to solve it ?"]}, {"number": 24366, "title": "Remove bazel installation from install_pi_toolchain.sh", "body": "1. Bazel is installed by install_bazel.sh, no need to install twice.\r\n2. Because the bazel installation in install_pi_toolchain.sh does not specify the target version of bazel, when bazel is newly released and TF is not ready to use it, It will make a error which is happend in r1.12(#24104) now.", "comments": ["@rky0930 please re base your branch", "I rebased my branch but there were some commits during the rebase. is it ok ?\r\n"]}, {"number": 24365, "title": "Tensor flow installation problem : Mac", "body": "I have Mac 10.12 Sierra, My python version is 2.7. \r\n\r\nInstallation steps are. \r\n```\r\n$source ~/tensorflow/bin/activate\r\n(tensorflow)$ pip install tensorflow\r\nRequirement already satisfied: tensorflow in /usr/local/lib/python2.7/site-packages (1.12.0)\r\nRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python2.7/site-packages (from tensorflow) (1.11.0)\r\nRequirement already satisfied: protobuf>=3.6.1 in /usr/local/Cellar/protobuf/3.6.1/libexec/lib/python2.7/site-packages (from tensorflow) (3.6.1)\r\nRequirement already satisfied: enum34>=1.1.6 in /usr/local/lib/python2.7/site-packages (from tensorflow) (1.1.6)\r\nRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python2.7/site-packages (from tensorflow) (0.2.0)\r\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python2.7/site-packages (from tensorflow) (1.0.5)\r\nRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python2.7/site-packages (from tensorflow) (0.7.1)\r\nRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python2.7/site-packages (from tensorflow) (1.17.0)\r\nRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python2.7/site-packages (from tensorflow) (1.0.6)\r\nRequirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/site-packages (from tensorflow) (2.0.0)\r\nRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python2.7/site-packages (from tensorflow) (1.15.0)\r\nRequirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /usr/local/lib/python2.7/site-packages (from tensorflow) (1.12.0)\r\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python2.7/site-packages (from tensorflow) (1.1.0)\r\nRequirement already satisfied: wheel in ./python2.7/site-packages (from tensorflow) (0.32.3)\r\nRequirement already satisfied: backports.weakref>=1.0rc1 in /usr/local/lib/python2.7/site-packages (from tensorflow) (1.0.post1)\r\nRequirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python2.7/site-packages (from tensorflow) (0.6.1)\r\nRequirement already satisfied: setuptools in ./python2.7/site-packages (from protobuf>=3.6.1->tensorflow) (40.6.3)\r\nRequirement already satisfied: futures>=2.2.0 in /usr/local/lib/python2.7/site-packages (from grpcio>=1.8.6->tensorflow) (3.2.0)\r\nRequirement already satisfied: h5py in /usr/local/lib/python2.7/site-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\r\nRequirement already satisfied: funcsigs>=1; python_version < \"3.3\" in /usr/local/lib/python2.7/site-packages (from mock>=2.0.0->tensorflow) (1.0.2)\r\nRequirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/site-packages (from mock>=2.0.0->tensorflow) (4.2.0)\r\nRequirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python2.7/site-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow) (0.14.1)\r\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python2.7/site-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow) (3.0.1)\r\n\r\n(tensorflow)$python\r\n```\r\n\r\n```\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/Cellar/python@2/2.7.15_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"/usr/local/Cellar/python@2/2.7.15_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 51, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/usr/local/Cellar/python@2/2.7.15_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 52, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"/usr/local/Cellar/python@2/2.7.15_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 41, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/usr/local/Cellar/python@2/2.7.15_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"/usr/local/Cellar/python@2/2.7.15_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\nImportError: dlopen(/usr/local/Cellar/python@2/2.7.15_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so, 10): Library not loaded: @rpath/libcublas.8.0.dylib\r\n  Referenced from: /usr/local/Cellar/python@2/2.7.15_1/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n  Reason: image not found\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n>>> \r\n```\r\n\r\n\r\nPlease help me to install it over mac.", "comments": ["I solved this problem by going to root directory where it was installed. But now the new issue is coming as.\r\n```\r\n(cv)$ python\r\nPython 3.7.1 (default, Nov 28 2018, 11:55:14) \r\n[Clang 9.0.0 (clang-900.0.39.2)] on darwin\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> x1 = tf.constant([1,2,3,4])\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nAttributeError: module 'tensorflow' has no attribute 'constant'\r\n```\r\n\r\n\r\nPlease help me to solve this", "Run `python --version` should say 3.7.1, but you may have installed tensorflow in python2.7\r\nYour pip may be associated with python2.7. on Mac OS (the python modules for each version of python are kept in separate folders called `site-packages`)\r\n\r\nOn Mac OS you can press Command + G and enter `/Library/Python` to find your python versions and then locate the `site-packages`. Here I suspect you will discover tensorflow is not installed for python3.\r\n\r\nSo to install tensorflow for python 3, you will need to use the pip version associated with python 3.\r\n\r\n`pip show tensorflow` will show which version of python the package is installed.\r\n\r\n`pip3` is the python 3 package manager... Some people associate the `pip3` command with the `pip` command. I don't like to do that because I often work without environment managers on smaller python scripts at times... so I maintain `pip3` and `pip` separate in order to support both python 2 and 3 locally. `Anaconda` is a great environment manager you should consider using. It also supports dependency bundles much like `Docker` does.\r\n\r\n`pip3 install tensorflow`\r\n\r\nYou may need to install `pip3` if you do not have it. There are multiple ways to do this.. Google around.\r\n\r\nEarly distros of python 3 did not come with `pip3`, because you are on Sierra its likely Mac OS did not come with `pip3` preinstalled... Mojave does.", "@prateektiwari7  Hi Prateek, what @cathybgyz  says is absolutely true. I can see that your system has Python 3.7 and you are using Python 2 version of pip. Please use pip3 and keep us posted. Thanks !", "Hi @cathybgyz ,\r\n\r\nThanks for sharing this to me. It is working fine now. Thanks @harshini-gadige for your support. "]}, {"number": 24363, "title": "delay compsensated gradient descent", "body": "This feature is important as discussed in [issue#8744](https://github.com/tensorflow/tensorflow/issues/8744).", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Hi @alextp any more advice?", "@cstur4 tf.contrib is currently being deprecated so I don't want to add any more code to it until the replacement addons package is ready. Please see https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md for more information.\r\n\r\nSo I'll close this :-/ sorry"]}, {"number": 24362, "title": "tf.cumsum low performance in 1.12.0", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 1803 Build 17134.407\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 1.12.0-gpu\r\n- Python version: 3.6.0\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: v9.0.176\r\n- GPU model and memory: GTX-970M, NVIDIA-SMI 385.54\r\n\r\n**Describe the current behavior**\r\nIn tensorflow-1.12.0-GPU, it takes around 0.8s for each iteration and the cumsum operation takes around 0.13s/run x 3class x 2run/class. So the cumsum operation nearly takes 0.78s for each iteration. After switching the code interpreter to python 3.6.0 with tensorflow-1.11.0-CPU, the iteration time decreases to around 0.14s and the highest time-consuming operation become the sorting operation.\r\nI notice that this issue has been reported in [https://github.com/tensorflow/tensorflow/issues/19570](url). I wonder whether this issue has been fixed in version 1.12.0? Or is there something wrong in my code caused this issue? I'm still learning how to use tensorflow recently. The lovasz_loss imported can be found in [https://github.com/bermanmaxim/LovaszSoftmax/blob/master/tensorflow/lovasz_losses_tf.py](url)\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n`\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport time\r\nimport lovasz_loss\r\nfrom tensorflow.python.client import timeline\r\n\r\nprint(tf.__version__)\r\n\r\nIMAGE_SIZE = 512\r\nIMAGE_CHANNEL = 2\r\nCLASS_NUM = 3\r\nIMAGE_NUM = 1\r\nX_train = np.random.randn(IMAGE_NUM,IMAGE_SIZE,IMAGE_SIZE,IMAGE_CHANNEL)\r\ny_train = np.random.randint(0,CLASS_NUM,size=[IMAGE_NUM,IMAGE_SIZE,IMAGE_SIZE],dtype=np.int32)\r\n\r\nX = tf.placeholder(dtype=tf.float32,shape=[None,IMAGE_SIZE,IMAGE_SIZE,IMAGE_CHANNEL],name='image_input')\r\ny = tf.placeholder(dtype=tf.int32,shape=[None,IMAGE_SIZE,IMAGE_SIZE],name='image_output')\r\n\r\nw = tf.get_variable('w',initializer=tf.truncated_normal(shape=[1,1,IMAGE_CHANNEL,CLASS_NUM],stddev=0.02))\r\ny_logits = tf.nn.conv2d(X,w,strides=[1,1,1,1],padding='SAME')\r\ny_prob = tf.nn.softmax(y_logits,axis=3)\r\n\r\nloss = lovasz_loss.lovasz_softmax(y_prob,y)\r\ntrain_op = tf.train.AdamOptimizer(0.005).minimize(loss)\r\n\r\nconfig = tf.ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\n\r\nrun_option = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\r\nrun_metadata = tf.RunMetadata()\r\n\r\nwith tf.Session(config=config) as sess:\r\n    tf.global_variables_initializer().run()\r\n    tf.local_variables_initializer().run()\r\n    for i in range(100):\r\n        st = time.time()\r\n        sess.run(train_op,feed_dict={X:X_train,y:y_train},options=run_option,run_metadata=run_metadata)\r\n        if i>5:\r\n            tl = timeline.Timeline(run_metadata.step_stats)\r\n            ctf = tl.generate_chrome_trace_format()\r\n            with open('timeline_lova.json','w') as f:\r\n                f.write(ctf)\r\n        print('Iter: {num}, duration: {sec}'.format(num=i,sec=time.time()-st))\r\n`\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/24362\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/24362\">No</a>\n", "Closing out this issue because it hasn't been updated in the last year.  Please reopen if this is still relevant."]}, {"number": 24361, "title": "Update RELEASE.md", "body": "Documentation issue", "comments": []}, {"number": 24360, "title": "Update custom_operators.md", "body": "Documentation issue", "comments": []}, {"number": 24359, "title": "ERROR: Installing Tensorflow GPU with CUDA 10.0 for python on Windows", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (Windows 10):\r\n- TensorFlow installed from (source):\r\n- TensorFlow version: 1.12\r\n- Python version:3.6\r\n- Installed using pip:\r\n- Bazel version (0.20.0):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:Cuda 10.0 cuDNN 7.3.1\r\n- GPU model and memory: GTX 1060 6GB\r\n\r\n\r\n\r\nI'm installing tensorflowgpu from source and following a guide from https://www.python36.com/how-to-install-tensorflow-gpu-with-cuda-10-0-for-python-on-windows/.\r\ni followed all instructions as far as i know, no errors are seen all through out the installation.\r\n\r\nAt step 12, i got an error log\r\n\r\nAdmin@Thesis-CCD MSYS /c/tensorflow/tensorflow\r\n$ bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --config=monolithic\r\nWARNING: The following configs were expanded more than once: [cuda, monolithic]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.\r\nWARNING: Option 'experimental_shortened_obj_file_path' is deprecated\r\nLoading:\r\nLoading: 0 packages loaded\r\nERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):\r\n        File \"C:/tensorflow/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1447\r\n                _create_local_cuda_repository(repository_ctx)\r\n        File \"C:/tensorflow/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1187, in _create_local_cuda_repository\r\n                _get_cuda_config(repository_ctx)\r\n        File \"C:/tensorflow/tensorflow/third_party/gpus/cuda_configure.bzl\", line 911, in _get_cuda_config\r\n                _cudnn_version(repository_ctx, cudnn_install_base..., ...)\r\n        File \"C:/tensorflow/tensorflow/third_party/gpus/cuda_configure.bzl\", line 614, in _cudnn_version\r\n                auto_configure_fail((\"cuDNN version detected from %s...)))\r\n        File \"C:/tensorflow/tensorflow/third_party/gpus/cuda_configure.bzl\", line 317, in auto_configure_fail\r\n                fail((\"\\n%sCuda Configuration Error:%...)))\r\n\r\nCuda Configuration Error: cuDNN version detected from C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.0/include/cudnn.h (7.3.1) does not match TF_CUDNN_VERSION (7)\r\nWARNING: Target pattern parsing failed.\r\nERROR: error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):\r\n        File \"C:/tensorflow/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1447\r\n                _create_local_cuda_repository(repository_ctx)\r\n        File \"C:/tensorflow/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1187, in _create_local_cuda_repository\r\n                _get_cuda_config(repository_ctx)\r\n        File \"C:/tensorflow/tensorflow/third_party/gpus/cuda_configure.bzl\", line 911, in _get_cuda_config\r\n                _cudnn_version(repository_ctx, cudnn_install_base..., ...)\r\n        File \"C:/tensorflow/tensorflow/third_party/gpus/cuda_configure.bzl\", line 614, in _cudnn_version\r\n                auto_configure_fail((\"cuDNN version detected from %s...)))\r\n        File \"C:/tensorflow/tensorflow/third_party/gpus/cuda_configure.bzl\", line 317, in auto_configure_fail\r\n                fail((\"\\n%sCuda Configuration Error:%...)))\r\n\r\nCuda Configuration Error: cuDNN version detected from C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v10.0/include/cudnn.h (7.3.1) does not match TF_CUDNN_VERSION (7)\r\nINFO: Elapsed time: 0.245s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\n\r\n\r\nANY HELP ABOUT THIS?", "comments": ["Me Too.\r\nWin10 cuda10+cudnn7.4+bazel0.17.2+tf1.12+python3.6.7\r\n\r\n# bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\nStarting local Bazel server and connecting to it...\r\nWARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.\r\nWARNING: Option 'experimental_shortened_obj_file_path' is deprecated\r\nLoading:\r\nLoading: 0 packages loaded\r\nLoading: 0 packages loaded\r\n    currently loading: tensorflow/tools/pip_package\r\nERROR: Skipping '//tensorflow/tools/pip_package:build_pip_package': error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):\r\n        File \"C:/tensorflow-gpu/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1447\r\n                _create_local_cuda_repository(repository_ctx)\r\n        File \"C:/tensorflow-gpu/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1303, in _create_local_cuda_repository\r\n                find_cc(repository_ctx)\r\n        File \"C:/tensorflow-gpu/tensorflow/third_party/gpus/cuda_configure.bzl\", line 217, in find_cc\r\n                _get_msvc_compiler(repository_ctx)\r\n        File \"C:/tensorflow-gpu/tensorflow/third_party/gpus/cuda_configure.bzl\", line 153, in _get_msvc_compiler\r\n                find_msvc_tool(repository_ctx, vc_path, \"cl.exe\").replace(\"\\\\\", \"/\")\r\ntype 'NoneType' has no method replace(string, string)\r\nWARNING: Target pattern parsing failed.\r\nAnalyzing: 0 targets (0 packages loaded)\r\nERROR: error loading package 'tensorflow/tools/pip_package': Encountered error while reading extension file 'cuda/build_defs.bzl': no such package '@local_config_cuda//cuda': Traceback (most recent call last):\r\n        File \"C:/tensorflow-gpu/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1447\r\n                _create_local_cuda_repository(repository_ctx)\r\n        File \"C:/tensorflow-gpu/tensorflow/third_party/gpus/cuda_configure.bzl\", line 1303, in _create_local_cuda_repository\r\n                find_cc(repository_ctx)\r\n        File \"C:/tensorflow-gpu/tensorflow/third_party/gpus/cuda_configure.bzl\", line 217, in find_cc\r\n                _get_msvc_compiler(repository_ctx)\r\n        File \"C:/tensorflow-gpu/tensorflow/third_party/gpus/cuda_configure.bzl\", line 153, in _get_msvc_compiler\r\n                find_msvc_tool(repository_ctx, vc_path, \"cl.exe\").replace(\"\\\\\", \"/\")\r\ntype 'NoneType' has no method replace(string, string)\r\nINFO: Elapsed time: 8.214s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\n\r\n\r\nwho can help me for this quession. thank you very much.", "Same problem.", "Same problem ", "same problem", "same problem", "Has everyone tried this with the latest Tensorflow version 1.13 ? Is this the same with 1.13 too ?", "First, I would suggest you to uninstall python and tensorflow completely from your systems and start a fresh installation by following these [instructions](https://github.com/jvishnuvardhan/Installing-TensorFlow-GPU-on-Windows-10-TF1.12). Please check the tested build configurations for cpu [here](https://www.tensorflow.org/install/source_windows#cpu) and for gpu [here](https://www.tensorflow.org/install/source_windows#gpu). Please note that TF1.12 was built with CUDA9.0 and Bazel 0.15.0. \r\n\r\nVersion | Python version | Compiler | Build tools | cuDNN | CUDA\r\n-- | -- | -- | -- | -- | --\r\ntensorflow_gpu-1.12.0 | 3.5-3.6 | MSVC 2015 update 3 | Bazel 0.15.0 | 7 | 9\r\n\r\nIf you want to install TF1.13.1, then you can use CUDA10 (not CUDA 10.1) and Bazel 0.21.0. Please let me know how it progresses. Thanks!", "I think it was resolved. I am closing the issue. Please open a new ticket if the bug persists with latest TF version. Thanks!", "@jvishnuvardhan I'm still having this issue. Cuda 10.0, trying to build tensorflow 2 on windows 10. The only reason I'm doing this is to hopefully alleviate severe windows performance issues that are not a problem in a linux environment. \r\n\r\nedit: so if you're here, this sucks, but hopefully this will help you:\r\n\r\nYou need to set BAZEL_VC and BAZEL_VS (https://docs.bazel.build/versions/0.21.0/install-compile-source.html#bootstrap-windows-bootstrap). From the TensorFlow instructions, you need the redis and build tools https://www.tensorflow.org/install/source_windows (ctrl+f: redis)\r\n\r\nSo you go get those. Now theoretically you can build from powershell and set these in the system, but this msys thing is like native gnu utils or something. I think it's gnu compiled against windows. I was able to build in this msys environment, ymmv. Too I should add, I had vs proper installed at some point so some of this might be residual. \r\n\r\n```\r\nvim ~/.bashrc\r\n#add these lines. Like I said you could probably do this in windows env if you're more comfortable\r\n#shift+ins to paste in the msys thing\r\nexport BAZEL_VS=\"C:\\Program Files (x86)\\Microsoft Visual C++ Build Tools\"\r\nexport BAZEL_VC=\"C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\"\r\n#write quit outta vim\r\n:wq!\r\nsource ~/.bashrc\r\n#Then this is what I did, review your build accordingly (mine is still building right now, but I got past initial errors)\r\n bazel build --config=opt --config=cuda --config=mkl --config=v2 //tensorflow/tools/pip_package:build_pip_package\r\n```\r\nYou might need to set python etc as well. Most of your issues are probably path issues."]}, {"number": 24358, "title": "TFLite bazel compile error, std::round vs round", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04.5 LTS Server\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): this repo\r\n- TensorFlow version: this repo, last commit is on Dec 11 17:41:45\r\n- Python version: 2.7.12\r\n- Installed using virtualenv? pip? conda?: no \r\n- Bazel version (if compiling from source): 0.20.0\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: no\r\n- GPU model and memory: no\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nfollowed this doc [demo_android.md](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/demo_android.md#build-the-source-code), when run `bazel build //tensorflow/lite/java/demo/app/src/main:TfLiteCameraDemo --cxxopt=--std=c++11 --verbose_failures`, I got an error says\r\n```\r\nno member named 'round' in namespace 'std'; did you mean simply 'round'?\r\n  return std::round(x);\r\n         ^~~~~~~~~~\r\n         round\r\n```\r\n\r\nafter Google searched, I think it's a c++11 problem and don't know why `--std=c++11` doesn't work. Some says should use `c++_static` instead of `gnustl_static` and I don't know how to config this in bazel\r\n\r\n\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n```\r\nERROR: /home/ubuntu/deeplearning/tensorflow/tensorflow/lite/kernels/BUILD:158:1: C++ compilation of rule '//tensorflow/lite/kernels:builtin_op_kernels' failed (Exit 1): clang failed: error executing command \r\n  (cd /home/ubuntu/.cache/bazel/_bazel_ubuntu/98810ecd1430da6ed1ea4de676f87bcd/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    ANDROID_BUILD_TOOLS_VERSION=28.0.3 \\\r\n    ANDROID_NDK_API_LEVEL=16 \\\r\n    ANDROID_NDK_HOME=/home/ubuntu/Android/Sdk/ndk-bundle \\\r\n    ANDROID_SDK_API_LEVEL=28 \\\r\n    ANDROID_SDK_HOME=/home/ubuntu/Android/Sdk \\\r\n    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/home/ubuntu/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/usr/bin/python \\\r\n    PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \\\r\n    TF_DOWNLOAD_CLANG=0 \\\r\n    TF_NEED_CUDA=0 \\\r\n    TF_NEED_OPENCL_SYCL=0 \\\r\n    TF_NEED_ROCM=0 \\\r\n  external/androidndk/ndk/toolchains/llvm/prebuilt/linux-x86_64/bin/clang '-D__ANDROID_API__=16' -isystemexternal/androidndk/ndk/sysroot/usr/include/arm-linux-androideabi -gcc-toolchain external/androidndk/ndk/toolchains/arm-linux-androideabi-4.9/prebuilt/linux-x86_64 -fpic -ffunction-sections -funwind-tables -fstack-protector-strong -Wno-invalid-command-line-argument -Wno-unused-command-line-argument -no-canonical-prefixes -fno-integrated-as -target armv7-none-linux-androideabi '-march=armv7-a' '-mfloat-abi=softfp' '-mfpu=vfpv3-d16' -mthumb -Os -g -DNDEBUG -MD -MF bazel-out/android-armeabi-v7a-opt/bin/tensorflow/lite/kernels/_objs/builtin_op_kernels/conv.d '-frandom-seed=bazel-out/android-armeabi-v7a-opt/bin/tensorflow/lite/kernels/_objs/builtin_op_kernels/conv.o' -DEIGEN_MPL2_ONLY '-DEIGEN_MAX_ALIGN_BYTES=64' '-DEIGEN_HAS_TYPE_TRAITS=0' -iquote . -iquote bazel-out/android-armeabi-v7a-opt/genfiles -iquote bazel-out/android-armeabi-v7a-opt/bin -iquote external/bazel_tools -iquote bazel-out/android-armeabi-v7a-opt/genfiles/external/bazel_tools -iquote bazel-out/android-armeabi-v7a-opt/bin/external/bazel_tools -iquote external/com_google_absl -iquote bazel-out/android-armeabi-v7a-opt/genfiles/external/com_google_absl -iquote bazel-out/android-armeabi-v7a-opt/bin/external/com_google_absl -iquote external/gemmlowp -iquote bazel-out/android-armeabi-v7a-opt/genfiles/external/gemmlowp -iquote bazel-out/android-armeabi-v7a-opt/bin/external/gemmlowp -iquote external/arm_neon_2_x86_sse -iquote bazel-out/android-armeabi-v7a-opt/genfiles/external/arm_neon_2_x86_sse -iquote bazel-out/android-armeabi-v7a-opt/bin/external/arm_neon_2_x86_sse -iquote external/androidndk -iquote bazel-out/android-armeabi-v7a-opt/genfiles/external/androidndk -iquote bazel-out/android-armeabi-v7a-opt/bin/external/androidndk -iquote external/eigen_archive -iquote bazel-out/android-armeabi-v7a-opt/genfiles/external/eigen_archive -iquote bazel-out/android-armeabi-v7a-opt/bin/external/eigen_archive -iquote external/local_config_sycl -iquote bazel-out/android-armeabi-v7a-opt/genfiles/external/local_config_sycl -iquote bazel-out/android-armeabi-v7a-opt/bin/external/local_config_sycl -iquote external/flatbuffers -iquote bazel-out/android-armeabi-v7a-opt/genfiles/external/flatbuffers -iquote bazel-out/android-armeabi-v7a-opt/bin/external/flatbuffers -iquote external/fft2d -iquote bazel-out/android-armeabi-v7a-opt/genfiles/external/fft2d -iquote bazel-out/android-armeabi-v7a-opt/bin/external/fft2d -iquote external/farmhash_archive -iquote bazel-out/android-armeabi-v7a-opt/genfiles/external/farmhash_archive -iquote bazel-out/android-armeabi-v7a-opt/bin/external/farmhash_archive -isystem external/eigen_archive -isystem bazel-out/android-armeabi-v7a-opt/genfiles/external/eigen_archive -isystem bazel-out/android-armeabi-v7a-opt/bin/external/eigen_archive -isystem tensorflow/lite/schema -isystem bazel-out/android-armeabi-v7a-opt/genfiles/tensorflow/lite/schema -isystem bazel-out/android-armeabi-v7a-opt/bin/tensorflow/lite/schema -isystem external/flatbuffers/include -isystem bazel-out/android-armeabi-v7a-opt/genfiles/external/flatbuffers/include -isystem bazel-out/android-armeabi-v7a-opt/bin/external/flatbuffers/include -isystem external/farmhash_archive/src -isystem bazel-out/android-armeabi-v7a-opt/genfiles/external/farmhash_archive/src -isystem bazel-out/android-armeabi-v7a-opt/bin/external/farmhash_archive/src '--std=c++11' -DFARMHASH_NO_CXX_STRING '-mfpu=neon' '-mfloat-abi=softfp' '-std=c++11' -O3 -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -fno-rtti -DGOOGLE_PROTOBUF_NO_RTTI -DGOOGLE_PROTOBUF_NO_STATIC_INITIALIZER '-Wno-error=reorder' '--sysroot=external/androidndk/ndk/platforms/android-16/arch-arm' -isystem external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/include -isystem external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/libs/armeabi-v7a/include -isystem external/androidndk/ndk/sources/cxx-stl/gnu-libstdc++/4.9/include/backward -isystemexternal/androidndk/ndk/sysroot/usr/include -c tensorflow/lite/kernels/conv.cc -o bazel-out/android-armeabi-v7a-opt/bin/tensorflow/lite/kernels/_objs/builtin_op_kernels/conv.o)\r\nExecution platform: @bazel_tools//platforms:host_platform\r\nIn file included from tensorflow/lite/kernels/conv.cc:23:\r\n./tensorflow/lite/c/builtin_op_data.h:154:9: warning: empty struct has size 0 in C, size 1 in C++ [-Wextern-c-compat]\r\ntypedef struct {\r\n        ^\r\n./tensorflow/lite/c/builtin_op_data.h:157:9: warning: empty struct has size 0 in C, size 1 in C++ [-Wextern-c-compat]\r\ntypedef struct {\r\n        ^\r\n./tensorflow/lite/c/builtin_op_data.h:227:9: warning: empty struct has size 0 in C, size 1 in C++ [-Wextern-c-compat]\r\ntypedef struct {\r\n        ^\r\n./tensorflow/lite/c/builtin_op_data.h:230:9: warning: empty struct has size 0 in C, size 1 in C++ [-Wextern-c-compat]\r\ntypedef struct {\r\n        ^\r\n./tensorflow/lite/c/builtin_op_data.h:269:9: warning: empty struct has size 0 in C, size 1 in C++ [-Wextern-c-compat]\r\ntypedef struct {\r\n        ^\r\nIn file included from tensorflow/lite/kernels/conv.cc:27:\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/multithreaded_conv.h:32:\r\nIn file included from ./tensorflow/lite/kernels/internal/optimized/optimized_ops.h:37:\r\nIn file included from ./tensorflow/lite/kernels/internal/quantization_util.h:23:\r\n./tensorflow/lite/kernels/internal/round.h:33:10: error: no member named 'round' in namespace 'std'; did you mean simply 'round'?\r\n  return std::round(x);\r\n         ^~~~~~~~~~\r\n         round\r\nexternal/androidndk/ndk/sysroot/usr/include/math.h:255:8: note: 'round' declared here\r\ndouble round(double __x);\r\n       ^\r\nIn file included from tensorflow/lite/kernels/conv.cc:26:\r\nIn file included from ./tensorflow/lite/kernels/gemm_support.h:18:\r\nIn file included from external/gemmlowp/public/gemmlowp.h:19:\r\nIn file included from external/gemmlowp/public/../internal/dispatch_gemm_shape.h:23:\r\nIn file included from external/gemmlowp/public/../internal/multi_thread_gemm.h:24:\r\nIn file included from external/gemmlowp/public/../internal/single_thread_gemm.h:26:\r\nIn file included from external/gemmlowp/public/../internal/compute.h:24:\r\nIn file included from external/gemmlowp/public/../internal/pack.h:430:\r\nexternal/gemmlowp/public/../internal/pack_neon.h:303:46: warning: array index 1 is past the end of the array (which contains 1 element) [-Warray-bounds]\r\n      int16x8_t sums8 = vpaddq_s16(sums4[0], sums4[1]);\r\n                                             ^     ~\r\nexternal/gemmlowp/public/../internal/pack.h:369:13: note: in instantiation of member function 'gemmlowp::PackingRegisterBlock<gemmlowp::SideMap<const unsigned char, gemmlowp::SideMapOrder::WidthMajor>, gemmlowp::PackedSideBlock<gemmlowp::KernelSideFormatInt8<gemmlowp::CellFormat<2, 16, gemmlowp::CellOrder::WidthMajor>, 1> > >::Pack' requested here\r\n          b.Pack(packed_side_block_, start_width);\r\n            ^\r\nexternal/gemmlowp/public/../internal/pack.h:339:7: note: in instantiation of member function 'gemmlowp::PackSideBlockImpl<gemmlowp::SideMap<const unsigned char, gemmlowp::SideMapOrder::WidthMajor>, gemmlowp::PackedSideBlock<gemmlowp::KernelSideFormatInt8<gemmlowp::CellFormat<2, 16, gemmlowp::CellOrder::WidthMajor>, 1> > >::PackRun' requested here\r\n      PackRun(start_width + w, ws, start_depth, depth);\r\n      ^\r\nexternal/gemmlowp/public/../internal/pack.h:328:9: note: in instantiation of member function 'gemmlowp::PackSideBlockImpl<gemmlowp::SideMap<const unsigned char, gemmlowp::SideMapOrder::WidthMajor>, gemmlowp::PackedSideBlock<gemmlowp::KernelSideFormatInt8<gemmlowp::CellFormat<2, 16, gemmlowp::CellOrder::WidthMajor>, 1> > >::PackL1' requested here\r\n        PackL1(w, ws, d, ds);\r\n        ^\r\nexternal/gemmlowp/public/../internal/pack.h:424:8: note: in instantiation of member function 'gemmlowp::PackSideBlockImpl<gemmlowp::SideMap<const unsigned char, gemmlowp::SideMapOrder::WidthMajor>, gemmlowp::PackedSideBlock<gemmlowp::KernelSideFormatInt8<gemmlowp::CellFormat<2, 16, gemmlowp::CellOrder::WidthMajor>, 1> > >::PackL2' requested here\r\n  impl.PackL2();\r\n       ^\r\nexternal/gemmlowp/public/../internal/multi_thread_gemm.h:661:5: note: in instantiation of function template specialization 'gemmlowp::PackRhs<gemmlowp::PackedSideBlock<gemmlowp::KernelSideFormatInt8<gemmlowp::CellFormat<2, 16, gemmlowp::CellOrder::WidthMajor>, 1> >, gemmlowp::MatrixMap<const unsigned char, gemmlowp::MapOrder::ColMajor> >' requested here\r\n    PackRhs(&packed_rhs, rhs.block(0, c, depth, cs));\r\n    ^\r\nexternal/gemmlowp/public/../internal/dispatch_gemm_shape.h:182:3: note: in instantiation of function template specialization 'gemmlowp::MultiThreadGemm<gemmlowp::KernelFormat<gemmlowp::KernelSideFormatInt8<gemmlowp::CellFormat<4, 16, gemmlowp::CellOrder::WidthMajor>, 1>, gemmlowp::KernelSideFormatInt8<gemmlowp::CellFormat<2, 16, gemmlowp::CellOrder::WidthMajor>, 1> >, unsigned char, unsigned char, gemmlowp::BitDepthParams<gemmlowp::OperandRange<1, 255>, gemmlowp::OperandRange<0, 255> >, gemmlowp::MapOrder::RowMajor, gemmlowp::MapOrder::ColMajor, gemmlowp::MapOrder::RowMajor, gemmlowp::VectorDup<const int, gemmlowp::VectorShape::Row>, gemmlowp::VectorDup<const int, gemmlowp::VectorShape::Col>, std::tuple<gemmlowp::OutputStageBiasAddition<gemmlowp::VectorMap<const int, gemmlowp::VectorShape::Row> >, gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent, gemmlowp::OutputStageClamp, gemmlowp::OutputStageSaturatingCastToUint8>, gemmlowp::GemmContext>' requested here\r\n  MultiThreadGemm<typename Kernel::Format, InputScalar, OutputScalar,\r\n  ^\r\nexternal/gemmlowp/public/../internal/dispatch_gemm_shape.h:175:12: note: in instantiation of function template specialization 'gemmlowp::DispatchGemmShape<unsigned char, unsigned char, gemmlowp::BitDepthParams<gemmlowp::OperandRange<1, 255>, gemmlowp::OperandRange<0, 255> >, gemmlowp::MapOrder::RowMajor, gemmlowp::MapOrder::ColMajor, gemmlowp::MapOrder::RowMajor, gemmlowp::VectorDup<const int, gemmlowp::VectorShape::Row>, gemmlowp::VectorDup<const int, gemmlowp::VectorShape::Col>, std::tuple<gemmlowp::OutputStageBiasAddition<gemmlowp::VectorMap<const int, gemmlowp::VectorShape::Row> >, gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent, gemmlowp::OutputStageClamp, gemmlowp::OutputStageSaturatingCastToUint8>, gemmlowp::GemmContext>' requested here\r\n    return DispatchGemmShape<InputScalar, OutputScalar, BitDepthParams>(\r\n           ^\r\nexternal/gemmlowp/public/gemmlowp.h:63:3: note: in instantiation of function template specialization 'gemmlowp::DispatchGemmShape<unsigned char, unsigned char, gemmlowp::BitDepthParams<gemmlowp::OperandRange<1, 255>, gemmlowp::OperandRange<0, 255> >, gemmlowp::MapOrder::RowMajor, gemmlowp::MapOrder::ColMajor, gemmlowp::MapOrder::ColMajor, gemmlowp::VectorDup<const int, gemmlowp::VectorShape::Col>, gemmlowp::VectorDup<const int, gemmlowp::VectorShape::Row>, std::tuple<gemmlowp::OutputStageBiasAddition<gemmlowp::VectorMap<const int, gemmlowp::VectorShape::Col> >, gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent, gemmlowp::OutputStageClamp, gemmlowp::OutputStageSaturatingCastToUint8>, gemmlowp::GemmContext>' requested here\r\n  DispatchGemmShape<InputScalar, OutputScalar, BitDepthParams>(\r\n  ^\r\n./tensorflow/lite/kernels/internal/optimized/optimized_ops.h:1082:13: note: in instantiation of function template specialization 'gemmlowp::GemmWithOutputPipeline<unsigned char, unsigned char, gemmlowp::BitDepthParams<gemmlowp::OperandRange<1, 255>, gemmlowp::OperandRange<0, 255> >, gemmlowp::MapOrder::RowMajor, gemmlowp::MapOrder::ColMajor, gemmlowp::MapOrder::ColMajor, std::tuple<gemmlowp::OutputStageBiasAddition<gemmlowp::VectorMap<const int, gemmlowp::VectorShape::Col> >, gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent, gemmlowp::OutputStageClamp, gemmlowp::OutputStageSaturatingCastToUint8>, gemmlowp::GemmContext>' requested here\r\n  gemmlowp::GemmWithOutputPipeline<uint8, uint8,\r\n            ^\r\nexternal/gemmlowp/public/../internal/pack_neon.h:297:5: note: array 'sums4' declared here\r\n    int16x8_t sums4[Width / 2];\r\n    ^\r\n6 warnings and 1 error generated.\r\n```", "comments": ["@lance6716 congrats, you hit a bug (of bazel or NDK r16?). Assuming you don't need x86 binaries and you have ARMv8 target devices, which is true mostly. Try, \r\n```\r\nbazel build --config android_arm64 //tensorflow/lite/java/demo/app/src/main:TfLiteCameraDemo --cxxopt=--std=c++11\r\n```\r\nOr, use NDK r17 instead of r16.", "> @lance6716 congrats, you hit a bug (of bazel or NDK r16?). Assuming you don't need x86 binaries and you have ARMv8 target devices, which is true mostly. Try,\r\n> \r\n> ```\r\n> bazel build --config android_arm64 //tensorflow/lite/java/demo/app/src/main:TfLiteCameraDemo --cxxopt=--std=c++11\r\n> ```\r\n> Or, use NDK r17 instead of r16.\r\n\r\nthanks, update NDK to 18 fix this. ", "Are you satisfied with the resolution of your issue?<br> [Yes](https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=24358)<br> [No](https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=24358)\r\n"]}, {"number": 24357, "title": "crash when run distributed training while using s3 tensorflow", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): I wrote a custom estimator\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):  Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): tensorflow/tensorflow:1.11.0-gpu-py3 docker image\r\n- TensorFlow version (use command below): tensorflow:1.11.0\r\n- Python version: Python 3.5.2\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: cuda:9.0\r\n- GPU model and memory: K80 (AWS EC2 P2.8xlarge instance)\r\n\r\nI am using [s3 tensorflow](https://www.tensorflow.org/deploy/s3) for reading the data and writing models-checkpoints/logs \r\n\r\n**Other info / logs**\r\n```\r\n2018-12-14 01:07:09.544639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10755 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:0f.0, compute capability: 3.7)\r\n2018-12-14 01:07:09.544952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10755 MB memory) -> physical GPU (device: 1, name: Tesla K80, pci bus id: 0000:00:10.0, compute capability: 3.7)\r\n2018-12-14 01:07:09.545164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10755 MB memory) -> physical GPU (device: 2, name: Tesla K80, pci bus id: 0000:00:11.0, compute capability: 3.7)\r\n2018-12-14 01:07:09.545382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 10755 MB memory) -> physical GPU (device: 3, name: Tesla K80, pci bus id: 0000:00:12.0, compute capability: 3.7)\r\n2018-12-14 01:07:09.545589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:4 with 10755 MB memory) -> physical GPU (device: 4, name: Tesla K80, pci bus id: 0000:00:13.0, compute capability: 3.7)\r\n2018-12-14 01:07:09.545833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:5 with 10755 MB memory) -> physical GPU (device: 5, name: Tesla K80, pci bus id: 0000:00:14.0, compute capability: 3.7)\r\n2018-12-14 01:07:09.546042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:6 with 10755 MB memory) -> physical GPU (device: 6, name: Tesla K80, pci bus id: 0000:00:15.0, compute capability: 3.7)\r\n2018-12-14 01:07:09.546242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:7 with 10755 MB memory) -> physical GPU (device: 7, name: Tesla K80, pci bus id: 0000:00:16.0, compute capability: 3.7)\r\n2018-12-14 01:07:09.546421: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:8 with 10755 MB memory) -> physical GPU (device: 8, name: Tesla K80, pci bus id: 0000:00:17.0, compute capability: 3.7)\r\n2018-12-14 01:07:09.546635: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:9 with 10755 MB memory) -> physical GPU (device: 9, name: Tesla K80, pci bus id: 0000:00:18.0, compute capability: 3.7)\r\n2018-12-14 01:07:09.546835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:10 with 10755 MB memory) -> physical GPU (device: 10, name: Tesla K80, pci bus id: 0000:00:19.0, compute capability: 3.7)\r\n2018-12-14 01:07:09.547045: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:11 with 10755 MB memory) -> physical GPU (device: 11, name: Tesla K80, pci bus id: 0000:00:1a.0, compute capability: 3.7)\r\n2018-12-14 01:07:09.547274: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:12 with 10755 MB memory) -> physical GPU (device: 12, name: Tesla K80, pci bus id: 0000:00:1b.0, compute capability: 3.7)\r\n2018-12-14 01:07:09.547484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:13 with 10755 MB memory) -> physical GPU (device: 13, name: Tesla K80, pci bus id: 0000:00:1c.0, compute capability: 3.7)\r\n2018-12-14 01:07:09.547688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:14 with 10755 MB memory) -> physical GPU (device: 14, name: Tesla K80, pci bus id: 0000:00:1d.0, compute capability: 3.7)\r\n2018-12-14 01:07:09.547886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:15 with 10755 MB memory) -> physical GPU (device: 15, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)\r\n2018-12-14 01:07:09.551770: I tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.\r\n2018-12-14 01:07:09.627089: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\r\n2018-12-14 01:07:09.627194: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\r\n2018-12-14 01:07:09.627373: I tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.\r\n2018-12-14 01:10:25.265510: I tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.\r\n2018-12-14 01:10:25.330682: E tensorflow/core/platform/s3/aws_logging.cc:60] No response body. Response code: 404\r\n2018-12-14 01:10:25.330719: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\r\n2018-12-14 01:10:25.330857: I tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.\r\n2018-12-14 01:12:58.847158: I tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.\r\n2018-12-14 01:13:06.793996: I tensorflow/core/platform/s3/aws_logging.cc:54] Deleting file: /tmp/s3_filesystem_XXXXXX20181214T0112571544749977988\r\n2018-12-14 01:13:06.861344: I tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.\r\n2018-12-14 01:13:06.883504: I tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.\r\n2018-12-14 01:13:09.892293: E tensorflow/core/platform/s3/aws_logging.cc:60] Curl returned error code 28\r\n2018-12-14 01:13:09.892400: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\r\n2018-12-14 01:13:09.892433: W tensorflow/core/platform/s3/aws_logging.cc:57] Request failed, now waiting 0 ms before attempting again.\r\n2018-12-14 01:13:09.892867: I tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.\r\n2018-12-14 01:13:13.899888: E tensorflow/core/platform/s3/aws_logging.cc:60] Curl returned error code 28\r\n2018-12-14 01:13:13.899977: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\r\n2018-12-14 01:13:13.899996: W tensorflow/core/platform/s3/aws_logging.cc:57] Request failed, now waiting 50 ms before attempting again.\r\n2018-12-14 01:13:13.950970: I tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.\r\n2018-12-14 01:13:17.957128: E tensorflow/core/platform/s3/aws_logging.cc:60] Curl returned error code 28\r\n2018-12-14 01:13:17.957192: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\r\n2018-12-14 01:13:17.957212: W tensorflow/core/platform/s3/aws_logging.cc:57] Request failed, now waiting 100 ms before attempting again.\r\n2018-12-14 01:13:18.058715: I tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.\r\n2018-12-14 01:13:22.065071: E tensorflow/core/platform/s3/aws_logging.cc:60] Curl returned error code 28\r\n2018-12-14 01:13:22.065155: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\r\n2018-12-14 01:13:22.065181: W tensorflow/core/platform/s3/aws_logging.cc:57] Request failed, now waiting 200 ms before attempting again.\r\n2018-12-14 01:13:22.266342: I tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.\r\n2018-12-14 01:13:26.273044: E tensorflow/core/platform/s3/aws_logging.cc:60] Curl returned error code 28\r\n2018-12-14 01:13:26.273111: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\r\n2018-12-14 01:13:26.273143: W tensorflow/core/platform/s3/aws_logging.cc:57] Request failed, now waiting 400 ms before attempting again.\r\n2018-12-14 01:13:26.674870: I tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.\r\n2018-12-14 01:13:30.681963: E tensorflow/core/platform/s3/aws_logging.cc:60] Curl returned error code 28\r\n2018-12-14 01:13:30.682039: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\r\n2018-12-14 01:13:30.682059: W tensorflow/core/platform/s3/aws_logging.cc:57] Request failed, now waiting 800 ms before attempting again.\r\n2018-12-14 01:13:31.483287: I tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.\r\n2018-12-14 01:13:35.489697: E tensorflow/core/platform/s3/aws_logging.cc:60] Curl returned error code 28\r\n2018-12-14 01:13:35.489748: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\r\n2018-12-14 01:13:35.489766: W tensorflow/core/platform/s3/aws_logging.cc:57] Request failed, now waiting 1600 ms before attempting again.\r\n2018-12-14 01:13:37.090948: I tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.\r\n2018-12-14 01:13:41.097136: E tensorflow/core/platform/s3/aws_logging.cc:60] Curl returned error code 28\r\n2018-12-14 01:13:41.097251: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\r\n2018-12-14 01:13:41.097272: W tensorflow/core/platform/s3/aws_logging.cc:57] Request failed, now waiting 3200 ms before attempting again.\r\n2018-12-14 01:13:44.299654: I tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.\r\n2018-12-14 01:13:48.307090: E tensorflow/core/platform/s3/aws_logging.cc:60] Curl returned error code 28\r\n2018-12-14 01:13:48.307182: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\r\n2018-12-14 01:13:48.307208: W tensorflow/core/platform/s3/aws_logging.cc:57] Request failed, now waiting 6400 ms before attempting again.\r\n2018-12-14 01:13:54.709486: I tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.\r\n2018-12-14 01:13:58.715801: E tensorflow/core/platform/s3/aws_logging.cc:60] Curl returned error code 28\r\n2018-12-14 01:13:58.715869: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\r\n2018-12-14 01:13:58.715895: W tensorflow/core/platform/s3/aws_logging.cc:57] Request failed, now waiting 12800 ms before attempting again.\r\n2018-12-14 01:14:11.518412: I tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.\r\n2018-12-14 01:14:15.525502: E tensorflow/core/platform/s3/aws_logging.cc:60] Curl returned error code 28\r\n2018-12-14 01:14:15.525595: W tensorflow/core/platform/s3/aws_logging.cc:57] If the signature check failed. This could be because of a time skew. Attempting to adjust the signer.\r\n2018-12-14 01:14:15.526863: I tensorflow/core/platform/s3/aws_logging.cc:54] Connection has been released. Continuing.\r\nTraceback (most recent call last):\r\nFile \"train.py\", line 191, in <module>\r\ntf.app.run()\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n_sys.exit(main(argv))\r\nFile \"train.py\", line 182, in main\r\ncyclegan_estimator.train(train_input_fn, steps=FLAGS.steps_per_eval)\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\", line 356, in train\r\nloss = self._train_model(input_fn, hooks, saving_listeners)\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\", line 1179, in _train_model\r\nreturn self._train_model_distributed(input_fn, hooks, saving_listeners)\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\", line 1326, in _train_model_distributed\r\nsaving_listeners)\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/estimator/estimator.py\", line 1406, in _train_with_estimator_spec\r\nlog_step_count_steps=self._config.log_step_count_steps) as mon_sess:\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 504, in MonitoredTrainingSession\r\nstop_grace_period_secs=stop_grace_period_secs)\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 921, in __init__\r\nstop_grace_period_secs=stop_grace_period_secs)\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 643, in __init__\r\nself._sess = _RecoverableSession(self._coordinated_creator)\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1107, in __init__\r\n_WrappedSession.__init__(self, self._create_session())\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 1112, in _create_session\r\nreturn self._sess_creator.create_session()\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/monitored_session.py\", line 807, in create_session\r\nhook.after_create_session(self.tf_sess, self.coord)\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/training/basic_session_run_hooks.py\", line 558, in after_create_session\r\n\"graph.pbtxt\")\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/graph_io.py\", line 71, in write_graph\r\ntext_format.MessageToString(graph_def))\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/lib/io/file_io.py\", line 436, in atomic_write_string_to_file\r\nrename(temp_pathname, filename, overwrite)\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/lib/io/file_io.py\", line 415, in rename\r\ncompat.as_bytes(oldname), compat.as_bytes(newname), overwrite, status)\r\nFile \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/errors_impl.py\", line 526, in __exit__\r\nc_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.UnknownError: : Unable to connect to endpoint\r\n```", "comments": ["Usually the first error you get is the one thats causing the problem. In this case it's `No response body. Response code: 404`. My guess is curl is not requesting correctly (posting vs putting?), not accepting certificates required for https or you may have not properly configured the connection to AWS / `CURLOPT_HEADER` is setup wrong... So your request header may not contain the proper api key or auth credentials AWS is looking for..\r\n\r\nYou will need to research the proper setup on AWS services / API Gateways etc .. Also authentication can be tricky and in your case may require environment variables with secret keys or SSH key handling.. \r\n\r\n`error code 28` is telling you curl is trying again but this time the response is timing out on you. perhaps because AWS is blocking you by starving your connections with no response due to constant 404 you've been generating.. This is a good way to prevent DDOS I guess.\r\n\r\nHope there is enough clues in here for you to research your unique solution", "@cathybgyz  I am running this on AWS Batch and I am sure that credentials are properly setup. But you raised some good points, I am going to talk to AWS support and see why this is happening. Thanks for the insights.", "@mmuppidi , I want to ask whether you solve this problem.", "@yw411 we had to increase the s3 request timeout to get this to work.\r\n\r\n```\r\nexport S3_REQUEST_TIMEOUT_MSEC=60000\r\n```\r\nRef: https://github.com/tensorflow/tensorflow/issues/15868", "@mmuppidi ,\r\nCan you please confirm if we can close this issue, as it worked for you.", "have the same error  but does not solve "]}, {"number": 24356, "title": "Python API Data Document fixes", "body": "The PR is to fix some minor typos in Python API Data.", "comments": []}, {"number": 24355, "title": "Add cuDNN deterministic env variable (only for convolution)", "body": "This change is a major component of the recipe for making TensorFlow training reproducible on GPUs.\r\n\r\nSetting the environment variable TF_CUDNN_DETERMINISTIC=1 (or true) will ensure that both forward and backwards convolution algorithms are both fixed and deterministic. It overrides autotune and selects deterministic back-prop algorithms.\r\n\r\nAttention @azaks2\r\n\r\nNote: This pull request was [previous issued incorrectly](https://github.com/tensorflow/tensorflow/pull/24301) based on r1.12.", "comments": ["There are some other refinements that I may want to make to this request before it gets pulled. I am going to close it for now, and I may re-open it later.", "Because I force-pushed the branch that this pull request is based on, while it was closed, it's not possible to re-open the pull request. I will have to create a new pull request.", "See follow-up [pull request #24747](https://github.com/tensorflow/tensorflow/pull/24747)."]}, {"number": 24354, "title": "Fixed typo in comment about docker build argument.", "body": "", "comments": []}]