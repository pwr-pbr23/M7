[{"number": 10225, "title": "Announce upgrade to cuDNN 6.0.", "body": "", "comments": []}, {"number": 10224, "title": "I can't run tensorflow at an atom.", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttp://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n-----------\r\nI'm using window 10 and ANAconda.\r\nI downloaded it using prompt.\r\nI can use it at the cmd, however, I can't using it at the atom.\r\nI also can't code complex program like linear regression.\r\nI only can code easy thing hello tensorflow using prompt.\r\nHow can I solve this problem?\r\nPlease help me.\r\nI uninstalled it and reinstalled it, however, it doesn't work.\r\n\r\n\r\nimport tensorflow as tf\r\nhello = tf.constant('Hello,Tensorflow!')\r\nsess = tf.Session()\r\nprint(sess.run(hello))\r\n\r\n\r\n\r\n\r\nPython - test.py:2\r\nTraceback (most recent call last):\r\n  File \"F:\\Python\\test.py\", line 1, in <module>\r\n    import tensorflow as tf\r\nModuleNotFoundError: No module named 'tensorflow'\r\n[Finished in 0.126s]\r\nhellotf.py5:1(4, 112)\r\nCRLFUTF-8Python\r\n", "comments": ["This still seems to be an issue with installation.\r\nAre you sure you followed our installation guide here:\r\nhttps://www.tensorflow.org/install/install_windows"]}, {"number": 10223, "title": "fix misspell", "body": "fix misspell", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "CLAs look good, thanks!\n\n<!-- ok -->", "I signed it!\r\n", "Jenkins test this please."]}, {"number": 10222, "title": "tf.nn.moments with tf.concat numerical ambiguity", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: custom code, see below\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04 LTE\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: ('v1.1.0-rc0-61-g1ec6ed5', '1.1.0')\r\n- **Bazel version (if compiling from source)**: n/a\r\n- **CUDA/cuDNN version**: CUDA: 8.0 / cuDNN: 5.1\r\n- **GPU model and memory**: GTX960m 4GB and GTX1080 8GB\r\n- **Exact command to reproduce**: run the code below\r\n\r\n### Describe the problem\r\n**tf.nn.moments** GPU version produces different mean and variance values for numerically same input tensors. The only difference between the inputs is that they are the outputs of one and two **tf.concat** operations (see the code below). CPU version works well.\r\n\r\nThe bad output is:\r\n```\r\ninput diff:0.0\r\nmean diff:2.98023223877e-08\r\nvar diff:7.45058059692e-09\r\n```\r\nThe correct output should be:\r\n```\r\ninput diff:0.0\r\nmean diff:0.0\r\nvar diff:0.0\r\n```\r\n\r\n### Source code / logs\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nwith tf.device(\"/gpu:0\"):\r\n    input = tf.placeholder(shape=[16, 4, 4, 8], dtype=tf.float32)\r\n    input1 = tf.concat([input], axis=0)\r\n    input2 = tf.concat([tf.concat([input], axis=0)], axis=0)\r\n\r\n    mean1, var1 = tf.nn.moments(input1, axes=[0,1,2])\r\n    mean2, var2 = tf.nn.moments(input2, axes=[0,1,2])\r\n\r\n    input_diff_max = tf.reduce_max(tf.abs(input1 - input2))\r\n    mean_diff_max = tf.reduce_max(tf.abs(mean1 - mean2))\r\n    var_diff_max = tf.reduce_max(tf.abs(var1 - var2))\r\n\r\n    with tf.Session() as sess:\r\n        i_v, m_v, v_v = sess.run([input_diff_max, mean_diff_max, var_diff_max], feed_dict={input: np.random.rand(16, 4, 4, 8)})\r\n        print(\"input diff:{}\".format(i_v))\r\n        print(\"mean diff:{}\".format(m_v))\r\n        print(\"var diff:{}\".format(v_v))\r\n```\r\n", "comments": ["@zheng-xq @ekelsen : Mind taking a look?", "The results are not deterministic on the GPU, sometimes I get:\r\n\r\n`input diff:0.0\r\nmean diff:0.0\r\nvar diff:1.49011611938e-08\r\n`\r\n\r\nLikely this is due to non-deterministic reductions inside nn.moments.\r\n\r\nWe are considering adding determinism options - out of curiosity, is this an actual problem, or just unexpected?", "Determinism option sounds great. Until then a notice in the docs would be nice, saying that the reduction ops might be non-deterministic.\r\n\r\nCurrently this behavior does not cause serious problems to us. The way it came up was a test, where we tried to numerically compare the outputs and gradients of our implementation of a method with the reference implementation of that method in tensorflow. We got suprised when the reference implementation was not consistent even with itself in our test.\r\n\r\nShortly after submitting this issue, we found this article: https://www.twosigma.com/insights/a-workaround-for-non-determinism-in-tensorflow"]}, {"number": 10221, "title": "Fixed crf_log_norm function in crf.py", "body": "The original version of crf_log_norm function will not output zero when the sequence length is zero.\r\nThis patch fixed the problem.", "comments": ["Can one of the admins verify this patch?"]}, {"number": 10220, "title": "Tensorflow crashes on build on Ubuntu 16.04 when building for skylake (avx512)", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: building from source\r\n- **TensorFlow version (use command below)**:  5ae244e\r\n- **Bazel version (if compiling from source)**:  0.4.5\r\n- **CUDA/cuDNN version**: CUDA 8.0.61, cudnn 6.0.21 (tried also 5.1)\r\n- **GPU model and memory**: 2x Tesla P100-PCIE-12GB\r\n- **Exact command to reproduce**: building\r\n- **Additional information**: Intel(R) Xeon(R) CPU E7-4860 v2 @ 2.60GHz, gcc version 5.4.1 20170519 (Ubuntu 5.4.1-11ubuntu2~16.04)\r\n\r\n\r\n### Describe the problem\r\nOn the regular rebuild of Tensorflow, the build crashes with bunch of `error: argument of type \"const void *\" is incompatible with parameter of type \"const something *\"`\r\n\r\n### Source code / logs\r\nCrash log:\r\n```\r\nINFO: From Compiling tensorflow/core/kernels/scatter_functor_gpu.cu.cc:\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9218): error: argument of type \"const void *\" is incompatible with parameter of type \"const float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9229): error: argument of type \"const void *\" is incompatible with parameter of type \"const float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9242): error: argument of type \"const void *\" is incompatible with parameter of type \"const double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9253): error: argument of type \"const void *\" is incompatible with parameter of type \"const double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9266): error: argument of type \"const void *\" is incompatible with parameter of type \"const float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9277): error: argument of type \"const void *\" is incompatible with parameter of type \"const float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9290): error: argument of type \"const void *\" is incompatible with parameter of type \"const double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9301): error: argument of type \"const void *\" is incompatible with parameter of type \"const double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9314): error: argument of type \"const void *\" is incompatible with parameter of type \"const int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9325): error: argument of type \"const void *\" is incompatible with parameter of type \"const int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9338): error: argument of type \"const void *\" is incompatible with parameter of type \"const long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9350): error: argument of type \"const void *\" is incompatible with parameter of type \"const long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9363): error: argument of type \"const void *\" is incompatible with parameter of type \"const int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9374): error: argument of type \"const void *\" is incompatible with parameter of type \"const int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9387): error: argument of type \"const void *\" is incompatible with parameter of type \"const long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9399): error: argument of type \"const void *\" is incompatible with parameter of type \"const long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9408): error: argument of type \"void *\" is incompatible with parameter of type \"float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9417): error: argument of type \"void *\" is incompatible with parameter of type \"float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9426): error: argument of type \"void *\" is incompatible with parameter of type \"double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9435): error: argument of type \"void *\" is incompatible with parameter of type \"double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9443): error: argument of type \"void *\" is incompatible with parameter of type \"float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9452): error: argument of type \"void *\" is incompatible with parameter of type \"float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9461): error: argument of type \"void *\" is incompatible with parameter of type \"double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9470): error: argument of type \"void *\" is incompatible with parameter of type \"double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9479): error: argument of type \"void *\" is incompatible with parameter of type \"int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9488): error: argument of type \"void *\" is incompatible with parameter of type \"int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9497): error: argument of type \"void *\" is incompatible with parameter of type \"long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9506): error: argument of type \"void *\" is incompatible with parameter of type \"long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9515): error: argument of type \"void *\" is incompatible with parameter of type \"int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9524): error: argument of type \"void *\" is incompatible with parameter of type \"int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9533): error: argument of type \"void *\" is incompatible with parameter of type \"long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512fintrin.h(9542): error: argument of type \"void *\" is incompatible with parameter of type \"long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(54): error: argument of type \"const void *\" is incompatible with parameter of type \"const long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(62): error: argument of type \"const void *\" is incompatible with parameter of type \"const int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(70): error: argument of type \"const void *\" is incompatible with parameter of type \"const long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(78): error: argument of type \"const void *\" is incompatible with parameter of type \"const int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(86): error: argument of type \"void *\" is incompatible with parameter of type \"const long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(95): error: argument of type \"void *\" is incompatible with parameter of type \"const int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(104): error: argument of type \"void *\" is incompatible with parameter of type \"const long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(112): error: argument of type \"void *\" is incompatible with parameter of type \"const int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(120): error: argument of type \"void *\" is incompatible with parameter of type \"const long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(129): error: argument of type \"void *\" is incompatible with parameter of type \"const int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(138): error: argument of type \"void *\" is incompatible with parameter of type \"const long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512pfintrin.h(146): error: argument of type \"void *\" is incompatible with parameter of type \"const int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10223): error: argument of type \"const void *\" is incompatible with parameter of type \"const float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10235): error: argument of type \"const void *\" is incompatible with parameter of type \"const float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10247): error: argument of type \"const void *\" is incompatible with parameter of type \"const double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10259): error: argument of type \"const void *\" is incompatible with parameter of type \"const double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10271): error: argument of type \"const void *\" is incompatible with parameter of type \"const float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10283): error: argument of type \"const void *\" is incompatible with parameter of type \"const float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10295): error: argument of type \"const void *\" is incompatible with parameter of type \"const double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10307): error: argument of type \"const void *\" is incompatible with parameter of type \"const double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10319): error: argument of type \"const void *\" is incompatible with parameter of type \"const int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10331): error: argument of type \"const void *\" is incompatible with parameter of type \"const int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10343): error: argument of type \"const void *\" is incompatible with parameter of type \"const long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10355): error: argument of type \"const void *\" is incompatible with parameter of type \"const long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10367): error: argument of type \"const void *\" is incompatible with parameter of type \"const int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10379): error: argument of type \"const void *\" is incompatible with parameter of type \"const int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10391): error: argument of type \"const void *\" is incompatible with parameter of type \"const long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10403): error: argument of type \"const void *\" is incompatible with parameter of type \"const long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10413): error: argument of type \"void *\" is incompatible with parameter of type \"float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10424): error: argument of type \"void *\" is incompatible with parameter of type \"float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10433): error: argument of type \"void *\" is incompatible with parameter of type \"float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10444): error: argument of type \"void *\" is incompatible with parameter of type \"float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10453): error: argument of type \"void *\" is incompatible with parameter of type \"double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10464): error: argument of type \"void *\" is incompatible with parameter of type \"double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10473): error: argument of type \"void *\" is incompatible with parameter of type \"double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10484): error: argument of type \"void *\" is incompatible with parameter of type \"double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10493): error: argument of type \"void *\" is incompatible with parameter of type \"float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10504): error: argument of type \"void *\" is incompatible with parameter of type \"float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10513): error: argument of type \"void *\" is incompatible with parameter of type \"float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10524): error: argument of type \"void *\" is incompatible with parameter of type \"float *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10533): error: argument of type \"void *\" is incompatible with parameter of type \"double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10544): error: argument of type \"void *\" is incompatible with parameter of type \"double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10553): error: argument of type \"void *\" is incompatible with parameter of type \"double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10564): error: argument of type \"void *\" is incompatible with parameter of type \"double *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10573): error: argument of type \"void *\" is incompatible with parameter of type \"int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10584): error: argument of type \"void *\" is incompatible with parameter of type \"int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10593): error: argument of type \"void *\" is incompatible with parameter of type \"int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10604): error: argument of type \"void *\" is incompatible with parameter of type \"int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10613): error: argument of type \"void *\" is incompatible with parameter of type \"long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10624): error: argument of type \"void *\" is incompatible with parameter of type \"long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10633): error: argument of type \"void *\" is incompatible with parameter of type \"long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10644): error: argument of type \"void *\" is incompatible with parameter of type \"long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10653): error: argument of type \"void *\" is incompatible with parameter of type \"int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10664): error: argument of type \"void *\" is incompatible with parameter of type \"int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10673): error: argument of type \"void *\" is incompatible with parameter of type \"int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10684): error: argument of type \"void *\" is incompatible with parameter of type \"int *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10693): error: argument of type \"void *\" is incompatible with parameter of type \"long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10704): error: argument of type \"void *\" is incompatible with parameter of type \"long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10713): error: argument of type \"void *\" is incompatible with parameter of type \"long long *\"\r\n\r\n/usr/lib/gcc/x86_64-linux-gnu/5/include/avx512vlintrin.h(10724): error: argument of type \"void *\" is incompatible with parameter of type \"long long *\"\r\n\r\n92 errors detected in the compilation of \"/tmp/tmpxft_00008f12_00000000-7_scatter_functor_gpu.cu.cpp1.ii\".\r\nERROR: /scratch/chaimb/tensorflow/tensorflow/core/kernels/BUILD:1140:1: output 'tensorflow/core/kernels/_objs/scatter_functor_gpu/tensorflow/core/kernels/scatter_functor_gpu.cu.pic.o' was not created.\r\nERROR: /scratch/chaimb/tensorflow/tensorflow/core/kernels/BUILD:1140:1: not all outputs were created or valid.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 147.888s, Critical Path: 69.54s\r\n```\r\n\r\n\r\nI've tried disabling most of the options (MKL, architecture optimizations, computability) but the crash happens even with full-default (except CUDA and XLA) configuration.", "comments": ["I had a similar problem and my workaround was to downgrade to gcc/g++ 4.8, see this page for [how2](https://ask.fedoraproject.org/en/question/95016/fedora-24-how-do-i-install-and-change-the-default-gcc-compiler-version/).\r\n\r\nubuntu 17.04 64 bit, CUDA 8.0.61, cudnn 6.0.21, tensorflow tag v1.1.0, bazel configured to use -msse4.1, -msse4.2, -mavx, -mavx2, -mfma, cuda compute capabilities 6.1, gpu is nvidia geforce gtx 1080 ti, cpu is amd ryzen 1700x\r\n", "From what I can see, you are trying to build with avx 512 instruction set?\r\nI am not sure if we tested with avx512 yet. Could you try rebuilding without avx512?", "@gunan No, I'm not, at least not explicitly. The processor is Ivy Bridge, and I was building with default settings. ", "@Randl Your build failure seems to be in `avx512fintrin.h`. \r\nI think it is included through `immintrin.h`, but looking at the files, most of the header should be skipped.\r\nWhat is the exact build command you are running before you saw this failure?", "@gunan That's what I run (different options set were tried):\r\n```\r\n\r\nchaimb@hpc1:/scratch/chaimb/tensorflow$ ./configure\r\nPlease specify the location of python. [Default is /usr/bin/python]: /usr/bin/python3\r\nFound possible Python library paths:\r\n  /usr/lib/python3/dist-packages\r\n  /usr/local/lib/python3.5/dist-packages\r\n  /usr/local/lib/python2.7/site-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/lib/python3/dist-packages]\r\n\r\nUsing python library path: /usr/lib/python3/dist-packages\r\nDo you wish to build TensorFlow with MKL support? [y/N] y\r\nMKL support will be enabled for TensorFlow\r\nDo you wish to download MKL LIB from the web? [Y/n] y\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native]:\r\nDo you wish to use jemalloc as the malloc implementation? [Y/n]\r\njemalloc enabled\r\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N]\r\nNo Google Cloud Platform support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with Hadoop File System support? [y/N]\r\nNo Hadoop File System support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] y\r\nXLA JIT support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with VERBS support? [y/N]\r\nNo VERBS support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with OpenCL support? [y/N]\r\nNo OpenCL support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with CUDA support? [y/N] y\r\nCUDA support will be enabled for TensorFlow\r\nDo you want to use clang as CUDA compiler? [y/N]\r\nnvcc will be used as CUDA compiler\r\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]:\r\nPlease specify the location where CUDA  toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]:\r\nPlease specify the cuDNN version you want to use. [Leave empty to use system default]:\r\nPlease specify the location where cuDNN  library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\r\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size.\r\n[Default is: \"3.5,5.2\"]: \"6.0\"\r\nDo you wish to build TensorFlow with MPI support? [y/N]\r\nMPI support will not be enabled for TensorFlow\r\nWARNING: Output base '/home/chaimb/.cache/bazel/_bazel_chaimb/7e5d2835edc3e2079ed27c4c385315e6' is on NFS. This may lead to surprising failures and undetermined behavior.\r\n.....................................\r\nINFO: Starting clean (this may take a while). Consider using --async if the clean takes more than several minutes.\r\nConfiguration finished\r\nchaimb@hpc1:/scratch/chaimb/tensorflow$ bazel build --verbose_failures --jobs 96 --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\n@csoehnel  Confirmed, using `/usr/bin/gcc-4.9` is a valid workaround. ", "Looks like you enabled MKL support. I think that is why the build is failing.", "@gunan disabling it gives same result", "Same thing happens using ``gcc-5.4.1`` on Debian 9.  This is my build command:\r\n\r\n```\r\nbazel build -c opt --config=cuda --copt=-msse4.1 --copt=-msse4.2 --copt=-mavx --copt=-mavx2 --copt=-mfma //tensorflow/tools/pip_package:build_pip_package\r\n```", "I believe #9296 is the same issue, and switching back to `gcc-4.9` seems to solve the problem.\r\n\r\n[Here](http://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#system-requirements) seems to be a combination supported by Nvidia.\r\n\r\n```\r\nDistribution\tKernel\tGCC\tGLIBC\r\nUbuntu 16.04\t4.4.0\t5.3.1\t2.23\r\n```", "Switching back to `gcc-4.9` only fixes the issue because it doesn't have the intrinsic for avx512 yet.\r\n\r\nSomething in the GPU code is including `immintrin.h` which now includes the new avx512 instructions for hardware enablement. \r\n\r\ngcc-5  5.4.1-11ubuntu2  is the version on my machine, and it doesn't matter if I add/remove MKL, XLA or any other options it will compile fine.  And yes I can compile with gcc-4.9 but it doesn't even natively support skylake let alone AVX512 instructions.\r\n\r\nMy C++ is rusty and bazel is new to me, but it seems like some work on includes in  `tensorflow/core/platform/platform.h` \r\n\r\nNvidia technically supports GCC 5.4 which would should this problem, and it is a problem with llvm 3.8.1 too as it also includes these intrinsic types with an include of immintrin.h.\r\n\r\nI wish I wasn't so rusty or I would help to get access to these instructions but from looking around the  real options seem to be either pull out the inclusion of the gcc intrinsics from cudacc code or adding explicit casts for the new types.\r\n\r\n", "I have this problem as well, made any progress?", "Stress before saying something that is likely not useful.  I do not recall building from head in the past few weeks.  Sharing what I have done recently, which I doubt is helpful but it is the only info I have that has a remote chance of being helpful.  \r\n\r\nI built 1.3.0rc2  multiple times on a stock 16.04 setup (on AWS) with AVX2,  CUDA 8 and cuDNN 6 .  I did not use the CUDA 8 Patch 2 (which I can say performs poorly for inception3 and Resnet and possibly others on K80s even more so as I scaled from 1 to 8 GPUs. No idea why (maybe I did something wrong) and I did not try other GPUs for 1 GPU is seemed the same).\r\n\r\nThe version of Bazel I use is 0.5.1.  I do not think that matters just sharing exactly what I was using.  I would NOT use 0.5.3 although I think the problem was fixed.\r\n\r\nI normally build with this command and the only option I add during the `./configure` that is not default is CUDA.\r\n`bazel build -c opt --copt=-march=\"haswell\" --config=cuda //tensorflow/tools/pip_package:build_pip_package`\r\n", "I have the exact same issue on Debian. Any update on this issue?", "@jplu \r\nI do not know if someone will look at this, but with out knowing the hash you are building from, gcc, debian version and bazel version as well as the full build command and ./configure options it is looking for a needle in a haystack.  I do custom TensorFlow builds weekly on 16.04 and I 100% understand there are many combinations of builds that could trigger a problem that I would never see.  If I know exactly what you are doing I can give it a try in my environment or possibly someone else can take a look.  Our build environment here is Ubuntu 14.04 and I mostly build ion 16.04 and sometimes amazon linux I do not remember the version.   ", "Sorry @tfboyd, Here is my setup:\r\n\r\n### System information\r\n- **OS Platform and Distribution**: Debian Buster\r\n- **TensorFlow installed from**: source\r\n- **TensorFlow version**: commit https://github.com/tensorflow/tensorflow/commit/12a628a623a5dae81b8fc699792eaf414e6ace41\r\n- **Python version**: 3.5.4\r\n- **Bazel version**: 0.5.4\r\n- **GCC version**: 5.4.1\r\n- **CUDA/cuDNN version**: CUDA 8/CuDNN 6\r\n- **GPU model and memory**: 2xTesla K80 with 12GB each\r\n- **CPU model**: Intel Xeon E5-2683 v4\r\n- **Exact command to reproduce**:\r\n\r\n```\r\nbazel build -c opt --copt=-mavx --copt=-mavx2 --copt=-mfma --copt=-mfpmath=both --copt=-msse4.2 --copt=-msse4.1 --config=mkl --config=cuda --verbose_failures -k //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\nOr\r\n\r\n```\r\nbazel build -c opt --copt=-march=native --copt=-mfpmath=both --config=mkl --config=cuda --verbose_failures -k //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n### Describe the problem\r\nI'm trying to compile a Tensorflow package specifically optimized for my machine. When I run the compilation with one of the command lines described above, I get some compilation errors. Doesn't matter if I let GCC deciding which optimization to make or if I force them. The kind of errors are always the same as described in the first post and finish by:\r\n\r\n```\r\n92 errors detected in the compilation of \"/tmp/tmpxft_00007482_00000000-7_zero_initializer_op_gpu.cu.cpp1.ii\".\r\nERROR: /opt/tensorflow/tensorflow/contrib/framework/BUILD:88:1: output 'tensorflow/contrib/framework/_objs/python/ops/_variable_ops_gpu/tensorflow/contrib/framework/kernels/zero_initializer_op_gpu.cu.pic.o' was not created\r\nERROR: /opt/tensorflow/tensorflow/contrib/framework/BUILD:88:1: not all outputs were created or valid\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 331.599s, Critical Path: 63.79s\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\nAm I using a wrong command line or is it a bug in the compilation process?\r\n\r\nThanks in advance for any help.", "Hello, I have found the same error when I add c++ random include in a .cu file (compiled by nvcc CUDA 8). This file random (/usr/include/c++/5/random in GNU/Debian 9) includes opt_random.h -> x86intrin.h -> immintrin.h -> avx512vlintrin.h. I don't have this problem when I compile with debug flags in nvcc (-g -O0). Finally I solved this problem changing include dependences in my application.", "Sorry @juanecito but I don't get your post. I don't see the relation between the compilation of Tensorflow and the compilation of your application. Can you give more details please.", "I think the problem here is that gcc-5.5 shipped with avx512\\*intrin.h headers that switched to using `void*` and `const void*` (https://gcc.gnu.org/bugzilla/show_bug.cgi?id=76731) but without switching the builtins to do the same.  This is why 5.4 works but 5.5 breaks.  The tensorflow r1.4 build at least can be unbroken for 5.5 by locally rolling back the above change with e.g.:\r\n```shell\r\nfor f in avx512fintrin.h avx512pfintrin.h avx512vlintrin.h; do\r\n   curl -H \"User-Agent:Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36\" -o $f \"https://gcc.gnu.org/viewcvs/gcc/branches/gcc-5-branch/gcc/config/i386/${f}?view=co&revision=245536&content-type=text%2Fplain&pathrev=245536\"\r\ndone && mv avx512*intrin.h  /usr/lib/gcc/x86_64-linux-gnu/5/include/\r\n```\r\nThis is a terrible idea (who knows what else it's rolling back? are you really cherrypicking 3 random files out of an entire release? and so on) and nobody should do it, of course.\r\n\r\nBut maybe, if you're trying to build tensorflow for GPU (so require nvcc, so require GCC < 6) inside an ubuntu:17.10 docker image (so don't have an apt-get'able gcc-5.4 option), this might be useful.", "I met same situation described above. It happened when my system (slackware linux) updated gcc from 5.3 to 5.5, as @fischman said. ", "Similar problem here. It's odd that it happened with GCC 5.4\r\n\r\n```\r\nC++ compilation of rule '@fft2d//:fft2d' failed (Exit 1)\r\nexternal/fft2d/fft/fftsg.c: In function 'cftf162':\r\nexternal/fft2d/fft/fftsg.c:3028:1: error: insn does not satisfy its constraints:\r\n }\r\n ^\r\n(insn 486 485 130 2 (set (reg:DF 50 xmm13 [orig:218 D.7773 ] [218])\r\n        (plus:DF (reg:DF 50 xmm13 [orig:218 D.7773 ] [218])\r\n            (reg:DF 56 xmm19 [orig:218 D.7773 ] [218]))) external/fft2d/fft/fftsg.c:2933 796 {*fop\r\n_df_comm_mixed}\r\n     (nil))\r\nexternal/fft2d/fft/fftsg.c:3028:1: internal compiler error: in extract_constrain_insn, at recog.c:\r\n2246\r\n```\r\n\r\n### System information\r\n- **OS Platform and Distribution**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: https://github.com/tensorflow/tensorflow/commit/92e6c3e4f5c1cabfda1e61547a6a1b268ef95fa5\r\n- **Python version**: 3.5.2\r\n- **Bazel version (if compiling from source)**: 0.11.0\r\n- **GCC/Compiler version (if compiling from source)**: 5.4.0\r\n- **CUDA/cuDNN version**: CUDA 9.1. cuDNN 7.1\r\n- **GPU model and memory**: NVIDIA K80\r\n- **CPU model**: 2.0 GHz Intel Xeon (Skylake) on GCP\r\n- **Exact command to reproduce**:\r\n```\r\nbazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\nOptimizations set with `./configure`:\r\n```\r\n-mavx -mavx2 -mavx512f -mfma -mfpmath=both -msse4.2 -Ofast\r\n```\r\n\r\nUpd: also tried with gcc 6.4.0 and `-march=skylake`, it failed almost instantly.", "@amq your report includes an \"internal compiler error\" which is not what the rest of this issue is about, and indicates a compiler bug. This issue is tracking workarounds for bugs in the intrinsics headers shipped with the compiler, but not the compiler itself.", "Interestingly though, compiling without `-mavx512f` works just fine.", "Doing a compare of the files replaced by the command provided by @fischman with the files in the Debian/Ubuntu package libgcc-5-dev 5.5.0-12ubuntu1 they appear to be compatible.  The only changes I found diffing the two copies with meld were some variables renamed within the functions (adding __ in some places) and the problematic type changes.  While hacky and not recommended as a blanket fix it does seem to solve the problem and shouldn't cause new issues in this particular scenario.", "i had same error with System information:\r\n    OS Platform and Distribution: Ubuntu 16.04\r\n    TensorFlow installed from: source\r\n    TensorFlow version: 1.8\r\n    Python version: 3.6.4\r\n    GCC version: 5.5.0\r\n    CUDA/cuDNN version: CUDA 9.1/CuDNN 7.1.3\r\n    GPU model and memory: 1080 Ti\r\n\r\nI solved this problem by switching to **gcc-4.9**:\r\n_**$ sudo apt-get install gcc-4.9 g++-4.9\r\n$ sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-4.9 50 --slave /usr/bin/g++ g++ /usr/bin/g++-4.9**_ \r\nNow you can switch to gcc-4.9 by using:\r\n_**$ sudo update-alternatives --config gcc**_\r\n\r\nthen run the following command:\r\n_**$ bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package**_ \r\n\r\n", "Same issue as hamiGH above", "Hi, has this issue been resolved? I am using Ubuntu 18.04 and the lowest version of gcc I could get there is 5.5 which gives the errors as asked in the question. On this same system, I had Ubuntu 16.04 with gcc 5.4 and TensorFlow compiled without a problem. I am really stuck and would appreciate any help! I have tested with TF version 1.9.0 and 1.8.0 both give the same error (the Cuda version I'm using is 9.0).", "I believe this was an nvcc issue.\r\n\r\nI can now compile 1.11.0-rc1 with CUDA 10.0 and gcc 5.5. (But CUDA 10.0 also supports gcc 7.3, so it's kind of moot)", "  If I compile with Debug, the problem is gone.\r\n xxx/xxx/build$ cmake -DCMAKE_BUILD_TYPE=Debug  /path/to/source/code", "Nagging Assignee @tfboyd: It has been 44 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Closing as this is resolved", "@wt-huang Could you share the fix that resolves this issue? I see the same error even with gcc-4.9. Compiling with debug isn't practical for performance reasons. \r\n"]}, {"number": 10219, "title": "Fixed crf.py to force log norm of zero length sequences to zero", "body": "The original log_norm function in crf.py will not output zero when sequence length is zero. This new version force it to be zero.", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->"]}, {"number": 10218, "title": "time and memory cost more and more while using keras.backend.ctc_decoder()", "body": "### memory not released bug with tf.python.ops.gen_ctc_ops  both with ctc_greedy_decoder and ctc_beam_search_decoder...\r\n\r\n\r\n```python\r\nimport time\r\n\r\nfrom keras import backend as K\r\n\r\nstart_time = time.time()\r\nwhile True:\r\n     y_pred  = K.ctc_decode(args)\r\n     cost_time = time.time()-start_time\r\n     print 'cost time', cost_time   # time cost more and more with the same input args. why ??!! \r\n ...\r\n```\r\nwhen using  K.ctc_decode() in a large loop, time cost longer  loop become larger...\r\n\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: ubuntu 14.04\r\n- **TensorFlow installed from (source or binary)**: source ( pip install -U tensorflow)\r\n- **TensorFlow version (use command below)**: (1.1.0)\r\n- **Bazel version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: None ( same problem occured if has CUDA7.5)\r\n- **GPU model and memory**: None ( same problem occured with GPU of 32G)\r\n- **Exact command to reproduce**:\r\n\r\n####  function in file  tensorflow.python.ops.ctc_ops.py\r\n\r\nPlease help, thank you very much!", "comments": ["Could you provide the full code?", "@aselle I have the same problem.  Here is my code.\r\n\r\n```\r\nimport string\r\nfrom io import BytesIO\r\nimport base64\r\nimport numpy as np\r\nfrom keras.models import load_model\r\nfrom keras import backend as K\r\nfrom scipy import misc\r\n\r\ncharacters = string.digits + string.ascii_lowercase + ' '\r\nwidth, height, n_len = 170, 60, 8\r\nbase_model = load_model('model.h5')\r\n\r\ndef predict(img_base64=None):\r\n    pfd = BytesIO(base64.b64decode(img_base64))\r\n    img = misc.imread(pfd, mode='RGB')\r\n    img = misc.imresize(img, (height, width))\r\n    img = img.transpose(1, 0, 2)\r\n    img = img.reshape(1, width, height, 3)\r\n    y_pred = base_model.predict(img)\r\n    y_pred = y_pred[:, 2:, :]\r\n    ctc_code = K.ctc_decode(y_pred, input_length=np.ones(y_pred.shape[0]) * y_pred.shape[1])\r\n    out = K.get_value(ctc_code[0][0])\r\n    out = out[:, :n_len]\r\n    out = np.array(out, dtype=np.int8)\r\n    out = ''.join([characters[x] for x in out[0]])\r\n    return out\r\n```\r\n\r\nAfter the function `predict` called abouts hundreds of times, it slows down, momery just keep going up.\r\n"]}, {"number": 10217, "title": "[XLA] Add a strides parameter to the XLA slice operation", "body": "This looks quite large but really it is just threading a strides parameter for the XLA Slice op through the stack.\r\n\r\nThe elemental emitter has actually changed, as it now performs the striding\r\nThe slice shape inference has changed to take into account striding\r\nthe strided slice tf2xla no longer uses concat to construct a strided slice\r\n", "comments": ["Can one of the admins verify this patch?", "i suspect no-one cares enough to discuss it on the mailing list.  If you think it should be positive strides only then I'm happy to change it.  Otherwise I think it should be merged sooner rather than later because it is quite a large change in terms of the number of files touched.", "@hawkinsp This is now positive strides only.\r\n", "@tensorflow-jenkins Test this please", "Hi.  See the comments on https://github.com/tensorflow/tensorflow/pull/10031 regarding the test failures.   I can't see a fix in the changes that I pulled a minute ago, but I filed an Issue with the main TF repo and hopefully someone is on it.  I imagine it is holding all public contributors up in the same way.\r\n", "oops - i jumped the gun by looking at only that there were 3 failures.  will look closely at the XLA one", "maybe the Python3 one is something to do with not having the latest tensorboard included (?) will assume that for the moment.", "and the Linux XLA one is down to bad initializers.  will fix ASAP", "@hawkinsp hi - i see that the XLA test failure is because there are tests in tensorflow/compiler/xla/service that i am not currently running (only tensorflow/compiler/xla and tensorflow/compiler/tests at the moment).\r\n\r\nis there a test suite runner for the ones in .../xla/service ?  I can't find one\r\n", "You should just be able to run something like this:\r\n\r\n```\r\n$ bazel test //tensorflow/compiler/xla/...\r\n```\r\n\r\nI don't think there's an explicit `test_suite` for those tests but you can just use the `...` pattern to test everything in a subdirectory.", "Do you need help running the tests, or are you working on these failures?", "working on failures.    have to pull recent changes - and also fix up one of our own internal problems.... getting there :)", "ps - @hawkinsp thanks for the tip - didn't know about '...'\r\n", "Ok - i think that the XLA tests are probably ok now.   ran all the tests as suggested.\r\n", "@tensorflow-jenkins Test this please\r\n", "maybe it doesn't work if i do it\r\n", "@tensorflow-jenkins Test this please", "phew\r\n", "the irony is that I only did that to see how easy it would be to add another Op called SliceUpdate (the non-dynamic version of DynamicUpdateSlice).  Since then I've decided to implement a cheat version of int64 in my device, because I suspect it is a losing battle to keep XLA using only types that the core Ops indicate.", "the nice thing is that this merge will mean that the difference between my repo and the public one is back to a few lines in 3 files. happy days.", "Thanks for all the contributions!"]}, {"number": 10216, "title": "tf.nn.max_pool_with_argmax bug with padding", "body": "There is a bug in the indices returned from `tf.nn.max_pool_with_argmax` when a padding is applied. The indices with be based on the shape supplied to `max_pool_with_argmax`, instead of the shape+padding.\r\n\r\nSimple code example to reproduce:\r\n```\r\nimport tensorflow as tf\r\n\r\ndef main():\r\n    with tf.Session() as session:\r\n        input = tf.get_variable('weights',\r\n                                  shape=[1, 301, 201, 1],\r\n                                  initializer=tf.truncated_normal_initializer(stddev=0.5, dtype=tf.float32),\r\n                                  dtype=tf.float32)\r\n\r\n        val, idx = tf.nn.max_pool_with_argmax(input, [1, 2, 2, 1], [1, 2, 2, 1], padding=\"SAME\") #padding will turn dimensions to 302x202\r\n\r\n        y1 = idx // 201\r\n        x1 = idx % 201\r\n\r\n        y2 = idx // 202\r\n        x2 = idx % 202\r\n\r\n        max_x1 = tf.reduce_max(x1)\r\n        max_y1 = tf.reduce_max(y1)\r\n        max_x2 = tf.reduce_max(x2)\r\n        max_y2 = tf.reduce_max(y2)\r\n\r\n\r\n        session.run(tf.global_variables_initializer())\r\n        m_x1, m_y1, m_x2, m_y2 = session.run([max_x1, max_y1, max_x2, max_y2])\r\n\r\n        print(\"%d, %d, %d, %d\"%(m_x1, m_y1, m_x2, m_y2))\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n\r\nThis prints `\"200, 300, 201, 299\"`. As you can see, the padding would increase the dimensions of the tensor to `302x202`, so the maximum `y` coordinate should be `301` and `x` should be `201`. But if we unravel the argmax indices with a width of `202`, we get a maximum `x` of `201`, but maximum `y` of only `299`. If we instead use `201` as width for unraveling (the unpadded width of the input tensor), we get `200` and `300`, respectively, which are the correct values for the unpadded input tensor.\r\n\r\nSo the `((b * height + y) * width + x) * channels + c` formula for `tf.nn.max_pool_with_argmax` uses the input tensor dimensions for `width`, not the input+padding dimensions.\r\n\r\nThis is relevant if you then use the indices to unpool/reverse the max_pool, since often you'll multiple the dimensions of the max_pool output by 2 to get the input dimensions, which would be off with a naive implementation like this.\r\n\r\nWhen using this to implement an unpooling operation (for instance for SegNet), this will cause every line of the image to shift (by 1 pixel) if padding is applied to the width of an image,  basically slightly tilting an image. It's especially obvious with multiple argmax&unpool in succession.\r\n\r\nIt also means that, with zero-padding, if the whole tensor is negative values (in which case the zero-padding would be the highest value in the tensor), it won't return the coordinates of the padding. Basically, it doesn't actually add any padding to the input tensor, it just pretends it does to make dimensions line up, but doesn't consider the actual values/zeros in the padding. This might be intended behaviour, though it would strike me as odd given the usual understanding of padding. If so, the documentation should be changed to make it clear that this is the way the operation works. But I think this would be against the principle of least astonishment, since I assume most people would think that an op talking about padding would actually add padding values.\r\n\r\nSee also #2169 for a use-case for this with additional discussion", "comments": ["@girving Since you participated a lot in the linked context thread, would you mind taking a look at this?", "I'm not sure whether this is intended behavior or not, but regardless I don't think we can change it.  It doesn't strike as clearly a bug, and changing it will break existing models and code in incredibly difficult to spot ways.\r\n\r\n@Panaetius For your purposes, can you just add the padding-related offset?\r\n\r\nNote that if an existing gradient routine uses the routine assuming the other behavior, and is therefore wrong, that's definitely a bug we should fix.  Similarly, if this routine fails to return negative indices in certain cases, I'd also consider that a bug which we should fix.  However, by itself the offset will probably have to remain.", "@girving I'm currently not really affected, by supplying the width without padding to my unpool op, it's working fine.\r\n\r\nIf this isn't changed, then you should update the documentation of tf.nn.max_pool_with_argmax to clearly reflect this behaviour.\r\n\r\nI can understand your reasoning, though I still regard it as a bug. Specifically, if there's [[-1, -2], [0, 0]] at the bottom of a tensor (the 0's being padding), this op would return the index of the -1, instead of one of the 0's, and that's not really what max_pooling should do. The way I see it right now, it's clearly a bug, but one without a lot of consequences (since it only affects the edges of an image), i.e. the example I just mentioned probably doesn't influence network performance, it might even be beneficial (not introducing arbitrary zeros). But it is conceptually a bug. \r\n\r\nThat said, if the documentation is changed, it shouldn't make much of a difference. At least I can't think of a use-case where the behaviour can't be easily circumvented (like supplying the original dimensions in the unpool example), so I don't see it as a bug that would prohibit someone from doing what they want.", "@girving would you take a stab at updating the docs or reassign?", "Hmm, pretty annoying that `max_pool_with_argmax` is GPU only. :/", "Fixing the documentation now.  I agree this is a conceptual bug, but I am too frightened to fix it since it could easily cause crashes.", "@girving @Panaetius \r\n\r\nI am sorry to comment on this closed issue, but I think `max_pool` has same behaviour with `max_pool_with_argmax `\r\n\r\nCode:\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nM = np.array([\r\n        [[1],[-1],[0]],\r\n        [[-1],[2],[1]],\r\n        [[0],[2],[-2]]\r\n    ])\r\n\r\nM = np.asarray(M, dtype='float32')\r\nM = M.reshape(1, 3, 3, 1)\r\n\r\ndata = tf.placeholder(\"float32\", shape=[1, 3, 3, 1])\r\npool = tf.nn.max_pool(data, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\r\n\r\nprint(pool.get_shape())\r\n\r\nwith tf.Session() as sess:\r\n    pooled_M = sess.run(pool,feed_dict={data:M})\r\n    print \"pooled_M: \\n\", pooled_M\r\n```\r\n\r\nOutput:\r\n```shell\r\npooled_M: \r\n[[[[ 2.]\r\n   [ 1.]]\r\n\r\n  [[ 2.]\r\n   [-2.]]]]\r\n```\r\n\r\nThe last element should be `0` with `zero-padding` as `0` is bigger than `-2`.\r\n\r\nWDYT?\r\n", "If they have the same bug, does that just mean the padding is with -inf?", "@girving thank you for the reply.\r\n\r\nCloud you give me more details? what is `-inf` meaning?\r\n\r\nI think i can working on this issue with more details.\r\n\r\nFirstly, i will add more unit tests for this ops, @girving WDYT?", "    emmy:tensorflow% python3\r\n    Python 3.6.1 (default, Apr 26 2017, 22:21:58) \r\n    [GCC 4.2.1 Compatible Apple LLVM 8.1.0 (clang-802.0.41)] on darwin\r\n    Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n    >>> -inf\r\n    -inf", "@girving Oh, i got it, but i don't think so.\r\n\r\nUse `avg_pool` instead of `max_pool` of the previous code:\r\n\r\nCode:\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nM = np.array([\r\n        [[1],[-1],[0]],\r\n        [[-1],[2],[1]],\r\n        [[0],[2],[-2]]\r\n    ])\r\n\r\nM = np.asarray(M, dtype='float32')\r\nM = M.reshape(1, 3, 3, 1)\r\n\r\ndata = tf.placeholder(\"float32\", shape=[1, 3, 3, 1])\r\npool = tf.nn.avg_pool(data, [1, 2, 2, 1], [1, 2, 2, 1], padding='SAME')\r\n\r\nprint(pool.get_shape())\r\n\r\nwith tf.Session() as sess:\r\n    pooled_M = sess.run(pool,feed_dict={data:M})\r\n    print \"pooled_M: \\n\", pooled_M\r\n```\r\n\r\nOutput: \r\n```shell\r\npooled_M: \r\n[[[[ 0.25]\r\n   [ 0.5 ]]\r\n\r\n  [[ 1.  ]\r\n   [-2.  ]]]]\r\n```\r\n\r\nIt seems like `padding` values is just not involved in calculation.", "`+` and `max` have different identity elements: 0 for `+` and -inf for `max`.", "@girving how about `avg_pool`?"]}, {"number": 10214, "title": "Definition of session -> run() in c++", "body": "Can I know the location of the code which contains the function definition of session-> run(const std::vector<std::pair<string, Tensor> >& inputs,\r\n                     const std::vector<string>& output_tensor_names,\r\n                     const std::vector<string>& target_node_names,\r\n                     std::vector<Tensor>* outputs)\r\n\r\nof session.h\r\n\r\nAfter looking at docs , I found that its a part of TensorFlow C++ api whose code is present in tensorflow/code location, but I couldn't find exact location.\r\nI could find only function declaration in session.h file in tensorflow/core/public but not its definition\r\n\r\nI would like to modify the implementation of session -> run() and use it.", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!\r\n\r\n(That said, [`Session`](https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/core/public/session.h#L119) is an abstract and there are multiple implementations of it, and hence multiple implementations of `Session::Run`, such as [`DirectSession::Run`](https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/core/common_runtime/direct_session.cc#L364))", "Hi , I am trying to print log statements in 'DirectSession::Run' from https://github.com/tensorflow/tensorflow/blob/r1.2/tensorflow/core/common_runtime/direct_session.cc#L364 \r\n\r\nas described in https://stackoverflow.com/questions/24325463/how-to-get-console-output-of-log-lines-printf-cout-etc-of-c-library-use\r\n\r\nand then built the libraries from source file.\r\n\r\nI have then used the library in android ndk , but the logs are not getting printed in android studio.\r\nPlease help in debugging the .so file code from Android Studio using ndk\r\n"]}, {"number": 10213, "title": "BasicLSTMCell zero_state() raise error in TF1.2 but works in TF1.1", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttp://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: YES\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux version 4.4.0-75-generic (buildd@lgw01-21) (gcc version 5.4.0 20160609 (Ubuntu 5.4.0-6ubuntu1~16.04.4) ) #96-Ubuntu SMP Thu Apr 20 09:56:33 UTC 2017\r\n- **TensorFlow installed from (source or binary)**:\r\nBinary\r\n- **TensorFlow version (use command below)**:\r\n('v1.2.0-rc0-312-g0b72359', '1.2.0-rc0')\r\n- **Bazel version (if compiling from source)**:\r\nNA\r\n- **CUDA/cuDNN version**:\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2016 NVIDIA Corporation\r\nBuilt on Sun_Sep__4_22:14:01_CDT_2016\r\nCuda compilation tools, release 8.0, V8.0.44\r\n- **GPU model and memory**:\r\nQuadro K620 \r\n- **Exact command to reproduce**:\r\n\r\n\r\n\r\n### Describe the problem\r\nWhen I try to create zero state tensor for a BasicLSTMCell, a error is raised as below. The same code can work in tensorflow 1.1\r\n\r\nFile \"/home/wangyao/PersonalCode/GAN/ganForTimeSeq.py\", line 204, in discriminator\r\n    init_state = lstmCell.zero_state(self.batch_size_t, dtype=tf.float32)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 229, in zero_state\r\n    return _zero_state_tensors(state_size, batch_size, dtype)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 130, in _zero_state_tensors\r\n    return nest.map_structure(get_state_shape, state_size)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/nest.py\", line 317, in map_structure\r\n    structure[0], [func(*x) for x in entries])\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 125, in get_state_shape\r\n    c = _concat(batch_size, s)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn_cell_impl.py\", line 90, in _concat\r\n    \"but saw tensor: %s\" % p)\r\nValueError: prefix tensor must be either a scalar or vector, but saw tensor: Tensor(\"Placeholder:0\", dtype=int32)\r\n\r\n\r\n### Source code / logs\r\nself.batch_size_t = tf.placeholder(tf.int32, None)\r\n\r\nwith tf.variable_scope('d_rnn'):\r\n                lstmCell = tf.contrib.rnn.BasicLSTMCell(num_units_in_LSTMCell,reuse=reuseParam)\r\n                init_state = lstmCell.zero_state(self.batch_size_t, dtype=tf.float32)\r\n                raw_output, final_state = tf.nn.dynamic_rnn(lstmCell, inputTensor, initial_state=init_state)\r\n", "comments": ["@ebrevdo Our friend is curious about your recent change 54efd636b504aad368eea254eca2970a16d457f6 which added a precondition that prevents placeholders with undefined shapes.", "Hi, yes.  We recently added support for Tensor state_size as well as Tensor\nbatch size. However to simplify the logic of propagating both the dynamic\nand static concatenation of the two, and to make explicit the requirement\nthat batch size should be either a scalar or a len 1 vector, we added this\ncheck.  My goal is to avoid more opaque errors down the line if someone\nprovides a higher rank batch size.\n\nOn May 27, 2017 5:20 PM, \"Justine Tunney\" <notifications@github.com> wrote:\n\n> @ebrevdo <https://github.com/ebrevdo> Our friend is curious about a your\n> recent change 54efd63\n> <https://github.com/tensorflow/tensorflow/commit/54efd636b504aad368eea254eca2970a16d457f6>\n> which added a precondition to prevent undefined shapes.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/10213#issuecomment-304483914>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim2ih1OVDp5bp4zNN8yqdMBkgedskks5r-L3cgaJpZM4NnbWv>\n> .\n>\n", "@ebrevdo Should the precondition apply when `tf.placeholder(..., shape=None)` is used? ", "Yes if the shape is none then it could be 2d+\n\nOn May 27, 2017 6:43 PM, \"Justine Tunney\" <notifications@github.com> wrote:\n\n> @ebrevdo <https://github.com/ebrevdo> Should the precondition apply when tf.placeholder(...,\n> shape=None) is used?\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/10213#issuecomment-304487320>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABtim4dTWFORPh-aMHnVuvJ9tpJrysBBks5r-NFPgaJpZM4NnbWv>\n> .\n>\n", "I'm mostly just asking due to backwards compatibility. Code that used shapeless placeholders and then passed a vector or scalar worked before.\r\n\r\nI'm going to close this one out because I suspect it doesn't fall under our [API stability promise](https://www.tensorflow.org/programmers_guide/version_semantics). This involves an intersection of functionality and is happening in private functions. I suspect it wouldn't be possible for the TensorFlow team to completely avoid breakages like these.\r\n\r\nFeel free to reopen if you feel differently.", "Thank you guys, after change the \"self.batch_size_t\" definition to self.batch_size_t = tf.placeholder(tf.int32, []), it fixed.", "thanks @wangyaobupt  for wonderful suggestion, it works.", "Hi everyone, please can someone help me to fix this below error in tensorflow, i am using tensorflow 1.2 version. thanks\r\n \"but saw tensor: %s\" % p)\r\nValueError: prefix tensor must be either a scalar or vector, but saw tensor: Tensor(\"batch_size:0\", dtype=int32)", "hi, adil25\r\nyou can just use ```batch_size = tf.shape(X)[0]```\r\ntf.shape is a powerful op that returns the dim of your tensor in the runtime\r\nwhere X is your input sequence", "Thank you for your reply, please i am new to tensorflow and i am not sure where to make your suggested change, please could you tell me where to make this change, i am sharing my code below.....\nimport random\nimport vizdoom as vd\nimport tensorflow as tf\nimport numpy as np\nimport scipy.ndimage as Simg\n\nfrom basic_ennemy_pos import basic_ennemy_x\nfrom network import tf, DRQN\nfrom video import VideoWriter\nfrom memory import ReplayMemory\nfrom config import (\n    N_ACTIONS, LEARNING_RATE, MIN_MEM_SIZE, MAX_MEM_SIZE,\n    MAX_CPUS, TRAINING_STEPS, BATCH_SIZE, SEQUENCE_LENGTH,\n    QLEARNING_STEPS, MAX_EPISODE_LENGTH, DEATH_PENALTY,\n    KILL_REWARD, PICKUP_REWARD, GREEDY_STEPS, IGNORE_UP_TO,\n    BACKPROP_STEPS, USE_GAME_FEATURES, LEARN_Q, USE_RECURRENCE,\n)\n\n# Config variables\nim_w, im_h = 108, 60\nN_FEATURES = 1\nACTION_SET = np.eye(N_ACTIONS, dtype=np.uint32).tolist()\nSECTION_SEPARATOR = \"------------\"\n\n# Neural nets and tools\nprint('Building main DRQN')\nmain = DRQN(im_h, im_w, N_FEATURES, N_ACTIONS, 'main', LEARNING_RATE, \n            use_game_features=USE_GAME_FEATURES, learn_q=LEARN_Q, \n            recurrent=USE_RECURRENCE)\nprint('Building target DRQN')\ntarget = DRQN(im_h, im_w, N_FEATURES, N_ACTIONS, 'target', LEARNING_RATE, True, \n        recurrent=USE_RECURRENCE)\nsaver = tf.train.Saver()\nmem = ReplayMemory(MIN_MEM_SIZE, MAX_MEM_SIZE)\n\n\ndef csv_output(*columns):\n    def wrapper(func):\n        def inner(*args, **kwargs):\n            print(\"---------\")\n            print(\"::\", func.__name__, \"::\")\n            print(\",\".join(columns))\n            return func(*args, **kwargs)\n        return inner\n    return wrapper\n\n\ndef create_game():\n    game = vd.DoomGame()\n    game.load_config(\"basic.cfg\")\n\n    # Ennemy detection\n    walls = None  # map_parser.parse(\"maps/deathmatch.txt\")\n    game.clear_available_game_variables()\n    game.add_available_game_variable(vd.GameVariable.POSITION_X)  # 0\n    game.add_available_game_variable(vd.GameVariable.POSITION_Y)  # 1\n    game.add_available_game_variable(vd.GameVariable.POSITION_Z)  # 2\n\n    game.add_available_game_variable(vd.GameVariable.KILLCOUNT)   # 3\n    game.add_available_game_variable(vd.GameVariable.DEATHCOUNT)  # 4\n    game.add_available_game_variable(vd.GameVariable.ITEMCOUNT)   # 5\n\n    game.set_labels_buffer_enabled(True)\n\n    game.init()\n    return game, walls\n\n\ndef reward_reshape(dump):\n    is_dead = len(dump) < MAX_EPISODE_LENGTH\n    reward = [frame[2] for frame in dump]\n    kills = [frame[4] for frame in dump]\n    items = [frame[5] for frame in dump]\n    kill_diff = [0] + [(kills[i] - kills[i - 1]) * KILL_REWARD for i in range(1, len(kills))]\n    item_diff = [0] + [(items[i] - items[i - 1]) * PICKUP_REWARD for i in range(1, len(items))]\n\n    reshaped_reward = [r + k + i for r, k, i in zip(reward, kill_diff, item_diff)]\n\n    if is_dead:\n        reshaped_reward[-1] -= DEATH_PENALTY\n\n    return [\n        (buffer, action, r_reward, game_features)\n        for (buffer, action, _, game_features, _, _), r_reward\n        in zip(dump, reshaped_reward)\n    ]\n\n\ndef play_random_episode(game, walls, verbose=False, skip=1):\n    game.new_episode()\n    dump = []\n    zoomed = np.zeros((MAX_EPISODE_LENGTH, im_h, im_w, 3), dtype=np.uint8)\n    action = ACTION_SET[0]\n    while not game.is_episode_finished():\n        # Get screen buf\n        state = game.get_state()\n        S = state.screen_buffer  # NOQA\n\n        # Resample to our network size\n        h, w = S.shape[:2]\n        Simg.zoom(S, [1. * im_h / h, 1. * im_w / w, 1],\n                  output=zoomed[len(dump)], order=0)\n        S = zoomed[len(dump)]  # NOQA\n\n        # Get game features an action\n        game_features = [basic_ennemy_x(state)]\n        action = random.choice(ACTION_SET)\n        reward = game.make_action(action, skip)\n        dump.append((S, action, reward, game_features))\n    return dump\n\n\ndef wrap_play_random_episode(i=0):\n    try:\n        game, walls = create_game()\n        res = play_random_episode(game, walls, skip=4)\n        game.close()\n        return res\n    except vd.vizdoom.ViZDoomErrorException:\n        print(\"ViZDoom ERROR\")\n        return []\n\n# Need to be imported and created after wrap_play_random_episode\nfrom multiprocessing import Pool, cpu_count\nN_CORES = min(cpu_count(), MAX_CPUS)\nif N_CORES > 1:\n    workers = Pool(N_CORES)\n\n\ndef multiplay():\n    if N_CORES <= 1:\n        return [wrap_play_random_episode()]\n    else:\n        return workers.map(wrap_play_random_episode, range(N_CORES))\n\n\ndef update_target(sess):\n    \"\"\"Transfer learned parameters from main to target NN\"\"\"\n    v = tf.trainable_variables()\n    main_vars = filter(lambda x: x.name.startswith('main'), v)\n    target_vars = filter(lambda x: x.name.startswith('target'), v)\n    for t, m in zip(target_vars, main_vars):\n        sess.run(t.assign(m.value()))\n\n\ndef init_phase(sess):\n    \"\"\"\n    Attempt to restore a model, or initialize all variables.\n    Then fills replay memory with random-action games\n    \"\"\"\n    try:\n        saver = tf.train.import_meta_graph('model.ckpt.meta')\n        saver.restore(sess, tf.train.latest_checkpoint('./'))\n        print(\"Successfully loaded model\")\n    except:\n        import traceback\n        traceback.print_exc()\n        init = tf.global_variables_initializer()\n        sess.run(init)\n        print(\"=== Recreate new model ! ===\")\n\n\n@csv_output(\"mem_size\", \"n_games\")\ndef bootstrap_phase(sess):\n    while not mem.initialized:\n        for episode in multiplay():\n            if len(episode) > SEQUENCE_LENGTH:\n                mem.add(episode)\n        print(\"{},{}\".format(len(mem), len(mem.episodes)))\n\ndef make_video(sess, filename, n_games=3):\n    \"\"\"Reinforcement learning for Qvalues\"\"\"\n    game, walls = create_game()\n    w, h = 200, 125\n    video = VideoWriter(w, h, 25, filename)\n    sep_frame = np.zeros((w, h, 3), dtype=np.uint8)\n\n    # From now on, we don't use game features, but we provide an empty\n    # numpy array so that the ReplayMemory is still zippable\n    for i in range(n_games):\n        screenbuf = np.zeros((im_h, im_w, 3), dtype=np.uint8)\n        epsilon = 0\n\n        try:\n            # Initialize new hidden state\n            total_reward = 0\n            game.new_episode()\n            h_size = main.h_size if USE_RECURRENCE else 0\n            hidden_state = (np.zeros((1, h_size)), np.zeros((1, h_size)))\n            while not game.is_episode_finished():\n                # Get and resize screen buffer\n                state = game.get_state()\n                for i in range(3):\n                    video.add_frame(state.screen_buffer)\n                h, w, d = state.screen_buffer.shape\n                Simg.zoom(state.screen_buffer,\n                          [1. * im_h / h, 1. * im_w / w, 1],\n                          output=screenbuf, order=0)\n\n                # Choose action with e-greedy network\n                action_no, hidden_state = main.choose(sess, epsilon, screenbuf,\n                        dropout_p=1, state_in=hidden_state)\n                action = ACTION_SET[action_no]\n                total_reward += game.make_action(action, 4)\n        except vd.vizdoom.ViZDoomErrorException:\n            print(\"VizDoom ERROR !\")\n            game, walls = create_game()\n\n        for i in range(25):\n            video.add_frame(sep_frame)\n    video.close()\n    game.close()\n\n\n\ncols = (\"qlearning_step\", \"epsilon\", \"reward\", \"steps\", \"loss_Q\", \"loss_gf\")\ncols += tuple(\"Q%d\" % i for i in range(N_ACTIONS))\n@csv_output(*cols)\ndef learning_phase(sess):\n    \"\"\"Reinforcement learning for Qvalues\"\"\"\n    game, walls = create_game()\n\n    # From now on, we don't use game features, but we provide an empty\n    # numpy array so that the ReplayMemory is still zippable\n    for i in range(QLEARNING_STEPS):\n        screenbuf = np.zeros((MAX_EPISODE_LENGTH, im_h, im_w, 3), dtype=np.uint8)\n\n        # Linearly decreasing epsilon\n        epsilon = max(0.1, 1 - (0.9 * i / GREEDY_STEPS))\n        episode = []\n\n        try:\n            game.new_episode()\n            # Initialize new hidden state\n            s = 0\n            h_size = 0 if not USE_RECURRENCE else main.h_size\n            hidden_state = (np.zeros((1, h_size)), np.zeros((1, h_size)))\n            while not game.is_episode_finished():\n                # Get and resize screen buffer\n                state = game.get_state()\n                h, w, d = state.screen_buffer.shape\n                Simg.zoom(state.screen_buffer,\n                          [1. * im_h / h, 1. * im_w / w, 1],\n                          output=screenbuf[s], order=0)\n\n                # Choose action with e-greedy network\n                action_no, hidden_state = main.choose(sess, epsilon, screenbuf[s],\n                                        dropout_p=0.75, state_in=hidden_state)\n\n                action = ACTION_SET[action_no]\n                reward = game.make_action(action, 4)\n                game_features = [basic_ennemy_x(state)]\n                episode.append((screenbuf[s], action, reward, game_features))\n                s += 1\n            # episode = reward_reshape(episode)\n            if len(episode) > SEQUENCE_LENGTH:\n                mem.add(episode)\n            # deaths = 1 if len(episode) != MAX_EPISODE_LENGTH else 0\n            tot_reward = sum(r for (s, a, r, f) in episode)\n        except vd.vizdoom.ViZDoomErrorException:\n            print(\"ViZDoom ERROR !\")\n            game, walls = create_game()\n\n        if i % 200 == 0:\n            make_video(sess, \"videos/learning%05d.mp4\" % i, 3)\n\n        # Adapt target every 10 runs\n        if i % 10 == 0:\n            update_target(sess)\n\n        # Then replay a few sequences\n        for j in range(BACKPROP_STEPS):\n            # Sample a batch and ingest into the NN\n            samples = mem.sample(BATCH_SIZE, SEQUENCE_LENGTH+1)\n            # screens, actions, rewards, game_features\n            S, A, R, F = map(np.array, zip(*samples))\n\n            target_q = sess.run(target.max_Q, feed_dict={\n                target.batch_size: BATCH_SIZE,\n                target.sequence_length: SEQUENCE_LENGTH,\n                target.images: S[:, 1:],\n                target.dropout_p: 1,\n            })\n\n            _, loss_q, loss_gf, qs = sess.run([main.train_step, main.q_loss, main.features_loss,main.Q], feed_dict={\n                main.batch_size: BATCH_SIZE,\n                main.sequence_length: SEQUENCE_LENGTH,\n                main.ignore_up_to: IGNORE_UP_TO,\n                main.images: S[:, :-1],\n                main.target_q: target_q,\n                main.gamma: 0.99,\n                main.rewards: R[:, :-1],\n                main.actions: A[:, :-1],\n                main.dropout_p: 0.75,\n                main.game_features_in: F[:, :-1]\n            })\n        qs = np.mean(np.mean(qs,axis =1),axis=0)\n        print(\"{},{},{},{},{},{},{}\".format(i, epsilon, tot_reward, len(episode), loss_q, loss_gf, \",\".join(map(str,qs))))\n\n        # Save the model periodically\n        if i > 0 and i % 500 == 0:\n            saver.save(sess, \"./model.ckpt\")\n\n    game.close()\n\nfeature_names = [\n    \"\\033[31;1mENNEMIES\\033[0m\",\n    \"\\033[32;1mPICKUPS\\033[0m\",\n    \"\\033[33;1mBLASTS\\033[0m\"\n]\n\n@csv_output(\"actual_ennemy_pos\", \"predicted_pos\")\ndef testing_phase(sess):\n    \"\"\"Reinforcement learning for Qvalues\"\"\"\n    game, walls = create_game()\n\n    # From now on, we don't use game features, but we provide an empty\n    # numpy array so that the ReplayMemory is still zippable\n    for i in range(QLEARNING_STEPS):\n        screenbuf = np.zeros((im_h, im_w, 3), dtype=np.uint8)\n        epsilon = 0\n\n        try:\n            # Initialize new hidden state\n            total_reward = 0\n            game.new_episode()\n            h_size = 0 if not USE_RECURRENCE else main.h_size\n            hidden_state = (np.zeros((1, h_size)), np.zeros((1, h_size)))\n            while not game.is_episode_finished():\n                # Get and resize screen buffer\n                state = game.get_state()\n                h, w, d = state.screen_buffer.shape\n                Simg.zoom(state.screen_buffer,\n                          [1. * im_h / h, 1. * im_w / w, 1],\n                          output=screenbuf, order=0)\n\n                features = sess.run(main.game_features, feed_dict={\n                    main.sequence_length: 1,\n                    main.batch_size: 1,\n                    main.images: [[screenbuf]],\n                    main.dropout_p: 1,  # No dropout in testing\n                })\n\n                observed_game_features = basic_ennemy_x(state)\n                predicted_game_features = features[0][0][0]\n                print(\"{},{}\".format(observed_game_features, predicted_game_features))\n\n                # Choose action with e-greedy network\n                action_no, hidden_state = main.choose(sess, epsilon, screenbuf,\n                        dropout_p=1, state_in=hidden_state)\n                action = ACTION_SET[action_no]\n                total_reward += game.make_action(action, 4)\n        except vd.vizdoom.ViZDoomErrorException:\n            print(\"VizDoom ERROR !\")\n            game, walls = create_game()\n\n    game.close()\n\n \n\n    On Sunday, October 8, 2017, 9:53:06 PM GMT+8, zhedongzheng <notifications@github.com> wrote:  \n \n \nhi, adil25\nyou can just use batch_size = tf.shape(X)[0]\ntf.shape is a powerful op that returns the dim of your tensor in the runtime\nwhere X is your input sequence\n\n\u2014\nYou are receiving this because you commented.\nReply to this email directly, view it on GitHub, or mute the thread.\n    ", "hi, adil25, the problem is not in the code you sent to me. The problem is in the DRQN of network.py, where the batch_size problem is happened in the initialization of rnn states. You need go to check DRQN in network.py", "@zhedongzheng ...Thank you for your reply, please after making the changes i got another error which i mentioning here below. but before that please forgive if you feel something nonsense about me skills as i am very new to python and tensorflow...here is the error and code,\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.slim as slim\r\n\r\n\r\nclass DRQN():\r\n    def __init__(self, im_h, im_w, k, n_actions, scope, learning_rate, \r\n            test=False, use_game_features=False, learn_q=True, recurrent=True):\r\n        self.learning_rate = learning_rate\r\n        self.im_h, self.im_w, self.k = im_h, im_w, k\r\n        self.scope, self.n_actions = scope, n_actions\r\n      # self.batch_size = tf.placeholder(tf.int32, name='batch_size')\r\n        self.batch_size=tf.shape(x)[0]\r\n        self.sequence_length = tf.placeholder(tf.int32, name='sequence_length')\r\n        self.use_game_features = use_game_features\r\n        self.learn_q = learn_q\r\n        self.recurrent = recurrent\r\n\r\n        # Dropout probability\r\n        self.dropout_p = tf.placeholder(tf.float32, name='dropout_p')\r\n\r\n        self.images = tf.placeholder(tf.float32, name='images',\r\n                                     shape=[None, None, im_h, im_w, 3])\r\n        # we'll merge all sequences in one single batch for treatment\r\n        # but all outputs will be reshaped to [batch_size, length, ...]\r\n        self.all_images = tf.reshape(self.images,\r\n                                     [self.batch_size*self.sequence_length,\r\n                                      im_h, im_w, 3])\r\n\r\n        self._init_conv_layers()\r\n        self._init_game_features_output()\r\n        if recurrent:\r\n            self._init_recurrent_part()\r\n        else:\r\n            self._init_dqn_output()\r\n        if not test:\r\n            self._define_loss()\r\n\r\n    def _init_conv_layers(self):\r\n        # First convolution from screen buffer\r\n        self.conv1 = slim.conv2d(\r\n            self.all_images, num_outputs=32,\r\n            kernel_size=[8, 8], stride=[4, 4], padding='VALID',\r\n            scope=self.scope+'_conv1'\r\n        )\r\n\r\n        # Second convolution layer\r\n        self.conv2 = slim.conv2d(\r\n            self.conv1, num_outputs=64,\r\n            kernel_size=[4, 4], stride=[2, 2], padding='VALID',\r\n            scope=self.scope+'_conv2'\r\n        )\r\n\r\n    def _init_game_features_output(self):\r\n        self.layer4 = tf.nn.dropout(\r\n            slim.fully_connected(slim.flatten(self.conv2), 512,\r\n                                 scope=self.scope+'_l4'),\r\n            self.dropout_p,\r\n        )\r\n        self.flat_game_features = slim.fully_connected(self.layer4, self.k,\r\n                                                       scope=self.scope+'_l4.5',\r\n                                                       activation_fn=None)\r\n\r\n        # Output layer\r\n        self.game_features = tf.reshape(self.flat_game_features,\r\n                                        shape=[self.batch_size, self.sequence_length, self.k])\r\n\r\n        # Observed game features\r\n        self.game_features_in = tf.placeholder(tf.float32,\r\n                                               name='game_features_in',\r\n                                               shape=[None, None, self.k])\r\n\r\n        # Difference between observed and predicted game features\r\n        delta = self.game_features - self.game_features_in\r\n        # delta = tf.Print(delta, [delta], summarize=10, name=\"dFeatures\")\r\n\r\n        # Optimize on RMS of this difference\r\n        self.features_loss = tf.reduce_mean(tf.square(delta))\r\n\r\n    def _init_dqn_output(self):\r\n        self.layer3 = tf.nn.dropout(\r\n            tf.reshape(slim.flatten(self.conv2),\r\n                       [self.batch_size, self.sequence_length, 4608]),\r\n            self.dropout_p,\r\n        )\r\n        self.layer3_5 = slim.fully_connected(self.layer3, 512,\r\n                scope=self.scope+\"_layer3_5\")\r\n        Q = slim.fully_connected(\r\n            self.layer3_5, self.n_actions, scope=self.scope+'_actions',\r\n            activation_fn=None)\r\n        self.Q = tf.reshape(Q, [self.batch_size, self.sequence_length,\r\n                                self.n_actions])\r\n        self.choice = tf.argmax(self.Q, 2)\r\n        self.max_Q = tf.reduce_max(self.Q, 2)\r\n\r\n    def _init_recurrent_part(self):\r\n        # Flat fully connected layer (Layer3' in the paper)\r\n        self.h_size = 300\r\n        self.layer3 = tf.nn.dropout(\r\n            tf.reshape(slim.flatten(self.conv2),\r\n                       [self.batch_size, self.sequence_length, 4608]),\r\n            self.dropout_p,\r\n        )\r\n\r\n        # LSTM cell\r\n        self.cell = tf.nn.rnn_cell.LSTMCell(self.h_size)\r\n        self.state_in = self.cell.zero_state(self.batch_size, tf.float32)\r\n\r\n        # Recurrence\r\n        rnn_output, self.state_out = tf.nn.dynamic_rnn(\r\n                self.cell,\r\n                self.layer3,\r\n                initial_state=self.state_in,\r\n                dtype=tf.float32,\r\n                scope=self.scope+'_RNN/')\r\n\r\n        self.rnn_output = tf.reshape(rnn_output, [-1, self.h_size])\r\n\r\n        # Q-estimator for actions\r\n        Q = slim.fully_connected(\r\n            self.rnn_output, self.n_actions, scope=self.scope+'_actions',\r\n            activation_fn=None)\r\n        self.Q = tf.reshape(Q, [self.batch_size, self.sequence_length,\r\n                                self.n_actions])\r\n        self.choice = tf.argmax(self.Q, 2)\r\n        self.max_Q = tf.reduce_max(self.Q, 2)\r\n\r\n    def _define_loss(self):\r\n        self.gamma = tf.placeholder(tf.float32, name='gamma')\r\n        self.target_q = tf.placeholder(tf.float32, name='target_q',\r\n                                       shape=[None, None])\r\n        self.rewards = tf.placeholder(tf.float32, name='rewards',\r\n                                      shape=[None, None])\r\n        self.actions = tf.placeholder(tf.float32, name='actions',\r\n                                      shape=[None, None, self.n_actions])\r\n        y = self.rewards + self.gamma * self.target_q\r\n        Qas = tf.reduce_sum(tf.one_hot(tf.argmax(self.actions, 2), \r\n                                       self.n_actions) * self.Q, 2)\r\n\r\n        self.ignore_up_to = tf.placeholder(tf.int32, name='ignore_up_to')\r\n        y = tf.slice(y, [0, self.ignore_up_to], [-1, -1])\r\n        Qas = tf.slice(Qas, [0, self.ignore_up_to], [-1, -1])\r\n        self.q_loss = tf.reduce_mean(tf.square(y-Qas))\r\n\r\n        if self.use_game_features:\r\n            if self.learn_q:\r\n                print(\"Learn Q and Game Features\")\r\n                self.loss = self.q_loss + self.features_loss\r\n            else:\r\n                print(\"Learn Game Features only\")\r\n                self.loss = self.features_loss\r\n        elif self.learn_q:\r\n            print(\"Learn Q only\")\r\n            self.loss = self.q_loss\r\n        self.train_step = tf.train.RMSPropOptimizer(self.learning_rate).minimize(self.loss)\r\n\r\n    def feed_lstm(self, sess, screens, actions, rewards):\r\n        assert screens.shape[:2] == actions.shape[:2]\r\n        assert screens.shape[:2] == rewards.shape[:2]\r\n        batch_size, sequence_length = screens.shape[:2]\r\n\r\n        actions, state = sess.run([self.choice, self.state_out], feed_dict={\r\n            self.batch_size: batch_size,\r\n            self.sequence_length: sequence_length,\r\n            self.images: screens,\r\n            self.state_in: self.rnn_state,\r\n            self.dropout_p: 0.75,\r\n        })\r\n\r\n        self.last_state = sess.run(self.state_out, feed_dict={\r\n            self.batch_size: batch_size,\r\n            self.sequence_length: sequence_length,\r\n            self.images: screens,\r\n            self.state_in: self.rnn_state,\r\n            self.dropout_p: 0.75,\r\n        })\r\n\r\n    def choose(self, sess, epsilon, screenbuf, dropout_p, state_in):\r\n        \"\"\"Choose an action based on the current screen buffer\"\"\"\r\n        is_random = np.random.rand() <= epsilon\r\n        to_get = [self.Q] if not self.recurrent else [self.state_out]\r\n        if not is_random:\r\n            to_get += [self.choice]\r\n        feed_dict={\r\n            self.batch_size: 1,\r\n            self.sequence_length: 1,\r\n            self.images: [[screenbuf]],\r\n            self.dropout_p: dropout_p,\r\n        }\r\n        if self.recurrent:\r\n            feed_dict[self.state_in] = state_in\r\n        r = sess.run(to_get, feed_dict)\r\n        res = (np.random.randint(self.n_actions), r[0])\r\n        if not is_random:\r\n            res = (r[1][0][0], r[0])\r\n        return res\r\n\r\n\r\nError:\r\n\r\nConnected to pydev debugger (build 163.15188.4)\r\nBuilding main DRQN\r\nTraceback (most recent call last):\r\n  File \"/home/adil/Desktop/pycharm-2016.3.3/helpers/pydev/pydevd.py\", line 1596, in <module>\r\n    globals = debugger.run(setup['file'], None, None, is_module)\r\n  File \"/home/adil/Desktop/pycharm-2016.3.3/helpers/pydev/pydevd.py\", line 974, in run\r\n    pydev_imports.execfile(file, globals, locals)  # execute the script\r\n  File \"/home/adil/Desktop/pycharm-2016.3.3/helpers/pydev/_pydev_imps/_pydev_execfile.py\", line 18, in execfile\r\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\r\n  File \"/home/adil/Documents/deepdoom-master/src/agent.py\", line 28, in <module>\r\n    recurrent=USE_RECURRENCE)\r\n  File \"/home/adil/Documents/deepdoom-master/src/network.py\", line 13, in __init__\r\n    self.batch_size=tf.shape(x)[0]\r\nNameError: name 'x' is not defined\r\n", "hi, adli25, please\r\nchange this\r\n```python\r\n# self.batch_size = tf.placeholder(tf.int32, name='batch_size')\r\nself.batch_size=tf.shape(x)[0]\r\n```\r\nto\r\n```python\r\nself.batch_size = tf.placeholder(tf.int32, [], name='batch_size')\r\n```\r\nand see if it works now\r\n", "@zhedongzheng ......yes it works, thank you very much, God Bless you............"]}, {"number": 10212, "title": "Support `if_darwin` condition", "body": "Sometimes we want it because libs differ from platforms.", "comments": ["Can one of the admins verify this patch?", "Jenkins test this please.", "@maciekcc , Changes made days ago on my local separating branch, sorry for the inconvenience. `clean_dep` added.", "Jenkins test this please."]}, {"number": 10211, "title": "Eye Iris Identification using Tensorflow", "body": "Hello, \r\n\r\nIn my android app, I'm looking to build eye iris identification for each user. Can I do this with Tensorflow lite? The user would use their native camera to put infront of their eyes, Tensorflow will detect if this is identified or not from our database.\r\n\r\nThank you,\r\nKind Regards,\r\n", "comments": ["This is more of a model design question than a TF issue, and would be more appropriately asked on StackOverflow.\r\n\r\nBut note that if you can do it in TensorFlow Lite (which is unreleased) you would also be able to do it today in TensorFlow. See the [TF Android demo](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android) for an example of how to get started integrating TF into an app which uses the camera."]}, {"number": 10210, "title": "tf.summary.image bug with input_queues", "body": "### System information\r\n- **Have I written custom code**: yes\r\n- **OS Platform and Distribution**: Windows 10, Linux Ubuntu 14.04.02\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.1.0\r\n- **CUDA/cuDNN version**: 8.0\r\n- **Exact command to reproduce**: python error_reading_with_summary.py\r\n\r\n### Describe the problem\r\nWhen creating `tf.summary.image()` summaries when using `tf.train.slice_input_producer()` for generating the images, the input queue gets emptied very fast and I end up with less data for training... \r\nFor example: When having 5 images, the first image gets read but when I try collecting the second image I get a `tf.errors.OutOfRangeError` error. This is not a problem with how I input the images because when I leave out the summaries I can read all images.\r\nI get multiple warnings like\r\n```\r\n2017-05-26 08:33:43.017260: W c:\\tf_jenkins\\home\\workspace\\release-win\\device\\gpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:1152] Out of range: FIFOQueue '_6_input_producer/input_producer' is closed and has insufficient elements (requested 1, current size 0)\r\n\t [[Node: input_producer/input_producer_Dequeue = QueueDequeueV2[component_types=[DT_INT32], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](input_producer/input_producer)]]\r\n```\r\nwhen I create the summary operation and then run the summary operation.\r\nInterestingly enough, I also get this warning when I run the summary operation without any summaries created. But at least then all my images get read.\r\nWhen I don't have any summaries and don't run any summary operation this warning doesn't appear at all.\r\n\r\nThe attached archive contains a minimal replicating example. The `tf.summary.image()` is at line 15-16 in the `get_batch()` function and the `merged_summary_op` is created at line 31 and run at line 45 in the `test_read_images_summary()` function.\r\nRun `python error_reading_with_summaries` to execute all 4 cases: \r\n1. When the summary isn't created and the summary operation isn't executed.\r\n2. When the summary is created but the summary operation isn't executed.\r\n3. When the summary isn't created but the summary operation is executed.\r\n4. When the summary is created and the summary operation is executed.\r\n\r\nUse the option `-s` for only creating the summary and `-r` only for executing the summary operation and use both `-r -s` for creating and executing the summary operation.\r\n\r\n### Source code / logs\r\nSource code, traceback and images are included: [error_reading_with_summary.zip](https://github.com/tensorflow/tensorflow/files/1031025/error_reading_with_summary.zip)\r\nRun `python error_reading_with_summaries.py` or `python error_reading_with_summaries.py -h` for help.", "comments": ["Please see https://github.com/tensorflow/tensorflow/issues/923.", "@jart\r\nThanks for replying :)\r\nThe \"problem\" at #923 isn't the same as this described bug. My code behaves differently when running the summary operation as opposed to when not running the summary operation.\r\n\r\nThe main difference is that there are 10 images in my dataset and when not running the summary op, I can read all images this way. \r\nHowever, if I run the summary operation I can only read one image before getting these warnings saying that the queue is closed. \r\n\r\n@jart Did you run the script I sent and didn't observe this different behavior? Is this the reason why you closed the issue?\r\nDoes the summary operation read internally more images? Because I can't explain why this different behavior occurs to me... That's also why I opened this issue, instead of going to stackoverflow to post an implementation question :)", "This issue tracker is for bugs and feature requests. Issues like these can easily be misconfiguration. The [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) community exists to support TensorFlow users. ", "@jart \r\nThanks for pointing me to the direction of StackOverflow. There I found the problem related to this \"issue\".\r\nApparently, a summary op triggers a dequeue everytime it is run.\r\nhttps://stackoverflow.com/questions/40723307/tensorflow-how-to-run-summary-operation-without-triggering-dequeue\r\n\r\nCould it be possible to implement the summary_op in such a way, that it doesn't automatically do a dequeue operation in the context of a normal session?", "Or should we update the documentation to mention **somewhere** that the summary operation will trigger a dequeue operation?"]}, {"number": 10209, "title": "Suppress windows build warnings to reduce win build log size.", "body": "Can't add as reviewers, but also happy to hear comments from @guschmue @vit-stepanovs \r\nThe suppressed warnings are:\r\n - 4003 - not enough actual parameters for macro 'identifier'\r\n - 4244 - 'conversion_type': conversion from 'type1' to 'type2', possible loss of data\r\n - 4267 - 'variable': conversion from 'size_t' to 'type', possible loss of data\r\n - 4503 - 'identifier': decorated name length exceeded, name was truncated\r\n - 4506 - no definition for inline function 'function'\r\n - 4800 - 'type': forcing value to bool 'true' or 'false' (performance warning)\r\n - 4996 - 'function' or 'variable' marked as deprecated\r\n\r\nThe numbers of times we encounter these:\r\n```\r\n   1374 C4003:\r\n   1106 C4244:\r\n    850 C4267:\r\n   1104 C4503:\r\n    156 C4506:\r\n    102 C4800:\r\n    116 C4996:\r\n```", "comments": ["I also have the following linker warnings:\r\n```\r\n    444 LNK4049:\r\n      2 LNK4070:\r\n    246 LNK4197:\r\n   1332 LNK4217:\r\n    126 LNK4221:\r\n```\r\ndo I need to change somewhere else for linker suppressions, or should I just add `/ignore:<id>` same way I add compiler warning suppressions.", "Change looks good to me; I don't know the answer about linker warnings.", "The linker errors: should do no harm to /ignore: them.\r\nMost of them seem to be coming from the external png lib. I can take a look why we see them.\r\nIf you are looking at disk usage for the builds in general: I noticed that some unit tests are collecting a good amount of disk space in \\windows\\temp\\"]}, {"number": 10208, "title": "TypeError: eval() got multiple values for argument 'feed_dict'", "body": "", "comments": []}, {"number": 10207, "title": "SVG or HTML Summary", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A\r\n- **TensorFlow installed from (source or binary)**: N/A\r\n- **TensorFlow version (use command below)**: 5ae244ed0b702e50fd6bb7bc73d45b9188c4239d\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\n\r\nTensorBoard supports image summaries, which is great for visualization. However, TensorFlow doesn't have rich operators for drawing, and people have to rely on Python libraries like `PIL` or `cv2` for rendering. Those libraries typically use software rendering and are not very fast.\r\n\r\nConsidering TensorBoard is a web app, and browsers already have rich support for rendering, why don't we offload the rendering to browsers? For example, SVG is a simple XML format, which supports vector graphics, text and embedded bitmap images. Outputting an SVG seems to be a fairly easy job with some text templates. ", "comments": ["I'm not sure how HTML summaries would work, but I could see the image dashboard supporting SVG summaries. Thoughts @dandelionmane?", "Thanks for the suggestion! I've gone ahead and migrated this to our new repository at https://github.com/tensorflow/tensorboard/issues/50. Feel free to submit a PR there!"]}, {"number": 10206, "title": "Branch 155393864", "body": "", "comments": ["Jenkins, test this please."]}, {"number": 10205, "title": "Release branch commits", "body": "Merges the changes from https://github.com/tensorflow/tensorflow/pull/9954 and https://github.com/tensorflow/tensorflow/pull/9975 into master, since they were only merged into r1.1.", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that they're okay with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "Both commit authors have already had their work merged into r1.1 in the pull requests linked above, so that should be fine.", "@andrewharp can we get this merged in?", "Failure is a known flaky test (should be disabled now).\r\nSince this is a merge PR, CLA is also OK, since all CLAs are signed.\r\nMerging."]}, {"number": 10204, "title": "tf.summary.text fails keeping summaries", "body": "I got following issues when I use `tf.summary.text` and view the summaries on tensorboard.\r\n\r\n- It shows me text summaries in random order.\r\n- It randomly removes existing summaries and show me only a few (Is there a configuration for maximum number of summaries to keep?)\r\n- I can usually see only around 5 summaries on tensorboard even if I added summaries 100+ times.\r\n- Other summaries work properly when I use summaries like below.\r\n```\r\nsummary_op = tf.summary.merge(summaries) # Other scalar, distribution, histogram summaries\r\nvalid_summary_op = tf.summary.merge([valid_sentence_summary]) # text summary with tf.summary.text\r\n```\r\n\r\n\r\nI can reproduce this problem in two different environments.\r\n\r\n1. Ubuntu 14.04 / CUDA 8.0 / Cudnn 5.1 / TF 1.1.0rc2 / Bazel 0.4.5 / GPU TITAN X Pascal (use 0 gpus~4gpus)\r\n2. Mac OSx Sierra / TF 1.1.0rc2 / Bazel 0.4.5 / No GPU\r\n\r\nBelow is sample code to reproduce this issue.\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\ntext_list = ['this is the first text', 'this is 2nd text', 'this is random text']\r\nid2sent = {id:sent for id, sent in enumerate(text_list)}\r\nsent2id = {sent:id for id, sent in id2sent.items()}\r\n\r\ntf.reset_default_graph()    \r\n\r\nouter_string = tf.convert_to_tensor('This is string outside inner scope.')\r\nouter_summary = tf.summary.text('outside_summary', outer_string)\r\n\r\nwith tf.name_scope('validation_sentences') as scope:\r\n    id_list = tf.placeholder(tf.int32, shape=[3], name='sent_ids')\r\n\r\n    valid_placeholder = tf.placeholder(tf.string, name='valid_summaries')\r\n\r\n    inner_summary = tf.summary.text('sent_summary', valid_placeholder)\r\n    summaries = [outer_summary, inner_summary]\r\n    summary_op = tf.summary.merge(summaries)\r\n        \r\nsess = tf.Session()\r\nsummary_writer = tf.summary.FileWriter(logdir='./text_summary', graph=sess.graph)\r\n\r\nfor step in range(10):\r\n\r\n    predicted_sents_ids = sess.run(\r\n        id_list,\r\n        feed_dict={\r\n            id_list: [0, 1, 2]\r\n        })\r\n\r\n    # list of string\r\n    predicted_sents = [id2sent[id] for id in predicted_sents_ids]\r\n\r\n    valid_summary = sess.run(summary_op, feed_dict={\r\n        valid_placeholder: predicted_sents\r\n    })\r\n\r\n    summary_writer.add_summary(valid_summary, global_step=step)\r\n    # summary_writer.flush()\r\n# summary_writer.flush()\r\n# flush() didn't help..\r\n```\r\n\r\nAnd below is the result on tensorboard.\r\n\r\n![image](https://cloud.githubusercontent.com/assets/18069263/26475951/2030a548-41f6-11e7-8898-ca7ac12aa137.png)\r\n", "comments": ["I just found that\r\n- In CPU environment, the summaries are correctly stored when I add `summary_writer.flush()` after every `summary_writer.add_summary()`and run the code with python. (The errors were produced in jupyter notebook environment)\r\nMaybe we can update documentation about using `Writer.flush()`?\r\n\r\n- However, in multi GPU environment, even if I use `summary_writer.flush()`, the order of summaries are correct, but still not all the summaries are saved.\r\n\r\nI was training image-captioning model.\r\nDuring training, I used 4 replica graphs sharing variables and update variable synchronously with average gradient across all towers at each step. \r\nEvery 100 step, I feed validation data sample text from separate validation graph sharing variables with training graphs above without loss function and optimizer like above.\r\nAnd I added the validation result summary right after running training ops.\r\n\r\nMoreover, I found that summaries are overwritten by recent summaries. For example, the summaries added at step 1900 erased summaries added at step 1800.\r\n\r\n![screenshot_20170526-155055](https://cloud.githubusercontent.com/assets/18069263/26496652/66efb8f8-4263-11e7-93e5-7773e055ca95.jpg)\r\n![screenshot_20170526-155313](https://cloud.githubusercontent.com/assets/18069263/26496654/686e8eac-4263-11e7-81fd-0bcde5bc69f9.jpg)\r\n\r\n\r\nThe brief codes look as below.\r\n```\r\nfor step in range(total_steps):\r\n    ....\r\n    sess.run([training_op, lost...])\r\n\r\n    if step % 100:\r\n        generated_valid_ids = sess.run(validation_graph_inference_result, feed_dict={validation_input_placeholder: validation_data}\r\n        valid_sent = id2sent(genrated_valid_ids)\r\n        valid_summary = sess.run(valid_summary_op, feed_dict={valid_summary_placeholder: valid_sent}\r\n        summary_writer.add_summary(valid_summary, global_step=step)\r\n        summary_writer.flush()\r\n```", "@dandelionmane @jart : Mind taking a look?", "On the 'summaries are overwritten' part: TensorBoard [downsamples](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tensorboard/README.md#is-my-data-being-downsampled-am-i-really-seeing-all-the-data) the summaries so that it can loaded into the memory.\r\n\r\n", "I have migrated this issue to tensorflow/tensorboard#83 because TensorBoard has moved into a separate repository. Lets continue discussion there. The logic for writing text summaries will change in v1.3. The previous means had used a construct called the plugin assets manager, which relied on a certain `plugins` directory existing within each run to identify text summaries."]}, {"number": 10203, "title": "Updating the release notes and the rc number.", "body": "", "comments": ["Jenkins, test this please."]}, {"number": 10202, "title": "update stage_ops_test to medium and add 2 shards", "body": "Fix timeout of stage_op_test.  Increase timeout and add 2 shards.", "comments": ["Can one of the admins verify this patch?", "Btw. do we know why the tests started to time out? Performance regression? CI overload?", "Jenkins test this please.", "This is the reason: https://github.com/tensorflow/tensorflow/pull/9686\r\n\r\nThe test got much longer as it tests the new op and more functionality in both ops."]}, {"number": 10201, "title": "Enable more robust Java lint and errorprone checks", "body": "1. Turn on stricter Xlint and errorprone checks in javac to converge\r\n   on a more consistent coding style.\r\n\r\n2. Minor changes to existing code to conform to the new checks.\r\n\r\n3. google-java-format corrections on any java file modified as part of\r\n   the fix.", "comments": ["Can one of the admins verify this patch?", "Jenkins test this please.", "Thanks @kbsriram . This is pretty neat.\r\n\r\nThough, I'm a bit confused about why we need to explicitly list out all the `-Xep` flags. Is there some documentation you can point to? http://errorprone.info/docs/installation suggests that \"Error Prone works out of the box with bazel\".\r\n\r\nIdeally we wouldn't have to list out 125 lines of flags :), so I'd like to understand the configuration here a bit better.", "(FYI @jhseu )", "Ah - sorry! Out of an abundance of caution, my goal was to reduce divergence between new java code coming in via github vs critique before we queue up our java-related changes.\r\n\r\nMany of these flags are \"hand-curated\" within g3 linting tools, and not enabled as errors in the out-of-box errorprone configuration (I'll send you links separately.) Happy to defer to your judgement of course; I've also grouped them into sections in case a smaller set seems to be preferable.", "Jenkins test this please."]}, {"number": 10200, "title": "Docker.gpu build fail: http 404", "body": "------------------------\r\n\r\n### System information\r\n- Only change: in Docker.gpu I added `apt-get python-tk`\r\n- Linux 14.04\r\n- Docker\r\n- Tesla k80\r\n-  what causes problem: ` sudo nvidia-docker build -t with_tk -f Dockerfile.gpu . `\r\n\r\n### Describe the problem\r\nWhen editing the dockerfile to simply add python-tk the build says:\r\n```\r\nCollecting tensorflow-gpu==0.0.0 from http://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.0.0-cp27-none-linux_x86_64.whl\r\n  HTTP error 404 while getting http://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.0.0-cp27-none-linux_x86_64.whl\r\n  Could not install requirement tensorflow-gpu==0.0.0 from http://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.0.0-cp27-none-linux_x86_64.whl because of error 404 Client Error: Not Found for url: http://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.0.0-cp27-none-linux_x86_64.whl\r\nCould not install requirement tensorflow-gpu==0.0.0 from http://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.0.0-cp27-none-linux_x86_64.whl because of HTTP error 404 Client Error: Not Found for url: http://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.0.0-cp27-none-linux_x86_64.whl for URL http://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.0.0-cp27-none-linux_x86_64.whl\r\nThe command '/bin/sh -c pip --no-cache-dir install     http://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-0.0.0-cp27-none-linux_x86_64.whl' returned a non-zero code: 1\r\n```\r\n\r\nTo fix I simply declared gpu-1.0.0 instead of 0.0.0, but I am not supposed to write in those lines!\r\n\r\n", "comments": ["@caisq Maybe we should just convert these files to run \"pip install tensorflow --pre\", now that we have pip packages in pypi?", "@gunan Good idea. @ljstrnadiii , want to send a PR to fix the issue?", "@gunan, thanks for the shout out for a PR. I am a bit clueless as to how to deal with the parameterized_docker_build.sh file. I think I would need someone to hold my hand. Otherwise, if it is as simple as adding something like \r\n\r\n```\r\nENV TENSORFLOW_VERSION 1.0.0\r\nRUN pip install tensorflow-gpu==$TENSORFLOW_VERSION\r\n```\r\n then I think I could do that haha. \r\n ", "@ljstrnadiii oh yes - that reminds me that the `parameterized_docker_build.sh` is a little complicated. I'll fix it.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you.", "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you.", "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you.", "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you."]}, {"number": 10199, "title": "Built tensorflow CPU mode with SIMD_OPTIONS but when when opening session it warns it wasn't compiled to use SSE", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttp://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug or a feature request.\r\n2. The form below must be filled out.\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10. Intel Core i7-6600U\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**:1.2.0-rc0\r\n- **Bazel version (if compiling from source)**: No\r\n- **CUDA/cuDNN version**:No\r\n- **GPU model and memory**:No\r\n- **Exact command to reproduce**:\r\nI built tensorflow on Windows following the instructions from \r\nhttps://github.com/tensorflow/tensorflow/tree/r0.12/tensorflow/contrib/cmake\r\nMy goal was to enable the SIMD options for performance improvements.\r\n\r\n1) Set up toolchain for for 64-bit: vcvarsall amd64\r\n2) Invoked CMAKE\r\nC:\\Projects\\tensorflow\\tensorflow\\contrib\\cmake\\build>cmake .. -A x64 -DCMAKE_BUILD_TYPE=Release -DSWIG_EXECUTABLE=C:/tools/swigwin-3.0.12\\swigwin-3.0.12/swig.exe -DPYTHON_EXECUTABLE=C:\\Users\\sergio.murillo\\AppData\\Local\\Programs\\Python\\Python35/PYTHON.EXE -DPYTHON_LIBRARIES=C:\\Users\\sergio.murillo\\AppData\\Local\\Programs\\Python\\Python35\\libs\\python35.lib -Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVX\r\n3) To build the PIP package\r\nMSBuild /p:Configuration=Release /filelogger tf_python_build_pip_package.vcxproj\r\nIt build with no errors.\r\n4) Install whl\r\npip install .\\tf_python\\dist\\tensorflow-1.2.0rc0-cp35-cp35m-win_amd64.whl\r\n5) Validate installation\r\n>> import tensorflow as tf\r\n>>> hello = tf.constant('Hello, Tensorflow!')\r\n>>> sess = tf.Session()\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\nI built tensorflow on Windows following the instructions from \r\nhttps://github.com/tensorflow/tensorflow/tree/r0.12/tensorflow/contrib/cmake\r\nMy goal was to enable the SIMD options for performance improvements. It builds without errors, but when I open a tensorflow session it still shows the warnings telling that SIMD was not enabled.\r\n\r\n1) Set up toolchain for for 64-bit: vcvarsall amd64\r\n2) Invoked CMAKE\r\nC:\\Projects\\tensorflow\\tensorflow\\contrib\\cmake\\build>cmake .. -A x64 -DCMAKE_BUILD_TYPE=Release -DSWIG_EXECUTABLE=C:/tools/swigwin-3.0.12\\swigwin-3.0.12/swig.exe -DPYTHON_EXECUTABLE=C:\\Users\\sergio.murillo\\AppData\\Local\\Programs\\Python\\Python35/PYTHON.EXE -DPYTHON_LIBRARIES=C:\\Users\\sergio.murillo\\AppData\\Local\\Programs\\Python\\Python35\\libs\\python35.lib -Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVX\r\n3) To build the PIP package\r\nMSBuild /p:Configuration=Release /filelogger tf_python_build_pip_package.vcxproj\r\nIt build with no errors.\r\n4) Install whl\r\npip install .\\tf_python\\dist\\tensorflow-1.2.0rc0-cp35-cp35m-win_amd64.whl\r\n5) Validate installation: This is when despite compiling and building without errors, I see the warnings about the SIMD instructions that should have been enabled in CMAKE with -Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVX\r\n\r\n>>> import tensorflow as tf\r\n>>> hello = tf.constant('Hello, Tensorflow!')\r\n>>> sess = tf.Session()\r\n2017-05-25 14:23:37.872523: W c:\\projects\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-25 14:23:37.873758: W c:\\projects\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-25 14:23:37.873870: W c:\\projects\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-25 14:23:37.874002: W c:\\projects\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-25 14:23:37.874191: W c:\\projects\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-25 14:23:37.874379: W c:\\projects\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-25 14:23:37.874565: W c:\\projects\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n\r\nI followed the instructions, but it seems that SIMD options were not build/compiled. Did I missed something?\r\nThanks!\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n[msbuild.zip](https://github.com/tensorflow/tensorflow/files/1030085/msbuild.zip)\r\n\r\n\r\n", "comments": ["Would it be possible to enable that using `-DCMAKE_CXX_FLAGS=-msse4.2`?", "Do you mean using both:  \r\n-Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVX \r\n-DCMAKE_CXX_FLAGS=-msse4.2\r\nI will try.", "Please let us know if it works.", "It just finished compiling. It did not work. I used\r\n`cmake .. -A x64 -DCMAKE_BUILD_TYPE=Release -DSWIG_EXECUTABLE=C:/tools/swigwin-3.0.12\\swigwin-3.0.12/swig.exe -DPYTHON_EXECUTABLE=C:\\Users\\sergio.murillo\\AppData\\Local\\Programs\\Python\\Python35/PYTHON.EXE -DPYTHON_LIBRARIES=C:\\Users\\sergio.murillo\\AppData\\Local\\Programs\\Python\\Python35\\libs\\python35.lib -Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVX -DCMAKE_CXX_FLAGS=-msse4.2`\r\nand\r\n`MSBuild /p:Configuration=Release /filelogger tf_python_build_pip_package.vcxproj`\r\nthen:\r\n`pip install .\\tf_python\\dist\\tensorflow-1.2.0rc0-cp35-cp35m-win_amd64.whl`\r\nFinally, to validate it\r\n>>> import tensorflow as tf\r\n>>> hello = tf.constant('Hello, TensorFlow!')\r\n>>> sess = tf.Session()\r\n2017-05-26 00:19:54.998072: W c:\\projects\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-26 00:19:54.999236: W c:\\projects\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-26 00:19:54.999340: W c:\\projects\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-26 00:19:54.999436: W c:\\projects\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-26 00:19:54.999519: W c:\\projects\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-26 00:19:54.999663: W c:\\projects\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\r\n2017-05-26 00:19:54.999817: W c:\\projects\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\r\n\r\nI am attaching the msbuild.log where I noticed that it logged the following:\r\n[msbuild.zip](https://github.com/tensorflow/tensorflow/files/1030888/msbuild.zip)\r\n\r\n`cl : Command line warning D9002: ignoring unknown option '-msse4.2' [C:\\Projects\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_core_lib.vcxproj]`\r\n\r\nIt is an unknown option for CL. \r\n\r\n\r\n\r\n", "If you look at the errors, it does not complain about \"avx\", but it does complain about \"sseX\", \"avx2\" and \"fma\". Your build command \"/arch:avx\" only enables compiling with avx instruction set.\r\n\r\n@guschmue @vit-stepanovs @mrry What would be the way to enable multiple instruction sets in windows? With \"arch:avx\" I would have expected \"everything up to avx, including all sse's\" to be enabled, but that does not seem to be the case.", "True. I was expecting the same, that everything up to avx including sse's be enabled with \"arch:avx\". ", "I think this is a bug in [`WarnAboutUnusedCPUFeatures()`](https://github.com/tensorflow/tensorflow/blob/5ae244ed0b702e50fd6bb7bc73d45b9188c4239d/tensorflow/core/platform/cpu_feature_guard.cc#L97) producing false warnings: it uses the definition of macros like `__SSE__`, `__SSE2__`, etc. to determine whether you have compiled with SSE, SSE2, etc. support, but MSVC doesn't define these macros even when you're building with SSE support. \r\n\r\nFrom my understanding of [this page about Visual C++ predefined macros](https://msdn.microsoft.com/en-us/library/b0084kay.aspx), all 64-bit x86 code generated by MSVC has up to SSE2 support. As far as I can tell, SSE3 and SSE4 are implied by `/arch:AVX` as well. @guschmue Does that fit with your understanding?", "Yes, I'm with @mrry  :)\r\nAs far I understand for **x64** - msvc assumes SSE and SSE2 for its own optimizer but does not set `__SSE__` or `__SSE2__`. I know Eigen deals with this the following way:\r\n#if (defined(_M_IX86_FP) && (_M_IX86_FP >= 2)) || **EIGEN_ARCH_x86_64**\r\n      #define EIGEN_SSE2_ON_MSVC_2008_OR_LATER\r\n\r\nFor SSE4 it should be save to assume to be there if AVX is there.\r\n/arch for x64 only takes AVX and AVX2.\r\n", "Hi.\r\nIt builds with \"arch:/avx\" and I installed the whl. It works and it actually does inference 30% faster than without the SIMD options! From what I understand, we are seeing false warnings.\r\n\r\nNow, since one of the warnings was that the CPU supports AVX2. I tried to build with AVX2\r\n`>cmake .. -A x64 -DCMAKE_BUILD_TYPE=Release -DSWIG_EXECUTABLE=C:/tools/swigwin-3.0.12\\swigwin-3.0.12/swig.exe -DPYTHON_EXECUTABLE=C:\\Users\\sergio.murillo\\AppData\\Local\\Programs\\Python\\Python35/PYTHON.EXE -DPYTHON_LIBRARIES=C:\\Users\\sergio.murillo\\AppData\\Local\\Programs\\Python\\Python35\\libs\\python35.lib -Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVX2`\r\n\r\nThen,\r\n\r\n`MSBuild /p:Configuration=Release /filelogger tf_python_build_pip_package.vcxproj`\r\n\r\nHere is when it returns 550 errors all variants of the following:\r\n\r\n`\"C:\\Projects\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_core_framework.vcxproj\" (default target) (7) ->\r\n(ClCompile target) -> \r\n  c:\\projects\\tensorflow\\third_party\\eigen3\\unsupported\\eigen\\cxx11\\src\\fixedpoint\\packetmathavx2.h(274): error C3861: '_mm256_extract_epi16': identifier not found (compiling source file C:\\Projects\\tensorflow\\tensorflow\\core\\framework\\allocator_registry.cc) [C:\\Projects\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_core_framework.vcxproj]\r\n  c:\\projects\\tensorflow\\third_party\\eigen3\\unsupported\\eigen\\cxx11\\src\\fixedpoint\\packetmathavx2.h(278): error C3861: '_mm256_extract_epi8': identifier not found (compiling source file C:\\Projects\\tensorflow\\tensorflow\\core\\framework\\allocator_registry.cc) [C:\\Projects\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_core_framework.vcxproj]`\r\n\r\nSame type of error but for different source files. My processor is i7-6600U which according to [this Intel page](http://www.intel.com/content/www/us/en/products/processors/core/core-vpro/i7-6600u.html) supports SSE4.1/4.2, AVX 2.0\r\n\r\nI do have `immintrin.h` in C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\include but  `_mm256_extract_epi8` and ` _mm256_extract_epi16 `are not defined in that file. ", "I fixed this in the past in my local tree but did not sent a pr because some include order I did not like (I have the code for the missing inlines but it needed to be included before packetmathavx2.h and that part wasn't clean).\r\nLet me try this again.\r\n", "Hello, I am trying to build tensorflow(1.2.0-rc1) with SIMD (SSE2), but it shows me the following error:` /arch SSE2 not supported`\r\nI'm using Visual C++ 2017 and Cmake 3.8.1\r\nHelp me please!\r\n\r\n\r\n![error](https://cloud.githubusercontent.com/assets/11799571/26530699/8fe88388-439f-11e7-87f8-d02d090f7a81.png)\r\n", "I have the same problems as @serchsm, @cesardelgadof.", "Its a few comments above: /arch takes only avx and avx2. \r\nsse and sse2 are 'implicit' set for x64 and tensorflow (eigen) assumes sse2 for x64 on msvc.\r\nTensorFlow should be using sse2 already but you still see the warning because the  `__SSE2__ ` define is not set by msvc.\r\nNot sure how to fix this the correct way, maybe setting   `__SSE2__ , __SSE__ `  in cmake would be ok since everybody is assuming SSE2 is set for x64.", "@petewarden Assigning this to you, since I think you added the CPU info warning. It looks like we can't use the same macros to test for the presence of SSE on Windows (and we're producing reams of false positives because almost all of our Windows builds are x86-64, and so always have SSE and SSE2).", "@serchsm _mm256_extract_epi8 and epi16 are part of AVX and not AVX2 .. That is the reason you are seeing error with AVX2 option. \r\nhttps://software.intel.com/sites/landingpage/IntrinsicsGuide/#text=extract&expand=2273,2273&techs=AVX,AVX2", "@gunan just got a fix for these warnings into our internal tree, so it should be fixed once that's merged with github. Assigning to him, since he did the work!", "What about avx2 support on windows?", "The scope of this issue is misleading error messages.\r\nThat support should be tracked elsewhere for clarity.", "I opened a new issue to track AVX2 support on Windows.", "Here's the fix for anyone wondering: \r\n\r\nhttps://github.com/ScottMudge/tensorflow/commit/8a6e5b2272b5ae7bbf2bfe5d717467b0e3737c7c\r\nAnd make things a little cleaner:\r\nhttps://github.com/ScottMudge/tensorflow/commit/66495e5e981b10ae65ce3f0b716f62efd65e24dc\r\n\r\nYou have to define two variations of _mm256_extract_epi8 and _mm256_extract_epi16, both where offset is either 0 or 1 (only two used), and put them in PacketMathAVX2.h.\r\n\r\nMSVC2015 does not offer _mm256_extract_epi8, -16, -32, or -64 in the immintrin.h header, nor in their runtimes, so it has to be implemented manually.\r\n", "@ScottMudge Thanks for figuring that out! Would you be willing to submit your change as a pull request?", "@mrry Sure, pull request #13525 .", "Thanks a ton @scottmudge, just tried building with AVX2 and VS 2017. Worked flawlessly.\r\n\r\nhttps://github.com/aluo-x/tensorflow_windows"]}, {"number": 10198, "title": "Cherrypicks", "body": "Cherrypick round 1 for rc1.", "comments": []}, {"number": 10197, "title": "Error when serializing LAYER_NAME_UIDS", "body": "### System information\r\n- **Have I written custom code**: yes\r\n- **OS Platform and Distribution**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from**: source\r\n- **TensorFlow version**: v1.2.0-rc0-312-g0b72359 1.2.0-rc0\r\n- **Bazel version**: 0.4.5\r\n- **CUDA/cuDNN version**: 8.0/5.1\r\n- **GPU model and memory**: NVIDIA GeForce GTX 750 Ti\r\n\r\nAfter recompiling TensorFlow I got this strange log message.\r\nI doesn't seem to affect any of the computation.\r\nAll of the other tools behave as expected.\r\n\r\n```\r\nWARNING:tensorflow:Error encountered when serializing LAYER_NAME_UIDS.\r\nType is unsupported, or the types of the items don't match field type in CollectionDef.\r\n'dict' object has no attribute 'name'\r\n```", "comments": ["This is triggered here:\r\n`tf.train.export_meta_graph(\"model.ckpt.meta\")`\r\n\r\nAnd here:\r\n`writer = tf.summary.FileWriter(\"/\", sess.graph)`\r\n\r\nThis holds if either is the first statement inside `with tf.Session() as sess`", "Just found this related issue: #9939", "Closing out duplicate. Thanks for the report."]}, {"number": 10196, "title": "tf.contrib.ffmpeg.decode_audio causes kernel crash w/ multi-threading", "body": "- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow version (use command below)**: v1.1.0 - gpu\r\n- **CUDA/cuDNN version**: 8.0\r\n- **Exact command to reproduce**:\r\n\r\nI have noticed that attempting to run the 'tf.contrib.ffmpeg.decode_audio' function with multiple threads causes the kernel to crash. This occurs when trying to create batches of data from audio binaries. \r\n\r\nThe code underlying 'tf.contrib.ffmpeg.decode_audio' appears to a basic reference to functions outside of tensorflow so I am unsure there is a solution inside of the tensorflow domain. Nonetheless I wanted to bring this up in case someone had a solution. This is probably not a bug report and more of a low priority feature request. \r\n\r\nThe code below will run without error when **num_threads=1** for tf.train.batch but the kernel will crash for **num_threads=2** or more. \r\n\r\n`\r\n```\r\ngraph = tf.Graph()\r\n\r\nwith graph.as_default():\r\n\r\n    \r\n    batch_size=2\r\n\r\n    queue = tf.train.slice_input_producer([paths, labels], \r\n                                          num_epochs=2, shuffle=True, capacity=32)\r\n    \r\n    \r\n    audio_binary = tf.read_file(queue[0])\r\n    signal = tf.contrib.ffmpeg.decode_audio(audio_binary, file_format='mp3', \r\n                                        samples_per_second=22500,  \r\n                                        channel_count=1)[:450000,0]\r\n    y_ = tf.one_hot(queue[1], 16, dtype=tf.float32)\r\n\r\n\r\n    batch_sig, batch_y_ = tf.train.batch([signal, y_], batch_size=batch_size, \r\n                                         shapes=[(450000,), (16,)], \r\n                                         num_threads=1, capacity=64)\r\n    \r\n    \r\n    with tf.Session(config=tf.ConfigProto(operation_timeout_in_ms=500)) as sess:\r\n        sess.run(tf.global_variables_initializer())\r\n        sess.run(tf.local_variables_initializer())\r\n\r\n        \r\n        coord = tf.train.Coordinator()\r\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\r\n        \r\n        \r\n        for i in range(2):\r\n            print(tf.reduce_max(batch_sig, axis=1).eval())\r\n            \r\n        coord.request_stop()\r\n        coord.join(threads)            \r\n        `\r\n\r\n\r\n", "comments": ["@fredbertsch can you have a look please?", "As an aside, I eventually found that `tf.train.slice_input_producer` is unlike the other input producers and does not return a queue object so the above code may be misleading. I am still confused as to the best way to handle queue/process/batch for lists of path/label pairs but the below seems to be closer:\r\n\r\n`with graph.as_default():`\r\n    \r\n    batch_size=32\r\n    n_samples = 100\r\n    \r\n    pathlist = tf.constant(paths, dtype=tf.string)[:n_samples]\r\n    labellist = tf.constant(labels, dtype=tf.int32)[:n_samples]\r\n\r\n    rsq = tf.RandomShuffleQueue(100000000, 0, [tf.string, tf.int32], shapes=[[],[]])\r\n    do_enqueues = rsq.enqueue_many([pathlist, labellist])\r\n        \r\n    gotpath, gotlabel = rsq.dequeue()\r\n\r\n    y_ = tf.one_hot(gotlabel, 16, dtype=tf.float32)\r\n\r\n    signal = tf.contrib.ffmpeg.decode_audio(tf.read_file(gotpath), file_format='mp3', \r\n                                       samples_per_second=sr,  channel_count=1)[:450000,0]     \r\n\r\n    batch_sig, batch_y_ = tf.train.batch([signal, y_], batch_size=batch_size, \r\n                                         shapes=[(450000,), (16,)], \r\n                                         num_threads=1, capacity=32)\r\n    \r\n    \r\n    with tf.Session(config=tf.ConfigProto(operation_timeout_in_ms=5000)) as sess:\r\n\r\n        sess.run(tf.global_variables_initializer())\r\n        sess.run(tf.local_variables_initializer())\r\n\r\n        \r\n        coord = tf.train.Coordinator()\r\n        threads = tf.train.start_queue_runners(sess=sess, coord=coord)\r\n        sess.run(do_enqueues)\r\n        \r\n        i=0\r\n        \r\n        try:\r\n            while not coord.should_stop():\r\n                for step in range(n_samples//batch_size):\r\n                    print(i, tf.reduce_max(batch_sig, axis=1).eval())\r\n                    i=i+1\r\n                coord.request_stop()\r\n        except tf.errors.OutOfRangeError:\r\n            coord.request_stop()\r\n            print('Done training -- epoch limit reached')\r\n        finally:\r\n            coord.request_stop()\r\n            coord.join(threads)            \r\n`", "Hi - This is still an issue. Anyone have thoughts?\r\n\r\nThe time it takes ffmpeg to decode audio is a significant bottleneck which multi-threading would relieve. ", "This issue appears to be the same as #5804, which has been open for a while now. Perhaps it's low-priority for the developers. \r\n\r\nHowever, I suggest that `ffmpeg.decode_audio` is not always a great solution for reading audio files, especially in large numbers. As you point out, decode_audio relies on the external ffmpeg library. In addition, for each audio file, it induces an additional disk write and read because it creates a temporary file during decoding. (According to #5804, the naming of these files is part of the multithreading problem.) For many thousands of audio files, that's a lot of disk IO. \r\n\r\nInstead, perhaps preprocess your audio files offline by decoding them (with ffmpeg or any other tool) and saving them into TFRecords. Decoded audio files can be encapsulated in `tf.train.SequenceExample` instances. Use the `SerializeToString` method to save a `SequenceExample` to a `TFRecord` using a `tf.python_io.TFRecordWriter` instance. Use a `tf.TFRecordReader` instance to read examples from the record and `tf.parse_single_sequence_example` to parse the examples.", "You are correct, it is the same issue as #5804. Closing here. \r\n\r\nThank you for the advice. "]}, {"number": 10194, "title": "Undefined references in android studio for libandroid_tensorflow_kernels.lo", "body": "I am using the prebuilt binaries and am using them in Android studio in windows 10 and have set it up \r\naccording to https://github.com/Qualeams/Android-Face-Recognition-with-Deep-Learning-Library/issues/1\r\nWhen I build the app , i get below errors\r\n\r\nFAILURE: Build failed with an exception.\r\n\r\n* What went wrong:\r\nExecution failed for task ':facerecognitionlibrary:externalNativeBuildRelease'.\r\n> Build command failed.\r\nError while executing process C:\\Users\\H242018\\AppData\\Local\\Android\\Sdk\\ndk-bundle\\ndk-build.cmd with arguments {NDK_PROJECT_PATH=null APP_BUILD_SCRIPT=C:\\Projects\\Android-Test1\\facerecognitionlibrary\\jni-build\\jni\\Android.mk NDK_APPLICATION_MK=C:\\Projects\\Android-Test1\\facerecognitionlibrary\\jni-build\\jni\\Application.mk APP_ABI=armeabi-v7a NDK_ALL_ABIS=armeabi-v7a NDK_DEBUG=0 APP_PLATFORM=android-21 NDK_OUT=C:/Projects/Android-Test1/facerecognitionlibrary/build/intermediates/ndkBuild/release/obj NDK_LIBS_OUT=C:\\Projects\\Android-Test1\\facerecognitionlibrary\\build\\intermediates\\ndkBuild\\release\\lib C:/Projects/Android-Test1/facerecognitionlibrary/build/intermediates/ndkBuild/release/obj/local/armeabi-v7a/libtensorflow.so}\r\nAndroid NDK: WARNING:C:\\Projects\\Android-Test1\\facerecognitionlibrary\\jni-build\\jni\\Android.mk:tensorflow: non-system libraries in linker flags: C:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libprotos_all_cc.a C:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libprotobuf.a C:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libprotobuf_lite.a C:/Users/H242018/AppData/Local/Android/sdk/ndk-bundle/build//../sources/cxx-stl/gnu-libstdc++/4.9/libs/armeabi-v7a/libgnustl_static.a C:/Users/H242018/AppData/Local/Android/sdk/ndk-bundle/build//../sources/cxx-stl/gnu-libstdc++/4.9/libs/armeabi-v7a/libsupc++.a    \r\nAndroid NDK:     This is likely to result in incorrect builds. Try using LOCAL_STATIC_LIBRARIES    \r\nAndroid NDK:     or LOCAL_SHARED_LIBRARIES instead to list the library dependencies of the    \r\nAndroid NDK:     current module    \r\n[armeabi-v7a] SharedLibrary  : libtensorflow.so\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(bias_op.o):bias_op.cc:function tensorflow::(anonymous namespace)::GetBiasValueDims(tensorflow::Tensor const&, tensorflow::TensorFormat, int*, int*, int*, int*): error: undefined reference to 'tensorflow::TensorShape::dim_size(int) const'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(bias_op.o):bias_op.cc:function tensorflow::(anonymous namespace)::GetBiasValueDims(tensorflow::Tensor const&, tensorflow::TensorFormat, int*, int*, int*, int*): error: undefined reference to 'tensorflow::TensorShape::dim_size(int) const'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(bias_op.o):bias_op.cc:function tensorflow::(anonymous namespace)::GetBiasValueDims(tensorflow::Tensor const&, tensorflow::TensorFormat, int*, int*, int*, int*): error: undefined reference to 'tensorflow::TensorShape::dim_size(int) const'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(bias_op.o):bias_op.cc:function tensorflow::(anonymous namespace)::GetBiasValueDims(tensorflow::Tensor const&, tensorflow::TensorFormat, int*, int*, int*, int*): error: undefined reference to 'tensorflow::TensorShape::dim_size(int) const'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(bias_op.o):bias_op.cc:function tensorflow::BiasOp<Eigen::ThreadPoolDevice, int>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::DebugString() const'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(bias_op.o):bias_op.cc:function tensorflow::BiasOp<Eigen::ThreadPoolDevice, int>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::DebugString() const'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(bias_op.o):bias_op.cc:function tensorflow::BiasOp<Eigen::ThreadPoolDevice, int>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::DebugString() const'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(bias_op.o):bias_op.cc:function tensorflow::BiasOp<Eigen::ThreadPoolDevice, int>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::DebugString() const'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(bias_op.o):bias_op.cc:function tensorflow::BiasGradOp<Eigen::ThreadPoolDevice, int>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::TensorShape(tensorflow::gtl::ArraySlice<long long>)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(bias_op.o):bias_op.cc:function tensorflow::BiasGradOp<Eigen::ThreadPoolDevice, int>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::DestructorOutOfLine()'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(bias_op.o):bias_op.cc:function tensorflow::BiasGradOp<Eigen::ThreadPoolDevice, float>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::TensorShape(tensorflow::gtl::ArraySlice<long long>)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(bias_op.o):bias_op.cc:function tensorflow::BiasGradOp<Eigen::ThreadPoolDevice, float>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::DestructorOutOfLine()'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(concat_op.o):concat_op.cc:function tensorflow::ConcatOffsetOp::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::TensorShape(tensorflow::gtl::ArraySlice<long long>)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(concat_op.o):concat_op.cc:function tensorflow::ConcatOffsetOp::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::DestructorOutOfLine()'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(concat_op.o):concat_op.cc:function tensorflow::ConcatOp<Eigen::ThreadPoolDevice, int>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::AddDim(long long)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(concat_op.o):concat_op.cc:function tensorflow::ConcatOp<Eigen::ThreadPoolDevice, int>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::DestructorOutOfLine()'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(concat_op.o):concat_op.cc:function tensorflow::ConcatOp<Eigen::ThreadPoolDevice, int>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::SlowCopyFrom(tensorflow::TensorShape const&)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(concat_op.o):concat_op.cc:function tensorflow::ConcatOp<Eigen::ThreadPoolDevice, int>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::set_dim(int, long long)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(concat_op.o):concat_op.cc:function tensorflow::ConcatOp<Eigen::ThreadPoolDevice, int>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::SlowCopyFrom(tensorflow::TensorShape const&)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(concat_op.o):concat_op.cc:function tensorflow::ConcatOp<Eigen::ThreadPoolDevice, float>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::AddDim(long long)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(concat_op.o):concat_op.cc:function tensorflow::ConcatOp<Eigen::ThreadPoolDevice, float>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::SlowCopyFrom(tensorflow::TensorShape const&)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(concat_op.o):concat_op.cc:function tensorflow::ConcatOp<Eigen::ThreadPoolDevice, float>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::set_dim(int, long long)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(concat_op.o):concat_op.cc:function tensorflow::ConcatOp<Eigen::ThreadPoolDevice, float>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::SlowCopyFrom(tensorflow::TensorShape const&)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(concat_op.o):concat_op.cc:function tensorflow::ConcatOp<Eigen::ThreadPoolDevice, Eigen::QUInt16>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::AddDim(long long)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(concat_op.o):concat_op.cc:function tensorflow::ConcatOp<Eigen::ThreadPoolDevice, Eigen::QUInt16>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::set_dim(int, long long)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(concat_op.o):concat_op.cc:function tensorflow::ConcatOp<Eigen::ThreadPoolDevice, Eigen::QInt8>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::AddDim(long long)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(concat_op.o):concat_op.cc:function tensorflow::ConcatOp<Eigen::ThreadPoolDevice, Eigen::QInt8>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::set_dim(int, long long)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(constant_op.o):constant_op.cc:function tensorflow::{lambda(tensorflow::OpKernelConstruction*)#7}::_FUN(tensorflow::OpKernelConstruction*): error: undefined reference to 'tensorflow::TensorShape::TensorShape()'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(constant_op.o):constant_op.cc:function tensorflow::{lambda(tensorflow::OpKernelConstruction*)#6}::_FUN(tensorflow::OpKernelConstruction*): error: undefined reference to 'tensorflow::TensorShape::TensorShape()'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(constant_op.o):constant_op.cc:function tensorflow::FillOp<Eigen::ThreadPoolDevice, int>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::TensorShape()'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(constant_op.o):constant_op.cc:function tensorflow::FillOp<Eigen::ThreadPoolDevice, float>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::TensorShape()'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(example_parsing_ops.o):example_parsing_ops.cc:function tensorflow::SingleSequenceExampleParserOp::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::Features_default_instance_'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(example_parsing_ops.o):example_parsing_ops.cc:function tensorflow::SingleSequenceExampleParserOp::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::dim_sizes() const'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(example_parsing_ops.o):example_parsing_ops.cc:function tensorflow::SingleSequenceExampleParserOp::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::TensorShape(tensorflow::gtl::ArraySlice<long long>)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(example_parsing_ops.o):example_parsing_ops.cc:function tensorflow::SingleSequenceExampleParserOp::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::FeatureLists_default_instance_'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(example_parsing_ops.o):example_parsing_ops.cc:function tensorflow::SingleSequenceExampleParserOp::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::dim_sizes() const'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(gather_op.o):gather_op.cc:function tensorflow::TTypes<int, 2u, int>::ConstTensor tensorflow::Tensor::flat_outer_dims<int, 2u>() const: error: undefined reference to 'tensorflow::Tensor::ComputeFlatOuterDims(long long) const'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(gather_op.o):gather_op.cc:function tensorflow::TTypes<float, 2u, int>::ConstTensor tensorflow::Tensor::flat_outer_dims<float, 2u>() const: error: undefined reference to 'tensorflow::Tensor::ComputeFlatOuterDims(long long) const'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(pack_op.o):pack_op.cc:function tensorflow::PackOp<Eigen::ThreadPoolDevice, int>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::InsertDim(int, long long)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(pack_op.o):pack_op.cc:function tensorflow::PackOp<Eigen::ThreadPoolDevice, float>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::InsertDim(int, long long)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(shape_ops.o):shape_ops.cc:function tensorflow::SqueezeOp::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::dim_sizes() const'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(shape_ops.o):shape_ops.cc:function tensorflow::ExpandDimsOp::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::dim_sizes() const'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(strided_slice_op.o):strided_slice_op.cc:function tensorflow::StridedSliceOp<Eigen::ThreadPoolDevice, int>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::ValidateStridedSliceOp(tensorflow::Tensor const&, tensorflow::Tensor const&, tensorflow::Tensor const&, tensorflow::ShapeReadWriteInterface const&, int, int, int, int, int, tensorflow::ShapeReadWriteInterface*, tensorflow::ShapeReadWriteInterface*, bool*, bool*, bool*, tensorflow::gtl::InlinedVector<long long, 4>*, tensorflow::gtl::InlinedVector<long long, 4>*, tensorflow::gtl::InlinedVector<long long, 4>*)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(strided_slice_op.o):strided_slice_op.cc:function tensorflow::StridedSliceGradOp<Eigen::ThreadPoolDevice, int>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::ValidateStridedSliceOp(tensorflow::Tensor const&, tensorflow::Tensor const&, tensorflow::Tensor const&, tensorflow::ShapeReadWriteInterface const&, int, int, int, int, int, tensorflow::ShapeReadWriteInterface*, tensorflow::ShapeReadWriteInterface*, bool*, bool*, bool*, tensorflow::gtl::InlinedVector<long long, 4>*, tensorflow::gtl::InlinedVector<long long, 4>*, tensorflow::gtl::InlinedVector<long long, 4>*)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(strided_slice_op.o):strided_slice_op.cc:function tensorflow::StridedSliceAssignOp<Eigen::ThreadPoolDevice, int>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::ValidateStridedSliceOp(tensorflow::Tensor const&, tensorflow::Tensor const&, tensorflow::Tensor const&, tensorflow::ShapeReadWriteInterface const&, int, int, int, int, int, tensorflow::ShapeReadWriteInterface*, tensorflow::ShapeReadWriteInterface*, bool*, bool*, bool*, tensorflow::gtl::InlinedVector<long long, 4>*, tensorflow::gtl::InlinedVector<long long, 4>*, tensorflow::gtl::InlinedVector<long long, 4>*)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(strided_slice_op.o):strided_slice_op.cc:function tensorflow::StridedSliceAssignOp<Eigen::ThreadPoolDevice, float>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::ValidateStridedSliceOp(tensorflow::Tensor const&, tensorflow::Tensor const&, tensorflow::Tensor const&, tensorflow::ShapeReadWriteInterface const&, int, int, int, int, int, tensorflow::ShapeReadWriteInterface*, tensorflow::ShapeReadWriteInterface*, bool*, bool*, bool*, tensorflow::gtl::InlinedVector<long long, 4>*, tensorflow::gtl::InlinedVector<long long, 4>*, tensorflow::gtl::InlinedVector<long long, 4>*)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(unpack_op.o):unpack_op.cc:function tensorflow::UnpackOp<Eigen::ThreadPoolDevice, int>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::RemoveDim(int)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(unpack_op.o):unpack_op.cc:function tensorflow::UnpackOp<Eigen::ThreadPoolDevice, float>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::RemoveDim(int)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(cwise_op_select.o):cwise_op_select.cc:function tensorflow::TTypes<int, 2u, int>::Tensor tensorflow::Tensor::flat_outer_dims<int, 2u>(): error: undefined reference to 'tensorflow::Tensor::ComputeFlatOuterDims(long long) const'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(cwise_op_select.o):cwise_op_select.cc:function tensorflow::TTypes<float, 2u, int>::Tensor tensorflow::Tensor::flat_outer_dims<float, 2u>(): error: undefined reference to 'tensorflow::Tensor::ComputeFlatOuterDims(long long) const'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(maxpooling_op.o):maxpooling_op.cc:function tensorflow::MaxPoolingGradOp<Eigen::ThreadPoolDevice, float>::MaxPoolingGradOp(tensorflow::OpKernelConstruction*): error: undefined reference to 'tensorflow::DeviceTypeString(tensorflow::DeviceType)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(maxpooling_op.o):maxpooling_op.cc:function tensorflow::MaxPoolingGradOp<Eigen::ThreadPoolDevice, Eigen::half>::MaxPoolingGradOp(tensorflow::OpKernelConstruction*): error: undefined reference to 'tensorflow::DeviceTypeString(tensorflow::DeviceType)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(random_op.o):random_op.cc:function tensorflow::(anonymous namespace)::RandomGammaOp<float>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::AppendShape(tensorflow::TensorShape const&)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(save_restore_tensor.o):save_restore_tensor.cc:function tensorflow::Status tensorflow::checkpoint::TensorSliceWriter::Add<int>(std::string const&, tensorflow::TensorShape const&, tensorflow::TensorSlice const&, int const*): error: undefined reference to 'tensorflow::TensorShape::TensorShape(tensorflow::TensorShapeProto const&)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(save_restore_tensor.o):save_restore_tensor.cc:function tensorflow::Status tensorflow::checkpoint::TensorSliceWriter::Add<int>(std::string const&, tensorflow::TensorShape const&, tensorflow::TensorSlice const&, int const*): error: undefined reference to 'tensorflow::TensorShape::AsProto(tensorflow::TensorShapeProto*) const'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(save_restore_tensor.o):save_restore_tensor.cc:function tensorflow::Status tensorflow::checkpoint::TensorSliceWriter::Add<int>(std::string const&, tensorflow::TensorShape const&, tensorflow::TensorSlice const&, int const*): error: undefined reference to 'tensorflow::TensorShape::TensorShape(tensorflow::TensorShapeProto const&)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(save_restore_tensor.o):save_restore_tensor.cc:function tensorflow::Status tensorflow::checkpoint::TensorSliceWriter::Add<int>(std::string const&, tensorflow::TensorShape const&, tensorflow::TensorSlice const&, int const*): error: undefined reference to 'tensorflow::SavedTensorSliceMeta_default_instance_'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(save_restore_tensor.o):save_restore_tensor.cc:function tensorflow::Status tensorflow::checkpoint::TensorSliceWriter::Add<int>(std::string const&, tensorflow::TensorShape const&, tensorflow::TensorSlice const&, int const*): error: undefined reference to 'tensorflow::TensorShapeProto_default_instance_'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(save_restore_tensor.o):save_restore_tensor.cc:function tensorflow::Status tensorflow::checkpoint::TensorSliceWriter::Add<float>(std::string const&, tensorflow::TensorShape const&, tensorflow::TensorSlice const&, float const*): error: undefined reference to 'tensorflow::TensorShape::TensorShape(tensorflow::TensorShapeProto const&)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(save_restore_tensor.o):save_restore_tensor.cc:function tensorflow::Status tensorflow::checkpoint::TensorSliceWriter::Add<float>(std::string const&, tensorflow::TensorShape const&, tensorflow::TensorSlice const&, float const*): error: undefined reference to 'tensorflow::TensorShape::AsProto(tensorflow::TensorShapeProto*) const'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(save_restore_tensor.o):save_restore_tensor.cc:function tensorflow::Status tensorflow::checkpoint::TensorSliceWriter::Add<float>(std::string const&, tensorflow::TensorShape const&, tensorflow::TensorSlice const&, float const*): error: undefined reference to 'tensorflow::TensorShape::TensorShape(tensorflow::TensorShapeProto const&)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(save_restore_tensor.o):save_restore_tensor.cc:function tensorflow::Status tensorflow::checkpoint::TensorSliceWriter::Add<float>(std::string const&, tensorflow::TensorShape const&, tensorflow::TensorSlice const&, float const*): error: undefined reference to 'tensorflow::SavedTensorSliceMeta_default_instance_'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(save_restore_tensor.o):save_restore_tensor.cc:function tensorflow::Status tensorflow::checkpoint::TensorSliceWriter::Add<float>(std::string const&, tensorflow::TensorShape const&, tensorflow::TensorSlice const&, float const*): error: undefined reference to 'tensorflow::TensorShapeProto_default_instance_'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(save_restore_tensor.o):save_restore_tensor.cc:function bool tensorflow::checkpoint::TensorSliceReader::CopySliceData<int>(std::string const&, tensorflow::TensorSlice const&, int*) const: error: undefined reference to 'tensorflow::TensorProto_default_instance_'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(save_restore_tensor.o):save_restore_tensor.cc:function bool tensorflow::checkpoint::TensorSliceReader::CopySliceData<int>(std::string const&, tensorflow::TensorSlice const&, int*) const: error: undefined reference to 'tensorflow::SavedSlice_default_instance_'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(save_restore_tensor.o):save_restore_tensor.cc:function bool tensorflow::checkpoint::TensorSliceReader::CopySliceData<float>(std::string const&, tensorflow::TensorSlice const&, float*) const: error: undefined reference to 'tensorflow::TensorProto_default_instance_'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(save_restore_tensor.o):save_restore_tensor.cc:function bool tensorflow::checkpoint::TensorSliceReader::CopySliceData<float>(std::string const&, tensorflow::TensorSlice const&, float*) const: error: undefined reference to 'tensorflow::SavedSlice_default_instance_'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(save_restore_v2_ops.o):save_restore_v2_ops.cc:function tensorflow::SaveV2::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::BundleWriter::~BundleWriter()'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(tensor_array_ops.o):tensor_array_ops.cc:function tensorflow::TensorArrayPackOrGatherOp<Eigen::ThreadPoolDevice, int, false>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::PartialTensorShape::IsFullyDefined() const'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(tensor_array_ops.o):tensor_array_ops.cc:function tensorflow::TensorArrayPackOrGatherOp<Eigen::ThreadPoolDevice, int, false>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::PartialTensorShape::DebugString() const'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(tensor_array_ops.o):tensor_array_ops.cc:function tensorflow::TensorArrayPackOrGatherOp<Eigen::ThreadPoolDevice, int, false>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::InsertDim(int, long long)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(tensor_array_ops.o):tensor_array_ops.cc:function tensorflow::TensorArrayPackOrGatherOp<Eigen::ThreadPoolDevice, int, false>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::PartialTensorShape::IsCompatibleWith(tensorflow::TensorShape const&) const'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(tensor_array_ops.o):tensor_array_ops.cc:function tensorflow::TensorArrayPackOrGatherOp<Eigen::ThreadPoolDevice, int, false>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::InsertDim(int, long long)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(tensor_array_ops.o):tensor_array_ops.cc:function tensorflow::TensorArrayPackOrGatherOp<Eigen::ThreadPoolDevice, int, false>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::PartialTensorShape::DebugString() const'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(tensor_array_ops.o):tensor_array_ops.cc:function tensorflow::TensorArrayPackOrGatherOp<Eigen::ThreadPoolDevice, Eigen::QInt32, true>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::PartialTensorShape::IsFullyDefined() const'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(tensor_array_ops.o):tensor_array_ops.cc:function tensorflow::TensorArrayPackOrGatherOp<Eigen::ThreadPoolDevice, Eigen::QInt32, true>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::PartialTensorShape::DebugString() const'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(tensor_array_ops.o):tensor_array_ops.cc:function tensorflow::TensorArrayPackOrGatherOp<Eigen::ThreadPoolDevice, Eigen::QInt32, true>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::PartialTensorShape::IsCompatibleWith(tensorflow::TensorShape const&) const'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(tensor_array_ops.o):tensor_array_ops.cc:function tensorflow::TensorArrayPackOrGatherOp<Eigen::ThreadPoolDevice, Eigen::QInt32, true>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::PartialTensorShape::DebugString() const'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(tensor_array_ops.o):tensor_array_ops.cc:function tensorflow::TensorArrayPackOrGatherOp<Eigen::ThreadPoolDevice, tensorflow::bfloat16, true>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::PartialTensorShape::IsFullyDefined() const'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(tensor_array_ops.o):tensor_array_ops.cc:function tensorflow::TensorArrayPackOrGatherOp<Eigen::ThreadPoolDevice, tensorflow::bfloat16, true>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::PartialTensorShape::IsCompatibleWith(tensorflow::TensorShape const&) const'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(tensor_array_ops.o):tensor_array_ops.cc:function tensorflow::TensorArrayPackOrGatherOp<Eigen::ThreadPoolDevice, int, true>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::PartialTensorShape::IsFullyDefined() const'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(tensor_array_ops.o):tensor_array_ops.cc:function tensorflow::TensorArrayPackOrGatherOp<Eigen::ThreadPoolDevice, int, true>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::PartialTensorShape::IsCompatibleWith(tensorflow::TensorShape const&) const'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(tensor_array_ops.o):tensor_array_ops.cc:function tensorflow::TensorArrayConcatOp<Eigen::ThreadPoolDevice, Eigen::QUInt8>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::RemoveDim(int)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(tensor_array_ops.o):tensor_array_ops.cc:function tensorflow::TensorArrayConcatOp<Eigen::ThreadPoolDevice, int>::Compute(tensorflow::OpKernelContext*): error: undefined reference to 'tensorflow::TensorShape::RemoveDim(int)'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(topk_op.o):topk_op.cc:function tensorflow::TTypes<int, 2u, int>::ConstTensor tensorflow::Tensor::flat_inner_dims<int, 2u>() const: error: undefined reference to 'tensorflow::Tensor::ComputeFlatInnerDims(long long) const'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(topk_op.o):topk_op.cc:function tensorflow::TTypes<float, 2u, int>::ConstTensor tensorflow::Tensor::flat_inner_dims<float, 2u>() const: error: undefined reference to 'tensorflow::Tensor::ComputeFlatInnerDims(long long) const'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(topk_op.o):topk_op.cc:function tensorflow::TTypes<int, 2u, int>::Tensor tensorflow::Tensor::flat_inner_dims<int, 2u>(): error: undefined reference to 'tensorflow::Tensor::ComputeFlatInnerDims(long long) const'\r\nC:/Projects/Android-Test1/facerecognitionlibrary/jni-build/jni/libs/armeabi-v7a/libandroid_tensorflow_kernels.lo(topk_op.o):topk_op.cc:function tensorflow::TTypes<float, 2u, int>::Tensor tensorflow::Tensor::flat_inner_dims<float, 2u>(): error: undefined reference to 'tensorflow::Tensor::ComputeFlatInnerDims(long long) const'\r\ntensorflow/core/framework/reader_base.cc:226: error: undefined reference to 'tensorflow::ReaderBaseState::Clear()'\r\ncollect2.exe: error: ld returned 1 exit status\r\nmake: *** [C:/Projects/Android-Test1/facerecognitionlibrary/build/intermediates/ndkBuild/release/obj/local/armeabi-v7a/libtensorflow.so] Error 1\r\n\r\n\r\n* Try:\r\nRun with --stacktrace option to get the stack trace. Run with --info or --debug option to get more log output.\r\n\r\nBUILD FAILED", "comments": ["Resolved the issue , deleted existing libandroid_tensorflow_kernels.lo as its not present in latest binary releases"]}]