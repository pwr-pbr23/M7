[{"number": 2895, "title": "fatal issue with _reverse_seq in rnn.py", "body": "I was trying to code bidirectional seq2seq on my own. I made a `cell with a embedding wrapper`, \nfollowing is the code of _reverse_seq which is from tensorflow ver r0.7(r0.9 doesn't work either)\n\n``` javascript\ndef _reverse_seq(input_seq, lengths):\n  \"\"\"Reverse a list of Tensors up to specified lengths.\n  Args:\n    input_seq: Sequence of seq_len tensors of dimension (batch_size, depth)\n    lengths:   A tensor of dimension batch_size, containing lengths for each\n               sequence in the batch. If \"None\" is specified, simply reverses\n               the list.\n  Returns:\n    time-reversed sequence\n  \"\"\"\n  if lengths is None:\n    return list(reversed(input_seq))\n\n  for input_ in input_seq:\n    input_.set_shape(input_.get_shape().with_rank(2))\n\n\n  # Join into (time, batch_size, depth)\n  s_joined = array_ops.pack(input_seq)\n\n  # Reverse along dimension 0\n  s_reversed = array_ops.reverse_sequence(s_joined, lengths, 0, 1)\n  # Split again into list\n  result = array_ops.unpack(s_reversed)\n  return result\n```\n\nit requires input_seq which is `sequence of seq_len tensors of dimension (batch_size, depth)`\nHowever, pay attention to a part of `def bidirectional_rnn` : \n\n``` javascript\nwith vs.variable_scope(name + \"_FW\"):\n    output_fw, _ = rnn(cell_fw, inputs, initial_state_fw, dtype,\n                       None) # modified\n  #print (inputs[0].get_shape())\n  #print (sequence_length.get_shape())\n\n  # Backward direction\n  with vs.variable_scope(name + \"_BW\"):\n    tmp, _ = rnn(cell_bw, _reverse_seq(inputs, sequence_length),\n                 initial_state_bw, dtype, None) #modified\n  output_bw = _reverse_seq(tmp, sequence_length)\n```\n\njust because I use a cell with a embedding wrapper, those inputs i feed are not embedded vector but one-hot encodded, and it has confliction with the requirement of _reverse_seq input.\n", "comments": ["Could you please cut and paste your complete program and errors? Thanks.\n", "Automatically closing due to lack of recent activity. Please reopen when further information becomes available.\n"]}, {"number": 2894, "title": "how to use multiple parameters server under synchronous gradient update", "body": "recently, I try to train the inceptionV3 mode with multi machine. As described in [https://github.com/tensorflow/models/tree/master/inception](url),  tutorial describes how to train inceptionv3 using tensorflow  distributed version, but only use a parameter server.\nI want to know how to use multiple parameters server under synchronous gradient update, anyone can give guidance?\n", "comments": ["This is a question better suited for StackOverflow. Please ask it there and tag it with the `tensorflow` tag.\n"]}, {"number": 2893, "title": "Deprecate contrib.learn.ops{dropout, dnn}", "body": "For dnn, simply added a deprecation message. BTW, there's a bug in `TensorFlowEstimator` where dropout is still happening during testing. But I am guessing that's not critical at this moment since it will be deprecated anyways. \n\nQuestion: do we want a separate layer that combines both dnn and dropout in `contrib.layers`, e.g. `dnn_with_dropout`? \n", "comments": ["Jenkins, test this please.\n", "Jenkins, test this please.\n", "Hello, I'm adjusting some examples to account for this deprecation, could you clarify how the new dnn method works? Because it isn't parameter compatible with the old one?\nMaybe a simple call with the old method, and the current equivalent?\n", "Some examples are updated as well. Please check them out.\n", "Great, I just updated the examples. Many thanks.\n"]}, {"number": 2892, "title": "Branch 124994976", "body": "", "comments": []}, {"number": 2891, "title": "Cherry-picking stability and doc fixes for r0.9", "body": "This PR contains all the bug fixes I have applied to the master branch since r0.9 was forked.\n", "comments": []}, {"number": 2890, "title": "Tensorflow Session hangs when tf.Session() is created", "body": "### Environment info\n\nOperating System:\n Ubuntu 14.04\n\nInstalled version of CUDA and cuDNN: \n(\nCUDA =7.5 cuDNN=4 \n\nashwin@smile-titan:~$ ls -l /usr/local/cuda-7.5/lib64/libcud*\n-rw-r--r-- 1 root root   322936 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18\n-rwxr-xr-x 1 root root   383336 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart.so.7.5.18\n-rw-r--r-- 1 root root   720192 Aug 15  2015 /usr/local/cuda-7.5/lib64/libcudart_static.a\n-rwxr-xr-x 1 root root 61453024 Apr 20 17:27 /usr/local/cuda-7.5/lib64/libcudnn.so\n-rwxr-xr-x 1 root root 61453024 Apr 20 17:27 /usr/local/cuda-7.5/lib64/libcudnn.so.4\n-rwxr-xr-x 1 root root 61453024 Apr 20 17:27 /usr/local/cuda-7.5/lib64/libcudnn.so.4.0.7\n-rw-r--r-- 1 root root 62025862 Apr 20 17:27 /usr/local/cuda-7.5/lib64/libcudnn_static.a\n\nIf installed from binary pip package, provide:\n1. Installed tensorflow-0.9.0rc0-cp27-none-linux_x86_64.whl  (gpu support one)\n2. Tensorflow version: 0.9.0rc0\n### What have you tried?\n1. When i do \n\n```\n import  tensorflow as tf \n sess=tf.Session()\n```\n\nThe program hangs. I am not able to do exit from the program as well. It was working fine 2 weeks before. I don't know whats wrong with this. \n", "comments": ["We have no released the non-release candidate version. Could you try that version and verify the problem has not been resolved. Also could you include the results of running\n\nThe output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n", "I am facing the same problem, i am using Ubuntu 14.04 cuda 7.5\n", "@ashwin1992 did you try  the new release 0.9.0  (rather than the RC)?\n@zhaolili  did release 0.9.0 (rather than the RC) work?\n", "yes, I was using version 0.9.0\n", "BTW, I finally solved this problem by re-installing correct GPU device driver for Ubuntu 14.04.\nMy Ubuntu version is 14.04, but I mistakely installed device driver for Ubuntu 15.x. So everytime it hangs on starting tensorflow Session.\n", "Nice find @zhaolili -- I'm tempted to close this bug since it's not TensorFlow-specific, it seems.\n\n(It would be good to know if TensorFlow is somehow hitting unique bugs in the driver that others aren't, so if anyone wants to validate that other GPU software works fine before trying to update to the correct device driver, that would be useful debugging info for the future).\n"]}, {"number": 2889, "title": "Comment erroneously says output instead of input for the input_node_names.", "body": "", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n"]}, {"number": 2888, "title": "Fix negation of flags with dashes, add test.", "body": "This fixes issue #2880 by replacing dashes with underscores when adding the negated version of a boolean flag. I also added a test making sure it behaves as expected.\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks!\n\n@tensorflow-jenkins test this please\n", "@craigcitro our internal flags library doesn't do this though, so we're unlikely to ever be able to accept code into our repo that has dashes in the flag name, but I guess it's still useful for everyone else?\n", "@vrv That was my thought -- actually, flags with dashes work just fine in both cases. The only wrinkle here is that externally, we can refer to `FLAGS.name_with_dashes`, whereas internally it would only be `FLAGS['name-with-dashes'].value`. Given that there _is_ a sane way to make it work in both cases, does that seem reasonable enough?\n", "Yeah, that's what I meant -- we wouldn't be able to use code in TensorFlow that has FLAGS.name_with_dashes, and it would be a pain to convert.  I'm happy to accept this change to be more consistent with argparse, but tf code should avoid FLAGS.name_with_dashes references.\n"]}, {"number": 2887, "title": "Retrain tutorial with tensorboard", "body": "I created a script that allows running the [Inception retraining example](https://www.tensorflow.org/versions/master/how_tos/image_retraining/index.html) with TensorBoard visualizations and figured I'd submit it so others can learn from it. It's based on the [retrain.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/image_retraining/retrain.py) and [mnist_with_summaries.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/mnist/mnist_with_summaries.py) scripts.\n\nNew to submitting open source PRs so let me know if there's anything else you need from me. Thanks!\n", "comments": ["Can one of the admins verify this patch?\n", "Jenkins, test this please.\n", "Thanks for this PR!\n\nInstead of creating a separate script with summaries, could you replace the existing retrain.py with the one with summaries? This will be easier to review, and to maintain. If we have two copies of the script (one with summaries and one without) they will go out of sync, and become very confusing.\n", "Sure thing! I will make the changes and update my pull request accordingly.\n", "I updated the PR to replace the existing retrain.py with the one with summaries. Please let me know if you need anything else.\n", "Thanks @maxmelnick ! Would you mind adding a short paragraph to https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/how_tos/image_retraining/index.md explaining how to view the summaries on TensorBoard?\n\nJenkins, test this please.\n", "Jenkins, test this please.\n", "@petewarden Will do! I'll add the paragraph for using retrain.py with TensorBoard to the doc and then update my PR.\n", "@petewarden If I want to include screenshots in my update to https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/how_tos/image_retraining/index.md where would I commit them? I can't find where the existing images that are in the file are committed in the overall tensorflow repository.\n\nIf it's too complicated to include images, I can just include the text explanation. \n", "We generally don't want images in the git repository (it makes fetching the repository take longer).  I'd suggest sticking with a text description for now -- we can externally host an image-based one later if it turns out to be super helpful.\n", "Sounds good! I finished adding a section to https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/how_tos/image_retraining/index.md explaining how to view the summaries on TensorBoard and updated the PR accordingly. Thanks!\n", "Thanks for the doc updates @maxmelnick! They all look good to me.\n\nJenkins, test this please.\n", "\ud83d\udc4d Thanks @petewarden! Let me know if you need anything else from me.\n", "All good, thanks for this @maxmelnick !\n", "You're welcome! Happy to contribute \ud83d\ude04 \n", "Hi @maxmelnick ,\nThank you for your example code.\n\nWould you mind adding the option input-image are both JPEG and PNG.\nI tried to change the code but I don't get error **\"Requested return_element 'DecodePng/contents:0' not found in graph_def.\"**\nthank you,\nKhoa\n", "Hey @maxmelnick and co.,\r\nIs there an example containing also the embedding visualization?\r\nThanks!", "@argavish - I'm not aware of a version of this image retraining example that contains the embedding visualization. Maybe a good opportunity for a new pull request? \r\n\r\nAssuming you've seen this? _TensorBoard: Embedding Visualization_ https://www.tensorflow.org/get_started/embedding_viz", "Thanks @maxmelnick !\r\nYep, seen this :) \r\nWorking on it, I'll upload the script as soon as I crack it.. "]}, {"number": 2886, "title": "Branch 124956736", "body": "", "comments": []}, {"number": 2885, "title": "Tensorflow import error despite correct installation", "body": "Hi everyone!\n### Environment info\n\nOperating System: Ubuntu 16.04 LTS\nGraphics card: GTX 1080 Founders Edition\nInstalled version of CUDA: 8.0 RC\nInstalled version of cuDNN: v5 (May 27, 2016), for CUDA 8.0 RC\n\nOutput of `ls -l /usr/local/cuda/lib64/libcud*`:\n\n```\n-rw-r--r-- 1 root root   560184 juin  15 16:06 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 juin  15 16:06 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\nlrwxrwxrwx 1 root root       19 juin  15 16:06 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27\n-rwxr-xr-x 1 root root   394472 juin  15 16:06 /usr/local/cuda/lib64/libcudart.so.8.0.27\n-rw-r--r-- 1 root root   737516 juin  15 16:06 /usr/local/cuda/lib64/libcudart_static.a\n-rwxr-xr-x 1 root root 78065952 juin  15 16:10 /usr/local/cuda/lib64/libcudnn.so\n-rwxr-xr-x 1 root root 78065952 juin  15 16:10 /usr/local/cuda/lib64/libcudnn.so.5\n-rwxr-xr-x 1 root root 78065952 juin  15 16:10 /usr/local/cuda/lib64/libcudnn.so.5.0.5\n-rw-r--r-- 1 root root 68709594 juin  15 16:10 /usr/local/cuda/lib64/libcudnn_static.a\n```\n\nTensorflow installed from source, last commit hash: 7644b3dd001355bf5e3734e541d9955277447601\n## Problem\n\nWhen I open the terminal and type\n`$ python`\nand then\n`>>> import tensorflow`\nI get:\n\n```\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\nImportError: No module named tensorflow\n```\n### Steps to reproduce\n\nPerform 'installing from sources' tutorial step by step https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html#installing-from-sources for a GPU-enabled Tensorflow on Linux 64 bits\n### What have you tried?\n\n1- Re-installing step by step: no change\n2- Typing in terminal `$ bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu` returns the correct output as indicated in the tutorial\n3- Typing in terminal `$ bazel test -c opt //tensorflow/python:graph_util_test --test_output=streamed` returns \n\n```\nOK\nConverted 1 variables to const ops.\nConverted 1 variables to const ops.\nTarget //tensorflow/python:graph_util_test up-to-date:\n  bazel-bin/tensorflow/python/graph_util_test\nINFO: Elapsed time: 379.479s, Critical Path: 299.62s\n//tensorflow/python:graph_util_test                                      PASSED in 1.1s\n\nExecuted 1 out of 1 test: 1 test passes.\n```\n\n4- Adding `/home/paul/Downloads/tensorflow` to `PYTHONPATH` and then retry `import tensorflow`. This time I get:\n\n```\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/home/paul/Downloads/tensorflow/tensorflow/__init__.py\", line 23, in <module>\n    from tensorflow.python import *\n  File \"/home/paul/Downloads/tensorflow/tensorflow/python/__init__.py\", line 48, in <module>\n    from tensorflow.python import pywrap_tensorflow\nImportError: cannot import name pywrap_tensorflow\n```\n\nI don't know what else to do to make this work. Would you have an idea?\n\nThanks a lot in advance,\nPaul\n", "comments": ["Did you follow the instructions in [Create the pip package and install](https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html#create-the-pip-package-and-install)? This step is necessary for your default Python installation to be able to `import tensorflow`.\n", "Thank you Derek for your message. It was precisely because of that. Now I feel bad. Next time I'll be more careful not to skip a part of the tutorial. \nNow everything works fine, thanks to you!\n", "That's no problem - I'm glad it's working, and don't feel bad!\n", "Hi guys, i am facing the same issue but in windows? Please help me to solve", "im using ubuntu i followed the tflow doc and im still facing the same problem", "How can I install Keras after installing theano? I tried to install keras but after complitation when I am trying to import keras it shows me error: No module name tensorflow.\r\nI also changed the default backend from tensorflow to theano but still I am facing the same problem. Could you people please help me to fix it. I am working on Jetson TK1 Embedded Board and the board has some limitations of tensorflow.", "> Did you follow the instructions in [Create the pip package and install](https://www.tensorflow.org/versions/r0.9/get_started/os_setup.html#create-the-pip-package-and-install)? This step is necessary for your default Python installation to be able to `import tensorflow`.\r\n\r\nthe link is deprecated... 404 not found"]}, {"number": 2884, "title": "Enable tf.sign() for SparseTensor", "body": "Enabled `tf.neg()` for `SparseTensor`. Added tests and verified locally. This partially addresses #1828.\n", "comments": ["Can one of the admins verify this patch?\n", "Jenkins, test this please.\n"]}, {"number": 2883, "title": "iOS example DecodeJpeg issue with Image Retraining model", "body": "### Environment info\n\nOperating System: iOS\n### Steps to reproduce\n1. Follow the contrib/makefile/README to install the tensorflow iOS core lib\n2. Create my own model with the Image Retraining tutorial\n3. Run the iOS example, error is logged.\n### Logs or other output that would be helpful\n\n`Running model failed:Invalid argument: No OpKernel was registered to support Op 'DecodeJpeg' with these attrs\n    [[Node: DecodeJpeg = DecodeJpeg[acceptable_fraction=1, channels=3, fancy_upscaling=true, ratio=1, try_recover_truncated=false](DecodeJpeg/contents)]]`\n### Related to\n#2754 except that I want to use the pd file generated from the Image Retraining tutorial\n", "comments": ["Sorry you're hitting problems! Since DecodeJpeg isn't supported as part of the core, you'll need to strip it out of the graph first. I'm working on a more user-friendly approach, but you should be able to run the strip_unused script on it, something like this:\n\n```\nbazel build tensorflow/python/tools:strip_unused && \\\nbazel-bin/tensorflow/python/tools/strip_unused \\\n--input_graph=your_retrained_graph.pb \\\n--output_graph=stripped_graph.pb \\\n--input_node_names=Mul \\\n--output_node_names=final_result \\\n--input_binary=true\n```\n\nLet me know if that helps.\n", "@petewarden \nI used your strip commands. The got rid of the DecodeJpeg error. But a new error has appeared.\n`Running model failed: Not found: FeedInputs: unable to find feed output input`\n", "Great! You should just need to update the input and output layer names to \"Mul\" and \"final_result\" respectively, here:\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/ios_examples/camera/CameraExampleViewController.mm#L300\n", "Awesome! That fixed the last error, but now I'm getting:\n\n`Running model failed: Invalid argument: computed output size would be negative\n     [[Node: pool_3 = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 8, 8, 1], padding=\"VALID\", strides=[1, 1, 1, 1], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](mixed_10/join)]]`\n", "Ah yes! The input sizes need to be 299, not 224. You'll also need to change the mean and std values both to 128. Here's the code I think you'll need:\n\n```\n  const int wanted_width = 299;\n  const int wanted_height = 299;\n  const int wanted_channels = 3;\n  const float input_mean = 128.0f;\n  const float input_std = 128.0f;\n```\n\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/ios_examples/camera/CameraExampleViewController.mm#L272\n\nWe will be collecting this in proper documentation soon too, but thanks for testing this out.\n", "It worked! Thanks for all the help.\n", "Hi,\n\nI encountered the same errors and followed the suggestions. No longer getting any errors but I get the same prediction no matter what I point the camera at. What could be the problem?\n", "After going through the procedure told by Pete I am getting this result: \n\"I /Users/mohammadzulqurnain/Downloads/tensorflow-master/tensorflow/contrib/ios_examples/camera/tensorflow_utils.mm:130] Session created.\nI /Users/mohammadzulqurnain/Downloads/tensorflow-master/tensorflow/contrib/ios_examples/camera/tensorflow_utils.mm:133] Graph created.\nI /Users/mohammadzulqurnain/Downloads/tensorflow-master/tensorflow/contrib/ios_examples/camera/tensorflow_utils.mm:149] Creating session.\nW tensorflow/core/framework/op_def_util.cc:332] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().\n2016-08-07 06:17:54.548 CameraExample[7424:1747649] Received memory warning.\u201d\n\" \nAnd eventually the application crashes. Can someone help me out with this?\n Thanx in advance.\n", "Just to let folks in the future know, the above steps outlined by @petewarden well for me. I was using macOS Sierra, Xcode 8.", "worked for me as @petewarden instructions", "This is a lot of steps .. is there anything more \"baked\" / mature that is closer to working out of the box?", "petewarden's solutions work for me. There is an additional memory consumption error on iOS devices. I have added a comment here https://github.com/mortenjust/trainer-mac/issues/3 and pete talks about it more here : \r\nhttps://github.com/tensorflow/tensorflow/issues/4255", "@Zulqurnain24 The app is crashing due to apple force closing it due to the tf model taking up a lot of memory. Solution here : https://github.com/tensorflow/tensorflow/issues/4255 and ^ comment.", "Thanx @scm-ns I have followed these instructions https://petewarden.com/2016/09/27/tensorflow-for-mobile-poets/ to reduce the footprint of the graph file and now it is working fine", "Hi I follow all the steps, all the model can get the right answer using bazel, but I still get this error when I run on Android.\r\n**Inference exception: java.lang.IllegalArgumentException: computed output size would be negative\r\n                                                                                   \t [[Node: pool_3 = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 8, 8, 1], padding=\"VALID\", strides=[1, 1, 1, 1], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](mixed_10/join)]]**\r\nhelp \uff01\r\n", "I can reproduce the issue from @lxtGH \r\n\r\n```\r\njava.lang.IllegalArgumentException: computed output size would be negative\r\n[[Node: pool_3 = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 8, 8, 1], padding=\"VALID\", strides=[1, 1, 1, 1], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](mixed_10/join)]]\r\n```\r\n\r\n", "I fixed @lxtGH & @AlvarezAriel problem by running:\r\n`/tensorflow/bazel-bin/tensorflow/tools/quantization/quantize_graph --input=YOUR_STRIPPED_MODEL.pb --output_node_names=final_result --output=quantized_stripped_model.pb --mode=weights`", "Tried the quantize_graphy command by @jakublipinski to regenerate pb file. It doesn't solve 'negative output' issue in my case. \r\nI followed all instructions above. Everything works great till the log shows \"...Running model failed: Invalid argument: computed output size would be negative...\". Does the training picture size matter here?\r\n ", "I have changes All the file name and Size  , but still getting below error.\r\n\r\nSource Code  URL:\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/ios/camera\r\n\r\nChanges Code : const int wanted_input_width = 229;\r\nconst int wanted_input_height = 229;\r\nconst int wanted_input_channels = 3;\r\nconst float input_mean = 128.0f;\r\nconst float input_std = 128.0f;\r\nconst std::string input_layer_name = \"Mul\";\r\nconst std::string output_layer_name = \"final_result\";\r\n\r\ncomputed output size would be negative\r\n\t [[Node: pool_3 = AvgPool[T=DT_FLOAT, data_format=\"NHWC\", ksize=[1, 8, 8, 1], padding=\"VALID\", strides=[1, 1, 1, 1], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](mixed_10/join)]]\r\n\r\nPlease suggest what we are doing wrong .\r\nIn build pb and txt are working fine (imagenet_comp_graph_label_strings.txt, tensorflow_inception_graph.pb)\r\n\r\nbut created new pb and .txt is not working(rounded_graph.pb and retrained_labels.txt).\r\nNote:  I also rename the pb and txt file , \r\n", "@petewarden I used tf.image.decode_jpeg to read in images while training my model. I want to deploy my model on android. Since this decode_jpeg is not available on android, is there an alternate solution using opencv or other java libraries. The pixel values are different when I read in the input image using decode_jpeg compared to opencv. This results in the logits being different for the same image. How can I have the same behaviour on android?"]}, {"number": 2882, "title": "TensorFlow cannot detect my GPU", "body": "I have a Ubuntu 14.04.4 with Titan X, cuda 7.5 and cudnn v4\n\ncuda 7.5 was installed by a run file, just like I used to installed Caffe.\nEnvironment variables have been added to /etc/profile  and ~/.bashrc \nA file named cuda.conf have been added to /etc/ld.so.conf.d/ \n\nI installed TensorFlow via pip, using the following command:\n\n$ sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl\n\nI followed the install instruction carefully, but I still met some issues.\n\n'>>> import tensorflow as tf\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally`\n\n`>>> sess = tf.Session()\n\nE tensorflow/stream_executor/cuda/cuda_driver.cc:481] failed call to cuInit: CUDA_ERROR_UNKNOWN\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:114] retrieving CUDA diagnostic information for host: DeepLearning\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:121] hostname: DeepLearning\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:146] libcuda reported version is: 352.79\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:257] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  352.79  Wed Jan 13 16:17:53 PST 2016\nGCC version:  gcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04.3) \n\"\"\"\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:150] kernel reported version is: 352.79\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:226] kernel version seems to match DSO: 352.79\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU devices available on machine.`\n\nIt seems that TensorFlow cannot find my GPU.\nI have no idea why these issues occur.\nPlease help, thanks \n", "comments": ["Could you run \"nvidia-smi\" and report back what GPU is available? \n\nTensorFlow successfully load alll the Cuda libraries. But failed to find any GPU. We need to make sure GPUs are actually visible there. \n", "@zheng-xq Here is my report\n`+------------------------------------------------------+  \n| NVIDIA-SMI 352.79     Driver Version: 352.79         |  \n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  GeForce GTX TIT...  Off  | 0000:01:00.0      On |                  N/A |\n| 22%   50C    P8    28W / 250W |    272MiB / 12287MiB |      8%      Default |\n+-------------------------------+----------------------+----------------------+\n\n+-----------------------------------------------------------------------------+\n| Processes:                                                       GPU Memory |\n|  GPU       PID  Type  Process name                               Usage      |\n|=============================================================================|\n|    0      1161    G   /usr/bin/X                                     155MiB |\n|    0      1917    G   compiz                                          90MiB |\n+-----------------------------------------------------------------------------+`\n", "@zheng-xq I managed to solve this issuse.\nI happened to run `$sudo ldconfig`,  and the terminal prompted  me that 'libcudnn.so' is not a valid symbolic link, although I followed the install instruction step by step.\nSo I deleted and reinstalled CUDNN in my own way.\nAt this time, tensorflow works correctly.\nThanks all the same.\nHave a nice day.\n\ns = tf.Session()\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:900] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: GeForce GTX TITAN X\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.076\npciBusID 0000:01:00.0\nTotal memory: 12.00GiB\nFree memory: 11.67GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:01:00.0)\n", "@yyyreal I am having the same problem with CUDA 8.0 and cudnn v5. Can you tell a bit more detail on how you were able to solve it? Thanks a ton!", "@rajiv235 I reinstalled my cudnn library and  authorized right permission to .a and .so.5.1.5 files. Please double check you soft links.", "Hi @yyyreal  -- I'm having the same problems!! It's driving me nuts.\r\n\r\nCould you post the correct permissions to the files you listed ?(\"I reinstalled my cudnn library and authorized right permission to .a and .so.5.1.5 files. \")\r\n\r\nThanks!!", "I'm on Mac OS X 10.11.6.  Installed CUDA 8, and CUDNN 5.1.  I've followed the install instructions from official TF site. (as of Jan 23, 2017)\r\n\r\n**Any idea how to resolve this??**  Any help appreciated!! Thanks!\r\n\r\nI'm getting this error: \r\n**\"libcuda reported version is: 310.42.25;  kernel reported version is: Invalid argument: expected %d.%d or %d.%d.%d form for driver version; got \"\"**\r\n\r\n```\r\n>>> sess = tf.Session()\r\nE tensorflow/stream_executor/cuda/cuda_driver.cc:509] failed call to cuInit: CUDA_ERROR_NO_DEVICE\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:158] retrieving CUDA diagnostic information for host: Atuls-MBP\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:165] hostname: Atuls-MBP\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] libcuda reported version is: 310.42.25\r\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:193] kernel reported version is: Invalid argument: expected %d.%d or %d.%d.%d form for driver version; got \"\"\r\n\r\n```\r\n\r\nWhen I run deviceQuery: this is what I get:\r\n```\r\n./deviceQuery \r\n./deviceQuery Starting...\r\n\r\n CUDA Device Query (Runtime API) version (CUDART static linking)\r\n\r\ncudaGetDeviceCount returned 38\r\n-> no CUDA-capable device is detected\r\nResult = FAIL\r\n\r\n```\r\n\r\nMy CUDA Driver: (from Apple > System Preferences > CUDA)\r\n```\r\nCUDA Driver Version: 8.0.57\r\nGPU Driver Version: 10.10.14 310.42.25f02\r\n```\r\n\r\nMy env vars:\r\n```\r\necho $CUDA_HOME \r\n/usr/local/cuda\r\n py35 \u25b6 ~ \u25b6 Developer \u276f \u2026 \u276f x86_64 \u276f darwin \u276f release \u25b6 $ \u25b6 \r\n py35 \u25b6 ~ \u25b6 Developer \u276f \u2026 \u276f x86_64 \u276f darwin \u276f release \u25b6 $ \u25b6 echo $DYLD_LIBRARY_PATH \r\n:/usr/local/cuda/lib:\r\n\r\nuname -a \r\nDarwin Atuls-MBP 15.6.0 Darwin Kernel Version 15.6.0: Thu Sep  1 15:01:16 PDT 2016; root:xnu-3248.60.11~2/RELEASE_X86_64 x86_64\r\n```\r\n", "@yyyreal @laventura I was able to solve this issue. I did the following:\r\n1. updated the CUDA driver to 367.57\r\n2. Installed CUDA 8.0 toolkit and CUDNN 5.1. Make sure to use -R with cp while copying cudnn library to cuda-8.0\\lib64. Need to reboot after this. Check with nvidia-smi if proper drivers are installed and CUDA device is detected.\r\n3. Follow http://expressionflow.com/2016/10/09/installing-tensorflow-on-an-aws-ec2-p2-gpu-instance/ for tensorflow installation. (Note the newer version of tensorflow would require bazel 0.42(not 0.32 as mentioned in the post.) I used installer for bazel which worked fine.\r\n\r\nAfter this TF should work with GPU. ", "@rajiv235 -- Thanks.  Your setup is Ubuntu I think.\r\n\r\nI'm on Mac OS X 10.11.6.\r\n\r\nI'm trying to see how to upgrade the existing GPU driver (reported from Apple > System Preferences > CUDA)\r\n\r\n`GPU Driver Version: 10.10.14 310.42.25f02`\r\n\r\nMaybe that's the source of the problem?? I dunno. \ud83d\ude29\ud83d\ude29\r\n", "@laventura, most likely your GPU is disabled. Install gfxCardStatus, switch to Discrete Only and try again."]}, {"number": 2881, "title": "Qualify references with @org_tensorflow to make function importable", "body": "Qualify references with @org_tensorflow to make function importable by other workspaces\n\nE.g. by syntaxnet which uses this function.\n\nI have signed CLA with Cobite, INC. but googlebot is confused.\n", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "Can one of the admins verify this patch?\n", "I signed it! Company is Cobite, INC.  If I visit linked page (check your CLA) it's not listed, but when I fill out the form (again) and submit it says it's already been signed.  Not sure what's up.\n", "CLAbot can be slow with company CLAs, don't worry about it. \n", "The approach used in the PR doesn't work in practice.  See a this stack overflow which asks the generic question about how to solve: http://stackoverflow.com/questions/37884031/how-to-write-a-bazel-select-macro-that-works-inside-or-outside-of-defining-works\n\n(Also, the email address in the commit was wrong, causing additional problems for CLAbot, which, BTW, did go through! eventually).\n\nI'll submit a different PR once a more robust solution has been found.\n", "Turns out the code is probably correct, but Bazel is buggy.  See:  https://github.com/bazelbuild/bazel/issues/1425\n"]}, {"number": 2880, "title": "tf.flags.DEFINE_boolean is broken for flags containing dashes", "body": "`tf.flags.DEFINE_boolean` does not replace dashes with underscores when adding the negated flag, which results in a bug for flags containing dashes.\n### Environment info\n\nOperating System: Mac OSX 10.11.5\nPip Package: https://storage.googleapis.com/tensorflow/mac/tensorflow-0.9.0rc0-py3-none-any.whl\nTensorFlow Version: 0.9.0rc0\n### Steps to reproduce\n- `foo.py`:\n\n``` python\nimport tensorflow as tf\n\ntf.flags.DEFINE_boolean('foo-bar', True, \"Foo Bar\")\ntf.flags.FLAGS._parse_flags()\nprint(tf.flags.FLAGS.__flags)\n```\n### What have you tried?\n- `$ python foo.py`: `{'foo_bar': True, 'foo-bar': True}`\n- `$ python foo.py --foo-bar`: `{'foo_bar': True, 'foo-bar': True}`\n- `$ python foo.py --nofoo-bar`: `{'foo_bar': True, 'foo-bar': False}`\n\nIn the last example it is impossible to get the False value of the flag, `tf.flags.FLAGS.foo-bar` results in an AttributeError, because the dash is interpreted as a minus and `FLAGS.foo` does not exist.\n\nIn order to support flags with dashes, Python's argparse replaces dashes with underscores ([docs](https://docs.python.org/dev/library/argparse.html#dest), [code](https://github.com/python/cpython/blob/master/Lib/argparse.py#L1471)).\n\nFixing this bug should be as simple as substituting `flag_name` with `flag_name.replace('-', '_')` in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/platform/flags.py#L106, but I haven't tested this yet.\n", "comments": ["@jdoerrie Yep, good catch. Would you have time to send a PR?\n", "I'm not quite sure whether referencing an issue triggers a notification, but I created a PR in the meantime. @craigcitro could you have a look at it when you get the chance? \n", "This should be fixed by #2888.\n"]}, {"number": 2879, "title": "tensorflow_learn", "body": "\u5b66\u4e60tensorflow \u6e90\u7801\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "it is wrong\n"]}, {"number": 2878, "title": "Hard-code libcuda version number to \"1\". Fixes #2865.", "body": "As per comments from nvidia-docker dev @3XX0, hardcoding \"1\" should be\nreasonably safe. The TF_CUDA_VERSION variable from the configure script\nis not appropriate here (it will contain something like \"7.0\" or \"7.5\",\nwhile the libcuda soname major version number should be \"1\").\n", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins test this please\n", "Was this change ever applied to the r0.9 branch?\n\nIt looks like, no:\n\n```\ngit merge-base --is-ancestor f45874b4a969a60fa9ced86e6769012e4912b5ca cbfd2787e8a4d539b813203b900ab3d6dca2fec4 ; echo $?\n1\n```\n", "I don't think so. But it should be in the r0.10 branch\n", "Would it be possible to get this cherry picked over? The checked in Dockerfiles (in master) still build against the r0.9 branch\n", "Sure, can you make a PR?\n", "done: https://github.com/tensorflow/tensorflow/pull/3576\n"]}, {"number": 2877, "title": "eigen_spatial_convolutions.h: reading of uninitialized variable 'k'", "body": "It appears that `k` is not initialized before being read below. From eigen_spatial_convolutions.h:848:\n\n```\n       for (Index k; k < depth; k++) {\n          block[0] = dm0.loadCoeffStandard(k);\n          block[1] = dm1.loadCoeffStandard(k);\n          block[2] = dm2.loadCoeffStandard(k);\n          block[3] = dm3.loadCoeffStandard(k);\n          block += 4;\n        }\n      } else {\n        for (Index k; k < depth; k++) {\n          block[0] = dm0(k);\n...\n```\n\nAm I missing something here?\n", "comments": ["@benoitsteiner seems like you fixed this in 406db8835d656540c96f69e9ac565ef8c22be3d1. This can be closed now.\n", "Indeed\n"]}, {"number": 2876, "title": "Branch 124906347", "body": "", "comments": ["Jenkins, test this please.\n"]}, {"number": 2875, "title": "Deprecated contrib.learn.ops.conv2d", "body": "", "comments": []}, {"number": 2874, "title": "FixedLenFeature with dimensions of unknown size fails with strange error", "body": "``` python\nimport tensorflow as tf\n\nexample = tf.train.Example(\n  features=tf.train.Features(\n    feature={'a': tf.train.Feature(int64_list=tf.train.Int64List(value=[1]))}))\nserialized = example.SerializeToString()\nfeatures = {'a': tf.FixedLenFeature([None], tf.int64)}\nparsed = tf.parse_single_example(serialized, features)\n```\n\n```\n>>> parsed\n{'a': <tf.Tensor 'ParseSingleExample_5/Squeeze_a:0' shape=(?,) dtype=int64>}\n>>> parsed['a'].eval()\nInvalidArgumentError: Shape [-1] has negative dimensions\n```\n\nIt would be nice to get an informative `ValueError` at graph construction time.\n", "comments": ["Closing this since the code might have change substantially around this. Feel free to open a new issue if the problem persists with new code."]}, {"number": 2873, "title": "Perform CUDA autoconfiguration in Skylark", "body": "Moving the CUDA autoconfiguration to a Skylark repository rule, similar to Bazel's [`cc_configure`](https://github.com/bazelbuild/bazel/blob/master/tools/cpp/cc_configure.bzl), will fix many pain points and build issues that have been reported. This will also eventually allow projects such as Serving and Magenta to include TensorFlow as a Bazel workspace dependency rather than a Git submodule.\n\nRelated to this is moving Python detection to a Skylark repository rule (see #1404).\n\nInternal tracking bug: b/29006900\n", "comments": []}, {"number": 2872, "title": "Deprecated contrib.learn.ops.batch_normalize", "body": "cc: @ilblackdragon @martinwicke I'll probably do similar thing for some other ops (different PRs) if you think this approach is ok. \n", "comments": ["@tensorflow-jenkins Test this please\n", "@benoitsteiner Error seems unrelated. Seems to have some flaky tests?\n", "@tensorflow-jenkins Test this please\n", "We've been mulling a decorator. It takes a message and adds a logging.warning(\"This function (%s, %s:%d) is deprecated. %s\", name, file, line, message) when the function/method is called. It can also add a warning to the beginning of the docstring. \n\nWe could have another one for classes. \n\nWe will use them a fair bit I feel. \n\nI sent this via email, but it seems it didn't make it.\n", "@martinwicke Thanks. Then I'll make changes later when that decorator is available. This PR should be ok, right? Some tests failed in other unrelated place. \n", "I think it's ok.\nOn Wed, Jun 15, 2016 at 12:34 Yuan (Terry) Tang notifications@github.com\nwrote:\n\n> @martinwicke https://github.com/martinwicke Thanks. Then I'll make\n> changes later when that decorator is available. This PR should be ok,\n> right? Some tests failed in other unrelated place.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/2872#issuecomment-226295520,\n> or mute the thread\n> https://github.com/notifications/unsubscribe/AAjO_UrOTNSHkYsNVuPJbjhpPoJIlUwSks5qMFOlgaJpZM4I15uS\n> .\n", "Ping @benoitsteiner required tests passed\n", "The one test failure is due to a known preexisting problem with the png decoder. I'll merge this PR.\n"]}, {"number": 2871, "title": "Make sure that concat complains about concat_dim < 0", "body": "`tf.concat` already checks whether `concat_dim` is too large for\nthe provided arguments at graph construction (if that's possible), but it\nshould also make sure that `concat_dim >= 0`.\n\nThis fixes #2868.\n", "comments": ["Can one of the admins verify this patch?\n", "A very simple test to exercise this code path would be great!\n", "Woohoo!  Thanks.  @tensorflow-jenkins test this please\n", "@tensorflow-jenkins test this please\n"]}, {"number": 2870, "title": "Update README.md", "body": "Fix for the Deep Neural Network example in tensorflow/contrib/learn/python/learn/README.md\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "Jenkins, test this please.\n"]}, {"number": 2869, "title": "Added iOS CI build script", "body": "", "comments": ["Jenkins, test me please.\n", "Jenkins, test this please.\n"]}, {"number": 2868, "title": "tf.concat(-1, list_of_tensors) should fail at graph build time, not eval time", "body": "Instead it gives an erroneous result:\n\n```\n>>> tf.concat(-1, [tf.range(3), tf.range(3)])\n<tf.Tensor 'concat_2:0' shape=(6, 3) dtype=int32>\n```\n\nWhen you run `.eval()` you get the expected error message:\n`InvalidArgumentError: ConcatOp : Expected concatenating dimensions in the range [0, 1), but got -1`\n\nOf course, it would be even better if negative indices counted axes from the end (like in NumPy), but that's a different matter...\n", "comments": ["Nice catch!\nThe problem is that it's only tested whether the concatenation axis is too large (`>= ndims`) here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/array_ops.py#L530\nThis also needs to test for `concat_dim < 0`.\n", "I've submitted a PR that adds the missing check.\n"]}, {"number": 2867, "title": "Support size 0 tensors with parse_example and parse_single_example", "body": "Currently, this fails `InvalidArgumentError: Name: <unknown>, Feature: a is required but could not be found.`:\n\n```\nimport tensorflow as tf\nsess = tf.InteractiveSession()\n\nfeatures = {'a': tf.FixedLenFeature([0], tf.int64, [])}\nserialized = tf.placeholder(tf.string, [])\nparsed = tf.parse_single_example(serialized, features)\n\nexample_str = tf.train.Example().SerializeToString()\nsess.run(parsed['a'], feed_dict={serialized: example_str})\n```\n\n(The same is true for `tf.parse_example`.)\n\nThis sort of thing may seem useless, but can be handy for writing generic code that handles variable sized input (with fixed size for each graph).\n", "comments": ["This is definitely useful.  Are you interested in piping this through the parser library?\n", "Automatically closing due to lack of recent activity. Thanks!"]}, {"number": 2866, "title": "Revert \"Logistic regression weights: Using a `tf.Tensor` as a Python `bool` is not allowed\"", "body": "Reverts tensorflow/tensorflow#2757 because check is the reverse.\n", "comments": []}]