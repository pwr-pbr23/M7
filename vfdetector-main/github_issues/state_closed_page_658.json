[{"number": 33869, "title": "How to save model, multi-worker training with Keras ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary):  binary\uff08pip install tensorflow-gpu\uff09\r\n- TensorFlow version (use command below):  2.0.0\r\n- Python version: 3.7.4\r\n- CUDA/cuDNN version:  CUDA-10.0/cuDNN 7 \r\n- GPU model and memory: 1X1080TI+2X1070Ti    11GB   8GB\r\n\r\n**Describe the current behavior**\r\nFailure to save model\r\n\r\n**Describe the expected behavior**\r\nSave model\r\n\r\n**Code to reproduce the issue**\r\n`\r\n\r\n    # multi worker strategy\r\n    strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\r\n    with strategy.scope():\r\n        train_dataset, validation_dataset, test_dataset = load_data()\r\n        multi_worker_model = Alexnet()\r\n        multi_worker_model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\r\n                                   optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2),\r\n                                   metrics=['accuracy'])\r\n    # fit\r\n    multi_worker_model.fit(train_dataset,\r\n                           epochs=EPOCHS,\r\n                           validation_steps=6,\r\n                           validation_data=validation_dataset,\r\n                           steps_per_epoch=45000//BATCH_SIZE,\r\n                           callbacks=callbacks,\r\n                           verbose=2)\r\n\r\n    # eval\r\n    multi_worker_model.evaluate(test_dataset)\r\n\r\n    # save model\r\n    # multi_worker_model.save(os.path.join(OUTPUT_PATH, 'model'))\r\n    tf.saved_model.save(multi_worker_model, os.path.join(OUTPUT_PATH, 'model'))\r\n`\r\n**Other info / logs**\r\nTraceback (most recent call last):\r\n  File \"training_cifar10_with_multi-woker.py\", line 197, in <module>\r\n    tf.saved_model.save(multi_worker_model, os.path.join(OUTPUT_PATH, 'model'))\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py\", line 893, in save\r\n    meta_graph_def, saveable_view, signatures, options.namespace_whitelist)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py\", line 596, in _fill_meta_graph_def\r\n    saver_def = saver.to_proto()\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saving/functional_saver.py\", line 150, in to_proto\r\n    save_tensor = self._traced_save(filename_tensor)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 457, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 503, in _call\r\n    self._initialize(args, kwds, add_initializers_to=initializer_map)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 408, in _initialize\r\n    *args, **kwds))\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1848, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2150, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2041, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\", line 915, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 358, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2653, in bound_method_wrapper\r\n    return wrapped_fn(weak_instance(), *args, **kwargs)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saving/functional_saver.py\", line 162, in _traced_save\r\n    save_op = self.save(file_prefix)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saving/functional_saver.py\", line 230, in save\r\n    sharded_saves.append(saver.save(shard_prefix))\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saving/functional_saver.py\", line 69, in save\r\n    tensors.append(spec.tensor)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saving/saveable_object.py\", line 52, in tensor\r\n    return self._tensor() if callable(self._tensor) else self._tensor\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/values.py\", line 1151, in tensor\r\n    return strategy.extended.read_var(sync_on_read_variable)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/mirrored_strategy.py\", line 736, in read_var\r\n    return replica_local_var._get_cross_replica()  # pylint: disable=protected-access\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/values.py\", line 1237, in _get_cross_replica\r\n    self, axis=None)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 805, in reduce\r\n    return self._extended._reduce(reduce_op, value)  # pylint: disable=protected-access\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 1436, in _reduce\r\n    device_util.current() or \"/device:CPU:0\"))[0]\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/collective_all_reduce_strategy.py\", line 490, in _reduce_to\r\n    reduce_op, value, destinations=destinations)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/cross_device_ops.py\", line 282, in reduce\r\n    destinations)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/cross_device_ops.py\", line 1025, in reduce_implementation\r\n    all_reduced = self._batch_all_reduce(reduce_op, [per_replica_value])[0]\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/cross_device_ops.py\", line 1091, in _batch_all_reduce\r\n    dense_results = self._do_batch_all_reduce_dense(reduce_op, dense_values)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/cross_device_ops.py\", line 1120, in _do_batch_all_reduce_dense\r\n    \"Id\")\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/cross_device_utils.py\", line 345, in build_collective_reduce\r\n    group_key = collective_keys.get_group_key(devices)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/cross_device_utils.py\", line 295, in get_group_key\r\n    names = sorted(['%s:%d' % (d.device_type, d.device_index) for d in parsed])\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/cross_device_utils.py\", line 295, in <listcomp>\r\n    names = sorted(['%s:%d' % (d.device_type, d.device_index) for d in parsed])\r\nTypeError: %d format: a number is required, not NoneType\r\n", "comments": ["@aefuimn Can you provide a standalone code to reproduce the issue? Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33869\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33869\">No</a>\n", "> @aefuimn Can you provide a standalone code to reproduce the issue? Thanks!\r\n\r\n```python\r\n# -*- coding: utf-8 -*-\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\n\r\nimport os\r\nimport json\r\nimport pickle\r\nimport tensorflow as tf\r\n\r\nos.environ['TF_CONFIG'] = json.dumps({\r\n    'cluster': {\r\n        'worker': ['10.10.2.37:12345', '10.10.2.38:12345']\r\n    },\r\n    'task': {'type': 'worker', 'index': 0}\r\n})\r\n\r\n\r\ndef image_enhancement(image, label):\r\n    image = tf.dtypes.cast(image, tf.dtypes.float32)\r\n    image = tf.reshape(image, [3, 32, 32])\r\n    image = tf.transpose(image, [1, 2, 0])\r\n\r\n    # image = tf.image.random_crop(image, [28, 28, 3])\r\n    image = tf.image.random_flip_left_right(image)\r\n    image = tf.image.random_brightness(image, max_delta=63)\r\n    image = tf.image.random_contrast(image, lower=0.2, upper=1.8)\r\n    image = tf.image.per_image_standardization(image)\r\n    return image, label\r\n\r\n\r\ndef test_image(image, label):\r\n    image = tf.dtypes.cast(image, tf.dtypes.float32)\r\n    image = tf.reshape(image, [3, 32, 32])\r\n    image = tf.transpose(image, [1, 2, 0])\r\n    image = tf.image.per_image_standardization(image)\r\n    return image, label\r\n\r\n\r\ndef load_data():\r\n    train_data = {b'data': [], b'labels': []}\r\n\r\n    for i in range(5):\r\n        with open(\"cifar-10-batches-py/data_batch_\" + str(i+1), mode='rb') as f:\r\n            data = pickle.load(f, encoding=\"bytes\")\r\n            train_data[b'data'] += list(data[b'data'])\r\n            train_data[b'labels'] += data[b'labels']\r\n\r\n    with open(\"cifar-10-batches-py/test_batch\", mode='rb') as file:\r\n        test_data = pickle.load(file, encoding='bytes')\r\n\r\n    train_ds = tf.data.Dataset.from_tensor_slices(\r\n        (train_data[b'data'][:45000], train_data[b'labels'][:45000]))\r\n    train_ds = train_ds.map(image_enhancement, num_parallel_calls=10)\r\n    train_ds = train_ds.shuffle(10000).batch(BATCH_SIZE).repeat()\r\n    validation_ds = tf.data.Dataset.from_tensor_slices(\r\n        (train_data[b'data'][45000:], train_data[b'labels'][45000:]))\r\n    validation_ds = validation_ds.map(image_enhancement, num_parallel_calls=10)\r\n    validation_ds = validation_ds.batch(BATCH_SIZE)\r\n    test_ds = tf.data.Dataset.from_tensor_slices((test_data[b'data'], test_data[b'labels']))\r\n    test_ds = test_ds.map(test_image, num_parallel_calls=10)\r\n    test_ds = test_ds.batch(BATCH_SIZE)\r\n    return train_ds, validation_ds, test_ds\r\n\r\n\r\nclass Alexnet(tf.keras.Model):\r\n    def __init__(self):\r\n        super(Alexnet, self).__init__()\r\n        self.conv1 = tf.keras.layers.Conv2D(64, 3, activation='relu', name='conv1')\r\n        self.conv2 = tf.keras.layers.Conv2D(128, 3, activation='relu', name='conv2')\r\n        self.conv3 = tf.keras.layers.Conv2D(256, 3, activation='relu', name='conv3')\r\n        self.pool1 = tf.keras.layers.MaxPool2D(2, 2, name='pool1')\r\n        self.pool2 = tf.keras.layers.MaxPool2D(2, 2, name='pool2')\r\n        self.pool3 = tf.keras.layers.MaxPool2D(2, 2, name='pool3')\r\n        self.batch_normalization1 = tf.keras.layers.BatchNormalization(name='bn1')\r\n        self.batch_normalization2 = tf.keras.layers.BatchNormalization(name='bn2')\r\n        self.batch_normalization3 = tf.keras.layers.BatchNormalization(name='bn3')\r\n        self.flatten = tf.keras.layers.Flatten(name='f1')\r\n        self.dropout = tf.keras.layers.Dropout(0.5)\r\n        self.d1 = tf.keras.layers.Dense(1024, activation='relu', name='d1')\r\n        self.d2 = tf.keras.layers.Dense(512, activation='relu', name='d2')\r\n        self.d3 = tf.keras.layers.Dense(256, activation='relu', name='d3')\r\n        self.d4 = tf.keras.layers.Dense(10, activation='softmax', name='out')\r\n\r\n    def call(self, x):\r\n        # conv1\r\n        x = self.conv1(x)\r\n        x = self.pool1(x)\r\n        x = self.batch_normalization1(x)\r\n\r\n        # conv2\r\n        x = self.conv2(x)\r\n        x = self.pool2(x)\r\n        x = self.batch_normalization2(x)\r\n\r\n        # conv3\r\n        x = self.conv3(x)\r\n        x = self.pool3(x)\r\n        x = self.batch_normalization3(x)\r\n\r\n        # Flatten\r\n        x = self.flatten(x)\r\n        x = self.dropout(x)\r\n\r\n        # Dense\r\n        x = self.d1(x)\r\n        x = self.d2(x)\r\n        x = self.d3(x)\r\n        return self.d4(x)\r\n\r\n\r\ndef decay(epoch):\r\n    if epoch < 30:\r\n        return 1e-2\r\n    elif epoch >= 30 and epoch < 50:\r\n        return 5e-3\r\n    elif epoch >= 50 and epoch < 80:\r\n        return 1e-3\r\n    elif epoch >= 80 and epoch < 120:\r\n        return 1e-4\r\n    else:\r\n        return 1e-5\r\n\r\n\r\nclass PrintLR(tf.keras.callbacks.Callback):\r\n    def on_epoch_end(self, epoch, logs=None):\r\n        print('\\nLearning rate for epoch {} is {}'.format(epoch + 1,\r\n                                                          multi_worker_model.optimizer.lr.numpy()))\r\n\r\n\r\nif __name__ == \"__main__\":\r\n\r\n    BATCH_SIZE_PER_WORKER = 384\r\n    NUM_WORKERS = 2\r\n    BATCH_SIZE = BATCH_SIZE_PER_WORKER * NUM_WORKERS\r\n    OUTPUT_PATH = '/home/output'\r\n    EPOCHS = 2\r\n\r\n    checkpoint_dir = os.path.join(OUTPUT_PATH, 'train_checkpoints')\r\n    checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\r\n\r\n    callbacks = [\r\n        tf.keras.callbacks.TensorBoard(log_dir=os.path.join(OUTPUT_PATH, 'logs')),\r\n        tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\r\n                                           save_weights_only=True),\r\n        tf.keras.callbacks.LearningRateScheduler(decay),\r\n        PrintLR()\r\n    ]\r\n\r\n    strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\r\n\r\n    with strategy.scope():\r\n        train_dataset, validation_dataset, test_dataset = load_data()\r\n        multi_worker_model = Alexnet()\r\n        multi_worker_model.compile(loss=tf.keras.losses.sparse_categorical_crossentropy,\r\n                                   optimizer=tf.keras.optimizers.Adam(learning_rate=1e-2),\r\n                                   metrics=['accuracy'])\r\n\r\n    multi_worker_model.fit(train_dataset,\r\n                           epochs=EPOCHS,\r\n                           validation_steps=6,\r\n                           validation_data=validation_dataset,\r\n                           steps_per_epoch=45000//BATCH_SIZE,\r\n                           callbacks=callbacks,\r\n                           verbose=2)\r\n\r\n    multi_worker_model.evaluate(test_dataset)\r\n\r\n    multi_worker_model.save(os.path.join(OUTPUT_PATH, 'model'))\r\n```\r\nThe dataset is cifar-10-batches-py", "I think this should be fixed by https://github.com/tensorflow/tensorflow/commit/c82df39b0cfd6fee460c1e942a3322061bc6f8bb#diff-39620d083041d43ea80ef9ef7246652b which was committed couple days ago.\r\n\r\nAre you able to test with a nightly version of tensorflow (https://pypi.org/project/tf-nightly-gpu/)", "> I think this should be fixed by [c82df39#diff-39620d083041d43ea80ef9ef7246652b](https://github.com/tensorflow/tensorflow/commit/c82df39b0cfd6fee460c1e942a3322061bc6f8bb#diff-39620d083041d43ea80ef9ef7246652b) which was committed couple days ago.\r\n> \r\n> Are you able to test with a nightly version of tensorflow (https://pypi.org/project/tf-nightly-gpu/)\r\n\r\nThis error occurred in my code on TF version 2.1.0-dev20191110\r\n```log\r\n[[{{node IteratorGetNext}}]]\r\n2019-11-11 14:08:07.039360: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\r\n\t [[{{node IteratorGetNext_1}}]]\r\n\t [[replica_1/metrics/accuracy/AssignAddVariableOp_1/_53]]\r\n2019-11-11 14:08:07.039467: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\r\n\t [[{{node IteratorGetNext_1}}]]\r\n\t [[allreduce_1/CollectiveReduce/_56]]\r\n2019-11-11 14:08:07.039615: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Out of range: End of sequence\r\n     14/Unknown - 1s 59ms/step - loss: 2.7934 - accuracy: 0.16942019-11-11 14:08:07.871879: W tensorflow/python/util/util.cc:319] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\r\nW1111 14:08:08.245472 140200689571584 deprecation.py:506] From /home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nIf using Keras pass *_constraint arguments to layers.\r\n2019-11-11 14:08:08.564973: E tensorflow/core/common_runtime/ring_alg.cc:279] Aborting RingReduce with Out of range: [_Derived_]End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n2019-11-11 14:08:08.564980: E tensorflow/core/common_runtime/ring_alg.cc:279] Aborting RingReduce with Out of range: [_Derived_]End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n2019-11-11 14:08:08.565051: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Out of range: [_Derived_]End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n2019-11-11 14:08:08.565059: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Out of range: [_Derived_]End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n2019-11-11 14:08:08.565173: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at collective_ops.cc:253 : Out of range: [_Derived_]End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n2019-11-11 14:08:08.565190: E tensorflow/core/common_runtime/ring_alg.cc:279] Aborting RingReduce with Out of range: [_Derived_]End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n2019-11-11 14:08:08.565219: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Out of range: [_Derived_]End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n2019-11-11 14:08:08.565174: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at collective_ops.cc:253 : Out of range: [_Derived_]End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n2019-11-11 14:08:08.565231: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Out of range: [_Derived_]End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n\t [[CollectiveReduce]]\r\n2019-11-11 14:08:08.565261: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at collective_ops.cc:253 : Out of range: [_Derived_]End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n2019-11-11 14:08:08.565324: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Out of range: [_Derived_]End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n\t [[CollectiveReduce_2]]\r\n2019-11-11 14:08:08.565374: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Out of range: [_Derived_]End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n\t [[CollectiveReduce_1]]\r\nTraceback (most recent call last):\r\n  File \"training_cifar10_with_multi-woker.py\", line 196, in <module>\r\n    multi_worker_model.save(os.path.join(OUTPUT_PATH, 'model'))\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/network.py\", line 1008, in save\r\n    signatures, options)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py\", line 115, in save_model\r\n    signatures, options)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/saved_model/save.py\", line 78, in save\r\n    save_lib.save(model, filepath, signatures, options)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/saved_model/save.py\", line 920, in save\r\n    object_saver.save(utils_impl.get_variables_path(export_dir))\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/util.py\", line 1168, in save\r\n    file_prefix=file_prefix_tensor, object_graph_tensor=object_graph_tensor)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/util.py\", line 1116, in _save_cached_when_graph_building\r\n    save_op = saver.save(file_prefix)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saving/functional_saver.py\", line 230, in save\r\n    sharded_saves.append(saver.save(shard_prefix))\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saving/functional_saver.py\", line 69, in save\r\n    tensors.append(spec.tensor)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/training/saving/saveable_object.py\", line 52, in tensor\r\n    return self._tensor() if callable(self._tensor) else self._tensor\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/values.py\", line 1252, in tensor\r\n    return strategy.extended.read_var(sync_on_read_variable)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/mirrored_strategy.py\", line 763, in read_var\r\n    return replica_local_var._get_cross_replica()  # pylint: disable=protected-access\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/values.py\", line 1347, in _get_cross_replica\r\n    self, axis=None)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 808, in reduce\r\n    return self._extended._reduce(reduce_op, value)  # pylint: disable=protected-access\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/distribute_lib.py\", line 1449, in _reduce\r\n    device_util.current() or \"/device:CPU:0\"))[0]\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/collective_all_reduce_strategy.py\", line 528, in _reduce_to\r\n    reduce_op, value, destinations=destinations)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/cross_device_ops.py\", line 282, in reduce\r\n    destinations)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/cross_device_ops.py\", line 1038, in reduce_implementation\r\n    all_reduced = self._batch_all_reduce(reduce_op, [per_replica_value])[0]\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/cross_device_ops.py\", line 1118, in _batch_all_reduce\r\n    dense_results = self._do_batch_all_reduce_dense(reduce_op, dense_values)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/cross_device_ops.py\", line 1160, in _do_batch_all_reduce_dense\r\n    \"Id\", communication_hint)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/distribute/cross_device_utils.py\", line 368, in build_collective_reduce\r\n    return collective_all_reduce()\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 568, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 638, in _call\r\n    return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1589, in _filtered_call\r\n    self.captured_inputs)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1670, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 523, in call\r\n    ctx=ctx)\r\n  File \"/home/ubuntu/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\", line 67, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.OutOfRangeError:  [_Derived_]End of sequence\r\n\t [[{{node IteratorGetNext}}]]\r\n\t [[CollectiveReduce]] [Op:__inference_collective_all_reduce_11819]\r\n```\r\nI upgraded my cuda, now:\r\ncuda version: 10.1\r\ncudnn version: 7.6.5.32-1+cuda10.1\r\nlibnvinfer version: 6.0.1-1+cuda10.1\r\n", "@aefuimn Can you please check whether this was resolved for you. Thanks!", "@aefuimn Can you please check whether this was resolved for you. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33869\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33869\">No</a>\n"]}, {"number": 33868, "title": "Distribution Strategy running variables: NCCL error crashes CUDA ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3.7.4\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.0/7.6.2\r\n- GPU model and memory: Titan XP 12 gb x 8\r\n\r\n**Describe the current behavior**\r\nWhen using distribution strategy, the following code runs in graph mode, but fails in eager mode resulting in an NCCL error. Since I need persistent Variables to normalize my loss, the loss function was implemented as a callable keras layer, instantiated as a property of the keras model for which is compute the loss.\r\n\r\n\r\n```\r\nclass HierarchicalLoss(tf.keras.layers.Layer):\r\n    def __init__(self):\r\n        super(HierarchicalLoss, self).__init__()\r\n\r\n        self.running_N = {}\r\n        self.running_sum = {}\r\n        self.running_mean = {}\r\n\r\n    def build(self, input_shapes):\r\n            for layer in input_shapes['nodes']:\r\n                var_scope = ['local_delta_loss' +  \"_\" + layer]\r\n\r\n                self.running_sum[var_scope] = tf.Variable(\r\n                    initial_value = 1.0,\r\n                    dtype = tf.float64,\r\n                    name = var_scope + '_' + 'running_sum',\r\n                    trainable = False,\r\n                    aggregation = tf.VariableAggregation.SUM)\r\n\r\n                self.running_N[var_scope] = tf.Variable(\r\n                    initial_value = 1,\r\n                    dtype = tf.int64,\r\n                    name = var_scope + '_' + 'running_N',\r\n                    trainable = False,\r\n                    aggregation = tf.VariableAggregation.SUM)\r\n    def call(self, model_outputs):\r\n        total_loss = 0.0\r\n        for layer in model_output['nodes']:\r\n            loss, sum, N = compute_loss_and_running_values(model_outputs[layer]) \r\n            self.running_N[layer].assign_add(N)\r\n            self.running_sum[layer].assign_add(sum\r\n            total_loss += 0.0\r\n        return total_loss * self.running_N/self.running_sum\r\n```\r\n\r\n```\r\n2019-10-31 00:57:17.308231: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at nccl_ops.cc:104 : Unknown: Error invoking NCCL: unhandled cuda error\r\n2019-10-31 00:57:17.308341: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Unknown: Error invoking NCCL: unhandled cuda error\r\n         [[{{node NcclAllReduce_7}}]]\r\n         [[NcclAllReduce_5/_26]]\r\n2019-10-31 00:57:17.308471: W tensorflow/core/common_runtime/base_collective_executor.cc:217] BaseCollectiveExecutor::StartAbort Unknown: Error invoking NCCL: unhandled cuda error\r\n         [[{{node NcclAllReduce_7}}]]\r\n```\r\n\r\n If I change the assign_add call to +=, the model runs in eager mode, but yields the following error in graph mode \r\n\r\n```\r\nTypeError: An op outside of the function building code is being passed\r\na \"Graph\" tensor. It is possible to have Graph tensors\r\nleak out of the function building context by including a\r\ntf.init_scope in your function building code.\r\nFor example, the following function will fail:\r\n  @tf.function\r\n  def has_init_scope():\r\n    my_constant = tf.constant(1.)\r\n    with tf.init_scope():\r\n      added = my_constant * 2\r\n```\r\n\r\nIs there a preferred way to have persistent variables within your model that are aggregated across multiple GPUs?\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\n\r\nNCCL debug info\r\n```\r\nnode05-ccncluster:220944:221234 [1] NCCL INFO NET/Socket : Using [0]enp96s0f0:10.102.2.200<0> [1]enp134s0:192.168.4.105<0>\r\nnode05-ccncluster:220944:221234 [1] NCCL INFO NET/Plugin : No plugin found (libnccl-net.so).\r\nnode05-ccncluster:220944:221234 [1] NCCL INFO NET/IB : No device found.\r\nNCCL version 2.4.7+cudaCUDA_MAJOR.CUDA_MINOR\r\nnode05-ccncluster:220944:224168 [1] NCCL INFO Setting affinity for GPU 1 to 0f,ff000fff\r\nnode05-ccncluster:220944:224167 [0] NCCL INFO Setting affinity for GPU 0 to 0f,ff000fff\r\nnode05-ccncluster:220944:224167 [0] NCCL INFO Channel 00 :    0   1\r\nnode05-ccncluster:220944:224167 [0] NCCL INFO Ring 00 : 0[0] -> 1[1] via P2P/direct pointer\r\nnode05-ccncluster:220944:224168 [1] NCCL INFO Ring 00 : 1[1] -> 0[0] via P2P/direct pointer\r\nnode05-ccncluster:220944:224167 [0] NCCL INFO Using 256 threads, Min Comp Cap 6, Trees disabled\r\nnode05-ccncluster:220944:224167 [0] NCCL INFO comm 0x7f7e38001b30 rank 0 nranks 2 cudaDev 0 nvmlDev 0 - Init COMPLETE\r\nnode05-ccncluster:220944:224168 [1] NCCL INFO comm 0x7f7e3c0010b0 rank 1 nranks 2 cudaDev 1 nvmlDev 1 - Init COMPLETE\r\nnode05-ccncluster:220944:224164 [0] NCCL INFO Launch mode Group/CGMD\r\nnode05-ccncluster:220944:224189 [0] NCCL INFO Setting affinity for GPU 0 to 0f,ff000fff\r\nnode05-ccncluster:220944:224190 [0] NCCL INFO Setting affinity for GPU 0 to 0f,ff000fff\r\nnode05-ccncluster:220944:224189 [0] NCCL INFO Channel 00 :    0   1\r\nnode05-ccncluster:220944:224189 [0] NCCL INFO Ring 00 : 0 -> 1 via P2P/common device\r\nnode05-ccncluster:220944:224190 [0] NCCL INFO Ring 00 : 1 -> 0 via P2P/common device\r\nnode05-ccncluster:220944:224189 [0] NCCL INFO Using 256 threads, Min Comp Cap 6, Trees disabled\r\nnode05-ccncluster:220944:224189 [0] NCCL INFO comm 0x7f7e44001550 rank 0 nranks 2 cudaDev 0 nvmlDev 0 - Init COMPLETE\r\nnode05-ccncluster:220944:224190 [0] NCCL INFO comm 0x7f7e30001040 rank 1 nranks 2 cudaDev 0 nvmlDev 0 - Init COMPLETE\r\n\r\nnode05-ccncluster:220944:224164 [0] external/nccl_archive/src/enqueue.cc:74 NCCL WARN Cuda failure 'invalid device ordinal'\r\nnode05-ccncluster:220944:224164 [0] NCCL INFO external/nccl_archive/src/enqueue.cc:175 -> 1\r\nnode05-ccncluster:220944:224164 [0] NCCL INFO external/nccl_archive/src/enqueue.cc:437 -> 1\r\n```\r\n", "comments": ["After some debugging, I think this might have to do with attempting to aggregate the int64? ", "Hi - can you provide the entire model + training code that you're using above? That will help us reproduce and debug the issue.\r\n\r\nThe all reduce is most likely triggered from the .assign_add() which will try to aggregate the delta before applying to the mirrored variables. But it's not clear to me why it fails. (because similar things happen for gradient aggregation as well and presumably those are not failing for you?)\r\n\r\nWhen you eager vs graph mode in TF 2.0, what do you mean? perhaps sharing your training code for either case would help. thanks\r\n\r\n\r\n\r\n", "@mjlbach Can you please provide the details @guptapriya is asking? \r\nPlease close the issue If the issue was already resolved. Thanks!", "I think it was resolved. Closing due to lack of recent activity. Please open new ticket if you see similar issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33868\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33868\">No</a>\n"]}, {"number": 33867, "title": "How does the graphdef file provided in simple audio recognition tutorial can be converted to tflite file?", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version (or github SHA if from [source):tensorflow 1.14\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\n# Copy and paste here\r\n```ValueError: std_dev and mean must be defined when inference_input_type is QUANTIZED_UINT8.\r\n\r\nwhere i dont know mean and std_dev values \r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\nhttps://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\ntflite_convert \\\r\n--output_file=model.tflite \\\r\n--graph_def_file=/home/unizen/Downloads/my_frozen_graph.pb \\\r\n--inference_type=QUANTIZED_UINT8 \\\r\n--input_shapes=16000,1:  \\\r\n--input_arrays=decoded_sample_data,decoded_sample_data:1 \\\r\n--output_arrays=labels_softmax \\\r\n", "comments": ["Can you please go through [link1](https://stackoverflow.com/questions/57272861/i-have-problem-converting-pb-file-to-tflite-file) and see if it helps you.Thanks!", "what are the mean and std dev values of the training network. Could you also verify the input and output arrays @ravikyram ", "Any update regarding the comment?", "From the user guide: https://www.tensorflow.org/lite/convert/quantization\r\n\r\nThe std_dev and mean need to be provided otherwise the model doesn't know how to map from uint8 to float ranges. Adding Alan for further suggestions.", "> From the user guide: https://www.tensorflow.org/lite/convert/quantization\r\n> \r\n> The std_dev and mean need to be provided otherwise the model doesn't know how to map from uint8 to float ranges. Adding Alan for further suggestions.\r\n\r\nThanks for the reply man. But i didn't do training with my code.I followed the tutorial in the below link for the creation of graphdef file\r\nhttps://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md\r\n", "Any update?"]}, {"number": 33866, "title": "How the tflite file has been created for a frozen file from the simple audio recognition tutorial?", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (or github SHA if from source):1.14\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\n# Copy and paste here\r\n`` \r\n Array AudioSpectrogram, which is an input to the (Unsupported TensorFlow op: Mfcc) operator producing the output array Mfcc, is lacking min/max data, which is necessary for quantization. If accuracy matters, either target a non-quantized output format, or run quantized training with your model from a floating point checkpoint to change the input graph to contain min/max information. If you don't care about accuracy, you can pass --default_ranges_min= and --default_ranges_max= for easy experimentation.\r\nFatal Python error: Aborted\r\nAlso, please include a link to a GraphDef or the model if possible.\r\nhttps://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md\r\n\r\n**Any other info / logs**\r\n\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\ntflite_convert \\\r\n--output_file=model.tflite \\\r\n--graph_def_file=/home/unizen/Downloads/my_frozen_graph.pb \\\r\n--inference_type=QUANTIZED_UINT8 \\\r\n--input_shapes=16000,1:1,1\\\r\n--input_arrays=decoded_sample_data,decoded_sample_data:1 \\\r\n--output_arrays=labels_softmax \\\r\n", "comments": ["> **System information**\r\n> \r\n> * OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 16.04\r\n> * TensorFlow installed from (source or binary): source\r\n> * TensorFlow version (or github SHA if from source):1.14\r\n> \r\n> **Provide the text output from tflite_convert**\r\n> \r\n> ```\r\n> # Copy and paste here\r\n> `` \r\n>  Array AudioSpectrogram, which is an input to the (Unsupported TensorFlow op: Mfcc) operator producing the output array Mfcc, is lacking min/max data, which is necessary for quantization. If accuracy matters, either target a non-quantized output format, or run quantized training with your model from a floating point checkpoint to change the input graph to contain min/max information. If you don't care about accuracy, you can pass --default_ranges_min= and --default_ranges_max= for easy experimentation.\r\n> Fatal Python error: Aborted\r\n> Also, please include a link to a GraphDef or the model if possible.\r\n> https://github.com/tensorflow/docs/blob/master/site/en/r1/tutorials/sequences/audio_recognition.md\r\n> \r\n> **Any other info / logs**\r\n> \r\n> \r\n> Include any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n> tflite_convert \\\r\n> --output_file=model.tflite \\\r\n> --graph_def_file=/home/unizen/Downloads/my_frozen_graph.pb \\\r\n> --inference_type=QUANTIZED_UINT8 \\\r\n> --input_shapes=16000,1:1,1\\\r\n> --input_arrays=decoded_sample_data,decoded_sample_data:1 \\\r\n> --output_arrays=labels_softmax \\\r\n> ```\r\n"]}, {"number": 33865, "title": "TensorFlow GPU version uses Eigen for convolution.", "body": "I am debugging the Tensorflow conv_ops_test in the core/kernel folder via VS code. \r\nI found that TensorFlow uses Eigen for GPU version convolution. Not sure why coz I heard that it should call cuBLAS library for GPU things. Hope someone could help me.\r\n\r\nThe settings and commands that I used are as follows:\r\n\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\nTensorFlow installed from (source or binary): Source\r\nTensorFlow version (use command below): 1.4\r\nPython version: 3.5\r\nBazel version (if compiling from source): 0.54\r\nGCC/Compiler version (if compiling from source): 5.5\r\nCUDA/cuDNN version: 8/6\r\nGPU model and memory: GTX 1080Ti\r\nExact command to reproduce: bazel build --spawn_strategy=standalone --verbose_failures --config=cuda --copt=\"-fPIC\" --copt=\"-DNDEBUG\" --local_resources 11048,2.0,2.0 -c dbg --copt -g //tensorflow/tools/pip_package:build_pip_package\r\nand then: bazel build --config=cuda -c dbg --copt -g //tensorflow/core/kernels:conv_ops_test", "comments": ["> I found that TensorFlow uses Eigen for GPU version convolution.\r\n\r\nCan you be more specific?  Why do you think TF is using Eigen for convolutions?  [LaunchConv2DOp<GPUDevice, T>::operator()](https://github.com/tensorflow/tensorflow/blob/d95e97aef9bc589d9b2a08bfc806e3c5f48fcc90/tensorflow/core/kernels/conv_ops.cc#L647) is the main entry point into cuBLAS / cuDNN.", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33865\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33865\">No</a>\n"]}, {"number": 33864, "title": "Windows fatal exception: access violation with tensorboard", "body": "I met a [strange problem]( https://stackoverflow.com/questions/58636880/windows-fatal-exception-access-violation-with-tensorboard), It works well before, then I move all anaconda files from one disk to another SSD, the error occurs. I have tried to remove all the anaconda file and reinstall the whole thing, but still nothing.", "comments": ["duplicate https://github.com/tensorflow/tensorboard/issues/2399", "I solved this, uninstall tf1.4 and install 1.13, then it works well"]}, {"number": 33862, "title": "Segfault on multiple writes to dynamically-sized TensorArray inside tf.function", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below): 1.15\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nThis code reliably produces a segmentation fault:\r\n\r\n```python\r\n%tensorflow_version 1.x\r\nimport faulthandler\r\nfaulthandler.enable()\r\nimport tensorflow as tf\r\ntf.enable_control_flow_v2()\r\nfrom tensorflow.python.ops.tensor_array_ops import build_ta_with_new_flow as ta_like\r\n\r\nnum_iterations = 5\r\n\r\nif True:\r\n  # dynamic sizing; this is the broken case.\r\n  initial_xs = tf.TensorArray(tf.float32, size=0,\r\n                              dynamic_size=True, clear_after_read=False)\r\nelse:\r\n  initial_xs = tf.TensorArray(tf.float32, size=chunk_size * num_iterations,\r\n                              dynamic_size=False, clear_after_read=False)\r\n\r\nz = tf.constant(0.)\r\n\r\n@tf.function(autograph=False)\r\ndef body_fn(i, flow):\r\n  xs = ta_like(initial_xs, flow)\r\n\r\n  # write to the TensorArray multiple times in consecutive locations.\r\n  # chunk_size > 1 is the broken case.\r\n  chunk_size = 2\r\n  for j in range(chunk_size):\r\n    xs = xs.write(i * chunk_size + j, z)\r\n\r\n  return i + 1, xs.flow\r\n\r\ni, xs = tf.constant(0), initial_xs\r\nfor _ in range(num_iterations):\r\n  i, flow = body_fn(i, xs.flow)\r\n  xs = ta_like(initial_xs, flow)\r\n\r\n# the second call to `tf.gradients` causes a segfault\r\ntf.gradients(tf.reduce_mean(xs.stack()), z)\r\ntf.gradients(tf.reduce_mean(xs.stack()), z)\r\n```\r\n\r\nThe loop code is pretty hairy but in plain python, it would read like this:\r\n\r\n```python\r\nxs = []\r\nfor i in range(num_iterations):\r\n  for j in range(chunk_size):\r\n    xs.append(0)\r\n```\r\n\r\nThe issue seems to be the combination of dynamic sizing of the `TensorArray` and multiple appends per iteration. Using `faulthandler` as above gives the following traceback at the point of the segfault:\r\n\r\n```\r\n File \"/home/tim/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 1607 in _create_c_op\r\n  File \"/home/tim/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 1770 in __init__\r\n  File \"/home/tim/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3426 in _create_op_internal\r\n  File \"/home/tim/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\", line 3357 in create_op\r\n  File \"/home/tim/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow_core/python/util/deprecation.py\", line 507 in new_func\r\n  File \"/home/tim/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 794 in _apply_op_helper\r\n  File \"/home/tim/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_functional_ops.py\", line 672 in stateful_partitioned_call\r\n  File \"/home/tim/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow_core/python/ops/functional_ops.py\", line 859 in partitioned_call\r\n  File \"/home/tim/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 540 in call\r\n  File \"/home/tim/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 1230 in _call_flat\r\n  File \"/home/tim/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 697 in _rewrite_forward_and_call_backward\r\n  File \"/home/tim/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow_core/python/eager/function.py\", line 715 in _registered_grad_fn\r\n  File \"/home/tim/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow_core/python/ops/gradients_util.py\", line 679 in <lambda>\r\n  File \"/home/tim/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow_core/python/ops/gradients_util.py\", line 350 in _MaybeCompile\r\n  File \"/home/tim/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow_core/python/ops/gradients_util.py\", line 679 in _GradientsHelper\r\n  File \"/home/tim/miniconda3/envs/py3/lib/python3.6/site-packages/tensorflow_core/python/ops/gradients_impl.py\", line 158 in gradients\r\n  File \"/home/tim/memoryhole/segfault.py\", line 39 in <module>\r\n[...]\r\nSegmentation fault (core dumped)\r\n```\r\n\r\nP.S., my use case is I'm trying to convert an existing `while_loop` into an unrolled sequence of `tf.function` calls in order to reduce graph size without giving up on second-order derivatives. It looks promising so far, but do let me know if this is wrong-headed.", "comments": ["I can reproduce the issue with `TF1.15.3`. [Here](https://colab.research.google.com/gist/jvishnuvardhan/02b255f1fcffb1d26ff51659eaa5239b/untitled942.ipynb) is a gist for our reference. Thanks", "Thanks for reporting this! This seems to be coming from shape inference code for list_ops. I'll take a look.", "This should be fixed by 8cc97997b7bda51d553dd251689023ab53344a28. Please reopen if not.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33862\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33862\">No</a>\n"]}, {"number": 33861, "title": "tf 1.14 compile error with gcc 4.9.2", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): RHEL\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 1.14.0\r\n- Python version: 2.7\r\n- Installed using virtualenv? pip? conda?: \r\n- Bazel version (if compiling from source): 0.25.0\r\n- GCC/Compiler version (if compiling from source): 4.9.2\r\n- CUDA/cuDNN version: \r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n`[944 / 2,400] Compiling external/protobuf_archive/src/google/protobuf/compiler/java/java_message_field_lite.cc [for host]; 0s local ... (47 actions running)\r\nERROR: /home/admin/tensorflow-1.14.0/tensorflow/lite/kernels/BUILD:403:1: C++ compilation of rule '//tensorflow/lite/kernels:lstm_eval' failed (Exit 1)\r\nIn file included from external/eigen_archive/Eigen/Core:161:0,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from tensorflow/lite/kernels/lstm_eval.cc:23:\r\nexternal/eigen_archive/Eigen/src/Core/arch/AVX512/PacketMath.h:124:1: error: 'Packet Eigen::internal::pset1(const typename Eigen::internal::unpacket_traits<Packet>::type&) [with Packet = __vector(16) float; typename Eigen::internal::unpacket_traits<Packet>::type = float]' conflicts with a previous declaration\r\n }\r\n ^\r\nIn file included from external/eigen_archive/Eigen/Core:158:0,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from tensorflow/lite/kernels/lstm_eval.cc:23:\r\nexternal/eigen_archive/Eigen/src/Core/arch/AVX/PacketMath.h:130:41: note: previous declaration 'Packet Eigen::internal::pset1(const typename Eigen::internal::unpacket_traits<Packet>::type&) [with Packet = __vector(8) float; typename Eigen::internal::unpacket_traits<Packet>::type = float]'\r\n template<> EIGEN_STRONG_INLINE Packet8f pset1<Packet8f>(const float&  from) { return _mm256_set1_ps(from); }\r\n                                         ^\r\nIn file included from external/eigen_archive/Eigen/Core:161:0,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from tensorflow/lite/kernels/lstm_eval.cc:23:\r\nexternal/eigen_archive/Eigen/src/Core/arch/AVX512/PacketMath.h:122:31: note: -fabi-version=6 (or =0) avoids this error with a change in mangling\r\n EIGEN_STRONG_INLINE Packet16f pset1<Packet16f>(const float& from) {\r\n                               ^\r\nexternal/eigen_archive/Eigen/src/Core/arch/AVX512/PacketMath.h:128:1: error: 'Packet Eigen::internal::pset1(const typename Eigen::internal::unpacket_traits<Packet>::type&) [with Packet = __vector(8) double; typename Eigen::internal::unpacket_traits<Packet>::type = double]' conflicts with a previous declaration\r\n }\r\n ^\r\nIn file included from external/eigen_archive/Eigen/Core:158:0,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from tensorflow/lite/kernels/lstm_eval.cc:23:\r\nexternal/eigen_archive/Eigen/src/Core/arch/AVX/PacketMath.h:131:41: note: previous declaration 'Packet Eigen::internal::pset1(const typename Eigen::internal::unpacket_traits<Packet>::type&) [with Packet = __vector(4) double; typename Eigen::internal::unpacket_traits<Packet>::type = double]'\r\n template<> EIGEN_STRONG_INLINE Packet4d pset1<Packet4d>(const double& from) { return _mm256_set1_pd(from); }\r\n                                         ^\r\nIn file included from external/eigen_archive/Eigen/Core:161:0,\r\n                 from ./third_party/eigen3/Eigen/Core:1,\r\n                 from tensorflow/lite/kernels/lstm_eval.cc:23:\r\nexternal/eigen_archive/Eigen/src/Core/arch/AVX512/PacketMath.h:126:30: note: -fabi-version=6 (or =0) avoids this error with a change in mangling\r\n EIGEN_STRONG_INLINE Packet8d pset1<Packet8d>(const double& from) {\r\n                                                           ^\r\nexternal/eigen_archive/Eigen/src/Core/arch/AVX512/PacketMath.h:132:1: error: 'Packet Eigen::internal::pset1(const typename Eigen::internal::unpacket_traits<Packet>::type&) [with Packet = __vector(8) long long int; typename Eigen::internal::unpacket_traits<Packet>::type = int]' conflicts with a previous declaration\r\n }\r\n ^`\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nbazel build --config=opt --config=mkl --cxxopt=-mavx --cxxopt=-mavx2 --cxxopt=-msse3 --cxxopt=-msse4.1 --cxxopt=-msse4.2 --cxxopt=-mfma --copt=-mavx --copt=-mavx2 --copt=-msse3 --copt=-msse4.1 --copt=-msse4.2 --copt=-mfma --cxxopt=-fabi-version=6 --copt=-fabi-version=6 //tensorflow/tools/pip_package:build_pip_package\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["I built successfully with gcc 4.8.5, i make sure that it is relate to gcc version", "@goldbalance, Please take a look at the Tensorflow [tested build configuration](https://www.tensorflow.org/install/source#tested_build_configurations).Tensorflow 1.14.0 supports GCC 4.8. Thanks!", "> @goldbalance, Please take a look at the Tensorflow [tested build configuration](https://www.tensorflow.org/install/source#tested_build_configurations).Tensorflow 1.14.0 supports GCC 4.8. Thanks!\r\n\r\nI see it. Thanks!. But param simd and cpu avx512 is only supportted with gcc 4.9 or above. Hope your supporting.", "Thanks for the report. As mentioned, TF 1.14.0 only officially supports GCC 4.8. If you'd like to use those newer options, please build at master, which supports GCC 7.3.1. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33861\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33861\">No</a>\n"]}, {"number": 33860, "title": "Remove duplicated name in 2.0.0 release note thanks section", "body": "The only change is from \"Sami Kama, Sami Kama\" to \"Sami Kama\". GitHub (and git) does not show the exact difference in this long line. [This online diff checker](https://www.diffchecker.com/) works.", "comments": ["Thank you, @martinwicke."]}, {"number": 33859, "title": "Wrong error being thrown with keras.utils.get_file when using extract=True", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nNo\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 LTS\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3.6.8\r\n\r\nFollowing on the stackoverflow question [here](https://stackoverflow.com/questions/58634576/whats-the-error-when-importing-url-data-set-to-colab), it seems like `keras.utils.get_file` does not throw the right error message when trying to download a zip file with archive extraction enabled. It throws a 403 HTTP Error even if it works fine with `extract=False`.\r\n\r\n**Describe the expected behavior**\r\nIt probably should throw an error explaining that the extraction failed.\r\n\r\n**Code to reproduce the issue**\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\n_URL = 'http://iies.ucaldas.edu.co/biostratigraphy/Training_particles.zip'\r\ntf.compat.v2.keras.utils.get_file('file.zip', origin=_URL, extract=True) ## HTTP Error 403\r\n# tf.compat.v2.keras.utils.get_file('file.zip', origin=_URL) // but this works \r\n```\r\n\r\n**Other info / logs**\r\n```\r\nException                                 Traceback (most recent call last)\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/data_utils.py in get_file(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\r\n    251         urlretrieve(origin, fpath, dl_progress)\r\n    252       except HTTPError as e:\r\n--> 253         raise Exception(error_msg.format(origin, e.code, e.msg))\r\n    254       except URLError as e:\r\n    255         raise Exception(error_msg.format(origin, e.errno, e.reason))\r\n\r\nException: URL fetch failure on http://iies.ucaldas.edu.co/biostratigraphy/Training_particles.zip: 403 -- Forbidden\r\n```", "comments": ["@keurcien,\r\nThis works for me,\r\n```\r\nimport tensorflow as tf\r\nURL = 'http://iies.ucaldas.edu.co/biostratigraphy/Training_particles.zip'\r\ntf.compat.v2.keras.utils.get_file('file.zip',origin=URL,extract=True, archive_format='auto')\r\n```\r\nAs per description in [doc](https://www.tensorflow.org/api_docs/python/tf/keras/utils/get_file#arguments) `archive_format: Archive format to try for extracting the file. Options are 'auto', 'tar', 'zip', and None. 'tar' includes tar, tar.gz, and tar.bz files. The default 'auto' is ['tar', 'zip']. None or an empty list will return no matches found.`\r\nPlease let us know if that solves your problem. Thanks!", "@gadagashwini \r\nIt does not, but today it seems like none of the option works. Hence it looks like it's more a problem with `urlretrieve` so I might as well close the issue. But if you're interested, the person on Stack Overflow shared his [colab](https://colab.research.google.com/drive/1oA_AkpOEqir0cNPIFPbrNrylXhMA8sUv).\r\n\r\nAnyway thanks! "]}, {"number": 33858, "title": "Fix a typo.", "body": "This is just a test PR. Please don't close, don't approve and don't\r\nmerge.", "comments": []}, {"number": 33857, "title": "Fail to invoke tflite_runtime.interpreter", "body": "I'm trying to run the `tflite_runtime.interpreter` on an armv7 board. It doesn't support AVX instruction so this is the reason for using tflite rather than the tensorflow binary available for raspberry pi's.\r\n\r\nAs far as I can tell I'm setting the tensor input correctly. I've tested this by using the 'tensorflow.compat.v2.audio.decode_wav' function to compare against.\r\n\r\nHowever when I go to run the interpreter I get the following error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/home/debian/xo/keyword-demo/test/test__litewave.py\", line 62, in test_detect_keywords\r\n    results = lite_wave.detect_keywords()\r\n  File \"./handlers/__litewave.py\", line 66, in detect_keywords\r\n    self.__interpreter.invoke()\r\n  File \"/home/debian/xo/keyword-demo/venv/lib/python3.7/site-packages/tflite_runtime/interpreter.py\", line 453, in invoke\r\n    self._interpreter.Invoke()\r\n  File \"/home/debian/xo/keyword-demo/venv/lib/python3.7/site-packages/tensorflow_core/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py\", line 109, in Invoke\r\n    return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_Invoke(self)\r\nRuntimeError: tensorflow/lite/kernels/mfcc.cc:131 params->dct_coefficient_count != mfcc_output.size() (40 != 0)Node number 1 (Mfcc) failed to invoke.\r\n```\r\n\r\nI couldn't find a python example for the keyword spotting demo using Tensorflow Lite so I'm adapting the following two examples:\r\nhttps://github.com/tensorflow/examples/blob/master/lite/examples/object_detection/raspberry_pi/detect_picamera.py\r\nhttps://github.com/tensorflow/examples/blob/master/lite/examples/image_classification/raspberry_pi/classify_picamera.py\r\n\r\nI'm using the following code to test:\r\n```\r\nimport sys\r\nimport unittest\r\n\r\nsys.path.append('./handlers')\r\n\r\nfrom __litewave import LiteWaveHandle\r\n\r\nimport numpy as np\r\nfrom tensorflow.compat.v2.audio import decode_wav\r\nfrom tensorflow.compat.v2.io import read_file\r\n\r\n\r\nclass TestLiteWaveHandle(unittest.TestCase):\r\n\r\n    def test_load_labels(self):\r\n        lite_wave = LiteWaveHandle()\r\n\r\n        labels = {0: '_silence_', 1: '_unknown_', 2: 'yes', 3: 'no', 4: 'up', 5: 'down', 6: 'left', 7: 'right', 8: 'on', 9: 'off', 10: 'stop', 11: 'go'}\r\n        self.assertEqual(lite_wave.load_labels(\"./models/speech_commands_lite/conv_actions_labels.txt\"), labels)\r\n\r\n    def test_decode_wav(self):\r\n        lite_wave_tf = LiteWaveHandle()\r\n        lite_wave_np = LiteWaveHandle()\r\n\r\n\r\n        # set the input tensor using tf wave decoder\r\n        audio, sample_rate = decode_wav(\r\n            read_file(\"./test/vectors/go/0a2b400e_nohash_0.wav\"),\r\n            desired_channels=1,\r\n            desired_samples=16000,\r\n        )\r\n        lite_wave_tf.set_input_tensor_tf(audio)\r\n        input_tensor_tf = lite_wave_tf.get_input_tensor()\r\n\r\n\r\n        # set the input tensor using custom wave decoder\r\n        audio = lite_wave_np.decode_wav('./test/vectors/go/0a2b400e_nohash_0.wav')\r\n        lite_wave_np.set_input_tensor(audio)\r\n        input_tensor_np = lite_wave_np.get_input_tensor() \r\n\r\n        self.assertTrue(np.array_equal(input_tensor_tf, input_tensor_np))\r\n\r\n    def test_set_input_tensor(self):\r\n        lite_wave = LiteWaveHandle()\r\n\r\n        audio = lite_wave.decode_wav('./test/vectors/go/0a2b400e_nohash_0.wav')\r\n        lite_wave.set_input_tensor(audio)\r\n        self.assertTrue(np.array_equal(audio, lite_wave.get_input_tensor()))\r\n\r\n    def test_get_output_tensor(self):\r\n        lite_wave = LiteWaveHandle()\r\n\r\n        output_details, output = lite_wave.get_output_tensor(0)\r\n        self.assertEqual(output_details[\"name\"], 'labels_softmax')\r\n\r\n    def test_detect_keywords(self):\r\n        lite_wave = LiteWaveHandle()\r\n\r\n        audio = lite_wave.decode_wav('./test/vectors/go/0a2b400e_nohash_0.wav')\r\n        lite_wave.set_input_tensor(audio)\r\n\r\n        label_id, prob = lite_wave.detect_keywords()[0]\r\n        self.assertEqual(lite_wave.labels[label_id], 'go')\r\n```\r\n\r\nAnd this is the actual code for the LiteWaveHandle I'm trying to create\r\n```\r\nimport os\r\n\r\nimport re\r\nimport wave\r\nimport struct\r\n\r\nfrom tflite_runtime.interpreter import Interpreter\r\nimport numpy as np\r\n\r\nclass LiteWaveHandle:\r\n    \"\"\"A class to handle lite inferences on wave data\"\"\"\r\n\r\n    def __init__(self):\r\n        self.labels = self.load_labels(\"./models/speech_commands_lite/conv_actions_labels.txt\")\r\n\r\n        self.__interpreter = Interpreter(model_path=\"./models/speech_commands_lite/conv_actions_frozen.tflite\")\r\n        self.__interpreter.allocate_tensors()\r\n\r\n    def load_labels(self, file_path):\r\n        with open(file_path, 'r', encoding='utf-8') as f:\r\n            lines = f.readlines()\r\n            labels = {}\r\n            for row_number, content in enumerate(lines):\r\n                pair = re.split(r'[:\\s]+', content.strip(), maxsplit=1)\r\n                if len(pair) == 2 and pair[0].strip().isdigit():\r\n                    labels[int(pair[0])] = pair[1].strip()\r\n                else:\r\n                    labels[row_number] = pair[0].strip()\r\n        return labels\r\n\r\n    def decode_wav(self, file_path):\r\n        \"\"\"wave file to a numpy array of floats limited size to 16000\"\"\"\r\n        with wave.open(file_path) as wf:\r\n            astr = wf.readframes(wf.getnframes())\r\n            # convert binary chunks to short \r\n            audio = struct.unpack(\"%ih\" % (wf.getnframes()* wf.getnchannels()), astr)\r\n            audio = [float(val) / pow(2, 15) for val in audio]\r\n            audio = np.asarray(audio)\r\n            return np.reshape(audio, (16000, 1))\r\n\r\n    def set_input_tensor(self, audio):\r\n        \"\"\"Sets the input tensor.\"\"\"\r\n        tensor_index = self.__interpreter.get_input_details()[0]['index']\r\n        input_tensor = self.__interpreter.tensor(tensor_index)()\r\n        input_tensor[:] = audio\r\n\r\n    def set_input_tensor_tf(self, audio):\r\n        tensor_index = self.__interpreter.get_input_details()[0]['index']\r\n        input_tensor = self.__interpreter.tensor(tensor_index)()[0]\r\n        self.__interpreter.set_tensor(tensor_index, audio)\r\n\r\n    def get_input_tensor(self):\r\n        tensor_index = self.__interpreter.get_input_details()[0]['index']\r\n        return self.__interpreter.get_tensor(tensor_index)\r\n\r\n    def get_output_tensor(self, index):\r\n        \"\"\"Returns the output tensor at the given index.\"\"\"\r\n        output_details = self.__interpreter.get_output_details()[index]\r\n        output = np.squeeze(self.__interpreter.get_tensor(output_details['index']))\r\n        return output_details, output\r\n\r\n    def detect_keywords(self, top_k=1):\r\n        \"\"\"Returns a list of detection results, each a dictionary of object info.\"\"\"\r\n        self.__interpreter.invoke()\r\n\r\n        output_details, output = self.get_output_tensor(0)\r\n\r\n        ordered = np.argpartition(-output, top_k)\r\n        return [(i, output[i]) for i in ordered[:top_k]]\r\n```\r\n\r\nThis is running on an armv7 with python3.7.3 built from source. tflite-runtime is 2.0.0. The tflite models used are these: https://storage.googleapis.com/download.tensorflow.org/models/tflite/conv_actions_tflite.zip\r\n\r\nIf there is anything else I can add to help debug let me know. \r\n", "comments": [" I face the same problem", "@lelopez-io,\r\nCould you please update TensorFlow to the latest stable version v2.4.1 and check if you are facing the same error. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33857\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33857\">No</a>\n"]}, {"number": 33856, "title": "Outdated doc for tf.keras.Model.save", "body": "## URL(s) with the issue:\r\n\r\n[https://www.tensorflow.org/api_docs/python/tf/keras/Model#save](https://www.tensorflow.org/api_docs/python/tf/keras/Model#save)\r\n\r\n## Description of issue (what needs changing):\r\n\r\nThe following sentence is outdated and recommends to use a deprecated method:\r\n\r\n> The 'tf' option is currently disabled (use [tf.keras.experimental.export_saved_model](https://www.tensorflow.org/api_docs/python/tf/keras/experimental/export_saved_model) instead).", "comments": ["Has this issue already been taken up? I can make the fix otherwise.", "I want to work on this issue! ", "@imskr If @nikochiko is not working on it, then you can work on it. If you have already worked on, then submit a PR to update the docs. Thanks!", "The docs have been updated. Changes are already visible in rc 2.1 API docs: https://www.tensorflow.org/versions/r2.1/api_docs/python/tf/keras/Model#save\r\nThis issue can be closed. @jvishnuvardhan @durandg12 "]}, {"number": 33855, "title": "Tensorflow 2 Integer Labels", "body": "From the docs, it says if I want to use labels without one_hot encoding in advance, I should use SparseCategoricalCrossentropy. And the result is strange. \r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 1903 18362.418\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d382ca 2.0.0\r\n- Python version: Python 3.7.3 (default, Mar 27 2019, 17:13:21) [MSC v.1915 64 bit (AMD64)] :: Anaconda, Inc.\r\n- Bazel version (if compiling from source): \r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: cudart64_100.dll\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\nthe model won't compile\r\nusing from_logits=False, reporting TypeError: Expected int32, got 1e-07 of type 'float' instead.\r\nusing from_logits=True, get TypeError: Value passed to parameter 'features' has DataType int32 not in list of allowed values: float16, bfloat16, float32, float64\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\tensor_util.py\", line 324, in _AssertCompatible\r\n    fn(values)\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\tensor_util.py\", line 263, in inner\r\n    _ = [_check_failed(v) for v in nest.flatten(values)\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\tensor_util.py\", line 264, in <listcomp>\r\n    if not isinstance(v, expected_types)]\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\tensor_util.py\", line 248, in _check_failed\r\n    raise ValueError(v)\r\nValueError: 1e-07\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:/Users/user/OneDrive/UH/cvxtest/main2.py\", line 84, in <module>\r\n    metrics=[\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 373, in compile\r\n    self._compile_weights_loss_and_weighted_metrics()\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 1653, in _compile_weights_loss_and_weighted_metrics\r\n    self.total_loss = self._prepare_total_loss(masks)\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 1713, in _prepare_total_loss\r\n    per_sample_losses = loss_fn.call(y_true, y_pred)\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\losses.py\", line 221, in call\r\n    return self.fn(y_true, y_pred, **self._fn_kwargs)\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\losses.py\", line 978, in sparse_categorical_crossentropy\r\n    y_true, y_pred, from_logits=from_logits, axis=axis)\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 4504, in sparse_categorical_crossentropy\r\n    epsilon_ = _constant_to_tensor(epsilon(), output.dtype.base_dtype)\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 673, in _constant_to_tensor\r\n    return constant_op.constant(x, dtype=dtype)\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\", line 227, in constant\r\n    allow_broadcast=True)\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\constant_op.py\", line 265, in _constant_impl\r\n    allow_broadcast=allow_broadcast))\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\tensor_util.py\", line 449, in make_tensor_proto\r\n    _AssertCompatible(values, dtype)\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\tensor_util.py\", line 331, in _AssertCompatible\r\n    (dtype.name, repr(mismatch), type(mismatch).__name__))\r\nTypeError: Expected int32, got 1e-07 of type 'float' instead.\r\n```\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"C:/Users/user/OneDrive/UH/cvxtest/main2.py\", line 84, in <module>\r\n    metrics=[\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 373, in compile\r\n    self._compile_weights_loss_and_weighted_metrics()\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\", line 457, in _method_wrapper\r\n    result = method(self, *args, **kwargs)\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 1653, in _compile_weights_loss_and_weighted_metrics\r\n    self.total_loss = self._prepare_total_loss(masks)\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 1713, in _prepare_total_loss\r\n    per_sample_losses = loss_fn.call(y_true, y_pred)\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\losses.py\", line 221, in call\r\n    return self.fn(y_true, y_pred, **self._fn_kwargs)\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\losses.py\", line 978, in sparse_categorical_crossentropy\r\n    y_true, y_pred, from_logits=from_logits, axis=axis)\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 4546, in sparse_categorical_crossentropy\r\n    labels=target, logits=output)\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\", line 3477, in sparse_softmax_cross_entropy_with_logits_v2\r\n    labels=labels, logits=logits, name=name)\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\", line 3397, in sparse_softmax_cross_entropy_with_logits\r\n    precise_logits, labels, name=name)\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_nn_ops.py\", line 11842, in sparse_softmax_cross_entropy_with_logits\r\n    labels=labels, name=name)\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 631, in _apply_op_helper\r\n    param_name=input_name)\r\n  File \"C:\\Users\\user\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 60, in _SatisfiesTypeConstraint\r\n    \", \".join(dtypes.as_dtype(x).name for x in allowed_list)))\r\nTypeError: Value passed to parameter 'features' has DataType int32 not in list of allowed values: float16, bfloat16, float32, float64\r\n```\r\n\r\n**Describe the expected behavior**\r\nCompile and run. It is a pretty simple model after all.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nfrom keras.datasets import fashion_mnist\r\n\r\ntf.random.set_seed(1)\r\nnp.random.seed(1)\r\n\r\n\r\nif __name__ == '__main__':\r\n    (train_X, train_Y), (test_X, test_Y) = fashion_mnist.load_data()\r\n\r\n    train_X = train_X.reshape(-1, 28, 28, 1)\r\n    test_X = test_X.reshape(-1, 28, 28, 1)\r\n\r\n    train_X = train_X.astype('float32')\r\n    test_X = test_X.astype('float32')\r\n    train_X = train_X / 255\r\n    test_X = test_X / 255\r\n\r\n    train_L = len(train_X)\r\n    test_L = len(test_X)\r\n\r\n    print(train_Y[0], type(train_Y[0]))\r\n\r\n    x_input = tf.keras.Input(dtype=tf.dtypes.float32, shape=[28, 28, 1])\r\n    y_input = tf.keras.Input(dtype=tf.dtypes.int32, shape=[1])\r\n    \r\n    x = tf.keras.layers.Flatten()(x_input)\r\n    y_target = tf.one_hot(y_input, 10)\r\n    y_logits = tf.keras.layers.Dense(10)(x)\r\n    y_probability = tf.keras.layers.Softmax()(y_logits)\r\n    y_output = tf.math.argmax(\r\n        input=y_probability,\r\n        axis=1,\r\n        output_type=tf.dtypes.int32\r\n    )\r\n\r\n    model = tf.keras.Model(inputs=[x_input, y_input], outputs=y_output)\r\n\r\n    model.compile(\r\n        optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3),\r\n        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\r\n\r\n        metrics=[\r\n            # 'accuracy'\r\n            #tf.keras.metrics.Accuracy()\r\n        ]\r\n    )\r\n\r\n    # Trains for 5 epochs\r\n    model.fit(x=train_X, y=train_Y, batch_size=32, epochs=5)\r\n\r\n```\r\n\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["It is possible to run with the following code, supposing we are using `from_logits=True`\r\nBut still, not sure what went wrong if using `from_logits=False`\r\n```\r\n    x_input = tf.keras.Input(dtype=tf.dtypes.float32, shape=[28, 28, 1])\r\n\r\n    x = tf.keras.layers.Flatten()(x_input)\r\n    y_logits = tf.keras.layers.Dense(10)(x)\r\n    y_probability = tf.keras.layers.Softmax()(y_logits)\r\n    y_output = tf.math.argmax(\r\n        input=y_probability,\r\n        axis=1,\r\n        output_type=tf.dtypes.int32\r\n    )\r\n\r\n    model = tf.keras.Model(inputs=x_input, outputs=y_logits)\r\n\r\n    model.compile(\r\n        optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3),\r\n        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n        # loss=tf.keras.losses.CategoricalCrossentropy(),\r\n        metrics=[\r\n            # 'accuracy'\r\n            # tf.keras.metrics.Accuracy()\r\n        ]\r\n    )\r\n```", "it seems there is inconsistency between docs.\r\nfrom https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy\r\n> Use this crossentropy loss function when there are two or more label classes. We expect labels to be provided in a one_hot representation. If you want to provide labels as integers, please use SparseCategoricalCrossentropy loss. There should be # classes floating point values per feature.\r\n\r\nHowever, from https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy#__init__\r\n> Use this crossentropy loss function when there are two or more label classes. We expect labels to be provided as integers. If you want to provide labels using one-hot representation, please use CategoricalCrossentropy loss. There should be # classes floating point values per feature for y_pred and a single floating point value per feature for y_true.\r\nIn the snippet below, there is a single floating point value per example for y_true and # classes floating pointing values per example for y_pred. The shape of y_true is [batch_size] and the shape of y_pred is [batch_size, num_classes].\r\n\r\nThe latter being said that where should always be # classes features for the input of SparseCategoricalCrossentropy.__call__ , whether it is in the form of probability distribution or logits. \r\n\r\nAnd here comes another question, if this is the case, how could I pass only integers as labels without the need one-hot encoding them first?\r\n", "I could reproduce the issue with TF2.0.0. \r\nPLease take a look at the [gist](https://colab.sandbox.google.com/gist/gadagashwini/7068e47f9312382957f23235899f68ca/untitled230.ipynb). Thanks!", "Hey @ziruizhuang I went through the issue and the gist that @gadagashwini  provided, It looked like casting the type of `y_output` to `float32` solves the problem. And another thing that I noticed, the value being shown is really really small, around 1e-07, so I can roughly guess there's some issue with the sparse_categorical_entropy kernel and it can't handle non-float data, may be trying to figure out the floating point alternative of the interger inputs, it breaks, because of some floating point error. Not sure if that's a bug, or a feature.\r\n@vbardiovskyg @srjoglekar246 can you confirm?", "@captain-pool Thanks for the suggestion. I tried to cast it to float32 but I got another error and it seems that it is related to the shape of the tensors.\r\n```\r\n    (train_X, train_Y), (test_X, test_Y) = fashion_mnist.load_data()\r\n\r\n    train_X = train_X.reshape(-1, 28, 28, 1)\r\n    test_X = test_X.reshape(-1, 28, 28, 1)\r\n\r\n    train_X = train_X.astype('float32')\r\n    test_X = test_X.astype('float32')\r\n    train_X = train_X / 255\r\n    test_X = test_X / 255\r\n\r\n    train_L = len(train_X)\r\n    test_L = len(test_X)\r\n\r\n    x_input = tf.keras.Input(dtype=tf.dtypes.float32, shape=[28, 28, 1])\r\n\r\n    x = tf.keras.layers.Flatten()(x_input)\r\n    y_logits = tf.keras.layers.Dense(10)(x)\r\n    y_probability = tf.keras.layers.Softmax()(y_logits)\r\n    y_output = tf.math.argmax(\r\n        input=y_probability,\r\n        axis=1,\r\n        output_type=tf.dtypes.int32\r\n    )\r\n    y_output = tf.dtypes.cast(y_output, tf.float32)\r\n\r\n    model = tf.keras.Model(inputs=x_input, outputs=y_output)\r\n\r\n    model.compile(\r\n        optimizer=tf.keras.optimizers.SGD(learning_rate=1e-3),\r\n        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\r\n\r\n        metrics=[\r\n            # 'accuracy'\r\n            tf.keras.metrics.Accuracy()\r\n        ]\r\n    )\r\n\r\n    # Trains for 5 epochs\r\n    model.fit(x=train_X, y=train_Y, batch_size=32, epochs=5)\r\n```\r\n```\r\nTraceback (most recent call last):\r\n  File \"C:/Users/user/OneDrive/UH/cvxtest/test3.py\", line 56, in <module>\r\n    model.fit(x=train_X, y=train_Y, batch_size=32, epochs=5)\r\n  File \"C:\\Users\\user\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 728, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"C:\\Users\\user\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 324, in fit\r\n    total_epochs=epochs)\r\n  File \"C:\\Users\\user\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 123, in run_one_epoch\r\n    batch_outs = execution_function(iterator)\r\n  File \"C:\\Users\\user\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\", line 86, in execution_function\r\n    distributed_function(input_fn))\r\n  File \"C:\\Users\\user\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 457, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"C:\\Users\\user\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 503, in _call\r\n    self._initialize(args, kwds, add_initializers_to=initializer_map)\r\n  File \"C:\\Users\\user\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 408, in _initialize\r\n    *args, **kwds))\r\n  File \"C:\\Users\\user\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1848, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"C:\\Users\\user\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 2150, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"C:\\Users\\user\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 2041, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"C:\\Users\\user\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\", line 915, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"C:\\Users\\user\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 358, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"C:\\Users\\user\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\", line 73, in distributed_function\r\n    per_replica_function, args=(model, x, y, sample_weights))\r\n  File \"C:\\Users\\user\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\", line 760, in experimental_run_v2\r\n    return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n  File \"C:\\Users\\user\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\", line 1787, in call_for_each_replica\r\n    return self._call_for_each_replica(fn, args, kwargs)\r\n  File \"C:\\Users\\user\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\", line 2132, in _call_for_each_replica\r\n    return fn(*args, **kwargs)\r\n  File \"C:\\Users\\user\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\autograph\\impl\\api.py\", line 292, in wrapper\r\n    return func(*args, **kwargs)\r\n  File \"C:\\Users\\user\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\", line 264, in train_on_batch\r\n    output_loss_metrics=model._output_loss_metrics)\r\n  File \"C:\\Users\\user\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\", line 311, in train_on_batch\r\n    output_loss_metrics=output_loss_metrics))\r\n  File \"C:\\Users\\user\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\", line 252, in _process_single_batch\r\n    training=training))\r\n  File \"C:\\Users\\user\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\", line 166, in _model_loss\r\n    per_sample_losses = loss_fn.call(targets[i], outs[i])\r\n  File \"C:\\Users\\user\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\losses.py\", line 221, in call\r\n    return self.fn(y_true, y_pred, **self._fn_kwargs)\r\n  File \"C:\\Users\\user\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\losses.py\", line 978, in sparse_categorical_crossentropy\r\n    y_true, y_pred, from_logits=from_logits, axis=axis)\r\n  File \"C:\\Users\\user\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\", line 4546, in sparse_categorical_crossentropy\r\n    labels=target, logits=output)\r\n  File \"C:\\Users\\user\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\", line 3477, in sparse_softmax_cross_entropy_with_logits_v2\r\n    labels=labels, logits=logits, name=name)\r\n  File \"C:\\Users\\user\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow_core\\python\\ops\\nn_ops.py\", line 3393, in sparse_softmax_cross_entropy_with_logits\r\n    logits.get_shape()))\r\nValueError: Shape mismatch: The shape of labels (received (32,)) should equal the shape of logits except for the last dimension (received (1, 32)).\r\n```", "Hello, how did you finally solve this issue?", "Hi @kenseii ,\r\nI choose to use low level API instead.\r\n\r\nfor your reference, the code works fine both using CategoricalCrossentropy and SparseCategoricalCrossentropy\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nfrom mnist import train_images, test_images, train_labels, test_labels\r\n\r\ntf.random.set_seed(1)\r\nnp.random.seed(1)\r\n\r\nLOSS_TYPES = {\r\n    'CE': tf.keras.losses.CategoricalCrossentropy(),\r\n    'SCE': tf.keras.losses.SparseCategoricalCrossentropy()\r\n}\r\nLOSS_TYPE1 = 'CE'\r\nLOSS_TYPE2 = LOSS_TYPES[LOSS_TYPE1]\r\n\r\nDTYPES = {\r\n    'float16': tf.float16,\r\n    'float32': tf.float32,\r\n    'float64': tf.float64\r\n}\r\n\r\nDTYPE1 = 'float32'\r\nDTYPE2 = DTYPES[DTYPE1]\r\n\r\ntf.keras.backend.set_floatx(DTYPE1)\r\n\r\nEPOCHS = 50\r\nNCLASS = 10\r\nBATCH_SIZE = 256\r\n\r\n\r\nclass MNISTModel(tf.keras.Model):\r\n    loss_object = LOSS_TYPE2\r\n\r\n    optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\r\n\r\n    train_loss = tf.keras.metrics.Mean(name='train_loss')\r\n    validate_loss = tf.keras.metrics.Mean(name='train_loss')\r\n    test_loss = tf.keras.metrics.Mean(name='test_loss')\r\n\r\n    train_acc = tf.keras.metrics.SparseCategoricalAccuracy(name='train_acc')\r\n    validate_acc = tf.keras.metrics.SparseCategoricalAccuracy(name='train_acc')\r\n    test_acc = tf.keras.metrics.SparseCategoricalAccuracy(name='test_acc')\r\n\r\n    n_class = None\r\n\r\n    def __init__(self, n_class):\r\n        super(MNISTModel, self).__init__()\r\n        self.n_class = n_class\r\n\r\n        self.d0 = tf.keras.layers.Conv2D(16, [3, 3], 1, 'same', activation='relu')\r\n        self.d1 = tf.keras.layers.Conv2D(16, [3, 3], 1, 'same', activation='relu')\r\n        self.d2 = tf.keras.layers.Conv2D(16, [3, 3], 1, 'same', activation='relu')\r\n        self.d3 = tf.keras.layers.Conv2D(16, [3, 3], 1, 'same', activation='relu')\r\n\r\n        self.p0 = tf.keras.layers.MaxPooling2D((2, 2))\r\n        self.p1 = tf.keras.layers.MaxPooling2D((2, 2))\r\n        self.p2 = tf.keras.layers.MaxPooling2D((2, 2))\r\n        self.p3 = tf.keras.layers.MaxPooling2D((2, 2))\r\n\r\n        self.d_prior = tf.keras.layers.Dense(64, activation='relu')\r\n        self.d_out = tf.keras.layers.Dense(self.n_class, activation='softmax')\r\n\r\n    @tf.function\r\n    def call(self, x, training):\r\n        x = tf.dtypes.cast(\r\n            tf.reshape(x, [-1, 28, 28, 1]),\r\n            dtype=DTYPE2\r\n        )\r\n\r\n        x = self.d0(x)\r\n        x = self.p0(x)\r\n\r\n        x = self.d1(x)\r\n        x = self.p1(x)\r\n\r\n        x = self.d2(x)\r\n        x = self.p2(x)\r\n\r\n        x = self.d3(x)\r\n        x = self.p3(x)\r\n\r\n        x = tf.keras.layers.Flatten()(x)\r\n\r\n        x = self.d_prior(x)\r\n        x = self.d_out(x)\r\n        return x\r\n\r\n    @tf.function\r\n    def train_step(self, x, y):\r\n        with tf.GradientTape() as tape:\r\n            predictions = self.call(x, training=True)\r\n\r\n            if LOSS_TYPE1 == 'CE':\r\n                y_one_hot = tf.one_hot(y, self.n_class)\r\n                loss = self.loss_object(y_one_hot, predictions)\r\n            elif LOSS_TYPE1 == 'SCE':\r\n                loss = self.loss_object(y, predictions)\r\n\r\n            # print('loss', loss)\r\n        gradients = tape.gradient(loss, self.trainable_variables)\r\n        # print([gvs.shape for gvs in gradients])\r\n\r\n        # gradients = [\r\n        #     tf.where(\r\n        #         tf.math.is_nan(grad),\r\n        #         tf.zeros_like(grad),\r\n        #         grad\r\n        #     )\r\n        #     for grad in gradients\r\n        # ]\r\n\r\n        # print('gradients', gradients)\r\n        self.optimizer.apply_gradients(zip(gradients, self.trainable_variables))\r\n        self.train_loss(loss)\r\n        self.train_acc.update_state(y, predictions)\r\n        return loss\r\n\r\n    @tf.function\r\n    def test_step(self, x, y):\r\n        predictions = self.call(x, training=False)\r\n        if LOSS_TYPE1 == 'CE':\r\n            y_one_hot = tf.one_hot(y, self.n_class)\r\n            t_loss = self.loss_object(y_one_hot, predictions)\r\n        elif LOSS_TYPE1 == 'SCE':\r\n            t_loss = self.loss_object(y, predictions)\r\n        # t_loss = tf.reduce_sum(t_loss) * (1. / BATCH_SIZE)\r\n        self.test_loss(t_loss)\r\n        self.test_acc.update_state(y, predictions)\r\n\r\n    @tf.function\r\n    def validate_step(self, x, y):\r\n        predictions = self.call(x, training=False)\r\n        if LOSS_TYPE1 == 'CE':\r\n            y_one_hot = tf.one_hot(y, self.n_class)\r\n            v_loss = self.loss_object(y_one_hot, predictions)\r\n        elif LOSS_TYPE1 == 'CE':\r\n            v_loss = self.loss_object(y, predictions)\r\n        # t_loss = tf.reduce_sum(t_loss) * (1. / BATCH_SIZE)\r\n        self.validate_loss(v_loss)\r\n        self.validate_acc.update_state(y, predictions)\r\n\r\n\r\nif __name__ == '__main__':\r\n    x_train = train_images()\r\n    y_train = train_labels()\r\n\r\n    x_test = test_images()\r\n    y_test = test_labels()\r\n\r\n    print(np.shape(y_train))\r\n\r\n    model = MNISTModel(NCLASS)\r\n\r\n    train_ds = tf.data.Dataset.from_tensor_slices(\r\n        (x_train, y_train)\r\n    ).shuffle(10000).batch(BATCH_SIZE)\r\n\r\n    test_ds = tf.data.Dataset.from_tensor_slices(\r\n        (x_test, y_test)\r\n    ).batch(BATCH_SIZE)\r\n\r\n    for epoch in range(EPOCHS):\r\n        for x, y in train_ds:\r\n            model.train_step(x, y)\r\n\r\n        for x, y in test_ds:\r\n            model.test_step(x, y)\r\n\r\n        template = 'Epoch {}, Train Loss: {}, Test Loss: {}, Train Acc: {}, Test Acc: {}'\r\n\r\n        epoch_str = template.format(\r\n            epoch + 1,\r\n            model.train_loss.result(),\r\n            model.test_loss.result(),\r\n            model.train_acc.result(),\r\n            model.test_acc.result()\r\n        )\r\n        print(epoch_str)\r\n\r\n        # Reset the metrics for the next epoch\r\n        model.train_loss.reset_states()\r\n        model.test_loss.reset_states()\r\n        model.train_acc.reset_states()\r\n        model.test_acc.reset_states()\r\n\r\n```", "@ziruizhuang Sorry for the late reply. I have updated some parts of your code such as removing `y_input`, `one_hot` etc. Now the code works as expected. [Here](https://colab.sandbox.google.com/gist/jvishnuvardhan/11beee9505007770ab8a750b4a567fdf/untitled733.ipynb) is the gist for your reference. These modifications are good for `loss=tf.keras.losses.SparseCategoricalCrossentropy()` but you can do similar things for `loss=tf.keras.losses.CategoricalCrossentropy()`. Thanks!\r\n\r\nI am closing this issue as it was resolved. Please feel free to open a new issue related to this work. Thanks! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33855\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33855\">No</a>\n", "@jvishnuvardhan Thank you for the gist. Now I see how to make it work using SparseCategoricalCrossentropy loss and keras model. \r\n\r\nStill, a little more discussion on this topic. Is it a designed behavior that a keras model always produce floating point output? I mean it would be more straightforward using the following two sets of configuration:\r\n\r\n * Config 1\r\n   - train_y/test_y are one_hot/probability vector (float), and y_output is probability vector (float)\r\n   - use CategoricalCrossentropy\r\n * Config 2\r\n   - train_y/test_y are integers, and y_output is integer as well\r\n   - use SparseCategoricalCrossentropy \r\n\r\nBasically, if a model learns to produce integers, it produces integers; and if a model learns to produce floats, it produces floats. \r\n\r\nHowever, the current behavior is\r\n * Config 3\r\n   - train_y/test_y are integers, and y_output is probability vector (float)\r\n   - use SparseCategoricalCrossentropy \r\n\r\nThat is to say, the model learns to produce integers, but it produces floats instead. \r\n\r\nAnd the exception thrown out is confusing if we ever try with Config 2. it says\r\n`TypeError: Expected int64, got 1e-07 of type 'float' instead.`\r\nwhich intuitively means something in the code should be int64 but we gave a really small float instead? In that sense, we should debug and find if something else should be cast to int64 in our code, which is the quite opposite of the reality. ", "@ziruizhuang Model generally output probabilities in classification. Please check a [tutorial](https://www.tensorflow.org/tutorials/quickstart/beginner) on `TF website`. If you want to predict classes, you can do \r\n\r\n```\r\ny_pred = model.predict(x_train)\r\npredictions = tf.argmax(y_pred,axis=1)\r\n```\r\n\r\nPlease post further questions in Stackoverflow. We will answer there. We want to keep this GitHub repository to address mainly bug/performance issues. Thanks!\r\n"]}, {"number": 33854, "title": "Add device annotations to gradient_function", "body": "This colocates the gradient functions with the input tensors.\r\nOtherwise they would be executed on the device that is current when\r\ncalling GradientTape.gradient() which breaks splitting a large model\r\nacross multiple GPUs.\r\n\r\nFixes #33688", "comments": ["Sure, done.", "Can you look at the failing tests? Some seem suspicious that something is seriously wrong here.", "I think the keras tests fail because the backward function is now executed on the CPU since the inputs are there. And the CPU implementation of the conv backward functions do not support 'channels_first', i.e. NCHW format.\r\nIt might be better to execute the backward function on the same device as the forward function...\r\n\r\nI don't know yet why exactly the eager forwardprop test fails. The gradient from the backward functions is still correct after applying this patch, but the numeric one is not. I will need some more time to figure out what is going on.\r\n\r\nI have an unrelated problem here with distribute tests that I have to solve first. But also here the problem might be that the last gradient op and the gradient values are on the device that has the input values.", "+Allen Lavoie <allenl@google.com> do you know what is happening with the\nforwardprop test?\n\nNiels, I thought the goal of your change was to run the backward on the\nsame device as the forward, so I'm quite surprised that in the keras test\nthis is not happening. Note that we keep tensors from the forward pass\nalive, so we should be able to look at their devices when placing things.\nOr am I missing something?\n\nOn Wed, Nov 6, 2019 at 6:00 AM Niels Ole Salscheider <\nnotifications@github.com> wrote:\n\n> I think the keras tests fail because the backward function is now executed\n> on the CPU since the inputs are there. And the CPU implementation of the\n> conv backward functions do not support 'channels_first', i.e. NCHW format.\n> As I said it might be better to execute the backward function on the same\n> device as the forward function, but we do not record that information on\n> the tape.\n>\n> I don't know yet why exactly the eager forwardprop test fails. The\n> gradient from the backward functions is still correct after applying this\n> patch, but the numeric one is not. I will need some more time to figure out\n> what is going on.\n>\n> I have an unrelated problem here with distribute tests that I have to\n> solve first. But also here the problem might be that the last gradient op\n> and the gradient values are on the device that has the input values.\n>\n> \u2014\n> You are receiving this because your review was requested.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/33854?email_source=notifications&email_token=AAABHRJHGRSTKQUG3ZD4HQLQSLEV7A5CNFSM4JG6BTK2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEDGTB4I#issuecomment-550318321>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHRO6CO34RQPDI3NIISLQSLEV7ANCNFSM4JG6BTKQ>\n> .\n>\n\n\n-- \n - Alex\n", "With my change we place the backward computation on the device of the first input tensor. In most of the cases this is the same device as the forward computation but it actually is not for the first node that is computed on another device on the forward pass. And this test hits exactly a node where this condition holds.\r\n\r\nI first tried to use output nodes instead of input nodes in the patch, but these were None (most of the time at least). I'm not sure if that is expected but...\r\n\r\nAs I said in the feature request it would be best to use the device placement of the forward pass directly but I think we don't have that information anymore unless we record it to the tape?", "The device placement of the forward pass is available as the device on\nwhich the forward pass input/output tensors live, though, and the tape\nkeeps those around.\n\nOn Wed, Nov 6, 2019 at 9:11 AM Niels Ole Salscheider <\nnotifications@github.com> wrote:\n\n> With my change we place the backward computation on the device of the\n> first input tensor. In most of the cases this is the same device as the\n> forward computation but it actually is not for the first node that is\n> computed on another device on the forward pass. And this test hits exactly\n> a node where this condition holds.\n>\n> I first tried to use output nodes instead of input nodes in the patch, but\n> these were None (most of the time at least). I'm not sure if that is\n> expected but...\n>\n> As I said in the feature request it would be best to use the device\n> placement of the forward pass directly but I think we don't have that\n> information anymore unless we record it to the tape?\n>\n> \u2014\n> You are receiving this because your review was requested.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/33854?email_source=notifications&email_token=AAABHRJRSU6XHNL66R3KKJ3QSL3CHA5CNFSM4JG6BTK2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEDHIIMI#issuecomment-550405169>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHRKMY6UOTIF4AZ5CKVDQSL3CHANCNFSM4JG6BTKQ>\n> .\n>\n\n\n-- \n - Alex\n", "Which forwardprop test has an issue? Could just be that the GPU versions\nhave different numerics (or something like that). Depending on the test the\ntolerance may just be set too low.\n\nOn Wed, Nov 6, 2019 at 8:49 AM Alexandre Passos <apassos@google.com> wrote:\n\n> +Allen Lavoie <allenl@google.com> do you know what is happening with the\n> forwardprop test?\n>\n> Niels, I thought the goal of your change was to run the backward on the\n> same device as the forward, so I'm quite surprised that in the keras test\n> this is not happening. Note that we keep tensors from the forward pass\n> alive, so we should be able to look at their devices when placing things.\n> Or am I missing something?\n>\n> On Wed, Nov 6, 2019 at 6:00 AM Niels Ole Salscheider <\n> notifications@github.com> wrote:\n>\n>> I think the keras tests fail because the backward function is now\n>> executed on the CPU since the inputs are there. And the CPU implementation\n>> of the conv backward functions do not support 'channels_first', i.e. NCHW\n>> format.\n>> As I said it might be better to execute the backward function on the same\n>> device as the forward function, but we do not record that information on\n>> the tape.\n>>\n>> I don't know yet why exactly the eager forwardprop test fails. The\n>> gradient from the backward functions is still correct after applying this\n>> patch, but the numeric one is not. I will need some more time to figure out\n>> what is going on.\n>>\n>> I have an unrelated problem here with distribute tests that I have to\n>> solve first. But also here the problem might be that the last gradient op\n>> and the gradient values are on the device that has the input values.\n>>\n>> \u2014\n>> You are receiving this because your review was requested.\n>> Reply to this email directly, view it on GitHub\n>> <https://github.com/tensorflow/tensorflow/pull/33854?email_source=notifications&email_token=AAABHRJHGRSTKQUG3ZD4HQLQSLEV7A5CNFSM4JG6BTK2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEDGTB4I#issuecomment-550318321>,\n>> or unsubscribe\n>> <https://github.com/notifications/unsubscribe-auth/AAABHRO6CO34RQPDI3NIISLQSLEV7ANCNFSM4JG6BTKQ>\n>> .\n>>\n>\n>\n> --\n>  - Alex\n>\n", "> The device placement of the forward pass is available as the device on which the forward pass input/output tensors live, though, and the tape keeps those around.\r\n\r\nWell, that's what I'm using. But as I said, at least when it comes to the input tensors there are a few exceptions were that assumption does not hold. E.g in Op1(cpu:0) -> Tensor1(cpu:0) -> Op2(gpu:0). Here, Tensor1 is the input to Op2 but has device cpu:0 because it was produced by Op1 which is on cpu:0.\r\n\r\nUsing the output nodes might work better but for me the `outputs` variable passed to `_gradient_function` has no device annotations or is None.", "> Which forwardprop test has an issue? Could just be that the GPU versions have different numerics (or something like that). Depending on the test the tolerance may just be set too low.\r\n\r\nThis is unlikely, the numeric gradient changes dramatically. It's only the `testBatchNormFused` test that fails.", "The outputs variable will sometimes be empty. So maybe we use it if it's\nthere, failing that the inputs, and failing that the gradient?\n\nOn Wed, Nov 6, 2019 at 9:35 AM Niels Ole Salscheider <\nnotifications@github.com> wrote:\n\n> The device placement of the forward pass is available as the device on\n> which the forward pass input/output tensors live, though, and the tape\n> keeps those around.\n>\n> Well, that's what I'm using. But as I said, at least when it comes to the\n> input tensors there are a few exceptions were that assumption does not\n> hold. E.g in Op1(cpu:0) -> Tensor1(cpu:0) -> Op2(gpu:0). Here, Tensor1 is\n> the input to Op2 but has device cpu:0 because it was produced by Op1 which\n> is on cpu:0.\n>\n> Using the output nodes might work better but for me the outputs variable\n> passed to _gradient_function has no device annotations or is None.\n>\n> \u2014\n> You are receiving this because your review was requested.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/33854?email_source=notifications&email_token=AAABHRLFO4W3UEOMHJHCNV3QSL56HA5CNFSM4JG6BTK2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEDHK4IA#issuecomment-550415904>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHRKDKOEZ7FZX3P6OMY3QSL56HANCNFSM4JG6BTKQ>\n> .\n>\n\n\n-- \n - Alex\n", "That's what I wanted to do first. I'm not sure if this prevents wrong assignment in any case, though.\r\nBut the bigger problem is that all the output variables passed to that function lack any device attribute. So I can't use that to assign the device placement.\r\nDo you have any idea why the device attribute is not there?", "Can you give me an example of what you mean by variables lacking the device\nattribute? All tensors have a device attribute...\n\nOn Wed, Nov 6, 2019 at 10:18 AM Niels Ole Salscheider <\nnotifications@github.com> wrote:\n\n> That's what I wanted to do first. I'm not sure if this prevents wrong\n> assignment in any case, though.\n> But the bigger problem is that all the output variables passed to that\n> function lack any device attribute. So I can't use that to assign the\n> device placement.\n> Do you have any idea why the device attribute is not there?\n>\n> \u2014\n> You are receiving this because your review was requested.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/33854?email_source=notifications&email_token=AAABHRISN2XCSKJP2VKBK3DQSMC63A5CNFSM4JG6BTK2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEDHPH4A#issuecomment-550433776>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHRLU5HTZPQBSEAR6LOLQSMC63ANCNFSM4JG6BTKQ>\n> .\n>\n\n\n-- \n - Alex\n", "I somehow remembered that the device attribute was set to `None`, but that is wrong. Sorry for that.\r\n\r\nI can get the keras tests to pass if I use output devices (if available) and hack `OpGradientDoesntRequireOutputIndices` to always return false. Without the latter the tests fail because it falls back to the input devices. I will try to find a nicer solution for that tomorrow.", "You're right, that looks like a concerning change in the fused batch norm gradient test. FWIW that assertion is not testing the forward gradient code at all, it's just comparing the backward gradient to the numeric equivalent. (https://github.com/tensorflow/tensorflow/pull/33854#issuecomment-550412171 was me, I accidentally impersonated Alex)\r\n\r\nIf the symbolic gradient is the same either way and the numeric gradient is different, then it sounds like fused batch norm is computing something different on GPU than it is on CPU. So maybe the gradient is correct but the forward pass is incorrect. You can file a bug and skip that test on GPU to unblock this PR..."]}, {"number": 33853, "title": "Tensorflow lite undefined reference on ARM64", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NVIDIA Drive PX2\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: master\r\n- GCC/Compiler version (if compiling from source): 5.5.0\r\n- CUDA/cuDNN version: 9.2/7.1.2\r\n- GPU model and memory: NVIDIA GP106\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nI cloned the tensorflow repository, then executed (as specified [here](https://www.tensorflow.org/lite/guide/build_arm64)) : \r\n`./tensorflow/lite/tools/make/download_dependencies.sh`\r\n`./tensorflow/lite/tools/make/build_aarch64_lib.sh`\r\n\r\nThen I tried to compile [minimal.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/examples/minimal/minimal.cc) with : \r\n`g++ minimal.cc -L /media/hdd/repositories/tensorflow/tensorflow/lite/tools/make/gen/aarch64_armv8-a/lib/libtensorflow-lite.a -o test -std=c++11 -I /media/hdd/repositories/tensorflow/ -I /media/hdd/repositories/flatbuffers/include`\r\n\r\nThis gives me the error :\r\n\r\n`/tmp/cceONMdq.o: In function `main':\r\nminimal.cc:(.text+0x6c): undefined reference to `tflite::DefaultErrorReporter()'\r\nminimal.cc:(.text+0x80): undefined reference to `tflite::FlatBufferModel::BuildFromFile(char const*, tflite::ErrorReporter*)'\r\nminimal.cc:(.text+0xe0): undefined reference to `tflite::ops::builtin::BuiltinOpResolver::BuiltinOpResolver()'\r\nminimal.cc:(.text+0x100): undefined reference to `tflite::InterpreterBuilder::InterpreterBuilder(tflite::FlatBufferModel const&, tflite::OpResolver const&)'\r\nminimal.cc:(.text+0x110): undefined reference to `tflite::InterpreterBuilder::operator()(std::unique_ptr<tflite::Interpreter, std::default_delete<tflite::Interpreter> >*)'\r\nminimal.cc:(.text+0x174): undefined reference to `tflite::Interpreter::AllocateTensors()'\r\nminimal.cc:(.text+0x1d8): undefined reference to `tflite::PrintInterpreterState(tflite::Interpreter*)'\r\nminimal.cc:(.text+0x1e4): undefined reference to `tflite::Interpreter::Invoke()'\r\nminimal.cc:(.text+0x248): undefined reference to `tflite::PrintInterpreterState(tflite::Interpreter*)'\r\nminimal.cc:(.text+0x25c): undefined reference to `tflite::InterpreterBuilder::~InterpreterBuilder()'\r\nminimal.cc:(.text+0x2a4): undefined reference to `tflite::InterpreterBuilder::~InterpreterBuilder()'\r\n/tmp/cceONMdq.o: In function `std::default_delete<tflite::FlatBufferModel>::operator()(tflite::FlatBufferModel*) const':\r\nminimal.cc:(.text._ZNKSt14default_deleteIN6tflite15FlatBufferModelEEclEPS1_[_ZNKSt14default_deleteIN6tflite15FlatBufferModelEEclEPS1_]+0x24): undefined reference to `tflite::FlatBufferModel::~FlatBufferModel()'\r\n/tmp/cceONMdq.o: In function `std::default_delete<tflite::Interpreter>::operator()(tflite::Interpreter*) const':\r\nminimal.cc:(.text._ZNKSt14default_deleteIN6tflite11InterpreterEEclEPS1_[_ZNKSt14default_deleteIN6tflite11InterpreterEEclEPS1_]+0x24): undefined reference to `tflite::Interpreter::~Interpreter()'\r\n/tmp/cceONMdq.o: In function `tflite::MutableOpResolver::~MutableOpResolver()':\r\nminimal.cc:(.text._ZN6tflite17MutableOpResolverD2Ev[_ZN6tflite17MutableOpResolverD5Ev]+0xc): undefined reference to `vtable for tflite::MutableOpResolver'\r\nminimal.cc:(.text._ZN6tflite17MutableOpResolverD2Ev[_ZN6tflite17MutableOpResolverD5Ev]+0x10): undefined reference to `vtable for tflite::MutableOpResolver'\r\n/tmp/cceONMdq.o: In function `tflite::ops::builtin::BuiltinOpResolver::~BuiltinOpResolver()':\r\nminimal.cc:(.text._ZN6tflite3ops7builtin17BuiltinOpResolverD2Ev[_ZN6tflite3ops7builtin17BuiltinOpResolverD5Ev]+0xc): undefined reference to `vtable for tflite::ops::builtin::BuiltinOpResolver'\r\nminimal.cc:(.text._ZN6tflite3ops7builtin17BuiltinOpResolverD2Ev[_ZN6tflite3ops7builtin17BuiltinOpResolverD5Ev]+0x10): undefined reference to `vtable for tflite::ops::builtin::BuiltinOpResolver'\r\ncollect2: error: ld returned 1 exit status`\r\n\r\nI tried options from https://github.com/tensorflow/tensorflow/issues/27629 and https://github.com/tensorflow/tensorflow/issues/16219 but this had no effect.\r\n\r\nI am not an expert in compiling, an idea what I should do ?\r\nThank you !\r\n", "comments": ["i have the same problem, how did you fix it?", "I have this issue as well. Any word on a fix?", "The fix was to remove the -L in front of the .a library :\r\n`g++ minimal.cc /media/hdd/repositories/tensorflow/tensorflow/lite/tools/make/gen/aarch64_armv8-a/lib/libtensorflow-lite.a -o test -std=c++11 -I /media/hdd/repositories/tensorflow/ -I /media/hdd/repositories/flatbuffers/include`"]}, {"number": 33852, "title": "[TF-Nightly-20191030] Import fails with SegFault on Custom-Op docker image", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 (Maybe others)\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): tf-nightly-20191030\r\n\r\n**Describe the current behavior**\r\nTensorFlow SegFaults on import\r\n\r\n**Code to reproduce the issue**\r\n```\r\ndocker run --rm -it tensorflow/tensorflow:custom-op-ubuntu16 /bin/bash\r\npip install tf-nightly==2.1.0.dev20191030\r\npython -c 'import tensorflow as tf'\r\n```\r\n\r\nProduces:\r\n```\r\n2019-10-30 15:12:21.473867: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory\r\n2019-10-30 15:12:21.473933: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\nSegmentation fault (core dumped)\r\n```\r\n\r\nI didn't see this behavior in colab so not sure whats causing this. Our GPU docker image imports successfully but downstream Addons GPU tests are breaking on this nightly so it would be helpful to identify the commit that is causing these issues.\r\n\r\ncc @yifeif @gunan \r\n", "comments": ["Thanks for the fix @yifeif !"]}, {"number": 33851, "title": "TF lite Gpu delegate  E/libEGL: call to OpenGL ES API with no current context (logged once per thread)", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nFllow this document \r\n[https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tensorflowlite.md](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/running_on_mobile_tensorflowlite.md)\r\nand using this project in android studio.\r\nhttps://github.com/tensorflow/examples/tree/master/lite/examples/object_detection\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) : virtual device Pixel 2 in Android Studio\r\n- TensorFlow installed from (source or binary):java package\r\n- TensorFlow version (use command below):   \r\norg.tensorflow:tensorflow-lite:0.0.0-nightly\r\norg.tensorflow:tensorflow-lite-gpu:0.0.0-nightly\r\n- Python version:---\r\n- Bazel version (if compiling from source):---\r\n- GCC/Compiler version (if compiling from source):---\r\n- CUDA/cuDNN version:CUDA 10.0\r\n- GPU model and memory: gpu 1080\r\n\r\n\r\n**Describe the current behavior**\r\nMy retrain ssd_mobilenet_v2 model with my  own datasets--called detect.tflite \r\n\r\nInput shape\r\n```\r\n[{'name': 'normalized_input_image_tensor',\r\n  'index': 308,\r\n  'shape': array([  1, 300, 300,   3], dtype=int32),\r\n  'dtype': numpy.float32,\r\n  'quantization': (0.0, 0)}]\r\n\r\n```\r\n\r\nOutput shape\r\n\r\n```\r\n[{'name': 'TFLite_Detection_PostProcess',\r\n  'index': 300,\r\n  'shape': array([ 1, 10,  4], dtype=int32),\r\n  'dtype': numpy.float32,\r\n  'quantization': (0.0, 0)},\r\n {'name': 'TFLite_Detection_PostProcess:1',\r\n  'index': 301,\r\n  'shape': array([ 1, 10], dtype=int32),\r\n  'dtype': numpy.float32,\r\n  'quantization': (0.0, 0)},\r\n {'name': 'TFLite_Detection_PostProcess:2',\r\n  'index': 302,\r\n  'shape': array([ 1, 10], dtype=int32),\r\n  'dtype': numpy.float32,\r\n  'quantization': (0.0, 0)},\r\n {'name': 'TFLite_Detection_PostProcess:3',\r\n  'index': 303,\r\n  'shape': array([1], dtype=int32),\r\n  'dtype': numpy.float32,\r\n  'quantization': (0.0, 0)}]\r\n\r\n```\r\n\r\nIt could run object detect app using  `https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection` projects, Just modify path to tflite and labelmap.\r\n\r\nHowever we want to Using Gpu delegate like  https://www.tensorflow.org/lite/performance/gpu.\r\n\r\nso I just using mobile_ssd_v2_float_coco.tflite which download from https://www.tensorflow.org/lite/performance/gpu .\r\n\r\n```\r\ninput_details\r\n[{'name': 'normalized_input_image_tensor',\r\n  'index': 306,\r\n  'shape': array([  1, 320, 320,   3], dtype=int32),\r\n  'dtype': numpy.float32,\r\n  'quantization': (0.0, 0)}]\r\n\r\noutput_details                                                                          \r\n\r\n[{'name': 'raw_outputs/box_encodings',\r\n  'index': 307,\r\n  'shape': array([   1, 2034,    4], dtype=int32),\r\n  'dtype': numpy.float32,\r\n  'quantization': (0.0, 0)},\r\n {'name': 'raw_outputs/class_predictions',\r\n  'index': 308,\r\n  'shape': array([   1, 2034,   91], dtype=int32),\r\n  'dtype': numpy.float32,\r\n  'quantization': (0.0, 0)}]\r\n\r\n```\r\n\r\n\r\nBut report this error in Android Studio when using virtual devices pixel 2 to Debug.\r\n```\r\nE/libEGL: call to OpenGL ES API with no current context (logged once per thread)\r\nE/AndroidRuntime: FATAL EXCEPTION: main\r\n                  Process: org.tensorflow.lite.examples.detection, PID: 5063\r\n                  java.lang.RuntimeException: java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: OpenCL library not loaded - dlopen failed: library \"libOpenCL-pixel.so\" not found\r\n                  Falling back to OpenGL\r\n                  TfLiteGpuDelegate Init: [GL_INVALID_ENUM]: An unacceptable value is specified for an enumerated argument.: glGetBufferParameteri64v in tensorflow/lite/delegates/gpu/gl/gl_buffer.cc:46\r\n                  TfLiteGpuDelegate Prepare: delegate is not initialized\r\n                  Node number 116 (TfLiteGpuDelegateV2) failed to prepare.\r\n\r\n``` \r\n\r\nIf I use my detect.tflite, error is \r\n\r\n```\r\ndelegate:\r\n                  CUSTOM TFLite_Detection_PostProcess: Operation is not supported.\r\n                  First 114 operations will run on the GPU, and the remaining 1 on the CPU.\r\n                  OpenCL library not loaded - dlopen failed: library \"libOpenCL-pixel.so\" not found\r\n```\r\n\r\nAnd I modify TFLiteObjectDetectionAPIModel.java to use Gpu Delegate:\r\n\r\n```\r\n  private ByteBuffer imgData;\r\n\r\n  private Interpreter tfLite;\r\n + private static GpuDelegate delegate = new GpuDelegate();\r\n + private static  Interpreter.Options options = (new Interpreter.Options()).addDelegate(delegate);\r\n  private TFLiteObjectDetectionAPIModel() {}\r\n\r\n.....\r\n.....\r\npublic static Classifier create(\r\n...\r\n\r\n+d.tfLite = new Interpreter(loadModelFile(assetManager, modelFilename),options);\r\n\r\n\r\n```\r\n\r\n\r\n**Describe the expected behavior**\r\n\r\n1.Why the mobile_ssd_v2_float_coco.tflite input shape and output shape is different from the model  retrained using object detection api ? \r\n2.The code  I modifyied  TFLiteObjectDetectionAPIModel.java to using Gpu delegate  is right?\r\n\r\n\r\n", "comments": ["Hi,\r\n\r\nI'm the assigned \"tensorflower\".  Sorry for the late response; I was out on a conference.\r\n\r\n1. Unfortunately, I'm not familiar with the object detection API and cannot answer your first question.\r\n2. It should be okay.  You can ignore the error messages `CUSTOM ... is not supported.` as it just a warning message.  It should be about the same for the `OpenCL library not loaded...` message as well.  It should fall back to OpenGL in that case.  In fact that's what the log in `FATAL EXCEPTION...` is describing.  Your program is probably failing because you are using a virtual device.  Emulators don't support compute shaders well, and can fail.  Can you check whether it fails on a real device?", "> Hi,\r\n> \r\n> I'm the assigned \"tensorflower\". Sorry for the late response; I was out on a conference.\r\n> \r\n> 1. Unfortunately, I'm not familiar with the object detection API and cannot answer your first question.\r\n> 2. It should be okay.  You can ignore the error messages `CUSTOM ... is not supported.` as it just a warning message.  It should be about the same for the `OpenCL library not loaded...` message as well.  It should fall back to OpenGL in that case.  In fact that's what the log in `FATAL EXCEPTION...` is describing.  Your program is probably failing because you are using a virtual device.  Emulators don't support compute shaders well, and can fail.  Can you check whether it fails on a real device?\r\n\r\nThank you\uff01On xiaomi 8 SE\uff0cGpu delegate ~60ms!\r\n\r\nBut how to get tflite file Like mobile_ssd_v2_float_coco.tflite \uff1f(mobile_ssd_v2_float_coco.tflite which download from https://www.tensorflow.org/lite/performance/gpu .  https://storage.googleapis.com/download.tensorflow.org/models/tflite/gpu/mobile_ssd_v2_float_coco.tflite)", "Hm, I was not directly involved in creating that model file, so the correct answer would be \"I don't know\".  There are two possibilities:\r\n* Either the Python script was modified to match the dimensions,\r\n* Or the TOCO was invoked with the new input dimensions.\r\n\r\nI don't think the person who prepared the TFLite file re-trained things with the 1st option.  I am guessing the 2nd option.", "OK\uff0cThank you very much!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33851\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33851\">No</a>\n", "> OK\uff0cThank you very much!\r\n\r\nHey, can you share that float model which you modified."]}, {"number": 33850, "title": "what is gen_rnn_ops in tensorflow/python/ops", "body": "Hi, I am trying to create my own linear tanh&sigmoid activation functions for lstmblockfusedcell (in lstm_ops.py), thus I directly create my own activation functions in rnn_cell_impl.py file and import this file in my own lstm_ops.py file. \r\nThen I got an error msg as follows:\r\n`File \"/home/git/DeepSpeech/lstm_ops_dpsp.py\", line 29, in <module>\r\n    from tensorflow.python.ops import gen_rnn_ops\r\nImportError: cannot import name 'gen_rnn_ops'`\r\n\r\nBut there is no much useful information about this _gen_rnn_ops_, and also I want to know whether my way to change the activation function is okay. \r\n\r\nBy the way, I'm using \r\nUbuntu 16.04\r\npython 3.5\r\ntensorflow-estimator 1.13.0\r\ntensorflow-gpu       1.13.1\r\n\r\nThank you \r\n\r\n", "comments": ["@Vampsj \r\nIn order to expedite the trouble-shooting process, please provide a minimal standalone code to reproduce the issue reported here. Thanks!", "@ravikyram Sorry for the lack of codes! \r\nI am working on Deepspeech(Mozilla) but trying to replace the activation functions with linear approximated functions in the LSTM. Here is a piece of the code, they used *LSTMBlockFusedCell* here. Thus I copied the _lstm\\_ops.py, rnn.py, rnn\\_cell\\_impl.py_ files and changed activation functions in _rnn\\_cell\\_impl.py_, and import my changed _rnn\\_cell\\_impl.py_ into the rest two files. \r\n\r\nCode in Deepspeech: \r\n```python\r\nimport Tensorflow as tf  \r\nimport rnn_dpsp as td_rnn # a copy of Tensorflow/python/ops/rnn.py\r\nimport lstm_ops_dpsp as td_lstm_ops # Tensorflow/python/ops/lstm_ops.py\r\nimport rnn_cell_impl_dpsp as td_rnn_cell # which is a copy of Tensorflow/python/ops/rnn_cell_impl.py  \r\ndef rnn_impl_lstmblockfusedcell(x, seq_length, previous_state, reuse):   \r\n     # Forward direction cell:  \r\n     # Original code: fw_cell = tf.contrib.rnn.LSTMBlockFusedCell(Config.n_cell_dim, reuse=reuse)  \r\n    fw_cell = td_lstm_ops.LSTMBlockFusedCell(Config.n_cell_dim, reuse=reuse)  \r\n    output, output_state = fw_cell(inputs=x,  \r\n                                   dtype=tf.float32,  \r\n                                   sequence_length=seq_length,  \r\n                                   initial_state=previous_state)  \r\n    return output, output_state\r\n```\r\nwhere, in my own _rnn_cell_impl_dpsp.py_ file, I added two linear approximated sigmoid&tanh functions:\r\n```python\r\ndef tf_tanh_poly(x, name=None):\r\n    with tf.name_scope(name, \"tanh_poly\", [x]) as name:\r\n        y = py_func(np_tanh_poly_32,\r\n                    [x],\r\n                    [tf.float32],\r\n                    name=name,\r\n                    grad=tanhpgrad)  # <-- here's the call to the gradient\r\n        return y[0]\r\n\r\ndef tf_sigmoid_poly(x, name=None):\r\n    with tf.name_scope(name, \"sigmoid_poly\", [x]) as name:\r\n        y = py_func(np_sigmoid_poly_32,\r\n                    [x],\r\n                    [tf.float32],\r\n                    name=name,\r\n                    grad=sigmoidgrad)  # <-- here's the call to the gradient\r\n        return y[0]\r\n\r\n....\r\n\r\n@tf_export(v1=[\"nn.rnn_cell.BasicLSTMCell\"])\r\nclass BasicLSTMCell(LayerRNNCell):\r\n  @deprecated(None, \"This class is equivalent as tf.keras.layers.LSTMCell,\"\r\n              \" and will be replaced by that in Tensorflow 2.0.\")\r\n  def __init__(self, num_units, forget_bias=1.0,  state_is_tuple=True, activation=None, reuse=None,        name=None,  dtype=None,  **kwargs):\r\n\r\n    self._num_units = num_units\r\n    self._forget_bias = forget_bias\r\n    self._state_is_tuple = state_is_tuple\r\n\r\n    if activation:\r\n      self._activation = math_ops.tanh\r\n    else:\r\n      self._activation = tf_tanh_poly     # HERE\r\n```\r\nand in the rest of two files, I only comment out the original import and changed to my own file :\r\n```python\r\n\"\"\"LSTM Block Cell ops.\"\"\"\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport abc\r\n\r\nimport six\r\n\r\nfrom tensorflow.python.framework import dtypes\r\nfrom tensorflow.python.framework import ops\r\nfrom tensorflow.python.keras.engine import input_spec\r\nfrom tensorflow.python.layers import base as base_layer\r\nfrom tensorflow.python.ops import array_ops\r\nfrom tensorflow.python.ops import gen_rnn_ops\r\nfrom tensorflow.python.ops import init_ops\r\nfrom tensorflow.python.ops import math_ops\r\nfrom tensorflow.python.ops import nn_ops\r\n# from tensorflow.python.ops import rnn_cell_impl\r\nimport rnn_cell_impl_dpsp as rnn_cell_impl\r\n\r\n\r\nLayerRNNCell = rnn_cell_impl.LayerRNNCell  # pylint: disable=invalid-name\r\n\r\n```\r\n\r\nThen I put these files in one folder, but I faced the \r\n`ImportError:in <module> from tensorflow.python.ops import gen_rnn_ops ImportError: cannot import name 'gen_rnn_ops'. \r\n`\r\nFor more detail, I used pip3 to install TensorFlow-gpu 1.13 rather than build from the source.\r\n\r\nI am new to Tensorflow, if there is a better way to change the activation function, please tell me! Thank you!", "@Vampsj, It is working with Tf 1.15.0.\r\nPlease see the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/8326e49854e8d1fbf1c644a51ee01e59/untitled261.ipynb). Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "I  am closing the issue as it was resolved with TF 1.15. Please, feel free to reopen the issue if you feel issue still persists. Thanks!"]}, {"number": 33849, "title": "C API: Session Options for prediction on GPU", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **yes for training and prediction**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Windows 10**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **no**\r\n- TensorFlow installed from (source or binary): **compile from sources**\r\n- TensorFlow version (use command below): **2.0**\r\n- Python version: **3.6.8**\r\n- Bazel version (if compiling from source): **0.24.1**\r\n- GCC/Compiler version (if compiling from source): **Visual Studio 2017 with MSVC 14.16.27023**\r\n- CUDA/cuDNN version: **CUDA 10.1.243 / cuDNN 7.6.4.38**\r\n- GPU model and memory: **NVIDIA GeForce RTX 2060 6Go**\r\n\r\n**Situation**\r\nI create a C++ program to train a model with the aim to perform image segmentation. This part works perfectly on the GPU and I export the pb file. The final application have to be in C# so this pb file is imported and the prediction is performed with TensorFlow.NET.\r\nThe prediction works as expected on CPU but not on the GPU. This issue is probably not caused by TensorFlow.NET (https://github.com/SciSharp/TensorFlow.NET/issues/434) so I think it is caused by C API. I don't understand why the training can be performed on the GPU and the prediction on the same GPU give me an out of memory error when I run the session.\r\n\r\n**Describe the current behavior**\r\nI set the number of GPU to one to be sure and I set the configuration GpuOptions.\r\nTo not allocate all the GPU memory I set allow_growth option to true but the issue is still present.\r\nTo limit the usage of memory I set the parameter per_process_gpu_memory_fraction 0.2, 0.5 or 0.9 but nothing changes.\r\nFor the training I only use allow_growth option and there is not out of memory error. For information I use ClientSession for this part.\r\n\r\n**Describe the expected behavior**\r\nUsing the C API or the original source code, the configuration of GPU must be the one defined with the code. I presume the issue is with the C API because the training in C++ works on GPU.\r\n\r\n**Code to reproduce the issue**\r\nTraining in C++:\r\n```\r\ntensorflow::ConfigProto& config = _sessionOptions.config;\r\nconfig.set_allow_soft_placement(true);\r\nconfig.set_log_device_placement(true);\r\nconfig.mutable_gpu_options()->set_allow_growth(true);\r\n```\r\nPrediction in C#:\r\n```\r\nConfigProto config = new ConfigProto();\r\nconfig.LogDevicePlacement = true;\r\nconfig.AllowSoftPlacement = true;\r\nGPUOptions gpuOptions = new GPUOptions();\r\ngpuOptions.AllowGrowth = true;\r\ngpuOptions.PerProcessGpuMemoryFraction = 0.5;\r\nconfig.DeviceCount.Add(\"GPU\", 1);\r\nconfig.GpuOptions = gpuOptions;\r\n```\r\n\r\n**Other info / logs**\r\nWith the log placement option, I noticed the GPU memory is allocated twice when I call the run method. The first allocation take almost all the available GPU memory then the second one grows \"step by step\". So I presume allow_growth option is operational for the second memory allocation but not the first one.\r\n", "comments": ["After more researches in sources, I think my issue is cause by the usage of GraphDef in ExtendSessionGraphHelper of [c_api.cc](https://github.com/tensorflow/tensorflow/blob/552d6a22f66f6f2c7eb749ac3e79d83a9476b0e2/tensorflow/c/c_api.cc#L315). Am I right ?\r\n```\r\n// TODO(josh11b,mrry): Change Session to be able to use a Graph*\r\n// directly, instead of requiring us to serialize to a GraphDef and\r\n// call Session::Extend().\r\nbool ExtendSessionGraphHelper(TF_Session* session, TF_Status* status)\r\n```\r\nDoes anyone try to do this TODO? Can @josh11b or @mrry help me?", "Can you confirm that TF is indeed trying to use the same GPU you used for training and not a graphics GPU for inference? \r\n\r\n\r\nWhether allow_growth is working on not should be completely unrelated to the TODO you filed.\r\n\r\nCan you give us a small script to reproduce exactly the behavior you're seeing?\r\n", "I confirm that TF is using same GPU for training and prediction.\r\n\r\nI agree allow_growth is working. Could my issue is related to the usage of Session for C API and my usage of Client_Session for training? I know Client_Session has an instance of Session but maybe the GPU configuration is not properly set with Session in C API...\r\n\r\nI don't know how to give you part of my code to reproduce the issue... I can't send you all my program. I'm using C# program with TF.NET that use C API. Did someone already test C API with a huge model (around 5GB on GPU memory)?\r\nWhen I run the model on CPU, RAM reaches 2GB. And when I run the model on GPU, RAM reaches 9GB and GPU memory reach 5.7GB then growth until the out of GPU memory error. I don't understand this memory usage on GPU...", "Could you somehow have two TF runtimes linked into the same process\ncompeting against each other to use the GPU?\n\nI don't really know how to debug this; can you try to make a minimal\nexample (like, maybe a graph which just has a 5gb-sized tf.zeros in it,\nplus the C# code to load it that OOMs)?\n\nOn Tue, Nov 5, 2019 at 3:43 AM quintakFR <notifications@github.com> wrote:\n\n> I confirm that TF is using same GPU for training and prediction.\n>\n> I agree allow_growth is working. Could my issue is related to the usage of\n> Session for C API and my usage of Client_Session for training? I know\n> Client_Session has an instance of Session but maybe the GPU configuration\n> is not properly set with Session in C API...\n>\n> I don't know how to give you part of my code to reproduce the issue... I\n> can't send you all my program. I'm using C# program with TF.NET that use\n> C API. Did someone already test C API with a huge model (around 5GB on GPU\n> memory)?\n> When I run the model on CPU, RAM reaches 2GB. And when I run the model on\n> GPU, RAM reaches 9GB and GPU memory reach 5.7GB then growth until the out\n> of GPU memory error. I don't understand this memory usage on GPU...\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/33849?email_source=notifications&email_token=AAABHRKDPTGFBFCM57TIZW3QSFL4NA5CNFSM4JGYDDU2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEDCRCRA#issuecomment-549785924>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHRJXYDRYT5RSV7446TTQSFL4NANCNFSM4JGYDDUQ>\n> .\n>\n\n\n-- \n - Alex\n", "I'm not sure to totally understand your question. I only use one Session created with TF.NET and I run it once so I'm assuming I only have one TF runtime.\r\n\r\nI will create this little example in the next days. How will I share it to you when it is done? (model file is around 112 MB)", "You can upload to google drive? Or come up with a smaller/simpler model\nwhich also exhibits the bug?\n\nOn Wed, Nov 6, 2019 at 12:35 AM quintakFR <notifications@github.com> wrote:\n\n> I'm not sure to totally understand your question. I only use one Session\n> created with TF.NET and I run it once so I'm assuming I only have one TF\n> runtime.\n>\n> I will create this little example in the next days. How will I share it to\n> you when it is done? (model file is around 112 MB)\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/33849?email_source=notifications&email_token=AAABHRIMBFIPE5EOEPCZEIDQSJ6VLA5CNFSM4JGYDDU2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEDFWNYY#issuecomment-550201059>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHRMK6N335SA7EAAXAMTQSJ6VLANCNFSM4JGYDDUQ>\n> .\n>\n\n\n-- \n - Alex\n", "Perfect I will upload it to google drive.\r\nThank you @alextp !", "@alextp I shared with you the program and the model on Google Drive (with you gmail address)\r\nThe variable \"DevicePredict\" in class Constants can be used to run the model on CPU or GPU:\r\n* If you set the variable to \"CPU\", the model will run normally\r\n* If you set the variable to \"GPU\", the error will appear. I use \"watch -n 0.5 nvidia-smi\" in PowerShell to observe the usage of GPU memory\r\n\r\nFor information:\r\n* EmguCV is used to simply manipulate images as matrix (like with OpenCV)\r\n* The TensorFlow dll is the one I build from source. I upload the files I modified to add functions. I didn't upload the BUILD file I modified to generate the dll because it can not be the issue. (Let me know if you would like to have more details about this)\r\n* TensorFlow.NET is developed for TF and not TF2 but the C API is the same between the 2 version so I decided to use TF2. I tested the same program with TF 1.14 and the issue is the same so I think this point could not be the issue", "I changed the version of cuDNN to use 7.4.2.24 then compile TensorFlow. All the GPU memory is allocated even if PerProcessGpuMemoryFraction is set but the issue doesn't appear. So cuDNN 7.4 instead of 7.6 fix the issue but there is still the allocation of the entire GPU memory", "Latest [tensorflow.dll ](https://github.com/tensorflow/tensorflow/issues/35405#issuecomment-653621878)for c# api ", "Is this still an issue for you and please let us know.Thanks!", "No, it's not. I managed all issues of memory allocation and memory access violation. Thanks", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as it seems this is no longer an issue. Please reopen if I am wrong.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33849\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33849\">No</a>\n"]}, {"number": 33848, "title": "CUDNN_STATUS_INTERNAL_ERROR when running with CUDA 10.0 tensorflow-gpu on RTX2080 ubuntu18", "body": "I have Geforce 2080, running latest nvidia drivers, Cuda 10.0, matching cudnn libs and I'm getting \r\nCUDNN_STATUS_INTERNAL_ERROR when running with tensorflow-gpu.\r\n\r\n\r\n**System information**\r\n- NVIDIA drivers:  NVIDIA-SMI 430.50       Driver Version: 430.50       CUDA Version: 10.1  \r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution: Linux Ubuntu 18.04)\r\n- TensorFlow installed from (source or binary): using pip install tensorflow\r\n- TensorFlow version (use command below): v2.0.0-rc2-26-g64c3d38\r\n- Python version: 3.7.4\r\n- GCC/Compiler version (if compiling from source): 7.4\r\n- CUDA: 10.0\r\n- cuDNN version: 7.6.4.38\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nGetting  CUDNN_STATUS_INTERNAL_ERROR when trying to run my tensorflow program.\r\n\r\n```\r\n\r\n> python classify_image2.py --image_file images/dakota/20262694-7620733-A_bit_of_skin_Scarlett_s_chicness_couldn_t_be_denied_as_she_step-a-3_1572251360982.jpg\r\n> Tagging None images/dakota/20262694-7620733-A_bit_of_skin_Scarlett_s_chicness_couldn_t_be_denied_as_she_step-a-3_1572251360982.jpg image_vectors\r\n> WARNING:tensorflow:From classify_image2.py:144: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> Use tf.gfile.GFile.\r\n> W1030 11:25:26.150423 140076018012288 deprecation.py:323] From classify_image2.py:144: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> Use tf.gfile.GFile.\r\n> Creating graph\r\n> 2019-10-30 11:25:26.333540: W tensorflow/core/framework/op_def_util.cc:370] Op BatchNormWithGlobalNormalization is deprecated. It will cease to work in GraphDef version 9. Use tf.nn.batch_normalization().\r\n> 2019-10-30 11:25:26.419195: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n> 2019-10-30 11:25:26.438190: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-10-30 11:25:26.438444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\n> name: GeForce RTX 2080 major: 7 minor: 5 memoryClockRate(GHz): 1.71\r\n> pciBusID: 0000:02:00.0\r\n> 2019-10-30 11:25:26.438552: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n> 2019-10-30 11:25:26.439222: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n> 2019-10-30 11:25:26.439782: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\r\n> 2019-10-30 11:25:26.439910: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\r\n> 2019-10-30 11:25:26.440597: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\r\n> 2019-10-30 11:25:26.441076: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\r\n> 2019-10-30 11:25:26.442559: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n> 2019-10-30 11:25:26.442603: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-10-30 11:25:26.442865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-10-30 11:25:26.443091: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n> 2019-10-30 11:25:26.443293: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n> 2019-10-30 11:25:26.462892: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3600000000 Hz\r\n> 2019-10-30 11:25:26.463602: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fa96c51240 executing computations on platform Host. Devices:\r\n> 2019-10-30 11:25:26.463612: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version\r\n> 2019-10-30 11:25:26.530626: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-10-30 11:25:26.530928: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fa96c50af0 executing computations on platform CUDA. Devices:\r\n> 2019-10-30 11:25:26.530940: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce RTX 2080, Compute Capability 7.5\r\n> 2019-10-30 11:25:26.531026: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-10-30 11:25:26.531249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \r\n> name: GeForce RTX 2080 major: 7 minor: 5 memoryClockRate(GHz): 1.71\r\n> pciBusID: 0000:02:00.0\r\n> 2019-10-30 11:25:26.531267: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n> 2019-10-30 11:25:26.531274: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n> 2019-10-30 11:25:26.531280: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0\r\n> 2019-10-30 11:25:26.531286: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0\r\n> 2019-10-30 11:25:26.531292: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0\r\n> 2019-10-30 11:25:26.531298: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0\r\n> 2019-10-30 11:25:26.531305: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n> 2019-10-30 11:25:26.531328: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-10-30 11:25:26.531555: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-10-30 11:25:26.531763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\r\n> 2019-10-30 11:25:26.531782: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\n> 2019-10-30 11:25:26.532197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n> 2019-10-30 11:25:26.532205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \r\n> 2019-10-30 11:25:26.532208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \r\n> 2019-10-30 11:25:26.532255: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-10-30 11:25:26.532487: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1006] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n> 2019-10-30 11:25:26.532713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7150 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080, pci bus id: 0000:02:00.0, compute capability: 7.5)\r\n> 2019-10-30 11:25:27.283539: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0\r\n> 2019-10-30 11:25:27.486979: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n> 2019-10-30 11:25:27.996932: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\r\n> 2019-10-30 11:25:27.998075: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\r\n> Traceback (most recent call last):\r\n>   File \"/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\r\n>     return fn(*args)\r\n>   File \"/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\r\n>     target_list, run_metadata)\r\n>   File \"/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\r\n>     run_metadata)\r\n> tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.\r\n>   (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n> \t [[{{node conv/Conv2D}}]]\r\n>   (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n> \t [[{{node conv/Conv2D}}]]\r\n> \t [[softmax/_3]]\r\n> 0 successful operations.\r\n> 0 derived errors ignored.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"classify_image2.py\", line 345, in <module>\r\n    tf.compat.v1.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"classify_image2.py\", line 296, in main\r\n    run_inference_on_image(image)\r\n  File \"classify_image2.py\", line 162, in run_inference_on_image\r\n    {'DecodeJpeg/contents:0': image_data})\r\n  File \"/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 956, in run\r\n    run_metadata_ptr)\r\n  File \"/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\r\n    run_metadata)\r\n  File \"/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\", line 1384, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.\r\n  (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n\t [[node conv/Conv2D (defined at /home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]]\r\n  (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n\t [[node conv/Conv2D (defined at /home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]]\r\n\t [[softmax/_3]]\r\n0 successful operations.\r\n0 derived errors ignored.\r\n\r\nOriginal stack trace for 'conv/Conv2D':\r\n  File \"classify_image2.py\", line 345, in <module>\r\n    tf.compat.v1.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"classify_image2.py\", line 296, in main\r\n    run_inference_on_image(image)\r\n  File \"classify_image2.py\", line 149, in run_inference_on_image\r\n    create_graph()\r\n  File \"classify_image2.py\", line 129, in create_graph\r\n    _ = tf.import_graph_def(graph_def, name='')\r\n  File \"/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/framework/importer.py\", line 405, in import_graph_def\r\n    producer_op_list=producer_op_list)\r\n  File \"/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/framework/importer.py\", line 517, in _import_graph_def_internal\r\n    _ProcessNewOps(graph)\r\n  File \"/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/framework/importer.py\", line 243, in _ProcessNewOps\r\n    for new_op in graph._add_new_tf_operations(compute_devices=False):  # pylint: disable=protected-access\r\n  File \"/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3564, in _add_new_tf_operations\r\n    for c_op in c_api_util.new_tf_operations(self)\r\n  File \"/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3564, in <listcomp>\r\n    for c_op in c_api_util.new_tf_operations(self)\r\n  File \"/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 3454, in _create_op_from_tf_operation\r\n    ret = Operation(c_op, self)\r\n  File \"/home/tomburnell/github/news-search-image-similarity/venv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 1751, in __init__\r\n    self._traceback = tf_stack.extract_stack()\r\n\r\n```\r\n\r\n\r\n**Describe the expected behavior**\r\n\r\nIt should not fail with this error  :-)\r\n\r\n\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n\r\nexport LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-10.0/lib64/\r\npython classify.py --image_file  someimage.jpg\r\n\r\n-----------classify.py--------------------\r\n\r\n```\r\n\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nimport argparse\r\nimport os.path\r\nimport re\r\nimport sys\r\nimport tarfile\r\nfrom collections import defaultdict\r\nimport psutil\r\n\r\nimport numpy as np\r\nfrom six.moves import urllib\r\nimport tensorflow as tf\r\n\r\nFLAGS = None\r\n\r\n# pylint: disable=line-too-long\r\nDATA_URL = 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'\r\n\r\ndef create_graph():\r\n  \"\"\"Creates a graph from saved GraphDef file and returns a saver.\"\"\"\r\n  # Creates graph from saved graph_def.pb.\r\n  with tf.compat.v1.gfile.FastGFile(os.path.join(\r\n      FLAGS.model_dir, 'classify_image_graph_def.pb'), 'rb') as f:\r\n    graph_def = tf.compat.v1.GraphDef()\r\n    graph_def.ParseFromString(f.read())\r\n    _ = tf.import_graph_def(graph_def, name='')\r\n\r\ndef run_inference_on_image(image):\r\n  if not tf.io.gfile.exists(image):\r\n    tf.compat.v1.logging.fatal('File does not exist %s', image)\r\n  image_data = tf.compat.v1.gfile.FastGFile(image, 'rb').read()\r\n\r\n  print(\"-----Creating graph\")\r\n  create_graph()\r\n\r\n  with tf.compat.v1.Session() as sess:\r\n    print(\"----Get softmax_tensor\")\r\n    softmax_tensor = sess.graph.get_tensor_by_name('softmax:0')\r\n\r\n    print(\"-----Get predictions\")\r\n    predictions = sess.run(softmax_tensor,\r\n                           {'DecodeJpeg/contents:0': image_data})\r\n\r\n\r\ndef maybe_download_and_extract():\r\n  \"\"\"Download and extract model tar file.\"\"\"\r\n  dest_directory = FLAGS.model_dir\r\n  if not os.path.exists(dest_directory):\r\n    os.makedirs(dest_directory)\r\n  filename = DATA_URL.split('/')[-1]\r\n  filepath = os.path.join(dest_directory, filename)\r\n  if not os.path.exists(filepath):\r\n    def _progress(count, block_size, total_size):\r\n      sys.stdout.write('\\r>> Downloading %s %.1f%%' % (\r\n          filename, float(count * block_size) / float(total_size) * 100.0))\r\n      sys.stdout.flush()\r\n    filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)\r\n    print()\r\n    statinfo = os.stat(filepath)\r\n    print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\r\n  tarfile.open(filepath, 'r:gz').extractall(dest_directory)\r\n\r\n\r\ndef main(_):\r\n  maybe_download_and_extract()\r\n  image = FLAGS.image_file if FLAGS.image_file else None\r\n           # else\r\n           # os.path.join(FLAGS.model_dir, 'cropped_panda.jpg'))\r\n\r\n  run_inference_on_image(image)\r\n\r\n\r\nif __name__ == '__main__':\r\n  parser = argparse.ArgumentParser()\r\n  parser.add_argument(\r\n      '--model_dir',\r\n      type=str,\r\n      default='/tmp/imagenet',\r\n      help=\"\"\"\\\r\n      Path to classify_image_graph_def.pb,\r\n      imagenet_synset_to_human_label_map.txt, and\r\n      imagenet_2012_challenge_label_map_proto.pbtxt.\\\r\n      \"\"\"\r\n  )\r\n  parser.add_argument(\r\n      '--image_file',\r\n      type=str,\r\n      default='',\r\n      help='Absolute path to image file.'\r\n  )\r\n  FLAGS, unparsed = parser.parse_known_args()\r\n  tf.compat.v1.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n~                                                                              \r\n```\r\n\r\n", "comments": ["I found to also be failing in the same way using docker gpu image\r\n\r\n```\r\nsudo docker run --gpus all -it --rm -v $PWD:$PWD  -w $PWD tensorflow/tensorflow:latest-gpu-py3 python classify.py --image_file someimage.jpg\r\n```\r\n\r\nI have shortened the code above that still replicates the problem\r\n\r\n", "Also I should say, the same nvidia driver/cuda/cudnn seems to work fine for my pytorch code\r\n", "@tombburnell Dude just move to Pytorch ! Tensorflow is the biggest crap i have seen in my life.", "@tombburnell, Similar issue [#24496](https://github.com/tensorflow/tensorflow/issues/24496).", "Apologies for the delay in response. Is this still an issue? \r\nYou may try gpu memory resources management by allowing gpu memory growth.  \r\nTo know more see https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth\r\nYou can try Allowing GPU memory growth with:\r\n```python\r\nimport tensorflow as tf\r\ngpu = tf.config.experimental.list_physical_devices('GPU')\r\ntf.config.experimental.set_memory_growth(gpu[0], True)\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33848\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33848\">No</a>\n", "The solution provided by @ymodak worked for me. I am using tensorflow 1.15, cudnn 7.6.5 on conda 4.8.2, Ubuntu 20.04. Thanks for the help. ", "> Apologies for the delay in response. Is this still an issue?\r\n> You may try gpu memory resources management by allowing gpu memory growth.\r\n> To know more see https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth\r\n> You can try Allowing GPU memory growth with:\r\n> \r\n> ```python\r\n> import tensorflow as tf\r\n> gpu = tf.config.experimental.list_physical_devices('GPU')\r\n> tf.config.experimental.set_memory_growth(gpu[0], True)\r\n> ```\r\n\r\nThanks. This solution worked for me. ", "I had the same problem and I solved it with this code\r\n\r\n\r\n`\r\nimport tensorflow as tf\r\nconfig = tf.compat.v1.ConfigProto()\r\nconfig.gpu_options.allow_growth = True\r\nsess = tf.compat.v1.InteractiveSession(config=config)\r\n`"]}, {"number": 33847, "title": "Support SelectV2 in grappler layout transposer", "body": "This issue is extracted from the conversation in https://github.com/tensorflow/tensorflow/pull/33694#issuecomment-546124837\r\n\r\n `SelectV2` currently isn't added to `grappler/op_types.cc`\r\nhttps://github.com/tensorflow/tensorflow/blob/543f61dcab11cc3461c97dcdce660536e3e498d7/tensorflow/core/grappler/op_types.cc#L460\r\nwhich is used in the layout optimizer?\r\nhttps://github.com/tensorflow/tensorflow/blob/543f61dcab11cc3461c97dcdce660536e3e498d7/tensorflow/core/grappler/optimizers/generic_layout_optimizer_transposer_factory.cc#L95-L97\r\n\r\nIdeally the layout optimizer would support `SelectV2` as well so it should be added to `grappler/op_types.cc`.\r\n\r\n@reedwm Mentioned that in `SelectV2`, the inputs do not need to be the same shape but only need to be broadcastable to each other, which might be problematic for the layout optimizer. @andyly, do you know?", "comments": ["Currently the layout optimizer checks for if the first input (the cond) to Select is rank 0, 1, or 4. There is also an assumption that the other inputs (t and e in the op def) are rank 4. There will need to be some changes required for the other inputs in terms of checking if transposes should be added, and which inputs to add transposes to.", "Thanks for the answer, that's good to know. I won't have time anytime soon to send a PR for this, so feel free to take over or close this issue.", "Closing, since it looks like support for this was added in 7ea9c329266e365f667cfb75965543c08bac7476"]}, {"number": 33846, "title": "Grappler: Remove FusedBatchNorm from NeverForwardsInputs list", "body": "@reedwm Mentioned in https://github.com/tensorflow/tensorflow/pull/33698#discussion_r338777281 that all versions of FusedBatchNorm can forward their inputs [here](https://github.com/tensorflow/tensorflow/blob/a12d05f82de28dceb62eaf4bb4b8b9daf3a3057b/tensorflow/core/kernels/fused_batch_norm_op.cc#L1185).\r\n@rmlarsen Is this correct?\r\n\r\nIf this isn't a bug, this list should also include `FusedBatchNormV3`.", "comments": ["Any updates on this?", "Thanks for the fix."]}, {"number": 33845, "title": "Fix for CMSIS-NN operator. Merge from ref conv.cc.", "body": "The testcase \"FilterDimsNotMatchingAffineQuantization\" was failing for CMSIS-NN. The reason is that there has been a change in the ref operator that is now merged into the cmsis operator. Also, I changed kMaxChannels to be able to handle the person detect model.\r\n\r\nChange-Id: I1311d2f8b8c6e297b3af97a7cc0498f146bd4677", "comments": ["@suharshs review approval needed ", "Hi @suharshs , I believe this PR needs your approval as well. Cheers!", "Ready to merge! Error seem unrelated to changes in this PR:\r\n\r\n```\r\n=== Sanity check step 5 of 15: do_buildifier (buildifier check) ===\r\nRunning do_buildifier on 373 files\r\ntensorflow/compiler/xla/BUILD # reformat\r\ntensorflow/compiler/jit/BUILD # reformat\r\nbuildifier took 0 s\r\nFAIL: buildifier found errors and/or warnings in above BUILD files.\r\nbuildifier suggested the following changes:\r\ntensorflow/compiler/xla/BUILD:\r\n1c1\r\n```", "@ravikyram \r\n\r\nReady to merge! \r\n\r\nErrors are still unrelated to this change as far as I can see:\r\n\r\n> ERROR: /tmpfs/tmp/bazel/external/com_google_protobuf/BUILD:106:1: C++ compilation of rule '@com_google_protobuf//:protobuf_lite' failed (Exit 1) gcc failed: error executing command /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections ... (remaining 32 argument(s) skipped)\r\n> \r\n> Use --sandbox_debug to see verbose messages from the sandbox\r\n> gcc: error: unrecognized command line option '-std=c++14'\r\n\r\nLet me know if there's something else I should check."]}, {"number": 33844, "title": "[tf2] Callbacks used in self-defined training", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.0.0\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nFor now,  callbacks can only be used in tf.keras.Model.fit method.\r\nIf one writes a self-defined loop, he has to write his own codes to save model, to show logs on tensorboard, and maybe many other things. \r\nI think if the callbacks are here, why can't we offer some methods to make it usable in self-defined loops ? Actually, self-defined loops also has concepts like batch_begin, epoch_end, etc.\r\nThis will make self-defined loops simple and easy to write. One can focus on many other things he has to do.\r\nThank you !\r\n\r\n**Will this change the current api? How?**\r\n\r\nI think there is no need to change the current api.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nI think the people train with self-defined loops wil benefit.\r\n\r\n**Any Other info.**\r\n", "comments": ["@Yablon Did you find a solution that had you close this issue? If so, I would be interested in knowing what your solution is, as I am currently trying to generalize the passing of callbacks to a keras-like custom training loop.", "@Yablon I agree that this should be reopened. With full distributed training support, TF2 only recommends two ways for training which is `.fit` and custom (gradient tape) training loops. \r\n\r\nAlso I think the callbacks can easily be rewritten so that they are available from custom training loops. E.g. think of using a learning rate scheduler\r\n\r\n```python\r\nsched = ReduceLROnPlateau(optimizer)\r\n\r\ndef train_step(x, y):\r\n    with tf.GradientTape() as tape:\r\n        logits = model(x, training=True)\r\n        loss, metrics = loss_fn(logits, y)\r\n        gradients = tape.gradient(loss, model.trainable_weights)\r\n        optimizer.apply_gradients(\r\n            zip(gradients, model.trainable_weights)\r\n        )\r\n        scheduler.step(loss)\r\n        return loss, metrics\r\n\r\n```\r\n\r\n", "@pandrey-fr @faroit Sorry for a so late reply. I thought the request made me feel myself stupid and I closed it. I thought people skilled at writing codes might write the callback things easily. And I thought maybe I could turn to tf2 later...\r\nAt last, I hope callbacks can be used in self-defined training loops in the future. If we can't, maybe there is a better choice.\r\nThank you! Hope you be safe and sound.   ", "@pandrey-fr @Yablon maybe this might not be necessary anymore with tf2.2 where users can add their custom [train_step to the fit function](https://www.tensorflow.org/versions/r2.2/api_docs/python/tf/keras/Model#fit)...", "@faroit I agree, TF 2.2 solves this issue - well, at least, it provides a general solution to it, which is really great!", "Thank you, I learned a lot ! I should think about turning to tf2 now !"]}, {"number": 33843, "title": "Change android.bzl indentation to 2", "body": "This commit changes the indent of android.bzl to 2. It fixes the error I encountered when building `r2.0` branch from source:\r\n\r\n```\r\nERROR: /workspace/.cache/bazel/_bazel_mironov/141a83512af494886339dd95e1e5a7a2/external/local_config_android/android.bzl:10:2: indentation error                                                                                                \r\nERROR: error loading package '': Extension 'android.bzl' has errors                                                                                                                                                                             \r\nERROR: error loading package '': Extension 'android.bzl' has errors\r\n```\r\n\r\nThe contents of android.bzl in `.cache` was:\r\n```\r\n\"\"\"Set up configurable Android SDK and NDK dependencies.\"\"\"\r\n\r\ndef android_workspace():\r\n    # String for replacement in Bazel template.\r\n    # These will either be replaced by android_sdk_repository if various ENV\r\n    # variables are set when `local_config_android` repo_rule is run, or they\r\n    # will be replaced by noops otherwise.\r\n    pass\r\n    \r\n  native.android_ndk_repository(\r\n      name=\"androidndk\",\r\n      path=\"/workspace/Android/Sdk/ndk/android-ndk-r18b/\",\r\n      api_level=21,\r\n  )\r\n```\r\nAs you can see, we need to either increase the indent of `_ANDROID_SDK_REPO_TEMPLATE` or decrease the indent of `androiud.bzl`. I decided to do the latter because I note this syle in other Python sources.", "comments": []}, {"number": 33842, "title": "Optimizer state gets automatically restored when loading weights from checkpoint and doesnt change when you compile the model", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): TF 2.0.0(stable)\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):None\r\n- GCC/Compiler version (if compiling from source): None\r\n\r\n\r\n**Describe the current behavior**\r\nOptimizer state is getting restored while loading weights from model checkpoint(tf.keras.callbacks.ModelCheckpoint). Later when you compile model with different learning rate(different from the restored optimizer state), it doesn't gets updated.  \r\n\r\n**Describe the expected behavior**\r\nCompiling the model should update the optimizer state\r\n\r\n**Code to reproduce the issue**\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.python.keras import backend as K\r\nimport numpy as np\r\n\r\ndef get_data():\r\n    images = np.zeros((64,224))\r\n    labels = np.zeros((64,5))\r\n    return images,labels\r\n\r\ndef create_model():\r\n    input_layer = tf.keras.layers.Input(name='Image_input', shape=(224), dtype='float32')\r\n    model = tf.keras.layers.Dense(5)(input_layer)\r\n    model = tf.keras.layers.Activation('softmax', name = \"output-softmax\")(model)\r\n    model = tf.keras.models.Model(inputs=input_layer, outputs=[model])\r\n    return model\r\n\r\nos.makedirs(\"checkpoints/\")\r\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(\"checkpoints/\", monitor='loss',\r\n                                                save_weights_only=True, save_freq='epoch')\r\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.1, patience=1, verbose=1)\r\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='loss', min_delta=0, patience=5, verbose=1)\r\n\r\nmodel = create_model()\r\ndata = get_data()\r\n\u200b\r\noptimizer = tf.keras.optimizers.Adadelta(learning_rate=1.0)\r\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\r\n\u200b\r\nprint (\"learning_rate\",float(K.get_value(model.optimizer.lr)))\r\n                                                       \r\nmodel.fit(data[0], data[1], batch_size=16, epochs=10,callbacks=[checkpoint,reduce_lr,early_stopping])\r\n\r\nprint (\"**learning_rate_1**\",float(K.get_value(model.optimizer.lr)))`\r\n\r\nmodel = create_model()\r\n\r\nmodel.load_weights('checkpoints/')\r\n\r\noptimizer = tf.keras.optimizers.Adadelta(learning_rate=0.1)\r\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\r\n\r\nprint (\"learning_rate\",float(K.get_value(model.optimizer.lr)))`\r\n```\r\n\r\nfinal learning rate should be **0.1** but it is equal to **learning_rate_1** .", "comments": ["I have tried on colab with TF version 2.0  and was able to reproduce the issue.Please, find the gist[ here](https://colab.sandbox.google.com/gist/ravikyram/2a4efeeee5fb43761848ea1c429c3e36/untitled320.ipynb). Thanks!", "The `K.get_value` seems to be making the change.\r\nUse the debugger remove the `K.get_value` and check the value", "I don't think so, because if you compile the model again (2nd time) , the optimizer state gets updated", "I have tried on colab with TF version 2.2-rc4 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/010fce8a813d407a528dd37847a19a24/untitled855.ipynb). Thanks!", "Was able to reproduce the issue with [TF v2.2](https://colab.research.google.com/gist/amahendrakar/897a7b0d1d9c928b89f6cab443615645/33842.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/2d40870dabfc9294880ba74d367d02f2/33842-tf-nightly.ipynb). Please find the attached gist. Thanks!", "I suppose it is something related to the deferred restore of optimizer value. Cause in `h5` is working:\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.python.keras import backend as K\r\nimport numpy as np\r\nimport os\r\ndef get_data():\r\n    images = np.zeros((64,224))\r\n    labels = np.zeros((64,5))\r\n    return images,labels\r\n\r\ndef create_model():\r\n    input_layer = tf.keras.layers.Input(name='Image_input', shape=(224), dtype='float32')\r\n    model = tf.keras.layers.Dense(5)(input_layer)\r\n    model = tf.keras.layers.Activation('softmax', name = \"output-softmax\")(model)\r\n    model = tf.keras.models.Model(inputs=input_layer, outputs=[model])\r\n    return model\r\n\r\n#os.makedirs(\"checkpoints/\")\r\n\r\n\r\nmodel = create_model()\r\ndata = get_data()\r\n\r\noptimizer = tf.keras.optimizers.Adadelta(learning_rate=0.1)\r\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\r\nprint (\"learning_rate\",float(K.get_value(model.optimizer.lr)))\r\n                                                       \r\nmodel.fit(data[0], data[1], batch_size=16, epochs=10)\r\nmodel.save_weights('/checkpoints_test/test.h5')\r\nprint (\"**learning_rate_1**\",float(K.get_value(model.optimizer.lr)))\r\nmodel = create_model()\r\n\r\nmodel.load_weights('/checkpoints_test/test.h5')\r\noptimizer = tf.keras.optimizers.SGD(learning_rate=1)\r\nmodel.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\r\n\r\nprint (\"learning_rate\",float(K.get_value(optimizer.lr)))\r\n```", "Was able to reproduce the issue in Tensorflow version 2.5, please find the gist [here](https://colab.research.google.com/gist/googly789/3f974e5f5efa0eaa39902e6a013d29f1/untitled40.ipynb).", "@Shubham3101 Was able to reproduce the issue on colab using TF v2.7.0, please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/41ec5087955cb5742591f3f9fd7b8375/untitled40.ipynb#scrollTo=TvcImRC67wGo).Thank you! ", "@sushreebarsa , I think it\u2019s the default behaviour to load the optimiser state with weights. \r\nonce it\u2019s loaded, you can compile it and start the training from the restored state. \r\n\r\nI am closing the issue for now, feel free to open it if required ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33842\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33842\">No</a>\n"]}, {"number": 33841, "title": "Is there a documentation/tutorial on step by step process for object detection and customised training using tensorflow2.0", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n", "comments": ["@devitnow15,\r\nPlease take a look at this [link](https://github.com/tensorflow/models/tree/master/research/object_detection). Thanks!", "Is there a documentation by Tensorflow which will allow newcomers like me who do not know tensorflow , to get a feel of training objects by following steps.\r\nWas following below tutorial , but train.py fails because contrib is deprecated in 2.0.upgrading thru script does not work.Is there a train.py that works with tensorflow2.0 ?\r\n\r\nhttps://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html\r\n\r\nAlso , tried below for 2.0 \r\nhttps://www.tensorflow.org/tutorials/customization/custom_training_walkthrough , got stuck with below error : \r\nC:\\Users\\itlas\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py:499 _apply_op_helper\r\n        raise TypeError(\"%s that don't all match.\" % prefix)\r\nTypeError: Tensors in list passed to 'values' of 'Pack' Op have types [string, int32, int32, string, int32, int32, int32, int32] that don't all match.\r\n\r\nIs there a easy documentation following which newbies like me can move forward for a POC.\r\n\r\nThanks.", "@devitnow15, Please refer this [link](https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb) for object detection. Thanks!", "@devitnow15, Did you check the link provided. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 33840, "title": "tf.image.ssim_multiscale does not work in tf-2.0.0", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- TensorFlow installed from: binary (pip)\r\n- TensorFlow version: `2.0.0`\r\n- Python version: `3.5.2`\r\n- CUDA version: `10.1`\r\n- GPU model and memory: GTX 1060, 6GB\r\n\r\n``` python\r\n# example image batches\r\nvideo1 = tf.random.uniform(shape=[8, 64, 64, 1], minval=0, maxval=1)\r\nvideo2 = tf.random.uniform(shape=[8, 64, 64, 1], minval=0, maxval=1)\r\n```\r\nssim works fine but when I use the multiscale ssim, I am getting the following error message. What am I doing wrong? How do I fix this? \r\n\r\n**SSIM**\r\n``` python\r\nssim_score = tf.image.ssim(img1=video1, img2=video1, max_val=1.0)\r\nprint(ssim_score) # tf.Tensor([1. 1. 1. 1. 1. 1. 1. 1.], shape=(8,), dtype=float32)\r\n```\r\n\r\n**MS-SSIM**\r\n``` python\r\nms_ssim_score = tf.image.ssim_multiscale(img1=video1, img2=video2, max_val=1.0)\r\n```\r\n``` python\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-9-cc68ceec0921> in <module>\r\n----> 1 ms_ssim_score = tf.image.ssim_multiscale(img1=video1, img2=video2, max_val=1.0)\r\n\r\n~/.local/lib/python3.5/site-packages/tensorflow_core/python/ops/image_ops_impl.py in ssim_multiscale(img1, img2, max_val, power_factors, filter_size, filter_sigma, k1, k2)\r\n   3405             filter_sigma=filter_sigma,\r\n   3406             k1=k1,\r\n-> 3407             k2=k2)\r\n   3408         mcs.append(nn_ops.relu(cs))\r\n   3409 \r\n\r\n~/.local/lib/python3.5/site-packages/tensorflow_core/python/ops/image_ops_impl.py in _ssim_per_channel(img1, img2, max_val, filter_size, filter_sigma, k1, k2)\r\n   3174               math_ops.greater_equal(shape1[-3:-1], filter_size)),\r\n   3175           [shape1, filter_size],\r\n-> 3176           summarize=8),\r\n   3177       control_flow_ops.Assert(\r\n   3178           math_ops.reduce_all(\r\n\r\n~/.local/lib/python3.5/site-packages/tensorflow_core/python/util/tf_should_use.py in wrapped(*args, **kwargs)\r\n    196   \"\"\"\r\n    197   def wrapped(*args, **kwargs):\r\n--> 198     return _add_should_use_warning(fn(*args, **kwargs))\r\n    199   return tf_decorator.make_decorator(\r\n    200       fn, wrapped, 'should_use_result',\r\n\r\n~/.local/lib/python3.5/site-packages/tensorflow_core/python/ops/control_flow_ops.py in Assert(condition, data, summarize, name)\r\n    154           op=None,\r\n    155           message=\"Expected '%s' to be true. Summarized data: %s\" %\r\n--> 156           (condition, \"\\n\".join(data_str)))\r\n    157     return\r\n    158 \r\n\r\nInvalidArgumentError: Expected 'tf.Tensor(False, shape=(), dtype=bool)' to be true. Summarized data: 8, 8, 8, 1\r\n11\r\n\r\n```\r\n", "comments": ["Issue is replicating on colab with TF 2.0. Please see the [gist](https://colab.sandbox.google.com/gist/gadagashwini/45c4eb25cbba648f1a48a0bade7587b8/untitled229.ipynb). Thanks!", "+1\r\nThe following code reproduces the error:\r\n\r\n```\r\na = np.random.randn(1, 10, 10, 1)\r\nmax_val = np.max(np.reshape(a, [-1]))\r\n\r\nl = tf.image.ssim_multiscale(a, a, max_val, filter_size=11)\r\n```", "Any update on this.  Have the same issue with 2.1.0-rc2", "Could replicate the issue with Tf-nightly == 2.2.0.dev20200316.\r\nPlease find the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/6bff2733702ece74d63d3de197bab46a/untitled458.ipynb). Thanks!", "I was also able to verify with your gist that psnr() has the same issue and is also broke.", "same here with tensorflow  `2.2.0-rc3`\r\ninterestingly it works for me on `(255,255,1)` shape tensors but got the same error with `(128,128,1)` tensors", "Could replicate the issue with TF 2.2.0-rc4.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/78e436329f8216cc39153b804181d402/untitled856.ipynb).Thanks!", "The issue appears to be with assertion after spatial-dimension reduction. In  `_ssim_per_channel `, the `H` and `W` of images is [asserted](https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/python/ops/image_ops_impl.py#L3524) against `filter_size` . Whereas in `ssim_multiscale`, [downsampling ](https://github.com/tensorflow/tensorflow/blob/2b96f3662bd776e277f86997659e61046b56c315/tensorflow/python/ops/image_ops_impl.py#L3741)is performed `len(power_factors)-1` times. \r\n\r\nHere are two workarounds:\r\n1. Make sure that `filter_size` is small enough to calculate ssim values for all the four spatial-scales(excluding first scale) after downsampling within `ssim_multiscale`. Contrarily, ensure both `H` and `W ` of your image are big enough such that **`H/(2**4) and W/(2**4) >= filter_size`** .  \r\n\r\n2. Since downsampling is performed `len(power_factors)-1` times, you can also use lesser number of `_MSSSIM_WEIGHTS` or power_factors than default, which means `H/(2**(len(power_factors)-1)) and W/(2**(len(power_factors)-1)) >= filter_size` .\r\n\r\n```python3\r\nfield1 = tf.random.uniform(shape=[8, 64, 64, 1], minval=0, maxval=1)\r\nfield2 = tf.random.uniform(shape=[8, 64, 64, 1], minval=0, maxval=1) \r\n#Use smaller filter_size\r\nms_ssim_score = tf.image.ssim_multiscale(img1=field1, img2=field2, max_val=1.0,\r\n                                         filter_size=4)\r\n#Or use lesser number of power_factors\r\nms_ssim_score = tf.image.ssim_multiscale(img1=field1, img2=field2, max_val=1.0,\r\n                                         power_factors=(0.0448, 0.2856, 0.3001),\r\n                                         filter_size=11)\r\n```\r\nHope this helps :-)", "@AravindGanesh,\r\nSorry for the delayed response. Can you please let us know if [this workaround](https://github.com/tensorflow/tensorflow/issues/33840#issuecomment-633715778) helped you so that we can work towards closure of this issue? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33840\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33840\">No</a>\n", "@AravindGanesh , The issue has been fixed in Tensorflow 2.5 version, please find the gist [here](https://colab.research.google.com/gist/sachinprasadhs/586e5ad2732c96c6ee5b547f906b4213/224.ipynb).", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33840\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33840\">No</a>\n", "> @AravindGanesh , The issue has been fixed in Tensorflow 2.5 version, please find the gist [here](https://colab.research.google.com/gist/sachinprasadhs/586e5ad2732c96c6ee5b547f906b4213/224.ipynb).\r\n\r\n@sachinprasadhs the issue is not fixed even with tf2.5,  you have pasted my workaround in your gist. The issue still persists, please check by pasting what OP @AravindGanesh has mentioned or check the proper gist [here](https://colab.research.google.com/gist/aakash30jan/7add0e61ea973844360cf569bf8dcffc/issue_33840.ipynb).  ", "@aakash30jan, There was some mistake, reopened the issue.", "Hi! @AravindGanesh  and Thanks @aakash30jan . Was able to replicate the issue with TF v2.5  with different numbers of power factors starting with default  values as mentioned in official  tensorflow document .The program ran successfully only when power_factor was 2 or 3 , Please find the [gist](https://colab.research.google.com/gist/mohantym/917ff98e449aeb85c98d2f58a5e065b4/33840.ipynb#scrollTo=08xZvKrGCfLn) here ..Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33840\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/33840\">No</a>\n"]}, {"number": 33839, "title": "tensorflow.linalg.norm document missing", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\nhttps://github.com/tensorflow/tensorflow/blob/1cf0898dd4331baf93fe77205550f2c2e6c90ee5/tensorflow/python/ops/linalg_ops.py#L426\r\n\r\n## Description of issue (what needs changing):\r\nI can't find ```tensorflow.linalg.norm``` on official v2.0 API document\r\n\r\n", "comments": ["Because ```tf.linalg.norm``` is same  as ```tf.norm```, the documentation is shared with ```tf.norm``` https://www.tensorflow.org/api_docs/python/tf/norm", "> Because `tf.linalg.norm` is same as `tf.norm`, the documentation is shared with `tf.norm` https://www.tensorflow.org/api_docs/python/tf/norm\r\n\r\nThanks"]}]