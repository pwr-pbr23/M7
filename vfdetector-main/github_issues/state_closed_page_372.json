[{"number": 42882, "title": "tensorflow lite div quantized problem", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):macOS 10.14.4\r\n- TensorFlow installed from (source or binary):binary(pip install tensorflow==2.3.0)\r\n- TensorFlow version (or github SHA if from source):2.3.0\r\n\r\nI want to quantify div operations, but I couldn't get a model with quant div Op.\r\n\r\nThe test code is as follows:\r\n#############################################\r\nimport tensorflow.compat.v1 as tf\r\nimport numpy as np\r\n\r\n\r\ntf.disable_eager_execution()\r\n\r\ndata1 = np.random.rand(3).astype(np.float32)\r\nbeginInput1 = tf.placeholder(tf.float32,shape=[3])\r\n\r\ndata2 = np.random.rand(3).astype(np.float32)\r\nbeginInput2 = tf.placeholder(tf.float32,shape=[3])\r\n\r\ny = tf.constant([4.0, 6.0, 2.0])\r\n\r\nresult = tf.div(beginInput1,y)\r\nresult = tf.quantization.fake_quant_with_min_max_args(result, 1, 2,name=\"quant\")\r\n\r\ninit_op = tf.initialize_all_variables()\r\n\r\ndef representative_data_gen():\r\n    yield [data1]\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(init_op)\r\n    end = sess.run(result,feed_dict={beginInput1:data1,beginInput2:data2})\r\n\r\n    output_graph_def = tf.graph_util.convert_variables_to_constants(sess,\r\n                                                                    sess.graph_def,\r\n                                                                    output_node_names=[\"quant\"])\r\n\r\n    with tf.gfile.FastGFile(\"../model/model.pb\", mode=\"wb\") as f:\r\n        f.write(output_graph_def.SerializeToString())\r\n\r\n    converter = tf.lite.TFLiteConverter.from_frozen_graph(\"../model/model.pb\",\r\n                                                        input_arrays=[\"Placeholder\"],\r\n                                                        output_arrays=[\"quant\"],\r\n                                                        input_shapes={\r\n                                                            \"Placeholder\": [3],\r\n                                                        })\r\n\r\n    converter.inference_type = tf.lite.constants.QUANTIZED_UINT8\r\n    input_arrays = converter.get_input_arrays()\r\n    converter.quantized_input_stats = {input_arrays[0]: (0., 1.)}\r\n\r\n    print(\"converter begin.\")\r\n    tflite_model = converter.convert()\r\n    open(\"../model/model.tflite\", \"wb\").write(tflite_model)\r\n#############################################\r\n\r\n**Failure details**\r\n![image](https://user-images.githubusercontent.com/16719562/91945888-b095a900-ed31-11ea-9bae-80046ab5422e.png)\r\n\r\nYou can see that tensorflow lite has supported quant div op.\r\nhttps://github.com/tensorflow/tensorflow/blob/r2.3/tensorflow/lite/toco/graph_transformations/quantize.cc#L56\r\n\r\nHow to convert a model containing quant div op?\r\n\r\n\r\n", "comments": ["@xiaoyaozhuzi could you try conversion with the following code?\r\n\r\n```\r\n   converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n    converter.target_spec.supported_ops = [\r\n        tf.lite.OpsSet.TFLITE_BUILTINS_INT8\r\n    ]\r\n```", "> @xiaoyaozhuzi could you try conversion with the following code?\r\n> \r\n> ```\r\n>    converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n>     converter.target_spec.supported_ops = [\r\n>         tf.lite.OpsSet.TFLITE_BUILTINS_INT8\r\n>     ]\r\n> ```\r\n\r\nPython 3.7.3 (default, Mar 27 2019, 16:54:48) \r\n[Clang 4.0.1 (tags/RELEASE_401/final)] on darwin\r\nTraceback (most recent call last):\r\n  File \"/Applications/PyCharm.app/Contents/helpers/pydev/pydev_run_in_console.py\", line 52, in run_file\r\n    pydev_imports.execfile(file, globals, locals)  # execute the script\r\n  File \"/Applications/PyCharm.app/Contents/helpers/pydev/_pydev_imps/_pydev_execfile.py\", line 18, in execfile\r\n    exec(compile(contents+\"\\n\", file, 'exec'), glob, loc)\r\n  File \"/Users/zhangshuo/githouse/toco-test/tensorflow-test/div_test.py\", line 51, in <module>\r\n    tflite_model = converter.convert()\r\n  File \"/anaconda2/envs/python3/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\", line 1970, in convert\r\n    return super(TFLiteConverter, self).convert()\r\n  File \"/anaconda2/envs/python3/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\", line 1339, in convert\r\n    result = self._calibrate_quantize_model(result, **flags)\r\n  File \"/anaconda2/envs/python3/lib/python3.7/site-packages/tensorflow/lite/python/lite.py\", line 452, in _calibrate_quantize_model\r\n    inference_output_type, allow_float, activations_type)\r\n  File \"/anaconda2/envs/python3/lib/python3.7/site-packages/tensorflow/lite/python/optimize/calibrator.py\", line 98, in calibrate_and_quantize\r\n    np.dtype(activations_type.as_numpy_dtype()).num)\r\nRuntimeError: Quantization not yet supported for op: \r\n\r\n\r\nShows that there are unsupported Quantization ops.\r\n", "Could you try the original conversion code with the tf-nightly version?\r\n\r\nI can create a model with one quantized multiply op node with the same code at the HEAD. FYI, the multiply op is used for the division calculation.", "> Could you try the original conversion code with the tf-nightly version?\r\n> \r\n> I can create a model with one quantized multiply op node with the same code at the HEAD. FYI, the multiply op is used for the division calculation.\r\n\r\n2.3.0 can also generate a model with only one multiplication operation, but division doesn't work.", "Could you elaborate more on your expectations on the division calculation from the generated model? It looks good to me.", "> Could you elaborate more on your expectations on the division calculation from the generated model? It looks good to me.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/r2.3/tensorflow/lite/kernels/div.cc#L155\r\n\r\nI want to verify the accuracy loss of quant div op, so I want to create a tflite model with only one quant div operation.", "@jianlijianli Could you help create a model with single quantized div operator?\r\n\r\n\r\n", "> @jianlijianli Could you help create a model with single quantized div operator?\r\n\r\nWhat else can I try?\r\n\r\n\r\n\r\n\r\n\r\n", "@xiaoyaozhuzi \r\nPlease update, does creating single quantized div operator help.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Can anyone confirm that Quantized Div is not supported as stated by https://github.com/tensorflow/tensorflow/issues/21526? "]}, {"number": 42881, "title": "[tf1.15] Low GPU usage with multi gpus and multi losses  ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: None\r\n- TensorFlow installed from (source or binary): build from source according to official documents. branch is r1.15\r\n- TensorFlow version (use command below): 1.15\r\n- Python version: 2.7\r\n- Bazel version (if compiling from source): 0.24.1\r\n- GCC/Compiler version (if compiling from source): 5.4.0\r\n- CUDA/cuDNN version: 10.1 / 7.6.2\r\n- GPU model and memory: v100, 16G\r\n\r\n**Describe the current behavior**\r\nI trained the model belowing with 2 v100 GPUs, each of which has 16GB memory, and get\r\nLow GPU usage, average is 20 percent.\r\n\r\nI tried batch size 384 on single GPU, the usage does not go any higher. I think it means that the low usage of GPU has nothing to do with batch size.\r\n\r\nAnd I tried on colab, [results](https://colab.research.google.com/drive/13N7ukulsc06WWf8B079jQIcEpQ7zUVYt?usp=sharing). Although I can't get the GPU usage while training, but the time by each step is the same with my local experiments.\r\n\r\n**Describe the expected behavior**\r\nHigh GPU usage and faster training.\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import backend as K\r\nfrom tensorflow.keras.callbacks import TensorBoard\r\nfrom tensorflow.keras.layers import GRU, CuDNNGRU, Dense, Embedding, Reshape\r\nfrom tensorflow.keras.optimizers import Adam\r\n\r\nbatch_size = 256\r\ntime_steps = 750\r\n\r\n# datasets with almost no time delay\r\nnp_input = np.random.random((batch_size, time_steps, 512))\r\nnp_output = np.random.randint(0, 32, size=(batch_size, time_steps, 8))\r\ndef generate():\r\n  while True:\r\n    yield np_input, np_output\r\noutput_shapes = ((batch_size, time_steps, 512), (batch_size, time_steps, 8))\r\n\r\n\r\n# split the output to 8 parts, calculate loss with 8 labels\r\ndef loss(y_true, y_pred):\r\n  y_true = tf.split(y_true, num_or_size_splits=8, axis=-1)\r\n  y_pred = tf.split(y_pred, num_or_size_splits=8, axis=-1)\r\n  loss_func = lambda true, pred: tf.keras.losses.sparse_categorical_crossentropy(\r\n      true, pred, from_logits=True)\r\n  return tf.reduce_mean(\r\n      tf.add_n([loss_func(y_true[i], y_pred[i]) for i in range(8)]))\r\n\r\n\r\n# two v100 gpus, each of which has 16GB of memory\r\nstrategy = tf.distribute.MirroredStrategy()\r\nwith strategy.scope():\r\n  # get dataset\r\n  dataset = tf.data.Dataset.from_generator(generate,\r\n                                           output_types=(tf.float32, tf.int32),\r\n                                           output_shapes=output_shapes)\r\n  dataset = dataset.prefetch(2)\r\n\r\n  # create model\r\n  inputs = tf.keras.Input(shape=(None, 512))\r\n  rnn_outputs, rnn_state = CuDNNGRU(384,\r\n                                    return_sequences=True,\r\n                                    return_state=True)(inputs)\r\n  h_1, h_2 = tf.split(rnn_outputs, num_or_size_splits=2, axis=-1)\r\n  logits_1 = Dense(128)(Dense(256, activation='relu')(h_1))\r\n  logits_2 = Dense(128)(Dense(256, activation='relu')(h_2))\r\n  outputs = K.concatenate([logits_1, logits_2], axis=-1)\r\n  model = tf.keras.Model(inputs, outputs)\r\n\r\n  tensorboard = TensorBoard(log_dir='/workspace/exp/tf_log',\r\n                            update_freq=500,\r\n                            profile_batch=0)\r\n  optimizer = Adam(lr=1e-4, clipnorm=1.)\r\n  model.compile(optimizer=optimizer, loss=loss)\r\n\r\n# train\r\nmodel.fit(dataset, epochs=4, steps_per_epoch=1000, callbacks=[tensorboard])\r\n\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nI split the outputs of CudnnGRU to 2 parts, and split the final logits to 8 parts to calculate loss. Is there any possible problems in my code ? If any, how can I improve the gpu usage ?\r\n\r\n", "comments": ["I have tried in colab with TF version 1.15.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/73a2948e34416502ff587892b945161b/untitled294.ipynb). Thanks!", "@ravikyram hi, I tried to remove the tf.distribute.MirroredStrategy and trained on a single GPU, and that problem did not disappear.", "@ravikyram I tried to simplify the codes, the following code leads to low usage of GPU on a 16G v100 too.\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.keras import backend as K\r\nfrom tensorflow.keras.callbacks import TensorBoard\r\nfrom tensorflow.keras.layers import GRU, CuDNNGRU, Dense, Embedding, Reshape\r\nfrom tensorflow.keras.optimizers import Adam\r\n\r\nbatch_size = 384\r\ntime_steps = 750\r\n\r\n# datasets with almost no time delay\r\nnp_input = np.random.random((batch_size, time_steps, 512))\r\nnp_output = np.random.randint(0, 32, size=(batch_size, time_steps, 1))\r\n\r\n\r\ndef generate():\r\n  while True:\r\n    yield np_input, np_output\r\n\r\n\r\noutput_shapes = ((batch_size, time_steps, 512), (batch_size, time_steps, 1))\r\n\r\n\r\n# split the output to 8 parts, calculate loss with 8 labels\r\ndef loss(y_true, y_pred):\r\n  loss_func = lambda true, pred: tf.keras.losses.sparse_categorical_crossentropy(\r\n      true, pred, from_logits=True)\r\n  return loss_func(y_true, y_pred)\r\n\r\n\r\n# get dataset\r\ndataset = tf.data.Dataset.from_generator(generate,\r\n                                         output_types=(tf.float32, tf.int32),\r\n                                         output_shapes=output_shapes)\r\ndataset = dataset.prefetch(3)\r\n\r\n# create model\r\ninputs = tf.keras.Input(shape=(None, 512))\r\nrnn_outputs, rnn_state = CuDNNGRU(384, return_sequences=True,\r\n                                  return_state=True)(inputs)\r\nlogits_1 = Dense(128)(Dense(256, activation='relu')(rnn_outputs))\r\nmodel = tf.keras.Model(inputs, logits_1)\r\n\r\noptimizer = Adam(lr=1e-4, clipnorm=1.)\r\nmodel.compile(optimizer=optimizer, loss=loss)\r\n\r\n# train\r\nmodel.fit(dataset, epochs=4, steps_per_epoch=1000)\r\n```", "Here is the [colab link](https://colab.research.google.com/drive/1j8CqU_7LoRqt8iIBlw2JRCpegN9OtBU8?usp=sharing) for the simplified code.", "Hi @Yablon, we are currently working on a performance debugging guide that will be added to the TF docs and hopefully help for issues like this. Until that's out I can try to help you here.\r\n\r\nCan you provide more detail on how you measured your GPU utilization?\r\n\r\nWhen debugging performance issues with a distribution strategy, it's useful to start by making sure you have optimal performance in the single GPU case first as you've noted in your comment above. \r\n\r\nThe first thing to do in these cases it to use the Tensorboard Profiler. With the trace viewer, we can get an idea of what could be causing the problem. Here is an [overview](https://www.tensorflow.org/guide/profiler) of how to use the Profiler, and here is a [simple example](https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras) for using the profiler with a single GPU.  If you can provide some screenshots based on the performance (especially the trace viewer) that will help to debug.\r\n\r\nI am also curious to know what you see when you replace the CuDNNGRU unit with another layer. Additionally, it also seems like your code should run fine with TF 2.x (with the exception of the CuDNNGRU layer) so I would be interested to know what the results look like in that case as well.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 42880, "title": "weight decay (regularization) does not work with add_loss() function", "body": "**System information**\r\n- OS Platform: Ubuntu 16.04\r\n- TensorFlow installed from: conda\r\n- TensorFlow version: 2.2.0\r\n- Python version: 3.7\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory:  nvidia 1080\r\n\r\n**Describe the current behavior**\r\nI tried to add regularization loss to a model with model.add_loss() function. Normally, if I set the regularization term large enough, the regularization should damage training and give a poor result. But regularization does not affect training at all, the following code shows a toy example\r\n```\r\nepochs = 18\r\nreg = 10 # set a very large regularization and see if it works\r\n(x_train, y_train),(x_test, y_test) = tf.keras.datasets.mnist.load_data()\r\nx_train = np.expand_dims(x_train, axis=-1) / 255.0\r\nx_test = np.expand_dims(x_test, axis=-1) / 255.0\r\nmodel = tf.keras.models.Sequential([\r\n  tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\r\n  tf.keras.layers.Dense(128, activation='relu'),\r\n  tf.keras.layers.Dropout(0.2),\r\n  tf.keras.layers.Dense(10, activation='softmax')\r\n])\r\nfor w in model.trainable_weights:\r\n    if 'bias' in w.name:\r\n        continue\r\n    model.add_loss(lambda: tf.nn.l2_loss(w) * reg )\r\nmodel.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\r\nmodel.fit(x_train, y_train, epochs=epochs)\r\nmodel.evaluate(x_test, y_test)\r\n```\r\n\r\n**Describe the expected behavior**\r\nI replace the model with the following code, and it works properly:\r\n```\r\nmodel = tf.keras.models.Sequential([\r\n  tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\r\n  tf.keras.layers.Dense(128, activation='relu',  kernel_regularizer=l2(reg)),\r\n  tf.keras.layers.Dropout(0.2),\r\n  tf.keras.layers.Dense(10, activation='softmax', kernel_regularizer=l2(reg))\r\n])\r\n```\r\n", "comments": ["> I tried to add regularization loss to a model with model.add_loss() function. Normally, if I set the regularization term large enough, the regularization should damage training and give a poor result.\r\n\r\n@Ao-Lee,\r\nOn adding regularization loss to the model, I did observe a decrease in the accuracy. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/7720418849b266771bde82168f149080/42880.ipynb). \r\n\r\nCould you please confirm if this is the behavior you are expecting. Thanks!", "@amahendrakar ,\r\nthis is not my expecting behavior \r\n\r\nwith the following code below, setting the regularization term to 10, I observe the training accuracy over one epoch is around 0.91,  which is the same result as there was no regularization. Since strong regularization is applied, my expected result was some value far below 0.91 (actually around 0.11\uff0csee the following ). I suspect that adding regularization via model.add_loss() is not officially supported.\r\n```\r\nreg = 10\r\nfor w in model.trainable_weights:\r\n    if 'bias' in w.name:\r\n        continue\r\n    model.add_loss(lambda: tf.nn.l2_loss(w) * reg)\r\n```\r\n\r\nIf the regularization is set with kernel_regularizer parameter of keras layers, I observed that the training accuracy over one epoch is around 0.11. \r\n```\r\nmodel = tf.keras.models.Sequential([\r\n  tf.keras.layers.Flatten(input_shape=(28, 28, 1)),\r\n  tf.keras.layers.Dense(128, activation='relu',  kernel_regularizer=l2(10.0)),\r\n  tf.keras.layers.Dropout(0.2),\r\n  tf.keras.layers.Dense(10, activation='softmax', kernel_regularizer=l2(10.0))\r\n])\r\n```\r\n", "If regularization loss can not be added to a model via model.add_loss(), it would be very hard to add regularization to pre-trained models, such as tensorflow.keras.applications.ResNet50. One temporary solution is here: https://sthalles.github.io/keras-regularizer/\r\nI tested the methods and it correctly works. But this method is not cost efficient and I hope there would be a convinent method which correctly add regularization losses to pre-defined models", "@Ao-Lee,\r\nThis issue is duplicate of [#38891](https://github.com/tensorflow/tensorflow/issues/38891). Can you please confirm if we can close this issue as it is being tracked [there](https://github.com/tensorflow/tensorflow/issues/38891). Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@Ao-Lee,\r\nCan you please respond to the [above comment](https://github.com/tensorflow/tensorflow/issues/42880#issuecomment-730431019). Thanks! ", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42880\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42880\">No</a>\n"]}, {"number": 42879, "title": "NMS support in XLA", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.3\r\n- Python version: 3.7.6\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): na\r\n- CUDA/cuDNN version: na\r\n- GPU model and memory: na\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nI saw the [NMS implementation in tf2xla](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/compiler/tf2xla/kernels/image_ops.cc#L399), but the op has not been registered yet via REGISTER_XLA_OP. I am wondering what is the status of nms support in xla, since it is a data dependent dynamic op, would love to see how dynamic output is handled by XLA.\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\ntf.compat.v1.enable_eager_execution()\r\n\r\n# Non-Maximum Suppression\r\n@tf.function(experimental_compile=True)\r\ndef test_nms():\r\n    box_shape = (20, 4)\r\n    score_shape = (20, )\r\n    iou_threshold = 0.7\r\n    score_threshold = 0.5\r\n    out_size = 10\r\n    dtype=\"float32\"\r\n\r\n    boxes = np.random.uniform(0, 10, size=box_shape).astype(dtype)\r\n    scores = np.random.uniform(size=score_shape).astype(dtype)\r\n    max_output_size = np.int32(out_size)\r\n    in_data_1 = tf.constant(boxes, dtype, boxes.shape, name=\"in_data_1\")\r\n    in_data_2 = tf.constant(scores, dtype, scores.shape, name=\"in_data_2\")\r\n    in_data_3 = tf.constant(max_output_size, \"int32\", name=\"in_data_3\")\r\n    res = tf.image.non_max_suppression(boxes=in_data_1, scores=in_data_2, max_output_size=in_data_3,\r\n                                       iou_threshold=iou_threshold, score_threshold=score_threshold, name=\"nms\")\r\n    return res\r\n\r\ntest_nms()\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nerror message\r\n```\r\nnms/NonMaxSuppressionV3: unsupported op: No registered 'NonMaxSuppressionV3' OpKernel for XLA_CPU_JIT devices compatible with node {{node nms/NonMaxSuppressionV3}}\r\n\tStacktrace:\r\n\t\tNode: __inference_test_nms_10, function: \r\n\t\tNode: nms/NonMaxSuppressionV3, function: __inference_test_nms_10\r\n [Op:__inference_test_nms_10]\r\n```", "comments": ["I am able to replicate the issue reported, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/19a5fc19c048117828334c9e5ad16fd2/untitled401.ipynb).", "@yongwww Looks like this was resolved. I tried your code with `tf-nightly` nad I cannot reproduce the error. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/adf3ebd661b088846a7e3d1e003aeb49/untitled401.ipynb).\r\n\r\nCan you please verify and close the issue if this was resolved for you. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42879\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42879\">No</a>\n"]}, {"number": 42877, "title": "tf.keras.Model.compile unexpectedly recovered old optimizer iterations", "body": "\r\n**System information**\r\n- TensorFlow version (use command below):2.4 nightly\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11\r\n- GPU model and memory: Titan RTX\r\n\r\nAfter I set a new optimizer in tf.keras.Model.compile. The \"iterations\" become previous trained iterations", "comments": ["Currently I am using `model.optimizer.iterations.assign(0)` to fix this isuse after compiled", "@edwardyehuang,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the dataset you are using. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42877\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42877\">No</a>\n"]}, {"number": 42874, "title": "Allow grappler layout optimizer to support LeakyRelu ops", "body": "This PR enables the LeakyRelu/LeakyReluGrad to be included in the layout agnostic list. Then, the grappler layout optimizer will be able to propagate desired layout formats through them to avoid unnecessary transpose back and forth.\r\n\r\n\r\nFYI @nluehr ", "comments": []}, {"number": 42873, "title": "TFLite conversion produces model with a different input shape despite providing input parameter", "body": "**System information**\r\n- OS Platform and Distribution: `Windows 10`\r\n- TensorFlow installed from: `Binary`\r\n- TensorFlow version: `2.4.0-dev20200901`\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\n\r\nThe original model is an SSD object detection model trained using ResNet50 as the base model.  TensorFlow core model operates as expected but lite model rejects the same input image.\r\n\r\n**Python API Conversion:**\r\n```python\r\nimport tensorflow as tf\r\nsaved_model_dir = r\"C:\\Users\\alfarok\\Desktop\\tflite_graph\\saved_model\"\r\noutput_file_dir = r\"C:\\Users\\alfarok\\Desktop\\output\"\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir, signature_keys=['serving_default'])\r\n\r\nconverter.input_shape=(None,640,640,3)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\r\n\r\ntflite_model = converter.convert()\r\nwith tf.io.gfile.GFile('model.tflite', 'wb') as f:\r\n    f.write(tflite_model)\r\nprint(f\"{output_file_dir} written\")\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\nC:\\Users\\alfarok\\Desktop\\output written\r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n\r\n```\r\n# Can be sent via email if required\r\n```\r\n\r\n**Failure details**\r\nIf the conversion is successful, but the generated model is wrong,\r\nstate what is wrong:\r\n- Input shape that was specified is not preserved\r\n- `converter.input_shape=(None,640,640,3)` produces `'shape': array([1, 1, 1, 3]), 'shape_signature': array([ 1, -1, -1,  3])`\r\n- Attempting to invoke the model `ValueError: Cannot set tensor: Dimension mismatch. Got 640 but expected 1 for dimension 1 of input 0.`\r\n\r\nDetails:\r\n```python\r\ninterpreter = tf.lite.Interpreter(model_path=tflite_model_path)\r\ninterpreter.allocate_tensors()\r\n    \r\ninput_details = interpreter.get_input_details()\r\noutput_details = interpreter.get_output_details()\r\n\r\nprint(input_details)\r\n```\r\n\r\n```\r\n[{'name': 'serving_default_input_tensor:0', 'index': 0, 'shape': array([1, 1, 1, 3]), 'shape_signature': array([ 1, -1, -1,  3]), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\r\n```\r\n\r\n```python\r\nprint(output_details)\r\n```\r\n\r\n```\r\n[{'name': 'StatefulPartitionedCall:5', 'index': 740, 'shape': array([1]), 'shape_signature': array([1]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:1', 'index': 836, 'shape': array([1, 1, 1]), 'shape_signature': array([ 1, -1, -1]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:2', 'index': 814, 'shape': array([1, 1]), 'shape_signature': array([ 1, -1]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:7', 'index': 452, 'shape': array([    1, 85250,    12]), 'shape_signature': array([    1, 85250,    12]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:4', 'index': 757, 'shape': array([1, 1]), 'shape_signature': array([ 1, -1]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:6', 'index': 436, 'shape': array([    1, 85250,     4]), 'shape_signature': array([    1, 85250,     4]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:3', 'index': 797, 'shape': array([1, 1, 1]), 'shape_signature': array([ 1, -1, -1]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}, {'name': 'StatefulPartitionedCall:0', 'index': 775, 'shape': array([1, 1]), 'shape_signature': array([ 1, -1]), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]\r\n```\r\n\r\n```python\r\n# Get expected width and height from models input dimensions\r\nheight = input_details[0]['shape'][1]\r\nwidth = input_details[0]['shape'][2]\r\nprint(height, width)\r\n```\r\n```\r\n1 1\r\n```\r\n\r\n**Any other info / logs**\r\n\r\nI also tried to use the CLI such as but the output file is never produced.  It runs for a while and looks like it completes but I cannot find the `.tflite` model in the expected directory?\r\n```\r\ntflite_convert --saved_model_dir=inference_graph_ssd_resnet50\\saved_model --output_file=inference_graph_ssd_resnet50.tflite --output_format=TFLITE --input_shapes=None,640,640,3 \r\n```\r\n\r\n```\r\nRuns for a while eventually producing this (let me know if you need the entire log):\r\n  %0 = \"tfl.cast\"(%cst_228) : (tensor<1x85250xi32>) -> tensor<1x85250xf32>\r\n  %1 = \"tfl.unpack\"(%0) {axis = 0 : i32, num = 1 : i32} : (tensor<1x85250xf32>) -> tensor<85250xf32>\r\n  %2 = \"tfl.slice\"(%1, %cst_258, %cst_24) : (tensor<85250xf32>, tensor<1xi32>, tensor<1xi32>) -> tensor<85250xf32>\r\n  %3 = \"tfl.cast\"(%arg0) : (tensor<1x?x?x3xui8>) -> tensor<1x?x?x3xf32>\r\n  %4 = \"tfl.sub\"(%3, %cst_34) {fused_activation_function = \"NONE\"} : (tensor<1x?x?x3xf32>, tensor<1x1x3xf32>) -> tensor<1x?x?x3xf32>\r\n  %5 = \"tfl.unpack\"(%4) {axis = 0 : i32, num = 1 : i32} : (tensor<1x?x?x3xf32>) -> tensor<?x?x3xf32>\r\n  %6 = \"tfl.expand_dims\"(%5, %cst_32) : (tensor<?x?x3xf32>, tensor<i32>) -> tensor<1x?x?x3xf32>\r\n  %7 = \"tfl.resize_bilinear\"(%6, %cst_33) {align_corners = false, half_pixel_centers = false} : (tensor<1x?x?x3xf32>, tensor<2xi32>) -> tensor<1x640x640x3xf32>\r\n  %8 = \"tfl.reshape\"(%7, %cst_229) : (tensor<1x640x640x3xf32>, tensor<3xi32>) -> tensor<640x640x3xf32>\r\n  %9 = \"tfl.pack\"(%8) {axis = 0 : i32, values_count = 1 : i32} : (tensor<640x640x3xf32>) -> tensor<1x640x640x3xf32>\r\n  %10 = \"tfl.pad\"(%9, %cst_37) : (tensor<1x640x640x3xf32>, tensor<4x2xi32>) -> tensor<1x646x646x3xf32>\r\n  %11 = \"tfl.conv_2d\"(%10, %cst_126, %cst_49) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"VALID\", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<1x646x646x3xf32>, tensor<64x7x7x3xf32>, tensor<64xf32>) -> tensor<1x320x320x64xf32>\r\n  %12 = \"tfl.max_pool_2d\"(%11) {filter_height = 3 : i32, filter_width = 3 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<1x320x320x64xf32>) -> tensor<1x160x160x64xf32>\r\n  %13 = \"tfl.conv_2d\"(%12, %cst_127, %cst_230) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x160x160x64xf32>, tensor<256x1x1x64xf32>, tensor<256xf32>) -> tensor<1x160x160x256xf32>\r\n  %14 = \"tfl.conv_2d\"(%12, %cst_128, %cst_50) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x160x160x64xf32>, tensor<64x1x1x64xf32>, tensor<64xf32>) -> tensor<1x160x160x64xf32>\r\n  %15 = \"tfl.conv_2d\"(%14, %cst_129, %cst_51) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x160x160x64xf32>, tensor<64x3x3x64xf32>, tensor<64xf32>) -> tensor<1x160x160x64xf32>\r\n  %16 = \"tfl.conv_2d\"(%15, %cst_130, %cst_231) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x160x160x64xf32>, tensor<256x1x1x64xf32>, tensor<256xf32>) -> tensor<1x160x160x256xf32>\r\n  %17 = \"tfl.add\"(%13, %16) {fused_activation_function = \"RELU6\"} : (tensor<1x160x160x256xf32>, tensor<1x160x160x256xf32>) -> tensor<1x160x160x256xf32>\r\n  %18 = \"tfl.conv_2d\"(%17, %cst_131, %cst_52) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x160x160x256xf32>, tensor<64x1x1x256xf32>, tensor<64xf32>) -> tensor<1x160x160x64xf32>\r\n  %19 = \"tfl.conv_2d\"(%18, %cst_132, %cst_53) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x160x160x64xf32>, tensor<64x3x3x64xf32>, tensor<64xf32>) -> tensor<1x160x160x64xf32>\r\n  %20 = \"tfl.conv_2d\"(%19, %cst_133, %cst_232) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x160x160x64xf32>, tensor<256x1x1x64xf32>, tensor<256xf32>) -> tensor<1x160x160x256xf32>\r\n  %21 = \"tfl.add\"(%17, %20) {fused_activation_function = \"RELU6\"} : (tensor<1x160x160x256xf32>, tensor<1x160x160x256xf32>) -> tensor<1x160x160x256xf32>\r\n  %22 = \"tfl.conv_2d\"(%21, %cst_134, %cst_54) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x160x160x256xf32>, tensor<64x1x1x256xf32>, tensor<64xf32>) -> tensor<1x160x160x64xf32>\r\n  %23 = \"tfl.conv_2d\"(%22, %cst_135, %cst_55) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x160x160x64xf32>, tensor<64x3x3x64xf32>, tensor<64xf32>) -> tensor<1x160x160x64xf32>\r\n  %24 = \"tfl.conv_2d\"(%23, %cst_136, %cst_233) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x160x160x64xf32>, tensor<256x1x1x64xf32>, tensor<256xf32>) -> tensor<1x160x160x256xf32>\r\n  %25 = \"tfl.add\"(%21, %24) {fused_activation_function = \"RELU6\"} : (tensor<1x160x160x256xf32>, tensor<1x160x160x256xf32>) -> tensor<1x160x160x256xf32>\r\n  %26 = \"tfl.conv_2d\"(%25, %cst_137, %cst_234) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<1x160x160x256xf32>, tensor<512x1x1x256xf32>, tensor<512xf32>) -> tensor<1x80x80x512xf32>\r\n  %27 = \"tfl.conv_2d\"(%25, %cst_138, %cst_56) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<1x160x160x256xf32>, tensor<128x1x1x256xf32>, tensor<128xf32>) -> tensor<1x80x80x128xf32>\r\n  %28 = \"tfl.conv_2d\"(%27, %cst_139, %cst_57) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x128xf32>, tensor<128x3x3x128xf32>, tensor<128xf32>) -> tensor<1x80x80x128xf32>\r\n  %29 = \"tfl.conv_2d\"(%28, %cst_140, %cst_235) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x128xf32>, tensor<512x1x1x128xf32>, tensor<512xf32>) -> tensor<1x80x80x512xf32>\r\n  %30 = \"tfl.add\"(%26, %29) {fused_activation_function = \"RELU6\"} : (tensor<1x80x80x512xf32>, tensor<1x80x80x512xf32>) -> tensor<1x80x80x512xf32>\r\n  %31 = \"tfl.conv_2d\"(%30, %cst_141, %cst_58) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x512xf32>, tensor<128x1x1x512xf32>, tensor<128xf32>) -> tensor<1x80x80x128xf32>\r\n  %32 = \"tfl.conv_2d\"(%31, %cst_142, %cst_59) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x128xf32>, tensor<128x3x3x128xf32>, tensor<128xf32>) -> tensor<1x80x80x128xf32>\r\n  %33 = \"tfl.conv_2d\"(%32, %cst_143, %cst_236) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x128xf32>, tensor<512x1x1x128xf32>, tensor<512xf32>) -> tensor<1x80x80x512xf32>\r\n  %34 = \"tfl.add\"(%30, %33) {fused_activation_function = \"RELU6\"} : (tensor<1x80x80x512xf32>, tensor<1x80x80x512xf32>) -> tensor<1x80x80x512xf32>\r\n  %35 = \"tfl.conv_2d\"(%34, %cst_144, %cst_60) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x512xf32>, tensor<128x1x1x512xf32>, tensor<128xf32>) -> tensor<1x80x80x128xf32>\r\n  %36 = \"tfl.conv_2d\"(%35, %cst_145, %cst_61) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x128xf32>, tensor<128x3x3x128xf32>, tensor<128xf32>) -> tensor<1x80x80x128xf32>\r\n  %37 = \"tfl.conv_2d\"(%36, %cst_146, %cst_237) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x128xf32>, tensor<512x1x1x128xf32>, tensor<512xf32>) -> tensor<1x80x80x512xf32>\r\n  %38 = \"tfl.add\"(%34, %37) {fused_activation_function = \"RELU6\"} : (tensor<1x80x80x512xf32>, tensor<1x80x80x512xf32>) -> tensor<1x80x80x512xf32>\r\n  %39 = \"tfl.conv_2d\"(%38, %cst_147, %cst_62) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x512xf32>, tensor<128x1x1x512xf32>, tensor<128xf32>) -> tensor<1x80x80x128xf32>\r\n  %40 = \"tfl.conv_2d\"(%39, %cst_148, %cst_63) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x128xf32>, tensor<128x3x3x128xf32>, tensor<128xf32>) -> tensor<1x80x80x128xf32>\r\n  %41 = \"tfl.conv_2d\"(%40, %cst_149, %cst_238) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x128xf32>, tensor<512x1x1x128xf32>, tensor<512xf32>) -> tensor<1x80x80x512xf32>\r\n  %42 = \"tfl.add\"(%38, %41) {fused_activation_function = \"RELU6\"} : (tensor<1x80x80x512xf32>, tensor<1x80x80x512xf32>) -> tensor<1x80x80x512xf32>\r\n  %43 = \"tfl.conv_2d\"(%42, %cst_150, %cst_239) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x512xf32>, tensor<256x1x1x512xf32>, tensor<256xf32>) -> tensor<1x80x80x256xf32>\r\n  %44 = \"tfl.conv_2d\"(%42, %cst_151, %cst_240) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<1x80x80x512xf32>, tensor<1024x1x1x512xf32>, tensor<1024xf32>) -> tensor<1x40x40x1024xf32>\r\n  %45 = \"tfl.conv_2d\"(%42, %cst_152, %cst_64) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<1x80x80x512xf32>, tensor<256x1x1x512xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %46 = \"tfl.conv_2d\"(%45, %cst_153, %cst_65) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %47 = \"tfl.conv_2d\"(%46, %cst_154, %cst_241) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<1024x1x1x256xf32>, tensor<1024xf32>) -> tensor<1x40x40x1024xf32>\r\n  %48 = \"tfl.add\"(%44, %47) {fused_activation_function = \"RELU6\"} : (tensor<1x40x40x1024xf32>, tensor<1x40x40x1024xf32>) -> tensor<1x40x40x1024xf32>\r\n  %49 = \"tfl.conv_2d\"(%48, %cst_155, %cst_66) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x1024xf32>, tensor<256x1x1x1024xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %50 = \"tfl.conv_2d\"(%49, %cst_156, %cst_67) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %51 = \"tfl.conv_2d\"(%50, %cst_157, %cst_242) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<1024x1x1x256xf32>, tensor<1024xf32>) -> tensor<1x40x40x1024xf32>\r\n  %52 = \"tfl.add\"(%48, %51) {fused_activation_function = \"RELU6\"} : (tensor<1x40x40x1024xf32>, tensor<1x40x40x1024xf32>) -> tensor<1x40x40x1024xf32>\r\n  %53 = \"tfl.conv_2d\"(%52, %cst_158, %cst_68) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x1024xf32>, tensor<256x1x1x1024xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %54 = \"tfl.conv_2d\"(%53, %cst_159, %cst_69) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %55 = \"tfl.conv_2d\"(%54, %cst_160, %cst_243) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<1024x1x1x256xf32>, tensor<1024xf32>) -> tensor<1x40x40x1024xf32>\r\n  %56 = \"tfl.add\"(%52, %55) {fused_activation_function = \"RELU6\"} : (tensor<1x40x40x1024xf32>, tensor<1x40x40x1024xf32>) -> tensor<1x40x40x1024xf32>\r\n  %57 = \"tfl.conv_2d\"(%56, %cst_161, %cst_70) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x1024xf32>, tensor<256x1x1x1024xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %58 = \"tfl.conv_2d\"(%57, %cst_162, %cst_71) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %59 = \"tfl.conv_2d\"(%58, %cst_163, %cst_244) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<1024x1x1x256xf32>, tensor<1024xf32>) -> tensor<1x40x40x1024xf32>\r\n  %60 = \"tfl.add\"(%56, %59) {fused_activation_function = \"RELU6\"} : (tensor<1x40x40x1024xf32>, tensor<1x40x40x1024xf32>) -> tensor<1x40x40x1024xf32>\r\n  %61 = \"tfl.conv_2d\"(%60, %cst_164, %cst_72) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x1024xf32>, tensor<256x1x1x1024xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %62 = \"tfl.conv_2d\"(%61, %cst_165, %cst_73) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %63 = \"tfl.conv_2d\"(%62, %cst_166, %cst_245) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<1024x1x1x256xf32>, tensor<1024xf32>) -> tensor<1x40x40x1024xf32>\r\n  %64 = \"tfl.add\"(%60, %63) {fused_activation_function = \"RELU6\"} : (tensor<1x40x40x1024xf32>, tensor<1x40x40x1024xf32>) -> tensor<1x40x40x1024xf32>\r\n  %65 = \"tfl.conv_2d\"(%64, %cst_167, %cst_74) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x1024xf32>, tensor<256x1x1x1024xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %66 = \"tfl.conv_2d\"(%65, %cst_168, %cst_75) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %67 = \"tfl.conv_2d\"(%66, %cst_169, %cst_246) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<1024x1x1x256xf32>, tensor<1024xf32>) -> tensor<1x40x40x1024xf32>\r\n  %68 = \"tfl.add\"(%64, %67) {fused_activation_function = \"RELU6\"} : (tensor<1x40x40x1024xf32>, tensor<1x40x40x1024xf32>) -> tensor<1x40x40x1024xf32>\r\n  %69 = \"tfl.conv_2d\"(%68, %cst_170, %cst_247) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x1024xf32>, tensor<256x1x1x1024xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %70 = \"tfl.conv_2d\"(%68, %cst_171, %cst_248) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<1x40x40x1024xf32>, tensor<2048x1x1x1024xf32>, tensor<2048xf32>) -> tensor<1x20x20x2048xf32>\r\n  %71 = \"tfl.conv_2d\"(%68, %cst_172, %cst_76) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<1x40x40x1024xf32>, tensor<512x1x1x1024xf32>, tensor<512xf32>) -> tensor<1x20x20x512xf32>\r\n  %72 = \"tfl.conv_2d\"(%71, %cst_173, %cst_77) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x512xf32>, tensor<512x3x3x512xf32>, tensor<512xf32>) -> tensor<1x20x20x512xf32>\r\n  %73 = \"tfl.conv_2d\"(%72, %cst_174, %cst_249) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x512xf32>, tensor<2048x1x1x512xf32>, tensor<2048xf32>) -> tensor<1x20x20x2048xf32>\r\n  %74 = \"tfl.add\"(%70, %73) {fused_activation_function = \"RELU6\"} : (tensor<1x20x20x2048xf32>, tensor<1x20x20x2048xf32>) -> tensor<1x20x20x2048xf32>\r\n  %75 = \"tfl.conv_2d\"(%74, %cst_175, %cst_78) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x2048xf32>, tensor<512x1x1x2048xf32>, tensor<512xf32>) -> tensor<1x20x20x512xf32>\r\n  %76 = \"tfl.conv_2d\"(%75, %cst_176, %cst_79) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x512xf32>, tensor<512x3x3x512xf32>, tensor<512xf32>) -> tensor<1x20x20x512xf32>\r\n  %77 = \"tfl.conv_2d\"(%76, %cst_177, %cst_250) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x512xf32>, tensor<2048x1x1x512xf32>, tensor<2048xf32>) -> tensor<1x20x20x2048xf32>\r\n  %78 = \"tfl.add\"(%74, %77) {fused_activation_function = \"RELU6\"} : (tensor<1x20x20x2048xf32>, tensor<1x20x20x2048xf32>) -> tensor<1x20x20x2048xf32>\r\n  %79 = \"tfl.conv_2d\"(%78, %cst_178, %cst_80) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x2048xf32>, tensor<512x1x1x2048xf32>, tensor<512xf32>) -> tensor<1x20x20x512xf32>\r\n  %80 = \"tfl.conv_2d\"(%79, %cst_179, %cst_81) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x512xf32>, tensor<512x3x3x512xf32>, tensor<512xf32>) -> tensor<1x20x20x512xf32>\r\n  %81 = \"tfl.conv_2d\"(%80, %cst_180, %cst_251) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x512xf32>, tensor<2048x1x1x512xf32>, tensor<2048xf32>) -> tensor<1x20x20x2048xf32>\r\n  %82 = \"tfl.add\"(%78, %81) {fused_activation_function = \"RELU6\"} : (tensor<1x20x20x2048xf32>, tensor<1x20x20x2048xf32>) -> tensor<1x20x20x2048xf32>\r\n  %83 = \"tfl.conv_2d\"(%82, %cst_181, %cst_252) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x2048xf32>, tensor<256x1x1x2048xf32>, tensor<256xf32>) -> tensor<1x20x20x256xf32>\r\n  %84 = \"tfl.pack\"(%83, %83) {axis = 3 : i32, values_count = 2 : i32} : (tensor<1x20x20x256xf32>, tensor<1x20x20x256xf32>) -> tensor<1x20x20x2x256xf32>\r\n  %85 = \"tfl.pack\"(%84, %84) {axis = 2 : i32, values_count = 2 : i32} : (tensor<1x20x20x2x256xf32>, tensor<1x20x20x2x256xf32>) -> tensor<1x20x2x20x2x256xf32>\r\n  %86 = \"tfl.reshape\"(%85, %cst_35) : (tensor<1x20x2x20x2x256xf32>, tensor<4xi32>) -> tensor<1x40x40x256xf32>\r\n  %87 = \"tfl.add\"(%86, %69) {fused_activation_function = \"NONE\"} : (tensor<1x40x40x256xf32>, tensor<1x40x40x256xf32>) -> tensor<1x40x40x256xf32>\r\n  %88 = \"tfl.conv_2d\"(%87, %cst_182, %cst_82) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %89 = \"tfl.pack\"(%88, %88) {axis = 3 : i32, values_count = 2 : i32} : (tensor<1x40x40x256xf32>, tensor<1x40x40x256xf32>) -> tensor<1x40x40x2x256xf32>\r\n  %90 = \"tfl.pack\"(%89, %89) {axis = 2 : i32, values_count = 2 : i32} : (tensor<1x40x40x2x256xf32>, tensor<1x40x40x2x256xf32>) -> tensor<1x40x2x40x2x256xf32>\r\n  %91 = \"tfl.reshape\"(%90, %cst_36) : (tensor<1x40x2x40x2x256xf32>, tensor<4xi32>) -> tensor<1x80x80x256xf32>\r\n  %92 = \"tfl.add\"(%91, %43) {fused_activation_function = \"NONE\"} : (tensor<1x80x80x256xf32>, tensor<1x80x80x256xf32>) -> tensor<1x80x80x256xf32>\r\n  %93 = \"tfl.conv_2d\"(%92, %cst_183, %cst_83) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x80x80x256xf32>\r\n  %94 = \"tfl.conv_2d\"(%83, %cst_184, %cst_84) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<1x20x20x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x10x10x256xf32>\r\n  %95 = \"tfl.conv_2d\"(%94, %cst_185, %cst_85) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<1x10x10x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x5x5x256xf32>\r\n  %96 = \"tfl.conv_2d\"(%93, %cst_186, %cst_86) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x80x80x256xf32>\r\n  %97 = \"tfl.conv_2d\"(%88, %cst_187, %cst_87) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %98 = \"tfl.conv_2d\"(%83, %cst_188, %cst_88) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x20x20x256xf32>\r\n  %99 = \"tfl.conv_2d\"(%94, %cst_189, %cst_89) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x10x10x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x10x10x256xf32>\r\n  %100 = \"tfl.conv_2d\"(%95, %cst_190, %cst_90) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x5x5x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x5x5x256xf32>\r\n  %101 = \"tfl.conv_2d\"(%96, %cst_191, %cst_91) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x80x80x256xf32>\r\n  %102 = \"tfl.conv_2d\"(%97, %cst_192, %cst_92) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %103 = \"tfl.conv_2d\"(%98, %cst_193, %cst_93) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x20x20x256xf32>\r\n  %104 = \"tfl.conv_2d\"(%99, %cst_194, %cst_94) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x10x10x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x10x10x256xf32>\r\n  %105 = \"tfl.conv_2d\"(%100, %cst_195, %cst_95) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x5x5x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x5x5x256xf32>\r\n  %106 = \"tfl.conv_2d\"(%101, %cst_196, %cst_96) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x80x80x256xf32>\r\n  %107 = \"tfl.conv_2d\"(%102, %cst_197, %cst_97) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %108 = \"tfl.conv_2d\"(%103, %cst_198, %cst_98) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x20x20x256xf32>\r\n  %109 = \"tfl.conv_2d\"(%104, %cst_199, %cst_99) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x10x10x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x10x10x256xf32>\r\n  %110 = \"tfl.conv_2d\"(%105, %cst_200, %cst_100) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x5x5x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x5x5x256xf32>\r\n  %111 = \"tfl.conv_2d\"(%106, %cst_201, %cst_101) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x80x80x256xf32>\r\n  %112 = \"tfl.conv_2d\"(%107, %cst_202, %cst_102) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %113 = \"tfl.conv_2d\"(%108, %cst_203, %cst_103) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x20x20x256xf32>\r\n  %114 = \"tfl.conv_2d\"(%109, %cst_204, %cst_104) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x10x10x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x10x10x256xf32>\r\n  %115 = \"tfl.conv_2d\"(%110, %cst_205, %cst_105) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x5x5x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x5x5x256xf32>\r\n  %116 = \"tfl.conv_2d\"(%93, %cst_206, %cst_106) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x80x80x256xf32>\r\n  %117 = \"tfl.conv_2d\"(%88, %cst_207, %cst_107) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %118 = \"tfl.conv_2d\"(%83, %cst_208, %cst_108) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x20x20x256xf32>\r\n  %119 = \"tfl.conv_2d\"(%94, %cst_209, %cst_109) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x10x10x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x10x10x256xf32>\r\n  %120 = \"tfl.conv_2d\"(%95, %cst_210, %cst_110) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x5x5x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x5x5x256xf32>\r\n  %121 = \"tfl.conv_2d\"(%116, %cst_211, %cst_111) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x80x80x256xf32>\r\n  %122 = \"tfl.conv_2d\"(%117, %cst_212, %cst_112) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %123 = \"tfl.conv_2d\"(%118, %cst_213, %cst_113) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x20x20x256xf32>\r\n  %124 = \"tfl.conv_2d\"(%119, %cst_214, %cst_114) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x10x10x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x10x10x256xf32>\r\n  %125 = \"tfl.conv_2d\"(%120, %cst_215, %cst_115) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x5x5x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x5x5x256xf32>\r\n  %126 = \"tfl.conv_2d\"(%121, %cst_216, %cst_116) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x80x80x256xf32>\r\n  %127 = \"tfl.conv_2d\"(%122, %cst_217, %cst_117) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %128 = \"tfl.conv_2d\"(%123, %cst_218, %cst_118) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x20x20x256xf32>\r\n  %129 = \"tfl.conv_2d\"(%124, %cst_219, %cst_119) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x10x10x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x10x10x256xf32>\r\n  %130 = \"tfl.conv_2d\"(%125, %cst_220, %cst_120) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x5x5x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x5x5x256xf32>\r\n  %131 = \"tfl.conv_2d\"(%126, %cst_221, %cst_121) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x80x80x256xf32>\r\n  %132 = \"tfl.conv_2d\"(%127, %cst_222, %cst_122) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %133 = \"tfl.conv_2d\"(%128, %cst_223, %cst_123) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x20x20x256xf32>\r\n  %134 = \"tfl.conv_2d\"(%129, %cst_224, %cst_124) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x10x10x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x10x10x256xf32>\r\n  %135 = \"tfl.conv_2d\"(%130, %cst_225, %cst_125) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x5x5x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x5x5x256xf32>\r\n  %136 = \"tfl.conv_2d\"(%111, %cst_226, %cst_253) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x256xf32>, tensor<40x3x3x256xf32>, tensor<40xf32>) -> tensor<1x80x80x40xf32>\r\n  %137 = \"tfl.reshape\"(%136, %cst_38) : (tensor<1x80x80x40xf32>, tensor<3xi32>) -> tensor<1x64000x4xf32>\r\n  %138 = \"tfl.conv_2d\"(%112, %cst_226, %cst_253) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<40x3x3x256xf32>, tensor<40xf32>) -> tensor<1x40x40x40xf32>\r\n  %139 = \"tfl.reshape\"(%138, %cst_38) : (tensor<1x40x40x40xf32>, tensor<3xi32>) -> tensor<1x16000x4xf32>\r\n  %140 = \"tfl.conv_2d\"(%113, %cst_226, %cst_253) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x256xf32>, tensor<40x3x3x256xf32>, tensor<40xf32>) -> tensor<1x20x20x40xf32>\r\n  %141 = \"tfl.reshape\"(%140, %cst_38) : (tensor<1x20x20x40xf32>, tensor<3xi32>) -> tensor<1x4000x4xf32>\r\n  %142 = \"tfl.conv_2d\"(%114, %cst_226, %cst_253) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x10x10x256xf32>, tensor<40x3x3x256xf32>, tensor<40xf32>) -> tensor<1x10x10x40xf32>\r\n  %143 = \"tfl.reshape\"(%142, %cst_38) : (tensor<1x10x10x40xf32>, tensor<3xi32>) -> tensor<1x1000x4xf32>\r\n  %144 = \"tfl.conv_2d\"(%115, %cst_226, %cst_253) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x5x5x256xf32>, tensor<40x3x3x256xf32>, tensor<40xf32>) -> tensor<1x5x5x40xf32>\r\n  %145 = \"tfl.reshape\"(%144, %cst_38) : (tensor<1x5x5x40xf32>, tensor<3xi32>) -> tensor<1x250x4xf32>\r\n  %146 = \"tfl.concatenation\"(%137, %139, %141, %143, %145) {axis = 1 : i32, fused_activation_function = \"NONE\"} : (tensor<1x64000x4xf32>, tensor<1x16000x4xf32>, tensor<1x4000x4xf32>, tensor<1x1000x4xf32>, tensor<1x250x4xf32>) -> tensor<1x85250x4xf32>\r\n  %147 = \"tfl.reshape\"(%146, %cst_29) : (tensor<1x85250x4xf32>, tensor<2xi32>) -> tensor<85250x4xf32>\r\n  %148 = \"tfl.transpose\"(%147, %cst_28) : (tensor<85250x4xf32>, tensor<2xi32>) -> tensor<4x85250xf32>\r\n  %149:4 = \"tfl.unpack\"(%148) {axis = 0 : i32, num = 4 : i32} : (tensor<4x85250xf32>) -> (tensor<85250xf32>, tensor<85250xf32>, tensor<85250xf32>, tensor<85250xf32>)\r\n  %150 = \"tfl.mul\"(%149#0, %cst_42) {fused_activation_function = \"NONE\"} : (tensor<85250xf32>, tensor<f32>) -> tensor<85250xf32>\r\n  %151 = \"tfl.mul\"(%150, %cst_45) {fused_activation_function = \"NONE\"} : (tensor<85250xf32>, tensor<85250xf32>) -> tensor<85250xf32>\r\n  %152 = \"tfl.add\"(%151, %cst_46) {fused_activation_function = \"NONE\"} : (tensor<85250xf32>, tensor<85250xf32>) -> tensor<85250xf32>\r\n  %153 = \"tfl.mul\"(%149#1, %cst_42) {fused_activation_function = \"NONE\"} : (tensor<85250xf32>, tensor<f32>) -> tensor<85250xf32>\r\n  %154 = \"tfl.mul\"(%153, %cst_47) {fused_activation_function = \"NONE\"} : (tensor<85250xf32>, tensor<85250xf32>) -> tensor<85250xf32>\r\n  %155 = \"tfl.add\"(%154, %cst_48) {fused_activation_function = \"NONE\"} : (tensor<85250xf32>, tensor<85250xf32>) -> tensor<85250xf32>\r\n  %156 = \"tfl.mul\"(%149#2, %cst_43) {fused_activation_function = \"NONE\"} : (tensor<85250xf32>, tensor<f32>) -> tensor<85250xf32>\r\n  %157 = \"tfl.exp\"(%156) : (tensor<85250xf32>) -> tensor<85250xf32>\r\n  %158 = \"tfl.mul\"(%157, %cst_45) {fused_activation_function = \"NONE\"} : (tensor<85250xf32>, tensor<85250xf32>) -> tensor<85250xf32>\r\n  %159 = \"tfl.mul\"(%158, %cst_44) {fused_activation_function = \"NONE\"} : (tensor<85250xf32>, tensor<f32>) -> tensor<85250xf32>\r\n  %160 = \"tfl.sub\"(%152, %159) {fused_activation_function = \"NONE\"} : (tensor<85250xf32>, tensor<85250xf32>) -> tensor<85250xf32>\r\n  %161 = \"tfl.add\"(%152, %159) {fused_activation_function = \"NONE\"} : (tensor<85250xf32>, tensor<85250xf32>) -> tensor<85250xf32>\r\n  %162 = \"tfl.mul\"(%149#3, %cst_43) {fused_activation_function = \"NONE\"} : (tensor<85250xf32>, tensor<f32>) -> tensor<85250xf32>\r\n  %163 = \"tfl.exp\"(%162) : (tensor<85250xf32>) -> tensor<85250xf32>\r\n  %164 = \"tfl.mul\"(%163, %cst_47) {fused_activation_function = \"NONE\"} : (tensor<85250xf32>, tensor<85250xf32>) -> tensor<85250xf32>\r\n  %165 = \"tfl.mul\"(%164, %cst_44) {fused_activation_function = \"NONE\"} : (tensor<85250xf32>, tensor<f32>) -> tensor<85250xf32>\r\n  %166 = \"tfl.sub\"(%155, %165) {fused_activation_function = \"NONE\"} : (tensor<85250xf32>, tensor<85250xf32>) -> tensor<85250xf32>\r\n  %167 = \"tfl.add\"(%155, %165) {fused_activation_function = \"NONE\"} : (tensor<85250xf32>, tensor<85250xf32>) -> tensor<85250xf32>\r\n  %168 = \"tfl.pack\"(%160, %166, %161, %167) {axis = 0 : i32, values_count = 4 : i32} : (tensor<85250xf32>, tensor<85250xf32>, tensor<85250xf32>, tensor<85250xf32>) -> tensor<4x85250xf32>\r\n  %169 = \"tfl.transpose\"(%168, %cst_28) : (tensor<4x85250xf32>, tensor<2xi32>) -> tensor<85250x4xf32>\r\n  %170 = \"tfl.reshape\"(%169, %cst_255) : (tensor<85250x4xf32>, tensor<3xi32>) -> tensor<1x85250x4xf32>\r\n  %171 = \"tfl.reshape\"(%169, %cst_254) : (tensor<85250x4xf32>, tensor<4xi32>) -> tensor<1x85250x1x4xf32>\r\n  %172 = \"tfl.unpack\"(%171) {axis = 0 : i32, num = 1 : i32} : (tensor<1x85250x1x4xf32>) -> tensor<85250x1x4xf32>\r\n  %173 = \"tfl.slice\"(%172, %cst_20, %cst_22) : (tensor<85250x1x4xf32>, tensor<3xi32>, tensor<3xi32>) -> tensor<85250x1x4xf32>\r\n  %174 = \"tfl.unpack\"(%173) {axis = 1 : i32, num = 1 : i32} : (tensor<85250x1x4xf32>) -> tensor<85250x4xf32>\r\n  %175 = \"tfl.conv_2d\"(%131, %cst_227, %cst_256) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x256xf32>, tensor<120x3x3x256xf32>, tensor<120xf32>) -> tensor<1x80x80x120xf32>\r\n  %176 = \"tfl.reshape\"(%175, %cst_39) : (tensor<1x80x80x120xf32>, tensor<3xi32>) -> tensor<1x64000x12xf32>\r\n  %177 = \"tfl.conv_2d\"(%132, %cst_227, %cst_256) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<120x3x3x256xf32>, tensor<120xf32>) -> tensor<1x40x40x120xf32>\r\n  %178 = \"tfl.reshape\"(%177, %cst_39) : (tensor<1x40x40x120xf32>, tensor<3xi32>) -> tensor<1x16000x12xf32>\r\n  %179 = \"tfl.conv_2d\"(%133, %cst_227, %cst_256) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x256xf32>, tensor<120x3x3x256xf32>, tensor<120xf32>) -> tensor<1x20x20x120xf32>\r\n  %180 = \"tfl.reshape\"(%179, %cst_39) : (tensor<1x20x20x120xf32>, tensor<3xi32>) -> tensor<1x4000x12xf32>\r\n  %181 = \"tfl.conv_2d\"(%134, %cst_227, %cst_256) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x10x10x256xf32>, tensor<120x3x3x256xf32>, tensor<120xf32>) -> tensor<1x10x10x120xf32>\r\n  %182 = \"tfl.reshape\"(%181, %cst_39) : (tensor<1x10x10x120xf32>, tensor<3xi32>) -> tensor<1x1000x12xf32>\r\n  %183 = \"tfl.conv_2d\"(%135, %cst_227, %cst_256) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x5x5x256xf32>, tensor<120x3x3x256xf32>, tensor<120xf32>) -> tensor<1x5x5x120xf32>\r\n  %184 = \"tfl.reshape\"(%183, %cst_39) : (tensor<1x5x5x120xf32>, tensor<3xi32>) -> tensor<1x250x12xf32>\r\n  %185 = \"tfl.concatenation\"(%176, %178, %180, %182, %184) {axis = 1 : i32, fused_activation_function = \"NONE\"} : (tensor<1x64000x12xf32>, tensor<1x16000x12xf32>, tensor<1x4000x12xf32>, tensor<1x1000x12xf32>, tensor<1x250x12xf32>) -> tensor<1x85250x12xf32>\r\n  %186 = \"tfl.logistic\"(%185) : (tensor<1x85250x12xf32>) -> tensor<1x85250x12xf32>\r\n  %187 = \"tfl.unpack\"(%186) {axis = 0 : i32, num = 1 : i32} : (tensor<1x85250x12xf32>) -> tensor<85250x12xf32>\r\n  %188 = \"tfl.slice\"(%187, %cst_21, %cst_23) : (tensor<85250x12xf32>, tensor<2xi32>, tensor<2xi32>) -> tensor<85250x12xf32>\r\n  %189 = \"tfl.slice\"(%186, %cst_30, %cst_31) : (tensor<1x85250x12xf32>, tensor<3xi32>, tensor<3xi32>) -> tensor<1x85250x11xf32>\r\n  %190 = \"tfl.unpack\"(%189) {axis = 0 : i32, num = 1 : i32} : (tensor<1x85250x11xf32>) -> tensor<85250x11xf32>\r\n  %191 = \"tfl.slice\"(%190, %cst_21, %cst_23) : (tensor<85250x11xf32>, tensor<2xi32>, tensor<2xi32>) -> tensor<85250x11xf32>\r\n  %192 = \"tfl.slice\"(%191, %cst_21, %cst_13) : (tensor<85250x11xf32>, tensor<2xi32>, tensor<2xi32>) -> tensor<85250x1xf32>\r\n  %193 = \"tfl.reshape\"(%192, %cst_257) : (tensor<85250x1xf32>, tensor<1xi32>) -> tensor<85250xf32>\r\n  %selected_indices, %selected_scores, %valid_outputs = \"tfl.non_max_suppression_v5\"(%174, %193, %cst_19, %cst_11, %cst_12, %cst_27) : (tensor<85250x4xf32>, tensor<85250xf32>, tensor<i32>, tensor<f32>, tensor<f32>, tensor<f32>) -> (tensor<?xi32>, tensor<?xf32>, tensor<i32>)\r\n  %194 = \"tfl.shape\"(%selected_indices) : (tensor<?xi32>) -> tensor<1xi32>\r\n  %195 = \"tfl.strided_slice\"(%194, %cst_258, %cst_260, %cst_260) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<1xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %196 = \"tfl.less\"(%cst_14, %195) : (tensor<100xi32>, tensor<i32>) -> tensor<100xi1>\r\n  %197 = \"tfl.sub\"(%cst_19, %195) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %198 = \"tfl.reshape\"(%197, %cst_257) : (tensor<i32>, tensor<1xi32>) -> tensor<1xi32>\r\n  %199 = \"tfl.fill\"(%198, %cst_32) : (tensor<1xi32>, tensor<i32>) -> tensor<?xi32>\r\n  %200 = \"tfl.fill\"(%198, %cst_27) : (tensor<1xi32>, tensor<f32>) -> tensor<?xf32>\r\n  %201 = \"tfl.concatenation\"(%selected_indices, %199) {axis = 0 : i32, fused_activation_function = \"NONE\"} : (tensor<?xi32>, tensor<?xi32>) -> tensor<?xi32>\r\n  %202 = \"tfl.gather\"(%2, %201) {axis = 0 : i32} : (tensor<85250xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %203 = \"tfl.gather\"(%188, %201) {axis = 0 : i32} : (tensor<85250x12xf32>, tensor<?xi32>) -> tensor<?x12xf32>\r\n  %204 = \"tfl.gather\"(%174, %201) {axis = 0 : i32} : (tensor<85250x4xf32>, tensor<?xi32>) -> tensor<?x4xf32>\r\n  %205 = \"tfl.concatenation\"(%selected_scores, %200) {axis = -1 : i32, fused_activation_function = \"NONE\"} : (tensor<?xf32>, tensor<?xf32>) -> tensor<?xf32>\r\n  %206 = \"tfl.select\"(%196, %205, %cst_15) : (tensor<100xi1>, tensor<?xf32>, tensor<100xf32>) -> tensor<100xf32>\r\n  %207 = \"tfl.slice\"(%191, %cst, %cst_13) : (tensor<85250x11xf32>, tensor<2xi32>, tensor<2xi32>) -> tensor<85250x1xf32>\r\n  %208 = \"tfl.reshape\"(%207, %cst_257) : (tensor<85250x1xf32>, tensor<1xi32>) -> tensor<85250xf32>\r\n  %selected_indices_261, %selected_scores_262, %valid_outputs_263 = \"tfl.non_max_suppression_v5\"(%174, %208, %cst_19, %cst_11, %cst_12, %cst_27) : (tensor<85250x4xf32>, tensor<85250xf32>, tensor<i32>, tensor<f32>, tensor<f32>, tensor<f32>) -> (tensor<?xi32>, tensor<?xf32>, tensor<i32>)\r\n  %209 = \"tfl.shape\"(%selected_indices_261) : (tensor<?xi32>) -> tensor<1xi32>\r\n  %210 = \"tfl.strided_slice\"(%209, %cst_258, %cst_260, %cst_260) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<1xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %211 = \"tfl.less\"(%cst_14, %210) : (tensor<100xi32>, tensor<i32>) -> tensor<100xi1>\r\n  %212 = \"tfl.sub\"(%cst_19, %210) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %213 = \"tfl.reshape\"(%212, %cst_257) : (tensor<i32>, tensor<1xi32>) -> tensor<1xi32>\r\n  %214 = \"tfl.fill\"(%213, %cst_32) : (tensor<1xi32>, tensor<i32>) -> tensor<?xi32>\r\n  %215 = \"tfl.fill\"(%213, %cst_27) : (tensor<1xi32>, tensor<f32>) -> tensor<?xf32>\r\n  %216 = \"tfl.concatenation\"(%selected_indices_261, %214) {axis = 0 : i32, fused_activation_function = \"NONE\"} : (tensor<?xi32>, tensor<?xi32>) -> tensor<?xi32>\r\n  %217 = \"tfl.gather\"(%2, %216) {axis = 0 : i32} : (tensor<85250xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %218 = \"tfl.gather\"(%188, %216) {axis = 0 : i32} : (tensor<85250x12xf32>, tensor<?xi32>) -> tensor<?x12xf32>\r\n  %219 = \"tfl.gather\"(%174, %216) {axis = 0 : i32} : (tensor<85250x4xf32>, tensor<?xi32>) -> tensor<?x4xf32>\r\n  %220 = \"tfl.concatenation\"(%selected_scores_262, %215) {axis = -1 : i32, fused_activation_function = \"NONE\"} : (tensor<?xf32>, tensor<?xf32>) -> tensor<?xf32>\r\n  %221 = \"tfl.select\"(%211, %220, %cst_15) : (tensor<100xi1>, tensor<?xf32>, tensor<100xf32>) -> tensor<100xf32>\r\n  %222 = \"tfl.slice\"(%191, %cst_0, %cst_13) : (tensor<85250x11xf32>, tensor<2xi32>, tensor<2xi32>) -> tensor<85250x1xf32>\r\n  %223 = \"tfl.reshape\"(%222, %cst_257) : (tensor<85250x1xf32>, tensor<1xi32>) -> tensor<85250xf32>\r\n  %selected_indices_264, %selected_scores_265, %valid_outputs_266 = \"tfl.non_max_suppression_v5\"(%174, %223, %cst_19, %cst_11, %cst_12, %cst_27) : (tensor<85250x4xf32>, tensor<85250xf32>, tensor<i32>, tensor<f32>, tensor<f32>, tensor<f32>) -> (tensor<?xi32>, tensor<?xf32>, tensor<i32>)\r\n  %224 = \"tfl.shape\"(%selected_indices_264) : (tensor<?xi32>) -> tensor<1xi32>\r\n  %225 = \"tfl.strided_slice\"(%224, %cst_258, %cst_260, %cst_260) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<1xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %226 = \"tfl.less\"(%cst_14, %225) : (tensor<100xi32>, tensor<i32>) -> tensor<100xi1>\r\n  %227 = \"tfl.sub\"(%cst_19, %225) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %228 = \"tfl.reshape\"(%227, %cst_257) : (tensor<i32>, tensor<1xi32>) -> tensor<1xi32>\r\n  %229 = \"tfl.fill\"(%228, %cst_32) : (tensor<1xi32>, tensor<i32>) -> tensor<?xi32>\r\n  %230 = \"tfl.fill\"(%228, %cst_27) : (tensor<1xi32>, tensor<f32>) -> tensor<?xf32>\r\n  %231 = \"tfl.concatenation\"(%selected_indices_264, %229) {axis = 0 : i32, fused_activation_function = \"NONE\"} : (tensor<?xi32>, tensor<?xi32>) -> tensor<?xi32>\r\n  %232 = \"tfl.gather\"(%2, %231) {axis = 0 : i32} : (tensor<85250xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %233 = \"tfl.gather\"(%188, %231) {axis = 0 : i32} : (tensor<85250x12xf32>, tensor<?xi32>) -> tensor<?x12xf32>\r\n  %234 = \"tfl.gather\"(%174, %231) {axis = 0 : i32} : (tensor<85250x4xf32>, tensor<?xi32>) -> tensor<?x4xf32>\r\n  %235 = \"tfl.concatenation\"(%selected_scores_265, %230) {axis = -1 : i32, fused_activation_function = \"NONE\"} : (tensor<?xf32>, tensor<?xf32>) -> tensor<?xf32>\r\n  %236 = \"tfl.select\"(%226, %235, %cst_15) : (tensor<100xi1>, tensor<?xf32>, tensor<100xf32>) -> tensor<100xf32>\r\n  %237 = \"tfl.slice\"(%191, %cst_1, %cst_13) : (tensor<85250x11xf32>, tensor<2xi32>, tensor<2xi32>) -> tensor<85250x1xf32>\r\n  %238 = \"tfl.reshape\"(%237, %cst_257) : (tensor<85250x1xf32>, tensor<1xi32>) -> tensor<85250xf32>\r\n  %selected_indices_267, %selected_scores_268, %valid_outputs_269 = \"tfl.non_max_suppression_v5\"(%174, %238, %cst_19, %cst_11, %cst_12, %cst_27) : (tensor<85250x4xf32>, tensor<85250xf32>, tensor<i32>, tensor<f32>, tensor<f32>, tensor<f32>) -> (tensor<?xi32>, tensor<?xf32>, tensor<i32>)\r\n  %239 = \"tfl.shape\"(%selected_indices_267) : (tensor<?xi32>) -> tensor<1xi32>\r\n  %240 = \"tfl.strided_slice\"(%239, %cst_258, %cst_260, %cst_260) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<1xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %241 = \"tfl.less\"(%cst_14, %240) : (tensor<100xi32>, tensor<i32>) -> tensor<100xi1>\r\n  %242 = \"tfl.sub\"(%cst_19, %240) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %243 = \"tfl.reshape\"(%242, %cst_257) : (tensor<i32>, tensor<1xi32>) -> tensor<1xi32>\r\n  %244 = \"tfl.fill\"(%243, %cst_32) : (tensor<1xi32>, tensor<i32>) -> tensor<?xi32>\r\n  %245 = \"tfl.fill\"(%243, %cst_27) : (tensor<1xi32>, tensor<f32>) -> tensor<?xf32>\r\n  %246 = \"tfl.concatenation\"(%selected_indices_267, %244) {axis = 0 : i32, fused_activation_function = \"NONE\"} : (tensor<?xi32>, tensor<?xi32>) -> tensor<?xi32>\r\n  %247 = \"tfl.gather\"(%2, %246) {axis = 0 : i32} : (tensor<85250xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %248 = \"tfl.gather\"(%188, %246) {axis = 0 : i32} : (tensor<85250x12xf32>, tensor<?xi32>) -> tensor<?x12xf32>\r\n  %249 = \"tfl.gather\"(%174, %246) {axis = 0 : i32} : (tensor<85250x4xf32>, tensor<?xi32>) -> tensor<?x4xf32>\r\n  %250 = \"tfl.concatenation\"(%selected_scores_268, %245) {axis = -1 : i32, fused_activation_function = \"NONE\"} : (tensor<?xf32>, tensor<?xf32>) -> tensor<?xf32>\r\n  %251 = \"tfl.select\"(%241, %250, %cst_15) : (tensor<100xi1>, tensor<?xf32>, tensor<100xf32>) -> tensor<100xf32>\r\n  %252 = \"tfl.slice\"(%191, %cst_2, %cst_13) : (tensor<85250x11xf32>, tensor<2xi32>, tensor<2xi32>) -> tensor<85250x1xf32>\r\n  %253 = \"tfl.reshape\"(%252, %cst_257) : (tensor<85250x1xf32>, tensor<1xi32>) -> tensor<85250xf32>\r\n  %selected_indices_270, %selected_scores_271, %valid_outputs_272 = \"tfl.non_max_suppression_v5\"(%174, %253, %cst_19, %cst_11, %cst_12, %cst_27) : (tensor<85250x4xf32>, tensor<85250xf32>, tensor<i32>, tensor<f32>, tensor<f32>, tensor<f32>) -> (tensor<?xi32>, tensor<?xf32>, tensor<i32>)\r\n  %254 = \"tfl.shape\"(%selected_indices_270) : (tensor<?xi32>) -> tensor<1xi32>\r\n  %255 = \"tfl.strided_slice\"(%254, %cst_258, %cst_260, %cst_260) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<1xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %256 = \"tfl.less\"(%cst_14, %255) : (tensor<100xi32>, tensor<i32>) -> tensor<100xi1>\r\n  %257 = \"tfl.sub\"(%cst_19, %255) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %258 = \"tfl.reshape\"(%257, %cst_257) : (tensor<i32>, tensor<1xi32>) -> tensor<1xi32>\r\n  %259 = \"tfl.fill\"(%258, %cst_32) : (tensor<1xi32>, tensor<i32>) -> tensor<?xi32>\r\n  %260 = \"tfl.fill\"(%258, %cst_27) : (tensor<1xi32>, tensor<f32>) -> tensor<?xf32>\r\n  %261 = \"tfl.concatenation\"(%selected_indices_270, %259) {axis = 0 : i32, fused_activation_function = \"NONE\"} : (tensor<?xi32>, tensor<?xi32>) -> tensor<?xi32>\r\n  %262 = \"tfl.gather\"(%2, %261) {axis = 0 : i32} : (tensor<85250xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %263 = \"tfl.gather\"(%188, %261) {axis = 0 : i32} : (tensor<85250x12xf32>, tensor<?xi32>) -> tensor<?x12xf32>\r\n  %264 = \"tfl.gather\"(%174, %261) {axis = 0 : i32} : (tensor<85250x4xf32>, tensor<?xi32>) -> tensor<?x4xf32>\r\n  %265 = \"tfl.concatenation\"(%selected_scores_271, %260) {axis = -1 : i32, fused_activation_function = \"NONE\"} : (tensor<?xf32>, tensor<?xf32>) -> tensor<?xf32>\r\n  %266 = \"tfl.select\"(%256, %265, %cst_15) : (tensor<100xi1>, tensor<?xf32>, tensor<100xf32>) -> tensor<100xf32>\r\n  %267 = \"tfl.slice\"(%191, %cst_3, %cst_13) : (tensor<85250x11xf32>, tensor<2xi32>, tensor<2xi32>) -> tensor<85250x1xf32>\r\n  %268 = \"tfl.reshape\"(%267, %cst_257) : (tensor<85250x1xf32>, tensor<1xi32>) -> tensor<85250xf32>\r\n  %selected_indices_273, %selected_scores_274, %valid_outputs_275 = \"tfl.non_max_suppression_v5\"(%174, %268, %cst_19, %cst_11, %cst_12, %cst_27) : (tensor<85250x4xf32>, tensor<85250xf32>, tensor<i32>, tensor<f32>, tensor<f32>, tensor<f32>) -> (tensor<?xi32>, tensor<?xf32>, tensor<i32>)\r\n  %269 = \"tfl.shape\"(%selected_indices_273) : (tensor<?xi32>) -> tensor<1xi32>\r\n  %270 = \"tfl.strided_slice\"(%269, %cst_258, %cst_260, %cst_260) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<1xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %271 = \"tfl.less\"(%cst_14, %270) : (tensor<100xi32>, tensor<i32>) -> tensor<100xi1>\r\n  %272 = \"tfl.sub\"(%cst_19, %270) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %273 = \"tfl.reshape\"(%272, %cst_257) : (tensor<i32>, tensor<1xi32>) -> tensor<1xi32>\r\n  %274 = \"tfl.fill\"(%273, %cst_32) : (tensor<1xi32>, tensor<i32>) -> tensor<?xi32>\r\n  %275 = \"tfl.fill\"(%273, %cst_27) : (tensor<1xi32>, tensor<f32>) -> tensor<?xf32>\r\n  %276 = \"tfl.concatenation\"(%selected_indices_273, %274) {axis = 0 : i32, fused_activation_function = \"NONE\"} : (tensor<?xi32>, tensor<?xi32>) -> tensor<?xi32>\r\n  %277 = \"tfl.gather\"(%2, %276) {axis = 0 : i32} : (tensor<85250xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %278 = \"tfl.gather\"(%188, %276) {axis = 0 : i32} : (tensor<85250x12xf32>, tensor<?xi32>) -> tensor<?x12xf32>\r\n  %279 = \"tfl.gather\"(%174, %276) {axis = 0 : i32} : (tensor<85250x4xf32>, tensor<?xi32>) -> tensor<?x4xf32>\r\n  %280 = \"tfl.concatenation\"(%selected_scores_274, %275) {axis = -1 : i32, fused_activation_function = \"NONE\"} : (tensor<?xf32>, tensor<?xf32>) -> tensor<?xf32>\r\n  %281 = \"tfl.select\"(%271, %280, %cst_15) : (tensor<100xi1>, tensor<?xf32>, tensor<100xf32>) -> tensor<100xf32>\r\n  %282 = \"tfl.slice\"(%191, %cst_4, %cst_13) : (tensor<85250x11xf32>, tensor<2xi32>, tensor<2xi32>) -> tensor<85250x1xf32>\r\n  %283 = \"tfl.reshape\"(%282, %cst_257) : (tensor<85250x1xf32>, tensor<1xi32>) -> tensor<85250xf32>\r\n  %selected_indices_276, %selected_scores_277, %valid_outputs_278 = \"tfl.non_max_suppression_v5\"(%174, %283, %cst_19, %cst_11, %cst_12, %cst_27) : (tensor<85250x4xf32>, tensor<85250xf32>, tensor<i32>, tensor<f32>, tensor<f32>, tensor<f32>) -> (tensor<?xi32>, tensor<?xf32>, tensor<i32>)\r\n  %284 = \"tfl.shape\"(%selected_indices_276) : (tensor<?xi32>) -> tensor<1xi32>\r\n  %285 = \"tfl.strided_slice\"(%284, %cst_258, %cst_260, %cst_260) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<1xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %286 = \"tfl.less\"(%cst_14, %285) : (tensor<100xi32>, tensor<i32>) -> tensor<100xi1>\r\n  %287 = \"tfl.sub\"(%cst_19, %285) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %288 = \"tfl.reshape\"(%287, %cst_257) : (tensor<i32>, tensor<1xi32>) -> tensor<1xi32>\r\n  %289 = \"tfl.fill\"(%288, %cst_32) : (tensor<1xi32>, tensor<i32>) -> tensor<?xi32>\r\n  %290 = \"tfl.fill\"(%288, %cst_27) : (tensor<1xi32>, tensor<f32>) -> tensor<?xf32>\r\n  %291 = \"tfl.concatenation\"(%selected_indices_276, %289) {axis = 0 : i32, fused_activation_function = \"NONE\"} : (tensor<?xi32>, tensor<?xi32>) -> tensor<?xi32>\r\n  %292 = \"tfl.gather\"(%2, %291) {axis = 0 : i32} : (tensor<85250xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %293 = \"tfl.gather\"(%188, %291) {axis = 0 : i32} : (tensor<85250x12xf32>, tensor<?xi32>) -> tensor<?x12xf32>\r\n  %294 = \"tfl.gather\"(%174, %291) {axis = 0 : i32} : (tensor<85250x4xf32>, tensor<?xi32>) -> tensor<?x4xf32>\r\n  %295 = \"tfl.concatenation\"(%selected_scores_277, %290) {axis = -1 : i32, fused_activation_function = \"NONE\"} : (tensor<?xf32>, tensor<?xf32>) -> tensor<?xf32>\r\n  %296 = \"tfl.select\"(%286, %295, %cst_15) : (tensor<100xi1>, tensor<?xf32>, tensor<100xf32>) -> tensor<100xf32>\r\n  %297 = \"tfl.slice\"(%191, %cst_5, %cst_13) : (tensor<85250x11xf32>, tensor<2xi32>, tensor<2xi32>) -> tensor<85250x1xf32>\r\n  %298 = \"tfl.reshape\"(%297, %cst_257) : (tensor<85250x1xf32>, tensor<1xi32>) -> tensor<85250xf32>\r\n  %selected_indices_279, %selected_scores_280, %valid_outputs_281 = \"tfl.non_max_suppression_v5\"(%174, %298, %cst_19, %cst_11, %cst_12, %cst_27) : (tensor<85250x4xf32>, tensor<85250xf32>, tensor<i32>, tensor<f32>, tensor<f32>, tensor<f32>) -> (tensor<?xi32>, tensor<?xf32>, tensor<i32>)\r\n  %299 = \"tfl.shape\"(%selected_indices_279) : (tensor<?xi32>) -> tensor<1xi32>\r\n  %300 = \"tfl.strided_slice\"(%299, %cst_258, %cst_260, %cst_260) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<1xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %301 = \"tfl.less\"(%cst_14, %300) : (tensor<100xi32>, tensor<i32>) -> tensor<100xi1>\r\n  %302 = \"tfl.sub\"(%cst_19, %300) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %303 = \"tfl.reshape\"(%302, %cst_257) : (tensor<i32>, tensor<1xi32>) -> tensor<1xi32>\r\n  %304 = \"tfl.fill\"(%303, %cst_32) : (tensor<1xi32>, tensor<i32>) -> tensor<?xi32>\r\n  %305 = \"tfl.fill\"(%303, %cst_27) : (tensor<1xi32>, tensor<f32>) -> tensor<?xf32>\r\n  %306 = \"tfl.concatenation\"(%selected_indices_279, %304) {axis = 0 : i32, fused_activation_function = \"NONE\"} : (tensor<?xi32>, tensor<?xi32>) -> tensor<?xi32>\r\n  %307 = \"tfl.gather\"(%2, %306) {axis = 0 : i32} : (tensor<85250xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %308 = \"tfl.gather\"(%188, %306) {axis = 0 : i32} : (tensor<85250x12xf32>, tensor<?xi32>) -> tensor<?x12xf32>\r\n  %309 = \"tfl.gather\"(%174, %306) {axis = 0 : i32} : (tensor<85250x4xf32>, tensor<?xi32>) -> tensor<?x4xf32>\r\n  %310 = \"tfl.concatenation\"(%selected_scores_280, %305) {axis = -1 : i32, fused_activation_function = \"NONE\"} : (tensor<?xf32>, tensor<?xf32>) -> tensor<?xf32>\r\n  %311 = \"tfl.select\"(%301, %310, %cst_15) : (tensor<100xi1>, tensor<?xf32>, tensor<100xf32>) -> tensor<100xf32>\r\n  %312 = \"tfl.slice\"(%191, %cst_6, %cst_13) : (tensor<85250x11xf32>, tensor<2xi32>, tensor<2xi32>) -> tensor<85250x1xf32>\r\n  %313 = \"tfl.reshape\"(%312, %cst_257) : (tensor<85250x1xf32>, tensor<1xi32>) -> tensor<85250xf32>\r\n  %selected_indices_282, %selected_scores_283, %valid_outputs_284 = \"tfl.non_max_suppression_v5\"(%174, %313, %cst_19, %cst_11, %cst_12, %cst_27) : (tensor<85250x4xf32>, tensor<85250xf32>, tensor<i32>, tensor<f32>, tensor<f32>, tensor<f32>) -> (tensor<?xi32>, tensor<?xf32>, tensor<i32>)\r\n  %314 = \"tfl.shape\"(%selected_indices_282) : (tensor<?xi32>) -> tensor<1xi32>\r\n  %315 = \"tfl.strided_slice\"(%314, %cst_258, %cst_260, %cst_260) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<1xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %316 = \"tfl.less\"(%cst_14, %315) : (tensor<100xi32>, tensor<i32>) -> tensor<100xi1>\r\n  %317 = \"tfl.sub\"(%cst_19, %315) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %318 = \"tfl.reshape\"(%317, %cst_257) : (tensor<i32>, tensor<1xi32>) -> tensor<1xi32>\r\n  %319 = \"tfl.fill\"(%318, %cst_32) : (tensor<1xi32>, tensor<i32>) -> tensor<?xi32>\r\n  %320 = \"tfl.fill\"(%318, %cst_27) : (tensor<1xi32>, tensor<f32>) -> tensor<?xf32>\r\n  %321 = \"tfl.concatenation\"(%selected_indices_282, %319) {axis = 0 : i32, fused_activation_function = \"NONE\"} : (tensor<?xi32>, tensor<?xi32>) -> tensor<?xi32>\r\n  %322 = \"tfl.gather\"(%2, %321) {axis = 0 : i32} : (tensor<85250xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %323 = \"tfl.gather\"(%188, %321) {axis = 0 : i32} : (tensor<85250x12xf32>, tensor<?xi32>) -> tensor<?x12xf32>\r\n  %324 = \"tfl.gather\"(%174, %321) {axis = 0 : i32} : (tensor<85250x4xf32>, tensor<?xi32>) -> tensor<?x4xf32>\r\n  %325 = \"tfl.concatenation\"(%selected_scores_283, %320) {axis = -1 : i32, fused_activation_function = \"NONE\"} : (tensor<?xf32>, tensor<?xf32>) -> tensor<?xf32>\r\n  %326 = \"tfl.select\"(%316, %325, %cst_15) : (tensor<100xi1>, tensor<?xf32>, tensor<100xf32>) -> tensor<100xf32>\r\n  %327 = \"tfl.slice\"(%191, %cst_7, %cst_13) : (tensor<85250x11xf32>, tensor<2xi32>, tensor<2xi32>) -> tensor<85250x1xf32>\r\n  %328 = \"tfl.reshape\"(%327, %cst_257) : (tensor<85250x1xf32>, tensor<1xi32>) -> tensor<85250xf32>\r\n  %selected_indices_285, %selected_scores_286, %valid_outputs_287 = \"tfl.non_max_suppression_v5\"(%174, %328, %cst_19, %cst_11, %cst_12, %cst_27) : (tensor<85250x4xf32>, tensor<85250xf32>, tensor<i32>, tensor<f32>, tensor<f32>, tensor<f32>) -> (tensor<?xi32>, tensor<?xf32>, tensor<i32>)\r\n  %329 = \"tfl.shape\"(%selected_indices_285) : (tensor<?xi32>) -> tensor<1xi32>\r\n  %330 = \"tfl.strided_slice\"(%329, %cst_258, %cst_260, %cst_260) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<1xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %331 = \"tfl.less\"(%cst_14, %330) : (tensor<100xi32>, tensor<i32>) -> tensor<100xi1>\r\n  %332 = \"tfl.sub\"(%cst_19, %330) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %333 = \"tfl.reshape\"(%332, %cst_257) : (tensor<i32>, tensor<1xi32>) -> tensor<1xi32>\r\n  %334 = \"tfl.fill\"(%333, %cst_32) : (tensor<1xi32>, tensor<i32>) -> tensor<?xi32>\r\n  %335 = \"tfl.fill\"(%333, %cst_27) : (tensor<1xi32>, tensor<f32>) -> tensor<?xf32>\r\n  %336 = \"tfl.concatenation\"(%selected_indices_285, %334) {axis = 0 : i32, fused_activation_function = \"NONE\"} : (tensor<?xi32>, tensor<?xi32>) -> tensor<?xi32>\r\n  %337 = \"tfl.gather\"(%2, %336) {axis = 0 : i32} : (tensor<85250xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %338 = \"tfl.gather\"(%188, %336) {axis = 0 : i32} : (tensor<85250x12xf32>, tensor<?xi32>) -> tensor<?x12xf32>\r\n  %339 = \"tfl.gather\"(%174, %336) {axis = 0 : i32} : (tensor<85250x4xf32>, tensor<?xi32>) -> tensor<?x4xf32>\r\n  %340 = \"tfl.concatenation\"(%selected_scores_286, %335) {axis = -1 : i32, fused_activation_function = \"NONE\"} : (tensor<?xf32>, tensor<?xf32>) -> tensor<?xf32>\r\n  %341 = \"tfl.select\"(%331, %340, %cst_15) : (tensor<100xi1>, tensor<?xf32>, tensor<100xf32>) -> tensor<100xf32>\r\n  %342 = \"tfl.slice\"(%191, %cst_8, %cst_13) : (tensor<85250x11xf32>, tensor<2xi32>, tensor<2xi32>) -> tensor<85250x1xf32>\r\n  %343 = \"tfl.reshape\"(%342, %cst_257) : (tensor<85250x1xf32>, tensor<1xi32>) -> tensor<85250xf32>\r\n  %selected_indices_288, %selected_scores_289, %valid_outputs_290 = \"tfl.non_max_suppression_v5\"(%174, %343, %cst_19, %cst_11, %cst_12, %cst_27) : (tensor<85250x4xf32>, tensor<85250xf32>, tensor<i32>, tensor<f32>, tensor<f32>, tensor<f32>) -> (tensor<?xi32>, tensor<?xf32>, tensor<i32>)\r\n  %344 = \"tfl.shape\"(%selected_indices_288) : (tensor<?xi32>) -> tensor<1xi32>\r\n  %345 = \"tfl.strided_slice\"(%344, %cst_258, %cst_260, %cst_260) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<1xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %346 = \"tfl.less\"(%cst_14, %345) : (tensor<100xi32>, tensor<i32>) -> tensor<100xi1>\r\n  %347 = \"tfl.sub\"(%cst_19, %345) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %348 = \"tfl.reshape\"(%347, %cst_257) : (tensor<i32>, tensor<1xi32>) -> tensor<1xi32>\r\n  %349 = \"tfl.fill\"(%348, %cst_32) : (tensor<1xi32>, tensor<i32>) -> tensor<?xi32>\r\n  %350 = \"tfl.fill\"(%348, %cst_27) : (tensor<1xi32>, tensor<f32>) -> tensor<?xf32>\r\n  %351 = \"tfl.concatenation\"(%selected_indices_288, %349) {axis = 0 : i32, fused_activation_function = \"NONE\"} : (tensor<?xi32>, tensor<?xi32>) -> tensor<?xi32>\r\n  %352 = \"tfl.gather\"(%2, %351) {axis = 0 : i32} : (tensor<85250xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %353 = \"tfl.concatenation\"(%202, %217, %247, %262, %277, %292, %307, %322, %337, %352, %232) {axis = 0 : i32, fused_activation_function = \"NONE\"} : (tensor<?xf32>, tensor<?xf32>, tensor<?xf32>, tensor<?xf32>, tensor<?xf32>, tensor<?xf32>, tensor<?xf32>, tensor<?xf32>, tensor<?xf32>, tensor<?xf32>, tensor<?xf32>) -> tensor<?xf32>\r\n  %354 = \"tfl.gather\"(%188, %351) {axis = 0 : i32} : (tensor<85250x12xf32>, tensor<?xi32>) -> tensor<?x12xf32>\r\n  %355 = \"tfl.concatenation\"(%203, %218, %248, %263, %278, %293, %308, %323, %338, %354, %233) {axis = 0 : i32, fused_activation_function = \"NONE\"} : (tensor<?x12xf32>, tensor<?x12xf32>, tensor<?x12xf32>, tensor<?x12xf32>, tensor<?x12xf32>, tensor<?x12xf32>, tensor<?x12xf32>, tensor<?x12xf32>, tensor<?x12xf32>, tensor<?x12xf32>, tensor<?x12xf32>) -> tensor<?x12xf32>\r\n  %356 = \"tfl.gather\"(%174, %351) {axis = 0 : i32} : (tensor<85250x4xf32>, tensor<?xi32>) -> tensor<?x4xf32>\r\n  %357 = \"tfl.concatenation\"(%204, %219, %249, %264, %279, %294, %309, %324, %339, %356, %234) {axis = 0 : i32, fused_activation_function = \"NONE\"} : (tensor<?x4xf32>, tensor<?x4xf32>, tensor<?x4xf32>, tensor<?x4xf32>, tensor<?x4xf32>, tensor<?x4xf32>, tensor<?x4xf32>, tensor<?x4xf32>, tensor<?x4xf32>, tensor<?x4xf32>, tensor<?x4xf32>) -> tensor<?x4xf32>\r\n  %358 = \"tfl.shape\"(%357) : (tensor<?x4xf32>) -> tensor<2xi32>\r\n  %359 = \"tfl.strided_slice\"(%358, %cst_258, %cst_260, %cst_260) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %360 = \"tfl.equal\"(%359, %cst_9) : (tensor<i32>, tensor<i32>) -> tensor<i1>\r\n  %361 = \"tfl.concatenation\"(%selected_scores_289, %350) {axis = -1 : i32, fused_activation_function = \"NONE\"} : (tensor<?xf32>, tensor<?xf32>) -> tensor<?xf32>\r\n  %362 = \"tfl.select\"(%346, %361, %cst_15) : (tensor<100xi1>, tensor<?xf32>, tensor<100xf32>) -> tensor<100xf32>\r\n  %363 = \"tfl.concatenation\"(%206, %221, %251, %266, %281, %296, %311, %326, %341, %362, %236) {axis = 0 : i32, fused_activation_function = \"NONE\"} : (tensor<100xf32>, tensor<100xf32>, tensor<100xf32>, tensor<100xf32>, tensor<100xf32>, tensor<100xf32>, tensor<100xf32>, tensor<100xf32>, tensor<100xf32>, tensor<100xf32>, tensor<100xf32>) -> tensor<1100xf32>\r\n  %values, %indices = \"tfl.topk_v2\"(%363, %359) : (tensor<1100xf32>, tensor<i32>) -> (tensor<?xf32>, tensor<?xi32>)\r\n  %364 = \"tfl.gather\"(%363, %indices) {axis = 0 : i32} : (tensor<1100xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %365 = \"tfl.gather\"(%353, %indices) {axis = 0 : i32} : (tensor<?xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %366 = \"tfl.gather\"(%355, %indices) {axis = 0 : i32} : (tensor<?x12xf32>, tensor<?xi32>) -> tensor<?x12xf32>\r\n  %367 = \"tfl.gather\"(%cst_16, %indices) {axis = 0 : i32} : (tensor<1100xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %368 = \"tfl.gather\"(%357, %indices) {axis = 0 : i32} : (tensor<?x4xf32>, tensor<?xi32>) -> tensor<?x4xf32>\r\n  %369:4 = \"tfl.split\"(%cst_41, %368) {num_splits = 4 : i32} : (tensor<i32>, tensor<?x4xf32>) -> (tensor<?x1xf32>, tensor<?x1xf32>, tensor<?x1xf32>, tensor<?x1xf32>)\r\n  %370 = \"tfl.minimum\"(%369#0, %cst_40) : (tensor<?x1xf32>, tensor<f32>) -> tensor<?x1xf32>\r\n  %371 = \"tfl.relu\"(%370) : (tensor<?x1xf32>) -> tensor<?x1xf32>\r\n  %372 = \"tfl.minimum\"(%369#2, %cst_40) : (tensor<?x1xf32>, tensor<f32>) -> tensor<?x1xf32>\r\n  %373 = \"tfl.relu\"(%372) : (tensor<?x1xf32>) -> tensor<?x1xf32>\r\n  %374 = \"tfl.minimum\"(%369#1, %cst_40) : (tensor<?x1xf32>, tensor<f32>) -> tensor<?x1xf32>\r\n  %375 = \"tfl.relu\"(%374) : (tensor<?x1xf32>) -> tensor<?x1xf32>\r\n  %376 = \"tfl.minimum\"(%369#3, %cst_40) : (tensor<?x1xf32>, tensor<f32>) -> tensor<?x1xf32>\r\n  %377 = \"tfl.relu\"(%376) : (tensor<?x1xf32>) -> tensor<?x1xf32>\r\n  %378 = \"tfl.concatenation\"(%371, %375, %373, %377) {axis = 1 : i32, fused_activation_function = \"NONE\"} : (tensor<?x1xf32>, tensor<?x1xf32>, tensor<?x1xf32>, tensor<?x1xf32>) -> tensor<?x4xf32>\r\n  %379:4 = \"tfl.split\"(%cst_41, %378) {num_splits = 4 : i32} : (tensor<i32>, tensor<?x4xf32>) -> (tensor<?x1xf32>, tensor<?x1xf32>, tensor<?x1xf32>, tensor<?x1xf32>)\r\n  %380 = \"tfl.sub\"(%379#2, %379#0) {fused_activation_function = \"NONE\"} : (tensor<?x1xf32>, tensor<?x1xf32>) -> tensor<?x1xf32>\r\n  %381 = \"tfl.sub\"(%379#3, %379#1) {fused_activation_function = \"NONE\"} : (tensor<?x1xf32>, tensor<?x1xf32>) -> tensor<?x1xf32>\r\n  %382 = \"tfl.mul\"(%380, %381) {fused_activation_function = \"NONE\"} : (tensor<?x1xf32>, tensor<?x1xf32>) -> tensor<?x1xf32>\r\n  %383 = \"tfl.greater\"(%382, %cst_27) : (tensor<?x1xf32>, tensor<f32>) -> tensor<?x1xi1>\r\n  %384 = \"tfl.reshape\"(%383, %cst_257) : (tensor<?x1xi1>, tensor<1xi32>) -> tensor<?xi1>\r\n  %385 = \"tfl.where\"(%384) : (tensor<?xi1>) -> tensor<?x1xi64>\r\n  %386 = \"tfl.reshape\"(%385, %cst_257) : (tensor<?x1xi64>, tensor<1xi32>) -> tensor<?xi64>\r\n  %387 = \"tfl.cast\"(%386) : (tensor<?xi64>) -> tensor<?xi32>\r\n  %388 = \"tfl.gather\"(%364, %387) {axis = 0 : i32} : (tensor<?xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %389 = \"tfl.gather\"(%365, %387) {axis = 0 : i32} : (tensor<?xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %390 = \"tfl.gather\"(%366, %387) {axis = 0 : i32} : (tensor<?x12xf32>, tensor<?xi32>) -> tensor<?x12xf32>\r\n  %391 = \"tfl.gather\"(%367, %387) {axis = 0 : i32} : (tensor<?xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %392 = \"tfl.gather\"(%378, %387) {axis = 0 : i32} : (tensor<?x4xf32>, tensor<?xi32>) -> tensor<?x4xf32>\r\n  %393:4 = \"tfl.split\"(%cst_41, %392) {num_splits = 4 : i32} : (tensor<i32>, tensor<?x4xf32>) -> (tensor<?x1xf32>, tensor<?x1xf32>, tensor<?x1xf32>, tensor<?x1xf32>)\r\n  %394 = \"tfl.sub\"(%393#2, %393#0) {fused_activation_function = \"NONE\"} : (tensor<?x1xf32>, tensor<?x1xf32>) -> tensor<?x1xf32>\r\n  %395 = \"tfl.sub\"(%393#3, %393#1) {fused_activation_function = \"NONE\"} : (tensor<?x1xf32>, tensor<?x1xf32>) -> tensor<?x1xf32>\r\n  %396 = \"tfl.mul\"(%394, %395) {fused_activation_function = \"NONE\"} : (tensor<?x1xf32>, tensor<?x1xf32>) -> tensor<?x1xf32>\r\n  %397 = \"tfl.reshape\"(%396, %cst_257) : (tensor<?x1xf32>, tensor<1xi32>) -> tensor<?xf32>\r\n  %398 = \"tfl.cast\"(%397) : (tensor<?xf32>) -> tensor<?xi1>\r\n  %399 = \"tfl.shape\"(%392) : (tensor<?x4xf32>) -> tensor<2xi32>\r\n  %400 = \"tfl.strided_slice\"(%399, %cst_258, %cst_260, %cst_260) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %401 = \"tfl.reshape\"(%400, %cst_257) : (tensor<i32>, tensor<1xi32>) -> tensor<1xi32>\r\n  %402 = \"tfl.fill\"(%401, %cst_40) : (tensor<1xi32>, tensor<f32>) -> tensor<?xf32>\r\n  %403 = \"tfl.mul\"(%402, %cst_10) {fused_activation_function = \"NONE\"} : (tensor<?xf32>, tensor<f32>) -> tensor<?xf32>\r\n  %404 = \"tfl.select\"(%398, %388, %403) : (tensor<?xi1>, tensor<?xf32>, tensor<?xf32>) -> tensor<?xf32>\r\n  %405 = \"tfl.greater_equal\"(%404, %cst_27) : (tensor<?xf32>, tensor<f32>) -> tensor<?xi1>\r\n  %406 = \"tfl.cast\"(%405) : (tensor<?xi1>) -> tensor<?xi32>\r\n  %407 = \"tfl.sum\"(%406, %cst_258) {keep_dims = false} : (tensor<?xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %408 = \"tf.Size\"(%404) {device = \"\"} : (tensor<?xf32>) -> tensor<i32>\r\n  %409 = \"tfl.equal\"(%400, %408) : (tensor<i32>, tensor<i32>) -> tensor<i1>\r\n  %values_291, %indices_292 = \"tfl.topk_v2\"(%404, %400) : (tensor<?xf32>, tensor<i32>) -> (tensor<?xf32>, tensor<?xi32>)\r\n  %410 = \"tfl.gather\"(%404, %indices_292) {axis = 0 : i32} : (tensor<?xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %411 = \"tfl.gather\"(%389, %indices_292) {axis = 0 : i32} : (tensor<?xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %412 = \"tfl.gather\"(%390, %indices_292) {axis = 0 : i32} : (tensor<?x12xf32>, tensor<?xi32>) -> tensor<?x12xf32>\r\n  %413 = \"tfl.gather\"(%391, %indices_292) {axis = 0 : i32} : (tensor<?xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %414 = \"tfl.gather\"(%392, %indices_292) {axis = 0 : i32} : (tensor<?x4xf32>, tensor<?xi32>) -> tensor<?x4xf32>\r\n  %415 = \"tfl.sub\"(%414, %cst_26) {fused_activation_function = \"NONE\"} : (tensor<?x4xf32>, tensor<4xf32>) -> tensor<?x4xf32>\r\n  %416:4 = \"tfl.split\"(%cst_41, %415) {num_splits = 4 : i32} : (tensor<i32>, tensor<?x4xf32>) -> (tensor<?x1xf32>, tensor<?x1xf32>, tensor<?x1xf32>, tensor<?x1xf32>)\r\n  %417 = \"tfl.concatenation\"(%416#0, %416#1, %416#2, %416#3) {axis = 1 : i32, fused_activation_function = \"NONE\"} : (tensor<?x1xf32>, tensor<?x1xf32>, tensor<?x1xf32>, tensor<?x1xf32>) -> tensor<?x4xf32>\r\n  %418 = \"tfl.shape\"(%417) : (tensor<?x4xf32>) -> tensor<2xi32>\r\n  %419 = \"tfl.strided_slice\"(%418, %cst_258, %cst_260, %cst_260) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %420 = \"tfl.minimum\"(%419, %cst_19) : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %421 = \"tfl.greater\"(%420, %407) : (tensor<i32>, tensor<i32>) -> tensor<i1>\r\n  %422 = \"tfl.select\"(%421, %407, %420) : (tensor<i1>, tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %423 = \"tfl.range\"(%cst_32, %422, %cst_41) : (tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<?xi32>\r\n  %424 = \"tfl.pack\"(%422) {axis = 0 : i32, values_count = 1 : i32} : (tensor<i32>) -> tensor<1xi32>\r\n  %425 = \"tfl.cast\"(%424) : (tensor<1xi32>) -> tensor<1xf32>\r\n  %426 = \"tfl.range\"(%cst_32, %420, %cst_41) : (tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<?xi32>\r\n  %427 = \"tfl.gather\"(%410, %426) {axis = 0 : i32} : (tensor<?xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %428 = \"tfl.gather\"(%427, %423) {axis = 0 : i32} : (tensor<?xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %429 = \"tfl.shape\"(%428) : (tensor<?xf32>) -> tensor<1xi32>\r\n  %430 = \"tfl.strided_slice\"(%429, %cst_258, %cst_260, %cst_260) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<1xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %431 = \"tfl.sub\"(%430, %cst_19) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %432 = \"tfl.greater\"(%431, %cst_32) : (tensor<i32>, tensor<i32>) -> tensor<i1>\r\n  %433 = \"tfl.select\"(%432, %cst_19, %cst_25) : (tensor<i1>, tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %434 = \"tfl.pack\"(%433) {axis = 0 : i32, values_count = 1 : i32} : (tensor<i32>) -> tensor<1xi32>\r\n  %435 = \"tfl.slice\"(%428, %cst_258, %434) : (tensor<?xf32>, tensor<1xi32>, tensor<1xi32>) -> tensor<?xf32>\r\n  %436 = \"tfl.shape\"(%435) : (tensor<?xf32>) -> tensor<1xi32>\r\n  %437 = \"tfl.strided_slice\"(%436, %cst_258, %cst_260, %cst_260) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<1xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %438 = \"tfl.sub\"(%cst_19, %437) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %439 = \"tfl.pack\"(%438) {axis = 0 : i32, values_count = 1 : i32} : (tensor<i32>) -> tensor<1xi32>\r\n  %440 = \"tfl.pack\"(%cst_258, %439) {axis = 1 : i32, values_count = 2 : i32} : (tensor<1xi32>, tensor<1xi32>) -> tensor<1x2xi32>\r\n  %441 = \"tfl.pad\"(%435, %440) : (tensor<?xf32>, tensor<1x2xi32>) -> tensor<?xf32>\r\n  %442 = \"tfl.pack\"(%441) {axis = 0 : i32, values_count = 1 : i32} : (tensor<?xf32>) -> tensor<1x?xf32>\r\n  %443 = \"tfl.gather\"(%411, %426) {axis = 0 : i32} : (tensor<?xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %444 = \"tfl.gather\"(%443, %423) {axis = 0 : i32} : (tensor<?xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %445 = \"tfl.shape\"(%444) : (tensor<?xf32>) -> tensor<1xi32>\r\n  %446 = \"tfl.strided_slice\"(%445, %cst_258, %cst_260, %cst_260) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<1xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %447 = \"tfl.sub\"(%446, %cst_19) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %448 = \"tfl.greater\"(%447, %cst_32) : (tensor<i32>, tensor<i32>) -> tensor<i1>\r\n  %449 = \"tfl.select\"(%448, %cst_19, %cst_25) : (tensor<i1>, tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %450 = \"tfl.pack\"(%449) {axis = 0 : i32, values_count = 1 : i32} : (tensor<i32>) -> tensor<1xi32>\r\n  %451 = \"tfl.slice\"(%444, %cst_258, %450) : (tensor<?xf32>, tensor<1xi32>, tensor<1xi32>) -> tensor<?xf32>\r\n  %452 = \"tfl.shape\"(%451) : (tensor<?xf32>) -> tensor<1xi32>\r\n  %453 = \"tfl.strided_slice\"(%452, %cst_258, %cst_260, %cst_260) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<1xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %454 = \"tfl.sub\"(%cst_19, %453) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %455 = \"tfl.pack\"(%454) {axis = 0 : i32, values_count = 1 : i32} : (tensor<i32>) -> tensor<1xi32>\r\n  %456 = \"tfl.pack\"(%cst_258, %455) {axis = 1 : i32, values_count = 2 : i32} : (tensor<1xi32>, tensor<1xi32>) -> tensor<1x2xi32>\r\n  %457 = \"tfl.pad\"(%451, %456) : (tensor<?xf32>, tensor<1x2xi32>) -> tensor<?xf32>\r\n  %458 = \"tfl.pack\"(%457) {axis = 0 : i32, values_count = 1 : i32} : (tensor<?xf32>) -> tensor<1x?xf32>\r\n  %459 = \"tfl.cast\"(%458) : (tensor<1x?xf32>) -> tensor<1x?xi32>\r\n  %460 = \"tfl.cast\"(%459) : (tensor<1x?xi32>) -> tensor<1x?xf32>\r\n  %461 = \"tfl.gather\"(%412, %426) {axis = 0 : i32} : (tensor<?x12xf32>, tensor<?xi32>) -> tensor<?x12xf32>\r\n  %462 = \"tfl.gather\"(%461, %423) {axis = 0 : i32} : (tensor<?x12xf32>, tensor<?xi32>) -> tensor<?x12xf32>\r\n  %463 = \"tfl.shape\"(%462) : (tensor<?x12xf32>) -> tensor<2xi32>\r\n  %464 = \"tfl.strided_slice\"(%463, %cst_258, %cst_260, %cst_260) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %465 = \"tfl.sub\"(%464, %cst_19) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %466 = \"tfl.greater\"(%465, %cst_32) : (tensor<i32>, tensor<i32>) -> tensor<i1>\r\n  %467 = \"tfl.select\"(%466, %cst_19, %cst_25) : (tensor<i1>, tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %468 = \"tfl.strided_slice\"(%463, %cst_260, %cst_259, %cst_260) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %469 = \"tfl.sub\"(%468, %cst_17) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %470 = \"tfl.greater\"(%469, %cst_32) : (tensor<i32>, tensor<i32>) -> tensor<i1>\r\n  %471 = \"tfl.select\"(%470, %cst_17, %cst_25) : (tensor<i1>, tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %472 = \"tfl.pack\"(%467, %471) {axis = 0 : i32, values_count = 2 : i32} : (tensor<i32>, tensor<i32>) -> tensor<2xi32>\r\n  %473 = \"tfl.slice\"(%462, %cst_21, %472) : (tensor<?x12xf32>, tensor<2xi32>, tensor<2xi32>) -> tensor<?x?xf32>\r\n  %474 = \"tfl.shape\"(%473) : (tensor<?x?xf32>) -> tensor<2xi32>\r\n  %475 = \"tfl.strided_slice\"(%474, %cst_258, %cst_260, %cst_260) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %476 = \"tfl.sub\"(%cst_19, %475) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %477 = \"tfl.strided_slice\"(%474, %cst_260, %cst_259, %cst_260) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %478 = \"tfl.sub\"(%cst_17, %477) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %479 = \"tfl.pack\"(%476, %478) {axis = 0 : i32, values_count = 2 : i32} : (tensor<i32>, tensor<i32>) -> tensor<2xi32>\r\n  %480 = \"tfl.pack\"(%cst_21, %479) {axis = 1 : i32, values_count = 2 : i32} : (tensor<2xi32>, tensor<2xi32>) -> tensor<2x2xi32>\r\n  %481 = \"tfl.pad\"(%473, %480) : (tensor<?x?xf32>, tensor<2x2xi32>) -> tensor<?x?xf32>\r\n  %482 = \"tfl.pack\"(%481) {axis = 0 : i32, values_count = 1 : i32} : (tensor<?x?xf32>) -> tensor<1x?x?xf32>\r\n  %483 = \"tfl.gather\"(%413, %426) {axis = 0 : i32} : (tensor<?xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %484 = \"tfl.gather\"(%483, %423) {axis = 0 : i32} : (tensor<?xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %485 = \"tfl.shape\"(%484) : (tensor<?xf32>) -> tensor<1xi32>\r\n  %486 = \"tfl.strided_slice\"(%485, %cst_258, %cst_260, %cst_260) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<1xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %487 = \"tfl.sub\"(%486, %cst_19) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %488 = \"tfl.greater\"(%487, %cst_32) : (tensor<i32>, tensor<i32>) -> tensor<i1>\r\n  %489 = \"tfl.select\"(%488, %cst_19, %cst_25) : (tensor<i1>, tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %490 = \"tfl.pack\"(%489) {axis = 0 : i32, values_count = 1 : i32} : (tensor<i32>) -> tensor<1xi32>\r\n  %491 = \"tfl.slice\"(%484, %cst_258, %490) : (tensor<?xf32>, tensor<1xi32>, tensor<1xi32>) -> tensor<?xf32>\r\n  %492 = \"tfl.shape\"(%491) : (tensor<?xf32>) -> tensor<1xi32>\r\n  %493 = \"tfl.strided_slice\"(%492, %cst_258, %cst_260, %cst_260) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<1xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %494 = \"tfl.sub\"(%cst_19, %493) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %495 = \"tfl.pack\"(%494) {axis = 0 : i32, values_count = 1 : i32} : (tensor<i32>) -> tensor<1xi32>\r\n  %496 = \"tfl.pack\"(%cst_258, %495) {axis = 1 : i32, values_count = 2 : i32} : (tensor<1xi32>, tensor<1xi32>) -> tensor<1x2xi32>\r\n  %497 = \"tfl.pad\"(%491, %496) : (tensor<?xf32>, tensor<1x2xi32>) -> tensor<?xf32>\r\n  %498 = \"tfl.pack\"(%497) {axis = 0 : i32, values_count = 1 : i32} : (tensor<?xf32>) -> tensor<1x?xf32>\r\n  %499 = \"tfl.add\"(%498, %cst_40) {fused_activation_function = \"NONE\"} : (tensor<1x?xf32>, tensor<f32>) -> tensor<1x?xf32>\r\n  %500 = \"tfl.gather\"(%417, %426) {axis = 0 : i32} : (tensor<?x4xf32>, tensor<?xi32>) -> tensor<?x4xf32>\r\n  %501 = \"tfl.gather\"(%500, %423) {axis = 0 : i32} : (tensor<?x4xf32>, tensor<?xi32>) -> tensor<?x4xf32>\r\n  %502 = \"tfl.shape\"(%501) : (tensor<?x4xf32>) -> tensor<2xi32>\r\n  %503 = \"tfl.strided_slice\"(%502, %cst_258, %cst_260, %cst_260) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %504 = \"tfl.sub\"(%503, %cst_19) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %505 = \"tfl.greater\"(%504, %cst_32) : (tensor<i32>, tensor<i32>) -> tensor<i1>\r\n  %506 = \"tfl.select\"(%505, %cst_19, %cst_25) : (tensor<i1>, tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %507 = \"tfl.strided_slice\"(%502, %cst_260, %cst_259, %cst_260) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %508 = \"tfl.sub\"(%507, %cst_18) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %509 = \"tfl.greater\"(%508, %cst_32) : (tensor<i32>, tensor<i32>) -> tensor<i1>\r\n  %510 = \"tfl.select\"(%509, %cst_18, %cst_25) : (tensor<i1>, tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %511 = \"tfl.pack\"(%506, %510) {axis = 0 : i32, values_count = 2 : i32} : (tensor<i32>, tensor<i32>) -> tensor<2xi32>\r\n  %512 = \"tfl.slice\"(%501, %cst_21, %511) : (tensor<?x4xf32>, tensor<2xi32>, tensor<2xi32>) -> tensor<?x?xf32>\r\n  %513 = \"tfl.shape\"(%512) : (tensor<?x?xf32>) -> tensor<2xi32>\r\n  %514 = \"tfl.strided_slice\"(%513, %cst_258, %cst_260, %cst_260) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %515 = \"tfl.sub\"(%cst_19, %514) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %516 = \"tfl.strided_slice\"(%513, %cst_260, %cst_259, %cst_260) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %517 = \"tfl.sub\"(%cst_18, %516) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %518 = \"tfl.pack\"(%515, %517) {axis = 0 : i32, values_count = 2 : i32} : (tensor<i32>, tensor<i32>) -> tensor<2xi32>\r\n  %519 = \"tfl.pack\"(%cst_21, %518) {axis = 1 : i32, values_count = 2 : i32} : (tensor<2xi32>, tensor<2xi32>) -> tensor<2x2xi32>\r\n  %520 = \"tfl.pad\"(%512, %519) : (tensor<?x?xf32>, tensor<2x2xi32>) -> tensor<?x?xf32>\r\n  %521 = \"tfl.pack\"(%520) {axis = 0 : i32, values_count = 1 : i32} : (tensor<?x?xf32>) -> tensor<1x?x?xf32>\r\n  \"std.return\"(%425, %521, %499, %186, %442, %170, %482, %460) : (tensor<1xf32>, tensor<1x?x?xf32>, tensor<1x?xf32>, tensor<1x85250x12xf32>, tensor<1x?xf32>, tensor<1x85250x4xf32>, tensor<1x?x?xf32>, tensor<1x?xf32>) -> ()\r\n}) {arg0 = {tf_saved_model.index_path = [\"input_tensor\"]}, result0 = {tf_saved_model.index_path = [\"num_detections\"]}, result1 = {tf_saved_model.index_path = [\"detection_boxes\"]}, result2 = {tf_saved_model.index_path = [\"detection_classes\"]}, result3 = {tf_saved_model.index_path = [\"raw_detection_scores\"]}, result4 = {tf_saved_model.index_path = [\"detection_scores\"]}, result5 = {tf_saved_model.index_path = [\"raw_detection_boxes\"]}, result6 = {tf_saved_model.index_path = [\"detection_multiclass_scores\"]}, result7 = {tf_saved_model.index_path = [\"detection_anchor_indices\"]}, sym_name = \"main\", tf.entry_function = {control_outputs = \"\", inputs = \"serving_default_input_tensor:0\", outputs = \"StatefulPartitionedCall:5,StatefulPartitionedCall:1,StatefulPartitionedCall:2,StatefulPartitionedCall:7,StatefulPartitionedCall:4,StatefulPartitionedCall:6,StatefulPartitionedCall:3,StatefulPartitionedCall:0\"}, tf_saved_model.exported_names = [\"serving_default\"], type = (tensor<1x?x?x3xui8>) -> (tensor<1xf32>, tensor<1x?x?xf32>, tensor<1x?xf32>, tensor<1x85250x12xf32>, tensor<1x?xf32>, tensor<1x85250x4xf32>, tensor<1x?x?xf32>, tensor<1x?xf32>)} : () -> ()\r\n\r\n\r\n(tf24_nightly) C:\\Users\\alfarok\\Desktop>\r\n```\r\n", "comments": ["@alfarok Currently, we do not support input shape overriding from TFLite Converter V2 API. If you want to use input shape overriding, you need to stick with TFLite Converter V1 API instead. For example,\r\n\r\n```\r\nconverter = tf.compat.v1.lite.TFLiteConverter.from_saved_model(\r\n        saved_model_dir, input_arrays=['inputA'], input_shapes={'inputA': [1, 640, 640, 1]})\r\n```", "@abattery I see, so if my original TensorFlow Core model expects an input shape of `(1, None, None, 3)`, the TFLite model will always return an input shape of `(1, 1, 1, 3)`.  Updating the Core model to a fixed size should fix the issue and allow me to use the V2 API?  \r\n\r\nAlso, I was under the impression that the new TFLite converter was required to convert SSD models due to improved operator support.  Is this not the case?", "I keep running into issues with either conversion method, probably because the base model which is my input layer has dynamic dimensions (1, None, None, 3).  I believe the TFLite Converter V1 API only supports dynamic values for the first dimension.  \r\nI now have been trying to wrap the model with a new fixed input layer (1, 640, 640, 3) to fix the issue.  [This reply](https://github.com/tensorflow/models/issues/8872#issuecomment-662160081) on a similar issue was helpful in setting that up.\r\n\r\nUnfortunately, I am seeing something similar to what I was seeing before with the CLI, it runs for a while then stops with no output file.  This is the last line of the output:\r\n```\r\n...\r\n%441 = \"tfl.concatenation\"(%436, %440, %438) {axis = 2 : i32, fused_activation_function = \"NONE\"} : (tensor<1x?x?xf32>, tensor<1x?x1xf32>, tensor<1x?x1xf32>) -> tensor<1x?x?xf32>\r\n  \"std.return\"(%441) : (tensor<1x?x?xf32>) -> ()\r\n}) {sym_name = \"main\", tf.entry_function = {control_outputs = \"\", inputs = \"input_1\", outputs = \"Identity\"}, type = (tensor<1x640x640x3xf32>) -> tensor<1x?x?xf32>} : () -> ()\r\n```", "@alfarok Instead of wrapping, is it possible to modify the original model to have a fixed size?", "@abattery The base model I am using is `ssd_resnet50_v1_fpn_640x640_coco17_tpu-8` from the model zoo.  I believe the input shape for this model is (1, None, None, 3).\r\n\r\n![image](https://user-images.githubusercontent.com/13341935/92043349-e777b900-ed49-11ea-96cf-8f3c6f77e3b8.png)\r\n", "Did you enable an option for select TF operators? The above conversion error seems related to operator coverage problem.\r\n\r\nhttps://www.tensorflow.org/lite/guide/ops_select", "I would rather not have to pull in the core TensorFlow runtime at all if possible as I am working with a slim size requirement.  I have a working version using efficientDet as a base instead and is much smaller.  @abattery thanks for your assistance and suggestions!"]}, {"number": 42872, "title": "ValueError: Unable to save the object (Saving a Keras.model)", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): at least 2.2.0 and 2.3.0.\r\n- Python version: 3.7.9\r\n\r\n**Describe the current behavior**\r\nModel saving crashes after `model.fit` is called:\r\n```\r\nValueError: Unable to save the object {'loss': <function f at 0x7fc4e9f5cc20>, 'pred': None, 'acc': None} (a dictionary wrapper constructed automatically on attribute assignment). The wrapped dictionary was modified outside the wrapper (its final value was {'loss': <function f at 0x7fc4e9f5cc20>, 'pred': None, 'acc': None}, its value when a checkpoint dependency was added was None), which breaks restoration on object creation.\r\n```\r\n\r\n**Describe the expected behavior**\r\nModel gets saved without crash (similar to calling `model.save` before first call of `model.fit`)\r\n\r\n**Standalone code to reproduce the issue**\r\n```[python]\r\n# TensorFlow and tf.keras\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nimport tensorflow.keras.backend as K\r\nfrom tensorflow.keras.callbacks import ModelCheckpoint\r\n\r\nprint(tf.__version__)\r\n\r\nfashion_mnist = keras.datasets.fashion_mnist\r\n\r\n\r\n# load data and create inputs\r\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\r\n\r\n\r\ndef group(img, gt):\r\n    return {'img': img}, {'gt': gt}\r\n\r\n\r\ntrain_data = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).batch(1).map(group)\r\ntest_data = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(1).map(group)\r\n\r\nactual_inputs = {'img': keras.layers.Input((28, 28), dtype='int32', name='img')}\r\nactual_targets = {'gt': keras.layers.Input(shape=(1,), dtype='int32', name='gt')}\r\n\r\n# Give access to inputs and targets to the network by joining all available data\r\n# this is required for setting up a loss that requires multiple inputs (e.g. ctc)\r\n# here we just create a cross entropy loss\r\ninputs = {**actual_inputs, **actual_targets}\r\n\r\n# create the actual model\r\nflatten_layer = keras.layers.Flatten()\r\ndense_layer = keras.layers.Dense(10)\r\nflattened = flatten_layer(K.expand_dims(K.cast(inputs['img'], dtype='float32')) / 255)\r\noutputs = {'pred': dense_layer(flattened)}\r\n\r\n# create losses and metric as 'outputs' of the network\r\nlosses = {'loss': tf.keras.layers.Lambda(lambda x: tf.keras.metrics.sparse_categorical_crossentropy(*x, from_logits=True),\r\n                                       name='loss')((inputs['gt'], outputs['pred']))}\r\nmetrics = {'acc': tf.keras.layers.Lambda(lambda x: tf.keras.metrics.sparse_categorical_crossentropy(*x), name='acc')(\r\n        (inputs['gt'], outputs['pred']))}\r\noutputs = {**outputs, **losses, **metrics}\r\n\r\n# create the model\r\nmodel = keras.Model(inputs=inputs, outputs=outputs)\r\n\r\n\r\n# compile the model but with a dummy loss that just returns the 'output' loss\r\n# the same goes for the metric\r\ndef f(t, p):\r\n    return p\r\n\r\n# compile the model\r\n# since we already comuted the loss as output, we can just forward the loss (function f)\r\nmodel.compile(optimizer='Adam', loss={k: f for k, _ in losses.items()}, metrics={k: f for k, _ in metrics.items()})\r\n\r\n\r\n# Saving the model before calling fit works\r\nmodel.save('test')\r\n\r\n\r\n# regroup adds a dummy output for every loss/metric so that they get mapped and called correctly\r\ndef regroup(inputs, outputs):\r\n    return {**inputs, **outputs}, \\\r\n           {l: [0] for l, v in {**losses, **metrics}.items()}\r\n\r\n\r\n# the model is training, but saving is not possible, e.g. in a ModelCheckpoint\r\nmodel.fit(train_data.map(regroup), validation_data=test_data.map(regroup), steps_per_epoch=1, callbacks=[ModelCheckpoint('model')])\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\nI digged a bit deeper into the code. The problem is, that `model.loss` gets changed during `model.fit` here:\r\n(line 64: `struct = map_missing_dict_keys(outputs, struct)`)\r\n\r\nStacktrace\r\n```\r\n_conform_to_outputs, compile_utils.py:64\r\nbuild, compile_utils.py:139\r\n__call__, compile_utils.py:187\r\ntrain_step, training.py:749\r\nrun_step, training.py:789\r\nwrapper, api.py:275\r\n_call_for_each_replica, distribute_lib.py:2945\r\ncall_for_each_replica, distribute_lib.py:2585\r\nrun, distribute_lib.py:1211\r\nstep_function, training.py:796\r\ntrain_function, training.py:806\r\nfit, training.py:1098\r\n```\r\n\r\n`struct` is the same dict as `model.loss`, `map_to_output_names` returns the identical object (no copy), `map_missing_dict_keys` changes `struct` and thus `model.loss`. If I manually create a copy of `struct` saving works flawlessly (possible fix)\r\n\r\n", "comments": ["I am able to replicate the issue reported, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/9349b1138c40303cd941077f740635c3/untitled405.ipynb)", "The commit that @ChWick has listed here fixes this issue for me. Can we get this pulled in?", "As a workaround, I added the following callback (first callback in list):\r\n```python\r\nimport tensorflow.keras.callbacks as cb\r\n\r\n\r\n# See https://github.com/tensorflow/tensorflow/issues/42872\r\nclass TensorflowFix(cb.Callback):\r\n    def __init__(self):\r\n        super(TensorflowFix, self).__init__()\r\n        self._supports_tf_logs = True\r\n        self._backup_loss = None\r\n\r\n    def on_train_begin(self, logs=None):\r\n        self._backup_loss = {**self.model.loss}\r\n\r\n    def on_train_batch_end(self, batch, logs=None):\r\n        self.model.loss = self._backup_loss\r\n```\r\n\r\nHacky, but works...", "Has there been any update on this? We've been able to get it to work with the workaround above adapted to the `save` step, but even as of 2.4.1 we're still hitting this issue. \r\n\r\nHere's a simple gist reproducing the issue: [code](https://gist.github.com/zachary-jablons-okcupid/b81629945bd930c1a6507633df40088f), [output](https://gist.github.com/zachary-jablons-okcupid/843cfbaa888bb20385fdbae00571e019) in TF 2.1 (works fine) and [output](https://gist.github.com/560df2201b5a3b1fe6c03989c60b9b08) in TF 2.4 (fails at the `save` step). \r\n\r\nThis is a common usecase for us and while the workarounds work, we'd prefer not to need them.", "I'm able to run your code successfully and the model is getting saved in Tf Nightly 2.6 version, please find the gist [here](https://colab.research.google.com/gist/sachinprasadhs/891b835fb809b5151f2adc3fc467480d/42872.ipynb). Thanks!", "Closing this issue since the error is resolved in Tf Nightly version, feel free to reopen. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42872\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42872\">No</a>\n"]}, {"number": 42871, "title": "Add ImageProjectiveTransform XLA kernel", "body": "As per comment https://github.com/tensorflow/tensorflow/pull/41365#issuecomment-658818273, cc @tanzhenyu for visibility.", "comments": ["@tanzhenyu I think we need an XLA expert to review this. Can you find one? Also, I find the speed does not improve (or even slower) for XLA ops. So maybe there might be some improvement for my handcrafted kernel. Another thought is that, we can probably turn this op into pure Python. I can do further performance profile if you think this is a choice. Thank you!", "From XLA discussion: seems this is not desired given the gathering logic would be expensive.", "@WindQAQ  Can you please check @tanzhenyu's comments and keep us posted ? Thanks!", "@tanzhenyu Do I have to do something specific on the implementation? Thank you!", "> @tanzhenyu Do I have to do something specific on the implementation? Thank you!\r\n\r\nWe can close this if you don't mind. The main reason is that gather takes too much cycles.", "Yep, sure. As it doesn't improve the performance, let me close it."]}, {"number": 42870, "title": "[INTEL MKL] Remove nGraph build support", "body": "This PR removes now-deprecated direct integration of nGraph in TensorFlow. nGraph integration is still available via the external ngraph-bridge at:\r\nhttps://github.com/tensorflow/ngraph-bridge/\r\n\r\nor via `pip install ngraph-tensorflow-bridge`.\r\n\r\nSigned-off-by: Abhishek Kulkarni <abhishek.kulkarni@intel.com>", "comments": ["@adk9  Can you please resolve conflicts? Thanks!", "Just for future reference, would you mind posting the error log that says `nlohmann_json_lib dep` is  needed by `google-cloud-cpp` (in d2a19ace23da5732796886b3f9020eae199cfb1)? Thank you very much! ", "@adk9 can you please check ubuntu sanity failures ?", "> @adk9 can you please check ubuntu sanity failures ?\r\n\r\nSorry about that! I pushed a fix to address the CI sanity failures.\r\n\r\n> Just for future reference, would you mind posting the error log that says nlohmann_json_lib dep is needed by google-cloud-cpp (in d2a19ac)? Thank you very much!\r\n\r\nI noticed that google-cloud-cpp was bumped to 1.17.1 (0a5e847646) after I opened this PR, and it seems to have a dependency now on `nlohmann_json_lib` which was originally an nGraph dependency. I hoisted it out preemptively but didn't actually run into any errors or have an error log handy.", "@adk9  Can you please resolve conflicts? Thanks!", "@adk9 Can you please resolve conflicts? Thanks!", "@adk9 Can you please resolve conflicts? Thanks!", "@adk9 So sorry for the inconvenience. We have had problems with our automatic code import for this PR. After the merge conflicts are resolved, I'll try to pull this PR in manually this time.", "> @adk9 So sorry for the inconvenience. We have had problems with our automatic code import for this PR. After the merge conflicts are resolved, I'll try to pull this PR in manually this time.\r\n\r\nNo worries, I've fixed the conflicts. \ud83d\udc4d "]}, {"number": 42869, "title": "Tensorflow warmup dataset is not used by tensorflow serving", "body": "We have 2 models in production in dockers with tensorflow serving. We have generated a warmup dataset for one of the models. Here are the docker logs:\r\n\r\n```\r\ntensorflow_serving/servables/tensorflow/saved_model_warmup.cc:117] Starting to read warmup data for model at /models/model2/5/assets.extra/tf_serving_warmup_requests with model-warmup-options\r\n\r\n2020-08-12 02:27:51.998915: I tensorflow_serving/servables/tensorflow/saved_model_warmup.cc:166] Finished reading warmup data for model at /models/model2/5/assets.extra/tf_serving_warmup_requests. Number of warmup records read: 1000. Elapsed time (microseconds): 1293140.\r\n\r\n2020-08-12 02:27:52.003127: I tensorflow_serving/core/loader_harness.cc:87] Successfully loaded servable version {name: model2 version: 5}\r\n\r\n2020-08-12 02:27:52.005692: I tensorflow_serving/model_servers/server_core.cc:462] Adding/updating models.\r\n\r\n2020-08-12 02:27:52.005711: I tensorflow_serving/model_servers/server_core.cc:573] (Re-)adding model: model1\r\n\r\n2020-08-12 02:27:52.005734: I tensorflow_serving/model_servers/server_core.cc:573] (Re-)adding model: model2\r\n\r\n2020-08-12 02:27:52.008151: I tensorflow_serving/model_servers/server.cc:353] Running gRPC ModelServer at 0.0.0.0:8500 ...\r\n\r\n[warn] getaddrinfo: address family for nodename not supported\r\n\r\n2020-08-12 02:27:52.012942: I tensorflow_serving/model_servers/server.cc:373] Exporting HTTP/REST API at:localhost:8501 ...\r\n\r\n[evhttp_server.cc : 238] NET_LOG: Entering the event loop ...\r\n```\r\n\r\nHowever, when I look in prometheus logs (http://localhost:8501/monitoring/prometheus/metrics) I see the following:\r\n\r\n```\r\n# TYPE :tensorflow:serving:model_warmup_latency histogram\r\n:tensorflow:serving:model_warmup_latency_bucket{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\",le=\"10\"} 0\r\n:tensorflow:serving:model_warmup_latency_bucket{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\",le=\"18\"} 0\r\n:tensorflow:serving:model_warmup_latency_bucket{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\",le=\"32.4\"} 0\r\n:tensorflow:serving:model_warmup_latency_bucket{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\",le=\"58.32\"} 0\r\n:tensorflow:serving:model_warmup_latency_bucket{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\",le=\"104.976\"} 0\r\n:tensorflow:serving:model_warmup_latency_bucket{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\",le=\"188.957\"} 0\r\n:tensorflow:serving:model_warmup_latency_bucket{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\",le=\"340.122\"} 0\r\n:tensorflow:serving:model_warmup_latency_bucket{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\",le=\"612.22\"} 0\r\n:tensorflow:serving:model_warmup_latency_bucket{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\",le=\"1102\"} 0\r\n:tensorflow:serving:model_warmup_latency_bucket{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\",le=\"1983.59\"} 0\r\n:tensorflow:serving:model_warmup_latency_bucket{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\",le=\"3570.47\"} 0\r\n:tensorflow:serving:model_warmup_latency_bucket{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\",le=\"6426.84\"} 0\r\n:tensorflow:serving:model_warmup_latency_bucket{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\",le=\"11568.3\"} 0\r\n:tensorflow:serving:model_warmup_latency_bucket{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\",le=\"20823\"} 0\r\n:tensorflow:serving:model_warmup_latency_bucket{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\",le=\"37481.3\"} 0\r\n:tensorflow:serving:model_warmup_latency_bucket{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\",le=\"67466.4\"} 0\r\n:tensorflow:serving:model_warmup_latency_bucket{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\",le=\"121440\"} 0\r\n:tensorflow:serving:model_warmup_latency_bucket{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\",le=\"218591\"} 0\r\n:tensorflow:serving:model_warmup_latency_bucket{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\",le=\"393464\"} 0\r\n:tensorflow:serving:model_warmup_latency_bucket{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\",le=\"708235\"} 0\r\n:tensorflow:serving:model_warmup_latency_bucket{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\",le=\"1.27482e+06\"} 0\r\n:tensorflow:serving:model_warmup_latency_bucket{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\",le=\"2.29468e+06\"} 1\r\n:tensorflow:serving:model_warmup_latency_bucket{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\",le=\"4.13043e+06\"} 1\r\n:tensorflow:serving:model_warmup_latency_bucket{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\",le=\"7.43477e+06\"} 1\r\n:tensorflow:serving:model_warmup_latency_bucket{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\",le=\"1.33826e+07\"} 1\r\n:tensorflow:serving:model_warmup_latency_bucket{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\",le=\"2.40887e+07\"} 1\r\n:tensorflow:serving:model_warmup_latency_bucket{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\",le=\"4.33596e+07\"} 1\r\n:tensorflow:serving:model_warmup_latency_bucket{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\",le=\"7.80473e+07\"} 1\r\n:tensorflow:serving:model_warmup_latency_bucket{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\",le=\"1.40485e+08\"} 1\r\n:tensorflow:serving:model_warmup_latency_bucket{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\",le=\"2.52873e+08\"} 1\r\n:tensorflow:serving:model_warmup_latency_bucket{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\",le=\"4.55172e+08\"} 1\r\n:tensorflow:serving:model_warmup_latency_bucket{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\",le=\"8.19309e+08\"} 1\r\n:tensorflow:serving:model_warmup_latency_bucket{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\",le=\"1.47476e+09\"} 1\r\n:tensorflow:serving:model_warmup_latency_bucket{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\",le=\"+Inf\"} 1\r\n:tensorflow:serving:model_warmup_latency_sum{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\"} 1.29314e+06\r\n:tensorflow:serving:model_warmup_latency_count{model_path=\"/models/model2/5\",status=\"Out of range: Read less bytes than requested\"} 1\r\n```\r\n\r\nThe question is: can I conclude that the warmup dataset was successfully consumed by tensorflow-serving? It does not seem so if I understand the Prometheus logs correctly.\r\n\r\nThank you!\r\n\r\n\r\n**System information**\r\n- Windows 10 (1909)\r\n- Docker desktop: 2.3.0.4\r\n- TensorFlow installed from binary\r\n- TensorFlow version: v2.2.0-rc4-8-g2b96f3662b 2.2.0\r\n- Tensorflow serving: tensorflow/serving:2.2.0\r\n- Python version: 3.7.7\r\n- CUDA/cuDNN version: Cuda compilation tools, release 10.1, V10.1.105", "comments": ["https://stackoverflow.com/questions/63411261/how-to-ensure-that-tensorflow-warmup-dataset-for-successfully-consumed-by-tensor", "@evodopyanov \r\n\r\nCan you please go through the[ link1](https://stackoverflow.com/questions/63411261/how-to-ensure-that-tensorflow-warmup-dataset-for-successfully-consumed-by-tensor), [link2](https://www.tensorflow.org/tfx/serving/saved_model_warmup) and see if it helps you. Thanks!", "> @evodopyanov\r\n> \r\n> Can you please go through the[ link1](https://stackoverflow.com/questions/63411261/how-to-ensure-that-tensorflow-warmup-dataset-for-successfully-consumed-by-tensor), [link2](https://www.tensorflow.org/tfx/serving/saved_model_warmup) and see if it helps you. Thanks!\r\n\r\nThank you for your answer @ravikyram.\r\n\r\nThe first link is my own post on stackoverflow (no answers yet).\r\nThe second link is a TF doc that I have already followed to create this warmup dataset.", "@evodopyanov \r\n\r\nThis issue is more suitable for TensorFlow Serving repo. Please post it on Serving repo from [here.](https://github.com/tensorflow/serving/issues) Thanks!", "> @evodopyanov\r\n> \r\n> This issue is more suitable for TensorFlow Serving repo. Please post it on Serving repo from [here.](https://github.com/tensorflow/serving/issues) Thanks!\r\n\r\n[Done](https://github.com/tensorflow/serving/issues/1728)\r\n\r\nThanks!", "@evodopyanov \r\n\r\nCan we track the issue in Tensorflow Serving repo and close here. Thanks!"]}, {"number": 42868, "title": "Delete ADOPTERS.md", "body": "", "comments": []}, {"number": 42867, "title": "Converting keras (`.h5`) models to `.tflite` fails with error `Windows fatal exception: access violation`", "body": "**System information**\r\n- OS Platform and Distribution: Windows 10, Version 1909\r\n- TensorFlow installed from: binary\r\n- TensorFlow version (or github SHA if from source): 2.2.0\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\n\r\nBasically I just modified the example from https://www.tensorflow.org/lite/convert/python_api#converting_a_keras_model_.\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\n# Load the model.\r\nmodel = tf.keras.models.load_model(\"model.h5\")\r\n\r\n# Convert the model.\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\ntflite_model = converter.convert()\r\n\r\n# Save the TF Lite model.\r\nwith tf.io.gfile.GFile('model.tflite', 'wb') as f:\r\n  f.write(tflite_model)\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\n2020-09-01 17:24:41.539597: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-09-01 17:24:43.716706: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n2020-09-01 17:24:44.420857: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce GTX 860M computeCapability: 5.0\r\ncoreClock: 1.0195GHz coreCount: 5 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 74.65GiB/s\r\n2020-09-01 17:24:44.427385: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-09-01 17:24:44.433460: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-09-01 17:24:44.444426: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-09-01 17:24:44.448774: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-09-01 17:24:44.463120: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-09-01 17:24:44.468504: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2020-09-01 17:24:44.482707: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-09-01 17:24:44.486066: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n2020-09-01 17:24:44.489318: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2020-09-01 17:24:44.502237: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x19f102e43f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-09-01 17:24:44.507055: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-09-01 17:24:44.509839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce GTX 860M computeCapability: 5.0\r\ncoreClock: 1.0195GHz coreCount: 5 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 74.65GiB/s\r\n2020-09-01 17:24:44.514421: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-09-01 17:24:44.517064: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-09-01 17:24:44.519967: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-09-01 17:24:44.524530: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-09-01 17:24:44.528097: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-09-01 17:24:44.530805: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2020-09-01 17:24:44.532843: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-09-01 17:24:44.535760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n2020-09-01 17:24:45.755590: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-09-01 17:24:45.758598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0\r\n2020-09-01 17:24:45.760523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N\r\n2020-09-01 17:24:45.762401: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1368 MB memory) -> physical GPU (device: 0, name: GeForce GTX 860M, pci bus id: 0000:01:00.0, compute capability: 5.0)\r\n2020-09-01 17:24:45.771301: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x19f2c581570 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-09-01 17:24:45.775896: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 860M, Compute Capability 5.0\r\n2020-09-01 17:24:46.935305: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\r\n2020-09-01 17:24:46.939007: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2020-09-01 17:24:46.942082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce GTX 860M computeCapability: 5.0\r\ncoreClock: 1.0195GHz coreCount: 5 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 74.65GiB/s\r\n2020-09-01 17:24:46.945811: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-09-01 17:24:46.947792: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-09-01 17:24:46.950626: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-09-01 17:24:46.953424: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-09-01 17:24:46.955355: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-09-01 17:24:46.958176: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2020-09-01 17:24:46.961427: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-09-01 17:24:46.963952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n2020-09-01 17:24:46.965588: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-09-01 17:24:46.967750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0\r\n2020-09-01 17:24:46.968919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N\r\n2020-09-01 17:24:46.970130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1368 MB memory) -> physical GPU (device: 0, name: GeForce GTX 860M, pci bus id: 0000:01:00.0, compute capability: 5.0)\r\n2020-09-01 17:24:47.005582: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize\r\n2020-09-01 17:24:47.009765: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0.003ms.\r\n2020-09-01 17:24:47.013518: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   function_optimizer: function_optimizer did nothing. time = 0ms.\r\n2020-09-01 17:24:48.527683: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\r\n2020-09-01 17:24:48.531120: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2020-09-01 17:24:48.533535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce GTX 860M computeCapability: 5.0\r\ncoreClock: 1.0195GHz coreCount: 5 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 74.65GiB/s\r\n2020-09-01 17:24:48.537018: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-09-01 17:24:48.538710: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-09-01 17:24:48.540380: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-09-01 17:24:48.543054: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-09-01 17:24:48.546077: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-09-01 17:24:48.549536: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2020-09-01 17:24:48.552508: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-09-01 17:24:48.554275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n2020-09-01 17:24:48.556311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-09-01 17:24:48.559038: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0\r\n2020-09-01 17:24:48.561108: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N\r\n2020-09-01 17:24:48.562745: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1368 MB memory) -> physical GPU (device: 0, name: GeForce GTX 860M, pci bus id: 0000:01:00.0, compute capability: 5.0)\r\n2020-09-01 17:24:49.508141: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:797] Optimization results for grappler item: graph_to_optimize\r\n2020-09-01 17:24:49.511726: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 135 nodes (-70), 166 edges (-71), time = 496.187ms.\r\n2020-09-01 17:24:49.513808: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:799]   constant_folding: Graph size after: 135 nodes (0), 166 edges (0), time = 142.545ms.\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 16, in <module>\r\n    tflite_model = converter.convert()\r\n  File \"C:\\Users\\chrismit3s\\projects\\lemon-finder\\nn\\venv\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\", line 514, in convert\r\n    result = _toco_convert_impl(\r\n  File \"C:\\Users\\chrismit3s\\projects\\lemon-finder\\nn\\venv\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\", line 491, in toco_convert_impl\r\n    data = toco_convert_protos(\r\n  File \"C:\\Users\\chrismit3s\\projects\\lemon-finder\\nn\\venv\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py\", line 227, in toco_convert_protos\r\n    raise ConverterError(\"See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\ntensorflow.lite.python.convert.ConverterError: See console for info.\r\n2020-09-01 17:25:45.917994: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-09-01 17:25:48.444793: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:144] Ignored output_format.\r\n2020-09-01 17:25:48.444956: W tensorflow/compiler/mlir/lite/python/graphdef_to_tfl_flatbuffer.cc:147] Ignored drop_control_dependency.\r\n2020-09-01 17:25:48.612894: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2020-09-01 17:25:48.620668: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x24e9af13c60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-09-01 17:25:48.620946: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-09-01 17:25:48.621845: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library nvcuda.dll\r\n2020-09-01 17:25:48.985335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:\r\npciBusID: 0000:01:00.0 name: GeForce GTX 860M computeCapability: 5.0\r\ncoreClock: 1.0195GHz coreCount: 5 deviceMemorySize: 2.00GiB deviceMemoryBandwidth: 74.65GiB/s\r\n2020-09-01 17:25:48.985688: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudart64_101.dll\r\n2020-09-01 17:25:48.988892: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cublas64_10.dll\r\n2020-09-01 17:25:48.991552: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cufft64_10.dll\r\n2020-09-01 17:25:48.992478: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library curand64_10.dll\r\n2020-09-01 17:25:48.997442: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusolver64_10.dll\r\n2020-09-01 17:25:48.999418: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cusparse64_10.dll\r\n2020-09-01 17:25:49.005007: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library cudnn64_7.dll\r\n2020-09-01 17:25:49.005431: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0\r\n2020-09-01 17:25:50.289313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-09-01 17:25:50.289550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0\r\n2020-09-01 17:25:50.289627: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N\r\n2020-09-01 17:25:50.289970: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1354 MB memory) -> physical GPU (device: 0, name: GeForce GTX 860M, pci bus id: 0000:01:00.0, compute capability: 5.0)\r\n2020-09-01 17:25:50.293330: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x24ec910a3e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n2020-09-01 17:25:50.293537: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 860M, Compute Capability 5.0\r\nloc(callsite(\"sequential/batch_normalization_1/FusedBatchNormV3\"(\"C:\\Users\\chrismit3s\\projects\\lemon-finder\\nn\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\":865:0) at callsite(\"C:\\Users\\chrismit3s\\projects\\lemon-finder\\nn\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\":959:0 at callsite(\"C:\\Users\\chrismit3s\\projects\\lemon-finder\\nn\\venv\\lib\\site-packages\\tensorflow\\lite\\python\\lite.py\":435:0 at \"test.py\":15:0)))): error: non-broadcastable operands\r\nWindows fatal exception: access violation\r\n\r\nCurrent thread 0x000036e4 (most recent call first):\r\n  File \"c:\\users\\chrismit3s\\projects\\lemon-finder\\nn\\venv\\lib\\site-packages\\tensorflow\\lite\\toco\\python\\toco_from_protos.py\", line 50 in execute\r\n  File \"c:\\users\\chrismit3s\\projects\\lemon-finder\\nn\\venv\\lib\\site-packages\\absl\\app.py\", line 251 in _run_main\r\n  File \"c:\\users\\chrismit3s\\projects\\lemon-finder\\nn\\venv\\lib\\site-packages\\absl\\app.py\", line 300 in run\r\n  File \"c:\\users\\chrismit3s\\projects\\lemon-finder\\nn\\venv\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 40 in run\r\n  File \"c:\\users\\chrismit3s\\projects\\lemon-finder\\nn\\venv\\lib\\site-packages\\tensorflow\\lite\\toco\\python\\toco_from_protos.py\", line 93 in main\r\n  File \"C:\\Users\\chrismit3s\\projects\\lemon-finder\\nn\\venv\\Scripts\\toco_from_protos.exe\\__main__.py\", line 7 in <module>\r\n  File \"C:\\Python38\\lib\\runpy.py\", line 86 in _run_code\r\n  File \"C:\\Python38\\lib\\runpy.py\", line 193 in _run_module_as_main\r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n\r\nhttps://drive.google.com/file/d/17V3oYDLKiAB_N13kNJZIk4ukcwyP44Yp/view?usp=sharing\r\n\r\n_Model definition:_\r\n\r\n```\r\nm = Sequential()\r\n\r\nm.add(Input(shape=(100, 100, 3)))\r\nm.add(GaussianNoise(stddev=0.06))\r\n\r\nm.add(Conv2D(filters=64, kernel_size=(5, 5), padding=\"valid\", data_format=\"channels_last\", activation=\"swish\"))\r\nm.add(Conv2D(filters=64, kernel_size=(5, 5), padding=\"valid\", data_format=\"channels_last\", activation=\"swish\"))\r\nm.add(Conv2D(filters=64, kernel_size=(5, 5), padding=\"valid\", data_format=\"channels_last\", activation=\"swish\"))\r\nm.add(Conv2D(filters=64, kernel_size=(5, 5), padding=\"valid\", data_format=\"channels_last\", strides=(2, 2)))\r\nm.add(GaussianNoise(stddev=0.02))\r\nm.add(BatchNormalization(axis=3))\r\nm.add(Activation(activation=\"swish\"))\r\n\r\nm.add(Conv2D(filters=256, kernel_size=(5, 5), padding=\"valid\", data_format=\"channels_last\", activation=\"swish\"))\r\nm.add(Conv2D(filters=256, kernel_size=(5, 5), padding=\"valid\", data_format=\"channels_last\", activation=\"swish\"))\r\nm.add(Conv2D(filters=256, kernel_size=(5, 5), padding=\"valid\", data_format=\"channels_last\", activation=\"swish\"))\r\nm.add(Conv2D(filters=256, kernel_size=(5, 5), padding=\"valid\", data_format=\"channels_last\", strides=(2, 2)))\r\nm.add(GaussianNoise(stddev=0.02))\r\nm.add(BatchNormalization(axis=3))\r\nm.add(Activation(activation=\"swish\"))\r\n\r\nm.add(Flatten())\r\n\r\nm.add(Dense(units=256, activation=\"swish\"))\r\nm.add(Dense(units=256, activation=\"swish\"))\r\nm.add(Dense(units=256, activation=\"swish\"))\r\nm.add(Dense(units=256))\r\nm.add(GaussianNoise(stddev=0.02))\r\nm.add(BatchNormalization(axis=3))\r\nm.add(Activation(activation=\"swish\"))\r\n\r\nm.add(Dense(units=64, activation=\"swish\"))\r\nm.add(Dense(units=64, activation=\"swish\"))\r\nm.add(Dense(units=64, activation=\"swish\"))\r\nm.add(Dense(units=64, activation=\"swish\"))\r\n\r\nm.add(Dense(units=4, activation=\"softmax\"))\r\n\r\nm.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\r\n```\r\n\r\nEDIT:\r\n\r\nRunning the same model through the `tflite_convert` script fails in a similar manner. With the `--experimental_new_converter=False` it still fails, just with a different error ([output](https://pastebin.com/SZ4N7zg4)).", "comments": ["Can you share your model definition? Thanks", "Oh, yeah sure:\r\n\r\n```\r\nm = Sequential()\r\n\r\nm.add(Input(shape=(100, 100, 3)))\r\nm.add(GaussianNoise(stddev=0.06))\r\n\r\nm.add(Conv2D(filters=64, kernel_size=(5, 5), padding=\"valid\", data_format=\"channels_last\", activation=\"swish\"))\r\nm.add(Conv2D(filters=64, kernel_size=(5, 5), padding=\"valid\", data_format=\"channels_last\", activation=\"swish\"))\r\nm.add(Conv2D(filters=64, kernel_size=(5, 5), padding=\"valid\", data_format=\"channels_last\", activation=\"swish\"))\r\nm.add(Conv2D(filters=64, kernel_size=(5, 5), padding=\"valid\", data_format=\"channels_last\", strides=(2, 2)))\r\nm.add(GaussianNoise(stddev=0.02))\r\nm.add(BatchNormalization(axis=3))\r\nm.add(Activation(activation=\"swish\"))\r\n\r\nm.add(Conv2D(filters=256, kernel_size=(5, 5), padding=\"valid\", data_format=\"channels_last\", activation=\"swish\"))\r\nm.add(Conv2D(filters=256, kernel_size=(5, 5), padding=\"valid\", data_format=\"channels_last\", activation=\"swish\"))\r\nm.add(Conv2D(filters=256, kernel_size=(5, 5), padding=\"valid\", data_format=\"channels_last\", activation=\"swish\"))\r\nm.add(Conv2D(filters=256, kernel_size=(5, 5), padding=\"valid\", data_format=\"channels_last\", strides=(2, 2)))\r\nm.add(GaussianNoise(stddev=0.02))\r\nm.add(BatchNormalization(axis=3))\r\nm.add(Activation(activation=\"swish\"))\r\n\r\nm.add(Flatten())\r\n\r\nm.add(Dense(units=256, activation=\"swish\"))\r\nm.add(Dense(units=256, activation=\"swish\"))\r\nm.add(Dense(units=256, activation=\"swish\"))\r\nm.add(Dense(units=256))\r\nm.add(GaussianNoise(stddev=0.02))\r\nm.add(BatchNormalization(axis=3))\r\nm.add(Activation(activation=\"swish\"))\r\n\r\nm.add(Dense(units=64, activation=\"swish\"))\r\nm.add(Dense(units=64, activation=\"swish\"))\r\nm.add(Dense(units=64, activation=\"swish\"))\r\nm.add(Dense(units=64, activation=\"swish\"))\r\n\r\nm.add(Dense(units=4, activation=\"softmax\"))\r\n\r\nm.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\r\n```", "What is your `input_shape`?", "Dammit, I knew I missed something... It's `(100, 100, 3)`", "Sure about `BatchNormalization(axis=3)`? Can you compile it?", "Double check your `BatchNormalization` axis cause this seems it is working.\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.layers import (\r\n    Conv2D,\r\n    GaussianNoise,\r\n    Activation,\r\n    BatchNormalization,\r\n    Input,\r\n    Dense,\r\n    Flatten\r\n)\r\n\r\n# Load the model.\r\n# Convert the model.\r\nm = tf.keras.models.Sequential()\r\n\r\nm.add(Input(shape=(100, 100, 3)))\r\nm.add(GaussianNoise(stddev=0.06))\r\n\r\nm.add(Conv2D(filters=64, kernel_size=(5, 5), padding=\"valid\", data_format=\"channels_last\", activation=\"swish\"))\r\nm.add(Conv2D(filters=64, kernel_size=(5, 5), padding=\"valid\", data_format=\"channels_last\", activation=\"swish\"))\r\nm.add(Conv2D(filters=64, kernel_size=(5, 5), padding=\"valid\", data_format=\"channels_last\", activation=\"swish\"))\r\nm.add(Conv2D(filters=64, kernel_size=(5, 5), padding=\"valid\", data_format=\"channels_last\", strides=(2, 2)))\r\nm.add(GaussianNoise(stddev=0.02))\r\nm.add(BatchNormalization())\r\nm.add(Activation(activation=\"swish\"))\r\n\r\nm.add(Conv2D(filters=256, kernel_size=(5, 5), padding=\"valid\", data_format=\"channels_last\", activation=\"swish\"))\r\nm.add(Conv2D(filters=256, kernel_size=(5, 5), padding=\"valid\", data_format=\"channels_last\", activation=\"swish\"))\r\nm.add(Conv2D(filters=256, kernel_size=(5, 5), padding=\"valid\", data_format=\"channels_last\", activation=\"swish\"))\r\nm.add(Conv2D(filters=256, kernel_size=(5, 5), padding=\"valid\", data_format=\"channels_last\", strides=(2, 2)))\r\nm.add(GaussianNoise(stddev=0.02))\r\nm.add(BatchNormalization())\r\nm.add(Activation(activation=\"swish\"))\r\n\r\nm.add(Flatten())\r\n\r\nm.add(Dense(units=256, activation=\"swish\"))\r\nm.add(Dense(units=256, activation=\"swish\"))\r\nm.add(Dense(units=256, activation=\"swish\"))\r\nm.add(Dense(units=256))\r\nm.add(GaussianNoise(stddev=0.02))\r\nm.add(BatchNormalization())\r\nm.add(Activation(activation=\"swish\"))\r\n\r\nm.add(Dense(units=64, activation=\"swish\"))\r\nm.add(Dense(units=64, activation=\"swish\"))\r\nm.add(Dense(units=64, activation=\"swish\"))\r\nm.add(Dense(units=64, activation=\"swish\"))\r\n\r\nm.add(Dense(units=4, activation=\"softmax\"))\r\n\r\nm.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\r\nm.save(\"/tmp/model.h5\")\r\nrecovered_model = tf.keras.models.load_model(\"/tmp/model.h5\")\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(recovered_model)\r\n\r\ntflite_model = converter.convert()\r\n\r\n# Save the TF Lite model.\r\nwith tf.io.gfile.GFile(\"/tmp/model.tflite\", \"wb\") as f:\r\n    f.write(tflite_model)\r\n```", "Yep, you were right, I got the axis wrong :) keras' docs are not too thorough on what the `axis` param acutally does, but [this](https://stackoverflow.com/q/47538391) stackoverflow post explains it pretty well.\r\n\r\nBut what's weird is I could _train_ the model [and got decent(-ish) results], so why does fail only now, when I try to convert it to tflite?\r\n\r\nThank you so much by the way, super quick and helpful responses :)\r\n\r\nEdit: Okay, so I tried to save it again, this time using `axis=1` and it fails again, so I guess tflite just can't handle any other axis except the default (`axis=-1`)... With `axis=0` or `2` tf can't actually build the model, but that makes kinda sense I guess...", "@chrismit3s Track the `axis` paramter in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/normalization.py#L162. At the end in `call` you can see that the underline call is `nn.batch_normalization` that don't consume the index.\r\nSo I think it is still interesting your `axis=1` case cause it is better that converter doesn't get a segmentation fault.\r\n\r\n@amahendrakar Can you mention a TFlite maintainer?", "@ymodak,\r\nCould you please take a look? Thanks!"]}, {"number": 42866, "title": "Converting keras (.h) models to `.tflite` fails with error `Windows fatal exception: access violation`", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (or github SHA if from source):\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\n# Copy and paste here the exact command\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\n# Copy and paste the output here.\r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n\r\n```\r\n# Put link here or attach to the issue.\r\n```\r\n\r\n**Failure details**\r\nIf the conversion is successful, but the generated model is wrong,\r\nstate what is wrong:\r\n- Producing wrong results and/or decrease in accuracy\r\n- Producing correct results, but the model is slower than expected (model generated from old converter)\r\n\r\n\r\n**RNN conversion support**\r\nIf converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["shit, hit enter too early.. butterfingers :)"]}, {"number": 42865, "title": "Unable to convert h5model file to tflite file", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): win 10\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (or github SHA if from source): 2.2.0\r\n\r\n# Put link here or attach to the issue.\r\n\r\nhttps://gist.github.com/SaiBalaji22/e3815c47970416c37328e9f69a43c958\r\n\r\n**Failure details**\r\n\r\nI have made a rps classifier using tensor flow python.The problem is i was able to convert it to h5 file.But while converting to tflite file it takes long time.So if I interrupt and restart the kernel it still gives me  error.\r\n\r\n**Any other info / logs**\r\n\r\n`UnavailableError                          Traceback (most recent call last)\r\n<ipython-input-6-217c00d782f4> in <module>\r\n      1 model = tf.keras.models.load_model('RPSKeras22.h5')\r\n      2 converter = tf.lite.TFLiteConverter.from_keras_model(model)\r\n----> 3 tflite_models = converter.convert()\r\n      4 open(\"RPS22.tflite\", \"wb\").write(tflite_model)\r\n\r\n~\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\lite\\python\\lite.py in convert(self)\r\n    421 \r\n    422     frozen_func = _convert_to_constants.convert_variables_to_constants_v2(\r\n--> 423         self._funcs[0], lower_control_flow=False)\r\n    424     input_tensors = [\r\n    425         tensor for tensor in frozen_func.inputs\r\n\r\n~\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\python\\framework\\convert_to_constants.py in convert_variables_to_constants_v2(func, lower_control_flow)\r\n    426   \"\"\"\r\n    427   # Inline the graph in order to remove functions when possible.\r\n--> 428   graph_def = _run_inline_graph_optimization(func, lower_control_flow)\r\n    429 \r\n    430   # Gets list of all node defs include those in the library.\r\n\r\n~\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\python\\framework\\convert_to_constants.py in _run_inline_graph_optimization(func, lower_control_flow)\r\n    125   rewrite_options.min_graph_nodes = -1  # do not skip small graphs\r\n    126   rewrite_options.optimizers.append(\"function\")\r\n--> 127   return tf_optimizer.OptimizeGraph(config, meta_graph)\r\n    128 \r\n    129 \r\n\r\n~\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\python\\grappler\\tf_optimizer.py in OptimizeGraph(config_proto, metagraph, verbose, graph_id, cluster, strip_default_attributes)\r\n     52                     type(config_proto))\r\n     53   if cluster is None:\r\n---> 54     cluster = gcluster.Cluster()\r\n     55   ret_from_swig = tf_opt.TF_OptimizeGraph(cluster.tf_cluster,\r\n     56                                           config_proto.SerializeToString(),\r\n\r\n~\\.conda\\envs\\tensorflow_env\\lib\\site-packages\\tensorflow_core\\python\\grappler\\cluster.py in __init__(self, allow_soft_placement, disable_detailed_stats, disable_timeline, devices)\r\n     52     if devices is None:\r\n     53       self._tf_cluster = tf_cluster.TF_NewCluster(allow_soft_placement,\r\n---> 54                                                   disable_detailed_stats)\r\n     55     else:\r\n     56       devices_serialized = [device.SerializeToString() for device in devices]\r\n\r\nUnavailableError: Can't provision more than one single cluster at a time`\r\n", "comments": ["@SaiBalaji22 \r\n\r\nCan you add the below  lines of code before converting and see if the issue still persists.\r\n```\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.experimental_new_converter=True\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS,\r\n                                       tf.lite.OpsSet.SELECT_TF_OPS]\r\n```\r\nYou can refer similar issues #42857,,#35615, #35590 and see if it helps you. Thanks!\r\n", "I resolved it by reducing the number of neurons in last convolutional layer.Is this problem related to GPU.My machine has no seperate GPU", "@SaiBalaji22 \r\n\r\nGlad to know the issue was resolved. Please, close this thread as your issue was resolved. Thanks!"]}, {"number": 42864, "title": "Inference only works if using same batch size as in training", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.14.6\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 2.3.0\r\n- Python version: 3.7.2\r\n\r\n**Describe the current behavior**\r\nI have trained a model using the functional api and exported it to a saved_model.  I trained it using a batch_size of 32 but would like to do inference using only one sample (64ms of streaming audio).  For troubleshooting purposes I am evaluating a subset of the training data.  I read the serialised data into a tf.data.dataset for both training and inference, using the dataset.batch() method to set the batch size. Setting batch_size=1 gives the following result.\r\n\r\n```\r\nloss: 2.6619 - accuracy: 0.5155 - precision: 0.5155 - recall: 1.0000 - true_positives: 183.0000 - true_negatives: 0.0000e+00 - false_positives: 172.0000 - false_negatives: 0.0000e+00\r\n```\r\nThis is a binary problem so the accuracy is only as good as random.\r\n\r\n**Describe the expected behavior**\r\nSetting the batch size to 32 (same as training) gives results consistent with the training metrics:\r\n```\r\nloss: 0.1208 - accuracy: 0.9549 - precision: 0.9665 - recall: 0.9454 - true_positives: 173.0000 - true_negatives: 166.0000 - false_positives: 6.0000 - false_negatives: 10.0000\r\n```\r\n\r\nI would expect the results to at least be similar to this when using a batch size of 1.  I have checked the input size at each layer of my model and the batch size dimension is unchanging.\r\n\r\n**Standalone code to reproduce the issue**\r\nI use the following code to generate the dataset \r\n```\r\ndef get_test_dataset(tfrecords,\r\n                batch_size,\r\n                input_size=1024,\r\n                n_classes=1,\r\n                shuffle=False,\r\n                fake_input=False):\r\n    \"\"\" Read and preprocess tfrecords into a tf.data.Dataset \"\"\"\r\n\r\n    def parse_func(example_proto):\r\n        \"\"\" Parse tfrecords into tf.Feature, to be made into a dataset \"\"\"\r\n\r\n        feature_dict = {\r\n            'signal/id': tf.io.FixedLenFeature([], tf.string),\r\n            'segment/start': tf.io.FixedLenFeature([], tf.int64),\r\n            'segment/end': tf.io.FixedLenFeature([], tf.int64),\r\n            'subsegment/id': tf.io.FixedLenFeature([], tf.int64),\r\n            'subsegment/length': tf.io.FixedLenFeature([], tf.int64),\r\n            'subsegment/signal': tf.io.FixedLenFeature([input_size],\r\n                                                       tf.float32),\r\n            'subsegment/features': tf.io.FixedLenFeature(\r\n                [FEAT_SIZE[0] * FEAT_SIZE[1]], tf.float32),\r\n            'subsegment/label': tf.io.FixedLenFeature([], tf.int64)\r\n        }\r\n\r\n        parsed_feature = tf.io.parse_single_example(serialized=example_proto,\r\n                                                    features=feature_dict)\r\n\r\n        signal = parsed_feature['subsegment/signal']\r\n        signal = tf.cast(signal, dtype=tf.float32)\r\n        signal = tf.expand_dims(signal, 0)\r\n\r\n        labels = parsed_feature['subsegment/label']\r\n        labels = tf.expand_dims(labels, axis=-1)\r\n        labels = tf.cast(labels, dtype=tf.float32)\r\n\r\n        return signal, labels\r\n\r\n    files = tf.data.Dataset.list_files(tfrecords)\r\n    dataset = tf.data.TFRecordDataset(files)\r\n    dataset = dataset.map(parse_func, num_parallel_calls=8)\r\n    dataset = dataset.batch(batch_size)\r\n    dataset = dataset.prefetch(buffer_size=256)\r\n\r\n    return dataset\r\n\r\ntest_audio = get_test_dataset(tfrecords, batch_size)\r\n```\r\nand evaluate using:\r\n```\r\nprint(model.evaluate(test_audio, batch_size))\r\n```\r\nPerhaps something is wrong in my model but since I have checked the dimensions at each stage I'm wondering whether it could be a bug.  Thanks!", "comments": ["@ow4g18,\r\nOn running the given code, I am facing an error stating `NameError: name 'tfrecords' is not defined`.\r\n\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the dataset you are using. Thanks!", "@amahendrakar Hi, I've created a repo at https://github.com/ow4g18/troubleshooting containing the python script, saved_model and tfrecord data.  batch_size is a variable in the code and running the script from the base directory will evaluate accordingly.  Hope this will do, thanks!", "Was able to reproduce the issue with TF v2.3 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/52eaa7f313f759e8e08cbdd2dfc0f815/42864.ipynb). Thanks!", "@ow4g18 Please take a look at the input and output shapes of the model and see if the batch size is fixed or unknown?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 42863, "title": "Conv3d", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (or github SHA if from source):\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: CONCATENATION, CONV_2D, PACK, SPLIT, SUM. Here is a list of operators for which you will need custom implementations: Conv3D.  \r\n\r\n\r\n**Standalone code to reproduce the issue** \r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\ntensorflow.keras.layers.Conv3D(3, 3, padding='same')(x)\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem.\r\nIf including tracebacks, please include the full traceback. Large logs and files\r\nshould be attached.\r\n", "comments": ["@shlomi-amitai \r\nPlease provide with simple stand alone code or a colab gist with the error faced for us to analyse, the tf version on which the error is faced.", "`Conv3d` is WIP and not supported for TF Lite yet. See tracker https://github.com/tensorflow/tensorflow/issues/21526 to know more.\r\n", "As @ymodak said, TFLite builtin operator set does not cover the Conv3D case. However, you can convert Conv3D op with the Select TF ops approach:\r\n\r\nhttps://www.tensorflow.org/lite/guide/ops_select\r\nhttps://www.tensorflow.org/lite/guide/reduce_binary_size", "Thanks, \r\nis converting Conv3d with TF ops possible also in tf 1.14 /1.15? if so, could you send me a pointer?\r\n\r\n\r\n\r\n", "You can use the above Select TF operator option in TF 1.15 version as well. Or you can export your model to a saved model directory under TF 1.15 version and you can try the TFLite conversion with the recent TF version since TFLite converter can support TF 1.x's saved model directory format.\r\n\r\nFor the TF 1.x converter API, you can refer to the following document: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/r1/convert/index.md", "@shlomi-amitai \r\nPlease feel free to close this issue if resoved.", "Sure, just another last thing, I tried to convert with TF v1.14 \r\nset \"converter.target_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS\"\r\n\r\nbut failed with \r\n\"F tensorflow/lite/toco/graph_transformations/resolve_constant_transpose.cc:142] Check failed: op->perm.size() <= 4 (5 vs. 4)\"\r\n\r\nwhile \"Converting unsupported operation: Conv3D\"\r\n\r\nAre you familiar with this?\r\n\r\n", "thanks!"]}, {"number": 42862, "title": "Keras model.predict on large datasets throws OOM", "body": "I am using ImageDataGenerator and a Keras model (tf.keras.applications.EfficientNetB5). While training I also use the ImageDataGenerator and everything works as expected. But if I use the predict function from the keras model on large data sets, it throws an OOM error, even if it worked in previous versions (e.g. 2.1).\r\n\r\nThe allocator also tries to allocate a weird shape, it seems like the GPU tries to allocate the memory for all the predictions in GPU memory and not into RAM. If I divide the data in chunks and process them in separate predict calls the error does not occur.\r\n\r\nPlattform: Windows 10\r\nGPU: RTX 2080 Ti (11GB)\r\nPython Version: 3.7.7\r\nCUDA Version: 11.0\r\nTensorflow version:  v2.3.0-rc2-23-gb36436b087 2.3.0\r\n", "comments": ["@digital-thinking \r\n\r\nRequest you to share colab link or simple stand alone code to reproduce the issue in our environment. It helps us in localizing the issue faster. Thanks!", "Sorry, I don't have a colab or stand alone code right now. ", "@digital-thinking Please provide standalone code for us to reproduce this issue. \r\nYou can take a look at this [issue](https://datascience.stackexchange.com/questions/47274/why-i-get-oom-error-although-my-model-is-not-that-large) Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42862\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42862\">No</a>\n"]}, {"number": 42861, "title": "How to start JupyterLab in a virtual environment", "body": "Could you please tell me how to start JupyterLab in a virtual environment?\r\n\r\nI use Windows 10 and have already installed Anaconda 64 bit.\r\n\r\nI failed to install tensorflow in the base environment. Therefore, I created a virtual environment where tensorflow was  installed, by writing the following command on Anaconda prompt.\r\n`conda create -n tf2 tensorflow python=3.7`\r\n\r\nWith this command, I created the virtual environment succesfully.\r\n\r\nThen, I wrote the following command on the activated virtual environment:\r\n`(tf2) conda install -c conda-forge jupyter lab`\r\n\r\nFinally, I wrote this command:\r\n`jupyter lab`\r\n\r\nHowever, JupyterLab did not start.\r\nCould you please teach me what I should do?", "comments": ["@momohina,\r\nThis question is better asked on [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow) since it is not a TensorFlow bug or feature request. There is also a larger community that reads questions there. Thanks!", "Thank you very much for advice!\r\n\r\nI am going to ask the question on StackOverflow."]}, {"number": 42860, "title": "Fix a bug that the file copied by TF from HDFS to local may be wrong,\u2026", "body": "This is a PR from TaiJi AI platform in Tencent.\r\n\r\n- The file copied by TF from HDFS to local may be wrong, when HDFS file is being overwritten [#42597](https://github.com/tensorflow/tensorflow/issues/42597)", "comments": ["@mihaimaruseac\r\nCan you help review the patch-3? I look forward to  your comments, thanks :).\r\n\r\n", "I will take care for the change and test in filesystem plugin for HDFS. However, I prefer reading the env in the initialization of the filesystem for a consistency between multiple calls for `hdfsRead`. what do you think @yuanbopeng @mihaimaruseac ", "@vnvo2409 \r\nI will add a test case for ReadWhileOverwriting soon, and I will also fix the compilation problem caused by the [HadoopFileSystemTest](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/hadoop/hadoop_file_system_test.cc)  call HDFS API without TransactionTokend. [S3FileSystemTest](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/s3/s3_file_system_test.cc) also has similar problems.\r\n![image](https://user-images.githubusercontent.com/70072713/93038262-19a4e700-f677-11ea-899d-454a45da0c92.png)\r\n\r\nIf it is necessary to modify, I prefer to reading the env in the initialization of [HDFSRandomAccessFile](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/hadoop/hadoop_file_system.cc#L205), which is more flexible and can support both WriteWhileReading and ReadWhileOverwriting use cases.\r\n", "@yuanbopeng \r\n- The filesystem plugin is something else. It lives here https://github.com/tensorflow/tensorflow/tree/master/tensorflow/c/experimental/filesystem/plugins/hadoop. The current filesystem will be replaced by the filesystem plugin but it will take some time. In the meantime, I think you could just work on the current filesystem and I will mimic your change to the filesystem plugins.\r\n- So i will read the `env` inside `NewRandomAccessFile` for Hadoop.", "@vnvo2409 \r\n> \r\n> * The filesystem plugin is something else. It lives here https://github.com/tensorflow/tensorflow/tree/master/tensorflow/c/experimental/filesystem/plugins/hadoop. The current filesystem will be replaced by the filesystem plugin but it will take some time. In the meantime, I think you could just work on the current filesystem and I will mimic your change to the filesystem plugins.\r\n\r\nok. In order to ensure that the `WriteWhileReading` test case can pass, I will delete test cases that caused the compilation problem locally, and finally submit only the WriteWhileReading test case code. \r\n\r\n> * So i will read the `env` inside `NewRandomAccessFile` for Hadoop.\r\n\r\nWould it be better to read env in the constructor of `HDFSRandomAccessFile`?\r\n", "@yuanbopeng \r\n\r\n> Would it be better to read env in the constructor of HDFSRandomAccessFile?\r\n\r\nAgree.\r\n\r\n> ok. In order to ensure that the `WriteWhileReading` test case can pass, I will delete test cases that caused the compilation problem locally, and finally submit only the WriteWhileReading test case code.\r\n\r\nThe cloud filesystems tests have a tag `manual` so the CI will skip them. You see the compilation problem because no one has run those tests for a long time while adding a new transactional token into the filesystem operation but not into the tests. I think it is not necessary adding the test here since you will have to add the transactional token ( a `nullptr` I think so ) to every functions to fix the compilation problem.\r\n\r\nI think I will add your change and add my own test into HDFS plugins. I will ping you in that PR so you could review the test and make sure that the test is what you want. The implementation of the filesystem plugin and the current filesystem are very similar so I think adding test in one place is enough.\r\n\r\nYou could also work with the filesystem plugin but keep in mind that if you would like to see the change immediately (`tf-nightly`). You will have to work with the current filesystem.\r\n\r\nlet's see if @mihaimaruseac agree with us.\r\n", "Sounds good to me. Thanks for driving this forward", "@vnvo2409\r\nadd `ReadWhileOverwriting` test cases. https://github.com/tensorflow/tensorflow/pull/43220\r\n \r\nIn addition, fixes the compilation problem.\r\nHDFS: https://github.com/tensorflow/tensorflow/pull/43221\r\nS3: https://github.com/tensorflow/tensorflow/pull/43222\r\n"]}, {"number": 42859, "title": "imdb.load_data() is not returning meaningful sentences as I have given print like x_train[0], x_train[1] after loading the data!", "body": "**code example for review** \r\n\r\n(x_train, y_train), (x_test, y_test) = imdb.load_data()\r\nword_to_ix = imdb.get_word_index()\r\n\r\nix_to_word = dict( (value, key) for key, value in word_to_ix.items() )\r\n\r\nfor i in range(len(x_train[0])):\r\n  print(ix_to_word[x_train[0][i]])\r\n", "comments": ["@tawsifsazid \r\nPlease fill in the issue template, if possible share colab gist with complete code and error faced.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42859\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42859\">No</a>\n"]}, {"number": 42858, "title": "Linking error: Undefined reference to 'omp_get_max_threads'/'omp_in_parallel'/omp_get_thread_num'/'omp_get_num_threads'", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.5\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: master\r\n- Python version: Python 3.7.0\r\n- Installed using virtualenv? pip? conda?: virtualenv\r\n- Bazel version (if compiling from source): bazel 3.4.0\r\n- GCC/Compiler version (if compiling from source): GCC  9.3.0\r\n- CUDA/cuDNN version: NA\r\n- GPU model and memory: NA\r\n\r\n\r\n\r\n**Describe the problem**\r\nI am building TensorFlow master with mkldnn_v1 (oneDNN) for Aarch64 (as per https://github.com/tensorflow/tensorflow/pull/41232#issuecomment-670049428), I want to incorporate changes into TensorFlow to get oneDNN built for Aarch64 automatically). I have made a temporary change to test this in the cc_library macro  in mkldnn_v1.BUILD to remove any x86 srcs:\r\n\r\n```\r\ncc_library(\r\n    name = \"mkl_dnn\",\r\n    srcs = glob([\r\n        \"src/common/*.cpp\",\r\n        \"src/common/*.hpp\",\r\n        \"src/cpu/*.cpp\",\r\n        \"src/cpu/*.hpp\",\r\n        \"src/cpu/rnn/*.cpp\",\r\n        \"src/cpu/rnn/*.hpp\",\r\n        \"src/cpu/matmul/*.cpp\",\r\n        \"src/cpu/matmul/*.hpp\",\r\n        \"src/cpu/gemm/*.cpp\",\r\n        \"src/cpu/gemm/*.hpp\",\r\n        \"src/cpu/gemm/**/*.cpp\",\r\n        \"src/cpu/gemm/**/*.hpp\",\r\n    ]) + [\r\n        \":dnnl_config_h\",\r\n        \":dnnl_version_h\",\r\n    ],\r\n    hdrs = glob([\"include/*\"]),\r\n    copts = [\r\n        \"-fexceptions\",\r\n        \"-DUSE_MKL\",\r\n        \"-DUSE_CBLAS\",\r\n    ] + if_mkl_open_source_only([\r\n        \"-UUSE_MKL\",\r\n        \"-UUSE_CBLAS\",\r\n    ]) + if_mkl_v1([\r\n        \"-UUSE_MKL\",\r\n        \"-UUSE_CBLAS\",\r\n    ]) + if_mkldnn_threadpool([\r\n        \"-UUSE_MKL\",\r\n        \"-UUSE_CBLAS\",\r\n    ]) + select({\r\n        \"@org_tensorflow//tensorflow:linux_x86_64\": [\r\n            \"-fopenmp\",  # only works with gcc\r\n        ],\r\n        # TODO(ibiryukov): enable openmp with clang by including libomp as a\r\n        # dependency.\r\n        \":clang_linux_x86_64\": [],\r\n        \"//conditions:default\": [],\r\n    }),\r\n    includes = [\r\n        \"include\",\r\n        \"src\",\r\n        \"src/common\",\r\n        \"src/cpu\",\r\n        \"src/cpu/gemm\",\r\n        \"src/cpu/xbyak\",\r\n    ],\r\n    visibility = [\"//visibility:public\"],\r\n    deps = if_mkl_ml(\r\n        [\"@org_tensorflow//third_party/mkl:intel_binary_blob\"],\r\n        [],\r\n    ),\r\n)\r\n```\r\n\r\n However, I am facing an issue at the linking stage as given below.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n```\r\nexport HOST_C_COMPILER=(which gcc)\r\nexport HOST_CXX_COMPILER=(which g++)\r\nexport PYTHON_BIN_PATH=(which python)\r\nexport USE_DEFAULT_PYTHON_LIB_PATH=1\r\nexport CC_OPT_FLAGS=\"\"\r\nexport TF_ENABLE_XLA=0\r\nexport TF_NEED_GCP=0\r\nexport TF_NEED_S3=0\r\nexport TF_NEED_OPENCL_SYCL=0\r\nexport TF_NEED_CUDA=0\r\nexport TF_DOWNLOAD_CLANG=0\r\nexport TF_NEED_MPI=0\r\nexport TF_SET_ANDROID_WORKSPACE=0\r\nexport TF_NEED_ROCM=0\r\n\r\n ./configure\r\n\r\nbazel build $extra_args \\\r\n       --config=mkl_opensource_only \\\r\n       --copt=\"-mcpu=native --copt=\"-moutline-atomics\" --copt=\"-O3\" \\\r\n       --cxxopt=\"-mcpu=native --cxxopt=\"-moutline-atomics\" --cxxopt=\"-O3\" \\\r\n       --linkopt=\"-lm\" --linkopt=\"-fopenmp\" \\\r\n       --config=noaws --config=v2 --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" -s --verbose_failures \\\r\n       //tensorflow/tools/pip_package:build_pip_package`\r\n```\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n```\r\nSUBCOMMAND: # //tensorflow/cc:ops/data_flow_ops_gen_cc [action 'Linking tensorflow/cc/ops/data_flow_ops_gen_cc', configuration: c23edb309cdc7c1c180dab9acba8e07353df62a2190a5128337821049fc4c4fe, execution platform: @local_execution_config_platform//:platform]\r\n(cd /home/ubuntu/.cache/bazel/_bazel_ubuntu/3083553ad2d6c5e705de8a2de81b65f3/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=/opt/openblas/0.3.9/lib \\\r\n    PATH=/home/ubuntu/python3-venv/bin:/home/ubuntu//packages/bazel/output:/home/ubuntu/python3-venv/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \\\r\n    PWD=/proc/self/cwd \\\r\n  /usr/bin/gcc @bazel-out/aarch64-opt-exec-50AE0418/bin/tensorflow/cc/ops/data_flow_ops_gen_cc-2.params)\r\nERROR: /home/ubuntu/packages/tensorflow/tensorflow/cc/BUILD:545:22: Linking of rule '//tensorflow/cc:ops/sparse_ops_gen_cc' failed (Exit 1): gcc failed: error executing command \r\n  (cd /home/ubuntu/.cache/bazel/_bazel_ubuntu/3083553ad2d6c5e705de8a2de81b65f3/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=/opt/openblas/0.3.9/lib\\\r\n    PATH=/home/ubuntu/python3-venv/bin:/home/ubuntu//packages/bazel/output:/home/ubuntu/python3-venv/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \\\r\n    PWD=/proc/self/cwd \\\r\n  /usr/bin/gcc @bazel-out/aarch64-opt-exec-50AE0418/bin/tensorflow/cc/ops/sparse_ops_gen_cc-2.params)\r\nExecution platform: @local_execution_config_platform//:platform\r\nbazel-out/aarch64-opt-exec-50AE0418/bin/_solib_aarch64/_U_S_Stensorflow_Scc_Cops_Ssparse_Uops_Ugen_Ucc___Utensorflow/libtensorflow_framework.so.2: error: undefined reference to 'omp_get_max_threads'\r\nbazel-out/aarch64-opt-exec-50AE0418/bin/_solib_aarch64/_U_S_Stensorflow_Scc_Cops_Ssparse_Uops_Ugen_Ucc___Utensorflow/libtensorflow_framework.so.2: error: undefined reference to 'omp_in_parallel'\r\nbazel-out/aarch64-opt-exec-50AE0418/bin/_solib_aarch64/_U_S_Stensorflow_Scc_Cops_Ssparse_Uops_Ugen_Ucc___Utensorflow/libtensorflow_framework.so.2: error: undefined reference to 'omp_get_thread_num'\r\nbazel-out/aarch64-opt-exec-50AE0418/bin/_solib_aarch64/_U_S_Stensorflow_Scc_Cops_Ssparse_Uops_Ugen_Ucc___Utensorflow/libtensorflow_framework.so.2: error: undefined reference to 'omp_get_num_threads'\r\ncollect2: error: ld returned 1 exit status\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 259.203s, Critical Path: 182.59s\r\nINFO: 3379 processes: 3379 local.\r\nFAILED: Build did NOT complete successfully\r\n\r\n```", "comments": ["Hi,\r\nI can see that the libmkldnn.so is built but not linked to libtensorflow_framework.so:\r\n![Screenshot 2020-09-03 at 09 18 53](https://user-images.githubusercontent.com/65665931/92107586-f60fb000-eddd-11ea-88b3-9af75144835b.png)\r\n", "I have been tracing the linking step for x86 builds built with --config=mkl\r\n```\r\nldd bazel-out/k8-opt-exec-50AE0418/bin/tensorflow/libtensorflow_framework.so\r\n        linux-vdso.so.1 =>  (0x00007ffff7ffa000)\r\n        libiomp5.so => /home/ubuntu/tensorflow/bazel-out/k8-opt-exec-50AE0418/bin/tensorflow/../_solib_k8/_U@mkl_Ulinux_S_S_Cmkl_Ulibs_Ulinux___Uexternal_Smkl_Ulinux_Slib/libiomp5.so (0x00007ffff42c1000)\r\n        libmklml_intel.so => /home/ubuntu/tensorflow/bazel-out/k8-opt-exec-50AE0418/bin/tensorflow/../_solib_k8/_U@mkl_Ulinux_S_S_Cmkl_Ulibs_Ulinux___Uexternal_Smkl_Ulinux_Slib/libmklml_intel.so (0x00007fffec82f000)\r\n        librt.so.1 => /lib64/librt.so.1 (0x00007fffec627000)\r\n        libpthread.so.0 => /lib64/libpthread.so.0 (0x00007fffec40b000)\r\n        libdl.so.2 => /lib64/libdl.so.2 (0x00007fffec207000)\r\n        libm.so.6 => /lib64/libm.so.6 (0x00007fffebf05000)\r\n        libc.so.6 => /lib64/libc.so.6 (0x00007fffebb38000)\r\n        /lib64/ld-linux-x86-64.so.2 (0x00007ffff7ddb000)\r\n        libgcc_s.so.1 => /opt/gcc/8.1.0/lib64/libgcc_s.so.1 (0x00007fffeb920000) \r\n```\r\nwith libmklml_intel.so located here:\r\n```\r\nls /home/ubuntu/tensorflow/bazel-out/k8-opt-exec-50AE0418/bin/tensorflow/../_solib_k8/_U@mkl_Ulinux_S_S_Cmkl_Ulibs_Ulinux___Uexternal_Smkl_Ulinux_Slib/\r\nlibiomp5.so  libmklml_intel.so\r\n```\r\nsymbolically linked with:\r\n```\r\n ls /home/ubuntu/.cache/bazel/_bazel_ubuntu/fa3441bb97e92be4a48358eda4f4181d/external/mkl_linux/lib/\r\nlibiomp5.so  libmklml_gnu.so  libmklml_intel.so\r\n```\r\n\r\nIs there a way to link libtensorflow.so to libdnnl.so/libmkldnn.so directly? \r\n", "I have rebuilt master and git commit d4a8e6515ea2abefa4133af13bdf15d09ffc9d7d on x86 with --config=mkl_opensource_only and I am seeing a similar issue. @agramesh1 is this a known issue with mkl_dnn_v1 builds? I have also tried with  --linkopt=\"-fopenmp\".\r\n```\r\n(cd /home/ubuntu/.cache/bazel/_bazel_ubuntu/fa3441bb97e92be4a48358eda4f4181d/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=/opt/gcc/8.1.0/lib64:/software/slurm/lib \\\r\n    PATH=/home/ubuntu/bazel/output:/opt/gcc/8.1.0/bin:/home/ubuntu/python3-venv/bin:/software/slurm/bin:/software/slurm/sbin:/usr/lib64/qt-3.3/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/software/pbs/bin:/software/pbs/bin:/software/pbs/bin:/home/ubuntu/.local/bin:/home/ubuntu/bin \\\r\n    PWD=/proc/self/cwd \\\r\n  /opt/gcc/8.1.0/bin/gcc @bazel-out/host/bin/tensorflow/python/gen_list_ops_py_wrappers_cc-2.params)\r\nERROR: /home/ubuntu/tensorflow/tensorflow/python/BUILD:3235:1: Linking of rule '//tensorflow/python:gen_ragged_conversion_ops_py_wrappers_cc' failed (Exit 1)\r\nbazel-out/host/bin/_solib_k8/_U_S_Stensorflow_Spython_Cgen_Uragged_Uconversion_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so.2: error: undefined reference to 'omp_set_num_threads'\r\nbazel-out/host/bin/_solib_k8/_U_S_Stensorflow_Spython_Cgen_Uragged_Uconversion_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so.2: error: undefined reference to 'omp_get_num_threads'\r\nbazel-out/host/bin/_solib_k8/_U_S_Stensorflow_Spython_Cgen_Uragged_Uconversion_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so.2: error: undefined reference to 'omp_get_thread_num'\r\nbazel-out/host/bin/_solib_k8/_U_S_Stensorflow_Spython_Cgen_Uragged_Uconversion_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so.2: error: undefined reference to 'omp_get_max_threads'\r\nbazel-out/host/bin/_solib_k8/_U_S_Stensorflow_Spython_Cgen_Uragged_Uconversion_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so.2: error: undefined reference to 'omp_in_parallel'\r\nbazel-out/host/bin/_solib_k8/_U_S_Stensorflow_Spython_Cgen_Uragged_Uconversion_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so.2: error: undefined reference to 'GOMP_parallel'\r\nbazel-out/host/bin/_solib_k8/_U_S_Stensorflow_Spython_Cgen_Uragged_Uconversion_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so.2: error: undefined reference to 'GOMP_barrier'\r\nbazel-out/host/bin/_solib_k8/_U_S_Stensorflow_Spython_Cgen_Uragged_Uconversion_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so.2: error: undefined reference to 'iJIT_IsProfilingActive'\r\nbazel-out/host/bin/_solib_k8/_U_S_Stensorflow_Spython_Cgen_Uragged_Uconversion_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so.2: error: undefined reference to 'iJIT_GetNewMethodID'\r\nbazel-out/host/bin/_solib_k8/_U_S_Stensorflow_Spython_Cgen_Uragged_Uconversion_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so.2: error: undefined reference to 'iJIT_NotifyEvent'\r\ncollect2: error: ld returned 1 exit status\r\n```", "@cfRod  You can add `linkopts = [\"-lgomp\"], ` here https://github.com/tensorflow/tensorflow/blob/master/third_party/mkl_dnn/mkldnn_v1.BUILD#L114 This will pull in gcc's openmp and allow you to build and run with gcc's omp library.  However gomp peformance not be as good as the intel openmp solution. For x86 builds, we get  libiomp5 as part of  binary blob. The intel openmp is available as opensource from llvm https://github.com/llvm/llvm-project that can be compiled for ARM as a third party dependency.  \r\nTo get rid of the iJIT errors,  you need this fix (adapted for ARM) https://github.com/tensorflow/tensorflow/commit/a39d2c5a26c2df6c26d150a3ba9bb570f459bc71", "@agramesh1, thanks for this pointer. I built TensorFlow with gcc's omp library for x86, I can see it linking to libgomp.so. I presumably should see a libdnnl.so/libmkldnn.so linked here (?)\r\n```\r\nldd k8-opt-exec-50AE0418/bin/tensorflow/libtensorflow_framework.so\r\n        linux-vdso.so.1 =>  (0x00007ffff7ffa000)\r\n        librt.so.1 => /lib64/librt.so.1 (0x00007ffff44ab000)\r\n        libpthread.so.0 => /lib64/libpthread.so.0 (0x00007ffff428f000)\r\n        libdl.so.2 => /lib64/libdl.so.2 (0x00007ffff408b000)\r\n        libm.so.6 => /lib64/libm.so.6 (0x00007ffff3d89000)\r\n        libgomp.so.1 => /opt/gcc/8.1.0/lib64/libgomp.so.1 (0x00007ffff3b5b000)\r\n        libc.so.6 => /lib64/libc.so.6 (0x00007ffff378e000)\r\n        /lib64/ld-linux-x86-64.so.2 (0x00007ffff7ddb000)\r\n```", "According to this (https://software.intel.com/content/www/us/en/develop/articles/intel-optimization-for-tensorflow-installation-guide.html?page=1&cid=&utm_medium=Syndication&utm_source=CodeProject&utm_campaign=AI_Developer_ASMO_2H_18_CodeProject), \r\nI used the sanity check here to confirm the optimizations are enabled. Both --config=mkl and --config=mkl_opensource_only builds on x86 show the following:\r\n```\r\n>>> from tensorflow.python import _pywrap_util_port\r\n>>> _pywrap_util_port.IsMklEnabled()                                                                                                                                                            \r\nTrue\r\n```\r\nI can close this issue if  this sanity check is the one for confirming whether oneDNN optimizations are enabled.\r\nI also ran MobileNet model in MLPerf which showed the following logs:  \r\n```\r\n2020-09-14 13:58:19.224305: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX\r\n```\r\nHowever, this log appears for both TensorFlow Eigen and TensorFlow oneDNN builds on x86 which I think might be a bug.\r\n\r\nFor TensorFlow-Eigen builds on x86 the sanity test showed the following:\r\n\r\n```\r\nfrom tensorflow.python import _pywrap_util_port\r\n_pywrap_util_port.IsMklEnabled()                                                                                                                                                            \r\nFalse\r\n```\r\n", "Okay, I can confirm that dnnl symbols are linked to libtensorflow_framework.so.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42858\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42858\">No</a>\n"]}, {"number": 42857, "title": "TFLite conversion stops midway", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (or github SHA if from source):  tf-nightly\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\ntflite_convert --saved_model_dir=.\\exported-models\\model2\\saved_model\\ --output_file=.\\model.tflite\r\n\r\nalso tried with \r\n\r\ntflite_convert --saved_model_dir=.\\exported-models\\model2\\saved_model\\ --output_file=.\\model.tflite --experimental_new_converter=true\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\n%cst_241 = \"std.constant\"() {value = dense<[0.00390369981, -0.0127573842, 0.0908339769, 0.0180643108, -0.00954434275, -0.0410878435, 0.0690650493, 0.0225697756, 0.00117305783, -0.0115958247, 0.26719141, -1.689380e-01, 0.0166990291, -9.513800e-03, 0.336577594, -0.351093948, -0.00157127564, -0.00931285507, -0.167294487, 0.267790347, -0.0237121694, -0.0350524895, -3.717270e-01, 0.36779502]> : tensor<24xf32>} : () -> tensor<24xf32>\r\n  %cst_242 = \"std.constant\"() {value = dense<[1, 51150, 1, 4]> : tensor<4xi32>} : () -> tensor<4xi32>\r\n  %cst_243 = \"std.constant\"() {value = dense<[1, 51150, 4]> : tensor<3xi32>} : () -> tensor<3xi32>\r\n  %cst_244 = \"std.constant\"() {value = dense<[-4.6671648, -4.234303, -4.66916609, -4.03752136, -4.66963768, -4.34722042, -4.6698885, -4.11983204, -4.67162561, -4.25614262, -4.67194557, -4.16072559]> : tensor<12xf32>} : () -> tensor<12xf32>\r\n  %cst_245 = \"std.constant\"() {value = dense<-1> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %cst_246 = \"std.constant\"() {value = dense<0> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %cst_247 = \"std.constant\"() {value = dense<2> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %cst_248 = \"std.constant\"() {value = dense<1> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %0 = \"tfl.cast\"(%arg0) : (tensor<1x?x?x3xui8>) -> tensor<1x?x?x3xf32>\r\n  %1 = \"tfl.sub\"(%0, %cst_23) {fused_activation_function = \"NONE\"} : (tensor<1x?x?x3xf32>, tensor<1x1x3xf32>) -> tensor<1x?x?x3xf32>\r\n  %2 = \"tfl.unpack\"(%1) {axis = 0 : i32, num = 1 : i32} : (tensor<1x?x?x3xf32>) -> tensor<?x?x3xf32>\r\n  %3 = \"tfl.expand_dims\"(%2, %cst_21) : (tensor<?x?x3xf32>, tensor<i32>) -> tensor<1x?x?x3xf32>\r\n  %4 = \"tfl.resize_bilinear\"(%3, %cst_22) {align_corners = false, half_pixel_centers = false} : (tensor<1x?x?x3xf32>, tensor<2xi32>) -> tensor<1x640x640x3xf32>\r\n  %5 = \"tfl.reshape\"(%4, %cst_217) : (tensor<1x640x640x3xf32>, tensor<3xi32>) -> tensor<640x640x3xf32>\r\n  %6 = \"tfl.pack\"(%5) {axis = 0 : i32, values_count = 1 : i32} : (tensor<640x640x3xf32>) -> tensor<1x640x640x3xf32>\r\n  %7 = \"tfl.pad\"(%6, %cst_26) : (tensor<1x640x640x3xf32>, tensor<4x2xi32>) -> tensor<1x646x646x3xf32>\r\n  %8 = \"tfl.conv_2d\"(%7, %cst_115, %cst_38) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"VALID\", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<1x646x646x3xf32>, tensor<64x7x7x3xf32>, tensor<64xf32>) -> tensor<1x320x320x64xf32>\r\n  %9 = \"tfl.max_pool_2d\"(%8) {filter_height = 3 : i32, filter_width = 3 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<1x320x320x64xf32>) -> tensor<1x160x160x64xf32>\r\n  %10 = \"tfl.conv_2d\"(%9, %cst_116, %cst_218) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x160x160x64xf32>, tensor<256x1x1x64xf32>, tensor<256xf32>) -> tensor<1x160x160x256xf32>\r\n  %11 = \"tfl.conv_2d\"(%9, %cst_117, %cst_39) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x160x160x64xf32>, tensor<64x1x1x64xf32>, tensor<64xf32>) -> tensor<1x160x160x64xf32>\r\n  %12 = \"tfl.conv_2d\"(%11, %cst_118, %cst_40) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x160x160x64xf32>, tensor<64x3x3x64xf32>, tensor<64xf32>) -> tensor<1x160x160x64xf32>\r\n  %13 = \"tfl.conv_2d\"(%12, %cst_119, %cst_219) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x160x160x64xf32>, tensor<256x1x1x64xf32>, tensor<256xf32>) -> tensor<1x160x160x256xf32>\r\n  %14 = \"tfl.add\"(%10, %13) {fused_activation_function = \"RELU6\"} : (tensor<1x160x160x256xf32>, tensor<1x160x160x256xf32>) -> tensor<1x160x160x256xf32>\r\n  %15 = \"tfl.conv_2d\"(%14, %cst_120, %cst_41) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x160x160x256xf32>, tensor<64x1x1x256xf32>, tensor<64xf32>) -> tensor<1x160x160x64xf32>\r\n  %16 = \"tfl.conv_2d\"(%15, %cst_121, %cst_42) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x160x160x64xf32>, tensor<64x3x3x64xf32>, tensor<64xf32>) -> tensor<1x160x160x64xf32>\r\n  %17 = \"tfl.conv_2d\"(%16, %cst_122, %cst_220) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x160x160x64xf32>, tensor<256x1x1x64xf32>, tensor<256xf32>) -> tensor<1x160x160x256xf32>\r\n  %18 = \"tfl.add\"(%14, %17) {fused_activation_function = \"RELU6\"} : (tensor<1x160x160x256xf32>, tensor<1x160x160x256xf32>) -> tensor<1x160x160x256xf32>\r\n  %19 = \"tfl.conv_2d\"(%18, %cst_123, %cst_43) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x160x160x256xf32>, tensor<64x1x1x256xf32>, tensor<64xf32>) -> tensor<1x160x160x64xf32>\r\n  %20 = \"tfl.conv_2d\"(%19, %cst_124, %cst_44) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x160x160x64xf32>, tensor<64x3x3x64xf32>, tensor<64xf32>) -> tensor<1x160x160x64xf32>\r\n  %21 = \"tfl.conv_2d\"(%20, %cst_125, %cst_221) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x160x160x64xf32>, tensor<256x1x1x64xf32>, tensor<256xf32>) -> tensor<1x160x160x256xf32>\r\n  %22 = \"tfl.add\"(%18, %21) {fused_activation_function = \"RELU6\"} : (tensor<1x160x160x256xf32>, tensor<1x160x160x256xf32>) -> tensor<1x160x160x256xf32>\r\n  %23 = \"tfl.conv_2d\"(%22, %cst_126, %cst_222) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<1x160x160x256xf32>, tensor<512x1x1x256xf32>, tensor<512xf32>) -> tensor<1x80x80x512xf32>\r\n  %24 = \"tfl.conv_2d\"(%22, %cst_127, %cst_45) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<1x160x160x256xf32>, tensor<128x1x1x256xf32>, tensor<128xf32>) -> tensor<1x80x80x128xf32>\r\n  %25 = \"tfl.conv_2d\"(%24, %cst_128, %cst_46) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x128xf32>, tensor<128x3x3x128xf32>, tensor<128xf32>) -> tensor<1x80x80x128xf32>\r\n  %26 = \"tfl.conv_2d\"(%25, %cst_129, %cst_223) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x128xf32>, tensor<512x1x1x128xf32>, tensor<512xf32>) -> tensor<1x80x80x512xf32>\r\n  %27 = \"tfl.add\"(%23, %26) {fused_activation_function = \"RELU6\"} : (tensor<1x80x80x512xf32>, tensor<1x80x80x512xf32>) -> tensor<1x80x80x512xf32>\r\n  %28 = \"tfl.conv_2d\"(%27, %cst_130, %cst_47) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x512xf32>, tensor<128x1x1x512xf32>, tensor<128xf32>) -> tensor<1x80x80x128xf32>\r\n  %29 = \"tfl.conv_2d\"(%28, %cst_131, %cst_48) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x128xf32>, tensor<128x3x3x128xf32>, tensor<128xf32>) -> tensor<1x80x80x128xf32>\r\n  %30 = \"tfl.conv_2d\"(%29, %cst_132, %cst_224) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x128xf32>, tensor<512x1x1x128xf32>, tensor<512xf32>) -> tensor<1x80x80x512xf32>\r\n  %31 = \"tfl.add\"(%27, %30) {fused_activation_function = \"RELU6\"} : (tensor<1x80x80x512xf32>, tensor<1x80x80x512xf32>) -> tensor<1x80x80x512xf32>\r\n  %32 = \"tfl.conv_2d\"(%31, %cst_133, %cst_49) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x512xf32>, tensor<128x1x1x512xf32>, tensor<128xf32>) -> tensor<1x80x80x128xf32>\r\n  %33 = \"tfl.conv_2d\"(%32, %cst_134, %cst_50) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x128xf32>, tensor<128x3x3x128xf32>, tensor<128xf32>) -> tensor<1x80x80x128xf32>\r\n  %34 = \"tfl.conv_2d\"(%33, %cst_135, %cst_225) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x128xf32>, tensor<512x1x1x128xf32>, tensor<512xf32>) -> tensor<1x80x80x512xf32>\r\n  %35 = \"tfl.add\"(%31, %34) {fused_activation_function = \"RELU6\"} : (tensor<1x80x80x512xf32>, tensor<1x80x80x512xf32>) -> tensor<1x80x80x512xf32>\r\n  %36 = \"tfl.conv_2d\"(%35, %cst_136, %cst_51) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x512xf32>, tensor<128x1x1x512xf32>, tensor<128xf32>) -> tensor<1x80x80x128xf32>\r\n  %37 = \"tfl.conv_2d\"(%36, %cst_137, %cst_52) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x128xf32>, tensor<128x3x3x128xf32>, tensor<128xf32>) -> tensor<1x80x80x128xf32>\r\n  %38 = \"tfl.conv_2d\"(%37, %cst_138, %cst_226) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x128xf32>, tensor<512x1x1x128xf32>, tensor<512xf32>) -> tensor<1x80x80x512xf32>\r\n  %39 = \"tfl.add\"(%35, %38) {fused_activation_function = \"RELU6\"} : (tensor<1x80x80x512xf32>, tensor<1x80x80x512xf32>) -> tensor<1x80x80x512xf32>\r\n  %40 = \"tfl.conv_2d\"(%39, %cst_139, %cst_227) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x512xf32>, tensor<256x1x1x512xf32>, tensor<256xf32>) -> tensor<1x80x80x256xf32>\r\n  %41 = \"tfl.conv_2d\"(%39, %cst_140, %cst_228) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<1x80x80x512xf32>, tensor<1024x1x1x512xf32>, tensor<1024xf32>) -> tensor<1x40x40x1024xf32>\r\n  %42 = \"tfl.conv_2d\"(%39, %cst_141, %cst_53) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<1x80x80x512xf32>, tensor<256x1x1x512xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %43 = \"tfl.conv_2d\"(%42, %cst_142, %cst_54) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %44 = \"tfl.conv_2d\"(%43, %cst_143, %cst_229) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<1024x1x1x256xf32>, tensor<1024xf32>) -> tensor<1x40x40x1024xf32>\r\n  %45 = \"tfl.add\"(%41, %44) {fused_activation_function = \"RELU6\"} : (tensor<1x40x40x1024xf32>, tensor<1x40x40x1024xf32>) -> tensor<1x40x40x1024xf32>\r\n  %46 = \"tfl.conv_2d\"(%45, %cst_144, %cst_55) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x1024xf32>, tensor<256x1x1x1024xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %47 = \"tfl.conv_2d\"(%46, %cst_145, %cst_56) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %48 = \"tfl.conv_2d\"(%47, %cst_146, %cst_230) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<1024x1x1x256xf32>, tensor<1024xf32>) -> tensor<1x40x40x1024xf32>\r\n  %49 = \"tfl.add\"(%45, %48) {fused_activation_function = \"RELU6\"} : (tensor<1x40x40x1024xf32>, tensor<1x40x40x1024xf32>) -> tensor<1x40x40x1024xf32>\r\n  %50 = \"tfl.conv_2d\"(%49, %cst_147, %cst_57) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x1024xf32>, tensor<256x1x1x1024xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %51 = \"tfl.conv_2d\"(%50, %cst_148, %cst_58) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %52 = \"tfl.conv_2d\"(%51, %cst_149, %cst_231) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<1024x1x1x256xf32>, tensor<1024xf32>) -> tensor<1x40x40x1024xf32>\r\n  %53 = \"tfl.add\"(%49, %52) {fused_activation_function = \"RELU6\"} : (tensor<1x40x40x1024xf32>, tensor<1x40x40x1024xf32>) -> tensor<1x40x40x1024xf32>\r\n  %54 = \"tfl.conv_2d\"(%53, %cst_150, %cst_59) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x1024xf32>, tensor<256x1x1x1024xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %55 = \"tfl.conv_2d\"(%54, %cst_151, %cst_60) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %56 = \"tfl.conv_2d\"(%55, %cst_152, %cst_232) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<1024x1x1x256xf32>, tensor<1024xf32>) -> tensor<1x40x40x1024xf32>\r\n  %57 = \"tfl.add\"(%53, %56) {fused_activation_function = \"RELU6\"} : (tensor<1x40x40x1024xf32>, tensor<1x40x40x1024xf32>) -> tensor<1x40x40x1024xf32>\r\n  %58 = \"tfl.conv_2d\"(%57, %cst_153, %cst_61) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x1024xf32>, tensor<256x1x1x1024xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %59 = \"tfl.conv_2d\"(%58, %cst_154, %cst_62) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %60 = \"tfl.conv_2d\"(%59, %cst_155, %cst_233) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<1024x1x1x256xf32>, tensor<1024xf32>) -> tensor<1x40x40x1024xf32>\r\n  %61 = \"tfl.add\"(%57, %60) {fused_activation_function = \"RELU6\"} : (tensor<1x40x40x1024xf32>, tensor<1x40x40x1024xf32>) -> tensor<1x40x40x1024xf32>\r\n  %62 = \"tfl.conv_2d\"(%61, %cst_156, %cst_63) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x1024xf32>, tensor<256x1x1x1024xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %63 = \"tfl.conv_2d\"(%62, %cst_157, %cst_64) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %64 = \"tfl.conv_2d\"(%63, %cst_158, %cst_234) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<1024x1x1x256xf32>, tensor<1024xf32>) -> tensor<1x40x40x1024xf32>\r\n  %65 = \"tfl.add\"(%61, %64) {fused_activation_function = \"RELU6\"} : (tensor<1x40x40x1024xf32>, tensor<1x40x40x1024xf32>) -> tensor<1x40x40x1024xf32>\r\n  %66 = \"tfl.conv_2d\"(%65, %cst_159, %cst_235) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x1024xf32>, tensor<256x1x1x1024xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %67 = \"tfl.conv_2d\"(%65, %cst_160, %cst_236) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<1x40x40x1024xf32>, tensor<2048x1x1x1024xf32>, tensor<2048xf32>) -> tensor<1x20x20x2048xf32>\r\n  %68 = \"tfl.conv_2d\"(%65, %cst_161, %cst_65) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<1x40x40x1024xf32>, tensor<512x1x1x1024xf32>, tensor<512xf32>) -> tensor<1x20x20x512xf32>\r\n  %69 = \"tfl.conv_2d\"(%68, %cst_162, %cst_66) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x512xf32>, tensor<512x3x3x512xf32>, tensor<512xf32>) -> tensor<1x20x20x512xf32>\r\n  %70 = \"tfl.conv_2d\"(%69, %cst_163, %cst_237) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x512xf32>, tensor<2048x1x1x512xf32>, tensor<2048xf32>) -> tensor<1x20x20x2048xf32>\r\n  %71 = \"tfl.add\"(%67, %70) {fused_activation_function = \"RELU6\"} : (tensor<1x20x20x2048xf32>, tensor<1x20x20x2048xf32>) -> tensor<1x20x20x2048xf32>\r\n  %72 = \"tfl.conv_2d\"(%71, %cst_164, %cst_67) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x2048xf32>, tensor<512x1x1x2048xf32>, tensor<512xf32>) -> tensor<1x20x20x512xf32>\r\n  %73 = \"tfl.conv_2d\"(%72, %cst_165, %cst_68) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x512xf32>, tensor<512x3x3x512xf32>, tensor<512xf32>) -> tensor<1x20x20x512xf32>\r\n  %74 = \"tfl.conv_2d\"(%73, %cst_166, %cst_238) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x512xf32>, tensor<2048x1x1x512xf32>, tensor<2048xf32>) -> tensor<1x20x20x2048xf32>\r\n  %75 = \"tfl.add\"(%71, %74) {fused_activation_function = \"RELU6\"} : (tensor<1x20x20x2048xf32>, tensor<1x20x20x2048xf32>) -> tensor<1x20x20x2048xf32>\r\n  %76 = \"tfl.conv_2d\"(%75, %cst_167, %cst_69) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x2048xf32>, tensor<512x1x1x2048xf32>, tensor<512xf32>) -> tensor<1x20x20x512xf32>\r\n  %77 = \"tfl.conv_2d\"(%76, %cst_168, %cst_70) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x512xf32>, tensor<512x3x3x512xf32>, tensor<512xf32>) -> tensor<1x20x20x512xf32>\r\n  %78 = \"tfl.conv_2d\"(%77, %cst_169, %cst_239) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x512xf32>, tensor<2048x1x1x512xf32>, tensor<2048xf32>) -> tensor<1x20x20x2048xf32>\r\n  %79 = \"tfl.add\"(%75, %78) {fused_activation_function = \"RELU6\"} : (tensor<1x20x20x2048xf32>, tensor<1x20x20x2048xf32>) -> tensor<1x20x20x2048xf32>\r\n  %80 = \"tfl.conv_2d\"(%79, %cst_170, %cst_240) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x2048xf32>, tensor<256x1x1x2048xf32>, tensor<256xf32>) -> tensor<1x20x20x256xf32>\r\n  %81 = \"tfl.pack\"(%80, %80) {axis = 3 : i32, values_count = 2 : i32} : (tensor<1x20x20x256xf32>, tensor<1x20x20x256xf32>) -> tensor<1x20x20x2x256xf32>\r\n  %82 = \"tfl.pack\"(%81, %81) {axis = 2 : i32, values_count = 2 : i32} : (tensor<1x20x20x2x256xf32>, tensor<1x20x20x2x256xf32>) -> tensor<1x20x2x20x2x256xf32>\r\n  %83 = \"tfl.reshape\"(%82, %cst_24) : (tensor<1x20x2x20x2x256xf32>, tensor<4xi32>) -> tensor<1x40x40x256xf32>\r\n  %84 = \"tfl.add\"(%83, %66) {fused_activation_function = \"NONE\"} : (tensor<1x40x40x256xf32>, tensor<1x40x40x256xf32>) -> tensor<1x40x40x256xf32>\r\n  %85 = \"tfl.conv_2d\"(%84, %cst_171, %cst_71) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %86 = \"tfl.pack\"(%85, %85) {axis = 3 : i32, values_count = 2 : i32} : (tensor<1x40x40x256xf32>, tensor<1x40x40x256xf32>) -> tensor<1x40x40x2x256xf32>\r\n  %87 = \"tfl.pack\"(%86, %86) {axis = 2 : i32, values_count = 2 : i32} : (tensor<1x40x40x2x256xf32>, tensor<1x40x40x2x256xf32>) -> tensor<1x40x2x40x2x256xf32>\r\n  %88 = \"tfl.reshape\"(%87, %cst_25) : (tensor<1x40x2x40x2x256xf32>, tensor<4xi32>) -> tensor<1x80x80x256xf32>\r\n  %89 = \"tfl.add\"(%88, %40) {fused_activation_function = \"NONE\"} : (tensor<1x80x80x256xf32>, tensor<1x80x80x256xf32>) -> tensor<1x80x80x256xf32>\r\n  %90 = \"tfl.conv_2d\"(%89, %cst_172, %cst_72) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x80x80x256xf32>\r\n  %91 = \"tfl.conv_2d\"(%80, %cst_173, %cst_73) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<1x20x20x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x10x10x256xf32>\r\n  %92 = \"tfl.conv_2d\"(%91, %cst_174, %cst_74) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 2 : i32, stride_w = 2 : i32} : (tensor<1x10x10x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x5x5x256xf32>\r\n  %93 = \"tfl.conv_2d\"(%90, %cst_175, %cst_75) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x80x80x256xf32>\r\n  %94 = \"tfl.conv_2d\"(%85, %cst_176, %cst_76) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %95 = \"tfl.conv_2d\"(%80, %cst_177, %cst_77) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x20x20x256xf32>\r\n  %96 = \"tfl.conv_2d\"(%91, %cst_178, %cst_78) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x10x10x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x10x10x256xf32>\r\n  %97 = \"tfl.conv_2d\"(%92, %cst_179, %cst_79) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x5x5x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x5x5x256xf32>\r\n  %98 = \"tfl.conv_2d\"(%93, %cst_180, %cst_80) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x80x80x256xf32>\r\n  %99 = \"tfl.conv_2d\"(%94, %cst_181, %cst_81) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %100 = \"tfl.conv_2d\"(%95, %cst_182, %cst_82) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x20x20x256xf32>\r\n  %101 = \"tfl.conv_2d\"(%96, %cst_183, %cst_83) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x10x10x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x10x10x256xf32>\r\n  %102 = \"tfl.conv_2d\"(%97, %cst_184, %cst_84) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x5x5x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x5x5x256xf32>\r\n  %103 = \"tfl.conv_2d\"(%98, %cst_185, %cst_85) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x80x80x256xf32>\r\n  %104 = \"tfl.conv_2d\"(%99, %cst_186, %cst_86) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %105 = \"tfl.conv_2d\"(%100, %cst_187, %cst_87) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x20x20x256xf32>\r\n  %106 = \"tfl.conv_2d\"(%101, %cst_188, %cst_88) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x10x10x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x10x10x256xf32>\r\n  %107 = \"tfl.conv_2d\"(%102, %cst_189, %cst_89) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x5x5x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x5x5x256xf32>\r\n  %108 = \"tfl.conv_2d\"(%103, %cst_190, %cst_90) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x80x80x256xf32>\r\n  %109 = \"tfl.conv_2d\"(%104, %cst_191, %cst_91) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %110 = \"tfl.conv_2d\"(%105, %cst_192, %cst_92) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x20x20x256xf32>\r\n  %111 = \"tfl.conv_2d\"(%106, %cst_193, %cst_93) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x10x10x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x10x10x256xf32>\r\n  %112 = \"tfl.conv_2d\"(%107, %cst_194, %cst_94) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x5x5x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x5x5x256xf32>\r\n  %113 = \"tfl.conv_2d\"(%90, %cst_195, %cst_95) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x80x80x256xf32>\r\n  %114 = \"tfl.conv_2d\"(%85, %cst_196, %cst_96) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %115 = \"tfl.conv_2d\"(%80, %cst_197, %cst_97) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x20x20x256xf32>\r\n  %116 = \"tfl.conv_2d\"(%91, %cst_198, %cst_98) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x10x10x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x10x10x256xf32>\r\n  %117 = \"tfl.conv_2d\"(%92, %cst_199, %cst_99) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x5x5x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x5x5x256xf32>\r\n  %118 = \"tfl.conv_2d\"(%113, %cst_200, %cst_100) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x80x80x256xf32>\r\n  %119 = \"tfl.conv_2d\"(%114, %cst_201, %cst_101) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %120 = \"tfl.conv_2d\"(%115, %cst_202, %cst_102) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x20x20x256xf32>\r\n  %121 = \"tfl.conv_2d\"(%116, %cst_203, %cst_103) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x10x10x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x10x10x256xf32>\r\n  %122 = \"tfl.conv_2d\"(%117, %cst_204, %cst_104) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x5x5x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x5x5x256xf32>\r\n  %123 = \"tfl.conv_2d\"(%118, %cst_205, %cst_105) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x80x80x256xf32>\r\n  %124 = \"tfl.conv_2d\"(%119, %cst_206, %cst_106) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %125 = \"tfl.conv_2d\"(%120, %cst_207, %cst_107) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x20x20x256xf32>\r\n  %126 = \"tfl.conv_2d\"(%121, %cst_208, %cst_108) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x10x10x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x10x10x256xf32>\r\n  %127 = \"tfl.conv_2d\"(%122, %cst_209, %cst_109) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x5x5x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x5x5x256xf32>\r\n  %128 = \"tfl.conv_2d\"(%123, %cst_210, %cst_110) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x80x80x256xf32>\r\n  %129 = \"tfl.conv_2d\"(%124, %cst_211, %cst_111) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x40x40x256xf32>\r\n  %130 = \"tfl.conv_2d\"(%125, %cst_212, %cst_112) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x20x20x256xf32>\r\n  %131 = \"tfl.conv_2d\"(%126, %cst_213, %cst_113) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x10x10x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x10x10x256xf32>\r\n  %132 = \"tfl.conv_2d\"(%127, %cst_214, %cst_114) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"RELU6\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x5x5x256xf32>, tensor<256x3x3x256xf32>, tensor<256xf32>) -> tensor<1x5x5x256xf32>\r\n  %133 = \"tfl.conv_2d\"(%108, %cst_215, %cst_241) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x256xf32>, tensor<24x3x3x256xf32>, tensor<24xf32>) -> tensor<1x80x80x24xf32>\r\n  %134 = \"tfl.reshape\"(%133, %cst_27) : (tensor<1x80x80x24xf32>, tensor<3xi32>) -> tensor<1x38400x4xf32>\r\n  %135 = \"tfl.conv_2d\"(%109, %cst_215, %cst_241) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<24x3x3x256xf32>, tensor<24xf32>) -> tensor<1x40x40x24xf32>\r\n  %136 = \"tfl.reshape\"(%135, %cst_27) : (tensor<1x40x40x24xf32>, tensor<3xi32>) -> tensor<1x9600x4xf32>\r\n  %137 = \"tfl.conv_2d\"(%110, %cst_215, %cst_241) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x256xf32>, tensor<24x3x3x256xf32>, tensor<24xf32>) -> tensor<1x20x20x24xf32>\r\n  %138 = \"tfl.reshape\"(%137, %cst_27) : (tensor<1x20x20x24xf32>, tensor<3xi32>) -> tensor<1x2400x4xf32>\r\n  %139 = \"tfl.conv_2d\"(%111, %cst_215, %cst_241) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x10x10x256xf32>, tensor<24x3x3x256xf32>, tensor<24xf32>) -> tensor<1x10x10x24xf32>\r\n  %140 = \"tfl.reshape\"(%139, %cst_27) : (tensor<1x10x10x24xf32>, tensor<3xi32>) -> tensor<1x600x4xf32>\r\n  %141 = \"tfl.conv_2d\"(%112, %cst_215, %cst_241) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x5x5x256xf32>, tensor<24x3x3x256xf32>, tensor<24xf32>) -> tensor<1x5x5x24xf32>\r\n  %142 = \"tfl.reshape\"(%141, %cst_27) : (tensor<1x5x5x24xf32>, tensor<3xi32>) -> tensor<1x150x4xf32>\r\n  %143 = \"tfl.concatenation\"(%134, %136, %138, %140, %142) {axis = 1 : i32, fused_activation_function = \"NONE\"} : (tensor<1x38400x4xf32>, tensor<1x9600x4xf32>, tensor<1x2400x4xf32>, tensor<1x600x4xf32>, tensor<1x150x4xf32>) -> tensor<1x51150x4xf32>\r\n  %144 = \"tfl.reshape\"(%143, %cst_17) : (tensor<1x51150x4xf32>, tensor<2xi32>) -> tensor<51150x4xf32>\r\n  %145 = \"tfl.transpose\"(%144, %cst_15) : (tensor<51150x4xf32>, tensor<2xi32>) -> tensor<4x51150xf32>\r\n  %146:4 = \"tfl.unpack\"(%145) {axis = 0 : i32, num = 4 : i32} : (tensor<4x51150xf32>) -> (tensor<51150xf32>, tensor<51150xf32>, tensor<51150xf32>, tensor<51150xf32>)\r\n  %147 = \"tfl.mul\"(%146#0, %cst_31) {fused_activation_function = \"NONE\"} : (tensor<51150xf32>, tensor<f32>) -> tensor<51150xf32>\r\n  %148 = \"tfl.mul\"(%147, %cst_34) {fused_activation_function = \"NONE\"} : (tensor<51150xf32>, tensor<51150xf32>) -> tensor<51150xf32>\r\n  %149 = \"tfl.add\"(%148, %cst_35) {fused_activation_function = \"NONE\"} : (tensor<51150xf32>, tensor<51150xf32>) -> tensor<51150xf32>\r\n  %150 = \"tfl.mul\"(%146#1, %cst_31) {fused_activation_function = \"NONE\"} : (tensor<51150xf32>, tensor<f32>) -> tensor<51150xf32>\r\n  %151 = \"tfl.mul\"(%150, %cst_36) {fused_activation_function = \"NONE\"} : (tensor<51150xf32>, tensor<51150xf32>) -> tensor<51150xf32>\r\n  %152 = \"tfl.add\"(%151, %cst_37) {fused_activation_function = \"NONE\"} : (tensor<51150xf32>, tensor<51150xf32>) -> tensor<51150xf32>\r\n  %153 = \"tfl.mul\"(%146#2, %cst_32) {fused_activation_function = \"NONE\"} : (tensor<51150xf32>, tensor<f32>) -> tensor<51150xf32>\r\n  %154 = \"tfl.exp\"(%153) : (tensor<51150xf32>) -> tensor<51150xf32>\r\n  %155 = \"tfl.mul\"(%154, %cst_34) {fused_activation_function = \"NONE\"} : (tensor<51150xf32>, tensor<51150xf32>) -> tensor<51150xf32>\r\n  %156 = \"tfl.mul\"(%155, %cst_33) {fused_activation_function = \"NONE\"} : (tensor<51150xf32>, tensor<f32>) -> tensor<51150xf32>\r\n  %157 = \"tfl.sub\"(%149, %156) {fused_activation_function = \"NONE\"} : (tensor<51150xf32>, tensor<51150xf32>) -> tensor<51150xf32>\r\n  %158 = \"tfl.add\"(%149, %156) {fused_activation_function = \"NONE\"} : (tensor<51150xf32>, tensor<51150xf32>) -> tensor<51150xf32>\r\n  %159 = \"tfl.mul\"(%146#3, %cst_32) {fused_activation_function = \"NONE\"} : (tensor<51150xf32>, tensor<f32>) -> tensor<51150xf32>\r\n  %160 = \"tfl.exp\"(%159) : (tensor<51150xf32>) -> tensor<51150xf32>\r\n  %161 = \"tfl.mul\"(%160, %cst_36) {fused_activation_function = \"NONE\"} : (tensor<51150xf32>, tensor<51150xf32>) -> tensor<51150xf32>\r\n  %162 = \"tfl.mul\"(%161, %cst_33) {fused_activation_function = \"NONE\"} : (tensor<51150xf32>, tensor<f32>) -> tensor<51150xf32>\r\n  %163 = \"tfl.sub\"(%152, %162) {fused_activation_function = \"NONE\"} : (tensor<51150xf32>, tensor<51150xf32>) -> tensor<51150xf32>\r\n  %164 = \"tfl.add\"(%152, %162) {fused_activation_function = \"NONE\"} : (tensor<51150xf32>, tensor<51150xf32>) -> tensor<51150xf32>\r\n  %165 = \"tfl.pack\"(%157, %163, %158, %164) {axis = 0 : i32, values_count = 4 : i32} : (tensor<51150xf32>, tensor<51150xf32>, tensor<51150xf32>, tensor<51150xf32>) -> tensor<4x51150xf32>\r\n  %166 = \"tfl.transpose\"(%165, %cst_15) : (tensor<4x51150xf32>, tensor<2xi32>) -> tensor<51150x4xf32>\r\n  %167 = \"tfl.reshape\"(%166, %cst_243) : (tensor<51150x4xf32>, tensor<3xi32>) -> tensor<1x51150x4xf32>\r\n  %168 = \"tfl.reshape\"(%166, %cst_242) : (tensor<51150x4xf32>, tensor<4xi32>) -> tensor<1x51150x1x4xf32>\r\n  %169 = \"tfl.unpack\"(%168) {axis = 0 : i32, num = 1 : i32} : (tensor<1x51150x1x4xf32>) -> tensor<51150x1x4xf32>\r\n  %170 = \"tfl.slice\"(%169, %cst_8, %cst_10) : (tensor<51150x1x4xf32>, tensor<3xi32>, tensor<3xi32>) -> tensor<51150x1x4xf32>\r\n  %171 = \"tfl.unpack\"(%170) {axis = 1 : i32, num = 1 : i32} : (tensor<51150x1x4xf32>) -> tensor<51150x4xf32>\r\n  %172 = \"tfl.conv_2d\"(%128, %cst_216, %cst_244) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x80x80x256xf32>, tensor<12x3x3x256xf32>, tensor<12xf32>) -> tensor<1x80x80x12xf32>\r\n  %173 = \"tfl.reshape\"(%172, %cst_28) : (tensor<1x80x80x12xf32>, tensor<3xi32>) -> tensor<1x38400x2xf32>\r\n  %174 = \"tfl.conv_2d\"(%129, %cst_216, %cst_244) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x40x40x256xf32>, tensor<12x3x3x256xf32>, tensor<12xf32>) -> tensor<1x40x40x12xf32>\r\n  %175 = \"tfl.reshape\"(%174, %cst_28) : (tensor<1x40x40x12xf32>, tensor<3xi32>) -> tensor<1x9600x2xf32>\r\n  %176 = \"tfl.conv_2d\"(%130, %cst_216, %cst_244) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x20x20x256xf32>, tensor<12x3x3x256xf32>, tensor<12xf32>) -> tensor<1x20x20x12xf32>\r\n  %177 = \"tfl.reshape\"(%176, %cst_28) : (tensor<1x20x20x12xf32>, tensor<3xi32>) -> tensor<1x2400x2xf32>\r\n  %178 = \"tfl.conv_2d\"(%131, %cst_216, %cst_244) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x10x10x256xf32>, tensor<12x3x3x256xf32>, tensor<12xf32>) -> tensor<1x10x10x12xf32>\r\n  %179 = \"tfl.reshape\"(%178, %cst_28) : (tensor<1x10x10x12xf32>, tensor<3xi32>) -> tensor<1x600x2xf32>\r\n  %180 = \"tfl.conv_2d\"(%132, %cst_216, %cst_244) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"SAME\", stride_h = 1 : i32, stride_w = 1 : i32} : (tensor<1x5x5x256xf32>, tensor<12x3x3x256xf32>, tensor<12xf32>) -> tensor<1x5x5x12xf32>\r\n  %181 = \"tfl.reshape\"(%180, %cst_28) : (tensor<1x5x5x12xf32>, tensor<3xi32>) -> tensor<1x150x2xf32>\r\n  %182 = \"tfl.concatenation\"(%173, %175, %177, %179, %181) {axis = 1 : i32, fused_activation_function = \"NONE\"} : (tensor<1x38400x2xf32>, tensor<1x9600x2xf32>, tensor<1x2400x2xf32>, tensor<1x600x2xf32>, tensor<1x150x2xf32>) -> tensor<1x51150x2xf32>\r\n  %183 = \"tfl.logistic\"(%182) : (tensor<1x51150x2xf32>) -> tensor<1x51150x2xf32>\r\n  %184 = \"tfl.unpack\"(%183) {axis = 0 : i32, num = 1 : i32} : (tensor<1x51150x2xf32>) -> tensor<51150x2xf32>\r\n  %185 = \"tfl.slice\"(%184, %cst_9, %cst_11) : (tensor<51150x2xf32>, tensor<2xi32>, tensor<2xi32>) -> tensor<51150x2xf32>\r\n  %186 = \"tfl.slice\"(%183, %cst_18, %cst_19) : (tensor<1x51150x2xf32>, tensor<3xi32>, tensor<3xi32>) -> tensor<1x51150x1xf32>\r\n  %187 = \"tfl.unpack\"(%186) {axis = 0 : i32, num = 1 : i32} : (tensor<1x51150x1xf32>) -> tensor<51150x1xf32>\r\n  %188 = \"tfl.slice\"(%187, %cst_9, %cst_11) : (tensor<51150x1xf32>, tensor<2xi32>, tensor<2xi32>) -> tensor<51150x1xf32>\r\n  %189 = \"tfl.slice\"(%188, %cst_9, %cst_2) : (tensor<51150x1xf32>, tensor<2xi32>, tensor<2xi32>) -> tensor<51150x1xf32>\r\n  %190 = \"tfl.reshape\"(%189, %cst_245) : (tensor<51150x1xf32>, tensor<1xi32>) -> tensor<51150xf32>\r\n  %selected_indices, %selected_scores, %valid_outputs = \"tfl.non_max_suppression_v5\"(%171, %190, %cst_7, %cst_0, %cst_1, %cst_14) : (tensor<51150x4xf32>, tensor<51150xf32>, tensor<i32>, tensor<f32>, tensor<f32>, tensor<f32>) -> (tensor<?xi32>, tensor<?xf32>, tensor<i32>)\r\n  %191 = \"tfl.shape\"(%selected_indices) : (tensor<?xi32>) -> tensor<1xi32>\r\n  %192 = \"tfl.strided_slice\"(%191, %cst_246, %cst_248, %cst_248) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<1xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %193 = \"tfl.less\"(%cst_3, %192) : (tensor<100xi32>, tensor<i32>) -> tensor<100xi1>\r\n  %194 = \"tfl.sub\"(%cst_7, %192) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %195 = \"tfl.reshape\"(%194, %cst_245) : (tensor<i32>, tensor<1xi32>) -> tensor<1xi32>\r\n  %196 = \"tfl.fill\"(%195, %cst_21) : (tensor<1xi32>, tensor<i32>) -> tensor<?xi32>\r\n  %197 = \"tfl.fill\"(%195, %cst_14) : (tensor<1xi32>, tensor<f32>) -> tensor<?xf32>\r\n  %198 = \"tfl.concatenation\"(%selected_indices, %196) {axis = 0 : i32, fused_activation_function = \"NONE\"} : (tensor<?xi32>, tensor<?xi32>) -> tensor<?xi32>\r\n  %199 = \"tfl.gather\"(%cst_20, %198) {axis = 0 : i32} : (tensor<51150xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %200 = \"tfl.gather\"(%185, %198) {axis = 0 : i32} : (tensor<51150x2xf32>, tensor<?xi32>) -> tensor<?x2xf32>\r\n  %201 = \"tfl.gather\"(%171, %198) {axis = 0 : i32} : (tensor<51150x4xf32>, tensor<?xi32>) -> tensor<?x4xf32>\r\n  %202 = \"tfl.shape\"(%201) : (tensor<?x4xf32>) -> tensor<2xi32>\r\n  %203 = \"tfl.strided_slice\"(%202, %cst_246, %cst_248, %cst_248) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %204 = \"tfl.equal\"(%203, %cst_7) : (tensor<i32>, tensor<i32>) -> tensor<i1>\r\n  %205 = \"tfl.concatenation\"(%selected_scores, %197) {axis = -1 : i32, fused_activation_function = \"NONE\"} : (tensor<?xf32>, tensor<?xf32>) -> tensor<?xf32>\r\n  %206 = \"tfl.select\"(%193, %205, %cst_4) : (tensor<100xi1>, tensor<?xf32>, tensor<100xf32>) -> tensor<100xf32>\r\n  %values, %indices = \"tfl.topk_v2\"(%206, %203) : (tensor<100xf32>, tensor<i32>) -> (tensor<?xf32>, tensor<?xi32>)\r\n  %207 = \"tfl.gather\"(%206, %indices) {axis = 0 : i32} : (tensor<100xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %208 = \"tfl.gather\"(%199, %indices) {axis = 0 : i32} : (tensor<?xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %209 = \"tfl.gather\"(%200, %indices) {axis = 0 : i32} : (tensor<?x2xf32>, tensor<?xi32>) -> tensor<?x2xf32>\r\n  %210 = \"tfl.gather\"(%cst_5, %indices) {axis = 0 : i32} : (tensor<100xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %211 = \"tfl.gather\"(%201, %indices) {axis = 0 : i32} : (tensor<?x4xf32>, tensor<?xi32>) -> tensor<?x4xf32>\r\n  %212:4 = \"tfl.split\"(%cst_30, %211) {num_splits = 4 : i32} : (tensor<i32>, tensor<?x4xf32>) -> (tensor<?x1xf32>, tensor<?x1xf32>, tensor<?x1xf32>, tensor<?x1xf32>)\r\n  %213 = \"tfl.minimum\"(%212#0, %cst_29) : (tensor<?x1xf32>, tensor<f32>) -> tensor<?x1xf32>\r\n  %214 = \"tfl.relu\"(%213) : (tensor<?x1xf32>) -> tensor<?x1xf32>\r\n  %215 = \"tfl.minimum\"(%212#2, %cst_29) : (tensor<?x1xf32>, tensor<f32>) -> tensor<?x1xf32>\r\n  %216 = \"tfl.relu\"(%215) : (tensor<?x1xf32>) -> tensor<?x1xf32>\r\n  %217 = \"tfl.minimum\"(%212#1, %cst_29) : (tensor<?x1xf32>, tensor<f32>) -> tensor<?x1xf32>\r\n  %218 = \"tfl.relu\"(%217) : (tensor<?x1xf32>) -> tensor<?x1xf32>\r\n  %219 = \"tfl.minimum\"(%212#3, %cst_29) : (tensor<?x1xf32>, tensor<f32>) -> tensor<?x1xf32>\r\n  %220 = \"tfl.relu\"(%219) : (tensor<?x1xf32>) -> tensor<?x1xf32>\r\n  %221 = \"tfl.concatenation\"(%214, %218, %216, %220) {axis = 1 : i32, fused_activation_function = \"NONE\"} : (tensor<?x1xf32>, tensor<?x1xf32>, tensor<?x1xf32>, tensor<?x1xf32>) -> tensor<?x4xf32>\r\n  %222:4 = \"tfl.split\"(%cst_30, %221) {num_splits = 4 : i32} : (tensor<i32>, tensor<?x4xf32>) -> (tensor<?x1xf32>, tensor<?x1xf32>, tensor<?x1xf32>, tensor<?x1xf32>)\r\n  %223 = \"tfl.sub\"(%222#2, %222#0) {fused_activation_function = \"NONE\"} : (tensor<?x1xf32>, tensor<?x1xf32>) -> tensor<?x1xf32>\r\n  %224 = \"tfl.sub\"(%222#3, %222#1) {fused_activation_function = \"NONE\"} : (tensor<?x1xf32>, tensor<?x1xf32>) -> tensor<?x1xf32>\r\n  %225 = \"tfl.mul\"(%223, %224) {fused_activation_function = \"NONE\"} : (tensor<?x1xf32>, tensor<?x1xf32>) -> tensor<?x1xf32>\r\n  %226 = \"tfl.greater\"(%225, %cst_14) : (tensor<?x1xf32>, tensor<f32>) -> tensor<?x1xi1>\r\n  %227 = \"tfl.reshape\"(%226, %cst_245) : (tensor<?x1xi1>, tensor<1xi32>) -> tensor<?xi1>\r\n  %228 = \"tfl.where\"(%227) : (tensor<?xi1>) -> tensor<?x1xi64>\r\n  %229 = \"tfl.reshape\"(%228, %cst_245) : (tensor<?x1xi64>, tensor<1xi32>) -> tensor<?xi64>\r\n  %230 = \"tfl.cast\"(%229) : (tensor<?xi64>) -> tensor<?xi32>\r\n  %231 = \"tfl.gather\"(%207, %230) {axis = 0 : i32} : (tensor<?xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %232 = \"tfl.gather\"(%208, %230) {axis = 0 : i32} : (tensor<?xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %233 = \"tfl.gather\"(%209, %230) {axis = 0 : i32} : (tensor<?x2xf32>, tensor<?xi32>) -> tensor<?x2xf32>\r\n  %234 = \"tfl.gather\"(%210, %230) {axis = 0 : i32} : (tensor<?xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %235 = \"tfl.gather\"(%221, %230) {axis = 0 : i32} : (tensor<?x4xf32>, tensor<?xi32>) -> tensor<?x4xf32>\r\n  %236:4 = \"tfl.split\"(%cst_30, %235) {num_splits = 4 : i32} : (tensor<i32>, tensor<?x4xf32>) -> (tensor<?x1xf32>, tensor<?x1xf32>, tensor<?x1xf32>, tensor<?x1xf32>)\r\n  %237 = \"tfl.sub\"(%236#2, %236#0) {fused_activation_function = \"NONE\"} : (tensor<?x1xf32>, tensor<?x1xf32>) -> tensor<?x1xf32>\r\n  %238 = \"tfl.sub\"(%236#3, %236#1) {fused_activation_function = \"NONE\"} : (tensor<?x1xf32>, tensor<?x1xf32>) -> tensor<?x1xf32>\r\n  %239 = \"tfl.mul\"(%237, %238) {fused_activation_function = \"NONE\"} : (tensor<?x1xf32>, tensor<?x1xf32>) -> tensor<?x1xf32>\r\n  %240 = \"tfl.reshape\"(%239, %cst_245) : (tensor<?x1xf32>, tensor<1xi32>) -> tensor<?xf32>\r\n  %241 = \"tfl.cast\"(%240) : (tensor<?xf32>) -> tensor<?xi1>\r\n  %242 = \"tfl.shape\"(%235) : (tensor<?x4xf32>) -> tensor<2xi32>\r\n  %243 = \"tfl.strided_slice\"(%242, %cst_246, %cst_248, %cst_248) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %244 = \"tfl.reshape\"(%243, %cst_245) : (tensor<i32>, tensor<1xi32>) -> tensor<1xi32>\r\n  %245 = \"tfl.fill\"(%244, %cst_29) : (tensor<1xi32>, tensor<f32>) -> tensor<?xf32>\r\n  %246 = \"tfl.mul\"(%245, %cst) {fused_activation_function = \"NONE\"} : (tensor<?xf32>, tensor<f32>) -> tensor<?xf32>\r\n  %247 = \"tfl.select\"(%241, %231, %246) : (tensor<?xi1>, tensor<?xf32>, tensor<?xf32>) -> tensor<?xf32>\r\n  %248 = \"tfl.greater_equal\"(%247, %cst_14) : (tensor<?xf32>, tensor<f32>) -> tensor<?xi1>\r\n  %249 = \"tfl.cast\"(%248) : (tensor<?xi1>) -> tensor<?xi32>\r\n  %250 = \"tfl.sum\"(%249, %cst_246) {keep_dims = false} : (tensor<?xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %251 = \"tf.Size\"(%247) {device = \"\"} : (tensor<?xf32>) -> tensor<i32>\r\n  %252 = \"tfl.equal\"(%243, %251) : (tensor<i32>, tensor<i32>) -> tensor<i1>\r\n  %values_249, %indices_250 = \"tfl.topk_v2\"(%247, %243) : (tensor<?xf32>, tensor<i32>) -> (tensor<?xf32>, tensor<?xi32>)\r\n  %253 = \"tfl.gather\"(%247, %indices_250) {axis = 0 : i32} : (tensor<?xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %254 = \"tfl.gather\"(%232, %indices_250) {axis = 0 : i32} : (tensor<?xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %255 = \"tfl.gather\"(%233, %indices_250) {axis = 0 : i32} : (tensor<?x2xf32>, tensor<?xi32>) -> tensor<?x2xf32>\r\n  %256 = \"tfl.gather\"(%234, %indices_250) {axis = 0 : i32} : (tensor<?xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %257 = \"tfl.gather\"(%235, %indices_250) {axis = 0 : i32} : (tensor<?x4xf32>, tensor<?xi32>) -> tensor<?x4xf32>\r\n  %258 = \"tfl.sub\"(%257, %cst_13) {fused_activation_function = \"NONE\"} : (tensor<?x4xf32>, tensor<4xf32>) -> tensor<?x4xf32>\r\n  %259:4 = \"tfl.split\"(%cst_30, %258) {num_splits = 4 : i32} : (tensor<i32>, tensor<?x4xf32>) -> (tensor<?x1xf32>, tensor<?x1xf32>, tensor<?x1xf32>, tensor<?x1xf32>)\r\n  %260 = \"tfl.concatenation\"(%259#0, %259#1, %259#2, %259#3) {axis = 1 : i32, fused_activation_function = \"NONE\"} : (tensor<?x1xf32>, tensor<?x1xf32>, tensor<?x1xf32>, tensor<?x1xf32>) -> tensor<?x4xf32>\r\n  %261 = \"tfl.shape\"(%260) : (tensor<?x4xf32>) -> tensor<2xi32>\r\n  %262 = \"tfl.strided_slice\"(%261, %cst_246, %cst_248, %cst_248) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %263 = \"tfl.minimum\"(%262, %cst_7) : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %264 = \"tfl.greater\"(%263, %250) : (tensor<i32>, tensor<i32>) -> tensor<i1>\r\n  %265 = \"tfl.select\"(%264, %250, %263) : (tensor<i1>, tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %266 = \"tfl.range\"(%cst_21, %265, %cst_30) : (tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<?xi32>\r\n  %267 = \"tfl.pack\"(%265) {axis = 0 : i32, values_count = 1 : i32} : (tensor<i32>) -> tensor<1xi32>\r\n  %268 = \"tfl.cast\"(%267) : (tensor<1xi32>) -> tensor<1xf32>\r\n  %269 = \"tfl.range\"(%cst_21, %263, %cst_30) : (tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<?xi32>\r\n  %270 = \"tfl.gather\"(%253, %269) {axis = 0 : i32} : (tensor<?xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %271 = \"tfl.gather\"(%270, %266) {axis = 0 : i32} : (tensor<?xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %272 = \"tfl.shape\"(%271) : (tensor<?xf32>) -> tensor<1xi32>\r\n  %273 = \"tfl.strided_slice\"(%272, %cst_246, %cst_248, %cst_248) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<1xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %274 = \"tfl.sub\"(%273, %cst_7) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %275 = \"tfl.greater\"(%274, %cst_21) : (tensor<i32>, tensor<i32>) -> tensor<i1>\r\n  %276 = \"tfl.select\"(%275, %cst_7, %cst_12) : (tensor<i1>, tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %277 = \"tfl.pack\"(%276) {axis = 0 : i32, values_count = 1 : i32} : (tensor<i32>) -> tensor<1xi32>\r\n  %278 = \"tfl.slice\"(%271, %cst_246, %277) : (tensor<?xf32>, tensor<1xi32>, tensor<1xi32>) -> tensor<?xf32>\r\n  %279 = \"tfl.shape\"(%278) : (tensor<?xf32>) -> tensor<1xi32>\r\n  %280 = \"tfl.strided_slice\"(%279, %cst_246, %cst_248, %cst_248) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<1xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %281 = \"tfl.sub\"(%cst_7, %280) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %282 = \"tfl.pack\"(%281) {axis = 0 : i32, values_count = 1 : i32} : (tensor<i32>) -> tensor<1xi32>\r\n  %283 = \"tfl.pack\"(%cst_246, %282) {axis = 1 : i32, values_count = 2 : i32} : (tensor<1xi32>, tensor<1xi32>) -> tensor<1x2xi32>\r\n  %284 = \"tfl.pad\"(%278, %283) : (tensor<?xf32>, tensor<1x2xi32>) -> tensor<?xf32>\r\n  %285 = \"tfl.pack\"(%284) {axis = 0 : i32, values_count = 1 : i32} : (tensor<?xf32>) -> tensor<1x?xf32>\r\n  %286 = \"tfl.gather\"(%254, %269) {axis = 0 : i32} : (tensor<?xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %287 = \"tfl.gather\"(%286, %266) {axis = 0 : i32} : (tensor<?xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %288 = \"tfl.shape\"(%287) : (tensor<?xf32>) -> tensor<1xi32>\r\n  %289 = \"tfl.strided_slice\"(%288, %cst_246, %cst_248, %cst_248) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<1xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %290 = \"tfl.sub\"(%289, %cst_7) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %291 = \"tfl.greater\"(%290, %cst_21) : (tensor<i32>, tensor<i32>) -> tensor<i1>\r\n  %292 = \"tfl.select\"(%291, %cst_7, %cst_12) : (tensor<i1>, tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %293 = \"tfl.pack\"(%292) {axis = 0 : i32, values_count = 1 : i32} : (tensor<i32>) -> tensor<1xi32>\r\n  %294 = \"tfl.slice\"(%287, %cst_246, %293) : (tensor<?xf32>, tensor<1xi32>, tensor<1xi32>) -> tensor<?xf32>\r\n  %295 = \"tfl.shape\"(%294) : (tensor<?xf32>) -> tensor<1xi32>\r\n  %296 = \"tfl.strided_slice\"(%295, %cst_246, %cst_248, %cst_248) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<1xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %297 = \"tfl.sub\"(%cst_7, %296) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %298 = \"tfl.pack\"(%297) {axis = 0 : i32, values_count = 1 : i32} : (tensor<i32>) -> tensor<1xi32>\r\n  %299 = \"tfl.pack\"(%cst_246, %298) {axis = 1 : i32, values_count = 2 : i32} : (tensor<1xi32>, tensor<1xi32>) -> tensor<1x2xi32>\r\n  %300 = \"tfl.pad\"(%294, %299) : (tensor<?xf32>, tensor<1x2xi32>) -> tensor<?xf32>\r\n  %301 = \"tfl.pack\"(%300) {axis = 0 : i32, values_count = 1 : i32} : (tensor<?xf32>) -> tensor<1x?xf32>\r\n  %302 = \"tfl.cast\"(%301) : (tensor<1x?xf32>) -> tensor<1x?xi32>\r\n  %303 = \"tfl.cast\"(%302) : (tensor<1x?xi32>) -> tensor<1x?xf32>\r\n  %304 = \"tfl.gather\"(%255, %269) {axis = 0 : i32} : (tensor<?x2xf32>, tensor<?xi32>) -> tensor<?x2xf32>\r\n  %305 = \"tfl.gather\"(%304, %266) {axis = 0 : i32} : (tensor<?x2xf32>, tensor<?xi32>) -> tensor<?x2xf32>\r\n  %306 = \"tfl.shape\"(%305) : (tensor<?x2xf32>) -> tensor<2xi32>\r\n  %307 = \"tfl.strided_slice\"(%306, %cst_246, %cst_248, %cst_248) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %308 = \"tfl.sub\"(%307, %cst_7) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %309 = \"tfl.greater\"(%308, %cst_21) : (tensor<i32>, tensor<i32>) -> tensor<i1>\r\n  %310 = \"tfl.select\"(%309, %cst_7, %cst_12) : (tensor<i1>, tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %311 = \"tfl.strided_slice\"(%306, %cst_248, %cst_247, %cst_248) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %312 = \"tfl.sub\"(%311, %cst_16) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %313 = \"tfl.greater\"(%312, %cst_21) : (tensor<i32>, tensor<i32>) -> tensor<i1>\r\n  %314 = \"tfl.select\"(%313, %cst_16, %cst_12) : (tensor<i1>, tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %315 = \"tfl.pack\"(%310, %314) {axis = 0 : i32, values_count = 2 : i32} : (tensor<i32>, tensor<i32>) -> tensor<2xi32>\r\n  %316 = \"tfl.slice\"(%305, %cst_9, %315) : (tensor<?x2xf32>, tensor<2xi32>, tensor<2xi32>) -> tensor<?x?xf32>\r\n  %317 = \"tfl.shape\"(%316) : (tensor<?x?xf32>) -> tensor<2xi32>\r\n  %318 = \"tfl.strided_slice\"(%317, %cst_246, %cst_248, %cst_248) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %319 = \"tfl.sub\"(%cst_7, %318) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %320 = \"tfl.strided_slice\"(%317, %cst_248, %cst_247, %cst_248) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %321 = \"tfl.sub\"(%cst_16, %320) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %322 = \"tfl.pack\"(%319, %321) {axis = 0 : i32, values_count = 2 : i32} : (tensor<i32>, tensor<i32>) -> tensor<2xi32>\r\n  %323 = \"tfl.pack\"(%cst_9, %322) {axis = 1 : i32, values_count = 2 : i32} : (tensor<2xi32>, tensor<2xi32>) -> tensor<2x2xi32>\r\n  %324 = \"tfl.pad\"(%316, %323) : (tensor<?x?xf32>, tensor<2x2xi32>) -> tensor<?x?xf32>\r\n  %325 = \"tfl.pack\"(%324) {axis = 0 : i32, values_count = 1 : i32} : (tensor<?x?xf32>) -> tensor<1x?x?xf32>\r\n  %326 = \"tfl.gather\"(%256, %269) {axis = 0 : i32} : (tensor<?xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %327 = \"tfl.gather\"(%326, %266) {axis = 0 : i32} : (tensor<?xf32>, tensor<?xi32>) -> tensor<?xf32>\r\n  %328 = \"tfl.shape\"(%327) : (tensor<?xf32>) -> tensor<1xi32>\r\n  %329 = \"tfl.strided_slice\"(%328, %cst_246, %cst_248, %cst_248) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<1xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %330 = \"tfl.sub\"(%329, %cst_7) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %331 = \"tfl.greater\"(%330, %cst_21) : (tensor<i32>, tensor<i32>) -> tensor<i1>\r\n  %332 = \"tfl.select\"(%331, %cst_7, %cst_12) : (tensor<i1>, tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %333 = \"tfl.pack\"(%332) {axis = 0 : i32, values_count = 1 : i32} : (tensor<i32>) -> tensor<1xi32>\r\n  %334 = \"tfl.slice\"(%327, %cst_246, %333) : (tensor<?xf32>, tensor<1xi32>, tensor<1xi32>) -> tensor<?xf32>\r\n  %335 = \"tfl.shape\"(%334) : (tensor<?xf32>) -> tensor<1xi32>\r\n  %336 = \"tfl.strided_slice\"(%335, %cst_246, %cst_248, %cst_248) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<1xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %337 = \"tfl.sub\"(%cst_7, %336) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %338 = \"tfl.pack\"(%337) {axis = 0 : i32, values_count = 1 : i32} : (tensor<i32>) -> tensor<1xi32>\r\n  %339 = \"tfl.pack\"(%cst_246, %338) {axis = 1 : i32, values_count = 2 : i32} : (tensor<1xi32>, tensor<1xi32>) -> tensor<1x2xi32>\r\n  %340 = \"tfl.pad\"(%334, %339) : (tensor<?xf32>, tensor<1x2xi32>) -> tensor<?xf32>\r\n  %341 = \"tfl.pack\"(%340) {axis = 0 : i32, values_count = 1 : i32} : (tensor<?xf32>) -> tensor<1x?xf32>\r\n  %342 = \"tfl.add\"(%341, %cst_29) {fused_activation_function = \"NONE\"} : (tensor<1x?xf32>, tensor<f32>) -> tensor<1x?xf32>\r\n  %343 = \"tfl.gather\"(%260, %269) {axis = 0 : i32} : (tensor<?x4xf32>, tensor<?xi32>) -> tensor<?x4xf32>\r\n  %344 = \"tfl.gather\"(%343, %266) {axis = 0 : i32} : (tensor<?x4xf32>, tensor<?xi32>) -> tensor<?x4xf32>\r\n  %345 = \"tfl.shape\"(%344) : (tensor<?x4xf32>) -> tensor<2xi32>\r\n  %346 = \"tfl.strided_slice\"(%345, %cst_246, %cst_248, %cst_248) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %347 = \"tfl.sub\"(%346, %cst_7) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %348 = \"tfl.greater\"(%347, %cst_21) : (tensor<i32>, tensor<i32>) -> tensor<i1>\r\n  %349 = \"tfl.select\"(%348, %cst_7, %cst_12) : (tensor<i1>, tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %350 = \"tfl.strided_slice\"(%345, %cst_248, %cst_247, %cst_248) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %351 = \"tfl.sub\"(%350, %cst_6) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %352 = \"tfl.greater\"(%351, %cst_21) : (tensor<i32>, tensor<i32>) -> tensor<i1>\r\n  %353 = \"tfl.select\"(%352, %cst_6, %cst_12) : (tensor<i1>, tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %354 = \"tfl.pack\"(%349, %353) {axis = 0 : i32, values_count = 2 : i32} : (tensor<i32>, tensor<i32>) -> tensor<2xi32>\r\n  %355 = \"tfl.slice\"(%344, %cst_9, %354) : (tensor<?x4xf32>, tensor<2xi32>, tensor<2xi32>) -> tensor<?x?xf32>\r\n  %356 = \"tfl.shape\"(%355) : (tensor<?x?xf32>) -> tensor<2xi32>\r\n  %357 = \"tfl.strided_slice\"(%356, %cst_246, %cst_248, %cst_248) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %358 = \"tfl.sub\"(%cst_7, %357) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %359 = \"tfl.strided_slice\"(%356, %cst_248, %cst_247, %cst_248) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<2xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %360 = \"tfl.sub\"(%cst_6, %359) {fused_activation_function = \"NONE\"} : (tensor<i32>, tensor<i32>) -> tensor<i32>\r\n  %361 = \"tfl.pack\"(%358, %360) {axis = 0 : i32, values_count = 2 : i32} : (tensor<i32>, tensor<i32>) -> tensor<2xi32>\r\n  %362 = \"tfl.pack\"(%cst_9, %361) {axis = 1 : i32, values_count = 2 : i32} : (tensor<2xi32>, tensor<2xi32>) -> tensor<2x2xi32>\r\n  %363 = \"tfl.pad\"(%355, %362) : (tensor<?x?xf32>, tensor<2x2xi32>) -> tensor<?x?xf32>\r\n  %364 = \"tfl.pack\"(%363) {axis = 0 : i32, values_count = 1 : i32} : (tensor<?x?xf32>) -> tensor<1x?x?xf32>\r\n  \"std.return\"(%268, %364, %342, %183, %285, %167, %325, %303) : (tensor<1xf32>, tensor<1x?x?xf32>, tensor<1x?xf32>, tensor<1x51150x2xf32>, tensor<1x?xf32>, tensor<1x51150x4xf32>, tensor<1x?x?xf32>, tensor<1x?xf32>) -> ()\r\n}) {arg0 = {tf_saved_model.index_path = [\"input_tensor\"]}, result0 = {tf_saved_model.index_path = [\"num_detections\"]}, result1 = {tf_saved_model.index_path = [\"detection_boxes\"]}, result2 = {tf_saved_model.index_path = [\"detection_classes\"]}, result3 = {tf_saved_model.index_path = [\"raw_detection_scores\"]}, result4 = {tf_saved_model.index_path = [\"detection_scores\"]}, result5 = {tf_saved_model.index_path = [\"raw_detection_boxes\"]}, result6 = {tf_saved_model.index_path = [\"detection_multiclass_scores\"]}, result7 = {tf_saved_model.index_path = [\"detection_anchor_indices\"]}, sym_name = \"main\", tf.entry_function = {control_outputs = \"\", inputs = \"serving_default_input_tensor:0\", outputs = \"StatefulPartitionedCall:5,StatefulPartitionedCall:1,StatefulPartitionedCall:2,StatefulPartitionedCall:7,StatefulPartitionedCall:4,StatefulPartitionedCall:6,StatefulPartitionedCall:3,StatefulPartitionedCall:0\"}, tf_saved_model.exported_names = [\"serving_default\"], type = (tensor<1x?x?x3xui8>) -> (tensor<1xf32>, tensor<1x?x?xf32>, tensor<1x?xf32>, tensor<1x51150x2xf32>, tensor<1x?xf32>, tensor<1x51150x4xf32>, tensor<1x?x?xf32>, tensor<1x?xf32>)} : () -> ()\r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n\r\n```\r\nhttps://cloud.zbe.si/s/ADNzzjizn82WtHe\r\n```\r\n\r\n**Failure details**\r\nIf the conversion is successful, but the generated model is wrong,\r\nstate what is wrong:\r\n- Producing wrong results and/or decrease in accuracy\r\n- Producing correct results, but the model is slower than expected (model generated from old converter)\r\n\r\nFile isnt generated. The converter just stops after this output. There is more outputed data but it cuts me off in the console. This is everything readable that is outputted. This happens about 10-15mins into the conversion.\r\n\r\n\r\n**RNN conversion support**\r\nIf converting TF RNN to TFLite fused RNN ops, please prefix [RNN] in the title.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@pablo3x6,\r\nLooks like the issue has been resolved in the latest TF-nightly. I was able to convert the model successfully after adding the below lines to the code.\r\n\r\n```\r\nconverter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir='/content/model2/saved_model', signature_keys=['serving_default'])\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\r\ntflite_model = converter.convert()\r\n```\r\n\r\nPlease find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/bc073fff0790cd10433168c04a708048/42857.ipynb#scrollTo=FWJIaa1sZf9g). Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 42856, "title": "[INTEL MKL] Add MKL Conv + Bias + LeakyRelu Fusion", "body": "Add Conv + Bias + LeakyRelu fusion MKL implementation", "comments": ["#42173 is being merged (will take a while). I'll add the `ready-to-pull` tag back to this PR after #42173 is done merging.", "The conflicts are fixed."]}, {"number": 42855, "title": "AttributeError: 'BatchDataset' object has no attribute 'ndim'", "body": "I have filelists to iterate over for 5-fold cross validation:\r\n```\r\ntrain_filelists = [ \"more_56_fold_1_train.txt\", \"more_56_fold_2_train.txt\", \"more_56_fold_3_train.txt\", \"more_56_fold_4_train.txt\", \"more_56_fold_5_train.txt\" ]\r\nval_filelists = [\"more_56_fold_1_val.txt\", \"more_56_fold_2_val.txt\", \"more_56_fold_3_val.txt\",\"more_56_fold_4_val.txt\", \"more_56_fold_5_val.txt\"]\r\n```\r\nI am reading the filelist as `train` and `val` sets into a `dataframe` , then defining the columns as `X_u_train_data`, `X_v_train_data` , `train_labels` and the same for `val` set. I have a double input model, therefore, `train_inputs` contains `u` va `v` column values having image paths for each input. I think the code snippet pretty much explains the rest.\r\n```\r\nfor train_filelist, val_filelist in zip(train_filelists, val_filelists):\r\n    cols = [\"class_id\", \"List_No\", \"u\", \"v\"]\r\n    df_train_data = pd.read_csv(train_filelist, sep=\"\\t\", header=None, names=cols)\r\n    df_train_data['class_id'] = df_train_data['class_id'].map({'more_Abnormal_05': \"abnormal\", 'more_Normal_05': \"normal\"})\r\n    df_val_data = pd.read_csv(val_filelist, sep=\"\\t\", header=None, names=cols)\r\n    df_val_data['class_id'] = df_val_data['class_id'].map({'more_Abnormal_05': \"abnormal\", 'more_Normal_05': \"normal\"})\r\n\r\n    X_u_train_data = df_train_data.u\r\n    X_v_train_data = df_train_data.v\r\n    train_labels = df_train_data.class_id\r\n                \r\n    train_inputs = tf.data.Dataset.from_tensor_slices((X_u_train_data, X_v_train_data) ).\\\r\n           map(lambda X_u_train_data, X_v_train_data: (load(X_u_train_data), load(X_v_train_data)))\r\n    tr_labels = tf.data.Dataset.from_tensor_slices(train_labels).map(lambda train_labels: label(train_labels))\r\n    ds_train = tf.data.Dataset.zip((train_inputs, tr_labels)).batch(64)\r\n    next(iter(ds_train)) # <BatchDataset shapes: (((None, 224, 224, 3), (None, 224, 224, 3)), (None,)), types: ((tf.float32, tf.float32), tf.int32)>\r\n\r\n    X_u_val_data = df_val_data.u\r\n    X_v_val_data = df_val_data.v\r\n    validation_labels = df_val_data.class_id\r\n                \r\n    val_inputs = tf.data.Dataset.from_tensor_slices((X_u_val_data, X_v_val_data)).\\\r\n          map(lambda X_u_val_data, X_v_val_data: (load(X_u_val_data), load(X_v_val_data)))\r\n    val_labels = tf.data.Dataset.from_tensor_slices(validation_labels).map(lambda validation_labels: label(validation_labels))\r\n    ds_val = tf.data.Dataset.zip((val_inputs, val_labels)).batch(64)\r\n    next(iter(ds_val))\r\n\r\n    base_model = combined_net()\r\n    hist = base_model.fit(ds_train,  epochs=EPOCHS,  verbose=1,  validation_data= ds_val, shuffle=True)\r\n```\r\n\r\n`load` and `label` functions are as follows:\r\n```\r\ndef load(file_path):\r\n    img = tf.io.read_file(file_path)\r\n    img = tf.image.decode_png(img, channels=channels)\r\n    img = tf.image.convert_image_dtype(img, tf.float32)\r\n    img = tf.image.resize(img, size=(img_height, img_width))\r\n    return img\r\n\r\ndef label(string):\r\n    return tf.cast(tf.equal(string, 'abnormal'), tf.int32)\r\n```\r\n\r\nWhen run, I get the following error\r\n\r\n```\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-19-47631c811be4> in <module>\r\n     45 \r\n     46                 base_model = combined_net()\r\n---> 47                 hist = base_model.fit(ds_train,  epochs=EPOCHS,  verbose=1,  validation_data= ds_val, shuffle=True)\r\n     48 \r\n     49                 preds = base_model.predict(ds_val)\r\n\r\n~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n   1152             sample_weight=sample_weight,\r\n   1153             class_weight=class_weight,\r\n-> 1154             batch_size=batch_size)\r\n   1155 \r\n   1156         # Prepare validation data.\r\n\r\n~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py in _standardize_user_data(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\r\n    577             feed_input_shapes,\r\n    578             check_batch_axis=False,  # Don't enforce the batch size.\r\n--> 579             exception_prefix='input')\r\n    580 \r\n    581         if y is not None:\r\n\r\n~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py in standardize_input_data(data, names, shapes, check_batch_axis, exception_prefix)\r\n     97         data = data.values if data.__class__.__name__ == 'DataFrame' else data\r\n     98         data = [data]\r\n---> 99     data = [standardize_single_array(x) for x in data]\r\n    100 \r\n    101     if len(data) != len(names):\r\n\r\n~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py in <listcomp>(.0)\r\n     97         data = data.values if data.__class__.__name__ == 'DataFrame' else data\r\n     98         data = [data]\r\n---> 99     data = [standardize_single_array(x) for x in data]\r\n    100 \r\n    101     if len(data) != len(names):\r\n\r\n~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py in standardize_single_array(x)\r\n     32                 'Got tensor with shape: %s' % str(shape))\r\n     33         return x\r\n---> 34     elif x.ndim == 1:\r\n     35         x = np.expand_dims(x, 1)\r\n     36     return x\r\n\r\nAttributeError: 'BatchDataset' object has no attribute 'ndim'\r\n```\r\n``\r\nI have seen some similar issues both here and SO, but could not find a way to solve this issue.\r\n\r\nI am trying to solve it on 2 environments: \r\n\r\n**keras=2.2.4-tf, tensorflow=2.1.0, python=3.7.4 on windows 10**\r\n\r\nand\r\n\r\n**keras=2.2.0, tensorflow-gpu=1.9.0, python=3.5.2 on Ubuntu 16.04**\r\n\r\n\r\n\r\nI hope one could help me. Thank you. ", "comments": ["@bit-scientist \r\nI ran the code shared and face different issue, please find [gist here](https://colab.research.google.com/gist/Saduf2019/bd987d4a6628500bb61d66951acb4a35/untitled402.ipynb).\r\nPlease share complete code to replicate the issue reported or is possible share a colab gist with the error faced.", "that error is saying that it cannot find a filelist `more_56_fold_1_train.txt`, it's obvious, because this is on my local machine. And its content is like below:\r\n```\r\nmore_Abnormal_05\t1001\tD:path/to/images/v05/train/abnormal/1001_8_Rel_A_05_TB10.png\tD:path/to/images/train/u06/train/abnormal/1001_8 Rel A_06_TB10.png\r\nmore_Abnormal_05\t1001\tD:path/to/images/v05/train/abnormal/1001_8_Rel_A_05_TB10_center.png\tD:path/to/images/u06/train/abnormal/1001_8 Rel A_06_TB10_center.png\r\nmore_Abnormal_05\t1001\tD:path/to/images/v05/train/abnormal/1001_8_Rel_A_05_TB10_left_bottom.png\tD:path/to/images/u06/train/abnormal/1001_8 Rel A_06_TB10_left_bottom.png\r\n...\r\nmore_Normal_05\t99\tD:path/to/images/v05/train/normal/99_7_Rel_Z_05_TB10_left_top.png\tD:path/to/images/u06/train/normal/99_7 Rel Z_06_TB10_left_top.png\r\nmore_Normal_05\t99\tD:path/to/images/v05/train/normal/99_7_Rel_Z_05_TB10_right_bottom.png\tD:path/to/images/u06/train/normal/99_7 Rel Z_06_TB10_right_bottom.png\r\nmore_Normal_05\t99\tD:path/to/images/v05/train/normal/99_7_Rel_Z_05_TB10_right_top.png\tD:path/to/images/u06/train/normal/99_7 Rel Z_06_TB10_right_top.png\r\n```\r\nThere are over 13.9k images for each `train_filelist` and around ~0.5k images for `val_filelist`. The number of images are all different but almost equal to the amount mentioned (~13.9k, ~0.5k)", "@bit-scientist Can you please share a simple standalone code to reproduce the error? Standalone code results in faster resolution of your issue. Also, try with recent TF version and let us know whether the issue persists with recent TF version. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 42854, "title": "Try running", "body": "==> I try pip install tensorflow==1.5.0 \r\nit was not working, and then I tried pip install tensorflow-gpu==1.5.0 \r\nit was working. Thanks.\r\nTry running\r\npip uninstall tensorflow\r\nAnd then\r\npip install tensorflow==1.5\r\n\r\nEDIT\r\njust to give credit, solution is from here:\r\nhttps://stackoverflow.com/questions/49094597/illegal-instruction-core-dumped-after-running-import-tensorflow\r\n\r\n_Originally posted by @konnerthg in https://github.com/tensorflow/tensorflow/issues/17411#issuecomment-370393493_", "comments": ["@kosohae \r\n\r\nThis may be due to conflicts in dependencies.Always it would be better to create an virtual environment and install tensorflow .\r\nTensorflow 1.5 version is too old. It will be advisable to use latest TF versions like 2.3. There were lots of performance improvements in the latest versions. Please, close this issue as i do not see any issue now.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42854\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42854\">No</a>\n"]}, {"number": 42853, "title": "Group Conv3D malloc abort trap 6 ", "body": "I am experiencing the following error on MacOS 10.15 (on two different machines). The same code executes without a problem in Colab.\r\n```\r\npython(19819,0x111fa9dc0) malloc: Incorrect checksum for freed object 0x7fbfe429a5e0: probably modified after being freed.\r\nCorrupt value: 0xbd67c765bd67c765\r\npython(19819,0x111fa9dc0) malloc: *** set a breakpoint in malloc_error_break to debug\r\nAbort trap: 6\r\n```\r\n\r\n\r\n**System information**\r\n- Python 3.6.9\r\n- Tensorflow 2.3.0 (tf.version.GIT_VERSION = v2.3.0-rc2-23-gb36436b087)\r\n- MacOS 10.15.6\r\n\r\n**Describe the current behavior**\r\nScript causes seg fault or abort with malloc error whenever `group`. > 1 in the Conv3D args. The issue seems to arise at the first call of `tape.gradient`. Forward calls `model(x)` cause no issues.\r\n\r\n**Describe the expected behavior**\r\nExpect gradients computation. \r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\n\r\ninput_shape = (4,12,12,12,4)\r\nfilters = 4\r\ngroups = 2\r\n\r\nmodel = tf.keras.layers.Conv3D(filters, kernel_size=3, strides=1, use_bias=False, groups=groups, padding='same')\r\n\r\n\r\nfor i in range(3):\r\n    with tf.GradientTape() as tape:\r\n        x = np.random.rand(*input_shape).astype(np.float32)\r\n        y = np.random.randint(2, size=(input_shape[0])).astype(np.int32)\r\n\r\n        out = model(x)\r\n        out = tf.reduce_mean(out, [1,2,3,4])\r\n\r\n        loss = tf.keras.losses.binary_crossentropy(y, out, from_logits=True)\r\n\r\n    grads = tape.gradient(loss, model.trainable_variables)\r\n    # raises error here\r\n\r\n```\r\n", "comments": ["can confirm. one week of searching for errors in my code, just to find exactly that.\r\n\r\nerrors can wildly vary. but all seem to occur on the c-level. \r\n", "System Information:\r\ndebian buster\r\npython 3.7.3\r\ntensorflow 2.3.1", "bump.\r\ncan we get an update on this?", "@kamenbliznashki It looks like you are using an older Version of Tensorflow. Many bugs have been fixed in the latest version. Could you please execute your code using Latest Version 2.6.0 and let us know if the issue still persists? I tried to run the code on colab and faced ` InvalidArgumentError ` please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/286ec3311b59efb400c2cd326be3f3de/untitled206.ipynb) for reference. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42853\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42853\">No</a>\n"]}, {"number": 42852, "title": "Save checkpoints and continue to training", "body": "https://www.tensorflow.org/tutorials/keras/save_and_load\r\n\r\nI read this doc to  save checkpionts by tf.keras.callbacks.ModelCheckpoint. \r\n\r\nI want to continue to training from last checkpiont but I don't know how to do . I use these code\r\n```\r\ncheckpoint_dir = 'training'\r\ncheckpoint_path = os.path.join(checkpoint_dir,\"cp-{epoch:04d}.ckpt\")\r\ncheckpoint_path = os.path.join(checkpoint_path)\r\ncp_callback = tf.keras.callbacks.ModelCheckpoint(\r\n    filepath=checkpoint_path,\r\n    verbose=1,\r\n    save_weights_only=True,\r\n    save_freq=500,\r\n    myModel=tinydarknet)\r\n\r\nmodel.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\r\nmodel.fit(\r\n    train_ds,\r\n    steps_per_epoch=TRAIN_STEPS_PER_EPOCH,\r\n    epochs=epochs,\r\n    validation_data=valid_ds,\r\n    validation_steps=VAL_STEPS_PER_EPOCH,\r\n    workers=NUM_WORKERS,\r\n    callbacks = [tboard_callback,cp_callback]\r\n)\r\n```\r\nThere is a error:\r\n```\r\nMake sure the slot variables are created under the same strategy scope. This may happen if you're restoring from a checkpoint outside the scope\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-0.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-1.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-2.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-3.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-4.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-5.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-6.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-6.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-7.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-8.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-8.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-9.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-9.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-9.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-9.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-9.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-10.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-10.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-11.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-11.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-11.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-11.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-11.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-12.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-12.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-13.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-13.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-13.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-13.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-13.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-14.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-14.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-15.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-15.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-15.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-15.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-15.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-16.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-16.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-17.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-17.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-17.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-17.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-17.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-18.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-18.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-19.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-19.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-19.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-19.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-19.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-20.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-20.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-21.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-21.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-21.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-21.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-21.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-22.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-22.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-23.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-23.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-23.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-23.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-23.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-24.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-24.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-25.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-25.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-25.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-25.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-25.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-26.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-26.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-27.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-27.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-27.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-27.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-27.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-28.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-28.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-29.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-29.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-29.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-29.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-29.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-30.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-30.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-31.axis\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-31.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-31.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-31.moving_mean\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-31.moving_variance\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-32.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).layer_with_weights-32.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-4.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-5.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-5.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-6.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-6.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-7.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-7.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-8.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-8.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-9.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-9.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-10.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-10.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-11.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-11.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-12.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-12.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-13.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-13.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-14.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-14.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-15.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-15.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-16.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-16.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-17.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-17.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-18.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-18.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-19.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-19.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-20.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-20.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-21.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-21.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-22.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-22.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-23.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-23.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-24.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-24.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-25.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-25.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-26.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-26.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-27.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-27.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-28.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-28.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-29.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-29.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-30.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-30.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-31.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-31.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-32.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-32.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-4.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-5.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-5.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-6.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-6.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-7.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-7.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-8.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-8.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-9.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-9.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-10.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-10.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-11.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-11.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-12.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-12.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-13.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-13.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-14.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-14.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-15.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-15.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-16.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-16.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-17.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-17.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-18.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-18.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-19.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-19.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-20.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-20.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-21.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-21.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-22.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-22.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-23.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-23.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-24.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-24.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-25.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-25.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-26.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-26.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-27.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-27.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-28.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-28.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-29.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-29.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-30.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-30.bias\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-31.gamma\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-31.beta\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-32.kernel\r\nWARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-32.bias\r\nWARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\r\n```", "comments": ["@smallworld-network-wupeng \r\nIt means you are not using all the checkpointed values you have restored.\r\nPlease refer to [this link](https://stackoverflow.com/questions/58289342/tf2-0-translation-model-error-when-restoring-the-saved-model-unresolved-objec) and let us know.", "> @smallworld-network-wupeng\r\n> It means you are not using all the checkpointed values you have restored.\r\n> Please refer to [this link](https://stackoverflow.com/questions/58289342/tf2-0-translation-model-error-when-restoring-the-saved-model-unresolved-objec) and let us know.\r\n\r\nThank you problem solve ", "I find the new issue :\r\nif use \r\n```\r\nmodel..compile(optimizer=\"sgd\",\r\n                 loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\r\n                 metrics=[\"accuracy\"])\r\n```\r\nthese isn't error, but if use\r\n```\r\nmodel.compile(optimizer=\"adam\",\r\n                 loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\r\n                 metrics=[\"accuracy\"])\r\n```\r\nthese is still error, why ?", "@smallworld-network-wupeng \r\nPlease create a new issue for this.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42852\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42852\">No</a>\n"]}, {"number": 42851, "title": "Is it possible to adjust available GPU during training?", "body": "Is it possible to adjust available GPU during training?\r\n\r\nThink about this scenario, during traing, the user think one GPU card is too slow to training, and want to add another card to speed up the training. So Is it possible to adjust available GPU without breaking the training\uff1f\r\n\r\n", "comments": ["@pokerfaceSad NO you can't, but you can use [distributed training](https://www.tensorflow.org/guide/distributed_training) to train on multiple GPUs but you can't add a gpu in between the training.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "> @pokerfaceSad NO you can't, but you can use [distributed training](https://www.tensorflow.org/guide/distributed_training) to train on multiple GPUs but you can't add a gpu in between the training.\r\n\r\nThx for your reply."]}, {"number": 42850, "title": "Android app keep crashing when executing `interpreter.run(input, output)`", "body": "**System information** `(for ML model creation and training)`\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): `yes`\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `Linux Ubuntu 20.04`\r\n- TensorFlow installed from (source or binary): `binary`\r\n- TensorFlow version (use command below): `(tf.version.GIT_VERSION: v2.3.0-rc2-23-gb36436b087, tf.version.VERSION: 2.3.0)`\r\n- Python version: `3.8.2`\r\n\r\n**System information** `(for running android app)`\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): `yes`\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `Linux Ubuntu 16.04`\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: `Samsung: Galaxy J7`\r\n- TensorFlow installed from (source or binary): `binary`\r\n- TensorFlow version (use command below): `org.tensorflow:tensorflow-lite:0.0.0-nightly, org.tensorflow:tensorflow-lite-select-tf-ops:0.0.0-nightly`\r\n- Android SDK version: `minSdkVersion = 21`, `targetSdkVersion = 29`, `compileSdkVersion = 29`\r\n- Java version: `1.8`\r\n- Kotlin version: `1.3.72-release-Studio4.0-5`\r\n\r\n\r\n**Describe the current behavior**\r\n- Using Python API: tflite model is able to load and correctly give output\r\n- Using Java API (When used in Android app): tflite model is able to load, gives correct i/p and o/p datatype and shape but it crashes the app when `interpreter.run(input, output)` gets executed\r\n\r\n**Describe the expected behavior**\r\n- Using Java API (When used in Android app): it should give the same response as in the case of python API instead of crashing the app\r\n\r\n\r\n**Standalone code to reproduce the issue** `(tflite model creation and inference using python API)`\r\n```\r\n# tflite model creation:\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ninput_names = [\"my_input\"]\r\noutput_names = [\"my_output\"]\r\ntf_model_path = \"../models/r2plus1d.pb\"\r\n\r\nip_shape = tf.TensorShape([1, 3, 8, 112, 112])\r\n\r\nconverter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph(tf_model_path, input_names, output_names)\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\r\ntflite_model = converter.convert()\r\n\r\nr2plus1d_tflite_file = \"../models/r2plus1d.tflite\"\r\nwith open(r2plus1d_tflite_file, \"wb\") as file:\r\n    file.write(tflite_model)\r\n\r\n---------------------------------------------------------------------------------------------\r\n# inference using tflite model:\r\ntflite_model_path = \"../models/r2plus1d.tflite\"\r\n\r\ninterpreter = tf.lite.Interpreter(model_path=tflite_model_path)\r\ninterpreter.allocate_tensors()\r\n\r\ninput_details = interpreter.get_input_details()\r\noutput_details = interpreter.get_output_details()\r\n\r\ninput_shape = input_details[0]['shape']\r\ninput_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\r\ninterpreter.set_tensor(input_details[0]['index'], input_data)\r\n\r\ninterpreter.invoke()\r\n\r\noutput_data = interpreter.get_tensor(output_details[0]['index'])\r\nprint(output_data)\r\n```\r\n\r\n**Code to reproduce the issue** `(Android app code snippet)` most of its logic has been copied from tensorflow/examples/android\r\n```\r\npackage com.myproject.tensorflow\r\n\r\nimport android.content.res.AssetManager\r\nimport android.graphics.Bitmap\r\nimport com.google.gson.Gson\r\nimport com.myproject.extension.AppLogger\r\nimport org.tensorflow.lite.DataType\r\nimport org.tensorflow.lite.Interpreter\r\nimport java.io.FileInputStream\r\nimport java.io.IOException\r\nimport java.nio.ByteBuffer\r\nimport java.nio.ByteOrder\r\nimport java.nio.MappedByteBuffer\r\nimport java.nio.channels.FileChannel\r\n\r\nclass TensorFlowImageClassifier private constructor() : Classifier {\r\n    private var counter = 0\r\n    private var isRunning: Boolean = false\r\n    private var interpreter: Interpreter? = null\r\n    override fun recognizeImageForObjectDetection(bitmap: Bitmap): Boolean {\r\n        return false\r\n    }\r\n\r\n    if(!isRunning) {\r\n        AppLogger.printLog(\"action isRunning : \"+counter++)\r\n        isRunning = true\r\n        AppLogger.printLog(\" launch recognised\")\r\n        // val byteBuffer = convertBitmapToByteBufferFinal(bitmap)\r\n        val input = Array(1) {Array(3 ) {Array(8) {Array(112) { FloatArray(112) }}}}\r\n        val result = Array(1) { FloatArray(11) }\r\n        try {\r\n            interpreter?.run(byteBuffer, result)\r\n            // interpreter?.run(input, result)\r\n        } catch (e: Exception) {\r\n            e.printStackTrace()\r\n        }\r\n        AppLogger.printLog(\"action output\")\r\n        AppLogger.printLog(\"action recognised output outer \" + Gson().toJson(result))\r\n    }\r\n\r\n    override fun close() {\r\n        interpreter!!.close()\r\n        interpreter = null\r\n    }\r\n\r\n    @Throws(IOException::class)\r\n    private fun loadModelFile(\r\n        assetManager: AssetManager,\r\n        modelPath: String\r\n    ): MappedByteBuffer {\r\n        val fileDescriptor = assetManager.openFd(modelPath)\r\n        val inputStream =  FileInputStream(fileDescriptor.fileDescriptor)\r\n        val fileChannel = inputStream.channel\r\n        val startOffset = fileDescriptor.startOffset\r\n        val declaredLength = fileDescriptor.declaredLength\r\n        return fileChannel.map(  FileChannel.MapMode.READ_ONLY, startOffset, declaredLength)\r\n    }\r\n\r\n    private fun convertBitmapToByteBufferFinal(bitmap: Bitmap): ByteBuffer {\r\n        val byteBuffer: ByteBuffer = ByteBuffer.allocateDirect(4 * 1 * 3 * 8 * 112 * 112) // byte\r\n        byteBuffer.order(ByteOrder.nativeOrder())\r\n        for (m in 0 until 3) {\r\n            for (i in 0 until 8) {\r\n                for (j in 0..111) {\r\n                    for (k in 0..111) {\r\n                        byteBuffer.putFloat(0.5f)\r\n                    }\r\n                }\r\n            }\r\n        }\r\n        return byteBuffer\r\n    }\r\n\r\n    companion object {\r\n        private lateinit var mAassetManager: AssetManager\r\n        private lateinit var mClassifier: TensorFlowImageClassifier\r\n        private lateinit var mModelPath: String\r\n        lateinit var imageShape: IntArray\r\n        var probabilityDataType: DataType? = null\r\n        var inputDataType: DataType? = null\r\n        lateinit var outputShape: IntArray\r\n        var inputBatchSize = 0\r\n        var imageSizeY = 0\r\n        var imageSizeX = 0\r\n        var pixelValue = 0\r\n\r\n        @Throws(IOException::class)\r\n        fun create( assetManager: AssetManager, modelPath: String): Classifier {\r\n            val classifier = TensorFlowImageClassifier()\r\n            classifier.interpreter = getInterpreter(classifier, assetManager, modelPath)\r\n            mAassetManager = assetManager\r\n            mModelPath = modelPath\r\n            mClassifier = classifier\r\n            val probabilityTensorIndex = 0\r\n            val imageTensorIndex = 0\r\n            imageShape = classifier.interpreter!!.getInputTensor(imageTensorIndex).shape() // {1, 3, 8, 112, 112}\r\n            pixelValue = imageShape[1]\r\n            inputBatchSize = imageShape[2]\r\n            imageSizeX = imageShape[3]\r\n            imageSizeY = imageShape[4]\r\n            probabilityDataType = classifier.interpreter!!.getOutputTensor(probabilityTensorIndex).dataType() //FLOAT32\r\n            inputDataType = classifier.interpreter!!.getInputTensor(probabilityTensorIndex).dataType() //FLOAT32\r\n            outputShape = classifier.interpreter!!.getOutputTensor(imageTensorIndex).shape() // {1, 11}\r\n            return classifier\r\n        }\r\n\r\n        private fun getInterpreter(\r\n            classifier: TensorFlowImageClassifier,\r\n            assetManager: AssetManager,\r\n            modelPath: String\r\n        ): Interpreter {\r\n            return Interpreter(\r\n                classifier.loadModelFile(assetManager, modelPath),\r\n                Interpreter.Options()\r\n            )\r\n        }\r\n    }\r\n}\r\n```\r\n\r\n\r\n**Other info / logs**\r\n- [R(2+1)D architecture for action recognition in videos](https://arxiv.org/pdf/1905.00561.pdf)\r\n- [tf model (r2plus1d.pb)](https://drive.google.com/file/d/1in71gffCtQf-eYrx7jz00ZC2IDGbBcVA/view?usp=sharing) - size is around 243MB, used it to convert to tflite\r\n- [tflite model (r2plus1d.tflite)](https://drive.google.com/file/d/1-cUsecwb2HOD0YOFdrhX6BBcRgPHcjUF/view?usp=sharing) - size is around 242MB\r\n- [visualize tflite model (r2plus1d.tflite.svg)](https://drive.google.com/file/d/1Rf8eXHbFH9hGdfwoSI6Jd4xy-KWq64oM/view?usp=sharing) - size is around 1MB\r\n- i/p shape: (1, 3, 8, 112, 112) -> (batch_size, channels, num_of_frames, img_height, img_width)\r\n- o/p shape: (1, 11) -> (num_of_classes)", "comments": ["Hi, could you capture the related error logs when android app is crashing?", "Hi, @abattery I'm unable to capture any error logs or trace the error. App just crashes when it reaches to `interpreter?.run(byteBuffer, result)`. Also, tried debugger with breakpoints on that line, it neither prints anything after that line nor going into `catch block`. ", "I ran your model with model_benchmark_plus_flex tool. No crashing found during execution.\r\n\r\n```\r\nPeak memory footprint (MB): init=13.0977 overall=1989.27\r\n```\r\n\r\nIt might be related to an out-of-memory issue since your model requires almost 2GB to run. If you can confirm it, how about reducing the overall model size through some techniques like post training quantization?\r\nhttps://www.tensorflow.org/lite/performance/post_training_quantization", "@pushpendrapratap Is this still an issue? Were you able to apply model optimization techniques as suggested above? Thanks!", "Hi, the NN architecture had mostly `Conv3D` layers, which (as I saw last time) can't be optimized by the current API. Eventually, I realized that this model can't be run on mobile devices and so I went with the `client-server` architecture.\r\n\r\nI'm closing this issue but if anyone wants to deploy any action recognition model on mobile devices, I have a few suggestions:\r\n1. Make sure all the operators used by your model can be supported on mobile, however, if that is not the case then try to be creative like `Conv3D -> Conv2D + LSTM` or something similar.\r\n2. See if the same objective can be achieved using the combination of simple models (e.g., object detection + pose estimation model), which requires processing a single frame (at a much faster rate) rather than a bunch of frames (as required by 3D CNNs with a much slower rate).", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42850\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/42850\">No</a>\n"]}]