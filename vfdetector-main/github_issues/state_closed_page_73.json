[{"number": 53018, "title": "Cannot open include file with meta_graph.pb.h after compiling tensorflow c++ from source", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n----\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n```\r\n        *\r\n        Version\tWindows 10 Pro\r\n        Version\t21H1\r\n        Install\t\u200e2021/\u200e8/\u200e30\r\n        OS build\t19043.1319\r\n        Experience\tWindows Feature Experience Pack 120.2212.3920.0\r\n        *\r\n```\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): install from source\r\n- TensorFlow version: 2.5.0\r\n- Python version: 3.8.11\r\n- Installed using virtualenv? pip? conda?: Anaconda\r\n```\r\n        *\r\n        > python\r\n        Python 3.8.11 (default, Aug  6 2021, 09:57:55) [MSC v.1916 64 bit (AMD64)] :: Anaconda, Inc. on win32\r\n        > conda -V\r\n        conda 4.10.3\r\n        *\r\n```\r\n- Bazel version (if compiling from source): 3.7.2\r\n```\r\n        *\r\n        > bazel version\r\n        Build label: 3.7.2\r\n        Build target: bazel-out/x64_windows-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\n        Build time: Thu Dec 17 17:02:17 2020 (1608224537)\r\n        Build timestamp: 1608224537\r\n        Build timestamp as int: 1608224537\r\n        *\r\n```\r\n- GCC/Compiler version (if compiling from source): MSVC 2019\r\n```\r\n        *\r\n        >cl.exe\r\n        Microsoft (R) C/C++ Optimizing Compiler Version 19.29.30136 for x86\r\n        Copyright (C) Microsoft Corporation.  All rights reserved.\r\n        \r\n        usage: cl [ option... ] filename... [ /link linkoption... ]\r\n        *\r\n```\r\n- CUDA/cuDNN version: 11.2.67 / 8.1.1.33\r\n```\r\n        *\r\n        > nvcc --version\r\n        nvcc: NVIDIA (R) Cuda compiler driver\r\n        Copyright (c) 2005-2020 NVIDIA Corporation\r\n        Built on Mon_Nov_30_19:15:10_Pacific_Standard_Time_2020\r\n        Cuda compilation tools, release 11.2, V11.2.67\r\n        Build cuda_11.2.r11.2/compiler.29373293_0\r\n        *\r\n```\r\n- GPU model and memory: NVIDIA Geforce RTX 3080 Ti\r\n\r\n----\r\n**Describe the problem**\r\nI want to use tensorflow c++ in my project with pretrained customized keras functional api model. I followed some step to convert .h5 model to .pb file. Then I followed [this step](https://stackoverflow.com/questions/59013401/run-tensorflow-model-in-cpp) (answered by @tensorflow Support). But I got an error at first line.\r\n![image](https://user-images.githubusercontent.com/41325962/141092204-8667f227-80fb-4b23-aee0-2a6fa04c3f6a.png)\r\n\r\n```\r\n        *\r\n        1>------ Build started: Project: tf_pb, Configuration: Release x64 ------\r\n        1>Source.cpp\r\n        1>D:\\tf_model\\tf_pb\\include\\tensorflow\\core\\protobuf\\meta_graph.pb.h(10,10): fatal error C1083: Cannot open include file: 'google/protobuf/port_def.inc': No such file or directory\r\n        1>Done building project \"tf_pb.vcxproj\" -- FAILED.\r\n        *\r\n```\r\nI thought that might be caused by incorrect build process.\r\n\r\n----\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nBefore I installed tensorflow c++ from source, I had already installed (python) tensorflow==2.5.0, tensorflow-gpu==2.5.0, tf-nightly-gpu 20210927 dev.\r\nSteps:\r\n```\r\n        *\r\n        > git clone https://github.com/tensorflow/tensorflow.git\r\n        > cd tensorflow\r\n        > git checkout r2.5\r\n        *\r\n```\r\n```\r\n        *\r\n        > python configure.py\r\n        You have bazel 3.7.2 installed.\r\n        Please specify the location of python. [Default is C:\\Users\\User\\.conda\\envs\\cuda11\\python.exe]:\r\n        \r\n        \r\n        Found possible Python library paths:\r\n          C:\\Users\\User\\.conda\\envs\\cuda11\\lib\\site-packages\r\n        Please input the desired Python library path to use.  Default is [C:\\Users\\User\\.conda\\envs\\cuda11\\lib\\site-packages]\r\n        \r\n        Do you wish to build TensorFlow with ROCm support? [y/N]: N\r\n        No ROCm support will be enabled for TensorFlow.\r\n        \r\n        Do you wish to build TensorFlow with CUDA support? [y/N]: y\r\n        CUDA support will be enabled for TensorFlow.\r\n        \r\n        Found CUDA 11.2 in:\r\n            C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.2/lib/x64\r\n            C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.2/include\r\n        Found cuDNN 8 in:\r\n            C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.2/lib/x64\r\n            C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v11.2/include\r\n        \r\n        \r\n        Please specify a list of comma-separated CUDA compute capabilities you want to build with.\r\n        You can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus. Each capability can be specified as \"x.y\" or \"compute_xy\" to include both virtual and binary GPU code, or as \"sm_xy\" to only include the binary code.\r\n        Please note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 3.5,7.0]: 8.6\r\n        \r\n        \r\n        Please specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is /arch:AVX]:\r\n        \r\n        \r\n        Would you like to override eigen strong inline for some C++ compilation to reduce the compilation time? [Y/n]: n\r\n        Not overriding eigen strong inline, some compilations could take more than 20 mins.\r\n        \r\n        Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: N\r\n        Not configuring the WORKSPACE for Android builds.\r\n        \r\n        Preconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n                --config=mkl            # Build with MKL support.\r\n                --config=mkl_aarch64    # Build with oneDNN and Compute Library for the Arm Architecture (ACL).\r\n                --config=monolithic     # Config for mostly static monolithic build.\r\n                --config=numa           # Build with NUMA support.\r\n                --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.\r\n                --config=v2             # Build TensorFlow 2.x instead of 1.x.\r\n        Preconfigured Bazel build configs to DISABLE default on features:\r\n                --config=noaws          # Disable AWS S3 filesystem support.\r\n                --config=nogcp          # Disable GCP support.\r\n                --config=nohdfs         # Disable HDFS support.\r\n                --config=nonccl         # Disable NVIDIA NCCL support.\r\n        *\r\n```\r\nThen compile with this command\r\n```\r\n        *\r\n        bazel build --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/pip_package:build_pip_package\r\n        *\r\n```\r\nWaited for about **16 hours compiling time**.\r\nIt showed \"successful completed\" after quite a long time.\r\nBut when I tried to include the library...\r\n`#include<tensorflow/core/protobuf/meta_graph.pb.h>`\r\nshowed\r\n```\r\n        *\r\n        Build started...\r\n        1>------ Build started: Project: tf_pb, Configuration: Release x64 ------\r\n        1>Source.cpp\r\n        1>D:\\tf_model\\tf_pb\\include\\tensorflow\\core\\protobuf\\meta_graph.pb.h(10,10): fatal error C1083: Cannot open include file: 'google/protobuf/port_def.inc': No such file or directory\r\n        1>Done building project \"tf_pb.vcxproj\" -- FAILED.\r\n        \r\n        Waiting for help!. Thanks.\r\n        ========== Build: 0 succeeded, 1 failed, 0 up-to-date, 0 skipped ==========\r\n        *\r\n```\r\n\r\n----\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@Wistar1308,\r\n\r\nThe error trace says that `No such file or directory` which may be caused due to incorrect build. So can you create a new environment and try using this [guide](https://iq.opengenus.org/build-tensorflow-cpp-library/) to do fresh build of tensorflow C++ from source and let me know if it works? Thanks", "@sanatmpa1 \r\nLooks well. I follow the step 2~4 and include files under bazel-bin\\tensorflow\\include to my project. \r\nBut now I am facing another problem...\r\n**Cannot open include file: 'google/protobuf/port_def.inc': No such file or directory**\r\n```\r\n        *\r\n        Build started...\r\n        1>------ Build started: Project: TF_savedmodel, Configuration: Release x64 ------\r\n        1>Source.cpp\r\n        1>D:\\python\\tensorflow\\bazel-bin\\tensorflow\\include\\Eigen\\src\\Core\\arch\\Default\\Half.h(1,1): warning C4819: The file contains a character that cannot be represented in the current code page (950). Save the file in Unicode format to prevent data loss\r\n        1>D:\\python\\tensorflow\\bazel-bin\\tensorflow\\include\\Eigen\\src\\Core\\arch\\Default\\BFloat16.h(1,1): warning C4819: The file contains a character that cannot be represented in the current code page (950). Save the file in Unicode format to prevent data loss\r\n        1>D:\\python\\tensorflow\\bazel-bin\\tensorflow\\include\\Eigen\\src\\Core\\arch\\Default\\GenericPacketMathFunctions.h(678,1): warning C4819: The file contains a character that cannot be represented in the current code page (950). Save the file in Unicode format to prevent data loss\r\n        1>D:\\python\\tensorflow\\bazel-bin\\tensorflow\\include\\Eigen\\src\\Core\\products\\GeneralBlockPanelKernel.h(2065,1): warning C4819: The file contains a character that cannot be represented in the current code page (950). Save the file in Unicode format to prevent data loss\r\n        1>D:\\python\\tensorflow\\bazel-bin\\tensorflow\\include\\tensorflow\\core\\protobuf\\error_codes.pb.h(10,10): fatal error C1083: Cannot open include file: 'google/protobuf/port_def.inc': No such file or directory\r\n        1>Done building project \"TF_savedmodel.vcxproj\" -- FAILED.\r\n        ========== Build: 0 succeeded, 1 failed, 0 up-to-date, 0 skipped ==========\r\n        *\r\n```\r\nShould I install google/protobuf by myself? Or I just did incorrect build again. Thanks\r\n", "@Wistar1308 ,\r\n\r\nCan you clarify if you have tried with the latest stable version i.e `2.7.0`? Also please make sure that you have the environment setup as per the [tested build configurations](https://www.tensorflow.org/install/source_windows#tested_build_configurations). Thanks!", "@sanatmpa1 I'm sure that I have the environment setup as the configurations. \r\nI tried [this](https://medium.com/vitrox-publication/deep-learning-frameworks-tensorflow-build-from-source-on-windows-python-c-cpu-gpu-d3aa4d0772d8) and created dll and lib. And I fixed some source codes like [this](https://stackoverflow.com/questions/70089873/solvedgot-error-message-when-run-a-simple-tensorflow-code-after-building-tenso). Then it seems to work with the following output log.\r\n```\r\n        *\r\n        2021-11-24 10:15:21.284305: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudart64_110.dll\r\n        v2.5.2-0-g957590ea15c\r\n        2021-11-24 10:15:25.565604: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\r\n        To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n        2021-11-24 10:15:25.707497: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library nvcuda.dll\r\n        2021-11-24 10:15:26.152191: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties:\r\n        pciBusID: 0000:01:00.0 name: NVIDIA GeForce RTX 3080 Ti computeCapability: 8.6\r\n        coreClock: 1.8GHz coreCount: 80 deviceMemorySize: 12.00GiB deviceMemoryBandwidth: 849.46GiB/s\r\n        2021-11-24 10:15:26.152735: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudart64_110.dll\r\n        2021-11-24 10:15:26.240942: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cublas64_11.dll\r\n        2021-11-24 10:15:26.241076: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cublasLt64_11.dll\r\n        2021-11-24 10:15:26.271758: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cufft64_10.dll\r\n        2021-11-24 10:15:26.280038: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library curand64_10.dll\r\n        2021-11-24 10:15:26.364927: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cusolver64_11.dll\r\n        2021-11-24 10:15:26.380789: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cusparse64_11.dll\r\n        2021-11-24 10:15:26.384559: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library cudnn64_8.dll\r\n        2021-11-24 10:15:26.409772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\r\n        2021-11-24 10:15:32.368605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n        2021-11-24 10:15:32.368786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0\r\n        2021-11-24 10:15:32.369496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N\r\n        2021-11-24 10:15:32.485083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9436 MB memory) -> physical GPU (device: 0, name: NVIDIA GeForce RTX 3080 Ti, pci bus id: 0000:01:00.0, compute capability: 8.6)\r\n        \r\n        D:\\tf_model\\TF_savedmodel\\x64\\Release\\TF_savedmodel.exe (process 13584) exited with code 0.\r\n        To automatically close the console when debugging stops, enable Tools->Options->Debugging->Automatically close the console when debugging stops.\r\n        Press any key to close this window . . .\r\n        \r\n        *\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53018\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53018\">No</a>\n"]}, {"number": 53017, "title": "Interconnect Issue + NaN Error", "body": "When I run python train.py (attached here) it does not give a Y next to the GPU when Interconnect Matrix is checked. Following which it runs the CPU version, and NaN error is attained after a few steps. i have not seen any such issue when training on NVIDIA Tesla K40c (attached as sm25epc.log) or Tesla T4 (attached as nohup.txt\r\n[nohup.txt](https://github.com/tensorflow/tensorflow/files/7510510/nohup.txt)\r\n[sm25epc.log](https://github.com/tensorflow/tensorflow/files/7510523/sm25epc.log)\r\n[train.txt](https://github.com/tensorflow/tensorflow/files/7510530/train.txt)\r\n)\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04.2 LTS\r\n\r\n- TensorFlow installed from (source or binary): Anaconda (GPU)\r\n- TensorFlow version: latest version (I'm guessing 2.5 above) I installed using conda create -n tf-gpu or something similar last week\r\n- Python version: 3.9.7\r\n- Installed using virtualenv? pip? conda?: Anaconda (2021.05 release)\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: NVIDIA-SMI 450.142.00   Driver Version: 450.142.00   CUDA Version: 11.0  \r\n- GPU model and memory: A100-SXM4-40GB\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["[job.21631.txt](https://github.com/tensorflow/tensorflow/files/7510565/job.21631.txt)\r\nError file attached here", "This is submitted in a GPU cluster (there's a SLURM script and all)\r\nI find that when submitting to a local A100 it does not give a N error but it still has a CUDA initialisation error and reverts to Tensorflow CPU Libary (There I use CUDA 11.5) Remaining is the same", "@AnishKumarNayak,\r\n\r\nCan you confirm if you're trying the code in latest stable version i.e `2.7.0`? Also from the template, I can see that you mentioned the CUDA version as 11.0 whereas as per tested build config for 2.7.0, cuda version 11.2 is used. You can refer this [link](https://www.tensorflow.org/install/source#gpu) and make sure you have corresponding versions of compiler, CUDA and cuDNN are used. Thanks!", "Hi,\r\nIt should be 2.7.0 as I have installed the default latest version available in Anaconda3 just a week back.\r\nMy bad, I was a little careless. I am using a GPU cluster at the moment, and we submit our job using SLURM script. I have used source to call upon CUDA 11.0.2 and CUDA 11.2 on separate occasions with the same issue.\r\nAs far as compilers are concerned, I am not familiar with that as we did not build Tensorflow from source, but rather installed using Anaconda3 as a virtual environment. CUDA and cuDNN have been confirmed to be compatible with each other.", "@AnishKumarNayak,\r\n\r\nI took a look at your code in train.txt and I am not able to get the `core` library that you've used in import section. Can you share a standalone reproducible code or a colab gist to expedite the trouble-shooting process? Thanks!\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53017\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53017\">No</a>\n"]}, {"number": 53016, "title": "Disabling autotune_serialize_test", "body": "The test failed for rocm in a weekly sync. Investigation under way but disabled it for rocm for now to keep community CI clean.\r\n@cheshire @chsigg  @deven-amd @stevenireeves ", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F53016) for more info**.\n\n<!-- need_author_consent -->", "@wenchenvincent  Can you please sign CLA. Thanks!", "> @wenchenvincent Can you please sign CLA. Thanks!\r\n\r\nI have signed CLA.", "@googlebot I consent. ", "@awpr FYI", "@wenchenvincent for this and others, could you also attach the failing log?", "> @wenchenvincent for this and others, could you also attach the failing log?\r\n\r\nAttached is the failing log.\r\n[autotune_serialize_test_gpu_test.log](https://github.com/tensorflow/tensorflow/files/7514602/autotune_serialize_test_gpu_test.log)\r\n"]}, {"number": 53015, "title": "Update curl to 7.79.1", "body": "This PR updates curl from 7.78 to 7.79.1.\r\n\r\nThe reason of update is to fix the following vulnerabilities in 7.78:\r\n- CVE-2021-22947: STARTTLS protocol injection via MITM\r\n- CVE-2021-22946: Protocol downgrade required TLS bypassed\r\n- CVE-2021-22945: UAF and double-free in MQTT sending\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F53015) for more info**.\n\n<!-- need_author_consent -->"]}, {"number": 53014, "title": "Use `int64_t` instead of `tensorflow::int64`", "body": "I realized `tensorflow::int64` was removed in 0b6b491d21d6a4eb5fbab1cca565bc1e94ca9543, but the lines I modified didn't change, leading to a compile warning when building custom ops:\r\n\r\n```cpp\r\n/tmp/pip-build-env-9xgnct5m/normal/lib/python3.7/site-packages/tensorflow/include/tensorflow/core/framework/tensor_shape.h:305:22: warning: \u2018tensorflow::int64\u2019 is deprecated: Use int64_t instead. [-Wdeprecated-declarations]\r\n       gtl::InlinedVector<int64, 4> dim_sizes() const;\r\n    /tmp/pip-build-env-9xgnct5m/normal/lib/python3.7/site-packages/tensorflow/include/tensorflow/core/platform/default/notification.h:61:65: warning: \u2018int64\u2019 is deprecated [-Wdeprecated-declarations]\r\n                                                  int64 timeout_in_us);\r\n                                                                     ^\r\n    /tmp/pip-build-env-9xgnct5m/normal/lib/python3.7/site-packages/tensorflow/include/tensorflow/core/platform/default/notification.h:62:58: warning: \u2018int64\u2019 is deprecated [-Wdeprecated-declarations]\r\n       bool WaitForNotificationWithTimeout(int64 timeout_in_us) {\r\n                                                              ^\r\n    /tmp/pip-build-env-9xgnct5m/normal/lib/python3.7/site-packages/tensorflow/include/tensorflow/core/platform/default/notification.h:81:63: warning: \u2018int64\u2019 is deprecated [-Wdeprecated-declarations]\r\n                                                int64 timeout_in_us) {\r\n```", "comments": []}, {"number": 53013, "title": "tflite-model-maker: audio_classifier's DataLoader loads .wav files as int32, resulting in TypeError when training model", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Custom Code\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow version (use command below): 2.7.0 (also repeated on 2.6 and 2.5)\r\n- Python version: 3.8\r\n\r\n**Describe the current behavior**\r\n\r\nFollowing this tutorial: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/tutorials/model_maker_audio_classification.ipynb\r\n\r\nWhen using my own .wav files (16kHz, Mono, float32) as the test and train data, the built in DataLoader function (audio_classifier.DataLoader) loads the arrays as int32's, which leads to this TypeError when I attempt to train the model:\r\n\r\n```\"TypeError: Input 'y' of 'FloorDiv' Op has type float32 that does not match type int32 of argument 'x'.\" ```\r\n\r\nThis is because the YAMnet model expects float32 as input. However, I can use the exact same .wav files as input into the TF Lite YAMnet, and the model processes an output array (1, 521) as expected - meaning these .wav files are in the correct format. It is only when I attempt to train the model via this transfer learning tutorial that this error appears, which leads me to believe it's a bug with the DataLoader. \r\n\r\n**Describe the expected behavior**\r\n\r\nThe DataLoader should process .wav files as float32s, and therefore allow model training.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nmy wav files: https://storage.googleapis.com/glass_net_wavs_zip/glass_data.zip\r\n\r\n```python\r\n\r\nfrom tflite_model_maker import audio_classifier\r\nimport os\r\n\r\ndata_dir = os.getcwd() + '\\\\glass_data\\\\sample_data'\r\n\r\nspec = audio_classifier.YamNetSpec(\r\n    keep_yamnet_and_custom_heads=False,\r\n    frame_step=0.5 * audio_classifier.YamNetSpec.EXPECTED_WAVEFORM_LENGTH,\r\n    frame_length=1 * audio_classifier.YamNetSpec.EXPECTED_WAVEFORM_LENGTH)\r\n\r\ntrain_data = audio_classifier.DataLoader.from_folder(spec, os.path.join(data_dir, 'train'), cache=True)\r\ntest_data = audio_classifier.DataLoader.from_folder(spec, os.path.join(data_dir, 'test'), cache=True)\r\ntrain_data, validation_data = train_data.split(0.8)\r\n\r\n# data = audio_classifier.DataLoader.from_folder(spec=spec, data_path=data_dir)\r\n# train_data, rest_data = data.split(0.8)\r\n# validation_data, test_data = rest_data.split(0.5)\r\n\r\nbatch_size = 16\r\nepochs = 100\r\n\r\nprint('Training the model')\r\nmodel = audio_classifier.create(\r\n    train_data,\r\n    spec,\r\n    validation_data,\r\n    batch_size=batch_size,\r\n    epochs=epochs)\r\n\r\nmodel.evaluate(test_data)\r\n\r\n```\r\n\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<input>\", line 2, in <module>\r\n  File \"C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow_examples\\lite\\model_maker\\core\\task\\audio_classifier.py\", line 148, in create\r\n    task.train(train_data, validation_data, epochs, batch_size)\r\n  File \"C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow_examples\\lite\\model_maker\\core\\task\\audio_classifier.py\", line 55, in train\r\n    train_ds, _ = self._get_dataset_and_steps(\r\n  File \"C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow_examples\\lite\\model_maker\\core\\task\\audio_classifier.py\", line 42, in _get_dataset_and_steps\r\n    dataset = tf.distribute.get_strategy().distribute_datasets_from_function(\r\n  File \"C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\", line 1159, in distribute_datasets_from_function\r\n    return self._extended._distribute_datasets_from_function(  # pylint: disable=protected-access\r\n  File \"C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow\\python\\distribute\\distribute_lib.py\", line 3574, in _distribute_datasets_from_function\r\n    return dataset_fn(InputContext())\r\n  File \"C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow_examples\\lite\\model_maker\\core\\task\\custom_model.py\", line 81, in _dataset_fn\r\n    dataset = input_data.gen_dataset(\r\n  File \"C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow_examples\\lite\\model_maker\\core\\data_util\\audio_dataloader.py\", line 360, in gen_dataset\r\n    ds = spec.preprocess_ds(ds, is_training=is_training, cache_fn=_cache_fn)\r\n  File \"C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow_examples\\lite\\model_maker\\core\\task\\model_spec\\audio_spec.py\", line 523, in preprocess_ds\r\n    ds = ds.map(self._frame, num_parallel_calls=autotune).unbatch()\r\n  File \"C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 1927, in map\r\n    return ParallelMapDataset(\r\n  File \"C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 4522, in __init__\r\n    self._map_func = StructuredFunctionWrapper(\r\n  File \"C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 3712, in __init__\r\n    self._function = fn_factory()\r\n  File \"C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3134, in get_concrete_function\r\n    graph_function = self._get_concrete_function_garbage_collected(\r\n  File \"C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3100, in _get_concrete_function_garbage_collected\r\n    graph_function, _ = self._maybe_define_function(args, kwargs)\r\n  File \"C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3444, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3279, in _create_graph_function\r\n    func_graph_module.func_graph_from_py_func(\r\n  File \"C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 999, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 3687, in wrapped_fn\r\n    ret = wrapper_helper(*args)\r\n  File \"C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\", line 3617, in wrapper_helper\r\n    ret = autograph.tf_convert(self._func, ag_ctx)(*nested_args)\r\n  File \"C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 889, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 933, in _call\r\n    self._initialize(args, kwds, add_initializers_to=initializers)\r\n  File \"C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 763, in _initialize\r\n    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n  File \"C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3050, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _ = self._maybe_define_function(args, kwargs)\r\n  File \"C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3444, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3279, in _create_graph_function\r\n    func_graph_module.func_graph_from_py_func(\r\n  File \"C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 999, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 672, in wrapped_fn\r\n    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3971, in bound_method_wrapper\r\n    return wrapped_fn(*args, **kwargs)\r\n  File \"C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\", line 986, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\nTypeError: in user code:\r\n    C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow_examples\\lite\\model_maker\\core\\task\\model_spec\\audio_spec.py:497 _frame  *\r\n        clips = tf.signal.frame(\r\n    C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper  **\r\n        return target(*args, **kwargs)\r\n    C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow\\python\\ops\\signal\\shape_ops.py:181 frame\r\n        0, 1 + (length_samples - frame_length) // frame_step)\r\n    C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1250 binary_op_wrapper\r\n        raise e\r\n    C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1234 binary_op_wrapper\r\n        return func(x, y, name=name)\r\n    C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206 wrapper\r\n        return target(*args, **kwargs)\r\n    C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:1526 floordiv\r\n        return gen_math_ops.floor_div(x, y, name=name)\r\n    C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:3796 floor_div\r\n        _, _, _op, _outputs = _op_def_library._apply_op_helper(\r\n    C:\\Users\\ghosinsk\\anaconda3\\envs\\GlassNet_v3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:555 _apply_op_helper\r\n        raise TypeError(\r\n    TypeError: Input 'y' of 'FloorDiv' Op has type float32 that does not match type int32 of argument 'x'.\r\n```\r\n\r\n\r\n\r\n\r\n", "comments": ["Hi @ghosinski! Could you try again after casting your input data then ? Attaching similar issues for your reference .[link1](https://stackoverflow.com/a/62282237/11530462),[link2](https://github.com/tensorflow/tensorflow/issues/33077) Thanks!", "Hey @mohantym thanks so much for the follow up! The input to train a tflite_model_maker audio_classifier model is just raw .wav audio files. For example, the [tutorial ](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/tutorials/model_maker_audio_classification.ipynb) uses [these ](https://storage.googleapis.com/laurencemoroney-blog.appspot.com/birds_dataset.zip) wav files. All of the casting / pre-processing (I assume) is done via the DataLoader class, and it seems it is casting audio data to int32 instead of float32. The training_data variable (when it gets assigned by the first call to audio_classifier.DataLoader) is of type:\r\n \r\n``` <class 'tensorflow_examples.lite.model_maker.core.data_util.audio_dataloader.DataLoader'> ```\r\n\r\n I have no idea how I would cast this before training the model... maybe the data is under some sub attribute? But regardless I shouldn't need to cast anything as the processing is supposedly done by the DataLoader. ", "Hi @sanatmpa1! Could you look at this issue . Attaching [Gist f](https://colab.sandbox.google.com/gist/mohantym/1069c2eec8a17574d0184138cee547d5/untitled183.ipynb)or reference.", "I've figured out the source of the error:\r\n```\r\nspec = audio_classifier.YamNetSpec(\r\n    keep_yamnet_and_custom_heads=False,\r\n    frame_step=0.5 * audio_classifier.YamNetSpec.EXPECTED_WAVEFORM_LENGTH,\r\n    frame_length=1 * audio_classifier.YamNetSpec.EXPECTED_WAVEFORM_LENGTH)\r\n````\r\nMultiplying by 0.5 casts the variable frame_step to float32, and the model-maker expects this to be int32. Might be good to make a note of this somewhere. \r\n\r\nAlso, for anyone's future reference, wav files need to be 16-bit PCM when using tflite model maker. That also tripped me up for a while and isn't documented anywhere. Cheers!\r\n", "@ghosinski,\r\n\r\nThanks for the detailed explanation, which may be useful for others in future. But I can already see in [this documentation](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker/audio_classifier/DataLoader#from_folder) that it already expects 16 bit PCM encoding for wav files.\r\n\r\n>  Each .wav file corresponds to an example. Each .wav file is mono (single-channel) and has the typical 16 bit pulse-code modulation (PCM) encoding.\r\n\r\nHope it helps. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53013\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53013\">No</a>\n"]}, {"number": 53010, "title": "New problem in TF 2.6 that does not appears in 2.3.1 (TypeError: Input must be a SparseTensor.)", "body": "Hi, \r\nI've been migrating our tensorflow images from 2.3 to 2.6. To my surprise, I've found bugs in the code that didn't appear before. The error is as follows: \r\n```bash\r\nTypeError: in user code:\r\n\r\n    <ipython-input-108-26abd43eddb2>:11 parse_function  *\r\n        values = [float(_fill_in_missing(value)) for value in values]\r\n    <ipython-input-110-f4a86837955a>:92 _fill_in_missing  *\r\n        return tf.sparse.to_dense(x, default_value)\r\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/sparse_ops.py:1711 sparse_tensor_to_dense  **\r\n        sp_input = _convert_to_sparse_tensor(sp_input)\r\n    /opt/conda/lib/python3.8/site-packages/tensorflow/python/ops/sparse_ops.py:71 _convert_to_sparse_tensor\r\n        raise TypeError(\"Input must be a SparseTensor.\")\r\n\r\n    TypeError: Input must be a SparseTensor.\r\n```\r\n\r\nThe functions that return this error are the following: \r\n```python\r\ndef parse_function(example_proto):\r\n    '''Parse the values from tf examples'''\r\n    feature_spec = tf_transform_output.transformed_feature_spec()\r\n    features = tf.io.parse_single_example(example_proto, feature_spec)\r\n    values = list(features.values())\r\n    values = [float(_fill_in_missing(value)) for value in values]  \r\n    features = tf.stack(values, axis=0)\r\n    return features\r\ndef _fill_in_missing(x):\r\n    \"\"\"Replace missing values in a SparseTensor.\r\n    Fills in missing values of `x` with '' or 0, and converts to a dense tensor.\r\n    Args:\r\n    x: A `SparseTensor` of rank 2.  Its dense shape should have size at most 1\r\n      in the second dimension.\r\n    Returns:\r\n    A rank 1 tensor where missing values of `x` have been filled in.\r\n    \"\"\"\r\n    default_value = '' if x.dtype == tf.string else 0\r\n    return tf.sparse.to_dense(x, default_value)\r\n\r\ndef get_dataset(path):\r\n    '''Get the dataset and group them into windows'''\r\n\r\n    dataset = tf.data.TFRecordDataset(path, compression_type=\"GZIP\")\r\n    dataset = dataset.map(parse_function)\r\n    dataset = dataset.window(HISTORY_SIZE, shift=SHIFT, drop_remainder=True)\r\n    dataset = dataset.flat_map(lambda window: window.batch(HISTORY_SIZE))\r\n    dataset = dataset.map(add_mode)\r\n    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\r\n    dataset = dataset.repeat()\r\n    \r\n    return dataset\r\n```\r\n\r\nI've tried ignoring the _fill_in_missing function and some new errors appears related to the batch (these errors also don't appear the TF 2.3 version): \r\n`Cannot add tensor to the batch: number of elements does not match. Shapes are: [tensor]: [2,1], [batch]: [1] [Op:IteratorGetNext]`\r\n\r\nIt's interesting that the previous batches can be used without any problem, but the last batch has a problem and I don't find a way to fix it. \r\n\r\n\r\nOlder versions (in which the code run without problems):\r\nTF version: 2.3.1\r\nBeam version: 2.28.0\r\nTFMA version: 0.24.3\r\nTFT version: 0.24.1\r\nTFX version: 0.24.0\r\n\r\nCurrent Versions:\r\ntfx-bsl==1.3.0\r\ntensorflow-model-analysis==0.34.1\r\ntensorflow-data-validation==1.3.0\r\ntfx==1.3.2\r\ntensorflow-metadata==1.2.0\r\nml-metadata==1.3.0\r\ntensorflow-transform==1.3.0\r\ntensorflow==2.6.2\r\npyarrow==2.0.0\r\napache-beam==2.32.0\r\ntensorflow-serving-api==2.6.0\r\ntensorflow-estimator==2.6.0", "comments": ["@FernandoDorado \r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!", "I've create a [COLAB ](https://colab.research.google.com/drive/1LC1B-wA_evEOi9X8vG2dYk02nVqyO3sT?usp=sharing) notebook in order to reproduce the error.\r\n\r\nThis is the [link ](https://drive.google.com/file/d/1nV7LGX5A8RroGh3ABPN6Z2agJs0IMsVM/view?usp=sharing) of the data, in case of problems with the data that I've previously loaded into the notebook. \r\n", "@FernandoDorado Could you please try to execute your code on latest TF version `2.7.0` and have a look at the  [tf.sparse](https://www.tensorflow.org/api_docs/python/tf/sparse/to_dense) and [guide](https://www.tensorflow.org/guide/sparse_tensor) for reference ? Please let us know if it helps ? Thanks!", "I took a look, but for now, don't work. Anyway, I see that the problem is more from my side, but I don't understand why the code works perfectly in the older version. "]}, {"number": 53009, "title": "model.fit() never calls custom metric", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): custom code\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu / OSX\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.6.0-0-g919f693420e 2.6.0, v2.7.0-rc1-69-gc256c071bb2 2.7.0\r\n- Python version: 3.7, 3.9\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nFollowing the [documentation](https://keras.io/api/metrics/) I'm trying to implement a custom metric, however the metric never gets called in the first place. I added sanity checks that should produce errors when the metric is called. You can find the full example in this [notebook][1]\r\n\r\n    def my_metric_fn(y_true, y_pred):\r\n        1 / 0\r\n        while True:\r\n            pass\r\n        squared_difference = tf.square(y_true - y_pred)\r\n        return tf.reduce_mean(squared_difference, axis=-1) \r\n\r\nThe code runs without a problem after passing the metric\r\n\r\n    model.compile(optimizer=opt, metrics=[my_metric_fn])\r\n    history = model.fit(\r\n    train_dataset,\r\n    validation_data=validation_dataset,\r\n    epochs=epochs,\r\n    callbacks=[early_stopping]\r\n    )\r\n\r\nWhat I actually get:\r\n\r\n    Epoch 1/100\r\n    59/59 [==============================] - 27s 451ms/step - loss: 16.3928 - my_metric_fn: 0.0000e+00 - val_loss: 16.5252 - val_my_metric_fn: 0.0000e+00\r\n    Epoch 2/100\r\n    59/59 [==============================] - 25s 420ms/step - loss: 16.3508 - my_metric_fn: 0.0000e+00 - val_loss: 16.5316 - val_my_metric_fn: 0.0000e+00\r\n    Epoch 3/100\r\n    59/59 [==============================] - 25s 420ms/step - loss: 16.3420 - my_metric_fn: 0.0000e+00 - val_loss: 16.5372 - val_my_metric_fn: 0.0000e+00\r\n    Epoch 4/100\r\n    59/59 [==============================] - 25s 417ms/step - loss: 16.3365 - my_metric_fn: 0.0000e+00 - val_loss: 16.5287 - val_my_metric_fn: 0.0000e+00\r\n    Epoch 5/100\r\n    59/59 [==============================] - 25s 418ms/step - loss: 16.3251 - my_metric_fn: 0.0000e+00 - val_loss: 16.5271 - val_my_metric_fn: 0.0000e+00\r\n\r\n\r\n  [1]: https://colab.research.google.com/drive/1YohoIRqUWuvAQvEot5cFXWRfAPxm82cm?usp=sharing\r\n\r\n**Describe the expected behavior**\r\n\r\nThe metric should be called followed by an error.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no):\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nI included a notebook earlier\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@schissmantics,\r\n\r\nAs you're trying to implement a custom metric which belongs to `Keras`. Please post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues),To know more see;[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53009\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53009\">No</a>\n"]}, {"number": 53008, "title": "MirroredStrategy fails with RaggedTensor", "body": "### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**: YES\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 Education N 1903\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**: None\r\n-   **TensorFlow installed from (source or binary)**: pip install\r\n-   **TensorFlow version (use command below)**: 2.6\r\n-   **Python version**: 3.9.7\r\n-   **Bazel version (if compiling from source)**: None\r\n-   **GCC/Compiler version (if compiling from source)**: None\r\n-   **CUDA/cuDNN version**:  11.2 / 8.1.0\r\n-   **GPU model and memory**: Nvidia GTX 1080 Ti 11GB\r\n-   **Exact command to reproduce**:\r\n\r\n```bash\r\npython name_of_file.py\r\n```\r\n\r\n### Describe the problem\r\nThe usage of any RaggedTensor in the model to train fails with the MirroredStrategy, whereas is works when there is no strategy. The code described bellow is a toy example, the ragged tensor is just included in the model graph by a tf.print but of course the problem is the same (and original one) when it is included in the calculations for the output of the model.\r\n\r\n### Source code / logs\r\n\r\n```bash\r\nimport tensorflow as tf\r\n\r\n@tf.function\r\ndef loss(a,b):\r\n    return tf.reduce_mean(tf.abs(a), axis=1)\r\n\r\nclass FailL(tf.keras.layers.Layer):\r\n    def __init__(self):\r\n        super(FailL, self).__init__()\r\n    \r\n    def call(self, inputs):\r\n        tf.print(tf.ragged.constant([[1],[1,1]]))\r\n        return inputs\r\n\r\nclass FailM(tf.keras.Model):\r\n    def __init__(self, strategy):\r\n        super(FailM, self).__init__()\r\n        self.strategy = strategy\r\n        if self.strategy is not None:\r\n            with self.strategy.scope():\r\n                self.layer1 = tf.keras.layers.Conv2D(1,[3,3])\r\n                self.layer2 = FailL()\r\n        else:\r\n            self.layer1 = tf.keras.layers.Conv2D(1,[3,3])\r\n            self.layer2 = FailL()\r\n    \r\n    @tf.function\r\n    def call(self, inputs):\r\n        return self.layer2(self.layer1(inputs))\r\n    \r\n    def compile(self):\r\n        if self.strategy is not None:\r\n            with self.strategy.scope():\r\n                super(FailM, self).compile()\r\n                self.loss = loss\r\n                self.optimizer = tf.keras.optimizers.Adam()\r\n        else:\r\n            super(FailM, self).compile()\r\n            self.loss = loss\r\n            self.optimizer = tf.keras.optimizers.Adam()\r\n            \r\n    def train_step(self, data):\r\n        with tf.GradientTape() as tape:\r\n            rag = self.layer2(self.layer1(data))\r\n            loss = self.loss(rag,0)\r\n        grads = tape.gradient(loss, self.trainable_weights)\r\n        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\r\n        return {\"loss\": loss}\r\n    \r\n    @tf.function\r\n    def distributed_train_step(self, data):\r\n        per_replica_losses = self.strategy.run(self.train_step, args=(data,))\r\n        return {prl: self.strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses[prl], axis=None) for prl in per_replica_losses}\r\n    \r\n    def choose_train_step(self, data):\r\n        if self.strategy is None:\r\n            return self.train_step(data)\r\n        else:\r\n            return self.distributed_train_step(data)\r\n\r\nfor choose_strat in [None, \r\n                     tf.distribute.MirroredStrategy(devices=['GPU:0']),\r\n                     ]:\r\n    tf.print('Try with a strategy: ', type(choose_strat))\r\n    model = FailM(choose_strat)\r\n    model.compile()\r\n    res = model.choose_train_step(tf.ones([3,10,10,3]))\r\n    tf.print('Result:', res)\r\n```\r\n\r\nAnd then run it\r\n\r\nTRACEBACK::\r\n\r\n```bash\r\nTry with a strategy:  <class 'tensorflow.python.distribute.mirrored_strategy.MirroredStrategy'>\r\nTraceback (most recent call last):\r\n  File \"C:\\..\\trash_test_ragfail.py\", line 74, in <module>\r\n    res = model.choose_train_step(tf.ones([3,10,10,3]))\r\n  File \"C:\\..\\trash_test_ragfail.py\", line 68, in choose_train_step\r\n    return self.distributed_train_step(data)\r\n  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\envs\\tf2_6\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 885, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\envs\\tf2_6\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\", line 950, in _call\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\envs\\tf2_6\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 3039, in __call__\r\n    return graph_function._call_flat(\r\n  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\envs\\tf2_6\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 1963, in _call_flat\r\n    return self._build_call_outputs(self._inference_function.call(\r\n  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\envs\\tf2_6\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\", line 591, in call\r\n    outputs = execute.execute(\r\n  File \"C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\envs\\tf2_6\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 59, in quick_execute\r\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\r\n  (0) Invalid argument:  2 root error(s) found.\r\n  (0) Invalid argument: 2 root error(s) found.\r\n  (0) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\r\n  (1) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\r\n0 successful operations.\r\n0 derived errors ignored.\r\n  (1) Invalid argument: 2 root error(s) found.\r\n  (0) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\r\n  (1) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\r\n0 successful operations.\r\n0 derived errors ignored.\r\n0 successful operations.\r\n0 derived errors ignored.\r\n         [[{{node test_l_1/StringFormat_1/AsString/map/TensorArrayUnstack/TensorListFromTensor/_18}}]]\r\n         [[Func/test_l_1/StringFormat_1/AsString/map/while/body/_1/input/_59/_32]]\r\n  (1) Invalid argument:  2 root error(s) found.\r\n  (0) Invalid argument: 2 root error(s) found.\r\n  (0) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\r\n  (1) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\r\n0 successful operations.\r\n0 derived errors ignored.\r\n  (1) Invalid argument: 2 root error(s) found.\r\n  (0) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\r\n  (1) Invalid argument: During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\r\n0 successful operations.\r\n0 derived errors ignored.\r\n0 successful operations.\r\n0 derived errors ignored.\r\n         [[{{node test_l_1/StringFormat_1/AsString/map/TensorArrayUnstack/TensorListFromTensor/_18}}]]\r\n0 successful operations.\r\n0 derived errors ignored. [Op:__inference_distributed_train_step_687]\r\n\r\nFunction call stack:\r\ndistributed_train_step -> distributed_train_step\r\n```", "comments": ["Hi @DenisUllmann! Could you please attach the same as a Colab Gist ? There was a **missing parameter named \"TestM\"** while replicating this issue. Thank you!", "Hi @mohantym I edited the code, that was a problem of copy paste. Thanks", "It seams to work on colab though:\r\n\r\nhttps://colab.research.google.com/drive/1SQB59sTwf8FLf9CxMj_rSnrcdFxgUiWa?usp=sharing\r\n\r\nIt uses the brand new TF2.7\r\n\r\nBut when I run it with TF2.7 on my device it still fails (conda environment,, pip install of tf, cuda 11.2, cudnn 8.1.0):\r\n\r\n```bash\r\n...\r\nTry with a strategy:  <class 'tensorflow.python.distribute.mirrored_strategy.MirroredStrategy'>\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\..\\trash_test_ragfail.py\", line 74, in <module>\r\n    res = model.choose_train_step(tf.ones([3,10,10,3]))\r\n  File \"C:\\Users\\..\\trash_test_ragfail.py\", line 66, in choose_train_step\r\n    return self.distributed_train_step(data)\r\n  File \"C:\\Users\\Denis\\.conda\\envs\\tf2_7\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\", line 153, in error_handler\r\n    raise e.with_traceback(filtered_tb) from None\r\n  File \"C:\\Users\\Denis\\.conda\\envs\\tf2_7\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\", line 58, in quick_execute\r\n    tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\r\n  (0) INVALID_ARGUMENT:  During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\r\n         [[{{node test_l_1/StringFormat/AsString/map/TensorArrayUnstack/TensorListFromTensor/_18}}]]\r\n         [[test_l_1/StringFormat/AsString/map/while/body/_1/test_l_1/StringFormat/AsString/map/while/cond/pivot_t/_78/_55]]\r\n  (1) INVALID_ARGUMENT:  During Variant Host->Device Copy: non-DMA-copy attempted of tensor type: string\r\n         [[{{node test_l_1/StringFormat/AsString/map/TensorArrayUnstack/TensorListFromTensor/_18}}]]\r\n0 successful operations.\r\n0 derived errors ignored. [Op:__inference_distributed_train_step_678]\r\n\r\nFunction call stack:\r\ndistributed_train_step -> distributed_train_step\r\n```\r\n\r\nThe problem may come from my setup Windows10/conda environment/pip install OR a different TF execution in commandline and jupyternotebook \r\n\r\nHere is the detail of the build_info:\r\n```bash\r\ntf.sysconfig.get_build_info()\r\n\r\nOut[1]: \r\nOrderedDict([('cpu_compiler',\r\n              'C:/Program Files (x86)/Microsoft Visual Studio/2019/Community/VC/Tools/MSVC/14.27.29110/bin/HostX64/x64/cl.exe'),\r\n             ('cuda_compute_capabilities',\r\n              ['sm_35', 'sm_50', 'sm_60', 'sm_70', 'sm_75', 'compute_80']),\r\n             ('cuda_version', '64_112'),\r\n             ('cudart_dll_name', 'cudart64_112.dll'),\r\n             ('cudnn_dll_name', 'cudnn64_8.dll'),\r\n             ('cudnn_version', '64_8'),\r\n             ('is_cuda_build', True),\r\n             ('is_rocm_build', False),\r\n             ('is_tensorrt_build', False),\r\n             ('msvcp_dll_names', 'msvcp140.dll,msvcp140_1.dll'),\r\n             ('nvcuda_dll_name', 'nvcuda.dll')])\r\n```", "Hi @DenisUllmann! Above Gist seems to have restricted access. Could you check with similar issues [.link1](https://github.com/TensorSpeech/TensorFlowASR/issues/71),[link2](https://github.com/tensorflow/tensorflow/issues/47325). Thanks!", "Hi @mohantym \r\n\r\nI made the Gist public.\r\nBy the way, TF runs on CPU in Colab, this is also shown in the Gist.\r\nSo running it in Colab is not a good test for the reported bug.\r\n\r\nThe problem is that the bug comes from the creation of any RaggedTensor in a MirroredStrategy with GPU, not even from the treatment of this RaggedTensor by a special function like in the reported issues with tf.map_fn", "Hi! @DenisUllmann! Issue is replicating in [TF 2.6](https://colab.sandbox.google.com/gist/mohantym/9bf16b0681eaff104c53065ed87fa7ee/github_53008.ipynb#scrollTo=V7E9CLpAqBJh) and getting resolved in [2.7 ](https://colab.sandbox.google.com/gist/mohantym/f33812adfb5a4d361baff2a8a43dc8c7/github_53008.ipynb#scrollTo=7vcF2wjZp66c) .Thanks!", "Hi @mohantym , unfortunately the issue is not getting resolved in TF2.7, but only in Colab that does not use GPU.", "Hi @sanatmpa1! Could you look at this issue ! Issue is not replicating in 2.7 through Colab CPU or GPU though. ", "Hi @sanatmpa1 , in Colab GPU it fails as well", "Issue is reproducible in TF `2.7.0` with GPU. Here's the [gist](https://colab.sandbox.google.com/gist/sanatmpa1/fa4e0ce9b0bad6936dcc8c4d5986c4cf/53008.ipynb)", "Hi as per the current design `Ragged Tensor variant objects` will not be copied to GPU hence the error, you can continue using CPU till that is made available. Thanks!", "Hi @sachinprasadhs , I understand but that is not a good option for HPC. I started to create a new simpler (without all the attributes of the TF RaggedTension class) 'RaggedTensor_GPU' class that can be used on GPU, to not loose to much efficiency..", "Hi, Did you try the above mentioned step? If it has resolved your issue please move this issue to closed. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53008\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53008\">No</a>\n"]}, {"number": 53007, "title": "Issue in import tensorflow", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@Jeevvenrat \r\nIn order to expedite the trouble-shooting process here,Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose),\r\nThanks!", "Hi @sushreebarsa,\r\n\r\nI have installed Anaconda 3 which has integrated python 3.7 within it.\r\nCurrently i need to install the latest version of tensorflow-base 2.6.0 from the below link for windows 64bit\r\nhttps://anaconda.org/main/tensorflow-base/files\r\nFile Name: tensorflow-base-2.6.0-mkl_py37h9201259_0.tar.bz2\r\nTensorflow is installed using command\r\nconda install tensorflow-base-2.6.0-mkl_py37h9201259_0.tar.bz2\r\nbut when i try to import the tensorflow using below command\r\nimport tensorflow as tf\r\n\r\nI get the below error and fails to import\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.eager import context\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\", line 28, in <module>\r\n    from absl import logging\r\nModuleNotFoundError: No module named 'absl'\r\n\r\ncan anyone please provide me a solution as it is very critical for me to resolve this\r\n\r\n", "@Jeevvenrat Thanks for the update!\r\nCould you please refer to the  official site to [install TF](https://www.tensorflow.org/install/pip#windows_1)  , [Build from source](https://www.tensorflow.org/install/source_windows) and let us know if it helps? Thank you!", "Also i want to install the library offline without creating environment or using pip install as the fire wall policies blocks and give an ssl error", "@sushreebarsa please let me know if there is any other dependencies other than pip version greater than 19.0 and c++  redistributable.", "When i install absl library offline using conda install command and then try to import tensorflow i get the below error\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.eager import context\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\", line 32, in <module>\r\n    from tensorflow.core.framework import function_pb2\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\function_pb2.py\", line 7, in <module>\r\n    from google.protobuf import descriptor as _descriptor\r\nModuleNotFoundError: No module named 'google'", "In the end when i install all the libraries which is giving no module named, i get a different error.\r\n(base) C:\\Temp\\anaconda library>conda install googleapis-common-protos-1.53.0-py37h9ae81ce_1.tar.bz2\r\n\r\nDownloading and Extracting Packages\r\n############################################################################################################### | 100%\r\nPreparing transaction: done\r\nVerifying transaction: done\r\nExecuting transaction: done\r\n\r\n(base) C:\\Temp\\anaconda library>python\r\nPython 3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)] :: Anaconda, Inc. on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.eager import context\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\", line 32, in <module>\r\n    from tensorflow.core.framework import function_pb2\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\core\\framework\\function_pb2.py\", line 7, in <module>\r\n    from google.protobuf import descriptor as _descriptor\r\nModuleNotFoundError: No module named 'google.protobuf'\r\n>>> exit()\r\n\r\n(base) C:\\Temp\\anaconda library>conda install protobuf-3.14.0-py37hd77b12b_1.tar.bz2\r\n\r\nDownloading and Extracting Packages\r\n############################################################################################################### | 100%\r\nPreparing transaction: done\r\nVerifying transaction: done\r\nExecuting transaction: done\r\n\r\n(base) C:\\Temp\\anaconda library>python\r\nPython 3.7.4 (default, Aug  9 2019, 18:34:13) [MSC v.1915 64 bit (AMD64)] :: Anaconda, Inc. on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\nRuntimeError: module compiled against API version 0xe but this version of numpy is 0xd\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python.eager import context\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\", line 37, in <module>\r\n    from tensorflow.python.client import pywrap_tf_session\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\pywrap_tf_session.py\", line 23, in <module>\r\n    from tensorflow.python.client._pywrap_tf_session import *\r\nImportError: SystemError: <built-in method __contains__ of dict object at 0x0000024B9C8FB868> returned a result with an error set", "@Jeevvenrat \r\nI suspect your cpu model does not support AVX instructions sets.See [hardware requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements)\r\nMake sure to download the latest [microsoft visual c++ redistributable](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads) from here.\r\n.Also, please follow the instructions  to install from [Tensorflow website](https://www.tensorflow.org/install/source_windows).\r\nPlease, check Your CPU/Python is on 32 bits?Please, refer #36167, #42367,#42197,#45435\r\nCould you please refer to the common [errors](https://www.tensorflow.org/install/errors) and let us know if it helps ?\r\n\r\nIf the issue still persists please post it on [Anaconda repo ](https://github.com/ContinuumIO/anaconda-issues/issues)as we do not support conda environment.\r\nThis issue is more suitable on [Continuum Anaconda](https://github.com/ContinuumIO/anaconda-issues/issues) repo since its related to TF installation with Anaconda.\r\nPlease post it on Continuum Anaconda.\r\nThank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53007\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53007\">No</a>\n"]}, {"number": 53006, "title": "py_function isn't working with CompositeTensor (especially TensorArray) tf 2.7.0", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04.6 LTS\r\n- TensorFlow installed from (source or binary): binary (pip install tensorflow)\r\n- TensorFlow version (use command below): .v2.7.0-rc1-69-gc256c071bb2 2.7.0\r\n- Python version: 3.7\r\n- CUDA/cuDNN version: 11.4\r\n- GPU model and memory: RTX 2080 Ti 11Go\r\n\r\n**Describe the current behavior**\r\nHi ! When using `tf.py_function()` with `Tout` a composite Tensor. I get an `ValueError : Attempt to convert a value (<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7ff622c6e850>) with an unsupported type (<class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>) to a Tensor` \r\n\r\n**Describe the expected behavior**\r\nI should get a ArrayTensor (or a composite Tensor as specifed in the `tf.py_function` documentation, but i didn't test other composite Tensor). Auto-graph is working but when calling the iterator it fail.\r\n\r\n**Standalone code to reproduce the issue**\r\n```python\r\n\r\nimport tensorflow as tf\r\n\r\ndataset = tf.data.Dataset.range(1)\r\n\r\n\r\n@tf.function\r\ndef exemple_tf(sample):\r\n    array = tf.py_function(exemple_py, [sample],\r\n                           Tout=tf.TensorArraySpec(element_shape=[None, 2],\r\n                                                   dtype=tf.dtypes.float32,\r\n                                                   dynamic_size=False,\r\n                                                   infer_shape=True), name=\"exemple\")\r\n    return sample\r\n\r\n\r\ndef exemple_py(sample):\r\n    tensor_array = tf.TensorArray(dtype=tf.float32,\r\n                                  size=1,\r\n                                  dynamic_size=False,\r\n                                  clear_after_read=False,\r\n                                  infer_shape=False,\r\n                                  element_shape=[None, 2])\r\n    return tensor_array\r\n\r\n\r\ndataset = dataset.map(exemple_tf) # Work here\r\n\r\nfor data in dataset:\r\n    print(data) # Fail here\r\n\r\n```\r\n\r\n**Other info / logs**\r\n ```\r\n\r\n2021-11-09 14:01:14.983740: W tensorflow/core/framework/op_kernel.cc:1733] INVALID_ARGUMENT: ValueError: Attempt to convert a value (<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7fab6045b910>) with an unsupported type (<class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>) to a Tensor.\r\nTraceback (most recent call last):\r\n\r\n  File \"/home/environment/TensorFlow_270_37/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 273, in __call__\r\n    return func(device, token, args)\r\n\r\n  File \"/home/environment/TensorFlow_270_37/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 151, in __call__\r\n    outputs = self._call(device, args)\r\n\r\n  File \"/home/environment/TensorFlow_270_37/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 170, in _call\r\n    for (x, dtype) in zip(ret, self._out_dtypes)\r\n\r\n  File \"/home/environment/TensorFlow_270_37/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 170, in <listcomp>\r\n    for (x, dtype) in zip(ret, self._out_dtypes)\r\n\r\n  File \"/home/environment/TensorFlow_270_37/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 135, in _convert\r\n    return ops.convert_to_tensor(value, dtype=dtype)\r\n\r\n  File \"/home/environment/TensorFlow_270_37/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py\", line 163, in wrapped\r\n    return func(*args, **kwargs)\r\n\r\n  File \"/home/environment/TensorFlow_270_37/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1621, in convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n\r\n  File \"/home/environment/TensorFlow_270_37/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 347, in _constant_tensor_conversion_function\r\n    return constant(v, dtype=dtype, name=name)\r\n\r\n  File \"/home/environment/TensorFlow_270_37/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 272, in constant\r\n    allow_broadcast=True)\r\n\r\n  File \"/home/environment/TensorFlow_270_37/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 283, in _constant_impl\r\n    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n\r\n  File \"/home/environment/TensorFlow_270_37/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 308, in _constant_eager_impl\r\n    t = convert_to_eager_tensor(value, ctx, dtype)\r\n\r\n  File \"/home/environment/TensorFlow_270_37/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 106, in convert_to_eager_tensor\r\n    return ops.EagerTensor(value, ctx.device_name, dtype)\r\n\r\nValueError: Attempt to convert a value (<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7fab6045b910>) with an unsupported type (<class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>) to a Tensor.\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"/home/ydupas/PycharmProjects/ExperimentArea/test py_function bug.py\", line 27, in <module>\r\n    for data in dataset:\r\n  File \"/home/environment/TensorFlow_270_37/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 800, in __next__\r\n    return self._next_internal()\r\n  File \"/home/environment/TensorFlow_270_37/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 786, in _next_internal\r\n    output_shapes=self._flat_output_shapes)\r\n  File \"/home/environment/TensorFlow_270_37/lib/python3.7/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 2845, in iterator_get_next\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"/home/environment/TensorFlow_270_37/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 7107, in raise_from_not_ok_status\r\n    raise core._status_to_exception(e) from None  # pylint: disable=protected-access\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: ValueError: Attempt to convert a value (<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7fab6045b910>) with an unsupported type (<class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>) to a Tensor.\r\nTraceback (most recent call last):\r\n\r\n  File \"/home/environment/TensorFlow_270_37/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 273, in __call__\r\n    return func(device, token, args)\r\n\r\n  File \"/home/environment/TensorFlow_270_37/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 151, in __call__\r\n    outputs = self._call(device, args)\r\n\r\n  File \"/home/environment/TensorFlow_270_37/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 170, in _call\r\n    for (x, dtype) in zip(ret, self._out_dtypes)\r\n\r\n  File \"/home/environment/TensorFlow_270_37/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 170, in <listcomp>\r\n    for (x, dtype) in zip(ret, self._out_dtypes)\r\n\r\n  File \"/home/environment/TensorFlow_270_37/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 135, in _convert\r\n    return ops.convert_to_tensor(value, dtype=dtype)\r\n\r\n  File \"/home/environment/TensorFlow_270_37/lib/python3.7/site-packages/tensorflow/python/profiler/trace.py\", line 163, in wrapped\r\n    return func(*args, **kwargs)\r\n\r\n  File \"/home/environment/TensorFlow_270_37/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 1621, in convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n\r\n  File \"/home/environment/TensorFlow_270_37/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 347, in _constant_tensor_conversion_function\r\n    return constant(v, dtype=dtype, name=name)\r\n\r\n  File \"/home/environment/TensorFlow_270_37/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 272, in constant\r\n    allow_broadcast=True)\r\n\r\n  File \"/home/environment/TensorFlow_270_37/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 283, in _constant_impl\r\n    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n\r\n  File \"/home/environment/TensorFlow_270_37/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 308, in _constant_eager_impl\r\n    t = convert_to_eager_tensor(value, ctx, dtype)\r\n\r\n  File \"/home/environment/TensorFlow_270_37/lib/python3.7/site-packages/tensorflow/python/framework/constant_op.py\", line 106, in convert_to_eager_tensor\r\n    return ops.EagerTensor(value, ctx.device_name, dtype)\r\n\r\nValueError: Attempt to convert a value (<tensorflow.python.ops.tensor_array_ops.TensorArray object at 0x7fab6045b910>) with an unsupported type (<class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>) to a Tensor.\r\n\r\n\r\n\t [[{{function_node __inference_exemple_tf_12}}{{node exemple}}]] [Op:IteratorGetNext]\r\n\r\nProcess finished with exit code 1\r\n\r\n```\r\n", "comments": ["Was able to reproduce your issue in Tensorflow 2.7, please find the gist [here](https://colab.research.google.com/gist/sachinprasadhs/8745aeef128939c928d4cbc70b293f27/53006.ipynb). Thanks!", "The underlying problem is that TensorArray isn't actually a CompositeTensor (even though the TensorArraySpec class is defined).  The proper fix is to convert TensorArray to be a CompositeTensor (i.e., add CompositeTensor as a base class, and add a \"_type_spec\" property that returns a TensorArraySpec).  \r\n\r\nThe main blocker (that I know of) for that fix is that TensorArray needs to have special handling in several contexts (e.g., tf.while_loop), but that special handling would get skipped if we made TensorArray be a CompositeTensor.  So fixing this would require auditing and adjusting the code that special-cases TensorArray, to ensure it still works properly.\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53006\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/53006\">No</a>\n"]}, {"number": 53004, "title": "Declare Go import path in distributed runtime payloads proto", "body": "PR declares `go_package` in proto definition and resolves protoc-gen-go error.", "comments": []}, {"number": 53003, "title": "[tflite] any way to extract operator attributes from interpreter", "body": "\r\n**System information**\r\n- python 3.8.11\r\n- TensorFlow 2.5.1\r\n- Are you willing to contribute it: No\r\n\r\n**Describe the feature and the current behavior/state.**\r\nWith current APIs I can extract operator details with\r\n> ip = tf.lite.Interpreter(model_path=tflite_file)\r\n> ip._get_ops_details()\r\n\r\nI could get (for example):\r\n\r\n> {'index': 0,\r\n>   'op_name': 'CONV_2D',\r\n>   'inputs': array([0, 4, 2], dtype=int32),\r\n>   'outputs': array([13], dtype=int32)}\r\n\r\nI would expect another key \"builtin_option\" in this dict to expose all attributes of this layer contained in flatbuffer, e.g. fused_activation_function, padding, stride_h/w etc.\r\nCurrently, I'm parsing a tflite model and automating code preparation for an edge device with a customized DNN accelerator. Those attributes data is important to configure hardware components. Now I'm parsing the tflite model with flatbuffer API to extract those attributes, but the code is bloated and ugly, so I expect that the interpreter._get_ops_details() can include this part.\r\n\r\n**Will this change the current api? How?**\r\nThe required \"attributes\" key doesn't change the current API.\r\nIn `_get_ops_details()` of `interpreter.py`, a new line like\r\n> op_attributes = self._interpreter.NodeAttributes(op_index)\r\n\r\ncould be added.\r\n**Who will benefit with this feature?**\r\nAnyone who only wants to take the single tflite model as the entry and easily parse both tensors and operators content for their own backend.\r\n**Any Other info.**\r\nI'm still new to tensorflow, if anyone can extract operators in a easy way, please leave comments below :) ", "comments": ["If you want to read the information from TensorFlow Lite builtin ops and write your own backends, the TensorFlow Lite **Delegate** mechanism is exactly for doing that. \r\n\r\nPlease take a look at https://www.tensorflow.org/lite/performance/implementing_delegate\r\n\r\nLet us know if you have any further questions. Thanks!"]}, {"number": 53001, "title": "Can I init a XlaBuilder using a existing XlaComputation\uff1f", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using):\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\n**Will this change the current api? How?**\r\n\r\n**Who will benefit with this feature?**\r\n\r\n**Any Other info.**\r\n\r\nIt will be useful to modify a existing  HloModule with XlaBuilder Operation Semantics", "comments": ["@chenzhengda ,\r\nCan you please elaborate about your Feature. Also, please specify the Use Cases for this feature. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 53000, "title": "Wrong Tensorflow Lite link to hexagon_nn_skel.run v1.21 (actually is pointing to the v1.20.0.1)", "body": "Hi, I want to download the hexagon_nn_skel.run v1.21. In the Tensorflow Lite Hexagon guide there are many links to many versions: https://www.tensorflow.org/lite/performance/hexagon_delegate. The problem is that v1.21 is pointing to v1.20. So the question is where can I find the version 1.21 of hexagon_nn_skel.run?\r\nAlso, in the guide it is specified that we must use the hexagon_nn libraries with the compatible version of interface library, as stated in bazel config. From bazel config (https://github.com/tensorflow/tensorflow/blob/master/third_party/hexagon/workspace.bzl) I understand that I must use the version 20.0.3 of the interface. So where can I find the version 20.0.3 of the interface library?", "comments": ["Hi! @sachinprasadhs! Could you please look at this bug?", "Hi @glodanclaudia thanks for reporting this.\r\n\r\nThis is the correct version. I think updating the documentation to mention v1.20.0.1 might be better.\r\nI sent a fix to update the documentation.\r\n\r\nRegarding the interface library.\r\nIf you're using the delegate through java API, then everything will be pulled from the gradle dependency as mentioned [here](https://www.tensorflow.org/lite/performance/hexagon_delegate#step_1_edit_appbuildgradle_to_use_the_nightly_hexagon_delegate_aar)\r\nIf you want to do it through bazel then you can do\r\n\r\nbazel build -c opt --config=android_arm64 //tensorflow/lite/delegates/hexagon/hexagon_nn:libhexagon_interface\r\n\r\nor download the tar file in the bzl file you pointed to and you will find the library inside it with header files.\r\n\r\nThanks again, and please let me know if you are having any issues.\r\n\r\nThanks", "Hi @karimnosseir , thank you for help! \r\nI understand now that v1.21 is actually v1.20.0.1.\r\nBut I want to use the delegate using C API, not Java. So yes, we built the interface using bazel but the resulted interface has version 1.20.0.3. This means that we need hexagon_nn_skel.run v1.20.0.3 in order to assure the compatibility. Where can I found this?", "One more thing.... I want to use tensorflow lite 2.6.0 or higher so that's why I need the version 1.20.0.3 of hexagon_nn_skel.run.\r\nAlso here https://github.com/tensorflow/tensorflow/blob/v2.7.0/third_party/hexagon/workspace.bzl is mentioned this version. ", "As mentioned here\r\nhttps://github.com/tensorflow/tensorflow/blob/v2.7.0/third_party/hexagon/workspace.bzl#L5\r\n\r\nYou should be using 1.20 this includes 1.20.0.1. So you should be good to go.\r\nIf you have issues when you use, please let us know.", "Closing because the questions seem fully answered. Please feel free to reopen if there are more questions. "]}, {"number": 52999, "title": "How to specify the output layers during model conversion to TFLite in TF2?", "body": "**Describe the problem**\r\nIs there any way to remove the TFLite_Detection_PostProcess in tf2 ssd mobilenet model during conversion to tflite model\uff1fIn tf1, there is a option to do so, but it seems that in tf2 the option for specifying the output layers is removed. \r\n\r\nIn tf1, I can specify the output layers by putting the name in output_array:\r\ninput_arrays=[\"normalized_input_image_tensor\"]\r\noutput_arrays=[\"raw_outputs/box_encodings\",\"raw_outputs/class_predictions\"]\r\ninput_tensor={\"normalized_input_image_tensor\":[1,320,320,1]}\r\n\r\nimport tensorflow as tf\r\nconverter = tf.compat.v1.lite.TFLiteConverter.from_frozen_graph('tflite_graph.pb',input_shapes = input_tensor,\r\ninput_arrays = input_arrays ,output_arrays = output_arrays)\r\n\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.allow_custom_ops = True\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8,tf.lite.OpsSet.SELECT_TF_OPS]\r\nconverter.inference_input_type = tf.int8\r\nconverter.inference_output_type = tf.int8\r\nconverter.representative_dataset = representative_dataset_gen\r\ntflite_model = converter.convert()\r\nopen('ssd_mobilenet_v2_tf1.tflite', \"wb\").write(tflite_model)\r\n", "comments": ["@qqwerter \r\nIn order to expedite the trouble-shooting process here,Could you please fill the issue [template](https://github.com/tensorflow/tensorflow/issues/new/choose), Please refer to this [link](https://www.tensorflow.org/lite/convert) for more details.\r\nThanks!"]}, {"number": 52998, "title": "[TF-TRT] Adding a widget to inform the user that we are still processing `TrtGraphConverterV2.build()`", "body": "@bixia1 for review\r\n\r\nThis PR adds a waiting widget to inform the user that we are still processing `TrtGraphConverterV2.build()`.\r\n\r\nPrint message on the console during the duration of the build indicating: `Building TensorRT Engines. Please wait ...`", "comments": ["@bixia1 Can you please review this PR ? Thanks!", "We discussed whether this is indeed needed at a meeting and hasn't reached a final solution yet.", "@DEKHTIARJonathan Can you please resolve conflicts? Thanks!", "@DEKHTIARJonathan Can you please resolve conflicts? Thanks!"]}, {"number": 52997, "title": "Remove xrange from tensorflow/python/kernel_tests", "body": "Also remove from an autograph file b/c it's no longer a builtin and I didn't want to make a PR to only change 1 line.", "comments": []}, {"number": 52996, "title": "Remove six from examples", "body": "Smaller PR this time so removed all of six instead of just xrange.", "comments": []}, {"number": 52995, "title": "Remove xrange from tensorflow/compiler", "body": "Other usages of six's xrange will be removed in other PR's(there's a lot of them).", "comments": []}, {"number": 52994, "title": "Unable to use tensorflow after installing", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version: 3.8.5\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nI try to install tensorflow and it just says all of the requirements are already satisfied but it throws an error everytime I try to use tensorflow.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\n\r\nC:\\Users\\josep\\Videos>pip3 install --user --upgrade tensorflow\r\nRequirement already up-to-date: tensorflow in c:\\users\\josep\\anaconda3\\lib\\site-packages (2.7.0)\r\nRequirement already satisfied, skipping upgrade: absl-py>=0.4.0 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from tensorflow) (0.15.0)\r\nRequirement already satisfied, skipping upgrade: flatbuffers<3.0,>=1.12 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from tensorflow) (1.12)\r\nRequirement already satisfied, skipping upgrade: wrapt>=1.11.0 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\r\nRequirement already satisfied, skipping upgrade: grpcio<2.0,>=1.24.3 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from tensorflow) (1.41.1)\r\nRequirement already satisfied, skipping upgrade: gast<0.5.0,>=0.2.1 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from tensorflow) (0.4.0)\r\nRequirement already satisfied, skipping upgrade: termcolor>=1.1.0 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.0)\r\nRequirement already satisfied, skipping upgrade: wheel<1.0,>=0.32.0 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from tensorflow) (0.37.0)\r\nRequirement already satisfied, skipping upgrade: h5py>=2.9.0 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from tensorflow) (3.1.0)\r\nRequirement already satisfied, skipping upgrade: tensorflow-estimator<2.8,~=2.7.0rc0 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\r\nRequirement already satisfied, skipping upgrade: keras<2.8,>=2.7.0rc0 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\r\nRequirement already satisfied, skipping upgrade: numpy>=1.14.5 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from tensorflow) (1.21.4)\r\nRequirement already satisfied, skipping upgrade: libclang>=9.0.1 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from tensorflow) (12.0.0)\r\nRequirement already satisfied, skipping upgrade: google-pasta>=0.1.1 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from tensorflow) (0.2.0)\r\nRequirement already satisfied, skipping upgrade: protobuf>=3.9.2 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from tensorflow) (3.19.1)\r\nRequirement already satisfied, skipping upgrade: tensorflow-io-gcs-filesystem>=0.21.0 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from tensorflow) (0.21.0)\r\nRequirement already satisfied, skipping upgrade: six>=1.12.0 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\r\nRequirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from tensorflow) (3.3.0)\r\nRequirement already satisfied, skipping upgrade: typing-extensions>=3.6.6 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\r\nRequirement already satisfied, skipping upgrade: astunparse>=1.6.0 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from tensorflow) (1.6.3)\r\nRequirement already satisfied, skipping upgrade: tensorboard~=2.6 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from tensorflow) (2.7.0)\r\nRequirement already satisfied, skipping upgrade: keras-preprocessing>=1.1.1 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from tensorflow) (1.1.2)\r\nRequirement already satisfied, skipping upgrade: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.6.1)\r\nRequirement already satisfied, skipping upgrade: setuptools>=41.0.0 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (58.5.3)\r\nRequirement already satisfied, skipping upgrade: tensorboard-plugin-wit>=1.6.0 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.8.0)\r\nRequirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.24.0)\r\nRequirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (0.4.6)\r\nRequirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (1.0.1)\r\nRequirement already satisfied, skipping upgrade: google-auth<3,>=1.6.3 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (2.3.3)\r\nRequirement already satisfied, skipping upgrade: markdown>=2.6.8 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from tensorboard~=2.6->tensorflow) (3.3.4)\r\nRequirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2020.6.20)\r\nRequirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (1.25.11)\r\nRequirement already satisfied, skipping upgrade: idna<3,>=2.5 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (2.10)\r\nRequirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow) (3.0.4)\r\nRequirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (1.3.0)\r\nRequirement already satisfied, skipping upgrade: rsa<5,>=3.1.4; python_version >= \"3.6\" in c:\\users\\josep\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.7.2)\r\nRequirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.2.8)\r\nRequirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (4.2.4)\r\nRequirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow) (3.1.1)\r\nRequirement already satisfied, skipping upgrade: pyasn1>=0.1.3 in c:\\users\\josep\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow) (0.4.8)\r\n\r\n\r\nC:\\Users\\josep\\Videos>python -c \"import tensorflow as tf; print(tf.reduce_sum(tf.random.normal([1000, 1000])))\"\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\josep\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"C:\\Users\\josep\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\josep\\anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 40, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"C:\\Users\\josep\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 79, in <module>\r\n    raise ImportError(\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\josep\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\nSee https://www.tensorflow.org/install/errors for some common causes and solutions.\r\nIf you need help, create an issue at https://github.com/tensorflow/tensorflow/issues and include the entire stack trace above this error message.\r\n", "comments": ["@josephcoveai ,\r\nCan you please take a look at this [comment](https://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156) from the issue with similar error.It helps.\r\nAlso in order to expedite the trouble-shooting process, could you please provide the following information\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nTensorFlow installed from (source or binary):\r\nTensorFlow version:\r\nPython version:\r\nInstalled using virtualenv? pip? conda?:\r\nBazel version (if compiling from source):\r\nGCC/Compiler version (if compiling from source):\r\nCUDA/cuDNN version:\r\nGPU model and memory:\r\n\r\nand the exact sequence of commands / steps that you executed before running into the problem.Thanks", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52994\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52994\">No</a>\n"]}, {"number": 52993, "title": "[ROCm] Added Matrix Inverse Op on ROCm", "body": "Primary Development @micmelesse. ", "comments": ["@cheshire there was a small fix, can you re-review? ", "@cheshire sorry, one more time, small fix to the fix. "]}, {"number": 52991, "title": "[LHLO-Affine] Fix bug in the conversion of lmhlo.gather to affine", "body": "  Initially, the code was not checking whether all the predicates\r\n  representing equality between the sum of start index and offset\r\n  and operand index. The mistake was in the upper bound of the loop\r\n  iterating the predicate vector. ", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F52991) for more info**.\n\n<!-- need_sender_cla -->", "> Thanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\r\n> \r\n> \ud83d\udcdd **Please visit https://cla.developers.google.com/ to sign.**\r\n> \r\n> Once you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\r\n> \r\n> #### What to do if you already signed the CLA\r\n> ##### Individual signers\r\n> * It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\r\n> \r\n> ##### Corporate signers\r\n> * Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\r\n> * The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\r\n> * The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\r\n> \r\n> \u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F52991) for more info**.\r\n\r\n@googlebot I signed it!", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F52991) for more info**.\n\n<!-- need_author_cla -->", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F52991) for more info**.\n\n<!-- need_author_cla -->", "> We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors. If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)? If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google. In order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\r\n> \r\n> \u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F52991) for more info**.\r\n@googlebot I fixed it.\r\n", "Hi all, I am not able to figure out the reason for failure of Windows Bazel GPU test, as there are no details provided. It would be great of someone can clarify. \r\nThanks in advance."]}, {"number": 52990, "title": "Fix TF 2.7 release notes", "body": "Fix https://github.com/tensorflow/tensorflow/pull/52670/. The changes is in TF2.7 and not 2.6.\r\n\r\n@mihaimaruseac ", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F52990) for more info**.\n\n<!-- need_author_consent -->", "@googlebot I consent.\r\n\r\nI already have the CLA signed. I'm not sure why this was asked.", "CLA bot is confused when doing cherrypicks.\r\n\r\nThere's a caveat here, we'll add a new commit on the branch after the release, but probably we can handle this the same as #52971", "Check out this pull request on&nbsp; <a href=\"https://app.reviewnb.com/tensorflow/tensorflow/pull/52990\"><img align=\"absmiddle\"  alt=\"ReviewNB\" height=\"28\" class=\"BotMessageButtonImage\" src=\"https://raw.githubusercontent.com/ReviewNB/support/master/images/button_reviewnb.png\"/></a> \n\n See visual diffs & provide feedback on Jupyter Notebooks. \n\n---\n\n <i>Powered by <a href='https://www.reviewnb.com/?utm_source=gh'>ReviewNB</a></i>", "> CLA bot is confused when doing cherrypicks.\r\n\r\nI didn't cherry-pick anything here.\r\n\r\n> There's a caveat here, we'll add a new commit on the branch after the release, but probably we can handle this the same as #52971\r\n\r\nCan you confirm that, I need to do this commit on top of master and not on the release branch? I updated this PR to do this. I changed the RELEASE.md files instead of README.md.", "All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F52990) for more info**.\n\n<!-- need_author_consent -->", "So we need one PR against the r2.7 branch and one against master. This way we ensure that the relnotes on the branch are always a subset of what's on master, each section matching.\r\n\r\nAfter the r2.7 branch PR lands I will update the GitHub release notes to match.", "Ok. So I updated this PR to be as at the start to modify only the 2.7 branch.\r\n\r\n@googlebot I consent.\r\nMy commit use an email that is in my github account. So it should works as before.\r\nBut my commit name is \"Frederic Bastien\", while my github account name is \"Fr\u00e9d\u00e9ric Bastien\". There is some special character that I converted in the github commit. Can Google bot started to check the name? If so, I'll check if I can use the special character in my github commit.\r\n\r\n\r\n", "Looks good"]}, {"number": 52986, "title": " Custom training with tf.distribute.Strategy fails with BatchNorm", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): using Docker image `tensorflow/tensorflow:2.5.0-gpu`\r\n- TensorFlow version (use command below): v2.5.0-rc3-213-ga4dfb8d1a71 2.5.0\r\n- Python version: Python 3.8.0\r\n- Bazel version (if compiling from source): None\r\n- GCC/Compiler version (if compiling from source): None\r\n- CUDA/cuDNN version: 11.2/8.1\r\n- GPU model and memory:\r\n\r\n```bash\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 460.73.01    Driver Version: 460.73.01    CUDA Version: 11.2     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|                               |                      |               MIG M. |\r\n|===============================+======================+======================|\r\n|   0  TITAN X (Pascal)    Off  | 00000000:02:00.0 Off |                  N/A |\r\n| 23%   43C    P0    69W / 250W |      0MiB / 12196MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  TITAN X (Pascal)    Off  | 00000000:03:00.0 Off |                  N/A |\r\n| 23%   43C    P0    69W / 250W |      0MiB / 12196MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  TITAN X (Pascal)    Off  | 00000000:82:00.0 Off |                  N/A |\r\n| 23%   37C    P0    57W / 250W |      0MiB / 12196MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  TITAN X (Pascal)    Off  | 00000000:83:00.0 Off |                  N/A |\r\n| 23%   42C    P0    67W / 250W |      0MiB / 12196MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n```\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nI tried adapting [this tutorial](https://www.tensorflow.org/tutorials/distribute/custom_training) on custom training loop with tf.distribute.Strategy, but I am facing an issue. I get the following exception if one of the replicas receives an empty batch:\r\n\r\n```bash\r\nAssertionError: in user code:\r\n\r\n    /tmp/ipykernel_21821/3562653524.py:98 distributed_train_step  *\r\n        per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))\r\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py:1285 run  **\r\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\r\n        return self._call_for_each_replica(fn, args, kwargs)\r\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/mirrored_strategy.py:678 _call_for_each_replica\r\n        return mirrored_run.call_for_each_replica(\r\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/mirrored_run.py:104 call_for_each_replica\r\n        return _call_for_each_replica(strategy, fn, args, kwargs)\r\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/mirrored_run.py:245 _call_for_each_replica\r\n        coord.join(threads)\r\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/training/coordinator.py:389 join\r\n        six.reraise(*self._exc_info_to_raise)\r\n    /usr/local/lib/python3.8/dist-packages/six.py:703 reraise\r\n        raise value\r\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/training/coordinator.py:297 stop_on_exception\r\n        yield\r\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/mirrored_run.py:220 _call_for_each_replica\r\n        merge_args = distribute_utils.regroup(\r\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_utils.py:62 regroup\r\n        regrouped_tuple = tuple(\r\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_utils.py:63 <genexpr>\r\n        regroup(tuple(v[i] for v in values), wrap_class, always_wrap)\r\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_utils.py:61 regroup\r\n        assert len(v) == len(v0)\r\n\r\n    AssertionError: \r\n```\r\n\r\nI think this issue happens when one of of the GPU receives an empty per-replica batch. I tried reproducing this bug with the minimal example provided [here](https://www.tensorflow.org/tutorials/distribute/custom_training), and it didn't happen. I suppose it's because this issue happens only if our model uses **BatchNorm**. So, I adapted this minimal example by using a ResNet (provided in tf.keras.applications) as a model. My full code is available below.\r\n\r\n**Describe the expected behavior**\r\n\r\nThis issue shouldn't happen. Also, I suppose this issue is raised because the **BatchNorm** statistics are computed locally, which can be a problem because each device would use different statistics.\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): no\r\n- Briefly describe your candidate solution(if contributing):\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nI couldn't reproduce this issue directly on Colab because it requires at least 2 GPUs:\r\n\r\n```python\r\n# Import TensorFlow\r\nimport tensorflow as tf\r\n\r\n# Helper libraries\r\nimport numpy as np\r\nimport os\r\n\r\nprint(tf.__version__)\r\n\r\nfashion_mnist = tf.keras.datasets.fashion_mnist\r\n\r\n(train_images, train_labels), _ = fashion_mnist.load_data()\r\n\r\n# Adding a dimension to the array -> new shape == (28, 28, 1)\r\n# We are doing this because the first layer in our model is a convolutional\r\n# layer and it requires a 4D input (batch_size, height, width, channels).\r\n# batch_size dimension will be added later on.\r\ntrain_images = train_images[..., None]\r\n\r\n# Getting the images in [0, 1] range.\r\ntrain_images = train_images / np.float32(255)\r\n\r\n# Padding images because ResNet requires a miniaml shape of (32, 32)\r\npadded_train_images = np.concatenate([\r\n    np.zeros((len(train_images), 2, 28, 1)), \r\n    train_images, \r\n    np.zeros((len(train_images), 2, 28, 1))\r\n], axis=1)\r\npadded_train_images = np.concatenate([\r\n    np.zeros((len(train_images), 32, 2, 1)), \r\n    padded_train_images, \r\n    np.zeros((len(train_images), 32, 2, 1))\r\n], axis=2)\r\n\r\n# If the list of devices is not specified in the\r\n# `tf.distribute.MirroredStrategy` constructor, it will be auto-detected.\r\nstrategy = tf.distribute.MirroredStrategy()\r\n\r\nprint ('Number of devices: {}'.format(strategy.num_replicas_in_sync))\r\n\r\nBUFFER_SIZE = len(train_images)\r\n\r\nBATCH_SIZE_PER_REPLICA = 64\r\nGLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\r\n\r\nEPOCHS = 10\r\n\r\n# We keep only the first images, so that the last GPU receives an empty batch\r\npadded_train_images = padded_train_images[:strategy.num_replicas_in_sync-1]\r\ntrain_labels = train_labels[:strategy.num_replicas_in_sync-1]\r\n\r\ntrain_dataset = tf.data.Dataset.from_tensor_slices((padded_train_images, train_labels)).shuffle(BUFFER_SIZE).batch(GLOBAL_BATCH_SIZE) \r\ntrain_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\r\n\r\ndef create_model():\r\n  inputs = tf.keras.Input((32, 32, 1))\r\n  preprocessed = tf.keras.layers.Conv2D(3, (1, 1))(inputs) # ResNet requires 3 channels\r\n  features = tf.keras.applications.ResNet50V2(\r\n      include_top=False, \r\n      input_tensor=preprocessed, \r\n      pooling=\"avg\", weights=None).output\r\n  logits = tf.keras.layers.Dense(10)(features)\r\n  return tf.keras.Model(inputs, features)\r\n\r\nwith strategy.scope():\r\n  # Set reduction to `none` so we can do the reduction afterwards and divide by\r\n  # global batch size.\r\n  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\r\n      from_logits=True,\r\n      reduction=tf.keras.losses.Reduction.NONE)\r\n  def compute_loss(labels, predictions):\r\n    per_example_loss = loss_object(labels, predictions)\r\n    return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)\r\n\r\n# model, optimizer, and checkpoint must be created under `strategy.scope`.\r\nwith strategy.scope():\r\n  model = create_model()\r\n\r\n  optimizer = tf.keras.optimizers.Adam()\r\n\r\n  checkpoint = tf.train.Checkpoint(optimizer=optimizer, model=model)\r\n\r\ndef train_step(inputs):\r\n  images, labels = inputs\r\n\r\n  with tf.GradientTape() as tape:\r\n    predictions = model(images, training=True)\r\n    loss = compute_loss(labels, predictions)\r\n\r\n  gradients = tape.gradient(loss, model.trainable_variables)\r\n  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n  return loss \r\n\r\n# `run` replicates the provided computation and runs it\r\n# with the distributed input.\r\n@tf.function\r\ndef distributed_train_step(dataset_inputs):\r\n  per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))\r\n  return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,\r\n                         axis=None)\r\n\r\nfor epoch in range(EPOCHS):\r\n  # TRAIN LOOP\r\n  total_loss = 0.0\r\n  num_batches = 0\r\n  for x in train_dist_dataset:\r\n    total_loss += distributed_train_step(x)\r\n    num_batches += 1\r\n  train_loss = total_loss / num_batches\r\n\r\n  print(f\"Epoch {epoch+1}, Loss: {train_loss}\")\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nHere is the full trace of the execution of the code above on 4 GPUs:\r\n\r\n```bash\r\n2021-11-08 14:37:06.516502: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\r\n\r\n2.5.0\r\nWARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\r\n\r\n2021-11-08 14:37:14.416516: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\r\n2021-11-08 14:37:14.609629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \r\npciBusID: 0000:02:00.0 name: TITAN X (Pascal) computeCapability: 6.1\r\ncoreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s\r\n2021-11-08 14:37:14.610983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \r\npciBusID: 0000:03:00.0 name: TITAN X (Pascal) computeCapability: 6.1\r\ncoreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s\r\n2021-11-08 14:37:14.612266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 2 with properties: \r\npciBusID: 0000:82:00.0 name: TITAN X (Pascal) computeCapability: 6.1\r\ncoreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s\r\n2021-11-08 14:37:14.613980: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 3 with properties: \r\npciBusID: 0000:83:00.0 name: TITAN X (Pascal) computeCapability: 6.1\r\ncoreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s\r\n2021-11-08 14:37:14.614027: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\r\n2021-11-08 14:37:14.619791: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\r\n2021-11-08 14:37:14.619850: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\r\n2021-11-08 14:37:14.620958: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\r\n2021-11-08 14:37:14.621767: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\r\n2021-11-08 14:37:14.622819: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\r\n2021-11-08 14:37:14.623705: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\r\n2021-11-08 14:37:14.623948: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\r\n2021-11-08 14:37:14.651130: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1, 2, 3\r\n2021-11-08 14:37:14.652061: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-11-08 14:37:15.287138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \r\npciBusID: 0000:02:00.0 name: TITAN X (Pascal) computeCapability: 6.1\r\ncoreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s\r\n2021-11-08 14:37:15.289012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 1 with properties: \r\npciBusID: 0000:03:00.0 name: TITAN X (Pascal) computeCapability: 6.1\r\ncoreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s\r\n2021-11-08 14:37:15.290747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 2 with properties: \r\npciBusID: 0000:82:00.0 name: TITAN X (Pascal) computeCapability: 6.1\r\ncoreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s\r\n2021-11-08 14:37:15.292413: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 3 with properties: \r\npciBusID: 0000:83:00.0 name: TITAN X (Pascal) computeCapability: 6.1\r\ncoreClock: 1.531GHz coreCount: 28 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 447.48GiB/s\r\n2021-11-08 14:37:15.303710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0, 1, 2, 3\r\n2021-11-08 14:37:15.303805: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\r\n2021-11-08 14:37:17.190690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-11-08 14:37:17.190759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 1 2 3 \r\n2021-11-08 14:37:17.190771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N Y N N \r\n2021-11-08 14:37:17.190779: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 1:   Y N N N \r\n2021-11-08 14:37:17.190786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 2:   N N N Y \r\n2021-11-08 14:37:17.190793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 3:   N N Y N \r\n2021-11-08 14:37:17.198780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11436 MB memory) -> physical GPU (device: 0, name: TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)\r\n2021-11-08 14:37:17.200356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 11436 MB memory) -> physical GPU (device: 1, name: TITAN X (Pascal), pci bus id: 0000:03:00.0, compute capability: 6.1)\r\n2021-11-08 14:37:17.202384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 11436 MB memory) -> physical GPU (device: 2, name: TITAN X (Pascal), pci bus id: 0000:82:00.0, compute capability: 6.1)\r\n2021-11-08 14:37:17.203758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:3 with 11436 MB memory) -> physical GPU (device: 3, name: TITAN X (Pascal), pci bus id: 0000:83:00.0, compute capability: 6.1)\r\n\r\nINFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\r\nNumber of devices: 4\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\nINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\r\n\r\n2021-11-08 14:37:18.079248: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:695] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Found an unshardable source dataset: name: \"TensorSliceDataset/_2\"\r\nop: \"TensorSliceDataset\"\r\ninput: \"Placeholder/_0\"\r\ninput: \"Placeholder/_1\"\r\nattr {\r\n  key: \"Toutput_types\"\r\n  value {\r\n    list {\r\n      type: DT_DOUBLE\r\n      type: DT_UINT8\r\n    }\r\n  }\r\n}\r\nattr {\r\n  key: \"output_shapes\"\r\n  value {\r\n    list {\r\n      shape {\r\n        dim {\r\n          size: 32\r\n        }\r\n        dim {\r\n          size: 32\r\n        }\r\n        dim {\r\n          size: 1\r\n        }\r\n      }\r\n      shape {\r\n      }\r\n    }\r\n  }\r\n}\r\n\r\n2021-11-08 14:37:21.185304: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\r\n2021-11-08 14:37:21.205000: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2199965000 Hz\r\n\r\nWARNING:tensorflow:Gradients do not exist for variables ['conv2_block1_preact_bn/gamma:0', 'conv2_block1_preact_bn/beta:0', 'conv2_block1_1_bn/gamma:0', 'conv2_block1_1_bn/beta:0', 'conv2_block1_2_bn/gamma:0', 'conv2_block1_2_bn/beta:0', 'conv2_block2_preact_bn/gamma:0', 'conv2_block2_preact_bn/beta:0', 'conv2_block2_1_bn/gamma:0', 'conv2_block2_1_bn/beta:0', 'conv2_block2_2_bn/gamma:0', 'conv2_block2_2_bn/beta:0', 'conv2_block3_preact_bn/gamma:0', 'conv2_block3_preact_bn/beta:0', 'conv2_block3_1_bn/gamma:0', 'conv2_block3_1_bn/beta:0', 'conv2_block3_2_bn/gamma:0', 'conv2_block3_2_bn/beta:0', 'conv3_block1_preact_bn/gamma:0', 'conv3_block1_preact_bn/beta:0', 'conv3_block1_1_bn/gamma:0', 'conv3_block1_1_bn/beta:0', 'conv3_block1_2_bn/gamma:0', 'conv3_block1_2_bn/beta:0', 'conv3_block2_preact_bn/gamma:0', 'conv3_block2_preact_bn/beta:0', 'conv3_block2_1_bn/gamma:0', 'conv3_block2_1_bn/beta:0', 'conv3_block2_2_bn/gamma:0', 'conv3_block2_2_bn/beta:0', 'conv3_block3_preact_bn/gamma:0', 'conv3_block3_preact_bn/beta:0', 'conv3_block3_1_bn/gamma:0', 'conv3_block3_1_bn/beta:0', 'conv3_block3_2_bn/gamma:0', 'conv3_block3_2_bn/beta:0', 'conv3_block4_preact_bn/gamma:0', 'conv3_block4_preact_bn/beta:0', 'conv3_block4_1_bn/gamma:0', 'conv3_block4_1_bn/beta:0', 'conv3_block4_2_bn/gamma:0', 'conv3_block4_2_bn/beta:0', 'conv4_block1_preact_bn/gamma:0', 'conv4_block1_preact_bn/beta:0', 'conv4_block1_1_bn/gamma:0', 'conv4_block1_1_bn/beta:0', 'conv4_block1_2_bn/gamma:0', 'conv4_block1_2_bn/beta:0', 'conv4_block2_preact_bn/gamma:0', 'conv4_block2_preact_bn/beta:0', 'conv4_block2_1_bn/gamma:0', 'conv4_block2_1_bn/beta:0', 'conv4_block2_2_bn/gamma:0', 'conv4_block2_2_bn/beta:0', 'conv4_block3_preact_bn/gamma:0', 'conv4_block3_preact_bn/beta:0', 'conv4_block3_1_bn/gamma:0', 'conv4_block3_1_bn/beta:0', 'conv4_block3_2_bn/gamma:0', 'conv4_block3_2_bn/beta:0', 'conv4_block4_preact_bn/gamma:0', 'conv4_block4_preact_bn/beta:0', 'conv4_block4_1_bn/gamma:0', 'conv4_block4_1_bn/beta:0', 'conv4_block4_2_bn/gamma:0', 'conv4_block4_2_bn/beta:0', 'conv4_block5_preact_bn/gamma:0', 'conv4_block5_preact_bn/beta:0', 'conv4_block5_1_bn/gamma:0', 'conv4_block5_1_bn/beta:0', 'conv4_block5_2_bn/gamma:0', 'conv4_block5_2_bn/beta:0', 'conv4_block6_preact_bn/gamma:0', 'conv4_block6_preact_bn/beta:0', 'conv4_block6_1_bn/gamma:0', 'conv4_block6_1_bn/beta:0', 'conv4_block6_2_bn/gamma:0', 'conv4_block6_2_bn/beta:0', 'conv5_block1_preact_bn/gamma:0', 'conv5_block1_preact_bn/beta:0', 'conv5_block1_1_bn/gamma:0', 'conv5_block1_1_bn/beta:0', 'conv5_block1_2_bn/gamma:0', 'conv5_block1_2_bn/beta:0', 'conv5_block2_preact_bn/gamma:0', 'conv5_block2_preact_bn/beta:0', 'conv5_block2_1_bn/gamma:0', 'conv5_block2_1_bn/beta:0', 'conv5_block2_2_bn/gamma:0', 'conv5_block2_2_bn/beta:0', 'conv5_block3_preact_bn/gamma:0', 'conv5_block3_preact_bn/beta:0', 'conv5_block3_1_bn/gamma:0', 'conv5_block3_1_bn/beta:0', 'conv5_block3_2_bn/gamma:0', 'conv5_block3_2_bn/beta:0', 'post_bn/gamma:0', 'post_bn/beta:0'] when minimizing the loss.\r\nINFO:tensorflow:Error reported to Coordinator: \r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/training/coordinator.py\", line 297, in stop_on_exception\r\n    yield\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/mirrored_run.py\", line 220, in _call_for_each_replica\r\n    merge_args = distribute_utils.regroup(\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_utils.py\", line 62, in regroup\r\n    regrouped_tuple = tuple(\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_utils.py\", line 63, in <genexpr>\r\n    regroup(tuple(v[i] for v in values), wrap_class, always_wrap)\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_utils.py\", line 61, in regroup\r\n    assert len(v) == len(v0)\r\nAssertionError\r\n\r\n---------------------------------------------------------------------------\r\nAssertionError                            Traceback (most recent call last)\r\n/tmp/ipykernel_21821/3562653524.py in <module>\r\n    105   num_batches = 0\r\n    106   for x in train_dist_dataset:\r\n--> 107     total_loss += distributed_train_step(x)\r\n    108     num_batches += 1\r\n    109   train_loss = total_loss / num_batches\r\n\r\n/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    887 \r\n    888       with OptionalXlaContext(self._jit_compile):\r\n--> 889         result = self._call(*args, **kwds)\r\n    890 \r\n    891       new_tracing_count = self.experimental_get_tracing_count()\r\n\r\n/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    931       # This is the first call of __call__, so we have to initialize.\r\n    932       initializers = []\r\n--> 933       self._initialize(args, kwds, add_initializers_to=initializers)\r\n    934     finally:\r\n    935       # At this point we know that the initialization is complete (or less\r\n\r\n/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)\r\n    761     self._graph_deleter = FunctionDeleter(self._lifted_initializer_graph)\r\n    762     self._concrete_stateful_fn = (\r\n--> 763         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n    764             *args, **kwds))\r\n    765 \r\n\r\n/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)\r\n   3048       args, kwargs = None, None\r\n   3049     with self._lock:\r\n-> 3050       graph_function, _ = self._maybe_define_function(args, kwargs)\r\n   3051     return graph_function\r\n   3052 \r\n\r\n/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n   3442 \r\n   3443           self._function_cache.missed.add(call_context_key)\r\n-> 3444           graph_function = self._create_graph_function(args, kwargs)\r\n   3445           self._function_cache.primary[cache_key] = graph_function\r\n   3446 \r\n\r\n/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   3277     arg_names = base_arg_names + missing_arg_names\r\n   3278     graph_function = ConcreteFunction(\r\n-> 3279         func_graph_module.func_graph_from_py_func(\r\n   3280             self._name,\r\n   3281             self._python_function,\r\n\r\n/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    997         _, original_func = tf_decorator.unwrap(python_func)\r\n    998 \r\n--> 999       func_outputs = python_func(*func_args, **func_kwargs)\r\n   1000 \r\n   1001       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\n/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)\r\n    670         # the function a weak reference to itself to avoid a reference cycle.\r\n    671         with OptionalXlaContext(compile_with_xla):\r\n--> 672           out = weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    673         return out\r\n    674 \r\n\r\n/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)\r\n    984           except Exception as e:  # pylint:disable=broad-except\r\n    985             if hasattr(e, \"ag_error_metadata\"):\r\n--> 986               raise e.ag_error_metadata.to_exception(e)\r\n    987             else:\r\n    988               raise\r\n\r\nAssertionError: in user code:\r\n\r\n    /tmp/ipykernel_21821/3562653524.py:98 distributed_train_step  *\r\n        per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))\r\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py:1285 run  **\r\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\r\n        return self._call_for_each_replica(fn, args, kwargs)\r\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/mirrored_strategy.py:678 _call_for_each_replica\r\n        return mirrored_run.call_for_each_replica(\r\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/mirrored_run.py:104 call_for_each_replica\r\n        return _call_for_each_replica(strategy, fn, args, kwargs)\r\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/mirrored_run.py:245 _call_for_each_replica\r\n        coord.join(threads)\r\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/training/coordinator.py:389 join\r\n        six.reraise(*self._exc_info_to_raise)\r\n    /usr/local/lib/python3.8/dist-packages/six.py:703 reraise\r\n        raise value\r\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/training/coordinator.py:297 stop_on_exception\r\n        yield\r\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/mirrored_run.py:220 _call_for_each_replica\r\n        merge_args = distribute_utils.regroup(\r\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_utils.py:62 regroup\r\n        regrouped_tuple = tuple(\r\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_utils.py:63 <genexpr>\r\n        regroup(tuple(v[i] for v in values), wrap_class, always_wrap)\r\n    /usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/distribute_utils.py:61 regroup\r\n        assert len(v) == len(v0)\r\n\r\n    AssertionError: \r\n```\r\n", "comments": ["I found 2 workarounds for this issue:\r\n- use the `drop_remainder` option when creating the training dataset, so that all batches are full. The problem with this solution is that the `BatchNormalization` layers are still not synced accross replicas, which blocks me to reproduce the performance of a single GPU training.\r\n- convert the `BatchNormalization` layers to `SyncBatchNormalization`. Since I'm using models from `tf.keras.applications`, I can't simply change the layers in the code. Thus, I implemented this method that allows me to do this programmatically:\r\n```python\r\n def convert_to_sync_batch_norm(old_model: tf.keras.Model, input_layer: tf.keras.Input):\r\n    old_layer_names = [layer.name for layer in old_model.layers]\r\n    new_xs = [input_layer]\r\n    for old_layer in old_model.layers[1:]:\r\n        if isinstance(old_layer.input, list):\r\n            input_x = [new_xs[old_layer_names.index(l.name.split(\"/\")[0])] for l in old_layer.input]\r\n        else:\r\n            input_x = new_xs[old_layer_names.index(old_layer.input.name.split(\"/\")[0])]\r\n        if isinstance(old_layer, tf.keras.layers.BatchNormalization):\r\n            old_layer = tf.keras.layers.experimental.SyncBatchNormalization.from_config(\r\n                old_layer.get_config()\r\n            )\r\n        x = old_layer(input_x)\r\n        new_xs.append(x)\r\n\r\n    new_model = tf.keras.Model(new_xs[0], new_xs[-1])\r\n    for old_layer, new_layer in zip(old_model.layers, new_model.layers):\r\n        new_layer.set_weights(old_layer.get_weights())\r\n\r\n    return new_model\r\n```\r\n  and here is how I call this method:\r\n  ```python\r\n    input = tf.keras.Input(shape, name=\"image\")\r\n    preprocess = tf.keras.layers.Lambda(\r\n        tf.keras.applications.resnet_v2.preprocess_input, name=\"x_preprocess\"\r\n    )(input)\r\n    backbone = tf.keras.applications.ResNet50V2(\r\n        include_top=False, pooling=\"avg\", input_tensor=preprocess\r\n    )\r\n    backbone = tf.keras.Model(input, backbone.output)\r\n    new_backbone = convert_to_sync_batch_norm(backbone, input_layer=input)\r\n  ```\r\nThis is not a very clean solution, but at least I can launch experiments with the `SyncBatchNormalization`", "Thanks for reporting the issue! We're able to reproduce it and are working on a fix.", "Could you try using tf-nightly and reporting if you still see this issue?", "The issue isn't present with `tf-nightly-2.9.0.dev20220120`", "Great, thanks for checking! The fix should be available with 2.9, until then keep using tf-nightly. Closing this issue now.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52986\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52986\">No</a>\n", "Thanks for your anwser !\r\nJust to be sure I understand the fix, it means that `BatchNormalization` layers won't fail when given an empty batch (because of the multi GPU context) so that `drop_remainder = False` isn't necessary anymore. But, the models in `tf.keras.applications` will still use `BatchNormalization` and not `SyncBatchNormalization`, meaning that they won't perform as good in a multi GPU context.\r\nAm I right ?", "right, the resnet models provided by keras don't use SyncBatchNormalization. If you use BatchNormalization with a synchronous multi-gpu context like MirroredStrategy, each GPU will normalize using only its own input, rather than including that of all other devices. Then during inference, each GPU will use its own computed mean and variance values based on the inputs it saw during training (with SyncBatchNormalization these values would be the same). \r\n\r\nIt should still train just fine and AFAIK could still lead to acceptable results, but it's not the same operation as SyncBatchNormalization"]}, {"number": 52985, "title": "Possible Bug on Building From Source (crosstool_wrapper_driver_is_not_gcc)", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 18:04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.5.x, 2.6.x, 2.7.0\r\n- Python version: 3.6.9\r\n- Installed using virtualenv? pip? conda?: Docker (nvidia/cuda:11.4.2-cudnn8-runtime-ubuntu18.04)\r\n- Bazel version (if compiling from source): 3.7.2- (@non-git)\r\n- GCC/Compiler version (if compiling from source): gcc (Ubuntu 7.5.0-3ubuntu1~18.04) 7.5.0\r\n- CUDA/cuDNN version: CUDA 11.4.2 & cuDNN 8.2.4\r\n- GPU model and memory: Both RTX 3060 12GB (C.C. 8.6) & NVIDIA A100 40GB PCIe (C.C. 8.0)\r\n\r\n\r\n\r\n**Describe the problem**\r\nHi. I am having problems while trying to build various versions of the TensorFlow from source. **I have successfully built TF v2.6.0 on NVIDIA A100 40GB PCIe server** but I can not build any other version. I tried with all the versions between 2.5.x and 2.7.0. The main problem is something related to `crosstool_wrapper_driver_is_not_gcc` error. However, I can not find any proper solution to this. I have tried the solution provided on the following link without any luck: #13481. Which was:\r\n\r\n```\r\nsh -c \"echo '/usr/local/cuda-11.4/lib64' >> /etc/ld.so.conf.d/nvidia.conf\"\r\nldconfig\r\n```\r\nNone of the following CUDA/cuDNN/TensorRT combination works. I am using TensorRT 8.0.3 deb file installation and NVIDIA claims `versions 10.2, 11.0 update 1, 11.1 update 1, 11.2 update 2, 11.3 update 1, and 11.4 update 2 are supported.` in the docs:\r\n\r\n- CUDA 11.4.2 | cuDNN 8.2.4 | TensorRT 8.0.3 --> For TF v2.7.0 \r\n- CUDA 11.3.1 | cuDNN 8.2.0 | TensorRT 8.0.3 --> For TF v2.5.x and v2.6.x\r\n- CUDA 11.2.2 | cuDNN 8.1.1 | TensorRT 8.0.3 --> For TF v2.5.x\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nThe list of inputs for the `./configure`:\r\n```\r\n'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/local/lib/python3.6/dist-packages --python_path=/usr/bin/python3 --config=tensorrt --action_env CUDA_TOOLKIT_PATH=/usr/local/cuda-11.4 --action_env TF_CUDA_COMPUTE_CAPABILITIES=8.6,8.0 --action_env LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 --action_env GCC_HOST_COMPILER_PATH=/usr/bin/x86_64-linux-gnu-gcc-7 --config=cuda\r\n```\r\nAnd here is the Bazel build command:\r\n`bazel build -j 10 -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package --verbose_failures`\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. This \r\n\r\nLast of all here is my full error output:\r\n```\r\nWARNING: The following configs were expanded more than once: [cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=211\r\nINFO: Reading rc options for 'build' from /root/tensorflow/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /root/tensorflow/.bazelrc:\r\n  'build' options: --define framework_shared_object=true --java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --host_java_toolchain=@tf_toolchains//toolchains/java:tf_java_toolchain --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --enable_platform_specific_config --define=with_xla_support=true --config=short_logs --config=v2 --define=no_aws_support=true --define=no_hdfs_support=true\r\nINFO: Reading rc options for 'build' from /root/tensorflow/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/local/lib/python3.6/dist-packages --python_path=/usr/bin/python3 --config=tensorrt --action_env CUDA_TOOLKIT_PATH=/usr/local/cuda-11.4 --action_env TF_CUDA_COMPUTE_CAPABILITIES=8.6,8.0 --action_env LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 --action_env GCC_HOST_COMPILER_PATH=/usr/bin/x86_64-linux-gnu-gcc-7 --config=cuda\r\nINFO: Reading rc options for 'build' from /root/tensorflow/.bazelrc:\r\n  'build' options: --deleted_packages=tensorflow/compiler/mlir/tfrt,tensorflow/compiler/mlir/tfrt/benchmarks,tensorflow/compiler/mlir/tfrt/jit/python_binding,tensorflow/compiler/mlir/tfrt/jit/transforms,tensorflow/compiler/mlir/tfrt/python_tests,tensorflow/compiler/mlir/tfrt/tests,tensorflow/compiler/mlir/tfrt/tests/saved_model,tensorflow/compiler/mlir/tfrt/transforms/lhlo_gpu_to_tfrt_gpu,tensorflow/core/runtime_fallback,tensorflow/core/runtime_fallback/conversion,tensorflow/core/runtime_fallback/kernel,tensorflow/core/runtime_fallback/opdefs,tensorflow/core/runtime_fallback/runtime,tensorflow/core/runtime_fallback/util,tensorflow/core/tfrt/common,tensorflow/core/tfrt/eager,tensorflow/core/tfrt/eager/backends/cpu,tensorflow/core/tfrt/eager/backends/gpu,tensorflow/core/tfrt/eager/core_runtime,tensorflow/core/tfrt/eager/cpp_tests/core_runtime,tensorflow/core/tfrt/fallback,tensorflow/core/tfrt/gpu,tensorflow/core/tfrt/run_handler_thread_pool,tensorflow/core/tfrt/runtime,tensorflow/core/tfrt/saved_model,tensorflow/core/tfrt/saved_model/tests,tensorflow/core/tfrt/tpu,tensorflow/core/tfrt/utils\r\nINFO: Found applicable config definition build:short_logs in file /root/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /root/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:tensorrt in file /root/tensorflow/.bazelrc: --repo_env TF_NEED_TENSORRT=1\r\nINFO: Found applicable config definition build:cuda in file /root/tensorflow/.bazelrc: --repo_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --@local_config_cuda//:enable_cuda\r\nINFO: Found applicable config definition build:cuda in file /root/tensorflow/.bazelrc: --repo_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --@local_config_cuda//:enable_cuda\r\nINFO: Found applicable config definition build:linux in file /root/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --define=PROTOBUF_INCLUDE_PATH=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels --distinct_host_configuration=false --experimental_guard_against_concurrent_changes\r\nINFO: Found applicable config definition build:dynamic_kernels in file /root/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS\r\nWARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/llvm/llvm-project/archive/43d6991c2a4cc2ac374e68c029634f2b59ffdfdf.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nWARNING: Download from http://mirror.tensorflow.org/github.com/tensorflow/runtime/archive/64c92c8013b557087351c91b5423b6046d10f206.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nDEBUG: /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/bazel_tools/tools/cpp/lib_cc_configure.bzl:118:10: \r\nAuto-Configuration Warning: 'TMP' environment variable is not set, using 'C:\\Windows\\Temp' as default\r\nDEBUG: Rule 'io_bazel_rules_docker' indicated that a canonical reproducible form can be obtained by modifying arguments shallow_since = \"1596824487 -0400\"\r\nDEBUG: Repository io_bazel_rules_docker instantiated at:\r\n  /root/tensorflow/WORKSPACE:23:14: in <toplevel>\r\n  /root/tensorflow/tensorflow/workspace0.bzl:108:34: in workspace\r\n  /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/bazel_toolchains/repositories/repositories.bzl:35:23: in repositories\r\nRepository rule git_repository defined at:\r\n  /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/bazel_tools/tools/build_defs/repo/git.bzl:199:33: in <toplevel>\r\nWARNING: Download from https://storage.googleapis.com/mirror.tensorflow.org/github.com/NVIDIA/cudnn-frontend/archive/73210a930333eaf66b42b01693bce7b70719c354.zip failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\r\nINFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (0 packages loaded, 0 targets configured).\r\nINFO: Found 1 target...\r\nERROR: /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/llvm-project/llvm/BUILD.bazel:673:11: C++ compilation of rule '@llvm-project//llvm:Core' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command \r\n  (cd /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    CUDA_TOOLKIT_PATH=/usr/local/cuda-11.4 \\\r\n    GCC_HOST_COMPILER_PATH=/usr/bin/x86_64-linux-gnu-gcc-7 \\\r\n    LD_LIBRARY_PATH=/usr/local/nvidia/lib:/usr/local/nvidia/lib64 \\\r\n    PATH=/usr/local/cuda-11.3/bin/nvcc:/root/bazel-3.7.2/output:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/usr/bin/python3 \\\r\n    PYTHON_LIB_PATH=/usr/local/lib/python3.6/dist-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n    TF_CUDA_COMPUTE_CAPABILITIES=8.6,8.0 \\\r\n  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -MD -MF bazel-out/k8-opt/bin/external/llvm-project/llvm/_objs/Core/TypeFinder.d '-frandom-seed=bazel-out/k8-opt/bin/external/llvm-project/llvm/_objs/Core/TypeFinder.o' '-DLLVM_ON_UNIX=1' '-DHAVE_BACKTRACE=1' '-DBACKTRACE_HEADER=<execinfo.h>' '-DLTDL_SHLIB_EXT=\".so\"' '-DLLVM_PLUGIN_EXT=\".so\"' '-DLLVM_ENABLE_THREADS=1' '-DHAVE_SYSEXITS_H=1' '-DHAVE_UNISTD_H=1' '-DHAVE_STRERROR_R=1' '-DHAVE_LIBPTHREAD=1' '-DHAVE_PTHREAD_GETNAME_NP=1' '-DHAVE_PTHREAD_SETNAME_NP=1' '-DHAVE_PTHREAD_GETSPECIFIC=1' '-DHAVE_REGISTER_FRAME=1' '-DHAVE_DEREGISTER_FRAME=1' -D_GNU_SOURCE '-DHAVE_LINK_H=1' '-DHAVE_LSEEK64=1' '-DHAVE_MALLINFO=1' '-DHAVE_POSIX_FALLOCATE=1' '-DHAVE_SBRK=1' '-DHAVE_STRUCT_STAT_ST_MTIM_TV_NSEC=1' '-DLLVM_NATIVE_ARCH=\"X86\"' '-DLLVM_NATIVE_ASMPARSER=LLVMInitializeX86AsmParser' '-DLLVM_NATIVE_ASMPRINTER=LLVMInitializeX86AsmPrinter' '-DLLVM_NATIVE_DISASSEMBLER=LLVMInitializeX86Disassembler' '-DLLVM_NATIVE_TARGET=LLVMInitializeX86Target' '-DLLVM_NATIVE_TARGETINFO=LLVMInitializeX86TargetInfo' '-DLLVM_NATIVE_TARGETMC=LLVMInitializeX86TargetMC' '-DLLVM_NATIVE_TARGETMCA=LLVMInitializeX86TargetMCA' '-DLLVM_HOST_TRIPLE=\"x86_64-unknown-linux-gnu\"' '-DLLVM_DEFAULT_TARGET_TRIPLE=\"x86_64-unknown-linux-gnu\"' -D__STDC_LIMIT_MACROS -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -iquote external/llvm-project -iquote bazel-out/k8-opt/bin/external/llvm-project -iquote external/llvm_terminfo -iquote bazel-out/k8-opt/bin/external/llvm_terminfo -iquote external/llvm_zlib -iquote bazel-out/k8-opt/bin/external/llvm_zlib -isystem external/llvm-project/llvm/include -isystem bazel-out/k8-opt/bin/external/llvm-project/llvm/include -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fPIE -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -fno-omit-frame-pointer -no-canonical-prefixes -fno-canonical-system-headers -DNDEBUG -g0 -O2 -ffunction-sections -fdata-sections -w -DAUTOLOAD_DYNAMIC_KERNELS '-std=c++14' -c external/llvm-project/llvm/lib/IR/TypeFinder.cpp -o bazel-out/k8-opt/bin/external/llvm-project/llvm/_objs/Core/TypeFinder.o)\r\nExecution platform: @local_execution_config_platform//:platform\r\nIn file included from external/llvm-project/llvm/include/llvm/ADT/Hashing.h:55:0,\r\n                 from external/llvm-project/llvm/include/llvm/ADT/DenseMapInfo.h:16,\r\n                 from external/llvm-project/llvm/include/llvm/ADT/DenseMap.h:16,\r\n                 from external/llvm-project/llvm/include/llvm/ADT/DenseSet.h:16,\r\n                 from external/llvm-project/llvm/include/llvm/IR/TypeFinder.h:16,\r\n                 from external/llvm-project/llvm/lib/IR/TypeFinder.cpp:13:\r\n/usr/include/c++/7/tuple: In instantiation of 'class std::tuple<llvm::DISubroutineType*, llvm::TempMDNodeDeleter>':\r\n/usr/include/c++/7/bits/unique_ptr.h:152:27:   required from 'class std::__uniq_ptr_impl<llvm::DISubroutineType, llvm::TempMDNodeDeleter>'\r\n/usr/include/c++/7/bits/unique_ptr.h:163:33:   required from 'class std::unique_ptr<llvm::DISubroutineType, llvm::TempMDNodeDeleter>'\r\nexternal/llvm-project/llvm/include/llvm/IR/DebugInfoMetadata.h:1307:42:   required from here\r\n/usr/include/c++/7/tuple:1128:2: internal compiler error: Segmentation fault\r\n  tuple(allocator_arg_t __tag, const _Alloc& __a,\r\n  ^~~~~\r\nPlease submit a full bug report,\r\nwith preprocessed source if appropriate.\r\nSee <file:///usr/share/doc/gcc-7/README.Bugs> for instructions.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 824.851s, Critical Path: 58.83s\r\nINFO: 3373 processes: 785 internal, 2588 local.\r\nFAILED: Build did NOT complete successfully\r\n\r\n```\r\n", "comments": ["Could you please refer [this](https://www.tensorflow.org/install/source#gpu) table and try the versions mentioned for Tensorflow 2.7 and let us know if you are still facing error. Thanks", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52985\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52985\">No</a>\n"]}, {"number": 52983, "title": "tensorflow-estimatior==2.0.0 not available so can't fix known issue", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution Linux Ubuntu 20.04.2 LTS\r\n- Installed using mamba\r\n- TensorFlow version: 2.0.0\r\n- Python version: 2.7.0\r\n\r\n**Describe the problem**\r\nDefault  tensorflow-estimator  mismatches tensorflow as in https://stackoverflow.com/questions/66022256/modulenotfounderror-no-module-named-tensorflow-core-estimator-for-tensorflow\r\nbut for 2.0.0 can't be installed direclty as in https://stackoverflow.com/a/66027093/7607734\r\n(it worked for tf 2.1.0)\r\nalso https://stackoverflow.com/a/66027135/7607734 gives nothing.\r\nSo seem to be unresolved for 2.0.0\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n1) \r\nmamba create --name py3_7_keras_ocr  python=3.7.0 keras-ocr anaconda\r\n2) \r\nconda activate py3_7_keras_ocr\r\n3)\r\n conda list | grep tensorflow\r\n4)\r\nmamba install tensorflow-estimatior==2.0.0\r\nor\r\nconda install tensorflow-estimatior==2.0.0\r\n\r\n**Any other info / logs**\r\n3)\r\n> conda list | grep tensorflow\r\n\r\n```\r\ntensorflow                2.0.0           mkl_py37h66b46cc_0  \r\ntensorflow-base           2.0.0           mkl_py37h9204916_0  \r\ntensorflow-estimator      2.6.0              pyh7b7c402_0  \r\n```\r\n\r\n4)\r\n> conda install tensorflow-estimatior==2.0.0\r\n```\r\nCollecting package metadata (current_repodata.json): done\r\nSolving environment: failed with initial frozen solve. Retrying with flexible solve.\r\nCollecting package metadata (repodata.json): done\r\nSolving environment: failed with initial frozen solve. Retrying with flexible solve.\r\n\r\nPackagesNotFoundError: The following packages are not available from current channels:\r\n\r\n  - tensorflow-estimatior==2.0.0\r\nCurrent channels:\r\n\r\n  - https://conda.anaconda.org/conda-forge/linux-64\r\n  - https://conda.anaconda.org/conda-forge/noarch\r\n  - https://repo.anaconda.com/pkgs/main/linux-64\r\n  - https://repo.anaconda.com/pkgs/main/noarch\r\n  - https://repo.anaconda.com/pkgs/r/linux-64\r\n  - https://repo.anaconda.com/pkgs/r/noarch\r\n```\r\n\r\n", "comments": ["You have a typo\r\n\r\n```diff\r\n-conda install tensorflow-estimatior==2.0.0\r\n+conda install tensorflow-estimator==2.0.0\r\n```", "Thank you!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52983\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52983\">No</a>\n"]}, {"number": 52982, "title": "Problem with calling the same object twice in the \"call\" part", "body": "My model is this:\r\n\r\n```\r\nclass DenseModel(Model):\r\n    def __init__(self):\r\n        super(DenseModel, self).__init__(name='class_dense_model')\r\n        self.dense_1 = layers.Dense(1)\r\n        self.dense_64 = layers.Dense(64, activation=tf.nn.relu)\r\n        self.dense_100 = layers.Dense(100,activation=tf.nn.relu)\r\n        self.dense_200 = layers.Dense(200,activation=tf.nn.relu)\r\n        self.dense_200_2 = layers.Dense(200, activation=tf.nn.relu)\r\n\r\n    def call(self, input_tensor, training=False, **kwargs):\r\n        out_1 = self.dense_64(input_tensor)\r\n        out_2 = self.dense_100(out_1)\r\n        out_3 = self.dense_200(out_2)\r\n        out_4 = self.dense_200(out_3)\r\n        return self.dense_1(out_4)\r\n\r\n    def build_graph(self, shape):\r\n        x = tf.keras.layers.Input(shape=shape)\r\n        return Model(inputs=[x], outputs=self.call(x))\r\n```\r\n\r\nThen I build it like this \r\n\r\n```\r\nmodel = DenseModel()\r\nmodel.build_graph(INPUT_SHAPE)\r\n```\r\n\r\nThis gives me the following error:\r\n\r\n\"ValueError: Dimensions must be equal, but are 200 and 100 for '{{node dense_5/MatMul}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Placeholder, dense_5/MatMul/ReadVariableOp)' with input shapes: [?,200], [100,200].\"\r\n\r\nWhen I change ```out_4 = self.dense_200(out_3)``` into ```out_4 = self.dense_200_2(out_3)``` the error is gone. I realized that the error is caused when using the same object twice in the \"call\" part. I checked the documentation from this link https://www.tensorflow.org/guide/keras/custom_layers_and_models\r\n\r\nI saw that you build two objects from the same class and the same parameters in __init__ part. Why? I mean, why do we have problem with calling the same object twice in the \"call\" part? What if I want to call one object 100 times in for loop? I mean, I just don't understand why I get this error when it shouldn't be the error.\r\n\r\n\r\n", "comments": ["@alemyewno \r\nPlease post this issue on [keras-team/keras repo.](https://github.com/keras-team/keras/issues)\r\nTo know more see;\r\n[https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999](https://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999)\r\nThank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52982\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52982\">No</a>\n"]}, {"number": 52981, "title": "Pip install tensorflow==2.7.0 expects cuda 11.0 instead 11.2", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\nWell, it seems to fall between a bug and an installation issue :P\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip \r\n- TensorFlow version: 2.6.1 upgrading to 2.7 via pip\r\n- Python version:  3.8.12\r\n- Installed using virtualenv? pip? conda?: conda for env incl cudatoolkit and cudnn, pip for tf 2.6.1 and 2.7.0\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: 11.2.2               he111cf0_8    nvidia; 8.1.0.77             h90431f1_0    conda-forge\r\n- GPU model and memory: k80\r\n\r\n\r\n\r\n**Describe the problem**\r\nJust set up a running TF 2.6.1 using pip in a conda env last week following the requirements as state in https://www.tensorflow.org/install/gpu. When I upgraded to 2.7 via pip the installed package suddenly required cuda 11.0 and thus fails to load/use the gpu. \r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nconda update --force conda\r\nconda create -n tf2 python=3.8\r\nconda activate tf2\r\nconda install cudatoolkit==11.3\r\nconda install cudatoolkit==11.3.1\r\nconda install cudnn\r\nconda install pandas numpy scikit-learn\r\nconda install cupti\r\nconda remove cudnn\r\nconda remove cupti\r\nconda remove cudatoolkit\r\nconda install -c nvidia cudatoolkit==11.2\r\nconda install -c nvidia cudatoolkit==11.2.2\r\nconda list -n tf2\r\nconda install -c nvidia cudnn=8.1.0\r\nconda install -c conda-forge cudnn=8.1.0\r\npip install --upgrade tensorflow     # this was under 2.6.1; needs ==2.6.1 now\r\nconda install matplotlib seaborn\r\nnvidia-smi\r\nconda install -c conda-forge notebook jupyter ipykernel jupyter_contrib_nbextensions\r\njupyter notebook --generate-config\r\nvi .jupyter/jupyter_notebook_config.py\r\njupyter notebook password\r\nvi .jupyter/jupyter_notebook_config.py\r\nsudo\r\nsudo print\r\nsudo systemctl start jupyter.service\r\nsudo systemctl stop jupyter.service\r\nsudo systemctl start jupyter.service\r\npip install tensorflow-datasets\r\n<em>this was my working 2.6.1 install with gpu available</em> Then I proceeded to upgrade to 2.7 once it became available:\r\npip install -U tensorflow\r\n<em> \r\nThis then leads to the new TF looking for Cuda 11.0!\r\nInstalling collected packages: tensorflow-estimator, keras, tensorflow\r\n  Attempting uninstall: tensorflow-estimator\r\n    Found existing installation: tensorflow-estimator 2.6.0\r\n    Uninstalling tensorflow-estimator-2.6.0:\r\n      Successfully uninstalled tensorflow-estimator-2.6.0\r\n  Attempting uninstall: keras\r\n    Found existing installation: keras 2.6.0\r\n    Uninstalling keras-2.6.0:\r\n      Successfully uninstalled keras-2.6.0\r\n  Attempting uninstall: tensorflow\r\n    Found existing installation: tensorflow 2.6.1\r\n    Uninstalling tensorflow-2.6.1:\r\n      Successfully uninstalled tensorflow-2.6.1\r\nSuccessfully installed keras-2.7.0 tensorflow-2.7.0 tensorflow-estimator-2.7.0\r\n\r\n>>> import tensorflow as tf\r\n2021-11-08 09:33:10.345741: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\r\n2021-11-08 09:33:10.345774: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n# packages in environment at /home/student/miniconda3/envs/tf2:\r\n#\r\n# Name                    Version                   Build  Channel\r\n_libgcc_mutex             0.1                        main\r\n_openmp_mutex             4.5                       1_gnu\r\nabsl-py                   0.12.0                   pypi_0    pypi\r\nargon2-cffi               20.1.0           py38h27cfd23_1\r\nastunparse                1.6.3                    pypi_0    pypi\r\nasync_generator           1.10                       py_0    conda-forge\r\nattrs                     21.2.0             pyhd8ed1ab_0    conda-forge\r\nbackcall                  0.2.0              pyh9f0ad1d_0    conda-forge\r\nbackports                 1.0                        py_2    conda-forge\r\nbackports.functools_lru_cache 1.6.4              pyhd8ed1ab_0    conda-forge\r\nblas                      1.0                         mkl\r\nbleach                    4.1.0              pyhd8ed1ab_0    conda-forge\r\nbottleneck                1.3.2            py38heb32a55_1\r\nbrotli                    1.0.9                he6710b0_2\r\nca-certificates           2021.10.8            ha878542_0    conda-forge\r\ncachetools                4.2.4                    pypi_0    pypi\r\ncertifi                   2021.10.8        py38h578d9bd_1    conda-forge\r\ncffi                      1.14.6           py38ha65f79e_0    conda-forge\r\ncharset-normalizer        2.0.7                    pypi_0    pypi\r\nclang                     5.0                      pypi_0    pypi\r\ncudatoolkit               11.2.2               he111cf0_8    nvidia\r\ncudnn                     8.1.0.77             h90431f1_0    conda-forge\r\ncycler                    0.10.0                   py38_0\r\ndbus                      1.13.18              hb2f20db_0\r\ndebugpy                   1.4.1            py38h709712a_0    conda-forge\r\ndecorator                 5.1.0              pyhd8ed1ab_0    conda-forge\r\ndefusedxml                0.7.1              pyhd8ed1ab_0    conda-forge\r\ndill                      0.3.4                    pypi_0    pypi\r\nentrypoints               0.3             pyhd8ed1ab_1003    conda-forge\r\nexpat                     2.4.1                h2531618_2\r\nflatbuffers               1.12                     pypi_0    pypi\r\nfontconfig                2.13.1               h6c09931_0\r\nfonttools                 4.25.0             pyhd3eb1b0_0\r\nfreetype                  2.11.0               h70c0345_0\r\nfuture                    0.18.2                   pypi_0    pypi\r\ngast                      0.4.0                    pypi_0    pypi\r\ngiflib                    5.2.1                h7b6447c_0\r\nglib                      2.69.1               h5202010_0\r\ngoogle-auth               2.3.3                    pypi_0    pypi\r\ngoogle-auth-oauthlib      0.4.6                    pypi_0    pypi\r\ngoogle-pasta              0.2.0                    pypi_0    pypi\r\ngoogleapis-common-protos  1.53.0                   pypi_0    pypi\r\ngrpcio                    1.41.1                   pypi_0    pypi\r\ngst-plugins-base          1.14.0               h8213a91_2\r\ngstreamer                 1.14.0               h28cd5cc_2\r\nh5py                      3.1.0                    pypi_0    pypi\r\nicu                       58.2                 he6710b0_3\r\nidna                      3.3                      pypi_0    pypi\r\nimportlib-metadata        4.8.1            py38h578d9bd_1    conda-forge\r\nimportlib-resources       5.4.0                    pypi_0    pypi\r\nintel-openmp              2021.4.0          h06a4308_3561\r\nipykernel                 6.4.2            py38he5a9106_0    conda-forge\r\nipython                   7.29.0           py38he5a9106_1    conda-forge\r\nipython_genutils          0.2.0                      py_1    conda-forge\r\nipywidgets                7.6.5              pyhd8ed1ab_0    conda-forge\r\njedi                      0.18.0           py38h578d9bd_3    conda-forge\r\njinja2                    3.0.2              pyhd8ed1ab_0    conda-forge\r\njoblib                    1.1.0              pyhd3eb1b0_0\r\njpeg                      9d                   h7f8727e_0\r\njsonschema                4.1.2              pyhd8ed1ab_0    conda-forge\r\njupyter                   1.0.0            py38h578d9bd_6    conda-forge\r\njupyter_client            7.0.6              pyhd8ed1ab_0    conda-forge\r\njupyter_console           6.4.0              pyhd8ed1ab_0    conda-forge\r\njupyter_contrib_core      0.3.3                      py_2    conda-forge\r\njupyter_contrib_nbextensions 0.5.1              pyhd8ed1ab_2    conda-forge\r\njupyter_core              4.9.1            py38h578d9bd_0    conda-forge\r\njupyter_highlight_selected_word 0.2.0           py38h578d9bd_1002    conda-forge\r\njupyter_latex_envs        1.4.6           pyhd8ed1ab_1002    conda-forge\r\njupyter_nbextensions_configurator 0.4.1            py38h578d9bd_2    conda-forge\r\njupyterlab_pygments       0.1.2              pyh9f0ad1d_0    conda-forge\r\njupyterlab_widgets        1.0.2              pyhd8ed1ab_0    conda-forge\r\nkeras                     2.6.0                    pypi_0    pypi\r\nkeras-preprocessing       1.1.2                    pypi_0    pypi\r\nkiwisolver                1.3.1            py38h2531618_0\r\nlcms2                     2.12                 h3be6417_0\r\nld_impl_linux-64          2.35.1               h7274673_9\r\nlibclang                  12.0.0                   pypi_0    pypi\r\nlibffi                    3.3                  he6710b0_2\r\nlibgcc-ng                 9.3.0               h5101ec6_17\r\nlibgfortran-ng            7.5.0               ha8ba4b0_17\r\nlibgfortran4              7.5.0               ha8ba4b0_17\r\nlibgomp                   9.3.0               h5101ec6_17\r\nlibpng                    1.6.37               hbc83047_0\r\nlibsodium                 1.0.18               h36c2ea0_1    conda-forge\r\nlibstdcxx-ng              9.3.0               hd4cf53a_17\r\nlibtiff                   4.2.0                h85742a9_0\r\nlibuuid                   1.0.3                h7f8727e_2\r\nlibwebp                   1.2.0                h89dd481_0\r\nlibwebp-base              1.2.0                h27cfd23_0\r\nlibxcb                    1.14                 h7b6447c_0\r\nlibxml2                   2.9.12               h03d6c58_0\r\nlibxslt                   1.1.34               hc22bd24_0\r\nlxml                      4.6.3            py38hf1fe3a4_0    conda-forge\r\nlz4-c                     1.9.3                h295c915_1\r\nmarkdown                  3.3.4                    pypi_0    pypi\r\nmarkupsafe                2.0.1            py38h497a2fe_0    conda-forge\r\nmatplotlib                3.4.3            py38h06a4308_0\r\nmatplotlib-base           3.4.3            py38hbbc1b5f_0\r\nmatplotlib-inline         0.1.3              pyhd8ed1ab_0    conda-forge\r\nmistune                   0.8.4           py38h497a2fe_1004    conda-forge\r\nmkl                       2021.4.0           h06a4308_640\r\nmkl-service               2.4.0            py38h7f8727e_0\r\nmkl_fft                   1.3.1            py38hd3c417c_0\r\nmkl_random                1.2.2            py38h51133e4_0\r\nmunkres                   1.1.4                      py_0\r\nnbclient                  0.5.4              pyhd8ed1ab_0    conda-forge\r\nnbconvert                 6.2.0            py38h578d9bd_0    conda-forge\r\nnbformat                  5.1.3              pyhd8ed1ab_0    conda-forge\r\nncurses                   6.3                  h7f8727e_0\r\nnest-asyncio              1.5.1              pyhd8ed1ab_0    conda-forge\r\nnotebook                  6.4.5              pyha770c72_0    conda-forge\r\nnumexpr                   2.7.3            py38h22e1b3c_1\r\nnumpy                     1.19.5                   pypi_0    pypi\r\noauthlib                  3.1.1                    pypi_0    pypi\r\nolefile                   0.46               pyhd3eb1b0_0\r\nopenssl                   1.1.1l               h7f8727e_0\r\nopt-einsum                3.3.0                    pypi_0    pypi\r\npackaging                 21.0               pyhd8ed1ab_0    conda-forge\r\npandas                    1.3.4            py38h8c16a72_0\r\npandoc                    2.16                 h7f98852_0    conda-forge\r\npandocfilters             1.5.0              pyhd8ed1ab_0    conda-forge\r\nparso                     0.8.2              pyhd8ed1ab_0    conda-forge\r\npcre                      8.45                 h295c915_0\r\npexpect                   4.8.0              pyh9f0ad1d_2    conda-forge\r\npickleshare               0.7.5                   py_1003    conda-forge\r\npillow                    8.4.0            py38h5aabda8_0\r\npip                       21.2.4           py38h06a4308_0\r\nprometheus_client         0.12.0             pyhd8ed1ab_0    conda-forge\r\npromise                   2.3                      pypi_0    pypi\r\nprompt-toolkit            3.0.21             pyha770c72_0    conda-forge\r\nprompt_toolkit            3.0.21               hd8ed1ab_0    conda-forge\r\nprotobuf                  3.19.1                   pypi_0    pypi\r\nptyprocess                0.7.0              pyhd3deb0d_0    conda-forge\r\npyasn1                    0.4.8                    pypi_0    pypi\r\npyasn1-modules            0.2.8                    pypi_0    pypi\r\npycparser                 2.20               pyh9f0ad1d_2    conda-forge\r\npygments                  2.10.0             pyhd8ed1ab_0    conda-forge\r\npyparsing                 3.0.4              pyhd3eb1b0_0\r\npyqt                      5.9.2            py38h05f1152_4\r\npyrsistent                0.17.3           py38h497a2fe_2    conda-forge\r\npython                    3.8.12               h12debd9_0\r\npython-dateutil           2.8.2              pyhd3eb1b0_0\r\npython_abi                3.8                      2_cp38    conda-forge\r\npytz                      2021.3             pyhd3eb1b0_0\r\npyyaml                    5.4.1            py38h497a2fe_0    conda-forge\r\npyzmq                     19.0.2           py38ha71036d_2    conda-forge\r\nqt                        5.9.7                h5867ecd_1\r\nqtconsole                 5.1.1              pyhd8ed1ab_0    conda-forge\r\nqtpy                      1.11.2             pyhd8ed1ab_0    conda-forge\r\nreadline                  8.1                  h27cfd23_0\r\nrequests                  2.26.0                   pypi_0    pypi\r\nrequests-oauthlib         1.3.0                    pypi_0    pypi\r\nrsa                       4.7.2                    pypi_0    pypi\r\nscikit-learn              1.0.1            py38h51133e4_0\r\nscipy                     1.7.1            py38h292c36d_2\r\nseaborn                   0.11.2             pyhd3eb1b0_0\r\nsend2trash                1.8.0              pyhd8ed1ab_0    conda-forge\r\nsetuptools                58.0.4           py38h06a4308_0\r\nsip                       4.19.13          py38he6710b0_0\r\nsix                       1.15.0                   pypi_0    pypi\r\nsqlite                    3.36.0               hc218d9a_0\r\ntensorboard               2.7.0                    pypi_0    pypi\r\ntensorboard-data-server   0.6.1                    pypi_0    pypi\r\ntensorboard-plugin-wit    1.8.0                    pypi_0    pypi\r\ntensorflow                2.6.1                    pypi_0    pypi\r\ntensorflow-datasets       4.4.0                    pypi_0    pypi\r\ntensorflow-estimator      2.6.0                    pypi_0    pypi\r\ntensorflow-io-gcs-filesystem 0.21.0                   pypi_0    pypi\r\ntensorflow-metadata       1.4.0                    pypi_0    pypi\r\ntermcolor                 1.1.0                    pypi_0    pypi\r\nterminado                 0.12.1           py38h578d9bd_0    conda-forge\r\ntestpath                  0.5.0              pyhd8ed1ab_0    conda-forge\r\nthreadpoolctl             2.2.0              pyh0d69192_0\r\ntk                        8.6.11               h1ccaba5_0\r\ntornado                   6.1              py38h27cfd23_0\r\ntqdm                      4.62.3                   pypi_0    pypi\r\ntraitlets                 5.1.1              pyhd8ed1ab_0    conda-forge\r\ntyping-extensions         3.7.4.3                  pypi_0    pypi\r\nurllib3                   1.26.7                   pypi_0    pypi\r\nwcwidth                   0.2.5              pyh9f0ad1d_2    conda-forge\r\nwebencodings              0.5.1                      py_1    conda-forge\r\nwerkzeug                  2.0.2                    pypi_0    pypi\r\nwheel                     0.37.0             pyhd3eb1b0_1\r\nwidgetsnbextension        3.5.2            py38h578d9bd_0    conda-forge\r\nwrapt                     1.12.1                   pypi_0    pypi\r\nxz                        5.2.5                h7b6447c_0\r\nyaml                      0.2.5                h516909a_0    conda-forge\r\nzeromq                    4.3.4                h9c3ff4c_0    conda-forge\r\nzipp                      3.6.0              pyhd8ed1ab_0    conda-forge\r\nzlib                      1.2.11               h7b6447c_3\r\nzstd                      1.4.9                haebb681_0\r\n\r\n", "comments": ["Downgrading to 2.6.2 (or 2.6.1 for tf plus manual downgrade for keras to 2.6.0) then brings the system back to a working state:\r\n\r\npip install -U tensorflow==2.6.2\r\nSuccessfully installed google-auth-1.35.0 keras-2.6.0 tensorboard-2.6.0 tensorflow-2.6.2 tensorflow-estimator-2.6.0\r\n(tf2) student@c4d-vw-14:~$ python\r\nPython 3.8.12 (default, Oct 12 2021, 13:49:34)\r\n[GCC 7.5.0] :: Anaconda, Inc. on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> tf.test.is_gpu_available()\r\nWARNING:tensorflow:From <stdin>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.config.list_physical_devices('GPU')` instead.\r\n2021-11-08 09:37:09.767605: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-11-08 09:37:16.173199: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:0 with 10801 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0001:00:00.0, compute capability: 3.7\r\nTrue\r\n>>> sys_details = tf.sysconfig.get_build_info()\r\n>>>\r\n>>> cuda_version = sys_details[\"cuda_version\"]\r\n>>>\r\n>>> print(cuda_version)\r\n11.2\r\n\r\nPlease note that it is not a problem to install cuda 11.0 for tf 2.7 but I am wondering why I'd need to do that. As per the official website any version >= 2.5 should support 11.2. I suspect a bug with the pip package. ", "@artus-LYTiQ ,\r\nWe can see that you have installed tensorflow from conda environment.Installation issues within the Anaconda environment are tracked in the Anaconda repo.Please try to install in new virtual environment from this [link](https://github.com/tensorflow/tensorflow/releases) and let us know if it is still an issue.Thanks!\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "> @artus-LYTiQ , We can see that you have installed tensorflow from conda environment.Installation issues within the Anaconda environment are tracked in the Anaconda repo.Please try to install in new virtual environment from this [link](https://github.com/tensorflow/tensorflow/releases) and let us know if it is still an issue.Thanks!\r\n\r\nI'm observing the same problem in anaconda, downgrading to 2.6 fixes the problem", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52981\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52981\">No</a>\n"]}, {"number": 52980, "title": "win11 gtx960M tensorflow2.5~ tensorflow2.7 CUDA out of memory", "body": "win11 gtx960M tensorflow2.5~ tensorflow2.7 report errors : CUDA out of memory ,but win10 gtx960M tensorflow2.5~ tensorflow2.7 can run normally", "comments": ["Hi @lindadamama ! Could you please provide the standalone code to reproduce this issue too as It helps expedite the issue. Thanks!", "Currently, tensorflow 2.4.4 can be used normally\r\n\u4ece Windows \u7248\u90ae\u4ef6<https://go.microsoft.com/fwlink/?LinkId=550986>\u53d1\u9001\r\n\r\n________________________________\r\n\u53d1\u4ef6\u4eba: mohantym ***@***.***>\r\n\u53d1\u9001\u65f6\u95f4: Monday, November 8, 2021 5:30:54 PM\r\n\u6536\u4ef6\u4eba: tensorflow/tensorflow ***@***.***>\r\n\u6284\u9001: lindadamama ***@***.***>; Mention ***@***.***>\r\n\u4e3b\u9898: Re: [tensorflow/tensorflow] win11 gtx960M tensorflow2.5~ tensorflow2.7 CUDA out of memory (Issue #52980)\r\n\r\n\r\nHi @lindadamama<https://github.com/lindadamama> ! Could you please provide the standalone code to reproduce this issue?\r\n\r\n\u2015\r\nYou are receiving this because you were mentioned.\r\nReply to this email directly, view it on GitHub<https://github.com/tensorflow/tensorflow/issues/52980#issuecomment-962966659>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ALUZR7STIHJ44K6WBVQF3ADUK6KE5ANCNFSM5HR6YW2A>.\r\nTriage notifications on the go with GitHub Mobile for iOS<https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675> or Android<https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.\r\n", "Hi @sanatmpa1! Could you please look at this issue ?", "@lindadamama,\r\n\r\nCan you clarify if you're getting this error while installing tensorflow or while running any code after installing tensorflow?", "running code after installing tensorflow \uff0c\r\nThis error occurred\r\nRun print\uff08tf.test.is_gpu_available()\uff09return true\r\nHowever, an error is reported when running the program\r\nI tried to install tensorflow 2.5~2.7\uff0cReported the same error\uff1acuda out of memeory\r\nI tried to install tensorflow 2.4.1~2.4.4\uff0crun normaly\r\nThe configuration of my computer is intel I76900HQ \uff0cnvida gtx960M 8GB \uff0c16GB RAM win11 ,cuda11.2\r\nHowever,using win10, everything is normal\r\nIt may be an API compatibility issue\r\nThe code is in the attachment\r\n\r\n\r\n\u4ece Windows \u7248\u90ae\u4ef6<https://go.microsoft.com/fwlink/?LinkId=550986>\u53d1\u9001\r\n\r\n\u53d1\u4ef6\u4eba: ***@***.***>\r\n\u53d1\u9001\u65f6\u95f4: 2021\u5e7411\u67089\u65e5 19:44\r\n\u6536\u4ef6\u4eba: ***@***.***>\r\n\u6284\u9001: ***@***.***>; ***@***.***>\r\n\u4e3b\u9898: Re: [tensorflow/tensorflow] win11 gtx960M tensorflow2.5~ tensorflow2.7 CUDA out of memory (Issue #52980)\r\n\r\n\r\n@lindadamama<https://github.com/lindadamama>,\r\n\r\nCan you clarify if you're getting this error while installing tensorflow or while running any code after installing tensorflow?\r\n\r\n\u2015\r\nYou are receiving this because you were mentioned.\r\nReply to this email directly, view it on GitHub<https://github.com/tensorflow/tensorflow/issues/52980#issuecomment-964073823>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ALUZR7XHL7ICE7ZRO6CPDWLULECTHANCNFSM5HR6YW2A>.\r\nTriage notifications on the go with GitHub Mobile for iOS<https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675> or Android<https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.\r\n\r\n", "anaconda 2021.05 python3.8\r\n\u4ece Windows \u7248\u90ae\u4ef6<https://go.microsoft.com/fwlink/?LinkId=550986>\u53d1\u9001\r\n\r\n\r\n________________________________\r\n\u53d1\u4ef6\u4eba: lin lin ***@***.***>\r\n\u53d1\u9001\u65f6\u95f4: Tuesday, November 9, 2021 8:01:49 PM\r\n\u6536\u4ef6\u4eba: tensorflow/tensorflow ***@***.***>\r\n\u4e3b\u9898: \u56de\u590d: [tensorflow/tensorflow] win11 gtx960M tensorflow2.5~ tensorflow2.7 CUDA out of memory (Issue #52980)\r\n\r\n\r\nrunning code after installing tensorflow \uff0c\r\n\r\nThis error occurred\r\n\r\nRun print\uff08tf.test.is_gpu_available()\uff09return true\r\n\r\nHowever, an error is reported when running the program\r\n\r\nI tried to install tensorflow 2.5~2.7\uff0cReported the same error\uff1acuda out of memeory\r\n\r\nI tried to install tensorflow 2.4.1~2.4.4\uff0crun normaly\r\n\r\nThe configuration of my computer is intel I76900HQ \uff0cnvida gtx960M 8GB \uff0c16GB RAM win11 ,cuda11.2\r\n\r\nHowever,using win10, everything is normal\r\n\r\nIt may be an API compatibility issue\r\n\r\nThe code is in the attachment\r\n\r\n\r\n\r\n\r\n\r\n\u4ece Windows \u7248\u90ae\u4ef6<https://go.microsoft.com/fwlink/?LinkId=550986>\u53d1\u9001\r\n\r\n\r\n\r\n\u53d1\u4ef6\u4eba: ***@***.***>\r\n\u53d1\u9001\u65f6\u95f4: 2021\u5e7411\u67089\u65e5 19:44\r\n\u6536\u4ef6\u4eba: ***@***.***>\r\n\u6284\u9001: ***@***.***>; ***@***.***>\r\n\u4e3b\u9898: Re: [tensorflow/tensorflow] win11 gtx960M tensorflow2.5~ tensorflow2.7 CUDA out of memory (Issue #52980)\r\n\r\n\r\n\r\n@lindadamama<https://github.com/lindadamama>,\r\n\r\nCan you clarify if you're getting this error while installing tensorflow or while running any code after installing tensorflow?\r\n\r\n\u2015\r\nYou are receiving this because you were mentioned.\r\nReply to this email directly, view it on GitHub<https://github.com/tensorflow/tensorflow/issues/52980#issuecomment-964073823>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ALUZR7XHL7ICE7ZRO6CPDWLULECTHANCNFSM5HR6YW2A>.\r\nTriage notifications on the go with GitHub Mobile for iOS<https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675> or Android<https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.\r\n\r\n\r\n", "@lindadamama,\r\n\r\n>I tried to install tensorflow 2.5~2.7\uff0cReported the same error\uff1acuda out of memeory\r\n\r\nCan you try killing the process that consumes significant amount of GPU memory? you can take a look at this [comment](https://stackoverflow.com/a/62382792) as a reference.\r\n\r\nAlso here's the set of [tested build configuration](https://www.tensorflow.org/install/source_windows#tested_build_configurations) which are already tested and works as expected. Since you haven't filled the issue template, Can you make sure that you have the configurations similar to tested build configuration for proper installation of TF. Thanks!", "I reinstalled tensorflow2.7 and the test results are in the attachment\uff0ctensorflow2.7 can not run\uff0cBut tensorflow 2.4.4 can run normally. I am from China and have limited English expression ability. Sorry\r\n\r\n\u4ece Windows \u7248\u90ae\u4ef6<https://go.microsoft.com/fwlink/?LinkId=550986>\u53d1\u9001\r\n\r\n________________________________\r\n\u53d1\u4ef6\u4eba: Sanat ***@***.***>\r\n\u53d1\u9001\u65f6\u95f4: Friday, November 12, 2021 12:56:02 AM\r\n\u6536\u4ef6\u4eba: tensorflow/tensorflow ***@***.***>\r\n\u6284\u9001: lindadamama ***@***.***>; Mention ***@***.***>\r\n\u4e3b\u9898: Re: [tensorflow/tensorflow] win11 gtx960M tensorflow2.5~ tensorflow2.7 CUDA out of memory (Issue #52980)\r\n\r\n\r\n@lindadamama<https://github.com/lindadamama>,\r\n\r\nI tried to install tensorflow 2.5~2.7\uff0cReported the same error\uff1acuda out of memeory\r\n\r\nCan you try killing the process that consumes significant amount of GPU memory? you can take a look at this comment<https://stackoverflow.com/a/62382792> as a reference.\r\n\r\nAlso here's the set of tested build configuration<https://www.tensorflow.org/install/source_windows#tested_build_configurations> which are already tested and works as expected. Since you haven't filled the issue template, Can you make sure that you have the configurations similar to tested build configuration for proper installation of TF. Thanks!\r\n\r\n\u2015\r\nYou are receiving this because you were mentioned.\r\nReply to this email directly, view it on GitHub<https://github.com/tensorflow/tensorflow/issues/52980#issuecomment-966462009>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ALUZR7UMSIRQQEAQLTKLLDDULPYSFANCNFSM5HR6YW2A>.\r\nTriage notifications on the go with GitHub Mobile for iOS<https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675> or Android<https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.\r\n", "@lindadamama,\r\n\r\nCan you share the error trace in the comment, as I am not able to open your attachment, Also Can you provide the below details for helping you with this issue? Thanks!\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n", "OS Platform \uff1a win11 home edition\r\nTensorFlow installed command\uff1apython -m pip  install  --user   tensorflow==2.7.0  -i https://pypi.tuna.tsinghua.edu.cn/simple\r\ncuda11.2 cudnn cudnn-11.2-windows-x64-v8.1.0.77\r\nGPU model and memory:nvdia gtx960M 8GB\r\nAnaconda 2021.05 python3.8\r\nRAM\uff1a8GB\r\nCPU\uff1a intel I7 6900HQ\r\nLog printed during installation\uff1a\r\n# LOG\r\n_(base) PS D:\\Dism++10.1.1000.90B_6db9c6e8045f93cc899878ccb48e2bc1e9d8bb72> python -m pip  install  --user   tensorflow==2.7.0 -i https://pypi.tuna.tsinghua.edu.cn/simple\r\nLooking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\r\nCollecting tensorflow==2.7.0\r\n  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/03/9e/63266f9324f3ac5ec9b2f0eaebec75872f424f79ca05442c605f9fa03c09/tensorflow-2.7.0-cp38-cp38-win_amd64.whl (430.8 MB)\r\nRequirement already satisfied: wrapt>=1.11.0 in d:\\anaconda\\lib\\site-packages (from tensorflow==2.7.0) (1.12.1)\r\nRequirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\a1057\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow==2.7.0) (3.3.0)\r\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in c:\\users\\a1057\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow==2.7.0) (0.21.0)\r\nRequirement already satisfied: h5py>=2.9.0 in d:\\anaconda\\lib\\site-packages (from tensorflow==2.7.0) (2.10.0)\r\nRequirement already satisfied: protobuf>=3.9.2 in c:\\users\\a1057\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow==2.7.0) (3.19.0)\r\nCollecting keras<2.8,>=2.7.0rc0\r\n  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/6b/8b/065f94ba03282fa41b2d76942b87a180a9913312c4611ea7d6508fbbc114/keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\r\nRequirement already satisfied: keras-preprocessing>=1.1.1 in c:\\users\\a1057\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow==2.7.0) (1.1.2)\r\nCollecting tensorflow-estimator<2.8,~=2.7.0rc0\r\n  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/db/de/3a71ad41b87f9dd424e3aec3b0794a60f169fa7e9a9a1e3dd44290b86dd6/tensorflow_estimator-2.7.0-py2.py3-none-any.whl (463 kB)\r\nRequirement already satisfied: wheel<1.0,>=0.32.0 in d:\\anaconda\\lib\\site-packages (from tensorflow==2.7.0) (0.36.2)\r\nRequirement already satisfied: six>=1.12.0 in d:\\anaconda\\lib\\site-packages (from tensorflow==2.7.0) (1.15.0)\r\nRequirement already satisfied: termcolor>=1.1.0 in c:\\users\\a1057\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow==2.7.0) (1.1.0)\r\nRequirement already satisfied: google-pasta>=0.1.1 in c:\\users\\a1057\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow==2.7.0) (0.2.0)\r\nRequirement already satisfied: gast<0.5.0,>=0.2.1 in d:\\anaconda\\lib\\site-packages (from tensorflow==2.7.0) (0.3.3)\r\nRequirement already satisfied: libclang>=9.0.1 in c:\\users\\a1057\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow==2.7.0) (12.0.0)\r\nRequirement already satisfied: tensorboard~=2.6 in c:\\users\\a1057\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow==2.7.0) (2.7.0)\r\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\anaconda\\lib\\site-packages (from tensorflow==2.7.0) (1.32.0)\r\nRequirement already satisfied: numpy>=1.14.5 in d:\\anaconda\\lib\\site-packages (from tensorflow==2.7.0) (1.19.5)\r\nRequirement already satisfied: typing-extensions>=3.6.6 in d:\\anaconda\\lib\\site-packages (from tensorflow==2.7.0) (3.7.4.3)\r\nRequirement already satisfied: flatbuffers<3.0,>=1.12 in c:\\users\\a1057\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow==2.7.0) (1.12)\r\nRequirement already satisfied: absl-py>=0.4.0 in c:\\users\\a1057\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow==2.7.0) (0.15.0)\r\nRequirement already satisfied: astunparse>=1.6.0 in c:\\users\\a1057\\appdata\\roaming\\python\\python38\\site-packages (from tensorflow==2.7.0) (1.6.3)\r\nRequirement already satisfied: setuptools>=41.0.0 in d:\\anaconda\\lib\\site-packages (from tensorboard~=2.6->tensorflow==2.7.0) (52.0.0.post20210125)\r\nRequirement already satisfied: requests<3,>=2.21.0 in d:\\anaconda\\lib\\site-packages (from tensorboard~=2.6->tensorflow==2.7.0) (2.25.1)\r\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\a1057\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.6.1)\r\nRequirement already satisfied: werkzeug>=0.11.15 in d:\\anaconda\\lib\\site-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.0.1)\r\nRequirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\a1057\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard~=2.6->tensorflow==2.7.0) (2.3.0)\r\nRequirement already satisfied: markdown>=2.6.8 in c:\\users\\a1057\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard~=2.6->tensorflow==2.7.0) (3.3.4)\r\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\a1057\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard~=2.6->tensorflow==2.7.0) (0.4.6)\r\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\a1057\\appdata\\roaming\\python\\python38\\site-packages (from tensorboard~=2.6->tensorflow==2.7.0) (1.8.0)\r\nRequirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\a1057\\appdata\\roaming\\python\\python38\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.2.8)\r\nRequirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\a1057\\appdata\\roaming\\python\\python38\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.7.2)\r\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\a1057\\appdata\\roaming\\python\\python38\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (4.2.4)\r\nRequirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\a1057\\appdata\\roaming\\python\\python38\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (1.3.0)\r\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\a1057\\appdata\\roaming\\python\\python38\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.6->tensorflow==2.7.0) (0.4.8)\r\nRequirement already satisfied: chardet<5,>=3.0.2 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (4.0.0)\r\nRequirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2020.12.5)\r\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (1.26.4)\r\nRequirement already satisfied: idna<3,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.6->tensorflow==2.7.0) (2.10)\r\nRequirement already satisfied: oauthlib>=3.0.0 in c:\\users\\a1057\\appdata\\roaming\\python\\python38\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow==2.7.0) (3.1.1)\r\nInstalling collected packages: tensorflow-estimator, keras, tensorflow\r\n  Attempting uninstall: tensorflow-estimator\r\n    Found existing installation: tensorflow-estimator 2.4.0\r\n    Uninstalling tensorflow-estimator-2.4.0:\r\n      Successfully uninstalled tensorflow-estimator-2.4.0\r\n  Attempting uninstall: tensorflow\r\n    Found existing installation: tensorflow 2.4.4\r\n    Uninstalling tensorflow-2.4.4:\r\n      Successfully uninstalled tensorflow-2.4.4\r\n  WARNING: The scripts estimator_ckpt_converter.exe, import_pb_to_tensorboard.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'C:\\Users\\A1057\\AppData\\Roaming\\Python\\Python38\\Scripts' which is not on PATH.\r\n  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\r\nSuccessfully installed keras-2.7.0 tensorflow-2.7.0 tensorflow-estimator-2.7.0\r\n#\r\n### test cuda\r\nimport tensorflow as tf \r\nprint(tf.__version__)\r\nprint(tf.test.is_gpu_available())\r\n I got it\u201c 2.7.0  true\u201d\r\n![testCuda](https://user-images.githubusercontent.com/48863486/141667718-6da00882-e936-4af1-9915-3f9aff5965c4.png)\r\n  run code  LOG:\r\n![runError](https://user-images.githubusercontent.com/48863486/141667735-d1c32854-3834-409b-b2e7-b642506210e8.png)_\r\n\r\n2021\udae1\udeaf\udae1\udea7 22:25:11.457012: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance\u2011critical operations: AVX AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021\udae1\udeaf\udae1\udea7 2021-11-03 22:45:58.919955: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-11-03 22:46:00.946967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:0 with 2821 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 960M, pci bus id: 0000:01:00.0, compute capability: 5.0\r\n2021-11-03 22:46:25.093703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2821 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 960M, pci bus id: 0000:01:00.0, compute capability: 5.0\r\n2021-11-03 22:46:25.226416: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 2.75G (2958177024 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2021-11-03 22:46:25.282507: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 2.48G (2662359296 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memoryI tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\r\n2021-11-03 22:45:58.919955: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-11-03 22:46:00.946967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /device:GPU:0 with 2821 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 960M, pci bus id: 0000:01:00.0, compute capability: 5.0\r\n2021-11-03 22:46:25.093703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2821 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 960M, pci bus id: 0000:01:00.0, compute capability: 5.0\r\n2021-11-03 22:46:25.226416: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 2.75G (2958177024 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n2021-11-03 22:46:25.282507: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 2.48G (2662359296 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\r\n\r\n\r\nThen python crashes, and then the computer freezes, I can only solve it by restarting the computer\r\n\r\n\r\nThen after installing tensorflow2.4.4, the same situation did not happen\r\n\r\n\r\n\r\n", "@lindadamama,\r\n\r\nThis looks like an OOM error and Can you try setting your allow_growth by adding below lines of code to your program and see if it works?\r\n\r\n```python\r\nimport os\r\nos.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\r\n```\r\n\r\nHave you also tried checking the GPU utilization using `nvidia-smi` command to see if its full? ", "I reinstalled version 2.7\uff0cadd the code\u201c os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\u201d and after the installation is successful, the computer is stuck when the program is run for the first time. After the forced shutdown and restart, it returns to normal,  but the time taken is about 4 to 5 times that of the 2.4.4 version. \r\n![\u5fae\u4fe1\u56fe\u7247_20211118181333](https://user-images.githubusercontent.com/48863486/142396699-bedd3163-f269-48a4-adc3-8acceef2f911.jpg)\r\n![\u5fae\u4fe1\u56fe\u7247_20211118181338](https://user-images.githubusercontent.com/48863486/142396770-2d1e51ce-1d33-4312-8ee6-7539aec1c888.jpg)\r\n![\u5fae\u4fe1\u56fe\u7247_20211118181320](https://user-images.githubusercontent.com/48863486/142396816-02419026-6d06-4f33-81a8-b9ac59482adc.jpg)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n", "@lindadamama,\r\n\r\nAs per the second screenshot, it shows that you're using CUDA version 11.5, whereas the tested configurations use CUDA 11.2 for TF 2.7. You can refer [here](https://www.tensorflow.org/install/source_windows#gpu).\r\n\r\nSince you're getting OOM error, Can you try reducing the amount of data that you're using and also try reducing the batch size while training?", "I just checked it again and it shows that 11.2 is installed \r\n![222](https://user-images.githubusercontent.com/48863486/142400281-a4719231-5521-4ce9-9d4c-33db748d3f0a.png)\r\n", "@lindadamama,\r\n\r\nAlright, Can you take a look at answers in this [ SO thread](https://stackoverflow.com/questions/39465503/cuda-error-out-of-memory-in-tensorflow/46021109) which discusses about the similar issue? Thanks!", "The server of this website may not be in China, I can\u2019t open it temporarily on my computer\uff0cThank you very much for helping to solve the problem", "@lindadamama,\r\n\r\nHave you got a chance to take a look at the link shared in above comment? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52980\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/52980\">No</a>\n"]}]