[{"number": 3888, "title": "Tensorflow loss not changing and also computed gradients and applied batch norm but still loss is not changing?", "body": "Tensorflow loss is not changing. This is my code.\n\n```\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport tensorflow as tf\nimport numpy as np\nimport math\nimport os\nimport nltk\nimport random\nimport tflearn\nbatch_size = 100\nstart = 0\nend = batch_size\nlearning_rate = 0.01\nnum_classes = 8\npath1 = \"/home/indy/Downloads/aclImdb/train/pos\"\npath2 = \"/home/indy/Downloads/aclImdb/train/neg\"\npath3 = \"/home/indy/Downloads/aclImdb/test/pos\"\npath4 = \"/home/indy/Downloads/aclImdb/test/neg\"\ntime_steps = 300\nembedding = 50\nstep = 1\n\n\ndef get_embedding():\n    gfile_path = os.path.join(\"/home/indy/Downloads/glove.6B\", \"glove.6B.50d.txt\")\n    f = open(gfile_path,'r')\n    embeddings = {}\n    for line in f:\n        sp_value = line.split()\n        word = sp_value[0]\n        embedding = [float(value) for value in sp_value[1:]]\n        assert len(embedding) == 50\n        embeddings[word] = embedding\n    return embeddings\n\nebd = get_embedding()\n\ndef get_y(file_path):\n    y_value = file_path.split('_')\n    y_value = y_value[1].split('.')\n    if y_value[0] == '1':\n       return 0\n    elif y_value[0] == '2':\n         return 1\n    elif y_value[0] == '3':\n          return 2\n    elif y_value[0] == '4':\n          return 3\n    elif y_value[0] == '7':\n          return 4\n    elif y_value[0] == '8':\n          return 5\n    elif y_value[0] == '9':\n          return 6\n    elif y_value[0] == '10':\n          return 7 \n\ndef get_x(file_path):\n    x_value = open(file_path,'r')\n    for line in x_value:\n        x_value = line.replace(\"<br /><br />\",\"\") \n        x_value = x_value.lower()\n    x_value = nltk.word_tokenize(x_value.decode('utf-8'))\n    padding = 300 - len(x_value)\n    if padding > 0:\n       p_value = ['pad' for i in range(padding)]\n       x_value = np.concatenate((x_value,p_value))\n    if padding < 0:\n       x_value = x_value[:300]\n    for i in x_value:\n        if ebd.get(i) == None:\n           ebd[i] = [float(np.random.normal(0.0,1.0)) for j in range(50)]\n    x_value = [ebd[value] for value in x_value]\n    assert len(x_value) == 300\n    return x_value\n\n\ndef get_total_files(path1,path2,path3,path4):\n    directory1 = os.listdir(path1)\n    file_path1 = [os.path.join(path1,file) for file in directory1]\n    directory2 = os.listdir(path2)\n    file_path2 = [os.path.join(path2,file) for file in directory2]\n    directory3 = os.listdir(path3)\n    file_path3 = [os.path.join(path3,file) for file in directory3]\n    directory4 = os.listdir(path4)\n    file_path4 = [os.path.join(path4,file) for file in directory4]\n    total_files_train = np.concatenate((file_path1,file_path2))\n    total_files_test = np.concatenate((file_path3,file_path4))\n    random.shuffle(total_files_train)\n    random.shuffle(total_files_test)    \n    x1 = [get_x(file) for file in total_files_train]\n    y1 = [get_y(file) for file in total_files_train]\n    x2 = [get_x(file) for file in total_files_test]\n    y2 = [get_y(file) for file in total_files_test]\n    return x1 , y1 , x2 , y2\n\ntotal_files_train_x, total_files_train_y, total_files_test_x, total_files_test_y = get_total_files(path1,path2,path3,path4)\n\n\ntrain_set_x = total_files_train_x[:10000]\nvalidate_set_x = total_files_train_x[10000:15000]\ntest_set_x = total_files_test_x[0:5000]\ntrain_set_y = total_files_train_y[:10000]\nvalidate_set_y = total_files_train_y[10000:15000]\ntest_set_y = total_files_test_y[0:5000]\n\n\nX = tf.placeholder(tf.float32, [None,time_steps,embedding])\nY = tf.placeholder(tf.int32, [None])\n\ndef build_nlp_model(x, _units,num_classes,num_of_filters):\n    x = tf.expand_dims(x,3)\n    with tf.variable_scope(\"one\"):      \n         filter_shape = [1, embedding, 1, num_of_filters]\n         conv_weights = tf.get_variable(\"conv_weights\" , filter_shape, tf.float32, tf.truncated_normal_initializer(mean=0.0, stddev=1.0))\n         conv_biases = tf.Variable(tf.constant(0.1, shape=[num_of_filters]))\n         conv = tf.nn.conv2d(x, conv_weights, strides=[1,1,1,1], padding = \"VALID\")\n         normalize = conv + conv_biases\n         tf_normalize = tflearn.layers.normalization.batch_normalization(normalize)\n         relu = tf.nn.elu(tf_normalize)\n         pooling = tf.reduce_max(relu, reduction_indices = 3, keep_dims = True)\n         outputs_fed_lstm = pooling\n\n    with tf.variable_scope(\"two\"):         \n         filter_shape = [1, 1, 1, 1000]\n         conv_weights = tf.get_variable(\"conv_weights\" , filter_shape, tf.float32, tf.truncated_normal_initializer(mean=0.0, stddev=1.0))\n         conv_biases = tf.Variable(tf.constant(0.1, shape=[1000]))\n         conv = tf.nn.conv2d(outputs_fed_lstm, conv_weights, strides=[1,1,1,1], padding = \"VALID\")\n         normalize = conv + conv_biases\n         tf_normalize = tflearn.layers.normalization.batch_normalization(normalize)\n         relu = tf.nn.elu(tf_normalize)\n         pooling = tf.reduce_max(relu, reduction_indices = 3, keep_dims = True)\n         outputs_fed_lstm = pooling\n\n    with tf.variable_scope(\"three\"):        \n         filter_shape = [1, 1, 1, 1000]\n         conv_weights = tf.get_variable(\"conv_weights\" , filter_shape, tf.float32, tf.truncated_normal_initializer(mean=0.0, stddev=1.0))\n         conv_biases = tf.Variable(tf.constant(0.1, shape=[1000]))\n         conv = tf.nn.conv2d(outputs_fed_lstm, conv_weights, strides=[1,1,1,1], padding = \"VALID\")\n         normalize = conv + conv_biases\n         tf_normalize = tflearn.layers.normalization.batch_normalization(normalize)\n         relu = tf.nn.elu(tf_normalize)\n         pooling = tf.reduce_max(relu, reduction_indices = 3, keep_dims = True)\n         outputs_fed_lstm = pooling\n\n    with tf.variable_scope(\"four\"):         \n         filter_shape = [1, 1, 1, num_of_filters]\n         conv_weights = tf.get_variable(\"conv_weights\" , filter_shape, tf.float32, tf.truncated_normal_initializer(mean=0.0, stddev=1.0))\n         conv_biases = tf.Variable(tf.constant(0.1, shape=[num_of_filters]))\n         conv = tf.nn.conv2d(outputs_fed_lstm, conv_weights, strides=[1,1,1,1], padding = \"VALID\")\n         normalize = conv + conv_biases\n         tf_normalize = tflearn.layers.normalization.batch_normalization(normalize)\n         relu = tf.nn.elu(tf_normalize)\n         pooling = tf.reduce_max(relu, reduction_indices = 3, keep_dims = True)\n         outputs_fed_lstm = pooling\n\n    with tf.variable_scope(\"five\"):         \n         filter_shape = [1, 1, 1, num_of_filters]\n         conv_weights = tf.get_variable(\"conv_weights\" , filter_shape, tf.float32, tf.truncated_normal_initializer(mean=0.0, stddev=1.0))\n         conv_biases = tf.Variable(tf.constant(0.1, shape=[num_of_filters]))\n         conv = tf.nn.conv2d(outputs_fed_lstm, conv_weights, strides=[1,1,1,1], padding = \"VALID\")\n         normalize = conv + conv_biases\n         tf_normalize = tflearn.layers.normalization.batch_normalization(normalize)\n         relu = tf.nn.elu(tf_normalize)\n         pooling = tf.reduce_max(relu, reduction_indices = 3, keep_dims = True)\n         outputs_fed_lstm = pooling\n\n    x = tf.squeeze(outputs_fed_lstm, [2])     \n    x = tf.transpose(x, [1, 0, 2])\n    x = tf.reshape(x, [-1, 1])\n    x = tf.split(0, time_steps, x)\n\n    lstm = tf.nn.rnn_cell.LSTMCell(num_units = _units)\n\n     # multi_lstm = tf.nn.rnn_cell.MultiRNNCell([lstm] * lstm_layers, state_is_tuple = True)\n\n    outputs , state = tf.nn.rnn(lstm,x, dtype = tf.float32)     \n\n    weights = tf.Variable(tf.random_normal([_units,num_classes]))\n    biases  = tf.Variable(tf.random_normal([num_classes]))\n\n    logits = tf.matmul(outputs[-1], weights) + biases\n    return logits\n\nlogits = build_nlp_model(X,500,num_classes,1000)\nc_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(logits,Y)\nloss = tf.reduce_mean(c_loss)\n\n\nglobal_step = tf.Variable(0, name=\"global_step\", trainable=False)\n# decayed_learning_rate = tf.train.exponential_decay(learning_rate,0,10000,0.9)\noptimizer= tf.train.AdamOptimizer(learning_rate)\nminimize_loss = optimizer.minimize(loss, global_step=global_step)   \nwith tf.variable_scope(\"four\", reuse = True):\n     weights = tf.get_variable(\"conv_weights\") \n     grads_and_vars = optimizer.compute_gradients(loss,[weights]) \ncorrect_predict = tf.nn.in_top_k(logits, Y, 1)\naccuracy = tf.reduce_mean(tf.cast(correct_predict, tf.float32))\n\n\ninit = tf.initialize_all_variables()\n\nwith tf.Session() as sess:\n     sess.run(init)\n     for i in range(10):\n         for j in range(100):\n             x = train_set_x[start:end]\n             y = train_set_y[start:end]\n             start = end\n             end += batch_size\n             if start >= 10000:\n                start = 0\n                end = batch_size  \n             sess.run(minimize_loss,feed_dict={X : x, Y : y})\n             step += 1  \n             gr_print = sess.run([grad for grad, _ in grads_and_vars], feed_dict={X : x, Y : y})\n             print (gr_print)\n         print (\"One Epoch Finished\")\n         cost = sess.run(loss,feed_dict = {X: x,Y: y})\n         accu = sess.run(accuracy,feed_dict = {X: x, Y: y})\n         print (\"Loss after one Epoch(Training) = \" + \"{:.6f}\".format(cost) + \", Training Accuracy= \" + \"{:.5f}\".format(accu))\n         q = validate_set_x[:100]\n         w = validate_set_y[:100]\n         cost = sess.run(loss,feed_dict = {X: q,Y: w})\n         accu = sess.run(accuracy,feed_dict = {X: q, Y: w})\n```\n\nMy loss remains the same after many Epochs. So I think that I'm having vanishing gradient problem and so I applied batch normalization but I got no difference in results.I also tried overfitting the model, but I'm getting same results. I'm using `optimizer.compute_gradients` for computing gradients. Below are the results of gradients of loss with respect to different conv layers, and how they look like. Here is how my gradients look like with respect to first conv layers and with respect to 4th conv layer.\n\nCode for gradients with respect to first conv layer:\n\n```\nwith tf.variable_scope(\"one\", reuse = True):\n     weights = tf.get_variable(\"conv_weights\") \n     grads_and_vars = optimizer.compute_gradients(loss,[weights])\n\n\ngr_print = sess.run([grad for grad, _ in grads_and_vars], feed_dict={X : x, Y : y})\n           print (gr_print)\n```\n\n And this is what I get after one iteration:\n\n```\n[array([[[[  2.38197345e-06,  -1.04135906e-04,   2.60035231e-05, ...,\n           -1.01550373e-04,   0.00000000e+00,   1.01060732e-06]],\n\n        [[ -1.98007251e-06,   8.13827137e-05,  -8.14055747e-05, ...,\n           -6.40711369e-05,   0.00000000e+00,   1.05516607e-04]],\n\n        [[  4.51127789e-06,   2.21654373e-05,  -4.99439229e-05, ...,\n            9.87191743e-05,   0.00000000e+00,   1.70595697e-04]],\n\n        ..., \n        [[ -4.70160239e-06,  -8.67914496e-05,   2.50699850e-05, ...,\n            1.18909593e-04,   0.00000000e+00,   2.43308150e-05]],\n\n        [[ -1.18101923e-06,  -7.71943451e-05,  -3.41630148e-05, ...,\n           -3.28040805e-05,   0.00000000e+00,  -6.01144784e-05]],\n\n        [[ -1.98778321e-06,  -3.23160748e-05,  -5.44797731e-05, ...,\n            2.23019324e-05,   0.00000000e+00,  -3.29296927e-05]]]], dtype=float32)]\n```\n\nCode for gradients with respect to 4th conv layer:\n\n```\nwith tf.variable_scope(\"four\", reuse = True):\n     weights = tf.get_variable(\"conv_weights\") \n     grads_and_vars = optimizer.compute_gradients(loss,[weights])\ngr_print = sess.run([grad for grad, _ in grads_and_vars], feed_dict={X : x, Y : y})\n           print (gr_print)\n```\n\nAnd this what I get after one iteration:\n\n```\n[array([[[[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        , -6.21198082,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.                ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.              ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n           0.        ,  0.        ,  0.        ,  0.        ,  0.        ]]]], dtype=float32)]\n```\n\nAfter first layer, gradients with respect to 2nd,3rd,4th,5th conv layers all look like above. But there's one thing common among all the gradients with respect to conv layers which are after first conv layer, they all have one number in the entire gradient array,that is not zero as shown above in the output. And I also applied batch norm and I'm still getting the above results.\n\nI'm totally confused, I don't know where the problem is?\n", "comments": ["Please post to StackOverflow, since it's not clear there's a bug here yet.\n"]}, {"number": 3887, "title": "tf.fill should accept dtype argument", "body": "The signature of `tf.fill` is  `tf.fill(dims, value, name=None)`, which not does allow to configure the dtype of the result. As opposed to `tf.ones`, `tf.ones(shape, dtype=tf.float32, name=None)`.\n\nShouldn't `tf.fill` also accept a dtype argument?\n", "comments": ["What would be the behavior when dtype of value conflicts with explicit\ndtype?\n\nOn Wed, Aug 17, 2016 at 3:05 PM, Dzmitry Bahdanau notifications@github.com\nwrote:\n\n> The signature of tf.fill is tf.fill(dims, value, name=None), which not\n> does allow to configure the dtype of the result. As opposed to tf.ones, tf.ones(shape,\n> dtype=tf.float32, name=None).\n> \n> Shouldn't tf.fill also accept a dtype argument?\n> \n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3887, or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AABaHEv0ueUQqi8gPrslRQ9PsTbFl0qMks5qg4WTgaJpZM4Jm77r\n> .\n", "Yes, I think the dtype of 'value' determines the output type, so either make sure 'value' is the right dtype, or you can use tf.cast afterwards.\n"]}, {"number": 3886, "title": "control_dependencies() maybe fails to mfence when an assign() with different shape occurs", "body": "### Environment info\n\nOperating System: OS X El Capitan\n\nInstalled CPU version (OSX pip package)\ntensorflow version: 0.10.0rc0\n### Steps to reproduce\n\nConsider the following code snippet:\n\n``` python\nx = tf.Variable(0.)\nx_op = tf.assign(x, [1.], validate_shape=False)\n\nwith tf.control_dependencies([x_op]):\n    plus_op = x+2\n\ntf.initialize_variables([x]).run()\nprint plus_op.eval()\n```\n\nThe expected output is `[3]`, but instead I get `2`\n### What have you tried?\n\nIf we don't assign an inconsistent shape (e.g. assign `1` instead of `[1]`), then things work the way one would expect (output is `3`)\n\nIf we replace\n\n`plus_op = x+2`\n\nwith\n\n`plus_op=x.ref() + 2`\n\nthen we get the expected output of `[3]` instead of `2`.\n\nI suspect this is because calling `ref()` may somehow trigger a memory fence which fixes the broken behavior.\n\nAlso, it is possible that this is the intended behavior and that I misunderstood control_dependencies(), in which case I apologize.\n", "comments": ["I can reproduce. That's kind of unexpected, `x+2` and `x.ref()+2` should work the same.\n", "I believe this code is actually non-deterministic.  (at least I see **both** values if I run repeatedly)\n\nIf you look at the GraphDef using this code:\n\n```\ntf.train.write_graph(sess.graph.as_graph_def(),  '.',  'issue3886.pbtxt')\n```\n\nThe Variable read of x is cached using an Identity op called `Variable/read`.  There is no control dependency between the cached read and the assign.  There **is** a control dependency on the Const input to the Add op. (@yuanbyu is the expert on why this is the case)\n\nHere is the full GraphDef for reference:\n\n```\nnode {\n  name: \"Variable/initial_value\"\n  op: \"Const\"\n  attr {\n    key: \"dtype\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"value\"\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 0.0\n      }\n    }\n  }\n}\nnode {\n  name: \"Variable\"\n  op: \"Variable\"\n  attr {\n    key: \"container\"\n    value {\n      s: \"\"\n    }\n  }\n  attr {\n    key: \"dtype\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"shape\"\n    value {\n      shape {\n      }\n    }\n  }\n  attr {\n    key: \"shared_name\"\n    value {\n      s: \"\"\n    }\n  }\n}\nnode {\n  name: \"Variable/Assign\"\n  op: \"Assign\"\n  input: \"Variable\"\n  input: \"Variable/initial_value\"\n  attr {\n    key: \"T\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"_class\"\n    value {\n      list {\n        s: \"loc:@Variable\"\n      }\n    }\n  }\n  attr {\n    key: \"use_locking\"\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: \"validate_shape\"\n    value {\n      b: true\n    }\n  }\n}\nnode {\n  name: \"Variable/read\"\n  op: \"Identity\"\n  input: \"Variable\"\n  attr {\n    key: \"T\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"_class\"\n    value {\n      list {\n        s: \"loc:@Variable\"\n      }\n    }\n  }\n}\nnode {\n  name: \"Assign/value\"\n  op: \"Const\"\n  attr {\n    key: \"dtype\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"value\"\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n          dim {\n            size: 1\n          }\n        }\n        float_val: 1.0\n      }\n    }\n  }\n}\nnode {\n  name: \"Assign\"\n  op: \"Assign\"\n  input: \"Variable\"\n  input: \"Assign/value\"\n  attr {\n    key: \"T\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"_class\"\n    value {\n      list {\n        s: \"loc:@Variable\"\n      }\n    }\n  }\n  attr {\n    key: \"use_locking\"\n    value {\n      b: true\n    }\n  }\n  attr {\n    key: \"validate_shape\"\n    value {\n      b: false\n    }\n  }\n}\nnode {\n  name: \"add/y\"\n  op: \"Const\"\n  input: \"^Assign\"\n  attr {\n    key: \"dtype\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n  attr {\n    key: \"value\"\n    value {\n      tensor {\n        dtype: DT_FLOAT\n        tensor_shape {\n        }\n        float_val: 2.0\n      }\n    }\n  }\n}\nnode {\n  name: \"add\"\n  op: \"Add\"\n  input: \"Variable/read\"\n  input: \"add/y\"\n  attr {\n    key: \"T\"\n    value {\n      type: DT_FLOAT\n    }\n  }\n}\nversions {\n  producer: 9\n}\n```\n", "This is intended behavior: variable reads are cached by default, and the implicitly created caching operator (a `tf.identity()`) is not ordered (by any control or data dependency) with the assignment operator. As a result, the caching operator can cache the value `0.` or `1.` depending on whether it runs before or after the `tf.assign()` operator.\n\nThere are several ways to avoid this:\n1. As you noticed, you can use the `Variable.ref()` method to perform a non-caching read of the variable. This will ensure that it's read after the assignment, and you will always get the result `3`.\n2. You can read the _result_ of the assignment, which is itself a ref-tensor (l-value) representing the value of the tensor after the assignment. The following program always prints `3`:\n   \n   ``` python\n   x = tf.Variable(0.)\n   x_op = tf.assign(x, [1.], validate_shape=False) \n   plus_op = x_op + 2\n   \n   tf.initialize_variables([x]).run()\n   print plus_op.eval()\n   ```\n3. (Perhaps least intuitively.) You would always get the result `3` if you didn't change the shape of the variable in the assignment. The following program also always prints `3`:\n   \n   ``` python\n   x = tf.Variable(0.)\n   x_op = tf.assign(x, 1.) \n   with tf.control_dependencies([x_op]) \n   plus_op = x + 2\n   \n   tf.initialize_variables([x]).run()\n   print plus_op.eval()\n   ```\n   \n   ...however this is an implementation detail (because the same buffer is used for `x` before and after the assignment, whereas when you change the shape a new buffer is allocated).\n\nThis is, admittedly, not the most intuitive semantics, but the caching tends to give the most efficient execution plan when running in a distributed setting with variables on a shared parameter server. \n"]}, {"number": 3885, "title": "Issues #2099 has become a problem again: using empty variables", "body": "The code below fails with \"Attempting to use uninitialized value Variable\".  See #2099. I presume that this was fixed in the past but regressed subsequently. I understand that the past stance was that it is fine to use variables with shapes that contain a 0 in one of the dimensions.\n\n```\nsess = tf.InteractiveSession()\nempty = np.zeros(shape=(0, 0) )\na = tf.Variable(empty)\nsess.run(tf.initialize_all_variables())\nsess.run(tf.reduce_sum(a))\n```\n", "comments": ["@allenlavoie, didn't you look at this before?\n", "Yes, we tried to fix exactly this case, and it seems to still be working for me. Andrew has confirmed that your code also works in .10 RC0; can you try that version and see if you still have an issue?\n", "Works in 0.10rc0. Thanks! fwiw, I was on 0.8.\n"]}, {"number": 3884, "title": "Branch 130554783", "body": "", "comments": []}, {"number": 3883, "title": "Fixing comment, wrong data type in argument description.", "body": "Usage can be seen in lines 445->446, the file is read in and passed directly in, it is not a Numpy array, but rather just a string of raw JPEG data passed into the DecodeJpeg layer of an arbitrary network (by default Inception v3).\n", "comments": ["Can one of the admins verify this patch?\n", "LGTM\n", "@tensorflow-jenkins PTAL\n", "I believe this correction is right, LGTM, thanks!\n", "Since this only changes a docstring, I am going to live dangerously and merge it without tests.\n"]}, {"number": 3882, "title": "dynamic_rnn time_major=False does not support rank>3 input", "body": "https://github.com/tensorflow/tensorflow/blob/33b336ada58529d5e0398feea423785f1c3d57c1/tensorflow/python/ops/rnn.py#L782\n\n```\nflat_input = tuple(array_ops.transpose(input_, [1, 0, 2])\nfor input_ in flat_input)\n```\n\nHere seems we can only transpose matrix of size batch_size \\* time_size \\* input_size. It doesn't work if my input at each time step is a matrix.\nIn torch you can just specify the two dimensions (0 and 1 here) to be swapped instead of perm. Is there a similar functionality?\n", "comments": ["It wouldn't be too hard to add support for a permutation of only the first two dimensions.  Are you interested in adding this?  If not, I'll try to work on it later this week.\n", "Ran into this. The following fix works:\n\n```\n flat_input = tuple(array_ops.transpose(input_, [1, 0] +range(2,input_.get_shape().ndims))\n                       for input_ in flat_input)\n```\n\nand, similarly for [Line 843](https://github.com/tensorflow/tensorflow/blob/33b336ada58529d5e0398feea423785f1c3d57c1/tensorflow/python/ops/rnn.py#L843):\n\n```\n      flat_output = [array_ops.transpose(output, [1, 0] + range(2,output.get_shape().ndims))\n                     for output in flat_output]\n```\n\nFix in pull request: #5142 \n", "Commented on the PR.\n\nOn Sat, Oct 22, 2016 at 3:37 PM, Ankush Gupta notifications@github.com\nwrote:\n\n> Ran into this. The following fix works:\n> \n>  flat_input = tuple(array_ops.transpose(input_, [1, 0] + [i for i in xrange(2,input_.get_shape().ndims)])\n>                        for input_ in flat_input)\n> \n> and, similarly for Line 843\n> https://github.com/tensorflow/tensorflow/blob/33b336ada58529d5e0398feea423785f1c3d57c1/tensorflow/python/ops/rnn.py#L843\n> :\n> \n> ```\n>   flat_output = [array_ops.transpose(output, [1, 0] + [i for i in xrange(2,output.get_shape().ndims)])\n>                  for output in flat_output]\n> ```\n> \n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3882#issuecomment-255558128,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/ABtimzZphsalCxMfeT4iiOOZ197Edwmbks5q2pAygaJpZM4Jm1JV\n> .\n"]}, {"number": 3881, "title": "ImportError: No module named tools (missing __init__.py?)", "body": "### Environment info\n\nOperating System: Ubuntu 14.04 LTS 64-bit\n\nInstalled version of CUDA and cuDNN: none\n\nIf installed from source, provide \n1. The commit hash (`git rev-parse HEAD`): fc9162975e52978d3af38549b570cc3cc5f0ab66\n2. The output of `bazel version`:\n\n```\nBuild label: 0.3.0\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Fri Jun 10 11:38:23 2016 (1465558703)\nBuild timestamp: 1465558703\nBuild timestamp as int: 1465558703\n```\n### Steps to reproduce\n1. Create a new IPython Notebook\n2. Run the following:\n\n```\nimport tensorflow as tf\nfrom tensorflow.python.tools import freeze_graph\n```\n### What have you tried?\n\nIt seems that the tools directory is missing an `__init__.py` (though there is one in the python directory), and so tools isn't being recognized as a module. However, this is a bit baffling, because [`freeze_graph_test.py`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph_test.py) uses these exact same import statements. Just to be sure, I tried copying in all the import statements in `freeze_graph_test.py`:\n\n```\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\n\nimport tensorflow as tf\n\nfrom tensorflow.python.framework import test_util\nfrom tensorflow.python.tools import freeze_graph\n```\n\nand sure enough, `freeze_graph` was the only one that gave an error.\n\n`__init__.py` doesn't appear in the repository on GitHub as well. I noticed there's a Bazel BUILD file instead, but as far as I know, Bazel is only used to build the Android demo. Am I missing something?\n### Logs or other output that would be helpful\n\n```\nImportError                               Traceback (most recent call last)\n<ipython-input-10-039cb956bb5c> in <module>()\n      1 import tensorflow as tf\n----> 2 from tensorflow.python.tools import freeze_graph\n\nImportError: No module named tools\n```\n", "comments": ["The tools are not part of the runtime.\n", "@sherrym in that case, how would I freeze a graph?\n", ".py file has instructions:\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py\n\nAn example of command-line usage is:\nbazel build tensorflow/python/tools:freeze_graph && \\\nbazel-bin/tensorflow/python/tools/freeze_graph \\\n--input_graph=some_graph_def.pb \\\n--input_checkpoint=model.ckpt-8361242 \\\n--output_graph=/tmp/frozen_graph.pb --output_node_names=softmax\n\nOn Thu, Aug 18, 2016 at 5:45 PM, cardshuffle notifications@github.com\nwrote:\n\n> @sherrym https://github.com/sherrym in that case, how would I freeze a\n> graph?\n> \n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3881#issuecomment-240898516,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AABaHJjPsBFFboasfvLukOysd32VYYzwks5qhPycgaJpZM4Jm1D3\n> .\n", "Am I right, that there is no way to use this script with pip install, and I need to install tensorflow from source?\n", "At the moment, that's correct.\n\nOn Thu, Sep 8, 2016 at 12:02 AM, kolesov93 notifications@github.com wrote:\n\n> Am I right, that there is no way to use this script with pip install, and\n> I need to install tensorflow from source?\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3881#issuecomment-245511151,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AMLa9Q7ayQbBMpiPORoDY8EDqHB_eRbNks5qn7MUgaJpZM4Jm1D3\n> .\n"]}, {"number": 3880, "title": "Change \"var1 == var2\" to \"var1 is var2\"", "body": "This is a detail and might be just a matter of taste. My reason for proposing this change is that the Python \"is\" operator stands for a stronger type of equality than the \"==\" operator, so perhaps it drives home the equality point more strongly. However, again, this could just be a matter of taste; I will certainly not be offended if this proposal is rejected.\n", "comments": ["Can one of the admins verify this patch?\n", "Looks good to me, thanks!\n"]}, {"number": 3879, "title": "Strange behavior of tf.control_dependencies", "body": "Consider the following code:\n\n```\nimport tensorflow as tf\n\nwith tf.variable_scope('a'):\n    a = tf.get_variable('v', [], initializer=tf.constant_initializer(0), dtype=tf.int32)\n    a_assign = a.assign(a+100)\n\nwith tf.variable_scope('a', reuse=True):\n    b = tf.get_variable('v', [], initializer=tf.constant_initializer(0), dtype=tf.int32)\n    b_assign = b.assign(b+1)\n\nwith tf.control_dependencies([a_assign, b_assign]):\n    c = tf.constant(0)\n\nsess = tf.InteractiveSession()\nsess.run(tf.initialize_all_variables())\nprint(sess.run([c, a, b]))\n\n```\n\nI expected this piece of code to return [0, 101, 101], but instead it returns [0, 100, 100]. \n\nThen I ran the \"print(sess.run([c, a, b]))\" line 10 times, the outputs were:\n\n[0, 100, 100]\n[0, 200, 200]\n[0, 201, 201]\n[0, 202, 202]\n[0, 303, 303]\n[0, 403, 403]\n[0, 404, 404]\n[0, 405, 405]\n[0, 406, 406]\n[0, 506, 506]\n\nThen I re-ran the program again and the outputs were:\n\n[0, 1, 1]\n[0, 2, 2]\n[0, 3, 3]\n[0, 4, 4]\n[0, 5, 5]\n[0, 6, 6]\n[0, 7, 7]\n[0, 8, 8]\n[0, 108, 108]\n[0, 208, 208]\n\nSo it seems like in this case tf.control_dependencies randomly executes either a_assign or b_assign and not both at each sess.run. Could anyone explain this behavior?\n### Environment info\n\nOperating System:\nUbuntu 14.04\nInstalled version of CUDA and cuDNN: \n-rw-r--r-- 1 root root 189170 Jun  6 15:17 /usr/local/cuda/lib/libcudadevrt.a\nlrwxrwxrwx 1 root root     16 Jun  6 15:17 /usr/local/cuda/lib/libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx 1 root root     19 Jun  6 15:17 /usr/local/cuda/lib/libcudart.so.7.5 -> libcudart.so.7.5.18\n-rwxr-xr-x 1 root root 311596 Jun  6 15:17 /usr/local/cuda/lib/libcudart.so.7.5.18\n-rw-r--r-- 1 root root 558020 Jun  6 15:17 /usr/local/cuda/lib/libcudart_static.a\n\nTensorFlow version 0.9.0\n", "comments": ["Which version are you using?\n\nI'm running 0.10rc0 and the output is always the same. \"tf.constant\" got\nrefactored between 0.9 and 0.10, maybe that's related\n\n[0, 101, 101]\n[0, 202, 202]\n[0, 203, 203]\n[0, 204, 204]\n[0, 304, 304]\n[0, 405, 405]\n[0, 506, 506]\n[0, 607, 607]\n[0, 708, 708]\n[0, 709, 709]\n\nOn Wed, Aug 17, 2016 at 11:51 AM, danfei notifications@github.com wrote:\n\n> Consider the following code:\n> \n> import tensorflow as tf\n> \n> with tf.variable_scope('a'):\n> a = tf.get_variable('v', [], initializer=tf.constant_initializer(0),\n> dtype=tf.int32)\n> a_assign = a.assign(a+100)\n> \n> with tf.variable_scope('a', reuse=True):\n> b = tf.get_variable('v', [], initializer=tf.constant_initializer(0),\n> dtype=tf.int32)\n> b_assign = b.assign(b+1)\n> \n> with tf.control_dependencies([a_assign, b_assign]):\n> c = tf.constant(0)\n> \n> sess = tf.InteractiveSession()\n> sess.run(tf.initialize_all_variables())\n> print(sess.run([c, a, b]))\n> \n> I expected this piece of code to return [0, 101, 101], but instead it\n> returns [0, 100, 100].\n> \n> When I run the \"print(sess.run([c, a, b]))\" line 10 times, the outputs are:\n> \n> [0, 100, 100]\n> [0, 200, 200]\n> [0, 201, 201]\n> [0, 202, 202]\n> [0, 303, 303]\n> [0, 403, 403]\n> [0, 404, 404]\n> [0, 405, 405]\n> [0, 406, 406]\n> [0, 506, 506]\n> \n> Then I re-ran the program again and the outputs are:\n> \n> [0, 1, 1]\n> [0, 2, 2]\n> [0, 3, 3]\n> [0, 4, 4]\n> [0, 5, 5]\n> [0, 6, 6]\n> [0, 7, 7]\n> [0, 8, 8]\n> [0, 108, 108]\n> [0, 208, 208]\n> \n> So it seems like in this case tf.control_dependencies randomly executes\n> either a_assign or b_assign and not both at each sess.run. Could anyone\n> explain this behavior?\n> Environment info\n> \n> Operating System:\n> Ubuntu 14.04\n> Installed version of CUDA and cuDNN:\n> -rw-r--r-- 1 root root 189170 Jun 6 15:17 /usr/local/cuda/lib/\n> libcudadevrt.a\n> lrwxrwxrwx 1 root root 16 Jun 6 15:17 /usr/local/cuda/lib/libcudart.so ->\n> libcudart.so.7.5\n> lrwxrwxrwx 1 root root 19 Jun 6 15:17 /usr/local/cuda/lib/libcudart.so.7.5\n> -> libcudart.so.7.5.18\n> -rwxr-xr-x 1 root root 311596 Jun 6 15:17 /usr/local/cuda/lib/libcudart.\n> so.7.5.18\n> -rw-r--r-- 1 root root 558020 Jun 6 15:17 /usr/local/cuda/lib/libcudart_\n> static.a\n> \n> TensorFlow version 0.9.0\n> \n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3879, or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AABaHMmMcEEJiav2UuQ4F0s8hEJE5kVtks5qg1hFgaJpZM4JmxLT\n> .\n", "@yaroslavvb Thanks!\n\nI tried both 0.9 and 0.10. The behavior still persists. \na.py:\n\n```\nimport tensorflow as tf\nprint(tf.__version__)\n\nwith tf.variable_scope('a'):\n    a = tf.get_variable('v', [], initializer=tf.constant_initializer(0), dtype=tf.int32)\n    a_assign = a.assign(a+100)\n\nwith tf.variable_scope('a', reuse=True):\n    b = tf.get_variable('v', [], initializer=tf.constant_initializer(0), dtype=tf.int32)\n    b_assign = b.assign(b+1)\n\nwith tf.control_dependencies([a_assign, b_assign]):\n    c = tf.constant(0)\n\nsess = tf.InteractiveSession()\nsess.run(tf.initialize_all_variables())\nfor _ in range(10):\n    print(sess.run([c, a, b]))\n```\n\n$ python a.py\n\n0.10.0rc0\n[0, 1, 1]\n[0, 2, 2]\n[0, 3, 3]\n[0, 103, 103]\n[0, 203, 203]\n[0, 204, 204]\n[0, 305, 305]\n[0, 405, 405]\n[0, 406, 406]\n[0, 506, 506]\n\n$ python a.py\n\n0.10.0rc0\n[0, 100, 100]\n[0, 201, 201]\n[0, 302, 302]\n[0, 303, 303]\n[0, 304, 304]\n[0, 305, 305]\n[0, 306, 306]\n[0, 406, 406]\n[0, 407, 407]\n[0, 507, 507]\n\nAlso, shouldn't it always execute a_assign and b_assign at each sess.run? It seems like your output also shows that tf.control_dependencies randomly picks a_assign, b_assign, or both.\n", "Ah, I see a problem, your two assign ops run in parallel so they overwrite each other's results. You could fix it by making assign_b depend on assign_a, or running the two assignments in separate `run` calls.\n", "Alternatively you can replace your \"assign\" ops with \"assign_add\".\nThe \"assign\" operation gets turned into variable read, add, assign. The\n\"read\" op can return value either before or after the parallel assign\nfinished. But with \"assign_add\", there's no separate read op so the result\nshould be deterministic (possibly need to use \"use_locking=True\" option)\n\nOn Wed, Aug 17, 2016 at 2:04 PM, danfei notifications@github.com wrote:\n\n> @yaroslavvb https://github.com/yaroslavvb Thanks!\n> \n> I tried both 0.9 and 0.10. The behavior still persists.\n> a.py:\n> \n> import tensorflow as tf\n> print(tf.**version**)\n> \n> with tf.variable_scope('a'):\n>     a = tf.get_variable('v', [], initializer=tf.constant_initializer(0), dtype=tf.int32)\n>     a_assign = a.assign(a+100)\n> \n> with tf.variable_scope('a', reuse=True):\n>     b = tf.get_variable('v', [], initializer=tf.constant_initializer(0), dtype=tf.int32)\n>     b_assign = b.assign(b+1)\n> \n> with tf.control_dependencies([a_assign, b_assign]):\n>     c = tf.constant(0)\n> \n> sess = tf.InteractiveSession()\n> sess.run(tf.initialize_all_variables())\n> for _ in range(10):\n>     print(sess.run([c, a, b]))\n> \n> $python a.py\n> \n> 0.10.0rc0\n> [0, 1, 1]\n> [0, 2, 2]\n> [0, 3, 3]\n> [0, 103, 103]\n> [0, 203, 203]\n> [0, 204, 204]\n> [0, 305, 305]\n> [0, 405, 405]\n> [0, 406, 406]\n> [0, 506, 506]\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/3879#issuecomment-240547859,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AABaHBBKxm4S-FsflvBZ0Ti4vdicGdb8ks5qg3dkgaJpZM4JmxLT\n> .\n", "I do not believe this is a bug.  As @yaroslavvb says, this is just a racy program which allows arbitrary interleavings of two variable reads and writes.\n\nIf you examine the graphdef this should be more clear.\n\nSince this is not a TensorFlow bug, please direct any followup questions to StackOverflow.\n"]}, {"number": 3878, "title": "Branch 130529399", "body": "", "comments": []}, {"number": 3877, "title": "Rename Tensor \"summary_op\" to \"summary\" in the 101 tutorial", "body": "\"summary_op\" is a Tensor, so it's incorrectly labeled as an op. This change renames it to \"summary\", and makes the corresponding changes in the explanation.\n", "comments": ["Can one of the admins verify this patch?\n", "Looks good to me.\n", "LGTM too :)\n", "@tensorflow-jenkins test this please\n", "One of the test errors is \"No space left on device\". I don't feel that I understand the testing system well enough to comment intelligently, though I'm speculating that the error is not in the code change because it's just a variable rename. Who could take a look and diagnose the problem?\n", "known infra issues, merged since all other tests passed\n"]}, {"number": 3876, "title": "Tensorboard log plot option", "body": "An option to switch between modified-log and linear y-axis scales for event charts in tensorboard. \n\nThe iron-icons are not being displayed properly, but I believe that issue is unrelated to this pull request.\n", "comments": ["Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "The CLA was signed under the company name Gravity Jack, Inc. The commit messages have been updated to an email that is in the Google group on the CLA.\n", "This is amazing. Thank you for taking the time to send us this pull request.\n\nWould you happen to have screenshots? Or better yet, could you set up a running demo server on a VM somewhere?\n", "Thanks for the pull request! This is the first first substantive non-Googler feature work on TensorBoard, I'm excited to receive it :)\n\nI'm not sure why @googlebot isn't happy with the CLA; looking up in our internal tool, I can see that your commit email address (ben@gravityjack.com) is covered by your corporate CLA. Maybe it could have to do with this email address not being associated with your GitHub account? I notice that if I look at the commits tab, your commits have an empty avatar icon, rather than a link to your GitHub account.\n", "Also, can you revert the dist/tf-tensorboard.html file in this pull request? It is going to generate conflicts, and we have tooling for regenerating it when we sync the GitHub repository.\n", "@jart To make things easier for bdilday here are some screenshots: \n![image](https://cloud.githubusercontent.com/assets/1400023/17786421/958f8006-6539-11e6-827e-ae8511d96254.png)\n\n(The bottom chart is in log mode).\n\nThe lack of a top line on the log plot is a bit weird, but really a manifestation of a different issue.\n\nN.b. the screenshots are with my proposed changes, ie. the icons are reversed so that it shows the current state of the chart.\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "Looks good to me except for the conflicts, could you merge changes from master?\n", "@tensorflow-jenkins test this please\n", "@tensorflow-jenkins test this please\n", "@bdilday please rebase your PR and resolve conflicts.\n", "@tensorflow-jenkins Test this please\n", "@bdilday It looks like you wiped out important changes in the rebase you did. Check the files changed on this PR.\n", "@tensorflow-jenkins Test this please.\n", "The failing test is flaky. Merging.\n"]}, {"number": 3875, "title": "Core dump running examples w/gpu", "body": "Running the post-build test throws a Floating point exception:\n\n```\n$ bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.7.5 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.7.5 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.7.5 locally\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:118] Found device 0 with properties: \nname: GeForce GTX TITAN X\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.076\npciBusID 0000:81:00.0\nTotal memory: 12.00GiB\nFree memory: 11.87GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:138] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:148] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:81:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:81:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:81:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:81:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:81:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:81:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:81:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:81:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:81:00.0)\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:868] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN X, pci bus id: 0000:81:00.0)\nFloating point exception (core dumped)\n\n```\n### Environment info\n\nOperating System: Ubuntu 14.04 x86_64\n\nInstalled version of CUDA and cuDNN: \n\n```\n-rw-r--r-- 1 root root   322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18\n-rwxr-xr-x 1 root root   383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18\n-rw-r--r-- 1 root root   720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a\n-rwxr-xr-x 1 root root 59909104 Aug 17 11:12 /usr/local/cuda/lib64/libcudnn.so\n-rwxr-xr-x 1 root root 59909104 Aug 17 11:12 /usr/local/cuda/lib64/libcudnn.so.5\n-rwxr-xr-x 1 root root 59909104 Aug 17 11:12 /usr/local/cuda/lib64/libcudnn.so.5.0.5\n-rw-r--r-- 1 root root 58775484 Aug 17 11:12 /usr/local/cuda/lib64/libcudnn_static.a\n\n```\n\nIf installed from source, provide:\n1. TF commit hash 33b336ada58529d5e0398feea423785f1c3d57c1\n2. Bazel 0.3.1\n\n```\n$ bazel version\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Thu Jan 01 00:00:00 1970 (0)\nBuild timestamp: Thu Jan 01 00:00:00 1970 (0)\nBuild timestamp as int: 0\n$ apt show bazel\nPackage: bazel\nVersion: 0.3.1\nDepends: google-jdk | java8-jdk | java8-sdk, pkg-config, zip, g++,\n zlib1g-dev, unzip, bash-completion\n...\n```\n### Steps to reproduce\n\n(steps taken from https://www.tensorflow.org/versions/r0.10/get_started/os_setup.html#installing-from-sources)\n1. Install CUDA 7.5 under x86_64 for Ubuntu 14.04 using deb (network)\n2. Install cuDNN 5.0 for Linux (Nvidia no longer supplies cudnn4.0 for CUDA 7.5, only for 7.0)\n3. Install Bazel\n4. Build tensorflow using Bazel\n5. Run $ bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu\n### What have you tried?\n1. Taking off the --use_gpu flag leads to successful execution\n2. The nvidia CUDA examples for deviceQuery and bandwidthTest work OK\n3. The GPU is not in exclusive mode (#1534); logs of nvidia-smi -a below\n4. gdb output is included below, too\n### Logs or other output that would be helpful\n\n[tf-gdb.txt](https://github.com/tensorflow/tensorflow/files/422383/tf-gdb.txt)\n[tf-nvsmi.txt](https://github.com/tensorflow/tensorflow/files/422382/tf-nvsmi.txt)\n", "comments": ["I also meet this problem, but not everytime. according to [source code](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/cc/tutorials/example_trainer.cc#L115), variable is randomly initialized, maybe some numerical operations cause this problem.\n", "This is not related to the numerics themselves and the bug disappears for me when `--num_concurrent_sessions=1` is passed in. The different sessions are apparently writing to the same memory locations. Stay tuned for a fix.\n", "Hi \n\nI have the exact same problem, running a TITAN X (Pascal) on Ubuntu 16.04, CUDA 8 + patch, cuDNN 5.1 and Bazel 0.3.1\n\nPassing `--num_concurrent_sessions=1` does not make the bug disappear for me.\n\nRunning without `--use_gpu`, it works\n\nRunning `gdb bazel-bin/tensorflow/cc/tutorials_example_trainer` and then `r --use_gpu`, I get\n\n`Thread 39 \"tutorials_examp\" received signal SIGFPE, Arithmetic exception.\n[Switching to Thread 0x7fffb1b72700 (LWP 20294)]\n0x00005555560f9a40 in tensorflow::functor::CastFunctor<Eigen::GpuDevice, float, int>::operator()(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16>, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16>) ()\n`\n(Number of thread is changing each time I execute)\n\n#3917 seems to be the same problem\n", "Hello, \n\nSame problem here as well.  GTX 1080, Ubuntu 14.04, CUDA 8.0, CuDNN 5.1, nvidia driver 367.27.  `--num_concurrent_sessions=1` does _not_ seem to change anything for me, either.  With `--use_gpu`, roughly 1 in 10-15 runs finishes without error.  Without `--use_gpu`, it works as expected.\n", "Same here with @iraadit and @jrecursive running Ubuntu 16.04, CUDA 8.0, CuDNN 5.1 and nvidia driver 370.\n\nBacktrace:\n`#0  0x000055555611e040 in tensorflow::functor::CastFunctor<Eigen::GpuDevice, float, int>::operator()(Eigen::GpuDevice const&, Eigen::TensorMap<Eigen::Tensor<float, 1, 1, long>, 16>, Eigen::TensorMap<Eigen::Tensor<int const, 1, 1, long>, 16>) ()`\n\n`#1  0x00005555560f364d in std::_Function_handler<void (tensorflow::OpKernelContext*, tensorflow::Tensor const&, tensorflow::Tensor*), tensorflow::GetGpuCastFromInt32(tensorflow::DataType)::{lambda(tensorflow::OpKernelContext*, tensorflow::Tensor const&, tensorflow::Tensor*)#9}>::_M_invoke(std::_Any_data const&, tensorflow::OpKernelContext*&&, tensorflow::Tensor const&, tensorflow::Tensor*&&) ()`\n\n`#2  0x00005555560bd75d in tensorflow::CastOpBase::Compute(tensorflow::OpKernelContext*) ()`\n\n`#3  0x0000555556b46da5 in tensorflow::BaseGPUDevice::Compute(tensorflow::OpKernel*, \ntensorflow::OpKernelContext*)()`\n\n`#4  0x0000555556b6bdb5 in tensorflow::(anonymous namespace)::ExecutorState::Process(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long) ()`\n\n`#5  0x0000555556b5fb15 in std::_Function_handler<void (), std::_Bind<std::_Mem_fn<void (tensorflow::(anonymous namespace)::ExecutorState::*)(tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long)> (tensorflow::(anonymous namespace)::ExecutorState*, tensorflow::(anonymous namespace)::ExecutorState::TaggedNode, long long)> >::_M_invoke(std::_Any_data const&) ()`\n\n`#6  0x0000555556cca70c in Eigen::NonBlockingThreadPoolTempl<tensorflow::thread::EigenEnvironment>::WorkerLoop(int)()`\n\n`#7  0x0000555556cc9337 in std::_Function_handler<void (), tensorflow::thread::EigenEnvironment::CreateThread(std::function<void ()>)::{lambda()#1}>::_M_invoke(std::_Any_data const&) ()`\n\n`#8  0x00007ffff7182c80 in ?? () from /usr/lib/x86_64-linux-gnu/libstdc++.so.6`\n\n`#9  0x00007ffff79606fa in start_thread (arg=0x7fffcf7fe700) at pthread_create.c:333`\n\n`#10 0x00007ffff6bf1b5d in clone () at ../sysdeps/unix/sysv/linux/x86_64/clone.S:109`\n", "Is that still happening with the latest version?", "Closing due to inactivity. Feel free to re-open if you would like us to look again.", "@aselle Could you comment on the reopen?  @poulson-google Did you ever figure out a fix?", "Just wanted to get a final followup since it was a crashing issue.\r\n", "This is fixed in HEAD:\r\nhttps://github.com/tensorflow/tensorflow/blob/6bdc4cdb8fe9557e567d59a6ad3a758bf120e2fc/tensorflow/cc/tutorials/example_trainer.cc#L149", "Great!"]}, {"number": 3874, "title": "SVD not accepting complex matrices", "body": "Just with a small test case on the Eigen BDCSVD which should work with complex matrices, I  get `TypeError: DataType complex128 for attr 'T' not in list of allowed values: float64, float32`. I know that TensorFlow SVD is very new, but where would I look to enable complex types?\n\nHere was my test code:\n\n``` python\nx = np.array([[0, -1j], [1j, 0]])\na = tf.placeholder(tf.complex128, [None, None])\ns, u, v = tf.svd(a)\nsess = tf.Session()\nprint(sess.run(u, feed_dict={a: x}))\n```\n", "comments": ["@AidanGG your PR was merged. Thanks for the contribution!\n"]}, {"number": 3873, "title": "Add some new features of mnist_replica", "body": "Modify the `mnist_replica.py`:\n1.Add `FLAGS.ps_hosts,  FLAGS.worker_hosts` and `get_cluster_setter()` function to set the cluster and allocate the device. It's more likely the Distributed Tutorial of Tensorflow [here](https://www.tensorflow.org/versions/r0.10/how_tos/distributed/index.html#putting-it-all-together-example-trainer-program)\n2.Add the `gpu_num` argument to allocate the gpu for worker server\n3.Add `Flags.steps_per_checkpoint` to manage the saving time of checkpoint file.\n", "comments": ["Can one of the admins verify this patch?\n"]}, {"number": 3872, "title": "Removing a confusing statement about training op", "body": "The statement seemed to suggest that optimizer.minimize() returns a Tensor, which it doesn't; I removed the statement.\n\nTo make the point even more explicit, I'm emphasizing that this is an op rather than a Tensor, but maybe that's overkill.\n", "comments": ["Can one of the admins verify this patch?\n"]}, {"number": 3871, "title": "Correct the Variable constructor docstring: there's no return value", "body": "It's a constructor, so it doesn't return anything. I removed the comment stating that it returns a Variable.\n", "comments": ["Can one of the admins verify this patch?\n"]}, {"number": 3870, "title": "DNNLinearCombinedClassifier in distributed system on cpu. Worker1 costs 1000% of CPU and other workers cost 30%~50%.", "body": "#### Installed from source, r0.10 branch.\n### Steps to reproduce\n\nI use multi-ps & multi-worker to train. Model is DNNLinearCombinedClassifier under `contrib.learn`.\n#### Distributed code:\n\n ps & worker entrance:\n\n```\n  server = tf.train.Server(\n    {'ps': ps_hosts,\n     'worker': worker_hosts},\n    job_name=FLAGS.job_name,\n    task_index=task_id)\n\n  if FLAGS.job_name == 'ps':\n    # `ps` jobs wait for incoming connections from the workers.\n    server.join()\n  else:      \n      # `worker` jobs will actually do the work.\n      self.worker_do(server.targer, cluster_spec, task_id)\n```\n\nself.worker_do:\n\n```\nnum_workers = len(cluster_spec.as_dict()['worker'])\nnum_parameter_servers = len(cluster_spec.as_dict()['ps']) \nrun_config = RunConfig(master=target, task=task_id, num_ps_replicas=num_parameter_servers,\n                     num_cores=8)\nclassifier = DNNLinearCombinedClassifier(dnn_hidden_units=[1024, 512, 256], config=run_config, dnn_feature_columns=deep, model_dir=FLAGS.train_dir)\nclassifier.fit(input_fn=_input, steps=FLAGS.max_steps)\n```\n\nStart ps1...N, then worker1...N\n\n`When training begin, I found worker1 cost 1000% CPU and other workers cost less on 100%.`\n### What have you tried?\n\ncode in BaseEstimator when `__init__`:\n\n```\n # Set device function depending if there are replicas or not.\nif self._config.num_ps_replicas > 0:\n  ps_ops = ['Variable', 'AutoReloadVariable']\n  self._device_fn = device_setter.replica_device_setter(\n      ps_tasks=self._config.num_ps_replicas,\n      merge_devices=False, ps_ops=ps_ops)\nelse:\n  self._device_fn = None\n```\n\nI tried to add a param to `device_setter.replica_device_setter`\n\n```\nworker_device='/job:worker/task:%d' % self._config.task \n```\n\nAnd it works. Cpu balances.\n### Suggesting\n\nCould you consider adding an API to place `_device_fn` to BaseEstimator. Then, tf users can customize their own `_device_fn`.\n\nThanks.\n", "comments": ["I think specifying `worker_device` as above in function `device_setter.replica_device_setter` means that your model is data parallel, not model parallel. Maybe my understanding of this function is not correct.\n", "@suiyuan2009 \nYes, I use data parallel to train model. Datasets has been partitioned into different workers. Every worker reads its own specific data which is one part of the whole datasets.\n", "if not specify `worker_device` in `device_setter.replica_device_setter`, will operations partition to different workers? maybe worker1 got some heavy operations.\n", "@suiyuan2009 I think if not specify `worker_device` in `device_setter.replica_device_setter`, ops executes on worker1 except `input op`\n", "Worker1 has more responsibilities than other workers. It saves/restores the graph, calculates/dumps summaries. I recommend to put more resources to the first worker.\n", "@ispirmustafa I agree with you about putting more resources to the first worker. But this issue, most of calculates except summaries and checkpoints are on worker1. Worker1 costs 1000% of cpu and other workers cost 30%~50%. When I set `worker_device='/job:worker/task:%d' % self._config.task`. Every worker cost 300%~500% of cpu.\n", "Closing due to inactivity. Feel free to reopen if this is still current."]}, {"number": 3869, "title": "Run \"bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu\", got \"No such file or directory\"", "body": "Hi everyone:\n### Environment info\n\nUbuntu 14.04 LTS\n\nInstalled version of CUDA and cuDNN: \nCUDA 7.5, cuDNN v5.1\n![image](https://cloud.githubusercontent.com/assets/12611573/17721639/5e9f7f32-645e-11e6-8ba6-ec7f37b1e139.png)\nI try to build tensorflow with CUDA 7.5, cuDNN v5.1 and bazel-0.3.1-installer-linux-x86_64.sh. When I run 'bazel build -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer', it seems good. But when I run 'bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu', I got the error 'No such file or directory'. So I find the tutorials_example_trainer in following path:\n![image](https://cloud.githubusercontent.com/assets/12611573/17721729/13e19b5a-645f-11e6-91e7-73667ea0905d.png)\nI tried to run '/home/caffe/.cache/bazel/_bazel_caffe/5954a53028453a61b395a19127f3e1cf/execroot/tensorflow/bazel-out/local_linux-opt/bin/tensorflow/cc/tutorials_example_trainer.runfiles/org_tensorflow/tensorflow/cc/tutorials_example_trainer --use_gpu' and got the result like following:\n![image](https://cloud.githubusercontent.com/assets/12611573/17721744/349e1ba2-645f-11e6-80a8-9746ac31a43a.png)\nIt seems ok, but I do not know why cann't I run 'bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu'.\nCan anyone help me ?\nThanks!\n", "comments": ["I can't reproduce, does this file `bazel-bin/tensorflow/cc/tutorials_example_trainer` exist in your tensorflow root directory?\n", "@suiyuan2009 It does not exist. I do not know why. I am still checking out something I ignored.\n", "@JohnnyY8 have you tried `bazel clean` and `./configure` then rebuilding?\n", "@suiyuan2009 OK, I will try it now.\n", "@suiyuan2009 \nI got this:\n![image](https://cloud.githubusercontent.com/assets/12611573/17729306/218e5004-6496-11e6-9291-01c65b46820f.png)\nI think this is the problem, but when I use \"sudo\", I got \"sudo: bazel: command not found\". So if I can run bazel with sudo, it may works, right?\n", "@JohnnyY8 run `which bazel`, and use full bazel bin file path instead of `bazel`.\n", "@suiyuan2009 I change the authority of tensorflow file, and it works. Thanks for you help!\nBTW, take the authority into account, do people usually git clone tensorflow under the $HOME path or somewhere? \n", "why bazel need sudo authority?\n", "@suiyuan2009 Maybe because I git clone the tensorflow under \"/home/common/\" path which is made by myself. This path belongs to root user.\n", "This looks like a simple Unix permissions issue, and not a TensorFlow bug.  Please reopen if this is not the case.\n", "I am having the same issue while building on cpu. Steps i followed\r\n1. bazel clean\r\n2. ./configure \r\n3. bazel build --config op\r\n```\r\nkush@kush-Lenovo-B40-80:~/machine_learning/deeplearning/tensorflow$ bazel build --config=op\r\nWarning: ignoring LD_PRELOAD in environment.\r\nWARNING: Config values are not defined in any .rc file: op\r\nINFO: Found 0 targets...\r\nINFO: Elapsed time: 2.365s, Critical Path: 0.03s\r\n\r\n```\r\n4. Now when i try to run \r\n`bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg`\r\n```\r\nkush@kush-Lenovo-B40-80:~/machine_learning/deeplearning/tensorflow$ bazel-bin/tensorflow/tools/pip_package/build_pip_package\r\nbash: bazel-bin/tensorflow/tools/pip_package/build_pip_package: No such file or directory\r\n```\r\n\r\nBut then i tried sudo it gives \r\n`sudo: bazel-bin/tensorflow/tools/pip_package/build_pip_package: command not found\r\n`\r\n\r\nbazel is installed in my system. i have checked it. \r\n\r\nI also tried giving full path in bazel-bin\r\n\r\n`sudo: /usr/bin/bazel-bin/tensorflow/tools/pip_package/build_pip_package: command not found\r\n`\r\nCan anyone help me on this?\r\n"]}, {"number": 3868, "title": "Move TensorBoard 25 into r0.10", "body": "TensorBoard 25 has some great features, including:\n- exponential smoothing\n- new Histogram dashboard\n- bugfixes \n", "comments": []}, {"number": 3867, "title": "parallel_iterations option behaves differently if per_process_gpu_memory_fraction is set", "body": "I'm seeing inconsistent behavior with the `parallel_iterations` option in dynamic RNNs. For large RNNs, if I set `parallel_iterations` to too high a number, I run out of memory. However, setting `parallel_iterations` to 1 or 2 solves the problem. This is only true however if `per_process_gpu_memory_fraction` is not set. If it is set, even to 1.0, then no matter what value I set `parallel_iterations` to, I always run out of memory (for this large RNN).\n\nI am not sure if this is related to #2610 or not.\n", "comments": ["@ebrevdo Do you know why this might be?\n", "yuan should be able to help with this.\n", "It is expected that lowering `parallel_iteration` would reduce memory consumption. A higher `parallel_iterations` increases the parallelism but may need to keep more intermediate tensors alive at any given time.\n\nI have no idea about the`per_process_gpu_memory_fraction` part of the question. \n", "Closing this due to inactivity. Feel free to open a new github issue if the problem still persists in recent versions."]}, {"number": 3866, "title": "Branch 130458942", "body": "", "comments": []}, {"number": 3865, "title": "docs(slim): fixes typos and capitalizes Tensorflow", "body": "Updates to docs:\n- A few misspellings\n- Grammar\n- \"tensorflow\" -> \"Tensorflow\"\n", "comments": ["Can one of the admins verify this patch?\n", "@benoitsteiner - updated `(T|t)ensorflow` -> `TensorFlow` in this file as well as other *.md files.  Stayed out of .py, .java and .h comments though.  Lemme know if you'd rather I only update slim readme.\n", "Closing due to lack of response, but feel free to make the fixes and ping back and we'll reopen.  Trying to keep the number of active PRs down so things don't fall through the cracks\n"]}, {"number": 3864, "title": "Tensorflow r.0.10, CUDA 8.0, cuDNN 5.1 core dumped, CUDA_ERROR_OUT_OF_MEMORY", "body": "On running a benchmark with MNIST data on a CNN (source below) tensorflow first complains about memory allocation and then appears to have trouble using cuDNN 5.1\nDetailed script and output at the bottom. \nProblem appears to affect cuDNN specifically as I could run CUDA examples as well as matmul on tensorflow without problems. \n### Environment info\n\nOperating System: ubuntu 16.04\nuname -a\nLinux <Name> 4.4.0-34-generic #53-Ubuntu SMP Wed Jul 27 16:06:39 UTC 2016 x86_64 x86_64 x86_64 GNU/Linux\n\nInstalled version of CUDA and cuDNN: \nls -l $CUDA_HOME/lib64/libcud*\n-rw-r--r-- 1 root root   560184 Aug 15 22:51 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Aug 15 22:51 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\nlrwxrwxrwx 1 root root       19 Aug 15 22:51 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27\n-rwxr-xr-x 1 root root   394472 Aug 15 22:51 /usr/local/cuda/lib64/libcudart.so.8.0.27\n-rw-r--r-- 1 root root   737516 Aug 15 22:51 /usr/local/cuda/lib64/libcudart_static.a\nlrwxrwxrwx 1 root root       13 Aug 15 23:39 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\nlrwxrwxrwx 1 root root       17 Aug 15 23:39 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5\n-rwxr-xr-x 1 root root 79337624 Aug 15 23:39 /usr/local/cuda/lib64/libcudnn.so.5.1.5\n-rw-r--r-- 1 root root 69756172 Aug 15 23:39 /usr/local/cuda/lib64/libcudnn_static.a\n### Environment variables\n\necho $LD_LIBRARY_PATH\n/usr/local/cuda/lib64:/usr/local/cuda/extras/CUPTI/lib64\necho $CUDA_HOME\n/usr/local/cuda\necho $PATH\n/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/usr/local/cuda/bin/:/usr/local/cuda/bin/\n### Tensorflow version\n\nCompiled from source, r0.10, built into pip package and installed this pip wheel\nConfigured with cuDNN path and version set to system default\n1. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n   see /// OUTPUT /// at the end\n\nIf installed from source, provide \n1. The commit hash (`git rev-parse HEAD`)\n   n.a.\n   version r0.10\n2. The output of `bazel version`\n   bazel version\n   Build label: 0.3.1-2016-08-15 (@936c2c2)\n   Build target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\n   Build time: Sun Aug 14 23:07:32 2016 (1471216052)\n   Build timestamp: 1471216052\n   Build timestamp as int: 1471216052\n### Steps to reproduce: run this script\n\nimport numpy\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.layers.convolutional import Convolution2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.utils import np_utils\n##### fix random seed for reproducibility\n\nseed = 7\nnumpy.random.seed(seed)\n##### load data\n\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\n##### reshape to be [samples][channels][width][height]\n\nX_train = X_train.reshape(X_train.shape[0], 1, 28, 28).astype('float32')\nX_test = X_test.reshape(X_test.shape[0], 1, 28, 28).astype('float32')\n##### normalize inputs from 0-255 to 0-1\n\nX_train = X_train / 255\nX_test = X_test / 255\n##### one hot encode outputs\n\ny_train = np_utils.to_categorical(y_train)\ny_test = np_utils.to_categorical(y_test)\nnum_classes = y_test.shape[1]\n##### define a simple CNN model\n\ndef baseline_model():\n    ##### create model\n    model = Sequential()\n    model.add(Convolution2D(32, 5, 5, border_mode='valid', input_shape=(1, 28, 28), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    model.add(Dense(num_classes, activation='softmax'))\n    ##### Compile model\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model\n##### build the model\n\nmodel = baseline_model()\n##### Fit the model\n\nmodel.fit(X_train, y_train, validation_data=(X_test, y_test), nb_epoch=10, batch_size=200, verbose=2)\n##### Final evaluation of the model\n\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"CNN Error: %.2f%%\" % (100-scores[1]*100))\n### ///////////// OUTPUT /////////////////\n\nUsing TensorFlow backend.\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.8.0 locally\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:925] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: GeForce GTX 1070\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.683\npciBusID 0000:01:00.0\nTotal memory: 7.91GiB\nFree memory: 148.69MiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:840] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)\nE tensorflow/stream_executor/cuda/cuda_driver.cc:965] failed to allocate 148.69M (155910144 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\nTrain on 60000 samples, validate on 10000 samples\nEpoch 1/10\nE tensorflow/stream_executor/cuda/cuda_dnn.cc:354] could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\nE tensorflow/stream_executor/cuda/cuda_dnn.cc:321] could not destroy cudnn handle: CUDNN_STATUS_BAD_PARAM\nF tensorflow/core/kernels/conv_ops.cc:457] Check failed: stream->parent()->GetConvolveAlgorithms(&algorithms) \nAborted (core dumped)\n", "comments": ["I tried to build again from source using r0.10 everything being the same EXCEPT cuDNN**5.0** this time. My code example from above worked without errors this time. Closing the issue. I'll reopen and report in case I find out more. \n", "Hi iNLyze, I got the same problem as you.\r\nThe point is here :\r\n\r\nname: GeForce GTX 1070\r\nmajor: 6 minor: 1 memoryClockRate (GHz) 1.683\r\npciBusID 0000:01:00.0\r\nTotal memory: 7.91GiB\r\nFree memory: 148.69MiB\r\n\r\nTotal memory we have is 7.91GiB, but available is only 148.69MiB.\r\nThis mean that our vram has been allocated to other places.\r\nSo before we run the code, just add : \r\n\r\nimport os\r\nos.system('export CUDA_VISIBLE_DEVICES=\"\"')\r\n\r\nor do it in your command line like this : \r\n\r\nexport CUDA_VISIBLE_DEVICES=\"\"\r\n\r\nto release all your devices using vram, then well done !"]}, {"number": 3863, "title": "Fix some comment and test case typos", "body": "", "comments": ["Can one of the admins verify this patch?\n", "Jenkins, test this please\n"]}, {"number": 3862, "title": "tf.cumprod's gradient produces nans given zeros", "body": "Example:\n\n```\ntf.reset_default_graph()\nvar = tf.Variable([0.])\ncumprod = tf.cumprod(var)\ngrad = tf.gradients(cumprod, var)\ninit = tf.initialize_all_variables()\nwith tf.Session() as sess:\n  sess.run(init)\n  print(sess.run(grad))\n\n---> [array([ nan], dtype=float32)]\n```\n\n@ibab Do you know the right way to fix this?\n", "comments": ["I've placed a comment on this in the gradient code here: [`tensorflow/python/ops/math_grad.py#L889`](https://github.com/tensorflow/tensorflow/blob/51fd9c024c4544ba1ef60862ec3f55b6e3ae79b1/tensorflow/python/ops/math_grad.py#L889)\n\nI've spent some time trying to come up with a version that doesn't use a division by `x`, but didn't  come up with anything elegant.\n", "Hmm, that is pretty awkward:\n\n```\nv = [x, y, z]\ncumprod = [x, xy, xyz]\ngrad = [dx + y dy + yz dz, x dy + xz dz, xy dz]\n```\n", "So in general you need all prefix products with each possible entry excluded.  Unfortunately if you write those as products of contiguous ranges you need quadratically many ranges.  Ug.\n", "A fast O(n) solution.\r\nAssume the input vector `x` and the upstream gradient `g` has the form:\r\n```\r\nx = [x1 x2 x3 ... xn, 0, -, -, ...]\r\ng = [g1 g2 g3 ... gn, gnp1, -, -, ...]\r\n```\r\n`-` Elements are irrelevant in this computation because the leftmost 0 cause `cumprod` become 0 after that.\r\n\r\nThe downstream gradient is:\r\n```\r\n[ dx1 ... dx <use unsafe method> ] + [ cumprod(x1,x2,x3...xn) * gnp1 ] + [0, 0, 0 ... 0]\r\n```\r\n\r\nTo gain full speedup, the forward computation should record the index of first occurrence of `0`, and automatically `memset(0)` for the results after that. This optimization is unique to `cumprod` and can't be done to `cumsum`. The backward computation can just use that index to quickly do the job.\r\n\r\nMaybe it's a good idea to modify `cumprod` interface to `def cumprod(input, use_unsafe_grad=False)`, so that user can force unsafe method if it can ensure no zero elements in input.\r\n\r\nSo far, this is useful in Deepmind's DNC model because it has a `cumprod` which often encounters zero.\r\n\r\nSorry, not familiar with C++, so no PR yet.", "The following workaround helps to avoid the NaN gradient issue (it lacks the `exclusive` or `reverse` flags but they're easy enough to implement):\r\n```python\r\ndef cumprod(tensor, axis=0):\r\n    transpose_permutation = None\r\n    n_dim = len(tensor.get_shape())\r\n    if n_dim > 1 and axis != 0:\r\n\r\n        if axis < 0:\r\n            axis = n_dim + axis\r\n\r\n        transpose_permutation = np.arange(n_dim)\r\n        transpose_permutation[-1], transpose_permutation[0] = 0, axis\r\n\r\n    tensor = tf.transpose(tensor, transpose_permutation)\r\n\r\n    def prod(acc, x):\r\n        return acc * x\r\n\r\n    prob = tf.scan(prod, tensor)\r\n    tensor = tf.transpose(prob, transpose_permutation)\r\n    return tensor\r\n```\r\n\r\nCan anyone comment on efficiency of this approach?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n\r\nIt looks like there is a workaround posted.", "I submitted a fix to this issue in the PR #32714"]}, {"number": 3861, "title": "enable python setup.py test using nose", "body": "when developing for the python package might be useful to use standard python testing \n\n`python setup.py test`\n", "comments": ["Can one of the admins verify this patch?\n", "From nose's website: \"New projects should consider using Nose2, py.test, or just plain unittest/unittest2.\"\n\nI'd rather keep using unittest for now, unless there's a clear reason for using something else.\n", "(Closing for now, feel free to comment -- after reading a bunch of the documentation, it seems like unittest + bazel test accomplishes a lot of what nose/nose2 does).\n"]}, {"number": 3860, "title": "dynamic_rnn error: cannot set initial_state, could before", "body": "So, I've come back to my code after a week, I was using dynamic_rnn and have the initial_state parameter set to a tuple, everything was working fine training worked beautifully... \n\nAnyway, now today I get this error:\nTypeError: The two structures don't have the same sequence type. First structure has type type 'tuple', while second structure has type class 'tensorflow.python.ops.rnn_cell.LSTMStateTuple'.\n\nI suspect there was an update somewhere, so If someone could point me to where/how I can make an LSTMStateTuple object I would be greatly appreciated. \n", "comments": ["  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 835, in dynamic_rnn\n    dtype=dtype)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/rnn.py\", line 1002, in _dynamic_rnn_loop\n    swap_memory=swap_memory)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 2002, in while_loop\n    result = context.BuildLoop(cond, body, loop_vars)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1887, in BuildLoop\n    pred, body, original_loop_vars, loop_vars)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/control_flow_ops.py\", line 1844, in _BuildLoop\n    nest.assert_same_structure(list(packed_vars_for_body), list(body_result))\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/nest.py\", line 137, in assert_same_structure\n    _recursive_assert_same_structure(nest1, nest2)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/nest.py\", line 115, in _recursive_assert_same_structure\n    _recursive_assert_same_structure(n1, n2)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/nest.py\", line 115, in _recursive_assert_same_structure\n    _recursive_assert_same_structure(n1, n2)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/util/nest.py\", line 112, in _recursive_assert_same_structure\n    % (type_nest1, type_nest2))\nTypeError: The two structures don't have the same sequence type. First structure has type <type 'tuple'>, while second structure has type <class 'tensorflow.python.ops.rnn_cell.LSTMStateTuple'>.\n\n", "@jarmstrong2 Please can you provide all of the information requested in the TensorFlow issues template - i.e. version information of all packages and full reproduction information.  It is very hard to triage issues if you do not provide these details.\n", "Sorry about the change, which broke backwards compatibility.  To create the new tuple type, use `tf.nn.rnn_cell.LSTMStateTuple(c, h)` instead of just `(c, h)`.\n", "@jarmstrong2 I hope @ebrevdo 's tip helped you fix your code, and sorry again about the backwards-incompatibility.  I'm closing this out, but feel free to re-open if problems still remain.\n"]}, {"number": 3859, "title": "Error from loading model when running /examples/skflow/iris_save_restore.py", "body": "I am running the example code [iris_save_restore.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/skflow/iris_save_restore.py):\n\nIn particular when running\n\n```\nipython iris_save_restore.py\n```\n\nI get the error:\n\n```\nWARNING:tensorflow:TensorFlowLinearClassifier class is deprecated. Please consider using LinearClassifier as an alternative.\nWARNING:tensorflow:Using temporary folder as model directory: /var/folders/k7/x_ddt3gn57z7x452wglt9brh0000gn/T/tmpgOl66O\nWARNING:tensorflow:Setting feature info to TensorSignature(dtype=tf.float32, shape=TensorShape([Dimension(None), Dimension(4)]), is_sparse=False)\nWARNING:tensorflow:Setting targets info to TensorSignature(dtype=tf.int64, shape=TensorShape([Dimension(None)]), is_sparse=False)\nAccuracy: 0.966667\n---------------------------------------------------------------------------\nValueError                                Traceback (most recent call last)\n/Users/brad/Downloads/iris_save_restore.py in <module>()\n     49 ## Restore everything\n     50 new_classifier = learn.TensorFlowEstimator.restore(\n---> 51     '/tmp/skflow_examples/iris_custom_model')\n     52 score = metrics.accuracy_score(y_test, new_classifier.predict(x_test))\n     53 print('Accuracy: {0:f}'.format(score))\n\n/Users/brad/anaconda/lib/python2.7/site-packages/tensorflow/contrib/learn/python/learn/estimators/base.pyc in restore(cls, path, config)\n    324     model_def_filename = os.path.join(path, 'model.def')\n    325     if not os.path.exists(model_def_filename):\n--> 326       raise ValueError(\"Restore folder doesn't contain model definition.\")\n    327     # list of parameters that are allowed to be reconfigured\n    328     reconfigurable_params = ['_config']\n\nValueError: Restore folder doesn't contain model definition.\n```\n\nBut in the model directory `/var/folders/k7/x_ddt3gn57z7x452wglt9brh0000gn/T/tmpgOl66O`, there are the following files:\n- `checkpoint`\n- `graph.pbtxt`\n- `model.ckpt-200.meta`\n- `events.out.tfevents.1471384242.ip-192-168-100-142.ec2.internal`\n- `model.ckpt-200-00000-of-00001`\n\nThanks so much for the help. \n### Environment info\n\nOperating System: OS X 10.11.6\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\n   sudo pip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.10.0rc0-py2-none-any.whl\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n   0.10.0rc0\n", "comments": []}]