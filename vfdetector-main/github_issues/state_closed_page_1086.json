[{"number": 20691, "title": "Failed to convert squeezenet quantized model to .tflite", "body": " System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:    NO\r\n- OS Platform and Distribution :\r\nLinux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: \r\nSOURCE\r\n- **TensorFlow version (use command below)**:\r\n1.8.0\r\n- **Python version**: \r\n2.7.12\r\n- **Bazel version (if compiling from source)**:\r\n0.11.0\r\n- **GCC/Compiler version (if compiling from source)**:\r\n5.4.0\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\n        ####Command to convert  to .tflite\r\n         bazel-bin/tensorflow/contrib/lite/toco/toco \\\r\n         --input_file=/pathOfQuantizedFile/xyz.pb \\\r\n         --output_file=/pathOfQuantizedFile/xyz.tflite \\\r\n         --input_format=TENSORFLOW_GRAPHDEF --output_format=TFLITE \\\r\n         --inference_type=QUANTIZED_UINT8 \\\r\n         --input_shape=1,256,256 \\\r\n         --input_array=input_node \\\r\n         --output_array=output_node \\\r\n         --std_value=127.5 --mean_value=127.5\r\n\r\n### Describe the problem\r\nI quantized squeezenet Model using command below:\r\n        \r\n        bazel build tensorflow/python/tools:strip_unused\r\n        bazel-bin/tensorflow/python/tools/strip_unused \\\r\n        --input_graph=/path/xyz.pb \\\r\n        --output_graph=/path/tem/xyz.pb\\\r\n        --input_node_names=input_node \\\r\n        --output_node_names=output_node \\\r\n        --input_binary=true\r\n\r\n        bazel build tensorflow/tools/quantization:quantize_graph\r\n        bazel-bin/tensorflow/tools/quantization/quantize_graph \\\r\n        --input=/path/tem/xyz.pb\\\r\n        --output=/pathOfQuantizedFile/xyz.pb\\\r\n        --output_node_names=output_node \\\r\n        --mode=weights\r\n but when I tried to convert this quantized file to .tflite. It gave error:\r\n\r\n        2018-07-11 15:51:46.317809: F tensorflow/contrib/lite/toco/tooling_util.cc:1445] Array                    \r\n        Conv2D_bias, which is an input to the Conv operator producing the output array Conv2D, is    \r\n        lacking min/max data, which is necessary for quantization. Either target a non-quantized output \r\n        format, or   change the input graph to contain min/max information, or pass                                                    \r\n       --default_ranges_min= and --default_ranges_max= if you do not care about the accuracy of  \r\n       results.\r\n       Aborted (core dumped)\r\n\r\n\r\n\r\n### Source code / logs\r\n\r\n2018-07-11 15:51:46.288981: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.289073: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.289110: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.289137: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.289163: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.289189: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.289236: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.289261: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.289282: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.289324: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.289346: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.289372: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.289394: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.289419: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.289457: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.289485: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.289514: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.289543: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.289572: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.289621: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.289651: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.289691: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.289737: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.289765: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.289794: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.289823: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.289852: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.289905: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.289933: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.289962: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.289993: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.290024: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.290082: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.290116: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.290177: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.290226: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.290255: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.290284: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.290314: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.290343: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.290383: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.290410: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.290440: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.290468: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.290497: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.290545: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.290576: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.290635: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.290685: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.290712: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.290742: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.290771: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.290800: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.290841: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.290868: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.290898: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.290927: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.290956: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.291023: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.291062: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.291204: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.291256: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.291284: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.291316: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.291350: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.291378: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.291419: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.291446: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.291475: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.291504: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.291533: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.291587: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.291620: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.291764: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.291816: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.291844: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.291874: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.291903: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.291933: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.291974: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.292001: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.292030: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.292059: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.292089: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.292152: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.292213: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.292681: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.292739: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.292768: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.292798: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.292828: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.292857: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.292898: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.292926: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.292956: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.292985: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.293014: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.293113: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.293154: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.293182: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.293211: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.293240: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.293270: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1265] Converting unsupported operation: Dequantize\r\n2018-07-11 15:51:46.296627: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 381 operators, 700 arrays (0 quantized)\r\n2018-07-11 15:51:46.301535: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 381 operators, 700 arrays (0 quantized)\r\n2018-07-11 15:51:46.307561: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 283 operators, 618 arrays (1 quantized)\r\n2018-07-11 15:51:46.312002: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 283 operators, 618 arrays (1 quantized)\r\n2018-07-11 15:51:46.314295: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After pre-quantization graph transformations pass 1: 283 operators, 618 arrays (1 quantized)\r\n2018-07-11 15:51:46.317809: F tensorflow/contrib/lite/toco/tooling_util.cc:1445] Array Conv2D_bias, which is an input to the Conv operator producing the output array Conv2D, is lacking min/max data, which is necessary for quantization. Either target a non-quantized output format, or change the input graph to contain min/max information, or pass --default_ranges_min= and --default_ranges_max= if you do not care about the accuracy of results.\r\nAborted (core dumped)\r\n\r\n       \r\n", "comments": ["Hi, Can you provide the input graph (pb) and the code for the squeezenet model so that we can work on resolving this issue?\r\nThanks,\r\n", "Thanks Raghuraman for reply but sorry, I cant share pb since it is confidential.", "I faced the same issue.\r\nThe working quantized model in Tensorflow when converted to .tflite file and used in Tensorflow-Lite, it did not work in version 1.9 also on master branch.\r\n\r\nin iOS it showed \r\n\r\n> Didn't find custom op for name 'Dequantize'\r\n> Didn't find custom op for name 'RSQRT'", "Hi, I tried converting same quantized model (pb) to .tflite, with command  below:\r\n        \r\n        bazel-bin/tensorflow/contrib/lite/toco/toco \\\r\n       --input_file=/pathOfQuantizedFile/xyz.pb \\\r\n       --input_format=TENSORFLOW_GRAPHDEF  --output_format=TFLITE \\\r\n       --output_file=/pathOfQuantizedFile/xyz.tflite   --inference_type=FLOAT \\\r\n       --input_type=FLOAT --input_arrays=input_node   --output_arrays=output_node    \r\n       --input_shapes=1,256,256  --allow_custom_ops\r\nThe file converted to .tflite successfully but when used in Android it gave error:\r\n\r\n         Didn't find custom op for name 'RSQRT'\r\n         Didn't find custom op for name 'Dequantize'\r\n         Didn't find custom op for name 'ReorderAxes'\r\n\r\n        \r\n         ", "Hi @ShubhamSrivastava93  and @simonfernandes7389 \r\n\r\nIf I understand correctly, both of you are trying to quantize a model using tensorflow/tools/quantization:quantize_graph. It seems that quantize_graph insert Dequantize ops in ways that TOCO can't handle. Would you be able to avoid quantized_graph and instead use tflite_convert or toco with --quantize_weights ?", "Thanks @andrehentz. I tried below command for non-quantized squeezenet model (.pb)\r\n```\r\nbazel-bin/tensorflow/contrib/lite/toco/toco \\\r\n  --input_file=/somePath/xyz.pb \\\r\n  --input_format=TENSORFLOW_GRAPHDEF  --output_format=TFLITE \\\r\n  --output_file=/somePath/xyz.tflite --inference_type=FLOAT \\\r\n  --input_type=FLOAT --input_arrays=input_node \\\r\n  --output_arrays=output_node --input_shapes=1,256,256 \\\r\n  --quantize_weights \r\n```\r\nbut the size of generated .tflite remains almost same, whereas by using quantized_graph, when I quantized model the size reduced to 1/4 th of the original squeezenet model.(.pb). I want nearly same size reduction in .tflite.  My main aim behind quantization is to reduce size. ", "toco does not convert weights into quantized values for small layers, this size is currently set to 1024 at [quantized_weights.cc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/toco/graph_transformations/quantize_weights.cc). This should not impact results for squeezenet as most layers are above this limit.  Can you try doing this for mobilenet_v1_1_224 and see if you observe a 4x size reduction? Can you also share the file sizes that you see at the output of toco with and without quantize_weights flag?", "Hi @raghuraman-k. I can't switch to mobilenet because of my project requirements. The size of converted .tflite is below : \r\n```\r\noriginal .pb file- 6.1 MB (60,88,741 bytes)\r\nwith quantize_weights .tflite - 6.0 MB (60,35,552 bytes)\r\nwithout quantize_weights .tflite - 6.0 MB (60,35,552 bytes)\r\n\r\n```\r\nI did not see any size difference", "can I expect implementation of required ops ( RSQRT, Dequantize, ReorderAxes) in coming TFLite version ?", "We just launched a post-training quantization toolkit. May you try running the post-training quantization flag to see if it improves your inference? Please let us know if it does not make your model smaller and faster. If the flag has no effect, provide us with your model.\r\n\r\nhttps://www.tensorflow.org/performance/post_training_quantization", "Nagging Assignee @raghuraman-k: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 20690, "title": "Invalid syntax error while importing tensorflow in python3.7.0", "body": "### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nMacOS High Sierra 10.13.5\r\n\r\n- **TensorFlow installed from (source or binary)**:\r\npip3\r\n\r\n- **TensorFlow version (use command below)**:\r\n1.9.0\r\n\r\n- **Python version**: \r\n3.7.0\r\n\r\n- **Exact command to reproduce**:\r\nimport tensorflow as tf\r\n\r\n### Describe the problem\r\nwhen import tensorflow in python3 prompt, it says \"SyntaxError: invalid syntax\".\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/__init__.py\", line 22, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 114\r\n    def TFE_ContextOptionsSetAsync(arg1, async):_\r\n                                             ^\r\nSyntaxError: invalid syntax\r\n\r\n### Source code / logs\r\nline 114, 115, 150 of pywrap_tensorflow_internal.py has \"async\" as parameter which seems to be a keyword.\r\nAfter changed to \"async1\", importing tensorflow works.\r\n\r\ndef TFE_ContextOptionsSetAsync(arg1, async1):\r\n    return _pywrap_tensorflow_internal.TFE_ContextOptionsSetAsync(arg1, async1)\r\nTFE_ContextOptionsSetAsync = _pywrap_tensorflow_internal.TFE_ContextOptionsSetAsync\r\n\r\n", "comments": ["`async` and `await` are reserved keywords in python 3.7", "duplicate of [20517](https://github.com/tensorflow/tensorflow/issues/20517)", "Any update on this issue?", "This is really annoying and unacceptable! How can we resolve this issue?", "As explained above, you can edit the last file of the trace where the error occur :\r\n/usr/local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\r\nand find anywhere the variable async is used and replace it with async1 so its not a python 3.7 keyword anymore.  you will find those \"async\" variables on line 114, 115, 150\r\nSo this (for instance):\r\ndef TFE_ContextOptionsSetAsync(arg1, async):\r\nbecomes this:\r\ndef TFE_ContextOptionsSetAsync(arg1, async1):\r\nHope this helps !", "The error is indeed resolved after your proposed change. Thanks @blured", "All you need to do is change the argument \"async\" to something else in \"/usr/local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\" in the function definition and return..", "Nagging Assignee @bignamehyp: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "This is weird. Needs to be fixed.", "some here", "@yifeif can you please take a look? Thanks.", "hi guys i have the same problem, i just did install tensor to mac sierra 12.10.6 im using python3 and \r\n\r\nvoala !! \r\nSyntaxError: invalid syntax\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/Users/juaporra/Library/Python/3.7/lib/python/site-packages/tensorflow/__init__.py\", line 22, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"/Users/juaporra/Library/Python/3.7/lib/python/site-packages/tensorflow/python/__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/Users/juaporra/Library/Python/3.7/lib/python/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/Users/juaporra/Library/Python/3.7/lib/python/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 114\r\n    def TFE_ContextOptionsSetAsync(arg1, async):\r\n\r\nthank you @tiehexue  i did update right in pywrap_tensorflow_internal.py  async for async1 , and woks !! ... the lastone was on line 155 ,\r\n\r\nthank you so much ! ", "Actually, there are four lines with `async`: 114, 115, 154, and 155.", "This worked for me. YMMV (modify the path).\r\n`sudo sed -i 's/async/async_py3/g' /usr/local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py`", "This worked for me, but if you are changing the\r\n\r\n```\r\ndef TFE_ContextOptionsSetAsync(arg1, async):\r\nbecomes this:\r\ndef TFE_ContextOptionsSetAsync(arg1, async1):\r\n\r\n```\r\n\r\nthen also please change the arguments in the return type, as they are also mentioned with the 'asyc'.", "I believe this should be fixed by #21202 (thanks to @bstriner) if you build from source. But looks like there [won't be](https://github.com/tensorflow/tensorflow/issues/20517#issuecomment-418442189) a python 3.7 pypi package for 1.11, cc @gunan.", "I'm facing the same issue for Python 3.6.6. Is Python 3.6.6 not supported as well?", "per the instructions above, after changing the \"async\" argument and returned variable names to async1, python quits on importing tensorflow.  ", "per the instructions above, after changing the \"async\" argument and returned variable names to async1 as folowing:\r\ndef TFE_ContextOptionsSetasync(arg1, async1):\r\n    return _pywrap_tensorflow_internal.TFE_ContextOptionsSetasync(arg1, async1)\r\n\r\ndef TFE_ContextSetasyncForThread(arg1, async1):\r\n    return _pywrap_tensorflow_internal.TFE_ContextSetasyncForThread(arg1, async1)\r\n\r\n### **There is another problem for me:**\r\n__Traceback (most recent call last):\r\n  File \"/Users/apple/Documents/ST/python/test.py\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/__init__.py\", line 22, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"/usr/local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 116, in <module>\r\n    **TFE_ContextOptionsSetasync = _pywrap_tensorflow_internal.TFE_ContextOptionsSetasync**\r\nAttributeError: module '_pywrap_tensorflow_internal' has no attribute 'TFE_ContextOptionsSetasync'__", "> This worked for me. YMMV (modify the path).\r\n> `sudo sed -i 's/async/async_py3/g' /usr/local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py`\r\n\r\nwrong syntax\r\nshould be \r\n`sudo sed -i \"backupname\"  's/async/async_py3/g' /usr/local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\r\n`\r\nand work", "Hi everyone can you enlighten me I barely get Tensorflow running every time he returns these errors \r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\WD\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\WD\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\WD\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\WD\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\WD\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: Une routine d\u2019initialisation d\u2019une biblioth\u00e8que de liens dynamiques (DLL) a \u00e9chou\u00e9.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<pyshell#0>\", line 1, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\WD\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\WD\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\WD\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\WD\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\WD\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\WD\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\WD\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\WD\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: Une routine d\u2019initialisation d\u2019une biblioth\u00e8que de liens dynamiques (DLL) a \u00e9chou\u00e9.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n", "after changing async to async1 i got the next error \ud83d\udc4d Using TensorFlow backend.\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(__file__)])\r\n  File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\imp.py\", line 296, in find_module\r\n    raise ImportError(_ERR_MSG.format(name), name=name)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    import _pywrap_tensorflow_internal\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:/Users/Firas/Desktop/f8.py\", line 1, in <module>\r\n    from keras.datasets import mnist\r\n  File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\r\n    from . import utils\r\n  File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\r\n    from . import conv_utils\r\n  File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\r\n    from .. import backend as K\r\n  File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\r\n    from .load_backend import epsilon\r\n  File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(__file__)])\r\n  File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\imp.py\", line 296, in find_module\r\n    raise ImportError(_ERR_MSG.format(name), name=name)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n    import _pywrap_tensorflow_internal\r\nModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nany idea?", "> after changing async to async1 i got the next error \ud83d\udc4d Using TensorFlow backend.\r\n> Traceback (most recent call last):\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n> fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(**file**)])\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\imp.py\", line 296, in find_module\r\n> raise ImportError(_ERR_MSG.format(name), name=name)\r\n> ImportError: No module named '_pywrap_tensorflow_internal'\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in\r\n> from tensorflow.python.pywrap_tensorflow_internal import *\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in\r\n> _pywrap_tensorflow_internal = swig_import_helper()\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n> import _pywrap_tensorflow_internal\r\n> ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n> File \"C:/Users/Firas/Desktop/f8.py\", line 1, in\r\n> from keras.datasets import mnist\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\keras__init__.py\", line 3, in\r\n> from . import utils\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\keras\\utils__init__.py\", line 6, in\r\n> from . import conv_utils\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in\r\n> from .. import backend as K\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\keras\\backend__init__.py\", line 1, in\r\n> from .load_backend import epsilon\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in\r\n> from .tensorflow_backend import *\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in\r\n> import tensorflow as tf\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow__init__.py\", line 24, in\r\n> from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\python__init__.py\", line 49, in\r\n> from tensorflow.python import pywrap_tensorflow\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in\r\n> raise ImportError(msg)\r\n> ImportError: Traceback (most recent call last):\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n> fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(**file**)])\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\imp.py\", line 296, in find_module\r\n> raise ImportError(_ERR_MSG.format(name), name=name)\r\n> ImportError: No module named '_pywrap_tensorflow_internal'\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in\r\n> from tensorflow.python.pywrap_tensorflow_internal import *\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in\r\n> _pywrap_tensorflow_internal = swig_import_helper()\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n> import _pywrap_tensorflow_internal\r\n> ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n> \r\n> Failed to load the native TensorFlow runtime.\r\n> \r\n> See https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n> \r\n> for some common reasons and solutions. Include the entire stack trace\r\n> above this error message when asking for help.\r\n> \r\n> any idea?\r\n\r\nI too have the same problem. Can anyone solve this issue?", "I've installed tensorflow using pip and encountered with module not found error. Based on some of the previous conversations I've uninstalled it and re-installed tensorflow via conda. The installation was successfull but it produces Syntax Error which have been attached below.\r\n\r\nTraceback (most recent call last):\r\n\r\nFile \"c:\\users\\elcot\\anaconda3\\envs'virtual_env'\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\r\nexec(code_obj, self.user_global_ns, self.user_ns)\r\n\r\nFile \"\", line 1, in\r\nimport tensorflow as tf\r\n\r\nFile \"c:\\users\\elcot\\anaconda3\\envs'virtual_env'\\lib\\site-packages\\tensorflow_init_.py\", line 101, in\r\nfrom tensorflow_core import *\r\n\r\nFile \"c:\\users\\elcot\\anaconda3\\envs'virtual_env'\\lib\\site-packages\\tensorflow_core_init_.py\", line 46, in\r\nfrom . _api.v2 import compat\r\n\r\nFile \"c:\\users\\elcot\\anaconda3\\envs'virtual_env'\\lib\\site-packages\\tensorflow_core_api\\v2\\compat_init_.py\", line 39, in\r\nfrom . import v1\r\n\r\nFile \"c:\\users\\elcot\\anaconda3\\envs'virtual_env'\\lib\\site-packages\\tensorflow_core_api\\v2\\compat\\v1_init_.py\", line 32, in\r\nfrom . import compat\r\n\r\nFile \"c:\\users\\elcot\\anaconda3\\envs'virtual_env'\\lib\\site-packages\\tensorflow_core_api\\v2\\compat\\v1\\compat_init_.py\", line 39, in\r\nfrom . import v1\r\n\r\nFile \"c:\\users\\elcot\\anaconda3\\envs'virtual_env'\\lib\\site-packages\\tensorflow_core_api\\v2\\compat\\v1\\compat\\v1_init_.py\", line 29, in\r\nfrom tensorflow._api.v2.compat.v1 import app\r\n\r\nFile \"c:\\users\\elcot\\anaconda3\\envs'virtual_env'\\lib\\site-packages\\tensorflow_core_api\\v2\\compat_init_.py\", line 39, in\r\nfrom . import v1\r\n\r\nFile \"c:\\users\\elcot\\anaconda3\\envs'virtual_env'\\lib\\site-packages\\tensorflow_core_api\\v2\\compat\\v1_init_.py\", line 32, in\r\nfrom . import compat\r\n\r\nFile \"c:\\users\\elcot\\anaconda3\\envs'virtual_env'\\lib\\site-packages\\tensorflow_core_api\\v2\\compat\\v1\\compat_init_.py\", line 39, in\r\nfrom . import v1\r\n\r\nFile \"c:\\users\\elcot\\anaconda3\\envs'virtual_env'\\lib\\site-packages\\tensorflow_core_api\\v2\\compat\\v1\\compat\\v1_init_.py\", line 35, in\r\nfrom tensorflow._api.v2.compat.v1 import debugging\r\n\r\nFile \"c:\\users\\elcot\\anaconda3\\envs'virtual_env'\\lib\\site-packages\\tensorflow_core_api\\v2\\compat\\v1\\debugging_init_.py\", line 10, in\r\nfrom . import experimental\r\n\r\nFile \"c:\\users\\elcot\\anaconda3\\envs'virtual_env'\\lib\\site-packages\\tensorflow_core_api\\v2\\compat\\v1\\debugging\\experimental_init_.py\", line 10, in\r\nfrom tensorflow.python.debug.lib.dumping_callback import disable_dump_debug_info\r\n\r\nFile \"c:\\users\\elcot\\anaconda3\\envs'virtual_env'\\lib\\site-packages\\tensorflow_core\\python\\debug\\lib\\dumping_callback.py\", line 29, in\r\nfrom tensorflow.python.debug.lib import debug_events_writer\r\n\r\nFile \"c:\\users\\elcot\\anaconda3\\envs'virtual_env'\\lib\\site-packages\\tensorflow_core\\python\\debug\\lib\\debug_events_writer.py\", line 24, in\r\nfrom tensorflow.python import _pywrap_debug_events_writer\r\n\r\nFile \"\", line 1020, in _handle_fromlist\r\n\r\nFile \"c:\\users\\elcot\\anaconda3\\envs'virtual_env'\\lib\\site-packages\\tensorflow_init_.py\", line 50, in getattr\r\nmodule = self._load()\r\n\r\nFile \"c:\\users\\elcot\\anaconda3\\envs'virtual_env'\\lib\\site-packages\\tensorflow_init_.py\", line 44, in _load\r\nmodule = _importlib.import_module(self.name)\r\n\r\nFile \"c:\\users\\elcot\\anaconda3\\envs'virtual_env'\\lib\\importlib_init_.py\", line 126, in import_module\r\nreturn _bootstrap._gcd_import(name[level:], package, level)\r\n\r\nFile \"c:\\users\\elcot\\anaconda3\\envs'virtual_env'\\lib\\site-packages\\tensorflow_core\\python_init_.py\", line 95, in\r\nfrom tensorflow.python import keras\r\n\r\nFile \"c:\\users\\elcot\\anaconda3\\envs'virtual_env'\\lib\\site-packages\\tensorflow_core\\python\\keras_init_.py\", line 27, in\r\nfrom tensorflow.python.keras import models\r\n\r\nFile \"c:\\users\\elcot\\anaconda3\\envs'virtual_env'\\lib\\site-packages\\tensorflow_core\\python\\keras_init_.py\", line 27, in\r\nfrom tensorflow.python.keras import models\r\n\r\nFile \"c:\\users\\elcot\\anaconda3\\envs'virtual_env'\\lib\\site-packages\\tensorflow_core\\python\\keras\\models.py\", line 26, in\r\nfrom tensorflow.python.keras.engine import sequential\r\n\r\nFile \"c:\\users\\elcot\\anaconda3\\envs'virtual_env'\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\", line 28, in\r\nfrom tensorflow.python.keras.engine import training\r\n\r\nFile \"c:\\users\\elcot\\anaconda3\\envs'virtual_env'\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 46, in\r\nfrom tensorflow.python.keras.engine import training_arrays\r\n\r\nFile \"c:\\users\\elcot\\anaconda3\\envs'virtual_env'\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_arrays.py\", line 41, in\r\nfrom scipy.sparse import issparse # pylint: disable=g-import-not-at-top\r\n\r\nFile \"c:\\users\\elcot\\anaconda3\\envs'virtual_env'\\lib\\site-packages\\scipy_init_.py\", line 131, in\r\nfrom scipy.config import show as show_config\r\n\r\nFile \"c:\\users\\elcot\\anaconda3\\envs'virtual_env'\\lib\\site-packages\\scipy_config_.py\", line 13\r\nlapack_mkl_info={'libraries': ['mkl_rt'], 'library_dirs': ['C:/Users/elcot/Anaconda3/envs/'virtual_env'\\Library\\lib'], 'define_macros': [('SCIPY_MKL_H', None), ('HAVE_CBLAS', None)], 'include_dirs': ['C:\\Program Files (x86)\\IntelSWTools\\compilers_and_libraries_2019.0.117\\windows\\mkl', 'C:\\Program Files (x86)\\IntelSWTools\\compilers_and_libraries_2019.0.117\\windows\\mkl\\include', 'C:\\Program Files (x86)\\IntelSWTools\\compilers_and_libraries_2019.0.117\\windows\\mkl\\lib', 'C:/Users/elcot/Anaconda3/envs/'virtual_env'\\Library\\include']}\r\n^\r\nSyntaxError: invalid syntax\r\n\r\nCan anyone help me out with this issue?", "> after changing async to async1 i got the next error \ud83d\udc4d Using TensorFlow backend.\r\n> Traceback (most recent call last):\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n> fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(**file**)])\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\imp.py\", line 296, in find_module\r\n> raise ImportError(_ERR_MSG.format(name), name=name)\r\n> ImportError: No module named '_pywrap_tensorflow_internal'\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in\r\n> from tensorflow.python.pywrap_tensorflow_internal import *\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in\r\n> _pywrap_tensorflow_internal = swig_import_helper()\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n> import _pywrap_tensorflow_internal\r\n> ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n> File \"C:/Users/Firas/Desktop/f8.py\", line 1, in\r\n> from keras.datasets import mnist\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\keras__init__.py\", line 3, in\r\n> from . import utils\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\keras\\utils__init__.py\", line 6, in\r\n> from . import conv_utils\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in\r\n> from .. import backend as K\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\keras\\backend__init__.py\", line 1, in\r\n> from .load_backend import epsilon\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in\r\n> from .tensorflow_backend import *\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in\r\n> import tensorflow as tf\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow__init__.py\", line 24, in\r\n> from tensorflow.python import pywrap_tensorflow # pylint: disable=unused-import\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\python__init__.py\", line 49, in\r\n> from tensorflow.python import pywrap_tensorflow\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in\r\n> raise ImportError(msg)\r\n> ImportError: Traceback (most recent call last):\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 18, in swig_import_helper\r\n> fp, pathname, description = imp.find_module('_pywrap_tensorflow_internal', [dirname(**file**)])\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\imp.py\", line 296, in find_module\r\n> raise ImportError(_ERR_MSG.format(name), name=name)\r\n> ImportError: No module named '_pywrap_tensorflow_internal'\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in\r\n> from tensorflow.python.pywrap_tensorflow_internal import *\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in\r\n> _pywrap_tensorflow_internal = swig_import_helper()\r\n> File \"C:\\Users\\Firas\\AppData\\Local\\Programs\\Python\\Python38-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 20, in swig_import_helper\r\n> import _pywrap_tensorflow_internal\r\n> ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n> \r\n> Failed to load the native TensorFlow runtime.\r\n> \r\n> See https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n> \r\n> for some common reasons and solutions. Include the entire stack trace\r\n> above this error message when asking for help.\r\n> \r\n> any idea?\r\n\r\nSo after changing async to async1 , I am also facing the same problem\r\n\"ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\"\r\n\r\nAny solution?\r\n\r\nPython 3.9.2", "Locate the pywrap_tensorflow_internal.py. It's generally in\npython3.7/site-packages/tensorflow/python/\nOpen any text editor (I prefer atom).\nFind async on the mentioned lines and replace it with async1.\nDont forget to take a backup of pywrap_tensorflow_internal.py in case\nsomething goes wrong.\n\nOn Wed, Apr 21, 2021 at 12:08 AM LesLuger ***@***.***> wrote:\n\n> As explained above, you can edit the last file of the trace where the\n> error occur :\n>\n> /usr/local/lib/python3.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\n> and find anywhere the variable async is used and replace it with async1 so\n> its not a python 3.7 keyword anymore. you will find those \"async\" variables\n> on line 114, 115, 150\n> So this (for instance):\n> def TFE_ContextOptionsSetAsync(arg1, async):\n> becomes this:\n> def TFE_ContextOptionsSetAsync(arg1, async1):\n> Hope this helps !\n>\n> how do you open the file to edit?\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/20690#issuecomment-823512283>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AL3UPJ2J5KLRGMAGJOMGJHTTJXC2XANCNFSM4FJLNJKA>\n> .\n>\n"]}, {"number": 20689, "title": "Trying to open a non-existing file in tf.data.Dataset on Windows crashes Python instance", "body": "## System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 7 Enterprise\r\n- **TensorFlow installed from (source or binary)**: binary (compiled by conda-forge)\r\n- **TensorFlow version (use command below)**: v1.8.0-0-g93bc2e2072, 1.8.0\r\n- **Python version**: Python 3.6.5\r\n- **Bazel version (if compiling from source)**: n/a\r\n- **GCC/Compiler version (if compiling from source)**: n/a\r\n- **CUDA/cuDNN version**: none (CPU only)\r\n- **GPU model and memory**: none (CPU only)\r\n- **Exact command to reproduce**:\r\n```python\r\nimport tensorflow as tf\r\n\r\nsess = tf.Session()\r\n\r\nfilenames = [r'C:\\nonexistent.tfrecords']\r\ndataset = tf.data.TFRecordDataset(filenames)\r\niterator = dataset.make_one_shot_iterator()\r\nnext_element = iterator.get_next()\r\n\r\nprint(sess.run(next_element))\r\n```\r\n\r\n### Describe the problem\r\nTrying to open a non-existing tfrecords dataset using `tf.data.Dataset` on Windows crashes Python instance. On Linux the same code properly raises a `NotFoundError`.\r\n\r\n### Source code / logs\r\nError on Windows:\r\n![image](https://user-images.githubusercontent.com/9080823/42564829-1d66b532-8502-11e8-9fd9-a9a235ad6523.png)\r\nError details (in Polish):\r\n```\r\nPodpis problemu:\r\n  Nazwa zdarzenia problemu:\tAPPCRASH\r\n  Nazwa aplikacji:\tpython.exe\r\n  Wersja aplikacji:\t3.6.5150.1013\r\n  Sygnatura czasowa aplikacji:\t5ac79d8c\r\n  Nazwa modu\u0142u z b\u0142\u0119dem:\t_pywrap_tensorflow_internal.pyd\r\n  Wersja modu\u0142u z b\u0142\u0119dem:\t0.0.0.0\r\n  Sygnatura czasowa modu\u0142u z b\u0142\u0119dem:\t5ae380ee\r\n  Kod wyj\u0105tku:\tc0000005\r\n  Przesuni\u0119cie wyj\u0105tku:\t0000000000236acf\r\n  Wersja systemu operacyjnego:\t6.1.7601.2.1.0.256.4\r\n  Identyfikator ustawie\u0144 regionalnych:\t1045\r\n  Dodatkowe informacje 1:\t2583\r\n  Dodatkowe informacje 2:\t258324ee3ae15385fdd62136546133f9\r\n  Dodatkowe informacje 3:\t1bc4\r\n  Dodatkowe informacje 4:\t1bc4034f8418cb6d1dc9351873ca4aa5\r\n```\r\nResult:\r\n```\r\nProcess finished with exit code -1073741819 (0xC0000005)\r\n```\r\n\r\nProper error on Linux (part of, full stacktrace removed):\r\n```\r\nNotFoundError (see above for traceback): C:\\nonexistent.tfrecords; No such file or directory\r\n         [[Node: IteratorGetNext = IteratorGetNext[output_shapes=[[]], output_types=[DT_STRING], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator)]]\r\n```\r\n\r\n", "comments": ["@PiotrDabrowskey I ran your code on Windows with `TF1.15.5`. Code is throwing the following `NotFoundError` error trace as expected. It is not crashing with `TF1.15.5`. \r\n\r\nPlease verify once and close the issue if this was resolved for you. Thanks!\r\n\r\n\r\n```\r\n1.15.5\r\nWARNING:tensorflow:From C:\\Users\\Vishnu\\Desktop\\Testing_TF\\GH20689.py:5: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\r\n\r\nWARNING:tensorflow:From C:\\Users\\Vishnu\\Desktop\\Testing_TF\\GH20689.py:9: DatasetV1.make_one_shot_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_one_shot_iterator(dataset)`.\r\nTraceback (most recent call last):\r\n\u00a0 File \"C:\\Users\\Vishnu\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1365, in _do_call\r\n\u00a0 \u00a0 return fn(*args)\r\n\u00a0 File \"C:\\Users\\Vishnu\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1350, in _run_fn\r\n\u00a0 \u00a0 target_list, run_metadata)\r\n\u00a0 File \"C:\\Users\\Vishnu\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1443, in _call_tf_sessionrun\r\n\u00a0 \u00a0 run_metadata)\r\ntensorflow.python.framework.errors_impl.NotFoundError: NewRandomAccessFile failed to Create/Open: C:\\nonexistent.tfrecords : The system cannot find the file specified.\r\n\r\n; No such file or directory\r\n\t [[{{node IteratorGetNext}}]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n\u00a0 File \"C:\\Users\\Vishnu\\Desktop\\Testing_TF\\GH20689.py\", line 12, in <module>\r\n\u00a0 \u00a0 print(sess.run(next_element))\r\n\u00a0 File \"C:\\Users\\Vishnu\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 956, in run\r\n\u00a0 \u00a0 run_metadata_ptr)\r\n\u00a0 File \"C:\\Users\\Vishnu\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1180, in _run\r\n\u00a0 \u00a0 feed_dict_tensor, options, run_metadata)\r\n\u00a0 File \"C:\\Users\\Vishnu\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1359, in _do_run\r\n\u00a0 \u00a0 run_metadata)\r\n\u00a0 File \"C:\\Users\\Vishnu\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1384, in _do_call\r\n\u00a0 \u00a0 raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.NotFoundError: NewRandomAccessFile failed to Create/Open: C:\\nonexistent.tfrecords : The system cannot find the file specified.\r\n\r\n; No such file or directory\r\n\t [[node IteratorGetNext (defined at C:\\Users\\Vishnu\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1748) ]]\r\n\r\nOriginal stack trace for 'IteratorGetNext':\r\n\u00a0 File \"<string>\", line 1, in <module>\r\n\u00a0 File \"C:\\Users\\Vishnu\\AppData\\Local\\Programs\\Python\\Python37\\Lib\\idlelib\\run.py\", line 155, in main\r\n\u00a0 \u00a0 ret = method(*args, **kwargs)\r\n\u00a0 File \"C:\\Users\\Vishnu\\AppData\\Local\\Programs\\Python\\Python37\\Lib\\idlelib\\run.py\", line 548, in runcode\r\n\u00a0 \u00a0 exec(code, self.locals)\r\n\u00a0 File \"C:\\Users\\Vishnu\\Desktop\\Testing_TF\\GH20689.py\", line 10, in <module>\r\n\u00a0 \u00a0 next_element = iterator.get_next()\r\n\u00a0 File \"C:\\Users\\Vishnu\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\data\\ops\\iterator_ops.py\", line 426, in get_next\r\n\u00a0 \u00a0 name=name)\r\n\u00a0 File \"C:\\Users\\Vishnu\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_dataset_ops.py\", line 2517, in iterator_get_next\r\n\u00a0 \u00a0 output_shapes=output_shapes, name=name)\r\n\u00a0 File \"C:\\Users\\Vishnu\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\framework\\op_def_library.py\", line 794, in _apply_op_helper\r\n\u00a0 \u00a0 op_def=op_def)\r\n\u00a0 File \"C:\\Users\\Vishnu\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\util\\deprecation.py\", line 507, in new_func\r\n\u00a0 \u00a0 return func(*args, **kwargs)\r\n\u00a0 File \"C:\\Users\\Vishnu\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3357, in create_op\r\n\u00a0 \u00a0 attrs, op_def, compute_device)\r\n\u00a0 File \"C:\\Users\\Vishnu\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 3426, in _create_op_internal\r\n\u00a0 \u00a0 op_def=op_def)\r\n\u00a0 File \"C:\\Users\\Vishnu\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 1748, in __init__\r\n\u00a0 \u00a0 self._traceback = tf_stack.extract_stack()\r\n```", "Hi! I haven't been using TensorFlow for 2 years now and was using it on Windows only for a limited time due to project specifics. I had a problem in 1.8.0 (vs yours 1.15.1). Maybe it got fixed in the meantime. I am not even able to check whether this issue is solved, as it'd require me to use a paid platform (Windows OS) to do so, but I guess if it works properly for you, it's solved. Thank you!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/20689\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/20689\">No</a>\n"]}, {"number": 20688, "title": "[Bazel] Error while build the grpc_tensorflow_server in windows 7.", "body": "### Describe the problem\r\n\r\nI wont to build the grpc_tensorflow_server in windows 7 64-bit, then an error occurs.\r\n\r\nThen I installed Bazel, MSYS2 shell, Visual Studio 2015 and JAVA 8 Update 171,\r\nand I have setup to BAZEL_VS, BAZEL_VC, BAZEL_SH and JAVA_HOME following site.\r\nhttps://docs.bazel.build/versions/master/install-windows.html\r\n\r\n\r\n### System information\r\n- **Have I written custom code** : None\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)** : Windows 7 64-bit\r\n- **TensorFlow installed from (source or binary)** : pip install --upgrade tensorflow==1.8.0\r\n- **TensorFlow version (use command below)** : b'v1.8.0-0-g93bc2e2072' 1.8.0\r\n- **Python version** : Python 3.5.5 :: Anaconda, Inc.\r\n- **Bazel version (if compiling from source)** : bazel-0.15.0-windows-x86_64.exe\r\n- **GCC/Compiler version (if compiling from source)** : None\r\n- **CUDA/cuDNN version** : None\r\n- **GPU model and memory** : None\r\n- **Exact command to reproduce**:bazel-0.15.0-windows-x86_64.exe build -c opt //tensorflow/core/distributed_runtime/rpc:grpc_tensorflow_server --verbose_failures\r\n\r\n### Source code\r\n\r\ngit clone -b v1.8.0 --recurse-submodules https://github.com/tensorflow/tensorflow.git\r\ncd tensorflow\r\nset BAZEL_VS=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\r\nset BAZEL_VC=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\r\nset BAZEL_SH=C:\\msys64\\usr\\bin\\bash.exe\r\nset JAVA_HOME=C:\\Program Files\\Java\\jre1.8.0_171\r\nset PATH=C:\\msys64\\usr\\bin;%PATH%\r\nbash.exe\r\nbazel-0.15.0-windows-x86_64.exe build -c opt //tensorflow/core/distributed_runtime/rpc:grpc_tensorflow_server --verbose_failures\r\n\r\n### Logs\r\n\r\nERROR: ./tensorflow/tensorflow/core/distributed_runtime/rpc/BUILD:311:1: Linking of rule '//tensorflow/core/distributed_runtime/rpc:grpc_tensorflow_server' failed (Exit 1181): link.exe failed: error executing command\r\n  cd %USERPROFILE%/_bazel_%USERNAME%/do34jop7/execroot/org_tensorflow\r\n  SET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\INCLUDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\INCLUDE;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.10240.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\include\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.10240.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.10240.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.10240.0\\winrt;\r\n    SET LIB=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\LIB\\amd64;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\ATLMFC\\LIB\\amd64;C:\\ProgramFiles (x86)\\Windows Kits\\10\\lib\\10.0.10240.0\\ucrt\\x64;C:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.6.1\\lib\\um\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\lib\\10.0.10240.0\\um\\x64;\r\n    SET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\BIN\\amd64;C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\VCPackages;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\IDE;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Common7\\Tools;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Team Tools\\Performance Tools\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\Team Tools\\Performance Tools;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x86;C:\\Program Files (x86)\\Microsoft SDKs\\Windows\\v10.0A\\bin\\NETFX 4.6.1 Tools\\x64\\;;C:\\Windows\\system32\r\n    SET PWD=/proc/self/cwd\r\n    SET TEMP=%USERPROFILE%\\AppData\\Local\\Temp\r\n    SET TMP=%USERPROFILE%\\AppData\\Local\\Temp\r\n    SET USE_LINKER=1\r\n  C:/Program Files (x86)/Microsoft Visual Studio 14.0/VC/bin/amd64/link.exe /nologo /OUT:bazel-out/x64_windows-opt/bin/tensorflow/core/distributed_runtime/rpc/grpc_tensorflow_server.exe tensorflow_framework /SUBSYSTEM:CONSOLE -DEFAULTLIB:advapi32.lib -pthread /MACHINE:X64 @bazel-out/x64_windows-opt/bin/tensorflow/core/distributed_runtime/rpc/grpc_tensorflow_server.exe-2.params\r\nLINK : warning LNK4044: unrecognized option '/pthread' ignored\r\nLINK : warning LNK4044: unrecognized option '/ldl' ignored\r\nLINK : warning LNK4044: unrecognized option  '/lpthread' ignored\r\nLINK : warning LNK4044: unrecognized option '/lm' ignored\r\nLINK : warning LNK4044: unrecognized option '/lm' ignored\r\nLINK : fatal error LNK1181: cannot open input file 'tensorflow_framework.obj'\r\nTarget //tensorflow/core/distributed_runtime/rpc:grpc_tensorflow_server failed to build\r\nINFO: Elapsed time: 3507.723s, Critical Path: 1648.75s\r\nINFO: 2235 processes: 2235 local.\r\nFAILED: Build did NOT complete successfully\r\nFAILED: Build did NOT complete successfully", "comments": ["`//tensorflow/core/distributed_runtime` and anything else that depends on `tensorflow_framework` shared library does not work on Windows for now.", "Reassigning this to @meteorcloudy, who knows what's going on in the Windows Bazel build.", "@kurita236 Looks like you didn't run `./configure`? Can you run `./configure` and retry the build?", "Nagging Assignee @meteorcloudy: It has been 45 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @meteorcloudy: It has been 61 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I believe `//tensorflow/core/distributed_runtime/rpc:grpc_tensorflow_server` is buildable after running `./configure`, so closing this issue now."]}, {"number": 20687, "title": "Speeding up TF custom ops on GPU", "body": "I have created some TF custom Ops [which you can think of as matmul or conv operations], as per TF's [tutorial](https://www.tensorflow.org/extend/adding_an_op), and would like to speed them up. I have used AWS' P3 instances (NVIDIA V100 GPU) to run my Ops. Depending on the size of the model, my GPU ops are between 1.5x and 5x slower than TF functions.\r\n\r\nI have seen that TF's implementation of various operations (such as Con2D, MatMul, Pooling etc) use DeviceMemory objects to encapsulate tensor data to be passed to the target device (GPU), then call different wrappers that end up launching Kernels using \"[Stream::ThenLaunch](https://github.com/petewarden/tensorflow_makefile/blob/master/tensorflow/stream_executor/stream_executor_pimpl.h#L729)\".\r\n\r\nA different type of implementation [(OpenAI's block sparse conv2d)](https://github.com/openai/blocksparse), choses to launch the Kernel using cuLaunchKernel after they allocate CUdeviceptr to the different Kernel arguments.\r\n\r\nIn my implementation, when I register my TF Ops, the Input/Output tensors are presumably on the device, as I do not set them to be located on the Host(is this correct?). Is TF copying tensors back and forth, between host and GPU after each OP?\r\n\r\nWould it make any difference, in terms of speed, if the Input/Output tensors are set on the Host then copied to the device (cudaMalloc/cudaMemCpy) used by GPU Kernels then copy the results to the Host?\r\n\r\nWould my Kernels run any faster if I were to use TF's approach, to use the DeviceMemory class for my arguments and the Stream::ThenLaunch method to launch the Kernel, or OpenAI's CUdeviceptr and cuLaunchKernel approach?\r\n\r\nThanks", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Thank you for your reply. I was using AWS's P3 instances with NVIDIA docker version 17.12. According to NVIDIA's [Release Notes](https://docs.nvidia.com/deeplearning/dgx/pdf/TensorFlow-Release-Notes.pdf)\r\nHave I written custom code: Yes\r\nOS Platform and Distribution: Ubuntu 16.04 \r\nTensorFlow installed from\r\nTensorFlow version:1.4.0\r\nBazel version:-\r\nCUDA/cuDNN version: 9.0/7.0.5\r\nGPU model and memory: V100\r\nExact command to reproduce: N/A", "In TensorFlow's abstraction, when the input tensor is not in the operator's device, there will be a data transfer operation between two devices. These data transfer operations are automatically added when the TensorFlow generates the dataflow graph from your source code. The data transfer operations are executed in another stream to overlap computation and I/O for GPUs.\r\n\r\nThe Stream::ThenLaunch function is a high level abstraction of CUDA launch APIs. There is no difference between these two approaches.\r\n\r\nI think the way to speedup your custom operator is to optimize your GPU kernels. You can use nvprof to profile your implementation to find the bottleneck.\r\n\r\nThe GEMM and CONV kernels in TensorFlow are from cuBLAS and cuDNN. You can also compare them with your kernels.", "@xysmlx How to use nvprof in tensorflow framework ? I mean that how to setting the tensorflow API to use/call nvprof or GPU-profile tools?", "@linrio Sorry, I have only used commands like \"nvprof python xxx.py\" to profile tensorflow applications. I think nvprof can provide enough information about the application and operators in this case. I do not know how to let TF call nvprof.", "@xysmlx yet using command like \"nvprof python xxx.py\" can profile program, But it's too slow to profile especially when I want to output profile data like \"nvprof --log-file out.csv --csv ......\" or \"nvprof --export-profile out.prof ......\". Have you ever had such a problem?", "@linrio If you do not profile metrics, the nvprof's speed will be the same as that of the native program. The extra cost of \"export-profile\" is little.", "@badreddinen,\r\nSorry for the delayed response. You can think of using [Profiler Tool of Tensorboard](https://www.tensorflow.org/tensorboard/tensorboard_profiling_keras), which highlights the **`Bottlenecks`** in the performance. Please refer to the [Guide](https://www.tensorflow.org/guide/profiler) and the [Performance profiling in TF 2 talk](https://www.youtube.com/watch?v=pXHAQIhhMhI) from the **TensorFlow Dev Summit 2020** to learn more about the **`TensorFlow Profiler`**. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/20687\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/20687\">No</a>\n"]}, {"number": 20686, "title": "Implement GetCurrentClockCycle and GetCycleCounterFrequencyImpl for Windows", "body": "", "comments": ["@satok16, can u take a look for this change? Thanks.", "Nagging Reviewer : You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 14 days with no activity and the `awaiting review` label has been applied."]}, {"number": 20685, "title": "Use FastBoundsCheck in roll_op.cc", "body": "This fix is a small enhancement of using `FastBoundsCheck` in roll_op.cc. The usage of `FastBoundsCheck` is fairly commonly used in other kernel implementations.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 20684, "title": "[tflite][quantization][deeplabv3] Constant array MobilenetV2/expanded_conv_7/depthwise/depthwise_weights lacks MinMax information", "body": "**System information**\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:no\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:Source\r\n- **TensorFlow version (use command below)**:1.9.0\r\n- **Python version**:2.7.12\r\n- **Bazel version (if compiling from source)**:0.12.0\r\n- **GCC/Compiler version (if compiling from source)**:5.4.0\r\n- **CUDA/cuDNN version**:cuda-9.0/7.0\r\n- **GPU model and memory**:GeForce GTX 1080/8105MiB\r\n- **Phone**:xiaomi5 (Snapdragon 820)\r\n- **Exact command to reproduce**:\r\nbazel run --config=opt //tensorflow/contrib/lite/toco:toco --\r\n--input_file=/external_home/data/model/deeplabv3_mnv2_pascal_train_aug/frozen_inference_graph.pb\r\n--output_file=/external_home/data/model/deeplabv3_mnv2_pascal_train_aug/kanul.tflite\r\n--inference_type=QUANTIZED_UINT8\r\n--input_shape=1,513,513,3\r\n--input_array=sub_7\r\n--output_array=ResizeBilinear_3\r\n\r\n**Describe the problem**\r\nI have tried to quantize MobileNetV2 for deeplabV3+ with TFlite. But I fail to convert the model.\r\nFrom the following issue, I saw that the operations were not supported for the option of quantization.\r\n\r\nhttps://github.com/tensorflow/models/blob/master/research/deeplab/g3doc/model_zoo.md\r\nCheckpoint name: mobilenetv2_coco_voc_trainaug\r\n\r\nAs we can see graphs from the tensorboard, there is one big problem.\r\n\r\nIn \"import/MobilenetV2/expanded_conv_7/depthwise/depthwise\",\r\n\r\nthe operation of depthwise consists of the subgraph with 3 nodes: (depthwise) and BatchToSpaceND, SpaceToBatchND.\r\n\r\nBut, in \"import/MobilenetV2/expanded_conv_6/depthwise/depthwise\",\r\n\r\nthe operation of depthwise is DepthwiseConv2dNative itself.\r\n\r\nFrom the difference, we can not quantize deeplabv3 based on mobilenetv2.\r\n\r\nThe one thing is that MobilenetV2/expanded_conv_7~16 does not have min/max value to be needed for quantization with tflite.\r\n\r\nAlthough I implement the needed min/max value in hardcode_min_max.cc,\r\n\r\nThis model does not run well in mobile environments.\r\n\r\nThe ultimate problem is caused by the fact that depthwise_conv_7~16 consist of 3 nodes with BatchToSpaceND and SpaceToBatchND.\r\n\r\nI request you to notify the method to resolve above issues.\r\n\r\n**Source code / logs**\r\n\r\nbazel run --config=opt //tensorflow/contrib/lite/toco:toco --\r\n--input_file=/external_home/data/model/deeplabv3_mnv2_pascal_train_aug/frozen_inference_graph.pb\r\n--output_file=/external_home/data/model/deeplabv3_mnv2_pascal_train_aug/kanul.tflite\r\n--inference_type=QUANTIZED_UINT8\r\n--input_shape=1,513,513,3\r\n--input_array=sub_7\r\n--output_array=ResizeBilinear_3\r\n\r\n2018-07-11 04:40:01.330069: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 166 operators, 340 arrays (1 quantized)\r\n2018-07-11 04:40:01.330711: W tensorflow/contrib/lite/toco/graph_transformations/hardcode_min_max.cc:339] Tweaking the MinMax of array ResizeBilinear_1, which is an input to {Concatenation operator with output concat}, because we want all inputs and outputs of a Concatenation operator to have the same MinMax so that it can be implemented as a pure byte-copy, no arithmetic.\r\n2018-07-11 04:40:01.332983: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After pre-quantization graph transformations pass 1: 111 operators, 285 arrays (1 quantized)\r\n2018-07-11 04:40:01.335731: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before quantization graph transformations: 111 operators, 285 arrays (1 quantized)\r\n2018-07-11 04:40:01.337575: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:92] Constant array MobilenetV2/expanded_conv_7/depthwise/depthwise_weights lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-07-11 04:40:01.337670: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:92] Constant array MobilenetV2/expanded_conv_7/depthwise/BatchNorm/FusedBatchNorm_mul_0_param lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-07-11 04:40:01.337695: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:92] Constant array MobilenetV2/expanded_conv_7/depthwise/BatchNorm/FusedBatchNorm_add_param lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-07-11 04:40:01.338553: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:92] Constant array MobilenetV2/expanded_conv_8/depthwise/depthwise_weights lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-07-11 04:40:01.338711: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:92] Constant array MobilenetV2/expanded_conv_8/depthwise/BatchNorm/FusedBatchNorm_mul_0_param lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-07-11 04:40:01.338786: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:92] Constant array MobilenetV2/expanded_conv_8/depthwise/BatchNorm/FusedBatchNorm_add_param lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-07-11 04:40:01.339777: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:92] Constant array MobilenetV2/expanded_conv_9/depthwise/depthwise_weights lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-07-11 04:40:01.339918: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:92] Constant array MobilenetV2/expanded_conv_9/depthwise/BatchNorm/FusedBatchNorm_mul_0_param lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-07-11 04:40:01.339985: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:92] Constant array MobilenetV2/expanded_conv_9/depthwise/BatchNorm/FusedBatchNorm_add_param lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-07-11 04:40:01.340933: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:92] Constant array MobilenetV2/expanded_conv_10/depthwise/depthwise_weights lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-07-11 04:40:01.341034: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:92] Constant array MobilenetV2/expanded_conv_10/depthwise/BatchNorm/FusedBatchNorm_mul_0_param lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-07-11 04:40:01.341059: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:92] Constant array MobilenetV2/expanded_conv_10/depthwise/BatchNorm/FusedBatchNorm_add_param lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-07-11 04:40:01.342497: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:92] Constant array MobilenetV2/expanded_conv_11/depthwise/depthwise_weights lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-07-11 04:40:01.342593: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:92] Constant array MobilenetV2/expanded_conv_11/depthwise/BatchNorm/FusedBatchNorm_mul_0_param lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-07-11 04:40:01.342620: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:92] Constant array MobilenetV2/expanded_conv_11/depthwise/BatchNorm/FusedBatchNorm_add_param lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-07-11 04:40:01.344311: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:92] Constant array MobilenetV2/expanded_conv_12/depthwise/depthwise_weights lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-07-11 04:40:01.344422: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:92] Constant array MobilenetV2/expanded_conv_12/depthwise/BatchNorm/FusedBatchNorm_mul_0_param lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-07-11 04:40:01.344452: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:92] Constant array MobilenetV2/expanded_conv_12/depthwise/BatchNorm/FusedBatchNorm_add_param lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-07-11 04:40:01.345978: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:92] Constant array MobilenetV2/expanded_conv_13/depthwise/depthwise_weights lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-07-11 04:40:01.346094: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:92] Constant array MobilenetV2/expanded_conv_13/depthwise/BatchNorm/FusedBatchNorm_mul_0_param lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-07-11 04:40:01.346122: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:92] Constant array MobilenetV2/expanded_conv_13/depthwise/BatchNorm/FusedBatchNorm_add_param lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-07-11 04:40:01.349163: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:92] Constant array MobilenetV2/expanded_conv_14/depthwise/depthwise_weights lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-07-11 04:40:01.349318: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:92] Constant array MobilenetV2/expanded_conv_14/depthwise/BatchNorm/FusedBatchNorm_mul_0_param lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-07-11 04:40:01.349351: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:92] Constant array MobilenetV2/expanded_conv_14/depthwise/BatchNorm/FusedBatchNorm_add_param lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-07-11 04:40:01.353356: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:92] Constant array MobilenetV2/expanded_conv_15/depthwise/depthwise_weights lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-07-11 04:40:01.353511: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:92] Constant array MobilenetV2/expanded_conv_15/depthwise/BatchNorm/FusedBatchNorm_mul_0_param lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-07-11 04:40:01.353545: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:92] Constant array MobilenetV2/expanded_conv_15/depthwise/BatchNorm/FusedBatchNorm_add_param lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-07-11 04:40:01.357264: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:92] Constant array MobilenetV2/expanded_conv_16/depthwise/depthwise_weights lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-07-11 04:40:01.357400: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:92] Constant array MobilenetV2/expanded_conv_16/depthwise/BatchNorm/FusedBatchNorm_mul_0_param lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n2018-07-11 04:40:01.357432: W tensorflow/contrib/lite/toco/graph_transformations/quantize.cc:92] Constant array MobilenetV2/expanded_conv_16/depthwise/BatchNorm/FusedBatchNorm_add_param lacks MinMax information. To make up for that, we will now compute the MinMax from actual array elements. That will result in quantization parameters that probably do not match whichever arithmetic was used during training, and thus will probably be a cause of poor inference accuracy.\r\n", "comments": ["@tatianashp\r\n\r\nHow can I get a help to resolve above issues?", "@aselle, @andrehentz Can you help?", "I also kept on getting similar errors with using a MobileNetV2 backbone for my network.\r\n\r\nTo solve my issue, I made sure to create the training quantization nodes (`tf.contrib.quantize.create_training_graph(quant_delay=quant_delay)`) in my training graph with MobileNetV2 training scope:\r\n```\r\nwith tf.contrib.slim.arg_scope(mobilenet_v2.training_scope()):\r\n    <create mobilenetv2 based network>\r\n```\r\n\r\nWhere when I created my eval graph with quantization nodes (`tf.contrib.quantize.create_eval_graph()`), I made sure to load my MobileNetv2 model **without** the above training scope. This solved all of my errors of having nodes without having min/max information. \r\n\r\nI separated my training and evaluation into different scripts/functions in order to make it easier to separate the two graphs. \r\n\r\nI then [froze](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py) my saved checkpoint weights from training with the graph from evaluation, then optimized them for [inference](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/optimize_for_inference.py), and finally converted to TFLite with [TOCO](https://github.com/tensorflow/tensorflow/blob/bfcfad55b7b3fa4a1093fa748d4241f9457b2a84/tensorflow/contrib/lite/python/tflite_convert.py) to get a quantized tflite file.\r\n\r\nHope this helps.", "Hi @G-mel\r\n\r\nThank you for your comments\r\n\r\nI have developed the segmentation based on mobilnetv2.\r\n\r\nHow could I edit train.py and eval.py to reflect you proposal.\r\n\r\nWhere should I add the training scope in train.py?\r\n\r\nYour suggestion is very helpful\r\n\r\nYou see train.py and other source codes as below\r\n\r\nhttps://github.com/tensorflow/models/tree/master/research/deeplab", "@kanul I've looked around at the deeplab source code and the code for training scope already appears on lines 58, 85 and 318 in [feature_extractor.py](https://github.com/tensorflow/models/blob/master/research/deeplab/core/feature_extractor.py).\r\n\r\nIt also looks like the training scope in DeepLab is handled properly if `is_training=False` is being passed into the training scope in `feature_extractor.py`.\r\n\r\nyou can take a look at [mobilenet.py](https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py#L415) to see how `is_training` is handled in the scope.\r\n\r\nIf the `train.py` and the `eval.py` training scopes are being handled properly, then you have to add `tf.contrib.quantize.create_training_graph(quant_delay=quant_delay)` into `train.py` to rewrite its graph with fake quant nodes, and add `tf.contrib.quantize.create_eval_graph()` into `eval.py` in order to rewrite the deeplab graph without training nodes into the eval graph with quant nodes.\r\n\r\nMake sure to save the checkpoints from `train.py`, and save the graph from `eval.py` (after adding eval quant nodes to graph), then using the training weights and the eval graph, follow the steps I said in my previous comments to generate the quantized tflite file.\r\n\r\nHopefully it ends up working out with deeplab", "Hi, @G-mel , @kanul ,\r\nI got the same error.\r\n\r\n\r\n`bazel-bin/tensorflow/contrib/lite/toco/toco   --input_file=${MODEL_PATH}/frozen_inference_graph_stripped.pb   --output_file=${MODEL_PATH}/deeplabv3+_quan.lite   --input_format=TENSORFLOW_GRAPHDEF   --output_format=TFLITE   --inference_type=QUANTIZED_UINT8   --input_shapes=1,513,513,3   --input_arrays=sub_7   --output_arrays=ResizeBilinear_3   --std_values=128   --mean_values=127   --dump_graphviz=${MODEL_PATH}`\r\n\r\n```\r\n2018-07-24 13:39:12.271875: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 639 operators, 1220 arrays (0 quantized)\r\n2018-07-24 13:39:12.293302: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 639 operators, 1220 arrays (0 quantized)\r\n2018-07-24 13:39:12.537359: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 166 operators, 340 arrays (1 quantized)\r\n2018-07-24 13:39:12.541454: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before pre-quantization graph transformations: 166 operators, 340 arrays (1 quantized)\r\n2018-07-24 13:39:12.541764: W tensorflow/contrib/lite/toco/graph_transformations/hardcode_min_max.cc:105] Tweaking the MinMax of array ResizeBilinear_1, which is an input to {Concatenation operator with output concat}, because we want all inputs and outputs of a Concatenation operator to have the same MinMax so that it can be implemented as a pure byte-copy, no arithmetic.\r\n2018-07-24 13:39:12.543031: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After pre-quantization graph transformations pass 1: 111 operators, 285 arrays (1 quantized)\r\n2018-07-24 13:39:12.544625: F tensorflow/contrib/lite/toco/tooling_util.cc:1607] **Array MobilenetV2/expanded_conv_7/depthwise/depthwise/SpaceToBatchND, which is an input to the DepthwiseConv operator producing the output array MobilenetV2/expanded_conv_7/depthwise/depthwise, is lacking min/max data, which is necessary for quantization.** Either target a non-quantized output format, or change the input graph to contain min/max information, or pass --default_ranges_min= and --default_ranges_max= if you do not care about the accuracy of results.\r\nAborted (core dumped)\r\n```\r\n\r\n@suharshs,\r\nIt seems that SpaceToBatchND operation is  unsupported  by the [quantization rewrite](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/quantize/python/quantize.py) .\r\n\r\n@G-mel ,\r\nI add with `tf.contrib.slim.arg_scope(mobilenet_v2.training_scope()):` to [feature_extractor.py#L60](https://github.com/tensorflow/models/blob/master/research/deeplab/core/feature_extractor.py#L60), there are still the same  errors!!\r\n\r\n```\r\nwith tf.variable_scope(scope, 'MobilenetV2', [net], reuse=reuse) as scope:\r\n    with slim.arg_scope(mobilenet_v2.training_scope(is_training=is_training)):\r\n        # TODO(b/68150321): Enable fused batch norm once quantization\r\n        # supports it.\r\n        with slim.arg_scope([slim.batch_norm], fused=True):#False):  \r\n            return mobilenet_v2.mobilenet_base(\r\n                net,\r\n                conv_defs=mobilenet_v2.V2_DEF,\r\n                depth_multiplier=depth_multiplier,\r\n                min_depth=8 if depth_multiplier == 1.0 else 1,\r\n                divisible_by=8 if depth_multiplier == 1.0 else 1,\r\n                final_endpoint=final_endpoint or _MOBILENET_V2_FINAL_ENDPOINT,\r\n                output_stride=output_stride,\r\n                scope=scope,\r\n                is_training=is_training)\r\n```\r\nThanks!\r\n", "Hi all, I had a chance to look into this. The issue is that dilated depthwise convolution isn't yet supported. The contrib/quantize rewrite supports this at HEAD but TOCO/TFLite doesn't have the inference transformations and quantized dilated depthwise convolution kernels implemented. This is something I am trying to complete soon so will keep you posted.\r\n\r\nThanks for your patience!", "Hi @suharshs \r\n\r\nI saw the commit id: 06228fb70858ef50f31cc8cdf909121c80e100b2\r\n\r\nI have checked that quantized atrous convolutions were already supported from above commit id.\r\n\r\nIs this very hard to add quantized dilated depthwise convolution kernels in TOCO/TFlite?", "Hi @suharshs\r\n\r\nHow is your status for the above issue?", "Hi sorry for the delay, I have a work in progress change, but need to make time to implement the necessary optimized kernels, but we are actively working on this issue. Thanks for your patience!", "Nagging Assignee @suharshs: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@suharshs When dilated depthwise convolution will be supported? Thanks for your hard work! ", "Hi sorry for the delay responding. I am working on it as we speak and I\nexpect all the necessary code to be done within 2 to 3 weeks. Thanks!\n\nOn Mon, Sep 10, 2018, 8:36 PM raninbowlalala <notifications@github.com>\nwrote:\n\n> @suharshs <https://github.com/suharshs> When dilated depthwise\n> convolution will be supported? Thanks for your hard work!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/20684#issuecomment-420135055>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABYidtYqRKDBByOocwCZe-AssdxJUOF5ks5uZy-wgaJpZM4VKgty>\n> .\n>\n", "Hi all, thanks for your patience.\r\n\r\nI have submitted optimized dilated depthwise conv support and better handling in TOCO of dilations. Everything should be available at the lastest nightly release, so please give it a try and create a new separate issue if you encounter problems with dilated depthwise conv support.\r\n\r\nHere are the list of commits, in case you are curious:\r\nReference implementations: https://github.com/tensorflow/tensorflow/commit/fb50c8e9a3cb2ccfac9cf4a847d5841cba80b524#diff-c748d758eb53ac58d70a13e07e02c6db\r\nOptimized implementations: https://github.com/tensorflow/tensorflow/commit/3365cd1cc7bf3dcb781c76652132119bf82133e6#diff-c748d758eb53ac58d70a13e07e02c6db\r\nTOCO transformations: https://github.com/tensorflow/tensorflow/commit/0ab89a599bdb9885532785a5e7b6bfe346e09ee3#diff-c748d758eb53ac58d70a13e07e02c6db \r\n\r\nThanks!", "Hi @suharshs \r\n\r\nI have a question for the meaning of optimized implementations.\r\n\r\nHow about your strategy to implement the optimized dilated conv?\r\n\r\nCould I obtain a clue from the function of Fast3x3FilterKernelSupported?"]}, {"number": 20683, "title": "matrix matmul ", "body": "Is there any way of computing the matrix inner of a matrix  and a vector, I use the tf.matmul operation and it raised an error : \r\n\r\n Shape must be rank 2 but is rank 3 for 'attention_query_1/MatMul' (op: 'MatMul') with input shapes: [?,1000,100], [100].\r\n\r\nIt seems that the operation does not support broadcasting. \r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "I have solved the issue with the help of stack overflow and other experienced engineers. Thanks for your reply.\nYours\n\nSent from Yomail\n\n", "Automatically closing this out since I understand it to be resolved, but please let me know if I'm mistaken.Thanks!"]}, {"number": 20682, "title": "Run model on ios", "body": "Hi friends,\r\nwhen I run a model on ios, I got an error:\r\nRunning model failed:Invalid argument: NodeDef mentions attr 'dilations' not in Op<name=Conv2D; signature=input:T, filter:T -> output:T; attr=T:type,allowed=[DT_HALF, DT_FLOAT, DT_DOUBLE]; attr=strides:list(int); attr=use_cudnn_on_gpu:bool,default=true; attr=padding:string,allowed=[\"SAME\", \"VALID\"]; attr=data_format:string,default=\"NHWC\",allowed=[\"NHWC\", \"NCHW\"]>; NodeDef: conv2d/Conv2D = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_x_0, conv2d/kernel/read). (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).\r\nI using tensorflow 1.8.0 to trainning (but when I using tensorflow 1.5.0 I still got same error when run model on ios)\r\nPlease kindly give me an advice for this. Thanks", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Thank you for your response, I fixed it. The reason is tensorflow for mobile using lower level than tensorflow for PC. I hope tensorflow team can update the version for tensorflow for mobile.\r\nThanks!", "Nagging Assignee @angersson: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "It looks like this issue has been resolved, so I'm closing it. Thanks!"]}, {"number": 20681, "title": "how can I use mkl with tbb in tensorflow ", "body": "I found that tbb is fast than openMp\r\nhttps://software.intel.com/en-us/articles/using-intel-mkl-and-intel-tbb-in-the-same-application\r\n\r\nBut in tensorflow, I cant use mkl with tbb, Is there a better solution\uff1f", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "@suhang1994  You can install your own version of MKL and configure TensorFlow to use it.  Please note, however, that the blog post that you refer to shows MKL with TBB outperforming MKL with OpenMP when executing ten simultaneous calls to LU factorization. This is quite unlikely situation for typical machine learning models. \r\n\r\nAdding @agramesh1 for any additional thoughts. ", "@tatianashp \r\n\r\nThanks, I found another way to speed up my multithreading by setting MKL_NUM_THREADS.\r\n\r\nAnd I have a question, tensorflow use mkl-dnn, if I use mkl, Is there any different?", "In my experience, the performance is similar when using MKL or MKL-DNN. Setting the environment variables for MKL might have a bigger effect. Please take a look at [CPU optimizations](https://www.tensorflow.org/performance/performance_guide#optimizing_for_cpu ) guide for more information. "]}, {"number": 20680, "title": "The default values of tf.app.flags are printed event though passed parameters at the first time", "body": "\r\n### System information\r\n\r\n== cat /etc/issue ===============================================\r\nDarwin mbp-2.local 17.5.0 Darwin Kernel Version 17.5.0: Fri Apr 13 19:32:32 PDT 2018; root:xnu-4570.51.2~1/RELEASE_X86_64 x86_64\r\nMac OS X 10.13.4\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nApple LLVM version 9.1.0 (clang-902.0.39.1)\r\nTarget: x86_64-apple-darwin17.5.0\r\nThread model: posix\r\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\r\n\r\n== uname -a =====================================================\r\nDarwin mbp-2.local 17.5.0 Darwin Kernel Version 17.5.0: Fri Apr 13 19:32:32 PDT 2018; root:xnu-4570.51.2~1/RELEASE_X86_64 x86_64\r\n\r\n== check pips ===================================================\r\nnumpy                              1.14.2\r\nprotobuf                           3.5.2.post1\r\ntensorflow                         1.8.0\r\ntensorflow-hub                     0.1.0\r\ntensorflow-model-analysis          0.6.0\r\ntensorflow-serving-api             1.8.0\r\ntensorflow-tensorboard             1.5.0\r\ntensorflow-transform               0.6.0\r\ntensorflowjs                       0.1.0\r\ntensorflowonspark                  1.0.0\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.8.0\r\ntf.GIT_VERSION = v1.8.0-0-g93bc2e2072\r\ntf.COMPILER_VERSION = v1.8.0-0-g93bc2e2072\r\nSanity check: array([1], dtype=int32)\r\n/usr/local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np\r\n.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\ntf_env_collect.sh: line 106: nvidia-smi: command not found\r\n\r\n== cuda libs  ===================================================\r\n\r\n### Describe the problem\r\n\r\nWe usually use `tf.app.flags` to declare the command-line parameters for TensorFlow scripts. But If we try to print the values of these parameters, it prints the default values at the first time even though we have passed the values.\r\n\r\nAnd if we actually \"get\" the values equal or more than one times, we can print the parameter values as expected.\r\n\r\n### Source code / logs\r\n\r\nHere is the example code to re-produce the issue.\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nflags = tf.app.flags\r\nflags.DEFINE_integer(\"image_width\", 224, \"Width of the image\")\r\nflags.DEFINE_integer(\"image_height\", 224, \"Height of the image\")\r\nflags.DEFINE_integer(\"channels\", 3, \"Channel of the image\")\r\n\r\nFLAGS = flags.FLAGS\r\nparameter_value_map = {}\r\nfor key in FLAGS.__flags.keys():\r\n  parameter_value_map[key] = FLAGS.__flags[key].value\r\nprint(\"Parameters: {}\".format(parameter_value_map))\r\n# Parameters: {'channels': 3, 'image_height': 224, 'image_width': 224}\r\n\r\nFLAGS.channels\r\nfor key in FLAGS.__flags.keys():\r\n    parameter_value_map[key] = FLAGS.__flags[key].value\r\nprint(\"Parameters: {}\".format(parameter_value_map))\r\n# Parameters: {'channels': 1, 'image_height': 1, 'image_width': 1}\r\n```\r\n\r\nWe can run the script with parameter `--image_width=1 --image_height=1 --channels=1`. And the results to print are different.\r\n", "comments": ["After diving into to source of `tensorflow/python/platform/flags.py`, we found that \"tf.flags.FLAGS implicitly parses flags with sys.argv when accessing the FLAGS values before it's explicitly parsed\".\r\n\r\nI'm not sure if it is by design. It is a little confusing if we want to print the \"final parameters\" before starting training or using the parameters.\r\n\r\nNow the parameter are implicit parsed when getting the values. It would be much better to provide an explicitly way to parse the parameters as well.\r\n\r\n```\r\n  def __getattr__(self, name):\r\n    wrapped = self.__dict__['__wrapped']\r\n    # To maintain backwards compatibility, implicitly parse flags when reading\r\n    # a flag.\r\n    if not wrapped.is_parsed():\r\n      wrapped(_sys.argv)\r\n    return wrapped.__getattr__(name)\r\n```", "By the way, if we want to parse the parameters and get values with key. Calling `FLAGS.__getattr__(\"channels\")` directly will throw this exception.\r\n\r\n```\r\nERROR:root:Trying to access flag --channels before flags were parsed.\r\nTraceback (most recent call last):\r\n  File \"./main.py\", line 25, in <module>\r\n    FLAGS.__getattr__(\"channels\")\r\n  File \"/usr/local/lib/python2.7/site-packages/absl/flags/_flagvalues.py\", line 488, in __getattr__\r\n    raise _exceptions.UnparsedFlagAccessError(error_message)\r\nabsl.flags._exceptions.UnparsedFlagAccessError: Trying to access flag --channels before flags were parsed.\r\n```", " As a workaround you can use `getattr()` to get values. This always prints correct arguments.\r\n```\r\n    print 'Arguments:'\r\n    for key in FLAGS.__flags.keys():\r\n        print '  {}: {}'.format(key, getattr(FLAGS, key))\r\n    print '===='\r\n```", "@tobegit3hub,\r\nWith respect to the above work around and for the fact that **`tf.app.flags`** are deprecated in **`Tensorflow Version 2.x`**, can you please let us know if we can close this issue? Thanks! ", "Thanks @rmothukuru and I will close this issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/20680\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/20680\">No</a>\n"]}, {"number": 20679, "title": "convert the t2t model to tflite error", "body": "Hi,\r\n\r\nRecently I am trying to convert the tensor2tensor machine translation model to android. There showed an error when trying to use tflite-convert tool.\r\nHere is the error code:\r\n```\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/tflite_convert\", line 11, in <module>\r\n    sys.exit(main())\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 320, in main\r\n    app.run(main=run_main, argv=sys.argv[:1])\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 316, in run_main\r\n    _convert_model(tflite_flags)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 121, in _convert_model\r\n    output_data = converter.convert()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/lite/python/lite.py\", line 309, in convert\r\n    allow_custom_ops=self.allow_custom_ops)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/lite/python/convert.py\", line 206, in toco_convert\r\n    input_tensor.dtype))\r\nValueError: Tensors serialized_example:0 not known type tf.string\r\n```\r\nI am using tensorflow 1.9.0rc2, firstly I have convert the original model to saved model with t2t-exporter tool, then the error came out when trying to convert the saved model to tflite model. \r\nCan someone help me fix this problem? Thanks.\r\n\r\n-------------------------------------------------\r\nupdate\r\nOS: Ubuntu 16.04\r\nTensorFlow Install from pip\r\nTensorFlow version 1.9.0rc2\r\nBazel version:0.15.0\r\nCUDA 9.0 cuDNN 7.0\r\nGPU: Nvidia GTX Titan V 12GB\r\nI firstly used the following command to export the model\r\nt2t-exporter \\ --model=transformer \\ --hparams_set=transformer_base_single_gpu \\ --problem=translate_enzh_wmt32k \\ --data_dir=../\\ --output_dir=./\r\nthen I got the exported model with a new folder \"export\"\r\nafter that I used the command\r\ntflite_convert --output_file=example.tflite --saved_model_dir=export/Servo/1531989270/\r\nNow I got the error I have described before.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "OS: Ubuntu 16.04\r\nTensorFlow Install from pip\r\nTensorFlow version 1.9.0rc2\r\nBazel version:0.15.0\r\nCUDA 9.0 cuDNN 7.0\r\nGPU: Nvidia GTX Titan V 12GB\r\nI firstly used the following command to export the model\r\n`t2t-exporter \\\r\n  --model=transformer \\\r\n  --hparams_set=transformer_base_single_gpu \\\r\n  --problem=translate_enzh_wmt32k \\\r\n  --data_dir=../\\\r\n  --output_dir=./`\r\nthen I got the exported model with a new folder \"export\"\r\nafter that I used the command \r\n`tflite_convert --output_file=example.tflite --saved_model_dir=export/Servo/1531989270/`\r\nNow I got the error I have described before.", "@gargn - would the tflite convert tool be expected to convert the t2t Transformer? Can you advise?", "I am not sure if t2t Transformer model is supported by TFLite.\r\n\r\nHowever, the issue above has been fixed in head. Use the nightly build. Either use \"pip install --upgrade tf_nightly\" or follow the instructions [here](https://www.tensorflow.org/install/install_sources).", "I've tried to rebuild the tensorflow with tf-nightly, but it is still not working. So I suppose the t2t transformer saved model is not supported by tflite.", "Could you provide an updated error message?", "`zyyt@ubuntu:~/tensordata$ tflite_convert --output_file=out/nmt.tflite --saved_model_dir=export/Servo/1530870898/\r\n2018-08-06 02:40:25.275242: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\nTraceback (most recent call last):\r\n  File \"/usr/local/bin/tflite_convert\", line 11, in <module>\r\n    sys.exit(main())\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 370, in main\r\n    app.run(main=run_main, argv=sys.argv[:1])\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 125, in run\r\n    _sys.exit(main(argv))\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 366, in run_main\r\n    _convert_model(tflite_flags)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/lite/python/tflite_convert.py\", line 143, in _convert_model\r\n    output_data = converter.convert()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/lite/python/lite.py\", line 375, in convert\r\n    dump_graphviz_video=self.dump_graphviz_video)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/lite/python/convert.py\", line 246, in toco_convert\r\n    input_data.SerializeToString())\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/lite/python/convert.py\", line 106, in toco_convert_protos\r\n    (stdout, stderr))\r\nRuntimeError: TOCO failed see console for info.\r\n2018-08-06 02:40:54.845514: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2018-08-06 02:40:54.936805: E tensorflow/contrib/lite/toco/import_tensorflow.cc:1709] tensorflow::ImportGraphDef failed with status: Invalid argument: Input 0 of node read_91/RefEnter was passed float from transformer/symbol_modality_32712_512/target_emb/weights_0:0 incompatible with expected float_ref.\r\n2018-08-06 02:40:54.947324: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: TensorSliceDataset\r\n2018-08-06 02:40:54.947365: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: MapDataset\r\n2018-08-06 02:40:54.947386: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: MapDataset\r\n2018-08-06 02:40:54.947404: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: MapDataset\r\n2018-08-06 02:40:54.947421: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: MapDataset\r\n2018-08-06 02:40:54.947439: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: PaddedBatchDataset\r\n2018-08-06 02:40:54.947458: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: MapDataset\r\n2018-08-06 02:40:54.947476: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: DatasetToSingleElement\r\n2018-08-06 02:40:54.973587: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: convert_gradient_to_tensor_HBc3xYw22Mw\r\n2018-08-06 02:40:54.973777: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Abs\r\n2018-08-06 02:40:54.973871: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: convert_gradient_to_tensor_HBc3xYw22Mw\r\n2018-08-06 02:40:54.974056: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Cos\r\n2018-08-06 02:40:54.974179: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Where\r\n2018-08-06 02:40:54.974726: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:54.975290: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:54.975830: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:54.976758: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:54.977031: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:54.978490: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:54.980047: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:54.980218: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ScatterNd\r\n2018-08-06 02:40:54.980847: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:54.981384: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:54.981909: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:54.982822: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:54.983088: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:54.984564: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:54.986139: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:54.986336: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ScatterNd\r\n2018-08-06 02:40:54.986843: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:54.987377: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:54.987905: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:54.988833: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:54.989094: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:54.990542: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:54.992098: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:54.992271: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ScatterNd\r\n2018-08-06 02:40:54.992777: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:54.993302: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:54.993826: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:54.994741: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:54.994998: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:54.996457: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:54.998008: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:54.998190: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ScatterNd\r\n2018-08-06 02:40:54.998709: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:54.999256: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:54.999785: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.000755: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.001013: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.002474: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.004014: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.004177: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ScatterNd\r\n2018-08-06 02:40:55.004685: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.005208: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.005734: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.006631: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.006884: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.008327: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.009869: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.010036: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ScatterNd\r\n2018-08-06 02:40:55.010243: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Cos\r\n2018-08-06 02:40:55.010348: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: MatrixBandPart\r\n2018-08-06 02:40:55.011741: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.012349: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.012965: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.013569: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.014167: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.014770: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.015385: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.015996: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.016617: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.017223: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.017828: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.018429: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.019217: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.019240: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.019254: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.019267: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.019280: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.019295: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.019310: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.019324: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.019339: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.019353: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.019364: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.019376: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.019387: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.019399: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.019411: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.019423: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.019437: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.019451: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.019466: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.019481: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.019496: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.019508: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.019520: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.019532: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.019544: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.019556: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.019567: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.019579: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.019593: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.019608: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.019622: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.019739: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.019833: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Any\r\n2018-08-06 02:40:55.019884: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: LogicalNot\r\n2018-08-06 02:40:55.019897: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: LogicalAnd\r\n2018-08-06 02:40:55.019909: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: LoopCond\r\n2018-08-06 02:40:55.020137: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.024568: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.025935: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.027317: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.028674: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.030060: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.032115: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.034436: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.036749: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.039079: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.041410: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.043742: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.046062: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.048395: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.050710: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.053043: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.055364: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.055410: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: convert_gradient_to_tensor_HBc3xYw22Mw\r\n2018-08-06 02:40:55.055567: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ZerosLike\r\n2018-08-06 02:40:55.055629: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.055717: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Enter\r\n2018-08-06 02:40:55.055754: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.055782: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.056202: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.056289: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.056763: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.056850: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.057312: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.057394: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.058292: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.058383: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.058519: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.058549: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.058971: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.059066: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.059782: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.059870: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.060008: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.060038: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.062403: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.062440: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.062518: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.064940: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.064975: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.065054: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.065187: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.065217: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.065634: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.065722: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.066199: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.066286: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.066995: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.067085: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.068198: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.068286: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.068415: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.068444: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.069093: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.069179: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.070124: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.070211: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.070339: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.070369: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.072761: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.072798: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.072878: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.075303: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.075338: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.075420: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.075546: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.075576: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.076235: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.076324: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.077031: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.077113: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.077824: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.077912: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.079042: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.079130: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.079258: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.079287: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.079942: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.080029: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.080985: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.081072: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.081199: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.081228: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.083607: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.083645: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.083725: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.086190: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.086223: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.086302: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.086432: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.086462: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.087123: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.087213: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.087916: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.088004: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.088712: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.088796: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.089928: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.090018: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.090150: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.090180: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.090838: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.090925: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.091874: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.091964: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.092094: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.092124: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.094489: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.094524: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.094603: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.097038: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.097071: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.097150: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.097287: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.097318: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.097975: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.098062: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.098758: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.098843: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.099561: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.099650: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.100780: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.100867: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.101005: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.101035: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.101690: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.101776: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.102732: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.102819: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.102950: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.102979: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.105381: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.105418: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.105498: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.107941: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.107975: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.108049: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.108209: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.108240: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.108896: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.108985: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.109691: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.109777: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.110490: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.110574: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.111718: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.111809: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.111946: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.111977: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.112393: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.112482: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.113442: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.113530: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.113662: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.113691: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.116069: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.116106: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.116186: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.118615: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.118648: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.118729: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ListDiff\r\n2018-08-06 02:40:55.118863: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.118892: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.121327: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.123659: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.125986: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.128304: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.130621: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.132953: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.135314: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.137648: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.139988: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.142307: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.144657: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.146992: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.149332: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.151643: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.155085: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.158486: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: RefEnter\r\n2018-08-06 02:40:55.158531: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: convert_gradient_to_tensor_HBc3xYw22Mw\r\n2018-08-06 02:40:55.160184: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: IsFinite\r\n2018-08-06 02:40:55.160203: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: ZerosLike\r\n2018-08-06 02:40:55.160378: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160395: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160408: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160421: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160434: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160446: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160459: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160471: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160483: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160495: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160507: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160518: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160530: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160542: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160554: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160565: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160576: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160588: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160600: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160611: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160620: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160629: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160640: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160650: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160659: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160669: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160772: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160785: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160817: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160829: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160842: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160855: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160867: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160879: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160892: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160905: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160918: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160930: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160943: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160955: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160968: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160980: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.160991: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.161004: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.161017: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.161029: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.161041: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.161053: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.161066: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.161078: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.161091: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.161103: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.161116: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.161261: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.161276: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.161289: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: GatherNd\r\n2018-08-06 02:40:55.161386: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Exit\r\n2018-08-06 02:40:55.161398: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Exit\r\n2018-08-06 02:40:55.161409: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Exit\r\n2018-08-06 02:40:55.161420: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Exit\r\n2018-08-06 02:40:55.161431: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Exit\r\n2018-08-06 02:40:55.161446: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Any\r\n2018-08-06 02:40:55.161466: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1064] Converting unsupported operation: Any\r\n2018-08-06 02:40:55.782366: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 4730 operators, 8121 arrays (0 quantized)\r\n2018-08-06 02:40:56.176083: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 4730 operators, 8121 arrays (0 quantized)\r\n2018-08-06 02:40:57.181053: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 3516 operators, 6315 arrays (0 quantized)\r\n2018-08-06 02:40:57.800836: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 3463 operators, 6253 arrays (0 quantized)\r\n2018-08-06 02:40:58.614300: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 3463 operators, 6253 arrays (0 quantized)\r\n2018-08-06 02:40:58.761401: F tensorflow/contrib/lite/toco/tooling_util.cc:682] Check failed: dim >= 1 (0 vs. 1)\r\nAborted (core dumped)\r\n\r\nNone\r\n`\r\n\r\nthis is the error message", "There have been some updates to related transformation code, so can you try rerunning your model? If there is still an issue with conversion, can you upload your SavedModel as a zip file so we can investigate it more closely?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "sorry for the late reply. I have tried to upload the model. but it's too big. the size is 1.3 GB while the maximum upload size is 10 MB. ", "So I think i can just tell you how to reproduce the model. you can install the tensor2tensor  package and follow the readme file to build an English to German model.", "I have tried with the latest version of tensorflow and tensor2tensor, It is still not working. Could you reopen this issue please?", "I reproduced the steps mentioned above. When I use the TensorFlow 1.10 install, I get the `dim >= 1` error mentioned above. However, when I use the most recent tf-nightly I get the following error indicating there are ops in the model that are not currently supported by TensorFlow Lite:\r\n\r\n> tensorflow/contrib/lite/toco/tflite/export.cc:386] Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.contrib.lite.TocoConverter(). Here is a list of operators for which  you will need custom implementations: Abs, All, BatchMatMul, Cos, DatasetToSingleElement, Enter, Exit, Fill, FloorMod, GatherNd, IsFinite, ListDiff, LoopCond, MapDataset, MatrixBandPart, Merge, PaddedBatchDatasetV2, Range, RefEnter, ScatterNd, Switch, TensorSliceDataset, Where, ZerosLike, convert_gradient_to_tensor_HBc3xYw22Mw.\r\n\r\nThe list of supported ops are available [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/tf_ops_compatibility.md). The two recommended solutions are:\r\n1. Add a custom op as described [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/custom_operators.md).\r\n2. Only use the ops that are currently supported by TFLite in your model.\r\n\r\nGiven how many operations are not implemented, I imagine it would be difficult to go either route. We are actively working on adding support for a broader set of TensorFlow ops. We are tracking operation requests here: https://github.com/tensorflow/tensorflow/issues/21526 to help with prioritizing.\r\n\r\nFor that reason, I am closing this issue. Thanks for reporting that the model is not supported and working through the issues. Additionally, please let me know if you get a different error when running your model against the most recent tf-nightly and I can reopen the issue."]}, {"number": 20678, "title": "Fix a couple typos", "body": "Fixes typos `its` to `it's` and `retrive` to `retrieve`", "comments": []}, {"number": 20677, "title": "C++ compilation of rule '@boringssl//:crypto' failed (Exit 1)", "body": "[jingfeng@Jingfeng_redhat tensorflow]$ bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n\r\nERROR: /home/jingfeng/.cache/bazel/_bazel_jingfeng/29120beece5f660cdcebf72073ed1bba/external/boringssl/BUILD:115:1: C++ compilation of rule '@boringssl//:crypto' failed (Exit 1)\r\nexternal/boringssl/src/crypto/cipher_extra/e_chacha20poly1305.c: In function 'poly1305_update_length':\r\nexternal/boringssl/src/crypto/cipher_extra/e_chacha20poly1305.c:145:3: error: 'for' loop initial declarations are only allowed in C99 mode\r\nfor (unsigned i = 0; i < sizeof(length_bytes); i++) {\r\n^\r\nexternal/boringssl/src/crypto/cipher_extra/e_chacha20poly1305.c:145:3: note: use option -std=c99 or -std=gnu99 to compile your code\r\nexternal/boringssl/src/crypto/cipher_extra/e_chacha20poly1305.c: In function 'aead_chacha20_poly1305_seal_scatter':\r\nexternal/boringssl/src/crypto/cipher_extra/e_chacha20poly1305.c:229:5: error: 'for' loop initial declarations are only allowed in C99 mode\r\nfor (size_t done = 0; done < extra_in_len; block_counter++) {\r\n^\r\nexternal/boringssl/src/crypto/cipher_extra/e_chacha20poly1305.c:233:7: error: 'for' loop initial declarations are only allowed in C99 mode\r\nfor (size_t i = offset; i < sizeof(block) && done < extra_in_len;\r\n^\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 8.244s, Critical Path: 6.30s\r\nINFO: 5 processes: 5 local.\r\nFAILED: Build did NOT complete successfully\r\n\r\n[jingfeng@Jingfeng_redhat ~]$ uname -a\r\nLinux Jingfeng_redhat 3.10.0-862.3.2.el7.ppc64le #1 SMP Tue May 15 22:31:16 UTC 2018 ppc64le ppc64le ppc64le GNU/Linux\r\n\r\n[jingfeng@Jingfeng_redhat ~]$ gcc -v\r\nUsing built-in specs.\r\nCOLLECT_GCC=gcc\r\nCOLLECT_LTO_WRAPPER=/usr/libexec/gcc/ppc64le-redhat-linux/4.8.5/lto-wrapper\r\nTarget: ppc64le-redhat-linux\r\nConfigured with: ../configure --prefix=/usr --mandir=/usr/share/man --infodir=/usr/share/info --with-bugurl=http://bugzilla.redhat.com/bugzilla --enable-bootstrap --enable-shared --enable-threads=posix --enable-checking=release --with-system-zlib --enable-__cxa_atexit --disable-libunwind-exceptions --enable-gnu-unique-object --enable-linker-build-id --with-linker-hash-style=gnu --enable-languages=c,c++,objc,obj-c++,java,fortran,ada,go,lto --enable-plugin --enable-initfini-array --disable-libgcj --with-isl=/builddir/build/BUILD/gcc-4.8.5-20150702/obj-ppc64le-redhat-linux/isl-install --with-cloog=/builddir/build/BUILD/gcc-4.8.5-20150702/obj-ppc64le-redhat-linux/cloog-install --enable-gnu-indirect-function --enable-secureplt --with-long-double-128 --enable-targets=powerpcle-linux --disable-multilib --with-cpu-64=power8 --with-tune-64=power8 --build=ppc64le-redhat-linux\r\nThread model: posix\r\ngcc version 4.8.5 20150623 (Red Hat 4.8.5-28) (GCC)\r\n\r\njingfeng@Jingfeng_redhat ~]$ bazel version\r\nExtracting Bazel installation...\r\nBuild label: 0.11.0- (@non-git)\r\nBuild target: bazel-out/ppc-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Fri Jul 13 14:25:29 +50491 (1531191651929)\r\nBuild timestamp: 1531191651929\r\nBuild timestamp as int: 1531191651929\r\n\r\npython3.4 \r\ncuda9.0 \r\ncudnn latest\r\n\r\n[root@Jingfeng_redhat ~]# nvidia-smi\r\nTue Jul 10 17:50:17 2018       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 396.26                 Driver Version: 396.26                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla K80           On   | 00000000:03:00.0 Off |                  Off |\r\n| N/A   30C    P8    26W / 149W |      0MiB / 12206MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  Tesla K80           On   | 00000000:04:00.0 Off |                  Off |\r\n| N/A   25C    P8    30W / 149W |      0MiB / 12206MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  Tesla K80           On   | 00000002:03:00.0 Off |                  Off |\r\n| N/A   41C    P0    N/A /  N/A |      0MiB / 12206MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  Tesla K80           On   | 00000002:04:00.0 Off |                  Off |\r\n| N/A   26C    P8    30W / 149W |      0MiB / 12206MiB |      0%      Default |\r\n\r\n\r\nMay I know the reason for this problem? & how to solve it? Many thanks for this\r\n\r\n", "comments": ["Try to run `bazel build --conlyopt=-std=c99`", "hi @rongjiecomputer, Thanks for reply\r\nI tried add `bazel build --conlyopt=-std=c99`, but C++ compilation problem still occurs. :( \r\n\r\n[root@Jingfeng_redhat tensorflow]# bazel build --config=opt --config=cuda --conlyopt=-std=c99 //tensorflow/tools/pip_package:build_pip_package\r\nWARNING: /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/protobuf_archive/WORKSPACE:1: Workspace name in /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/protobuf_archive/WORKSPACE (@com_google_protobuf) does not match the name given in the repository's definition (@protobuf_archive); this will cause a build error in future versions\r\nWARNING: /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/grpc/WORKSPACE:1: Workspace name in /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/grpc/WORKSPACE (@com_github_grpc_grpc) does not match the name given in the repository's definition (@grpc); this will cause a build error in future versions\r\nWARNING: /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/grpc/BUILD:1992:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_common.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/grpc/bazel/grpc_build_system.bzl:172:12\r\nWARNING: /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/grpc/BUILD:1992:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_decode.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/grpc/bazel/grpc_build_system.bzl:172:12\r\nWARNING: /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/grpc/BUILD:1992:1: in srcs attribute of cc_library rule @grpc//:grpc_nanopb: please do not import '@grpc//third_party/nanopb:pb_encode.c' directly. You should either move the file to this package or depend on an appropriate rule there. Since this rule was created by the macro 'grpc_generate_one_off_targets', the error might have been caused by the macro implementation in /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/grpc/bazel/grpc_build_system.bzl:172:12\r\nWARNING: /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/absl_py/WORKSPACE:1: Workspace name in /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/absl_py/WORKSPACE (@io_abseil_py) does not match the name given in the repository's definition (@absl_py); this will cause a build error in future versions\r\nWARNING: /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/flatbuffers/WORKSPACE:1: Workspace name in /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/flatbuffers/WORKSPACE (@com_github_google_flatbuffers) does not match the name given in the repository's definition (@flatbuffers); this will cause a build error in future versions\r\nWARNING: /root/tensorflow/tensorflow/contrib/learn/BUILD:17:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:exporter': No longer supported. Switch to SavedModel immediately.\r\nWARNING: /root/tensorflow/tensorflow/contrib/learn/BUILD:17:1: in py_library rule //tensorflow/contrib/learn:learn: target '//tensorflow/contrib/learn:learn' depends on deprecated target '//tensorflow/contrib/session_bundle:gc': No longer supported. Switch to SavedModel immediately.\r\nWARNING: /root/tensorflow/tensorflow/contrib/bayesflow/BUILD:17:1: in py_library rule //tensorflow/contrib/bayesflow:bayesflow_py: target '//tensorflow/contrib/bayesflow:bayesflow_py' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /root/tensorflow/tensorflow/contrib/timeseries/python/timeseries/BUILD:356:1: in py_library rule //tensorflow/contrib/timeseries/python/timeseries:ar_model: target '//tensorflow/contrib/timeseries/python/timeseries:ar_model' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /root/tensorflow/tensorflow/contrib/timeseries/python/timeseries/state_space_models/BUILD:230:1: in py_library rule //tensorflow/contrib/timeseries/python/timeseries/state_space_models:filtering_postprocessor: target '//tensorflow/contrib/timeseries/python/timeseries/state_space_models:filtering_postprocessor' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /root/tensorflow/tensorflow/contrib/timeseries/python/timeseries/state_space_models/BUILD:73:1: in py_library rule //tensorflow/contrib/timeseries/python/timeseries/state_space_models:kalman_filter: target '//tensorflow/contrib/timeseries/python/timeseries/state_space_models:kalman_filter' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /root/tensorflow/tensorflow/contrib/kfac/python/ops/BUILD:80:1: in py_library rule //tensorflow/contrib/kfac/python/ops:loss_functions: target '//tensorflow/contrib/kfac/python/ops:loss_functions' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /root/tensorflow/tensorflow/contrib/seq2seq/BUILD:23:1: in py_library rule //tensorflow/contrib/seq2seq:seq2seq_py: target '//tensorflow/contrib/seq2seq:seq2seq_py' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nWARNING: /root/tensorflow/tensorflow/contrib/BUILD:14:1: in py_library rule //tensorflow/contrib:contrib_py: target '//tensorflow/contrib:contrib_py' depends on deprecated target '//tensorflow/contrib/distributions:distributions_py': TensorFlow Distributions has migrated to TensorFlow Probability (https://github.com/tensorflow/probability). Deprecated copies remaining in tf.contrib.distributions are unmaintained, unsupported, and will be removed by late 2018. You should update all usage of `tf.contrib.distributions` to `tfp.distributions`.\r\nINFO: Analysed target //tensorflow/tools/pip_package:build_pip_package (0 packages loaded).\r\nINFO: Found 1 target...\r\nERROR: /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/boringssl/BUILD:115:1: C++ compilation of rule '@boringssl//:crypto' failed (Exit 1)\r\nIn file included from external/boringssl/src/crypto/cipher_extra/../fipsmodule/cipher/internal.h:65:0,\r\n                 from external/boringssl/src/crypto/cipher_extra/e_aesctrhmac.c:21:\r\nexternal/boringssl/src/crypto/cipher_extra/../fipsmodule/cipher/../../internal.h:414:3: error: unknown type name 'pthread_rwlock_t'\r\n   pthread_rwlock_t lock;\r\n   ^\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 3.844s, Critical Path: 3.21s\r\nFAILED: Build did NOT complete successfully\r\n\r\n", "Aha, `-std=c99` will disable `pthread_rwlock_t` because it is non-standard type. Try `-std=gnu99` instead.\r\n\r\nhttps://stackoverflow.com/questions/15673492/gcc-compile-fails-with-pthread-and-option-std-c99", "@rongjiecomputer \r\nHmmm. I tried that as well, it stills fails.  The same error occurs again. \r\n\r\n[root@Jingfeng_redhat tensorflow]# bazel build --config=opt --config=cuda --conlyopt=-std=gnu99 //tensorflow/tools/pip_package:build_pip_package\r\n\r\nERROR: /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/boringssl/BUILD:115:1: C++ compilation of rule '@boringssl//:crypto' failed (Exit 1)\r\nexternal/boringssl/src/crypto/cipher_extra/e_chacha20poly1305.c: In function 'poly1305_update_length':\r\nexternal/boringssl/src/crypto/cipher_extra/e_chacha20poly1305.c:145:3: error: 'for' loop initial declarations are only allowed in C99 mode\r\n   for (unsigned i = 0; i < sizeof(length_bytes); i++) {\r\n   ^\r\nexternal/boringssl/src/crypto/cipher_extra/e_chacha20poly1305.c:145:3: note: use option -std=c99 or -std=gnu99 to compile your code\r\nexternal/boringssl/src/crypto/cipher_extra/e_chacha20poly1305.c: In function 'aead_chacha20_poly1305_seal_scatter':\r\nexternal/boringssl/src/crypto/cipher_extra/e_chacha20poly1305.c:229:5: error: 'for' loop initial declarations are only allowed in C99 mode\r\n     for (size_t done = 0; done < extra_in_len; block_counter++) {\r\n     ^\r\nexternal/boringssl/src/crypto/cipher_extra/e_chacha20poly1305.c:233:7: error: 'for' loop initial declarations are only allowed in C99 mode\r\n       for (size_t i = offset; i < sizeof(block) && done < extra_in_len;\r\n       ^\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 5.563s, Critical Path: 3.10s\r\nFAILED: Build did NOT complete successfully\r\n\r\n\r\n", "I am out of idea (not a Linux expert). Hope other experts can jump in.", "@wdirons @sandipmgiri Do you also see this problem?\r\nCould you help with this issue?", "@wdirons @sandipmgiri for this question about building on PPC. Have you seen this? Looks like gcc4.8 is stricter on PPC than X86?", "@jayfurmanek, I know before I joined PowerAI, it was carrying a patch for boringssl. Is that patch needed in this case?\r\n\r\n@zjfheart , Can you clarify what version of Tensorflow your trying to install? v1.9.0 ? master?\r\n", "We have needed to carry a patch now and again for boringSSL, but they should all no longer be needed. \r\nI do see the s390x patch was recently removed:\r\nhttps://github.com/tensorflow/tensorflow/commit/da3789cd66290db7fbfc43d2c5091c4b0273fbdd\r\n\r\nWe piggy-backed a change for ppc64le in there at one point, but again, that all should be merged in now.\r\n@zjfheart Can you share more details on how you are building? (tf version, bazel version, config options enabled)", "boringssl is building for me on Ubuntu 16.04 with gcc 5.4.0.\r\n\r\nOn RHEL with gcc 4.8.5 I recreated the problem. I'm going to be doing more investigation on it.\r\n\r\nboringssl is only needed for google cloud platform, if you don't need tensorflow built with support for that function you can modify .tf_configure.bazelrc  and find the line for gcp_support and modify the value to false:\r\n\r\nbuild --define with_gcp_support=false\r\n\r\n[ I have been deleting $HOME/.cache after changing .tf_configure.bazelrc to force everything to be re-built ]", "Hi @wdirons \r\nI git clone the latest version. \r\ngit clone https://github.com/tensorflow/tensorflow\r\n[root@Jingfeng_redhat tensorflow]# vi RELEASE.md \r\n```\r\n\r\n # Release 1.9.0\r\n## Major Features And Improvements\r\n * Updated docs for `tf.keras`: New Keras-based [get started](http://tensorflow.org/versions/r1.9/get_started),\r\n and [programmers guide page](http://tensorflow.org/versions/r1.9/programmers_guide/keras).\r\n* Update `tf.keras` to the Keras 2.1.6 API.\r\n....\r\n```\r\n\r\nI modify the .tf_configure.bazelrc file, changing it to false (see below), and then clear the cache. But still get the same error. \r\n\r\n[root@Jingfeng_redhat tensorflow]# rm -rf  ~/.cache/\r\n[root@Jingfeng_redhat tensorflow]# vi .tf_configure.bazelrc\r\nbuild --action_env PYTHON_BIN_PATH=\"/usr/bin/python3.4\"\r\nbuild --action_env PYTHON_LIB_PATH=\"/usr/lib64/python3.4/site-packages\"\r\nbuild --python_path=\"/usr/bin/python3.4\"\r\nbuild --define with_jemalloc=true\r\nbuild:gcp --define with_gcp_support=false\r\nbuild:hdfs --define with_hdfs_support=true\r\nbuild:aws --define with_aws_support=true\r\nbuild --define with_kafka_support=true\r\nbuild:xla --define with_xla_support=true\r\nbuild:gdr --define with_gdr_support=true\r\nbuild:verbs --define with_verbs_support=true\r\nbuild --action_env TF_NEED_OPENCL_SYCL=\"0\"\r\nbuild --action_env TF_NEED_CUDA=\"1\"\r\nbuild --action_env CUDA_TOOLKIT_PATH=\"/usr/local/cuda\"\r\nbuild --action_env TF_CUDA_VERSION=\"9.0\"\r\nbuild --action_env CUDNN_INSTALL_PATH=\"/usr/local/cuda-9.0\"\r\nbuild --action_env TF_CUDNN_VERSION=\"7\"\r\nbuild --action_env TF_NCCL_VERSION=\"1\"\r\nbuild --action_env TF_CUDA_COMPUTE_CAPABILITIES=\"3.5,5.2\"\r\nbuild --action_env TF_CUDA_CLANG=\"0\"\r\nbuild --action_env GCC_HOST_COMPILER_PATH=\"/usr/bin/gcc\"\r\nbuild --config=cuda\r\ntest --config=cuda\r\nbuild --define grpc_no_ares=true\r\nbuild:opt --copt=-mcpu=native\r\nbuild:opt --define with_default_optimizations=true\r\nbuild --strip=always\r\n\r\n\r\n[root@Jingfeng_redhat tensorflow]# bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\nExtracting Bazel installation...\r\n................\r\nERROR: /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/boringssl/BUILD:115:1: C++ compilation of rule '@boringssl//:crypto' failed (Exit 1)\r\nexternal/boringssl/src/crypto/digest_extra/digest_extra.c: In function 'EVP_get_digestbynid':\r\nexternal/boringssl/src/crypto/digest_extra/digest_extra.c:110:3: error: 'for' loop initial declarations are only allowed in C99 mode\r\n   for (unsigned i = 0; i < OPENSSL_ARRAY_SIZE(nid_to_digest_mapping); i++) {\r\n   ^\r\nexternal/boringssl/src/crypto/digest_extra/digest_extra.c:110:3: note: use option -std=c99 or -std=gnu99 to compile your code\r\nexternal/boringssl/src/crypto/digest_extra/digest_extra.c: In function 'cbs_to_md':\r\nexternal/boringssl/src/crypto/digest_extra/digest_extra.c:141:3: error: 'for' loop initial declarations are only allowed in C99 mode\r\n   for (size_t i = 0; i < OPENSSL_ARRAY_SIZE(kMDOIDs); i++) {\r\n   ^\r\nexternal/boringssl/src/crypto/digest_extra/digest_extra.c: In function 'EVP_marshal_digest_algorithm':\r\nexternal/boringssl/src/crypto/digest_extra/digest_extra.c:204:3: error: 'for' loop initial declarations are only allowed in C99 mode\r\n   for (size_t i = 0; i < OPENSSL_ARRAY_SIZE(kMDOIDs); i++) {\r\n   ^\r\nexternal/boringssl/src/crypto/digest_extra/digest_extra.c: In function 'EVP_get_digestbyname':\r\nexternal/boringssl/src/crypto/digest_extra/digest_extra.c:230:3: error: 'for' loop initial declarations are only allowed in C99 mode\r\n   for (unsigned i = 0; i < OPENSSL_ARRAY_SIZE(nid_to_digest_mapping); i++) {\r\n   ^\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 57.111s, Critical Path: 0.81s\r\nFAILED: Build did NOT complete successfully\r\n\r\n\r\nHi @jayfurmanek  now, I am using the bazel 0.11.0. I also tried the version 0.15.0 (still the same error) \r\n[root@Jingfeng_redhat tensorflow]# bazel version\r\nBuild label: 0.11.0- (@non-git)\r\nBuild target: bazel-out/ppc-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Fri Jul 13 14:25:29 +50491 (1531191651929)\r\nBuild timestamp: 1531191651929\r\nBuild timestamp as int: 1531191651929\r\n\r\n\r\nHere is the configuration info: \r\n[root@Jingfeng_redhat tensorflow]# ./configure \r\nWARNING: Running Bazel server needs to be killed, because the startup options are different.\r\nYou have bazel 0.11.0- (@non-git) installed.\r\nPlease specify the location of python. [Default is /root/anaconda3/bin/python]: /usr/bin/python3.4\r\n\r\n\r\nFound possible Python library paths:\r\n  /usr/lib64/python3.4/site-packages\r\n  /usr/lib/python3.4/site-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/lib64/python3.4/site-packages]\r\n\r\nDo you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: y\r\njemalloc as malloc support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: n\r\nNo Google Cloud Platform support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Hadoop File System support? [Y/n]: n\r\nNo Hadoop File System support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Amazon AWS Platform support? [Y/n]: n\r\nNo Amazon AWS Platform support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Apache Kafka Platform support? [Y/n]: n\r\nNo Apache Kafka Platform support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [y/N]: n\r\nNo XLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with GDR support? [y/N]: n\r\nNo GDR support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with VERBS support? [y/N]: n\r\nNo VERBS support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with OpenCL SYCL support? [y/N]: n\r\nNo OpenCL SYCL support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nPlease specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 9.0]: \r\n\r\n\r\nPlease specify the location where CUDA 9.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\n\r\n\r\nPlease specify the cuDNN version you want to use. [Leave empty to default to cuDNN 7.0]: \r\n\r\n\r\nPlease specify the location where cuDNN 7 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]:\r\n\r\n\r\nDo you wish to build TensorFlow with TensorRT support? [y/N]: n\r\nNo TensorRT support will be enabled for TensorFlow.\r\n\r\n\r\nPlease specify the NCCL version you want to use. [Leave empty to default to NCCL 1.3]: \r\n\r\n\r\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size. [Default is: 3.5,5.2]\r\n\r\n\r\nDo you want to use clang as CUDA compiler? [y/N]: n\r\nnvcc will be used as CUDA compiler.\r\n\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \r\n\r\n\r\nDo you wish to build TensorFlow with MPI support? [y/N]: n\r\nNo MPI support will be enabled for TensorFlow.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -mcpu=native]: \r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n\r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See tools/bazel.rc for more details.\r\n\t--config=mkl         \t# Build with MKL support.\r\n\t--config=monolithic  \t# Config for mostly static monolithic build.\r\nConfiguration finished\r\n[root@Jingfeng_redhat tensorflow]# \r\n\r\n\r\n\r\n\r\n\r\n\r\n", "@zjfheart \r\n\r\nI have submitted PR #20791 to fix this issue. One of the patches in PowerAI's fork of Tensorflow is still needed. \r\n\r\nIf you want to try before the PR is merged, you can cherry-pick the fix:\r\n\r\n```\r\ngit clone https://github.com/tensorflow/tensorflow\r\ncd tensorflow\r\ngit remote add wdirons https://github.com/wdirons/tensorflow\r\ngit fetch wdirons\r\ngit cherry-pick 8a5c6c4c305905a206065b0f5fa9a86c03876428\r\n```", "Hi @wdirons \r\nThanks for response. \r\n\r\nI cherry-picked the fix by: \r\n```\r\ngit clone https://github.com/tensorflow/tensorflow\r\ncd tensorflow\r\ngit remote add wdirons https://github.com/wdirons/tensorflow\r\ngit fetch wdirons\r\ngit cherry-pick --no-commit 8a5c6c4c305905a206065b0f5fa9a86c03876428\r\n```\r\n(without \"--no-commit\", there will be \"cherry-pick error: Your local changes would be overwritten by cherry-pick.\" ) \r\n\r\nThen I bazel build it, but still get C++ compilation errors.\r\n \r\n[root@Jingfeng_redhat tensorflow]# bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\nERROR: /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/com_github_googlecloudplatform_google_cloud_cpp/google/cloud/bigtable/BUILD:30:1: C++ compilation of rule '@com_github_googlecloudplatform_google_cloud_cpp//google/cloud/bigtable:bigtable_client' failed (Exit 1)\r\nIn file included from external/com_github_googlecloudplatform_google_cloud_cpp/google/cloud/bigtable/row_reader.h:22:0,\r\n                 from external/com_github_googlecloudplatform_google_cloud_cpp/google/cloud/bigtable/internal/table.h:25,\r\n                 from external/com_github_googlecloudplatform_google_cloud_cpp/google/cloud/bigtable/table.h:19,\r\n                 from external/com_github_googlecloudplatform_google_cloud_cpp/google/cloud/bigtable/table.cc:15:\r\nexternal/com_github_googlecloudplatform_google_cloud_cpp/google/cloud/bigtable/internal/rowreaderiterator.h: In member function 'const google::cloud::bigtable::v0::Row&& google::cloud::bigtable::v0::internal::RowReaderIterator::operator*() const &&':\r\nexternal/com_github_googlecloudplatform_google_cloud_cpp/google/cloud/bigtable/internal/rowreaderiterator.h:57:44: error: ambiguous overload for 'operator*' (operand type is 'std::remove_reference<const google::cloud::v0::internal::optional<google::cloud::bigtable::v0::Row>&>::type {aka const google::cloud::v0::internal::optional<google::cloud::bigtable::v0::Row>}')\r\n   Row const&& operator*() const&& { return *std::move(row_); }\r\n                                            ^\r\nexternal/com_github_googlecloudplatform_google_cloud_cpp/google/cloud/bigtable/internal/rowreaderiterator.h:57:44: note: candidates are:\r\nIn file included from external/com_github_googlecloudplatform_google_cloud_cpp/google/cloud/bigtable/internal/rowreaderiterator.h:19:0,\r\n                 from external/com_github_googlecloudplatform_google_cloud_cpp/google/cloud/bigtable/row_reader.h:22,\r\n                 from external/com_github_googlecloudplatform_google_cloud_cpp/google/cloud/bigtable/internal/table.h:25,\r\n                 from external/com_github_googlecloudplatform_google_cloud_cpp/google/cloud/bigtable/table.h:19,\r\n                 from external/com_github_googlecloudplatform_google_cloud_cpp/google/cloud/bigtable/table.cc:15:\r\nexternal/com_github_googlecloudplatform_google_cloud_cpp/google/cloud/internal/optional.h:121:22: note: constexpr const T& google::cloud::v0::internal::optional<T>::operator*() const & [with T = google::cloud::bigtable::v0::Row]\r\n   constexpr T const& operator*() const& {\r\n                      ^\r\nexternal/com_github_googlecloudplatform_google_cloud_cpp/google/cloud/internal/optional.h:126:23: note: constexpr const T&& google::cloud::v0::internal::optional<T>::operator*() const && [with T = google::cloud::bigtable::v0::Row]\r\n   constexpr T const&& operator*() const&& {\r\n                       ^\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 103.567s, Critical Path: 73.97s\r\nFAILED: Build did NOT complete successfully\r\n ", "@zjfheart  - Glad to see you made it past the boringssl errors. This failure building the google cloud platform looks like it was resolved with this commit: https://github.com/tensorflow/tensorflow/commit/82d122cd1efc905070ed86ed55951b7437209523\r\n\r\nCan you verify that file change is in your environment ?", "@wdirons \r\n\r\nI remove old tensorflow folder and git clone it again. Cherry pick the fix again. \r\n\r\nInstallation works well, but verification fails. \r\n\r\n[root@Jingfeng_redhat tensorflow]# bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n... ...\r\nTarget //tensorflow/tools/pip_package:build_pip_package up-to-date:\r\nbazel-bin/tensorflow/tools/pip_package/build_pip_package\r\nINFO: Elapsed time: 916.321s, Critical Path: 539.31s\r\nINFO: 7813 processes: 7813 local.\r\nINFO: Build completed successfully, 10232 total actions\r\n\r\n\r\nHere is the part of info in the ~/tensorflow/tensorflow/workspace.bzl\r\n\r\n```\r\ntf_http_archive(\r\n      name = \"com_googlesource_code_re2\",\r\n      urls = [\r\n          \"https://mirror.bazel.build/github.com/google/re2/archive/2018-04-01.tar.gz\",\r\n          \"https://github.com/google/re2/archive/2018-04-01.tar.gz\",\r\n\r\n      ],\r\n      sha256 = \"2f945446b71336e7f5a2bcace1abcf0b23fbba368266c6a1be33de3de3b3c912\",\r\n      strip_prefix = \"re2-2018-04-01\",\r\n      system_build_file = clean_dep(\"//third_party/systemlibs:re2.BUILD\"),\r\n  )\r\n\r\n  tf_http_archive(\r\n      name = \"com_github_googlecloudplatform_google_cloud_cpp\",\r\n      urls = [\r\n          \"https://mirror.bazel.build/github.com/GoogleCloudPlatform/google-cloud-cpp/archive/f875700a023bdd706333cde45aee8758b272c357.tar.gz\",\r\n          \"https://github.com/GoogleCloudPlatform/google-cloud-cpp/archive/f875700a023bdd706333cde45aee8758b272c357.tar.gz\",\r\n      ],\r\n      sha256 = \"a34f3c50b237686dc870b13baaa6a5836ce3473f2f2a02717299f0ff318372db\",\r\n      strip_prefix = \"google-cloud-cpp-f875700a023bdd706333cde45aee8758b272c357\",\r\n  )\r\n\r\n  tf_http_archive(\r\n      name = \"com_github_googleapis_googleapis\",\r\n      urls = [\r\n          \"https://mirror.bazel.build/github.com/googleapis/googleapis/archive/f81082ea1e2f85c43649bee26e0d9871d4b41cdb.zip\",\r\n          \"https://github.com/googleapis/googleapis/archive/f81082ea1e2f85c43649bee26e0d9871d4b41cdb.zip\",\r\n      ],\r\n      sha256 = \"824870d87a176f26bcef663e92051f532fac756d1a06b404055dc078425f4378\",\r\n      strip_prefix=\"googleapis-f81082ea1e2f85c43649bee26e0d9871d4b41cdb\",\r\n      build_file = clean_dep(\"//third_party:googleapis.BUILD\"),\r\n  )\r\n```\r\n\r\nI continue with \r\nbazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/tensorflow_pkg\r\npip install /tmp/tensorflow_pkg/tensorflow-1.9.0rc0-cp34-cp34m-linux_ppc64le.whl\r\n\r\nBut after installation, there is another problem: I've managed to get a TF distribution with nothing in it. \r\n[jingfeng@Jingfeng_redhat ~]$ python3.4\r\n```\r\n>>> import tensorflow as tf\r\n>>> var = tf.Variable(100, name=\"variable_counter\")\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nAttributeError: 'module' object has no attribute 'Variable'\r\n>>> dir(tf)\r\n['__doc__', '__loader__', '__name__', '__package__', '__path__', '__spec__']\r\n```\r\n\r\n", "@zjfheart , was there any errors running pip install? On my system I have to use 'pip3' install to install into the python3.4 site-packages directory. It would be good to see the output of pip3 install in case any errors occurred. \r\n\r\n```\r\n[root@19c4b8726925 tensorflow_pkg]# pip3 install tensorflow-1.9.0rc0-cp34-cp34m-linux_ppc64le.whl\r\nProcessing ./tensorflow-1.9.0rc0-cp34-cp34m-linux_ppc64le.whl\r\nCollecting tensorboard<1.9.0,>=1.8.0 (from tensorflow==1.9.0rc0)\r\n  Downloading https://files.pythonhosted.org/packages/59/a6/0ae6092b7542cfedba6b2a1c9b8dceaf278238c39484f3ba03b03f07803c/tensorboard-1.8.0-py3-none-any.whl (3.1MB)\r\n    100% |################################| 3.1MB 365kB/s\r\nCollecting astor>=0.6.0 (from tensorflow==1.9.0rc0)\r\n  Downloading https://files.pythonhosted.org/packages/35/6b/11530768cac581a12952a2aad00e1526b89d242d0b9f59534ef6e6a1752f/astor-0.7.1-py2.py3-none-any.whl\r\nCollecting gast>=0.2.0 (from tensorflow==1.9.0rc0)\r\n  Downloading https://files.pythonhosted.org/packages/5c/78/ff794fcae2ce8aa6323e789d1f8b3b7765f601e7702726f430e814822b96/gast-0.2.0.tar.gz\r\nCollecting termcolor>=1.1.0 (from tensorflow==1.9.0rc0)\r\n  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\r\nCollecting absl-py>=0.1.6 (from tensorflow==1.9.0rc0)\r\n  Downloading https://files.pythonhosted.org/packages/57/8d/6664518f9b6ced0aa41cf50b989740909261d4c212557400c48e5cda0804/absl-py-0.2.2.tar.gz (82kB)\r\n    100% |################################| 92kB 4.9MB/s\r\nCollecting grpcio>=1.8.6 (from tensorflow==1.9.0rc0)\r\n  Downloading https://files.pythonhosted.org/packages/e6/27/1f138a6f8691b8d1c1a4f2005f9293da6641c806d5626eb6c43e765962b1/grpcio-1.13.0.tar.gz (14.3MB)\r\n    100% |################################| 14.3MB 84kB/s\r\nCollecting protobuf>=3.6.0 (from tensorflow==1.9.0rc0)\r\n  Downloading https://files.pythonhosted.org/packages/85/f8/d09e4bf21c4de65405ce053e90542e728c5b7cf296b9df36b0bf0488f534/protobuf-3.6.0-py2.py3-none-any.whl (390kB)\r\n    100% |################################| 399kB 2.7MB/s\r\nCollecting numpy>=1.13.3 (from tensorflow==1.9.0rc0)\r\n  Downloading https://files.pythonhosted.org/packages/d5/6e/f00492653d0fdf6497a181a1c1d46bbea5a2383e7faf4c8ca6d6f3d2581d/numpy-1.14.5.zip (4.9MB)\r\n    100% |################################| 4.9MB 250kB/s\r\nCollecting six>=1.10.0 (from tensorflow==1.9.0rc0)\r\n  Downloading https://files.pythonhosted.org/packages/67/4b/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a/six-1.11.0-py2.py3-none-any.whl\r\nRequirement already satisfied (use --upgrade to upgrade): wheel>=0.26 in /usr/lib/python3.4/site-packages (from tensorflow==1.9.0rc0)\r\nRequirement already satisfied (use --upgrade to upgrade): setuptools<=39.1.0 in /usr/lib/python3.4/site-packages (from tensorflow==1.9.0rc0)\r\nCollecting bleach==1.5.0 (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.9.0rc0)\r\n  Downloading https://files.pythonhosted.org/packages/33/70/86c5fec937ea4964184d4d6c4f0b9551564f821e1c3575907639036d9b90/bleach-1.5.0-py2.py3-none-any.whl\r\nCollecting werkzeug>=0.11.10 (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.9.0rc0)\r\n  Downloading https://files.pythonhosted.org/packages/20/c4/12e3e56473e52375aa29c4764e70d1b8f3efa6682bef8d0aae04fe335243/Werkzeug-0.14.1-py2.py3-none-any.whl (322kB)\r\n    100% |################################| 327kB 3.3MB/s\r\nCollecting html5lib==0.9999999 (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.9.0rc0)\r\n  Downloading https://files.pythonhosted.org/packages/ae/ae/bcb60402c60932b32dfaf19bb53870b29eda2cd17551ba5639219fb5ebf9/html5lib-0.9999999.tar.gz (889kB)\r\n    100% |################################| 890kB 1.3MB/s\r\nCollecting markdown>=2.6.8 (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.9.0rc0)\r\n  Downloading https://files.pythonhosted.org/packages/6d/7d/488b90f470b96531a3f5788cf12a93332f543dbab13c423a5e7ce96a0493/Markdown-2.6.11-py2.py3-none-any.whl (78kB)\r\n    100% |################################| 81kB 9.9MB/s\r\nBuilding wheels for collected packages: gast, termcolor, absl-py, grpcio, numpy, html5lib\r\n  Running setup.py bdist_wheel for gast ... done\r\n  Stored in directory: /root/.cache/pip/wheels/9a/1f/0e/3cde98113222b853e98fc0a8e9924480a3e25f1b4008cedb4f\r\n  Running setup.py bdist_wheel for termcolor ... done\r\n  Stored in directory: /root/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\r\n  Running setup.py bdist_wheel for absl-py ... done\r\n  Stored in directory: /root/.cache/pip/wheels/a0/f8/e9/1933dbb3447ea6ef57062fd5461cb118deb8c2ed074e8344bf\r\n  Running setup.py bdist_wheel for grpcio ... done\r\n  Stored in directory: /root/.cache/pip/wheels/de/c8/4e/45b155e462290b725a21364baa4396a1b1c48e4e84be033cd8\r\n  Running setup.py bdist_wheel for numpy ... done\r\n  Stored in directory: /root/.cache/pip/wheels/8e/6f/1c/e089e6eef4d32bdd8a9ab9dfed2da700ebd383c3eb28a37b7d\r\n  Running setup.py bdist_wheel for html5lib ... done\r\n  Stored in directory: /root/.cache/pip/wheels/50/ae/f9/d2b189788efcf61d1ee0e36045476735c838898eef1cad6e29\r\nSuccessfully built gast termcolor absl-py grpcio numpy html5lib\r\nInstalling collected packages: numpy, six, protobuf, html5lib, bleach, werkzeug, markdown, tensorboard, astor, gast, termcolor, absl-py, grpcio, tensorflow\r\n  Found existing installation: numpy 1.10.4\r\n    DEPRECATION: Uninstalling a distutils installed project (numpy) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project.\r\n    Uninstalling numpy-1.10.4:\r\n      Successfully uninstalled numpy-1.10.4\r\nSuccessfully installed absl-py-0.2.2 astor-0.7.1 bleach-1.5.0 gast-0.2.0 grpcio-1.13.0 html5lib-0.9999999 markdown-2.6.11 numpy-1.14.5 protobuf-3.6.0 six-1.11.0 tensorboard-1.8.0 tensorflow-1.9.0rc0 termcolor-1.1.0 werkzeug-0.14.1\r\nYou are using pip version 8.1.2, however version 10.0.1 is available.\r\nYou should consider upgrading via the 'pip install --upgrade pip' command.\r\n[root@19c4b8726925 tensorflow_pkg]# python3.4\r\nPython 3.4.8 (default, Mar 23 2018, 10:06:54)\r\n[GCC 4.8.5 20150623 (Red Hat 4.8.5-16)] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> var = tf.Variable(100, name=\"variable_counter\")\r\n>>> dir(tf)\r\n['AUTO_REUSE', 'AggregationMethod', 'Assert', 'AttrValue', 'COMPILER_VERSION', 'CXX11_ABI_FLAG', 'ConditionalAccumulator', 'ConditionalAccumulatorBase', 'ConfigProto', 'DType', 'DeviceSpec', 'Dimension', 'Event', 'FIFOQueue', 'FixedLenFeature', 'FixedLenSequenceFeature', 'FixedLengthRecordReader', 'GIT_VERSION', 'GPUOptions', 'GRAPH_DEF_VERSION', 'GRAPH_DEF_VERSION_MIN_CONSUMER', 'GRAPH_DEF_VERSION_MIN_PRODUCER', 'GradientTape', 'Graph', 'GraphDef', 'GraphKeys', 'GraphOptions', 'HistogramProto', 'IdentityReader', 'IndexedSlices', 'InteractiveSession', 'LMDBReader', 'LogMessage', 'MONOLITHIC_BUILD', 'MetaGraphDef', 'NameAttrList', 'NoGradient', 'NodeDef', 'NotDifferentiable', 'OpError', 'Operation', 'OptimizerOptions', 'PaddingFIFOQueue', 'Print', 'PriorityQueue', 'QUANTIZED_DTYPES', 'QueueBase', 'RandomShuffleQueue', 'ReaderBase', 'RegisterGradient', 'RunMetadata', 'RunOptions', 'Session', 'SessionLog', 'SparseConditionalAccumulator', 'SparseFeature', 'SparseTensor', 'SparseTensorValue', 'Summary', 'SummaryMetadata', 'TFRecordReader', 'Tensor', 'TensorArray', 'TensorInfo', 'TensorShape', 'TextLineReader', 'VERSION', 'VarLenFeature', 'Variable', 'VariableAggregation', 'VariableScope', 'VariableSynchronization', 'WholeFileReader', '__all__', '__builtins__', '__cached__', '__compiler_version__', '__cxx11_abi_flag__', '__doc__', '__file__', '__git_version__', '__loader__', '__monolithic_build__', '__name__', '__package__', '__path__', '__spec__', '__version__', '_names_with_underscore', 'abs', 'accumulate_n', 'acos', 'acosh', 'add', 'add_check_numerics_ops', 'add_n', 'add_to_collection', 'add_to_collections', 'all_variables', 'angle', 'app', 'arg_max', 'arg_min', 'argmax', 'argmin', 'as_dtype', 'as_string', 'asin', 'asinh', 'assert_equal', 'assert_greater', 'assert_greater_equal', 'assert_integer', 'assert_less', 'assert_less_equal', 'assert_near', 'assert_negative', 'assert_non_negative', 'assert_non_positive', 'assert_none_equal', 'assert_positive', 'assert_proper_iterable', 'assert_rank', 'assert_rank_at_least', 'assert_rank_in', 'assert_same_float_dtype', 'assert_scalar', 'assert_type', 'assert_variables_initialized', 'assign', 'assign_add', 'assign_sub', 'atan', 'atan2', 'atanh', 'batch_to_space', 'batch_to_space_nd', 'betainc', 'bfloat16', 'bincount', 'bitcast', 'bitwise', 'bool', 'boolean_mask', 'broadcast_dynamic_shape', 'broadcast_static_shape', 'broadcast_to', 'case', 'cast', 'ceil', 'check_numerics', 'cholesky', 'cholesky_solve', 'clip_by_average_norm', 'clip_by_global_norm', 'clip_by_norm', 'clip_by_value', 'colocate_with', 'compat', 'complex', 'complex128', 'complex64', 'concat', 'cond', 'confusion_matrix', 'conj', 'constant', 'constant_initializer', 'container', 'contrib', 'control_dependencies', 'convert_to_tensor', 'convert_to_tensor_or_indexed_slices', 'convert_to_tensor_or_sparse_tensor', 'cos', 'cosh', 'count_nonzero', 'count_up_to', 'create_partitioned_variables', 'cross', 'cumprod', 'cumsum', 'custom_gradient', 'data', 'debugging', 'decode_base64', 'decode_compressed', 'decode_csv', 'decode_json_example', 'decode_raw', 'delete_session_tensor', 'depth_to_space', 'dequantize', 'deserialize_many_sparse', 'device', 'diag', 'diag_part', 'digamma', 'distributions', 'div', 'divide', 'double', 'dtypes', 'dynamic_partition', 'dynamic_stitch', 'edit_distance', 'einsum', 'enable_eager_execution', 'encode_base64', 'equal', 'erf', 'erfc', 'errors', 'estimator', 'executing_eagerly', 'exp', 'expand_dims', 'expm1', 'extract_image_patches', 'eye', 'fake_quant_with_min_max_args', 'fake_quant_with_min_max_args_gradient', 'fake_quant_with_min_max_vars', 'fake_quant_with_min_max_vars_gradient', 'fake_quant_with_min_max_vars_per_channel', 'fake_quant_with_min_max_vars_per_channel_gradient', 'feature_column', 'fft', 'fft2d', 'fft3d', 'fill', 'fixed_size_partitioner', 'flags', 'float16', 'float32', 'float64', 'floor', 'floor_div', 'floordiv', 'floormod', 'foldl', 'foldr', 'gather', 'gather_nd', 'get_collection', 'get_collection_ref', 'get_default_graph', 'get_default_session', 'get_local_variable', 'get_seed', 'get_session_handle', 'get_session_tensor', 'get_variable', 'get_variable_scope', 'gfile', 'global_norm', 'global_variables', 'global_variables_initializer', 'glorot_normal_initializer', 'glorot_uniform_initializer', 'gradients', 'graph_util', 'greater', 'greater_equal', 'group', 'guarantee_const', 'half', 'hessians', 'histogram_fixed_width', 'histogram_fixed_width_bins', 'identity', 'identity_n', 'ifft', 'ifft2d', 'ifft3d', 'igamma', 'igammac', 'imag', 'image', 'import_graph_def', 'initialize_all_tables', 'initialize_all_variables', 'initialize_local_variables', 'initialize_variables', 'initializers', 'int16', 'int32', 'int64', 'int8', 'invert_permutation', 'io', 'is_finite', 'is_inf', 'is_nan', 'is_non_decreasing', 'is_numeric_tensor', 'is_strictly_increasing', 'is_variable_initialized', 'keras', 'layers', 'lbeta', 'less', 'less_equal', 'lgamma', 'lin_space', 'linalg', 'linspace', 'load_file_system_library', 'load_op_library', 'local_variables', 'local_variables_initializer', 'log', 'log1p', 'log_sigmoid', 'logging', 'logical_and', 'logical_not', 'logical_or', 'logical_xor', 'losses', 'make_ndarray', 'make_template', 'make_tensor_proto', 'manip', 'map_fn', 'matching_files', 'math', 'matmul', 'matrix_band_part', 'matrix_determinant', 'matrix_diag', 'matrix_diag_part', 'matrix_inverse', 'matrix_set_diag', 'matrix_solve', 'matrix_solve_ls', 'matrix_transpose', 'matrix_triangular_solve', 'maximum', 'meshgrid', 'metrics', 'min_max_variable_partitioner', 'minimum', 'mod', 'model_variables', 'moving_average_variables', 'multinomial', 'multiply', 'name_scope', 'negative', 'newaxis', 'nn', 'no_op', 'no_regularizer', 'norm', 'not_equal', 'one_hot', 'ones', 'ones_initializer', 'ones_like', 'op_scope', 'orthogonal_initializer', 'pad', 'parallel_stack', 'parse_example', 'parse_single_example', 'parse_single_sequence_example', 'parse_tensor', 'placeholder', 'placeholder_with_default', 'polygamma', 'pow', 'profiler', 'py_func', 'python_io', 'pywrap_tensorflow', 'qint16', 'qint32', 'qint8', 'qr', 'quantization', 'quantize', 'quantize_v2', 'quantized_concat', 'quint16', 'quint8', 'random_crop', 'random_gamma', 'random_normal', 'random_normal_initializer', 'random_poisson', 'random_shuffle', 'random_uniform', 'random_uniform_initializer', 'range', 'rank', 'read_file', 'real', 'realdiv', 'reciprocal', 'reduce_all', 'reduce_any', 'reduce_join', 'reduce_logsumexp', 'reduce_max', 'reduce_mean', 'reduce_min', 'reduce_prod', 'reduce_sum', 'regex_replace', 'register_tensor_conversion_function', 'report_uninitialized_variables', 'required_space_to_batch_paddings', 'reset_default_graph', 'reshape', 'resource', 'resource_loader', 'reverse', 'reverse_sequence', 'reverse_v2', 'rint', 'round', 'rsqrt', 'saturate_cast', 'saved_model', 'scalar_mul', 'scan', 'scatter_add', 'scatter_div', 'scatter_max', 'scatter_min', 'scatter_mul', 'scatter_nd', 'scatter_nd_add', 'scatter_nd_sub', 'scatter_nd_update', 'scatter_sub', 'scatter_update', 'segment_max', 'segment_mean', 'segment_min', 'segment_prod', 'segment_sum', 'self_adjoint_eig', 'self_adjoint_eigvals', 'sequence_mask', 'serialize_many_sparse', 'serialize_sparse', 'serialize_tensor', 'set_random_seed', 'setdiff1d', 'sets', 'shape', 'shape_n', 'sigmoid', 'sign', 'sin', 'sinh', 'size', 'slice', 'space_to_batch', 'space_to_batch_nd', 'space_to_depth', 'sparse', 'sparse_add', 'sparse_concat', 'sparse_fill_empty_rows', 'sparse_mask', 'sparse_matmul', 'sparse_maximum', 'sparse_merge', 'sparse_minimum', 'sparse_placeholder', 'sparse_reduce_max', 'sparse_reduce_max_sparse', 'sparse_reduce_sum', 'sparse_reduce_sum_sparse', 'sparse_reorder', 'sparse_reset_shape', 'sparse_reshape', 'sparse_retain', 'sparse_segment_mean', 'sparse_segment_sqrt_n', 'sparse_segment_sum', 'sparse_slice', 'sparse_softmax', 'sparse_split', 'sparse_tensor_dense_matmul', 'sparse_tensor_to_dense', 'sparse_to_dense', 'sparse_to_indicator', 'sparse_transpose', 'spectral', 'split', 'sqrt', 'square', 'squared_difference', 'squeeze', 'stack', 'stop_gradient', 'strided_slice', 'string', 'string_join', 'string_split', 'string_strip', 'string_to_hash_bucket', 'string_to_hash_bucket_fast', 'string_to_hash_bucket_strong', 'string_to_number', 'strings', 'substr', 'subtract', 'summary', 'svd', 'sysconfig', 'tables_initializer', 'tan', 'tanh', 'tensordot', 'test', 'tile', 'timestamp', 'to_bfloat16', 'to_complex128', 'to_complex64', 'to_double', 'to_float', 'to_int32', 'to_int64', 'trace', 'train', 'trainable_variables', 'transpose', 'truediv', 'truncated_normal', 'truncated_normal_initializer', 'truncatediv', 'truncatemod', 'tuple', 'uint16', 'uint32', 'uint64', 'uint8', 'uniform_unit_scaling_initializer', 'unique', 'unique_with_counts', 'unravel_index', 'unsorted_segment_max', 'unsorted_segment_mean', 'unsorted_segment_min', 'unsorted_segment_prod', 'unsorted_segment_sqrt_n', 'unsorted_segment_sum', 'unstack', 'user_ops', 'variable_axis_size_partitioner', 'variable_op_scope', 'variable_scope', 'variables_initializer', 'variance_scaling_initializer', 'variant', 'verify_tensor_all_finite', 'where', 'while_loop', 'write_file', 'zeros', 'zeros_initializer', 'zeros_like', 'zeta']\r\n>>>\r\n```\r\n", "Hi @wdirons \r\nI think I my system the pip and pip3 is the same. \r\n\r\n```\r\n[root@Jingfeng_redhat ~]# which pip\r\n/usr/bin/pip\r\n[root@Jingfeng_redhat ~]# pip --version\r\npip 10.0.1 from /usr/lib/python3.4/site-packages/pip (python 3.4)\r\n[root@Jingfeng_redhat ~]# which pip3\r\n/usr/bin/pip3\r\n[root@Jingfeng_redhat ~]# pip3 --version\r\npip 10.0.1 from /usr/lib/python3.4/site-packages/pip (python 3.4)\r\n```\r\n\r\nI install the same whl from pip3, but it cannot installed it into python3.4 site-packages directory\r\n\r\n```\r\n[root@Jingfeng_redhat ~]# cd /tmp/tensorflow_pkg\r\n[root@Jingfeng_redhat tensorflow_pkg]# ls\r\ntensorflow-1.9.0rc0-cp34-cp34m-linux_ppc64le.whl\r\n[root@Jingfeng_redhat tensorflow_pkg]# pip3 install tensorflow-1.9.0rc0-cp34-cp34m-linux_ppc64le.whl \r\nProcessing ./tensorflow-1.9.0rc0-cp34-cp34m-linux_ppc64le.whl\r\nRequirement already satisfied: six>=1.10.0 in /usr/lib/python3.4/site-packages (from tensorflow==1.9.0rc0) (1.11.0)\r\nCollecting absl-py>=0.1.6 (from tensorflow==1.9.0rc0)\r\nRequirement already satisfied: grpcio>=1.8.6 in /usr/lib64/python3.4/site-packages (from tensorflow==1.9.0rc0) (1.13.0)\r\nCollecting astor>=0.6.0 (from tensorflow==1.9.0rc0)\r\n  Using cached https://files.pythonhosted.org/packages/35/6b/11530768cac581a12952a2aad00e1526b89d242d0b9f59534ef6e6a1752f/astor-0.7.1-py2.py3-none-any.whl\r\nRequirement already satisfied: wheel>=0.26 in /usr/lib/python3.4/site-packages (from tensorflow==1.9.0rc0) (0.31.1)\r\nRequirement already satisfied: protobuf>=3.6.0 in /usr/lib/python3.4/site-packages (from tensorflow==1.9.0rc0) (3.6.0)\r\nCollecting numpy>=1.13.3 (from tensorflow==1.9.0rc0)\r\nRequirement already satisfied: termcolor>=1.1.0 in /usr/lib/python3.4/site-packages (from tensorflow==1.9.0rc0) (1.1.0)\r\nRequirement already satisfied: setuptools<=39.1.0 in /usr/lib/python3.4/site-packages (from tensorflow==1.9.0rc0) (19.6.2)\r\nRequirement already satisfied: gast>=0.2.0 in /usr/lib/python3.4/site-packages (from tensorflow==1.9.0rc0) (0.2.0)\r\nCollecting tensorboard<1.9.0,>=1.8.0 (from tensorflow==1.9.0rc0)\r\n  Using cached https://files.pythonhosted.org/packages/59/a6/0ae6092b7542cfedba6b2a1c9b8dceaf278238c39484f3ba03b03f07803c/tensorboard-1.8.0-py3-none-any.whl\r\nRequirement already satisfied: markdown>=2.6.8 in /usr/lib64/python3.4/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.9.0rc0) (2.6.11)\r\nRequirement already satisfied: bleach==1.5.0 in /usr/lib/python3.4/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.9.0rc0) (1.5.0)\r\nRequirement already satisfied: werkzeug>=0.11.10 in /usr/lib64/python3.4/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.9.0rc0) (0.14.1)\r\nRequirement already satisfied: html5lib==0.9999999 in /usr/lib/python3.4/site-packages (from tensorboard<1.9.0,>=1.8.0->tensorflow==1.9.0rc0) (0.9999999)\r\nnotebook 5.5.0 has requirement jupyter-core>=4.4.0, but you'll have jupyter-core 4.3.0 which is incompatible.\r\nInstalling collected packages: absl-py, astor, numpy, tensorboard, tensorflow\r\n  Found existing installation: numpy 1.10.4\r\nCannot uninstall 'numpy'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\r\n[root@Jingfeng_redhat tensorflow_pkg]# python3.4\r\nPython 3.4.8 (default, Mar 23 2018, 10:06:54) \r\n[GCC 4.8.5 20150623 (Red Hat 4.8.5-16)] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nImportError: No module named 'tensorflow'\r\n>>> \r\n\r\n```\r\n\r\n\r\nFor above problem: \r\n\r\nI need to firstly yum erase numpy\r\n`yum erase python34-numpy-f2py python34-numpy`\r\n`pip3 install tensorflow-1.9.0rc0-cp34-cp34m-linux_ppc64le.whl `\r\n\r\nThen problem solved! \r\n\r\nThanks again for this help @wdirons ", "Hey all, I am getting similar errors for aarch64 tensorflow 1.14.0 . Any tips?"]}, {"number": 20676, "title": "FLAGS,what's mean in the code?", "body": "I could't understand the mean ''FLAGS\" in the code,just like in your code:\r\n\r\n\r\n`with tf.name_scope('train'):\r\n  train_step = tf.train.AdamOptimizer(FLAGS.learning_rate).minimize(\r\n      cross_entropy)\r\n\r\nwith tf.name_scope('accuracy'):\r\n  with tf.name_scope('correct_prediction'):\r\n    correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\r\n  with tf.name_scope('accuracy'):\r\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\r\ntf.summary.scalar('accuracy', accuracy)\r\n\r\n# Merge all the summaries and write them out to /tmp/mnist_logs (by default)\r\nmerged = tf.summary.merge_all()\r\ntrain_writer = tf.summary.FileWriter(FLAGS.summaries_dir + '/train',\r\n                                      sess.graph)\r\ntest_writer = tf.summary.FileWriter(FLAGS.summaries_dir + '/test')`\r\n\r\n\r\nFLAGS is None by default, so what's the  mean of FLAGS.learning_rate,FLAGS.summaries_dir?\r\nor could you give me a example about the dir?", "comments": ["normally you will see code like ` tf.app.flags.DEFINE_string(...)` which defines some paras before training the model. Consider FLAGS as wrapperd  argparse in tensorflow.\r\nRefer to [1] & [2] for more information.\r\n[1] https://stackoverflow.com/questions/33932901/whats-the-purpose-of-tf-app-flags-in-tensorflow\r\n[2] https://github.com/abseil/abseil-py", "Thanks so much ,I got it~\n\n2018-07-11 11:25:51lexee <notifications@github.com>\u5199\u9053\uff1a\n\nnormally you will see code like tf.app.flags.DEFINE_string(...) which defines some paras before training the model. Consider FLAGS as wrapperd argparse in tensorflow.\nRefer to [1] & [2] for more information.\n[1] https://stackoverflow.com/questions/33932901/whats-the-purpose-of-tf-app-flags-in-tensorflow\n[2] https://github.com/abseil/abseil-py\n\n\u2014\nYou are receiving this because you authored the thread.\nReply to this email directly, view it on GitHub, or mute the thread."]}, {"number": 20675, "title": "rename interfaces in StreamInterface and StreamExecutorInterface to support both CUDA and ROCm", "body": "In this pull request, 2 interface changes are proposed:\r\n\r\n    1) StreamInterface::CudaStreamMemberHack()\r\n\r\n    Despite the fact that StreamExecutor and GPU common runtime are largely\r\n    orthogonal, this particular routine in StreamExecutor is used in GPU common\r\n    runtime and a couple of other operators. In this commit it's renamed as\r\n    StreamInterface::GpuStreamMemberHack() and their call sites are also changed.\r\n\r\n    2) StreamExecutorInterface::CudaContextHack()\r\n\r\n    This member is renamed to StramExecutorInterface::GpuContextHack().\r\n\r\n    Changes introduced in this commit includes:\r\n\r\n    - some StreamExecutor interfaces and CUDA implementation\r\n    - GPU common runtime related to interface changes in StreamExecutor\r\n    - operators affected by interface changes in StreamExecutor\r\n ", "comments": ["/cc @jlebar ", "BTW, this looks remarkably good to me on a first (very superficial) glance.", "@jlebar Thanks. I'll split up this PR into smaller chunks. Actually I make sure nothing breaks on either CUDA or ROCm before I submit PRs.\r\n\r\nBut in order to easily review the changes proposed here, I'll break this PR into following pieces:\r\n\r\n1) interface changes for `StreamInterface::CudaStreamMemberHack()`\r\n2) interface changes for pooling\r\n3) barebone ROCm StreamExecutor implementation, after clang-format\r\n4) BLAS logic\r\n5) FFT logic\r\n6) DNN logic", ">> I suspect things are going to break in exciting ways when we try to check this in\r\n\r\n> Actually I make sure nothing breaks on either CUDA or ROCm before I submit PRs.\r\n\r\nI should have specified: What I was thinking about is checking this code in to \"upstream\" google.  This is  fundamental code used not only by TensorFlow, and we're probably going to have to modify some internal classes based on these API changes.  So smaller pieces are going to be a lot easier to land.", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_author_cla -->", "CLAs look good, thanks!\n\n<!-- ok -->", "@jlebar I've updated this PR so it's minimal now (32 lines). Would you mind to take a look at it again? Thanks a lot. I'll continue file subsequent PRs to cover other parts of StreamExecutor for ROCm platform.", "LGTM.  Would you mind updating the PR title to match the new description here?", "Thanks. Updated PR title according to match description.", "Hi Wen-Heng. Would you maybe mind to change to change 'GPUStreamMemberHack' to 'GpuStreamMemberHack'? We generally capitalize acronyms as single words. Thanks!", "@chsigg Revised to `GpuStreamMemberHack` now", "ping. @jlebar / @chsigg ", "@qlzh727 It seems the failing test has nothing to do with this PR. Would it be possible to force re-run the test?", "Oh, its fine. We have changed our sync process, all the changes will be port to our internal system and test again there. The test here is just some early indicator before we port the change.", "I'm in the process of merging this change internally; I just need a few more people to approve it."]}, {"number": 20674, "title": "Tensorflow 1.8.0 cpu fails on import on Windows 10 used through SQL Server 2017", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No.  import tensorflow as tf\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10 x64 on SQL Server 2017\r\n- **TensorFlow installed from (source or binary)**: Binary - pip install N:\\Packages\\Python\\tensorflow-1.8.0-cp35-cp35m-win_amd64.whl -f ./ --no-index\r\n- **TensorFlow version (use command below)**: 1.8.0\r\n- **Python version**: 3.5\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**:  import tensorflow as tf\r\n\r\nrunning through sql the full code is:\r\n\r\nEXECUTE sp_execute_external_script\r\n@language=N'Python',\r\n@script = N'\r\nimport tensorflow as tf\r\n'\r\n\r\n\r\n\r\n### Describe the problem\r\nAll dependencies for tensorflow 1.8.0 are installed.\r\nInstallation through pip ends with \"Successfully installed tensorflow-1.8.0\"\r\n\r\nAttempting to import tensorflow fails with:\r\nMsg 39019, Level 16, State 2, Line 7\r\nAn external script error occurred: \r\nFailed to load the native TensorFlow runtime.\r\n\r\nFull error report below.\r\n\r\n\r\nI have checked that MSVCP140.DLL exists in System32 and in SysWOW64.\r\nI don't know how to check for an AVX issue or to bypass it.\r\n\r\n\r\n\r\n### Source code / logs\r\nTraceback (most recent call last):\r\n  File \"D:\\MSSQL14.MSSQLSERVER\\PYTHON_SERVICES\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 14, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"D:\\MSSQL14.MSSQLSERVER\\PYTHON_SERVICES\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 906, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\n\r\nMsg 39019, Level 16, State 2, Line 7\r\nAn external script error occurred: \r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\MSSQL14.MSSQLSERVER\\PYTHON_SERVICES\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"D:\\MSSQL14.MSSQLSERVER\\PYTHON_SERVICES\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 17, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"D:\\MSSQL14.MSSQLSERVER\\PYTHON_SERVICES\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 16, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"D:\\MSSQL14.MSSQLSERVER\\PYTHON_SERVICES\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n\r\nMsg 39019, Level 16, State 2, Line 7\r\nAn external script error occurred: \r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 5, in <module>\r\n  File \"D:\\MSSQL14.MSSQLSERVER\\MSSQL\\ExtensibilityData\\MSSQLSERVER01\\EA86FFCC-FD02-4E32-B3CB-E9AF5CE7CC5F\\sqlindb.py\", line 31, in transform\r\n    import tensorflow as tf\r\n  File \"D:\\MSSQL14.MSSQLSERVER\\PYTHON_SERVICES\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"D:\\MSSQL14.MSSQLSERVER\\PYTHON_SERVICES\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"D:\\MSSQL14.MSSQLSERVER\\PYTHON_SERVICES\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n\r\nMsg 39019, Level 16, State 2, Line 7\r\nAn external script error occurred: \r\n  File \"D:\\MSSQL14.MSSQLSERVER\\PYTHON_SERVICES\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 14, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"D:\\MSSQL14.MSSQLSERVER\\PYTHON_SERVICES\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 906, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\n\r\nMsg 39019, Level 16, State 2, Line 7\r\nAn external script error occurred: \r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\MSSQL14.MSSQLSERVER\\PYTHON_SERVICES\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"D:\\MSSQL14.MSSQLSERVER\\PYTHON_SERVICES\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 17, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"D:\\MSSQL14.MSSQLSERVER\\PYTHON_SERVICES\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 16, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"D:\\MSSQL14.MSSQLSERVER\\PYTHON_SERVICES\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\n\r\n\r\nMsg 39019, Level 16, State 2, Line 7\r\nAn external script error occurred: \r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n", "comments": ["Could you share your CPU model?\r\nThis can be a duplicate of #19584", "It is a windows server 2016 datacenter.\r\nProcessor: Intel(R) Xeon(R) CPU E5-2660 v3 @ 2.60Hz 2.60GHz\r\nInstalled Memory (RAM):  12.0 GB\r\nSystem Type: 64-bit Operating System, x64-based processor", "Hmm, it looks like CPU model has AVX, but still the failure we see is during dll loading.\r\nHere are a few more questions:\r\n1 - What happens if you use the standard python terminal, and run import tensorflow as tf? do you see the same error?\r\n2 - If it is easy, what do you see when you try the same with tensorflow 1.5?", "1 - It looks like the same error as before. Posted below.\r\n\r\n2 - The server doesn't have an internet connection. I am installing tensorflow and all of its dependencies through wheel files found on PyPI. When I went through finding all of the dependencies for 1.5, some were no longer available on PyPI.", "Traceback (most recent call last):\r\n  File \"D:\\MSSQL14.MSSQLSERVER\\PYTHON_SERVICES\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 14, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"D:\\MSSQL14.MSSQLSERVER\\PYTHON_SERVICES\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 906, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\MSSQL14.MSSQLSERVER\\PYTHON_SERVICES\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"D:\\MSSQL14.MSSQLSERVER\\PYTHON_SERVICES\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 17, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"D:\\MSSQL14.MSSQLSERVER\\PYTHON_SERVICES\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 16, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"D:\\MSSQL14.MSSQLSERVER\\PYTHON_SERVICES\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"D:\\MSSQL14.MSSQLSERVER\\PYTHON_SERVICES\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"D:\\MSSQL14.MSSQLSERVER\\PYTHON_SERVICES\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"D:\\MSSQL14.MSSQLSERVER\\PYTHON_SERVICES\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"D:\\MSSQL14.MSSQLSERVER\\PYTHON_SERVICES\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 14, in swig_import_helper\r\n    return importlib.import_module(mname)\r\n  File \"D:\\MSSQL14.MSSQLSERVER\\PYTHON_SERVICES\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 986, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 969, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 958, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 666, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 577, in module_from_spec\r\n  File \"<frozen importlib._bootstrap_external>\", line 906, in create_module\r\n  File \"<frozen importlib._bootstrap>\", line 222, in _call_with_frames_removed\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"D:\\MSSQL14.MSSQLSERVER\\PYTHON_SERVICES\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"D:\\MSSQL14.MSSQLSERVER\\PYTHON_SERVICES\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 17, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"D:\\MSSQL14.MSSQLSERVER\\PYTHON_SERVICES\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 16, in swig_import_helper\r\n    return importlib.import_module('_pywrap_tensorflow_internal')\r\n  File \"D:\\MSSQL14.MSSQLSERVER\\PYTHON_SERVICES\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nImportError: No module named '_pywrap_tensorflow_internal'\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/install_sources#common_installation_problems\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "For the record, I am fine trying 1.5, if someone can provide me with the .whl or .tar.gz files for the for everything.", "Let me see, we may be lucky and it may just have the same dependencies.", "Any more word on this?", "Sorry for the radio silence. I am travelling right now, thus unable to respond. I will check the dependencies of TF 1.5 and 1.8, and see if there is an easy way to try this out.\r\nIn the meantime, @meteorcloudy @mrry @guschmue in case they have another idea.", "Checking in on this again and hoping for a good solution.", "Checking in on this again.", "Sorry for the delay, I am trying to find and share a non-avx 1.8 pip package for you, but I have been quite busy lately.\r\nI am sorry for the delay.", "I have exactly the same issue, with also an Intel Xeon E5-2623 v4.\r\nImpossible to import tensorflow-cpu.\r\nSee ticket: #22512 ", "Could you try this package out?\r\nhttps://github.com/pubac15/TF_noAVX/blob/master/r1.10/tensorflow-1.10.1-cp36-cp36m-win_amd64.whl", "I tried this code in command prompt:\r\n\r\npip install N:\\Packages\\Python\\tensorflow-1.10.1-cp36-cp36m-win_amd64.whl -f ./ --no-index\r\n\r\nand it returned this error:\r\n\r\ntensorflow-1.10.1-cp36-cp36m-win_amd64.whl is not a supported wheel on this platform.", "I need cp35 I think.", "You may try requesting a wheel from here, given that I was not able to provide a wheel in time.\r\n\r\nAnother issue that came up is, (actually brought up by @Overdrivr ) It looks like when Microsoft Visual C++ 2015 Redistributable 64 bits. is missing we also error out the same way.\r\nCould you try installing that from here?\r\nhttps://www.microsoft.com/en-us/download/details.aspx?id=53840", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!", "also having this issue when installing tensorflow 2.3.1 on a machine with no internet connection; as far as I can tell, I have pip installed all the appropriate wheel files.\r\n\r\n_pywrap_tensorflow_internal does exist (twice) in the correct place, but the file endings are .pyd and .lib\r\n\r\n"]}, {"number": 20673, "title": "Frozen model is twice as large after applying tf.contrib.model_pruning", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: pip\r\n- **TensorFlow version (use command below)**:1.9.0rc1\r\n- **Python version**:  2.7\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 9/7.1\r\n- **GPU model and memory**: 1080ti\r\n- **Exact command to reproduce**:\r\n1. Follow the workflow from [here,](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/model_pruning\r\n) \r\n2. freeze_graph script from tensorflow\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\nThe pruned model(frozen protobuf) is exactly twice in terms of storage (13.1mb vs 26.2 mb) for a MNIST model \r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["Please describe the problem clearly here.", "Case 1: Regular TF model - freeze it -> file size(.pb) = X mb\r\nCase2: Use Model Pruining on the TF model from case 1- freeze it -> file size(.pb) >=2X mb", "Please provide a reproducible test case that is the bare minimum necessary to generate the problem. \r\n\r\nWe need to decide if this is a special case or a general issue. Since using model pruning we saw size reduction in most models we tested. But we don't guarantee it worked for every model.", "I cannot reproduce it with smaller (MNIST) model, it affects larger graphs, object detection model in my case."]}, {"number": 20672, "title": "Fix incorrect documentation", "body": "process detailed in comment is not the one in the code. This isn't anything code breaking but it's nice to have correct documentation.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->"]}, {"number": 20671, "title": "Add complex support for tan", "body": "At the moment tan in tensorflow supports float and double, but not complex types.\r\n\r\nThis fix adds the support for tan, and removes related TODO in the test\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["@yifeif I am concerned about copybara here -- can it get stuck? Or what is the failure mode here?", "I think its waiting for at least one approval from reviewer."]}, {"number": 20670, "title": "KeyError: \"Couldn't find message protos.FasterRcnnBoxCoder\"", "body": "### System information\r\n-  **Using ssd_mobilenet_pets_config and edit serval codes to solve the import errors**\r\n- **Windows 10**:\r\n- **installation via pip**:\r\n- **Tensorflow 1.8**:\r\n- **Python  3.6.0**: \r\n- **CUDA 9.0, cudnn 9.0*:\r\n- **Geforce GTX 1050Ti 4GB VRAM**:\r\n- **Exact command to reproduce:** python train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v1_pets.config running via cmd.exe from folder object_detection:\r\n\r\n\r\n\r\n### Describe the problem\r\nFirst of all I face import issues with for examples \"from object_detection.core import box_coder\", which was solved by \"from core import box_coder\".\r\n\r\n    `Traceback (most recent call last):\r\n     File \"train.py\", line 52, in <module>\r\n     from builders import model_builder\r\n    File \"C:\\Users\\azach\\Desktop\\python\\tensorflow\\models0- \r\n    master\\research\\object_detection\\builders\\model_builder.py\", line 18, in <module>\r\n    from builders import box_coder_builder\r\n    File \"C:\\Users\\azach\\Desktop\\python\\tensorflow\\models- \r\n    master\\research\\object_detection\\builders\\box_coder_builder.py\", line 21, in <module>\r\n    from protos import box_coder_pb2\r\n    File \"C:\\Users\\azach\\Desktop\\python\\tensorflow\\models- \r\n    master\\research\\object_detection\\protos\\box_coder_pb2.py\", line 16, in <module>\r\n    from protos import faster_rcnn_box_coder_pb2 as protos_dot_faster__rcnn__box__coder__pb2\r\n    File \"C:\\Users\\azach\\Desktop\\python\\tensorflow\\models- \r\n    master\\research\\object_detection\\protos\\faster_rcnn_box_coder_pb2.py\", line 76, in <module>\r\n    serialized_end=191,\r\n    File \"C:\\Users\\azach\\Anaconda3\\lib\\site-packages\\google\\protobuf\\descriptor.py\", line 288, in __ \r\n    new__\r\n    return _message.default_pool.FindMessageTypeByName(full_name)\r\n    KeyError: \"Couldn't find message protos.FasterRcnnBoxCoder\"`\r\n\r\n### Source code / logs\r\n\r\n    `# Generated by the protocol buffer compiler.  DO NOT EDIT!\r\n     # source: object_detection/protos/faster_rcnn_box_coder.proto\r\n      import sys\r\n    _b=sys.version_info[0]<3 and (lambda x:x) or (lambda x:x.encode('latin1'))\r\n     from google.protobuf import descriptor as _descriptor\r\n     from google.protobuf import message as _message\r\n     from google.protobuf import reflection as _reflection\r\n     from google.protobuf import symbol_database as _symbol_database\r\n     from google.protobuf import descriptor_pb2\r\n     # @@protoc_insertion_point(imports)\r\n\r\n    _sym_db = _symbol_database.Default()\r\n    DESCRIPTOR = _descriptor.FileDescriptor(\r\n    name='protos/faster_rcnn_box_coder.proto',\r\n    package='protos',\r\n    syntax='proto2', \r\n    #next part is shortend for increased readability  \r\nserialized_pb=_b('\\n3object_detection/protos/faster_rcnn_box_coder.proto\\x12\\x17object_detection.protos\\\"o\\n\\x12\\x46\\x61sterRcnnBoxCoder....')\r\n)\r\n\r\n\r\n\r\n\r\n    _FASTERRCNNBOXCODER = _descriptor.Descriptor(\r\n     name='FasterRcnnBoxCoder',\r\n     full_name='protos.FasterRcnnBoxCoder',\r\n     filename=None,\r\n     file=DESCRIPTOR,\r\n     containing_type=None,\r\n     fields=[\r\n    _descriptor.FieldDescriptor(\r\n      name='y_scale', full_name='object_detection.protos.FasterRcnnBoxCoder.y_scale', index=0,\r\n      number=1, type=2, cpp_type=6, label=1,\r\n      has_default_value=True, default_value=float(10),\r\n      message_type=None, enum_type=None, containing_type=None,\r\n      is_extension=False, extension_scope=None,\r\n      options=None),\r\n    _descriptor.FieldDescriptor(\r\n      name='x_scale', full_name='object_detection.protos.FasterRcnnBoxCoder.x_scale', index=1,\r\n      number=2, type=2, cpp_type=6, label=1,\r\n      has_default_value=True, default_value=float(10),\r\n      message_type=None, enum_type=None, containing_type=None,\r\n      is_extension=False, extension_scope=None,\r\n      options=None),\r\n    _descriptor.FieldDescriptor(\r\n      name='height_scale', full_name='object_detection.protos.FasterRcnnBoxCoder.height_scale', index=2,\r\n      number=3, type=2, cpp_type=6, label=1,\r\n      has_default_value=True, default_value=float(5),\r\n      message_type=None, enum_type=None, containing_type=None,\r\n      is_extension=False, extension_scope=None,\r\n      options=None),\r\n    _descriptor.FieldDescriptor(\r\n      name='width_scale', full_name='object_detection.protos.FasterRcnnBoxCoder.width_scale', index=3,\r\n      number=4, type=2, cpp_type=6, label=1,\r\n      has_default_value=True, default_value=float(5),\r\n      message_type=None, enum_type=None, containing_type=None,\r\n      is_extension=False, extension_scope=None,\r\n      options=None),\r\n      ],\r\n     extensions=[\r\n     ],\r\n     nested_types=[],\r\n     enum_types=[\r\n     ],\r\n     options=None,\r\n     is_extendable=False,\r\n     syntax='proto2',\r\n     extension_ranges=[],\r\n     oneofs=[\r\n     ],\r\n     serialized_start=80,\r\n     serialized_end=191,\r\n    )\r\n\r\n    DESCRIPTOR.message_types_by_name['FasterRcnnBoxCoder'] = _FASTERRCNNBOXCODER\r\n    _sym_db.RegisterFileDescriptor(DESCRIPTOR)\r\n\r\n     FasterRcnnBoxCoder = _reflection.GeneratedProtocolMessageType('FasterRcnnBoxCoder', \r\n     (_message.Message,), dict(\r\n     DESCRIPTOR = _FASTERRCNNBOXCODER,\r\n      __module__ = 'protos.faster_rcnn_box_coder_pb2'\r\n      # @@protoc_insertion_point(class_scope:object_detection.protos.FasterRcnnBoxCoder)\r\n      ))\r\n     _sym_db.RegisterMessage(FasterRcnnBoxCoder)\r\n \r\n\r\n     # @@protoc_insertion_point(module_scope)`\r\n\r\n\r\nThis is the script which causes the error.\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory", "@azacha I'm sorry, I don't understand the situation. Did you write your own code? Or is the not-found error happening with an unmodified build? It sounds like you changed an import to make progress, but is there now some other problem?  ", "It has been 34 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 20669, "title": "Error in Compiling the CPU Module for Python", "body": "System information\r\n- Have I written custom code: No\r\n- OS Platform and Distribution: Windows 10 64bit\r\n- TensorFlow installed from: Latest master source\r\n- TensorFlow version: commit dfcec822728c6569914db37eb55a78a019866e6f\r\n- Python version: 3.6.5 \r\n- CMake version: 3.12.0-rc2\r\n- MS C+_+ Compiler version: 19.00.24234.1\r\n- CPU model and memory: i5-4460 with 16GB of RAM\r\n- Exact command to reproduce:\r\n\r\n1- Opening Developer Command Line as admin\r\n2- Choosing the 64bit compiler\r\n\"C:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\Tools\\vsdevcmd\\ext\\vcvars.bat\" amd64\r\n3- cd D:\\opencv\\tensorflow\\tensorflow\\contrib\\cmake\\build\\\r\n4- \r\ncmake .. -A x64 -T host=x64 -DCMAKE_BUILD_TYPE=Release -DSWIG_EXECUTABLE=D:/opencv/swigwin-3.0.12/swig.exe -DPYTHON_EXECUTABLE=\"C:/Users/FiFo/AppData/Local/Programs/Python/Python36/python.exe\" -DPYTHON_LIBRARIES=\"C:/Users/FiFo/AppData/Local/Programs/Python/Python36/libs/python36.lib\" -Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVX2 -Dtensorflow_BUILD_CC_TESTS=OFF -Dtensorflow_BUILD_PYTHON_TESTS=OFF -Dtensorflow_BUILD_MORE_PYTHON_TESTS=OFF -Dtensorflow_BUILD_CC_EXAMPLE=ON -Dtensorflow_BUILD_PYTHON_BINDINGS=ON -Dtensorflow_BUILD_CC_TESTS=OFF -Dtensorflow_OPTIMIZE_FOR_NATIVE_ARCH=ON -Dtensorflow_ENABLE_MKL_SUPPORT=ON -Dtensorflow_ENABLE_MKLDNN_SUPPORT=ON -Dtensorflow_VERBOSE=ON -Dtensorflow_BUILD_SHARED_LIB=ON\r\n5- MSBuild /p:Configuration=Release ALL_BUILD.vcxproj\r\nSUCCESS\r\n6- MSBuild  /p:Configuration=Release INSTALL.vcxproj\r\nSUCCESS\r\n7- MSBuild /p:Configuration=Release tf_python_build_pip_package.vcxproj\r\nFails with:\r\n\r\n  Generating __init__.py files for Python API.\r\n  Traceback (most recent call last):\r\n    File \"D:\\opencv\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 14, in swig_import_helper\r\n      return importlib.import_module(mname)\r\n    File \"C:\\Users\\FiFo\\AppData\\Local\\Programs\\Python\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n      return _bootstrap._gcd_import(name[level:], package, level)\r\n    File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n    File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n    File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n    File \"<frozen importlib._bootstrap>\", line 658, in _load_unlocked\r\n    File \"<frozen importlib._bootstrap>\", line 571, in module_from_spec\r\n    File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n    File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  ImportError: DLL load failed: N\u00d2o foi poss\u00ddvel encontrar o m\u00bedulo especificado.\r\n\r\n  During handling of the above exception, another exception occurred:\r\n\r\n  Traceback (most recent call last):\r\n    File \"D:\\opencv\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n      from tensorflow.python.pywrap_tensorflow_internal import *\r\n    File \"D:\\opencv\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 17, in <module>\r\n      _pywrap_tensorflow_internal = swig_import_helper()\r\n    File \"D:\\opencv\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 16, in swig_import_helper\r\n      return importlib.import_module('_pywrap_tensorflow_internal')\r\n    File \"C:\\Users\\FiFo\\AppData\\Local\\Programs\\Python\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n      return _bootstrap._gcd_import(name[level:], package, level)\r\n  ModuleNotFoundError: No module named '_pywrap_tensorflow_internal'\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nIt used to work before with version 1.8\r\nI don't want to install the PIP version\r\nCompilation works without any problem on Ubuntu 16.04", "comments": ["In the tf_python_build_pip_package.vcxproj I found the following command:\r\nC:\\Program Files\\CMake\\bin\\cmake.exe\" -E copy D:/opencv/tensorflow/tensorflow/tools/pip_package/setup.py D:/opencv/tensorflow/tensorflow/contrib/cmake/build/tf_python/\r\n\r\nBut it doesn't look like the file was copied\r\nSo I copied it manually and did:\r\npython setup.py bdist_wheel\r\n\r\nWhich generated a wheel that I installed with pip install sucessfully\r\nBut then when I try to import tensorflow it gives me the same error message\r\n\r\nAny ideas?", "any news?", "Can you share the full log from running `MSBuild /p:Configuration=Release tf_python_build_pip_package.vcxproj`?", "Here you go\r\n[log1.txt](https://github.com/tensorflow/tensorflow/files/2196102/log1.txt)\r\n", "From the log, it appears that something is failing during the build of `estimator_python_api.vcxproj`. Assigning to @case540, since he added that project in 501cf726cbee2ee13efef43884a6552ca211979d, and I'm not familiar with its mechanics. Mike: from this traceback, it looks like the API code generator is attempting to `from tensorflow.python import pywrap_tensorflow` *before* `pywrap_tensorflow.pyd` has been build:\r\n\r\n```\r\n  Traceback (most recent call last):\r\n    File \"D:/opencv/tensorflow/tensorflow/contrib/cmake/build/tf_python/tensorflow/python/tools/api/generator/create_python_api.py\", line 27, in <module>\r\n      from tensorflow.python.tools.api.generator import doc_srcs\r\n    File \"D:\\opencv\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python\\tensorflow\\__init__.py\", line 24, in <module>\r\n      from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n    File \"D:\\opencv\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n      from tensorflow.python import pywrap_tensorflow\r\n    File \"D:\\opencv\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n      raise ImportError(msg)\r\n  ImportError: Traceback (most recent call last):\r\n    File \"D:\\opencv\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 14, in swig_import_helper\r\n      return importlib.import_module(mname)\r\n    File \"C:\\Users\\FiFo\\AppData\\Local\\Programs\\Python\\Python36\\lib\\importlib\\__init__.py\", line 126, in import_module\r\n      return _bootstrap._gcd_import(name[level:], package, level)\r\n    File \"<frozen importlib._bootstrap>\", line 994, in _gcd_import\r\n    File \"<frozen importlib._bootstrap>\", line 971, in _find_and_load\r\n    File \"<frozen importlib._bootstrap>\", line 955, in _find_and_load_unlocked\r\n    File \"<frozen importlib._bootstrap>\", line 658, in _load_unlocked\r\n    File \"<frozen importlib._bootstrap>\", line 571, in module_from_spec\r\n    File \"<frozen importlib._bootstrap_external>\", line 922, in create_module\r\n    File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  ImportError: DLL load failed: N\u00d2o foi poss\u00ddvel encontrar o m\u00bedulo especificado.\r\n```\r\n\r\nI'm not sure how this is working in other builds, but perhaps we need a build dependency to ensure that the C++ extension is built first?", "[tensorflow.zip](https://github.com/tensorflow/tensorflow/files/2196581/tensorflow.zip)\r\nhere is the full log if anybody is interested", "@fifothekid @mrry \r\nI noticed that you built tensorflow with **MKL**, there is a known issue that comes with the previously installed tensorflow package in the system.\r\n\r\nIn detail, if your system has an installed tensorflow package, the cmake script will firstly import system module, rather than your compiled one. This will cause version mismatch and some import error occurs.\r\n\r\nThere is also another issue while importing `google.protobuf`, and I'm working it out. I suggest you at first uninstall any tensorflow packages (`tensorflow-gpu`, `protobuf`, `grpcio`) and build from scratch.\r\n\r\n**P.S** For now, it will failed at importing google.protobuf, to work around, you must install and only install `protobuf` in the system.\r\n\r\n**UPDATE** `absl-py` is required before building in cmake", "I'm building with CPU not with GPU\r\nI don't have an installed tensorflow package, and I've just unisntalled grpcio\r\nI'll try building again", "Hi @fifothekid \r\nI recognized, the problem may lie in the generating of `estimator_python_api`, you can first try to only build `tf_python_api`.\r\nIf you are urgent with this, please refer to my [PR](https://github.com/tensorflow/tensorflow/pull/20951 )", "Tried the latest version merged with the PR above, and had the following error:\r\n\r\nCustomBuild:\r\n  Generating __init__.py files for Python API.\r\n  Traceback (most recent call last):\r\n    File \"D:/opencv/tensorflow/tensorflow/contrib/cmake/build/tf_python/tensorflow/python/tools/api/generator/create_python_api.py\", line 27, in <module>\r\n      from tensorflow.python.tools.api.generator import doc_srcs\r\n    File \"D:\\opencv\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python\\tensorflow\\__init__.py\", line 31, in <module>\r\n      app.flags = flags  # pylint: disable=undefined-variable\r\n  NameError: name 'app' is not defined\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\VC\\VCTargets\\Microsoft.CppCommon.targets(171,5): error MSB6006: \"cmd.exe\" foi enc\r\nerrado com o c\u00f3digo 1. [D:\\opencv\\tensorflow\\tensorflow\\contrib\\cmake\\build\\estimator_python_api.vcxproj]", "@fifothekid Have you install absl-py? That\u2019s a required module and must be installed at the beginning.", "Requirement already satisfied: absl-py in c:\\users\\fifo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (0.2.2)\r\nRequirement already satisfied: six in c:\\users\\fifo\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from absl-py) (1.11.0)", "@fifothekid I'm not able to reproduce your error, specifically your error message:\r\n```\r\nFile \"D:\\opencv\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python\\tensorflow_init_.py\", line 31, in \r\napp.flags = flags # pylint: disable=undefined-variable\r\nNameError: name 'app' is not defined\r\n```\r\nIs `tensorflow_init__.py` actually `tensorflow\\__init__.py`? If so, the line 31 of mine isn't `app.flags = flags`, which is in line 604 for me, and I also have the declaration of `app` (`from tensorflow import app`) \r\n\r\nAs suggestion, could you build `tf_tutorials_example_trainer` and run it (of course you may need to copy mklml.dll and mkldnn.dll to **Release directory**)", "Are you using the latest Master with the PR?\r\nI'll just clean-up everything and build and run tf_tutorials_example_trainer", "Yeah, I committed PR using the latest branch several days ago, though it's not the very **LATEST**, but there seems no new commits for CMAKE and related python scripts recently.", "@fifothekid I have the same error. \r\n\r\n> File \"D:\\opencv\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python\\tensorflow_init_.py\", line 31, in \r\napp.flags = flags # pylint: disable=undefined-variable\r\nNameError: name 'app' is not defined\r\n\r\n I am building tensorflow1.8 on Win7 with cuda9.0 and cudnn6.0. Have you found a solution?", "@LoSealL I cloned a fresh copy of the Master branch without the PR\r\nBuild and ran tf_tutorials_example_trainer and it worked perfectly\r\nNow what?\r\n\r\n@zhangcong2009 not yet, only on Linux with Bazel", "@fifothekid Is this build with or without MKL & MKLDNN?\r\n\r\nFor the concern, you may better install `absl-py` as well as `protobuf` before the build.\r\nPlease try to build `tf_python_api` and then `estimator_python_api`, if anything failed, could you paste the failure information?\r\n(With cmake options unchanged)\r\n\r\nAs I expect, it may fail for `estimator_python_api` but will success for `tf_python_api`", "> @fifothekid Is this build with or without MKL & MKLDNN?\r\n\r\nYes I did. I used this CMake command:\r\n\r\n`cmake .. -A x64 -T host=x64 -DCMAKE_BUILD_TYPE=Release -DSWIG_EXECUTABLE=D:/opencv/swigwin-3.0.12/swig.exe -DPYTHON_EXECUTABLE=\"C:/Users/FiFo/AppData/Local/Programs/Python/Python36/python.exe\" -DPYTHON_LIBRARIES=\"C:/Users/FiFo/AppData/Local/Programs/Python/Python36/libs/python36.lib\" -Dtensorflow_WIN_CPU_SIMD_OPTIONS=/arch:AVX2 -Dtensorflow_BUILD_CC_TESTS=OFF -Dtensorflow_BUILD_PYTHON_TESTS=OFF -Dtensorflow_BUILD_MORE_PYTHON_TESTS=OFF -Dtensorflow_BUILD_CC_EXAMPLE=ON -Dtensorflow_BUILD_PYTHON_BINDINGS=ON -Dtensorflow_BUILD_CC_TESTS=OFF -Dtensorflow_OPTIMIZE_FOR_NATIVE_ARCH=ON -Dtensorflow_ENABLE_MKL_SUPPORT=ON -Dtensorflow_ENABLE_MKLDNN_SUPPORT=ON -Dtensorflow_BUILD_SHARED_LIB=OFF`\r\n\r\nI'll try building again today\r\nRebuilding on Windows takes soooooooooo much time\r\nIt seems like on Linux with Bazel only the addition files are built, not everything!\r\nI mean, for building the Python project I assume about 10% more files need to be built, still the building process takes 90+ minutes, and it seems like it almost rebuilds everything", "Built tf_python_api in 43 minutes with no errors\r\nNow building estimator_python_api ", "after 41 minutes I had this error\r\n\r\nCustomBuild:\r\n  Generating __init__.py files for Python API.\r\n  Traceback (most recent call last):\r\n    File \"D:/opencv/tensorflow/tensorflow/contrib/cmake/build/tf_python/tensorflow/python/tools/api/gene\r\n  rator/create_python_api.py\", line 27, in <module>\r\n      from tensorflow.python.tools.api.generator import doc_srcs\r\n    File \"D:\\opencv\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python\\tensorflow\\__init__.py\", line 31\r\n  , in <module>\r\n      app.flags = flags  # pylint: disable=undefined-variable\r\n  NameError: name 'app' is not defined\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2017\\Enterprise\\Common7\\IDE\\VC\\VCTargets\\Microsoft.CppCom\r\nmon.targets(171,5): error MSB6006: \"cmd.exe\" foi encerrado com o c\u00f3digo 1. [D:\\opencv\\tensorflow\\tensorf\r\nlow\\contrib\\cmake\\build\\estimator_python_api.vcxproj]", "Hi @fifothekid @zhangcong2009 \r\nI tried a new build on the very latest master branch, **without** my PR, I manually copied `mklml.dll` and `mkldnn.dll` and `libiomp5md.dll` into `build\\tf_python\\tensorflow\\python` (mkdir if the directory doesn't exist), with an absolutely new python environment, and the build of `tf_python_build_pip_package` succeeded.\r\n\r\nYou can try this \"last\" method, good luck.", "copied the DLL's to the directory and ended with the same compilation error...\r\nwhich version of Python are you using?\r\nI think that I'll uninstall completely my Python 3.6.5 and reinstall it without any additional packages", "@fifothekid 3.6.5, the same as yours.\r\nThat's very strange and unusual, and I never could reproduce your error. Could you provide me your full log? And could you list your package by `pip list`?", "I'll be sending the full log later today\r\n\r\npip list\r\nPackage          Version\r\n---------------- ---------\r\nabsl-py          0.2.2\r\nasn1crypto       0.24.0\r\nastor            0.7.1\r\nawscli           1.15.63\r\nbcrypt           3.1.4\r\nbleach           2.1.3\r\nboto             2.49.0\r\nbotocore         1.10.62\r\ncached-property  1.4.3\r\ncertifi          2018.4.16\r\ncffi             1.11.5\r\nchardet          3.0.4\r\ncolorama         0.3.9\r\ncryptography     2.3\r\ndocker           3.4.1\r\ndocker-compose   1.22.0\r\ndocker-pycreds   0.3.0\r\ndockerpty        0.4.1\r\ndocopt           0.6.2\r\ndocutils         0.14\r\nfabric           2.2.1\r\ngast             0.2.0\r\nhtml5lib         1.0.1\r\nhttpie           0.9.9\r\nidna             2.7\r\ninvoke           1.1.0\r\njmespath         0.9.3\r\njsonschema       2.6.0\r\nMarkdown         2.6.11\r\nnumpy            1.14.5\r\nparamiko         2.4.1\r\npip              18.0\r\nprettytable      0.7.2\r\nprotobuf         3.6.0\r\npyasn1           0.4.3\r\npycparser        2.18\r\nPygments         2.2.0\r\nPyNaCl           1.2.1\r\npypiwin32        223\r\nPyQt4            4.11.4\r\nPyQt5            5.11.2\r\nPyQt5-sip        4.19.12\r\npython-dateutil  2.7.3\r\npywin32          223\r\nPyYAML           3.13\r\nrequests         2.19.1\r\nrsa              3.4.2\r\ns3transfer       0.1.13\r\nsetuptools       40.0.0\r\nsip              4.19.8\r\nsix              1.11.0\r\ntensorboard      1.9.0\r\ntermcolor        1.1.0\r\ntexttable        1.4.0\r\nurllib3          1.23\r\nvirtualenv       16.0.0\r\nwebencodings     0.5.1\r\nwebsocket-client 0.48.0\r\nWerkzeug         0.14.1\r\nwheel            0.31.1", "@fifothekid can you try deleting D:\\opencv\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python\\tensorflow\\__init__.py and rerunning?\r\n\r\nOur cmake build is actually supposed to remove this file before running create_python_api:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/cmake/tf_python.cmake#L802\r\nI wonder why that didn't work in this case.\r\n", "the problem is the rebuilding on Windows takes at least 45 minutes to reach the same point where I had an error last time! this is not the case with Bazel on Linux\r\nthat's why I usually let it do the compilation overnight since I use the computer every single hour of the day", "Nagging Assignee @case540: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "I can build now with bazel and CMake support will be ended soon\r\nYou can close this issue"]}, {"number": 20668, "title": "tensorflow error-fatal: not a git repository (or any parent up to mount point /media/ds) Stopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set). Not a git repository", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: I was trying to run facenet preprocessing as described here :\r\n**https://github.com/davidsandberg/facenet/wiki/Validate-on-lfw**\r\n- **OS Platform and Distribution **:Linux Ubuntu 18.04\r\n- **TensorFlow installed from**: source\r\n- **TensorFlow version **:1.9.0.rc0\r\n- **Python version**: 3.6.5\r\n- **Bazel version (if compiling from source)**: 0.15.0\r\n- **GCC/Compiler version (if compiling from source)**: gcc6\r\n- **CUDA/cuDNN version**: cuda9.2/ cudnn7.1.3\r\n- **GPU model and memory**:Nvidia geforce 940m\r\n- **Exact command to reproduce**:  \r\npython src/align/align_dataset_mtcnn.py \\\r\n~/datasets/lfw/raw \\\r\n~/datasets/lfw/lfw_mtcnnpy_160 \\\r\n--image_size 160 \\\r\n--margin 32 \\\r\n\r\n\r\n### Describe the problem\r\nWhile running it above file along with arguments command in spyder, it throws the  following error in detect_face module\r\n\r\n### Source code / logs\r\nfatal: not a git repository (or any parent up to mount point /media/ds)\r\nStopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\r\nNot a git repository\r\nTo compare two paths outside a working tree:\r\nusage: git diff [\u2011\u2011no\u2011index] \r\n2018\udae1\udeab\udae1\udeae 16:37:25.006640: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (\ud810\udcab), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018\udae1\udeab\udae1\udeae 16:37:25.007978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1404] Found device 0 with properties: \r\nname: GeForce 940M major: 5 minor: 0 memoryClockRate(GHz): 1.176\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 1.96GiB freeMemory: 1.84GiB\r\n2018\udae1\udeab\udae1\udeae 16:37:25.008008: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1483] Adding visible gpu devices: 0\r\n2018\udae1\udeab\udae1\udeae 16:37:25.334405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:964] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018\udae1\udeab\udae1\udeae 16:37:25.334449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:970] 0 \r\n2018\udae1\udeab\udae1\udeae 16:37:25.334458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:983] 0: N \r\n2018\udae1\udeab\udae1\udeae 16:37:25.334616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2004 MB memory) \u2011> physical GPU (device: 0, name: GeForce 940M, pci bus id: 0000:01:00.0, compute capability: 5.0)\r\n2018\udae1\udeab\udae1\udeae 16:37:25.334817: E tensorflow/core/common_runtime/gpu/gpu_device.cc:228] Illegal GPUOptions.experimental.num_dev_to_dev_copy_streams=0 set to 1 instead.\r\n2018\udae1\udeab\udae1\udeae 16:37:25.337581: E tensorflow/stream_executor/cuda/cuda_driver.cc:903] failed to allocate 1.96G (2101870592 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\r\n2018\udae1\udeab\udae1\udeae 16:37:28.896856: E tensorflow/stream_executor/cuda/cuda_dnn.cc:352] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\r\n", "comments": ["This command from stackoverflow post solved the issue:\r\n\r\n sudo rm -rf ~/.vn/\r\n"]}, {"number": 20667, "title": "[tf.keras] Remove relu6 and unused imports", "body": "", "comments": ["Thanks for the cleanup.", "Can u fix the failed test cases?", "Fixed. Please review it."]}, {"number": 20666, "title": "BUG on saving bidirectional CuDNNLSTM/GRU", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.9.0rc2 and also test on nightly\r\n- **Python version**:  3.5\r\n- **Bazel version (if compiling from source)**: None\r\n- **GCC/Compiler version (if compiling from source)**: None\r\n- **CUDA/cuDNN version**:  not important\r\n- **GPU model and memory**: not important\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\n\r\nWights are not stored when using `tf.keras.layers.CuDNNLSTM/GRU` with `tf.keras.layers.Bidirectional`\r\n\r\n### Source code / logs\r\n```\r\nimport tensorflow as tf\r\n\r\n\r\nclass Model(tf.keras.Model):\r\n    def __init__(self):\r\n        super(Model, self).__init__()\r\n        # this line works fine, but when commented and uncomment the second line, weights of rnn\r\n        # will not be saved\r\n        self.lstm = tf.keras.layers.CuDNNGRU(2)\r\n        # self.lstm = tf.keras.layers.Bidirectional(tf.keras.layers.CuDNNGRU(2))\r\n\r\n    def call(self, inputs):\r\n        return self.lstm(inputs)\r\n\r\n\r\ni = tf.random_normal((3, 4, 5))\r\nm = Model()\r\no = m(i)\r\nm.save_weights(\"test/save\")\r\n\r\nreader = tf.train.NewCheckpointReader(\"test/save\")\r\n# weights are not store when using CuDNNLSTM/GRU with bidirectional layer\r\nprint(reader.get_variable_to_dtype_map().keys())\r\n\r\n```\r\n", "comments": ["I find that this problem exists even in undirectional cpu version rnn. Please fix it as soon as possible\r\n```\r\nimport tensorflow as tf\r\n\r\n\r\nclass Model(tf.keras.Model):\r\n    def __init__(self):\r\n        super(Model, self).__init__()\r\n        # this line works fine\r\n        self.d = tf.keras.layers.Dense(2)\r\n\r\n        # following three lines related with rnn do not work with Model.save_weights\r\n        # self.d = tf.keras.layers.Bidirectional(tf.keras.layers.CuDNNLSTM(2))\r\n        # self.d = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(2))\r\n        # self.d = tf.keras.layers.LSTM(2)\r\n\r\n    def call(self, inputs, training=True, mask=None):\r\n        return self.d(inputs)\r\n\r\n\r\nr = tf.random_normal((4, 3, 5))\r\nm = Model()\r\no = m(r)\r\n\r\nm.save_weights(\"save/save\", save_format=\"tf\")\r\nreader = tf.train.NewCheckpointReader(\"save/save\")\r\nprint(reader.get_variable_to_shape_map())\r\n```", "Thank you for reporting this. The issue has been fixed by https://github.com/tensorflow/tensorflow/commit/6bfa38ef2963f0062fbe12d532ab188c7d5ea8dd#diff-e0b6d73c209a5deb070afea16a59060b\r\n\r\nThis will be available in the next nightly release. Please try and let us know if it works for you.", "@pavithrasv thank you for your fix!", "I tried the new-released nightly and it now works for me, thank you again @pavithrasv "]}, {"number": 20665, "title": "Fix masking of beam ids in gather_tree_from_array", "body": "The `sequence_length` argument that is passed to the function is the\r\nlengths of the **reordered** predictions and was incorrectly used to\r\nmask beam ids *before* reordering. Instead, we can reorder beam ids\r\nwithout caring about out of range steps and only select the reodered\r\nids that are in bounds.\r\n\r\nThe added test covers a beam trajectory that previously produced an\r\nout of range error because `gather_tree` returned `end_token` (here\r\n`beam_width + 1`) for some steps.", "comments": ["@qlzh727 @ebrevdo This change looks good to me!"]}, {"number": 20664, "title": "ImportError: cannot import name bessel_i0", "body": "Hi, I cannot figure out what happened. Anyone help?\r\n>>> import tensorflow\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/yinxiaoyi/Software/anaconda2/lib/python2.7/site-packages/tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *  # pylint: disable=redefined-builtin\r\n  File \"/home/yinxiaoyi/Software/anaconda2/lib/python2.7/site-packages/tensorflow/python/__init__.py\", line 47, in <module>\r\n    import numpy as np\r\n  File \"/home/yinxiaoyi/Software/anaconda2/lib/python2.7/site-packages/numpy/__init__.py\", line 142, in <module>\r\n    from . import add_newdocs\r\n  File \"/home/yinxiaoyi/Software/anaconda2/lib/python2.7/site-packages/numpy/add_newdocs.py\", line 13, in <module>\r\n    from numpy.lib import add_newdoc\r\n  File \"/home/yinxiaoyi/Software/anaconda2/lib/python2.7/site-packages/numpy/lib/__init__.py\", line 3, in <module>\r\n    import math\r\n  File \"math/__init__.py\", line 11, in <module>\r\n    from tensorflow.python import bessel_i0\r\nImportError: cannot import name bessel_i0\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Well, your user name exposed...\r\nAs well as someone's true name?\r\n:-)", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?"]}, {"number": 20663, "title": "use pre-trained embedding with tf.feature_column.embedding_column by initializer", "body": "I  used pre-trained embedding with tf.feature_column.embedding_column by parameter initializer  ,my code is blow\r\n\r\n# code here\r\n```\r\nweight, vocab_size, emb_size = _create_pretrained_emb_from_txt(FLAGS.vocab,FLAGS.pre_emb)\r\n W = tf.get_variable(trainable=False, name='W', shape=[vocab_size, emb_size])\r\nembedding_placeholder = tf.placeholder(tf.float32, [vocab_size, emb_size])\r\nembedding_init = W.assign(embedding_placeholder)\r\n\r\nsess = tf.Session()\r\nsess.run(embedding_init, feed_dict={embedding_placeholder: weight})\r\n\r\nitemx_vocab = tf.feature_column.categorical_column_with_vocabulary_file(\r\n    key='itemx',\r\n    vocabulary_file=FLAGS.vocabx)\r\n\r\nitemx_emb = tf.feature_column.embedding_column(itemx_vocab,\r\n                                               dimension=emb_size,\r\n                                               initializer=W,\r\n                                               trainable=False)\r\n```\r\n\r\n# it says:\r\n\r\n ValueError: initializer must be callable if specified. Embedding of column_name: itemx\r\n\r\n### then I tried set` lambda w: W`. \r\n```\r\nitemx_emb = tf.feature_column.embedding_column(itemx_vocab,\r\n                                               dimension=emb_size,\r\n                                               initializer=lambda w: W,\r\n                                               trainable=False)\r\n```\r\n\r\nbut it doesn't work and  got a typeError: TypeError: () got an unexpected keyword argument 'dtype'\r\n\r\nI'm confused is this a bug?\r\n\r\nthks fou your guys suggestion! \r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "thks for quick response! details below:\r\nHave I written custom code: No\r\nOS Platform and Distribution: Linux\r\nTensorFlow installed from: pip \r\nTensorFlow version: 1.5.1\r\nGPU model and memory: NVIDIA-SMI 384.66 16GB\r\nTest Environment: Python 2.7.5\r\n\r\n", "finally I figured out. Although. I'm not clear why answer above is not effective. @angersson if you saw my question, Thanks to give some suggestion to me.\r\n\r\nok~~~~here is my solvement. Actually from  here \r\n[stackoverflow: feature-columns-embedding-lookup](https://stackoverflow.com/questions/47523374/feature-columns-embedding-lookup)\r\n\r\n```\r\nitemx_vocab = tf.feature_column.categorical_column_with_vocabulary_file(\r\n        key='itemx',\r\n        vocabulary_file=FLAGS.vocabx)\r\n\r\nembedding_initializer_x = tf.contrib.framework.load_embedding_initializer(\r\n        ckpt_path='model.ckpt',\r\n        embedding_tensor_name='w_in',\r\n        new_vocab_size=itemx_vocab.vocabulary_size,\r\n        embedding_dim=emb_size,\r\n        old_vocab_file=FLAGS.vocab_emb,\r\n        new_vocab_file=FLAGS.vocabx\r\n    )\r\nitemx_emb = tf.feature_column.embedding_column(itemx_vocab,\r\n                                                   dimension=128,\r\n                                                   initializer=embedding_initializer_x,\r\n                                                   trainable=False)\r\n```\r\n", "Looks like this issue has been resolved, so I'm closing it. Thanks for posting your updates!\r\n\r\nIf you have any more questions that are not bug reports or feature requests, please ask a question on [Stack Overflow](http://stackoverflow.com/questions/tagged/tensorflow), which has a wider audience. Thanks!", "You are passing the weights directly to the \"embedding_column\" layer, but it is expecting callable object.\r\n\r\nBest way to create an initializer class and pass it to the embedding_column like this\r\n\r\n````\r\nimport tensorflow as tf\r\n\r\nclass embedding_initialize(tf.keras.initializers.Initializer):\r\n  def __call__(self, shape, dtype=None, **kwargs):\r\n    return tf.compat.v1.Variable(initial_value=[[1, 2], [2,3],[3,4]], dtype = dtype)\r\n\r\n\r\none_hot_layer = tf.feature_column.sequence_categorical_column_with_identity('text', num_buckets=3)\r\ntext_embedding = tf.feature_column.embedding_column(one_hot_layer,\r\n                                      dimension=2, \r\n                                      initializer = embedding_initialize())\r\ncolumns = [text_embedding]\r\n\r\nfeatures = {'text': tf.sparse.from_dense([[1, 2], [2, 1]])}\r\n\r\nsequence_input_layer = tf.keras.experimental.SequenceFeatures(columns)\r\nsequence_input, sequence_length = sequence_input_layer(features, training=True)\r\n````"]}, {"number": 20662, "title": "Compilation with Cuda 9.1 Cudnn 7.0.5, In python3, \"help(tensorflow)\" caused core dump", "body": "Have I written custom code: No\r\nOS Platform and Distribution: Ubuntu 16.04 Server\r\nTensorFlow installed from: source cloned from current branch\r\nTensorFlow version: 1.9.0-rc2 the active version from the master branch\r\nBazel version: 1.5.0, a most recent release\r\nCUDA/cuDNN version: 9.1/7.0.5\r\nGPU model and memory: NVIDIA GTX 1080Ti 11GB\r\nTest Environment: Python 3.5\r\nExact command to reproduce: python3 -c \"import tensorflow; help(tensorflow)\"\r\n\r\n\r\nIf this could help....\r\nCode Version: v1.9.0-rc2-205-g216887d 1.9.0-rc0\r\n\r\n\r\n\r\nHello guys, \r\nI recently cloned the bench and compiled with all (Y/n) set to y and (y/N) set to n. while the Cuda is set to yes.\r\nThe cuda environment is 9.1 and cudnn is 7.0.5.\r\nThe compilation succeeded, and I tried some subtle code to run tensorflow on gpu, it also returns.\r\nThen I tried to read some help, but when I typed \"help(tensorflow)\" python halted and crushed.\r\n\r\n> Segmentation fault (core dumped)\r\n\r\nI'm wondering why this happened? Could you lend some help?\r\n\r\n\r\nThe template data is filled up, If you require a snapshot of installed python packages, I would make a list.\r\nCurrently I have no idea what's happening, There is no error report, only a core dump....\r\n\r\nFine, after all I'll try an earlier version of tensorflow.\r\n\r\nToday I rebuilt with tensorflow 1.8.0 release source code, it works. It might imply there was something wrong with the 1.9.0 source\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "I've edited, so that you may see more details", "@Heermosi This is a stale issue. I think this was resolved in recent TF versions.\r\n\r\nAlso, there is no support for `TF1.x`. \r\n\r\nI am closing this issue as this was resolved in recent TF versions. Please feel free to test with `TF2.x` and open a new issue If the issue persists with recent TF versions. Thanks!"]}]