[{"number": 54581, "title": "Use MultiProcessCluster instead of in-process cluster.", "body": "Use MultiProcessCluster instead of in-process cluster.\n", "comments": []}, {"number": 54580, "title": "Extend lowering of reshape to linalg to also cover reshape to static shape with trailing dynamic input dimensions.", "body": "Extend lowering of reshape to linalg to also cover reshape to static shape with trailing dynamic input dimensions.\n", "comments": []}, {"number": 54579, "title": "[XLA] Don't do redundant work in `GlobalDecreasingSizeBestFitHeap::GetTransitiveColocations`.", "body": "[XLA] Don't do redundant work in `GlobalDecreasingSizeBestFitHeap::GetTransitiveColocations`.\n", "comments": []}, {"number": 54578, "title": "failed: (Exit 2): cl.exe failed: error executing command\uff0cBazel=5.0.0, tf=2.8.0,MSVC2019 ", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):win11\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):build it from the source\r\n- TensorFlow version:2.8.0\r\n- Python version:3.10 && 3.8.8\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):5.0.0 && 4.2.1\r\n- GCC/Compiler version (if compiling from source):MSVC2019\r\n- CUDA/cuDNN version:No\r\n- GPU model and memory:No\r\n\r\n\r\n\r\n**Describe the problem**\r\nwhen I use bazel to build the tf2.8, the blow error happened.\r\n`failed: (Exit 2): cl.exe failed: error executing command`\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n`F:\\tensorflow>python ./configure.py`\r\nYou have bazel 5.0.0 installed.\r\nPlease specify the location of python. [Default is D:\\JetBrain\\python\\python.exe]:\r\n\r\nFound possible Python library paths:\r\nD:\\JetBrain\\python\\lib\\site-packages\r\nPlease input the desired Python library path to use. Default is [D:\\JetBrain\\python\\lib\\site-packages]\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: n\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: n\r\nNo CUDA support will be enabled for TensorFlow.\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is /arch:AVX]:\r\n\r\nWould you like to override eigen strong inline for some C++ compilation to reduce the compilation time? [Y/n]: y\r\nEigen strong inline overridden.\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n\r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n--config=mkl # Build with MKL support.\r\n--config=mkl_aarch64 # Build with oneDNN and Compute Library for the Arm Architecture (ACL).\r\n--config=monolithic # Config for mostly static monolithic build.\r\n--config=numa # Build with NUMA support.\r\n--config=dynamic_kernels # (Experimental) Build kernels into separate shared objects.\r\n--config=v1 # Build with TensorFlow 1 API instead of TF 2 API.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n--config=nogcp # Disable GCP support.\r\n--config=nonccl # Disable NVIDIA NCCL support.\r\n\r\n\r\n`bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package`\r\nExtracting Bazel installation...\r\nStarting local Bazel server and connecting to it...\r\n\r\n\r\n**Any other info / logs**\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nERROR: F:/tensorflow/tensorflow/core/framework/BUILD:1400:31 Middleman _middlemen/_S_Stensorflow_Score_Sframework_Cattr_Uvalue_Uproto_Utext-BazelCppSemantics_build_arch_x64_windows-opt failed: (Exit 2): cl.exe failed: error executing command\r\ncd /d C:/users/manyuan/_bazel_manyuan/2qttxlm7/execroot/org_tensorflow\r\nSET INCLUDE=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.29.30133\\include;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.16299.0\\ucrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.16299.0\\shared;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.16299.0\\um;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.16299.0\\winrt;C:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.16299.0\\cppwinrt\r\nSET PATH=C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.29.30133\\bin\\HostX64\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\VC\\VCPackages;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\TestWindow;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE\\CommonExtensions\\Microsoft\\TeamFoundation\\Team Explorer;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\MSBuild\\Current\\bin\\Roslyn;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\Tools\\devinit;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\10.0.16299.0\\x64;C:\\Program Files (x86)\\Windows Kits\\10\\bin\\x64;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\MSBuild\\Current\\Bin;C:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\IDE;C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\Common7\\Tools;;C:\\Windows\\system32\r\nSET PWD=/proc/self/cwd\r\nSET PYTHON_BIN_PATH=D:/JetBrain/python/python.exe\r\nSET PYTHON_LIB_PATH=D:/JetBrain/python/lib/site-packages\r\nSET RUNFILES_MANIFEST_ONLY=1\r\nSET TEMP=C:\\Users\\manyuan\\AppData\\Local\\Temp\r\nSET TF2_BEHAVIOR=1\r\nSET TMP=C:\\Users\\manyuan\\AppData\\Local\\Temp\r\nC:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC\\Tools\\MSVC\\14.29.30133\\bin\\HostX64\\x64\\cl.exe @bazel-out/x64_windows-opt/bin/tensorflow/core/platform/windows/_objs/platform_port/port.obj.params", "comments": ["@Leemy9612 Please have a look at this [link](https://www.tensorflow.org/install/source_windows), [link1](https://github.com/tensorflow/docs/blob/cbaa96238c823b39e4433c843823895cef903343/site/en/install/source.md#gpu) and verify the configurations.Please let us know if it helps?Thanks! ", ">I want to build tf from source on windows, so I follow the [https://github.com/tensorflow/docs/blob/cbaa96238c823b39e4433c843823895cef903343/site/en/install/source_windows.md](url), but now, the bazel 4.2.1 is too out-of-date to build tf. and it report that `Please upgrade your bazel installation to version 4.2.2 or higher to build TensorFlow!`. So I tried the version 5.0.0 which is also useless.\r\n\r\n", "@Leemy9612,\r\n`cl.exe` is more related to Microsoft C Compiler. Make sure MSVC 2019 PATH is properly set where the python is installed, so that `cl.exe` can be found. Thanks!", "Building tensorflow on Windows didn't work for me either. I had to apply several workarounds and code changes to make it work (e.g. adding Visual Studio 2022 toolset support to Bazel).\r\n\r\nFor MSVC 2019 make sure to add a `BAZEL_VC` environment variable that points to `C:\\Program Files (x86)\\Microsoft Visual Studio\\2019\\Community\\VC` or your MSBUILD toolkit path, since at least on my machine (also Win11 Pro) Bazel wasn't able to find `cl.exe` either (because in 2022 it still stumbled over a space in the path name\ud83e\udd26\u200d\u2642\ufe0f).\r\n\r\nAnother issue that arose was the error `realpath not found`, which can be fixed by changing \"-c\" to \"-cl\" in [third_party/remote_config/common.bzl:273](https://github.com/tensorflow/tensorflow/blob/master/third_party/remote_config/common.bzl#L273). This [had been fixed before](https://github.com/tensorflow/tensorflow/commit/572f537ea9efba9130e735dfd0feee07bcb44ffe), but was rolled back in later versions for some reason.\r\n\r\nIn case you get an error that says a directory couldn't be mapped, symlink creation might have failed. This can be fixed by [activating developer mode](https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development) - others might suggest to simply start the `cmd.exe` as administrator instead (which would also work), but I don't recommend that for obvious reasons.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54578\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54578\">No</a>\n", "i run: bazel build  tensorflow/tools/graph_transforms:summarize_graph ,the same error.\r\nbazel:6.0\r\ncpu model,no GPU. \r\nmsvc 2017.\r\n![0c2fcd430716766437bffa025449e61](https://user-images.githubusercontent.com/59092819/159540678-215e0a5c-bb83-475f-b89c-9ce6a81e5ac0.png)\r\n"]}, {"number": 54577, "title": "[TFRT GPU] Change convolution algorithm to a specific type, add ops to create it.", "body": "[TFRT GPU] Change convolution algorithm to a specific type, add ops to create it.\n\nRemove chain argument from ops that create a descriptor, mark them `NoSideEffect`.\n\nUse the correct signedness for EnumAttr.\n", "comments": []}, {"number": 54576, "title": "[XLA] Optimizations / cleanup of `ComputeInstructionPostOrder`.", "body": "[XLA] Optimizations / cleanup of `ComputeInstructionPostOrder`.\n\n- Remove redundant hash lookup of `visited`.\n- Remove redundant check of channel group dependencies.\n- Extract common `GetChannelId` function.\n", "comments": []}, {"number": 54575, "title": "CanCreateTensorWithShape moved into TensorDescriptor.", "body": "CanCreateTensorWithShape moved into TensorDescriptor.\n", "comments": []}, {"number": 54574, "title": "Support of reading int based images in OpenCL.", "body": "Support of reading int based images in OpenCL.\n", "comments": []}, {"number": 54573, "title": "while do evaluation in the runhook, the eval_metrics calculate each batch and the average the result or calculate after all evaluation dataset?", "body": " like auc in eval_metrics. Anybody knows this?Please help", "comments": ["@satyrswang ,\r\nCan you please take a look at this link [1](https://stackoverflow.com/questions/51757345/what-is-the-impact-from-choosing-auc-error-logloss-as-eval-metric-for-xgboost-bi), [2](https://www.tensorflow.org/guide/keras/train_and_evaluate) and [3](https://www.tensorflow.org/api_docs/python/tf/keras/metrics) which delivers the information for eval_metrics.It helps.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54573\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54573\">No</a>\n"]}, {"number": 54572, "title": "[hlo] algebraic simplifier select not pred pattern ", "body": "select(not(pred), on_true, on_false) => select(pred, on_false, on_true)", "comments": ["I got below error message.\r\n```\r\nThe specified bucket does not exist.\r\n````", "> I got below error message.\r\n> \r\n> ```\r\n> The specified bucket does not exist.\r\n> ```\r\n\r\nI guess it is an infrastructure problem. I have notified our infrastructure team.", "> > I got below error message.\r\n> > ```\r\n> > The specified bucket does not exist.\r\n> > ```\r\n> \r\n> I guess it is an infrastructure problem. I have notified our infrastructure team.\r\n\r\nThanks.", "There was indeed an error in our infrastructure configuration, which I've now fixed -- the \"Details\" link for that job was pointing to the wrong place. It should be fixed for any future check runs.\r\n\r\nFYI, Code Check - Changed Files is not a blocking presubmit. It suggests clang and python format changes that may be needed to merge, but since we're still working on finding similar linter settings for internal and external presubmits it's not guaranteed that the suggested changes are necessary.", "> Now that we can see the presubmit error, it seems to indicate that algebraic_simplifier.cc has the wrong chmod config. It seems it has 755, but should have 644. Can you maybe check that, and if that is true, change it to 644?\r\n\r\nOk, I just checked that this wrong mode is pre-existing, still it seems this blocks merging of this PR. I could also try to change it, but then you would have to rebase once my change lands (and I am not sure if rebasing will do the right thing). Please let me know if you need help with changing the mode.", "I have fixed the permissions now in f4b9d3dbb2d55b73a9a02b4e31cbbf9d02bee32e\r\nCan you please rebase your PR? Lets hope this will keep the new file mode.", "Done."]}, {"number": 54571, "title": "Implement asynchronous checkpoint for the eager mode, i.e., context.running_eagerly().", "body": "Implement asynchronous checkpoint for the eager mode, i.e., context.running_eagerly().\n", "comments": []}, {"number": 54570, "title": "Support group conv2d in reference kernels", "body": "Support group conv2d in reference kernels\n", "comments": []}, {"number": 54569, "title": "Remove ExperimentalAssertNextDataset op.", "body": "Remove ExperimentalAssertNextDataset op.\n\nThis is a duplicate of AssertNextDataset.\n", "comments": []}, {"number": 54568, "title": "How to propagate gradients after a assign op?", "body": "Hello,\r\nI got the no gradient error if I changed the update of self.key_memory and self.long_memory to . assign. It seems that assign op would break gradient. If I used \"=\", then it will create a new tensor.\r\n\r\nWARNING:tensorflow:Gradients do not exist for variables ['memory_layer_write_controller/hidden_layer_0/kernel:0', 'memory_layer_write_controller/hidden_layer_0/bias:0', 'memory_layer_write_controller/hidden_layer_1/kernel:0', 'memory_layer_write_controller/hidden_layer_1/bias:0', 'memory_layer_key_erase_layer/hidden_layer_0/kernel:0', 'memory_layer_key_erase_layer/hidden_layer_0/bias:0', 'memory_layer_key_add_layer/hidden_layer_0/kernel:0', 'memory_layer_key_add_layer/hidden_layer_0/bias:0', 'memory_layer_long_erase_layer/hidden_layer_0/kernel:0', 'memory_layer_long_erase_layer/hidden_layer_0/bias:0', 'memory_layer_long_add_layer/hidden_layer_0/kernel:0', 'memory_layer_long_add_layer/hidden_layer_0/bias:0'] when minimizing the loss.\r\n\r\nclass MemoryLayer(tf.keras.layers.Layer):\r\ndef init(self, controller_layers, controller_hidden_act='relu', controller_output_act=None, n_clusters=100, key_dims=8, long_dims=8, short_dims=8, temperature=0.1, alpha=0.1, is_short=False, name=\"memory_layer\", **kwargs):\r\nsuper(MemoryLayer, self).init(name=name, trainable=True, **kwargs)\r\nself.controller_layers = controller_layers\r\nself.controller_hidden_act = controller_hidden_act\r\nself.controller_output_act = controller_output_act\r\nself.n_clusters = n_clusters\r\nself.key_dims = key_dims\r\nself.long_dims = long_dims\r\nself.short_dims = short_dims\r\nself.temperature = temperature\r\nself.alpha = alpha\r\nself.is_short = is_short\r\n\r\n    # self.key_memory = tf.compat.v1.get_variable(\r\n    #     f\"{self.name}_key_memory\",\r\n    #     shape=[self.n_clusters, self.key_dims],\r\n    #     initializer=tf.compat.v1.glorot_normal_initializer())\r\n    self.key_memory = self.add_weight(f\"{self.name}_key_memory\",\r\n                          shape=(self.n_clusters, self.key_dims),\r\n                          initializer=tf.keras.initializers.GlorotNormal(),\r\n                          trainable=True)\r\n\r\n\r\n    self.long_memory = self.add_weight(f\"{self.name}_long_memory\",\r\n                          shape=(self.n_clusters, self.long_dims),\r\n                          initializer=tf.keras.initializers.GlorotNormal(),\r\n                          trainable=True)\r\n\r\n    # self.long_memory = tf.compat.v1.get_variable(\r\n    #     f\"{self.name}_long_memory\",\r\n    #     shape=[self.n_clusters, self.long_dims],\r\n    #     initializer=tf.compat.v1.glorot_normal_initializer())\r\n\r\n    if is_short:\r\n        self.short_memory = self.add_weight(f\"{self.name}_short_memory\",\r\n                          shape=(self.n_clusters, self.short_dims),\r\n                          initializer=tf.keras.initializers.GlorotNormal(),\r\n                          trainable=False)\r\n\r\n        self.short_erase_layer = DNNLayer([self.short_dims], 'sigmoid',\r\n                                         name=f\"{self.name}_short_erase_layer\")  # short\u7684\u5220\u9664\u5c42\r\n        self.short_add_layer = DNNLayer([self.short_dims], 'tanh', name=f\"{self.name}_short_add_layer\")  #short\u7684\u66f4\u65b0\u5c42\r\n\r\n    self.write_controller = DNNLayer(controller_layers, controller_hidden_act, controller_output_act, name=f\"{self.name}_write_controller\") #write\u63a7\u5236\u5668\r\n\r\n    self.read_controller = DNNLayer(controller_layers, controller_hidden_act, controller_output_act, name=f\"{self.name}_read_controller\") #read\u63a7\u5236\u5668\r\n\r\n    self.key_erase_layer = DNNLayer([self.key_dims], 'sigmoid', name=f\"{self.name}_key_erase_layer\") #key\u7684\u5220\u9664\u5c42\r\n    self.key_add_layer = DNNLayer([self.key_dims], 'tanh', name=f\"{self.name}_key_add_layer\") #key\u7684\u66f4\u65b0\u5c42\r\n\r\n    self.long_erase_layer = DNNLayer([self.long_dims], 'sigmoid', name=f\"{self.name}_long_erase_layer\")  #long\u7684\u5220\u9664\u5c42\r\n    self.long_add_layer = DNNLayer([self.long_dims], 'tanh', name=f\"{self.name}_long_add_layer\")  # long\u7684\u66f4\u65b0\u5c42\r\n\r\n\r\n@tf.function\r\ndef call(self, inputs, training=None, **kwargs):\r\n    attr_emb = inputs[0]  # [batch_size, attr_emb]\r\n    long_emb = inputs[1]  # [batch, long_dims] \u957f\u671f\u5174\u8da3\u8868\u5f81\r\n    isActive = inputs[2]  # [batch_size, 1] \u662f\u5426\u9700\u8981\u66f4\u65b0long\u3001short memory\r\n\r\n    active_status = tf.cast(tf.transpose(isActive, perm=[1, 0]), dtype='float32')\r\n\r\n    denominator = tf.math.count_nonzero(isActive)  # \u7edf\u8ba1\u975e0\u7684\u4e2a\u6570\r\n\r\n    # \uff1e0\u624d\u66f4\u65b0\r\n    if denominator > 0 and training:\r\n        # write memory\r\n        # [batch_size, key_dims]\r\n        write_query = self.write_controller(tf.stop_gradient(attr_emb))  # \u83b7\u53d6\u5199\u63a7\u5236\u5668\u7684\u8868\u5f81\r\n\r\n        # [batch, n_clusters]\r\n        write_attention = compute_cosine_similarity(write_query, self.key_memory, temperature=self.temperature)\r\n        #\r\n        # #[1, n_clusters]\r\n        write_memory_attention = tf.matmul(active_status, write_attention) / tf.cast(denominator, dtype=tf.float32)\r\n\r\n        # [n_clusters, 1]\r\n        write_memory_attention = tf.transpose(write_memory_attention, perm=[1, 0])\r\n\r\n        # write key memory\r\n        key_erase_vector = self.key_erase_layer(write_query)  # [batch, key_dims]\r\n        key_erase_vector = tf.matmul(active_status, key_erase_vector) / tf.cast(denominator,\r\n                                                                                dtype=tf.float32)  # [1,key_dims]\r\n        #\r\n        key_add_vector = self.key_add_layer(write_query)  # [batch, key_dims]\r\n        key_add_vector = tf.matmul(active_status, key_add_vector) / tf.cast(denominator,\r\n                                                                            dtype=tf.float32)  # [1,key_dims]\r\n\r\n        key_val = tf.stop_gradient(self.key_memory) \\\r\n                          * (1. - self.alpha * tf.matmul(write_memory_attention, key_erase_vector)) \\\r\n                          + self.alpha * tf.matmul(write_memory_attention, key_add_vector)\r\n\r\n        # self.key_memory.assign(key_val)\r\n        tf.compat.v1.assign(self.key_memory, key_val)\r\n\r\n        # write long_memory\r\n        long_erase_vector = self.long_erase_layer(long_emb)  # [batch, long_dims]\r\n        long_erase_vector = tf.matmul(active_status, long_erase_vector) / tf.cast(denominator,\r\n                                                                                  dtype=tf.float32)  # [1,long_dims]\r\n        #\r\n        long_add_vector = self.long_add_layer(long_emb)  # [batch, long_dims]\r\n        long_add_vector = tf.matmul(active_status, long_add_vector) / tf.cast(denominator,\r\n                                                                              dtype=tf.float32)  # [1,long_dims]\r\n\r\n        long_val = tf.stop_gradient(self.long_memory) \\\r\n                           * (1. - self.alpha * tf.matmul(write_memory_attention, long_erase_vector)) \\\r\n                           + self.alpha * tf.matmul(write_memory_attention, long_add_vector)\r\n\r\n        # self.long_memory.assign(long_val)\r\n        tf.compat.v1.assign(self.long_memory, long_val)\r\n\r\n        # read memory\r\n    # [batch, key_dims]\r\n    read_query = self.read_controller(tf.stop_gradient(attr_emb))\r\n\r\n    # [batch, n_clusters]\r\n    read_attention = compute_cosine_similarity(read_query, self.key_memory, temperature=self.temperature)\r\n\r\n    # read_attention = self.read_sim_layer([read_query, self.key_memory], temperature=self.temperature)\r\n\r\n    long_cluster_emb = tf.matmul(read_attention, self.long_memory)  # [batch, long_dims] \u957f\u671f\u5174\u8da3\u8868\u5f81\r\n\r\n    return long_cluster_emb", "comments": ["Hi @pnuzyf ! Could you please share same code as Colab gist to expedite the issue?", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54568\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/54568\">No</a>\n"]}, {"number": 54567, "title": "[XLA] Use priority to represent multiple layout assignment passes in layout_assignment.cc without saving the intermediate result inside HLO and then clearing them.", "body": "[XLA] Use priority to represent multiple layout assignment passes in layout_assignment.cc without saving the intermediate result inside HLO and then clearing them.\n", "comments": []}, {"number": 54565, "title": "Replace _tpu_replicate with _xla_compile_device_type=TPU and _replication_info=X in MLIR TPU bridge.", "body": "Replace _tpu_replicate with _xla_compile_device_type=TPU and _replication_info=X in MLIR TPU bridge.\n", "comments": []}, {"number": 54564, "title": "#tf-data-service Add a utility function to compare dataset graphs.", "body": "#tf-data-service Add a utility function to compare dataset graphs.\n\nWhen the users need to register named datasets, this will be used\nto validate that the dataset graphs have the same structure.\n", "comments": []}, {"number": 54563, "title": "expose HloModule's spmd_parameters_shardings to python", "body": "expose HloModule's spmd_parameters_shardings to python\n", "comments": []}, {"number": 54562, "title": "Add send ops as control outputs on both lazy and non-lazy paths, so that they do not get removed in the following transformations.", "body": "Add send ops as control outputs on both lazy and non-lazy paths, so that they do not get removed in the following transformations.\n", "comments": []}, {"number": 54561, "title": "Add no_oss tag to failing tests.", "body": "Add no_oss tag to failing tests.\n", "comments": []}, {"number": 54560, "title": "XNNPack delegate to support delegating grouped conv2d op.", "body": "XNNPack delegate to support delegating grouped conv2d op.\n", "comments": []}, {"number": 54558, "title": "Support nnapi delegate to choose grouped con2d op.", "body": "Support nnapi delegate to choose grouped con2d op.\n", "comments": []}, {"number": 54557, "title": "This CL reduces the high average looping count (~4,435,487) in the RandomDims() utility function which slows down dependent tests; i.e. RFFT", "body": "This CL reduces the high average looping count (~4,435,487) in the RandomDims() utility function which slows down dependent tests; i.e. RFFT\n", "comments": []}, {"number": 54556, "title": "#tf-data-service Add a `dataset_name` param to `register_dataset`.", "body": "#tf-data-service Add a `dataset_name` param to `register_dataset`.\n\nIf multiple client jobs need to read from the same dataset, they can\nuse the same dataset name. The datasets with the same name should have\nthe same definition. Otherwise, it will raise an invalid argument\nerror.\n", "comments": []}, {"number": 54555, "title": "Check in the Python codes for TensorFlow quantization passes", "body": "Check in the Python codes for TensorFlow quantization passes\n", "comments": []}, {"number": 54554, "title": "Check in the test MLIR files for TensorFlow quantization passes", "body": "Check in the test MLIR files for TensorFlow quantization passes\n\nThe test codes will be enabled in the followup change.\n", "comments": []}, {"number": 54553, "title": "Change tag from nooss to no_oss.", "body": "Change tag from nooss to no_oss.\n\nOnly no_oss causes the test not to be run in OSS.\n", "comments": []}, {"number": 54552, "title": "Export current optimizer to legacy namespace. ", "body": "Export current optimizer to legacy namespace. \n\nA new-version optimizer is going to be available in TF 2.9 release. Although the new optimizer is now under experimental namespace, it will in future become the default optimizer. For backward compatibility, we will continue support the current optimizer in the legacy namespace.\n", "comments": []}, {"number": 54551, "title": "Add spmd_parameters_shardings to HloModuleProto.", "body": "Add spmd_parameters_shardings to HloModuleProto.\n", "comments": []}, {"number": 54550, "title": "Allow only float values for gelu.", "body": "Allow only float values for gelu.\n\nFixes #54475\n", "comments": []}]