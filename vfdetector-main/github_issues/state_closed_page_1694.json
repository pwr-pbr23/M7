[{"number": 2080, "title": "Fix markdown syntax of skflow README.md", "body": "I find it very inconvenient since links are not clickable and code blocks are not highlighted.\n", "comments": ["Can one of the admins verify this patch?\n", "You may also want to remove license and pypi badges.\nI moved them from the bottom because I couldn't decide whether you still need them.\n", "Great! Simply removing them should be fine. \n", "OK, removed them.\n", "@tensorflow-jenkins please test this!\n", "@tensorflow-jenkins test this please.\n"]}, {"number": 2079, "title": "Attention Mask Ops", "body": "The current attention seq2seq example (i.e., in seq2seq.py function attention_decoder) has a bug. The code (quoted below):\n\n520     def attention(query):\n521       \"\"\"Put attention masks on hidden using hidden_features and query.\"\"\"\n522       ds = []  # Results of attention reads will be stored here.\n523       for a in xrange(num_heads):\n524         with variable_scope.variable_scope(\"Attention_%d\" % a):\n525           y = rnn_cell.linear(query, attention_vec_size, True)\n526           y = array_ops.reshape(y, [-1, 1, 1, attention_vec_size])\n527           # Attention mask is a softmax of v^T \\* tanh(...).\n528           s = math_ops.reduce_sum(\n529               v[a] \\* math_ops.tanh(hidden_features[a] + y), [2, 3])\n530           a = nn_ops.softmax(s)\n531           # Now calculate the attention-weighted vector d.\n532           d = math_ops.reduce_sum(\n533               array_ops.reshape(a, [-1, attn_length, 1, 1]) \\* hidden,\n534               [1, 2])\n535           ds.append(array_ops.reshape(d, [-1, attn_size]))\n536       return ds\n\ndoes not do a masking op before the softmax. This git pull request will fix this problem, i.e., we should mask the attention energies before the softmax based on the encoder sequence length.\n", "comments": ["Can one of the admins verify this patch?\n", "this is in reference to this issue: https://github.com/tensorflow/tensorflow/issues/512\n", "I agree that it would be good to add masking to the attention model and API. But I think adding an op and a separate cuda kernel just for that is a huge overkill. Why not just multiply pointwise by the mask in python before the softmax? Without a good reason, I find a PR like this not acceptable, the code complexity and maintenance cost looks much larger than the simple problem it solves.\n", "sometimes the mask is generated dynamically (i.e., the mask is a function\nof the previous attention)...\n\nfor example in speech recognition: Bahdanau/Chorowski et. al.,\nhttp://arxiv.org/pdf/1508.04395.pdf\nhttp://papers.nips.cc/paper/5847-attention-based-models-for-speech-recognition.pdf\n\n## \n\nWilliam Chan\nCarnegie Mellon University\n(650) 450-9455\nwilliamchan.ca\n\nOn Mon, Apr 25, 2016 at 11:28 PM, Lukasz Kaiser notifications@github.com\nwrote:\n\n> I agree that it would be good to add masking to the attention model and\n> API. But I think adding an op and a separate cuda kernel just for that is a\n> huge overkill. Why not just multiply pointwise by the mask in python before\n> the softmax? Without a good reason, I find a PR like this not acceptable,\n> the code complexity and maintenance cost looks much larger than the simple\n> problem it solves.\n> \n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/2079#issuecomment-214628517\n", "It is possible that I don't understand the problem, so please, clarify. But why would it need a special op to make the mask a function? If it's a tensor of 0s and 1s, it can be changed at every step, why can't this be done the simple way in python? Is there a very big speed advantage to having an extra op?\n", "Well, the python side does not know what mask to generate (i.e., it doesnt\nknow the sequence_len of each sample in the minibatch). This is especially\ntrue in speech where your minibatch has a high variance in sequence_len.\nHowever, this problem can be somewhat alleviated to generate the mask of 1\nand -FLT_MAX (not 1 and 0), if our input layer generates that for us.\n\nHowever, this is not true for all attention masks, for example in speech\nrecognition where the encoder length can be thousands of frames, we want\nthe attention mask to be a function of the previous attention alignment,\ni.e., in the papers I cited above, they generate the mask by looking at the\nmedian of the previous attention and then use a window around it (in\nessence, you have a somewhat monotonic sliding window on where to attend\nto). Correct me if I am wrong, but I believe this can not be generated\npython side?\n\nIts not a speed advantage, (correct me if I am wrong), but I don't think\nyou can mask properly w/o an op like this.\n\n## \n\nWilliam Chan\nCarnegie Mellon University\n(650) 450-9455\nwilliamchan.ca\n\nOn Mon, Apr 25, 2016 at 11:45 PM, Lukasz Kaiser notifications@github.com\nwrote:\n\n> It is possible that I don't understand the problem, so please, clarify.\n> But why would it need a special op to make the mask a function? If it's a\n> tensor of 0s and 1s, it can be changed at every step, why can't this be\n> done the simple way in python? Is there a very big speed advantage to\n> having an extra op?\n> \n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/2079#issuecomment-214635456\n", "I was thinking about it a bit and I still don't see the problem. Here is how I'd do it:\n- add a parameter to attention_decoder called mask_function\n- this parameter is a python function that takes the step number and the previous attention mask tensor\n  and outputs a new attention mask tensor\n- every attention is multiplied by mask_function(prev_attention, step_number) (one-liner in python)\n\nWould that work? If you want to feed-in attention, you'd just provide mask_function(_, i) = length-tensor[i] so you can feed the example lengths. And if you want to average by previous (or move it with a step), you just need to write a lambda that does it.\n\nOr am I missing something crucial here?\n", "sorry, didnt quite catch the last step:\n\n> you'd just provide mask_function(_, i) = length-tensor[i]\n> \n> how does \"length - tensor[i]\" generate the mask? length is a tensor of the\n> sample length? and tensor[i] is what? and doesn't this result in a scalar\n> not a mask?\n\nthanks!\n", "ok. i think ur right, just need a tf.cond or something similar in the\nmask_function right? and then use that to generate the mask?\n\n## \n\nWilliam Chan\nCarnegie Mellon University\n(650) 450-9455\nwilliamchan.ca\n\nOn Tue, Apr 26, 2016 at 11:15 PM, William Chan williamchan@cmu.edu wrote:\n\n> sorry, didnt quite catch the last step:\n> \n> > you'd just provide mask_function(_, i) = length-tensor[i]\n> > \n> > how does \"length - tensor[i]\" generate the mask? length is a tensor of the\n> > sample length? and tensor[i] is what? and doesn't this result in a scalar\n> > not a mask?\n> \n> thanks!\n", "To answer your question, let me be a little bit more precise. What I suggest is to modify the [seq2seq.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/seq2seq.py) in two ways.\n\n(1) on lines 546, 565, 567 instead of `attns = attention(state)` let's do `attns = attention(state, attns, inp, i)` so the `attention()` function now takes the arguments `attention(query, previous_attention, decoder_input, step_number)`\n\n(2) on line 530 instead of `a = nn_ops.softmax(s)` let's do `a = nn_ops.softmax(s + mask_f(previous_attention, decoder_input, step_number) * -LARGE_NUMBER` where `mask_f` is an extra argument to the decoder.\n\nIn this way the mask_f function gets all the current information in the step. Its task is to generate 1.0 (or anything positive) if we want to mask something and 0.0 otherwise. The 1.0 will be turned into a -LARGE_NUMBER bias in the softmax and effectively disable that field for attention, right?\n\nThe tensor s has shape [batch_size x attn_length], where attn_length is the size of the attention_states (length of the encoder in a seq2seq model). Let me focus on the basic case when we want mask_f to mask an input iff the decoder input symbol is a padding, which means that it is all zeros. We can do this in two ways, I think. If we're sure the decoder input is all 0s only if it's padded and has a reasonably large norm otherwise, then we can do `mask_f(_, dec_inp, _) = tf.minimum(1.0, tf.nn.l2_loss(dec_inp) * LARGE)`. If we're not sure of that, then we can do `mask_f(_, _, step) = self.decoder_mask[i]` when declaring the `mask_f` function somewhere in our model code. In this case `decoder_mask` are placeholders of the same kind as `decoder_inputs` that are 1 in case of padding and 0 otherwise -- and we need to make sure to feed the appropriate values.\n\nI'm sure I missed some things. In particular, `previous_attention` coming to the `attention` function should probably be the previous attention mask, not the previous attention vector as I suggested above (so the new mask needs to be returned in the function and the pointer saved in the loop, a few more lines). But does the general idea sound reasonable and flexible enough?\n", "I agree in general your idea works. Just some minor things...\n\n> The tensor s has shape [batch_size x attn_length], where attn_length is\n> the size of the attention_states (length of the encoder in a seq2seq\n> model). Let me focus on the basic case when we want mask_f to mask an input\n> iff the decoder input symbol is a padding, which means that it is all\n> zeros. We can do this in two ways, I think. If we're sure the decoder input\n> is all 0s only if it's padded and has a reasonably large norm otherwise,\n> then we can do mask_f(_, dec_inp, _) = tf.minimum(1.0,\n> tf.nn.l2_loss(dec_inp) \\* LARGE). If we're not sure of that, then we can\n> do mask_f(_, _, step) = self.decoder_mask[i] when declaring the mask_f\n> function somewhere in our model code. In this case decoder_mask are\n> placeholders of the same kind as decoder_inputs that are 1 in case of\n> padding and 0 otherwise -- and we need to make sure to feed the appropriate\n> values.\n> \n> The problem w/ this approach is (where self.decoder_inputs is generated by\n> the input layer), is that the encoder may have a pyramid architecture\n> (i.e., time subsampling) which is very common in speech. i.e., depending on\n> the graph, we may reduce it by 4/8/16 multipliers. so we need to know this\n> ahead of time (the time factor reduction) and pass that in to the input op\n> that is generating the mask.\n\nWhere as w/ a op that does the masking for you where you only need to pass\nin the sequence_length, every time we do hierarchical subsampling in the\ngraph, we can just do sequence_length_tensor = sequence_length_tensor / 2;\nenergies = attention_mask(energies, sequence_length);\n\nHowever, I think this problem can be alleviated by tf.cond(), where we can\ndo something like tf.cond(sequence_length < encoder_idx, 0, -FLT_MAX),\nsomething like that... however we need to do this T times where T is the\nlength of the encoder and encoder_idx \\in range(0, T).\n\nBut I agree w/ you, I think (havent completely tested it out) you are right\nthis can be done almost completely w/ the existing python ops. Personally,\nI'll still be using my op since I already wrote it and it works and it\nshould be slightly faster (and simplier graph). But we can close this PR if\nyou think this is adding too much code to maintain.\n"]}, {"number": 2078, "title": "remove unused array assignment", "body": "The `array` in\n\n```\narray = np.random.rand(32, 100, 100)\n```\n\nin the context \n\n```\nimport numpy as np\narray = np.random.rand(32, 100, 100)\n\ndef my_func(arg):\n  arg = tf.convert_to_tensor(arg, dtype=tf.float32)\n  return tf.matmul(arg, arg) + arg\n\n# The following calls are equivalent.\nvalue_1 = my_func(tf.constant([[1.0, 2.0], [3.0, 4.0]]))\nvalue_2 = my_func([[1.0, 2.0], [3.0, 4.0]])\nvalue_3 = my_func(np.array([[1.0, 2.0], [3.0, 4.0]], dtype=np.float32))\n```\n\nis never used. I suggest removing it for clarity.\n", "comments": ["Can one of the admins verify this patch?\n", "The markdown file is auto-generated from a docstring in `tensorflow/python/framework/ops.py`. Can you please make the change there?\n", "Can one of the admins verify this patch?\n", "Can one of the admins verify this patch?\n", "@mrry Ah, sorry about that ... that was quite stupid; reverted the previous change and applied the fix to the ops.py file now\n", "@tensorflow-jenkins, test this please.\n", "Thanks for the fix! It looks like Jenkins isn't listening to me, so I'm going to go ahead and merge it directly.\n"]}, {"number": 2077, "title": "Gradient of TensorArray updated during while loop yields error", "body": "GitHub issues are for bugs / installation problems / feature requests.  \nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\n\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\n### Environment info\n\nOperating System: Mac OS X 10.11.4\n\nInstalled version of CUDA and cuDNN: none\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed: Installed from source\n2. The output from python -c \"import tensorflow; print(tensorflow.**version**)\": 0.8.0rc0\n\nIf installed from sources, provide the commit hash:\ncommit 504e8a6ac678f83f88862b3826d54bb9b484cc33\n### Steps to reproduce\n1. See http://stackoverflow.com/questions/36807107/strange-error-when-taking-gradient-of-tensorarray\n### What have you tried?\n1. I've tried removing the while loop (just writing out one iteration) and it works.  Introducing the while loop back in yields error.\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\nSee http://stackoverflow.com/questions/36807107/strange-error-when-taking-gradient-of-tensorarray\n", "comments": ["@yuanbyu Could that be related to the recent gradients code in while/loop?\n", "I will have to take a look.  My guess is that the gradient code for one of the TensorArray ops missed a dependency, resulting in reading an unwritten slot.\n", "I see you are performing an unpack to write into one of the TensorArrays.  Though I haven't taken a careful look at the code, make sure all the elements you unpack have a corresponding read or you have a pack(); otherwise there may be no gradient written to the corresponding slot at runtime.\n\nIt's also easier to debug if you can write a very simple failing case.\n", "When reading an unwritten slot from a gradient TensorArray, could we return zeros instead of an error?\n", "Is it actually reading an unwritten slot?  At least in the forward stage, all read slots should be previously written to.\n", "They should all be read from also.\nOn Apr 27, 2016 11:32 AM, \"ofirnachum\" notifications@github.com wrote:\n\n> Is it actually reading an unwritten slot? At least in the forward stage,\n> all read slots should be previously written to.\n> \n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/2077#issuecomment-215184037\n", "This should also be the case.  In fact, when I replace the 'while' loop with a written out single iteration (equivalent in the case that I test), the code works fine forwards and backwards.  So I would assume there is something to do with using the TensorArray's inside the while loop that is causing issues.\n", "Are you using a separate tensor array inside each while loop iteration?\nOn Apr 28, 2016 7:29 PM, \"ofirnachum\" notifications@github.com wrote:\n\n> This should also be the case. In fact, when I replace the 'while' loop\n> with a written out single iteration (equivalent in the case that I test),\n> the code works fine forwards and backwards. So I would assume there is\n> something to do with using the TensorArray's inside the while loop that is\n> causing issues.\n> \n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/2077#issuecomment-215613376\n", "The inner handle of the tensor array should be the same through all iterations.  The style is similar to _dynamic_rnn_loop in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn.py\n(the TensorArray is written-to to yield a new TensorArray which is passed to the next iteration - the difference in my code is that the array is also read from).\n", "We haven't tested your use case very carefully.  I'll have to review your\ncode.. May be a few weeks unless Yuan has time to do it before I get to it.\nOn Apr 28, 2016 7:49 PM, \"ofirnachum\" notifications@github.com wrote:\n\n> The inner handle of the tensor array should be the same through all\n> iterations. The style is similar to _dynamic_rnn_loop in\n> https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn.py\n> (the TensorArray is written-to to yield a new TensorArray which is passed\n> to the next iteration - the difference in my code is that the array is also\n> read from).\n> \n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/2077#issuecomment-215615001\n", "@ebrevdo, @yuanbyu: What's the status of this?  \n", "We have a bug in gradient support for unpack and split of dynamic TensorArray. I have a pending CL fixing this problem.\n"]}, {"number": 2076, "title": "Including timestamp with tf.Print?", "body": "I'm trying to implement a batched version of the Inception example for TensorFlow Serving, and I'd like to benchmark the performance. \n\nIs it possible to have `tf.Print` emit a timestamp along with the logging information? Particularly if the op is bundled via `tensorflow_serving.session_bundle.exporter`?\n\nI think it's possible to do with:\n\n`x = tf.Print(x, [x], \"(%s) Obtained: \" % asctime())`\n\nalthough I'm not sure if this will work appropriately when exported.\n", "comments": ["That won't work, I'm afraid: `asctime()` will be evaluated once when you build the graph in Python, and all log entries will include the same timestamp. The `tf.Print()` op uses the [standard logging implementation in TensorFlow](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/default/logging.h), which does not have a particularly rich feature set.\n\nIt might be useful to add a timestamp to all log entries, but that would be a fairly invasive change. Alternatively, one could add some ops (perhaps in `tf.contrib`) that returned/formatted the current time, so that you could build whatever log you wanted.\n\nI'll mark this one contributions welcome.\n", "@eriophora you can use a placeholder, no need to add code\n\n```\n cti=tf.placeholder(tf.string,shape=(1,1))   \n z=tf.constant(10)                               \n y=tf.Print(z,[cti,z])                    \n with tf.Session() as sess:                                \n         for i in range(10):\n         time.sleep(1)                          \n         ti=time.asctime()    \n         xx=np.array([ti],ndmin=2)         \n         y.eval(feed_dict={cti:xx}) \n```\n", "blocked by #5682\n", "Are we ready to proceed on this?", "drpngx@ should be merged soon.", "One second granularity is a bit too coarse for benchmarking, it would be nice to get microsecond granularity in LOG statements , ie, using `NowMicros` instead of `NowSeconds`. Maybe something like this in `GenerateLogMessage`?\r\n\r\n```\r\nchar time_buffer[time_buffer_size];\r\nuint64 micros = env_time->NowMicros()\r\ntime_t now = static_cast<time_t>(micros/1000000);\r\nstrftime(time_buffer, time_buffer_size, \"%Y-%m-%d %H:%M:%S:%d\", localtime(&now));\r\nfprintf(stderr, \"%s:%ld: %c %s:%d] %s\\n\", time_buffer, micros%1000000, \"IWEF\"[severity_], fname_, line_, str().c_str());\r\n```"]}, {"number": 2075, "title": "tf.unravel_index (Was: tf.argmin across all dimensions)", "body": "Hi,\n\ntf.argmin only works in one dimension.\nLet's say I have a picture which is a 2x2 array of pixels (each pixels is a 3 value array) and I want to know which pixel is closest to a certain color. In that case I have to reshape the 2x2 array to a 1-D array then get the min index, then find out that index to what 2x2 array position corresponds.\n\nCouldn't I just as tensorflow to give me the index in the 2x2 array. For instance [1,15]?\n\nI really don't understand the reason for having to translate between lineal index and array location all the time.\n\nThanks.\n", "comments": ["I think it'd be better to handle this the way numpy does it, with `np.unravel_index`: https://bytes.com/topic/python/answers/509074-numpy-argmin-multidimensional-arrays.  Making `tf.argmin` do this directly would either require a new op or an unpleasant boolean flag that indexes over everything, and it still wouldn't be what you want since most of time you want to minimize over some but not all of the dimensions (e.g., the last three dims of a 4D batched image tensor).\n\nCc @aselle since `unravel_index` sounds vaguely index related, but I'll mark this contributions welcome for now.\n", "where is tf.unravel_index in the document? I cannot find it.\nThank you.\n", "Not sure which document you mean, but `tf.unravel_index` doesn't exist yet.  `np.unravel_index` is described in that thread I linked to.\n", "Yeah. I know np.unravel_index. but can np.unravel_index be used to build the graph?\nI write a simple example. How to achieve that using Tensorflow?\nThank you.\n\n```\nksize = 3\nstride = 1\n\ninput_image = tf.placeholder(tf.float32, name='input_image')\n\n#conv1\nkernel = tf.Variable(tf.truncated_normal([ksize, ksize, 3, 16],stddev=0.1),\n                    name='kernel')\nconv = tf.nn.conv2d(input_image, kernel, [1,stride,stride,1], padding='SAME')\nbiases = tf.Variable(tf.constant(0.0, shape = [16]), name = 'biases')\nbias = tf.nn.bias_add(conv, biases)\nconv1 = tf.nn.relu(bias, name='conv1')\n\n#pool1\npool1, pool1_indices = tf.nn.max_pool_with_argmax(conv1, ksize=[1, 2, 2, 1], \n                                                  strides=[1, 2, 2, 1], \n                                                  padding='SAME', name='pool1')\n\n#upsample by assigning the values of pool1 to the position in unpooling Tensor according to pool1_indices                                                \nindices = pool1_indices\nunravel_pool1_indices = np.unravel_index(indices,[4,32,32,16])\nunravel_pool1_coordinates = np.array(unravel_pool1_indices)\ncoor_shape = np.shape(unravel_pool1_coordinates)\nunravel_pool1_coordinates = np.reshape(unravel_pool1_coordinates,(coor_shape[0],coor_shape[1]*coor_shape[2]*coor_shape[3]*coor_shape[4]))\nunravel_pool1_coordinates = unravel_pool1_coordinates.T\n\nvalues = pool1\nvalues = np.reshape(values,(np.size(values)))\n\nup1 = tf.constant(0.0, shape = [4,32,32,16])\ndelta = tf.SparseTensor(unravel_pool1_coordinates, values, shape = [4,32,32,16])\n\nresult = up1 + tf.sparse_tensor_to_dense(delta)\n\n\nwith tf.Session() as session:\n    session.run(tf.initialize_all_variables())\n    test_image = np.random.rand(4,32,32,3)\n    sess_outputs = session.run([pool1, pool1_indices],\n                               {input_image.name: test_image})\n```\n", "Someone would have to write a TensorFlow version of `np.unravel_index`, which could be called `tf.unravel_index`.  We might not do that soon, so PRs adding it would be welcome.  `tf.unravel_index` could either be a new C++ op or something written in Python.\n", "Here's a sketch of a possible Python implementation using `cumprod`:\n\n``` python\nimport tensorflow as tf\n\ndef unravel_index(indices, shape):\n  with tf.name_scope('unravel_index'):\n    indices = tf.expand_dims(indices, 0)\n    shape = tf.expand_dims(shape, 1)\n    strides = tf.cumprod(shape, reverse=True)\n    strides_shifted = tf.cumprod(shape, exclusive=True, reverse=True)\n    return (indices // strides_shifted) % strides\n\ns = tf.Session()\nout = unravel_index([22, 41, 37], (7, 6))\nprint(s.run(out))\n# ==> [[3 6 6]\n#      [4 5 1]]\n```\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "@ibab The last line in the function `unravel_index` should be `return (indices % strides) // strides_shifted`.\r\n", "I think `unravel_index` is quite a useful feature that could be used in many places. Created a PR #14895 to add the C++ kernel for it. Please take a look if interested.", "@ibab @meijun \r\n\r\nIn fact, the implementation must depend on the parity of the rank of the shape. \r\n\r\nFollowing modification works for both cases and runs smoothly on cpu and gpu.\r\n```\r\ndef unravel_index(indices, shape):\r\n    indices = tf.expand_dims(indices, 0)\r\n    shape = tf.expand_dims(shape, 1)\r\n    shape = tf.cast(shape, tf.float32)\r\n    strides = tf.cumprod(shape, reverse=True)\r\n    strides_shifted = tf.cumprod(shape, exclusive=True, reverse=True)\r\n    strides = tf.cast(strides, tf.int32)\r\n    strides_shifted = tf.cast(strides_shifted, tf.int32)\r\n    def even():\r\n        rem = indices - (indices // strides) * strides\r\n        return rem // strides_shifted\r\n    def odd():\r\n        div = indices // strides_shifted\r\n        return div - (div // strides) * strides\r\n    rank = tf.rank(shape)\r\n    return tf.cond(tf.equal(rank - (rank // 2) * 2, 0), even, odd)\r\n```\r\n\r\n"]}, {"number": 2074, "title": "Add a link for installing from sources in os_setup.md", "body": "Add a link for installing from sources in os_setup.md\n", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins test this please\n(and as a test for yourself along the way)\n"]}, {"number": 2073, "title": "solve compatibility issue for ubuntu 16.04", "body": "Ubuntu 16.04 LTS has update default `gcc` to 5.3 and `string.h` as well, even we install a `gcc-4.9`,\nwe will get a bug like\n\n```\nusr/include/string.h: In function 'void* __mempcpy_inline(void*, const void*, size_t)':\n/usr/include/string.h:652:42: error: 'memcpy' was not declared in this scope\n     return (char *) memcpy (__dest, __src, __n) + __n;\n```\n\nthis bus is described in https://github.com/tensorflow/tensorflow/issues/1346\nand can be solved by \ninsert `cxx_flag: \"-D_FORCE_INLINES\"` into `tensorflow/third_party/gpus/crosstool/CROSSTOOL`\n", "comments": ["Can one of the admins verify this patch?\n", "I've confirmed this commit solved my same issue. :-)\n", "This change has more impact that this issue alone. So I would like to find out whether there is another way. \n1. Is aggregate_ops_gpu.cu.cc the only *.cu.cc translation unit that has this problem? You can continue to build with \"-k\". \n2. Could you list the header file inclusion order from aggregate_ops_gpu.cu.cc to the offending header file on your system? We should check whether all of them are necessary.\n", "I can confirm that the problem is not confined to aggregate_ops_gpu.cu.cc. On my home Ubuntu 16.04 machine, if I\nbazel build -k -c opt --config=cuda //tensorflow/cc:tutorials_example_trainer  \nI get ~190 instances of the same error (presumably that's almost all of the CUDA code).\n\nThe suggested fix works for me.\n", "@zheng-xq @fayeshine any updates? \n", "friendly ping for updates?\n", "@vrv @zheng-xq sorry for the late reply, I'm sorry that I don't have enough to further work on this problem. This will touch too much fundamental code in c++ and cuda. If someone can help this, welcome.\n", "Have we changed this recently? I have just build \"bazel test //tensrflow/...\" without any error on 16.04...\n\nI will setup CI build for it tomorrow then we will know for sure :)\n", "@jendap what if you do`bazel test --config=cuda` \n", "@zheng-xq: apparently discussion on https://github.com/torch/torch7/issues/670 suggests that others have\n\n1) added this flag FORCE_INLINES\n\n2) Suggested people move to cuda 8.0 RC which apparently fixes the problem. \n", "#2 seems to be good path right now. \n", "ok, closing, since it sounds like a cuda / nvidia problem that has a workaround (upgrade), and we'd rather not add the large hammer of FORCE_INLINES in our entire build\n", "It's the right way to fix it\n"]}, {"number": 2072, "title": "run image_retraining always get  \u2018integer division or modulo by zero\u2019", "body": "I tried `bazel build tensorflow/examples/image_retraining:retrain && \\\nbazel-bin/tensorflow/examples/image_retraining/retrain \\\n--image_dir ~/flowers`\nbut get `retrain.py\", line 257, in get_image_path\n    mod_index = index % len(category_list)\nZeroDivisionError: integer division or modulo by zero\n`\nI have got some files, like  flower.jpg.txt. \nwhy the length of category list could be zero?\n", "comments": ["You probably saw this warning when running: `WARNING: Folder has less than 20 images, which may cause issues.`\n\nThe retrain script randomly assigns images into three sets: 'training', 'testing', and 'validation' in a way that means you may have 0 validation files if you have less than 20 total training images for a particular label. Try adding at least 20 images per label and you should be good.\n\nHere is the comment in tensorflow/tensorflow/examples/image_retraining/retrain.py that explains what is happening:\n`# This looks a bit magical, but we need to decide whether this file should\n      # go into the training, testing, or validation sets, and we want to keep\n      # existing files in the same set even if more files are subsequently\n      # added.\n      # To do that, we need a stable way of deciding based on just the file name\n      # itself, so we do a hash of that and then use that to generate a\n      # probability value that we use to assign it.`\n", "thanks  for ur answer,I just fixed it by set a constant value when it get zero.and I got the final pb file and test will.\n", "After step 0 of finding train accuracy and cross entropy , i am getting error:\nCRITICAL :tensorflow : category has no images - validation.\n.\n.\n.\nZeroDivisionError: integer division or modulo by zero\n\nI have two class folders : darth vader = 60 images of darth vader and darth maul =60 images.\nKindly suggest solution\n", "I had the same issue, I resolved it by increasing the number of images.\nI was experiencing it with 31 images per label, it disappeared after increasing this number to over 40 per label\n", "Thanks , I will check this out\n\nOn 8 November 2016 at 06:40, Pawel Ratajczak notifications@github.com\nwrote:\n\n> I had the same issue, I resolved it by increasing number of images.\n> I was experiencing it with 31 images per label, it disappeared after\n> increasing this number to over 40 per label\n> \n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/2072#issuecomment-259153218,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AL-XBxa_RBSsnM0Dq-U0qDCsY_olgv0tks5q8InigaJpZM4IOLfz\n> .\n", "so i have about 30 in each folder (not the same number in each). all category look similar. works fine. add to more categorys and i end up here... i fear overriding this if i can photos are hard to find for me...\r\n", "Why not ensuring that there is at least an image in validation? At least it does not crash.\r\nI've modified retrain.py to ensure that at least there is an image in validation (line 201)\r\n\r\n```\r\nif len(validation_images) == 0:\r\n   validation_images.append(base_name)\r\nelif percentage_hash < validation_percentage:\r\n```", "it worked.. i increased image sizes above 25.. ", "For those who have more than 50 images per class and still get the error: The code only works with .jpg files, you need to add 'png' to the list of extensions in 'retrain.py'."]}, {"number": 2071, "title": "Tensorflow placeholders and exporting to c++", "body": "Hello everyone,\n\nMy TF installation is working fine, but I'm running into a serious issue when exporting my trained model to a c++ environment. I'm trying to do something similar to this tutorial:\nhttps://www.tensorflow.org/versions/r0.8/tutorials/image_recognition/index.html\n\nI replaced the inception model with my own trained model, however, the graph won't run in c++. My own model is based on this tutorial:\nhttps://www.tensorflow.org/versions/r0.8/tutorials/mnist/pros/index.html#deep-mnist-for-experts\n\nIt gives me this error:\n\nRunning model failed: Invalid argument: You must feed a value for placeholder tensor 'Placeholder' with dtype float\n     [[Node: Placeholder = Placeholder[dtype=DT_FLOAT, shape=[], _device=\"/job:localhost/replica:0/task:0/cpu:0\"]()]]\n\nThe problem appears to be the placeholders at the input layer of my model. The model expects a feed_dict for them, but I don't believe there is c++ API for defining feed_dicts? If placeholders cannot be used with c++ API, I wonder how I should set up the input layer of my model for use with c++.\n\nThanks!\n", "comments": ["PS: I used the freeze_graph method to save my model.\n", "I think I [answered your question](http://stackoverflow.com/a/36817586/3574081) on Stack Overflow.\n\n(To save other readers a click, the `inputs` argument to `tensorflow::Session::Run()` is equivalent to the `feed_dict` in `tf.Session.run()`.)\n"]}, {"number": 2070, "title": "Guide Tensorflow for JAVA EE", "body": "Hello all,\n\nDo we have any guideline or document to help get started with JAVA EE? In case we want to build with Java server application.\n\nBest regards\nJohnny\n", "comments": ["I'm not aware that this issue has been raised before.  Could you clarify what you think the problems are?\n", "Thanks @poxvoculi for the response.\nI've just start for researching solution for integration Tensorflow with Java web app, so I wondering if there is any document available for that.\n", "There is no supported Java API for TensorFlow at present, but you could look at the source of the [Android JNI wrapper](https://github.com/tensorflow/tensorflow/tree/e39d8feebb9666a331345cd8d960f5ade4652bba/tensorflow/examples/android/jni) for guidance in how to build your own interface.\n", "Thank you @mrry \nOk, I will check with that.\n"]}, {"number": 2069, "title": "FIFOBucketedQueue", "body": "New FIFOBucketedQueue! This queue is similar to the existing FIFOQueue but w/ buckets. This allows you to use the same graph for all your buckets rather than creating multiple graphs for each bucket (i.e., as shown in the TF examples for seq2seq). The main advantage is having a single graph (makes creating a graph much faster and simplier python code). Finally, for those unfamiliar w/ bucketing, see Sutskever et al., 2014 \"Sequence to Sequence Learning with Neural Networks\", it is a strategy to sample by say sequence length to reduce the variance of each minibatch, and consequently be much more efficient in computation (at the cost of losing uniform sampling, however this doesn't seem to be a big problem w/ large datasets).\n\nFIFOBucketedQueueTest also included ; )\n", "comments": ["Can one of the admins verify this patch?\n", "I've been able to replicate this behavior by constructing n+1 padded queues and using tf.case (default a noop).  n queues, one for each bucket, deququeing batch_size elements and enqueueing the result in a single enqueue to the final queue you will read from.\n", "You'll also need Queue.from_list\n", "update on this?  @ebrevdo @wchan \n", "We'll work together to see if we can build a simple implementation using\nqueues.  That said, this approach has a certain appeal to me.\nOn May 24, 2016 2:13 PM, \"Vijay Vasudevan\" notifications@github.com wrote:\n\n> update on this? @ebrevdo https://github.com/ebrevdo @wchan\n> https://github.com/wchan\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/2069#issuecomment-221394836\n", "At the very least I'd like this to work more like PaddingFIFOQueue, if we go with this approach.\n", "Closing due to inactivity\n"]}, {"number": 2068, "title": "No mechanism for handling user-defined Tensor wrappers in the arguments to `Session.run()`", "body": "GitHub issues are for bugs / installation problems / feature requests.  \nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\n\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\n### Environment info\n\nOperating System: Ubuntu 14.04\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\n-rw-r--r-- 1 root root   322936 Feb 25 17:24 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Feb 25 17:24 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx 1 root root       19 Feb 25 17:24 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18\n-rwxr-xr-x 1 root root   383336 Feb 25 17:24 /usr/local/cuda/lib64/libcudart.so.7.5.18\n-rw-r--r-- 1 root root   720192 Feb 25 17:24 /usr/local/cuda/lib64/libcudart_static.a\n-rwxr-xr-x 1 root root 61453024 Feb 25 17:38 /usr/local/cuda/lib64/libcudnn.so\n-rwxr-xr-x 1 root root 61453024 Feb 25 17:38 /usr/local/cuda/lib64/libcudnn.so.4\n-rwxr-xr-x 1 root root 61453024 Feb 25 17:38 /usr/local/cuda/lib64/libcudnn.so.4.0.7\n-rw-r--r-- 1 root root 62025862 Feb 25 17:38 /usr/local/cuda/lib64/libcudnn_static.a\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\n\nVersion: 0.8.0rc0\n1. The output from python -c \"import tensorflow; print(tensorflow.**version**)\".\n\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\n0.8.0rc0\n\nIf installed from sources, provide the commit hash:\n### Steps to reproduce\n\nA simple script to illustrate what I'm trying to do is pasted below. The conversion function works as advertised when applying a downstream TensorFlow operator to a registered class. However, it appears that the run function does not try to apply registered conversion functions to the fetches. It seems intuitive that it would try. Adding in this functionality would make libraries built on top of TensorFlow feel a bit more seamless.\n\n``` python\nimport numpy as np\nimport tensorflow as tf\n\n\n# create some dummy class that wraps a tensor\nclass SquaredTensor(object):\n    def __init__(self, tensor):\n        self.sq = tf.square(tensor)\n\n\n# create conversion function back to a tensor\ndef squared_to_tensor(value, dtype=None, name=None, as_ref=False):\n    return value.sq\n\n# register conversion function\ntf.register_tensor_conversion_function(SquaredTensor, squared_to_tensor)\n\nwith tf.Session() as sess:\n    a = np.random.random(1000)\n    b = SquaredTensor(a)\n\n    # works as intended when a tf function is applied to class with conversion function\n    c = tf.sqrt(b)\n    c_eval = sess.run([c])\n    assert np.allclose(a, c_eval)\n\n    # directly evaluating the registered class fails\n    # seems like this should work by trying to apply conversions on run fetches:\n    # b_eval = sess.run([b])\n    # instead we need to explicitly convert:\n    b_eval = sess.run([b.sq])\n    assert np.allclose(a*a, b_eval)\n```\n### What have you tried?\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n\nTrying to fetch a SquaredTensor directly yields:\n\n`TypeError: Fetch argument <__main__.SquaredTensor object at 0x7f63a5fa84d0> of <__main__.SquaredTensor object at 0x7f63a5fa84d0> has invalid type <class '__main__.SquaredTensor'>, must be a string or Tensor. (Can not convert a SquaredTensor into a Tensor or Operation.)`\n", "comments": ["This was an intentional decision: the existing \"tensor conversion functions\" (perhaps an ambiguous name...) are mostly used to add nodes to the current graph, so we decided that these shouldn't be run on the arguments to `Session.run()`. In addition, the tensor conversion functions, which return a single tensor, aren't compatible with the mechanism used to flatten objects (e.g. `tf.SparseTensor` or `tf.SparseTensorValue`) into the component tensors, so that they can be passed to the underlying API.\n\nIt might be useful to add a mechanism for registering fetch and feed conversion functions, so I'll mark this as \"contributions welcome\".\n", "I'll work on this.\n", "Closing since there is no recent activity on this issue. If this is still an important feature and still being worked on, please reopen or create a new issue."]}, {"number": 2067, "title": "Update cuda instructions to be more specific about versions (#2065)", "body": "(cherry-pick of change to r0.8 branch)\n", "comments": []}, {"number": 2066, "title": "segmentation fault when stride > ksize in conv2d", "body": "Hello,\n\nI experience segfault trying to use recently merged modification of conv2d to support stride > ksize (yes, residual networks). Somehow it only arises in a complicated graph. I wrote minimal example, but it is still pretty big.\n### Environment info\n\nOperating System: Fedora 21\nPython 3.4, GPU Titan X and Titan Z\n\nInstalled version of CUDA and cuDNN: Cuda 7.5, Cudnn 4.\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\n```\n$ ls -1 $CUDA_HOME/lib/libcud*\n$CUDA_HOME/lib/libcudadevrt.a\n$CUDA_HOME/lib/libcudart.so\n$CUDA_HOME/lib/libcudart.so.7.5\n$CUDA_HOME/lib/libcudart.so.7.5.18\n$CUDA_HOME/lib/libcudart_static.a\n\n$ ls -1 $CUDA_HOME/lib64/libcud*\n$CUDA_HOME/lib64/libcudadevrt.a\n$CUDA_HOME/lib64/libcudart.so\n$CUDA_HOME/lib64/libcudart.so.7.5\n$CUDA_HOME/lib64/libcudart.so.7.5.18\n$CUDA_HOME/lib64/libcudart_static.a\n$CUDA_HOME/lib64/libcudnn.so\n$CUDA_HOME/lib64/libcudnn.so.4\n$CUDA_HOME/lib64/libcudnn.so.4.0.7\n$CUDA_HOME/lib64/libcudnn_static.a\n```\n\ncommit hash (nightly): 7b536cd5cfdbfd0fbc80496a38624557fb977783\n### Steps to reproduce\n\nRun the following code.\n\n```\nimport tensorflow as tf\nimport numpy as np\n\nFLAGS = tf.app.flags.FLAGS\n\ntf.app.flags.DEFINE_integer('res_n', 18,\n                            \"\"\"Residual network parameter.\"\"\")\ntf.app.flags.DEFINE_integer('batch_size', 128,\n                            \"\"\"Batch size.\"\"\")\ntf.app.flags.DEFINE_integer('proj_ksize', 1,\n                            \"\"\"Kernel size of identity projection.\"\"\")\n\n\ndef weight_variable(shape):\n    init = tf.uniform_unit_scaling_initializer()\n    var = tf.get_variable('weights', shape, initializer=init)\n    return var\n\n\ndef batch_norm(x, conv=True, scope='bn'):\n    phase_train = tf.get_collection('is_train')[0]\n    n_out = int(x.get_shape()[-1])\n    with tf.variable_scope(scope):\n        beta = tf.get_variable('beta', shape=[n_out],\n                initializer=tf.constant_initializer(0.0), trainable=True)\n        gamma = tf.get_variable('gamma', shape=[n_out],\n                initializer=tf.constant_initializer(1.0), trainable=True)\n\n        axes = [0, 1, 2] if conv else [0]\n        batch_mean, batch_var = tf.nn.moments(x, axes, name='moments')\n        ema = tf.train.ExponentialMovingAverage(decay=0.9)\n        ema_apply_op = ema.apply([batch_mean, batch_var])\n        ema_mean, ema_var = ema.average(batch_mean), ema.average(batch_var)\n        def mean_var_with_update():\n            with tf.control_dependencies([ema_apply_op]):\n                return tf.identity(batch_mean), tf.identity(batch_var)\n        mean, var = tf.python.control_flow_ops.cond(phase_train,\n            mean_var_with_update,\n            lambda: (ema_mean, ema_var))\n\n        normed = tf.nn.batch_normalization(x, mean, var, beta, gamma, 1e-3)\n    return normed\n\n\ndef create_conv_layer(src, name, ksize, out_filters,\n                      stride=1, padding='SAME'):\n    in_filters = int(src.get_shape()[-1])\n    with tf.variable_scope(name):\n        W = weight_variable([ksize, ksize, in_filters, out_filters])\n        conv = tf.nn.conv2d(src, W, strides=[1, stride, stride, 1],\n                            padding=padding)\n    return conv\n\n\ndef res_block(layer, i, lvl, num_filters, preact=True):\n    in_filters = int(layer.get_shape()[-1])\n    name = 'conv%i_%i' % (lvl, i)\n    if preact:\n        layer_act = tf.nn.relu(batch_norm(layer,\n                                          scope='bn_%i_%i_0' % (lvl, i)))\n    else:\n        layer_act = layer\n    if num_filters != in_filters:\n        stride = 2\n    else:\n        stride = 1\n    layer2 = create_conv_layer(layer_act, name+'_1', 3, num_filters, stride=stride)\n    layer2_act = tf.nn.relu(batch_norm(layer2, scope='bn_%i_%i_1' % (lvl, i)))\n    layer3 = create_conv_layer(layer2_act, name+'_2', 3, num_filters)\n    if stride > 1:\n        layer_proj = create_conv_layer(layer, name+'_proj', FLAGS.proj_ksize, num_filters,\n                                       stride=stride)\n        res = layer_proj + layer3\n    else:\n        res = layer + layer3\n    return res\n\n\ndef inference(layer, n):\n    layer = create_conv_layer(layer, 'conv1_0', 3, 16)\n    layer = tf.nn.relu(batch_norm(layer, scope='conv1_bn'))\n    for i in range(n):\n        layer = res_block(layer, i, 1, 16, preact=(i > 0))\n    for i in range(n):\n        layer = res_block(layer, i, 2, 32)\n    for i in range(n):\n        layer = res_block(layer, i, 3, 64)\n    layer = tf.nn.relu(batch_norm(layer, scope='bn_post'))\n    layer = tf.reduce_mean(layer, [1, 2], keep_dims=True)\n    layer = create_conv_layer(layer, 'conv5', 1, 10)\n    layer = tf.squeeze(layer)\n    return layer\n\n\nif __name__ == '__main__':\n    np.random.seed(42)\n    a = np.random.randn(FLAGS.batch_size, 32, 32, 3)\n    b = np.random.randint(0, 10, size=FLAGS.batch_size)\n\n    sess = tf.Session()\n\n    phase_train = tf.Variable(True, trainable=False, name='phase_train')\n    tf.add_to_collection('is_train', phase_train)\n\n    x = tf.placeholder(tf.float32, shape=(FLAGS.batch_size, 32, 32, 3))\n    y = tf.placeholder(tf.int64, shape=(FLAGS.batch_size))\n    logits = inference(x, FLAGS.res_n)\n    loss = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits, y))\n\n    opt = tf.train.GradientDescentOptimizer(0.01)\n    train_op = opt.minimize(loss)\n\n    sess.run(tf.initialize_all_variables())\n    sess.run(train_op, feed_dict={x: a, y: b})\n```\n\nIt fails with an error cited below (if run on gpu with cudnn).\n### What have you tried?\n1. It doesn't look like a memory issue, it still fails with tiny batch size.\n2. It works on CPU though.\n3. It works if `proj_ksize=3` which again shows it isn't OOM issue and points to recently introduced feature.\n4. It doesn't fail on a trivial example (just isolated conv2d with stride=2, ksize=1). While writing it, I realize I forgot to check the trivial example with backward pass.\n5. It works for forward pass even on gpu.\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n\n```\n$ python3 conv_bug.py\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:\nname: GeForce GTX TITAN Z\nmajor: 3 minor: 5 memoryClockRate (GHz) 0.8755\npciBusID 0000:05:00.0\nTotal memory: 6.00GiB\nFree memory: 5.91GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN Z, pci bus id: 0000:05:00.0)\nF tensorflow/stream_executor/cuda/cuda_dnn.cc:904] failed to enqueue convolution on stream: CUDNN_STATUS_BAD_PARAM\n[1]    10160 abort (core dumped)  python3 conv_bug.py\n```\n", "comments": ["@zheng-xq any ideas?\n", "I managed to reduce it to really clean case:\n\n```\nimport tensorflow as tf\nimport numpy as np\n\nnp.random.seed(42)\na = np.random.randn(64, 32, 32, 3)\n\nsess = tf.Session()\n\nx = tf.placeholder(tf.float32, shape=(64, 32, 32, 3))\n\nW = tf.get_variable('weights', [1, 1, 3, 16], initializer=tf.random_normal_initializer())\nout = tf.nn.conv2d(x, W, strides=[1, 2, 2, 1], padding='SAME')\nloss = tf.reduce_mean(out)\n\nopt = tf.train.GradientDescentOptimizer(0.01)\ntrain_op = opt.minimize(loss)\n\nsess.run(tf.initialize_all_variables())\nsess.run(train_op, feed_dict={x: a})\n```\n\nLooks like something is wrong in backward pass call to cudnn.\n", "Can you reproduce it?\n\nI have installed a recent commit with merged PR referenced above: no new logs.\n", "Sorry, yes, I can reproduce it with the latest nightly.  We'll try to take a look at this.\n", "I've created a PR [2137](https://github.com/tensorflow/tensorflow/pull/2137) to fix this issue. \n", "Fixed in #2137\n", "I can still reproduce the issue with the minimal example mentioned above with the latest nightly wheel. Is there something that i missed?\n", "http://ci.tensorflow.org/view/Nightly/job/nigntly-matrix-linux-gpu/TF_BUILD_CONTAINER_TYPE=GPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-working/\n\nIt looks like the nightly gpu wheels have been failing to build recently.  It likely doesn't have the above fix in it -- :(\n", "@caisq  -- seems like more platform python issues (can't import default/ dir).  I assume that's fixed internally and just needs to be pushed?\n", "works with latest build. \n"]}, {"number": 2065, "title": "Update cuda instructions to be more specific about versions", "body": "", "comments": []}, {"number": 2064, "title": "sess = tf.Session() get stuck!", "body": "GitHub issues are for bugs / installation problems / feature requests.  \nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\n\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\n### Environment info\n\nOperating System: Ubuntu 14.04.4 LTS (GNU/Linux 3.13.0-85-generic x86_64)\n\nInstalled version of CUDA and cuDNN: \n-rw-r--r-- 1 root root   322936 Apr 22 10:12 /usr/local/cuda-7.5/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Apr 22 10:12 /usr/local/cuda-7.5/lib64/libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx 1 root root       19 Apr 22 10:12 /usr/local/cuda-7.5/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18\n-rwxr-xr-x 1 root root   383336 Apr 22 10:12 /usr/local/cuda-7.5/lib64/libcudart.so.7.5.18\n-rw-r--r-- 1 root root   720192 Apr 22 10:12 /usr/local/cuda-7.5/lib64/libcudart_static.a\n-rwxr-xr-x 1 root root 61453024 Apr 22 10:57 /usr/local/cuda-7.5/lib64/libcudnn.so\n-rwxr-xr-x 1 root root 61453024 Apr 22 10:57 /usr/local/cuda-7.5/lib64/libcudnn.so.4\n-rwxr-xr-x 1 root root 61453024 Apr 22 10:57 /usr/local/cuda-7.5/lib64/libcudnn.so.4.0.7\n-rw-r--r-- 1 root root 62025862 Apr 22 10:57 /usr/local/cuda-7.5/lib64/libcudnn_static.a\n\nMy cudnn package: cudnn-7.0-linux-x64-v4.0-prod\nIf installed from binary pip package, provide:\n1. Which pip package you installed.\n   sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.8.0-cp27-none-linux_x86_64.whl\n2. The output from python -c \"import tensorflow; print(tensorflow.**version**)\".\n   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\n   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\n   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\n   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\n   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\n   0.8.0rc0\n### What have you tried?\n\n1.I ran 'python -m tensorflow.models.image.mnist.convolutional', and for the first time the model can print 'initialization' and train, but got stuck at the end. The second time I want to run it, it got stuck at the beginning after extracting from data. When I debug it, I find it's tf.Session() that making it get stuck.  When I tried '>>> hello = tf.constant('Hello, TensorFlow!')  >>> sess = tf.Session()', it got stuck here.\n2.I have run the NVIDIA_CUDA-7.5_Samples/1_Utilities/deviceQuery, and the result is PASS. I have even reinstall the cuda, but the result remain the same.\n3.I have tried the CPU model, and it went just fine.\n4.I tried to install from the source, the result remain the same.\n\nWhere is wrong? It seemed that the cuda and cudnn went wrong, but how to fix it?\nPlease help me!\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment).\n", "comments": ["I am unable to reproduce this on my installation...\n\nCould you please provide more information. e.g. did you have a previous version of TensorFlow installed, and if so did you remove it before installing 0.8?   (see note on https://www.tensorflow.org/versions/r0.8/get_started/os_setup.html#pip-installation)\n\nWhat is your LD_LIBRARY_PATH?\n\nThanks, Paul\n", "I installed the tensorflow 0.8 on a brand new ubuntu server, and I'm sure I was following the steps on the tensorflow website. \nLD_LIBRARY_PATH = /usr/local/cuda-7.5/lib64\nCUDA_HOME = /usr/local/cuda-7.5\nI'm thinking if the cuda test can pass, and the CPU model went well. Can it be cuDNN that caused the bug?\nThanks!\n", "Are you still having a problem?  When you say it \"gets stuck\", what do you mean?  What are the symptoms?  Have you identified exactly where it gets stuck?\n", "The most obvious symptom is whenever I want to use tf.Session() in GPU model, it would show nothing including the command prompt and I can't input anything. Like this in IPYTHON,\n_In [1]: import tensorflow as tf  \nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\n\nIn [2]: hello =  tf.constant('Hello')\n\nIn [3]: sess = tf.Session()_\nIt stuck here and stop showing anything, but it went just well in CPU model.\nWhat should I do? I have tested CUDA and cuDNN respectively, and both worked just fine.\nThank you very much!!\n@poxvoculi \n", "I ran into the same issue trying to setup an EC2 machine. Although deviceQuery ran fine, nvidia-smi would run halfway then crash the first time then hang on subsequent tries. I also tried running the [Theano test](http://deeplearning.net/software/theano/tutorial/using_gpu.html) which hung the same way as TensorFlow.\n\nUltimately I stumbled on https://devtalk.nvidia.com/default/topic/880246/cuda-7-5-unstable-on-ec2-/ which points to CUDA 7.5 as the issue. When I switched to CUDA 7.0 at least Theano would work. That nvidia forum thread has some directions at the end that might get 7.5 working.\n", "WOW! It works with CUDA 7.0! \nI've been trying to solve this problem for one week. You save me! Thanks! @ktrnka \n", "You're welcome. Yesterday I followed the script on the nvidia forum thread\nand got 7.5 working so now I can use pip tensor flow without problems.\nOn Apr 29, 2016 1:31 AM, \"wangbm\" notifications@github.com wrote:\n\nWOW! It works with CUDA 7.0!\nI've been trying to solve this problem for one week. You save me! Thanks!\n@ktrnka https://github.com/ktrnka\n\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly or view it on GitHub\nhttps://github.com/tensorflow/tensorflow/issues/2064#issuecomment-215657771\n", "I am having this problem with CUDA 8.0. I am following this guide here: https://gist.github.com/jganzabal/8e59e3b0f59642dd0b5f2e4de03c7687"]}, {"number": 2063, "title": "skflow and missing scalar_summary ?", "body": "Hi,\nI'm having issue to get the loss summary showing in tensorboard using skflow\n\nthis is my code\n\n---\n\nclassifier = skflow.TensorFlowEstimator(  model_fn=conv_model, n_classes=2,   batch_size=BATCH_SIZE, \n                                          steps=100000,  learning_rate=0.001,\n                                          config=RunConfig(gpu_memory_fraction=0.9))                                          \n\nval_monitor = monitors.ValidationMonitor(X_val, y_val, n_classes=2, print_steps=100)\nclassifier.fit(X_train, y_train, val_monitor, logdir='my_model_1/')\nclassifier.save('my_model_1/')\n\n---\n\neverything runs well\n\n---\n\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\n/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/io/data_feeder.py:281: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n  out.itemset((i, self.y[sample]), 1.0)\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties:\nname: GeForce GTX 980\nmajor: 5 minor: 2 memoryClockRate (GHz) 1.253\npciBusID 0000:03:00.0\nTotal memory: 4.00GiB\nFree memory: 3.91GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 980, pci bus id: 0000:03:00.0)\n/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/io/data_feeder.py:370: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n  out.itemset((i, y), 1.0)\nStep #99, avg. train loss: 2.22587, avg. val loss: 2.14521\nStep #199, avg. train loss: 0.82641, avg. val loss: 0.89103\nStep #299, avg. train loss: 0.78344, avg. val loss: 0.85636\nStep #399, avg. train loss: 0.76420, avg. val loss: 0.85675\nStep #499, avg. train loss: 0.75868, avg. val loss: 0.84104\nStep #599, avg. train loss: 0.75467, avg. val loss: 0.84945\nStep #699, avg. train loss: 0.73990, avg. val loss: 0.91238\nStep #799, avg. train loss: 0.73400, avg. val loss: 0.92720\nStep #899, avg. train loss: 0.72879, avg. val loss: 0.91054\nStep #999, avg. train loss: 0.73448, avg. val loss: 0.89823\nStep #1099, avg. train loss: 0.70125, avg. val loss: 0.91640\nStep #1199, avg. train loss: 0.71879, avg. val loss: 0.90597\nStep #1299, avg. train loss: 0.70713, avg. val loss: 0.90736\nStep #1399, avg. train loss: 0.70023, avg. val loss: 0.91414\nStep #1499, avg. train loss: 0.69566, avg. val loss: 0.91007\nStep #1599, avg. train loss: 0.68030, avg. val loss: 0.92729\nStep #1699, avg. train loss: 0.68919, avg. val loss: 0.91168\nStep #1799, avg. train loss: 0.67088, avg. val loss: 0.91744\nStep #1899, avg. train loss: 0.68732, avg. val loss: 0.88844\nStep #1999, avg. train loss: 0.67585, avg. val loss: 0.88854\n\n---\n\nit generates the file .tfevents that have  4,8M size (attached)\n\nwhen I connect to the machine using chrome as explorer I have data in graphs/histograms/ but nothing in events(No scalar data was found)\n\ndid I miss something to have loss logged ?\n\nNB:I added \n`logging_ops.scalar_summary(\"model_loss\", self._model_loss)`\nin learn/python/learn/estimators/base.py  and the loss is appearing in tensorbord\n\nPs: I'm running on GPU machine using the last build [tensorflow](http://ci.tensorflow.org/view/Nightly/job/nigntly-matrix-linux-gpu/TF_BUILD_CONTAINER_TYPE=GPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-working/lastBuild/)\nattached tfevents [my_model_1.zip](https://github.com/tensorflow/skflow/files/229812/my_model_1.zip)\n", "comments": ["Thanks for fixing, I just tested it by modifying my installed Tensorflow version and it works.\nAnother question! could we get the validation monitoring loss also? it's very interesting to see the evolution of validation loss \nfor the moment we can see only the loss and loss/mean of training process  \nthanks again\n", "as the build fails [this one](http://ci.tensorflow.org/view/Nightly/job/nigntly-matrix-linux-gpu/TF_BUILD_CONTAINER_TYPE=GPU,TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-working/lastBuild/) \nI've reported the modification in my tensorflow version and still missing the Validation (monitoring) loss.\nThe training loss is reported but not the validation\nLet me know if I missed something.\nThanks again\n", "@laouer I'll send PR for validation loss later today.\n", "Thank you very match it works like a charm.\nI will try to find a solution to be able to monitor the accuracy summary on validation data as it's also an interesting information.\nThanks again  \n", "Cool, let me know if this fixes the issue fully.\n\nI'm going to add more flexible validation evaluation API in next few weeks - so there will be easier to log bunch of metrics.\n", "I've reported the modifications in my installed tensorflow version and it's OK we get the validation loss in tensorboard the loss/mean for validation is not reported but it doesn't matter.\nThanks again.\n I close the issue. :) \n", "@laouer or @ilblackdragon Could one of you please tell me how I get at that best step value in python, the one that's printed to the console after stopping.\n", "With the fix of #2487 I'll add a property to the `ValidationMonitor` to get best value. Currently you need to rerun `evaluate` again to get the value.\n"]}, {"number": 2062, "title": "tf.cond not working with depedencies", "body": "tf.cond seems to have a bug if one of the condition have a dependency. (Dependencies are run, whatever tf.cond arg is True or False).\n\nTo illustrate:\n\n```\nimport tensorflow as tf\n\na = tf.Variable(0)\nincr = a.count_up_to(1)\n\ndef todo_if_true():\n  with tf.control_dependencies([incr]):\n    return tf.identity(a)\ndef todo_if_false():\n  return tf.identity(a)\n\ng = tf.cond(tf.constant(False), todo_if_true, todo_if_false)\ninit = tf.initialize_all_variables()\n\nwith tf.Session() as sess:\n  sess.run(init)\n  print(sess.run(g))\n```\n\nOutput:\n\n```\n1 #But should be 0\n```\n", "comments": ["@yuanbyu - any ideas?\n", "You need to move the count_up_to op inside the conditional branch you want it to be executed.\n\n```\na = tf.Variable(0)\n\ndef todo_if_true():\n  incr = a.count_up_to(1)\n  with tf.control_dependencies([incr]):\n    return tf.identity(a)\ndef todo_if_false():\n  return tf.identity(a)\n\ng = tf.cond(tf.constant(False), todo_if_true, todo_if_false)\n```\n\nI have added the following paragraph to the doc:\n\n Note that the conditional execution applies only to the operations defined in\n  fn1 and fn2. Consider the following simple program:\n\n``` python\n  z = tf.mul(a, b)\n  result = tf.cond(x < y, lambda: tf.add(x, z), lambda: tf.square(y))\n```\n\n  If x < y, the tf.add operation will be executed and tf.square\n  operation will not be executed. Since z is needed for at least one\n  branch of the cond, the tf.mul operation is always executed, unconditionally.\n  Although this behavior is consistent with the dataflow model of TensorFlow,\n  it has occasionally surprised some users who expected a lazier semantics.\n"]}, {"number": 2061, "title": "no variable name in repr() of variables from tf.trainable_variables()", "body": "`repr()` does not show names of variables obtained from `tf.trainable_variables()`\n### Environment info\n\nOperating System:\nMacOSX Yosemite, Python3.5\n\nIf installed from sources, provide the commit hash:\nnightly build a week ago from wheel\n### Steps to reproduce\n\n```\n       scope = \"myscope\"\n       trainables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope)\n       \"OR\"\n       trainables = tf.trainable_variables()\n       print(\"trainable variables in scope '%s':\\t%s\" % (scope, [\"%s\" % repr(x) for x in trainables] ) )\n       \"trainable variables in scope 'model/states':    ['<tensorflow.python.ops.variables.Variable object at 0x10bb3a518>', '<tensorflow.python.ops.variables.Variable object at 0x10bb3aa20>']\"\n       print(\"trainable variables in scope '%s':\\t%s\" % (scope, [\"%s\" % repr(x.name) for x in trainables] ) )\n       \"scope/name ...\"\n```\n", "comments": ["It seems to have been a deliberate stylistic choice not to define **repr** within tensorflow.  Not being a python enthusiast myself, I can't comment on the virtues of that decision.  If you feel differently, perhaps the tensorflow discussion group would be a good place to raise the issue.  [https://groups.google.com/a/tensorflow.org/forum/?utm_medium=email&utm_source=footer#!forum/discuss] \n", "I am a little bit curious on that decision, and therefore opened a thread in the discussion group: https://groups.google.com/a/tensorflow.org/forum/?utm_medium=email&utm_source=footer#!topic/discuss/u8eIulwX_OY\n"]}, {"number": 2060, "title": "ResourceExhaustedError: When using VGG16 model architecture and training on own images", "body": "", "comments": []}, {"number": 2059, "title": "Add caffe importer to resources", "body": "", "comments": []}, {"number": 2058, "title": "use cudnnGetErrorString to get cudnn error string", "body": "the built-in cudnnGetErrorString does exactly the same as the ToString helper\n", "comments": ["Can one of the admins verify this patch?\n", "@leary-google any ideas why you did it the other way?\n", "@tensorflow-jenkins: test this please\n", "ah damn @vrv the reason it was done the other way is because the macro is for the cudnn functions that return status, and this function is the only one that returns a `char *`.... ok closing\n"]}, {"number": 2057, "title": "Word2Vec model crashes with unicode train data", "body": "### Environment info\n\nOperating System: OS X 10.11.3\n\nInstalled version of CUDA and cuDNN: CUDA-7.5\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\nDeveloper/NVIDIA/CUDA-7.5/lib/libcudadevrt.a\n/Developer/NVIDIA/CUDA-7.5/lib/libcudart.dylib\n/Developer/NVIDIA/CUDA-7.5/lib/libcudart.7.5.dylib\n/Developer/NVIDIA/CUDA-7.5/lib/libcudart_static.a\n\nIf installed from binary pip package, provide: 0.8.0rc0\n### Steps to reproduce\n1. Clone folder https://github.com/tensorflow/tensorflow/blob/r0.8/tensorflow/models/embedding/\n2. Run successful python word2vec_optimized.py --train_data=questions-words.txt --eval_data=questions-words.txt --save_path=model/\n3. Run failed if i add some unicode text in train data (e.g. russian word \"\u0442\u0435\u0441\u0442\")\n### Logs or other output that would be helpful\n\nTraceback (most recent call last):\n  File \"../lib/word2vec/word2vec_optimized.py\", line 431, in <module>\n    tf.app.run()\n  File \"/usr/local/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"../lib/word2vec/word2vec_optimized.py\", line 416, in main\n    model = Word2Vec(opts, session)\n  File \"../lib/word2vec/word2vec_optimized.py\", line 146, in **init**\n    self.save_vocab()\n  File \"../lib/word2vec/word2vec_optimized.py\", line 242, in save_vocab\n    opts.vocab_counts[i]))\nUnicodeEncodeError: 'ascii' codec can't encode characters in position 0-5: ordinal not in range(128)\n", "comments": ["temporary workaround\n\n``` python\n  def save_vocab(self):\n    \"\"\"Save the vocabulary to a file so the model can be reloaded.\"\"\"\n    opts = self._options\n    with open(os.path.join(opts.save_path, \"vocab.txt\"), \"w\") as f:\n      for i in xrange(opts.vocab_size):\n        f.write(u\"{} {}\\n\".format(tf.compat.as_text(opts.vocab_words[i]),\n                             opts.vocab_counts[i]).encode('utf8'))\n\n```\n", "Solution works fine\n", "Closing since the workaround works.\n", "This workaround produces the following lines in vocab.txt:\n`b'\\xd0\\xb8' 3185432`\n\nIs there any way to load these sequences as utf8 strings (str) besides using `eval()`?\n\nI think it would be better to store utf8-strings in the vocab as utf8-encoded file.\nFor now it seems to be weird for me:\nit is `bytes` object representation saved in file\n"]}, {"number": 2056, "title": "error with \"import tensorflow; print(tensorflow.__version__)\"", "body": "Why the fuck is this not in assembly? What happened to the good old days where people couldn't just drag and drop chunks of code? Anti-Fortran Elitist scum. Viva la resistance. This is why bush did 9/11 3========D~~~~~~ ps. I bounced to my boys dick while writing this. #TrumpForPresident #MakeAssemblyGreatAgain #HuckFitler #WhyDoesEveryoneHateHitler? #Cornflakes \n", "comments": []}, {"number": 2055, "title": "libpthread.so was not created => can't build Android example", "body": "I don't know if it is a tensorflow bug, a bazel bug or a misconfiguration on my side (maybe with SDK/NDK) but could you guys just have a short look at my stackoverflow issue: http://stackoverflow.com/q/36731061/828184\n\nHere the errors (also can be seen on stackoverflow):\n\n> ERROR: /home/administrator/TensorFlow_Git/tensorflow/examples/android/BUILD:41:1: output 'tensorflow/examples/android/libpthread.so' was not created.\n> \n> ERROR: /home/administrator/TensorFlow_Git/tensorflow/examples/android/BUILD:41:1: not all outputs were created.\n\nSorry for cross-posting but I waited a while, would really need this and don't even know if stackoverflow is the right address at this point.\n", "comments": ["What bazel version do you have installed, and what command line are you using to build?\n\nlibpthread is actually not needed on Android, and the demo only depends on it to make the protobuf dependency happy at link time. Once Tensorflow upgrades to the newer version of protobuf, this hack will no longer be necessary. As a temporary workaround you can you try removing \"-lpthread\" from LINK_OPTS in google/protobuf/BUILD, and similarly removing all references to it from tensorflow/examples/android/BUILD.\n\nIt's possible you might have a more systematic installation issue, though, and this is just the first error the build process encounters.\n", "I digged around in the Pull Requests and History and noticed that there is some moving around and wanting it gone :-)\n\nGNU bash, version 4.3.11(1)-release (x86_64-pc-linux-gnu)\nbazel version 0.2.1\n\nChanged it to `LINK_OPTS = []` and same result\n", "Did you also delete the references from tensorflow/examples/android/BUILD?\n", "I tried but got an error. Did it again to write down the error but it doesn't say much:\n/home/administrator/TensorFlow/tensorflow/tensorflow/examples/android/BUILD:12:1: output 'tensorflow/examples/android/libtensorflow_demo.so' was not created.\n\ntensorflow/examples/android/BUILD file:\n\n```\n# Description:\n#   Tensorflow camera demo app for Android.\n\npackage(default_visibility = [\"//visibility:public\"])\n\nlicenses([\"notice\"])  # Apache 2.0\n\nload(\"//tensorflow:tensorflow.bzl\", \"tf_copts\")\n\nexports_files([\"LICENSE\"])\n\ncc_binary(\n    name = \"libtensorflow_demo.so\",\n    srcs = glob([\n        \"jni/**/*.cc\",\n        \"jni/**/*.h\",\n    ]),# + [\":libpthread.so\"],\n    copts = tf_copts(),\n    linkopts = [\n        \"-landroid\",\n        \"-ljnigraphics\",\n        \"-llog\",\n        \"-lm\",\n        \"-z defs\",\n        \"-s\",\n        \"-Wl,--icf=all\",  # Identical Code Folding\n        \"-Wl,--exclude-libs,ALL\",  # Exclude syms in all libs from auto export\n    ],\n    linkshared = 1,\n    linkstatic = 1,\n    tags = [\n        \"manual\",\n        \"notap\",\n    ],\n    deps = [\"//tensorflow/core:android_tensorflow_lib\"],\n)\n\n# This library only exists as a workaround to satisfy dependencies\n# that declare -lpthread in their linkopts. Although Android supports\n# pthreads, it does not provide it as a separate library.\n#cc_binary(\n#    name = \"libpthread.so\",\n#    srcs = [],\n#    linkopts = [\"-shared\"],\n#    tags = [\n#        \"manual\",\n#        \"notap\",\n#    ],\n#)\n\ncc_library(\n    name = \"tensorflow_native_libs\",\n    srcs = [\n        #\":libpthread.so\",\n        \":libtensorflow_demo.so\",\n    ],\n    tags = [\n        \"manual\",\n        \"notap\",\n    ],\n)\n\nandroid_binary(\n    name = \"tensorflow_demo\",\n    srcs = glob([\n        \"src/**/*.java\",\n    ]),\n    assets = glob([\"assets/**\"]),\n    assets_dir = \"assets\",\n    custom_package = \"org.tensorflow.demo\",\n    inline_constants = 1,\n    manifest = \"AndroidManifest.xml\",\n    resource_files = glob([\"res/**\"]),\n    tags = [\n        \"manual\",\n        \"notap\",\n    ],\n    deps = [\n        \":tensorflow_native_libs\",\n    ],\n)\n\nfilegroup(\n    name = \"all_files\",\n    srcs = glob(\n        [\"**/*\"],\n        exclude = [\n            \"**/METADATA\",\n            \"**/OWNERS\",\n            \"bin/**\",\n            \"gen/**\",\n        ],\n    ),\n    visibility = [\"//tensorflow:__subpackages__\"],\n)\n\nfilegroup(\n    name = \"java_files\",\n    srcs = glob([\"src/**/*.java\"]),\n)\n\nfilegroup(\n    name = \"jni_files\",\n    srcs = glob([\n        \"jni/**/*.cc\",\n        \"jni/**/*.h\",\n    ]),\n)\n\nfilegroup(\n    name = \"resource_files\",\n    srcs = glob([\"res/**\"]),\n)\n\nexports_files([\"AndroidManifest.xml\"])\n```\n", "That looks like it should work. What command are you using to build?\n", "`bazel build //tensorflow/examples/android:tensorflow_demo`\n", "Strange, are you sure there are no error messages before that? If you run `bazel clean` and then build with `bazel build -s //tensorflow/examples/android:tensorflow_demo`, do you see anything that stands out?\n", "You could also try building with `--verbose_failures` to see if it outputs any additional error messages.\n", "I watched it now compiling and didn't see any other error. I wanted to be sure and write the output to a file but I'm not a linux expert and this doesn't seem to work:\n`sudo bazel build -s //tensorflow/examples/android:tensorflow_demo --verbose_failures > output.txt`\n", "You can try `bazel build -s //tensorflow/examples/android:tensorflow_demo --verbose_failures > output.txt 2>&1` which will redirect all output to the file.\n\nYou shouldn't need to use sudo for building if your Bazel is installed properly -- have you been using it the entire time?\n", "I now did all again from scratch. I mean I git pulled freshly, edited WORKSPACE file, added the submodule and said submodule  update, changed BUILD file so no libpthread.so files are present (as above), made the LINK_OPTS an empty array in the protobuf BUILD file, made whole tensorflow folder chmod 777, and executed it with your last written command without sudo. I still ran into this issue. Attached my output.txt.\n[output.txt](https://github.com/tensorflow/tensorflow/files/232888/output.txt)\n", "It looks like the libpthread.so issue was only a symptom of a more general issue as your build environment can't find libtensorflow_demo.so either.\n\nIf you look in your bazel-\\* dirs for libtensorflow_demo.so, what do you find?\n\nFor reference, this is what I see:\n\n```\n$ find bazel-*/ | grep libtensorflow_demo.so$\nbazel-bin/tensorflow/examples/android/_dx/tensorflow_demo/native_symlinks/armeabi-v7a/libtensorflow_demo.so\nbazel-out/local_linux-opt/bin/tensorflow/examples/android/_dx/tensorflow_demo/native_symlinks/armeabi-v7a/libtensorflow_demo.so\nbazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-opt/bin/tensorflow/examples/android/libtensorflow_demo.so\nbazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-opt/bin/tensorflow/examples/android/_objs/libtensorflow_demo.so\nbazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-opt/bin/_solib_armeabi-v7a/_U_S_Stensorflow_Sexamples_Sandroid_Ctensorflow_Unative_Ulibs___Utensorflow_Sexamples_Sandroid/libtensorflow_demo.so\nbazel-tensorflow/bazel-out/local_linux-opt/bin/tensorflow/examples/android/_dx/tensorflow_demo/native_symlinks/armeabi-v7a/libtensorflow_demo.so\nbazel-tensorflow/bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-opt/bin/tensorflow/examples/android/libtensorflow_demo.so\nbazel-tensorflow/bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-opt/bin/tensorflow/examples/android/_objs/libtensorflow_demo.so\nbazel-tensorflow/bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-opt/bin/_solib_armeabi-v7a/_U_S_Stensorflow_Sexamples_Sandroid_Ctensorflow_Unative_Ulibs___Utensorflow_Sexamples_Sandroid/libtensorflow_demo.so\n\n```\n", "[libtensorflowDemoOutput.txt](https://github.com/tensorflow/tensorflow/files/239538/libtensorflowDemoOutput.txt)\n\nI also noticed that if I type which bazel it gives me that. Don't know if that's normal\n![whichbazel](https://cloud.githubusercontent.com/assets/10122382/14871069/414885a4-0cdf-11e6-908a-1e37c38dc265.JPG)\n\nHere my bazel install log if I execute it again\n[bazelInstallLog.txt](https://github.com/tensorflow/tensorflow/files/239545/bazelInstallLog.txt)\n", "Odd, obviously it's creating the files, it's just not finding them for some reason. Can you check for permission issues, e.g.:\n`find bazel-*/ | grep libtensorflow_demo.so$ | xargs ls -la` ?\n\nThe only command you should run with sudo is the one to install bazel, that should put it in /usr/bin. e.g. `sudo ./bazel-0.2.1-installer-linux-x86_64.sh`. I'd try installing it that way and see if it gets you anywhere.\n", "[permission.txt](https://github.com/tensorflow/tensorflow/files/239554/permission.txt)\nNo doesn't help.\n", "What about `ls -la ~/.cache/bazel/_bazel_administrator` or `ls -la /home/administrator/.cache/bazel/_bazel_administrator/d80406fadc9e2685aed9bed686923250/tensorflow/bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-fastbuild/bin/tensorflow/examples/android/libtensorflow_demo.so` ?\n", "It's not in `/home/administrator/.cache/bazel/_bazel_administrator/d80406fadc9e2685aed9bed686923250/tensorflow/bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-fastbuild/bin/tensorflow/examples/android/libtensorflow_demo.so`\n\n`ls -la ~/.cache/bazel/_bazel_administrator` gives me\n![res](https://cloud.githubusercontent.com/assets/10122382/14871691/0cb15c2a-0ce5-11e6-8acc-ccbf86280d7a.JPG)\n\nBut I have something new now. I uninstalled bazel with `rm -fr ~/.bazel ~/.bazelrc ~/.cache/bazel` copied the `bazel-0.2.1-installer-linux-x86_64.sh` file to the tensorflow directory and executed it with sudo. Am I now a step further or back? ^^\n![new](https://cloud.githubusercontent.com/assets/10122382/14871723/5c6c29ca-0ce5-11e6-88a3-575cfcc00aef.JPG)\n", "Update: I did chmod 777 on the whole tensorflow directory and I am now step 613 but OS seems to be frozen now\n", "Same error on step 671\n", "Ok the problem with the EOF seems to be because of too less memory and gets fixed with --jobs 4 parameter but I then run into a c++ error. Anyway all that looks like topics for another thread in case I can't find existing ones.\n\nWhat seemed to have helped now was executing `-fr ~/.bazel ~/.bazelrc ~/.cache/bazel` and calling `bazel-0.2.1-installer-linux-x86_64.sh` INSIDE the tensorflow directory.\n\nThanks for your help.\n", "Okay sorry but after increasing my swap partition with gparted to fix another error and running the command with --jobs 4 I get this `libtensorflow_demo.so` was not created error again.\n\nLogs: [output1.txt](https://github.com/tensorflow/tensorflow/files/243192/output1.txt)\n\nThis is the command I executed:\n`sudo bazel build //tensorflow/examples/android:tensorflow_demo --verbose_failures --jobs 4 >output2.txt 2>&1`\n", "You really should not be running bazel build with sudo. If you have to do that something is broken with your install. What happens when you run without the sudo?\n\nThe only time bazel and sudo should mix is when you're running the installer, so that it can install itself in /usr/bin\n", "Tried it without too. Or is the output \"dirty\" than?\nUpdate: Tried `bazel clean` and same command without sudo and same result\n", "Can you search for the libtensorflow_demo.so file using the find command referenced earlier, and follow the links to check all the permissions? Earlier you said that it wasn't there, does that mean that the symlink existed but pointed to a non-existent file?\n\nAlso, you've attached output1.txt but your command should have written to output2.txt. Are the output logs the same?\n", "Yesterday I've spent the whole day trying out different tensorflow github releases and bazel releases and combinations of those and I kept running into this libpthread.so error. If I remove dependency to libpthread.so (seems this dependency was in the BUILD file before it wen't into the WORKSPACE file) it's usally a C++ compilation of rule error that gets fixed with --jobs 2 (sometimes 4 work but 2 allways works) but then it stops at this libtensorflow_demo.so not created error.\nI searched for all libtensorflow_demo.so files on the drive and made them chmod 777  and also the whole tensorflow folder and .cache/bazel folder and it just doesn't work.\n\nYou are right that I wrote ouput1.txt and ouput2.txt but just because I edited the post afterwards to add the command but it wasn't the original command but a few tries later. The output1.txt is/was correct and error also came without writing to file.\n\nBecause I now tried many different versions I suspect the NDK or SDK to be honest. The ndk doesn't work with r11c (because it doesn't find a README file) and I somewhere got the android-ndk-r10e and placed it in my Downloads folder. Not sure if it matters where its located. Also installed it via SDK manager but that doesn't tell me where its located. The SDK is installed normally via SDK Manager but I added the 23.0.1 folder manually which I also found somewhere on the internet. Also tried the 23.03 with same result a few times (and just now).\n\nAny more ideas? I would even create a new VM with OS, bazel, tensorflow, Android SDK and NDK versions of your choice etc. if you think that helps. The error isn't really that useful, that's the problem.\n\nAgain current command:\n`bazel build //tensorflow/examples/android:tensorflow_demo --verbose_failures --jobs 2 >output.txt 2>&1`\n\nCurrent output (used bazel clean before): [output.txt](https://github.com/tensorflow/tensorflow/files/244363/output.txt)\n\nBut I currently tried it with the older TensorFlow v0.7.1, bazel v0.2.0 on Ubuntu 14.04 LTS\n", "A few notes first:\n- libpthread.so itself is not the problem, just a symptom here, as it seems you have a general issue with your bazel install\n- There's currently a Bazel/NDK 11 incompatibility, so you should be using r10e\n- Bazel 0.2.0 or 0.2.1 should work, and \"which bazel\" should tell you /usr/bin/bazel after install\n\nYou said before that:\n`/home/administrator/.cache/bazel/_bazel_administrator/d80406fadc9e2685aed9bed686923250/tensorflow/bazel-out/android-arm-linux-androideabi-4.9-v7a-gnu-libstdcpp-fastbuild/bin/tensorflow/examples/android/libtensorflow_demo.so`\n\"wasn't there\". So that means the link exists (since you provided the \"find\" output that showed it), but the target of the link doesn't? Can you check your current set of links produced by bazel in the [workspace]/bazel-\\* folder, and see if they point to nothing as well?\n\nHow much free disk space/memory do you have?\n", "FINALLY I GOT IT! I have no idea what and where something went wrong but you are right and there were broken link files pointing to a non existing directory with libtensorflow_demo.so.\nThe solution for me was to start all over with a fresh VM with enough diskspace (20GB is clearly not enough), enough memory (default is pretty low) and all cores assigned (default is 1) with the current Ubuntu 16.04 LTS and Android Studio. Also tensorflow v8.0 which came out meanwhile seems to be a bit less troublesome.\n\nI described everything in my blog. It's in German but you'll only need the console commands anyway.\n[http://blog.codingyourlife.at/?page_id=1315](http://blog.codingyourlife.at/?page_id=1315)\n"]}, {"number": 2054, "title": "Manual placement on GPU of a custom operator with both CPU and GPU implementation will always run the CPU version", "body": "### Environment info\n\nOperating System: ubuntu 14.04 64-bit\n\nInstalled version of CUDA and cuDNN: 7.5 and 4\n$ ls -l /usr/local/cuda/lib64/libcud*\n-rw-r--r-- 1 root root   322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18\n-rwxr-xr-x 1 root root   383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18\n-rw-r--r-- 1 root root   720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a\n-rwxr-xr-x 1 root root 61453024 Feb 23 16:00 /usr/local/cuda/lib64/libcudnn.so\n-rwxr-xr-x 1 root root 61453024 Feb 23 16:00 /usr/local/cuda/lib64/libcudnn.so.4\n-rwxr-xr-x 1 root root 61453024 Feb 23 16:00 /usr/local/cuda/lib64/libcudnn.so.4.0.7\n-rw-r--r-- 1 root root 62025862 Feb 23 16:00 /usr/local/cuda/lib64/libcudnn_static.a\n\nIf installed from binary pip package, provide:\n1. Which pip package you installed. tensorflow==0.8.0rc0\n2. The output from python -c \"import tensorflow; print(tensorflow.**version**)\".\npython -c \"import tensorflow; print(tensorflow.**version**)\"\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\n0.8.0rc0\n### Steps to reproduce\n1. Modify the How-to example cuda_op_kernel.cc to create both a CPU and GPU implementation for the AddOneOp operator\n2. Make the GPU version do a different operation - I added 2 instead of 1 - so you can verify which version is running\n3. Change the input and output type from int32 to float. This step is bizarre but critical!\n4. Test the operator with manual placement - ie. with tf.device('/gpu:0'). This has to be done NOT in the self.test_session as in the example, but rather with a regular tf session - ie:  with tf.Session(config=tf.ConfigProto(log_device_placement=True)). This step is also critical. The tf.test.TestCase.test_session()  masks the issue. \n5. The operator will run the CPU version despite the placer saying it is being placed on the GPU and the test fails. \n   $ python cuda_op_unittest.py \n   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\n   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\n   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\n   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\n   I tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\n   I tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \n   name: GeForce GTX TITAN\n   major: 3 minor: 5 memoryClockRate (GHz) 0.928\n   pciBusID 0000:05:00.0\n   Total memory: 6.00GiB\n   Free memory: 5.29GiB\n   I tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \n   I tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \n   I tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN, pci bus id: 0000:05:00.0)\n   Device mapping:\n   /job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce GTX TITAN, pci bus id: 0000:05:00.0\n   I tensorflow/core/common_runtime/direct_session.cc:149] Device mapping:\n   /job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce GTX TITAN, pci bus id: 0000:05:00.0\n\nAddOne/input: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:388] AddOne/input: /job:localhost/replica:0/task:0/gpu:0\nAddOne: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:388] AddOne: /job:localhost/replica:0/task:0/gpu:0\n**\\* running on CPU ***\n# F\n## FAIL: test (**main**.AddOneTest)\n\nTraceback (most recent call last):\n  File \"cuda_op_unittest.py\", line 30, in test\n    assert allclose(result.eval(), [7.0, 6.0, 5.0, 4.0, 3.0])\nAssertionError\n\n---\n\nRan 1 test in 0.342s\n\nFAILED (failures=1)\n### What have you tried?\n\nWe first noticed this on a much more complicated custom operator. This is a regression from the tensorflow version 0.7.1, which worked for us. The steps above are the result of several days spent trying to reproduce the problem with a minimal operator. The critical things seem to be using floats instead of ints and using the standard session instead of the tf test one. \n\nNote also, that if I comment out the REGISTER_KERNEL_BUILDER line for the CPU and try to run only on the gpu device, the test passes, but the executor is still trying to create a CPU version. Log looks like:\n$ python cuda_op_unittest.py \nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcublas.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcufft.so locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:105] successfully opened CUDA library libcurand.so locally\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \nname: GeForce GTX TITAN\nmajor: 3 minor: 5 memoryClockRate (GHz) 0.928\npciBusID 0000:05:00.0\nTotal memory: 6.00GiB\nFree memory: 5.29GiB\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:755] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX TITAN, pci bus id: 0000:05:00.0)\nDevice mapping:\n/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce GTX TITAN, pci bus id: 0000:05:00.0\nI tensorflow/core/common_runtime/direct_session.cc:149] Device mapping:\n/job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce GTX TITAN, pci bus id: 0000:05:00.0\n\nAddOne/input: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:388] AddOne/input: /job:localhost/replica:0/task:0/gpu:0\nAddOne: /job:localhost/replica:0/task:0/gpu:0\nI tensorflow/core/common_runtime/simple_placer.cc:388] AddOne: /job:localhost/replica:0/task:0/gpu:0\nE tensorflow/core/common_runtime/executor.cc:332] Executor failed to create kernel. Not found: No registered 'AddOne' OpKernel for CPU devices compatible with node AddOne = AddOne[_device=\"/job:localhost/replica:0/task:0/gpu:0\"](AddOne/input)\n     [[Node: AddOne = AddOne[_device=\"/job:localhost/replica:0/task:0/gpu:0\"](AddOne/input)]]\n**\\* running on GPU ***\n## .\n\nRan 1 test in 0.552s\n\nOK\n### Logs or other output that would be helpful\n\nattaching source files. To build I do:\n/usr/local/cuda/bin/nvcc -std=c++11 -c -o cuda_op_kernel.cu.o cuda_op_kernel.cu.cc -I $TF_INC -D GOOGLE_CUDA=1 -x cu -Xcompiler -fPIC\ng++ -std=c++11 -shared -o cuda_op_kernel.so cuda_op_kernel.cc cuda_op_kernel.cu.o -I $TF_INC -fPIC -Wl,-rpath .\npython cuda_op_unittest.py\n\nI am running python 2.7. \n\n[cuda_op.tar.gz](https://github.com/tensorflow/tensorflow/files/230677/cuda_op.tar.gz)\n", "comments": ["Thanks - this does look suspicious and I see the same behavior on my machine.  \nWe are investigating.\n", "Any idea where the bug could come from? I ran into the same issue.\n", "Thanks to @prb12 for debugging this with me.\nThe TensorFlow runtime optimizes the graph before it runs it the first time. One particular optimization of interest here is constant folding, that replaces a node whose input is a constant, with the output of the node after executing it. The 'execution' of the node during constant folding always happens on the CPU. Note that this is functionally correct, as both the CPU and GPU kernel implementations for an op are supposed to produce the same result. To make sure your op runs on the GPU in tests (where you presumably feed in constant values as inputs), use `self.test_session` to run your test. That [disables](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/test_util.py#L246) optimization when running the graph. Note that when you use your custom op in a larger program that has real inputs instead of constants, it will run on the GPU as expected. Closing this issue because this is the expected behavior. Please feel free to add follow up comments in case you need more info.\n", "We need to use the standard unittest.TestCase framework, not your TensorFlowTestCase framework, so self.test_session does not exist. Is there any way to disable this optimization in a regular tensorflow session - ie. with tf.Session()?\n", "Yes, test_session is just a thin wrapper around creating a normal TF session, so you can see how the code disables this optimization here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/test_util.py#L246\n", "I tried your suggestion and that works. Thanks.\n"]}, {"number": 2053, "title": "Failed to build from source due to missing libcudart.so.7.5:", "body": "Hi! I tried to compile the tutorials_example_trainer file, and I have quite a journey behind me. I recompiled GCC several times, I recompiled bazel dozens of times and did a fair share of CROSSTOOLS editing.\nAt this point, I am stuck. The compliation fails with the message:\n\n`bazel-out/host/bin/tensorflow/cc/ops/random_ops_gen_cc: error while loading shared libraries: libcudart.so.7.5: cannot open shared object file: No such file or directory\nTarget //tensorflow/cc:tutorials_example_trainer failed to build`\n\nI am using Tensorflow HEAD (currently 7b536cd5cfdbfd0fbc80496a38624557fb977783), I have CUDA 7.5 installed in /usr/local/cuda-7.5 .\n\nMy LD_LIBRARY_PATH is set to :/usr/local/cuda/lib64:/usr/local/cuda/lib64 , and the files exist there.\nI tried to point bazel to the library directory by adding \n\n`+  linker_flag: \"-L/usr/local/cuda/lib64\"`\n.\n### Environment info\n\nOperating System: Fedora 23\n\nInstalled version of CUDA and cuDNN: 7.5 and 4.0.7\n\n```\n$ ls /usr/local/cuda-7.5/lib64/libcud*\n/usr/local/cuda-7.5/lib64/libcudadevrt.a    /usr/local/cuda-7.5/lib64/libcudart.so.7.5.18  /usr/local/cuda-7.5/lib64/libcudnn.so.4\n/usr/local/cuda-7.5/lib64/libcudart.so      /usr/local/cuda-7.5/lib64/libcudart_static.a   /usr/local/cuda-7.5/lib64/libcudnn.so.4.0.7\n/usr/local/cuda-7.5/lib64/libcudart.so.7.5  /usr/local/cuda-7.5/lib64/libcudnn.so          /usr/local/cuda-7.5/lib64/libcudnn_static.a\n```\n\nIf installed from sources, provide the commit hash: 7b536cd5cfdbfd0fbc80496a38624557fb977783\n### Steps to reproduce\n1. Recompiled Bazel, version 0.2.1 with the following patch: https://gist.github.com/akors/5db13e874c144b3b111f0e0326d7b771#file-bazel-custom-gcc-patch\n2. Applied the following patch to TensorFlow: https://gist.github.com/akors/5db13e874c144b3b111f0e0326d7b771#file-tensorflow-custom-gcc-patch\n3. Ran ./configure with /opt/gcc-4.9/bin/gcc as compiler, but default otherwise.\n4. Ran bazel build -c opt --config=cuda --local_resources 4096,3.0,1.0 -j 4 //tensorflow/cc:tutorials_example_trainer --verbose_failures\n### What have you tried?\n1. I cried a lot.\n2. Add `linker_flag: \"-L/usr/local/cuda/lib64\"` to `third_party/gpus/crosstool/CROSSTOOL`\n3. Add `linker_flag: \"-Wl,-R/usr/local/cuda/lib64\"`  to `third_party/gpus/crosstool/CROSSTOOL`\n4. Recompile bazel, with added `linker_flag: \"-Wl,-R/usr/local/cuda/lib64\"` in `tools/cpp/CROSSTOOL`\n5. Create a file `/etc/ld.so.conf.d/LOCAL_cuda-lib64.conf` with the contents `/usr/local/cuda/lib64` and ran `ldconfig`\n### Logs or other output that would be helpful\n\nHere's the full output of the last operation:\n\n```\nERROR: /home/alexander/.local/src/tensorflow/tensorflow/cc/BUILD:28:1: Executing genrule //tensorflow/cc:random_ops_genrule failed: namespace-sandbox failed: error executing command \n  (cd /home/alexander/.cache/bazel/_bazel_alexander/3fc3a90944d6c7fe99106d6e515412c7/tensorflow && \\\n  exec env - \\\n    PATH=/usr/lib/ccache:/usr/lib/ccache:/usr/lib64/qt-3.3/bin:/usr/lib64/ccache:/usr/local/bin:/usr/local/sbin:/usr/bin:/usr/sbin:/home/alexander/.local/bin:/home/alexander/bin:/home/alexander/.local/bin:/home/alexander/bin \\\n  /home/alexander/.cache/bazel/_bazel_alexander/3fc3a90944d6c7fe99106d6e515412c7/tensorflow/_bin/namespace-sandbox @/home/alexander/.cache/bazel/_bazel_alexander/3fc3a90944d6c7fe99106d6e515412c7/tensorflow/bazel-sandbox/7d27406c-6595-46a2-a8dc-b7faf7c28c88-0.params -- /bin/bash -c 'source external/bazel_tools/tools/genrule/genrule-setup.sh; bazel-out/host/bin/tensorflow/cc/ops/random_ops_gen_cc bazel-out/local_linux-opt/genfiles/tensorflow/cc/ops/random_ops.h bazel-out/local_linux-opt/genfiles/tensorflow/cc/ops/random_ops.cc 0').\nbazel-out/host/bin/tensorflow/cc/ops/random_ops_gen_cc: error while loading shared libraries: libcudart.so.7.5: cannot open shared object file: No such file or directory\nTarget //tensorflow/cc:tutorials_example_trainer failed to build\nINFO: Elapsed time: 630.365s, Critical Path: 137.07s\n```\n\nps.: Out of curiosity, what are you TensorFlow devs using for a development machine? Has any of you actually tried using a modern Linux distribution that comes with GCC newer than 4.9 for compilation? You really should. It's quite the experience.\n", "comments": ["Fun fact: Symlinking all Cuda shared libraries to the custom GCC library directory also doesn't work.\n", "I have been having this issue, too. For now I resorted to using the nightly builds, which work just fine, and hope that I won't have to touch the C++ portions of tensorflow or contribute a patch that requires rebuilding...\nThere was another issue that seemed related (#1701), also on Fedora23.\nI am on Fedora21 here, with gcc 4.9.2\n", "@black-puppydog Thanks for your information.\nDo I understand correctly that\na) You are using nightly builds as \"user\", but do not build it from source?\nb) Even on Fedora 21, it fails to compile with the missing libcudart.so.7.5? \n\nAnother fun fact:\nSymlinking `/usr/lib64/libcudart.so.7.5` -> `/usr/local/cuda/lib64/libcudart.so.7.5` also doesn't work.\n\nI'm out of ideas over here. I will go back to the CPU-based build, which seems to work and come back when some dev has shed some light on this issue.\n", "gcc 4.9.2 is what I currently use and it has worked for me.  @keveman in case he has any ideas, or maybe we have to rope in bazel devs.\n", "@vrv Thanks for the reply. And you are able to build the GPU-version of TensorFlow from source?\nWhich distribution (with version) do you have? Is the GCC 4.9.2 from your distro? Or self-compiled?\n", "I also just tried from another machine and it still works for me (just synced to HEAD today).\n\nOn this machine, I'm using ubuntu 14.04, gcc 4.8.4 provided by distro.\n\nIf you manually run bazel-out/host/bin/tensorflow/cc/ops/random_ops_gen_cc, do you still see the failure?\n\nDo you see a bazel-out/host/bin/tensorflow/cc/ops/random_ops_gen_cc.runfiles/third_party/gpus/cuda/lib64/libcudart.so symlink?\n", "Btw the reason we don't use gcc 5+ is that nvcc currently isn't compatible with it, so we're all stuck on 4.8 or 4.9 :(\n", "> If you manually run bazel-out/host/bin/tensorflow/cc/ops/random_ops_gen_cc, do you still see the failure?\n\nNo, then the library can be found.\n\n```\n$ bazel-out/host/bin/tensorflow/cc/ops/logging_ops_gen_cc\nUsage: bazel-out/host/bin/tensorflow/cc/ops/logging_ops_gen_cc out.h out.cc include_internal\n  include_internal: 1 means include internal ops\n[alexander@desktop-fedora tensorflow]$ ldd bazel-out/host/bin/tensorflow/cc/ops/logging_ops_gen_cc\n    linux-vdso.so.1 (0x00007ffcef5b6000)\n    libcudart.so.7.5 => /home/alexander/.local/src/tensorflow/bazel-out/host/bin/tensorflow/cc/ops/../../../_solib_local/_U_S_Sthird_Uparty_Sgpus_Scuda_Ccudart___Uthird_Uparty_Sgpus_Scuda_Slib64/libcudart.so.7.5 (0x00007f5991bd4000)\n    libm.so.6 => /lib64/libm.so.6 (0x00007f59918a1000)\n    libdl.so.2 => /lib64/libdl.so.2 (0x00007f599169d000)\n    libz.so.1 => /lib64/libz.so.1 (0x00007f5991487000)\n    libpthread.so.0 => /lib64/libpthread.so.0 (0x00007f5991269000)\n    libstdc++.so.6 => /lib64/libstdc++.so.6 (0x00007f5990ee7000)\n    libgcc_s.so.1 => /lib64/libgcc_s.so.1 (0x00007f5990cd0000)\n    libc.so.6 => /lib64/libc.so.6 (0x00007f599090e000)\n    librt.so.1 => /lib64/librt.so.1 (0x00007f5990706000)\n    /lib64/ld-linux-x86-64.so.2 (0x000055fcecd2f000)\n```\n\n> Do you see a bazel-out/host/bin/tensorflow/cc/ops/random_ops_gen_cc.runfiles/third_party/gpus/cuda/lib64/libcudart.so symlink?\n\nNot `libcudart.so`, but `libcudart.so.7.5` . The link is valid, and links into the bazel-cache directory.\n\n> Btw the reason we don't use gcc 5+ is that nvcc currently isn't compatible with it, so we're all stuck on 4.8 or 4.9 :(\n\nI understand. Did you also have to patch your CROSSTOOL file?\n\n> On this machine, I'm using ubuntu 14.04, gcc 4.8.4 provided by distro.\n\nThanks. Does this mean you are using CUDA 7.0, not 7.5?\n", "Hmm, this is probably a bazel-related problem, since the binary itself does seem to have the right linkages.  @damienmg for some help, if he has ideas.\n\n(No, it works for me at 7.5 too, I did not have to patch my CROSSTOOL file).  To be completely honest, I'm not sure why some configurations work and others don't.\n", "It is running with sandboxing so cannot find the sjared library\n", "Sorry _shared_. I should not use my phone configured in French ever again...\n\nTry to add `--genrule_strategy=standalone` when building TensorFlow\n", "Thanks a lot! Adding `--genrule_strategy=standalone` to the bazel command line works! I can now compile the trainer and run the trainer with GPU support.\n\nFor the curious, the full command line is now: \n`bazel build -c opt --config=cuda --genrule_strategy=standalone --local_resources 4096,3.0,1.0 -j 2 //tensorflow/cc:tutorials_example_trainer --verbose_failures`\nTotally obvious ;)\n\nI will now try to minimize all the changes that I did to get it to run on my system, and then write them up in a comprehensible way.\n\nAs for this bug: compiling in standalone mode is not very obvious, so at the very least I think it should go in the documentation. I do believe that some fixing is required (either for bazel or for the tensorflow build rules), but you can close this issue at your discretion.\n", "Actually tensorflow's configure should add that flag, what is in tools/bazel.rc for you?\n", "This is my `tools/bazel.rc` after ./configure.\n\n```\n# Autogenerated by configure: DO NOT EDIT\nbuild:cuda --crosstool_top=//third_party/gpus/crosstool\nbuild:cuda --define=using_cuda=true\n\nbuild --force_python=py2\nbuild --python2_path=/usr/bin/python\nbuild --define=use_fast_cpp_protos=true\nbuild --define=allow_oversize_protos=true\n\nbuild --spawn_strategy=standalone\ntest --spawn_strategy=standalone\nrun --spawn_strategy=standalone\n```\n\nIs it possible that the `--spawn_strategy=standalone` is only added to the build target, but not to the build:cuda target?\n", "/cc @aehlig who knows exactly how this file is parsed. Yes it is definitely possible but should not\n", "> /cc @aehlig who knows exactly how this file is parsed.\n\nMy understanding is that `build:cuda` options are more specific than plain `build` options and hence take precedence where conflicting options are specified for `build` and `build:cuda`; but otherwise they're just added additionally. So, in your case you should get `--spawn_startegy=standalone`.  You can also verify which options are taken from the rc-files by adding `--announce_rc` to the command-line.\n\nNote, however,  that on the command-line you specified `--genrule_strategy=standalone` whereas from the rc-file you inherit `--spawn_strategy=standalone` and I'm not sure how those two strategy options interact.\n", "Hi, this is for the people coming from Google, trying to get TensorFlow to compile on their machines:\n\n# How to compile TensorFlow from source on Fedora 23 with a custom compiler.\n\nCompiling TensorFlow with GPU support is possible, but a bit tricky on Fedora 23 and up.\nThe compilation requires a specific GCC version which is not available from Fedora repoisitories and specifying the compiler is more complicated than it should be.\n\n## Compiling GCC\n\nFor CUDA version 7.5, you need to obtain the source code for GCC version 4.9. You can obtain it from [here](ftp://ftp.gnu.org/gnu/gcc/gcc-4.9.2/).\n\nNext, you need to install GCC compile-time dependencies:\n\n```\nsudo dnf install mpfr-devel gmp-devel libmpc-devel isl-devel\n```\n\nNow you have to configure the GCC build. For details, check out the [GCC configuration page](https://gcc.gnu.org/install/configure.html). I suggest installing into a custom prefix, such as `/opt/gcc-4.9`. I suggest enabling only C and C++ and skipping the rest of the GCC languages to save time and disk space. The options --with-as, --with-ld and --with-nm are required, because otherwise TensorFlow build will fail, complaining that those binaries cannot be found.\n\n```\n/configure --prefix=/opt/gcc-4.9 --disable-nls --enable-languages=c,c++ --with-ld=/bin/ld --with-nm=/bin/nm --with-as=/usr/bin/as\n```\n\nWhen this step is done, you can compile GCC with the following command:\n\n```\nmake -j4\n```\n\nThis assumes you want to use 4 processing cores. You can use more or less, or omit the -j option entirely.\n\nFinally, run as root:\n\n```\nmake install\n```\n\n## Compiling bazel\n\nObtain the bazel source code. You need the current master branch, NOT any of the recent releases.\n\n```\ngit clone https://github.com/bazelbuild/bazel.git\n```\n\nTo compile bazel, you need to specify \n\n```\nexport CC=/opt/gcc-4.9/bin/gcc\n./compile\n```\n\nThis will produce the bazel binary in `path/to/bazel/output/bazel`\n\n## Compiling TensorFlow\n\nObtain the TensorFlow source code\n\n```\ngit clone --recurse-submodules https://github.com/tensorflow/tensorflow\n```\n\nModify the file `third_party/gpus/crosstool/CROSSTOOL`: Find the toolchain entry where the `toolchain_identifier`is set to `\"local_linux\"`. Only change entries here, the rest is irrelevant.\n\nReplace the following lines:\n\ncxx_builtin_include_directory: \"/usr/lib/gcc/\"\ncxx_builtin_include_directory: \"/usr/local/include\"\n\nwith the following lines:\ncxx_builtin_include_directory: \"/opt/gcc-4.9/lib/gcc/\"\ncxx_builtin_include_directory: \"/opt/gcc-4.9/local/include\"\ncxx_builtin_include_directory: \"/opt/gcc-4.9/include\"\n\nNext, run the `./configure` and set your options. Specify your self-compiled GCC (for me `/opt/gcc-4.9/bin/gcc`) as the compiler to be used by nvcc.\n\nTo compile the source, use the following command line:\n\n```\npath/to/bazel/output/bazel build -c opt --config=cuda --genrule_strategy=standalone --local_resources 4096,4.0,1.0 -j 4 //tensorflow/cc:tutorials_example_trainer\n```\n\nExplanations:\n- build: what bazel should do\n- -c opt: Don't know, says so in the docu\n- --config=cuda: Compile with CUDA support. Don't ask me why you have to specify that again, even though you did so in ./configure.\n- --genrule_strategy=standalone: This compiles in \"standalone mode\". Don't ask me what that is, but it's required so that generated output files can find the `libcudart.so` that they are linked to (see issue #2053).\n- --local_resources 4096,4.0,1.0 -j 4: Use at most 4096M of memory, 4.0 CPU's, 1.0 of I/O and 4 threads. This is required so that the compilation doesn't crash due to out-of-memory (I have 8GB of physical memory and 4GB of swap). The 4096 is still a lie, because the compilation still used more - but at least it didn't crash.\n- //tensorflow/cc:tutorials_example_trainer: What to build.\n\nI sincerely hope that this guide will be obsolete very soon, and you can just get cracking without all these workarounds. But for now, this will probably be useful.\n", "@aehlig \n\nHere's the output with `--announce_rc` but not `--genrule_strategy=standalone`\n\n```\n$ bazel build -c opt --config=cuda --local_resources 4096,4.0,1.0 -j 4 --announce_rc //tensorflow/cc:tutorials_example_trainerINFO: Options provided by the client:\n  Inherited 'common' options: --isatty=1 --terminal_columns=173\nINFO: Reading options for 'build' from /home/alexander/.local/src/tensorflow/tools/bazel.rc:\n  'build' options: --force_python=py2 --python2_path=/usr/bin/python --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone\nINFO: Reading options for 'build' from /home/alexander/.local/src/tensorflow/tools/bazel.rc:\n  'build' options: --crosstool_top=//third_party/gpus/crosstool --define=using_cuda=true\n```\n\nHere's the output with both\n\n```\n$ bazel build -c opt --config=cuda --genrule_strategy=standalone --local_resources 4096,4.0,1.0 -j 4 --announce_rc //tensorflow/cc:tutorials_example_trainer\nINFO: Options provided by the client:\n  Inherited 'common' options: --isatty=1 --terminal_columns=173\nINFO: Reading options for 'build' from /home/alexander/.local/src/tensorflow/tools/bazel.rc:\n  'build' options: --force_python=py2 --python2_path=/usr/bin/python --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone\nINFO: Reading options for 'build' from /home/alexander/.local/src/tensorflow/tools/bazel.rc:\n  'build' options: --crosstool_top=//third_party/gpus/crosstool --define=using_cuda=true\n```\n\nI really don't know how `--spawn_startegy=standalone` interacts with `--genrule_strategy=standalone`, but I know that without the latter being passed on the command line, the compilation fails with the missing libcudart.so. \n", "As discussed offline with @aehlig, --spawn_strategy and --genrule_strategy\nare two different things, I totally missed that tensorflow does not have\nthe later in their rc file.\n\nOn Tue, Apr 26, 2016 at 11:35 PM Alexander Korsunsky <\nnotifications@github.com> wrote:\n\n> @aehlig https://github.com/aehlig\n> \n> Here's the output with --announce_rc but not --genrule_strategy=standalone\n> \n> $ bazel build -c opt --config=cuda --local_resources 4096,4.0,1.0 -j 4 --announce_rc //tensorflow/cc:tutorials_example_trainerINFO: Options provided by the client:\n>   Inherited 'common' options: --isatty=1 --terminal_columns=173\n> INFO: Reading options for 'build' from /home/alexander/.local/src/tensorflow/tools/bazel.rc:\n>   'build' options: --force_python=py2 --python2_path=/usr/bin/python --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone\n> INFO: Reading options for 'build' from /home/alexander/.local/src/tensorflow/tools/bazel.rc:\n>   'build' options: --crosstool_top=//third_party/gpus/crosstool --define=using_cuda=true\n> \n> Here's the output with both\n> \n> $ bazel build -c opt --config=cuda --genrule_strategy=standalone --local_resources 4096,4.0,1.0 -j 4 --announce_rc //tensorflow/cc:tutorials_example_trainer\n> INFO: Options provided by the client:\n>   Inherited 'common' options: --isatty=1 --terminal_columns=173\n> INFO: Reading options for 'build' from /home/alexander/.local/src/tensorflow/tools/bazel.rc:\n>   'build' options: --force_python=py2 --python2_path=/usr/bin/python --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone\n> INFO: Reading options for 'build' from /home/alexander/.local/src/tensorflow/tools/bazel.rc:\n>   'build' options: --crosstool_top=//third_party/gpus/crosstool --define=using_cuda=true\n> \n> I really don't know how --spawn_startegy=standalone interacts with\n> --genrule_strategy=standalone, but I know that without the latter being\n> passed on the command line, the compilation fails with the missing\n> libcudart.so.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly or view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/2053#issuecomment-214893548\n", "--genrule_strategy=standalone also helped me build on Fedora 23.  Now I can run the example trainer.\n", "Hi, @itsmeolivia , is there any particular reason why you closed this issue?\n\nBecause I just checked again with the latest head (5681406e2874a02835d34be579810a93ad74a473), and I still have the same error as described in the original message.\n\nI believe that compilation should succeed without any magical options that are not described in the tutorial. And my setup really isn't that exotic ;)\n", "@akors Thanks a lot for pointing this out - it took me quite some time until I found this thread...\n"]}, {"number": 2052, "title": "Merge internal changes", "body": "", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "@vrv @wicke PTAL\n"]}, {"number": 2051, "title": "Document the type of \"feed_dict\" values", "body": "Seems undocumented in session, came up in http://stackoverflow.com/questions/36758114/valueerror-setting-an-array-element-with-a-sequence-when-using-feed-dict-in-ten\n", "comments": []}]