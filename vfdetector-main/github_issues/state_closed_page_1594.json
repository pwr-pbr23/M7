[{"number": 5092, "title": "GPU sync failed when use mesos and nvidia-docker for distributed training", "body": "### Environment info\n\nhost os: centos7\nhost cuda: `/usr/local/cuda -> cuda-7.5`\ndocker images: [Dockerfile](https://github.com/chenbiaolong/tfmesos/blob/master/docker/Dockerfile)\ntotal 4 GPUs, output of `curl -s slave-ip:3476/mesos/cli`\n\n```\n--attributes=gpus:eJzUlN9r2zAQx9_3V4x7tlL9sGTJb6mzldINwtbsZfThJEuLqWsXO00pIf_7zoEyAmFjEMaqJ0u6u-_39OG8g29xGJu-g3IHi6HZxgFKUFrOCgcZVKvFnPbFTMM-g0XcNiGOUH7fwWp1vaCbq-WK-UQrcMsMcscwFcikVYqZOmBSmCvjAtVa4mZNGRd13F5026ZukNPp576OLR3fxrHF9zeSH0L758mHlJosLFfzlJqu2bxAyemuup68Xj6NBwOcVsllyflsKnc5_yIoURv6xK5-bupJ1FIQ-a_aPtyPU3bVD1MfhbbkID70A9WW5hB02z_2bf_j5dDlsUr-qvKp6e6hVPu7DD7iQ9NSMNzEx5ZMZzAfwtSnojfLXoVk7swvpR18qCooN8NTzOCq7T3SC-SFcxl8XeMQa9rZKbcbN9htoDQ5acoKwzpCKaTlR91Jfuhvnx1RQY9ae2sYL0LOguOGuYSeKa2Tz9FH7sVJKuJsVPLfU8nPQ0W-JSo6cZnnKJg20TLpuWdJG8us1UIIZ4Wo_Ukq8q-piNNUrPoXs2Lf1Kwor40mWaYxchZ9on9ZEo5JlM4r5VQI-iQVdTYqf5iVM1FR_zeVu_27nwEAAP__G6_XAw --resources=gpus:{GPU-bffffc08-6a09-af7a-2833-6dcaf3a4369c,GPU-aba55b86-07c4-c906-9fab-355fb4abe0b1,GPU-5f0244a1-56e8-2b0b-f568-8851119811db,GPU-3b565496-5ae0-ebf8-6f19-2a29b3393cc5}\n```\n### tensorflow info\n\n**In docker images**:\npip install from:\n\n```\nhttps://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.9.0-cp27-none-linux_x86_64.whl; python_version == '2.7'\n>>> import tensorflow; print(tensorflow.__version__)\n0.9.0\n```\n### details\n\nI try to use **mesos** and **nvidia-docker** for tensorflow distributed training.The main idea of my code (code fork from [douban/tfmesos](https://github.com/douban/tfmesos))is mapping host GPUs into nvidia-docker and run distributed training scrip in docker environment.Most of my code is in [chenbiaolong/tfmesos/docker](https://github.com/chenbiaolong/tfmesos/tree/master/docker),you can see how I build my docker images in Dockerfile.\n\nHowever,when I try to start training(use [nvidia_docker_run.sh](https://github.com/chenbiaolong/tfmesos/blob/master/nvidia_docker_run.sh)), I got errors:\n\n```\nI tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job ps -> {node39.com:36921}\nI tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:206] Initialize HostPortsGrpcChannelCache for job worker -> {localhost:42324, node39.com:36202, node39.com:58828}\nI tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:202] Started server with target: grpc://localhost:42324\nINFO:tensorflow:SyncReplicas enabled: replicas_to_aggregate=3; total_num_replicas=3\nI1020 09:07:12.418039 10 sync_replicas_optimizer.py:175] SyncReplicas enabled: replicas_to_aggregate=3; total_num_replicas=3\nI1020 09:07:12.592327 10 mnist_replica.py:200] Chief Worker 0: Initializing session...\nTraceback (most recent call last):\n  File \"/mnt/example/mnist/mnist_replica.py\", line 247, in <module>\n    tf.app.run()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv))\n  File \"/mnt/example/mnist/mnist_replica.py\", line 211, in main\n    config=sess_config)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/supervisor.py\", line 684, in prepare_or_wait_for_session\n    init_feed_dict=self._init_feed_dict, init_fn=self._init_fn)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/session_manager.py\", line 176, in prepare_session\n    sess.run(init_op, feed_dict=init_feed_dict)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 372, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 636, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 708, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 728, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.AbortedError: RecvTensor expects a different device incarnation: 7338322613985075898 vs. 11093212615818549611. Your worker job was probably restarted. Check your worker job for the reason why it was restarted.\n     [[Node: truncated_normal_S3 = _Recv[client_terminated=false, recv_device=\"/job:ps/replica:0/task:0/cpu:0\", send_device=\"/job:worker/replica:0/task:0/gpu:0\", send_device_incarnation=7338322613985075898, tensor_name=\"edge_42_truncated_normal\", tensor_type=DT_FLOAT, _device=\"/job:ps/replica:0/task:0/cpu:0\"]()]]\nE tensorflow/stream_executor/cuda/cuda_driver.cc:1140] could not synchronize on CUDA context: CUDA_ERROR_DEINITIALIZED :: No stack trace available\nF tensorflow/core/common_runtime/gpu/gpu_util.cc:370] GPU sync failed\nAborted (core dumped)\nTraceback (most recent call last):\n  File \"/usr/local/bin/tfrun\", line 84, in <module>\n    subprocess.check_call(cmd, shell=True)\n  File \"/usr/lib/python2.7/subprocess.py\", line 540, in check_call\n    raise CalledProcessError(retcode, cmd)\nsubprocess.CalledProcessError: Command 'python /mnt/example/mnist/mnist_replica.py --ps_hosts node39.com:36921 --worker_hosts node39.com:42324,node39.com:36202,node39.com:58828 --job_name worker --task_index 0' returned non-zero exit status 134\n\n```\n\nAlthough **nvidia_docker_run.sh** throw errors, mesos tasks(both job:ps and job:worker) seems work well,util they are killed by the framework. Run **nvidia-smi** can see 3GPUs are used(since I ran 3 workers and each work cost 1 GPU ). My training scrip is [mnist_replica.py](https://github.com/chenbiaolong/tfmesos/blob/master/docker/example/mnist/mnist_replica.py)\n### logs\n\n**Logs from tasks** is available [here](https://github.com/chenbiaolong/tfmesos/tree/master/docker/logs)\n\n**mesos slave start**\n\n```\nmesos-slave  --master=$master_ip \\\n            --containerizers=docker,mesos \\\n            --hostname=slave-ip \\\n            --ip=slave-ip \\\n            --log_dir=/var/log/mesos/ \\\n            --work_dir=/var/lib/mesos/ \\\n            $(curl -s slave-ip:3476/mesos/cli)\n```\n", "comments": ["Which version of TensorFlow are you using? In the future, please provide all the information requested for in the [New issue template](https://github.com/tensorflow/tensorflow/issues/new)\n\n@jhseu might have some thoughts in this.\n", "@asimshankar sorry, I had added some information that maybe helpful. \n", "I finally solved the problem.It is a bug in my code, not the tensorflow issue.when I ran the `nvidia_docker_run.sh` I create a worker:0 job,which is no under the mesos's control. And the mesos create another worker:0 container  after the  mesos framework launched.So there are 2 worker:0 containers cause the mismatch of device incarnation.\n", "how do you use mesos to run tensorflow? marathon or some else framwork?  thank you!", "@sunhongtao mesos can launch tasks in docker, no other frameworks are used in my code.I just build a docker image with tensorflow, and mesos launch container base on the image.you can read the https://github.com/douban/tfmesos for details, my code is based on that."]}, {"number": 5091, "title": "doc: fix possible copy&paste error in cumprod docs", "body": "", "comments": ["@temporaer, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener to be a potential reviewer.\n", "Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "Sorry, the docs are auto-generated. Please fix this upstream in tensorflow/python/ops/math_ops.py.\n"]}, {"number": 5090, "title": "LSTM's forget gate biases", "body": "Hi all,\n\nI was looking into the LSTMCell code and I got confused:\n\n[Line 505](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn_cell.py#L505) show us the computations of new input and the gates: input, forget and output.\n\nBoth [line 517](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn_cell.py#L517) and [line 520](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/rnn_cell.py#L517) show the addition of the forget gate (which is a scalar in this particular piece of code).\n\nI got confused by this addition as it seems to be already done when we split the gate's values  in line 505 as mentioned before. Am I missing something or is this a second addition to the forget gate computations? If it is a second addition, wouldn't that change the computations?\n\nBy the way, that bias shouldn't be a vector instead of a single scalar?\n\nSorry if I am saying nonsense. but I'd like to double check that before saying it is a bug.\n", "comments": ["@ebrevdo : Any insights?\n", "Those lines don't both get executed.  Only one of them does.  It depends on you enable using peepholes or not.  Finally, this forget_bias is added via broadcasting (so it's ok for it to be a scalar).  The \"true\" bias is added at line 504, via tf.bias_add.\n"]}, {"number": 5089, "title": "word2vec_basic: matplotlib warning", "body": "Running the example: `word2vec_basic` - https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/word2vec/word2vec_basic.py\n\nreturns the following warning \n\n```\n/System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python/matplotlib/collections.py:548: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n  if self._edgecolors == 'face':\n```\n\nplatforms\n\n```\n$ sw_vers\nProductName:    Mac OS X\nProductVersion: 10.12\nBuildVersion:   16A323\n$ python -c 'import tensorflow; print tensorflow.__version__'\n0.11.0rc0\n```\n", "comments": ["Which version of numpy and matplotlib do you have installed?\nYou can use the following to obtain them:\n\n```\npython -c \"import matplotlib; import numpy as np; print matplotlib.__version__; print np.__version__\"\n```\n\nI suspect you're using an old version of matplotlib (before 1.5.0) are are being affected by https://github.com/matplotlib/matplotlib/issues/5209\n", "@asimshankar \n\n```\n$ python -c \"import matplotlib; import numpy as np; print matplotlib.__version__; print np.__version__\"\n1.3.1\n1.11.2\n```\n\nI did via\n\n```\n$ sudo virtualenv --system-site-packages ~/tensorflow\n$ source ~/tensorflow/bin/activate\n```\n\nto update dependencies. So it seems they are not updating?\n", "**[UPDATE]**\n\nOk I did\n\n```\n$ sudo pip install matplotlib --upgrade\n```\n\nnow I get\n\n```\n$ python -c \"import matplotlib; import numpy as np; print matplotlib.__version__; print np.__version__\"\n1.5.3\n1.11.2\n```\n\nI will try again then.\n", "**[UPDATE]**\n\nThis this I get a weird error from `matplotlib`:\n\n```\nRuntimeError: Python is not installed as a framework. The Mac OS X backend will not be able to function correctly if Python is not installed as a framework. See the Python documentation for more information on installing Python as a framework on Mac OS X. Please either reinstall Python as a framework, or try one of the other backends. If you are Working with Matplotlib in a virtual enviroment see 'Working with Matplotlib in Virtual environments' in the Matplotlib FAQ\n```\n\nhere it is the stacktrace\n\n```\nTraceback (most recent call last):\n  File \"word2vec_basic.py\", line 240, in <module>\n    import matplotlib.pyplot as plt\n  File \"/Users/admin/tensorflow/lib/python2.7/site-packages/matplotlib/pyplot.py\", line 114, in <module>\n    _backend_mod, new_figure_manager, draw_if_interactive, _show = pylab_setup()\n  File \"/Users/admin/tensorflow/lib/python2.7/site-packages/matplotlib/backends/__init__.py\", line 32, in pylab_setup\n    globals(),locals(),[backend_name],0)\n  File \"/Users/admin/tensorflow/lib/python2.7/site-packages/matplotlib/backends/backend_macosx.py\", line 24, in <module>\n    from matplotlib.backends import _macosx\n```\n\nI do not know what is this, but, hopefully this solution will be time saving for other users:\n\nYou can check that this happens as well\n\n```\nimport matplotlib.pyplot\n```\n\nand to fix it\n\n```\n(tensorflow) admin@macbookproloreto:~/Projects/MusiXmatch/AI/tensorflow$ echo \"backend: TkAgg\" >> ~/.matplotlib/matplotlibrc\n```\n\nnow it will work!\n\n```\nw$ python\nPython 2.7.10 (default, Jul 30 2016, 18:31:42) \n[GCC 4.2.1 Compatible Apple LLVM 8.0.0 (clang-800.0.34)] on darwin\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import matplotlib.pyplot\n/Users/admin/tensorflow/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n>>> \n```\n\nFor reference see: https://github.com/JuliaPy/PyCall.jl/issues/218\n", "Unfortunately, how to get other packages such as matplotlib to work in specific environments is not our area of expertise and not something that we can debug in the TensorFlow project.\n\nThat said, just going off the error message you pointed to above, have you looked at [\"Working with Matplotlib in Virtual environments\"](http://matplotlib.org/faq/virtualenv_faq.html) in the Matplotlib FAQ.\n\nPerhaps you can get advice on stackoverflow or on the Matplotlib project. You may also find this link: http://matplotlib.org/faq/installing_faq.html#which-python-for-os-x interesting.\n\nHope you find a solution, best of luck!\n"]}, {"number": 5088, "title": "issue-4737", "body": "Issue description: https://github.com/tensorflow/tensorflow/issues/4737\nI test it by: \n\n```\nx = tf.constant(-1,tf.float32)\ny = tf.nn.elu(x)\ndy = tf.gradients(y,x)\nddy = tf.gradients(dy,x)\ndddy = tf.gradients(ddy,x)\n\nelu2 = lambda x: tf.select(x < 0., tf.exp(x) - 1., x)\ndy2 = tf.gradients(elu2(x), x)\nddy2 = tf.gradients(dy2,x)\n\nwith tf.Session() as sess:\n    print sess.run(dy2)\n    print sess.run(ddy2)\n    print sess.run(dy)\n    print sess.run(ddy)\n    print sess.run(dddy)\n```\n", "comments": ["@guotong1988, thanks for your PR! By analyzing the history of the files in this pull request, we identified @keveman, @tensorflower-gardener and @zheng-xq to be potential reviewers.\n", "Can one of the admins verify this patch?\n", "Thanks for the contribution. Can you extend the tests in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/kernel_tests/relu_op_test.py to also cover the second order derivatives for Elu ? Thanks.\n", "OK\n", "@guotong1988 , to be clear, did you address Benoit's request?\n", "I already commit the unit test.\n", "Jenkins, test this please.\n"]}, {"number": 5087, "title": "C++ style concern of potential memory leak", "body": "All the factories methods consisting a `static` pointer to heap allocated variable potentially cause memory leak, as the static in-function variables are allocated/disposed for the program life-time, but if the object is dynamically allocated on heap, the object itself is never disposed (only its pointer gets disposed).\n\nFor example, in [session_factory.cc:37](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/session_factory.cc#L37)\n\n``` cpp\nstatic mutex* get_session_factory_lock() {\n  static mutex session_factory_lock;\n  return &session_factory_lock;\n}\n\ntypedef std::unordered_map<string, SessionFactory*> SessionFactories;\nSessionFactories* session_factories() {\n  static SessionFactories* factories = new SessionFactories;\n  return factories;\n}\n```\n\nNote that the `factories` is a _static pointer_, not a _pointer to a static object_. Since the object itself is not static, it will not be disposed and cause memory leak.\n\nSuggested change:\n\n``` cpp\nstatic mutex* get_session_factory_lock() {\n  static mutex session_factory_lock;\n  return &session_factory_lock;\n}\n\ntypedef std::unordered_map<string, SessionFactory*> SessionFactories;\nSessionFactories* session_factories() {\n  static SessionFactories factories = SessionFactories();\n  return &factories;\n}\n```\n\nOne could easily write a small program and use `valgrind` to verify the memory leak. One example is [here](https://gist.github.com/a5b0d262e5f64f36b299003634493eca).\n", "comments": ["@byronyi : Destruction order of static objects is not fully specified in C++, so our [programming style](https://google.github.io/styleguide/cppguide.html#Static_and_Global_Variables) avoids using them. This does mean that the destructor for objects allocated for the lifetime of the process are never called, but one could make the case that running those destructors at program exit (when all process memory is going to be released anyway) is of questionable value.\n\nHope that helps. Thanks.\n"]}, {"number": 5086, "title": "Some workers doesn't exist when training in distributed mode", "body": "We have tried distributed TensorFlow and it works for training. But sometimes only some workers will execute the code and exit after training. Sometimes all workers will exit finally with the same code. \n\nThe code of distributed TensorFlow application is [here](https://github.com/tobegit3hub/deep_recommend_system/tree/master/distributed). Is that a bug or can anyone explain why?\n### Environment info\n\nOperating System: Ubuntu 16.04\n\nInstalled version of CUDA and cuDNN:  Not installed.\n\nTensorFlow version: 0.11.0rc0\n", "comments": ["Your ps should never exit (because of `server.join()`)\n", "Thanks @yaroslavvb for quick response.\n\nSorry about my statement. When I mention \"worker\", I mean the \"worker task\" not including \"ps\". \n\nI thinks the actual workers should exit after training. And sometimes they work like what we expect but sometimes not.\n", "I'm interpreting your original issue is that some workers get stuck. If so, there can be many reasons, and you could isolate better where exactly it gets stuck, here's a related issue with better information -- https://github.com/tensorflow/tensorflow/issues/4932#issuecomment-254234355\n", "Yes and thanks @yaroslavvb . We will have a look at that issue.\n", "Automatically closing due to lack of recent activity. Please let us know when further information is available and we will reopen. Thanks!\n"]}, {"number": 5085, "title": "replaced inception file with v3", "body": "This is to fix issue #5007\n", "comments": ["Can one of the admins verify this patch?\n", "@ghego, thanks for your PR! By analyzing the history of the files in this pull request, we identified @petewarden, @vrv and @tensorflower-gardener to be potential reviewers.\n", "Can you verify that the process documented in the codelab at codelabs.developers.google.com/codelabs/tensorflow-for-poets/index.html still works with this change? I'm a bit surprised we don't need to change any of the layer names for example, but it may be that the naming is the same.\n", "Ok, will verify that\n", "@petewarden This week I won't have time to check that https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/index.html#0 still works. If anyone wants to step up and do it sooner please feel free, otw I'll do it after Nov 1st\n", "friendly ping\n", "friendly ping\n", "@petewarden finally found some time to work on this. I rebased my fork to be up-to-date with current master, downloaded and started docker container, pulled my branch (i.e. most recent commit on upstream + my commit of v3 inception) and followed the instructions at https://codelabs.developers.google.com/codelabs/tensorflow-for-poets/index.html#4.\r\nUnfortunately this breaks because `tf.app.run` in v0.12 has `argv` param, and the docker file still has tensorflow binaries for v0.11, which doesn't have `argv`.\r\n\r\n```bash\r\nroot@f313c94f7236:/tensorflow# python tensorflow/examples/image_retraining/retrain.py \\\r\n> --bottleneck_dir=/tf_files/bottlenecks \\\r\n> --how_many_training_steps 500 \\\r\n> --model_dir=/tf_files/inception \\\r\n> --output_graph=/tf_files/retrained_graph.pb \\\r\n> --output_labels=/tf_files/retrained_labels.txt \\\r\n> --image_dir /tf_files/flower_photos\r\n\r\nTraceback (most recent call last):\r\n  File \"tensorflow/examples/image_retraining/retrain.py\", line 1012, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\nTypeError: run() got an unexpected keyword argument 'argv'\r\n```\r\n\r\nhow do you suggest to proceed?", "Tested it on `r0.12rc0`. It fails because the content of the zip file is different from the previous one. Here's the error:\r\n\r\n```\r\n>> Downloading inception-v3-2016-03-01.tar.gz 100.0%\r\nSuccessfully downloaded inception-v3-2016-03-01.tar.gz 399307177 bytes.\r\nTraceback (most recent call last):\r\n  File \"tensorflow/examples/image_retraining/retrain.py\", line 1012, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 43, in run\r\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\r\n  File \"tensorflow/examples/image_retraining/retrain.py\", line 753, in main\r\n    create_inception_graph())\r\n  File \"tensorflow/examples/image_retraining/retrain.py\", line 260, in create_inception_graph\r\n    graph_def.ParseFromString(f.read())\r\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/lib/io/file_io.py\", line 106, in read\r\n    self._preread_check()\r\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/lib/io/file_io.py\", line 73, in _preread_check\r\n    compat.as_bytes(self.__name), 1024 * 512, status)\r\n  File \"/anaconda/lib/python2.7/contextlib.py\", line 24, in __exit__\r\n    self.gen.next()\r\n  File \"/anaconda/lib/python2.7/site-packages/tensorflow/python/framework/errors_impl.py\", line 469, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\ntensorflow.python.framework.errors_impl.NotFoundError: /tf_files/inception/classify_image_graph_def.pb\r\n```\r\n\r\nHere's the content of `inception-2015-12-05`:\r\n```\r\nclassify_image_graph_def.pb\r\ncropped_panda.jpg\r\nimagenet_2012_challenge_label_map_proto.pbtxt\r\nimagenet_synset_to_human_label_map.txt\r\nLICENSE\r\n```\r\n\r\nwhile here's the content of  `inception-v3-2016-03-01`:\r\n\r\n```\r\ncheckpoint\r\nmodel.ckpt-157585\r\nREADME.txt\r\n```\r\n\r\nI think the solution is to change the how the function `create_inception_graph` reloads the model, not sure how to fix it yet.", "The new zip file doesn't contain the graph. I think the graph you need is the one in https://github.com/tensorflow/models/inception. \r\n\r\nAs soon as feasible, we should migrate all these examples to use SavedModel, which would contain both the graph, the checkpoint, and also annotations to say which tensors to feed and fetch. ", "@ghego could you merge conflicts and push again?", "Close due to inactivity. Please read Martin's comment for requested updates. Thanks."]}, {"number": 5084, "title": "[feature request] Defining gradient functions of new Ops using custom python functions", "body": "As explained in https://www.tensorflow.org/versions/r0.11/how_tos/adding_an_op/index.html, the gradient functions for new Ops have to use other tensorflow Ops. This is a big limitation for me. I want to use other python functions to implement the gradient function.\n\nBtw, this is a good [answer](http://stackoverflow.com/questions/39048984/tensorflow-how-to-write-op-with-gradient-in-python) to define new Ops purely in python, but it still has the limitation that the gradient function has to use other existing tensorflow Ops.\n", "comments": ["Hi @chenqifeng22 : Could you elaborate a bit as to why you need to define this in python only? If the gradient for your custom op cannot be implemented in terms of existing ops, then you can also define a custom op for the gradient and use that. For example, the gradient of the `Sqrt` operation is the [`SqrtGrad`](https://github.com/tensorflow/tensorflow/blob/c8a45a8e236776bed1d14fd71f3b6755bd63cc58/tensorflow/core/ops/math_ops.cc#L258) operation. Would something like that not work for you?\n\nCalling back into python during graph execution for any operation (and consequently gradient computation) is going to create performance problems - greatly hampering the use of multiple threads, cores and devices.\n", "Hi @asimshankar I am defining a new Op in which a Caffe model is called. Its return value can be computed by the forward inference of Caffe in tf.py_func following this [post](http://stackoverflow.com/questions/39048984/tensorflow-how-to-write-op-with-gradient-in-python). For the gradient function of the new Op, I want to use the backpropagation of Caffe to compute gradients. Otherwise, I need to take some efforts to convert the Caffe model to tensorflow.\n\nThanks for your suggestion about SqrtGrad. I will try to define a custom Op for the gradient.\n", "@chenqifeng22 you can use py_func to define gradient function using Python\nops, as described here --\nhttp://stackoverflow.com/questions/40060047/tensorflow-how-can-i-process-in-numpy-op-outputs-in-py-func-gradient/40065673#40065673\n\nOn Wed, Oct 19, 2016 at 7:02 PM, chenqifeng22 notifications@github.com\nwrote:\n\n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/5084, or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AABaHGw2TS9OPNM4BSpKd5pRQLi7rYs0ks5q1suggaJpZM4KbpM8\n> .\n", "@yaroslavvb This looks like a great solution! Thanks!\n"]}, {"number": 5083, "title": "Strange memory usage with atrous_conv2d on 1D signal.", "body": "I am trying to build my own wavenet to generate sound.  For this I need to perform a dilated convolution on a 1D signal.  To accomplish this I simply added dummy dimension to my input and filter.\n\n```\ndef dilated_causal_conv1d(x, filter, dialation):\n    padding = (tf.shape(filter)[0] - 1) * dialation\n    x = tf.pad(x, ((0, 0), (padding, 0), (0, 0)))\n    filter = tf.expand_dims(filter, 0)\n    x = tf.expand_dims(x, 0)\n    x = tf.nn.atrous_conv2d(x, filter, dialation, 'VALID')\n    x = tf.squeeze(x, (0,))\n    return x[:, padding:]\n```\n\nThis appears to be working although I have not tried training it yet.  I have just managed to send a bunch of zeros through the network to make sure all of the shapes are in alignment.  When I ran it with an input of size (2, 16000) I got an error saying...\n\n> W tensorflow/core/common_runtime/bfc_allocator.cc:217] Ran out of memory trying to allocate 2.75GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\n\nI did manage to successfully run even with this message so I increased the batch size and ran it again and it still worked.  I kept doing this and I was able to get my batch size up to 64 and it still has not failed to execute.  This is strange to me since I only ever get these warning when I am on the verge of running out of memory.  I remember reading somewhere that atrous_conv2d can be very inefficient in terms of memory on 1D signals, however I have not been able to find that again or an explanation of why.\n\nI am using the latest tensorflow on Ubuntu 16.04 with Cuda 8.  The size of the dilations range from 1 to 1024 in powers of 2 increments.\n", "comments": ["@chasep255 : Could you elaborate on what you're finding strange? The warning log line means that the framework was unable to allocate 2.75G of memory, but this failure to allocate can be tolerated at the cost of some performance. So your runs should finish successfully.\n", "Automatically closing due to lack of recent activity. Please let us know when further information is available and we will reopen. Thanks!\n"]}, {"number": 5082, "title": "Feature request - Check that QueueRunner enqueue ops use the correct queue", "body": "The documentation for [`tf.train.QueueRunner.__init__`](https://www.tensorflow.org/versions/r0.11/api_docs/python/train.html#QueueRunner) states:\n\n\"The enqueue ops do not have to all be the same op, but it is expected that they all enqueue tensors in `queue`.\"\n\nWould it be possible for tensorflow to check that the given ops do in fact enqueue tensors in the correct queue, and throw an error if they do not?  I encountered a problem recently where I mistakenly passed the wrong queue to my `QueueRunner`, and as a result, the clean shutdown behavior described [here](https://www.tensorflow.org/versions/r0.11/how_tos/reading_data/index.html#creating-threads-to-prefetch-using-queuerunner-objects) wasn't working as expected.  Changing to the correct queue solved the problem.  This was definitely user error on my part, but it was a bit tricky to track this problem down, and it seems like the kind of thing that would be possible to check automatically.\n", "comments": ["There was no check preventing people from doing that, so there may be people using single queue runner to enqueue to multiple queues successfully out there. So starting to enforce that now will break those people. The practical issue for maintainers is that they would have to make all Google tests pass, and changing default behavior can turn into a lot of work. I once spent some time trying to change \"start_queue_runners\" to finalize a graph to prevent thread race like http://stackoverflow.com/questions/36645799/tensorflows-target-pruning-cant-find-nodes/36649470#36649470, but it turned out to need more than >1week of work rewriting unit tests for teams who relied on incorrect (but allowed) usage\n", "OK, that sounds like a reasonable argument for not doing this. :)\n"]}, {"number": 5081, "title": "why there are so many different versions for models?", "body": "I am confused about the versions of tensor flow models. There are at lease 3.\n\n1) This one i can call as **main** folder.\n\nhttps://github.com/tensorflow/models\n\n2) Another one is inside of the main folder is called **slim** and it has instructions about how to use, such as **train_image_classifier.py** , which currently i am using. I do not need write more code, just input some parameters.\n\nhttps://github.com/tensorflow/models/tree/master/slim\n\n3) the second **slim** is in the folder blow, which provide different instructions as above **slim**.  It seems that I must write additional python code to make it work. And the **learning.py** under this slim folder is different from above **train_image_classifier.py**.\n\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim\n# \n\nIs there any necessity to provide so many branches or versions?  I guess they belong to different teams? Is there any consensus (internally) about which is the major one? This may not be a technical issue but a political issue.\n", "comments": ["The tensorflow/models repository contains models for multiple tasks and the code used to build them. For example, tensorflow/models/im2txt is very different from tensorflow/models/inception.\n\n(2) and (3) that you point out are very similar and over time they will be consolidated.\nA general rule of thumb is that models in the tensorflow/models are more of a demonstration of interesting models built with TensorFlow while the code in the tensorflow/tensorflow repository is the supported API of TensorrFlow.\n\nHope that helps.\n"]}, {"number": 5080, "title": "no such package '@lodash//': Error downloading...", "body": "Trying to install Tensorflow and getting this issue:\n\nchad@chad-GA-990XA-UD3:~/tensorflow$ ./configure\n~/tensorflow ~/tensorflow\nPlease specify the location of python. [Default is /usr/bin/python]: \nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] n\nNo Google Cloud Platform support will be enabled for TensorFlow\nDo you wish to build TensorFlow with Hadoop File System support? [y/N] n\nNo Hadoop File System support will be enabled for TensorFlow\nFound possible Python library paths:\n  /usr/local/lib/python2.7/dist-packages\n  /usr/lib/python2.7/dist-packages\nPlease input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]\n\n/usr/local/lib/python2.7/dist-packages\nDo you wish to build TensorFlow with GPU support? [y/N] y\nGPU support will be enabled for TensorFlow\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \nPlease specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \nPlease specify the Cudnn version you want to use. [Leave empty to use system default]: 5.1.5\nPlease specify the location where cuDNN 5.1.5 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\nPlease note that each additional compute capability significantly increases your build time and binary size.\n\nINFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.\n..........\nERROR: /home/chad/tensorflow/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@lodash//': Error downloading from https://github.com/lodash/lodash/archive/3.8.0.tar.gz to /home/chad/.cache/bazel/_bazel_chad/e711407cb831141b1f7166a396931060/external/lodash: Error downloading https://github.com/lodash/lodash/archive/3.8.0.tar.gz to /home/chad/.cache/bazel/_bazel_chad/e711407cb831141b1f7166a396931060/external/lodash/3.8.0.tar.gz: Timed out connecting to https://github.com/lodash/lodash/archive/3.8.0.tar.gz : connect timed out and referenced by '//tensorflow/tensorboard/bower:bower'.\nERROR: /home/chad/tensorflow/tensorflow/tensorboard/bower/BUILD:5:1: no such package '@lodash//': Error downloading from https://github.com/lodash/lodash/archive/3.8.0.tar.gz to /home/chad/.cache/bazel/_bazel_chad/e711407cb831141b1f7166a396931060/external/lodash: Error downloading https://github.com/lodash/lodash/archive/3.8.0.tar.gz to /home/chad/.cache/bazel/_bazel_chad/e711407cb831141b1f7166a396931060/external/lodash/3.8.0.tar.gz: Timed out connecting to https://github.com/lodash/lodash/archive/3.8.0.tar.gz : connect timed out and referenced by '//tensorflow/tensorboard/bower:bower'.\nERROR: Evaluation of query \"deps((//tensorflow/... union @bazel_tools//tools/jdk:toolchain))\" failed: errors were encountered while computing transitive closure.\nchad@chad-GA-990XA-UD3:~/tensorflow$ \n\nCan anyone help?\n", "comments": ["So i ran it again and now i'm getting the same sort of error but for different packages..\n\nI have run pings to google.com and github.com while running this operation and both pings are fine and don't time out.\n\nchad@chad-GA-990XA-UD3:~/tensorflow$ ./configure\n~/tensorflow ~/tensorflow\nPlease specify the location of python. [Default is /usr/bin/python]: \nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] n\nNo Google Cloud Platform support will be enabled for TensorFlow\nDo you wish to build TensorFlow with Hadoop File System support? [y/N] n\nNo Hadoop File System support will be enabled for TensorFlow\nFound possible Python library paths:\n  /usr/local/lib/python2.7/dist-packages\n  /usr/lib/python2.7/dist-packages\nPlease input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]\n\n/usr/local/lib/python2.7/dist-packages\nDo you wish to build TensorFlow with GPU support? [y/N] y\nGPU support will be enabled for TensorFlow\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]: \nPlease specify the Cuda SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \nPlease specify the Cudnn version you want to use. [Leave empty to use system default]: 5.1.5\nPlease specify the location where cuDNN 5.1.5 library is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\nPlease note that each additional compute capability significantly increases your build time and binary size.\n\nINFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.\n...........\nERROR: /home/chad/tensorflow/tensorflow/core/platform/default/build_config/BUILD:75:1: no such package '@highwayhash//': Error downloading from http://github.com/google/highwayhash/archive/4bce8fc6a9ca454d9d377dbc4c4d33488bbab78f.tar.gz to /home/chad/.cache/bazel/_bazel_chad/e711407cb831141b1f7166a396931060/external/highwayhash: Error downloading http://github.com/google/highwayhash/archive/4bce8fc6a9ca454d9d377dbc4c4d33488bbab78f.tar.gz to /home/chad/.cache/bazel/_bazel_chad/e711407cb831141b1f7166a396931060/external/highwayhash/4bce8fc6a9ca454d9d377dbc4c4d33488bbab78f.tar.gz: Timed out connecting to http://github.com/google/highwayhash/archive/4bce8fc6a9ca454d9d377dbc4c4d33488bbab78f.tar.gz : connect timed out and referenced by '//tensorflow/core/platform/default/build_config:platformlib'.\nERROR: /home/chad/tensorflow/tensorflow/core/platform/default/build_config/BUILD:75:1: no such package '@highwayhash//': Error downloading from http://github.com/google/highwayhash/archive/4bce8fc6a9ca454d9d377dbc4c4d33488bbab78f.tar.gz to /home/chad/.cache/bazel/_bazel_chad/e711407cb831141b1f7166a396931060/external/highwayhash: Error downloading http://github.com/google/highwayhash/archive/4bce8fc6a9ca454d9d377dbc4c4d33488bbab78f.tar.gz to /home/chad/.cache/bazel/_bazel_chad/e711407cb831141b1f7166a396931060/external/highwayhash/4bce8fc6a9ca454d9d377dbc4c4d33488bbab78f.tar.gz: Timed out connecting to http://github.com/google/highwayhash/archive/4bce8fc6a9ca454d9d377dbc4c4d33488bbab78f.tar.gz : connect timed out and referenced by '//tensorflow/core/platform/default/build_config:platformlib'.\nERROR: Evaluation of query \"deps((//tensorflow/... union @bazel_tools//tools/jdk:toolchain))\" failed: errors were encountered while computing transitive closure.\nchad@chad-GA-990XA-UD3:~/tensorflow$ \n", "Every time i run this it happens with different packages..\n", "This seems like there might be some networking issues on the device you're running the build on. I see many error messages of the form \"Timed out connecting to <some URL>\" in the output you've provided above.\n\nPerhaps your internet connection is a bit flaky at this time?\n", "@asimshankar I don't think so, i have been running many tests constantly and getting this same issue, while the configure is running i can see the script is transferring and 0b/s but if i open the link its trying to download in the browser then it downloads fine, but the script still cant get it. and while the test is running i had monitors monitoring the network , pints, qos, and i did live transfers and everything went smoothly. \n\nI think this is something code related, but i'm not sure. \n", "Perhaps there is some proxy or other networking configuration set in the browser?\nCan you download these files on the command line using `curl` or `wget`?\n", "There is no specific config set, brand new os installed. and yeah i can download with curl and wget :)\n", "I have tried this morning and getting same issue but internet seems fine.\n", "@asimshankar Do you know if there is a temporary workaround where i can download the packages manually and put them somewhere to make it work?\n", "So it seems like you're having an issue with bazel being able to download dependencies. Unfortunately, debugging that isn't something that we have the bandwidth for in the TensorFlow team. I'd encourage you to seek advice on stackoverflow and/or bazel. \n\nThat said, one possibility is that there is some configuration issue preventing Java programs from fetching data over the network (bazel is written in Java). Is there a simpler program (such as something like https://docs.oracle.com/javase/tutorial/networking/urls/readingURL.html) you can use to validate network access from the JVM?\n\nAn alternative workaround: we did see someone try this trick: https://github.com/tensorflow/tensorflow/issues/5029#issuecomment-254769127\nto work with pre-downloaded packages.\n\nHope that helps!\n", "Closing this issue out due to inactivity. Let us know if there still is a problem. Thanks!\n", "Thanks, the method worked. I forgot to reply back. \n\nI downloaded all the files manually and made a virtual server to serve the files and then changed the urls in the code manually so that it would download the files locally.\n\nThanks for the help you provided.\n"]}, {"number": 5079, "title": "Fix typo in conv2d doc", "body": "Currently, docs for conv2d:\n\n``` markdown\nFor the most common case of the same\nhorizontal and **vertices** strides, `strides = [1, stride, stride, 1]`.\n```\n\nI believe it should be:\n\n``` markdown\nFor the most common case of the same\nhorizontal and **vertical** strides, `strides = [1, stride, stride, 1]`.\n```\n", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins test this please\n", "PR Merged. Thanks, @Quarazy \n"]}, {"number": 5078, "title": "Tensorflow on Ubuntu 14 with cuda 8 and cudnn 5.1", "body": "Hello I am trying to install tensorflow on ubuntu 14 with cuda 8 and cudnn 5.1. I followed the instructions here  https://www.tensorflow.org/versions/r0.11/get_started/os_setup.html#installing-from-sources\nI was able to run the demo model but when I try to import tensorflow in python I get the following error\n\n> > > import tensorflow\n> > > I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so.8.0 locally\n> > > I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so.5.1.5 locally\n> > > I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so.8.0 locally\n> > > I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\n> > > I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so.8.0 locally\n> > > Traceback (most recent call last):\n> > >   File \"<stdin>\", line 1, in <module>\n> > >   File \"/usr/local/lib/python2.7/dist-packages/tensorflow/**init**.py\", line 23, in <module>\n> > >     from tensorflow.python import *\n> > >   File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/**init**.py\", line 63, in <module>\n> > >     from tensorflow.core.framework.graph_pb2 import *\n> > >   File \"/usr/local/lib/python2.7/dist-packages/tensorflow/core/framework/graph_pb2.py\", line 9, in <module>\n> > >     from google.protobuf import symbol_database as _symbol_database\n> > >   File \"/usr/local/lib/python2.7/dist-packages/google/protobuf/symbol_database.py\", line 165, in <module>\n> > >     _DEFAULT = SymbolDatabase(pool=descriptor_pool.Default())\n> > > AttributeError: 'module' object has no attribute 'Default'\n", "comments": ["I get the same error, how did you fix this ?\n", "I used 0.10 instead of the master and that fixed it\n"]}, {"number": 5077, "title": "Little change in tf.contrib.learn Quickstart tutorial", "body": "", "comments": ["Can one of the admins verify this patch?\n", "@boing102, thanks for your PR! By analyzing the history of the files in this pull request, we identified @jart, @tensorflower-gardener and @philstahlfeld to be potential reviewers.\n", "Can you elaborate why this is needed?\n", "Because the tf.contrib.learn.datasets.base.load_csv_with_header function takes 3 arguments not only 2. I dont think the examples in those files work.\n\nEdit: I followed the commit partially solving a problem here: https://github.com/tensorflow/tensorflow/issues/4923\n", "Ah, thanks!\n@jart is this still needed?\n", "Jenkins, test this please.\n", "Can you rebase to deal with the conflict?\n", "I used your guys' version as in tensorflow/master to resolve the conflict.\n", "@tensorflow-jenkins test this please\n", "@tensorflow-jenkins test this please\n"]}, {"number": 5076, "title": "windows specific eigen patch to enable gpu support for windows", "body": "compiling cuda kernels for windows fails. The following windows specific patch does temporarily fix this. Going to send the change also to eigen.\n", "comments": ["Can one of the admins verify this patch?\n", "@mrry maybe interested?\nAuto notifier on original patch went to @ebrevdo and @ibab \n", "This change looks fine to me, but it'd be great if @benoitsteiner or @rmlarsen could comment on how we could get these changes upstream in Eigen (or if there's another workaround for compiling with NVCC on Windows (MSVC 2015)).\n", "going to take a look if that will work.\n", "Yes, https://bitbucket.org/eigen/eigen/commits/59db0512e12d98e8e223483f785931a076984288 fixes the Macros.h issue and is the better fix. If you are planning to update the master with a new Eigen version that contains that fix I could take Macros.h out of this patch.\n", "Triangular Solver is a side effect of how I changed Macros.h. If I take , https://bitbucket.org/eigen/eigen/commits/59db0512e12d98e8e223483f785931a076984288  instead, it seems fine. Clean master with only 59db0512e12d98e8e223483f785931a076984288  on top builds and runs fine.\nSo I could either update this pull request to only include 59db0512e12d98e8e223483f785931a076984288 or better if there is a chance that 59db0512e12d98e8e223483f785931a076984288  goes into the master  any time soon I could just close this PR.\nPlease advice.\n", "Would this\n\n  eigen_version = \"1c7159a65db4\"  eigen_sha256 =\n\"b089a6eae493c32703c6beb5fdae9d64a7667c3a5440bae00ac8e517cc822e62\"work?\nThis is pending merge, probably today.\n\nOn Thu, Oct 20, 2016 at 7:55 AM, schmuell notifications@github.com wrote:\n\n> Triangular Solver is a side effect of how I changed Macros.h. If I take ,\n> https://bitbucket.org/eigen/eigen/commits/59db0512e12d98e8e223483f785931\n> a076984288 instead, it seems fine. Clean master with only\n> 59db0512e12d98e8e223483f785931a076984288 on top builds and runs fine.\n> So I could either update this pull request to only include\n> 59db0512e12d98e8e223483f785931a076984288 or better if there is a chance\n> that 59db0512e12d98e8e223483f785931a076984288 goes into the master any\n> time soon I could just close this PR.\n> Please advice.\n> \n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/pull/5076#issuecomment-255129370,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AT_SbdRBZqqPlDiK1u3Hdsw0XmzktWYyks5q14DJgaJpZM4KbY4s\n> .\n", "I think this will do. Going to watch for the merge and test it. If all is good I'll close this PR.\n", "1c7159a65db4 contains  https://bitbucket.org/eigen/eigen/commits/59db0512e12d98e8e223483f785931a076984288, so once the Eigen upgrade is merged the issue should be solved.\n", "Merged #5105, let us know how this works out.\n", "Verified: master builds and works on windows without this PR. Thank You!\n", "Nice!\n"]}, {"number": 5075, "title": "Update protobuf to get fix from mrry/msvc_fix", "body": "Fetch the fix at https://github.com/google/protobuf/pull/2203\nI thought it was fetched at PR #4967, but turns out it didn't...\n@mrry \n", "comments": ["Can one of the admins verify this patch?\n", "@meteorcloudy, thanks for your PR! By analyzing the history of the files in this pull request, we identified @kirilg, @tensorflower-gardener and @jart to be potential reviewers.\n", "After this change, I expect users be able to build PIP package on Windows with the next Bazel release, Visual Studio 2015 update 2(or later) and Python 3.5.\n\nBazel@head is currently not working for building TF, because my change caused some internal issue and got rollback at https://github.com/bazelbuild/bazel/commit/aecf826aa0cd12d25a8f6d69604d721f50d940f0\n\nI'll get back to fix Bazel, but if you want to try the PIP package build, a known good Bazel version is at https://github.com/bazelbuild/bazel/commit/5338f48b54c996265271ba83561fe0a0b9ac43ab\n\nAnyway, I have successfully installed the PIP package, and looks like it's working fine! \\o/\n![image](https://cloud.githubusercontent.com/assets/4171702/19535575/88f62e04-9648-11e6-85c4-67f4cd77d97f.png)\n", "Mr. Jenkins: test this please\n", "LGTM. Thank you for this contribution.\n"]}, {"number": 5074, "title": "cmake changes to enable gpu support on windows", "body": "cmake changes to enable gpu support on windows. This goes on top of https://github.com/tensorflow/tensorflow/pull/5071\n", "comments": ["Can one of the admins verify this patch?\n", "@guschmue, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener, @ageron and @ebrevdo to be potential reviewers.\n", "@tensorflow-jenkins test this please.\n"]}, {"number": 5073, "title": "export/00000000-tmp/export-?????-of-00001 is not in all_model_checkpoint_paths. Manually adding it.", "body": "Now that I am using the 11rc, I am seeing a lot of this printed out:\n\n```\nINFO in saver: /output/4885/export/00000000-tmp/export-?????-of-00001 is not in all_model_checkpoint_paths. Manually adding it.\n```\n\nI believe when I call:\n\n```\n# Done once:\nsaver = tf_saver.Saver(sharded=True)\nmodel_exporter = exporter.Exporter(saver)\nmodel_exporter.init(...)\n...\n# Done each epoch / step:\nmodel_exporter.export(export_path, tf.constant(i), sess)\n```\n### Environment info\n\nOperating System:\nUsing nvidia Docker,\n\n```\nuname -a\nLinux b2dcea60c730 3.13.0-57-generic #95-Ubuntu SMP Fri Jun 19 09:28:15 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\n```\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\n```\n# ls -l /usr/local/cuda/lib64/libcud*\n-rw-r--r-- 1 root root 322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root     16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx 1 root root     19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18\n-rwxr-xr-x 1 root root 383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18\n-rw-r--r-- 1 root root 720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a\n```\n1. The commit hash (`git rev-parse HEAD`)\n   `8915f0f8072c406ae3fe0dff888f51b4cad02d7d`\n2. The output of `bazel version`\n\n```\n# bazel version\nINFO: Reading 'startup' options from /root/.bazelrc: --batch\nExtracting Bazel installation...\nBuild label: 0.3.1\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Fri Jul 29 09:09:52 2016 (1469783392)\nBuild timestamp: 1469783392\nBuild timestamp as int: 1469783392\n```\n", "comments": ["@cancan101 : That is an informational log line, not an error. That logging line has been there for a while, so I'm surprised that you're seeing it only now. Perhaps your logs were being redirected somewhere else before and you didn't notice them?\n\nRegardless, this shouldn't be causing any problems. Is it?\n", "On older versions of TF, instead of the log I got exceptions like:\n\n```\n    model_exporter.export(export_path, tf.constant(i), sess)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/session_bundle/exporter.py\", line 268, in export\n    meta_graph_suffix=constants.EXPORT_SUFFIX_NAME)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1078, in save\n    meta_graph_suffix=meta_graph_suffix)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 941, in _MaybeDeleteOldCheckpoints\n    self._CheckpointFilename(p)):\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/lib/io/file_io.py\", line 53, in get_matching_files\n    return pywrap_tensorflow.GetMatchingFiles(compat.as_bytes(filename), status)\n  File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__\n    self.gen.next()\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors.py\", line 450, in raise_exception_on_not_ok_status\n    pywrap_tensorflow.TF_GetCode(status))\ntensorflow.python.framework.errors.NotFoundError: /output/gap/4887/export/00000000-tmp\n```\n\nwhich actually killed training.\n\nIs there any way to suppress that log message? It fills my logs and I don't even know what / if I am doing anything wrong.\n", "@concretevitamin : Could you take a look at this?\n", "@sukritiramesh: can you take a look?  Is it caused by the way `Exporter.export()` uses `Saver`?  \n", "@cancan101: to answer your original question -- I am a bit hesitant on removing the info log, since these logs are useful sometimes.  Do you see it if just using `Saver` and without `Exporter`?  If so, we can maybe make `Exporter` not hit that condition.\n", "I don't see it when just using the Saver\n", "@concretevitamin This might be related to exporter using a -tmp location and then performing an atomic copy to the final export location. In this case, the checkpoint file contents include the -tmp location but the actual export location is the final one. Do you think that might be the case here, re: interaction with how Saver reads the checkpoint file?\n", "@sukritiramesh: yes, I agree w/ your hypothesis.  I think you're already working on making the paths in \"checkpoint\" relative?  That could mitigate the issue.\n", "@concretevitamin Not sure we'll be able to switch Exporter to use relative paths since that might impact existing exports. We could try to see if relative paths could be made the default in future versions though. Thoughts?\n", "So I think this issue is related to the checkpoint file containing the `tmp` path before the rename occurs.\r\n\r\nInside the `checkpoint` folder:\r\n```\r\n# cat output/diam/20170130-005509/export/00000060/checkpoint\r\nmodel_checkpoint_path: \"/usr/src/app/output/diam/20170130-005509/export/00000060-tmp/export\"\r\nall_model_checkpoint_paths: \"/usr/src/app/output/diam/20170130-005509/export/00000060-tmp/export\"\r\n```\r\n\r\nbut that folder has been renamed:\r\n```\r\n# ls /usr/src/app/output/diam/20170130-005509/export/00000060/\r\ncheckpoint  export.data-00000-of-00001  export.index  export.meta\r\n```", "Any way to suppress this INFO message? It is entirely spurious.", "This INFO message is not blocked even when I set:\r\n\r\n    import os\r\n    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\r\n    import tensorflow as tf\r\n\r\nIt seems like this is very old code?\r\n\r\nI need to turn this off because I want to run these jobs in the background in iPython and I don't want to have any messages written to stdout.", "<pre>tf.logging.set_verbosity(tf.logging.WARN)</pre>\r\nThis should have the desired effect", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activityand the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 5072, "title": "Use fast IDCT for JPEG decoding by default", "body": "Please refer to issue #4833 for details.\n", "comments": ["@mkolod, thanks for your PR! By analyzing the history of the files in this pull request, we identified @keveman, @dave-andersen and @girving to be potential reviewers.\n", "Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "Weird potential reviewers given by the bot. A human (#4833) suggested @prb12 and @poxvoculi..\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "@keveman Not sure what the implications are. It looks like we disabled this intentionally.\n", "@drpngx @keveman For the record, Caffe and other frameworks use the default (i.e. fast) IDCT. With compressed JPEGs, the slow IDCT is very unlikely to give any accuracy gains, and slows down processing dramatically, especially when the CPU is the bottleneck for another component in the system that has much higher throughput, e.g. a GPU.\n", "@drpngx @keveman I tried convergence on ResNet-50 and I can't determine whether the slow IDCT is markedly better than the fast one from a convergence perspective. This was with the data loading queue and preprocessing queue all set to 1 thread, and using fixed initialization seeds, so this is as much determinism as I could imagine having control over. I'd imagine the Inception results would be very similar, and if anything, smaller nets like AlexNet would be even less sensitive to decoding issues.\n\n![slow_vs_fast](https://cloud.githubusercontent.com/assets/476135/19537852/6abd3cb2-9606-11e6-8bb0-81302fdf1c2b.png)\n", "@drpngx @keveman Note that for e.g. AlexNet, the speed-up due to this small change is about 30% on a GTX 1080 and a Core i7-5930K, running off of a 500 MB/s SSD. That's a pretty significant speed-up. For multi-GPU cases, this will be even more important since then the bottleneck will be the CPU component even more so than in the single-GPU case. Also, it may matter even more on say ARM than on x86, including for the JPEG-based inference speeds.\n", "I don't know about the implications of making that modification in all of users. My intuition would usually be to provide a flag, and consider flipping the default to new behavior.\n\n@keveman any comment on the analysis provided?\n", "Also, see [here](https://github.com/tensorflow/tensorflow/issues/4807#issuecomment-256718844) for perf impact. The importance of fast IDCT varies by image size, and of course its impact on training depends on how compute-heavy the model is (less impact for Inception, more for AlexNet). \n", "@tensorflow-jenkins test this please.\n", "Not a very critical failure. Fails due to: \nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/image_ops_test.py#L1806\nWith error `AssertionError: 0.64828776041666669 not less than 0.6` on the color-ramp test, comparing an image after encode/decode trip.\nBarely overshoots the threshold - bearing in mind the range is [0:255]. I bet the magical threshold value of 0.6 is set because the non-IDCT gets something just below 0.6. Given the lossy nature of a jpeg, and the performance gain by IDCT, increasing the threshold wouldn't feel out of place.\n", "@TimZaman Updated to 0.7. I agree that the assertion's tolerance was based on what the slow IDCT would typically get. The fast IDCT's result is barely different, and that is to be expected due to algo difference, but isn't different for practical purposes.\n\n@keveman Could you review again please?\n", "@tensorflow-jenkins test this please\n", "@mkolod Can you please take a look at the failures?\n", "It looks like they all fail on jpeg unit test, and mac additionally fails on env test\n\n@gunan @caisq not sure if we bazel rc with test output on failure on macs\n", "@keveman @drpngx I looked at the test and my findings are as follows. There isn't any bug in libjpeg, but, I would argue, the tolerance on the JPEG fixed point test (encode/decode/encode several times and see if there is stability in that the diffs go to zero) is pretty tight. For the first encode-decode, the diff is about 0.55 out of 255, but with the slow IDCT, the diff goes to 0.02 or so on the second encode/decode pass. The fast IDCT does generate more error, this is a known thing. The error is actually basically the same on the first pass in fast and slow IDCT, but the difference is that slow IDCT is more stable on the second decode and re-encode. I'd argue that since TensorFlow is not an image editing platform but a machine learning platform, it would be a real corner case if someone ended up decoding and re-encoding the same image dozens of times over (also in that case, why not use a lossless format?). If there is say one decoding and re-encoding (e.g. due to the need to preprocess an existing dataset offline for more optimized use later, e.g. pre-resizing ImageNet), that would be a single such preprocessing pass, not counting the final decoding at learning time. In case further updates to the offline preprocessing pipeline are needed, they could be recomputed from the original images so there's only one lossy pass, and that one lossy pass is identical between fast and slow IDCT. The only difference is in case of multiple read/write/read passes. So, while the fixed point test would matter a lot for image editing, I don't think it's that important for machine learning applications, because (a) there's usually 1 or 2 decode passes followed by encode at most, and (b) because in a programmatic environment, all changes can be applied to in-memory data before applying a single encoding pass. If you agree that this is a reasonable explanation as to why the tolerance of the fixed point test can be widened. Please let me what you think.\n", "Sorry, I had lost context. Yes, we should bump up the epsilons in the tests to make them all pass.\n\nIf you could create a separate commit so that we can see them that would be great.\n", "@drpngx Will do, thanks!\n", "@drpngx @keveman Should be fine for re-running tests now, I ran \nbazel test //tensorflow/python/...\nlocally on Linux and everything seemed fine. Could you re-run the CI pipeline?\n", "@tensorflow-jenkins test this please.\n", "@keveman Apologies, looks like the Python tests pass but the C++ tests still fail. I thought all the testing of the transforms was in Python, hence I ran only the Python test suite. Will re-run all the tests including C++ ones.\n", "@keveman I re-ran all the tests now (Python and C++) using \n`bazel test //tensorflow/...`\nand I don't see anything failing in the mainline code on my Linux box.\n", "Okay let's kick off another test to find out!\n\n@tensorflow-jenkins test this please\n", "Okay, sadly I have to roll this change back -- it looks like some of our groups internally might rely on having higher quality decoding.  Let's re-make this change possibly via an option to DecodeJpegOp, rather than flipping the default everywhere.\n", "@mkolod: are you still working on getting this change back in again via the configurable option?  If not, would you like us to do it instead?", "> Let's re-make this change possibly via an option to DecodeJpegOp, rather than flipping the default everywhere.\r\n\r\n+1   This should obviously be the default, but retaining the option for slow high quality is a good thing.\r\nBTW, this op contributes significantly to multi-GPU inception training being bottlenecked on host CPU.", "Yes, we'll first add the option, then we can try to quickly find those that depend on the slow path for accuracy (not many, but there are some), and then we can switch the default after converting them to explicitly depend on the slow option."]}, {"number": 5071, "title": "support for gpu on windows", "body": "code changes to enable gpu support for windows\n", "comments": ["Can one of the admins verify this patch?\n", "@guschmue, thanks for your PR! By analyzing the history of the files in this pull request, we identified @keveman, @davidzchen and @mrry to be potential reviewers.\n", "pushed the requested changes\n", "@tensorflow-jenkins test this please.\n", "**For people looking for ways to compile:**\n\nIt is in\nhttps://github.com/schmuell/tensorflow/blob/b11ef5128f7341cfc7018ac0771d8939b8535cfc/tensorflow/contrib/cmake/README.md\n\nyou need to instal the cuda 8.0 SDK + cudnn 5.1 and add 2 options to cmake\n-Dtensorflow_ENABLE_GPU=ON  -DCUDNN_HOME=c:\\local\\cudnn\n\nI normally do:\ncd tensorflow\\contrib\\cmake\\\nmkdir build\ncd build\ncmake .. -A x64 -DCMAKE_BUILD_TYPE=RelWithDebInfo\n-DPYTHON_EXECUTABLE=C:\\local\\Anaconda2\\envs\\py3\\python.exe\n-DPYTHON_LIBRARIES=C:\\local\\Anaconda2\\envs\\py3\\libs\\python35.lib\n-DSWIG_EXECUTABLE=c:\\local\\swigwin-3.0.10\\swig.exe\n-Dtensorflow_ENABLE_GPU=ON  -DCUDNN_HOME=\"C:\\local\\cudnn\"\nmsbuild /p:Configuration=RelWithDebInfo tf_python_build_pip_package.vcxproj\n", "@mrry @guschmue awesome contribution! Should the readme be updated as it is confusing some folks due to:\n\n```\nCurrently, only CPU builds are supported, but we are working on\n providing a GPU build as well.\n```\n\n?\n", "Fair, we can fix that and add some more details to the readme file. \nShould be getting to it today.\n", "Following the above build instructions, I am getting the following errors when trying to compile:\n\n\"C:\\ST\\Tensorflow\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_build_pip_package.vcxproj\" (default target) (1) ->\n\"C:\\ST\\Tensorflow\\tensorflow\\tensorflow\\contrib\\cmake\\build\\pywrap_tensorflow.vcxproj\" (default target) (3) ->\n\"C:\\ST\\Tensorflow\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_core_gpu_kernels.vcxproj\" (default target) (33) ->\n(CustomBuild target) ->\n  c:\\st\\tensorflow\\tensorflow\\tensorflow\\contrib\\cmake\\build\\external\\eigen_archive\\eigen\\src/Core/Ref.h(89): error : \"operator=\" has already been declared in the current scope [C:\\ST\\Tensorflow\\tensorflow\\tensorflow\\contrib\\cmake\\build\n\\tf_core_gpu_kernels.vcxproj]\n  c:\\st\\tensorflow\\tensorflow\\tensorflow\\contrib\\cmake\\build\\external\\eigen_archive\\eigen\\src/Core/Block.h(111): error : \"operator=\" has already been declared in the current scope [C:\\ST\\Tensorflow\\tensorflow\\tensorflow\\contrib\\cmake\\bu\nild\\tf_core_gpu_kernels.vcxproj]\n\n369 Warning(s)\n2 Error(s)\n\nThis is with the following cmake command:\n\ncmake .. -A x64 -DCMAKE_BUILD_TYPE=Release \n-DSWIG_EXECUTABLE=C:/ST/Tensorflow/swigwin-3.0.10/swig.exe \n-Dtensorflow_ENABLE_GPU=ON \n-DCUDNN_HOME=C:/ST/Tensorflow/cuda8_0_cudnn5_1 \n-DPYTHON_EXECUTABLE=C:/Anaconda3/envs/tensorflow/python.exe \n-DPYTHON_LIBRARIES=C:/Anaconda3/envs/tensorflow/libs/python35.lib\n\nAnd the following MSBuild command:\n\nMSBuild /p:Configuration=Release tf_python_build_pip_package.vcxproj\n", "yes, see here:\nhttps://github.com/tensorflow/tensorflow/pull/5076\nRhis should resolve once the eigen version in the master get updated.\nIf you want it fixed right away you could apply 5076.\n", "@JimSEOW Hi\n\nI tried to build following the steps above. \nI was able to build with Dtensorflow_ENABLE_GPU=OFF\nBut, with Dtensorflow_ENABLE_GPU=ON, I am getting the following error\n\n\"D:\\temp\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_build_pip_package.vcxproj\" (default target) (1) ->\n\"D:\\temp\\tensorflow\\tensorflow\\contrib\\cmake\\build\\pywrap_tensorflow.vcxproj\" (default target) (3) ->\n\"D:\\temp\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_core_gpu_kernels.vcxproj\" (default target) (33) ->\n(CustomBuild target) ->\n  C:\\Program Files (x86)\\MSBuild\\Microsoft.Cpp\\v4.0\\V140\\Microsoft.CppCommon.targets(171,5): error MSB6006: \"cmd.exe\" e\nxited with code 1. [D:\\temp\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_core_gpu_kernels.vcxproj]\n\n```\n362 Warning(s)\n1 Error(s)\n```\n\nAny idea how to fix this\n\nThanks\n", "Looks it fails compiling the cuda kernels. The real error messages is earlier in the output. If you can get that for me ...\n", "edit:\n@guschmue \nI've found this:\n\n```\nCustomBuild:\n  Building NVCC (Device) object CMakeFiles/tf_core_gpu_kernels.dir/__/__/core/kernels/Release/tf_core_gpu_kernels_gener\n  ated_adjust_contrast_op_gpu.cu.cc.obj\n  CMake Warning (dev) at tf_core_gpu_kernels_generated_adjust_contrast_op_gpu.cu.cc.obj.Release.cmake:81:\n    Syntax Warning in cmake code at column 125\n\n    Argument not separated from preceding token by whitespace.\n  This warning is for project developers.  Use -Wno-dev to suppress it.\n\n  nvcc fatal   : Stray '\"' character\n\n  CMake Error at tf_core_gpu_kernels_generated_adjust_contrast_op_gpu.cu.cc.obj.Release.cmake:222 (message):\n    Error generating\n    C:/.../tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/tf_core_gpu_kernels.dir/__/__/core/\n  kernels/Release/tf_core_gpu_kernels_generated_adjust_contrast_op_gpu.cu.cc.obj\n\n\nC:\\Program Files (x86)\\MSBuild\\Microsoft.Cpp\\v4.0\\V140\\Microsoft.CppCommon.targets(171,5): error MSB6006: \"cmd.exe\" exi\nted with code 1. [C:\\...\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_core_gpu_kernels.vcxproj]\nDone Building Project \"C:\\...\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_core_gpu_kernels.vcxproj\n\" (default targets) -- FAILED.\n```\n", "the warnings will not prevent the build from completing. Somewhere between the warnings should be a error message in the format 'somesource.cc(line#): error ....'. \nMaybe search from the top of the output for ': error'\n", "@guschmue Hi\nI am uploading the output file for reference\n\nIt looks like in tf_core_gpu_kernels_generated_adjust_contrast_op_gpu.cu.cc.obj.RelWithDebInfo.cmake file, at line 176 :  execute_process(COMMAND ${ARGN} RESULT_VARIABLE CUDA_result ) \nCUDA_result gets value 1 (cmd.exe exited with code 1) \nat line 222\nif(CUDA_result)\n  message(FATAL_ERROR \"Error generating ${generated_file}\")\nendif()\nit prints this message.\n[output.txt](https://github.com/tensorflow/tensorflow/files/545022/output.txt)\n", "line 888 in your output: nvcc fatal   : Stray '\"' character\nMight be that one of the -D options that cmake is called with has some wrong quote.\nBest way to debug would be vi tf_core_gpu_kernels_generated_adjust_contrast_op_gpu.cu.cc.obj.RelWithDebInfo.cmake\n", "Hi I believe I had the same error, cmake bat file looked like so:\ncd \"C:\\Users\\Cameron\\Desktop\\tensorflow\\tensorflow\\tensorflow\\contrib\\cmake\\build\"\ncmake .. -A x64 -DCMAKE_BUILD_TYPE=Release ^\n-DSWIG_EXECUTABLE=C:/swigwin-3.0.10/swig.exe ^\n-DPYTHON_EXECUTABLE=C:/Python35/python.exe ^\n-DPYTHON_LIBRARIES=C:/Python35/libs/python35.lib ^\n-Dtensorflow_ENABLE_GPU=ON ^\n-DCUDNN_HOME=C:/cuda\n", "@guschmue \nI guess there is a problem with the line 81 in  tf_core_gpu_kernels_generated_adjust_contrast_op_gpu.cu.cc.obj.RelWithDebInfo.cmake\nthe line is \nset(CUDA_NVCC_COMPILE_DEFINITIONS \"EIGEN_AVOID_STL_ARRAY;NOMINMAX;_WIN32_WINNT=0x0A00;LANG_CXX11;COMPILER_MSVC;__VERSION__=\"MSVC\";WIN32;OS_WIN;_MBCS;WIN64;WIN32_LEAN_AND_MEAN;NOGDI;PLATFORM_WINDOWS;TENSORFLOW_USE_EIGEN_THREADPOOL;EIGEN_HAS_C99_MATH;_ITERATOR_DEBUG_LEVEL=0;GOOGLE_CUDA=1;TF_EXTRA_CUDA_CAPABILITIES=3.5,5.2\") # list (needs to be in quotes to handle spaces properly).\n\nwhen I print the value of CUDA_NVCC_COMPILE_DEFINITIONS , I get the following:\nEIGEN_AVOID_STL_ARRAY;NOMINMAX;_WIN32_WINNT=0x0A00;LANG_CXX11;COMPILER_MSVC;__VERSION__=;MSVC\";WIN32;OS_WIN;_MBCS;WIN64;WIN32_LEAN_AND_MEAN;NOGDI;PLATFORM_WINDOWS;TENSORFLOW_USE_EIGEN_THREADPOOL;EIGEN_HAS_C99_MATH;_ITERATOR_DEBUG_LEVEL=0;GOOGLE_CUDA=1;TF_EXTRA_CUDA_CAPABILITIES=3.5,5.2\"\n\nthere is an \" after MVSC. I guess the stray character referred belongs to this line.\n", "going to look at it shortly. My cuda is installed under program files as well and its happy. Definitely the \"MSVC\" looks suspicious, just need to understand why some people have the problem and others don't.\nWhat version of cmake do you use ? \n", "I'm on 3.7.0-rc2, downloaded yesterday\n", "I'm on 3.7.0-rc2 too. \n", "ok, I'm on 3.5.2 and 3.6 - let me update and see my build breaks too. \n", "I tried with cmake 3.6 version and was able to build successfully.\n", "thank you, knowing that its something in cmake 3.7 helps a ton. Going see if we can do something on it.\n", "I had internally setup a jenkins build for windows gpu from tf master which is unhappy with https://github.com/tensorflow/tensorflow/pull/5127. Going to look at it today.\n", "I had now these kind of errors building with cmake 3.6.\n\n```\n\"c:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_tutorials_example_trainer.vcxproj\" (default ta\nrget) (1) ->\n\"C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_core_gpu_kernels.vcxproj\" (default target) (81\n) ->\n(CustomBuild target) ->\n  C:/tensorflow/tensorflow/core/kernels/cwise_op_gpu_select.cu.cc(42): error : namespace \"Eigen\n\" has no member \"IndexList\" [C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_core_gpu_kernels.v\ncxproj]\n  C:/tensorflow/tensorflow/core/kernels/cwise_op_gpu_select.cu.cc(42): error : namespace \"Eigen\n\" has no member \"type2index\" [C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_core_gpu_kernels.\nvcxproj]\n```\n\n```\n\n 1844 Warning(s)\n    21 Error(s)\n```\n", "Same exact problem with 3.6. Looks like a problem with Eigen, not sure if it matters that I'm using vs 2015 community, not enterprise? Don't have the exact error but can post at home\n", "this is something that came in with #5127. You can do a \ngit reset --hard 41ba1e0e6fbf443f1a972ff0130ba6741b9b7a50\nto go before that change.\n", "@guschmue will do. Thank you.\n", "Still getting build errors even after resetting the branch, this time after 4 hours 30 minutes. Error is \n\n> \"C:\\Users\\Cameron\\Desktop\\tensorflow\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_build_pip_package.vcxproj\" (default\n> target) (1) ->\n> (PostBuildEvent target) ->\n>   EXEC : error : invalid command 'bdist_wheel' [C:\\Users\\Cameron\\Desktop\\tensorflow\\tensorflow\\tensorflow\\contrib\\cmake\\build\n> \\tf_python_build_pip_package.vcxproj]\n>   C:\\Program Files (x86)\\MSBuild\\Microsoft.Cpp\\v4.0\\V140\\Microsoft.CppCommon.targets(133,5): error MSB3073: The command \"setl\n> ocal\\r [C:\\Users\\Cameron\\Desktop\\tensorflow\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_build_pip_package.vcxproj]\n> C:\\Program Files (x86)\\MSBuild\\Microsoft.Cpp\\v4.0\\V140\\Microsoft.CppCommon.targets(133,5): error MSB3073: \"C:\\Program Files\\C\n> Make\\bin\\cmake.exe\" -E copy C:/Users/Cameron/Desktop/tensorflow/tensorflow/tensorflow/contrib/cmake/setup.py C:/Users/Cameron\n> /Desktop/tensorflow/tensorflow/tensorflow/contrib/cmake/build/tf_python/\\r [C:\\Users\\Cameron\\Desktop\\tensorflow\\tensorflow\\te\n> nsorflow\\contrib\\cmake\\build\\tf_python_build_pip_package.vcxproj]\n> C:\\Program Files (x86)\\MSBuild\\Microsoft.Cpp\\v4.0\\V140\\Microsoft.CppCommon.targets(133,5): error MSB3073: if %errorlevel% neq\n\n...\n\n> ```\n> 2948 Warning(s)\n> 2 Error(s)\n> ```\n", "\"pip install wheel\" fixed this, finally have a successful build.\n", "Cool. I have https://github.com/tensorflow/tensorflow/pull/5157 out to fix the master for windows gpu as well.\n", "Another note, after installing with pip I also had to set the LD_LIBRARY_PATH environment variable to C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v8.0\\lib\\Win32. May want to add these steps to the readme. Thanks btw for this feature, been excited about it for a while \n", "Hm, that is odd: the nvidia dlls need to be in PATH but the nvidia installer adds them to PATH already (I forgot if this is maybe optional). The dll that is not in the PATH is the cudnn dll because that comes from a zip file. So you are right, we should add something to the README.md. On windows LD_LIBRARY_PATH is odd, maybe using PATH is more the windows way.\nI polish the readme some tomorrow.\nThank you for trying this out - greatly appreciated and invaluable to have more eyeballs!!!\nBtw, there are a few smaller issues we know about - we'll address them in a PR sometime this week. \n", "Sure, please fix the readme.\nGood to know that it works for you \u2013 thank you for verifying! There are a few minor issues we know about but we have another pr coming up that will address those.\n\nFrom: Adriano Carmezim [mailto:notifications@github.com]\nSent: Thursday, October 20, 2016 5:48 PM\nTo: tensorflow/tensorflow tensorflow@noreply.github.com\nCc: Guenther Schmuelling guschmue@microsoft.com; Mention mention@noreply.github.com\nSubject: Re: [tensorflow/tensorflow] support for gpu on windows (#5071)\n\n@guschmuehttps://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fguschmue&data=02%7C01%7Cguschmue%40microsoft.com%7C48e38779b02c466c1f0a08d3f94bef29%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C636126076941600834&sdata=pi6j18KwNKXJmziDmYUOvuVBym8DozZ%2BYyBKivHi1pE%3D&reserved=0 All working great so far, thank you for this contribution.\nIf you want I can make those edits on \"current limitations\" and \"current status\" regarding the availability for GPU support and submit a PR, just ping me if you will.\n\n\u2014\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHubhttps://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F5071%23issuecomment-255265994&data=02%7C01%7Cguschmue%40microsoft.com%7C48e38779b02c466c1f0a08d3f94bef29%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C636126076941600834&sdata=jecyqg1wOurTyR7O6s4odF8oQwQm5B7TTJxLAGa3ux8%3D&reserved=0, or mute the threadhttps://na01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAV4NiA_xiknMX7FJ2Q54DDKxRtoI73kaks5q2AvKgaJpZM4KbRfF&data=02%7C01%7Cguschmue%40microsoft.com%7C48e38779b02c466c1f0a08d3f94bef29%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C636126076941600834&sdata=otJznv2FyAE5saFEDRR6Ak8JSzIX92us%2FuhfOFDKAKg%3D&reserved=0.\n", "@guschmue \nI'm getting an NVCC error while trying to compile with GPU support. My setup is:\n- Windows 10\n- Microsoft Visual Studio Community 2015 with Visual C++ 2015\n- CUDNN 5.1\n- CUDA 8.0\n- Anaconda3 4.2.0\n- swigwin-3.0.10\n- EDIT: cmake 3.6.2\n\nRelevant environment variables:\n\n```\nCUDA_PATH=C:\\NVIDIAGPUComputingToolkit\\CUDA\\v8.0\nCUDA_PATH_V8_0=C:\\NVIDIAGPUComputingToolkit\\CUDA\\v8.0\nPath=C:\\NVIDIAGPUComputingToolkit\\CUDA\\v8.0\\bin;C:\\NVIDIAGPUComputingToolkit\\CUDA\\v8.0\\libnvvp;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0\\;C:\\Program Files (x86)\\Skype\\Phone\\;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\Program Files\\Git\\cmd;C:\\Users\\<user>\\.dnx\\bin;C:\\Program Files\\Microsoft DNX\\Dnvm\\;C:\\Program Files\\Microsoft SQL Server\\130\\Tools\\Binn\\;C:\\Program Files (x86)\\Windows Kits\\8.1\\Windows Performance Toolkit\\;C:\\Users\\<user>\\cudnn\\bin\\;C:\\Users\\<user>\\Anaconda3;C:\\Users\\<user>\\Anaconda3\\Scripts;C:\\Users\\<user>\\Anaconda3\\Library\\bin;C:\\Users\\<user>\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Python;C:\\Program Files\\CMake\\bin;C:\\Program Files (x86)\\Microsoft Visual Studio 14.0\\VC\\bin\\\n```\n\nI'm running the following CMake command standing in `tensorflow\\contrib\\cmake\\build\\` without problems:\n\n```\ncmake .. -A x64 -DCMAKE_BUILD_TYPE=Release -DSWIG_EXECUTABLE=C:\\Users\\<user>\\swigwin-3.0.10\\swig.exe -DPYTHON_EXECUTABLE=C:\\Users\\<user>\\Anaconda3\\python.exe -DPYTHON_LIBRARIES=C:\\Users\\<user>\\Anaconda3\\libs\\python35.lib -DCUDA_TOOLKIT_ROOT_DIR=C:\\NVIDIAGPUComputingToolkit\\CUDA\\v8.0  -Dtensorflow_ENABLE_GPU=ON -DCUDNN_HOME=C:\\Users\\<user>\\cudnn\\\n```\n\nI run the following MSBuild command:\n\n```\nC:\\Windows\\Microsoft.NET\\Framework64\\v4.0.30319\\MSBuild /p:Configuration=Release tf_tutorials_example_trainer.vcxproj\n```\n\nIt runs for a while and terminates with the following error:\n\n```\nProject \"C:\\Users\\<user>\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_tutorials_example_trainer.vcxproj\" (1) is building \"C:\\Users\\<user>\\tensorflow\n\\tensorflow\\contrib\\cmake\\build\\tf_core_gpu_kernels.vcxproj\" (81) on node 1 (default targets).\nInitializeBuildStatus:\n  Touching \"tf_core_gpu_kernels.dir\\Release\\tf_core_.99484E5D.tlog\\unsuccessfulbuild\".\nCustomBuild:\n  Building NVCC (Device) object CMakeFiles/tf_core_gpu_kernels.dir/__/__/core/kernels/Release/tf_core_gpu_kernels_generated_adjust_contrast_op_gpu.cu.cc.obj\n  nvcc fatal   : A single input file is required for a non-link phase when an outputfile is specified\n\n  CMake Error at tf_core_gpu_kernels_generated_adjust_contrast_op_gpu.cu.cc.obj.Release.cmake:207 (message):\n    Error generating\n    C:/Users/<user>/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/tf_core_gpu_kernels.dir/__/__/core/kernels/Release/tf_core_gpu_kernels_generated_adjust_contrast_op_gpu.cu.cc.obj\n\n\nC:\\Program Files (x86)\\MSBuild\\Microsoft.Cpp\\v4.0\\V140\\Microsoft.CppCommon.targets(171,5): error MSB6006: \"cmd.exe\" exited with code 1. [C:\\Users\\<user>\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_core_gpu_kernels.vcxproj]\nDone Building Project \"C:\\Users\\<user>\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_core_gpu_kernels.vcxproj\" (default targets) -- FAILED.\n.\n.\n.\n\"C:\\Users\\<user>\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_tutorials_example_trainer.vcxproj\" (default target) (1) ->\n\"C:\\Users\\<user>\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_core_gpu_kernels.vcxproj\" (default target) (81) ->\n(CustomBuild target) ->\n  C:\\Program Files (x86)\\MSBuild\\Microsoft.Cpp\\v4.0\\V140\\Microsoft.CppCommon.targets(171,5): error MSB6006: \"cmd.exe\" exited with code 1. [C:\\Users\\<user>\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_core_gpu_kernels.vcxproj]\n\n    5 Warning(s)\n    1 Error(s)\n```\n\nFrom what I can tell I've followed all instructions from `tensorflow\\tensorflow\\contrib\\cmake\\README.md`. What am I missing? \n\nEDIT: Also added 6.1 capabilities to the `CMakeLists.txt`:\n\n``````\narch=compute_61,code=sm_61, \n-DTF_EXTRA_CUDA_CAPABILITIES=3.5,5.2,6.1, \n#define TF_CUDA_CAPABILITIES CudaVersion(\\\"3.5\\\"),CudaVersion(\\\"5.2\\\"), CudaVersion(\\\"6.1\\\")\\n\"```\n``````\n"]}, {"number": 5070, "title": "Upgrade Udacity class Docker image.", "body": "Current Docker image uses TF 7.1.0, which is no longer showing on the online documentation page.\nNeed to:\n\n1- Update to latest stable release.\n2- Make sure the assignments still work.\n3- Move from b.gcr.io to gcr.io\n", "comments": ["Thanks for creating this issue @vincentvanhoucke! Just a note that I had to modify the `Dockerfile` to get this working myself. The modified file looked like the following:\n\n``` bash\nFROM gcr.io/tensorflow/tensorflow:latest\nMAINTAINER Vincent Vanhoucke <vanhoucke@google.com>\nRUN pip install scikit-learn pyreadline Pillow==2.3.0\nRUN rm -rf /notebooks/*\nADD *.ipynb /notebooks/\nWORKDIR /notebooks\nCMD [\"/run_jupyter.sh\"]\n```\n\nI pinned Pillow to the version from the current 0.5.0 container. Pillow 3.x requires some updated libraries and I wasn't able to figure out how to install them in the container.\n\nThanks again!\n", "The tensorflow base image is ubuntu 14.04.  I used the following Dockerfile to successfully pip install Pillow 3.x (based on instructions here https://pillow.readthedocs.io/en/3.0.0/installation.html#linux-installation)\n\n``` sh\nFROM gcr.io/tensorflow/tensorflow:latest\nMAINTAINER Vincent Vanhoucke <vanhoucke@google.com>\nRUN apt-get update && apt-get install -y libtiff5-dev libjpeg8-dev zlib1g-dev libfreetype6-dev \\\n liblcms2-dev libwebp-dev tcl8.6-dev tk8.6-dev python-tk\nRUN pip install scikit-learn pyreadline Pillow\nRUN rm -rf /notebooks/*\nADD *.ipynb /notebooks/\nWORKDIR /notebooks\nCMD [\"/run_jupyter.sh\"]\n```\n", "A new image will be published with the next merge from our internal repo.\n"]}, {"number": 5069, "title": "symbol(s) not found for architecture amrv7 and armv64", "body": "Using XCode 8 and OSX Sierra, the TensorFlow iOS build fails with:\n\n```\nUndefined symbols for architecture armv7:\n  \"google::protobuf::Any::MergeFrom(google::protobuf::Any const&)\", referenced from:\n      tensorflow::MetaGraphDef_MetaInfoDef::UnsafeMergeFrom(tensorflow::MetaGraphDef_MetaInfoDef const&) in libtensorflow-core-armv7.a(meta_graph.pb.o)\n      google::protobuf::internal::GenericTypeHandler<google::protobuf::Any>::Merge(google::protobuf::Any const&, google::protobuf::Any*) in libtensorflow-core-armv7.a(meta_graph.pb.o)\n  \"google::protobuf::internal::WireFormatLite::WriteBytesMaybeAliased(int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, google::protobuf::io::CodedOutputStream*)\", referenced from:\n      tensorflow::Event::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(event.pb.o)\n      tensorflow::TaggedRunMetadata::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(event.pb.o)\n      tensorflow::TensorProto::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(tensor.pb.o)\n      tensorflow::Summary_Image::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(summary.pb.o)\n      tensorflow::Summary_Audio::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(summary.pb.o)\n      tensorflow::Summary_Value::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(summary.pb.o)\n      tensorflow::AttrValue::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(attr_value.pb.o)\n      ...\n  \"vtable for google::protobuf::internal::MapFieldBase\", referenced from:\n      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2futil_2ftest_5flog_2eproto_impl() in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::BenchmarkEntry::BenchmarkEntry() in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::BenchmarkEntry::New(google::protobuf::Arena*) const in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::CPUInfo::CPUInfo() in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::CPUInfo::New(google::protobuf::Arena*) const in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::MachineConfiguration::_slow_mutable_cpu_info() in libtensorflow-core-armv7.a(test_log.pb.o)\n      google::protobuf::internal::GenericTypeHandler<tensorflow::BenchmarkEntry>::New(google::protobuf::Arena*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      ...\n  NOTE: a missing vtable usually means the first non-inline virtual member function has no definition.\n  \"typeinfo for google::protobuf::Any\", referenced from:\n      google::protobuf::Any* google::protobuf::Arena::CreateMaybeMessage<google::protobuf::Any>(google::protobuf::Arena*, ...) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::MetaGraphDef_MetaInfoDef::UnsafeMergeFrom(tensorflow::MetaGraphDef_MetaInfoDef const&) in libtensorflow-core-armv7.a(meta_graph.pb.o)\n      tensorflow::MetaGraphDef_MetaInfoDef::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(meta_graph.pb.o)\n  \"google::protobuf::internal::InitEmptyString()\", referenced from:\n      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2futil_2ftest_5flog_2eproto_impl() in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2futil_2fsaved_5ftensor_5fslice_2eproto_impl() in libtensorflow-core-armv7.a(saved_tensor_slice.pb.o)\n      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2futil_2fmemmapped_5ffile_5fsystem_2eproto_impl() in libtensorflow-core-armv7.a(memmapped_file_system.pb.o)\n      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2futil_2fevent_2eproto_impl() in libtensorflow-core-armv7.a(event.pb.o)\n      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2fprotobuf_2ftensorflow_5fserver_2eproto_impl() in libtensorflow-core-armv7.a(tensorflow_server.pb.o)\n      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2fprotobuf_2fsaver_2eproto_impl() in libtensorflow-core-armv7.a(saver.pb.o)\n      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2fprotobuf_2fqueue_5frunner_2eproto_impl() in libtensorflow-core-armv7.a(queue_runner.pb.o)\n      ...\n  \"google::protobuf::io::CodedOutputStream::default_serialization_deterministic_\", referenced from:\n      tensorflow::BenchmarkEntry::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::CPUInfo::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::JobDef::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(tensorflow_server.pb.o)\n      tensorflow::MetaGraphDef::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(meta_graph.pb.o)\n      tensorflow::SignatureDef::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(meta_graph.pb.o)\n      tensorflow::ConfigProto::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(config.pb.o)\n      tensorflow::NodeDef::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(node_def.pb.o)\n      ...\n  \"google::protobuf::internal::MapFieldBase::SpaceUsedExcludingSelfNoLock() const\", referenced from:\n      vtable for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue> in libtensorflow-core-armv7.a(test_log.pb.o)\n      vtable for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, long long> in libtensorflow-core-armv7.a(test_log.pb.o)\n      vtable for google::protobuf::internal::TypeDefinedMapFieldBase<int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > in libtensorflow-core-armv7.a(tensorflow_server.pb.o)\n      vtable for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::CollectionDef> in libtensorflow-core-armv7.a(meta_graph.pb.o)\n      vtable for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::SignatureDef> in libtensorflow-core-armv7.a(meta_graph.pb.o)\n      vtable for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::TensorInfo> in libtensorflow-core-armv7.a(meta_graph.pb.o)\n      vtable for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, int> in libtensorflow-core-armv7.a(config.pb.o)\n      ...\n  \"google::protobuf::internal::MapFieldBase::SyncRepeatedFieldWithMapNoLock() const\", referenced from:\n      vtable for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue> in libtensorflow-core-armv7.a(test_log.pb.o)\n      vtable for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, long long> in libtensorflow-core-armv7.a(test_log.pb.o)\n      vtable for google::protobuf::internal::TypeDefinedMapFieldBase<int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > in libtensorflow-core-armv7.a(tensorflow_server.pb.o)\n      vtable for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::CollectionDef> in libtensorflow-core-armv7.a(meta_graph.pb.o)\n      vtable for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::SignatureDef> in libtensorflow-core-armv7.a(meta_graph.pb.o)\n      vtable for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::TensorInfo> in libtensorflow-core-armv7.a(meta_graph.pb.o)\n      vtable for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, int> in libtensorflow-core-armv7.a(config.pb.o)\n      ...\n  \"google::protobuf::Any::Any()\", referenced from:\n      google::protobuf::Any* google::protobuf::Arena::CreateMaybeMessage<google::protobuf::Any>(google::protobuf::Arena*, ...) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::MetaGraphDef_MetaInfoDef::UnsafeMergeFrom(tensorflow::MetaGraphDef_MetaInfoDef const&) in libtensorflow-core-armv7.a(meta_graph.pb.o)\n      tensorflow::MetaGraphDef_MetaInfoDef::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(meta_graph.pb.o)\n  \"google::protobuf::Any_default_instance_\", referenced from:\n      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2fprotobuf_2fmeta_5fgraph_2eproto_impl() in libtensorflow-core-armv7.a(meta_graph.pb.o)\n      tensorflow::MetaGraphDef_MetaInfoDef::UnsafeMergeFrom(tensorflow::MetaGraphDef_MetaInfoDef const&) in libtensorflow-core-armv7.a(meta_graph.pb.o)\n  \"google::protobuf::Any::ByteSizeLong() const\", referenced from:\n      tensorflow::MachineConfiguration::ByteSizeLong() const in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::MetaGraphDef_MetaInfoDef::ByteSizeLong() const in libtensorflow-core-armv7.a(meta_graph.pb.o)\n      tensorflow::CollectionDef_AnyList::ByteSizeLong() const in libtensorflow-core-armv7.a(meta_graph.pb.o)\n      tensorflow::CollectionDef::ByteSizeLong() const in libtensorflow-core-armv7.a(meta_graph.pb.o)\n  \"google::protobuf::protobuf_AddDesc_google_2fprotobuf_2fany_2eproto()\", referenced from:\n      tensorflow::protobuf_AddDesc_tensorflow_2fcore_2futil_2ftest_5flog_2eproto_impl() in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::protobuf_AddDesc_tensorflow_2fcore_2fprotobuf_2fmeta_5fgraph_2eproto_impl() in libtensorflow-core-armv7.a(meta_graph.pb.o)\n  \"google::protobuf::io::CodedInputStream::ReadLengthAndPushLimit()\", referenced from:\n      tensorflow::BenchmarkEntries::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::MachineConfiguration::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::SavedSliceMeta::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(saved_tensor_slice.pb.o)\n      tensorflow::SavedTensorSliceMeta::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(saved_tensor_slice.pb.o)\n      tensorflow::MemmappedFileSystemDirectory::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(memmapped_file_system.pb.o)\n      tensorflow::ClusterDef::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(tensorflow_server.pb.o)\n      tensorflow::MetaGraphDef::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(meta_graph.pb.o)\n      ...\n  \"google::protobuf::internal::RepeatedPtrFieldBase::InternalExtend(int)\", referenced from:\n      tensorflow::BenchmarkEntries::UnsafeMergeFrom(tensorflow::BenchmarkEntries const&) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::MachineConfiguration::UnsafeMergeFrom(tensorflow::MachineConfiguration const&) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::SavedSliceMeta::UnsafeMergeFrom(tensorflow::SavedSliceMeta const&) in libtensorflow-core-armv7.a(saved_tensor_slice.pb.o)\n      tensorflow::SavedTensorSliceMeta::UnsafeMergeFrom(tensorflow::SavedTensorSliceMeta const&) in libtensorflow-core-armv7.a(saved_tensor_slice.pb.o)\n      tensorflow::MemmappedFileSystemDirectory::UnsafeMergeFrom(tensorflow::MemmappedFileSystemDirectory const&) in libtensorflow-core-armv7.a(memmapped_file_system.pb.o)\n      tensorflow::ClusterDef::UnsafeMergeFrom(tensorflow::ClusterDef const&) in libtensorflow-core-armv7.a(tensorflow_server.pb.o)\n      tensorflow::QueueRunnerDef::UnsafeMergeFrom(tensorflow::QueueRunnerDef const&) in libtensorflow-core-armv7.a(queue_runner.pb.o)\n      ...\n  \"google::protobuf::io::CodedInputStream::CheckEntireMessageConsumedAndPopLimit(int)\", referenced from:\n      tensorflow::BenchmarkEntries::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::MachineConfiguration::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::SavedSliceMeta::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(saved_tensor_slice.pb.o)\n      tensorflow::SavedTensorSliceMeta::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(saved_tensor_slice.pb.o)\n      tensorflow::MemmappedFileSystemDirectory::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(memmapped_file_system.pb.o)\n      tensorflow::ClusterDef::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(tensorflow_server.pb.o)\n      tensorflow::MetaGraphDef::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(meta_graph.pb.o)\n      ...\n  \"google::protobuf::io::CodedInputStream::ReadVarint64Fallback()\", referenced from:\n      tensorflow::BenchmarkEntry::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::CommitId::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::CPUInfo::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::MemoryInfo::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::AvailableDeviceInfo::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::TestResults::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      google::protobuf::internal::MapEntryLite<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, long long, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)3, 0>::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      ...\n  \"google::protobuf::io::CodedInputStream::ReadVarintSizeAsIntFallback()\", referenced from:\n      tensorflow::BenchmarkEntry::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::CPUInfo::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::MachineConfiguration::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::TestResults::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      google::protobuf::internal::MapEntryLite<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      google::protobuf::internal::MapEntryLite<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::Parser<google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>, google::protobuf::Map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue> >::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::SavedSliceMeta::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(saved_tensor_slice.pb.o)\n      ...\n  \"google::protobuf::internal::empty_string_once_init_\", referenced from:\n      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2futil_2ftest_5flog_2eproto_impl() in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2futil_2fsaved_5ftensor_5fslice_2eproto_impl() in libtensorflow-core-armv7.a(saved_tensor_slice.pb.o)\n      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2futil_2fmemmapped_5ffile_5fsystem_2eproto_impl() in libtensorflow-core-armv7.a(memmapped_file_system.pb.o)\n      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2futil_2fevent_2eproto_impl() in libtensorflow-core-armv7.a(event.pb.o)\n      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2fprotobuf_2ftensorflow_5fserver_2eproto_impl() in libtensorflow-core-armv7.a(tensorflow_server.pb.o)\n      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2fprotobuf_2fsaver_2eproto_impl() in libtensorflow-core-armv7.a(saver.pb.o)\n      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2fprotobuf_2fqueue_5frunner_2eproto_impl() in libtensorflow-core-armv7.a(queue_runner.pb.o)\n      ...\n  \"google::protobuf::io::CodedInputStream::IncrementRecursionDepthAndPushLimit(int)\", referenced from:\n      tensorflow::BenchmarkEntry::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::CPUInfo::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::MachineConfiguration::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::TestResults::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      google::protobuf::internal::MapEntryLite<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      google::protobuf::internal::MapEntryLite<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::Parser<google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>, google::protobuf::Map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue> >::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::SavedSliceMeta::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(saved_tensor_slice.pb.o)\n      ...\n  \"google::protobuf::internal::MapFieldBase::~MapFieldBase()\", referenced from:\n      tensorflow::BenchmarkEntry::~BenchmarkEntry() in libtensorflow-core-armv7.a(test_log.pb.o)\n      google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::~MapField() in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::CPUInfo::~CPUInfo() in libtensorflow-core-armv7.a(test_log.pb.o)\n      google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, long long, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)3, 0>::~MapField() in libtensorflow-core-armv7.a(test_log.pb.o)\n      google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::~MapField() in libtensorflow-core-armv7.a(test_log.pb.o)\n      non-virtual thunk to google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::~MapField() in libtensorflow-core-armv7.a(test_log.pb.o)\n      non-virtual thunk to google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::~MapField() in libtensorflow-core-armv7.a(test_log.pb.o)\n      ...\n  \"google::protobuf::io::CodedOutputStream::WriteVarint32SlowPath(unsigned int)\", referenced from:\n      tensorflow::QueueRunnerDef::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(queue_runner.pb.o)\n      tensorflow::CollectionDef_Int64List::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(meta_graph.pb.o)\n      tensorflow::CollectionDef_FloatList::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(meta_graph.pb.o)\n      tensorflow::VersionDef::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(versions.pb.o)\n      tensorflow::SaveSliceInfoDef::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(variable.pb.o)\n      tensorflow::TensorProto::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(tensor.pb.o)\n      tensorflow::HistogramProto::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(summary.pb.o)\n      ...\n  \"google::protobuf::io::CodedOutputStream::WriteStringWithSizeToArray(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, unsigned char*)\", referenced from:\n      tensorflow::EntryValue::InternalSerializeWithCachedSizesToArray(bool, unsigned char*) const in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::BenchmarkEntry::InternalSerializeWithCachedSizesToArray(bool, unsigned char*) const in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::BuildConfiguration::InternalSerializeWithCachedSizesToArray(bool, unsigned char*) const in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::CommitId::InternalSerializeWithCachedSizesToArray(bool, unsigned char*) const in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::CPUInfo::InternalSerializeWithCachedSizesToArray(bool, unsigned char*) const in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::GPUInfo::InternalSerializeWithCachedSizesToArray(bool, unsigned char*) const in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::PlatformInfo::InternalSerializeWithCachedSizesToArray(bool, unsigned char*) const in libtensorflow-core-armv7.a(test_log.pb.o)\n      ...\n  \"google::protobuf::internal::WireFormatLite::WriteStringMaybeAliased(int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, google::protobuf::io::CodedOutputStream*)\", referenced from:\n      tensorflow::EntryValue::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::BenchmarkEntry::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::BuildConfiguration::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::CommitId::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::CPUInfo::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::GPUInfo::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::PlatformInfo::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(test_log.pb.o)\n      ...\n  \"google::protobuf::Arena::AddListNode(void*, void (*)(void*))\", referenced from:\n      void google::protobuf::Arena::Own<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      google::protobuf::RepeatedPtrField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > >::Add() in libtensorflow-core-armv7.a(test_log.pb.o)\n      google::protobuf::Any* google::protobuf::Arena::CreateMaybeMessage<google::protobuf::Any>(google::protobuf::Arena*, ...) in libtensorflow-core-armv7.a(test_log.pb.o)\n      google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::SyncRepeatedFieldWithMapNoLock() const in libtensorflow-core-armv7.a(test_log.pb.o)\n      google::protobuf::Map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue>::Init() in libtensorflow-core-armv7.a(test_log.pb.o)\n      void google::protobuf::Arena::Own<google::protobuf::internal::MapEntry<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0> >(google::protobuf::internal::MapEntry<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      void google::protobuf::Arena::OwnDestructor<google::protobuf::internal::Mutex>(google::protobuf::internal::Mutex*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      ...\n  \"google::protobuf::internal::WireFormatLite::VerifyUtf8String(char const*, int, google::protobuf::internal::WireFormatLite::Operation, char const*)\", referenced from:\n      tensorflow::EntryValue::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::EntryValue::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::EntryValue::InternalSerializeWithCachedSizesToArray(bool, unsigned char*) const in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::BenchmarkEntry::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::BenchmarkEntry::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::BenchmarkEntry::InternalSerializeWithCachedSizesToArray(bool, unsigned char*) const in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::BuildConfiguration::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      ...\n  \"google::protobuf::protobuf_InitDefaults_google_2fprotobuf_2fany_2eproto()\", referenced from:\n      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2futil_2ftest_5flog_2eproto_impl() in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2fprotobuf_2fmeta_5fgraph_2eproto_impl() in libtensorflow-core-armv7.a(meta_graph.pb.o)\n  \"google::protobuf::internal::MergeFromFail(char const*, int)\", referenced from:\n      tensorflow::(anonymous namespace)::MergeFromFail(int) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::(anonymous namespace)::MergeFromFail(int) in libtensorflow-core-armv7.a(saved_tensor_slice.pb.o)\n      tensorflow::(anonymous namespace)::MergeFromFail(int) in libtensorflow-core-armv7.a(memmapped_file_system.pb.o)\n      tensorflow::(anonymous namespace)::MergeFromFail(int) in libtensorflow-core-armv7.a(event.pb.o)\n      tensorflow::(anonymous namespace)::MergeFromFail(int) in libtensorflow-core-armv7.a(tensorflow_server.pb.o)\n      tensorflow::(anonymous namespace)::MergeFromFail(int) in libtensorflow-core-armv7.a(saver.pb.o)\n      tensorflow::(anonymous namespace)::MergeFromFail(int) in libtensorflow-core-armv7.a(queue_runner.pb.o)\n      ...\n  \"google::protobuf::internal::GeneratedMessageReflection::GeneratedMessageReflection(google::protobuf::Descriptor const*, google::protobuf::Message const*, int const*, int, int, int, google::protobuf::DescriptorPool const*, google::protobuf::MessageFactory*, int, int)\", referenced from:\n      tensorflow::(anonymous namespace)::protobuf_RegisterTypes(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) in libtensorflow-core-armv7.a(test_log.pb.o)\n      google::protobuf::internal::MapEntry<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::CreateDefaultInstance(google::protobuf::Descriptor const*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::(anonymous namespace)::protobuf_RegisterTypes(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) in libtensorflow-core-armv7.a(tensorflow_server.pb.o)\n      google::protobuf::internal::MapEntry<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::CollectionDef, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::CreateDefaultInstance(google::protobuf::Descriptor const*) in libtensorflow-core-armv7.a(meta_graph.pb.o)\n      google::protobuf::internal::MapEntry<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::SignatureDef, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::CreateDefaultInstance(google::protobuf::Descriptor const*) in libtensorflow-core-armv7.a(meta_graph.pb.o)\n      google::protobuf::internal::MapEntry<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::TensorInfo, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::CreateDefaultInstance(google::protobuf::Descriptor const*) in libtensorflow-core-armv7.a(meta_graph.pb.o)\n      tensorflow::(anonymous namespace)::protobuf_RegisterTypes(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) in libtensorflow-core-armv7.a(config.pb.o)\n      ...\n  \"google::protobuf::internal::MapFieldBase::InitMetadataOnce() const\", referenced from:\n      google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::InitDefaultEntryOnce() const in libtensorflow-core-armv7.a(test_log.pb.o)\n      google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, long long, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)3, 0>::InitDefaultEntryOnce() const in libtensorflow-core-armv7.a(test_log.pb.o)\n      google::protobuf::internal::MapField<int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, (google::protobuf::internal::WireFormatLite::FieldType)5, (google::protobuf::internal::WireFormatLite::FieldType)9, 0>::InitDefaultEntryOnce() const in libtensorflow-core-armv7.a(tensorflow_server.pb.o)\n      google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::CollectionDef, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::InitDefaultEntryOnce() const in libtensorflow-core-armv7.a(meta_graph.pb.o)\n      google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::SignatureDef, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::InitDefaultEntryOnce() const in libtensorflow-core-armv7.a(meta_graph.pb.o)\n      google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::TensorInfo, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::InitDefaultEntryOnce() const in libtensorflow-core-armv7.a(meta_graph.pb.o)\n      google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, int, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)5, 0>::InitDefaultEntryOnce() const in libtensorflow-core-armv7.a(config.pb.o)\n      ...\n  \"google::protobuf::internal::RegisterMapEntryDefaultInstance(google::protobuf::MessageLite*)\", referenced from:\n      tensorflow::(anonymous namespace)::protobuf_RegisterTypes(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) in libtensorflow-core-armv7.a(test_log.pb.o)\n      google::protobuf::internal::MapEntry<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::CreateDefaultInstance(google::protobuf::Descriptor const*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::(anonymous namespace)::protobuf_RegisterTypes(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) in libtensorflow-core-armv7.a(tensorflow_server.pb.o)\n      google::protobuf::internal::MapEntry<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::CollectionDef, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::CreateDefaultInstance(google::protobuf::Descriptor const*) in libtensorflow-core-armv7.a(meta_graph.pb.o)\n      google::protobuf::internal::MapEntry<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::SignatureDef, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::CreateDefaultInstance(google::protobuf::Descriptor const*) in libtensorflow-core-armv7.a(meta_graph.pb.o)\n      google::protobuf::internal::MapEntry<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::TensorInfo, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::CreateDefaultInstance(google::protobuf::Descriptor const*) in libtensorflow-core-armv7.a(meta_graph.pb.o)\n      tensorflow::(anonymous namespace)::protobuf_RegisterTypes(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) in libtensorflow-core-armv7.a(config.pb.o)\n      ...\n  \"google::protobuf::io::CodedInputStream::ReadTagFallback(unsigned int)\", referenced from:\n      tensorflow::EntryValue::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::BenchmarkEntry::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::BenchmarkEntries::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::BuildConfiguration::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::CommitId::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::CPUInfo::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::MemoryInfo::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      ...\n  \"google::protobuf::io::CodedInputStream::ReadVarint32Fallback(unsigned int)\", referenced from:\n      tensorflow::SavedSliceMeta::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(saved_tensor_slice.pb.o)\n      tensorflow::LogMessage::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(event.pb.o)\n      tensorflow::SessionLog::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(event.pb.o)\n      tensorflow::ServerDef::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(tensorflow_server.pb.o)\n      google::protobuf::internal::MapEntryLite<int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, (google::protobuf::internal::WireFormatLite::FieldType)5, (google::protobuf::internal::WireFormatLite::FieldType)9, 0>::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(tensorflow_server.pb.o)\n      google::protobuf::internal::MapEntryLite<int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, (google::protobuf::internal::WireFormatLite::FieldType)5, (google::protobuf::internal::WireFormatLite::FieldType)9, 0>::Parser<google::protobuf::internal::MapField<int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, (google::protobuf::internal::WireFormatLite::FieldType)5, (google::protobuf::internal::WireFormatLite::FieldType)9, 0>, google::protobuf::Map<int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > >::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(tensorflow_server.pb.o)\n      tensorflow::SaverDef::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(saver.pb.o)\n      ...\n  \"google::protobuf::Any::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*)\", referenced from:\n      tensorflow::MachineConfiguration::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::MetaGraphDef_MetaInfoDef::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(meta_graph.pb.o)\n      tensorflow::CollectionDef_AnyList::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(meta_graph.pb.o)\n  \"google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(google::protobuf::Descriptor const*, google::protobuf::Message const*, int const*, int, int, int, void const*, int, int, int, int)\", referenced from:\n      tensorflow::protobuf_AssignDesc_tensorflow_2fcore_2futil_2ftest_5flog_2eproto() in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::protobuf_AssignDesc_tensorflow_2fcore_2futil_2fevent_2eproto() in libtensorflow-core-armv7.a(event.pb.o)\n      tensorflow::protobuf_AssignDesc_tensorflow_2fcore_2fprotobuf_2fmeta_5fgraph_2eproto() in libtensorflow-core-armv7.a(meta_graph.pb.o)\n      tensorflow::protobuf_AssignDesc_tensorflow_2fcore_2fframework_2ftensor_5fslice_2eproto() in libtensorflow-core-armv7.a(tensor_slice.pb.o)\n      tensorflow::protobuf_AssignDesc_tensorflow_2fcore_2fframework_2fsummary_2eproto() in libtensorflow-core-armv7.a(summary.pb.o)\n      tensorflow::protobuf_AssignDesc_tensorflow_2fcore_2fframework_2fattr_5fvalue_2eproto() in libtensorflow-core-armv7.a(attr_value.pb.o)\n      tensorflow::protobuf_AssignDesc_tensorflow_2fcore_2fexample_2ffeature_2eproto() in libtensorflow-core-armv7.a(feature.pb.o)\n      ...\n  \"google::protobuf::Arena::AllocateAligned(std::type_info const*, unsigned long)\", referenced from:\n      tensorflow::EntryValue::New(google::protobuf::Arena*) const in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::BenchmarkEntry::New(google::protobuf::Arena*) const in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::BenchmarkEntry::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::BenchmarkEntry::InternalSerializeWithCachedSizesToArray(bool, unsigned char*) const in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::BenchmarkEntry::ByteSizeLong() const in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::BenchmarkEntries::New(google::protobuf::Arena*) const in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::BuildConfiguration::New(google::protobuf::Arena*) const in libtensorflow-core-armv7.a(test_log.pb.o)\n      ...\n  \"google::protobuf::internal::GeneratedMessageReflection::NewGeneratedMessageReflection(google::protobuf::Descriptor const*, google::protobuf::Message const*, int const*, int, int, int, int, int, int)\", referenced from:\n      tensorflow::protobuf_AssignDesc_tensorflow_2fcore_2futil_2ftest_5flog_2eproto() in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::protobuf_AssignDesc_tensorflow_2fcore_2futil_2fsaved_5ftensor_5fslice_2eproto() in libtensorflow-core-armv7.a(saved_tensor_slice.pb.o)\n      tensorflow::protobuf_AssignDesc_tensorflow_2fcore_2futil_2fmemmapped_5ffile_5fsystem_2eproto() in libtensorflow-core-armv7.a(memmapped_file_system.pb.o)\n      tensorflow::protobuf_AssignDesc_tensorflow_2fcore_2futil_2fevent_2eproto() in libtensorflow-core-armv7.a(event.pb.o)\n      tensorflow::protobuf_AssignDesc_tensorflow_2fcore_2fprotobuf_2ftensorflow_5fserver_2eproto() in libtensorflow-core-armv7.a(tensorflow_server.pb.o)\n      tensorflow::protobuf_AssignDesc_tensorflow_2fcore_2fprotobuf_2fsaver_2eproto() in libtensorflow-core-armv7.a(saver.pb.o)\n      tensorflow::protobuf_AssignDesc_tensorflow_2fcore_2fprotobuf_2fqueue_5frunner_2eproto() in libtensorflow-core-armv7.a(queue_runner.pb.o)\n      ...\n  \"google::protobuf::io::CodedInputStream::BytesUntilTotalBytesLimit() const\", referenced from:\n      tensorflow::CollectionDef_FloatList::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(meta_graph.pb.o)\n      tensorflow::TensorProto::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(tensor.pb.o)\n      tensorflow::HistogramProto::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(summary.pb.o)\n      tensorflow::AttrValue_ListValue::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(attr_value.pb.o)\n      tensorflow::FloatList::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(feature.pb.o)\n  \"google::protobuf::internal::MapFieldBase::SetMapDirty()\", referenced from:\n      tensorflow::BenchmarkEntry::UnsafeMergeFrom(tensorflow::BenchmarkEntry const&) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::BenchmarkEntry::Clear() in libtensorflow-core-armv7.a(test_log.pb.o)\n      google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::Clear() in libtensorflow-core-armv7.a(test_log.pb.o)\n      google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::MergeFrom(google::protobuf::internal::MapFieldLite<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0> const&) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::CPUInfo::UnsafeMergeFrom(tensorflow::CPUInfo const&) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::CPUInfo::Clear() in libtensorflow-core-armv7.a(test_log.pb.o)\n      google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, long long, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)3, 0>::Clear() in libtensorflow-core-armv7.a(test_log.pb.o)\n      ...\n  \"google::protobuf::internal::MapFieldBase::SyncMapWithRepeatedField() const\", referenced from:\n      tensorflow::benchmark_model::InitializeSession(int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&, std::__1::unique_ptr<tensorflow::Session, std::__1::default_delete<tensorflow::Session> >*, std::__1::unique_ptr<tensorflow::StatSummarizer, std::__1::default_delete<tensorflow::StatSummarizer> >*) in benchmark_model.o\n      tensorflow::BenchmarkEntry::UnsafeMergeFrom(tensorflow::BenchmarkEntry const&) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::BenchmarkEntry::Clear() in libtensorflow-core-armv7.a(test_log.pb.o)\n      google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::Clear() in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::BenchmarkEntry::SerializeWithCachedSizes(google::protobuf::io::CodedOutputStream*) const in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::BenchmarkEntry::InternalSerializeWithCachedSizesToArray(bool, unsigned char*) const in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::BenchmarkEntry::ByteSizeLong() const in libtensorflow-core-armv7.a(test_log.pb.o)\n      ...\n  \"typeinfo for google::protobuf::internal::MapFieldBase\", referenced from:\n      typeinfo for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue> in libtensorflow-core-armv7.a(test_log.pb.o)\n      typeinfo for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, long long> in libtensorflow-core-armv7.a(test_log.pb.o)\n      typeinfo for google::protobuf::internal::TypeDefinedMapFieldBase<int, std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > > in libtensorflow-core-armv7.a(tensorflow_server.pb.o)\n      typeinfo for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::CollectionDef> in libtensorflow-core-armv7.a(meta_graph.pb.o)\n      typeinfo for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::SignatureDef> in libtensorflow-core-armv7.a(meta_graph.pb.o)\n      typeinfo for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::TensorInfo> in libtensorflow-core-armv7.a(meta_graph.pb.o)\n      typeinfo for google::protobuf::internal::TypeDefinedMapFieldBase<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, int> in libtensorflow-core-armv7.a(config.pb.o)\n      ...\n  \"google::protobuf::io::CodedInputStream::DecrementRecursionDepthAndPopLimit(int)\", referenced from:\n      tensorflow::BenchmarkEntry::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::CPUInfo::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::MachineConfiguration::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::TestResults::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      google::protobuf::internal::MapEntryLite<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      google::protobuf::internal::MapEntryLite<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>::Parser<google::protobuf::internal::MapField<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue, (google::protobuf::internal::WireFormatLite::FieldType)9, (google::protobuf::internal::WireFormatLite::FieldType)11, 0>, google::protobuf::Map<std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> >, tensorflow::EntryValue> >::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::SavedSliceMeta::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(saved_tensor_slice.pb.o)\n      ...\n  \"google::protobuf::internal::fixed_address_empty_string\", referenced from:\n      tensorflow::TestReporter::Initialize() in reporter.o\n      tensorflow::protobuf_InitDefaults_tensorflow_2fcore_2futil_2ftest_5flog_2eproto_impl() in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::(anonymous namespace)::protobuf_RegisterTypes(std::__1::basic_string<char, std::__1::char_traits<char>, std::__1::allocator<char> > const&) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::EntryValue::UnsafeMergeFrom(tensorflow::EntryValue const&) in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::EntryValue::~EntryValue() in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::EntryValue::Clear() in libtensorflow-core-armv7.a(test_log.pb.o)\n      tensorflow::EntryValue::MergePartialFromCodedStream(google::protobuf::io::CodedInputStream*) in libtensorflow-core-armv7.a(test_log.pb.o)\n```\n\nAnyone run into this issue?\n", "comments": ["@levelvc : Could you elaborate on the steps you used to get there? (It helps to provide all the information in the [\"New\" issue template](https://github.com/tensorflow/tensorflow/issues/new)).\n\nHow did you go about building the library? Were you following https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile#ios ?\n", "I hit the same issue.\n", "@varung : Same question to you: Could you add some detail as to the precise steps followed that resulted in this?\n", "Closing due to inactivity. Please feel free to reopen if this is still happening and you can add more information on the steps you took.\n"]}, {"number": 5068, "title": "Restoring a tensorflow model for finetuning, with \u201cslim.learning.train\u201d", "body": "with slim.learning.train (TF 0.11), I would like to restore a model from a checkpoint and continue the training. The model had a successful training session, and I would like to fine tune it. However, when I do that, TF crash with an error \n`Init operations did not make model ready.`\n\nI do the training with:\n\n```\ntf.contrib.slim.learning.train(\n    train_op,\n    train_dir,\n    log_every_n_steps=FLAGS.log_every_n_steps,\n    graph=g,\n    global_step=model.global_step,\n    number_of_steps=FLAGS.number_of_steps,\n    init_fn=model.init_fn,\n    saver=model.saver,\n    session_config=session_config)\n```\n\nI tried 3 alternatives:\n### 1\n\nFollowing [this doc](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/training/session_manager.py#L183)\n\n```\nmodel.init_fn = None\n```\n### 2\n\n```\nwith g.as_default():\n    model_path = tf.train.latest_checkpoint(train_dir)\n    if model_path:\n        def restore_fn(sess):\n            tf.logging.info(\n                \"Restoring SA&T variables from checkpoint file %s\",\n                restore_fn.model_path)\n            model.saver.restore(sess, restore_fn.model_path)\n        restore_fn.model_path = model_path\n        model.init_fn = restore_fn\n    else:\n        model.init_fn = None\n```\n### 3\n\nFollowing [slim doc](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim)\n\n```\nwith g.as_default():\n    model_path = tf.train.latest_checkpoint(train_dir)\n    if model_path:\n        variables_to_restore = tf.contrib.slim.get_variables_to_restore()\n        model.init_fn = tensorflow.contrib.framework.assign_from_checkpoint_fn(\n            model_path, variables_to_restore)\n    else:\n        model.init_fn = None\n```\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\n\nhttp://stackoverflow.com/questions/38499136/tensorflow-learn-initialize-variables\n### Environment info\n\nOperating System:\nLinux\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\nIf installed from binary pip package, provide:\n1. A link to the pip package you installed:\n   https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0rc0-cp27-none-linux_x86_64.whl\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n   I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so locally\n   I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so locally\n   I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so locally\n   I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\n   I tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so locally\n   0.11.0rc0\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment or provide link).\n\n[alternative1.txt](https://github.com/tensorflow/tensorflow/files/538795/alternative1.txt)\n[alternative2.txt](https://github.com/tensorflow/tensorflow/files/538797/alternative2.txt)\n[alternative3.txt](https://github.com/tensorflow/tensorflow/files/538796/alternative3.txt)\n", "comments": ["Issue was solved. It happened because the saver (tf.train.Saver) was defined directly after the model build.\n\nInstead, defining it following the train op definition, solved the issue.\n", "Can you know how you solved this issue in detail? I have a same problem. Although I move Saver right before the train op definition, it didn't work.."]}, {"number": 5067, "title": "Does TensorFlow support Intel PHI?", "body": "Intel is driving Caffe to support MKL. Any plans to make tensorflow support Intel PHI also?\n", "comments": ["Support for MKL is on the way, though there is no specific date at this time...\n"]}, {"number": 5066, "title": "Multiple GPU Memory Being Allocated for single device script", "body": "I am unable to run a TF script on a single GPU. Both of my GTX 1080's memory are being fully absorbed by Tensorflow when the model is initialized, but only one of the GPU is being used for computations (based on what I'm seeing in nvidia-smi).\n\nBecause both GPUs memory are fully occupied, I cannot run two models at once.\n\n<img width=\"572\" alt=\"screen shot 2016-10-18 at 11 11 38 pm\" src=\"https://cloud.githubusercontent.com/assets/4795661/19507497/4293ff2e-9588-11e6-92dd-4b79b86eaa9e.png\">\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\n\nhttp://stackoverflow.com/questions/34199233/how-to-prevent-tensorflow-from-allocating-the-totality-of-a-gpu-memory\nhttps://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/jw4FtKOivZE\n### Environment info\n\nOperating System:\nUbuntu 16.04\n\nInstalled version of CUDA and cuDNN: \nCuda Toolkit 8.0, cuDNN 5.1.5\n\n```\nI tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcudnn.so.5.1.5 locally\nI tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcurand.so.8.0 locally\n0.11.0rc0\n```\n\n```\nBuild label: 0.3.2\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Fri Oct 7 17:25:10 2016 (1475861110)\nBuild timestamp: 1475861110\nBuild timestamp as int: 1475861110\n```\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\n\nI'm using the example from here: https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/convolutional_network.py\n### What other attempted solutions have you tried?\n\nCUDA_VISIBLE_DEVICES\n\nand\n\nconfig = tf.ConfigProto(\n    device_count = {'GPU': 1}\n)\n\nsess = tf.Session(config=config)\n\nand \n\nwith tf.device('/gpu:0'):\n ...\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment or provide link).\n", "comments": ["Thanks for the report @alexandercrosson . Just to make sure I understood correctly, you're saying that even if you set `CUDA_VISIBLE_DEVICES=0` or set the `device_count` in `ConfigProto` your program still uses memory of both GPUs?\n\nDo you have a pointer to the code that you used? (The one you linked to above: https://github.com/aymericdamien/TensorFlow-Examples/blob/master/examples/3_NeuralNetworks/convolutional_network.py - seems to be without any `ConfigProto` or `tf.device`).\n", "@asimshankar . When I use `device_count = {'GPU': 1}` it does only allow me to use the first GPU, but this isn't helpful because I can never use the second GPU.\n\nFor instance if i use `device_count = {'GPU': 1}` and set tf.device('/gpu:1') i'll get the error message:\n\n```\ntensorflow.python.framework.errors.InvalidArgumentError: Cannot assign a device to node 'Adam/epsilon': Could not satisfy explicit device specification '/device:GPU:1' because no devices matching that specification are registered in this process; available devices: /job:localhost/replica:0/task:0/cpu:0, /job:localhost/replica:0/task:0/gpu:0\n         [[Node: Adam/epsilon = Const[dtype=DT_FLOAT, value=Tensor<type: float shape: [] values: 1e-08>, _device=\"/device:GPU:1\"]()]]\n```\n\nHere's a gist : https://gist.github.com/alexandercrosson/8dc970578e1d1d4e7b00b1dba63a45b4\n", "What about [`CUDA_VISIBLE_DEVICES`](http://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#env-vars)? That should control which process sees what GPUs. So you'd run one process with `CUDA_VISIBLE_DEVICES=0` and the other with `CUDA_VISIBLE_DEVICES=1`.\n\n`device_count` is meant to limit the number of devices used - so it won't allocate memory on both devices. When `device_count` is 1, the device name will still be just `/gpu:0`.  You might find https://www.tensorflow.org/versions/r0.11/how_tos/using_gpu/index.html#allowing-gpu-memory-growth - which talks about limiting memory use interesting as well.\n\nBut long story short, does `CUDA_VISIBLE_DEVICES` not do the trick?\n", "@asimshankar CUDA_VISIBLE_DEVICES works! I tested it by setting CUDA_VISIBLE_DEVICES=\"0\" in one tmux instance and CUDA_VISIBLE_DEVICES=\"1\" in another. Both instances are able to train.\n\nThe memory being allocated to both by default - is that the intended functionality of TF?\n", "Great to hear it worked. \nYes, taking over all devices that are accessible to the process is intended. Some more detail in this comment: https://github.com/tensorflow/tensorflow/issues/3644#issuecomment-237631171\n\nSince your issue has been resolved, I'm going to close this. If you run into trouble, feel free to create a new issue. Thanks\n", "Hi,@alexandercrosson \nThanks for your reply. You mentioned that `export CUDA_VISIBLE_DEVICES=\"0\"`can be used. But I still don't   know how to use it. I was using a tensorflow backend  keras, and want to run different unrelated scripts at the same time.\nWhere should I add `export CUDA_VISIBLE_DEVICES=\"0\"`?\n\nI also tried  with `tf.device`('/gpu:0'). For example, \n\n```\nwith tf.device('/gpu:0'):\n         model.fit(trainX, trainY)\n```\n\nBut it did't change anything.\n", "@anewlearner : `CUDA_VISIBLE_DEVICES` is an [environment variable](https://en.wikipedia.org/wiki/Environment_variable) that you would say set in your shell before invoking the python program.\n", "You run export CUDA_VISIBLE_DEVICES=\"0\" in the environment before running\nyour tensorflow script.\n\nOn Sat, Oct 22, 2016 at 7:27 AM, Carol notifications@github.com wrote:\n\n> Hi,@alexandercrosson https://github.com/alexandercrosson\n> Thanks for your reply. You mentioned that export CUDA_VISIBLE_DEVICES=\"0\"can\n> be used. But I still don't know how to use it. I was using a tensorflow\n> backend keras, and want to run different unrelated scripts at the same time.\n> Where should I add export CUDA_VISIBLE_DEVICES=\"0\"?\n> \n> I also tried with tf.device('/gpu:0'). For example,\n> \n> with tf.device('/gpu:0'):\n>          model.fit(trainX, trainY)\n> \n> But it did't change anything.\n> \n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/5066#issuecomment-255531550,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AABaHN2KCeeBm9zWh4cCExFm4O_6Ex_dks5q2h1kgaJpZM4KanKw\n> .\n", "Is this because of using SLI bridge?", "@zylix666 I think it is definitely something about SLI bridge. I have 2 GTX 1080Ti in SLI mode and even though I set only one device with `CUDA_VISIBLE_DEVICES` environment variable, it still uses both of the GPU memory but executes on single GPU. Do you have any suggestions about running on SLI mode or should I just disable SLI completely? ", "any updates on this?", "I run training on both the GPU's, I can see the process on both the GPU say it apears my python command is on both the GPUS, but then the GPU memory is being utilized by only the first GPU i mention. I am trying to train images for FRCNN.\r\n\r\ncommand : os.environ[CUDA_VISIBLE_DEVICES[ = \"0,1\"\r\n"]}, {"number": 5065, "title": "How to export the wide and deep model and use java client to request", "body": "", "comments": ["@jasonhere : I'm missing some context here, where are these code snippets from? What is `m` and `w_d.py`?\n\nRegardless, it appears that you're looking for some demo code for serving a model. Perhaps [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) will be a more appropriate venue for seeking such advice from the community.\n"]}, {"number": 5064, "title": "Urgently need the pip installation package with ubuntu14/04/05 & cuda8 & cudnn5(bithpy27 an py34))", "body": "In some country , it cannot download some package like bazel or protobuff etc, so install from source is impossible.\n### Environment info\n\nOperating System:\nubuntu14/04/05\n\nInstalled version of CUDA and cuDNN: \ncuda8 & cudnn5\n", "comments": ["All the release packages for TensorFlow (pip, docker etc.) are listed at https://www.tensorflow.org/versions/r0.11/get_started/os_setup.html#download-and-setup\n\nAny other combinations will require a source installation.\nSorry I don't have better news.\n"]}, {"number": 5063, "title": "Bump up size of gradient_checker_test", "body": "Seen in [this build](https://ci.tensorflow.org/job/tensorflow-pull-requests-gpu/2197/)\n", "comments": ["@terrytangyuan, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener, @keveman and @vrv to be potential reviewers.\n", "Same as #5062\n", "Ok I missed that. \n"]}]