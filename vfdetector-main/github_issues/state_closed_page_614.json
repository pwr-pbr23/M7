[{"number": 35230, "title": "[ROCm] Fixing RNNFowardV2 autotuning loop and unit tests", "body": "The first commit is cherry-picked from #34532, and has been approved in #31849 (authored by @whchung ). Without the first commit, r1.15 branch will not build for the latest ROCm release.\r\n\r\nThe second commit is cherry picked from [#710](https://github.com/ROCmSoftwarePlatform/tensorflow-upstream/pull/710). Fixed the RNN V2 kernels by enabled the auto-tuning loop in `ROCm` path. It should also fix the warning \"No RNN Algorithm Found.\" `cudnn_recurrent_test` used to have 68 failures on value difference, now is all passing", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F35230) for more info**.\n\n<!-- need_author_consent -->", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F35230) for more info**.\n\n<!-- ok -->", "I accidentally deleted the branch, causing the pull request to close. Reopening the pull request again.", "@jerryyin , please resolve the `Ubuntu Sanity` failures, and check whether the other failures are related to this PR", "Note that the currently running presubmits might still fail. https://github.com/tensorflow/tensorflow/pull/34532#issuecomment-574814561", "Thanks for helping out @mihaimaruseac "]}, {"number": 35229, "title": "Update math_ops.py", "body": "Updating tf.multiply with usage example, and description", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F35229) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F35229) for more info**.\n\n<!-- ok -->", "Yes\n\nOn Fri, Dec 27, 2019 at 8:47 AM Ananya Gangavarapu <notifications@github.com>\nwrote:\n\n> *@anigasan* commented on this pull request.\n> ------------------------------\n>\n> In tensorflow/python/ops/math_ops.py\n> <https://github.com/tensorflow/tensorflow/pull/35229#discussion_r361703216>\n> :\n>\n> > @@ -354,10 +353,6 @@ def multiply(x, y, name=None):  # pylint: disable=missing-docstring\n>      A 'Tensor'. Has the same type as 'x'\n>    \"\"\"\n>\n> -  return gen_math_ops.mul(x, y, name)\n>\n> When you say remove, do you mean lines 338 and 341?\n>\n> \u2014\n> You are receiving this because your review was requested.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/35229?email_source=notifications&email_token=AAABHRJ4BUJGMBAY7UPBEE3Q2YWTBA5CNFSM4J4QFP7KYY3PNVWWK3TUL52HS4DFWFIHK3DMKJSXC5LFON2FEZLWNFSXPKTDN5WW2ZLOORPWSZGOCQJXK7A#discussion_r361703216>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHRKXL7E4VKMUVKSEYC3Q2YWTBANCNFSM4J4QFP7A>\n> .\n>\n\n\n-- \n - Alex\n", "@mihaimaruseac I was wondering about how my change wasn't able to be migrated to the master branch. Is there anything I need to fix or is it just a simple bug?", "There are the two nits that need to be resolved and then the change seems to be able to land in master (after another round of CI)", "@mihaimaruseac Is there anything that I can resolve in order to fix the two nits?", "Yes, please add back that empty line you removed and remove the trailing whitespace. See comments on the review above.", "@mihaimaruseac I will add the necessary changes", "Please rebase against master and also remove the trailing whitespace", "```\r\nExpected:\r\n    <tf.Tensor: shape=(3, 2, 3), dtype=float32, numpy=\r\n    array([[[ 1.815     ,  0.5831516 , -0.7149856 ],\r\n          [ 4.815     ,  0.5831516 , -0.7149855 ]],\r\n         [[ 7.815     ,  0.5831516 , -0.7149856 ],\r\n          [10.815001  ,  0.5831518 , -0.7149852 ]],\r\n         [[13.815001  ,  0.58315134, -0.7149857 ],\r\n          [16.815     ,  0.58315134, -0.7149854 ]]], dtype=float32)> \r\nGot:\r\n    <tf.Tensor: shape=(3, 2, 3), dtype=float32, numpy=\r\n    array([[[ 1.815     ,  0.5831516 , -0.7149856 ],\r\n            [ 4.815     ,  0.5831516 , -0.7149856 ]],\r\n\r\n           [[ 7.815     ,  0.5831516 , -0.7149856 ],\r\n            [10.815001  ,  0.58315134, -0.7149854 ]],\r\n\r\n           [[13.815     ,  0.58315134, -0.7149856 ],\r\n            [16.815     ,  0.58315134, -0.7149854 ]]], dtype=float32)>\r\n```\r\n\r\nPlease fix", "@anigasan Can you please check mihaimaruseac's comments and keep us posted? Thanks!", "Hello @mihaimaruseac, can you tell me the line numbers where I should make the changes? Thanks!", "@mihaimaruseac Any update on this PR, please. Thanks!", "Please rebase on master and run the doctests locally. It prints out the error lines.", "I am testing the doctests locally and will change cordially", "@anigasan, @mihaimaruseac Any update on this PR, please. Thanks!", "Closing the PR as another stale PR. Please reopen when doctests are working and is ready for a new review round."]}, {"number": 35228, "title": "Configuring issues with tag 2.1.0", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 9\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.1.0rc1 (and rc0)\r\n- Python version: 3.6.8\r\n- Installed using virtualenv? pip? conda?: virtualenv\r\n- Bazel version (if compiling from source): bazelisk\r\n- GCC/Compiler version (if compiling from source): 6.3.0\r\n- CUDA/cuDNN version: 10.1 and 7.6.5\r\n- GPU model and memory: 2x NVidia Titan XP 11GB\r\n\r\n\r\n\r\n1. Configuring from both tags (rc0 and rc1) picks the wrong bazel (0.26 instead of 1.1.0) due to misconfigured .bazelversion, which should be cherry-picked from a later commit to make it work. I don't see the reason for this to be necessary and not having a buildable tag. The commit a5f9bcd64453ff3d1f64cb4da4786db3d2da7f82 should be the one but, while I understand this making rc0 not work, I don't understand rc1 also not working since it's a later tag.\r\n\r\n2. Configuring out of source, i.e. with a tree made to be able to call `../configure` (hybrid out-of-source) or `../tensorflow/configure` (full out-of-source) results in `/usr/local/bin/python3.6: can't open file 'third_party/gpus/find_cuda_config.py': [Errno 2] No such file or directory`, likely due to 'third_party/gpus/find_cuda_config.py' being an absoulte path instead of a relative one.", "comments": ["Ok\n\nOn Wed, Dec 18, 2019, 08:24 aPonza <notifications@github.com> wrote:\n\n> *Please make sure that this is a build/installation issue. As per our\n> GitHub Policy\n> <https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md>, we only\n> address code/doc bugs, performance issues, feature requests and\n> build/installation issues on GitHub. tag:build_template*\n>\n> *System information*\n>\n>    - OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 9\n>    - Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\n>    happens on mobile device: no\n>    - TensorFlow installed from (source or binary): source\n>    - TensorFlow version: 2.1.0rc1 (and rc0)\n>    - Python version: 3.6.8\n>    - Installed using virtualenv? pip? conda?: virtualenv\n>    - Bazel version (if compiling from source): bazelisk\n>    - GCC/Compiler version (if compiling from source): 6.3.0\n>    - CUDA/cuDNN version: 10.1 and 7.6.5\n>    - GPU model and memory: 2x NVidia Titan XP 11GB\n>\n>\n>    1.\n>\n>    Configuring from both tags (rc0 and rc1) picks the wrong bazel (0.26\n>    instead of 1.1.0) due to misconfigured .bazelversion, which should be\n>    cherry-picked from a later commit to make it work. I don't see the reason\n>    for this to be necessary and not having a buildable tag. The commit is\n>    a5f9bcd\n>    <https://github.com/tensorflow/tensorflow/commit/a5f9bcd64453ff3d1f64cb4da4786db3d2da7f82>\n>    should be the one but, while I understand this making rc0 not work, I don't\n>    understand rc1 also not working since it's a later tag.\n>    2.\n>\n>    Configuring out of source, i.e. with a tree made to be able to call\n>    ../configure (hybrid out-of-source) or ../tensorflow/configure (full\n>    out-of-source) results in /usr/local/bin/python3.6: can't open file\n>    'third_party/gpus/find_cuda_config.py': [Errno 2] No such file or directory,\n>    likely due to 'third_party/gpus/find_cuda_config.py' being an absoulte path\n>    instead of a relative one.\n>\n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/35228?email_source=notifications&email_token=AOBPXOQMRDENFD6MAQMTG4TQZIXA3A5CNFSM4J4LV4UKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4IBLJPYA>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AOBPXOVOMPLOQEUSNC7LRXLQZIXA3ANCNFSM4J4LV4UA>\n> .\n>\n", "@mihaimaruseac: the `.bazelversion` in the r2.1 branch does not match the allowed range in `configure.py` (range is 0.27-0.29, `.bazelversion is 0.26)\r\n\r\n", "I'll make a cherry-pick", "Actually, there is #35470 already for this.", "I still don't see the reason to not have a buildable tag. Regardless, that would fix point 1. What about the second? Could that be a valid way to fix the issue or am I the only one having it?", "`r2.1` branch was cut before changes were made to support bazel 1.1.0. Thus, tags on this branch should be buildable with Bazel from `0.27` to `0.29`. It is lucky if it also builds with 1.1.0.\r\n\r\nRegarding second point, I don't think you're supposed to run configure out of tree. I don't know of any other open source project which allows you to `${path_to}/configure` from outside the tree", "`tags on this branch should be buildable with Bazel from 0.27 to 0.29` isn't true though, due to said bazelversion being incorrectly set to 0.26. The point of my last comment was to point out my desire to have r2.1 build out of the box after dependencies are satisfied (i.e. include the commit from 5 days ago which you linked in the final r2.1 tag), I suppose that's the reason it's still a release candidate.\r\n\r\nNow that you say it, I can only think of CMake Open Source projects which allow it, but it is a \"best practice\" so to speak, as far as I know. Many projects not only allow it but enforce it as well (e.g. OpenCV, ROS, ...), but still mostly CMake ones. Actually [google tells me Qt allows it](https://www.qtcentre.org/threads/23086-Building-qt-out-of-source?s=0f1acc001d79521205a72a0b7790fe9e&p=112396#post112396), but I see your point, and that is a very old link.", " #35470 has been merged", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35228\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35228\">No</a>\n"]}, {"number": 35227, "title": "Tensorflow build unsuccessful using bazel build", "body": "So I have been following to this guide https://www.tensorflow.org/install/source and https://www.tensorflow.org/install/gpu. My system configuration is\r\n\r\n\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 1050    Off  | 00000000:01:00.0  On |                  N/A |\r\n| 45%   27C    P8    N/A /  75W |    258MiB /  1997MiB |     10%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                              \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0      1022      G   /usr/lib/xorg/Xorg                           151MiB |\r\n|    0      2686      G   compiz                                       102MiB |\r\n|    0      5660      G   /usr/lib/firefox/firefox                       1MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n./deviceQuery Starting...\r\n\r\n CUDA Device Query (Runtime API) version (CUDART static linking)\r\n\r\nDetected 1 CUDA Capable device(s)\r\n\r\nDevice 0: \"GeForce GTX 1050\"\r\n  CUDA Driver Version / Runtime Version          10.2 / 9.0\r\n  CUDA Capability Major/Minor version number:    6.1\r\n  Total amount of global memory:                 1998 MBytes (2094989312 bytes)\r\n  ( 5) Multiprocessors, (128) CUDA Cores/MP:     640 CUDA Cores\r\n  GPU Max Clock rate:                            1455 MHz (1.46 GHz)\r\n  Memory Clock rate:                             3504 Mhz\r\n  Memory Bus Width:                              128-bit\r\n  L2 Cache Size:                                 1048576 bytes\r\n  Maximum Texture Dimension Size (x,y,z)         1D=(131072), 2D=(131072, 65536), 3D=(16384, 16384, 16384)\r\n  Maximum Layered 1D Texture Size, (num) layers  1D=(32768), 2048 layers\r\n  Maximum Layered 2D Texture Size, (num) layers  2D=(32768, 32768), 2048 layers\r\n  Total amount of constant memory:               65536 bytes\r\n  Total amount of shared memory per block:       49152 bytes\r\n  Total number of registers available per block: 65536\r\n  Warp size:                                     32\r\n  Maximum number of threads per multiprocessor:  2048\r\n  Maximum number of threads per block:           1024\r\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\r\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\r\n  Maximum memory pitch:                          2147483647 bytes\r\n  Texture alignment:                             512 bytes\r\n  Concurrent copy and kernel execution:          Yes with 2 copy engine(s)\r\n  Run time limit on kernels:                     Yes\r\n  Integrated GPU sharing Host Memory:            No\r\n  Support host page-locked memory mapping:       Yes\r\n  Alignment requirement for Surfaces:            Yes\r\n  Device has ECC support:                        Disabled\r\n  Device supports Unified Addressing (UVA):      Yes\r\n  Supports Cooperative Kernel Launch:            Yes\r\n  Supports MultiDevice Co-op Kernel Launch:      Yes\r\n  Device PCI Domain ID / Bus ID / location ID:   0 / 1 / 0\r\n  Compute Mode:\r\n     < Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) >\r\n\r\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 10.2, CUDA Runtime Version = 9.0, NumDevs = 1\r\n\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2017 NVIDIA Corporation\r\nBuilt on Fri_Sep__1_21:08:03_CDT_2017\r\nCuda compilation tools, release 9.0, V9.0.176\r\n\r\nlibcudnn => 7.6.0\r\n#define CUDNN_MAJOR 7\r\n#define CUDNN_MINOR 6\r\n#define CUDNN_PATCHLEVEL 0\r\n--\r\n#define CUDNN_VERSION (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)\r\n\r\n#include \"driver_types.h\"\r\n\r\nNCCL version => 2.4.7\r\ngcc => 5.4.0\r\npyhton => 2.7.0\r\n\r\ndpkg -l | grep TensorRT\r\nii  graphsurgeon-tf                                            5.1.5-1+cuda9.0                                 amd64        GraphSurgeon for TensorRT package\r\nii  libnvinfer-dev                                             5.1.5-1+cuda9.0                                 amd64        TensorRT development libraries and headers\r\nii  libnvinfer-samples                                         5.1.5-1+cuda9.0                                 all          TensorRT samples and documentation\r\nii  libnvinfer5                                                5.1.5-1+cuda9.0                                 amd64        TensorRT runtime libraries\r\nii  python-libnvinfer                                          5.1.5-1+cuda9.0                                 amd64        Python bindings for TensorRT\r\nii  python-libnvinfer-dev                                      5.1.5-1+cuda9.0                                 amd64        Python development package for TensorRT\r\nii  tensorrt                                                   5.1.5.0-1+cuda9.0                               amd64        Meta package of TensorRT\r\nii  uff-converter-tf                                           5.1.5-1+cuda9.0                                 amd64        UFF converter for TensorRT package\r\n\r\n\r\n\r\nafter running this command\r\n**bazel build --config=opt --config=cuda --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" //tensorflow/tools/pip_package:build_pip_package\r\nand\r\nbazel build --config=opt  --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" //tensorflow/tools/pip_package:build_pip_package**\r\n\r\nI got the same error both time mentioned at bottom\r\n\r\n**ERROR: /home/user/tensorflow/tensorflow/core/kernels/BUILD:2951:1: output 'tensorflow/core/kernels/_objs/cwise_op_gpu/tensorflow/core/kernels/cwise_op_gpu_mul.cu.pic.o' was not created\r\nERROR: /home/user/tensorflow/tensorflow/core/kernels/BUILD:2951:1: not all outputs were created or valid\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nFAILED: Build did NOT complete successfully**\r\n\r\nAny help would be appreciated I am still learning and trying to understand tensorflow and its conepts. It would be great and exciting if anyone could give any suggestions or advice where I am going wrong. Though I am referring to couple of references will keep you guys posted if I come across anything relevant. Let me know if more info is required. Thanks\r\n\r\n", "comments": ["A quick update in this sections. ERROR: /home/user/tensorflow/tensorflow/BUILD:533:1: Executing genrule //tensorflow:tf_python_api_gen_v1 failed (Exit 1)\r\nTraceback (most recent call last):\r\n  File \"/home/user/.cache/bazel/_bazel_user/f11a7014505dc3312336ee3d012a10b6/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py\", line 27, in <module>\r\n    from tensorflow.python.tools.api.generator import doc_srcs\r\n  File \"/home/user/.cache/bazel/_bazel_user/f11a7014505dc3312336ee3d012a10b6/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/__init__.py\", line 59, in <module>\r\n    from tensorflow.core.framework.graph_pb2 import *\r\n  File \"/home/user/.cache/bazel/_bazel_user/f11a7014505dc3312336ee3d012a10b6/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/core/framework/graph_pb2.py\", line 15, in <module>\r\n    from tensorflow.core.framework import node_def_pb2 as tensorflow_dot_core_dot_framework_dot_node__def__pb2\r\n  File \"/home/user/.cache/bazel/_bazel_user/f11a7014505dc3312336ee3d012a10b6/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/core/framework/node_def_pb2.py\", line 15, in <module>\r\n    from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2\r\n  File \"/home/user/.cache/bazel/_bazel_user/f11a7014505dc3312336ee3d012a10b6/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/core/framework/attr_value_pb2.py\", line 15, in <module>\r\n    from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2\r\n  File \"/home/user/.cache/bazel/_bazel_user/f11a7014505dc3312336ee3d012a10b6/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/core/framework/tensor_pb2.py\", line 15, in <module>\r\n    from tensorflow.core.framework import resource_handle_pb2 as tensorflow_dot_core_dot_framework_dot_resource__handle__pb2\r\n  File \"/home/user/.cache/bazel/_bazel_user/f11a7014505dc3312336ee3d012a10b6/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/core/framework/resource_handle_pb2.py\", line 22, in <module>\r\n    serialized_pb=_b('\\n/tensorflow/core/framework/resource_handle.proto\\x12\\ntensorflow\\\"r\\n\\x13ResourceHandleProto\\x12\\x0e\\n\\x06\\x64\\x65vice\\x18\\x01 \\x01(\\t\\x12\\x11\\n\\tcontainer\\x18\\x02 \\x01(\\t\\x12\\x0c\\n\\x04name\\x18\\x03 \\x01(\\t\\x12\\x11\\n\\thash_code\\x18\\x04 \\x01(\\x04\\x12\\x17\\n\\x0fmaybe_type_name\\x18\\x05 \\x01(\\tBn\\n\\x18org.tensorflow.frameworkB\\x0eResourceHandleP\\x01Z=github.com/tensorflow/tensorflow/tensorflow/go/core/framework\\xf8\\x01\\x01\\x62\\x06proto3')\r\n**TypeError: __new__() got an unexpected keyword argument 'serialized_options'**\r\n\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 2315.104s, Critical Path: 235.46s\r\nINFO: 3311 processes: 3311 local.\r\n\r\n**FAILED: Build did NOT complete successfully**\r\n\r\nSo I am now trying to figure out how to solve this error. If anyone is familiar with this error feel free to drop any suggestions or advice it would be really helpful thanks", "@spurani, Could you post the `./configure` output log. Thanks!", "@gadagashwini Here is my ./configure output. I ran this command **cat .tf_configure.bazelrc**. I hope this helps. Please feel free to reach out if you require more information.\r\n\r\nbuild --action_env PYTHON_BIN_PATH=\"/usr/bin/python\"\r\nbuild --action_env PYTHON_LIB_PATH=\"/usr/local/lib/python2.7/dist-packages\"\r\nbuild --python_path=\"/usr/bin/python\"\r\nbuild:ignite --define with_ignite_support=true\r\nbuild:xla --define with_xla_support=true\r\nbuild --action_env TF_NEED_OPENCL_SYCL=\"0\"\r\nbuild --action_env TF_NEED_ROCM=\"0\"\r\nbuild --action_env TF_NEED_CUDA=\"1\"\r\nbuild --action_env CUDA_TOOLKIT_PATH=\"/usr/local/cuda\"\r\nbuild --action_env TF_CUDA_VERSION=\"9.0\"\r\nbuild --action_env CUDNN_INSTALL_PATH=\"/usr/lib/x86_64-linux-gnu\"\r\nbuild --action_env TF_CUDNN_VERSION=\"7\"\r\nbuild --action_env TENSORRT_INSTALL_PATH=\"/usr/lib/x86_64-linux-gnu\"\r\nbuild --action_env TF_TENSORRT_VERSION=\"5.1.5\"\r\nbuild --action_env NCCL_INSTALL_PATH=\"/usr/lib/x86_64-linux-gnu\"\r\nbuild --action_env NCCL_HDR_PATH=\"/usr/include\"\r\nbuild --action_env TF_NCCL_VERSION=\"2\"\r\nbuild --action_env TF_CUDA_COMPUTE_CAPABILITIES=\"6.1\"\r\nbuild --action_env TF_CUDA_CLANG=\"0\"\r\nbuild --action_env GCC_HOST_COMPILER_PATH=\"/usr/bin/gcc\"\r\nbuild --config=cuda\r\ntest --config=cuda\r\nbuild:opt --copt=-march=native\r\nbuild:opt --host_copt=-march=native\r\nbuild:opt --define with_default_optimizations=true\r\nbuild:v2 --define=tf_api_version=2", "@spurani, Looks like in the `./configure` output, CUDA version is 9.0 but at the `nvidia-smi` CUDA 10.2.\r\nPlease check the CUDA and cuDNN version. Provide the Tenosrflow version/branch that you are building. Thanks!", "@gadagashwini thanks for your prompt reply really appreciate it. I am building tensorflow version 1.12.0\r\nhttps://github.com/tensorflow/tensorflow/releases/tag/v1.12.0. I haven't installed cudnn separately it came along with cuda 9.0. Also I have been following these instructions for setting up tensorflow before installationhttps://www.tensorflow.org/install/gpu and here is test build compatibility configurations for gpu https://www.tensorflow.org/install/source#linux  and for installation https://www.tensorflow.org/install/source#linux. \r\n\r\nas you said in your previous comment that in the ./configure output, CUDA version is 9.0 but at the nvidia-smi CUDA 10.2. In explanation can you please refer to this blog I hope it will clear any doubts if you have https://stackoverflow.com/questions/53422407/different-cuda-versions-shown-by-nvcc-and-nvidia-smi. Please feel free to reach out should you have any questions or If you require any further information. Thanks", "@spurani, If you have multiple CUDA versions, \r\nAdd cuda, cudnn, cupti variables to your environment path.https://www.tensorflow.org/install/gpu#linux_setup.\r\nPlease take a look at tested build configuration.\r\nhttps://www.tensorflow.org/install/source#gpu\r\nTensorflow 1.12 supports CUDA 9.0.\r\nThanks!", "@gadagashwini I have already added cuda, cudnn, cupti variables to your environment path based on this https://www.tensorflow.org/install/gpu#linux_setup. The same issue(as mentioned above) still exists.  **TypeError: new() got an unexpected keyword argument 'serialized_options'**. Is there anything else you could suggest? Though I am trying my best to figure out the issue. But till now I didn't find anything relevant on internet which could help me solve the issue. Thanks", "@gadagashwini . So basically I removed tensorflow completely and started from scratch with the help of the mentioned guide. I was successfully able to build and run to install tensorflow after following this guide https://medium.com/repro-repo/speed-up-learning-by-building-tensorflow-gpu-from-source-on-ubuntu-d03bb4e06b23 .\r\n\r\nTarget //tensorflow/tools/pip_package:build_pip_package up-to-date:\r\n  bazel-bin/tensorflow/tools/pip_package/build_pip_package\r\n\r\nINFO: Elapsed time: 3517.322s, Critical Path: 250.75s\r\nINFO: 9346 processes: 9346 local.\r\nINFO: Build completed successfully, 9500 total actions\r\n\r\nI ran these 2 commands to verify the installation\r\n**python -c \"import tensorflow as tf; print(tf.__version__)\"**\r\n/home/path/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\n/home/path/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\r\n/home/path/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\r\n/home/path/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\r\n/home/path/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\r\n/home/path/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\r\n1.12.0\r\n\r\n**python -c \"import tensorflow as tf; print(tf.contrib.eager.num_gpus())\"**\r\n/home/path/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\n/home/path/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\r\n/home/path/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\r\n/home/path/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\r\n/home/path/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\r\n/home/path/.local/lib/python3.5/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\r\n2019-12-25 18:15:33.357674: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-12-25 18:15:33.416894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:964] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-12-25 18:15:33.417115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \r\nname: GeForce GTX 1050 major: 6 minor: 1 memoryClockRate(GHz): 1.455\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 1.95GiB freeMemory: 1.65GiB\r\n2019-12-25 18:15:33.417129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0\r\n2019-12-25 18:15:33.634565: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-12-25 18:15:33.634593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 \r\n2019-12-25 18:15:33.634599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N \r\n2019-12-25 18:15:33.634702: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1397 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n1\r\n\r\nBut still my digits says Tensorflow support disabled. Can you please guide me through this?\r\nThanks", "> But still my digits says Tensorflow support disabled. Can you please guide me through this?\r\n> Thanks\r\n\r\n\r\nLooks like the Tensorflow installed correctly.\r\nCould you elaborate the issue with context. Thanks!\r\n", "> > But still my digits says Tensorflow support disabled. Can you please guide me through this?\r\n> > Thanks\r\n> \r\n> Looks like the Tensorflow installed correctly.\r\n> Could you elaborate the issue with context. Thanks!\r\n\r\nI am trying to integrate Tensorflow framework in Nvidia Digits. I already have nvidia Digits working with Caffe framework. https://github.com/NVIDIA/DIGITS/blob/master/docs/BuildTensorflow.md and https://github.com/NVIDIA/DIGITS/blob/master/docs/GettingStartedTensorflow.md might answer your question. Please let me know if you require more info. Thanks", "@gadagashwini Is it possible to build Tensorflow using python 2.7? Because I removed my previous tensorflow installation which was built on python 3.5. I have tried building tensorflow several times using python 2.7 but it fails everytime is there a command from where I can trace logs and show you what's the exact issue. It would a learning lesson for me is you could me solve this issue. My system configuration is exactly the same mentioned in my previous posts. Thanks and cheers.", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35227\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35227\">No</a>\n"]}, {"number": 35226, "title": "ValueError: `handle` is not available outside the replica context or a `tf.distribute.Strategy.update()` call.", "body": "I am not able to run training using tf.distribute.Strategy\r\nHowever, it works fine without distribution.\r\nBelow is the code block for training loop\r\n\r\n```\r\nfrom __future__ import absolute_import\r\nfrom __future__ import division\r\nfrom __future__ import print_function\r\n\r\nfrom absl import app\r\nimport os\r\nimport tensorflow as tf # TF2\r\nimport model_timit as model\r\nimport kaldi_io\r\nfrom DataLoader_timit import SequentialLoader\r\nfrom warprnnt_tensorflow import rnnt_loss\r\nassert tf.__version__.startswith('2')\r\n\r\nclass Train(object):\r\n\r\n  def __init__(self, epochs, decoder,batch_size):\r\n    self.epochs = epochs\r\n    self.decoder = decoder\r\n    self.batch_size = batch_size\r\n    self.optimizer = tf.keras.optimizers.Adam(learning_rate=0.0004)\r\n    self.train_loss_metric = tf.keras.metrics.Mean(name='train_loss')\r\n    self.checkpoint = tf.train.Checkpoint(\r\n            decoder=self.decoder,\r\n            optimizer=self.optimizer)\r\n\r\n  def loss_function(self, pred,real,xlen,ylen):\r\n    loss_ = rnnt_loss(pred,real,xlen,ylen,0)\r\n    return tf.reduce_sum(loss_) * 1. / self.batch_size\r\n\r\n  def train_step(self, inputs):\r\n    loss = 0\r\n    inp, targ,xlen,ylen = inputs\r\n\r\n    with tf.GradientTape() as tape:\r\n      xs_1,xs,predictions = self.decoder(\r\n            inp, targ)\r\n      time_dim = tf.shape(predictions)[1]\r\n      loss += self.loss_function(predictions,targ,xlen,ylen)\r\n\r\n    batch_loss = (loss / int(targ.shape[1]))\r\n    variables = (self.decoder.trainable_variables)\r\n    gradients = tape.gradient(loss, variables)\r\n    self.optimizer.apply_gradients(zip(gradients, variables))\r\n    #self.optimizer.apply_gradients(list(zip(gradients, variables)))\r\n\r\n    self.train_loss_metric(batch_loss)\r\n\r\n    return self.train_loss_metric.result().numpy()\r\n\r\nclass DistributedTrain(Train):\r\n  def __init__(self, epochs, decoder, batch_size, local_batch_size):\r\n    Train.__init__(\r\n        self, epochs, decoder, local_batch_size)\r\n\r\n  def training_loop(self, train_ds, test_ds, strategy):\r\n    def distributed_train(inp, targ, xlen, ylen):\r\n      returnstrategy.experimental_run_v2(self.train_step((inp, targ, xlen, ylen)))\r\n\r\n    distributed_train = tf.function(distributed_train)\r\n    template = 'Epoch: {}, Train Loss: {}, Test Loss: {}'\r\n    for epoch in range(self.epochs):\r\n      self.train_loss_metric.reset_states()\r\n      for i, (inp, targ, xlen, ylen) in enumerate(train_ds):\r\n        distributed_train(inp, targ, xlen, ylen)\r\n\r\ndef main(epochs=200, batch_size=16, num_examples=70000, embedding_dim=256, enc_units=1024, dec_units=1024):\r\n\r\n  strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\",\"/gpu:1\"])\r\n  num_replicas = strategy.num_replicas_in_sync\r\n\r\n  train_ds = SequentialLoader('train', batch_size)\r\n  test_ds = SequentialLoader('test', batch_size)\r\n\r\n  with strategy.scope():\r\n    decoder = model.Transducer(39, 62, 250, 3, 0.5,bidirectional=False)\r\n    train_obj = DistributedTrain(10, decoder, batch_size, 8)\r\n\r\n    print ('Training ...')\r\n    return train_obj.training_loop(train_ds, test_ds, strategy)\r\n\r\nif __name__ == '__main__':\r\n  app.run(main)\r\n\r\n\r\n```\r\n\r\nThis is the error.\r\n\r\n```\r\ntrain_timit_distributed.py:97 distributed_train  *\r\n        per_example_loss = strategy.experimental_run_v2(self.train_step((inp, targ, xlen, ylen)))\r\n    train_timit_distributed.py:61 train_step  *\r\n        gradients = tape.gradient(loss, variables)\r\n    /home/ubuntu/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/backprop.py:996 gradient\r\n        flat_sources = [_handle_or_self(x) for x in flat_sources]\r\n    /home/ubuntu/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/backprop.py:996 <listcomp>\r\n        flat_sources = [_handle_or_self(x) for x in flat_sources]\r\n    /home/ubuntu/tf2/lib/python3.6/site-packages/tensorflow_core/python/eager/backprop.py:687 _handle_or_self\r\n        x = x.handle\r\n    /home/ubuntu/tf2/lib/python3.6/site-packages/tensorflow_core/python/distribute/values.py:717 handle\r\n        raise ValueError(\"`handle` is not available outside the replica context\"\r\n\r\n    ValueError: `handle` is not available outside the replica context or a `tf.distribute.Strategy.update()` call.\r\n\r\n```\r\nHow to fix this?", "comments": ["@manish-kumar-garg \r\n\r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Thanks!\r\n\r\n\r\n", "I get the same error trying to create a Resnet50 model with mirrored distribution across 2 GPUs.\r\n \r\nI am training on:\r\n- Ubuntu 18\r\n- Anaconda 2019 Python 3.7\r\n- Tensorflow 2.0\r\n- Keras\r\n\r\n", "`>>> with strategy.scope():\r\n\r\n...     parallel_model =  EAST_model(FLAGS.input_size)\r\n\r\n...\r\n\r\nTraceback (most recent call last):\r\n\r\n  File \"<stdin>\", line 2, in <module>\r\n\r\n  File \"/d/src/pid/EAST/model.py\", line 30, in __init__\r\n    resnet = ResNet50(input_tensor=input_image, weights='imagenet', include_top=False, pooling=None)\r\n  File \"/d/home/aisrv/.conda/envs/aidev/lib/python3.7/site-packages/keras/applications/__init__.py\", line 20, in wrapper\r\n    return base_fun(*args, **kwargs)\r\n  File \"/d/home/aisrv/.conda/envs/aidev/lib/python3.7/site-packages/keras/applications/resnet50.py\", line 11, in ResNet50\r\n    return resnet50.ResNet50(*args, **kwargs)\r\n  File \"/d/home/aisrv/.conda/envs/aidev/lib/python3.7/site-packages/keras_applications/resnet50.py\", line 231, in ResNet50\r\n    x = layers.BatchNormalization(axis=bn_axis, name='bn_conv1')(x)\r\n  File \"/d/home/aisrv/.conda/envs/aidev/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\", line 75, in symbolic_fn_wrapper\r\n    return func(*args, **kwargs)\r\n  File \"/d/home/aisrv/.conda/envs/aidev/lib/python3.7/site-packages/keras/engine/base_layer.py\", line 489, in __call__\r\n    output = self.call(inputs, **kwargs)\r\n  File \"/d/home/aisrv/.conda/envs/aidev/lib/python3.7/site-packages/keras/layers/normalization.py\", line 199, in call\r\n    self.momentum),\r\n  File \"/d/home/aisrv/.conda/envs/aidev/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\", line 75, in symbolic_fn_wrapper\r\n    return func(*args, **kwargs)\r\n  File \"/d/home/aisrv/.conda/envs/aidev/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\", line 1296, in moving_average_update\r\n    with tf_ops.colocate_with(x):\r\n  File \"/d/home/aisrv/.conda/envs/aidev/lib/python3.7/contextlib.py\", line 112, in __enter__\r\n    return next(self.gen)\r\n  File \"/d/home/aisrv/.conda/envs/aidev/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 4220, in _colocate_with_for_gradient\r\n    with self.colocate_with(op, ignore_existing):\r\n  File \"/d/home/aisrv/.conda/envs/aidev/lib/python3.7/contextlib.py\", line 112, in __enter__\r\n    return next(self.gen)\r\n  File \"/d/home/aisrv/.conda/envs/aidev/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 4269, in colocate_with\r\n    op = _op_to_colocate_with(op, self)\r\n  File \"/d/home/aisrv/.conda/envs/aidev/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 6603, in _op_to_colocate_with\r\n    if hasattr(v, \"handle\") and hasattr(v.handle, \"op\") and isinstance(\r\n  File \"/d/home/aisrv/.conda/envs/aidev/lib/python3.7/site-packages/tensorflow_core/python/distribute/values.py\", line 717, in handle\r\n    raise ValueError(\"`handle` is not available outside the replica context\"\r\nValueError: `handle` is not available outside the replica context or a `tf.distribute.Strategy.update()` call.`", "haha\uff0cI also have same problem.\r\n\r\nI am training on:\r\n```\r\nUbuntu 16.04.2\r\nPython 3.7\r\nTensorflow 2.0 (install from the source code)\r\ncuda 9.0\r\ncudnn 7\r\n```\r\n\r\n\r\nmy codes are not able to run training using tf.distribute.Strategy\r\nHowever, it works fine without distribution.\r\nBelow is the error.\r\n\r\n\r\n```python\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 134, in <module>\r\n    train_step(inp, tar, enc_hidden)\r\n  File \"/disk1/lx/conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 457, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/disk1/lx/conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 503, in _call\r\n    self._initialize(args, kwds, add_initializers_to=initializer_map)\r\n  File \"/disk1/lx/conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 408, in _initialize\r\n    *args, **kwds))\r\n  File \"/disk1/lx/conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1848, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/disk1/lx/conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2150, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/disk1/lx/conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2041, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/disk1/lx/conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\", line 915, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/disk1/lx/conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 358, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/disk1/lx/conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\", line 905, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\nValueError: in converted code:\r\n\r\n    main.py:90 train_step  *\r\n        gradients = tape.gradient(loss, variables)\r\n    /disk1/lx/conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py:996 gradient\r\n        flat_sources = [_handle_or_self(x) for x in flat_sources]\r\n    /disk1/lx/conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py:996 <listcomp>\r\n        flat_sources = [_handle_or_self(x) for x in flat_sources]\r\n    /disk1/lx/conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/backprop.py:687 _handle_or_self\r\n        x = x.handle\r\n    /disk1/lx/conda/envs/tf2/lib/python3.7/site-packages/tensorflow_core/python/distribute/values.py:717 handle\r\n        raise ValueError(\"`handle` is not available outside the replica context\"\r\n\r\n    ValueError: `handle` is not available outside the replica context or a `tf.distribute.Strategy.update()` call.\r\n```\r\n\r\nand if my code works without distribution, the gpu:0 used 11000MB, the gpu:1 used 128Mb.\r\n", "manish-kumar-garg@ Is this the complete stack trace? Does the failure happen at the `tape.gradient` call? Can you also provide a smaller reproducible snippet which will help in debugging?", "It looks like the issue is how you are using `experimental_run_v2`. Can you specify the args argument like this:\r\n`return strategy.experimental_run_v2(self.train_step, args=((inp, targ, xlen, ylen)))`", "@SmileTM  I could not find the `experimental_run_v2` call in the repo above. Can you point me to that?", "> @SmileTM I could not find the `experimental_run_v2` call in the repo above. Can you point me to that?\r\n\r\n\ud83d\ude2foh\uff0c thank you. \r\n I thought it was as simple as keras,  just add two lines of code.\r\nI have rebuilt my code\uff0c it works well in two GPU  .\r\nthank you.", "I get the same error with 4 lines of code\r\n\r\n```\r\nimport sys\r\nprint(sys.version)\r\n# 3.6.9 (default, Nov  7 2019, 10:44:02) \r\n# [GCC 8.3.0]\r\n\r\nimport tensorflow \r\n\r\n\r\nprint(f\"version = {tensorflow.__version__}\")\r\n# version = 2.1.0-rc2\r\n\r\n# Crop of real program, just to show it does not crash.\r\n# Real program has much more, and fully works with a single gpu\r\ninput_data = tensorflow.keras.layers.Input(name=\"input\", shape=(256, 64, 1))\r\n\r\ncnn = tensorflow.keras.layers.Conv2D(filters=16, kernel_size=(3,3), strides=(2,2), padding=\"same\", kernel_initializer=\"he_uniform\")(input_data)\r\ncnn = tensorflow.keras.layers.PReLU(shared_axes=[1,2])(cnn)\r\ncnn = tensorflow.keras.layers.BatchNormalization(renorm=True)(cnn)\r\n\r\nprint(f\"Everything good up to here, shape={cnn.shape}\")\r\n# Everything good up to here, shape=(None, 128, 32, 16)\r\n\r\n\r\n################################################################\r\n# same code inside MirroredStrategy crashes\r\nstrategy = tensorflow.distribute.MirroredStrategy()\r\nwith strategy.scope():\r\n\r\n    input_data = tensorflow.keras.layers.Input(name=\"input\", shape=(256, 64, 1))\r\n\r\n    cnn = tensorflow.keras.layers.Conv2D(filters=16, kernel_size=(3,3), strides=(2,2), padding=\"same\", kernel_initializer=\"he_uniform\")(input_data)\r\n    cnn = tensorflow.keras.layers.PReLU(shared_axes=[1,2])(cnn)\r\n    cnn = tensorflow.keras.layers.BatchNormalization(renorm=True)(cnn)\r\n\r\n    print(\"crash in step above\")\r\n```\r\nMy environment is docker. Nothing special, but just in case here is my Dockerfile:\r\n\r\n```\r\nFROM tensorflow/tensorflow:2.1.0rc2-gpu-py3-jupyter\r\n\r\nRUN pip3 install ptvsd\r\n\r\n# see bug tensorflow/tensorflow #35434 \r\nARG CUDA=10.1\r\nRUN apt-get update && apt-get install -y --no-install-recommends --allow-downgrades \\\r\n        cuda-nvrtc-${CUDA/./-} \\\r\n        cuda-nvrtc-dev-${CUDA/./-} \\\r\n        libcublas10=10.2.1.243-1 \\ \r\n        libcublas-dev=10.2.1.243-1 \r\n\r\n# kludge in main.py needs to be looked at\r\n# when driver changes. Search for \r\n# https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth\r\n\r\n# Stuff needed for the ocr app\r\nRUN pip install autopep8==1.4.4\r\nRUN pip install editdistance==0.5.3\r\nRUN pip install flake8==3.7.9\r\nRUN pip install kaldiio==2.15.0\r\nRUN pip install numba==0.46.0\r\nRUN [\"apt-get\", \"install\", \"-y\", \"libsm6\", \"libxext6\", \"libxrender-dev\"]\r\nRUN pip install opencv-python==4.1.2.30\r\n\r\nRUN apt-get update\r\n\r\n# for the visual debugger\r\nRUN pip3 install ptvsd\r\n\r\n# A place for tensorboard logs. Not using presently.\r\nRUN mkdir /tmp/logs\r\n\r\n# replicate the tensorflow/tensorflow launch command\r\nCMD [\"bash\", \"-c\", \"source /etc/bash.bashrc && jupyter notebook --NotebookApp.iopub_data_rate_limit=1000000000000 --notebook-dir=/tf --ip 0.0.0.0 --no-browser --allow-root\"]\r\n\r\n```\r\nI don't understand the solution SmileTM is referring to. Can someone elaborate?\r\n\r\n", "> I get the same error with 4 lines of code\r\n> \r\n> ```\r\n> import sys\r\n> print(sys.version)\r\n> # 3.6.9 (default, Nov  7 2019, 10:44:02) \r\n> # [GCC 8.3.0]\r\n> \r\n> import tensorflow \r\n> \r\n> \r\n> print(f\"version = {tensorflow.__version__}\")\r\n> # version = 2.1.0-rc2\r\n> \r\n> # Crop of real program, just to show it does not crash.\r\n> # Real program has much more, and fully works with a single gpu\r\n> input_data = tensorflow.keras.layers.Input(name=\"input\", shape=(256, 64, 1))\r\n> \r\n> cnn = tensorflow.keras.layers.Conv2D(filters=16, kernel_size=(3,3), strides=(2,2), padding=\"same\", kernel_initializer=\"he_uniform\")(input_data)\r\n> cnn = tensorflow.keras.layers.PReLU(shared_axes=[1,2])(cnn)\r\n> cnn = tensorflow.keras.layers.BatchNormalization(renorm=True)(cnn)\r\n> \r\n> print(f\"Everything good up to here, shape={cnn.shape}\")\r\n> # Everything good up to here, shape=(None, 128, 32, 16)\r\n> \r\n> \r\n> ################################################################\r\n> # same code inside MirroredStrategy crashes\r\n> strategy = tensorflow.distribute.MirroredStrategy()\r\n> with strategy.scope():\r\n> \r\n>     input_data = tensorflow.keras.layers.Input(name=\"input\", shape=(256, 64, 1))\r\n> \r\n>     cnn = tensorflow.keras.layers.Conv2D(filters=16, kernel_size=(3,3), strides=(2,2), padding=\"same\", kernel_initializer=\"he_uniform\")(input_data)\r\n>     cnn = tensorflow.keras.layers.PReLU(shared_axes=[1,2])(cnn)\r\n>     cnn = tensorflow.keras.layers.BatchNormalization(renorm=True)(cnn)\r\n> \r\n>     print(\"crash in step above\")\r\n> ```\r\n> \r\n> My environment is docker. Nothing special, but just in case here is my Dockerfile:\r\n> \r\n> ```\r\n> FROM tensorflow/tensorflow:2.1.0rc2-gpu-py3-jupyter\r\n> \r\n> RUN pip3 install ptvsd\r\n> \r\n> # see bug tensorflow/tensorflow #35434 \r\n> ARG CUDA=10.1\r\n> RUN apt-get update && apt-get install -y --no-install-recommends --allow-downgrades \\\r\n>         cuda-nvrtc-${CUDA/./-} \\\r\n>         cuda-nvrtc-dev-${CUDA/./-} \\\r\n>         libcublas10=10.2.1.243-1 \\ \r\n>         libcublas-dev=10.2.1.243-1 \r\n> \r\n> # kludge in main.py needs to be looked at\r\n> # when driver changes. Search for \r\n> # https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth\r\n> \r\n> # Stuff needed for the ocr app\r\n> RUN pip install autopep8==1.4.4\r\n> RUN pip install editdistance==0.5.3\r\n> RUN pip install flake8==3.7.9\r\n> RUN pip install kaldiio==2.15.0\r\n> RUN pip install numba==0.46.0\r\n> RUN [\"apt-get\", \"install\", \"-y\", \"libsm6\", \"libxext6\", \"libxrender-dev\"]\r\n> RUN pip install opencv-python==4.1.2.30\r\n> \r\n> RUN apt-get update\r\n> \r\n> # for the visual debugger\r\n> RUN pip3 install ptvsd\r\n> \r\n> # A place for tensorboard logs. Not using presently.\r\n> RUN mkdir /tmp/logs\r\n> \r\n> # replicate the tensorflow/tensorflow launch command\r\n> CMD [\"bash\", \"-c\", \"source /etc/bash.bashrc && jupyter notebook --NotebookApp.iopub_data_rate_limit=1000000000000 --notebook-dir=/tf --ip 0.0.0.0 --no-browser --allow-root\"]\r\n> ```\r\n> \r\n> I don't understand the solution SmileTM is referring to. Can someone elaborate?\r\n\r\n@johngrabner \r\nI think you should remove renorm=True. \r\nMaybe,  renorm=True will have some conflicts  in GPU distribute.\r\n\r\n```python\r\ncnn = tensorflow.keras.layers.BatchNormalization(renorm=True)(cnn)\r\n```\r\nchange to\r\n```python\r\ncnn = tensorflow.keras.layers.BatchNormalization()(cnn)\r\n```", "@manish-kumar-garg Passing experimental_run_v2 arguments using the args tuple should fix the issue. Please reopen if the suggested solution does not work.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35226\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35226\">No</a>\n", "Sorry, I don't understand \"Passing experimental_run_v2 arguments using the args tuple\"\r\n\r\nHow do I modify this code to use your suggestion?\r\n\r\n```\r\nstrategy = tensorflow.distribute.MirroredStrategy()\r\nwith strategy.scope():\r\n\r\n    input_data = tensorflow.keras.layers.Input(name=\"input\", shape=(256, 64, 1))\r\n\r\n    cnn = tensorflow.keras.layers.Conv2D(filters=16, kernel_size=(3,3), strides=(2,2), padding=\"same\", kernel_initializer=\"he_uniform\")(input_data)\r\n    cnn = tensorflow.keras.layers.PReLU(shared_axes=[1,2])(cnn)\r\n    cnn = tensorflow.keras.layers.BatchNormalization(renorm=True)(cnn)\r\n\r\n    print(\"crash in step above\")\r\n```", "Same here, can someone  elaborate the solution further?", "Same here...", "@johngrabner you might be interested in this https://github.com/tensorflow/tensorflow/issues/31531.\r\n\r\nand for @ElPapi42 & @fzyzcjy the doco is here https://www.tensorflow.org/api_docs/python/tf/distribute/Strategy#experimental_run_v2 and its referenced because the original issue is raised around use of this API. ", "Has there been any update on this?", "I'm having the same issue. Perhaps there is something with using BatchNormalization in the strategy scope. If you remove this normalization layer, the training goes well....", "I'm also having the same issue. I have a U-Net architecture with multiple BatchNormalization layers, but whenever I remove this layer the problem no longer exists.\r\nA code snippet is something like this:\r\n`pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)`\r\n`renorm=True` is not included!\r\nHow to fix it?", "> I'm having the same issue. Perhaps there is something with using BatchNormalization in the strategy scope. If you remove this normalization layer, the training goes well....\r\n\r\nDid you find a solution to this problem without removing the BatchNormalization  layers? \r\n@samcaetano ", "> > I'm having the same issue. Perhaps there is something with using BatchNormalization in the strategy scope. If you remove this normalization layer, the training goes well....\r\n> \r\n> Did you find a solution to this problem without removing the BatchNormalization layers?\r\n> @samcaetano\r\n\r\nI couldn't find a solution for that. I really didn't understand this bug. By now, I'm running the same model with the strategy scope on cpu, WITH batchNormalization, and the model doesn't complain about this ValueError no longer.\r\n\r\nI still have something in mind which is: maybe the strategy scope on gpu has problem on normalizing the batches.\r\n\r\nBut actually, I am not sure.", "Same issue here. How shall we reopen the issue?  @anj-s ", "some isshe +1...  how to solve it?", "@marchss @Zepan Is this still an issue with latest TF version (2.4.1)? Can you please post a new issue thread with minimal code to reproduce?  This thread is relatively old and the original author has not responded. Thanks!", "I just ran into this exact issue as well any answers? Batch Normalization layer within strategy scope seems to be the issue. any Ideas or fixes?", "I'm also facing the same error. Could you please look into my code snippet and help to figure out the problem?\r\n\r\n```\r\nimport tensorflow.compat.v1 as tf\r\ntf.disable_v2_behavior()\r\nimport numpy as np\r\nimport gym\r\nfrom gym import wrappers\r\nimport tflearn\r\nimport argparse\r\nimport pprint as pp\r\nfrom replay_buffer import ReplayBuffer\r\n\r\n\r\nclass ActorNetwork(object):\r\n    def __init__(self, sess, state_dim, action_dim, action_bound, learning_rate, tau, batch_size):\r\n        self.sess = sess\r\n        self.s_dim = state_dim\r\n        self.a_dim = action_dim\r\n        self.action_bound = action_bound\r\n        self.learning_rate = learning_rate\r\n        self.tau = tau\r\n        self.batch_size = batch_size\r\n\r\n        # Actor Network\r\n        self.inputs, self.out, self.scaled_out = self.create_actor_network()\r\n\r\n        self.network_params = tf.trainable_variables()\r\n\r\n        # Target Network\r\n        self.target_inputs, self.target_out, self.target_scaled_out = self.create_actor_network()\r\n\r\n        self.target_network_params = tf.trainable_variables()[\r\n            len(self.network_params):]\r\n\r\n        # Op for periodically updating target network with online network\r\n        # weights\r\n        self.update_target_network_params = \\\r\n            [self.target_network_params[i].assign(tf.multiply(self.network_params[i], self.tau) +\r\n                                                  tf.multiply(self.target_network_params[i], 1. - self.tau))\r\n                for i in range(len(self.target_network_params))]\r\n\r\n        # This gradient will be provided by the critic network\r\n        self.action_gradient = tf.placeholder(tf.float32, [None, self.a_dim])\r\n\r\n        # Combine the gradients here\r\n        self.unnormalized_actor_gradients = tf.gradients(\r\n            self.scaled_out, self.network_params, -self.action_gradient)\r\n        self.actor_gradients = list(map(lambda x: tf.div(x, self.batch_size), self.unnormalized_actor_gradients))\r\n\r\n        # Optimization Op\r\n        self.optimize = tf.train.AdamOptimizer(self.learning_rate).\\\r\n            apply_gradients(zip(self.actor_gradients, self.network_params))\r\n\r\n        self.num_trainable_vars = len(\r\n            self.network_params) + len(self.target_network_params)\r\n\r\n    def create_actor_network(self):\r\n        inputs = tflearn.input_data(shape=[None, self.s_dim])\r\n        net = tf.keras.layers.Dense(400)(inputs)\r\n        net = tf.keras.layers.BatchNormalization()(net)\r\n        net = tf.keras.layers.ReLU()(net)\r\n        net = tf.keras.layers.Dense(300)(net)\r\n        net = tf.keras.layers.BatchNormalization()(net)\r\n        net = tf.keras.layers.ReLU()(net)\r\n        # Final layer weights are init to Uniform[-3e-3, 3e-3]\r\n        w_init = tf.keras.initializers.RandomUniform(minval=-0.003, maxval=0.003)\r\n        out = tf.keras.layers.Dense(self.a_dim, activation='linear', kernel_initializer=w_init)(net)\r\n        # Scale output to -action_bound to action_bound\r\n        scaled_out = tf.multiply(out, self.action_bound)\r\n        return inputs, out, scaled_out\r\n\r\n    def train(self, inputs, a_gradient):\r\n        self.sess.run(self.optimize, feed_dict={\r\n            self.inputs: inputs,\r\n            self.action_gradient: a_gradient\r\n        })\r\n\r\n    def predict(self, inputs):\r\n        return self.sess.run(self.scaled_out, feed_dict={\r\n            self.inputs: inputs\r\n        })\r\n\r\n    def predict_target(self, inputs):\r\n        return self.sess.run(self.target_scaled_out, feed_dict={\r\n            self.target_inputs: inputs\r\n        })\r\n\r\n    def update_target_network(self):\r\n        self.sess.run(self.update_target_network_params)\r\n\r\n    def get_num_trainable_vars(self):\r\n        return self.num_trainable_vars\r\n\r\nclass CriticNetwork(object):\r\n    def __init__(self, sess, state_dim, action_dim, learning_rate, tau, gamma, num_actor_vars):\r\n        self.sess = sess\r\n        self.s_dim = state_dim\r\n        self.a_dim = action_dim\r\n        self.learning_rate = learning_rate\r\n        self.tau = tau\r\n        self.gamma = gamma\r\n\r\n        # Create the critic network\r\n        self.inputs, self.action, self.out = self.create_critic_network()\r\n\r\n        self.network_params = tf.trainable_variables()[num_actor_vars:]\r\n\r\n        # Target Network\r\n        self.target_inputs, self.target_action, self.target_out = self.create_critic_network()\r\n\r\n        self.target_network_params = tf.trainable_variables()[(len(self.network_params) + num_actor_vars):]\r\n\r\n        # Op for periodically updating target network with online network\r\n        # weights with regularization\r\n        self.update_target_network_params = \\\r\n            [self.target_network_params[i].assign(tf.multiply(self.network_params[i], self.tau) \\\r\n            + tf.multiply(self.target_network_params[i], 1. - self.tau))\r\n                for i in range(len(self.target_network_params))]\r\n\r\n        # Network target (y_i)\r\n        self.predicted_q_value = tf.placeholder(tf.float32, [None, 1])\r\n\r\n        # Define loss and optimization Op\r\n        self.loss = tflearn.mean_square(self.predicted_q_value, self.out)\r\n        self.optimize = tf.train.AdamOptimizer(\r\n            self.learning_rate).minimize(self.loss)\r\n\r\n        # Get the gradient of the net w.r.t. the action.\r\n        # For each action in the minibatch (i.e., for each x in xs),\r\n        # this will sum up the gradients of each critic output in the minibatch\r\n        # w.r.t. that action. Each output is independent of all\r\n        # actions except for one.\r\n        self.action_grads = tf.gradients(self.out, self.action)\r\n\r\n\r\n    def create_critic_network(self):\r\n        inputs = tflearn.input_data(shape=[None, self.s_dim])\r\n        action = tflearn.input_data(shape=[None, self.a_dim])\r\n        net = tf.keras.layers.Dense(400)(inputs)\r\n        net = tf.keras.layers.BatchNormalization()(net)\r\n        net = tf.keras.layers.ReLU()(net)\r\n        # Add the action tensor in the 2nd hidden layer\r\n        # Use two temp layers to get the corresponding weights and biases\r\n        #t1 = tflearn.fully_connected(net, 300)\r\n        #t2 = tflearn.fully_connected(action, 300)\r\n\r\n        #net = tflearn.activation(\r\n         #   tf.matmul(net, t1.W) + tf.matmul(action, t2.W) + t2.b, activation='relu')\r\n\r\n        # linear layer connected to 1 output representing Q(s,a)\r\n        # Weights are init to Uniform[-3e-3, 3e-3]\r\n        w_init = tf.keras.initializers.RandomUniform(minval=-0.003, maxval=0.003)\r\n        out = out = tf.keras.layers.Dense(1, kernel_initializer=w_init)(net)\r\n        return inputs, action, out\r\n\r\n    def train(self, inputs, action, predicted_q_value):\r\n        return self.sess.run([self.out, self.optimize], feed_dict={\r\n            self.inputs: inputs,\r\n            self.action: action,\r\n            self.predicted_q_value: predicted_q_value\r\n        })\r\n\r\n    def predict(self, inputs, action):\r\n        return self.sess.run(self.out, feed_dict={\r\n            self.inputs: inputs,\r\n            self.action: action\r\n        })\r\n\r\n    def predict_target(self, inputs, action):\r\n        return self.sess.run(self.target_out, feed_dict={\r\n            self.target_inputs: inputs,\r\n            self.target_action: action\r\n        })\r\n\r\n    def action_gradients(self, inputs, actions):\r\n        return self.sess.run(self.action_grads, feed_dict={\r\n            self.inputs: inputs,\r\n            self.action: actions\r\n        })\r\n\r\n    def update_target_network(self):\r\n        self.sess.run(self.update_target_network_params)\r\n\r\nclass OrnsteinUhlenbeckActionNoise:\r\n    def __init__(self, mu, sigma=0.3, theta=.15, dt=1e-2, x0=None):\r\n        self.theta = theta\r\n        self.mu = mu\r\n        self.sigma = sigma\r\n        self.dt = dt\r\n        self.x0 = x0\r\n        self.reset()\r\n\r\n    def __call__(self):\r\n        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + \\\r\n                self.sigma * np.sqrt(self.dt) * np.random.normal(size=self.mu.shape)\r\n        self.x_prev = x\r\n        return x\r\n\r\n    def reset(self):\r\n        self.x_prev = self.x0 if self.x0 is not None else np.zeros_like(self.mu)\r\n\r\n    def __repr__(self):\r\n        return 'OrnsteinUhlenbeckActionNoise(mu={}, sigma={})'.format(self.mu, self.sigma)\r\n\r\n\r\n\r\ndef build_summaries():\r\n    episode_reward = tf.Variable(0.)\r\n    tf.summary.scalar(\"Reward\", episode_reward)\r\n    episode_ave_max_q = tf.Variable(0.)\r\n    tf.summary.scalar(\"Qmax Value\", episode_ave_max_q)\r\n\r\n    summary_vars = [episode_reward, episode_ave_max_q]\r\n    summary_ops = tf.summary.merge_all()\r\n\r\n    return summary_ops, summary_vars\r\n\r\n\r\ndef train(sess, env, args, actor, critic, actor_noise):\r\n\r\n    # Set up summary Ops\r\n    summary_ops, summary_vars = build_summaries()\r\n\r\n    sess.run(tf.global_variables_initializer())\r\n    writer = tf.summary.FileWriter(args['summary_dir'], sess.graph)\r\n\r\n    # Initialize target network weights\r\n    actor.update_target_network()\r\n    critic.update_target_network()\r\n\r\n    # Initialize replay memory\r\n    replay_buffer = ReplayBuffer(int(args['buffer_size']), int(args['random_seed']))\r\n\r\n    # Needed to enable BatchNorm. \r\n    # This hurts the performance on Pendulum but could be useful\r\n    # in other environments.\r\n    # tflearn.is_training(True)\r\n\r\n    for i in range(int(args['max_episodes'])):\r\n\r\n        s = env.reset()\r\n\r\n        ep_reward = 0\r\n        ep_ave_max_q = 0\r\n\r\n        for j in range(int(args['max_episode_len'])):\r\n\r\n            if args['render_env']:\r\n                env.render()\r\n\r\n            # Added exploration noise\r\n            #a = actor.predict(np.reshape(s, (1, 3))) + (1. / (1. + i))\r\n            a = actor.predict(np.reshape(s, (1, actor.s_dim))) + actor_noise()\r\n\r\n            s2, r, terminal, info = env.step(a[0])\r\n\r\n            replay_buffer.add(np.reshape(s, (actor.s_dim,)), np.reshape(a, (actor.a_dim,)), r,\r\n                              terminal, np.reshape(s2, (actor.s_dim,)))\r\n\r\n            # Keep adding experience to the memory until\r\n            # there are at least minibatch size samples\r\n            if replay_buffer.size() > int(args['minibatch_size']):\r\n                s_batch, a_batch, r_batch, t_batch, s2_batch = \\\r\n                    replay_buffer.sample_batch(int(args['minibatch_size']))\r\n\r\n\r\n                # Calculate targets\r\n                target_q = critic.predict_target(\r\n                    s2_batch, actor.predict_target(s2_batch))\r\n\r\n                y_i = []\r\n                for k in range(int(args['minibatch_size'])):\r\n                    if t_batch[k]:\r\n                        y_i.append(r_batch[k])\r\n                    else:\r\n                        y_i.append(r_batch[k] + critic.gamma * target_q[k])\r\n\r\n                # Update the critic given the targets\r\n                predicted_q_value, _ = critic.train(\r\n                    s_batch, a_batch, np.reshape(y_i, (int(args['minibatch_size']), 1)))\r\n\r\n                ep_ave_max_q += np.amax(predicted_q_value)\r\n\r\n                # Update the actor policy using the sampled gradient\r\n                a_outs = actor.predict(s_batch)\r\n                grads = critic.action_gradients(s_batch, a_outs)\r\n                actor.train(s_batch, grads[0])\r\n\r\n                # Update target networks\r\n                actor.update_target_network()\r\n                critic.update_target_network()\r\n\r\n            s = s2\r\n            ep_reward += r\r\n\r\n            if terminal:\r\n\r\n                summary_str = sess.run(summary_ops, feed_dict={\r\n                    summary_vars[0]: ep_reward,\r\n                    summary_vars[1]: ep_ave_max_q / float(j)\r\n                })\r\n\r\n                writer.add_summary(summary_str, i)\r\n                writer.flush()\r\n\r\n                print('| Reward: {:d} | Episode: {:d} | Qmax: {:.4f}'.format(int(ep_reward), \\\r\n                        i, (ep_ave_max_q / float(j))))\r\n                break\r\n\r\ndef main(args):\r\n\r\n    device_type = 'GPU'\r\n    devices = tf.config.experimental.list_physical_devices(device_type)\r\n    devices_names = [d.name.split(\"e:\")[1] for d in devices]\r\n    strategy = tf.distribute.MirroredStrategy(devices=devices_names[:int(args['ngpus'])])\r\n\r\n    with strategy.scope():\r\n        with tf.Session() as sess:\r\n\r\n            env = gym.make(args['env'])\r\n            np.random.seed(int(args['random_seed']))\r\n            tf.set_random_seed(int(args['random_seed']))\r\n            env.seed(int(args['random_seed']))\r\n\r\n            state_dim = env.observation_space.shape[0]\r\n            action_dim = env.action_space.shape[0]\r\n            action_bound = env.action_space.high\r\n            # Ensure action bound is symmetric\r\n            assert (env.action_space.high == -env.action_space.low)\r\n\r\n            actor = ActorNetwork(sess, state_dim, action_dim, action_bound,\r\n                             float(args['actor_lr']), float(args['tau']),\r\n                             int(args['minibatch_size']))\r\n\r\n            critic = CriticNetwork(sess, state_dim, action_dim,\r\n                               float(args['critic_lr']), float(args['tau']),\r\n                               float(args['gamma']),\r\n                               actor.get_num_trainable_vars())\r\n\r\n            actor_noise = OrnsteinUhlenbeckActionNoise(mu=np.zeros(action_dim))\r\n\r\n            if args['use_gym_monitor']:\r\n                if not args['render_env']:\r\n                    env = wrappers.Monitor(\r\n                        env, args['monitor_dir'], video_callable=False, force=True)\r\n                else:\r\n                    env = wrappers.Monitor(env, args['monitor_dir'], force=True)\r\n\r\n            train(sess, env, args, actor, critic, actor_noise)\r\n\r\n            if args['use_gym_monitor']:\r\n                env.monitor.close()\r\n\r\nif __name__ == '__main__':\r\n    parser = argparse.ArgumentParser(description='provide arguments for DDPG agent')\r\n\r\n    # agent parameters\r\n    parser.add_argument('--actor-lr', help='actor network learning rate', default=0.0001)\r\n    parser.add_argument('--critic-lr', help='critic network learning rate', default=0.001)\r\n    parser.add_argument('--gamma', help='discount factor for critic updates', default=0.99)\r\n    parser.add_argument('--tau', help='soft target update parameter', default=0.001)\r\n    parser.add_argument('--buffer-size', help='max size of the replay buffer', default=1000000)\r\n    parser.add_argument('--minibatch-size', help='size of minibatch for minibatch-SGD', default=64)\r\n    parser.add_argument('--ngpus', help='Number of GPUs', default=2)\r\n\r\n    # run parameters\r\n    parser.add_argument('--env', help='choose the gym env- tested on {Pendulum-v0}', default='Pendulum-v1')\r\n    parser.add_argument('--random-seed', help='random seed for repeatability', default=1234)\r\n    parser.add_argument('--max-episodes', help='max num of episodes to do while training', default=50000)\r\n    parser.add_argument('--max-episode-len', help='max length of 1 episode', default=1000)\r\n    parser.add_argument('--render-env', help='render the gym env', action='store_true')\r\n    parser.add_argument('--use-gym-monitor', help='record gym results', action='store_true')\r\n    parser.add_argument('--monitor-dir', help='directory for storing gym results', default='./results/gym_ddpg')\r\n    parser.add_argument('--summary-dir', help='directory for storing tensorboard info', default='./results/tf_ddpg')\r\n\r\n    parser.set_defaults(render_env=False)\r\n    parser.set_defaults(use_gym_monitor=True)\r\n\r\n    args = vars(parser.parse_args())\r\n\r\n    pp.pprint(args)\r\n\r\n    main(args)\r\n```\r\n\r\n\r\nOUTPUT:\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nnon-resource variables are not supported in the long term\r\nScipy not supported!\r\n{'actor_lr': 0.0001,\r\n 'buffer_size': 1000000,\r\n 'critic_lr': 0.001,\r\n 'env': 'Pendulum-v1',\r\n 'gamma': 0.99,\r\n 'max_episode_len': 1000,\r\n 'max_episodes': 50000,\r\n 'minibatch_size': 64,\r\n 'monitor_dir': './results/gym_ddpg',\r\n 'ngpus': 2,\r\n 'random_seed': 1234,\r\n 'render_env': False,\r\n 'summary_dir': './results/tf_ddpg',\r\n 'tau': 0.001,\r\n 'use_gym_monitor': True}\r\n2022-04-11 19:58:20.286219: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions\r\nin performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2022-04-11 19:58:21.117294: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:0 with 10795 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:04:00.0, compute capability: 3.7\r\n2022-04-11 19:58:21.118538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /device:GPU:1 with 10795 MB memory:  -> device: 1, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7\r\n2022-04-11 19:58:21.136084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 10795 MB memory:  -> device: 0, name: Tesla K80, pci bus id: 0000:04:00.0, compute capability: 3.7\r\n2022-04-11 19:58:21.137010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 10795 MB memory:  -> device: 1, name: Tesla K80, pci bus id: 0000:05:00.0, compute capability: 3.7\r\nWARNING:tensorflow:From ddpg.py:77: The name tf.keras.initializers.RandomUniform is deprecated. Please use tf.compat.v1.keras.initializers.RandomUniform instead.\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/keras/initializers/initializers_v1.py:277: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and\r\nwill be removed in a future version.\r\nInstructions for updating:\r\nCall initializer instance with the dtype argument instead of passing it to the constructor\r\nTraceback (most recent call last):\r\n  File \"ddpg.py\", line 406, in <module>\r\n    main(args)\r\n  File \"ddpg.py\", line 354, in main\r\n    actor = ActorNetwork(sess, state_dim, action_dim, action_bound,\r\n  File \"ddpg.py\", line 57, in __init__\r\n    self.unnormalized_actor_gradients = tf.gradients(\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gradients_impl.py\", line 165, in gradients\r\n    return gradients_util._GradientsHelper(\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gradients_util.py\", line 516, in _GradientsHelper\r\n    xs = [\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/ops/gradients_util.py\", line 517, in <listcomp>\r\n    x.handle if resource_variable_ops.is_resource_variable(x) else x\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/distribute/values.py\", line 698, in handle\r\n    raise ValueError(\r\nValueError: DistributedVariable.handle is not available outside the replica context or a `tf.distribute.Strategy.update()` call.\r\n\r\n\r\n\r\n\r\n\r\nNote that I also tried running it without BatchNormalization, however, it did not work for me. Any help will be greatly appreciated. Thanks\r\n"]}, {"number": 35225, "title": " how to inference online with tensorflow2.0? #24 ", "body": "i am trying to inference online with tensorflow2.0. my code is as follows:\r\n\r\n>         self.graph = tf.Graph()\r\n> \r\n>         with self.graph.as_default() as g:\r\n>             self.input_ids = tf.compat.v1.placeholder(tf.int32, [FLAGS.batch_size,\r\n>                                                                  FLAGS.max_seq_length], name=\"input_ids\")\r\n>             self.input_mask = tf.compat.v1.placeholder(tf.int32, [FLAGS.batch_size,\r\n>                                                                   FLAGS.max_seq_length], name=\"input_mask\")\r\n>             self.p_mask = tf.compat.v1.placeholder(tf.float32, [FLAGS.batch_size,\r\n>                                                                 FLAGS.max_seq_length], name=\"p_mask\")\r\n>             self.segment_ids = tf.compat.v1.placeholder(tf.int32, [FLAGS.batch_size,\r\n>                                                                    FLAGS.max_seq_length], name=\"segment_ids\")\r\n>             self.cls_index = tf.compat.v1.placeholder(tf.int32, [FLAGS.batch_size], name=\"segment_ids\")\r\n>             self.unique_ids = tf.compat.v1.placeholder(tf.int32, [FLAGS.batch_size], name=\"unique_ids\")\r\n> \r\n>             # unpacked_inputs = tf_utils.unpack_inputs(inputs)\r\n>             self.squad_model = ALBertQAModel(\r\n>                 albert_config, FLAGS.max_seq_length, init_checkpoint, FLAGS.start_n_top, FLAGS.end_n_top,\r\n>                 FLAGS.squad_dropout)\r\n> \r\n>             learning_rate_fn = tf.keras.optimizers.schedules.PolynomialDecay(initial_learning_rate=1e-5,\r\n>                                                                              decay_steps=10000,\r\n>                                                                              end_learning_rate=0.0)\r\n>             optimizer_fn = AdamWeightDecay\r\n>             optimizer = optimizer_fn(\r\n>                 learning_rate=learning_rate_fn,\r\n>                 weight_decay_rate=0.01,\r\n>                 beta_1=0.9,\r\n>                 beta_2=0.999,\r\n>                 epsilon=1e-6,\r\n>                 exclude_from_weight_decay=['layer_norm', 'bias'])\r\n> \r\n>             self.squad_model.optimizer = optimizer\r\n>             graph_init_op = tf.compat.v1.global_variables_initializer()\r\n> \r\n>             y = self.squad_model(\r\n>                 self.unique_ids, self.input_ids, self.input_mask, self.segment_ids, self.cls_index,\r\n>                 self.p_mask, training=False)\r\n>             self.unique_ids, self.start_tlp, self.start_ti, self.end_tlp, self.end_ti, self.cls_logits = y\r\n> \r\n>             self.sess = tf.compat.v1.Session(graph=self.graph, config=gpu_config)\r\n>             self.sess.run(graph_init_op)\r\n>             with self.sess.as_default() as sess:\r\n>                 self.squad_model.load_weights(FLAGS.model_dir)\r\n\r\n\r\nThis code is executable, but it runs bad result. It looks like the parameters are unloaded.I guess this is probably because I'm not using tf.Session to set default parameters on the model, such as' saver.restore(sess, tf.train. Latest_checkpoint (init_checkpoint)) '.\r\nI've tried several ways to do this, but it hasn't worked.And there are very few examples of online inferencing using tensorflow2.0 on the Internet, and I have trouble finding a solution.  :((((\r\nMay i get some help here, thx very much!!", "comments": ["@freefuiiismyname ,\r\nHi,code looks incomplete can you please provide complete being used to reproduce the error reported?Thanks!", "@oanush \r\nsimilar to https://github.com/cdathuraliya/bert-inference", "@freefuiiismyname Please post this issue is in stack overflow as it is not related to build/install, bug/performance, feature request or doc related issues. Thanks!"]}, {"number": 35224, "title": "Sparse Feature in c++, different shape cause different result", "body": "HI :\r\n     I was using c++ api of tensorflow-1.14.0 and found a problem.\r\n     I had a model in pb format and loaded it use c++. The model had a sparse node, so I construct indices, values shape for it.\r\n     Three tensor name for a sparse node:\r\n     DeserializeSparse:0  for indices,\r\n     DeserializeSparse:1   for values,\r\n     DeserializeSparse:2  for shape,\r\n\r\n    case 1:\r\n    shape = [1, 1];  indices = [0, 0]; values = [\"\"]  c++ got a predict result was same as python's result .\r\n    case 2:\r\n    shape = [1, 1];  indices = [0, 0]; values = [\"abc\"] c++ got a predict result  was different from python's.\r\n    case 3:\r\n    shape = [1, 100] indices = [0, 0]; values = [\"abc\"] c++ got a predict result was different from case 2.\r\n    \r\n    I found python always got the same answer with different shape but with the same indices and values.\r\n    I thought, there may be some difference between c++ and python, and may be c++ is wrong.\r\n  ", "comments": ["After many tests, I found that:I must append an empty string into values(the tail of vector), then c++ predict result was same as python's.  Why?", "commit:  tensorflow 1.15 also  has this problem.", "Can you provide some code that reproduces the buggy behavior? I can't really follow the textual description in the bug.", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 35223, "title": "Fix a typo in tflite_inference_stage", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F35223) for more info**.\n\n<!-- need_sender_cla -->", "@tigert1998 thank you for your contribution, please sign CLA.", "@googlebot I signed it!", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F35223) for more info**.\n\n<!-- ok -->"]}, {"number": 35222, "title": "imp.py", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**:\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with:\r\n\r\n```bash\r\npython -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\n```\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["Please reopen filling in the template, if you have a real issue with using TF."]}, {"number": 35221, "title": "Crash on Hexagon Delegate", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Mi A2, Pixel3\r\n- TensorFlow version (use command below): 1.15.0\r\n- Python version: \r\n- Bazel version (if compiling from source): 1.1.0\r\n- GCC/Compiler version (if compiling from source):\r\n\r\n**Describe the current behavior**\r\nI've built the dsp delegate aar.\r\nBut on my miA2, I always got the following crash in native code.\r\nIs there anything I can do to debug with the cc files?\r\nAlso, I tried on Pixel3, it returned this device does not support hexagon delegate.\r\nIt doesn't seem to be normal for a snapdragon 845 device.\r\n```\r\n2019-12-18 18:30:38.484 18124-18510/com.ivuu I/tflite: Created TensorFlow Lite delegate for Hexagon.\r\n2019-12-18 18:30:38.491 18124-18510/com.ivuu I/tflite: Initialized TensorFlow Lite runtime.\r\n2019-12-18 18:30:38.952 18124-18510/com.ivuu A/libc: Fatal signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0x2 in tid 18510 (Thread-130), pid 18124\r\n```\r\n", "comments": ["@jdduke Dear tensorflower,\r\n\r\nAfter several tests, I found out that the release version is not compatible with hexagon delegate.\r\n`0.0.0-nightly` actually worked.\r\nFirst issue resolved, but here it comes next issue.\r\nIt seems the kernel registration is failed and lead to the following crash.\r\nAny advice would be helpful, thanks!\r\n```\r\nvendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:270: rpc latency thread start\r\nvendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:1688: Searching for fastrpc_shell_3 ...\r\nvendor/qcom/proprietary/commonsys-intf/adsprpc/src/apps_std_imp.c:729:Error 45: fopen failed for oemconfig.so. (No such file or directory)\r\nvendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:1864: Error 0xffffffff: apps_dev_init failed for domain 3, errno Operation not permitted\r\nvendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:1956: Error ffffffff: open dev -1 for domain 3 failed\r\nvendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:999: Error 3b: remote handle64 open failed. name file:///libhexagon_nn_skel.so?hexagon_nn_domains_skel_handle_invoke&_modver=1.0&_dom=cdsp\r\ntflite: Hexagon delegate: 61 nodes delegated out of 61 nodes.\r\ntflite:hexagon_dsp: Hexagon delegate: 61 nodes delegated out of 61 nodes. (the android log I added in cc file)\r\ntflite:hexagon_dsp: Hexagon Kernel was not initialized (the android log I added in cc file)\r\n    java.lang.RuntimeException: java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: hexagon_nn_config failed. Error: -1\r\n    Hexagon Kernel was not initialized\r\n    Node number 61 (TfLiteHexagonDelegate) failed to prepare.\r\n```", "You're right, we should update the documentation to note the version compatibility requirements. I'll let Karim respond about the Hexagon failure. Does the latest init failure occur on both devices? or only the Pixel 3?\r\n\r\nUnfortunately, Pixel devices do not support the Hexagon delegate. For the Pixel 3, you can use NNAPI to get DSP acceleration.", "Thanks @lcycoding for reporting the issue:\r\n\r\n1) For the pixel devices as Jared mentioned, you can't use the delegate, you can only use NNAPI .\r\n2) For the release, yes please use nightly till next release. Sorry for the confusion, i am updating the documentation with this now.\r\n3) For the crash, i just tried it on mi A2 and working.\r\nCan you please provide the details of your setup ?\r\nincluding:\r\nHow are you creating the delegate ?\r\nWhich API (Java/C) are you using ?\r\nDevice/Android version ?\r\nHow you bundle the libraries in your app ?\r\n\r\nThanks", "FYR. Dunno the situation of Pixel 3, but I was able to use Hexagon Delegate on Pixel 2, 3a, and 4 by 'setenforce 0', as far as I can remember.", "\u00a0@karimnosseir Thanks for promptly reply!\r\n\r\n> How are you creating the delegate ?\r\n\r\nBy simply using the provided build script\r\n`bazel build -c opt --config=android_arm64 tensorflow/lite/experimental/delegates/hexagon/java:tensorflow-lite-hexagon`\r\n\r\n> Which API (Java/C) are you using ?\r\n\r\nJava API 29, android ndk r20\r\nFor the C part, it's c++14 I believe... ( default by bazel 1.1.0 )\r\n\r\n> Device/Android version ?\r\n\r\nMi A2 with Android 9\r\n\r\n> How you bundle the libraries in your app ?\r\n\r\nBy putting `.aar` files into libs folder, and the generated nn_skel.so into jniLibs folder.", "By which API i mean are you creating the delegate in C++ code or Java code ?\r\nAlso, can you include the logcat\r\n\r\nThanks", "Ahh.. Sorry for the misunderstanding..\r\nI'm creating delegate with Java Code.\r\nThe full logcat message is as followed\r\n```\r\n2019-12-20 10:13:52.016 11662-12221/com.ivuu V/com.ivuu: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:1688: Searching for fastrpc_shell_0 ...\r\n2019-12-20 10:13:52.046 11662-12221/com.ivuu V/com.ivuu: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:1838: Successfully created user PD on domain 0 (attrs 0x0)\r\n2019-12-20 10:13:52.050 11662-12231/com.ivuu V/com.ivuu: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:270: rpc latency thread start\r\n2019-12-20 10:13:52.050 11662-12221/com.ivuu I/tflite: Created TensorFlow Lite delegate for Hexagon.\r\n2019-12-20 10:13:52.052 11662-12221/com.ivuu I/tflite: Hexagon delegate: 95 nodes delegated out of 96 nodes.\r\n2019-12-20 10:13:52.053 11662-12221/com.ivuu V/com.ivuu: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:1688: Searching for fastrpc_shell_3 ...\r\n2019-12-20 10:13:52.053 11662-12229/com.ivuu E/com.ivuu: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/apps_std_imp.c:729:Error 45: fopen failed for oemconfig.so. (No such file or directory)\r\n2019-12-20 10:13:52.066 11662-12221/com.ivuu D/com.ivuu: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:1864: Error 0xffffffff: apps_dev_init failed for domain 3, errno Operation not permitted\r\n2019-12-20 10:13:52.066 11662-12221/com.ivuu D/com.ivuu: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:1956: Error ffffffff: open dev -1 for domain 3 failed\r\n2019-12-20 10:13:52.066 11662-12221/com.ivuu D/com.ivuu: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:999: Error 3b: remote handle64 open failed. name file:///libhexagon_nn_skel.so?hexagon_nn_domains_skel_handle_invoke&_modver=1.0&_dom=cdsp\r\n2019-12-20 10:13:52.066 11662-12221/com.ivuu E/tflite:hexagon_dsp: Hexagon Kernel was not initialized in prepare\r\n2019-12-20 10:13:52.067 11662-12221/com.ivuu E/AndroidRuntime: FATAL EXCEPTION: Thread-128\r\n    Process: com.ivuu, PID: 11662\r\n    java.lang.RuntimeException: java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: hexagon_nn_config failed. Error: -1\r\n    Hexagon Kernel was not initialized\r\n    Node number 96 (TfLiteHexagonDelegate) failed to prepare.\r\n    \r\n    Restored previous execution plan after delegate application failure.\r\n        at com.alfredcamera.plugin.objectdetector.TFLiteObjectDetectionAPIModel.doInit(TFLiteObjectDetectionAPIModel.java:121)\r\n        at com.alfredcamera.plugin.objectdetector.TFLiteObjectDetectionAPIModel.recognizeImage(TFLiteObjectDetectionAPIModel.java:128)\r\n        at com.alfredcamera.plugin.objectdetector.BoxPrediction.bBoxInference(BoxPrediction.java:70)\r\n        at com.alfredcamera.plugin.objectdetector.TensorFlowThread.inference(TensorFlowThread.java:110)\r\n        at com.alfredcamera.plugin.objectdetector.TensorFlowThread.run(TensorFlowThread.java:45)\r\n     Caused by: java.lang.IllegalArgumentException: Internal error: Failed to apply delegate: hexagon_nn_config failed. Error: -1\r\n    Hexagon Kernel was not initialized\r\n    Node number 96 (TfLiteHexagonDelegate) failed to prepare.\r\n    \r\n    Restored previous execution plan after delegate application failure.\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.applyDelegate(Native Method)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.modifyGraphWithDelegate(NativeInterpreterWrapper.java:195)\r\n        at org.tensorflow.lite.Interpreter.modifyGraphWithDelegate(Interpreter.java:409)\r\n        at com.alfredcamera.plugin.objectdetector.TFLiteObjectDetectionAPIModel.doInit(TFLiteObjectDetectionAPIModel.java:111)\r\n        \t... 4 more\r\n\r\n```", "Thanks\r\nFew more questions\r\n\r\nIn the initialize line for the delegate\r\n  (e.g.) hexagonDelegate = new HexagonDelegate(activity);\r\nCan you print \r\n  activity.getApplicationInfo().nativeLibraryDir\r\nand check that the shared lib files are on the device under the same path.\r\n\r\nadb shell ls -al <PATH_PRINTED_FROM_ABOVE>", "Yes, I believe the files are there\r\n\r\n```\r\ntotal 19044\r\ndrwxr-xr-x 2 system system    4096 2019-12-20 10:18 .\r\ndrwxr-xr-x 3 system system    4096 2019-12-20 10:18 ..\r\n-rwxr-xr-x 1 system system    5912 1979-11-30 00:00 libGLNativeBridge.so\r\n-rwxr-xr-x 1 system system  297064 1979-11-30 00:00 libcrashlytics.so\r\n-rwxr-xr-x 1 system system   81088 1979-11-30 00:00 libfaac.so\r\n-rwxr-xr-x 1 system system   82832 1979-11-30 00:00 libhexagon_interface.so\r\n-rwxr-xr-x 1 system system 1019196 1979-11-30 00:00 libhexagon_nn_skel.so\r\n-rwxr-xr-x 1 system system 1035580 1979-11-30 00:00 libhexagon_nn_skel_v65.so\r\n-rwxr-xr-x 1 system system 1035644 1979-11-30 00:00 libhexagon_nn_skel_v66.so\r\n-rwxr-xr-x 1 system system 3509344 1979-11-30 00:00 libopencv_java3.so\r\n-rwxr-xr-x 1 system system  943736 1979-11-30 00:00 libopenh264.so\r\n-rwxr-xr-x 1 system system  461304 1979-11-30 00:00 libtensorflowlite_hexagon_jni.so\r\n-rwxr-xr-x 1 system system 1825464 1979-11-30 00:00 libtensorflowlite_jni.so\r\n```", "- Does it run on other devices, can you try ?\r\n- If possible and you can share the code i can have a look - you can email if you don't want to share here.\r\n\r\nThanks", "Hi Karim,\r\nSorry, the only compatible device I got is Mi A2. ( Pixel3 does not work )\r\nCan I have your e-mail address to send you the java code?\r\n\r\nAlso, I noticed the blogpost you made, it mentioned the built aar file approx take 380 KB.\r\nBut my built file was 197KB, is there any possibility that my build script go wrong?\r\n\r\n**Update:**\r\nI tried it on galaxy s8+(835), it worked...\r\nReally weird...", "Hi Karim,\r\nAfter several tries, I decided to upgrade my A2's system.\r\nIt worked in the end!\r\nSo there's no problem here, thanks for your kindly help!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35221\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35221\">No</a>\n", "Thanks @lcycoding for the update. Glad it worked.\r\n"]}, {"number": 35220, "title": "Imputing missing tensor values with the mean is unsuccessful", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux-4.14.106+-x86_64-with-debian-buster-sid\r\n- TensorFlow installed from (source or binary): pip install\r\n- TensorFlow version (use command below): 2.0.0\r\n- Python version: 3.6.6\r\n\r\n**Describe the current behavior**\r\nI am trying to impute the missing values in a tensor with the sample mean. As the size of my dataset is potentially quite large and the calculation of means require a full pass of the dataset, I am using tf.Transform to perform this computation.\r\n\r\nAs there is no native support for imputation on tf.Transform, I am implementing this by creating a `SparseTensor`, and specifying a default_value when converting to a dense tensor (as suggested in https://github.com/tensorflow/transform/issues/78#issuecomment-427919062).\r\n\r\nHowever, this does not seem to be successful as the output tensor still contains `nan`.\r\n\r\n**Describe the expected behavior**\r\nI expect the missing values in the output tensor to be replaced by the mean of the non-null values.\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nimport tempfile\r\nfrom glob import glob\r\n\r\nimport apache_beam as beam\r\nimport pandas as pd\r\nimport tensorflow as tf\r\nimport tensorflow_transform as tft\r\nimport tensorflow_transform.beam as tft_beam\r\nfrom tensorflow_transform.tf_metadata import dataset_metadata, schema_utils\r\n\r\nassert tf.__version__ == \"2.0.0\" and tft.__version__ == \"0.15.0\" and beam.__version__ == \"2.16.0\"\r\n\r\ndef create_raw_data(output_file):\r\n    df = pd.DataFrame({\"age\": [35.2, 17.3, None, 25.0]})\r\n    with tf.io.TFRecordWriter(output_file) as writer:\r\n        for _, row in df.iterrows():\r\n            features = tf.train.Features(\r\n                feature={\"age\": tf.train.Feature(float_list=tf.train.FloatList(value=[row]))}\r\n            )\r\n            example_proto = tf.train.Example(features=features)\r\n            writer.write(example_proto.SerializeToString())\r\n\r\n            \r\ndef run_tftransform(input_file, output_file):\r\n    def preprocessing_fn(inputs):\r\n        def _impute(tensor, replacement):\r\n            sparse = tf.sparse.SparseTensor(\r\n                tensor.indices, tensor.values, [tensor.dense_shape[0], 1]\r\n            )\r\n            dense = tf.sparse.to_dense(sp_input=sparse, default_value=replacement)\r\n            dense = tf.squeeze(dense, axis=1)\r\n            return dense\r\n\r\n        outputs = inputs.copy()\r\n        mean_age = tft.mean(outputs[\"age\"])\r\n        outputs[\"age\"] = _impute(outputs[\"age\"], mean_age)  # mean is 25.833333333\r\n        return outputs\r\n\r\n    RAW_DATA_FEATURE_SPEC = {\"age\": tf.io.VarLenFeature(tf.float32)}\r\n    RAW_DATA_METADATA = dataset_metadata.DatasetMetadata(\r\n        schema_utils.schema_from_feature_spec(RAW_DATA_FEATURE_SPEC)\r\n    )\r\n\r\n    with beam.Pipeline() as pipeline:\r\n        with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\r\n            raw_data_coder = tft.coders.ExampleProtoCoder(RAW_DATA_METADATA.schema)\r\n            raw_train_data = (\r\n                pipeline | beam.io.ReadFromTFRecord(input_file, coder=raw_data_coder)\r\n            )\r\n            (transformed_train_data, transformed_metadata), transform_fn = (\r\n                (raw_train_data, RAW_DATA_METADATA)| tft_beam.AnalyzeAndTransformDataset(preprocessing_fn)\r\n            )\r\n            transformed_data_coder = tft.coders.ExampleProtoCoder(transformed_metadata.schema)\r\n            _ = (\r\n                transformed_train_data| beam.io.WriteToTFRecord(\r\n                    output_file, coder=transformed_data_coder\r\n                )\r\n            )\r\n            \r\n            \r\nif __name__ == \"__main__\":\r\n    create_raw_data(\"raw_data.tfrecord\")\r\n    run_tftransform(\"raw_data.tfrecord\", \"transformed_data.tfrecord\")\r\n\r\n    TRANSFORMED_FEATURE_SPEC = {\"age\": tf.io.FixedLenFeature([], tf.float32)}\r\n    raw_dataset = tf.data.TFRecordDataset(filenames=glob(\"transformed_data.tfrecord*\"))\r\n    parsed_dataset = raw_dataset.map(lambda x: tf.io.parse_single_example(x, TRANSFORMED_FEATURE_SPEC)).batch(4)\r\n\r\n    print(next(iter(parsed_dataset.take(1))))\r\n```\r\n\r\nExpected output:\r\n```python\r\n{'age': <tf.Tensor: id=533, shape=(4,), dtype=float32, numpy=array([35.2, 17.3,  25.8333, 25. ], dtype=float32)>}\r\n```\r\nActual (incorrect) output which still contains `nan` values:\r\n```python\r\n{'age': <tf.Tensor: id=533, shape=(4,), dtype=float32, numpy=array([35.2, 17.3,  nan, 25. ], dtype=float32)>}\r\n```", "comments": ["Closing this issue as it is a Duplicate of [TFT_152](https://github.com/tensorflow/transform/issues/152). Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35220\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35220\">No</a>\n"]}, {"number": 35219, "title": "Install Tensorflow for Gitlab-CI", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Gitlab-CI, I think that's Linux\r\n- TensorFlow version: 2.0.0\r\n- Python version: 3.8\r\n- Installed using virtualenv? pip? conda?: pip\r\n\r\n**Describe the problem**\r\n\r\nI need to add Tensorflow to my requirement.txt. First I added \"tensorflow\" without a specific version, but in Gitlab-CI linters give me information that I need to add a specific version, so I added it and it looks like \"tensorflow == 2.0.0-rc0\" but in Gitlab-CI I got that:\r\n\r\n```\r\n$ pip install -r requirements.txt\r\nCollecting numpy==1.16.4\r\n  Downloading https://files.pythonhosted.org/packages/d3/4b/f9f4b96c0b1ba43d28a5bdc4b64f0b9d3fbcf31313a51bc766942866a7c7/numpy-1.16.4.zip (5.1MB)\r\nERROR: Could not find a version that satisfies the requirement tensorflow==2.0.0-rc0 (from -r requirements.txt (line 2)) (from versions: none)\r\nERROR: No matching distribution found for tensorflow==2.0.0-rc0 (from -r requirements.txt (line 2))\r\n```\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n1. Create .Gitlab-CI.yml\r\n2. Code for that file:\r\n```\r\nimage: \"python:3.8\"\r\n\r\nbefore_script:\r\n  - python --version\r\n  - python -c 'import struct;print( 8 * struct.calcsize(\"P\"))'\r\n  - pip install --upgrade pip\r\n  - pip install --upgrade setuptools\r\n  - pip install -r requirements.txt\r\n```\r\n\r\n3. Add file requirements.txt with that:\r\n```\r\nnumpy==1.16.4\r\ntensorflow==2.0.0-rc0\r\n```\r\n4. Push branch to repo\r\n5. CI give me error like above.\r\n\r\n**Any other info / logs**\r\ntensorflow==2.0.0rc0 and tensorflow==2.0.0 or tensorflow==2.0.0-rc0 give me same error.\r\n", "comments": ["Change image from Python 3.8 for Python 3.7 work for me. So problem is with latest Python 3.8", "@BElluu \r\nWe can expect python 3.8 support with TF 2.2.See [#33374 (comment)](https://github.com/tensorflow/tensorflow/issues/33374#issuecomment-562663993).Can i close this issue as the issue resolved by downgrading to Python 3.7. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35219\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35219\">No</a>\n"]}, {"number": 35218, "title": "Added ragged option for is_keras_tensor", "body": "Further work towards [this](https://github.com/tensorflow/tensorflow/issues/27170)", "comments": ["@jackd Can you please resolve conflicts? Thanks!", "@gbaned done :)"]}, {"number": 35217, "title": "Cherrypick a fix for experimental_relax_shapes to work on instance methods decorated with tf.function.", "body": "This pull request suggest to cherrypick for TF 2.1 a fix allowing `experimental_relax_shapes` to work on instance methods decorated with `tf.function`, which is currently silently ignored.\r\n\r\nThe original issue is #34905, the fix was merged to master in #35021.\r\n\r\n@goldiegadde and @martinwicke I understand it is quite late in the release cycle. However, this is a small and clear patch correcting and obvious bug, which I saw affect several users. But feel free to close this if you think it is a bad idea.", "comments": ["This is a cherry-pick from master, though.\n\nOn Wed, Dec 18, 2019 at 8:33 AM Martin Wicke <notifications@github.com>\nwrote:\n\n> *@martinwicke* requested changes on this pull request.\n>\n> This looks good to me (and better than what we had, for sure).\n>\n> Can you please make this PR against master? We generally do not take\n> patches into release branches that are not cherry-picks from master.\n>\n> \u2014\n> You are receiving this because your review was requested.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/35217?email_source=notifications&email_token=AAABHROEWO2UXS4RLO4TB4DQZJGGJA5CNFSM4J4HFBL2YY3PNVWWK3TUL52HS4DFWFIHK3DMKJSXC5LFON2FEZLWNFSXPKTDN5WW2ZLOORPWSZGOCPVAH6I#pullrequestreview-334103545>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHRLS2HK6X43ERALMOA3QZJGGJANCNFSM4J4HFBLQ>\n> .\n>\n\n\n-- \n - Alex\n", "As in, the commit is https://github.com/tensorflow/tensorflow/pull/35021", "@goldiegadde FYI."]}, {"number": 35216, "title": "tf.keras CANNOT use my custom metrics or loss function!", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n\r\nPreviously, I used Keras instead of tf.keras to run my code and it can work smoothly.\r\nCCC is the function I implemented.\r\n\r\n`\r\ndef CCC(y_true, y_pred, sample_weight=None, multioutput='uniform_average'):\r\n\r\n    y_true = K.reshape(y_true, (-1,NB_LABELS))\r\n    y_pred = K.reshape(y_pred, (-1,NB_LABELS))\r\n    y_true = K.argmax(y_true, axis=1)\r\n    y_pred = K.argmax(y_pred, axis=1)\r\n\r\n    y_true = K.cast(y_true, K.floatx())\r\n    y_pred = K.cast(y_pred, K.floatx())\r\n\r\n    # covariance between y_true and y_pred\r\n\r\n    s_xy = K.mean((y_true - K.mean(y_true)) * (y_pred - K.mean(y_pred)))\r\n    # means\r\n    x_m = K.mean(y_true)\r\n    y_m = K.mean(y_pred)\r\n    # variances\r\n    s_x_sq = K.var(y_true)\r\n    s_y_sq = K.var(y_pred)\r\n\r\n    # condordance correlation coefficient\r\n    ccc = (2.0 * s_xy) / (s_x_sq + s_y_sq + (x_m - y_m) ** 2 + K.epsilon())\r\n    ccc = K.maximum(K.minimum(ccc, 1.0), -1.0)\r\n\r\n    return ccc\r\n`\r\n\r\n- OS Platform and Distribution: Linux  Ubuntu 18.04.2\r\n- TensorFlow version (use command below): tensorflow 2.1.0rc1   \r\n- Python version: python3.7\r\n- CUDA/cuDNN version:CUDA Version: 10.1   \r\n- GPU model and memory:  Tesla T4 16GB Memory\r\n\r\n**Other info / logs**\r\nThe reason why I tried to use tf.keras is that I want to use keras-tuner to tune my parameters.\r\nThese are errors when combining my code with keras-tuner, but it seems like tf.keras issue not keras-tuner issue..\r\n\r\n`\r\nTRAIN STEPS:\r\n2\r\nVAL STEPS:\r\n2\r\nclass_weight\r\n{0: 6.695558842629338, 1: 31.333890492832904, 2: 17.24165962151265, 3: 4.737384205783776, 4: 4.5054695617553095, 5: 7.342352322135755, 6: 5.259447664120839, 7: 7.3335032481388405, 8: 1.9969838777884066, 9: 11.858626198083067, 10: 3.5724254090471605}\r\nx_array.shape, y_array.shape, sample_weight_array.shape:\r\n(500, 2048) (500, 11)\r\nWARNING:tensorflow:sample_weight modes were coerced from\r\n  ...\r\n    to  \r\n  ['...']\r\nx_array.shape, y_array.shape, sample_weight_array.shape:\r\n(500, 2048) (500, 11)\r\nWARNING:tensorflow:sample_weight modes were coerced from\r\n  ...\r\n    to  \r\n  ['...']\r\nTrain for 2 steps, validate for 2 steps\r\nx_array.shape, y_array.shape, sample_weight_array.shape:\r\n(500, 2048) (500, 11)\r\n1/2 [==============>...............] - ETA: 2sWARNING:tensorflow:Early stopping conditioned on metric 'val_CCC' which is not available. Available metrics are: \r\nWARNING:tensorflow:Can save best model only with val_CCC available, skipping.\r\nWARNING:tensorflow:Can save best model only with val_CCC available, skipping.\r\nTraceback (most recent call last):\r\n  File \"hp_tunning.py\", line 297, in <module>\r\n    tunning()\r\n  File \"hp_tunning.py\", line 206, in tunning\r\n    train_weight=train_weight)\r\n  File \"/home/i/i0000013/EmoPain2020-FinalVersion/train_tunning.py\", line 144, in train_tunning\r\n    class_weight=class_weight)\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/kerastuner/engine/base_tuner.py\", line 122, in search\r\n    self.run_trial(trial, *fit_args, **fit_kwargs)\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/kerastuner/engine/multi_execution_tuner.py\", line 95, in run_trial\r\n    history = model.fit(*fit_args, **fit_kwargs, callbacks=callbacks)\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 819, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 342, in fit\r\n    total_epochs=epochs)\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 128, in run_one_epoch\r\n    batch_outs = execution_function(iterator)\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\", line 98, in execution_function\r\nx_array.shape, y_array.shape, sample_weight_array.shape:\r\n    distributed_function(input_fn))\r\n(500, 2048) (500, 11)\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 568, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 632, in _call\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2363, in __call__\r\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1611, in _filtered_call\r\n    self.captured_inputs)\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1692, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 545, in call\r\n    ctx=ctx)\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\", line 67, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\r\n  (0) Invalid argument:  Can not squeeze dim[0], expected a dimension of 1, got 500\r\n\t [[node metrics/CCC_1/Squeeze (defined at /home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/kerastuner/engine/multi_execution_tuner.py:95) ]]\r\n\t [[metrics/mse_1/broadcast_weights/assert_broadcastable/is_valid_shape/else/_47/has_valid_nonscalar_shape/then/_285/has_invalid_dims/_68]]\r\n  (1) Invalid argument:  Can not squeeze dim[0], expected a dimension of 1, got 500\r\n\t [[node metrics/CCC_1/Squeeze (defined at /home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/kerastuner/engine/multi_execution_tuner.py:95) ]]\r\n0 successful operations.\r\n0 derived errors ignored. [Op:__inference_distributed_function_3424]\r\n\r\nFunction call stack:\r\ndistributed_function -> distributed_function\r\n`\r\n\r\n\r\nThese are errors when running the code using tf.keras but that worked fine in Keras....\r\n\r\n`\r\nWARNING:tensorflow:From /home/i/i0000013/EmoPain2020-FinalVersion/train.py:117: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease use Model.fit, which supports generators.\r\nx_array.shape, y_array.shape, sample_weight_array.shape:\r\n(500, 2048) (500, 11)\r\nWARNING:tensorflow:sample_weight modes were coerced from\r\n  ...\r\n    to  \r\n  ['...']\r\nx_array.shape, y_array.shape, sample_weight_array.shape:\r\n(500, 2048) (500, 11)\r\nWARNING:tensorflow:sample_weight modes were coerced from\r\n  ...\r\n    to  \r\n  ['...']\r\nTrain for 2 steps, validate for 2 steps\r\nx_array.shape, y_array.shape, sample_weight_array.shape:\r\n(500, 2048) (500, 11)\r\n1/2 [==============>...............] - ETA: 2sWARNING:tensorflow:Early stopping conditioned on metric `val_CCC` which is not available. Available metrics are: \r\nWARNING:tensorflow:Can save best model only with val_CCC available, skipping.\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 283, in <module>\r\n    run()\r\n  File \"main.py\", line 196, in run\r\n    train_weight=train_weight)\r\n  File \"/home/i/i0000013/EmoPain2020-FinalVersion/train.py\", line 117, in train\r\n    class_weight=class_weight)\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/util/deprecation.py\", line 324, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 1306, in fit_generator\r\n    initial_epoch=initial_epoch)\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 819, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 342, in fit\r\n    total_epochs=epochs)\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 128, in run_one_epoch\r\n    batch_outs = execution_function(iterator)\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\", line 98, in execution_function\r\n    distributed_function(input_fn))\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 568, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\", line 632, in _call\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 2363, in __call__\r\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1611, in _filtered_call\r\n    self.captured_inputs)\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1692, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 545, in call\r\n    ctx=ctx)\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\", line 67, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\r\n  (0) Invalid argument:  Can not squeeze dim[0], expected a dimension of 1, got 500\r\n\t [[node metrics/CCC_1/Squeeze (defined at /home/i/i0000013/EmoPain2020-FinalVersion/train.py:117) ]]\r\n\t [[metrics/acc_1/broadcast_weights/assert_broadcastable/is_valid_shape/else/_24/has_valid_nonscalar_shape/then/_275/has_invalid_dims/ExpandDims_1/_56]]\r\n  (1) Invalid argument:  Can not squeeze dim[0], expected a dimension of 1, got 500\r\n\t [[node metrics/CCC_1/Squeeze (defined at /home/i/i0000013/EmoPain2020-FinalVersion/train.py:117) ]]\r\n0 successful operations.\r\n0 derived errors ignored. [Op:__inference_distributed_function_3010]\r\n\r\nFunction call stack:\r\ndistributed_function -> distributed_function\r\n`", "comments": ["When I set up my environment from scratch and used tensorflow-gpu 2.0.0, I still got errors as follows.\r\n\r\n`\r\nTraceback (most recent call last):\r\n  File \"main.py\", line 283, in <module>\r\n    run()\r\n  File \"main.py\", line 196, in run\r\n    train_weight=train_weight)\r\n  File \"/home/i/i0000013/EmoPain2020-FinalVersion/train.py\", line 117, in train\r\n    class_weight=class_weight)\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 1297, in fit_generator\r\n    steps_name='steps_per_epoch')\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_generator.py\", line 265, in model_iteration\r\n    batch_outs = batch_function(*batch_data)\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 1018, in train_on_batch\r\n    outputs = self.train_function(ins)  # pylint: disable=not-callable\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\", line 3740, in __call__\r\n    outputs = self._graph_fn(*converted_inputs)\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1081, in __call__\r\n    return self._call_impl(args, kwargs)\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1121, in _call_impl\r\n    return self._call_flat(args, self.captured_inputs, cancellation_manager)\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 1224, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager)\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\", line 511, in call\r\n    ctx=ctx)\r\n  File \"/home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\", line 67, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: 2 root error(s) found.\r\n  (0) Invalid argument:  Can not squeeze dim[0], expected a dimension of 1, got 500\r\n\t [[node metrics_2/pearson_r_1/Squeeze (defined at /home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]]\r\n\t [[metrics_2/mse_1/broadcast_weights/assert_broadcastable/is_valid_shape/else/_80/has_valid_nonscalar_shape/then/_444/has_invalid_dims/concat/_48]]\r\n  (1) Invalid argument:  Can not squeeze dim[0], expected a dimension of 1, got 500\r\n\t [[node metrics_2/pearson_r_1/Squeeze (defined at /home/i/i0000013/miniconda3/envs/emopain-tf2/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]]\r\n0 successful operations.\r\n0 derived errors ignored. [Op:__inference_keras_scratch_graph_2525]\r\n\r\nFunction call stack:\r\nkeras_scratch_graph -> keras_scratch_graph\r\n\r\n`", "@ZYHZ100 Did you find a solution for this? I'm having the same problem right now after migrating from `keras` to `tensorflow.keras` with a custom loss function."]}, {"number": 35215, "title": "[tflite] fix handling of avgpool in NNAPI delegate", "body": "After NNAPI 1.2, the h * w <= 256 limit is gone, see its CPU avgpool kernel [code](https://android.googlesource.com/platform/external/tensorflow/+/3589bbfbc68ddb8a4c87f90bf7c8dc87c5a50556%5E%21/tensorflow/lite/kernels/internal/optimized/optimized_ops.h) here", "comments": ["I'm actually still seeing a failure when running on API 29 for this case: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/kernels/pooling_test.cc#L559. So I don't think we can land this.\r\n```\r\ntensorflow/lite/kernels/pooling_test.cc:572: Failure\r\nValue of: m.GetOutput()\r\nExpected: has 1 element that is equal to '\\xFF' (255)\r\n  Actual: { '\\x1C' (28) } (of type NSt6__ndk16vectorIhNS_9allocatorIhEEEE), whose element #0 doesn't match\r\n```", "@jdduke Got it. Yes, I ran into the same problem when testing with `poolingtest` on Pixel 4. Actually, what I want is to offload avg pooling without specifying a specific accelerator (otherwise some models such as DeepLab V3 and MobileNet V3 will have avgpool un-accelerated).", "Close this since the nnapi-reference avg pooling still cannot handle it :-("]}, {"number": 35214, "title": "tflite.load_delegate() failed when running Demo API on Google Coral mini PCIe", "body": "I am also facing a similar issue.\r\nThe demo API gives error at tflite.load_delegate.\r\n\r\n```\r\npi@bpi-iot-ros-ai:~/coral/tflite/python/examples/classification$ python3 classify_image.py --model models/mobilenet_v2_1.0_224_inat_bird_quant_edgetpu.tflite --labels models/inat_bird_labels.txt --input images/parrot.jpg\r\nE :248] HIB Error. hib_error_status = 0000000000000001, hib_first_error_status = 0000000000000001\r\nE :248] HIB Error. hib_error_status = 0000000000000001, hib_first_error_status = 0000000000000001\r\nINFO: Initialized TensorFlow Lite runtime.\r\n----INFERENCE TIME----\r\nNote: The first inference on Edge TPU is slow because it includes loading the model into Edge TPU memory.\r\n\r\n\r\n\r\npi@bpi-iot-ros-ai:~$ uname -a\r\nLinux bpi-iot-ros-ai 5.4.0-bpi-r64 #1 SMP PREEMPT Mon Dec 16 16:00:08 IST 2019 aarch64 aarch64 aarch64 GNU/Linux\r\npi@bpi-iot-ros-ai:~$ lscpu\r\nArchitecture:          aarch64\r\nByte Order:            Little Endian\r\nCPU(s):                2\r\nOn-line CPU(s) list:   0,1\r\nThread(s) per core:    1\r\nCore(s) per socket:    2\r\nSocket(s):             1\r\nCPU max MHz:           1350.0000\r\nCPU min MHz:           30.0000\r\npi@bpi-iot-ros-ai:~$ ls -l /usr/lib/aarch64-linux-gnu/libedge*\r\nlrwxrwxrwx 1 root root     17 Sep 17 04:27 /usr/lib/aarch64-linux-gnu/libedgetpu.so.1 -> libedgetpu.so.1.0\r\n-rwxrwxrwx 1 root root 792376 Sep 17 04:27 /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0\r\npi@bpi-iot-ros-ai:~$ lspci\r\n00:00.0 PCI bridge: MEDIATEK Corp. Device 3258\r\n01:00.0 System peripheral: Device 1ac1:089a\r\npi@bpi-iot-ros-ai:~$ ls /dev/apex_0 \r\n/dev/apex_0\r\npi@bpi-iot-ros-ai:~$ sudo sh -c \"echo 'SUBSYSTEM==\\\"apex\\\", MODE=\\\"0660\\\", GROUP=\\\"apex\\\"' >> /etc/udev/rules.d/65-apex.rules\"\r\npi@bpi-iot-ros-ai:~$ sudo groupadd apex\r\ngroupadd: group 'apex' already exists\r\npi@bpi-iot-ros-ai:~$ sudo adduser $USER apex\r\nThe user `pi' is already a member of `apex'.\r\n```\r\n", "comments": ["As suggested by the Coral support and Troubleshooting https://coral.ai/docs/m2/get-started/#troubleshooting\r\nThe error still persist.\r\n", "I have now loaded the libedgetpu as per the instructions here https://coral.ai/news/updates-04-2019/.\r\nNow I do not get the HIB error but the follwoing error\r\n```\r\n\r\n`Traceback (most recent call last):\r\n  File \"classify_image.py\", line 122, in <module>\r\n    main()\r\n  File \"classify_image.py\", line 98, in main\r\n    interpreter = make_interpreter(args.model)\r\n  File \"classify_image.py\", line 71, in make_interpreter\r\n    {'device': device[0]} if device else {})\r\n  File \"/usr/local/lib/python3.5/dist-packages/tflite_runtime/interpreter.py\", line 165, in load_delegate\r\n    delegate = Delegate(library, options)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tflite_runtime/interpreter.py\", line 89, in __init__\r\n    self._library = ctypes.pydll.LoadLibrary(library)\r\n  File \"/usr/lib/python3.5/ctypes/__init__.py\", line 425, in LoadLibrary\r\n    return self._dlltype(name)\r\n  File \"/usr/lib/python3.5/ctypes/__init__.py\", line 347, in __init__\r\n    self._handle = _dlopen(self._name, mode)\r\nOSError: /usr/lib/aarch64-linux-gnu/libc++abi.so.1: undefined symbol: _Unwind_GetRegionStart\r\nException ignored in: <bound method Delegate.__del__ of <tflite_runtime.interpreter.Delegate object at 0x7f99af6550>>\r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.5/dist-packages/tflite_runtime/interpreter.py\", line 124, in __del__\r\n    if self._library is not None:\r\nAttributeError: 'Delegate' object has no attribute '_library'\r\n```\r\n`\r\nI have updated the g++ and gcc to version 6 and installed libunwind8. but the same error is still present.", "@batulrangwala is this still happening?", "Yes", "What's the target OS you're using?\r\nIf you're using Coral, could you update OS to 4.0 Day or later?\r\nhttps://coral.ai/software/#mendel-linux\r\n\r\nCould you also share the result of this command?\r\n\r\n```\r\nldd -r /usr/lib/aarch64-linux-gnu/libedgetpu.so.1.0\r\n```", "I am using BananaPi R64.\r\nKernel version 4.19 on Ubuntu 16", "Hi @batulrangwala !\r\nHi ! we are  checking to see if you are still looking for assistance in this issue.\r\nCould you please try on latest stable version  TF 2.6  and let us know if this is still an issue.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35214\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35214\">No</a>\n"]}, {"number": 35213, "title": "macOS compiling: hidden symbol `__dso_handle' isn't defined and undefined reference to `operator delete(void*)'", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- macOS 10.15 Catalina\r\n- TensorFlow installed from source \r\n- Tensorflow version (commit SHA if source):2ba0b2ef68d4259e8b02fa8be77a9372020b81b7 (Dec. 16)\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.): bluepill\r\n\r\n**Describe the problem**\r\n```\r\narm-none-eabi-g++ -O3 -DNDEBUG -std=c++11 -g -DTF_LITE_STATIC_MEMORY -fno-rtti -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK -DTF_LITE_STATIC_MEMORY -DTF_LITE_MCU_DEBUG_LOG -fno-rtti -fmessage-length=0 -fno-exceptions -fno-unwind-tables -fno-builtin -ffunction-sections -fdata-sections -funsigned-char -MMD -mcpu=cortex-m3 -mthumb -std=gnu++11 -Wvla -Wall -Wextra -Wno-unused-parameter -Wno-missing-field-initializers -Wno-write-strings -Wno-sign-compare -fno-delete-null-pointer-checks -fomit-frame-pointer -fpermissive -nostdlib -g -Os -I. -Itensorflow/lite/micro/tools/make/downloads/ -Itensorflow/lite/micro/tools/make/downloads/gemmlowp -Itensorflow/lite/micro/tools/make/downloads/flatbuffers/include -isystemtensorflow/lite/micro/tools/make/downloads/cmsis/CMSIS/Core/Include/ -Itensorflow/lite/micro/tools/make/downloads/stm32_bare_lib/include -Itensorflow/lite/micro/tools/make/downloads/kissfft -o tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/bin/hello_world tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/obj/tensorflow/lite/micro/examples/hello_world/main.o tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/obj/tensorflow/lite/micro/examples/hello_world/main_functions.o tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/obj/tensorflow/lite/micro/examples/hello_world/sine_model_data.o tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/obj/tensorflow/lite/micro/examples/hello_world/output_handler.o tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/obj/tensorflow/lite/micro/examples/hello_world/constants.o  tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/lib/libtensorflow-microlite.a -T tensorflow/lite/micro/tools/make/targets/bluepill/bluepill.lds -Wl,-Map=tensorflow/lite/micro/tools/make/gen/bluepill.map,--cref -Wl,--gc-sections -lm\r\ntensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/obj/tensorflow/lite/micro/examples/hello_world/main_functions.o: In function `setup()':\r\n/Users/pinxue/projects/rt-thread/ai/tensorflow/tensorflow/lite/micro/examples/hello_world/main_functions.cc:47: undefined reference to `__cxa_guard_acquire'\r\n/Users/pinxue/projects/rt-thread/ai/tensorflow/tensorflow/lite/micro/examples/hello_world/main_functions.cc:47: undefined reference to `__cxa_guard_release'\r\n/Users/pinxue/projects/rt-thread/ai/tensorflow/tensorflow/lite/micro/examples/hello_world/main_functions.cc:63: undefined reference to `__cxa_guard_acquire'\r\n/Users/pinxue/projects/rt-thread/ai/tensorflow/tensorflow/lite/micro/examples/hello_world/main_functions.cc:63: undefined reference to `__cxa_guard_release'\r\n/Users/pinxue/projects/rt-thread/ai/tensorflow/tensorflow/lite/micro/examples/hello_world/main_functions.cc:67: undefined reference to `__cxa_guard_acquire'\r\n/Users/pinxue/projects/rt-thread/ai/tensorflow/tensorflow/lite/micro/examples/hello_world/main_functions.cc:67: undefined reference to `__cxa_guard_release'\r\n/Users/pinxue/projects/rt-thread/ai/tensorflow/tensorflow/lite/micro/examples/hello_world/main_functions.cc:83: undefined reference to `__dso_handle'\r\ntensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/lib/libtensorflow-microlite.a(greedy_memory_planner.o): In function `tflite::GreedyMemoryPlanner::~GreedyMemoryPlanner()':\r\n/Users/pinxue/projects/rt-thread/ai/tensorflow/tensorflow/lite/micro/memory_planner/greedy_memory_planner.cc:70: undefined reference to `operator delete(void*)'\r\n`__lock___atexit_recursive_mutex' referenced in section `.data.__atexit_recursive_mutex' of /Users/pinxue/projects/rt-thread/ai/tensorflow/tensorflow/lite/micro/tools/make/downloads/gcc_embedded/bin/../lib/gcc/arm-none-eabi/7.3.1/../../../../arm-none-eabi/lib/thumb/v7-m/libc.a(lib_a-__call_atexit.o): defined in discarded section `COMMON' of /Users/pinxue/projects/rt-thread/ai/tensorflow/tensorflow/lite/micro/tools/make/downloads/gcc_embedded/bin/../lib/gcc/arm-none-eabi/7.3.1/../../../../arm-none-eabi/lib/thumb/v7-m/libc.a(lib_a-lock.o)\r\n/Users/pinxue/projects/rt-thread/ai/tensorflow/tensorflow/lite/micro/tools/make/downloads/gcc_embedded/bin/../lib/gcc/arm-none-eabi/7.3.1/../../../../arm-none-eabi/bin/ld: tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/bin/hello_world: hidden symbol `__dso_handle' isn't defined\r\n/Users/pinxue/projects/rt-thread/ai/tensorflow/tensorflow/lite/micro/tools/make/downloads/gcc_embedded/bin/../lib/gcc/arm-none-eabi/7.3.1/../../../../arm-none-eabi/bin/ld: final link failed: Bad value\r\ncollect2: error: ld returned 1 exit status\r\ngmake: *** [tensorflow/lite/micro/examples/hello_world/Makefile.inc:42: tensorflow/lite/micro/tools/make/gen/bluepill_cortex-m3/bin/hello_world] Error 1\r\n```\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\n\r\n```\r\n$ /opt/local/bin/gmake -j1 -f tensorflow/lite/micro/tools/make/Makefile TARGET=bluepill hello_world\r\n```\r\n", "comments": ["@pinxue,\r\nIs this still an issue?\r\n\r\nCould you please update TensorFlow to the latest stable version v2.4.1 and check if you are facing the same error. Thanks!", "Is this still an issue?\r\n\r\nCould you please update TensorFlow to the latest stable version v2.4.1 and check if you are facing the same error. Thanks!", "Sorry, I no longer have that environment to reproduce it. ", "@pinxue \r\nIn that case, can you move this to closed status.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35213\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35213\">No</a>\n"]}, {"number": 35212, "title": "tf.load_op_library bug", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): https://github.com/cogaplex-bts/bts\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): ubuntu 1604\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below):1.13.2\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source): pip \r\n- CUDA/cuDNN version: 10.0 \r\n- GPU model and memory: 1060, 6G\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nin a process, use full path , twice load:\r\ntf.load_op_library(os.path.join(dname, 'build/libcompute_depth.so'))\r\nthe second time, OP_LIST is empty, \r\nbut with relative path, twice  tf.load_op_library not empty\r\n**Describe the expected behavior**\r\nuse full path, twice  tf.load_op_library, OP_LIST should not empty\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\nI compile https://github.com/cogaplex-bts/bts, met this problem. But I think this is a general problem, reproduce: just in a python file, load the library twice, with full path and relative path   \r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n```\r\ncompute_depth_grad_module dict: {'__name__': 'a11935c229913616b7b14d8da52f01ac', '__doc__': 'Python wrappers around TensorFlow ops.\\n\\nThis file is MACHINE GENERATED! Do not edit.\\n', ...  , 'LIB_HANDLE': <Swig Object of type 'TF_Library *' at 0x7ff4ad011f60>, 'OP_LIST': op {\r\n  name: \"ComputeDepth\"\r\n  input_arg {\r\n    name: \"input\"\r\n    type: DT_FLOAT\r\n  }\r\n  input_arg {\r\n    name: \"focal\"\r\n    type: DT_FLOAT\r\n  }\r\n  output_arg {\r\n    name: \"depth\"\r\n    type: DT_FLOAT\r\n  }\r\n  attr {\r\n    name: \"upratio\"\r\n    type: \"int\"\r\n  }\r\n}\r\nop {\r\n  name: \"ComputeDepthGrad\"\r\n  input_arg {\r\n    name: \"depth_grad\"\r\n    type: DT_FLOAT\r\n  }\r\n  input_arg {\r\n    name: \"input\"\r\n    type: DT_FLOAT\r\n  }\r\n  input_arg {\r\n    name: \"focal\"\r\n    type: DT_FLOAT\r\n  }\r\n  output_arg {\r\n    name: \"grad_input\"\r\n    type: DT_FLOAT\r\n  }\r\n  output_arg {\r\n    name: \"grad_focal\"\r\n    type: DT_FLOAT\r\n  }\r\n}\r\n}\r\n{'__name__': 'a11935c229913616b7b14d8da52f01ac', '__doc__': 'Python wrappers around TensorFlow ops.\\n\\nThis file is MACHINE GENERATED! Do not edit.\\n', '__package__': None,  ... , 'LIB_HANDLE': <Swig Object of type 'TF_Library *' at 0x7ff4ad011f60>, 'OP_LIST': op {\r\n  name: \"ComputeDepth\"\r\n  input_arg {\r\n    name: \"input\"\r\n    type: DT_FLOAT\r\n  }\r\n  input_arg {\r\n    name: \"focal\"\r\n    type: DT_FLOAT\r\n  }\r\n  output_arg {\r\n    name: \"depth\"\r\n    type: DT_FLOAT\r\n  }\r\n  attr {\r\n    name: \"upratio\"\r\n    type: \"int\"\r\n  }\r\n}\r\nop {\r\n  name: \"ComputeDepthGrad\"\r\n  input_arg {\r\n    name: \"depth_grad\"\r\n    type: DT_FLOAT\r\n  }\r\n  input_arg {\r\n    name: \"input\"\r\n    type: DT_FLOAT\r\n  }\r\n  input_arg {\r\n    name: \"focal\"\r\n    type: DT_FLOAT\r\n  }\r\n  output_arg {\r\n    name: \"grad_input\"\r\n    type: DT_FLOAT\r\n  }\r\n  output_arg {\r\n    name: \"grad_focal\"\r\n    type: DT_FLOAT\r\n  }\r\n}\r\n}\r\n```\r\n\r\nbut with full name, second will print:\r\n```\r\ncompute_depth_grad_module dict: {'__name__': '670cc8cfec5b6d3b8635f39bd583d769', '__doc__': 'Python wrappers around TensorFlow ops.\\n\\nThis file is MACHINE GENERATED! Do not edit.\\n', '__package__': None, ... , 'LIB_HANDLE': <Swig Object of type 'TF_Library *' at 0x7f6b2a8f3e70>, 'OP_LIST': }\r\n```\r\n", "comments": ["Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35212\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35212\">No</a>\n"]}, {"number": 35211, "title": "TensorImage grayscale (single channel) image support ", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: Huawei\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: 2.0\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: \r\n- **GCC/Compiler version (if compiling from source)**: \r\n- **CUDA/cuDNN version**: 10.2\r\n- **GPU model and memory**: GTX2080TI\r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nThis is a feature request. I am struggling to make a TFLITE model that works perfectly in Python to  also work in and Android apk. It seems I have problems related with the conversion from Bitmap to a bytebuffer, std, mean and that stuff (I've been using old Android examples that made the conversion Bitmap -> Bytebuffer manually). \r\n\r\nNow I've seen this new TensorImage feature in tensorflow-lite-support and tried it, but it seems it only supports loading RGB images. My model is MNIST-based, so the input shape of the images are (28, 28, 1). I don't see how I can use TensorImage to feed my model in this scenario.\r\n\r\nCan you please support grayscale (1 channel) images also please? \r\n\r\nThanks,\r\n\r\n### Source code / logs\r\n\r\n", "comments": ["@lu-wang-g Could you take a look?", "Thanks for letting us know about your requests! The grayscale image is on our todo list, but is not prioritized at this moment. We'll definitely consider your feedback into our roadmap planning for Q1 2020. I'll give you updates once it is confirmed.", "OK, thanks for the feedback, I will gladly test the feature as soon as you release it. By now I was able to solve my problem manipulating the ByteBuffer manually.", "@hvico hello sir,\r\ncan you tell us how exactly you did this?", "Hello. It's been a while, unfortunatelly I couldn't find this code now. For what I recall I think I just dropped the usage of TensorImage and managed to load the ByteBuffer manually for this particular model. Thanks!", "@hvico,\r\nSorry for the delayed response. Can you please refer the documentation of [TF Lite Basic image manipulation and conversion ](https://www.tensorflow.org/lite/inference_with_metadata/lite_support#basic_image_manipulation_and_conversion) and let us know if this issue is resolved? Thanks!", "TFLite Support library can help convert RGB image to grayscale. You can create  the ImageProcessor as follows:\r\n\r\n```\r\nImageProcessor processor =\r\n        new ImageProcessor.Builder().add(new TransformToGrayscaleOp()).build();\r\n```\r\n\r\nSee more instructions about ImageProcessor as @rmothukuru pointed out above.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Why when i traid to use TransformToGrayscaleOp i see a: **Unresolved reference: TransformToGrayscaleOp** error?", "@AndryCU have you pulled in the lastest tflite support library, \"org.tensorflow:tensorflow-lite-support:0.3.0\"? ", "@lu-wang-g SOLVED. I don't know why android studio don't said me that was avaible a newer version, anyway...thanks...", "You're welcome!"]}, {"number": 35210, "title": "I need a function which like np.argwhere", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using):2.0\r\n- Are you willing to contribute it (Yes/No):No\r\n\r\n**Describe the feature and the current behavior/state.**\r\nThe current API only includes argmax and argmin for return the index of tensor\uff0ci need a function \r\nwhich like np.argwhere for inference centernet\r\n**Will this change the current api? How?**\r\nit will not change.only append an api in tf.math\r\n**Who will benefit with this feature?**\r\neveryone\r\n**Any Other info.**\r\n", "comments": ["np.argwhere is related to Numpy issue. Do you mean tf.math.argwhere", "I am willing to work on this issue. Can you please assign this to me?", "I believe you can get the indexes when the condition is met as tensors just by using _tf.where(condition)_\r\nSample code \r\n\r\n`import tensorflow as t`\r\n`import numpy as np`\r\n\r\n`numpy_array = np.arange(6).reshape(2,3)`\r\n`indices = np.argwhere(numpy_array>1)`\r\n`print(indices)`\r\n\r\n>>>[[0 2]\r\n [1 0]\r\n [1 1]\r\n [1 2]]\r\n\r\n`tensor_array = tf.convert_to_tensor(numpy_array)`\r\n`cond_indices = tf.where(tensor_array>1)`\r\n`print(cond_indices)`\r\n\r\n>>>tf.Tensor(\r\n[[0 2]\r\n [1 0]\r\n [1 1]\r\n [1 2]], shape=(4, 2), dtype=int64)\r\n", "@xinyidaren \r\nCan you please check @Athul8raj suggestion.Thanks!", "thanks a lot!!"]}, {"number": 35209, "title": "Does TF2.0 absolutely support TPU now\uff1f", "body": "Our TF code is written with TF2.0 (eager mode). However we heard that TF2.0 cannot run on TPU\r\n device. So is there any supporting plan ? Or when to release TPU-friendly TF2.X?", "comments": ["@xixiaoyao ,\r\nHello, 2.0 indeed supports TPU, please refer the link [TPUstrategy](https://www.tensorflow.org/guide/distributed_training#tpustrategy) for more information.Thanks!\r\n", "@xixiaoyao ,\r\nAny update on the issue?Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 35208, "title": "TypeError: expected bytes, Descriptor found", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (Windows 10)\r\n- TensorFlow installed from (source):\r\n- TensorFlow version: Tensorflow GPU Version 1.14.0\r\n- Python version: 3.6.9\r\n- Installed using conda:\r\n- CUDA/cuDNN version: cuda_10.0.130_411.31_win10 / cudnn-10.0-windows10-x64-v7.4.1.5\r\n- GPU model and memory: nvidia mx 250 with 2GB0\r\n\r\n\r\n\r\n**Describe the problem**\r\nI am folliowing the [Edge Electronics](https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10#1-install-anaconda-cuda-and-cudnn) github repository. At [step 2d. Set up new Anaconda virtual environment](https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10#2d-set-up-new-anaconda-virtual-environment)  I created a virtual environment using `conda create -n tensorflow1 pip python=3.6` \r\nThe other commands I executed are:\r\n`activate tensorflow1`\r\n`python -m pip install --upgrade pip`\r\n`pip install --ignore-installed --upgrade tensorflow-gpu==1.14.0`\r\nAfter last command, when I try to import tensorflow, it get imported successfully but after running follwoing command,\r\n`conda install -c anaconda protobuf` when I again try to import tensorflow, I get the following error. \r\n(tensorflow1) C:\\>python\r\nPython 3.6.9 |Anaconda, Inc.| (default, Jul 30 2019, 14:00:49) [MSC v.1915 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\saqib\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\__init__.py\", line 28, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\saqib\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 52, in <module>\r\n    from tensorflow.core.framework.graph_pb2 import *\r\n  File \"C:\\Users\\saqib\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\core\\framework\\graph_pb2.py\", line 16, in <module>\r\n    from tensorflow.core.framework import node_def_pb2 as tensorflow_dot_core_dot_framework_dot_node__def__pb2\r\n  File \"C:\\Users\\saqib\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\core\\framework\\node_def_pb2.py\", line 16, in <module>\r\n    from tensorflow.core.framework import attr_value_pb2 as tensorflow_dot_core_dot_framework_dot_attr__value__pb2\r\n  File \"C:\\Users\\saqib\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\core\\framework\\attr_value_pb2.py\", line 16, in <module>\r\n    from tensorflow.core.framework import tensor_pb2 as tensorflow_dot_core_dot_framework_dot_tensor__pb2\r\n  File \"C:\\Users\\saqib\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\core\\framework\\tensor_pb2.py\", line 16, in <module>\r\n    from tensorflow.core.framework import resource_handle_pb2 as tensorflow_dot_core_dot_framework_dot_resource__handle__pb2\r\n  File \"C:\\Users\\saqib\\Anaconda3\\envs\\tensorflow2\\lib\\site-packages\\tensorflow\\core\\framework\\resource_handle_pb2.py\", line 92, in <module>\r\n    __module__ = 'tensorflow.core.framework.resource_handle_pb2'\r\nTypeError: expected bytes, Descriptor found\r\n\r\nI have tried everthing like removing the virtual environment and creating the new but still the same error. \r\nWhat mistake dou you think I am doing?\r\nAny possible solution will be apppreciated.\r\nThanks in advance :) \r\nLooking forward for quick reply\r\n", "comments": ["@saqibshakeel035 ,\r\nHello, I indeed tried following all the steps as given in the [link](https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10#2d-set-up-new-anaconda-virtual-environment), make sure you install all the necessary packages mentioned in the link, and try using latest version` tf-1.15 `\r\n`pip install --ignore-installed --upgrade tensorflow-gpu==1.15.0`, I was able to import tensorflow successfully.Thanks!", "@saqibshakeel035 ,\r\nAny update on the issue ?Thanks!", "> @saqibshakeel035 ,\r\n> Any update on the issue ?Thanks!\r\n\r\nThanks for your update on the issue,  I didn't read your previous comment and was waiting. Now I am gonna try again and than will update you in few hours.\r\n", "@saqibshakeel035 ,\r\nAny latest update ?Thanks!", "> @saqibshakeel035 ,\r\n> Any latest update ?Thanks!\r\n\r\nSorry for a late reply, Actually I am able to import TensorFlow  after installation using pip install --ignore-installed --upgrade tensorflow-gpu==1.15.0 but it gives me error after installation of protobuf using conda install -c anaconda protobuf, I get the same error mentioned above. ", "Any update as I am still stuck at this point????", "You don't need to install protobuf separately. Can you try and create a new virtual environment and install TF again without installing protobuf? Thanks!\r\nSee https://www.tensorflow.org/install/pip?lang=python3#2.-create-a-virtual-environment-recommended", "> You don't need to install protobuf separately. Can you try and create a new virtual environment and install TF again without installing protobuf? Thanks!\r\n> See https://www.tensorflow.org/install/pip?lang=python3#2.-create-a-virtual-environment-recommended\r\n\r\nIt worked fine. Just to mention one thing that if someone is using [Edge Electronics github repository](https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10#1-install-anaconda-cuda-and-cudnn) and facing the same issue as mine, I recommend you to install all other packages in step  [2d](https://github.com/EdjeElectronics/TensorFlow-Object-Detection-API-Tutorial-Train-Multiple-Objects-Windows-10#2d-set-up-new-anaconda-virtual-environment) and then install tensorflow using  `pip install --ignore-installed --upgrade tensorflow-gpu==1.15.0` . It worked for me. \r\nGood Luck!! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35208\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35208\">No</a>\n", "try resarting the cmd\r\n", "still got the same issue after following that guide xD", "Same here, I tried making a new virtual environment and used pip install --ignore-installed --upgrade tensorflow-gpu==1.15.0 this time but I ended up with the same error.", "I am facing this error when importing tensorflow (TypeError: expected bytes, Descriptor found ) and secondly when from keras.models import Sequential it render this error (Using TensorFlow backend.)"]}, {"number": 35207, "title": "Add additional padding layer to deconv converter to fix output_shape", "body": "- TensorFlow has the argument output_shape in Deconv API (conv2d_transpose) that specifies the output size, otherwise the output size is ambiguous if strides>1.\r\n- TRT API for IDeconvolution doesn't have such an argument, and thus the size of the TRT output tensor is off if stride>1.\r\n- This PR adds a padding layer on the output of Deconv if needed, in order to fix the output size.\r\n\r\n", "comments": []}, {"number": 35206, "title": "tf.function makes tf.keras.layers.LSTM significantly slower,  no leading to retracing", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution:  Linux Ubuntu 16.04 and 18.04.\r\n- TensorFlow installed from: pip\r\n- TensorFlow version: v2.0.0-rc2-26-g64c3d38 2.0.0\r\n- Python version:3.7.3\r\n- CUDA/cuDNN version: both (Nvidia 410.79, CUDA Version: 10.0) and (418.87.01, 10.1)\r\n- GPU model and memory: both 1080 and V100.\r\n\r\n**Describe the current behavior**\r\n  **case** 1. run normally in CPU mode.\r\n  **case** 2. run normally in eager mode in one GPU card, which is several times faster than the case 1.\r\n  **case**  3. run erroneously when using tf.function in train.py:_train_one_batch in one GPU card. I use input signature, and examine there are **no** extra retracing. The speed is much slower than that in the eager mode and almost the same with the CPU mode. I also found the GPU usage is close to 100%.\r\n\r\n**Describe the expected behavior**\r\n The case 3 should have similar speed with the case 2, and be faster than the case 1.\r\n\r\n**Code to reproduce the issue**\r\nI provide a reproducible test case.\r\n\r\n**Other info / logs**\r\nI\r\n[tf_2_mvp.zip](https://github.com/tensorflow/tensorflow/files/3976188/tf_2_mvp.zip)\r\n\r\n\r\n", "comments": ["I found a temporary solution.\r\nAdd @tf.function for all 'call' functions in _model.py, then the speed runs reasonably. But these new decorators are not necessary, since the _train_one_batch, invoking them, already has a @tf.function. \r\n\r\nHowever, the speed is still not the fastest, compared to pytorch. Let me recap my test results.\r\nAll hidden dims are set to 256, the batch size is 128.\r\n\r\ncase 1. run normally in CPU mode, about **6s.**\r\n\r\ncase 2. run normally in eager mode in one GPU card, which is several times faster than the case 1, about **2s.**\r\n\r\ncase 3. run erroneously when using tf.function in train.py:_train_one_batch in one GPU card. I use input signature, and examine there are no extra retracing. The speed is much slower than that in the eager mode and almost the same with the CPU mode. I also found the GPU usage is close to 100%. About **6s**.\r\n\r\ncase 4, add tf.function to all \"call\" in _model.py, about **0.4s**.\r\n\r\ncase 5, pytorch with the almost the same algorithm, is about **0.3s**. I have very carefully examined the implementation details of pytorch version!\r\n\r\nSo far the original issues has evolved to that, why adding tf.function to all invoked son functions are necessary? Otherwise, only tf.function for the top-level function would lead to huge speed slow down.", " My issue is the same with https://github.com/tensorflow/tensorflow/issues/35165. I replied my findings to that issue.\r\n\r\nPlease  help resolve this kind of issues, which would greatly influence our confidence of using tensorflow 2.0.", "In the nightly new version, the \"bug\" is solved. The tf.function on train_one_batch would not lead to \"extremely  slow speed\". However, the  speed is still much slower than pytorch version, 0.6s vs 0.3s."]}, {"number": 35205, "title": "Object detection producing incorrect results on mobile (ios)", "body": "Object detection SSD trained and tested to produce expected results in PC. \r\nhttp://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2018_01_28.tar.gz\r\nhttps://github.com/tensorflow/models/blob/master/research/object_detection/samples/configs/ssd_inception_v2_pets.config\r\n\r\nModel works well and produces accurate results on PC. \r\nAfter converting to tflite and loading in mobile, the camera view shows incorrect detection (several detection of same class and in fixed place even when moving the camera).", "comments": ["Found a similar reported issue - https://github.com/tensorflow/tensorflow/issues/25746", "@Lhogeshwaran, There is a objection detection model in Tflite for iOS.\r\nhttps://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/ios\r\n", "@Lhogeshwaran Could you also describe how exactly you loaded the model on mobile, and how you preprocessed the inputs?", "Thank you both! \r\n\r\n@yyoon I converted the model to the .tflite format, placed it inside ObjectDetection/Model and changed the ModelDataHandler modelInfo and labelInfo to point to the custom model.", "I used the saved_model.pb to check the output by capturing photos/videos using the mobile and using them to test in the system", "@Lhogeshwaran We see that you are using older version of tensorflow .Many bug have been fixed in latest version. We recommend that you upgrade to latest stable version of tensorflow 2.6.0 and let us know if the issue still persists in newer versions .Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35205\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/35205\">No</a>\n"]}, {"number": 35204, "title": "DLL load failed for Tensorflow-GPU==1.14/1.13 but not Tensorflow-GPU==2.0", "body": "**System information**\r\nCUDA Version: 10.2\r\nCUDNN Version: 7\r\nOS: Windows 10\r\nConda Version: 4.8\r\nPython version: 3.7.4\r\n\r\nI understand that this issue is common, however, I believe my case is sufficiently unique to warrant a new issue. Using the above versions of CUDA and CUDNN, after running `pip install tensorflow-gpu==2.0` and then importing the library in my conda virtual env, everything works. However, after uninstalling `tensorflow-gpu==2.0` and running `pip install tensorflow-gpu==1.14`, when importing I get:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\Harry\\Anaconda3\\envs\\tfv1\\lib\\site-packages\\tensorflow\\__init__.py\", line 28, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\Harry\\Anaconda3\\envs\\tfv1\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Harry\\Anaconda3\\envs\\tfv1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Harry\\Anaconda3\\envs\\tfv1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Harry\\Anaconda3\\envs\\tfv1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Harry\\Anaconda3\\envs\\tfv1\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Harry\\Anaconda3\\envs\\tfv1\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Harry\\Anaconda3\\envs\\tfv1\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n```\r\n\r\nI am confused because both versions of tensorflow-GPU are supposed to work with these versions of CUDA and CUDNN according to: https://www.tensorflow.org/install/source_windows.\r\n\r\nWhy I am I not facing any issues with `Tensorflow-GPU==2.0` but I am with `Tensorflow-GPU==1.14`?\r\n\r\nIf it is a compatibility issue, exactly what downgrades are necessary and why?\r\n\r\nI am trying to use an older version of Tensorflow so that I can follow along with: https://github.com/chrisdonahue/wavegan which is not written in version 2 of Tensorflow.\r\n", "comments": ["@HStuart18 \r\n\r\nPlease use cuda 10.0 against TF 1.13,1.14 and in addition to that make sure you add cuda, cudnn paths to your environment.Please, let us know how it progress. Thanks!", "I actually just decided to bite the bullet and convert my TF1 code to TF2, so I better close this issue. But it does seem that doing what you suggested would fix the problem since it is a compatibility issue.", "@HStuart18 Reason you are able to use TF 2.0 gpu and not TF 1.14 gpu is because; For releases 1.14 and older, CPU and GPU packages are separate.\r\nSee https://www.tensorflow.org/install/pip?lang=python3#older-versions-of-tensorflow\r\nSo when you use TF 2.0 gpu you are actually using TF cpu version as it requires cuda 10.0"]}, {"number": 35203, "title": "Overriding gradients in eager mode with TF 2 after the model is defined", "body": "When I wrote SHAP for TensorFlow 1.x I was able to temporarily override the gradient operators inside `tensorflow.python.framework.ops._gradient_registry._registry`. This allowed me to use the back-propagation mechanisms of TF to compute explainable AI methods on models that had already been defined by the user. I couldn't use the `gradient_override_map` since that would require the user to build their model within my SHAP context...and I need to assume they already have a model they have built. Since I can \"back-propagate\" explanations through non-differentiable functions I also need to temporarily override `tensorflow.python.ops.gradients_impl._IsBackpropagatable` so my gradient handlers get called everywhere and things don't get pruned from the graph. Both of these are not public APIs, but there was no other way I found to get it to work.\r\n\r\nNow in TF 2.0 I can't seem to replicate this while in eager mode. It looks like I can get everything to work using `tf.GradientTape` when everything between the input and the output is differentiable. But as soon as something that is not differentiable shows up (like ResourceGather) then it seems that in eager mode overriding `_IsBackpropagatable` no longer ensures that the gradient handlers will get called. I assume this is because the GradientTape doesn't think the \"watched\" tensor is connected to the output when the path through the graph includes non-differentiable operators. One would think that overriding  `_IsBackpropagatable` would fix this, but apparently not in TF 2.0 with eager mode. In fact I never see _IsBackpropagatable getting called at all in TF 2 eager mode. I was trying to figure out what the equivalent function is I can override, but with TF2 the GradientTape does all the primary work now in C++, so it is not as easy to trace through and get at what I need.\r\n\r\nAny advice? Thanks!", "comments": ["Quick update: It looks like the equivalent of `_IsBackpropagatable` in eager mode is now a hard-coded C++ type check on the op inputs at: https://github.com/tensorflow/tensorflow/blob/7b094e93b906f32b971b13c6b7fb5df75cde5cf6/tensorflow/c/eager/tape.h#L340-L369", "I finally worked around this by overriding `tensorflow.python.eager.execute.record_gradient` and temporarily lying about the index input type of `ResourceGather` making it a float instead of an int just during the duration of the C++ call `TFE_Py_RecordGradient`. This was the only way I could figure out to force the GradientTape to work with non-differential operators.\r\n\r\nSo while now things work, I am still very interested in suggestions to find a less hacky and hence more stable solution.", "Hi, I'm trying to implement [guided backprop](https://arxiv.org/abs/1412.6806) using tensorflow 2.0. For this, I need to override the gradient map to make ReLU layers rectify the gradient, example [here](https://stackoverflow.com/questions/38340791/guided-back-propagation-in-tensorflow). Using `custom_gradient` is far from ideal here since we want to use this custom gradient  computation in inference time only for interpretability and sometimes we just don't have easy access to the network code.\r\n\r\nI've search for some time now and the only solution I found without hacking the code seems to swap to graph mode, but this is not ideal since it removes all the other 2.0 capabilities that I was using. Is there an other way yet? Thanks in advance!", "I have a similar use case as @lerobitaille - I'd like to be able to override ReLU's default gradient calculation with a custom one. Previously it was possible to do it using `gradient_override_map`. Is there a way to replace gradient (even during the model loading is fine, too) in the eager execution of TensorFlow 2.0?", "To be able to override gradients use tf.custom_gradient.\r\n\r\nWe don't really support overriding these things after the fact, though, just before the model is created.\r\n"]}, {"number": 35202, "title": "fixes #35136", "body": "fixes #35136", "comments": ["We cannot accept PRs to `r2.0` or other release branches after the corresponding release has finished, except if they are related to a patch release for security.", "I tried changing base to `master` but there are some conflicting commits so it would need your work to rebase. Please reopen against `master`"]}, {"number": 35201, "title": "[Intel MKL] Fixed a bug in mkl_conv2d constant filter caching which c\u2026", "body": "\u2026aused the filter output tensor not get updated", "comments": []}]