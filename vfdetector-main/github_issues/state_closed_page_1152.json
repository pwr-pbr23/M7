[{"number": 18647, "title": "Ordered bijector", "body": "This PR implements the Ordered bijector. The Inverse of Ordered bijector maps a normal distributed vector `y ~ normal(0, 1)` to a sorted random vector that has the same distribution (i.e., `normal(0, 1)`)\r\nclose https://github.com/tensorflow/probability/issues/7\r\ncc @srvasude @dustinvtran ", "comments": ["@srvasude is that the only problem with this PR, or are you reviewing still?", "Still reviewing. I haven't gotten used to github review tool :) (so apologies for the accidental single comment).", "Np. When you're done, remove the \"awaiting review\" label.", "Thanks for reviewing! I only see the comment about copyright, is there anything else?", "@srvasude I am not sure if my changes are fully satisfactory, could you provide some further comments? ", "Apologies, thought the comments will auto-close. Taking a look now.", "Thanks for reviewing! @martinwicke "]}, {"number": 18646, "title": "Update debugger.md", "body": "Should be using normal softmax not sparse.", "comments": []}, {"number": 18645, "title": "Key LayerCollection/ff_fckron/concat_10_False/cov not found in checkpoint", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: NA\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n     Ubuntu 16.04 (ppc64le)\r\n- **TensorFlow installed from (source or binary)**:\r\n      Installed from source\r\n- **TensorFlow version (use command below)**:\r\n     TF1.6.0\r\n- **Python version**: \r\n     Python 2.7.5\r\n- **Bazel version (if compiling from source)**:\r\n       0.11.1\r\n- **CUDA/cuDNN version**:\r\n     NA\r\n- **GPU model and memory**:\r\n      NA\r\n- **Exact command to reproduce**:\r\n      bazel test -c opt //tensorflow/contrib/kfac/examples/tests:mlp_test\r\n\r\n### Describe the problem\r\nThis test passed successfully on x86 , however its failing on ppc64le with below error  - \r\n```\r\n\r\nINFO: From Testing //tensorflow/contrib/kfac/examples/tests:mlp_test:\r\n==================== Test output for //tensorflow/contrib/kfac/examples/tests:mlp_test:\r\n..WARNING:tensorflow:Estimator's model_fn (<function model_fn at 0x3fff9b1c45f0>) includes params argument, but params are not passed to Estimator.\r\n2018-04-18 10:12:24.430611: W tensorflow/core/framework/op_kernel.cc:1202] OP_REQUIRES failed at save_restore_v2_ops.cc:184 : Not found: Key LayerCollection/ff_fckron/concat_10_False/cov not found in checkpoint\r\nE..\r\n======================================================================\r\nERROR: testTrainMnistEstimator (__main__.MlpTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/contrib/kfac/examples/tests/mlp_test.py\", line 59, in testTrainMnistEstimator\r\n    mlp.train_mnist_estimator(data_dir=None, num_epochs=1, use_fake_data=True)\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/contrib/kfac/examples/mlp.py\", line 326, in train_mnist_estimator\r\n    estimator.train(input_fn=input_fn)\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/estimator/estimator.py\", line 352, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/estimator/estimator.py\", line 888, in _train_model\r\n    log_step_count_steps=self._config.log_step_count_steps) as mon_sess:\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/training/monitored_session.py\", line 384, in MonitoredTrainingSession\r\n    stop_grace_period_secs=stop_grace_period_secs)\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/training/monitored_session.py\", line 795, in __init__\r\n    stop_grace_period_secs=stop_grace_period_secs)\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/training/monitored_session.py\", line 518, in __init__\r\n    self._sess = _RecoverableSession(self._coordinated_creator)\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/training/monitored_session.py\", line 981, in __init__\r\n    _WrappedSession.__init__(self, self._create_session())\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/training/monitored_session.py\", line 986, in _create_session\r\n    return self._sess_creator.create_session()\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/training/monitored_session.py\", line 675, in create_session\r\n    self.tf_sess = self._session_creator.create_session()\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/training/monitored_session.py\", line 446, in create_session\r\n    init_fn=self._scaffold.init_fn)\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/training/session_manager.py\", line 275, in prepare_session\r\n    config=config)\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/training/session_manager.py\", line 207, in _restore_checkpoint\r\n    saver.restore(sess, ckpt.model_checkpoint_path)\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/training/saver.py\", line 1755, in restore\r\n    {self.saver_def.filename_tensor_name: save_path})\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 905, in run\r\n    run_metadata_ptr)\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 1137, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 1355, in _do_run\r\n    options, run_metadata)\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 1374, in _do_call\r\n    raise type(e)(node_def, op, message)\r\nNotFoundError: Key LayerCollection/ff_fckron/concat_10_False/cov not found in checkpoint\r\n         [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\r\n\r\nCaused by op u'save/RestoreV2', defined at:\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/contrib/kfac/examples/tests/mlp_test.py\", line 63, in <module>\r\n    tf.test.main()\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/platform/test.py\", line 76, in main\r\n    return _googletest.main(argv)\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/platform/googletest.py\", line 99, in main\r\n    benchmark.benchmarks_main(true_main=main_wrapper)\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/platform/benchmark.py\", line 338, in benchmarks_main\r\n    true_main()\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/platform/googletest.py\", line 98, in main_wrapper\r\n    return app.run(main=g_main, argv=args)\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/platform/app.py\", line 126, in run\r\n    _sys.exit(main(argv))\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/platform/googletest.py\", line 69, in g_main\r\n    return unittest_main(argv=argv)\r\n  File \"/usr/lib/python2.7/unittest/main.py\", line 95, in __init__\r\n    self.runTests()\r\n  File \"/usr/lib/python2.7/unittest/main.py\", line 232, in runTests\r\n    self.result = testRunner.run(self.test)\r\n  File \"/usr/lib/python2.7/unittest/runner.py\", line 151, in run\r\n    test(result)\r\n  File \"/usr/lib/python2.7/unittest/suite.py\", line 70, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"/usr/lib/python2.7/unittest/suite.py\", line 108, in run\r\n    test(result)\r\n  File \"/usr/lib/python2.7/unittest/suite.py\", line 70, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"/usr/lib/python2.7/unittest/suite.py\", line 108, in run\r\n    test(result)\r\n  File \"/usr/lib/python2.7/unittest/case.py\", line 393, in __call__\r\n    return self.run(*args, **kwds)\r\n  File \"/usr/lib/python2.7/unittest/case.py\", line 329, in run\r\n    testMethod()\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/contrib/kfac/examples/tests/mlp_test.py\", line 59, in testTrainMnistEstimator\r\n    mlp.train_mnist_estimator(data_dir=None, num_epochs=1, use_fake_data=True)\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/contrib/kfac/examples/mlp.py\", line 326, in train_mnist_estimator\r\n    estimator.train(input_fn=input_fn)\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/estimator/estimator.py\", line 352, in train\r\n    loss = self._train_model(input_fn, hooks, saving_listeners)\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/estimator/estimator.py\", line 888, in _train_model\r\n    log_step_count_steps=self._config.log_step_count_steps) as mon_sess:\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/training/monitored_session.py\", line 384, in MonitoredTrainingSession\r\n    stop_grace_period_secs=stop_grace_period_secs)\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/training/monitored_session.py\", line 795, in __init__\r\n    stop_grace_period_secs=stop_grace_period_secs)\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/training/monitored_session.py\", line 518, in __init__\r\n    self._sess = _RecoverableSession(self._coordinated_creator)\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/training/monitored_session.py\", line 981, in __init__\r\n    _WrappedSession.__init__(self, self._create_session())\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/training/monitored_session.py\", line 986, in _create_session\r\n    return self._sess_creator.create_session()\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/training/monitored_session.py\", line 675, in create_session\r\n    self.tf_sess = self._session_creator.create_session()\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/training/monitored_session.py\", line 437, in create_session\r\n    self._scaffold.finalize()\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/training/monitored_session.py\", line 214, in finalize\r\n    self._saver.build()\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/training/saver.py\", line 1302, in build\r\n    self._build(self._filename, build_save=True, build_restore=True)\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/training/saver.py\", line 1339, in _build\r\n    build_save=build_save, build_restore=build_restore)\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/training/saver.py\", line 790, in _build_internal\r\n    restore_sequentially, reshape)\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/training/saver.py\", line 502, in _AddShardedRestoreOps\r\n    name=\"restore_shard\"))\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/training/saver.py\", line 449, in _AddRestoreOps\r\n    restore_sequentially)\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/training/saver.py\", line 847, in bulk_restore\r\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/ops/gen_io_ops.py\", line 1030, in restore_v2\r\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/framework/ops.py\", line 3271, in create_op\r\n    op_def=op_def)\r\n  File \"/root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/bin/tensorflow/contrib/kfac/examples/tests/mlp_test.runfiles/org_tensorflow/tensorflow/python/framework/ops.py\", line 1650, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nNotFoundError (see above for traceback): Key LayerCollection/ff_fckron/concat_10_False/cov not found in checkpoint\r\n         [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, ..., DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_INT64], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\r\n\r\n\r\n----------------------------------------------------------------------\r\nRan 5 tests in 3.637s\r\n\r\nFAILED (errors=1)\r\n================================================================================\r\nTarget //tensorflow/contrib/kfac/examples/tests:mlp_test up-to-date:\r\n  bazel-bin/tensorflow/contrib/kfac/examples/tests/mlp_test\r\nINFO: Elapsed time: 5.752s, Critical Path: 5.12s\r\nINFO: Build completed, 1 test FAILED, 2 total actions\r\n//tensorflow/contrib/kfac/examples/tests:mlp_test                        FAILED in 5.1s\r\n  /root/.cache/bazel/_bazel_root/f1b093cb2d3fbb9bf169263a57926f78/execroot/org_tensorflow/bazel-out/ppc-opt/testlogs/tensorflow/contrib/kfac/examples/tests/mlp_test/test.log\r\n\r\nExecuted 1 out of 1 test: 1 fails locally.\r\n\r\n```\r\n\r\nI have started looking into the issue. \r\nPlease provide if any suggestions/inputs on what would be the reason of failure. Thanks! ", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 22 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "This test is passing in TF master, hence closing this issue."]}, {"number": 18644, "title": "TensorBoard not running correctly with TF 1.8.0-rc0", "body": "Hi, I upgraded TF to 1.8.0-rc0 to use the new `tf.data.prefetch_to_device()` feature. But with this version tensorboard won't run well. Here is output when I run tensorboard.\r\n![image](https://user-images.githubusercontent.com/13655756/38924425-e7eb7f16-4337-11e8-81a9-5b07dfcf39a1.png)\r\n(The command was valid when I entered with TF 1.7.)\r\nAlso when I entered to the tensorboard on the browser, tensorboard page opened but no event was displayed.\r\n![image](https://user-images.githubusercontent.com/13655756/38924904-1ec3ab3e-4339-11e8-94e3-233242a0f14b.png)\r\n\r\n\r\nEnvironment info\r\nTF version: ('v1.7.0-1569-g3970b47da5', '1.8.0-rc0')\r\nOperating System: Ubuntu 16.04.3\r\nInstalled version of CUDA and cuDNN: CUDA 9.0 and cuDNN 7 but I guess it's not CUDA related.\r\n\r\nThe latest version of TensorBoard is still 1.7.0, so there might be a reason for the problem.\r\n\r\nThank you for your hard working :^)", "comments": ["I also encountered the same problem!", "This is probably because you are using a Tensorboard of version 1.7.0, which must have been already fixed in its corresponding release. See tensorflow/tensorboard#1086 for a dispatching solution that handles both version of `_reader.GetNext()`, which might already have fixed the issue in TB 1.8.\r\n\r\nBut why TF core has changed its API? As a result, it seems that there are some kind of requirements that minor versions of TF and TB should match.", "Nagging Assignee @rohan100jain: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Apologies for the backwards incompatible change that was made but following the discussion on the PR pointed out by @wookayin, this should work now. Can you confirm?", "I found new version of tensorboard(tensorboard-1.8.0) is installed when I install tensorflow-gpu-1.8.0, and I works well! I think this issue can be closed!\r\n\r\nThanks for your hard working!"]}, {"number": 18643, "title": "TensorFlow 1.8.0-rc1 fails on aarch64 platforms", "body": "Building TensorFlow 1.8.0-rc0 from source fails on aarch64 platforms (NVIDIA TX1 and Linaro HiKey960) with a linking error for some Neon function:\r\n```\r\nLinking of rule '//tensorflow/cc:ops/remote_fused_graph_ops_gen_cc' failed (Exit 1)\r\nbazel-out/host/bin/_solib_arm/_U_S_Stensorflow_Scc_Cops_Sremote_Ufused_Ugraph_Uops_Ugen_Ucc___Utensorflow/libtensorflow_framework.so: error: undefined reference to 'png_init_filter_functions_neon'\r\n```\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A (a build problem)\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04 (JetPack 3.1)\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.8.0-rc0\r\n- **Python version**: 2.7.12\r\n- **Bazel version (if compiling from source)**: 0.12.0\r\n- **GCC/Compiler version (if compiling from source)**: 5.4.1\r\n- **CUDA/cuDNN version**: N/A (CPU ony)\r\n- **GPU model and memory**: N/A (CPU only)\r\n- **Exact command to reproduce**: Install dependencies and build via [CK-TensorFlow](github.com/ctuning/ck-tensorflow):\r\n```\r\n$ sudo apt install liblapack-dev libatlas-dev\r\n$ sudo pip install enum34 mock pillow wheel absl-py scipy ck\r\n$ ck pull repo:ck-tensorflow\r\n$ ck install ck-env:package:tool-bazel-0.12.0-linux\r\n$ ck install package:lib-tensorflow-1.8.0-src-cpu --env.CK_HOST_CPU_NUMBER_OF_PROCESSORS=1\r\n```\r\n**NB:** Restricting the number of building processes to 1 is necessary to prevent running out of memory on the NVIDIA TX1 platform (4 GB and no swap enabled) or similar.\r\n\r\n### Describe the problem\r\n\r\nBuilding TensorFlow 1.8.0-rc0 fails on aarch64 platforms (NVIDIA TX1 and Linaro HiKey960). Similar instructions for TensorFlow 1.7.0 with Bazel 0.11.1 worked well (both with and without XLA support):\r\n```\r\n$ ck install package:lib-tensorflow-1.7.0-src-cpu --env.CK_HOST_CPU_NUMBER_OF_PROCESSORS=1\r\n$ ck install package:lib-tensorflow-1.7.0-src-cpu-xla --env.CK_HOST_CPU_NUMBER_OF_PROCESSORS=1\r\n\r\n$ ck show env --tags=tensorflow,v1.7\r\nEnv UID:         Target OS: Bits: Name:                                       Version: Tags:\r\n\r\ned191cc45dda7ee4   linux-64    64 TensorFlow library (from sources, cpu, xla) 1.7      64bits,bazel,channel-stable,host-os-linux-64,lib,needs-bazel,needs-bazel-0.11.1,target-os-linux-64,tensorflow,tensorflow-cpu,v1,v1.7,v1.7.0,vcpu,vsrc,vxla\r\ned191cc45dda7ee3   linux-64    64 TensorFlow library (from sources, cpu)      1.7      64bits,bazel,channel-stable,host-os-linux-64,lib,needs-bazel,needs-bazel-0.11.1,target-os-linux-64,tensorflow,tensorflow-cpu,v1,v1.7,v1.7.0,vcpu,vsrc\r\n```\r\n\r\n### Source code / logs\r\n```\r\nERROR: /home/anton/CK_TOOLS/lib-tensorflow-src-cpu-1.8-linux-64/src/tensorflow/cc/BUILD:510:1: Linking of rule '//tensorflow/cc:ops/remote_fused_graph_ops_gen_cc' failed (Exit 1)\r\nbazel-out/host/bin/_solib_arm/_U_S_Stensorflow_Scc_Cops_Sremote_Ufused_Ugraph_Uops_Ugen_Ucc___Utensorflow/libtensorflow_framework.so: error: undefined reference to 'png_init_filter_functions_neon'\r\ncollect2: error: ld returned 1 exit status\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 15373.402s, Critical Path: 153.22s\r\nFAILED: Build did NOT complete successfully\r\n```", "comments": ["Getting same error when building Tensorflow master with the same system information and Bazel 0.12.0. With Cuda 9.0 on Tx2", "Im getting the same error when building Tensorflow master and Bazel 0.11.1.", "FWIW, I've got a different error building TensorFlow 1.7.0 using Bazel 0.12.0 on Linaro HiKey960:\r\n```\r\n$ ck install package:lib-tensorflow-1.7.0-src-cpu --env.CK_HOST_CPU_NUMBER_OF_PROCESSORS=2\r\n...\r\nERROR: /home/anton/.cache/bazel/_bazel_anton/19f8e08691d47ead673afa362fc193f9/external/jpeg/BUILD:269:1: C++ compilation of rule '@jpeg//:simd_armv7a' failed (Exit 1)                                                                                                   \r\ngcc: error: unrecognized command line option '-mfloat-abi=softfp'                                                       \r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build                                                                                                                                                                                                  \r\nUse --verbose_failures to see the command lines of failed build steps.                                            \r\nINFO: Elapsed time: 668.059s, Critical Path: 63.27s                                                                                                                                                                                                                      \r\nFAILED: Build did NOT complete successfully\r\n```\r\nSmells like a Bazel 0.12.0 problem separate from the issue reported here.\r\n\r\n**Update:** Reported this Bazel 0.12.0 issue here: https://github.com/bazelbuild/bazel/issues/5080", "@gunan could you please take a look?", "@andrewharp @petewarden What are the instructions to build on TX1?", "@gunan You can simply follow Collective Knowledge based instructions above. They encapsulate a couple of patches our community found necessary on aarch64 systems (including TX1). ", "@psyhtest Thanks for the pointer. However I am reaching out to my teammates who I know has looked into running and building TF on NVIDIA Tegra TX1 before, to check if we have any official instructions somewhere. Sorry for the ambiguous question I posted above.", "@gunan No problem at all. Just wanted to help you reduce the drudgery to the minimum and accelerate time-to-solution :). I believe our community has built TensorFlow 1.7 using the CK based instructions on at least 5 aarch64 platforms...", "I confirm @WilliamJuel's finding that 1.8.0-rc0 fails with Bazel 0.11.1 too:\r\n```\r\nERROR: /home/anton/CK_TOOLS/lib-tensorflow-src-cpu-1.8-linux-64/src/tensorflow/contrib/lite/toco/BUILD:395:1: Linking of rule '//tensorflow/contrib/lit\r\ne/toco:toco' failed (Exit 1)\r\nbazel-out/arm-opt/bin/_solib_arm/_U_S_Stensorflow_Scontrib_Slite_Stoco_Ctoco___Utensorflow/libtensorflow_framework.so: error: undefined reference to 'png_init_filter_functions_neon'\r\ncollect2: error: ld returned 1 exit status\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 31484.303s, Critical Path: 156.89s\r\n```", "I confirm I have found the same error on Jetson TX2 with r1.8 and bazel 0.12\r\n", "More concretely:\r\n```\r\nERROR: /home/nvidia/Documents/tensorflow/tensorflow/python/BUILD:1569:1: Linking of rule '//tensorflow/python:gen_set_ops_py_wrappers_cc' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command \r\n  (cd /home/nvidia/.cache/bazel/_bazel_nvidia/38f510ce87073e6e7989e37d45036c24/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=/usr/local/cuda/lib64/: \\\r\n    PATH=/usr/local/cuda/bin/:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin \\\r\n    PWD=/proc/self/cwd \\\r\n  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -o bazel-out/host/bin/tensorflow/python/gen_set_ops_py_wrappers_cc '-Wl,-rpath,$ORIGIN/../../_solib_local/_U_S_Stensorflow_Spython_Cgen_Uset_Uops_Upy_Uwrappers_Ucc___Utensorflow' '-Wl,-rpath,$ORIGIN/../../_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccudart___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib' -Lbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Uset_Uops_Upy_Uwrappers_Ucc___Utensorflow -Lbazel-out/host/bin/_solib_local/_U@local_Uconfig_Ucuda_S_Scuda_Ccudart___Uexternal_Slocal_Uconfig_Ucuda_Scuda_Scuda_Slib '-Wl,-rpath,$ORIGIN/,-rpath,$ORIGIN/..' -Wl,-z,notext -Wl,-z,notext -Wl,-rpath,../local_config_cuda/cuda/lib64 -Wl,-rpath,../local_config_cuda/cuda/extras/CUPTI/lib64 -pthread -Wl,-no-as-needed -B/usr/bin/ -pie -Wl,-z,relro,-z,now -no-canonical-prefixes -pass-exit-codes '-Wl,--build-id=md5' '-Wl,--hash-style=gnu' -Wl,--gc-sections -Wl,-S -Wl,@bazel-out/host/bin/tensorflow/python/gen_set_ops_py_wrappers_cc-2.params)\r\nbazel-out/host/bin/_solib_local/_U_S_Stensorflow_Spython_Cgen_Uset_Uops_Upy_Uwrappers_Ucc___Utensorflow/libtensorflow_framework.so: undefined reference to `png_init_filter_functions_neon'\r\ncollect2: error: ld returned 1 exit status\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 4073.346s, Critical Path: 358.03s\r\n```\r\n ", "1.8.0-rc1 fails too; also on Firefly-RK3399.", "I can confirm (as stated above) that  TensorFlow 1.7.0 with Bazel 0.11.1 works. But i have to change the hardcoded x86 paths to aarch64 in tensorflow....", "@WilliamJuel Interesting. Could you please provide a couple of examples what you need to do? I don't think we need to change anything with our automatic Collective Knowledge workflow. By the way, feel free to give it a try to see if it's easier than what you have to do currently.", "Potentially the same/related issue - the nightly Raspberry Pi builds are hitting this (and have been failing for several weeks now):\r\nhttp://ci.tensorflow.org/view/Nightly/job/nightly-pi/245/console", "I think on our end, our bazel build did not work on tegra tx1 yet. As far as I can learn internally our makefile build was working on tx1 last we experimented.\r\nI will keep on looking to see if we have docs or instructions.", "@gunan I believe one does need to patch Bazel on TX1 but the Collective Knowledge package takes care of that. So you can install Bazel using one CK command, and then TensorFlow using another one. (Just copy and paste the instructions from the top of the issue, and give it about 8-9 hours on TX1.)\r\n\r\nThis will allow you to reproduce the issue in the least painful way. As you can see from other reports, it's not specific to using CK for TensorFlow installation. ", "What I am trying to say is, we never officially made it working. It may or may not work, but we got the makefile build working.\r\nI will mark this issue contributions welcome. I will add our official status later when I have it.", "@gunan What I mean is that we've been able to build TensorFlow on TX1 since 1.4.0. 1.8.0-rc0 was the first to break.\r\n\r\nIf TX1 is not officially supported, then surely Raspberry Pi is (if it's part of the nightlies)? I agree with @jessebenson - it looks like the same issue. Would it be easier for you to investigate it there? I could help you then test across other aarch64 platforms I have access to (TX1, HiKey960, RK3399)?", "If you google (sorry) for the name of the function (`png_init_filter_functions_neon`), you may find similar issues e.g. https://github.com/opencv/opencv/issues/7600. ", "Nightlies mean we are working on it. If it is released as an artifact during releases, or announced during releases that means we have official support for it.\r\nWe definitely want tensorflow to build and work properly on both TX1 and Raspberry Pi.\r\nHowever, we want to make sure we have proper infrastructure to continuously build and test it before we announce our official support.", "@psyhtest - yeah I looked into this yesterday, and found the same link you pointed out.  I was able to get the Raspberry Pi nightlies to build by adding `--copt=-DPNG_ARM_NEON_OPT=0` - see (https://github.com/jessebenson/tensorflow/commit/b135e2d9a234e23cebc7b6d63043b40b07e76a1a).  I didn't include this in my pull request (https://github.com/tensorflow/tensorflow/pull/18892), as I'm not sure if that's the desired fix.", "@jessebenson  Yes. It works. I build tensorflow-1.8.0rc1-cp27-cp27mu-linux_aarch64.whl and work successfully.\r\nI also created a patch for this. Could I create a new PR for this ? \r\n\r\nUpdated:\r\nBut I think this may not best fix. Maybe we should try to add aarch64_linux arch to formal config files ?\r\nCurrently, we have \"android_x86,android_x86_64,raspberry_pi_armeabi,android_arm,android_mips64,linux_x86_64\" and so on.\r\nIn many config file, we can do like this\r\n```\r\n    copts = select({\r\n        \"@org_tensorflow//tensorflow:aarch64_linux\": [\r\n            \"-DPNG_ARM_NEON_OPT=0\",\r\n        ],\r\n        \"@org_tensorflow//tensorflow:windows_msvc\": [\r\n            \"/DHAVE_CONFIG_H\",\r\n            \"/EHsc\",\r\n        ]\r\n    }),\r\n```\r\nPatch\r\n```\r\ndiff --git a/third_party/png.BUILD b/third_party/png.BUILD\r\nindex 76ab32d..bc4551a 100644\r\n--- a/third_party/png.BUILD\r\n+++ b/third_party/png.BUILD\r\n@@ -35,6 +35,7 @@ cc_library(\r\n     ],\r\n     includes = [\".\"],\r\n     linkopts = [\"-lm\"],\r\n+    copts = [\"-DPNG_ARM_NEON_OPT=0\"],\r\n     visibility = [\"//visibility:public\"],\r\n     deps = [\"@zlib_archive//:zlib\"],\r\n )\r\n```", "@jessebenson @peterlee0127 Thanks for the update! We'll give it a go.", "@peterlee0127 I've incorporated your patch into [`ck-tensorflow:package:lib-tensorflow-1.8.0-src-cpu`](https://github.com/ctuning/ck-tensorflow/tree/master/package/lib-tensorflow-1.8.0-src-cpu), and also tested that (the latest) TensorFlow v1.8.0 can be built with (the latest) Bazel v0.13.0:\r\n```\r\n$ sudo apt install liblapack-dev libatlas-dev\r\n$ sudo pip install enum34 mock pillow wheel absl-py scipy ck\r\n$ ck pull repo:ck-tensorflow\r\n$ ck install ck-env:package:tool-bazel-0.13.0-linux\r\n$ ck install package:lib-tensorflow-1.8.0-src-cpu [--env.CK_HOST_CPU_NUMBER_OF_PROCESSORS=1]\r\n```\r\nSpecifically, here's how I built on:\r\n- Firefly RK3399 (4 GB RAM, with swap):\r\n```\r\n$ ck install package:lib-tensorflow-1.8.0-src-cpu --env.CK_HOST_CPU_NUMBER_OF_PROCESSORS=3\r\n...\r\nInstallation time: 24036.3912299 sec.\r\n```\r\n- Linaro HiKey960 (3 GB RAM, with swap):\r\n```\r\n$ ck install package:lib-tensorflow-1.8.0-src-cpu --env.CK_HOST_CPU_NUMBER_OF_PROCESSORS=2\r\n...\r\nInstallation time: 28039.245172 sec.\r\n```\r\n\r\n- Jetson TX1 (4 GB RAM, without swap):\r\n```\r\n$ ck install package:lib-tensorflow-1.8.0-src-cpu --env.CK_HOST_CPU_NUMBER_OF_PROCESSORS=1\r\n...\r\nInstallation time: 51031.3029599 sec.\r\n```\r\n(In other words, it took less than 7 hours on RK3399, and more than 14 hours on TX1.)\r\n\r\nLook forward to a more elegant solution to appear in TensorFlow v1.9.0, so this workaround is no longer needed.", "In TX2, it still need about 3 hours. We should use cross compiler for building whl file in the future.", "@peterlee0127 Agree but it sounds a bit scary given all the dependencies.\r\n\r\n**Update:** ... and @petewarden's advice in [\"Building Mobile Applications with TensorFlow\"](https://www.oreilly.com/data/free/building-mobile-applications-with-tensorflow.csp):\r\n> it can be challenging to run directly on devices that have limited resources, such as the Raspberry Pi. It\u2019s also not easy to set up cross-compilation if you\u2019re compiling on a different machine than you\u2019re deploying to", "By the way, for [ReQuEST](https://github.com/dividiti/ck-request-asplos18-mobilenets-armcl-opencl), I've run MobileNets-v1 on the [Firefly RK3399](http://en.t-firefly.com/product/rk3399.html) platform using TensorFlow v1.7 and v1.8. The experiments were repeated 50 times at the highest CPU frequencies (2x Cortex-A72 @ 1800 MHz; 4x Cortex-A53 @ 1416 MHz). The minimum and the maximum execution times for each model are plotted below vs. the top 1 accuracy on a set of 500 images. Given that the CPU frequencies were fixed and that the CPU temperature never exceeded 40 Celsium, I guess that the large execution time variation is due to vagaries of big.LITTLE scheduling.\r\n\r\n/cc @petewarden \r\n\r\n![firefly-accuracy_top1-500-tf-complete](https://user-images.githubusercontent.com/6597818/39606680-80ac2e1a-4f2e-11e8-922b-1d6f884b3315.png)\r\n\r\nHere's how to read the plot:\r\n- The _colour_ of a marker denotes the version of TensorFlow: v1.8 - blue, v1.7 - cyan.\r\n- The _size_ of a marker is proportional to the input resolution: 224 (the largest), 192, 160, 128 (the smallest).\r\n- The _shape_ of a marker denotes both the channel multiplier and the execution time metric:\r\n  - Minimum execution time: 1.00 - pentagon, 0.75 - square, 0.50 - triangle-up, 0.25 - circle.\r\n  - Maximum execution time: 1.00 - star, 0.75 - diamond, 0.50 - triangle-down, 0.25 - octagon.\r\n\r\n**NB:** Roughly speaking, a shape has **N** corners for the channel multiplier of **(N-1) * 0.25**:\r\n- 5 corners for the channel multiplier of 1.00 (pentagon or star);\r\n- 4 corners for the channel multiplier of 0.75 (square or diamond);\r\n- 3 corners for the channel multiplier of 0.50 (triangle-up or triangle-down); \r\n- \"no corners\" for the channel multiplier of 0.25 (circle or octagon).", "@gunan - can you take a look at this PR as well?  https://github.com/tensorflow/tensorflow/pull/18892  I want to get the official binaries built so I can extend Tensorflow for C# (https://github.com/migueldeicaza/TensorFlowSharp) to use ARM natively.", "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you.", "As a update for this issue. This issue was patch at\r\nhttps://github.com/tensorflow/tensorflow/commit/f0a506f67fe316c3adb282b58b7087e11d7c493f", "This issue is fixed at head.\r\nAs 1.8 did not have official support for this platform, we will not patch the previous release."]}, {"number": 18642, "title": "Keras models fit() method not converging with eager execution", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes, see below.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nUbuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:\r\nBinary, with pip3\r\n- **TensorFlow version (use command below)**:\r\nv1.7.0-3-g024aecf414 1.7.0\r\n- **Python version**: \r\n3.5.2\r\n- **Bazel version (if compiling from source)**:\r\nN/A\r\n- **GCC/Compiler version (if compiling from source)**:\r\nN/A\r\n- **CUDA/cuDNN version**:\r\n9.0.176/7.0.5\r\n- **GPU model and memory**:\r\nGTX 1080 (Armor MSI) with 8 GB VRAM\r\n- **Exact command to reproduce**:\r\nRun program below\r\n\r\n### Describe the problem\r\n\r\nAfter enabling eager execution, method `tf.keras.models.Sequential.fit()` doesn't seem to converge, as the computed loss doesn't go down (stays around 9 to 11); also, method `fit()` doesn't report the requested metric \"accuracy\": it doesn't print the metric to console, and does not return it in the History object.\r\n\r\nAfter disabling eager execution, the same optimization converges, as loss goes down (to around 1); also, method `fit()` correctly reports the requested metric \"accuracy\", both to console and in the returned History object.\r\n\r\n### Source code / logs\r\n\r\n```\r\nimport os\r\nimport pandas as pd\r\nimport numpy as np\r\nimport time\r\nimport matplotlib.pyplot as plt\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.eager as tfe\r\n\r\n\"\"\"\r\nCheck the beginning of main() for parameters\r\n\"\"\"\r\n\r\n\r\ndef load_data(folder):\r\n    file_name = os.path.join(folder, 'winequality-data.csv')\r\n    if os.path.isfile(file_name):\r\n        data = pd.read_csv(file_name)\r\n    else:\r\n        print('File {} not found.'.format(file_name, folder))\r\n        print('Dataset can be downloaded from https://www.kaggle.com/c/uci-wine-quality-dataset/data')\r\n        exit(1)\r\n    # solutions = pd.read_csv(os.path.join(folder, 'winequality-solution-input.csv'))\r\n    return data\r\n\r\n\r\ndef train_input_fn(features, labels, batch_size):\r\n    features_tensor = tf.constant(features)\r\n    labels_tensor = tf.constant(labels)\r\n    # Convert the inputs to a Dataset.\r\n    dataset = tf.data.Dataset.from_tensor_slices((features_tensor, labels_tensor))\r\n\r\n    # Shuffle, repeat, and batch the examples.\r\n    dataset = dataset.shuffle(len(labels)).repeat(count=1).batch(batch_size)\r\n\r\n    # Return the dataset.\r\n    return dataset\r\n\r\n\r\ndef loss(model, X, y):\r\n    logits = model(X)\r\n    the_loss = tf.losses.sparse_softmax_cross_entropy(labels=y, logits=logits)\r\n    return the_loss\r\n\r\n\r\ndef grad(model, inputs, targets):\r\n    with tfe.GradientTape() as tape:\r\n        loss_value = loss(model, inputs, targets)\r\n    return tape.gradient(loss_value, model.variables)\r\n\r\n\r\ndef train(model, X, y, batch_size, epochs):\r\n    train_ds = train_input_fn(X, y, batch_size=batch_size)\r\n    optimizer = tf.train.AdamOptimizer()\r\n\r\n    loss_by_epoch = []\r\n    accuracy_by_epoch = []\r\n\r\n    for epoch in range(epochs):\r\n        epoch_loss_avg = tfe.metrics.Mean()\r\n        epoch_error = tfe.metrics.Mean()\r\n        for batch, (batch_X, batch_y) in enumerate(tfe.Iterator(train_ds)):\r\n            grads = grad(model, batch_X, batch_y)\r\n            optimizer.apply_gradients(zip(grads, model.variables), global_step=tf.train.get_or_create_global_step())\r\n            epoch_loss_avg(loss(model, batch_X, batch_y))\r\n            correct_prediction = tf.equal(tf.argmax(model(batch_X), axis=1, output_type=tf.int32), batch_y)\r\n            epoch_error(tf.reduce_mean(tf.cast(correct_prediction, tf.float32)))\r\n        print('Epoch {}:  loss={}  accuracy={}'.format(epoch, epoch_loss_avg.result(), epoch_error.result()))\r\n        loss_by_epoch.append(epoch_loss_avg.result())\r\n        accuracy_by_epoch.append(epoch_error.result())\r\n\r\n    return loss_by_epoch, accuracy_by_epoch\r\n\r\n\r\ndef main():\r\n    # Just comment the next line out to disable eager execution\r\n    tf.enable_eager_execution()\r\n\r\n    \"\"\"\r\n    Set use_fit to True to optimize by calling tf.keras.models.Sequential.fit(),\r\n    set to False to use tfe.GradientTape() instead. Note that in order to use tfe.Gradient.tape(),\r\n    eager execution must be enabled\r\n    \"\"\"\r\n    use_fit = True\r\n\r\n    epochs = 200\r\n    batch_size = 64\r\n    dataset_folder = '.'\r\n\r\n    # Load dataset and convert it to numpy arrays\r\n    data = load_data(dataset_folder)\r\n    train_X = data.iloc[:, 0:11].values.astype(np.float32)\r\n    train_y = data.iloc[:, 11].values.astype(np.int32)\r\n\r\n    if use_fit:  # train_y needs to be 1-hot encoded for usage with model.fit()\r\n        train_y = tf.keras.utils.to_categorical(train_y, num_classes=11)\r\n\r\n    model = tf.keras.models.Sequential([\r\n        tf.keras.layers.InputLayer(input_shape=(11,)),\r\n        tf.keras.layers.Dense(64, activation='relu'),\r\n        tf.keras.layers.Dense(32, activation='relu'),\r\n        tf.keras.layers.Dense(11, activation='softmax') if use_fit else tf.keras.layers.Dense(11)\r\n    ])\r\n\r\n    start = time.time()\r\n\r\n    if use_fit:\r\n        optimizer = tf.train.AdamOptimizer()\r\n        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\r\n        history = model.fit(x=train_X, y=train_y, epochs=epochs, batch_size=batch_size, verbose=2)\r\n        loss_by_epoch = history.history['loss']\r\n        accuracy_by_epoch = history.history['acc'] if 'acc' in history.history else []\r\n\r\n    else:\r\n        loss_by_epoch, accuracy_by_epoch = train(model=model, X=train_X, y=train_y, batch_size=batch_size,\r\n                                                 epochs=epochs)\r\n\r\n    end = time.time()\r\n    print('It took {} seconds'.format(end - start))\r\n\r\n    # Chart loss and error\r\n    fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\r\n    fig.suptitle('Training Metrics')\r\n\r\n    axes[0].set_ylabel(\"Loss\", fontsize=14)\r\n    axes[0].plot(loss_by_epoch)\r\n\r\n    axes[1].set_ylabel(\"Accuracy\", fontsize=14)\r\n    axes[1].set_xlabel(\"Epoch\", fontsize=14)\r\n    axes[1].plot(accuracy_by_epoch)\r\n\r\n    plt.show()\r\n\r\n\r\nif __name__ == '__main__':\r\n    main()\r\n\r\n```", "comments": ["Thank you for the bug report. We have a fix for this issue, that will show up on GitHub soon."]}, {"number": 18641, "title": "i think it can add a Factorization Machines module", "body": "", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 22 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 18639, "title": "Remove useless duplicate lines in *.py files", "body": "This PR is to remove useless duplicate lines in *.py files.\r\n\r\nWrote a regex script to scan throught the python files in the repo, and found the remaining useless duplicate lines like [saver_test.py#L104](https://github.com/imsheridan/tensorflow/blob/master/tensorflow/contrib/eager/python/saver_test.py#L104):\r\n>       self.assertEqual(v1.read_value().numpy(), 1.0)\r\n>       self.assertEqual(v1.read_value().numpy(), 1.0)", "comments": ["Cool, thanks!"]}, {"number": 18638, "title": "DO NOT MERGE: Test remote cache on Windows", "body": "This is just a test for internal change on github presubmit", "comments": ["Nagging Assignee @martinwicke: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 18637, "title": "R1.8", "body": "ERROR: testFreezeGraphV1 (__main__.FreezeGraphTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"freeze_graph_test.py\", line 162, in testFreezeGraphV1\r\n    self._testFreezeGraph(saver_pb2.SaverDef.V1)\r\n  File \"freeze_graph_test.py\", line 100, in _testFreezeGraph\r\n    checkpoint_version=saver_write_version)\r\nTypeError: freeze_graph() got an unexpected keyword argument 'checkpoint_version'\r\n", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "I think this PR was made in error, please open a new clean PR."]}, {"number": 18636, "title": "Does anyone know how to make network output int instead of float?", "body": "I try to use tf.round to make elements in tensor convert to int, but then I meet this error:\r\n\r\nValueError: No gradients provided for any variable, check your graph for ops that do not support gradients, between variables ['Tensor(\"conv_w_0/read:0\", shape=(9, 9, 1, 64), dtype=float32)', 'Tensor(\"conv_b_0/read:0\", shape=(64,), dtype=float32)', 'Tensor(\"conv_w_1/read:0\", shape=(1, 1, 64, 32), dtype=float32)', 'Tensor(\"conv_b_1/read:0\", shape=(32,), dtype=float32)', 'Tensor(\"conv_w_2/read:0\", shape=(5, 5, 32, 1), dtype=float32)', 'Tensor(\"conv_b_2/read:0\", shape=(1,), dtype=float32)'] and loss Tensor(\"Mean:0\", shape=(), dtype=float32).\r\n\r\nAnd this is my  code:\r\nLoss = tf.reduce_mean(tf.nn.l2_loss(tf.round(Train_output) * Train_tao / 2 + Train_img_LR[:,6:27,6:27,:] - Train_img_HR))\r\n\r\nI just want to transfer the elements in Train_output from float to int, Train_output is my network's output.\r\nI have an idea is that I can add a binary_step activation to the end of my model, but I don't know how to write it, because tensor is not iterable, can anyone help me?\r\n", "comments": ["I try to change type to int but tensorflow says input must float.", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 18635, "title": "Strange result of float division", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nLinux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary\r\n- **TensorFlow version (use command below)**:\r\n1.5.0\r\n- **Python version**: \r\n3.5.2\r\n- **CUDA/cuDNN version**:\r\n9.0\r\n- **GPU model and memory**:\r\nGTX 1080Ti\r\n\r\n### Describe the problem\r\n\r\nThe below Numpy and TensorFlow codelets produce different results, while I suppose they should be the same.\r\n\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nx = np.array([247.], dtype=np.float32)\r\ny = x / 255.\r\nprint('{:12.10f}'.format(y[0]))\r\n# 0.9686274529\r\n\r\na = tf.placeholder(tf.float32)\r\nb = a / 255.\r\nwith tf.Session() as sess:\r\n    _b = sess.run(b, feed_dict={a: x})\r\nprint('{:12.10f}'.format(_b[0]))\r\n# 0.9686275125\r\n```\r\n\r\nRunning on CPU gives the same issue.\r\n\r\nHowever, if I use `a = tf.constant(x, dtype=tf.float32)` instead of `tf.placeholder`, the result seems correct.\r\n\r\nIs this an issue about `tf.placeholder` or something else? Does this affect other operations?", "comments": ["@weichiche: I'm not a tensorflow expert, but I suspect you're seeing a difference in the behavior in your example is because of casting between types and precision handled inside tensorflow vs inside numpy. \r\n\r\nPython's standard float type is a C double.  Numpy's standard `np.float` is a reference to python's float.  Therefore your divisor in `y`, 255., is actually np.float64.  You've specifically declared x as `np.float32`.  So because of numpy's casting logic, your resulting y is `np.float32 / np.float64 = np.float32`.  \r\n\r\nIn tensorflow, it looks like your `a` is declared as `tf.float32` but when tf runs `tf.convert_to_tensor` on 255., the type is inferred according to tensorflow and `255.` is treated as a `Constant tf.float32`.  So your op is `tf.float32 / tf.float32 = tf.float32`\r\n\r\n If I do the following in float64, the tf result matches numpy:\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nx = np.array([247.], dtype=np.float64)\r\ny = x / 255.\r\nprint('{:12.10f}'.format(y[0]))\r\n# 0.9686274510\r\n\r\na = tf.placeholder(tf.float64)\r\nb = a / 255.\r\nwith tf.Session() as sess:\r\n    _b = sess.run(b, feed_dict={a: x})\r\nprint('{:12.10f}'.format(_b[0]))\r\n# 0.9686274510\r\n```\r\n\r\nFor `tf.placeholder` and using `feed_dict`, If the feed_dict key is a tf.Tensor, the value may be a Python scalar, string, list, or numpy ndarray that can be converted to the same dtype as that tensor.  \r\n\r\n\r\n", "@Benyuel: I tried explicitly making the divisor `float32` (in TensorFlow, the divisor is created using `tf.constant`), and the discrepancy still exists. Though if I test with `float64`, I get identical results just as you did.\r\n\r\nAnd, as I said before,\r\n\r\n> if I use `a = tf.constant(x, dtype=tf.float32)` instead of `tf.placeholder`, the result seems correct.\r\n\r\nIt seems the divisor is innocent :).\r\n\r\nBesides, the result of C-`float` division should be `0.9686274529` (Numpy result), rather than `0.9686275125` (TensorFlow result).", "@weichiche:    I suspect that tensorflow core is doing the division or casting dtypes differently, and if so, the question then becomes if tf operations using `tf.placeholder` should mirror numpy logic or not?   \r\nWith a constant, the value is a part of the computation graph itself, specified when the constant is created. With a placeholder, every time you run the computation graph, you can feed in a different value in your feed_dict, and tf core has to do some checking/casting.\r\n\r\n```\r\nimport numpy as np\r\nnp.can_cast(np.float32, np.float64)\r\n# True\r\nnp.can_cast(np.float64, np.float32)\r\n# False\r\n```\r\nInternal numpy casting logic: `np.float64` cannot be automatically cast to `np.float32`\r\n```\r\n# Returns the data type with the smallest size and smallest scalar kind to which both type1 and type2 may be safely cast. The returned data type is always in native byte order.\r\n# Per my previous comment, x = np.float32, y = np.float64\r\nnp.promote_types(np.float32, np.float64)\r\n# dtype('float64')\r\n```\r\nTherefore, numpy core is actually performing `np.float64 / np.float64` and then casting to `np.float32`.\r\n\r\nAlso, you're printing 10 digits, so you're likely within the rounding error (Single precision (float32) ~= 7 decimal digits, Double precision(float64) ~= 16 decimal digits).  Instead of printing and checking equality for floating point, you probably just check `np.allclose`.  ", "@Benyuel: I said that _I tried explicitly making the divisor `float32`_. Let's make it more clear. For **Numpy**,\r\n\r\n```python\r\nnp_dtype = np.float32\r\n\r\nx = np.array(247., dtype=np_dtype)\r\nz = np.array(255., dtype=np_dtype)\r\ny = x / z\r\n\r\nprint(x.dtype, x)\r\nprint(z.dtype, z)\r\nprint(y.dtype, list(struct.pack('!f', y)))\r\n```\r\n\r\nprints\r\n\r\n```\r\nfloat32 247.0\r\nfloat32 255.0\r\nfloat32 [63, 119, 247, 248]\r\n```\r\n\r\nAnd for **TensorFlow**,\r\n\r\n```python\r\ntf_dtype = tf.float32\r\n\r\na = tf.placeholder(tf_dtype)\r\nc = tf.constant(z, dtype=tf_dtype)\r\nb = a / c\r\n\r\nwith tf.Session() as sess:\r\n    _a, _b, _c = sess.run([a, b, c], feed_dict={a: x})\r\n    \r\nprint(a.dtype.name, _a)\r\nprint(c.dtype.name, _c)\r\nprint(b.dtype.name, list(struct.pack('!f', _b)))\r\n```\r\n\r\nprints\r\n\r\n```\r\nfloat32 247.0\r\nfloat32 255.0\r\nfloat32 [63, 119, 247, 249]\r\n```\r\n\r\nThe number of printed digits may be inappropriate. But both `y` and `_b` are Numpy data, thus they should be represented in the same way. Anyhow, I turn to print the bytes which should reflect the true difference.\r\n\r\nAs to your question\r\n\r\n> ... and if so, the question then becomes if tf operations using `tf.placeholder` should mirror numpy logic or not?\r\n\r\nI hope so. As many TensorFlow users also use Numpy a lot, consistency makes less confusion, I suppose.", "@weichiche: Had a random idea and it seems to work with placeholders.  It may help in figuring this out\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nx = np.array([247.], dtype=np.float32)\r\ny = x / 255.\r\n\r\nwith tf.device('/device:CPU:0'):\r\n  a = tf.placeholder(tf.float32)\r\n  b = tf.placeholder(tf.float32)\r\n  c = a / b\r\n\r\nconfig = tf.ConfigProto(log_device_placement=True)\r\nwith tf.Session(config=config) as sess:\r\n  _c = sess.run(c, feed_dict={a:x, b:255.})\r\n\r\nprint('TF:    {:12.10f}'.format(_c[0]))\r\nprint('NUMPY: {:12.10f}'.format(y[0]))\r\n```", "@Benyuel: Do you suggest that the device matters?\r\n\r\nI've found that using `tf.placeholder` for both dividend and divisor results in quotient consistent with Numpy. How ever, if you declare the divisor by `tf.constant`, on CPU, the output is inconsistent again.\r\n\r\nSo I guess device is not the crux.\r\n\r\nPlease let me know if I misunderstand you.", "Correct, I'm not saying that device matters.\r\n\r\nI think I've narrowed it down to one of 2 or both possible causes, not 100% certain though:\r\n1.  How type conversion is handled\r\n2.  How a constant tensor is embedded into the graph def which means it is stored in the client and in the runtime.  Placeholders values are as you would expect not stored in the graph def. \r\n\r\nSorry for all of these snippets, but here's another one.\r\n```\r\na = 247.\r\nb = 255.\r\nx = np.array([247.], dtype=np.float32)\r\ny = x / b\r\n# x.dtype = float32\r\n# x.tobytes() = b'\\x00\\x00wC'\r\n# np.array(b).dtype = float64\r\n# np.array(b).tobytes() = b'\\x00\\x00\\x00\\x00\\x00\\xe0o@'\r\n# y = 0.9686274529\r\n```\r\n\r\n```\r\na_placeholder_32 = tf.placeholder(tf.float32)\r\nc = a_placeholder_32 / b\r\n# b is treated as a tf.constant by default\r\nsess = tf.Session()\r\n_c  = sess.run(c,  feed_dict={a_placeholder_32:x})\r\n# numerator = float32\r\n# denominator = float64\r\nprint(sess.graph_def.node[0].attr['dtype'])\r\nprint(sess.graph_def.node[1].attr['dtype'])\r\n# numerator & denominator in graph_def = DT_FLOAT\r\n# np.array(b).tobytes() = b'\\x00\\x00\\x00\\x00\\x00\\xe0o@'\r\n# _c =  0.9686275125\r\n```\r\n\r\n```\r\na_placeholder_32 = tf.placeholder(tf.float32)\r\nb_placeholder_32 = tf.placeholder(tf.float32)\r\nc = a_placeholder_32 / b_placeholder_32\r\nsess = tf.Session()\r\n_b_placeholder_32 = sess.run(b_placeholder_32, feed_dict={b_placeholder_32:b})\r\n_c  = sess.run(c,  feed_dict={a_placeholder_32:x, b_placeholder_32:b})\r\n# numerator = float32\r\n# denominator = float32\r\nprint(sess.graph_def.node[0].attr['dtype'])\r\nprint(sess.graph_def.node[1].attr['dtype'])\r\n# numerator & denominator in graph_def = DT_FLOAT\r\nprint(_b_placeholder_32.tobytes())\r\n# b'\\x00\\x00\\x7fc'\r\n_c =  0.9686274529\r\n```\r\n\r\nNote the difference in bytes in the denominators.\r\nNote the difference in denominator dtypes.", "@Benyuel: I've made a misleading example in my first comment. Please allow me to rephrase my questions.\r\n\r\nConsider two _float32-by-float32_ divisions:\r\n\r\n* (**_TF_**) - dividing a `tf.float32` `Tensor` created by `tf.placeholder()` by a `float32` `Tensor` created by `tf.constant()` ,\r\n* (**_NP_**) - dividing an `np.float32` (or `np.float32` `ndarray` created by `np.array()`) by another `np.float32` (or `np.float32` `ndarray` created by `np.array()`).\r\n\r\nand a statement:\r\n\r\n* (**_EQ_**) - (_TF_) produces, numerically, the same quotient as (_NP_),\r\n\r\nHere're the questions:\r\n\r\n1. Can we expect (_EQ_)?\r\n2. Should we expect (_EQ_)?\r\n\r\n---\r\n\r\nAs to our long-discussed example (i.e. dividing 247 by 255).\r\n\r\nIn Numpy, if the dividend is a scalar (created by `np.float32(247.)`) or a 0-dimensional array (created by `np.array(247., dtype=np.float32)`), the division by a Python `float` (which is actually a 64-bit float as you mentioned before) will be lifted to a _float64-by-float64_ division. However, if the dividend is an array with one or more dimensions (e.g. created  by `np.array([247.], dtype=np.float32)`), then the divisor is converted to a 32-bit float, and the result is the same as _float32-by-float32_ division. So the first snippet in your last comment, whether the divisor is 32-bit or 64-bit, gives exact result of (_NP_).\r\n\r\nYour second snippet is an example of (_TF_). Though the divisor is 64-bit, it is converted to a `DT_FLOAT`, which I think is 32-bit. This division should also be a _float32-by-float32_ division. But somehow the result is slightly different from that of (_NP_), even if the divisor is explicitly created as 32-bit using `tf.constant(255., dtype=tf.float32)`. This is where my concern comes from.\r\n\r\nI've tried the same example in TensorFlow 1.1.0, and the result is consistent with (_NP_). It looks like this issue is introduced during TensorFlow upgrading. \r\n\r\nThe third snippet is out of my consideration, as it gives expected result.", "As this issue has invited community support, please remove the assignee. Otherwise, remove the `community support` label. Thank you.", "`tf.placeholder` is not compatible with eager execution(which is default in Tensorflow 2) and in `tf.function` and there is no plan to modify that, upgrade your Tensorflow version to recent version and report a new issue for any errors/challenges. Thanks!"]}, {"number": 18634, "title": "`tf.contrib.layers.variance_scaling_initializer` is not consistent with `tf.variance_scaling_initializer`?", "body": "I found the implementation of `tf.contrib.layers.variance_scaling_initializer` is not consistent with implementation of `tf.variance_scaling_initializer`?\r\n\r\nIn [https://github.com/tensorflow/tensorflow/blob/r1.7/tensorflow/contrib/layers/python/layers/initializers.py#L148](https://github.com/tensorflow/tensorflow/blob/r1.7/tensorflow/contrib/layers/python/layers/initializers.py#L148), the `trunc_stddev` is multiplied by 1.3.\r\n\r\nWhile in [https://github.com/tensorflow/tensorflow/blob/r1.7/tensorflow/python/ops/init_ops.py#L466](https://github.com/tensorflow/tensorflow/blob/r1.7/tensorflow/python/ops/init_ops.py#L466), there is no 1.3.\r\n\r\nSo, which is correct?", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Sorry, I didn't notice it, the information is listed bellow:\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.7\r\n- **Python version**: 3.5.4\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**: 5.4.0\r\n- **CUDA/cuDNN version**: 9.0\r\n- **GPU model and memory**: gtx1080ti (11GB)\r\n- **Exact command to reproduce**: ", "Nagging Assignee @fchollet: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @fchollet: It has been 36 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @fchollet: It has been 51 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "This has been fixed some time ago."]}, {"number": 18633, "title": "Open the build.gradle file (you can go to 1:Project in the side panel and find it under the Gradle Scripts zippy under Android). Look for the nativeBuildSystem variable and set it to none if it isn't already:  // set to 'bazel', 'cmake', 'makefile', 'none' def nativeBuildSystem = 'none' this do not exisit i need help rearding it if anyone can ??", "body": "Please go to Stack Overflow for help and support:\r\n\r\nhttps://stackoverflow.com/questions/tagged/tensorflow\r\n\r\nIf you open a GitHub issue, here is our policy:\r\n\r\n1. It must be a bug, a feature request, or a significant problem with documentation (for small docs fixes please send a PR instead).\r\n2. The form below must be filled out.\r\n3. It shouldn't be a TensorBoard issue. Those go [here](https://github.com/tensorflow/tensorboard/issues).\r\n\r\n**Here's why we have that policy**: TensorFlow developers respond to issues. We want to focus on work that benefits the whole community, e.g., fixing bugs and adding features. Support only helps individuals. GitHub also notifies thousands of people when issues are filed. We want them to see you communicating an interesting problem, rather than being redirected to Stack Overflow.\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n- **TensorFlow installed from (source or binary)**:\r\n- **TensorFlow version (use command below)**:\r\n- **Python version**: \r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\n- **GPU model and memory**:\r\n- **Exact command to reproduce**:\r\n\r\nYou can collect some of this information using our environment capture script:\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh\r\n\r\nYou can obtain the TensorFlow version with\r\n\r\npython -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"\r\n\r\n### Describe the problem\r\nDescribe the problem clearly here. Be sure to convey here why it's a bug in TensorFlow or a feature request.\r\n\r\n### Source code / logs\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached. Try to provide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 18632, "title": "Fix wrong api name in apis.md", "body": "typed_output_tensor is the correct api name.\r\nIt is implemented in the interpreter class.\r\n\r\nSigned-off-by: MyungSung Kwak <yesmung@gmail.com>", "comments": ["Dear @gunan \r\nThis typo can cause confusion when developers try to use the this api for TensorFlow Lite.\r\nPlease review my commit."]}, {"number": 18631, "title": "Make TensorFlow Lite library for Android target", "body": "You can compile Tensorflow Lite library using Makefile.\r\nIt is possible to compile both static and shared library\r\nincluding benchmark tools.\r\n\r\nFor more details, see TensorFlow Lite Makefile section\r\nof the README.md file.\r\n\r\nSigned-off-by: MyungSung Kwak <yesmung@gmail.com>", "comments": ["@martinwicke \r\nHello, I have a question.\r\nHow long does it take verify check list approximately? There seems to be no progress.\r\nPlease reply if you can.", "We're waiting for a review from @petewarden. He will get to it as soon as he can. ", "@martinwicke\r\nThank you for comment", "Is there any update?", "@petewarden any update?", "@yesmung have you tried the latest Android target of TensorFlow Lite? This issue is already resolved at head. Thanks", "Nagging Reviewer @petewarden, @jdduke: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 29 days with no activity and the `awaiting review` label has been applied.", "So, the primary reason for the Makefile's existence is to allow compilation on platforms that aren't natively (or well) supported by bazel.  As Android is wells-supported by bazel, is there any reason you cannot use that path? We're hoping to avoid yet another parallel build system.", "Closing as we have no plans to support Makefile builds for Android."]}, {"number": 18630, "title": "Grpc+RDMA problem", "body": "For RDMA, when start the `ps` server, it will do RDMA connect to `worker` server, but failed because worker still not started:\r\n\r\n```\r\n# python tf_rdma.py --ps_hosts='workernode2:1111' --worker_hosts='workernode3:2222' --job_name=ps --task_id=0\r\n....\r\n2018-04-04 11:23:38.912680: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:324] Started server with target: grpc://localhost:1111\r\n2018-04-04 11:23:38.920106: E tensorflow/contrib/verbs/rdma_mgr.cc:119] Connecting to /job:worker/replica:0/task:0: Got Transport closed. Retrying (1/5)...\r\n2018-04-04 11:23:41.920544: E tensorflow/contrib/verbs/rdma_mgr.cc:119] Connecting to /job:worker/replica:0/task:0: Got OS Error. Retrying (2/5)...\r\n2018-04-04 11:23:43.921039: E tensorflow/contrib/verbs/rdma_mgr.cc:119] Connecting to /job:worker/replica:0/task:0: Got OS Error. Retrying (3/5)...\r\n2018-04-04 11:23:46.922376: E tensorflow/contrib/verbs/rdma_mgr.cc:119] Connecting to /job:worker/replica:0/task:0: Got OS Error. Retrying (4/5)...\r\n2018-04-04 11:23:48.922817: E tensorflow/contrib/verbs/rdma_mgr.cc:119] Connecting to /job:worker/replica:0/task:0: Got OS Error. Retrying (5/5)...\r\n2018-04-04 11:23:48.922848: I tensorflow/contrib/verbs/rdma_mgr.cc:128] Connected to remote node /job:worker/replica:0/task:0\r\n```\r\n\r\nThen start the worker server:\r\n\r\n```\r\n# python tf_rdma.py --ps_hosts='workernode2:1111' --worker_hosts='workernode3:2222' --job_name=worker --task_id=0\r\n...\r\n2018-04-04 14:12:38.008214: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> workernode2:1111}\r\n2018-04-04 14:12:38.008256: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2222}\r\n2018-04-04 14:12:38.013784: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job ps -> {0 -> workernode2:1111}\r\n2018-04-04 14:12:38.013803: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:215] Initialize GrpcChannelCache for job worker -> {0 -> localhost:2222}\r\n2018-04-04 14:12:38.019732: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:324] Started server with target: grpc://localhost:2222\r\n2018-04-04 14:12:38.028558: I tensorflow/contrib/verbs/rdma_mgr.cc:128] Connected to remote node /job:ps/replica:0/task:0\r\n```\r\n\r\nthe worker server can do RDMA connect successfully. But hanged up with the follows:\r\n\r\n```\r\n(gdb) bt\r\n#0  0x00007fbdcc4f7a54 in mlx4_poll_cq () from /lib64/libmlx4-rdmav2.so\r\n#1  0x00007fbdf16301d8 in tensorflow::RdmaMgr::ConnectivityCheck() () from /usr/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#2  0x00007fbdf1628874 in tensorflow::VerbsServer::Start() () from /usr/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#3  0x00007fbdf12abf9b in _wrap_PyServer_Start () from /usr/lib/python2.7/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#4  0x00007fbe01542aa4 in PyEval_EvalFrameEx () from /lib64/libpython2.7.so.1.0\r\n```\r\n\r\nI think `ps` server should wait `worker` server setup before [connect worker server](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/verbs/verbs_server_lib.cc#L105).\r\n\r\nAm I right?", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 22 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!", "I had got this problem.\r\nOnly start ps, it will got error, when worker is on other node. And will waiting when worker is on the same node.\r\nHave I written custom code\uff1a No\r\nOS Platform\uff1a Ubuntu 16.04.3 LTS\r\nTensorFlow installed from\uff1a by source code\r\nTensorFlow version\uff1a1.8.0\r\nBazel version: bazel release 0.16.0\r\nCUDA/cuDNN version: 9.0\r\nGPU model and memory: P100-PCIE 16280MiB"]}, {"number": 18629, "title": "tensorflow lite android demo import falied!", "body": "### System information\r\n== cat /etc/issue ===============================================\r\nLinux apuser-H81-M1 4.13.0-38-generic #43~16.04.1-Ubuntu SMP Wed Mar 14 17:48:43 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"16.04.3 LTS (Xenial Xerus)\"\r\nVERSION_ID=\"16.04\"\r\nVERSION_CODENAME=xenial\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 5.4.0-6ubuntu1~16.04.9) 5.4.0 20160609\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n\r\n== uname -a =====================================================\r\nLinux apuser-H81-M1 4.13.0-38-generic #43~16.04.1-Ubuntu SMP Wed Mar 14 17:48:43 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy                              1.14.2     \r\nprotobuf                           3.5.2.post1\r\ntensorflow                         1.8.0rc0   \r\ntensorflow-gpu                     1.7.0      \r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.8.0-rc0\r\ntf.GIT_VERSION = v1.8.0-rc0-525-ga2607aa\r\ntf.COMPILER_VERSION = v1.8.0-rc0-525-ga2607aa\r\nSanity check: array([1], dtype=int32)\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\n  File \"tensorflow/__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"tensorflow/python/__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"tensorflow/python/pywrap_tensorflow.py\", line 25, in <module>\r\n    from tensorflow.python.platform import self_check\r\nImportError: No module named platform\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH :/usr/local/cuda-9.0/lib64:/usr/local/cuda-9.0/extras/CUPTI/lib64\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nWed Apr 18 11:38:35 2018       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 384.111                Driver Version: 384.111                   |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  GeForce GTX 1080    Off  | 00000000:01:00.0  On |                  N/A |\r\n| 27%   39C    P0    54W / 250W |    384MiB /  8105MiB |     20%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0       905      G   /usr/lib/xorg/Xorg                           225MiB |\r\n|    0      1746      G   compiz                                        84MiB |\r\n|    0      1968      G   fcitx-qimpanel                                 8MiB |\r\n|    0      2280      G   ...-token=D7E00697E1E0DD52292B521137FD9307    64MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs  ===================================================\r\n/usr/local/MATLAB/R2016b/bin/glnxa64/libcudart.so.7.5.18\r\n/usr/local/cuda-9.0/lib64/libcudart.so.9.0.176\r\n/usr/local/cuda-9.0/lib64/libcudart_static.a\r\n/usr/local/cuda-9.0/doc/man/man7/libcudart.7\r\n/usr/local/cuda-9.0/doc/man/man7/libcudart.so.7\r\n\r\n### Describe the problem\r\n1Q:\r\nI am trying to use a custom model in the [tflitedemo](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite/examples/android).\r\nWhen importing this project to android studio, I encountered a configuration failure error \" Plugin with id 'com.android.application' not found.\",  how to solve this problem \uff1f\r\n\r\n2Q:\r\n[box_priors.txt](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/lite/examples/android/assets) is from where ?  how to generate it ?  \r\n\r\nThanks!\r\n\r\n\r\n\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 18628, "title": "Add decode uint16 PNG images support for tf.image.decode_image.", "body": "Add `dtype` argument to decode uint16 PNG images.\r\nUpdate instructions for tf.image.decode_image.", "comments": ["Thanks for your suggestion.\r\n\r\nNew version has been updated.", "Updated, thanks : )", "Though, out of curiosity: If you know it is a `png`, when why not use use `tf.image.decode_png`?", "Thanks @asimshankar ,\r\nI use tensorflow object detection api for medical research.\r\nThe data of medical images are not always in uint8 data type.\r\nWhen I decoded these tfrecord files created from medical uint16 dataset, they are converted to uint8.\r\nI found that object detection api decode tool is based on slim.tfexample_decoder function, and it uses tf.image.decode_image function to decode images.\r\nTherefore, if uint16 data type can be supported, it should make tf.image.decode_image more versatile.", "Thanks @seanli9jan \r\nThough, I'm still confused - given that the other image decoding functions actually decode into `uint8`s, then even after the cast to `uint16`, the range of the pixel values will be [0, 255]. While for PNGs the range will be `[0, 65535]`. So, I'm worried that if one invokes `tf.image.decode_image` and actually has a mix of image files, then there will be these subtle discrepancies in the data.\r\n\r\n(I apologize, I should have thought of this before suggesting the `cast`).\r\n\r\nIt appears to me that if the images are actually `uint16` PNGs, then you're better off invoking `tf.image.decode_png` directly instead of plumbing a `dtype` argument through various libraries. Does that make sense? Or am I missing something?", "Hi @asimshankar\r\nPerhaps I should replace `math_opt.cast` with `convert_image_dtype` to make sure that returned values always be `[0, 65535]` when `dtype=tf.uint16`.\r\nSomething like:\r\n```python\r\ndef _convert_image_dtype(t):\r\n  if dtype == dtypes.uint8: return t\r\n  return convert_image_dtype(t, dtype)\r\n\r\ndef _bmp():\r\n  ...\r\n  return _convert_image_dtype(gen_image_ops.decode_bmp(contents))\r\n```", "In fact you don't need to make that conditional -- `convert_image_dtype` is a noop if the style already is the same. ", "New version has been updated,\r\nThanks!", "Updated, thanks : )", "New version has been updated,\r\nThanks :)", "Can you add test cases for the new behavior? I think the code is fine.", "Updated, thanks : )", "Updated, thanks : )", "Some checks were not successful!\r\nAm I missing something?", "There are linter errors. Check the sanity log for those. (maybe other errors too, check the other logs)", "I fix a few error, can we test again?", "@seanli9jan you need to regenerate the goldens so that the API test works.", "Oh, I missed that,\r\nthanks @drpngx ", "@seanli9jan BTW, did you address @asimshankar comment about removing `convert_image_dtype`?", "@drpngx @asimshankar, \r\nI am not sure about removing `convert_image_dtype` from these decode functions, because `decode_png` will return uint16 tensor, and other decode functions always return uint8s. \r\nIn function `tf.image.decode_image`, `tf.cond` is used to check image format, but it is unsupported with different input data type.", "@seanli9jan @drpngx : Yup, what you have seems reasonable. Thanks."]}, {"number": 18627, "title": "Fix the calculation of the histogram buckets and writing to the tensor in summary_db_writer", "body": "[Issue: 1141](https://github.com/tensorflow/tensorboard/issues/1141): Incorrect data being written out for the histogram in the db\r\n\r\n- The calculation of the histogram buckets is incorrect per the histogramProto defined in \t[summary.proto](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/summary.proto)\r\n- The data is getting clobbered in MigrateHistogram when writing it to a Tensor. This results in incorrect data being stored in the db\r\n\r\nThe pr provides a fix for this.\r\n\r\nTesting: \r\n- Added a unit test", "comments": ["Thanks for the review.   Yes, thats right. I noticed that too in my experiments and had to hack/strip the dbl min in order to get the rendering to work.  I was thinking of opening an issue but if the todo's in code suffice, I can leave it at that. \r\n\r\nI have added the todo's per your request and that made your approval stale.  Can you please approve again.  Thank you. ", "That sounds good.  I have updated the title for that TensorBoard issue and reopened it, so we can use that.", "Thank you @nfelt"]}, {"number": 18626, "title": "Update version strings for 1.8.0rc1.", "body": "", "comments": []}, {"number": 18625, "title": "\"1.8.0-rc1 cherry-pick request: Increase softmax gpu unittest numeric stability", "body": "PiperOrigin-RevId: 193103363\r\n\r\nThis fixes a breakage in kokora windows build. Other builds are fine.", "comments": ["Would the release owner merge the PR? Seems I'm not authorized."]}, {"number": 18624, "title": "1.8rc1 cherry-pick request: [tf.data] Fix a device placement issue in `prefetch_to_device()`. ", "body": "Cherry pick #18607 to the r1.8 branch.\r\n\r\nThe `tf.contrib.data.prefetch_to_device()` utility was broken when using GPUs (its primary use case), as first noticed on Stack Overflow: https://stackoverflow.com/q/49876643/3574081 . If this cherry-pick is not included, the feature promised for 1.8 at the Dev Summit will not be available to use in the release.\r\n", "comments": ["Thank you!!"]}, {"number": 18623, "title": "1.8.0-rc1 cherry-pick request: boosted trees fixes/cleanup", "body": "It includes fixes and API cleanups.\r\n\r\n- regularizer parameters are inputs, not attributes, to be future-proof.\r\n- train_in_memory mode now works with Datasets properly.\r\n", "comments": []}, {"number": 18622, "title": "1.8.0-rc1 cherry-pick request: Enable consumption of GIT_TAG_OVERRIDE env var in release build scrip\u2026", "body": "\u2026t. (#18579)\r\n\r\nEnable consumption of GIT_TAG_OVERRIDE env var in release build script.", "comments": []}, {"number": 18621, "title": "1.8.0-rc1 cherry-pick request: boosted trees fixes/cleanup", "body": "It includes fixes and API cleanups.\r\n - regularizer parameters are inputs, not attributes, to be future-proof.\r\n - train_in_memory mode now works with Datasets properly.\r\n", "comments": ["Thanks for the merge!"]}, {"number": 18620, "title": "1.8.0-rc1 cherry-pick request: In model_to_estimator, only run get_weights when there are initialize\u2026", "body": "PiperOrigin-RevId: 192541442", "comments": []}, {"number": 18619, "title": "r1.8-rc1 cherry-pick request: adding tests for `decode_proto`, `encode_proto`, `rpc_op`", "body": "The `decode_proto`, `encode_proto`, and `rpc_op` ops are a major feature introduced in r1.8 and this PR ports their tests to OS that -- beside testing the ops functionality in OS -- illustrate how to uses these ops.", "comments": []}, {"number": 18618, "title": "Remove duplicate imports in all python source", "body": "Wrote a script to scan throught the python files in the repo, and found the remaining duplicate imports  like:\r\n```\r\n from tensorflow.python.ops import random_ops\r\n-from tensorflow.python.ops import random_ops\r\n from tensorflow.python.util.deprecation import deprecated\r\n```\r\nThis fix removed all of them for duplicate imports in the repo.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 18617, "title": "How to include xla_op_kernel.h to the TensorFlow python package?", "body": "Have I written custom code: None\r\nOS Platform and Distribution: Linux Ubuntu 16.04\r\nOpen MPI version: 3.0.0\r\nTensorFlow installed from: source\r\nBazel version: 0.11.1\r\nPython version: 3.5.2\r\nGCC version: 6.3.0\r\nCUDA/cuDNN version: N/A\r\nGPU model and memory: N/A\r\nHorovod: 0.12.1\r\nTensorflow version: b'v1.7.0-rc1-816-g1712002ad0' 1.7.0-rc1\r\nExact command to reproduce: N/A\r\nFeature request: I would like to call REGISTER_XLA_OP in Horovod and it requires that `xla_op_kernel.h` be included in tensorflow Python package. I wonder if it is easy to add this feature.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nTensorFlow version\nExact command to reproduce", "It has been 17 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 20 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}]