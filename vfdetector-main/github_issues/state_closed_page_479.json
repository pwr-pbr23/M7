[{"number": 39428, "title": "Error when trying to use tensorflow. Installation issue.", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Home; Version: 1909; OS Build 18363.815\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Not using on mobile device. Only on desktop.\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.2.0\r\n- Python version: 3.7.7\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: NA. I dont have GPU and hence not explicitly installed this.\r\n- GPU model and memory: NA. Dont have GPU.\r\n\r\n\r\n\r\n**Describe the problem**\r\nWhen loading the MNIST dataset, I get an error message saying failed to load DLL. I have just installed tensorflow and hence think this is related to how it was installed.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nThe below command was used in the .py file\r\n\r\nimport tensorflow as tf\r\n\r\n# Use MNIST handwriting dataset\r\nmnist = tf.keras.datasets.mnist\r\n\r\n# Prepare data for training\r\n(x_train, y_train), (x_test, y_test) = mnist.load_data()\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\jaisw\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\jaisw\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\jaisw\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\jaisw\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\jaisw\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"E:/DataInOnePlace/Puneet/eDX/Intro to AI/5. Neural Networks/Lectures/src5/digits/test.py\", line 2, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\jaisw\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\jaisw\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 50, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\jaisw\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 69, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\jaisw\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\jaisw\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\jaisw\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\jaisw\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\jaisw\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\n\n* For TF-GPU - See point 1\n* For TF-CPU - See point 2\n\n-----------------------------------------------------------------------------------------------\n\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\n\n*TF Version >= 1.13 requires CUDA 10.0 and TF Version < 1.13 (till TF 1.5) requires CUDA 9.0.*\n\n* If you have above configuration and using _**Windows**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\n  * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\n* If you have above configuration and using _**Ubuntu/Linux**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\n  * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\n* If error still persists then, apparently your CPU model does not support AVX instruction sets.\n  * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\n\n-----------------------------------------------------------------------------------------------\n\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\n\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\n\n Therefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\n\n* Try Google Colab to use TensorFlow.\n  * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true).You get pre-installed latest stable TF version. Also you can use```pip install``` to install any other preferred TF version.\n  * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\n  * All you need is a good internet connection and you are all set.\n* Try to build TF from sources by changing CPU optimization flags.\n\n*Please let us know if this helps.*", "@puneetjais  \r\nWhat is make/model of your cpu?\r\nI suspect your cpu model does not support AVX instructions sets.See [hardware requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements)\r\nMake sure to download the latest [microsoft visual c++ redistributable](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads) from here.\r\n.Also, please follow the instructions from to install from [Tensorflow website](https://www.tensorflow.org/install/source_windows).\r\n\r\nPlease, check Your CPU/Python is on 32 bits?Please, refer #36167 and see if it helps you.\r\nPlease, refer similar issue #36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204\r\nThanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39428\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39428\">No</a>\n"]}, {"number": 39427, "title": "[ROCm] hip-clang / ROCm 3.5 build fixes", "body": "ROCm migrates from hcc to hip-clang in version 3.5, and these changes are needed to support the transition. \r\n\r\nSummary of the changes:\r\n* ROCm 3.5 includes gtest and gmock in its install tree, and we have to delete them when copying over the headers, otherwise they take precedence over tensorflow's own gtest/gmock\r\n* Adding rccl's dependency on librt\r\n* The XLA compiler is switched from code object v2 to v3\r\n* A resource handling issue is fixed (it was present all along but it got exposed by the transition)\r\n* An unneeded command-line warning flag is removed", "comments": []}, {"number": 39426, "title": "Add mlir_graph_optimization_pass.h header to pip wheel", "body": "This PR adds mlir_graph_optimization_pass.h header to tf-nightly pip wheel.\r\n\r\nmlir_graph_optimization_pass.h is a header file that allows to register mlir based graph optimizaton (either part of the tensorflow, or externally registered).\r\n\r\nHowever, it is not part of the pip install so it is not possible to register with installed version of tensorflow. This PR adds the header file to be part of the pip install.\r\n\r\nThis PR is related to #39231\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["Hello @yongtang \r\nI am using tf-nightly and having the same issue here. I have read your PR but find;t understand how to add this header file into my TensorFlow library. Would you please elaborate on how to do add the mlir graph optimization in simple manner? \r\nThank you in advance. "]}, {"number": 39425, "title": "Update lstm.cc", "body": "fixing 'effecgive' typo", "comments": ["We will not be encouraging one liner grammatical changes as this is expensive process, if possible include more such changes in a single PR.Thank you\r\nCC @mihaimaruseac @chanshah"]}, {"number": 39424, "title": "Add uint32/uint64 support for tf.tile", "body": "This PR tries to address the issue raised in #39405 where there is no uint32/uint64 support for tf.tile.\r\n\r\nThe related kernel impl for uint32 and uint64 has been added in this PR.\r\n\r\nThis PR fixes #39405\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": ["This PR breaks `tensorflow/lite/experimental/delegates/coreml:coreml_diff_test_IOS_12`\r\n\r\n```\r\nUndefined symbols for architecture x86_64:\r\n  \"tensorflow::functor::Tile<Eigen::ThreadPoolDevice, unsigned int, int>::operator()(Eigen::ThreadPoolDevice const&, tensorflow::Tensor*, tensorflow::Tensor const&, absl::Span<int const>) const\", referenced from:\r\n      void tensorflow::TileOp<Eigen::ThreadPoolDevice, int>::HandleCaseImpl<(tensorflow::DataType)22>(tensorflow::OpKernelContext*, absl::Span<int const> const&, tensorflow::Tensor*) in libportable_tensorflow_kernels.lo(tile_ops_8df9402447fb5c99fae84bd69e6311f0.o)\r\n  \"tensorflow::functor::Tile<Eigen::ThreadPoolDevice, unsigned int, long long>::operator()(Eigen::ThreadPoolDevice const&, tensorflow::Tensor*, tensorflow::Tensor const&, absl::Span<long long const>) const\", referenced from:\r\n      void tensorflow::TileOp<Eigen::ThreadPoolDevice, long long>::HandleCaseImpl<(tensorflow::DataType)22>(tensorflow::OpKernelContext*, absl::Span<long long const> const&, tensorflow::Tensor*) in libportable_tensorflow_kernels.lo(tile_ops_8df9402447fb5c99fae84bd69e6311f0.o)\r\n  \"tensorflow::functor::Tile<Eigen::ThreadPoolDevice, unsigned long long, int>::operator()(Eigen::ThreadPoolDevice const&, tensorflow::Tensor*, tensorflow::Tensor const&, absl::Span<int const>) const\", referenced from:\r\n      void tensorflow::TileOp<Eigen::ThreadPoolDevice, int>::HandleCaseImpl<(tensorflow::DataType)23>(tensorflow::OpKernelContext*, absl::Span<int const> const&, tensorflow::Tensor*) in libportable_tensorflow_kernels.lo(tile_ops_8df9402447fb5c99fae84bd69e6311f0.o)\r\n  \"tensorflow::functor::Tile<Eigen::ThreadPoolDevice, unsigned long long, long long>::operator()(Eigen::ThreadPoolDevice const&, tensorflow::Tensor*, tensorflow::Tensor const&, absl::Span<long long const>) const\", referenced from:\r\n      void tensorflow::TileOp<Eigen::ThreadPoolDevice, long long>::HandleCaseImpl<(tensorflow::DataType)23>(tensorflow::OpKernelContext*, absl::Span<long long const> const&, tensorflow::Tensor*) in libportable_tensorflow_kernels.lo(tile_ops_8df9402447fb5c99fae84bd69e6311f0.o)\r\nld: symbol(s) not found for architecture x86_64\r\nclang++: error: linker command failed with exit code 1 (use -v to see invocation)\r\n```\r\n\r\nI'll take a look at this build errors next week, if you have time to find what's going on before that I'd appreciate that. From the error message it seems that build error is reproducible with a regular x86 compiler.", "Thanks @ezhulenev for the help\r\n\r\n I don't have access to ios build. However, this PR adds two additional new files (for tile_ops functor template specialization). I also noticed similar tile_ops functor c++ files are added both in `tile_ops` rule and `android_extended_ops_group2` rule of the `tensorflow/core/kernels/BUILD` file. My wild guess is that `android_extended_ops_group2` was used for ios as well, thus the ios `Undefined symbols` error case if those two files are not in `android_extended_ops_group2`.\r\n\r\nI updated the PR with two functor files added to `android_extended_ops_group2` to give it a try. Maybe you can take a look and see if the issue could be resolved? If not I will try to see if I can find something else.", "Thanks! Will try to pull it in if tooling will work, otherwise will do manual pull, unlikely earlier than tuesday."]}, {"number": 39423, "title": "DLL load failed: A dynamic link library (DLL) initialization routine failed.", "body": "Traceback (most recent call last):\r\n  File \"C:\\Users\\Mukesh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Mukesh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Mukesh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Mukesh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Mukesh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<pyshell#1>\", line 1, in <module>\r\n    import tensorflow\r\n  File \"C:\\Users\\Mukesh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\Mukesh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 50, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Mukesh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 69, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Mukesh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Mukesh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Mukesh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Mukesh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Mukesh\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\n\n* For TF-GPU - See point 1\n* For TF-CPU - See point 2\n\n-----------------------------------------------------------------------------------------------\n\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\n\n*TF Version >= 1.13 requires CUDA 10.0 and TF Version < 1.13 (till TF 1.5) requires CUDA 9.0.*\n\n* If you have above configuration and using _**Windows**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\n  * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\n* If you have above configuration and using _**Ubuntu/Linux**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\n  * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\n* If error still persists then, apparently your CPU model does not support AVX instruction sets.\n  * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\n\n-----------------------------------------------------------------------------------------------\n\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\n\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\n\n Therefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\n\n* Try Google Colab to use TensorFlow.\n  * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true).You get pre-installed latest stable TF version. Also you can use```pip install``` to install any other preferred TF version.\n  * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\n  * All you need is a good internet connection and you are all set.\n* Try to build TF from sources by changing CPU optimization flags.\n\n*Please let us know if this helps.*", "@mukesh15j \r\n\r\nPlease, fill [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).It helps us in localizing the issue faster.\r\n\r\nWhat is make/model of your cpu?\r\nI suspect your cpu model does not support AVX instructions sets.See [hardware requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements).\r\n\r\nMake sure to download the[ latest microsoft visual c++ redistributable from here](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads).\r\n\r\n.Also, please follow the instructions from to install from [Tensorflow website.](https://www.tensorflow.org/install/source_windows).\r\n\r\nPlease, check Your CPU/Python is on 32 bits?.Refer #36167 and see if it helps you.Thanks!", "For clarity as it isn't clear......  IF you are using GPU but your CPU doesn't support AVX then you'll get this error?  CPU is Xeon 5560 (no AVX support) GPU is 1060i and I get the above error.  C++ ok", "@jf19742016 \r\n\r\nThe error is due to cpu compatibility .As you mentioned Xeon 5560 has no AVX support.I have confirmed the same from product details page (https://ark.intel.com/content/www/us/en/ark/products/37109/intel-xeon-processor-x5560-8m-cache-2-80-ghz-6-40-gt-s-intel-qpi.html).\r\n\r\nAs an alternative i suggest you to use Google colab (https://colab.research.google.com).\r\nThanks!", "Sorry I know it doesn't have AVX support.  To be clear this is expected behaviour?  So i know my CPU doesn't support AVX and my GPU is a 1060i - i'll get \"DLL load failed: A dynamic link library (DLL) initialization routine failed.\"?  A nicer error message would be better as clearly from the other threads this can happen for a lot of reasons.  \r\n", "Unfortunately the error message comes from windows and all of our attempts to fix that (checking and then presenting a better error message) resulted in failure since the code that was checking this was also compiled using AVX.\r\n\r\nYou can compile everything from source or use Google Colab Notebooks.\r\n\r\nCan we close the issue?", "Really?  So a version or view back it warned you and gave some message about not being compiled for AVX, i remember you could even set a flag to turn the warning off.  You're saying that this is a Windows issue - that's hard to believe.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39423\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39423\">No</a>\n"]}, {"number": 39422, "title": "Move training op helpers to framework and fix linking issues", "body": "Hi, this PR encompasses the PR #37873 and fixes the linking issues. @alextp @Squadrick @spidyDev ", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F39422) for more info**.\n\n<!-- need_author_consent -->", "@vcarpani @Squadrick Since I keep your commits from earlier PR to credit your work, could you please approve the CLA?", "@googlebot I consent.", "@samikama  Thanks for making this change. The PR works fine with custom ops  in TF addons.", "@samikama can you please sign CLA ?", "@googlebot I consent", "@Squadrick do you consent to include your commits in PR or should I open a new one without your changes?", "@googlebot I consent.", "@googlebot I consent.", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F39422) for more info**.\n\n<!-- ok -->", "@rthadur, it looks like copybara failed but can't see the reason. Is there anything on my side to help?", "@rthadur and @alextp There seems to be an issue with copybara but I can't see the error. Is there anything I can do to help?", "Copybara fails because we no longer have `contrib`. Can we remove the `contrib` files from the PR?", "@mihaimaruseac Thanks for catching that. I thought these were removed in earlier PRs that this is based on. I removed contrib directory now.", "@mihaimaruseac I believe current failures are not related with this PR, since there wasn't any change that would have caused them wrt previous commit. Is that correct?\r\n", "The MacOS failures are not related. They also won't block merging this. Currently this is waiting import approval, but it shouldn't take longer.", "@rthadur I just did a clean build and can't reproduce the issue. I am using bazel 2.0.0? Is this observed in internal build? If not can you tell me how can I reproduce it?", "@rthadur any help on this? If I can't see the errors I can't know what is wrong or verify if they are fixed.", "These seem to be caused by `BUILD` files not mirroring the include hierarchy. I'll try to import and fix manually later today/this week", "Unfortunately I have to give up trying to manually import. Errors are either of this form:\r\n\r\n```\r\n...$ bazel build //tensorflow/core/kernels:variable_ops\r\n...\r\nERROR: .../tensorflow/core/kernels/BUILD:5716:18: C++ compilation of rule '//tensorflow/core/kernels:variable_ops' failed (Exit 1)[..] \r\ntensorflow/core/kernels/variable_ops.cc:19:10: error: use of private header from outside its module: 'tensorflow/core/framework/op_kernel.h'. [-Wprivate-header]\r\n#include \"tensorflow/core/framework/op_kernel.h\"\r\n         ^\r\n...\r\nFAILED: Build did NOT complete successfully\r\n```\r\n\r\nor errors of the form\r\n\r\n```\r\n...$ bazel build //tensorflow/core/kernels:count_up_to_op  \r\n...                                                                                                                                                                                                       \r\nERROR: .../tensorflow/core/kernels/BUILD:5640:18: C++ compilation of rule '//tensorflow/core/kernels:count_up_to_op' failed (Exit 1)[..]                                                                              \r\ntensorflow/core/kernels/count_up_to_op.cc:18:10: error: module //tensorflow/core/kernels:count_up_to_op does not depend on a module exporting 'tensorflow/core/framework/resource_var.h'                                                              \r\n#include \"tensorflow/core/framework/resource_var.h\"                                                                    \r\n         ^         \r\n...                           \r\nFAILED: Build did NOT complete successfully  \r\n```\r\n\r\nThis results in over 16000 tests failing internally.\r\n\r\nCan we try splitting this PR into smaller components and merging them one by one. Can assign me as reviewer for each component.", "Thanks for looking into that @mihaimaruseac. I can try to give another go if I can have a way to reproduce the problem. I believe these issues are originating from an incomplete refactoring in the past. If is it possible to have a small reproducer, it might be easier to solve these issues. Could you provide a simple example manifesting the errors?", "Sure. The errors I got were reproduceable when building the equivalent of `bazel build //tensorflow/core/kernels:variable_ops` and `bazel build //tensorflow/core/kernels:count_up_to_op`,\r\n\r\nIf you cannot reproduce, can we try a different approach where we duplicate the code first (one PR), slowly migrate targets to use the new code (multiple PRs), then we do one more PR to sync the duplicates and remove the old copy? I could attempt to do that internally but not in the next 1-2 weeks :(", "@mihaimaruseac, thanks. I just did another clean build and the targets you mention. They all went through without any problems. I used bazel 2.0.0 as well as 3.2.0. I wonder what is so different between imported code and OSS. Could it be an import issue?", "Also I extended the visibility of the framework header exports to core/kernels. Perhaps this helps", "Let's try a new pull with the visibility extended.", "@mihaimaruseac there are still internal errors , can you please check.", "@samikama here are new errors which are failing internally , can you please check \r\n\r\n`/tensorflow/core/kernels/stateful_random_ops.cc:19:10: error: module ///tensorflow/core/kernels:stateful_random_ops does not depend on a module exporting '/tensorflow/core/framework/training_op_helpers.h'\r\n\r\nbuild_cleaner ///tensorflow/core/kernels:stateful_random_ops\r\n#include \"/tensorflow/core/framework/training_op_helpers.h\"\r\n        ^\r\n1 error generated.\r\nBroken by missing target ///tensorflow/core/kernels:count_up_to_op\r\ncontent_copy\r\n/tensorflow/core/kernels/count_up_to_op.cc:18:10: error: module ///tensorflow/core/kernels:count_up_to_op does not depend on a module exporting '/tensorflow/core/framework/resource_var.h'\r\n\r\nbuild_cleaner ///tensorflow/core/kernels:count_up_to_op\r\n#include \"/tensorflow/core/framework/resource_var.h\"\r\n        ^\r\n1 error generated.\r\nBroken by missing target ///tensorflow/core/kernels:variable_ops\r\ncontent_copy\r\n/tensorflow/core/kernels/variable_ops.cc:19:10: error: use of private header from outside its module: '/tensorflow/core/framework/control_flow.h'; see \r\n#include \"/tensorflow/core/framework/control_flow.h\"\r\n        ^\r\n/tensorflow/core/kernels/variable_ops.cc:20:10: error: use of private header from outside its module: '/tensorflow/core/framework/op_kernel.h'; see \r\n#include \"/tensorflow/core/framework/op_kernel.h\"\r\n        ^\r\n/tensorflow/core/kernels/variable_ops.cc:21:10: error: use of private header from outside its module: '/tensorflow/core/framework/register_types.h'; see \r\n#include \"/tensorflow/core/framework/register_types.h\"\r\n        ^\r\n3 errors generated.\r\nBroken by missing target ///tensorflow/core/kernels:scatter_nd_op\r\ncontent_copy\r\n/tensorflow/core/kernels/scatter_nd_op.cc:29:10: error: module ///tensorflow/core/kernels:scatter_nd_op does not depend on a module exporting '/tensorflow/core/framework/resource_var.h'\r\n\r\nbuild_cleaner ///tensorflow/core/kernels:scatter_nd_op\r\n#include \"/tensorflow/core/framework/resource_var.h\"\r\n        ^\r\n/tensorflow/core/kernels/scatter_nd_op.cc:33:10: error: module ///tensorflow/core/kernels:scatter_nd_op does not depend on a module exporting '/tensorflow/core/kernels/dense_update_functor.h'\r\n\r\nbuild_cleaner ///tensorflow/core/kernels:scatter_nd_op\r\n#include \"/tensorflow/core/kernels/dense_update_functor.h\"\r\n        ^\r\n2 errors generated.\r\nBroken by missing target ///tensorflow/core/kernels:strided_slice_op\r\ncontent_copy\r\n/tensorflow/core/kernels/strided_slice_op.cc:29:10: error: module ///tensorflow/core/kernels:strided_slice_op does not depend on a module exporting '/tensorflow/core/framework/resource_var.h'\r\n\r\nbuild_cleaner ///tensorflow/core/kernels:strided_slice_op\r\n#include \"/tensorflow/core/framework/resource_var.h\"\r\n        ^\r\n1 error generated.\r\nBroken by missing target ///tensorflow/core/kernels:resource_variable_ops\r\ncontent_copy\r\n/tensorflow/core/kernels/resource_variable_ops.cc:65:10: error: module ///tensorflow/core/kernels:resource_variable_ops does not depend on a module exporting '/tensorflow/core/framework/resource_var.h'\r\n\r\nbuild_cleaner ///tensorflow/core/kernels:resource_variable_ops\r\n#include \"/tensorflow/core/framework/resource_var.h\"\r\n        ^\r\n/tensorflow/core/kernels/resource_variable_ops.cc:70:10: error: module ///tensorflow/core/kernels:resource_variable_ops does not depend on a module exporting '/tensorflow/core/kernels/dense_update_functor.h'\r\nbuild_cleaner ///tensorflow/core/kernels:resource_variable_ops\r\n#include \"/tensorflow/core/kernels/dense_update_functor.h\"\r\n        ^\r\n2 errors generated.\r\nBroken by missing target ///tensorflow/core:training_op_helpers\r\ncontent_copy\r\n/tensorflow/core/framework/training_op_helpers.cc:18:10: error: module ///tensorflow/core:training_op_helpers does not depend on a module exporting '/tensorflow/core/util/ptr_util.h'\r\nbuild_cleaner ///tensorflow/core:training_op_helpers\r\n#include \"/tensorflow/core/util/ptr_util.h\"\r\n        ^\r\n1 error generated.\r\nBroken by missing target ///tensorflow/core/kernels:dense_update_functor\r\ncontent_copy\r\n/tensorflow/core/kernels/dense_update_functor.cc:20:10: error: use of private header from outside its module: '/tensorflow/core/framework/register_types.h'; see \r\n#include \"/tensorflow/core/framework/register_types.h\"\r\n        ^\r\n/tensorflow/core/kernels/dense_update_functor.cc:21:10: error: use of private header from outside its module: '/tensorflow/core/framework/variant_op_registry.h'; see \r\n#include \"/tensorflow/core/framework/variant_op_registry.h\"\r\n        ^\r\n2 errors generated.\r\n\r\n`", "@samikama Can you please check @rthadur's comments and keep us posted. Thanks!", "@gbaned This is a bit hard to resolve since we can not reproduce the issue with public TF release and bazel. ", "@mihaimaruseac can you please with internal errors ?", "I will need to find some uninterrupted time without any urgent priority. Unfortunately this has not been the case yet, sorry about this.\r\n\r\nI have the PR on my list and will surely get to fixing it.\r\n\r\nThere is a merge conflict, can we fix it?", "@samikama Can you please resolve conflicts? Thanks!", "@samikama, Any update on this PR? Please. Thanks!\r\n", "I will rework this PR when I have time.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "@samikama  Any update on this PR? and please resolve conflicts. Thanks!", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 39421, "title": "Problem with tf.keras.metrics.Mean", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nUbuntu 19.10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\nFrom source\r\n- TensorFlow version (use command below):\r\nv2.1.0-0-ge5bf8de410 2.1.0\r\n- Python version:\r\n3.7\r\n- Bazel version (if compiling from source):\r\n? (built a while ago)\r\n- GCC/Compiler version (if compiling from source):\r\n? \r\n- CUDA/cuDNN version:\r\n10.2\r\n- GPU model and memory:\r\nGeForce GTX 1080 8G\r\n\r\n**Describe the current behavior**\r\n\r\nThe following code:\r\n\r\n    tf.keras.metrics.Mean(name='train_loss')\r\n\r\nresults in the error:\r\n\r\n    tensorflow.python.framework.errors_impl.InvalidArgumentError: assertion failed: [0] [Op:Assert] name: EagerVariableNameReuse\r\n\r\nThis same behaviour has been observed many times, for example:\r\n\r\nhttps://stackoverflow.com/questions/61321380/gpu-out-of-memory-error-just-by-declaring-tf-keras-metrics\r\n\r\nThere is also the (same?) issue which should not have been closed:\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/38518\r\n\r\nIn my case, the code was working and then began giving this error even though no code changes were made. Moreover, this persisted even when I killed all python processes first.\r\n\r\n", "comments": ["@quantitative-technologies,\r\nI was able to run the code without any issues on [TF v2.1](https://colab.research.google.com/gist/amahendrakar/6169c4eab69d248cb83950eb17431d20/39421-2-1.ipynb) and [TF v2.2](https://colab.research.google.com/gist/amahendrakar/45eab1d9eb03ffa7a08cab3efd28da3c/39421.ipynb). Please find the attached gist. \r\n\r\nCould you please check if you are facing the same error in a virtual environment. Thanks!", "I was running in a virtual environment when I made this bug report.\r\n\r\nI just tried starting the python console from my virtualenv, and running the two lines of code from your gist. Here is the complete output:\r\n\r\n>>> import tensorflow as tf\r\n>>> tf.__version__\r\n'2.1.0'\r\n>>> tf.keras.metrics.Mean(name='train_loss')\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/home/james/.virtualenvs/netraml/lib/python3.7/site-packages/tensorflow_core/python/keras/metrics.py\", line 460, in __init__\r\n    reduction=metrics_utils.Reduction.WEIGHTED_MEAN, name=name, dtype=dtype)\r\n  File \"/home/james/.virtualenvs/netraml/lib/python3.7/site-packages/tensorflow_core/python/keras/metrics.py\", line 296, in __init__\r\n    'total', initializer=init_ops.zeros_initializer)\r\n  File \"/home/james/.virtualenvs/netraml/lib/python3.7/site-packages/tensorflow_core/python/keras/metrics.py\", line 276, in add_weight\r\n    aggregation=aggregation)\r\n  File \"/home/james/.virtualenvs/netraml/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer.py\", line 446, in add_weight\r\n    caching_device=caching_device)\r\n  File \"/home/james/.virtualenvs/netraml/lib/python3.7/site-packages/tensorflow_core/python/training/tracking/base.py\", line 744, in _add_variable_with_custom_getter\r\n    **kwargs_for_getter)\r\n  File \"/home/james/.virtualenvs/netraml/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/base_layer_utils.py\", line 142, in make_variable\r\n    shape=variable_shape if variable_shape else None)\r\n  File \"/home/james/.virtualenvs/netraml/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py\", line 258, in __call__\r\n    return cls._variable_v1_call(*args, **kwargs)\r\n  File \"/home/james/.virtualenvs/netraml/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py\", line 219, in _variable_v1_call\r\n    shape=shape)\r\n  File \"/home/james/.virtualenvs/netraml/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py\", line 197, in <lambda>\r\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\r\n  File \"/home/james/.virtualenvs/netraml/lib/python3.7/site-packages/tensorflow_core/python/ops/variable_scope.py\", line 2596, in default_variable_creator\r\n    shape=shape)\r\n  File \"/home/james/.virtualenvs/netraml/lib/python3.7/site-packages/tensorflow_core/python/ops/variables.py\", line 262, in __call__\r\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n  File \"/home/james/.virtualenvs/netraml/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\", line 1411, in __init__\r\n    distribute_strategy=distribute_strategy)\r\n  File \"/home/james/.virtualenvs/netraml/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\", line 1557, in _init_from_args\r\n    graph_mode=self._in_graph_mode)\r\n  File \"/home/james/.virtualenvs/netraml/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\", line 232, in eager_safe_variable_handle\r\n    shape, dtype, shared_name, name, graph_mode, initial_value)\r\n  File \"/home/james/.virtualenvs/netraml/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py\", line 164, in _variable_handle_from_shape_and_dtype\r\n    math_ops.logical_not(exists), [exists], name=\"EagerVariableNameReuse\")\r\n  File \"/home/james/.virtualenvs/netraml/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_logging_ops.py\", line 55, in _assert\r\n    _ops.raise_from_not_ok_status(e, name)\r\n  File \"/home/james/.virtualenvs/netraml/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 6606, in raise_from_not_ok_status\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: assertion failed: [0] [Op:Assert] name: EagerVariableNameReuse\r\n\r\n\r\nThis is an intermittent error. I believe it will work for a while if I restart my system.", "@quantitative-technologies,\r\nIs this still an issue.", "No, but that is because I am exclusively using Tensorflow 2 now.\n\nOn Mon, Aug 17, 2020 at 1:02 PM Saduf2019 <notifications@github.com> wrote:\n\n> @quantitative-technologies <https://github.com/quantitative-technologies>,\n> Is this still an issue.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/39421#issuecomment-674997898>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AG6M5F5IW5HPZYEANBSKA3DSBFPCZANCNFSM4M6DD3NQ>\n> .\n>\n", "@quantitative-technologies,\r\nIn that case can we move this issue to closed status.", "Marking as closed as the issue is not reproducible in TF 2. Please feel free to comment on the issue if there are more questions.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39421\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39421\">No</a>\n"]}, {"number": 39420, "title": "[INTEL MKL] enabling mkldnn threadpool build options", "body": "This implements the mkldnn threadpool build options.\r\n--config=mkl_threadpool for eigen based mkldnn backend.\r\n--config=mkl for OMP based mkldnn backend.", "comments": ["@penpornk , I have addressed the changes. Please take a look."]}, {"number": 39419, "title": "Tensorflow Build from Source Raspberry Pi", "body": "**System information**\r\n- Windows 10 Pro Version 1909 \r\n- Python 3.8.2\r\n- pip 20.1\r\n- virtualenv 20.0.20\r\n\r\n\r\nHello,\r\nI am trying to follow these installation instructions https://www.tensorflow.org/install/source_rpi.\r\n\r\nWhen I try to \"cross-compile the TensorFlow source code to build a Python pip package\", I get the error message:\r\n`The command \"CI_DOCKER_EXTRA_PARAMS\" is either misspelled or could not be found`\r\n\r\nThis is the command:\r\n`CI_DOCKER_EXTRA_PARAMS=\"-e CI_BUILD_PYTHON=python3 -e CROSSTOOL_PYTHON_INCLUDE_PATH=/usr/include/python3.4\" \\`\r\n\r\nThe test command for Docker works fine:\r\n`docker run --rm hello-world`\r\n`\"Hello from Docker!\r\nThis message shows that your installation appears to be working correctly.\"`\r\n\r\nDoes anyone have an idea or a tip? I suspect something is not installed properly. Is \"CI_DOCKER_EXTRA_PARAMS\" a Docker-command? What is the requirement for the OS to know or recognize this command?\r\n\r\n", "comments": ["Probably the problem is that you did not fully copy command from the site, what is visible from your text. It should look like this:\r\n`CI_DOCKER_EXTRA_PARAMS=\"-e CI_BUILD_PYTHON=python3 -e CROSSTOOL_PYTHON_INCLUDE_PATH=/usr/include/python3.4\" \\\r\n    tensorflow/tools/ci_build/ci_build.sh PI-PYTHON3 \\\r\n    tensorflow/tools/ci_build/pi/build_raspberry_pi.sh`\r\nOr so, if you need support for all rpi devices:\r\n`tensorflow/tools/ci_build/ci_build.sh PI \\\r\n    tensorflow/tools/ci_build/pi/build_raspberry_pi.sh PI_ONE`", "Of course i copied the code using the \"copy code sample to clipboard\" button first. The individual lines in the command window are interpreted separately. But I also wrote the entire command individually, as you suggested., which unfortunately does not help. The command \"CI_DOCKER_EXTRA_PARAMS\" is unknown.", "The build script only works with Linux. Please use Linux workstation. Thanks.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39419\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39419\">No</a>\n"]}, {"number": 39418, "title": "ModuleNotFoundError: No module named 'tensorflow_core.core'", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **No**\r\n- OS Platform and Distribution : **Debian GNU/Linux 10.x (buster) 64Bit**\r\n- TensorFlow installed from (source or binary): **source**\r\n- TensorFlow version (use command below): **Command not working**\r\n- Python version: **3.7.3**\r\n- CUDA/cuDNN version: **10.1**\r\n- GPU model and memory: **nVidia Titan X 12GB**\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nEven basic commands like import tensorflow are giving me the error specified in the title, which shows to be in the __init__.py file in the traceback call.\r\n\r\n**Describe the expected behavior**\r\nTensorflow should run normally\r\n\r\n**Standalone code to reproduce the issue**\r\n`import tensorflow as tf;`\r\n\r\n**Other info / logs** \r\n```\r\n File \"<string>\", line 1, in <module>\r\n  File \"/home/bilank/py_envs/dev/lib/python3.7/site-packages/tensorflow/__init__.py\", line 101, in <module>\r\n    from tensorflow_core import *\r\n  File \"/home/bilank/py_envs/dev/lib/python3.7/site-packages/tensorflow_core/__init__.py\", line 40, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"/home/bilank/py_envs/dev/lib/python3.7/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"/home/bilank/py_envs/dev/lib/python3.7/site-packages/tensorflow/__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"/home/bilank/py_envs/dev/lib/python3.7/importlib/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"/home/bilank/py_envs/dev/lib/python3.7/site-packages/tensorflow_core/python/__init__.py\", line 64, in <module>\r\n    from tensorflow.core.framework.graph_pb2 import *\r\n  File \"/home/bilank/py_envs/dev/lib/python3.7/site-packages/tensorflow/__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"/home/bilank/py_envs/dev/lib/python3.7/site-packages/tensorflow/__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"/home/bilank/py_envs/dev/lib/python3.7/importlib/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\nModuleNotFoundError: No module named 'tensorflow_core.core'\r\n\r\n```", "comments": ["@MeteoRex11 \r\n\r\nWhich version of Tensorflow you are using?\r\ntensorflow_core only exists in 1.15, 2.0 and 2.1\r\nAlso, please post output of pip freeze using ``` around computer generated messages (so the formatting is preserved).Thanks!", "@ravikyram Thanks for the reply\r\nI am using tensorflow 2.2.0\r\nThe output of pip freeze is below\r\n\r\n```\r\nabsl-py==0.9.0\r\nace==0.3.2\r\nacefile==0.6.12\r\naiodns==1.1.1\r\nappdirs==1.4.4\r\nargcomplete==1.11.1\r\nasn1crypto==0.24.0\r\nastor==0.8.1\r\nastunparse==1.6.3\r\nbooleanOperations==0.8.2\r\nboto==2.49.0\r\nboto3==1.9.249\r\nbotocore==1.12.249\r\nBrotli==1.0.7\r\ncached-property==1.5.1\r\ncachetools==4.1.0\r\ncertifi==2018.8.24\r\nchardet==3.0.4\r\ncheck-systemd==2.0.9\r\nchrome-gnome-shell==0.0.0\r\ncryptography==2.6.1\r\ncson==0.7\r\ncupshelpers==1.0\r\ncycler==0.10.0\r\ndecorator==4.3.0\r\ndefusedxml==0.6.0\r\n# Editable install with no version control (Depman==0.1)\r\n-e /home/bilank/depman-master\r\ndevscripts==2.19.5+deb10u1\r\ndistro==1.3.0\r\ndnspython==1.16.0\r\ndocutils==0.15.2\r\neasygui==0.96\r\nentrypoints==0.3\r\nexchangelib==3.1.1\r\nfonttools==3.35.1\r\nfs==2.2.1\r\ngast==0.3.3\r\ngensim==3.8.1\r\ngeographiclib==1.49\r\ngeopy==1.18.1\r\ngoogle-auth==1.14.2\r\ngoogle-auth-oauthlib==0.4.1\r\ngoogle-pasta==0.2.0\r\ngpg==1.12.0\r\ngrpcio==1.28.1\r\nh5py==2.10.0\r\nidna==2.6\r\nimagecodecs==2020.2.18\r\nimageio==2.8.0\r\nimportlib-metadata==1.6.0\r\niotop==0.6\r\nipython==5.8.0\r\nipython-genutils==0.2.0\r\nisodate==0.6.0\r\njedi==0.13.2\r\njieba==0.39\r\njmespath==0.9.4\r\njoblib==0.14.0\r\nKeras==2.3.1\r\nKeras-Applications==1.0.8\r\nKeras-Preprocessing==1.1.0\r\nkeyring==17.1.1\r\nkeyrings.alt==3.1.1\r\nkiwisolver==1.0.1\r\nLatLon==1.0.2\r\nldap3==2.4.1\r\nlimit-gpus==0.1\r\nllvmlite==0.32.1\r\nlxml==4.4.2\r\nmailer==0.8.1\r\nMarkdown==3.2.2\r\nmatplotlib==3.0.2\r\nmpmath==1.1.0\r\nmysqlclient==1.3.10\r\nnagiosplugin==1.2.4\r\nnetworkx==2.4\r\nnltk==3.4.5\r\nnose==1.3.7\r\nntlm-auth==1.4.0\r\nnumba==0.49.1\r\nnumpy==1.16.2\r\noauthlib==3.1.0\r\nolefile==0.46\r\nopencv-python==4.2.0.34\r\nopt-einsum==3.2.1\r\nosmium==2.15.1\r\npackaging==20.3\r\nparso==0.3.1\r\npexpect==4.6.0\r\npickleshare==0.7.5\r\nPillow==5.4.1\r\npinyin-jyutping-sentence==0.5\r\npkg-resources==0.0.0\r\npooch==1.1.0\r\nprompt-toolkit==1.0.15\r\nprotobuf==3.11.3\r\npsutil==5.7.0\r\npyasn1==0.4.2\r\npyasn1-modules==0.2.1\r\npycairo==1.16.2\r\npycares==2.1.1\r\npyclipper==1.1.0.post2\r\npycrypto==2.6.1\r\npycups==1.9.73\r\nPygments==2.3.1\r\nPyGObject==3.30.4\r\nPyMsgBox==1.0.7\r\nPyOpenGL==3.1.0\r\npyparsing==2.2.0\r\npyproj==1.9.6\r\npysmbc==1.0.15.6\r\npython-apt==1.8.4.1\r\npython-crfsuite==0.9.6\r\npython-dateutil==2.8.0\r\npython-debian==0.1.35\r\npython-ldap==3.1.0\r\npython-magic==0.4.16\r\npytz==2019.1\r\nPyWavelets==1.1.1\r\npyxattr==0.6.1\r\npyxdg==0.25\r\nPyYAML==5.3.1\r\nQtPy==1.3.1\r\nreportlab==3.5.13\r\nrequests==2.21.0\r\nrequests-ntlm==1.1.0\r\nrequests-oauthlib==1.3.0\r\nrsa==4.0\r\ns3transfer==0.2.1\r\nscikit-image==0.17.1\r\nscikit-learn==0.21.3\r\nscipy==1.4.1\r\nscour==0.37\r\nSecretStorage==2.3.1\r\nsetproctitle==1.1.10\r\nShapely==1.6.4\r\nsimplegeneric==0.8.1\r\nsix==1.12.0\r\nsklearn==0.0\r\nsklearn-crfsuite==0.3.6\r\nsmart-open==1.8.4\r\nspeg==0.3\r\nsympy==1.3\r\ntabulate==0.8.5\r\ntensorboard==2.2.1\r\ntensorboard-plugin-wit==1.6.0.post3\r\ntensorflow==2.2.0\r\ntensorflow-estimator==2.2.0\r\ntensorflow-gpu==2.1.0\r\ntermcolor==1.1.0\r\ntifffile==2020.5.7\r\ntltk==1.2.4\r\ntqdm==4.36.1\r\ntraitlets==4.3.2\r\ntzlocal==2.0.0\r\nunidiff==0.5.4\r\nurllib3==1.24.1\r\nvboxapi==1.0\r\nvirtualenv==15.1.0\r\nwcwidth==0.1.7\r\nWerkzeug==1.0.1\r\nwrapt==1.12.1\r\nyoutube-dl==2019.1.17\r\nzipp==3.1.0\r\n\r\n```", "I suspect this is due to version mismatch of various TF packages in your configuration.\r\nCan you please try installing TF in a virtual environment?", "I had a similar issue with tensorflow.python.tools when importing tensorflow on my Ubuntu Server\r\nTry installing this version:\r\n\r\n    pip3 install uninstall tensorflow\r\n    pip3 install tensorflow==2.2.0rc4", "Please install `tensorflow==2.2` instead of `rc4`.\r\n\r\nAlso, if you're building from source, what is the commit hash you are building from? Are you building from master?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39418\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39418\">No</a>\n"]}, {"number": 39417, "title": "experimental_run_v2 throws AttributeError with MultiWorkerMirroredStrategy", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.1 and 2.2 affected\r\n\r\n**Describe the current behavior**\r\n\r\nUsing `strategy.experimental_run_v2` (or `strategy.run` for TF 2.2) with `MultiWorkerMirroredStrategy` throws `AttributeError: 'CollectiveAllReduceExtended' object has no attribute '_cfer_fn_cache'` when passing it a tf.function\r\n\r\nThis is caused by the access at https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/distribute/mirrored_strategy.py#L743 due to `CollectiveAllReduceExtended` not calling the `super().__init__` function which creates that dictionary at https://github.com/tensorflow/tensorflow/blob/v2.2.0/tensorflow/python/distribute/mirrored_strategy.py#L472\r\n\r\nI noted that the relevant code was removed in current master by https://github.com/tensorflow/tensorflow/commit/b16d24a342c5de1384dcb9ee408a74f206d332b2 but wanted to make sure it is included in the next release or in a patch release. Also `MultiWorkerMirroredStrategy` is not mentioned in the commit, so it might be a good idea to include something like this as a test case to avoid regressions. Looking at the commit I guess this is fixed too.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nstrategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\r\n\r\nwith strategy.scope():\r\n    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\r\n    x_train, x_test = x_train / 255.0, x_test / 255.0\r\n    train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(32)\r\n\r\n    model = tf.keras.models.Sequential([\r\n        tf.keras.layers.Flatten(input_shape=(28, 28)),\r\n        tf.keras.layers.Dense(128, activation='relu'),\r\n        tf.keras.layers.Dense(10),\r\n    ])\r\n\r\n    model.compile(\r\n        optimizer=tf.keras.optimizers.SGD(),\r\n        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n        metrics=['accuracy'])\r\n\r\n\r\n@tf.function\r\ndef train_step(model, data, target):\r\n    with tf.GradientTape() as tape:\r\n        predictions = model(data, training=True)\r\n        loss = model.loss(target, predictions)\r\n\r\n    gradients = tape.gradient(loss, model.trainable_variables)\r\n    model.optimizer.apply_gradients(zip(gradients, model.trainable_variables))\r\n    return loss\r\n\r\n\r\ndef distributed_train_step(strategy, model, x, y):\r\n    strategy.experimental_run_v2(train_step, args=(model, x, y))\r\n\r\n\r\nfor x, y in train_dataset:\r\n    distributed_train_step(strategy, model, x, y)\r\n\r\n```", "comments": ["Was able to reproduce the issue with TF v2.1 and [TF v2.2](https://colab.research.google.com/gist/amahendrakar/316a940c03a42bbb52b1d8ce4db15d43/39417.ipynb) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/948f56175057fb095317cd2c91fff970/39417-tf-nightly.ipynb#scrollTo=vA2ulWhPWgOe). Please find the attached gist. Thanks!", "The issue should already be fixed at HEAD. As a workaround for 2.2, you can wrap distributed_train_step with @tf.function.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39417\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39417\">No</a>\n", "@crccw The suggested workaround does not work in neither TF 2.1 or TF 2.2: https://colab.research.google.com/drive/1563oBryExvogSUexRlR64C4nuK52WMR5?usp=sharing", "Try only wrap distributed_train_step, not train_step.", "Dear @Flamefire \r\n\r\nMaybe you can help to reproduce the @brianwa84 's [example](https://colab.research.google.com/github/tensorflow/probability/blob/master/discussion/examples/cross_gpu_logprob.ipynb) on Slurm machines (below the code). The main idea is to execute log probability calculations in MCMC algorithm across GPUs. \r\n\r\nI've tested lots of combinations (as you can see in the commented code below) but none of them work :(\r\n\r\nThe first attempt was to use the same configuration as @brianwa84 has in his [notebook](https://colab.research.google.com/github/tensorflow/probability/blob/master/discussion/examples/cross_gpu_logprob.ipynb). It worked, but I want to use physical GPUs in the machine (several nodes), and not to create logical GPUs as he did. But when I try to use physical GPUs then MirroredStrategy  does not execute  calculations, the GPUs do not show activity (volatility 0%). Due to this behaviour my second attempt was try MultiWorkerMirroredStrategy but throws the same errors discussed here\r\n``` AttributeError: 'CollectiveAllReduceExtended' object has no attribute '_cfer_fn_cache' ```\r\n\r\nPlease could you help me how to reproduce the @brianwa84 's [notebook](https://colab.research.google.com/github/tensorflow/probability/blob/master/discussion/examples/cross_gpu_logprob.ipynb) using Slurm queues? \r\n\r\n```python \r\n#!/apps/PYTHON/3.7.4_ML/bin/python \r\nfrom __future__ import absolute_import, division, print_function, unico \r\nimport sys \r\nimport os \r\n# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\" \r\n# os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1,2,3\" \r\nimport numpy as np \r\nimport tensorflow as tf \r\nimport tensorflow_probability as tfp \r\ntfb, tfd = tfp.bijectors, tfp.distributions \r\nprint(\"TF version: \", tf.__version__) \r\nprint(\"TFP: \", tfp.__version__) \r\nfrom slurm_cluster_resolver import SlurmClusterResolver \r\n# Sanity check to observe which device has calculations \r\ntf.debugging.set_log_device_placement(True) \r\n# ------------------------ \r\n# Setting up physical GPUs \r\n# ------------------------ \r\n# \r\n# Nothing to do with previos os.eviron['CUDA...] the system recognize t \r\nphysical_gpus = tf.config.list_physical_devices('GPU') \r\nprint(len(physical_gpus), \"Physical GPUs\") \r\nresolver = tf.distribute.cluster_resolver.SlurmClusterResolver() \r\nst = tf.distribute.experimental.MultiWorkerMirroredStrategy(resolver) \r\n# st = tf.distribute.MirroredStrategy() \r\n# strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:0\") \r\n# ----------------------- \r\n# Setting up logical GPUs \r\n# ----------------------- \r\n# \r\n# GPU_SIZE = 6 # (G)  MemorySIZE per GPU \r\n# for gpu in physical_gpus: \r\n#    tf.config.experimental.set_virtual_device_configuration( \r\n#        gpu, \r\n#        [tf.config.experimental.VirtualDeviceConfiguration(memory_limi \r\n# logical_gpus = tf.config.list_logical_devices('GPU') \r\n# print(len(logical_gpus), \"Logical GPUs\") \r\n# st = tf.distribute.MirroredStrategy( \r\n#    devices=tf.config.list_logical_devices('GPU')) \r\n# resolver = tf.distribute.cluster_resolver.SlurmClusterResolver() \r\n# st = tf.distribute.experimental.MultiWorkerMirroredStrategy(cluster_r \r\n# Sanity check \r\nprint ('Number of devices to do the strategy: {}'.format(st.num_replica \r\nprint('Woker devices: {}', st.extended.worker_devices) \r\n# sys.exit() \r\n\r\n# Model and dataset \r\n# ----------------- \r\n# \r\n# Draw samples from an MVN, then sort them. This way we can easily visu \r\n# verify the correct partition ends up on the correct GPUs. \r\nndim = 3 \r\ndef model(): \r\n    Root = tfd.JointDistributionCoroutine.Root \r\n    loc = yield Root(tfb.Shift(.5)(tfd.MultivariateNormalDiag(loc=tf.ze \r\n    scale_tril = yield Root(tfb.FillScaleTriL()(tfd.MultivariateNormalD \r\n + 1) // 2])))) \r\n    yield tfd.MultivariateNormalTriL(loc=loc, scale_tril=scale_tril) \r\n\r\ndist = tfd.JointDistributionCoroutine(model) \r\n\r\ntf.random.set_seed(1) \r\nloc, scale_tril, _ = dist.sample(seed=2) \r\nsamples = dist.sample(value=([loc] * 1024, scale_tril, None), seed=3)[2 \r\nsamples = tf.round(samples * 1000) / 1000 \r\nfor dim in reversed(range(ndim)): \r\n  samples = tf.gather(samples, tf.argsort(samples[:,dim])) \r\n\r\n# print(len(samples)) \r\n# print(loc) \r\n# print(scale_tril) \r\n# print(tf.reduce_mean(samples, 0)) \r\n# sys.exit() \r\n\r\ndef dataset_fn(ctx): \r\n    batch_size = ctx.get_per_replica_batch_size(len(samples)) \r\n    d = tf.data.Dataset.from_tensor_slices(samples).batch(batch_size) \r\n    return d.shard(ctx.num_input_pipelines, ctx.input_pipeline_id) \r\nds = st.experimental_distribute_datasets_from_function(dataset_fn) \r\n\r\n# Sanity check playing with dataset from function \r\n# iterator = iter(ds) \r\n# def replica_fn(arg): \r\n#    return tf.reduce_mean(arg, 0) \r\n# for batch in ds: \r\n#    replica1 = st.run(replica_fn, args=(batch,)) \r\n# print(replica1) \r\n\r\n# Toy 2 \r\n# iterator = iter(ds) \r\n# @tf.function(input_signature=[iterator.element_spec]) \r\n# def replica_fn2(arg): \r\n#    return tf.reduce_mean(arg, 0) \r\n# replica2 = st.run(replica_fn2, args=(next(iterator),)) \r\n# print(replica2) \r\n# replicas_sum = st.reduce(tf.distribute.ReduceOp.SUM, replica1) \r\n# print(replicas_sum) \r\n# sys.exit() \r\nobservations = next(iter(ds)) \r\n# print(observations) \r\n\r\n@tf.function(autograph=False) \r\ndef log_prob_and_grad(loc, scale_tril, observations): \r\n    ctx = tf.distribute.get_replica_context() \r\n    with tf.GradientTape() as tape: \r\n        tape.watch((loc, scale_tril)) \r\n        lp = tf.reduce_sum(dist.log_prob(loc, scale_tril, observations)) / len(samples) \r\n    grad = tape.gradient(lp, (loc, scale_tril)) \r\n    return ctx.all_reduce('sum', lp), [ctx.all_reduce('sum', g) for g in grad] \r\n\r\n@tf.function(autograph=False) \r\n@tf.custom_gradient \r\ndef target_log_prob(loc, scale_tril): \r\n    lp, grads = st.run(log_prob_and_grad, (loc, scale_tril, observations)) \r\n    return lp.values[0], lambda grad_lp: [grad_lp * g.values[0] for g in grads] \r\n\r\nsingleton_vals = tfp.math.value_and_gradient(target_log_prob, (loc, scale_tril)) \r\nprint(singleton_vals) \r\nprint(\"*\"*50) \r\n# sys.exit() \r\n\r\nkernel = tfp.mcmc.HamiltonianMonteCarlo(target_log_prob, step_size=.35, num_leapfrog_steps=2) \r\nkernel = tfp.mcmc.TransformedTransitionKernel(kernel, bijector=[tfb.Identity(), tfb.FillScaleTriL()])\r\n\r\n@tf.function(autograph=False) \r\ndef sample_chain(): \r\n    return tfp.mcmc.sample_chain( \r\n        num_results=200, num_burnin_steps=100, \r\n        current_state=[tf.ones_like(loc), tf.linalg.eye(scale_tril.shape[-1])], \r\n        kernel=kernel, trace_fn=lambda _, kr: kr.inner_results.is_accepted) \r\n\r\nsamps, is_accepted = sample_chain() \r\nprint(f'accept rate: {np.mean(is_accepted)}') \r\nprint(f'ess: {tfp.mcmc.effective_sample_size(samps)}') \r\nprint(tf.reduce_mean(samps[0], axis=0)) \r\nprint(tf.reduce_mean(samps[1], axis=0)) \r\n```\r\n\r\n```\r\n#!/bin/bash \r\n#SBATCH --job-name='test_cross_gpu' \r\n#SBATCH --qos=debug \r\n# \r\n#SBATCH --nodes=1 \r\n#SBATCH --ntasks=1 \r\n#SBATCH --cpus-per-task=160 \r\n#SBATCH --gres=gpu:4 \r\n#SBATCH --time=00:15:00 \r\n#------- I/O ------- \r\n#SBATCH -D . \r\n#SBATCH --output=test_cross_gpu_%j.out \r\n#SBATCH --error=test_cross_gpu_%j.err \r\n#------- modules ------- \r\nmodule purge \r\nmodule load gcc/8.3.0 cuda/10.1 cudnn/7.6.4 nccl/2.4.8 tensorrt/6.0.1 openmpi/4.0.1 atlas/3.10.3 scalapack/2.0.2 fftw/3.3.8 szip/2.1.1 ffmpeg/4.2.1 opencv/4.1.1 python/3.7.4_ML \r\necho \"== Starting run at $(date)\" \r\necho \"== Job ID: ${SLURM_JOBID}\" \r\necho \"== Job NPROCS: ${SLURM_NPROCS}\" \r\necho \"== Job NNODES: ${SLURM_NNODES}\" \r\necho \"== Node list: ${SLURM_NODELIST}\" \r\necho \"== Submit dir. : ${SLURM_SUBMIT_DIR}\" \r\n#------- srun ------ \r\nsrun test_cross_gpu_logprob.py \r\n```\r\n", "Which Tensorflow version are you using? Could you upgrade to 2.2?", "I use TF 2.2.0 and TFP 0.9.0", "Sorry the fix was not in 2.2. Could you try use nightly? If it's not possible, please wrap strategy.run() in a tf.function **and** pass a **non** tf.function to strategy.run", "Sorry, I can't update to nightly. It's difficult to me understand your last sentence. Please, could you tell me how to do that using the code above?", "Many thanks @crccw ! \r\n\r\n@brianwa84 and @Flamefire in CC.\r\n\r\nIn previous code I have commented ```@tf.function(autograph=False) ``` for ``` def_log_prob_and_grad```. I have not commented ```@tf.funtcion``` in  ```def target_log_prob(loc, scale_tril):``` which contains strategy.run()\r\n\r\nNow, I have not errors, but the process freezes. This also happens using MirroredStrategy with one machine and 4 GPUs.\r\n\r\nAny clue?\r\n\r\n\r\n```python\r\n# @tf.function(autograph=False) \r\ndef log_prob_and_grad(loc, scale_tril, observations): \r\n    ctx = tf.distribute.get_replica_context() \r\n    with tf.GradientTape() as tape: \r\n        tape.watch((loc, scale_tril)) \r\n        lp = tf.reduce_sum(dist.log_prob(loc, scale_tril, observations)) / len(samples) \r\n    grad = tape.gradient(lp, (loc, scale_tril)) \r\n    return ctx.all_reduce('sum', lp), [ctx.all_reduce('sum', g) for g in grad] \r\n\r\n@tf.function(autograph=False) \r\n@tf.custom_gradient \r\ndef target_log_prob(loc, scale_tril): \r\n    lp, grads = st.run(log_prob_and_grad, (loc, scale_tril, observations)) \r\n    return lp.values[0], lambda grad_lp: [grad_lp * g.values[0] for g in grads] \r\nsingleton_vals = tfp.math.value_and_gradient(target_log_prob, (loc, scale_tril)) \r\nprint(singleton_vals) \r\nprint(\"*\"*50) \r\nsys.exit() \r\n\r\nkernel = tfp.mcmc.HamiltonianMonteCarlo(target_log_prob, step_size=.35, num_leapfrog_steps=2) \r\nkernel = tfp.mcmc.TransformedTransitionKernel(kernel, bijector=[tfb.Identity(), tfb.FillScaleTriL()]) \r\n\r\n@tf.function(autograph=False) \r\ndef sample_chain(): \r\n    return tfp.mcmc.sample_chain( \r\n        num_results=200, num_burnin_steps=100, \r\n        current_state=[tf.ones_like(loc), tf.linalg.eye(scale_tril.shape[-1])], \r\n        kernel=kernel, trace_fn=lambda _, kr: kr.inner_results.is_accepted) \r\n\r\nsamps, is_accepted = sample_chain() \r\n\r\nprint(f'accept rate: {np.mean(is_accepted)}') \r\nprint(f'ess: {tfp.mcmc.effective_sample_size(samps)}') \r\nprint(tf.reduce_mean(samps[0], axis=0)) \r\nprint(tf.reduce_mean(samps[1], axis=0)) \r\n```\r\n\r\n```\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 440.33.01    Driver Version: 440.33.01    CUDA Version: 10.2     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla V100-SXM2...  On   | 00000004:04:00.0 Off |                    0 |\r\n| N/A   38C    P0    51W / 300W |  15360MiB / 16160MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  Tesla V100-SXM2...  On   | 00000004:05:00.0 Off |                    0 |\r\n| N/A   40C    P0    50W / 300W |  15220MiB / 16160MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  Tesla V100-SXM2...  On   | 00000035:03:00.0 Off |                    0 |\r\n| N/A   37C    P0    50W / 300W |  15220MiB / 16160MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  Tesla V100-SXM2...  On   | 00000035:04:00.0 Off |                    0 |\r\n| N/A   40C    P0    55W / 300W |  15220MiB / 16160MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0    129007      C   /apps/PYTHON/3.7.4_ML/bin/python           15349MiB |\r\n|    1    129007      C   /apps/PYTHON/3.7.4_ML/bin/python           15209MiB |\r\n|    2    129007      C   /apps/PYTHON/3.7.4_ML/bin/python           15209MiB |\r\n|    3    129007      C   /apps/PYTHON/3.7.4_ML/bin/python           15209MiB |\r\n+-----------------------------------------------------------------------------+\r\n```", "I am not experienced w/ slurm, though I might be interested enough to learn and get a GCP example set up. I don't expect to have cycles to do so imminently though.\r\n\r\nMeantime you might find fellow users with experience in https://groups.google.com/forum/#!forum/google-cloud-slurm-discuss It seems GCP does support slurm with GPUs. https://cloud.google.com/blog/products/compute/hpc-made-easy-announcing-new-features-for-slurm-on-gcp so I'd think there may be a user on there with the relevant experience.", "Many thanks @brianwa84 !\r\n\r\nFor me this is frustrating. I've spent three weeks trying to run your [notebook](https://colab.research.google.com/github/tensorflow/probability/blob/master/discussion/examples/cross_gpu_logprob.ipynb) using multiple GPUs, and I get no advance. I'm afraid I'm not asking myself the right questions.\r\n\r\nI'll ask to slurm-discuss forum.", "hi,dear\r\nI have a similar problem with tf-gpu==2.4.1 with the [URL](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/distribute/custom_training.ipynb#scrollTo=bAXAo_wWbWSb) or this [docs](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/distribute/custom_training.ipynb)\r\neight 3090 cards, cuda 11.3, driver 465 ,\r\nso how to deal with this ?\r\nthx\r\n```\r\nTraceback (most recent call last):\r\n  File \"/data/prod/xulm1/custom_training.py\", line 113, in <module>\r\n    total_loss += distributed_train_step(x)\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\", line 828, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\", line 871, in _call\r\n    self._initialize(args, kwds, add_initializers_to=initializers)\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\", line 725, in _initialize\r\n    self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\", line 2969, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\", line 3361, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\", line 3196, in _create_graph_function\r\n    func_graph_module.func_graph_from_py_func(\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\", line 990, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\", line 634, in wrapped_fn\r\n    out = weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/func_graph.py\", line 977, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\nAttributeError: in user code:\r\n\r\n    /data/prod/xulm1/custom_training.py:99 distributed_train_step  *\r\n        per_replica_losses = strategy.experimental_run_v2(train_step,\r\n\r\n    AttributeError: 'MirroredStrategy' object has no attribute 'experimental_run_v2'\r\n```\r\n\r\n\r\n", "We have recently added this notebook:\nhttps://www.tensorflow.org/probability/examples/Distributed_Inference_with_JAX\n\nThe approach should be similar with MirroredStrategy, though there may be\nsome gymnastics needed to avoid a merge_call since\nReplicaContext.all_reduce puts one in unconditionally.\n\nOn Fri, May 14, 2021, 6:02 AM VideoRec ***@***.***> wrote:\n\n> hi,dear\n> I have a similar problem with tf-gpu==2.4.1 with the URL\n> <https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/distribute/custom_training.ipynb#scrollTo=bAXAo_wWbWSb>\n> eight 3090 cards, cuda 11.3, driver 465 ,\n> so how to deal with this ?\n> thx\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/39417#issuecomment-841145277>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AFJFSIYZGOLAY5KXUIUUALDTNTYJVANCNFSM4M6BIXSQ>\n> .\n>\n"]}, {"number": 39416, "title": "Update saving_utils.py", "body": "", "comments": ["Please make against master and describe what does it solve. Is there an issue?"]}, {"number": 39415, "title": "TensorFlow Lite Cant convert my model to .lite version", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (or github SHA if from source):\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\n# Copy and paste here\r\n```\r\n\r\n**Standalone code to reproduce the issue** \r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n\r\n2020-05-11 18:02:37.694825: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2\r\n2020-05-11 18:02:38.353968: I tensorflow/core/grappler/devices.cc:60] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA support)\r\n2020-05-11 18:02:38.360550: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2020-05-11 18:02:38.697609: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:786] Optimization results for grappler item: graph_to_optimize\r\n2020-05-11 18:02:38.703347: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 1226 nodes (-186), 1603 edges (-240), time = 90.665ms.\r\n2020-05-11 18:02:38.708737: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:788]   constant_folding: Graph size after: 1226 nodes (0), 1603 edges (0), time = \r\n30.288ms.\r\nTraceback (most recent call last):\r\n  File \"convert_modell2.0.py\", line 8, in <module>\r\n    tflite_model = converter.convert()\r\n  File \"E:\\Users\\Santiados\\anaconda3\\envs\\tflitecon\\lib\\site-packages\\tensorflow_core\\lite\\python\\lite.py\", line 983, in convert\r\n    **converter_kwargs)\r\n  File \"E:\\Users\\Santiados\\anaconda3\\envs\\tflitecon\\lib\\site-packages\\tensorflow_core\\lite\\python\\convert.py\", line 449, in toco_convert_impl\r\n    enable_mlir_converter=enable_mlir_converter)\r\n  File \"E:\\Users\\Santiados\\anaconda3\\envs\\tflitecon\\lib\\site-packages\\tensorflow_core\\lite\\python\\convert.py\", line 200, in toco_convert_protos\r\n    raise ConverterError(\"See console for info.\\n%s\\n%s\\n\" % (stdout, stderr))\r\ntensorflow.lite.python.convert.ConverterError: See console for info.\r\n2020-05-11 18:02:44.625539: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.625766: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.625953: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.626134: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.626300: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.626537: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.626774: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.626941: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.627118: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.627320: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.627490: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.627695: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.627900: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.628117: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.628312: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.628509: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.628710: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.628936: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.629169: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.629399: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.629623: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.629857: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.630063: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.630292: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.630495: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.630701: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.630910: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.631113: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.631310: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.631531: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.631744: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.631921: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.632031: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.632229: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.632460: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.632612: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.632847: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.633076: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.633320: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.633544: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.633754: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.633972: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.634220: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.634440: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.634679: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.634906: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.635104: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.635309: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.635534: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.635733: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.635961: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.636169: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.636392: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.636618: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.636829: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.637009: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.637225: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.637423: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.637651: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.637857: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.638068: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.638294: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.638522: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.638721: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.638947: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.639155: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.639360: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.639593: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.639814: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.640019: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.640218: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.640431: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.640633: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.640855: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.641070: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.641293: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.641532: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.641705: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.641904: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.642092: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.642274: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.642461: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.642645: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.642859: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.643055: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.643261: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.643464: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.643637: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.643834: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.644026: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.644202: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.644365: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.644555: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.644745: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.644935: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.645117: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.645314: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.645508: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.645696: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.645874: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.646088: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.646297: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.646512: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.646720: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.649215: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-05-11 18:02:44.649471: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-05-11 18:02:44.649683: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-05-11 18:02:44.649908: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-05-11 18:02:44.650117: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.650336: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-05-11 18:02:44.650561: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-05-11 18:02:44.650766: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-05-11 18:02:44.650966: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-05-11 18:02:44.651152: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.651364: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.651570: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.651758: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.651947: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.652133: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-05-11 18:02:44.652340: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.652528: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-05-11 18:02:44.652718: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3\r\n2020-05-11 18:02:44.652942: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.653143: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.653345: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-05-11 18:02:44.653547: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-05-11 18:02:44.653773: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-05-11 18:02:44.653992: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-05-11 18:02:44.654187: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.654383: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.654587: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.654793: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.655016: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.655223: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-05-11 18:02:44.655420: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.655629: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-05-11 18:02:44.655835: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3\r\n2020-05-11 18:02:44.656076: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.656311: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.656531: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-05-11 18:02:44.656779: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-05-11 18:02:44.656994: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-05-11 18:02:44.657200: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-05-11 18:02:44.657398: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.657598: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: LoopCond\r\n2020-05-11 18:02:44.657815: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.658020: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.658213: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.658412: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-05-11 18:02:44.658654: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.658847: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-05-11 18:02:44.659052: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3\r\n2020-05-11 18:02:44.659280: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: LoopCond\r\n2020-05-11 18:02:44.659442: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.659653: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.659847: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.660026: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-05-11 18:02:44.660235: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.660445: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-05-11 18:02:44.660639: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3\r\n2020-05-11 18:02:44.660851: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.661026: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.661207: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: LoopCond\r\n2020-05-11 18:02:44.661399: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.661597: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.661791: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.661959: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: LoopCond\r\n2020-05-11 18:02:44.662147: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.662336: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2020-05-11 18:02:44.662534: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2020-05-11 18:02:44.662713: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3\r\n2020-05-11 18:02:44.662979: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3\r\n2020-05-11 18:02:44.663235: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2020-05-11 18:02:44.663456: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3\r\n2020-05-11 18:02:44.663705: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3\r\n2020-05-11 18:02:44.663953: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2020-05-11 18:02:44.664221: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3\r\n2020-05-11 18:02:44.664490: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3\r\n2020-05-11 18:02:44.664769: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3\r\n2020-05-11 18:02:44.665027: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3\r\n2020-05-11 18:02:44.665306: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3\r\n2020-05-11 18:02:44.665600: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3\r\n2020-05-11 18:02:44.665896: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3\r\n2020-05-11 18:02:44.666157: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3\r\n2020-05-11 18:02:44.666622: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-05-11 18:02:44.666853: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-05-11 18:02:44.667088: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-05-11 18:02:44.667341: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-05-11 18:02:44.667582: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.667814: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2020-05-11 18:02:44.668075: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2020-05-11 18:02:44.668321: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.668515: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.668740: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.668963: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.669179: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-05-11 18:02:44.669429: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.669642: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-05-11 18:02:44.669874: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3\r\n2020-05-11 18:02:44.670137: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.670369: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.670607: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-05-11 18:02:44.670836: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-05-11 18:02:44.671043: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-05-11 18:02:44.671269: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-05-11 18:02:44.671491: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.671694: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2020-05-11 18:02:44.671931: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2020-05-11 18:02:44.672174: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: LoopCond\r\n2020-05-11 18:02:44.672403: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.672587: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.672815: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.673028: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-05-11 18:02:44.673258: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.673476: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-05-11 18:02:44.673721: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3\r\n2020-05-11 18:02:44.673985: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.674198: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.674404: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: LoopCond\r\n2020-05-11 18:02:44.674630: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.674847: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2020-05-11 18:02:44.675055: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3\r\n2020-05-11 18:02:44.675350: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3\r\n2020-05-11 18:02:44.675615: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2020-05-11 18:02:44.675859: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3\r\n2020-05-11 18:02:44.676154: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArraySizeV3\r\n2020-05-11 18:02:44.676425: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3\r\n2020-05-11 18:02:44.676710: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayGatherV3\r\n2020-05-11 18:02:44.677044: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-05-11 18:02:44.677278: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-05-11 18:02:44.677514: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-05-11 18:02:44.677762: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-05-11 18:02:44.677995: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.678224: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2020-05-11 18:02:44.678494: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.678720: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.678952: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.679166: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.679407: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-05-11 18:02:44.679659: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.679872: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-05-11 18:02:44.680076: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3\r\n2020-05-11 18:02:44.680268: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.680461: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.680664: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-05-11 18:02:44.680908: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-05-11 18:02:44.681132: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayV3\r\n2020-05-11 18:02:44.681364: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-05-11 18:02:44.681602: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.681821: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2020-05-11 18:02:44.682066: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: LoopCond\r\n2020-05-11 18:02:44.682298: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.682512: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.682726: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.682942: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-05-11 18:02:44.683183: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.683412: I tensorflow/lite/toco/import_tensorflow.cc:193] Unsupported data type in placeholder op: 20\r\n2020-05-11 18:02:44.683644: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayScatterV3\r\n2020-05-11 18:02:44.683845: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.684089: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.684292: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: LoopCond\r\n2020-05-11 18:02:44.684492: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Enter\r\n2020-05-11 18:02:44.684691: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2020-05-11 18:02:44.684875: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2020-05-11 18:02:44.685067: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3\r\n2020-05-11 18:02:44.685319: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2020-05-11 18:02:44.685500: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: Exit\r\n2020-05-11 18:02:44.685707: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3\r\n2020-05-11 18:02:44.685929: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3\r\n2020-05-11 18:02:44.686191: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayReadV3\r\n2020-05-11 18:02:44.686538: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2020-05-11 18:02:44.686776: I tensorflow/lite/toco/import_tensorflow.cc:659] Converting unsupported operation: TensorArrayWriteV3\r\n2020-05-11 18:02:44.700426: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 792 operators, 1274 arrays (0 quantized)\r\n2020-05-11 18:02:44.712374: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 720 operators, 1154 arrays (0 \r\nquantized)\r\n2020-05-11 18:02:44.726002: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 720 operators, 1154 arrays (0 quantized)\r\n2020-05-11 18:02:44.750457: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 646 operators, 1085 \r\narrays (0 quantized)\r\n2020-05-11 18:02:44.768568: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before Group bidirectional sequence lstm/rnn: 646 operators, 1085 arrays (0 quantized)\r\n2020-05-11 18:02:44.780627: I tensorflow/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 646 operators, 1085 arrays (0 quantized)\r\n2020-05-11 18:02:44.797189: I tensorflow/lite/toco/allocate_transient_arrays.cc:345] Total transient array allocated size: 37952 bytes, theoretical optimal value: 11008 bytes.\r\n2020-05-11 18:02:44.800826: I tensorflow/lite/toco/toco_tooling.cc:454] Number of parameters: 666633\r\n2020-05-11 18:02:44.802516: E tensorflow/lite/toco/toco_tooling.cc:481] We are continually in the process of adding support to TensorFlow Lite for more ops. It would \r\nbe helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nTensorFlow Lite currently doesn't support control flow ops: Enter, Exit, Merge, Switch. We are working on supporting control flow ops, please see github issue at https://github.com/tensorflow/tensorflow/issues/28485. Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONCATENATION, EXPAND_DIMS, FILL, FULLY_CONNECTED, LESS, LOGISTIC, MAXIMUM, MINIMUM, MUL, RANGE, RESHAPE, REVERSE_V2, SHAPE, STRIDED_SLICE, SUB, SUM, TANH, TILE, TRANSPOSE, ZEROS_LIKE. Here is a list of operators for which you \r\nwill need custom implementations: LoopCond, TensorArrayGatherV3, TensorArrayReadV3, TensorArrayScatterV3, TensorArraySizeV3, TensorArrayV3, TensorArrayWriteV3.       \r\nTraceback (most recent call last):\r\n  File \"E:\\Users\\Santiados\\anaconda3\\envs\\tflitecon\\Scripts\\toco_from_protos-script.py\", line 10, in <module>\r\n    sys.exit(main())\r\n  File \"E:\\Users\\Santiados\\anaconda3\\envs\\tflitecon\\lib\\site-packages\\tensorflow_core\\lite\\toco\\python\\toco_from_protos.py\", line 89, in main\r\n    app.run(main=execute, argv=[sys.argv[0]] + unparsed)\r\n  File \"E:\\Users\\Santiados\\anaconda3\\envs\\tflitecon\\lib\\site-packages\\tensorflow_core\\python\\platform\\app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"E:\\Users\\Santiados\\anaconda3\\envs\\tflitecon\\lib\\site-packages\\absl\\app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"E:\\Users\\Santiados\\anaconda3\\envs\\tflitecon\\lib\\site-packages\\absl\\app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"E:\\Users\\Santiados\\anaconda3\\envs\\tflitecon\\lib\\site-packages\\tensorflow_core\\lite\\toco\\python\\toco_from_protos.py\", line 52, in execute\r\n    enable_mlir_converter)\r\nException: We are continually in the process of adding support to TensorFlow Lite for more ops. It would be helpful if you could inform us of how this conversion went by opening a github issue at https://github.com/tensorflow/tensorflow/issues/new?template=40-tflite-op-request.md\r\n and pasting the following:\r\n\r\nTensorFlow Lite currently doesn't support control flow ops: Enter, Exit, Merge, Switch. We are working on supporting control flow ops, please see github issue at https://github.com/tensorflow/tensorflow/issues/28485. Some of the operators in the model are not supported by the standard TensorFlow Lite runtime. If those are native TensorFlow operators, you might be able to use the extended runtime by passing --enable_select_tf_ops, or by setting target_ops=TFLITE_BUILTINS,SELECT_TF_OPS when calling tf.lite.TFLiteConverter(). Otherwise, if you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONCATENATION, EXPAND_DIMS, FILL, FULLY_CONNECTED, LESS, LOGISTIC, MAXIMUM, MINIMUM, MUL, RANGE, RESHAPE, REVERSE_V2, SHAPE, STRIDED_SLICE, SUB, SUM, TANH, TILE, TRANSPOSE, ZEROS_LIKE. Here is a list of operators for which you \r\nwill need custom implementations: LoopCond, TensorArrayGatherV3, TensorArrayReadV3, TensorArrayScatterV3, TensorArraySizeV3, TensorArrayV3, TensorArrayWriteV3.\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem.\r\nIf including tracebacks, please include the full traceback. Large logs and files\r\nshould be attached.\r\n", "comments": ["@Santiados \r\nIn order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. \r\n\r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. \r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!\r\n\r\n ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 39414, "title": "Why tf data window not using in tutorials/structured_data/time_series", "body": "Why tf data window not using in [tf tutorial](https://www.tensorflow.org/tutorials/structured_data/time_series)\r\nI am looking for window in timeseries. \r\ntf data only useful if it does not need to generate window data first. But the tutorial is just using batch, shuffle and repeart which does not help on reduce data generate for training.", "comments": ["@jimmy6 \r\n\r\n Do you have any use case that requires the feature you are interested in? Please feel free to submit a PR if you have use cases that supports that feature.Thanks!", "Here is my [Use Case](https://github.com/jimmy6/j6stock-deeplearning/blob/master/Transformer_1D-CNN_Feature_Extraction/xau_usd_OHLC2Tp1Cl100VpConc0_4801Vl.ipynb).  My complicated level is even 2 input\r\n`model.fit([train_X, train_X2], [train_y, train_y],`\r\nI am still struggling to turn it to TF Data in [here](https://github.com/jimmy6/j6stock-deeplearning/blob/master/Transformer_1D-CNN_Feature_Extraction/xau_usd_OHLCTail2Tp1Cl100VpConc0_4801Vl.ipynb)", "@jimmy6 \r\nHere's some of my code that uses window function for you to get started.\r\n```\r\ndef create_data(data: np.ndarray,\r\n                window_size: int,\r\n                batch_size: int,\r\n                shift_size: int,\r\n                stride_size: int) -> tf.data.Dataset:\r\n\r\n    # shape and load the 1D array\r\n    data = tf.data.Dataset.from_tensor_slices(data.reshape(-1, 1))\r\n\r\n    # create moving window\r\n    data = data.window(size=window_size,\r\n                       shift=shift_size,\r\n                       stride=stride_size,\r\n                       drop_remainder=True)\r\n\r\n    # flatten and group the moving window\r\n    data = data.flat_map(lambda window: window.batch(window_size, drop_remainder=True))\r\n\r\n    # create (feature, target).  here, if window size is 5,\r\n    # [0, 1, 2, 3, 4] -> [5]\r\n\r\n    # shape ((None, window_size - 1, 1), (None,))\r\n    data = data.map(lambda window: (window[:-1], tf.reshape(window[-1:], [])))\r\n\r\n    # cache, batch, and repeat the data\r\n    data = data.cache().batch(batch_size).repeat()\r\n\r\n    return data\r\n```\r\nBut I totally agree, the documentation and community support is quite poor for Tensorflow. And the example documentation is done using Jupyter Notebooks", "@leehanchung \r\nThe time series tutorial already score 99. It just missing you part there to get 100 score.", "@lamberta this question is related to a tutorial you worked on, could you please take a look? thank you", "Anyway i found my solution already. \r\n\r\n```\r\ndef make_window_dataset(ds, window_size=seq_len, shift=1, stride=1):\r\n  windows = ds.window(window_size, shift=shift, stride=stride)\r\n\r\n  def sub_to_batch(sub, sub2): \r\n    return tf.data.Dataset.zip(((sub[0].batch(window_size, drop_remainder=True), \r\n                                 sub[1].batch(window_size, drop_remainder=True))\r\n                                , (sub2, sub2)))\r\n  windows = windows.flat_map(sub_to_batch)\r\n  windows = windows.map(lambda sub1, sub2: ((sub1[0], sub1[1][-1:]), sub2))\r\n  return windows\r\n\r\ntrain_dataset = tf.data.Dataset.from_tensor_slices(((df_to_dataset.values, df_to_dataset_tail.values),(df_to_dataset_y)))#.range(int(len(df)/2))\r\ntrain_dataset = make_window_dataset(train_dataset).cache.batch(batch_size, drop_remainder=True).repeat(2) \r\n\r\n```", "For Time series windowing you may also refer [`tf.data Input pipeline guide`](https://www.tensorflow.org/guide/data#time_series_windowing). Thanks!", "@leehanchung I am encountering an error with your code sample and I'm still relatively new to tf.data so I'm not sure how to resolve this error.\r\n\r\nIn the method I am taking a pandas dataframe with multiple features and converting it into tensors, I'm then creating a window of length 5 which works but I encounter an error when I try to flatten the structure, \r\n\r\nWould you know who to resolve this?\r\n\r\n<h2> Method </h2>\r\n\r\n```\r\ndef df_to_dataset(dataframe, batch_size=32):\r\n    labels = dataframe.pop('target')\r\n    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\r\n    \r\n    # create moving window\r\n    ds = ds.window(5)\r\n    \r\n    # flatten and group the moving window\r\n    ds = ds.flat_map(lambda window: window.batch(window_size, drop_remainder=True))\r\n    \r\n    ds = ds.cache().batch(batch_size).repeat()\r\n    \r\n    return ds\r\n```\r\n\r\n<h2> Error Message </h2>\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-107-2853e2b4b940> in <module>\r\n----> 1 train_ts = df_to_dataset(train_df, batch_size=90)\r\n      2 val_ts = df_to_dataset(val_df, batch_size=90)\r\n      3 test_ts = df_to_dataset(test_df, batch_size=90)\r\n\r\n<ipython-input-106-3408a4646092> in df_to_dataset(dataframe, batch_size)\r\n      7 \r\n      8     # flatten and group the moving window\r\n----> 9     ds = ds.flat_map(lambda window: window.batch(window_size, drop_remainder=True))\r\n     10 \r\n     11     ds = ds.cache().batch(batch_size).repeat()\r\n\r\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py in flat_map(self, map_func)\r\n   1955       Dataset: A `Dataset`.\r\n   1956     \"\"\"\r\n-> 1957     return FlatMapDataset(self, map_func)\r\n   1958 \r\n   1959   def interleave(self,\r\n\r\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py in __init__(self, input_dataset, map_func)\r\n   4562     \"\"\"See `Dataset.flat_map()` for details.\"\"\"\r\n   4563     self._input_dataset = input_dataset\r\n-> 4564     self._map_func = StructuredFunctionWrapper(\r\n   4565         map_func, self._transformation_name(), dataset=input_dataset)\r\n   4566     if not isinstance(self._map_func.output_structure, DatasetSpec):\r\n\r\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py in __init__(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\r\n   3710     resource_tracker = tracking.ResourceTracker()\r\n   3711     with tracking.resource_tracker_scope(resource_tracker):\r\n-> 3712       self._function = fn_factory()\r\n   3713       # There is no graph to add in eager mode.\r\n   3714       add_to_graph &= not context.executing_eagerly()\r\n\r\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py in get_concrete_function(self, *args, **kwargs)\r\n   3132          or `tf.Tensor` or `tf.TensorSpec`.\r\n   3133     \"\"\"\r\n-> 3134     graph_function = self._get_concrete_function_garbage_collected(\r\n   3135         *args, **kwargs)\r\n   3136     graph_function._garbage_collector.release()  # pylint: disable=protected-access\r\n\r\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py in _get_concrete_function_garbage_collected(self, *args, **kwargs)\r\n   3098       args, kwargs = None, None\r\n   3099     with self._lock:\r\n-> 3100       graph_function, _ = self._maybe_define_function(args, kwargs)\r\n   3101       seen_names = set()\r\n   3102       captured = object_identity.ObjectIdentitySet(\r\n\r\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py in _maybe_define_function(self, args, kwargs)\r\n   3442 \r\n   3443           self._function_cache.missed.add(call_context_key)\r\n-> 3444           graph_function = self._create_graph_function(args, kwargs)\r\n   3445           self._function_cache.primary[cache_key] = graph_function\r\n   3446 \r\n\r\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   3277     arg_names = base_arg_names + missing_arg_names\r\n   3278     graph_function = ConcreteFunction(\r\n-> 3279         func_graph_module.func_graph_from_py_func(\r\n   3280             self._name,\r\n   3281             self._python_function,\r\n\r\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    997         _, original_func = tf_decorator.unwrap(python_func)\r\n    998 \r\n--> 999       func_outputs = python_func(*func_args, **func_kwargs)\r\n   1000 \r\n   1001       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py in wrapped_fn(*args)\r\n   3685           attributes=defun_kwargs)\r\n   3686       def wrapped_fn(*args):  # pylint: disable=missing-docstring\r\n-> 3687         ret = wrapper_helper(*args)\r\n   3688         ret = structure.to_tensor_list(self._output_structure, ret)\r\n   3689         return [ops.convert_to_tensor(t) for t in ret]\r\n\r\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py in wrapper_helper(*args)\r\n   3615       if not _should_unpack(nested_args):\r\n   3616         nested_args = (nested_args,)\r\n-> 3617       ret = autograph.tf_convert(self._func, ag_ctx)(*nested_args)\r\n   3618       if _should_pack(ret):\r\n   3619         ret = tuple(ret)\r\n\r\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py in wrapper(*args, **kwargs)\r\n    693       except Exception as e:  # pylint:disable=broad-except\r\n    694         if hasattr(e, 'ag_error_metadata'):\r\n--> 695           raise e.ag_error_metadata.to_exception(e)\r\n    696         else:\r\n    697           raise\r\n\r\nTypeError: in user code:\r\n\r\n    TypeError: <lambda>() takes 1 positional argument but 2 were given\r\n```", "` TypeError: <lambda>() takes 1 positional argument but 2 were given`\r\n\r\nThat's talking about this lambda: `lambda window: window.batch(window_size, drop_remainder=True)`\r\n\r\nIt's failing there because each dataset element contains two items, the dict of features, and the labels:  `tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))`\r\n\r\n`.window`creates a sub-dataset for each tensor in the element, not one sub-dataset for the whole element.  See the new version of the [docs for .window](https://www.tensorflow.org/api_docs/python/tf/data/Dataset?version=nightly#nested_elements). You'll want to batch each of those sub-datasets, and return the same \"nest\" striucture.\r\n\r\nBut if you're using the default settings for `shift` and `stride` then `ds.window(N).flat_map(lambda x: x.batch(N))` is eqivalent to `ds.batch(N)`, you may not need window.", "@MarkDaoust thanks for your response. \r\n\r\nUsing batch() works without issues however I am trying to create a moving window for a timeseries dataset so batch wouldn't work for my application.\r\n\r\nAfter I remove the label dict I encounter a different error where after using window() each feature is of type \"_VariantDataset\". Do I need to convert the dataset after window into another type before I pass it to the batch method?\r\n\r\n<h1>Method</h2>\r\n\r\n```\r\ndef df_to_dataset_window(dataframe, batch_size=32):\r\n\r\n    ds = tf.data.Dataset.from_tensor_slices(dict(dataframe))\r\n    \r\n   # create moving window\r\n    ds = ds.window(size=5,\r\n                   shift=1,\r\n                   drop_remainder=True)\r\n    \r\n    # flatten and group the moving window\r\n    ds = ds.flat_map(lambda x: x.batch(5))\r\n        \r\n    return ds\r\n```\r\n\r\n<h1>Output</h2>\r\n\r\n```\r\n--------------------------------------------------------------------------\r\nAttributeError                            Traceback (most recent call last)\r\n<ipython-input-137-1aed37faaa7e> in <module>\r\n----> 1 train_ts = df_to_dataset_window(train_df, batch_size=90)\r\n      2 val_ts = df_to_dataset_window(val_df, batch_size=90)\r\n      3 test_ts = df_to_dataset_window(test_df, batch_size=90)\r\n\r\n<ipython-input-136-bb6500dd07a1> in df_to_dataset_window(dataframe, batch_size)\r\n      9 \r\n     10     # flatten and group the moving window\r\n---> 11     ds = ds.flat_map(lambda x: x.batch(5))\r\n     12 \r\n     13     return ds\r\n\r\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py in flat_map(self, map_func)\r\n   1955       Dataset: A `Dataset`.\r\n   1956     \"\"\"\r\n-> 1957     return FlatMapDataset(self, map_func)\r\n   1958 \r\n   1959   def interleave(self,\r\n\r\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py in __init__(self, input_dataset, map_func)\r\n   4562     \"\"\"See `Dataset.flat_map()` for details.\"\"\"\r\n   4563     self._input_dataset = input_dataset\r\n-> 4564     self._map_func = StructuredFunctionWrapper(\r\n   4565         map_func, self._transformation_name(), dataset=input_dataset)\r\n   4566     if not isinstance(self._map_func.output_structure, DatasetSpec):\r\n\r\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py in __init__(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\r\n   3710     resource_tracker = tracking.ResourceTracker()\r\n   3711     with tracking.resource_tracker_scope(resource_tracker):\r\n-> 3712       self._function = fn_factory()\r\n   3713       # There is no graph to add in eager mode.\r\n   3714       add_to_graph &= not context.executing_eagerly()\r\n\r\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py in get_concrete_function(self, *args, **kwargs)\r\n   3132          or `tf.Tensor` or `tf.TensorSpec`.\r\n   3133     \"\"\"\r\n-> 3134     graph_function = self._get_concrete_function_garbage_collected(\r\n   3135         *args, **kwargs)\r\n   3136     graph_function._garbage_collector.release()  # pylint: disable=protected-access\r\n\r\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py in _get_concrete_function_garbage_collected(self, *args, **kwargs)\r\n   3098       args, kwargs = None, None\r\n   3099     with self._lock:\r\n-> 3100       graph_function, _ = self._maybe_define_function(args, kwargs)\r\n   3101       seen_names = set()\r\n   3102       captured = object_identity.ObjectIdentitySet(\r\n\r\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py in _maybe_define_function(self, args, kwargs)\r\n   3442 \r\n   3443           self._function_cache.missed.add(call_context_key)\r\n-> 3444           graph_function = self._create_graph_function(args, kwargs)\r\n   3445           self._function_cache.primary[cache_key] = graph_function\r\n   3446 \r\n\r\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   3277     arg_names = base_arg_names + missing_arg_names\r\n   3278     graph_function = ConcreteFunction(\r\n-> 3279         func_graph_module.func_graph_from_py_func(\r\n   3280             self._name,\r\n   3281             self._python_function,\r\n\r\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\framework\\func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    997         _, original_func = tf_decorator.unwrap(python_func)\r\n    998 \r\n--> 999       func_outputs = python_func(*func_args, **func_kwargs)\r\n   1000 \r\n   1001       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py in wrapped_fn(*args)\r\n   3685           attributes=defun_kwargs)\r\n   3686       def wrapped_fn(*args):  # pylint: disable=missing-docstring\r\n-> 3687         ret = wrapper_helper(*args)\r\n   3688         ret = structure.to_tensor_list(self._output_structure, ret)\r\n   3689         return [ops.convert_to_tensor(t) for t in ret]\r\n\r\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py in wrapper_helper(*args)\r\n   3615       if not _should_unpack(nested_args):\r\n   3616         nested_args = (nested_args,)\r\n-> 3617       ret = autograph.tf_convert(self._func, ag_ctx)(*nested_args)\r\n   3618       if _should_pack(ret):\r\n   3619         ret = tuple(ret)\r\n\r\n~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py in wrapper(*args, **kwargs)\r\n    693       except Exception as e:  # pylint:disable=broad-except\r\n    694         if hasattr(e, 'ag_error_metadata'):\r\n--> 695           raise e.ag_error_metadata.to_exception(e)\r\n    696         else:\r\n    697           raise\r\n\r\nAttributeError: in user code:\r\n\r\n    <ipython-input-124-bb6500dd07a1>:11 None  *\r\n        lambda x: x.batch(5)\r\n\r\n    AttributeError: 'dict' object has no attribute 'batch'\r\n```\r\n\r\n<h2> Object</h2>\r\nThis is the resulting object after the above window method using a for loop to iterate over the records.\r\n\r\n```\r\n{'timestamp': <_VariantDataset shapes: (), types: tf.float64>, 'feature1': <_VariantDataset shapes: (), types: tf.float64>, OTHER FEATURES...\r\n```", "Please re-read my previous comment:\r\n\r\n>It's failing there because each dataset element contains two items, the dict of features, and the labels: `tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))`\r\n\r\n> `.window` creates a sub-dataset for each tensor in the element, not one sub-dataset for the whole element. See the new version of the docs for .window. You'll want to batch each of those sub-datasets, and return the same \"nest\" structure.\r\n\r\nOr in the updated docs see the section called on nested elements:  https://www.tensorflow.org/api_docs/python/tf/data/Dataset?version=nightly#nested_elements\r\n\r\nYour dataset contains dictionaries of windows (the VariantDatasets). A dictionary doesn't have a `.batch` method.  you want:\r\n\r\n`lambda xs: {key: window.batch(N) for key, window in xs}`", "I don't understand what is going on with this object. In the documentation they show that after window we can use batch as taken from the documentation. Why is it working with the example in the document and not in my example. Does it have something to do with how I imported the data from the pandas dataframe that is causing this issue?\r\n\r\n```\r\nsize = 3\r\ndataset = tf.data.Dataset.range(7).window(size, shift=1,\r\n                                          drop_remainder=True)\r\nbatched = dataset.flat_map(lambda x:x.batch(3))\r\nfor batch in batched:\r\n  print(batch.numpy())\r\n```", "> Does it have something to do with how I imported the data from the pandas dataframe that is causing this issue\r\n\r\nYes. This gives you a dataset of `{str: Tensor}` dictionaries:\r\n\r\n```\r\nds = tf.data.Dataset.from_tensor_slices(dict(dataframe))\r\n```\r\n\r\nThis gives you a dataset of (scalar) tensors:\r\n\r\n```\r\ntf.data.Dataset.range(7)\r\n```\r\n\r\n`.window` replaces each tensor with a dataset. You can only call `.batch` on a dataset.\r\n\r\n", "@MarkDaoust that makes more sense thanks for the clarification, I was able to resolve the issue by referencing the issue linked below :)\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/43703#issue-712836365\r\n\r\n<h2> Working code </h2>\r\n\r\n```\r\ndef flatten(x):\r\n    result = {}\r\n    for key in x.keys():\r\n        result[key] = tf.data.experimental.get_single_element(x[key].batch(5))\r\n    return result\r\n\r\ndef df_to_dataset_window(dataframe, batch_size=32):\r\n    ds = tf.data.Dataset.from_tensor_slices(dict(dataframe))\r\n    \r\n   # create moving window\r\n    ds = ds.window(size=5,\r\n                   shift=1,\r\n                   drop_remainder=True)\r\n    \r\n    ds = ds.map(lambda x: flatten(x))\r\n    \r\n    return ds\r\n\r\ntrain_ts = df_to_dataset_window(train_df)\r\n```"]}, {"number": 39413, "title": "Model.fit() process grabs generators that were not passed to it. ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS, Catalina\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:NA\r\n- TensorFlow installed from (source or binary): Source\r\n- TensorFlow version (use command below): 2.2.0-dev20200508\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: release 10.0, V10.0.130\r\n- GPU model and memory: Titan RTX 24 GB\r\n\r\n**Describe the current behavior**\r\nModel.fit(generator_train) grabs generator_test information that was NEVER passed to it. \r\n\r\n**Describe the expected behavior**\r\nModel.fit(generator_train) only works on generator_train information \r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nclass GeneratorFile(tf.keras.utils.Sequence):\r\n    def __init__(self, file_list):\r\n        self.file_list = file_list\r\n        self.desired_file = self.file_list[0]\r\n        print('This should be file 1:', self.desired_file)\r\n    def __len__(self):\r\n        return 2\r\n    def on_epoch_end(self):\r\n        self.desired_file = self.file_list[1]\r\n        print('This should be file 2:', self.desired_file)\r\n    def __getitem__(self, item):\r\n        return np.zeros((16, 1)), np.zeros((16,))\r\n\r\nmodel = tf.keras.Sequential()\r\nmodel.add(tf.keras.layers.Dense(1, input_dim=1, activation=\"softmax\"))\r\nmodel.compile(\r\n    optimizer='Adam',\r\n    loss='binary_crossentropy',\r\n    metrics=['accuracy']\r\n)\r\n\r\nmodel_file_train = ['file1', 'file2']\r\nmodel_file_test = ['file3']\r\ngenerator_train = GeneratorFile(model_file_train)\r\ngenerator_test = GeneratorFile(model_file_test) #THIS IS NEVER PASSED IN\r\nmodel.fit(generator_train, epochs=2, initial_epoch = 0)\r\n\r\n```\r\n\r\nThe output of the above code snippet: \r\n\r\n```\r\nThis should be file 1: file1\r\nThis should be file 1: file3\r\nEpoch 1/2\r\n2/2 [==============================] - 0s 1ms/step - loss: 15.2492 - accuracy: 0.0000e+00\r\nThis should be file 2: file2\r\nEpoch 2/2\r\n2/2 [==============================] - 0s 1ms/step - loss: 15.2492 - accuracy: 0.0000e+00\r\nThis should be file 2: file2\r\n```\r\n\r\n`file3` was NEVER passed to model.fit(), so how would the generator even be aware of that file? Granted, I'm not even sure if this is a Tensorflow issue, could just be I'm misunderstanding exactly how Model.fit() is supposed to work, but this is extremely unintuitive behavior. \r\n\r\nAs a side note, if I comment out the line that defines `generator_test`, file3 never appears. ", "comments": ["Line:\r\n`        print('This should be file 1:', self.desired_file)\r\n`\r\nbelongs to the class initializer.  Everything that is in the `__init__` method automatically runs when you create an object of this class:\r\n`generator_test = GeneratorFile(model_file_test) #THIS IS NEVER PASSED IN`\r\nTherefore, you see this line on the log screen.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39413\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39413\">No</a>\n"]}, {"number": 39412, "title": "add bias to transpose_conv.py TESTs.", "body": "minor update that add bias to transpose_conv.py in op_tests.", "comments": ["@psunn Can you please address Ubuntu Sanity errors? Thanks!", "@gbaned thanks for checking\r\ndone, please have a review.", "@jdduke @suharshs \r\nI update this PR to fix minor sanity error, can you please re-approve please? Thanks"]}, {"number": 39411, "title": "Categorical CrossEntropy returning wrong values", "body": "tf.losses.CategoricalCrossentropy is returning values different from those of numpy\r\n\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ny_pred = np.array([7.3216137e-07, 3.3240074e-11, 4.4985552e-12,\r\n                   3.9974657e-05, 7.3216137e-07, 4.4985552e-12, \r\n                   4.4985552e-12, 2.9537498e-04, 8.8050038e-01,\r\n                   1.1916277e-01])\r\ny_true = np.zeros(10)\r\ny_true[5] = 1\r\ncce = tf.losses.CategoricalCrossentropy()\r\n\r\n\r\nprint(f\"NUMPY {-1*np.sum(y_true*np.log(y_pred))}\")\r\nprint(f\"TF {cce(y_true, y_pred)}\")\r\n```\r\n\r\n**System information**\r\n- Have I written custom code: NO\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab\r\n- TensorFlow installed from (source or binary): Default of Colab\r\n- TensorFlow version (use command below): 2.2.0-rc4\r\n- Python version: 3.6.9\r\n\r\n**Describe the current behavior**\r\n\r\n```\r\nNUMPY 26.12726483737188\r\nTF 16.11809539794922\r\n```\r\n\r\n**Describe the expected behavior**\r\n```\r\nNUMPY 26.12726483737188\r\nTF 26.12726483737188\r\n```\r\n\r\n**Standalone code to reproduce the issue**\r\nColab Link: https://colab.research.google.com/drive/1gKb0eiKfIw4GKZo_lzDTaswWFz7gsAU0?usp=sharing\r\n", "comments": ["I am able to replicate the issue reported, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/5214d720aa6019d3919d723ee5e660f7/untitled174.ipynb). Thanks!", "@renan-cunha Can you try with 2D inputs? https://www.tensorflow.org/api_docs/python/tf/keras/losses/CategoricalCrossentropy?version=nightly#__call__", "Hi, by using 2d inputs the output stays the same\r\n\r\n\r\n```import numpy as np\r\nimport tensorflow as tf\r\n\r\ny_pred = np.array([[7.3216137e-07, 3.3240074e-11, 4.4985552e-12,\r\n                   3.9974657e-05, 7.3216137e-07, 4.4985552e-12, \r\n                   4.4985552e-12, 2.9537498e-04, 8.8050038e-01,\r\n                   1.1916277e-01]])\r\ny_true = np.zeros(10).reshape(1, 10)\r\ny_true[0, 5] = 1\r\ncce = tf.losses.CategoricalCrossentropy()\r\n\r\nprint(f\"NUMPY {-1*np.sum(y_true*np.log(y_pred))}\")\r\nprint(f\"TF {cce(y_true, y_pred)}\")\r\n```\r\n\r\nLink to reproduce: https://colab.research.google.com/drive/1gKb0eiKfIw4GKZo_lzDTaswWFz7gsAU0?usp=sharing", "Hi, it seems the `reduction` argument is involved in this, using the above [script](https://github.com/tensorflow/tensorflow/issues/39411#issuecomment-629799292) with different `reduction` values yield the following results:\r\n```python\r\n# tf version: v2.3.0\r\ncce = tf.losses.CategoricalCrossentropy(reduction=tf.keras.losses.Reduction.AUTO)  # wrong, 1.1769444942474365\r\ncce = tf.losses.CategoricalCrossentropy(reduction=tf.keras.losses.Reduction.SUM_OVER_BATCH_SIZE)  # wrong, 1.1769444942474365\r\ncce = tf.losses.CategoricalCrossentropy(reduction=tf.keras.losses.Reduction.SUM)  # correct, 2.353888988494873\r\n```", "I have tried in colab with TF nightly version (`2.5.0-dev20201029`) and was able to reproduce the issue. Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/385c58c24fde2f917497cb19543da06e/untitled99.ipynb?authuser=1).Thanks!", "I have tried in colab with TF nightly version (2.6.0-dev20210415) and was able to reproduce the issue. Please, find the [gist here](https://colab.research.google.com/gist/Saduf2019/426febbf26350372206d0a84b1a977c1/untitled590.ipynb).Thanks!", "Hi There,\n\n This is a stale issue. As you are using an older version of tensorflow, we are checking to see if you still need help on this issue. Please test the issue with the latest TensorFlow (TF2.7 and tf-nightly). If the issue still persists with the newer versions of TF, please feel free to open it in [keras-team/keras](https://github.com/keras-team/keras/issues) repository by providing details about the issue and a standalone code to reproduce the issue. Thanks! \n\n Please note that Keras development has moved to a separate Keras-team/keras repository to focus entirely on only Keras. Thanks! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39411\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39411\">No</a>\n"]}, {"number": 39410, "title": "Training a model for my own dataset using tensorflow speech commands ", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution : Google Colab \r\n- TensorFlow version: Tensorflow-gpu 1.14.0\r\n- Python version: 3.6\r\n- Installed using virtualenv? pip? conda?: pip \r\n- Bazel version (if compiling from source): \r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: Updated Google colab's CUDA and cuDNN\r\n- GPU model and memory: Inbuilt Colab-pro GPU \r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nDear Authors, \r\n\r\nI am trying to train the speech recognition model for small vocabulary from the following link : https://github.com/tensorflow/tensorflow/tree/r1.9/tensorflow/examples/speech_commands\r\n\r\nI am trying to run the following command:\r\n\r\n!python tensorflow/examples/speech_commands/train.py --data_url= --clip_duration_ms=5000 --train_dir= /content/drive/My Drive/wuw-checkpoint --data_dir= /content/drive/My Drive/wake-up-word/ --wanted_words = up, down\r\n\r\nI cloned into the default master file to run the same. I am getting the following error, can you please help me out in giving the right tf, CUDA and cuDNN versions that I could use to run the same?  Here's the following error I got\r\n\r\nTraceback (most recent call last):\r\n  File \"tensorflow/examples/speech_commands/train.py\", line 452, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"tensorflow/examples/speech_commands/train.py\", line 201, in main\r\n    f.write('\\n'.join(audio_processor.words_list))\r\nAttributeError: 'AudioProcessor' object has no attribute 'words_list'\r\nThank you, I look forward to hearing from you \r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@krishnabairavi95 Can you try build against the master branch? ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 39409, "title": "upgraded from 2.1 to 2.2 raised 'Unexpectedly high number of iterations in HLO passes, exiting fixed point loop'", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Gentoo\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.2.0-rc2\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source): 2.0\r\n- GCC/Compiler version (if compiling from source): 8.4\r\n- CUDA/cuDNN version: 10.2/7.6\r\n- GPU model and memory: \r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nI'm using Gentoo linux and tf is installed by Gentoo's package management system(portage/emerge). After upgrading tf from 2.1.0 to 2.2.0-rc2, a new warning raised training on a same model:\r\n`W ./tensorflow/compiler/xla/service/hlo_pass_fix.h:49] Unexpectedly high number of iterations in HLO passes, exiting fixed point loop.`\r\nThis warning might not affect training speed, but takes more GPU memory. The model with same setting works well in tf 2.1 but throws OOM in tf 2.2. It's unclear to me what this warning means and not helpful to find the problem. \r\n\r\n**Describe the expected behavior**\r\nshould not occupy more memory\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@naturomics.\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39409\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39409\">No</a>\n"]}, {"number": 39408, "title": "About loading of saved_model format in tf2", "body": "There are too many versions of tf. Before, I used a function to load the saved_model format model.\r\n\r\n`new_model = tf.contrib.saved_model.load_keras_model(saved_model_path) new_model.summary()`\r\n\r\nBut if folder \u201cassets\u201d does not exist, an error will occur,and this file is not available for every model.\r\n\r\nSo which function should I use to load\uff1f\r\n\r\nThank you !!", "comments": ["@wangwenchao-job \r\nCould you please let us know which version of tf are you using and please share a simple stand alone code so we could replicate the issue faced by you..Thanks!", "> @wangwenchao-job\r\n> Could you please let us know which version of tf are you using and please share a simple stand alone code so we could replicate the issue faced by you..Thanks!\r\n\r\nThank you very much for your reply\uff01\uff01\r\n\r\nMy code execution environment is:\r\nWindows = 10\r\ntf = 1.14\r\n\r\n\r\nfrom tensorflow.keras.applications import *\r\nfrom tensorflow.keras.models import Model\r\nimport tensorflow as tf\r\nkeras = tf.keras\r\nmodel_dir = './saved_model/'\r\nreload_model = tf.keras.experimental.load_from_saved_model(model_dir)\r\nreload_model.summary()\r\nreload_model.save('./det_model.h5')\r\n\r\n\r\nAs above is my code, I also tried other functions:\r\n\r\ntf.compat.v1.keras.experimental.load_from_saved_model\r\ntf.compat.v2.keras.experimental.load_from_saved_model\r\ntf.contrib.saved_model.load_keras_model\r\n\r\nBut none of these methods succeeded\uff01\r\n", "> @wangwenchao-job\r\n> Could you please let us know which version of tf are you using and please share a simple stand alone code so we could replicate the issue faced by you..Thanks!\r\n\r\nMore information\uff1a\r\nMy saved_model only has .pb and adjustables, no assets.\r\n\r\nWhen there is an assets file before, it can be imported using function \uff1a\r\ntf.contrib.saved_model.load_keras_model\r\n\r\nBut now I get an error:\r\nPython unhandled win32 exception...\r\n\r\nAnd automatically open vs for me to debug.\r\n\r\nIf you need a model, I can email it to you. Due to network problems, I cannot share files here, sorry.", "@wangwenchao-job\r\nYes, please email the model.", "> @wangwenchao-job\r\n> Yes, please email the model.\r\n\r\nThe model has been sent to you at the address:\r\nnotifications@github.com\r\nOr this download link\uff1a\r\nhttps://www.jianguoyun.com/p/DRuhIW8QtKK2CBjB95cD\r\n\r\nI don't know if you can access", "@wangwenchao-job\r\nyou can email it as saduf@google.com", "> @wangwenchao-job\r\n> you can email it as [saduf@google.com](mailto:saduf@google.com)\r\n\r\n@Saduf2019 \r\nThe model has been sent to you to the above email address.", "> > @wangwenchao-job\r\n> > you can email it as [saduf@google.com](mailto:saduf@google.com)\r\n> \r\n> @Saduf2019\r\n> The model has been sent to you to the above email address.\r\n\r\nupdate\r\n----\r\nIn addition, I use the following method to load the savedmodel and export pb, and my ultimate goal is to convert the savedmodel format model into a pb format file (frozen_graph)\r\n\r\n```\r\nimport tensorflow as tf\r\nprint(tf.__version__)\r\n\r\nfrom tensorflow.python.framework.convert_to_constants import convert_variables_to_constants_v2\r\n\r\nloaded = tf.saved_model.load('saved_model')\r\ninfer = loaded.signatures['serving_default']\r\n\r\nf = tf.function(infer).get_concrete_function(inputs=tf.TensorSpec(shape=[None, 28, 28, 3], dtype=tf.float32))\r\nf2 = convert_variables_to_constants_v2(f)\r\ngraph_def = f2.graph.as_graph_def()\r\n\r\nfor node in graph_def.node:\r\n   print(node.op, node.name)\r\n\r\nwith tf.io.gfile.GFile('frozen_graph.pb', 'wb') as f:\r\n   f.write(graph_def.SerializeToString())\r\n```\r\n\r\n\r\nBut the obtained pb model is only 1k in size, so this conversion method should be problematic.", "@ Saduf2019\r\nHi\uff0c\r\nDo you have received my email, do you have any suggestions\uff1f\r\n\r\nthank you very much\uff01", "@wangwenchao-job\r\nno i have not received, can you please share a colab gist with the issue for us to analyse the issue faced.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 39407, "title": "tensorflow.lib missing some symbols on linking in a application", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (Woindows 10):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (r2.1):\r\n- TensorFlow version:\r\n- Python version:3.7\r\n- Installed using virtualenv? pip? conda?:venv\r\n- Bazel version (if compiling from source):0.29.1\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:10.1, 7.6\r\n- GPU model and memory: GTX1080\r\n\r\n\r\n**Describe the problem**\r\n\r\nI want use to tensotflow in windows 10. I have built r2.1 from source finally.\r\nAnother problem stop me again, there are some missing symbols on linking tensorflow.lib in my application.\r\n\r\nSeverity\tCode\tDescription\tProject\tFile\tLine\tSuppression State\r\nError\tLNK2019\tunresolved external symbol \"class tensorflow::Session * __cdecl tensorflow::NewSession(struct tensorflow::SessionOptions const &)\" (?NewSession@tensorflow@@YAPEAVSession@1@AEBUSessionOptions@1@@Z) \r\n\r\nIt works in Linux. The same application does not work in windows.\r\n\r\nPlease help.\r\nThanks.\r\n\r\n\r\n", "comments": ["@heyufei2008 \r\n\r\nJust to verify did you follow the instructions mentioned in [Tensorflow website.](https://www.tensorflow.org/install/source_windows) .You can check your cpu is avx2 instruction sets supported or not.Also, go through [link](https://github.com/tensorflow/tensorflow/issues/30647) and see if it helps you.Thanks!", "Yes\uff0c I followed the instructions from the website.\nThe link you provided is for 1.14 mostly.\n\nCan you tell what I should do for r2.1?\n\nThanks.\nJohn\n\nOn Mon, May 11, 2020 at 9:30 AM ravikyram <notifications@github.com> wrote:\n\n> @heyufei2008 <https://github.com/heyufei2008>\n>\n> Just to verify did you follow the instructions mentioned in Tensorflow\n> website. <https://www.tensorflow.org/install/source_windows> .You can\n> check your cpu is avx2 instruction sets supported or not.Also, go through\n> link <https://github.com/tensorflow/tensorflow/issues/30647> and see if\n> it helps you.Thanks!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/39407#issuecomment-626702970>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AL7BCAZLMPHL6ZMXJVIZDY3RQ74Y5ANCNFSM4M53PRVQ>\n> .\n>\n", "Can you try this hack https://github.com/tensorflow/tensorflow/issues/34159#issuecomment-565805682 ?", "Hi Yasir\r\nI will try your answer. Thanks.\r\n", "I get the same issue, it works ok in ubuntu18.04, but can't run in windows10.  ", "Thanks for https://github.com/conradjones/tensorflow/commit/ffdbaa25411340cf49b2eba8e180733340af61cd\r\nI solve the problem with:\r\nadd \r\n#include \"tensorflow/core/platform/macros.h\" \r\nadd TF_EXPORT:\r\n**TF_EXPORT** Status Reset(const SessionOptions& options,\r\n             const std::vector<string>& containers);\r\n**TF_EXPORT** Session*  NewSession(const SessionOptions& options);\r\n", "Thanks\r\n", "Can we close this issue if it solved your problem? Thanks!", "TF2.0 & windows10 & VS2019 & /arch:AVX2\r\nI am sorry, I don not think we can close the issue. Although I compile the .dll and .lib success, and have linked them without any error, but when I run the program which I just build, it crashed.\r\nAnybody get the similar issue like this?... \r\n\r\n```\r\n        tensorflow::SessionOptions session_options;\r\n        tensorflow::RunOptions run_options;\r\n        tensorflow::SavedModelBundle bundle;\r\n        tensorflow::Status status;\r\n        constexpr char kSavedModelTagServe[] = \"serve\";\r\n\r\n        status = tensorflow::LoadSavedModel(session_options, run_options, model_path, { kSavedModelTagServe }, &bundle);\r\n```\r\n\r\nI got a exception:\r\nUnhandled exception at 0x00007FFC5DE93E49 in TensorflowTest.exe: Microsoft C++ exception: std::length_error at memory location 0x0000009852D5DF20.\r\n\r\n\r\n", "No, can  not close it yet.", "Hi Yasir\r\nI think this is in a dangerous direction by adding TF_EXPORT to some functions.\r\nWhat's your official solution to fix this issue completely?\r\nThanks\r\n\r\nJohn", "I still have 2 unresolved external symbols:\r\n\r\nunresolved external symbol \"public: __cdecl tensorflow::ops::Placeholder::Placeholder(class tensorflow::Scope const &,enum\r\n\r\nunresolved external symbol \"public: __cdecl tensorflow::ops::Cast::Cast(class tensorflow::Scope const &,class tensorflow::Input,enum tensorflow::DataType\r\n\r\nWhere can I find the 2 functions ?\r\n\r\n", "@ymodak Hi Yasir \r\nCan you give me more help on this issue? I need tensorflow in windows. it's super urgent\r\nJohn", "I have same issue:\r\n- TensorFlow (v2.2) compiled using VS2019 and Bazel\r\n\r\nBuild with command:\r\n`bazel build --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/lib_package:libtensorflow`\r\n\r\nOutput is then located on\r\n- DLL => {PROEJCT_DIR}\\tensorflow\\bazel-bin\\tensorflow\\tensorflow.dll\r\n- LIB =>{PROEJCT_DIR}\\tensorflow\\bazel-bin\\tensorflow\\libtensorflow.dll.ifso (renamed in project to tensorflow.lib)\r\n\r\nIt can link some symbols like:\r\n`tensorflow::port::InitMain(argv[0], &argc, &argv);`\r\nBut can't link \r\n`tensorflow::NewSession(tensorflow::SessionOptions())`\r\n\r\nFound this if it helps to debug:\r\nhttps://stackoverflow.com/questions/58176287/cannot-link-c-using-tensorflow-c-api-tensorflow-cc-lib-on-windows-10-visual\r\n\r\n", "@ymodak we really need a good fix for this from Google.", "Any ETA on potential fix ?\r\n", "I found some instruction how to make it work on Windows \r\nhttps://github.com/sitting-duck/stuff/tree/master/ai/tensorflow/build_tensorflow_1.14_source_for_Windows\r\n\r\nProblem is .dll is limited to 64k exported symbols.\r\nAs suggested by comment above is to use TF_EXPORT.\r\nOther solution could be to exclude more non essential symbols in \r\n`tensorflow\\tools\\def_file_filter\\def_file_filter.py.tpl`", "I need 2.0, my code in linux is based on 2.0", "Adding TF_EXPORT manually is risky. ", "@heyufei2008 how so ?\r\nI made it work", "@jgasperlin \r\nCan you tell me how you made it work?\r\nThanks.\r\n", "@heyufei2008  \r\nJust [follow](https://github.com/sitting-duck/stuff/tree/master/ai/tensorflow/build_tensorflow_1.14_source_for_Windows) and add necessary TF_EXPORT\r\ni rebuild both dll and lib and used \r\n`bazel build --config=opt --config=cuda --define=no_tensorflow_py_deps=true //tensorflow/tools/lib_package:libtensorflow`\r\nAnd then checked they both exported `NewSession` and `SessionOptions`\r\n`dumbbin /EXPORTS tensorflow.dll > dll-export.txt`\r\n>23630 5C4D 06CCB8E0 ?NewSession@tensorflow@@YA?AVStatus@1@AEBUSessionOptions@1@PEAPEAVSession@1@@Z = ?NewSession@tensorflow@@YA?AVStatus@1@AEBUSessionOptions@1@PEAPEAVSession@1@@Z (class tensorflow::Status __cdecl tensorflow::NewSession(struct tensorflow::SessionOptions const &,class tensorflow::Session * *))\r\n\r\n`dumbbin /EXPORTS tensorflow.lib > lib-export.txt`\r\n>?NewSession@tensorflow@@YA?AVStatus@1@AEBUSessionOptions@1@PEAPEAVSession@1@@Z (class tensorflow::Status __cdecl tensorflow::NewSession(struct tensorflow::SessionOptions const &,class tensorflow::Session * *))\r\n\r\n\r\n", "@jgasperlin \r\nI did the same TF_EXPORT for NewSession and SessionOptions.\r\n\r\nI still have 2 unresolved external symbols:\r\n\r\nunresolved external symbol \"public: __cdecl tensorflow::ops::Placeholder::Placeholder(class tensorflow::Scope const &,enum\r\n\r\nunresolved external symbol \"public: __cdecl tensorflow::ops::Cast::Cast(class tensorflow::Scope const &,class tensorflow::Input,enum tensorflow::DataType\r\n\r\nI don't know where they are.\r\n\r\n\r\n", "@heyufei2008 most IDS if you click + ctrl on class it show you file that contains it or follow your includes or use docs https://www.tensorflow.org/api_docs/cc/class/tensorflow/ops/placeholder.\r\n=> tensorflow\\cc\\ops\\array_ops.h\r\n", "Although I compile the .dll and .lib success with the TF_EXPORT declaration, and have linked them without any error, but when I run the program which I just build, it crashed. Can you test it whether this method can work ok?\r\nThanks a lot.", "@richaolas \r\nhttps://github.com/tensorflow/tensorflow/issues/17778", "Hi Gens\r\nI use the Cast class like this:\r\nauto uint8Caster = Cast(root.WithOpName(\"uint8_Cast\"), outTensor, tensorflow::DT_UINT8);\r\n\r\nBut Cast class is defined in math_ops.h, which is \"// This file is MACHINE GENERATED! Do not edit.\"\r\n\r\nHow to add TF_EXPORT to class Cast ?\r\n\r\nThanks\r\n\r\n", "TF_EXPORT can not solve this issue clearly, manual adding is painful and also could miss some other symbols. Bazel script for link needs to solve it.", "@jeffhwang02 Yes. it's still not fixed for me.\r\nDo you know how to change Bazel script for this issue?\r\n\r\nThanks.\r\n\r\n", "> @jeffhwang02 Yes. it's still not fixed for me.\r\n> Do you know how to change Bazel script for this issue?\r\n> \r\n> Thanks.\r\n\r\nI have managed to make a tensorflow.dll which has no symbol error by using link again with some exported symbols def file.\r\nBut when it runs with my code, it still shows some another running time error.\r\nSo it still has not been solved clearly.", "> > @jeffhwang02 Yes. it's still not fixed for me.\r\n> > Do you know how to change Bazel script for this issue?\r\n> > Thanks.\r\n> \r\n> I have managed to make a tensorflow.dll which has no symbol error by using link again with some exported symbols def file.\r\n> But when it runs with my code, it still shows some another running time error.\r\n> So it still has not been solved clearly.\r\n\r\nhi @jeffhwang02 \r\nDo you think you could please elaborate what exactly did you do to fix the issue with unresolved exported symbols? As you pointed out, manually adding `TF_EXPORT` is a bit tedious, but at least it's a viable workaround. Unfortunately, it does not appear to be working for certain symbols residing in machine-generated files, as mentioned here https://github.com/tensorflow/tensorflow/issues/35178, simply because rebuilding the `*.lib` file will regenerate the said files, removing any introduced modifications. An example of such symbol is `GraphDef` in `graph.pb.h`, which has the following statement at the top:\r\n```\r\n// Generated by the protocol buffer compiler.  DO NOT EDIT!\r\n// source: tensorflow/core/framework/graph.proto\r\n```", "I solved the problem by using tf_exported_symbols_msvc.ids file in TF1.13 version.\r\nBut newer tf1.15 does not work by the same method.\r\nAnyway I am using the TF1.13 DLL in Windows10 which could be enough currently.\r\nI hope some one could find more root solution for every version sooner or late.", "@springile We are checking to see if you still need help on this issue. We recommend that you upgrade to 2.6 which is latest stable version of TF and let us know if the issue still persists in newer versions. please check [**`link1`**](https://github.com/tensorflow/tensorflow/issues/35178) , [**`link2`**](https://stackoverflow.com/questions/62954634/tensorflow-2-3-unresolved-external-symbols-in-machine-generated-files-when-build) Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39407\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39407\">No</a>\n"]}, {"number": 39406, "title": "Can't run tensorflow in PyCharm/ Jupyter", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip and interpreter settings\r\n- TensorFlow version: 2.2.0\r\n- Python version: 3.7.7\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): \r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: -\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nInstalled tensorflow via \"Interpreter Settings\" of PyCharm. Now I tried to import \"import tensorflow\" but will not works.\r\n\r\n\r\n**Any other info / logs**\r\nPip freeze:\r\n```\r\ntensorboard==2.2.1\r\ntensorboard-plugin-wit==1.6.0.post3\r\ntensorflow==2.2.0\r\ntensorflow-cpu==2.2.0\r\ntensorflow-estimator==2.2.0\r\ntensorflow-gpu-estimator==2.2.0\r\n```\r\n\r\nError_log:\r\n```\r\n---------------------------------------------------------------------------\r\n\r\nImportError                               Traceback (most recent call last)\r\n\r\nd:\\tuc\\gitlab\\dmc_bh8\\louis_jupyter\\venv\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     57 \r\n---> 58   from tensorflow.python.pywrap_tensorflow_internal import *\r\n     59 \r\n\r\nd:\\tuc\\gitlab\\dmc_bh8\\louis_jupyter\\venv\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in <module>\r\n     27             return _mod\r\n---> 28     _pywrap_tensorflow_internal = swig_import_helper()\r\n     29     del swig_import_helper\r\n\r\nd:\\tuc\\gitlab\\dmc_bh8\\louis_jupyter\\venv\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py in swig_import_helper()\r\n     23             try:\r\n---> 24                 _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n     25             finally:\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py in load_module(name, file, filename, details)\r\n    241         else:\r\n--> 242             return load_dynamic(name, filename, file)\r\n    243     elif type_ == PKG_DIRECTORY:\r\n\r\n~\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py in load_dynamic(name, path, file)\r\n    341             name=name, loader=loader, origin=path)\r\n--> 342         return _load(spec)\r\n    343 \r\n\r\nImportError: DLL load failed: Das angegebene Modul wurde nicht gefunden.\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nImportError                               Traceback (most recent call last)\r\n\r\n<ipython-input-4-f9575c251aea> in <module>\r\n----> 1 import tensorflow\r\n      2 \r\n      3 \r\n\r\nd:\\tuc\\gitlab\\dmc_bh8\\louis_jupyter\\venv\\lib\\site-packages\\tensorflow\\__init__.py in <module>\r\n     39 import sys as _sys\r\n     40 \r\n---> 41 from tensorflow.python.tools import module_util as _module_util\r\n     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader\r\n     43 \r\n\r\nd:\\tuc\\gitlab\\dmc_bh8\\louis_jupyter\\venv\\lib\\site-packages\\tensorflow\\python\\__init__.py in <module>\r\n     48 import numpy as np\r\n     49 \r\n---> 50 from tensorflow.python import pywrap_tensorflow\r\n     51 \r\n     52 # Protocol buffers\r\n\r\nd:\\tuc\\gitlab\\dmc_bh8\\louis_jupyter\\venv\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     67 for some common reasons and solutions.  Include the entire stack trace\r\n     68 above this error message when asking for help.\"\"\" % traceback.format_exc()\r\n---> 69   raise ImportError(msg)\r\n     70 \r\n     71 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"d:\\tuc\\gitlab\\dmc_bh8\\louis_jupyter\\venv\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"d:\\tuc\\gitlab\\dmc_bh8\\louis_jupyter\\venv\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"d:\\tuc\\gitlab\\dmc_bh8\\louis_jupyter\\venv\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\...\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\...\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: Das angegebene Modul wurde nicht gefunden.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\n```\r\n", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\n\n* For TF-GPU - See point 1\n* For TF-CPU - See point 2\n\n-----------------------------------------------------------------------------------------------\n\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\n\n*TF Version >= 1.13 requires CUDA 10.0 and TF Version < 1.13 (till TF 1.5) requires CUDA 9.0.*\n\n* If you have above configuration and using _**Windows**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\n  * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\n* If you have above configuration and using _**Ubuntu/Linux**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\n  * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\n* If error still persists then, apparently your CPU model does not support AVX instruction sets.\n  * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\n\n-----------------------------------------------------------------------------------------------\n\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\n\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\n\n Therefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\n\n* Try Google Colab to use TensorFlow.\n  * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true).You get pre-installed latest stable TF version. Also you can use```pip install``` to install any other preferred TF version.\n  * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\n  * All you need is a good internet connection and you are all set.\n* Try to build TF from sources by changing CPU optimization flags.\n\n*Please let us know if this helps.*", "@KreLou,\r\nPlease take a look at [this comment](https://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156) from a similar issue and let us know if it helps. Thanks!", "Closing as duplicate.\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156\r\n\r\nJust to sample over 100 similar issues: #36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204\r\n\r\nPlease make sure you do a search in the future.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39406\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39406\">No</a>\n"]}, {"number": 39405, "title": "Unsigned int (tf.uint{32,64}) support for tf.{tile,repeat}", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): `macOS Catalina 10.15.2 (19C57)`\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): `2.2.0`\r\n- Python version: `3.7.5`\r\n\r\n**Describe the feature and the current behavior/state.**\r\nFeature: `tf.tile` and `tf.repeat` do not fail when input is of dtype `tf.uint{32,64}`.\r\nCurrent behavior: `tf.tile` and `tf.repeat` fail when input is of dtype `tf.uint{32,64}`.\r\n\r\n**Will this change the current api? How?**\r\nWould add new supported input type to `tf.tile` and `tf.repeat`.\r\n\r\n**Who will benefit with this feature?**\r\nUsers that need to repeat or tile their data of type `tf.uint{32,64}`\r\n\r\n**Sketch of a test case**\r\n```python\r\nimport tensorflow as tf\r\n\r\n\r\ntf.tile(tf.constant([1,2,3], dtype=tf.uint64), (3, ))\r\ntf.tile(tf.constant([1,2,3], dtype=tf.uint32), (3, ))\r\ntf.repeat(tf.constant([1,2,3], dtype=tf.uint64), 3, axis=0)\r\ntf.repeat(tf.constant([1,2,3], dtype=tf.uint32), 3, axis=0)\r\n```\r\n\r\n**Logs for current behavior**\r\n```\r\nipdb> tf.tile(tf.constant([1,2,3], dtype=tf.uint64), (3, ))\r\n*** tensorflow.python.framework.errors_impl.UnimplementedError: TileOp : The input data type is not supported, DataType : uint64, Dimension : 1 [Op:Tile]\r\nipdb> tf.tile(tf.constant([1,2,3], dtype=tf.uint32), (3, ))\r\n*** tensorflow.python.framework.errors_impl.UnimplementedError: TileOp : The input data type is not supported, DataType : uint32, Dimension : 1 [Op:Tile]\r\nipdb> tf.repeat(tf.constant([1,2,3], dtype=tf.uint64), 3, axis=0)\r\n*** tensorflow.python.framework.errors_impl.UnimplementedError: TileOp : The input data type is not supported, DataType : uint64, Dimension : 2 [Op:Tile]\r\nipdb> tf.repeat(tf.constant([1,2,3], dtype=tf.uint32), 3, axis=0)\r\n*** tensorflow.python.framework.errors_impl.UnimplementedError: TileOp : The input data type is not supported, DataType : uint32, Dimension : 2 [Op:Tile]\r\n```\r\n", "comments": ["I am able to replicate this issue, please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/782744d7438a74267b8e6a82a62ef2a0/untitled175.ipynb)", "Added a PR #39424 for uint32/uint64 support.", "Wow, that was super fast. Thanks @yongtang, much appreciated!"]}, {"number": 39404, "title": "[tflite] reformat/cleanup label_image readme.md", "body": "", "comments": []}, {"number": 39403, "title": "tf.data.Dataset doesn't handle namedtuples properly", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): true\r\n- TensorFlow installed from (source or binary): collab notebook\r\n- TensorFlow version (use command below): v2.2.0-rc4-0-g70087ab4f4\r\n- Python version: 3.6.9\r\n\r\n**Describe the current behavior**\r\nHandling of namedtuples by datasets is not coherent: elementspec does not reflect the input type\r\n\r\n**Describe the expected behavior**\r\nThe elementspec should reflect the structured input\r\n\r\n**Standalone code to reproduce the issue**\r\nhttps://colab.research.google.com/drive/1w3vHiI2mItjL1uv8c8RzMEqATPI9v7u3?usp=sharing\r\n\r\n", "comments": ["@AdrienCorenflos \r\n\r\nI am not able to access the colab link you have provided. Please, grant me access it helps us to debug the issue.Thanks!", "I have tried in colab with TF version 2.2-rc4 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/edb0f86a8d0a05ef67738df19602ed4a/untitled876.ipynb).Thanks!", "@AdrienCorenflos As far as I can tell, `element_spec` does work correctly for named tuples:\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport collections\r\n\r\nPoint = collections.namedtuple('Point', ['x', 'y'])\r\ndataset = tf.data.Dataset.from_tensor_slices(Point([1, 2, 3], [4, 5, 6]))\r\n\r\nprint(dataset.element_spec)\r\n```\r\n```python\r\nPoint(x=TensorSpec(shape=(), dtype=tf.int32, name=None), y=TensorSpec(shape=(), dtype=tf.int32, name=None))\r\n```\r\n\r\nOne easy mistake to make is passing a list of tuples or named tuples to `from_tensor_slices`. `from_tensor_slices` expects its input to be a structure of tensors, and will coerce Python `list`s (along with their contents) into tensors. For example, `[(1, 2), (3, 4)]` is seen as a 2d tensor of integers, equivalent to `[[1, 2], [3, 4]]`. The same applies to `[Point(1, 2), Point(3, 4)]`. This could make it look like named tuples aren't being respected properly if you call `tf.data.Dataset.from_tensor_slices([Point(1, 2), Point(3, 4)])`. The argument `[Point(1, 2), Point(3, 4)]` will be interpreted as equivalent to `[[1, 2], [3, 4]]`.\r\n\r\nI think this behavior is pretty unintuitive (it looked like a bug at first to me too). However, we can't change the behavior without breaking backwards compatibility, so I think the action item here is to improve the documentation to make it clear that the input is treated as a structure of Tensors, **not** a list of dataset elements.", "\r\n@AdrienCorenflos It looks like you are using an older Version of Tensorflow . Many bugs have been fixed in the latest version. Can you please execute your code using Latest Version 2.5 or 2.4.1 and let us know if the issue still persists? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39403\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39403\">No</a>\n"]}, {"number": 39402, "title": "Add support for more dimensions -  ImageDataGenerator's .flow_from_directory()", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.1.0\r\n- Are you willing to contribute it (Yes/No): No\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nWhen using ImageDataGenerator's .flow_from_directory(), one has to specify color_mode \u2208 {\"grayscale\", \"rgb\", \"rgba\"} (1, 3 or 4 dim).\r\n\r\nI propose to change the color mode to an input_shape() to be able to handle more dimensions.\r\n\r\n**Will this change the current api? How?**\r\nEither remove the color_mode completely and handle it dynamically or let the user input the input_shape of the data.\r\n\r\n**Who will benefit with this feature?**\r\nWhen working with multiclass image segmentations and an one-hot encoded representations of the segmentation masks, it is very convenient to use the ImageDataGenerator's .flow_from_directory() for both the image and the mask, then zip them when inputted to model.fit(). \r\n\r\nToday, this does only work if the mask is of dim \u2208 {1, 3, 4}.\r\n\r\nOne way to circumvent this is to write your own generator by inheriting from keras.utils.Sequence class, but it would be nice to have support for it in ImageDataGenerator as one then can use the built-in augmentations.\r\n\r\n**Any Other info.**\r\nRelated question on Stackoverflow: https://stackoverflow.com/questions/60551136/how-to-use-imagedatagenerator-with-multi-label-masks-for-multi-class-image-segme", "comments": ["@maxvfischer Sorry for the late response. Are you still interested in contributing? If yes, please feel free to open a PR in  [keras-team/keras repo.](https://github.com/keras-team/keras/issues) repository.\r\n\r\nPlease note that Keras development moved to keras-team/keras repository to focus on only keras. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 39401, "title": "Failed to load the native TensorFlow runtime.", "body": "(base) PS C:\\Users\\Asteroids\\Downloads\\Real-Time-Voice-Cloning-master> python demo_cli.py\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Asteroids\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Asteroids\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Asteroids\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Asteroids\\anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Asteroids\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: \u041f\u0440\u043e\u0438\u0437\u043e\u0448\u0435\u043b \u0441\u0431\u043e\u0439 \u0432 \u043f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u0435 \u0438\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u0438 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0438 \u0434\u0438\u043d\u0430\u043c\u0438\u0447\u0435\u0441\u043a\u043e\u0439 \u043a\u043e\u043c\u043f\u043e\u043d\u043e\u0432\u043a\u0438 (DLL).\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"demo_cli.py\", line 3, in <module>\r\n    from synthesizer.inference import Synthesizer\r\n  File \"C:\\Users\\Asteroids\\Downloads\\Real-Time-Voice-Cloning-master\\synthesizer\\inference.py\", line 1, in <module>\r\n    from synthesizer.tacotron2 import Tacotron2\r\n  File \"C:\\Users\\Asteroids\\Downloads\\Real-Time-Voice-Cloning-master\\synthesizer\\tacotron2.py\", line 3, in <module>\r\n    from synthesizer.models import create_model\r\n  File \"C:\\Users\\Asteroids\\Downloads\\Real-Time-Voice-Cloning-master\\synthesizer\\models\\__init__.py\", line 1, in <module>\r\n    from .tacotron import Tacotron\r\n  File \"C:\\Users\\Asteroids\\Downloads\\Real-Time-Voice-Cloning-master\\synthesizer\\models\\tacotron.py\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\Asteroids\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 28, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\Asteroids\\anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Asteroids\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Asteroids\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Asteroids\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Asteroids\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Asteroids\\anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Asteroids\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: \u041f\u0440\u043e\u0438\u0437\u043e\u0448\u0435\u043b \u0441\u0431\u043e\u0439 \u0432 \u043f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u0435 \u0438\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u0438 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0438 \u0434\u0438\u043d\u0430\u043c\u0438\u0447\u0435\u0441\u043a\u043e\u0439 \u043a\u043e\u043c\u043f\u043e\u043d\u043e\u0432\u043a\u0438 (DLL).\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\n\n* For TF-GPU - See point 1\n* For TF-CPU - See point 2\n\n-----------------------------------------------------------------------------------------------\n\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\n\n*TF Version >= 1.13 requires CUDA 10.0 and TF Version < 1.13 (till TF 1.5) requires CUDA 9.0.*\n\n* If you have above configuration and using _**Windows**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\n  * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\n* If you have above configuration and using _**Ubuntu/Linux**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\n  * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\n* If error still persists then, apparently your CPU model does not support AVX instruction sets.\n  * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\n\n-----------------------------------------------------------------------------------------------\n\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\n\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\n\n Therefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\n\n* Try Google Colab to use TensorFlow.\n  * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true).You get pre-installed latest stable TF version. Also you can use```pip install``` to install any other preferred TF version.\n  * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\n  * All you need is a good internet connection and you are all set.\n* Try to build TF from sources by changing CPU optimization flags.\n\n*Please let us know if this helps.*", "@Nelsi0 \r\nWhat is the version of the tensorflow.\r\n\r\nWhat is make/model of your cpu?\r\nI suspect your cpu model does not support AVX instructions sets.See [hardware requirements](https://www.tensorflow.org/install/pip?lang=python3#hardware-requirements)\r\nMake sure to download the latest [microsoft visual c++ redistributable](https://support.microsoft.com/en-us/help/2977003/the-latest-supported-visual-c-downloads) from here.\r\n.Also, please follow the instructions from to install from[ Tensorflow website](https://www.tensorflow.org/install/source_windows).\r\n\r\nPlease, check Your CPU/Python is on 32 bits?Please, refer #36167 and see if it helps you.\r\nPlease, refer similar issue #36167 #36151 #36138 #36054 #36045 #36020 #36003 #35988 #35903 #35880 #35865 #35805 #35789 #35773 #35772 #35767 #35766 #35749 #35721 #35618 #35204\r\nThanks!", "1.14.0\r\npentium g4600", "@Nelsi0 \r\nIs there any particular reason for using an older version of tensor flow when there are later versions. can you try the later versions and let us know if you face any issues.\r\n\r\nHave you refereed to any of the mentioned issues as this is a common occurring issue and the solution is as per above mentioned issues. [please do so and let us know]", "Processor does not support AVX. Closing as duplicate.\r\n\r\nYou can try compiling from source or using Google Colab Notebooks.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39401\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39401\">No</a>\n"]}, {"number": 39400, "title": "Failed to load the native TensorFlow runtime.", "body": "(base) PS C:\\Users\\Asteroids\\Downloads\\Real-Time-Voice-Cloning-master> python demo_cli.py\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Asteroids\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Asteroids\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Asteroids\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Asteroids\\anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Asteroids\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: \u041f\u0440\u043e\u0438\u0437\u043e\u0448\u0435\u043b \u0441\u0431\u043e\u0439 \u0432 \u043f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u0435 \u0438\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u0438 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0438 \u0434\u0438\u043d\u0430\u043c\u0438\u0447\u0435\u0441\u043a\u043e\u0439 \u043a\u043e\u043c\u043f\u043e\u043d\u043e\u0432\u043a\u0438 (DLL).\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"demo_cli.py\", line 3, in <module>\r\n    from synthesizer.inference import Synthesizer\r\n  File \"C:\\Users\\Asteroids\\Downloads\\Real-Time-Voice-Cloning-master\\synthesizer\\inference.py\", line 1, in <module>\r\n    from synthesizer.tacotron2 import Tacotron2\r\n  File \"C:\\Users\\Asteroids\\Downloads\\Real-Time-Voice-Cloning-master\\synthesizer\\tacotron2.py\", line 3, in <module>\r\n    from synthesizer.models import create_model\r\n  File \"C:\\Users\\Asteroids\\Downloads\\Real-Time-Voice-Cloning-master\\synthesizer\\models\\__init__.py\", line 1, in <module>\r\n    from .tacotron import Tacotron\r\n  File \"C:\\Users\\Asteroids\\Downloads\\Real-Time-Voice-Cloning-master\\synthesizer\\models\\tacotron.py\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\Asteroids\\anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 28, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\Asteroids\\anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Asteroids\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Asteroids\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Asteroids\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Asteroids\\anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Asteroids\\anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Asteroids\\anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: \u041f\u0440\u043e\u0438\u0437\u043e\u0448\u0435\u043b \u0441\u0431\u043e\u0439 \u0432 \u043f\u0440\u043e\u0433\u0440\u0430\u043c\u043c\u0435 \u0438\u043d\u0438\u0446\u0438\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u0438 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u0438 \u0434\u0438\u043d\u0430\u043c\u0438\u0447\u0435\u0441\u043a\u043e\u0439 \u043a\u043e\u043c\u043f\u043e\u043d\u043e\u0432\u043a\u0438 (DLL).\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\n\n* For TF-GPU - See point 1\n* For TF-CPU - See point 2\n\n-----------------------------------------------------------------------------------------------\n\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\n\n*TF Version >= 1.13 requires CUDA 10.0 and TF Version < 1.13 (till TF 1.5) requires CUDA 9.0.*\n\n* If you have above configuration and using _**Windows**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\n  * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\n* If you have above configuration and using _**Ubuntu/Linux**_ platform -\n  * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\n  * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\n* If error still persists then, apparently your CPU model does not support AVX instruction sets.\n  * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\n\n-----------------------------------------------------------------------------------------------\n\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\n\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\n\n Therefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\n\n* Try Google Colab to use TensorFlow.\n  * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true).You get pre-installed latest stable TF version. Also you can use```pip install``` to install any other preferred TF version.\n  * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\n  * All you need is a good internet connection and you are all set.\n* Try to build TF from sources by changing CPU optimization flags.\n\n*Please let us know if this helps.*", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39400\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/39400\">No</a>\n"]}, {"number": 39399, "title": "Refactoring: Format String -> Format Method", "body": "I think this method is more pythonic.\r\n\r\nThx", "comments": []}]