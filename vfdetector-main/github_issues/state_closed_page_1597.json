[{"number": 5002, "title": "could you release binary for cuda8", "body": "Could you release binary package for cuda8?\n\nSome devices, e.g., gtx 1070/1080, build off cuda8. It will save a lot of work for installation from source.\n\nthanks.\n", "comments": ["You're going to be so happy to hear that we're working on this right now. Please subscribe to #2559 for updates.\n"]}, {"number": 5001, "title": "[g3doc] Fix image link error", "body": "", "comments": ["@jybaek, thanks for your PR! By analyzing the history of the files in this pull request, we identified @vrv, @keveman and @fayeshine to be potential reviewers.\n", "Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n", "I signed it!\n", "CLAs look good, thanks!\n\n<!-- ok -->\n", "Thanks for spotting the broken link!\n\nWe understand that the images are not checked in into github at the moment and that github looks broken right now. If you are building your internal version of the docs, we'd recommend you post-process the markdowns with a script.\n\nWe don't really want an absolute link since it will impair our ability to have multiple sites, for instance, a doc site for v1.0, and the last of the v0.xx.\n", "@drpngx Thank you for your answer. I understand. \n"]}, {"number": 5000, "title": "Add support for dict Input to DataFeeder, StreamingDataFeeder, Estimator.fit() and Estimator.evaluate()", "body": "# Problem\n\nThe `Estimator.fit()` function takes as argument either\n- (`x`, `y`, and `batch_size`) where `x` and `y` could be numpy arrays or iterators.\n  - **PROS**\n    1.   Easy to use.\n    2.  Allows feeding data from arbitrary source as long as problem can be decomposed into `x` and `y`.\n  - **CONS**\n    1.  No provision to provide epoch\n    2.  In case, `x` and `y` are arrays, the data aggregate must be available as opposed to reading on the fly ( say from database)\n    3. Whether array or iterator, `x` and `y` can't be dictionaries. Most complex problems cannot be reduced to input matrix and output matrix and may require multiple input features matrices.\n- `input_fn` - this is callback function which must return `features` and `target` tensors or dictionary of tensors.\n  - **PROS**\n    1. Allows feeding data from arbitrary source (in theory).\n    2. returned features and targets can be dictionary thus allowing to solve complex problems which takes multiple inputs.\n  - **CONS**\n    1. Only found support for reading files using `read_batch_examples()`, `read_batch_features()`, `read_batch_record_features()`, etc.\n    2. No support for passing placeholder and feed_fn to allow for arbitrary source of input data which don't require queue.\n# Relevant discussions\n1. https://github.com/tensorflow/tensorflow/pull/4696#issuecomment-253632403\n2. http://stackoverflow.com/questions/39855375/how-to-use-streamingdatafeeder-as-contrib-learn-estimator-fits-input-fn\n# Additional problem\n\nCurrently the self.feature_info (feature signature) must be same for training as well as evaluation. However, there can be cases where evaluation if done differently than training. For example, DualEncoderLSTM model where training just requires Context and Utterance, while Evaluation (Validation) requires context and multiple utterances.\n# Solution\n\nThis PR basically combines the pros of using (`x`, `y`, and `batch_size`) with pros of input_fn by allowing `x`, `y` to be dictionary of multiple arrays. This also works for `x` and `y` iterators returning dictionary of streaming data. \n\nAlso, added support for different feature/target signature for training and evaluation.\n", "comments": ["Can one of the admins verify this patch?\n", "@abhitopia, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener, @ilblackdragon and @vrv to be potential reviewers.\n", "@martinwicke -  Would be great to have your thoughts on this too.\n", "@tyfkda is that something you would be interested in looking at perhaps?\n", "Just also added support for different feature_info (Signature) for train and evaluation. \n", "@martinwicke , @drpngx , @tyfkda - Have you guys had a chance to review it yet?\n", "Sorry, not my area, but please resolve changes and ping again.\n", "Sorry -- we're thinking about predict quite a bit right now. This comes at a good time. Please give us some time to discuss.\n", "@martinwicke - Do I need to fix the conflicts first or perhaps I do it once you have reviewed it?\n", "@martinwicke - Any way I can contribute to the discussion?\n", "+1 definitely see the use case of the functionality, when will get accepted?\n", "@vrv, @martinwicke - It would be great to get it reviewed soon. Please respond.\n", "Exactly what I was looking for. When will this get merged in master? @abhitopia @martinwicke \n", "We found a Contributor License Agreement for you (the sender of this pull request) and all commit authors, but as best as we can tell these commits were authored by someone else.  If that's the case,  please add them to this pull request and have them confirm that they're okay with these commits being contributed to Google.  If we're mistaken and you did author these commits, just reply here to confirm.\n\n<!-- need_author_consent -->\n", "@abhitopia Sorry, I'm not very familiar with the tf learn components at all, so I'll let @martinwicke guide :)\n", "@martinwicke - I messed up my branch somehow, will recreate the PR\n", "Here is an update on current state:\n- we just split up SK compatibility from `Estimator` into separate class `SKCompat`. E.g. if one wants to use `fit(x, y)` they need to wrap their estimator with `SKCompat(Estimator(...))`. Otherwise preferred way will be .\n  - there is a pending change (hopefully goes in today) to add `pandas_input_fn` that would allow you to `est.fit(pandas_input_fn(x_df, y_series), ...)` which would pass all the columns of the data frame as dict of features. It will also use local queue to feed data, which increases performance a bit compared to current data feeder solution.\n\nGoing forward we are thinking to remove data feeders, and rely on input functions similar to `pandas_input_fn` for other types of data. And `SKCompat` interface can just seamlessly wrap the passed data into this functions.\n", "Reponing in #5546 \n"]}, {"number": 4999, "title": "[bugs] TensorFlow ci_build docker bazel extration error", "body": "Within the past week I started getting a bazel extraction error when trying to build my docker image for testing.\nBelow is a reproducible description of the error.\n\nGeneric Ubuntu 14.04 on AWS (c4.4xlarge)\n\n```\n$uname -r\n3.13.0-91-generic\n```\n\nInstall docker according to installation instructions at [docker ubuntu](https://docs.docker.com/engine/installation/linux/ubuntulinux/) with a docker group added to the default user.\n\n```\n$sudo apt-get install git\n$git clone https://github.com/tensorflow/tensorflow.git\n$cd tensorflow\n$tensorflow/tools/ci_build/ci_build.sh CPU bazel test //tensorflow/...\n```\n\nI then receive the following error\n\n```\nStep 10 : RUN /install/install_buildifier.sh\n ---> Running in f38c73826642\nCloning into 'buildifier'...\n/buildifier /\nExtracting Bazel installation...\n.\nERROR: com.google.devtools.build.lib.packages.BuildFileContainsErrorsException: error loading package '': Encountered error while reading extension file 'go/def.bzl': no such package '@io_bazel_rules_go//go': Error cloning repository: https://github.com/bazelbuild/rules_go.git: cannot open git-upload-pack caused by https://github.com/bazelbuild/rules_go.git: cannot open git-upload-pack caused by java.lang.RuntimeException: Unexpected error: java.security.InvalidAlgorithmParameterException: the trustAnchors parameter must be non-empty caused by Unexpected error: java.security.InvalidAlgorithmParameterException: the trustAnchors parameter must be non-empty caused by the trustAnchors parameter must be non-empty.\n____Elapsed time: 1.730s\nThe command '/bin/sh -c /install/install_buildifier.sh' returned a non-zero code: 1\nERROR: docker build failed. Dockerfile is at /home/ubuntu/tensorflow/tensorflow/tools/ci_build/Dockerfile.cpu\n```\n", "comments": ["This bug is most likely upstream. jgit is very buggy and prone to random failures such as these. I filed bazelbuild/buildifier#18. I'm not sure what to recommend for you as a workaround at this moment. But thank you for bringing this to our attention.\n", "This bug is not in tensorflow code, but I may have a possible solution.\nAfter installing JDK on your VM, could you run the two following commands?\nThese may solve your problems:\n\n$ sudo apt-get install ca-certificates-java\n$ sudo update-ca-certificates -f\n\nThis seems to fix the flakes we see in our own CI builds ( #5041 ) but if you want a fix faster you may try the two above commands.\n"]}, {"number": 4998, "title": "Please make the documentation headlines linkable/clickable", "body": "That would make it easier to refer to particular parts/anchors in the documentation.\n", "comments": ["This is a terrific idea. Thank you for proposing it. Having anchor links that appear next to headers when you hover over them is a very common practice. Let's see what our documentation czar @xmbrst thinks.\n", "This seems like a good idea that we haven't done even in the new docs.\r\n", "Sorry, what are we talking about here?  We provide header/subhead links, like this:\r\n\r\nhttps://www.tensorflow.org/get_started/get_started#importing_tensorflow\r\n\r\nAll the links are available on the table of contents on the right.\r\n\r\nCan you clarify which headers you want links to?", "Indeed, the table of contents basically implements this feature. This issue remains a minor feature request that the headers which are already linkable via the table of contents should be wrapped in anchor elements to make them clickable. This is sometimes implemented by displaying a chain/link symbol \ud83d\udd17 on the MouseOver event (e.g. in the [PyTorch docs](http://pytorch.org/docs/torch.html#torch.add)). That saves the step of scanning the table of contents for the particular section that one wants to link to.", "I will suggest this to the team that manages our CMS, but unless they implement it, we are not going to do it given there's an immediate workaround.  I'm closing the bug against TensorFlow, with the caveat that I will file it against the CMS on another tracker."]}, {"number": 4997, "title": "xcode build system broken", "body": "I am getting the error  'unsupported/Eigen/CXX11/Tensor' while trying to run camera example in iOS i do have Eigen installed on my mac..\n", "comments": ["Are you running the tensorflow/contrib/makefile build system or are you using one of the xcode projects?\n", "i am using the xcode projects in this repo @jart \n", "@jart  and this is the only error i get and also can i ask how do you manage to get a tensorflow repo into ios ive been struggling to do that..\n\nThanks \nAryan\n", "Those xcode project files are in the contrib folder, so they are community supported. We don't have any automated regression tests that guarantee they stay correct. We also aren't able to test them manually when we make changes to our Bazel build.\n\nIt is likely that https://github.com/tensorflow/tensorflow/commit/65038b084059cf934df50fa86dba5b0e765f9d65 is what broke the xcode project definitions. Perhaps you could help us fix these files. I'm marking this issue as contributions welcome.\n", "@petewarden \n", "@NSAryan12 have you had success following the iOS build instructions here?\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile#ios\n\nYou'll need to run `tensorflow/contrib/makefile/build_all_ios.sh` before you can compile the Xcode example projects.\n", "@petewarden /usr/local/Cellar/autoconf/2.69/bin/autoconf failed with exit status: 1 i get that error :(\n", "when i do tensorflow/contrib/makefile/build_all_ios.sh \n", "Can you give me the full console output you see after running the build_all_ios.sh script?\n", "```\nPROTOC = \"protoc\"\nCC_PREFIX = \"\"\nrm -rf /Users/Aryan/Documents/libs/tensorflow/tensorflow/contrib/makefile/gen\nrm -rf tensorflow/core/util/version_info.cc\ndownloading http://bitbucket.org/eigen/eigen/get/97c1ebe6ccc2.tar.gz\ndownloading http://github.com/google/gemmlowp/archive/c0bacf11fb509a2cbe15a97362a2df067ffd57a2.tar.gz\ndownloading https://github.com/google/googletest/archive/release-1.8.0.tar.gz\ndownloading http://github.com/google/protobuf/archive/c2b3e70efd2038a54ef8973771ac58192885125e.tar.gz\ndownloading http://github.com/google/re2/archive/7bab3dc83df6a838cc004cc7a7f51d5fe1a427d5.tar.gz\ndownload_dependencies.sh completed successfully.\n++ dirname tensorflow/contrib/makefile/compile_ios_protobuf.sh\n+ SCRIPT_DIR=tensorflow/contrib/makefile\n+ source tensorflow/contrib/makefile/build_helper.subr\n+ cd tensorflow/contrib/makefile\n++ pwd\n+ HOST_GENDIR=/Users/Aryan/documents/libs/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host\n+ mkdir -p /Users/Aryan/documents/libs/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host\n+ [[ ! -f ./downloads/protobuf/autogen.sh ]]\n+ '[' 1 -gt 1 ']'\n+ JOBS_COUNT=4\n++ pwd\n+ GENDIR=/Users/Aryan/documents/libs/tensorflow/tensorflow/contrib/makefile/gen/protobuf_ios/\n+ LIBDIR=/Users/Aryan/documents/libs/tensorflow/tensorflow/contrib/makefile/gen/protobuf_ios/lib\n+ mkdir -p /Users/Aryan/documents/libs/tensorflow/tensorflow/contrib/makefile/gen/protobuf_ios/lib\n+ OSX_VERSION=darwin14.0.0\n++ xcrun --sdk iphoneos --show-sdk-platform-path\n+ IPHONEOS_PLATFORM=/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform\n++ xcrun --sdk iphoneos --show-sdk-path\n+ IPHONEOS_SYSROOT=/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneOS.platform/Developer/SDKs/iPhoneOS10.0.sdk\n++ xcrun --sdk iphonesimulator --show-sdk-platform-path\n+ IPHONESIMULATOR_PLATFORM=/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform\n++ xcrun --sdk iphonesimulator --show-sdk-path\n+ IPHONESIMULATOR_SYSROOT=/Applications/Xcode.app/Contents/Developer/Platforms/iPhoneSimulator.platform/Developer/SDKs/iPhoneSimulator10.0.sdk\n++ xcrun --sdk iphoneos --show-sdk-version\n+ IOS_SDK_VERSION=10.0\n+ MIN_SDK_VERSION=8.2\n+ CFLAGS='-DNDEBUG -Os -pipe -fPIC -fno-exceptions'\n+ CXXFLAGS='-DNDEBUG -Os -pipe -fPIC -fno-exceptions -std=c++11 -stdlib=libc++'\n+ LDFLAGS=-stdlib=libc++\n+ LIBS='-lc++ -lc++abi'\n+ cd downloads/protobuf\n+ PROTOC_PATH=/Users/Aryan/documents/libs/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host/bin/protoc\n+ [[ ! -f /Users/Aryan/documents/libs/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host/bin/protoc ]]\n+ echo 'protoc not found at /Users/Aryan/documents/libs/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host/bin/protoc. Build it first.'\nprotoc not found at /Users/Aryan/documents/libs/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host/bin/protoc. Build it first.\n+ make_host_protoc /Users/Aryan/documents/libs/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host\n+ [[ ! -n /Users/Aryan/documents/libs/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host ]]\n+ HOST_GENDIR=/Users/Aryan/documents/libs/tensorflow/tensorflow/contrib/makefile/gen/protobuf-host\n+ ./autogen.sh\nGoogle Mock not present.  Fetching gmock-1.7.0 from the web...\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100   129    0   129    0     0    182      0 --:--:-- --:--:-- --:--:--   181\n100  362k  100  362k    0     0   153k      0  0:00:02  0:00:02 --:--:--  353k\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100   129    0   129    0     0    188      0 --:--:-- --:--:-- --:--:--   188\n100  618k  100  618k    0     0   207k      0  0:00:02  0:00:02 --:--:--  295k\n+ autoreconf -f -i -Wall,no-obsolete\nconfigure.ac:30: error: possibly undefined macro: AC_PROG_LIBTOOL\n      If this token and others are legitimate, please use m4_pattern_allow.\n      See the Autoconf documentation.\nautoreconf: /usr/local/Cellar/autoconf/2.69/bin/autoconf failed with exit status: 1\n```\n\n@petewarden \n", "Does running `brew install libtool` help? If so, we may need to update the documentation to include that.\n", "Cool it worked but now i get an error saying `#include \"tensorflow/core/framework/types.pb.h\"` not found in the xcode project. @petewarden \n", "Closing since the bug seems stale.  We're happy to accept pull requests with further xcode fixes."]}, {"number": 4996, "title": "tensorflow/core/framework/common_shape_fns.h not in includes path (v0.11.0rc0)", "body": "### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\n\nNone\n### Environment info\n\nOperating System: **Ubuntu 14.04 x64**\n\nInstalled version of CUDA and cuDNN: **CUDA 7.5 and CUDNN 5.1**\n\n```\n$ ll /usr/local/cuda/lib64/libcud*\n-rw-r--r-- 1 root root   322936 Aug 15  2015 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5*\nlrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18*\n-rwxr-xr-x 1 root root   383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18*\n-rw-r--r-- 1 root root   720192 Aug 15  2015 /usr/local/cuda/lib64/libcudart_static.a\n-rwxr-xr-x 1 root root 60696704 Sep 21 21:07 /usr/local/cuda/lib64/libcudnn.so*\n-rwxr-xr-x 1 root root 60696704 Sep 21 21:07 /usr/local/cuda/lib64/libcudnn.so.5*\n-rwxr-xr-x 1 root root 60696704 Sep 21 21:07 /usr/local/cuda/lib64/libcudnn.so.5.1.3*\n-rw-r--r-- 1 root root 59715990 Sep 21 21:07 /usr/local/cuda/lib64/libcudnn_static.a\n```\n\nIf installed from binary pip package, provide:\n1. A link to the pip package you installed: **https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.11.0rc0-cp27-none-linux_x86_64.whl**\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n   **0.11.0rc0**\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\n\nCannot `#include \"tensorflow/core/framework/common_shape_fns.h` to use `::tensorflow::shape_inference::UnchangedShape`\n\nAlso:\n\n```\n$ ls /usr/local/lib/python2.7/dist-packages/tensorflow/include/tensorflow/core/framework/common_shape_fns.h\nls: cannot access /usr/local/lib/python2.7/dist-packages/tensorflow/include/tensorflow/core/framework/common_shape_fns.h: No such file or directory\n```\n### What other attempted solutions have you tried?\n\nUse python to infer custom op's shape instead (which works):\n\n``` python\ntf.RegisterShape(\"MyOp\")(common_shapes.unchanged_shape)\n```\n", "comments": ["Thanks for reporting this issue. Can you provide commands to reproduce this problem?\n", "Here's a sample op (sample_op.cc):\n\n``` c++\n#include \"tensorflow/core/framework/op.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n#include \"tensorflow/core/framework/shape_inference.h\"\n#include \"tensorflow/core/framework/common_shape_fns.h\"\n\nusing namespace tensorflow;\n\nREGISTER_OP(\"SampleOp\")\n    .Input(\"input: string\")\n    .Output(\"output: string\")\n    /* .SetShapeFn([](shape_inference::InferenceContext* c) { */\n    /*     shape_inference::ShapeHandle input; */\n    /*     TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 1, &input)); */\n    /*     if (c->Value(c->Dim(input, 0)) > 1) { */\n    /*         return errors::InvalidArgument( */\n    /*             \"Shape of a default must be a length-0 or length-1 vector\"); */\n    /*     } */\n    /*     c->set_output(0, input); */\n    /*     return Status::OK(); */\n    /* }) */\n    .SetShapeFn([](shape_inference::UnchangedShape))\n    .Doc(R\"doc(\nReturn input strings uchanged\ninput: 1-D. Input strings\noutput: A vector of strings corresponding to the input strings.\n)doc\");\n\nclass SampleOp : public OpKernel {\n public:\n  explicit SampleOp(OpKernelConstruction* context): OpKernel(context) {\n  }\n\n  void Compute(OpKernelContext* ctx) override {\n    const Tensor* input_tensor;\n    OP_REQUIRES_OK(ctx, ctx->input(\"input\", &input_tensor));\n    auto records_t = input_tensor->flat<string>();\n    const int64 input_size = records_t.size();\n\n    Tensor* output_t;\n    OP_REQUIRES_OK(\n        ctx, ctx->allocate_output(0, input_tensor->shape(), &output_t));\n    auto output = output_t->flat<string>();\n\n    for (int64 i = 0; i < input_size; ++i) {\n      output(i) = records_t(i);\n    }\n  }\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"SampleOp\").Device(DEVICE_CPU), SampleOp);\n```\n\nCompiling this file yields:\n\n```\n$ TF_INC=$(python -c 'import tensorflow as tf; print(tf.sysconfig.get_include())')\n$ g++ -std=c++11 -shared sample_op.cc -o sample_op.so -fPIC -I $TF_INC -O2 -D_GLIBCXX_USE_CXX11_ABI=0\nsample_op.cc:4:56: fatal error: tensorflow/core/framework/common_shape_fns.h: No such file or directory\ncompilation terminated.\n```\n\ng++ version:\n\n```\n$ g++ --version                                                                                                                                         1 \u21b5\ng++ (Ubuntu 5.4.0-6ubuntu1~16.04.2) 5.4.0 20160609\nCopyright (C) 2015 Free Software Foundation, Inc.\nThis is free software; see the source for copying conditions.  There is NO\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\n```\n", "Thanks for the report @sirfz . \n\n@cwhipkey, @vrv : Should `common_shape_fns.h` be included in `core:framework_headers`? Or should we not export these? (If they should be included, then we might also have to include `util/padding.h`?)\n", "Reopening since the attempted fix was rolled back in 8a0e81d81f88d49f49af969e9e7fe5807322931d\n\nWe'll attempt another fix soon\n", "So, how did you solve that problem? I have the same problem and I didn't see any header files inside either in tensorflow/core/framework directory."]}, {"number": 4995, "title": "Partial training of im2txt runs only 1 step", "body": "After running an initial training of model 'im2txt' of 5100 steps, when trying to run more steps, it only runs one and saves the model, i've tried using 10 , 100 and 5000 steps\n\nmodel url: https://github.com/tensorflow/models/tree/master/im2txt\n\nParams:\n--input_file_pattern=\"/Users/carlosescamilla/im2text/data/mscoco/train-?????-of-00256\" \n--inception_checkpoint_file=\"/Users/carlosescamilla/im2text/data/inception_v3.ckpt\" \n--train_dir=\"/Users/carlosescamilla/im2text/model/train\"\n --train_inception=false \n--number_of_steps=100\n\nOutput:\n\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.1.dylib locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.dylib locally\nINFO:tensorflow:Prefetching values from 256 files matching /Users/carlosescamilla/im2text/data/mscoco/train-?????-of-00256\nI tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] OS X does not support NUMA - returning NUMA node zero\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:951] Found device 0 with properties: \nname: GeForce GT 750M\nmajor: 3 minor: 0 memoryClockRate (GHz) 0.9255\npciBusID 0000:01:00.0\nTotal memory: 2.00GiB\nFree memory: 1.77GiB\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:972] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:982] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:1041] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GT 750M, pci bus id: 0000:01:00.0)\nINFO:tensorflow:Starting Session.\nINFO:tensorflow:Starting Queues.\nINFO:tensorflow:global_step/sec: 0\nW tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 759.69MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\nW tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 759.69MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\nW tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 1.01GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\nW tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 1.01GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\nW tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 759.69MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\nW tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 759.69MiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\nW tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 1.51GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\nW tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 1.51GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\nW tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 2.22GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\nW tensorflow/core/common_runtime/bfc_allocator.cc:213] Ran out of memory trying to allocate 2.22GiB. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory is available.\nINFO:tensorflow:global step 5111: loss = 3.0275 (45.44 sec/step)\nINFO:tensorflow:Stopping Training.\nINFO:tensorflow:Finished training! Saving model to disk.\n### Environment info\n\nMacOS 10.11.6 El Capitan\n\nInstalled version of CUDA and cuDNN: \nCUDA Toolkit 7.5\ncuDNN 5005\n\ninstalled with pip3\nexport TF_BINARY_URL=https://storage.googleapis.com/tensorflow/mac/gpu/tensorflow-0.11.0rc0-py3-none-any.whl\n", "comments": ["How much RAM do you have? We frequently encounter issues where people are running the stuff in tensorflow/models on systems that don't have a generous amount of resources.\n", "i have 2 GB on GPU and 16 GB on RAM, i already tried running the training process on CPU only and it fails too after the initial steps\n", "Can you try --number_of_steps=5100 instead?\n", "i have uninstalled tensorflow from my computer due to this issue, maybe in a near future i can give it another try.\n"]}, {"number": 4994, "title": "Feature request: ExportCostModels in C/Python API?", "body": "Exporting cost models of graphs seems to be a great feature with which users could figure out the resource-intensive (or even slowest) part of graphs, but currently it's not visible in the C/Python API.\n\nI've tried to make it work and found that ExportCostModels() is not a member function in the \"Session\" interface. Also, a CostGraphDef object is related to a partition of some graph, placed on some device. ExportCostModels() in \"DirectSession\" only provides a mapping from partitions (note that for all the graphs executed) to CostGraphDef objects and it's hard to get CostGraphDef directly for the concerning parts. So I think there should be more works to make the code eligible and easy for use.\n\nI wonder whether is anybody working on this and how developers think about this feature. Thank you!\n", "comments": ["@yuanbyu has been looking at CostModels recently\n", "I read though session.py and finally found that `CostGraphDef` is exported via `RunMetadata` which is one of the paramters for `Session.run`. I think this issue could be closed. Thanks anyway.\n", "I'm going to close this issue for now since, as you pointed out the `CostGraphDef` is available from the `RunMetadata`. However, if profiling your graph is what is driving you, you might also want to consider [tracing](https://github.com/tensorflow/tensorflow/issues/1824#issuecomment-225754659)\n\nPlease feel free to re-open if your concerns weren't addressed\n"]}, {"number": 4993, "title": "Uninitialized memory read on send_device_incarnation", "body": "Running the following snippet several times shows random numbers in the `send_device_incarnation` of last device which looks like uninitialized memory read. @dave-andersen would know if it's still a priority to get rid of such reads\n\n```\nimport tensorflow as tf\n\nconfig = tf.ConfigProto(device_count={\"CPU\": 3},\n                    inter_op_parallelism_threads=3,\n                    intra_op_parallelism_threads=1)\nwith tf.device(\"cpu:0\"):\n    a = tf.ones(())\nwith tf.device(\"cpu:1\"):\n    b = tf.ones(())\nwith tf.device(\"cpu:2\"):\n    c = a+b\n\nsess = tf.Session(config=config)\nrun_options = options=tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE,\n                                    output_partition_graphs=True)\nrun_metadata = tf.RunMetadata()\nsess.run(c, options=run_options, run_metadata=run_metadata)\nprint(str(run_metadata))\n\n```\n\nThis shows something like this\n\n```\n    attr {\n      key: \"send_device_incarnation\"\n      value {\n        i: -1672352343731902606\n      }\n    }\n    attr {\n      key: \"tensor_name\"\n      value {\n        s: \"add:0\"\n      }\n    }\n  }\n  versions {\n    producer: 15\n  }\n}\n\n```\n", "comments": ["Thanks for the report @yaroslavvb .\n\nOn further investigation, I don't think this is uninitialized memory but rather an intentional random number. This number is initialized to a random value when a [`Device` object is constructed](https://github.com/tensorflow/tensorflow/blob/754048a0453a04a761e112ae5d99c149eb9910dd/tensorflow/core/common_runtime/device.cc#L43) .\n\nClosing this out. Feel free to re-open/file a new issue if you think there still is a problem.\n\nThanks!\n"]}, {"number": 4992, "title": "Deprecated the `is_training` argument in vgg.py.", "body": "This fixes #4887.\n", "comments": ["@haosdent, thanks for your PR! By analyzing the history of the files in this pull request, we identified @nathansilberman, @sguada and @lukaszkaiser to be potential reviewers.\n", "Can one of the admins verify this patch?\n", "Hi, @jart May you help to review this, thank you in advance.\n", "Actually I think it is actually better to let the is_training argument as part of the network, see \nhttps://github.com/tensorflow/models/tree/master/slim/nets which have unified API and would be merge soon into tf.contrib\n", "Thanks @sguada and @jart I think we should discard this pull request, right?\n"]}, {"number": 4991, "title": "E tensorflow/core/framework/op_kernel.cc:925] unknown op: Round", "body": "Hi, sorry I am a bit new to Tensorflow and could not find this error anywhere else.\nMy system is:\nUbuntu 14.04.5 LTS\nCUDA 8.0.44 cuDNN 5.1 on Titan X Pascal\n\n```\n-rw-r--r-- 1 root root   558720 Oct 15 18:04 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Oct 15 18:04 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.8.0\nlrwxrwxrwx 1 root root       19 Oct 15 18:04 /usr/local/cuda/lib64/libcudart.so.8.0 -> libcudart.so.8.0.44\n-rwxr-xr-x 1 root root   415432 Oct 15 18:04 /usr/local/cuda/lib64/libcudart.so.8.0.44\n-rw-r--r-- 1 root root   775162 Oct 15 18:04 /usr/local/cuda/lib64/libcudart_static.a\nlrwxrwxrwx 1 root root       13 Oct 15 23:51 /usr/local/cuda/lib64/libcudnn.so -> libcudnn.so.5\nlrwxrwxrwx 1 root root       17 Oct 15 23:51 /usr/local/cuda/lib64/libcudnn.so.5 -> libcudnn.so.5.1.5\n-rwxr-xr-x 1 root root 79337624 Oct 15 18:24 /usr/local/cuda/lib64/libcudnn.so.5.1.5\n-rw-r--r-- 1 root root 69756172 Oct 15 18:24 /usr/local/cuda/lib64/libcudnn_static.a\n```\n\nTensorflow 0.11(f794cd393b1e7821fcc3cdcee9b6a4400f2540bf)\nBazel  0.3.2\n\nMy problem is:\n\n```\nimport tensorflow as tf\nI tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:116] successfully opened CUDA library libcurand.so.8.0 locally\nsess = tf.Session()\na = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 3], name='a')\nb = tf.matmul(a, a)\nprint sess.run(b)\nE tensorflow/core/framework/op_kernel.cc:925] OpKernel ('op: \"Round\" device_type: \"GPU\" constraint { name: \"T\" allowed_values { list { type: DT_INT64 } } }') for unknown op: Round\nE tensorflow/core/framework/op_kernel.cc:925] OpKernel ('op: \"Round\" device_type: \"GPU\" constraint { name: \"T\" allowed_values { list { type: DT_INT32 } } }') for unknown op: Round\nE tensorflow/core/framework/op_kernel.cc:925] OpKernel ('op: \"Round\" device_type: \"GPU\" constraint { name: \"T\" allowed_values { list { type: DT_DOUBLE } } }') for unknown op: Round\nE tensorflow/core/framework/op_kernel.cc:925] OpKernel ('op: \"Round\" device_type: \"GPU\" constraint { name: \"T\" allowed_values { list { type: DT_FLOAT } } }') for unknown op: Round\nE tensorflow/core/framework/op_kernel.cc:925] OpKernel ('op: \"Round\" device_type: \"GPU\" constraint { name: \"T\" allowed_values { list { type: DT_HALF } } }') for unknown op: Round\nE tensorflow/core/framework/op_kernel.cc:925] OpKernel ('op: \"Round\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_INT64 } } }') for unknown op: Round\nE tensorflow/core/framework/op_kernel.cc:925] OpKernel ('op: \"Round\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_INT32 } } }') for unknown op: Round\nE tensorflow/core/framework/op_kernel.cc:925] OpKernel ('op: \"Round\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_DOUBLE } } }') for unknown op: Round\nE tensorflow/core/framework/op_kernel.cc:925] OpKernel ('op: \"Round\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_FLOAT } } }') for unknown op: Round\nE tensorflow/core/framework/op_kernel.cc:925] OpKernel ('op: \"Round\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_HALF } } }') for unknown op: Round\n[[ 27.  30.  33.]\n [ 60.  69.  78.]\n [ 66.  78.  90.]]\n```\n\nThis error only comes up once, could you please guide me on what is going on here?\n\nThank you!\n", "comments": ["I also meet this problem. And my system is Ubuntu 16.04. Have you fixed this problem?\n", "I have the same issue on Arch Linux.\n", "Same here. The tensorflow example seems to work, but it doesn't seem to use the card. I am using an AWS p2.xlarge machine (K80). The same installation on a p2.8xlarge machine (8 x K80) works perfectly.\n", "+1 on OS X\n", "This is a benign, albeit annoying error.\nI'm guessing this is happening to you when you build tensorflow from sources and not the release versions?\n\nAnyway, this should be fixed by commit 221a9154e64070d7dbdc7f4cea8cf4a3620c9a9c, which will get merged in with PR #5013.\n", "FYI, we're investigating issues with the build that prevents this from being merged.\n", "This ended up in PR #5054 which has been merged and this error should stop appearing.\nDo file a new issue/re-open this if it didn't get fixe.\n\nThanks!\n"]}, {"number": 4990, "title": "Update README.md", "body": "1st push here\n", "comments": ["@biomassives, thanks for your PR! By analyzing the history of the files in this pull request, we identified @keveman, @vrv and @ebrevdo to be potential reviewers.\n", "Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n"]}, {"number": 4989, "title": "Fail to load user op compiled by bazel with gcc 6", "body": "User op built by bazel with gcc >=5 could not be loaded in python. Hope there is a solution to pass g++ config to bazel.\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\n\n[#2455 Adding a New Op Error: can not load the customed file](https://github.com/tensorflow/tensorflow/issues/2455)\n[Custom new operation in Tensorflow results in exception 'pointer being freed was not allocated'](http://stackoverflow.com/questions/38048266/custom-new-operation-in-tensorflow-results-in-exception-pointer-being-freed-was)\n### Environment info\n\nOperating System: macOS 10.12\n\nIf installed from source, provide \n1. The commit hash (`git rev-parse HEAD`)\n\n73b01567d68d4639d2329deb335ddfcd9c04f87c\n1. The output of `bazel version`\n\n```\nBuild label: 0.3.1-homebrew\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Thu Aug 4 09:58:27 2016 (1470304707)\nBuild timestamp: 1470304707\nBuild timestamp as int: 1470304707\n```\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\n\nzero_out.cc:\n\n```\n#include \"tensorflow/core/framework/op.h\"\n#include \"tensorflow/core/framework/op_kernel.h\"\n\nusing namespace tensorflow;\n\nREGISTER_OP(\"ZeroOut\")\n    .Input(\"to_zero: int32\")\n    .Output(\"zeroed: int32\");\n\nclass ZeroOutOp : public OpKernel {\n public:\n  explicit ZeroOutOp(OpKernelConstruction* context) : OpKernel(context) {}\n\n  void Compute(OpKernelContext* context) override {\n    // Grab the input tensor\n    const Tensor& input_tensor = context->input(0);\n    auto input = input_tensor.flat<int32>();\n\n    // Create an output tensor\n    Tensor* output_tensor = NULL;\n    OP_REQUIRES_OK(context, context->allocate_output(0, input_tensor.shape(),\n                                                     &output_tensor));\n    auto output = output_tensor->flat<int32>();\n\n    // Set all but the first element of the output tensor to 0.\n    const int N = input.size();\n    for (int i = 1; i < N; i++) {\n      output(i) = 0;\n    }\n\n    // Preserve the first input value if possible.\n    if (N > 0) output(0) = input(0);\n  }\n};\n\nREGISTER_KERNEL_BUILDER(Name(\"ZeroOut\").Device(DEVICE_CPU), ZeroOutOp);\n```\n\nBUILD\n\n```\nload(\"//tensorflow:tensorflow.bzl\", \"tf_custom_op_library\")\n\ntf_custom_op_library(\n    name = \"zero_out.so\",\n    srcs = [\"zero_out.cc\"]\n)\n```\n\nrun:\n\n```\nbazel build -c opt //tensorflow/core/user_ops:zero_out.so\n```\n\nthen load the lib from python:\n\n```\n>>> import tensorflow as tf\n>>> tf.load_op_library('zero_out.so')\npython(61257,0x7fffb7e123c0) malloc: *** error for object 0x7fa5fcb46028: pointer being freed was not allocated\n*** set a breakpoint in malloc_error_break to debug\n```\n### What other attempted solutions have you tried?\n\nFirstly, I tried to rebuild it with g++, with the option of `-D_GLIBCXX_USE_CXX11_ABI=0` mentioned in the tutorial:\n\n```\ng++ -v -std=c++11 -shared zero_out.cc -o zero_out.so -fPIC -I $TF_INC -O2 -undefined dynamic_lookup -D_GLIBCXX_USE_CXX11_ABI=0\n```\n\nit works.\n\nThen, I tried to add this option to bazel:\n\n```\nbazel build --copt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" -c opt //tensorflow/core/user_ops:zero_out.so\n```\n\nthe problem is still there.\n### Logs or other output that would be helpful\n\n[bazel log](https://gist.github.com/tongda/b9b7c17c9d574669a0925e5606d9aa23)\n", "comments": ["@keveman could you help out this gentleman who's getting a pointer free() error when calling `tf.load_op_library()`?\n", "@tongda I don't have a machine with gcc6 handy. But meanwhile, can you post the output of\n\n```\n$ bazel build -s --copt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" -c opt //tensorflow/core/user_ops:zero_out.so\n```\n\nI wanted to make sure that `-D_GLIBCXX_USE_CXX11_ABI=0` is really being used.\n", "@keveman the output is as follows:\n\n```\nINFO: Found 1 target...\n>>>>> # //tensorflow/core/user_ops:zero_out.so [action 'Creating runfiles tree bazel-out/local-py3-opt/bin/tensorflow/core/user_ops/zero_out.so.runfiles']\n(cd /private/var/tmp/_bazel_dtong/ed93ba28e6cbe33f12d58f73f06ca5d0/execroot/tensorflow && \\\n  exec env - \\\n    PATH=/Users/dtong/.virtualenvs/tensorflow/bin:/Users/dtong/code/scala/activator-dist-1.3.10/bin:/Users/dtong/.nodenv/shims:/Users/dtong/.pyenv/shims:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin \\\n    TMPDIR=/var/folders/zp/dz_k9jps25g03l5thtv4lhc40000gn/T/ \\\n  /private/var/tmp/_bazel_dtong/ed93ba28e6cbe33f12d58f73f06ca5d0/execroot/tensorflow/_bin/build-runfiles bazel-out/local-py3-opt/bin/tensorflow/core/user_ops/zero_out.so.runfiles_manifest bazel-out/local-py3-opt/bin/tensorflow/core/user_ops/zero_out.so.runfiles)\n>>>>> # //tensorflow/core/user_ops:zero_out.so [action 'Compiling tensorflow/core/user_ops/zero_out.cc']\n(cd /private/var/tmp/_bazel_dtong/ed93ba28e6cbe33f12d58f73f06ca5d0/execroot/tensorflow && \\\n  exec env - \\\n    PATH=/Users/dtong/.virtualenvs/tensorflow/bin:/Users/dtong/code/scala/activator-dist-1.3.10/bin:/Users/dtong/.nodenv/shims:/Users/dtong/.pyenv/shims:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin \\\n    TMPDIR=/var/folders/zp/dz_k9jps25g03l5thtv4lhc40000gn/T/ \\\n  external/local_config_cc/cc_wrapper.sh -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wthread-safety -Wself-assign -fcolor-diagnostics -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections '-D_GLIBCXX_USE_CXX11_ABI=0' '-std=c++0x' -MD -MF bazel-out/local-py3-opt/bin/tensorflow/core/user_ops/_objs/zero_out.so/tensorflow/core/user_ops/zero_out.pic.d '-frandom-seed=bazel-out/local-py3-opt/bin/tensorflow/core/user_ops/_objs/zero_out.so/tensorflow/core/user_ops/zero_out.pic.o' -fPIC -DEIGEN_MPL2_ONLY -iquote . -iquote bazel-out/local-py3-opt/genfiles -iquote external/protobuf -iquote bazel-out/local-py3-opt/genfiles/external/protobuf -iquote external/bazel_tools -iquote bazel-out/local-py3-opt/genfiles/external/bazel_tools -iquote external/eigen_archive -iquote bazel-out/local-py3-opt/genfiles/external/eigen_archive -isystem external/protobuf/src -isystem bazel-out/local-py3-opt/genfiles/external/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -isystem external/eigen_archive -isystem bazel-out/local-py3-opt/genfiles/external/eigen_archive -fno-exceptions -DEIGEN_AVOID_STL_ARRAY -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -c tensorflow/core/user_ops/zero_out.cc -o bazel-out/local-py3-opt/bin/tensorflow/core/user_ops/_objs/zero_out.so/tensorflow/core/user_ops/zero_out.pic.o)\n>>>>> # //tensorflow/core/user_ops:zero_out.so [action 'Linking tensorflow/core/user_ops/zero_out.so']\n(cd /private/var/tmp/_bazel_dtong/ed93ba28e6cbe33f12d58f73f06ca5d0/execroot/tensorflow && \\\n  exec env - \\\n  external/local_config_cc/cc_wrapper.sh -shared -o bazel-out/local-py3-opt/bin/tensorflow/core/user_ops/zero_out.so -Wl,-all_load bazel-out/local-py3-opt/bin/tensorflow/core/user_ops/_objs/zero_out.so/tensorflow/core/user_ops/zero_out.pic.o bazel-out/local-py3-opt/bin/external/protobuf/libprotobuf.pic.a bazel-out/local-py3-opt/bin/external/protobuf/libprotobuf_lite.pic.a '' -lpthread -lstdc++ -lm -undefined dynamic_lookup -headerpad_max_install_names)\nTarget //tensorflow/core/user_ops:zero_out.so up-to-date:\n  bazel-bin/tensorflow/core/user_ops/zero_out.so\nINFO: Elapsed time: 7.742s, Critical Path: 2.75s\n```\n\nWell, I am so embarrassed that this time, the generated `zero_out.so` could be properly loaded in python. It seems weird. I will keep updated if something happens. Sorry to bother you guys.\n", "The `.so` should be loadable if you indeed pass `-D_GLIBCXX_USE_CXX11_ABI=0`, which I see in the flags passed to the compiler. Thanks for verifying, and feel free to reopen in case you have this issue again.\n", "@tongda @keveman : \nIts not working for me. I indeed used -D_GLIBCXX_USE_CXX11_ABI=0, it indeed showed up in the build command with -s. But it is still not loading without absolute path.\n", "@singlasahil14 I am a little confused. Do you mean that the `.so` file could be properly loaded with absolute path, while it could NOT be loaded with relative path?\n", "@tongda : Yes, that's exactly what I meant.\n", "@singlasahil14 Well, I am afraid that loading `.so` lib require using absolute path, except the lib is in the current directory."]}, {"number": 4988, "title": "Error building tensorflow from source", "body": "Getting below error while building tensorflow from source.  \n\n$ sudo bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\n\n/home/jenisha/.cache/bazel/_bazel_root/d76a8cba20478b6f06262b0e7e986df4/external/nanopb_git/BUILD:6:1: undeclared inclusion(s) in rule '@nanopb_git//:nanopb':\nthis rule is missing dependency declarations for the following files included by 'external/nanopb_git/pb_common.c':\n  '/usr/include/stdc-predef.h'\n  '/usr/lib/gcc/x86_64-linux-gnu/4.8/include/stdint.h'\n  '/usr/include/stdint.h'\n  '/usr/include/features.h'\n  '/usr/include/x86_64-linux-gnu/sys/cdefs.h'\n  '/usr/include/x86_64-linux-gnu/bits/wordsize.h'\n  '/usr/include/x86_64-linux-gnu/gnu/stubs.h'\n  '/usr/include/x86_64-linux-gnu/gnu/stubs-64.h'\n  '/usr/include/x86_64-linux-gnu/bits/wchar.h'\n  '/usr/lib/gcc/x86_64-linux-gnu/4.8/include/stddef.h'\n  '/usr/lib/gcc/x86_64-linux-gnu/4.8/include/stdbool.h'\n  '/usr/include/string.h'\n  '/usr/include/xlocale.h'\n  '/usr/include/x86_64-linux-gnu/bits/string.h'\n  '/usr/include/x86_64-linux-gnu/bits/string2.h'\n  '/usr/include/endian.h'\n  '/usr/include/x86_64-linux-gnu/bits/endian.h'\n  '/usr/include/x86_64-linux-gnu/bits/byteswap.h'\n  '/usr/include/x86_64-linux-gnu/bits/types.h'\n  '/usr/include/x86_64-linux-gnu/bits/typesizes.h'\n  '/usr/include/x86_64-linux-gnu/bits/byteswap-16.h'\n  '/usr/include/stdlib.h'\n  '/usr/include/x86_64-linux-gnu/bits/string3.h'.\n", "comments": ["What's your config? CUDA and cuDNN version? Your OS version? @joyjeni \n", "Cuda 8.0 , Cudann 5.1, Ubuntu 16.04 \n", "@joyjeni We have hit the same issue. As I was told, support for CUDA 8.0 will come officially in TensorFlow version 0.11rc1. Referencing my issue #4841 .\n", "@joyjeni : I'm having trouble reproducing your error and from the snippet above, it doesn't appear to be CUDA related. Do you get the same error when building for CPU only? (using `bazel build -c opt //tensorflow/tools/pip_package:build_pip_package`).\n\nPlease include all the information requested for in the [\"New Issue\" template](https://github.com/tensorflow/tensorflow/issues/new), as that would help in diagnosing the problem. (And in the future, please do fill in the template when filing issues).\n", "[installtf.pdf](https://github.com/tensorflow/tensorflow/files/537691/installtf.pdf)\n\nAttached list of steps followed while building tensorflow from source\n", "Do you get the same error when building for CPU only?\nCan you run bazel with `--verbose_failures` to get more insight into the failing command?\n", "Yes with CPU also I get error.\n\nERROR: /home/jenisha/.cache/bazel/_bazel_jenisha/09415e5fa53b65f11f76c6af77c3c91f/external/local_config_cuda/crosstool/BUILD:4:1: Traceback (most recent call last):\n    File \"/home/jenisha/.cache/bazel/_bazel_jenisha/09415e5fa53b65f11f76c6af77c3c91f/external/local_config_cuda/crosstool/BUILD\", line 4\n        error_gpu_disabled()\n    File \"/home/jenisha/.cache/bazel/_bazel_jenisha/09415e5fa53b65f11f76c6af77c3c91f/external/local_config_cuda/crosstool/error_gpu_disabled.bzl\", line 3, in error_gpu_disabled\n        fail(\"ERROR: Building with --config=c...\")\nERROR: Building with --config=cuda but TensorFlow is not configured to build with GPU support. Please re-run ./configure and enter 'Y' at the prompt to build with GPU support.\nUnhandled exception thrown during build; message: Unrecoverable error while evaluating node 'CONFIGURATION_FRAGMENT:com.google.devtools.build.lib.skyframe.ConfigurationFragmentValue$ConfigurationFragmentKey@2abbbba' (requested by nodes 'CONFIGURATION_COLLECTION:com.google.devtools.build.lib.skyframe.ConfigurationCollectionValue$ConfigurationCollectionKey@1764fa10', 'CONFIGURATION_FRAGMENT:com.google.devtools.build.lib.skyframe.ConfigurationFragmentValue$ConfigurationFragmentKey@253fcc46', 'CONFIGURATION_FRAGMENT:com.google.devtools.build.lib.skyframe.ConfigurationFragmentValue$ConfigurationFragmentKey@ee578016')\nINFO: Elapsed time: 1.400s\njava.lang.RuntimeException: Unrecoverable error while evaluating node 'CONFIGURATION_FRAGMENT:com.google.devtools.build.lib.skyframe.ConfigurationFragmentValue$ConfigurationFragmentKey@2abbbba' (requested by nodes 'CONFIGURATION_COLLECTION:com.google.devtools.build.lib.skyframe.ConfigurationCollectionValue$ConfigurationCollectionKey@1764fa10', 'CONFIGURATION_FRAGMENT:com.google.devtools.build.lib.skyframe.ConfigurationFragmentValue$ConfigurationFragmentKey@253fcc46', 'CONFIGURATION_FRAGMENT:com.google.devtools.build.lib.skyframe.ConfigurationFragmentValue$ConfigurationFragmentKey@ee578016')\n    at com.google.devtools.build.skyframe.ParallelEvaluator$Evaluate.run(ParallelEvaluator.java:1070)\n    at com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$WrappedRunnable.run(AbstractQueueVisitor.java:474)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.IllegalStateException: com.google.devtools.build.lib.packages.NoSuchTargetException: no such target '@local_config_cuda//crosstool:toolchain': target 'toolchain' not declared in package 'crosstool' defined by /home/jenisha/.cache/bazel/_bazel_jenisha/09415e5fa53b65f11f76c6af77c3c91f/external/local_config_cuda/crosstool/BUILD\n    at com.google.devtools.build.lib.rules.cpp.CrosstoolConfigurationLoader.getCrosstoolProtofromBuildFile(CrosstoolConfigurationLoader.java:179)\n    at com.google.devtools.build.lib.rules.cpp.CrosstoolConfigurationLoader.findCrosstoolConfiguration(CrosstoolConfigurationLoader.java:239)\n    at com.google.devtools.build.lib.rules.cpp.CrosstoolConfigurationLoader.readCrosstool(CrosstoolConfigurationLoader.java:281)\n    at com.google.devtools.build.lib.rules.cpp.CppConfigurationLoader.createParameters(CppConfigurationLoader.java:128)\n    at com.google.devtools.build.lib.rules.cpp.CppConfigurationLoader.create(CppConfigurationLoader.java:73)\n    at com.google.devtools.build.lib.rules.cpp.CppConfigurationLoader.create(CppConfigurationLoader.java:48)\n    at com.google.devtools.build.lib.skyframe.ConfigurationFragmentFunction.compute(ConfigurationFragmentFunction.java:78)\n    at com.google.devtools.build.skyframe.ParallelEvaluator$Evaluate.run(ParallelEvaluator.java:1016)\n    ... 4 more\nCaused by: com.google.devtools.build.lib.packages.NoSuchTargetException: no such target '@local_config_cuda//crosstool:toolchain': target 'toolchain' not declared in package 'crosstool' defined by /home/jenisha/.cache/bazel/_bazel_jenisha/09415e5fa53b65f11f76c6af77c3c91f/external/local_config_cuda/crosstool/BUILD\n    at com.google.devtools.build.lib.packages.Package.makeNoSuchTargetException(Package.java:559)\n    at com.google.devtools.build.lib.packages.Package.getTarget(Package.java:543)\n    at com.google.devtools.build.lib.skyframe.SkyframePackageLoaderWithValueEnvironment.getTarget(SkyframePackageLoaderWithValueEnvironment.java:71)\n    at com.google.devtools.build.lib.skyframe.ConfigurationFragmentFunction$ConfigurationBuilderEnvironment.getTarget(ConfigurationFragmentFunction.java:193)\n    at com.google.devtools.build.lib.rules.cpp.CrosstoolConfigurationLoader.getCrosstoolProtofromBuildFile(CrosstoolConfigurationLoader.java:177)\n    ... 11 more\njava.lang.RuntimeException: Unrecoverable error while evaluating node 'CONFIGURATION_FRAGMENT:com.google.devtools.build.lib.skyframe.ConfigurationFragmentValue$ConfigurationFragmentKey@2abbbba' (requested by nodes 'CONFIGURATION_COLLECTION:com.google.devtools.build.lib.skyframe.ConfigurationCollectionValue$ConfigurationCollectionKey@1764fa10', 'CONFIGURATION_FRAGMENT:com.google.devtools.build.lib.skyframe.ConfigurationFragmentValue$ConfigurationFragmentKey@253fcc46', 'CONFIGURATION_FRAGMENT:com.google.devtools.build.lib.skyframe.ConfigurationFragmentValue$ConfigurationFragmentKey@ee578016')\n    at com.google.devtools.build.skyframe.ParallelEvaluator$Evaluate.run(ParallelEvaluator.java:1070)\n    at com.google.devtools.build.lib.concurrent.AbstractQueueVisitor$WrappedRunnable.run(AbstractQueueVisitor.java:474)\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)\n    at java.lang.Thread.run(Thread.java:745)\nCaused by: java.lang.IllegalStateException: com.google.devtools.build.lib.packages.NoSuchTargetException: no such target '@local_config_cuda//crosstool:toolchain': target 'toolchain' not declared in package 'crosstool' defined by /home/jenisha/.cache/bazel/_bazel_jenisha/09415e5fa53b65f11f76c6af77c3c91f/external/local_config_cuda/crosstool/BUILD\n    at com.google.devtools.build.lib.rules.cpp.CrosstoolConfigurationLoader.getCrosstoolProtofromBuildFile(CrosstoolConfigurationLoader.java:179)\n    at com.google.devtools.build.lib.rules.cpp.CrosstoolConfigurationLoader.findCrosstoolConfiguration(CrosstoolConfigurationLoader.java:239)\n    at com.google.devtools.build.lib.rules.cpp.CrosstoolConfigurationLoader.readCrosstool(CrosstoolConfigurationLoader.java:281)\n    at com.google.devtools.build.lib.rules.cpp.CppConfigurationLoader.createParameters(CppConfigurationLoader.java:128)\n    at com.google.devtools.build.lib.rules.cpp.CppConfigurationLoader.create(CppConfigurationLoader.java:73)\n    at com.google.devtools.build.lib.rules.cpp.CppConfigurationLoader.create(CppConfigurationLoader.java:48)\n    at com.google.devtools.build.lib.skyframe.ConfigurationFragmentFunction.compute(ConfigurationFragmentFunction.java:78)\n    at com.google.devtools.build.skyframe.ParallelEvaluator$Evaluate.run(ParallelEvaluator.java:1016)\n    ... 4 more\nCaused by: com.google.devtools.build.lib.packages.NoSuchTargetException: no such target '@local_config_cuda//crosstool:toolchain': target 'toolchain' not declared in package 'crosstool' defined by /home/jenisha/.cache/bazel/_bazel_jenisha/09415e5fa53b65f11f76c6af77c3c91f/external/local_config_cuda/crosstool/BUILD\n    at com.google.devtools.build.lib.packages.Package.makeNoSuchTargetException(Package.java:559)\n    at com.google.devtools.build.lib.packages.Package.getTarget(Package.java:543)\n    at com.google.devtools.build.lib.skyframe.SkyframePackageLoaderWithValueEnvironment.getTarget(SkyframePackageLoaderWithValueEnvironment.java:71)\n    at com.google.devtools.build.lib.skyframe.ConfigurationFragmentFunction$ConfigurationBuilderEnvironment.getTarget(ConfigurationFragmentFunction.java:193)\n    at com.google.devtools.build.lib.rules.cpp.CrosstoolConfigurationLoader.getCrosstoolProtofromBuildFile(CrosstoolConfigurationLoader.java:177)\n    ... 11 more\n", "That seems to be a different error, see the error log message:\n`ERROR: Building with --config=cuda but TensorFlow is not configured to build with GPU support. Please re-run ./configure and enter 'Y' at the prompt to build with GPU support.`\n\nWhen building for CPU, please re-run `./configure` and do not use `--config=cuda`\n", "It's taking more than 5 hours to build. I will not build from source again will continue with binary. \n", "Seems like there is something specific about your environment which we cannot get to the bottom of.\n\nHopefully the binary installation works for you.\n\nIf you do need to install from source and run into trouble again, please do file a new issue with as much information about your specific environment as you can provide. Thanks.\n", "What's your bazel version, @joyjeni ?\n", "Build label: 0.3.1\n", "Will you please try re-installing it? I got rid of those Java errors when I re-installed it / upgraded it (can't remember which one was it though) @joyjeni \n"]}, {"number": 4987, "title": "Feature request: dropout with noise_shape does not support varied batchsize", "body": "Since it's convenient to support varied batchsize in tf.placeholder by setting the head element of argument \"shape\" to None, tf.nn.dropout does not allow None in its argument \"noise_shape\", leading to models using dropout with noise_shape cumbersome to implement varied batchsize.  I wonder is it possible to allow None in noise_shape for better support for varied batchsize? Thank you!\n", "comments": ["@ebrevdo : Any thoughts?\n", "Noise shape may be a Tensor where any of the dimensions are not known at graph build time; i.e., you can have noise_shape = tf.Placeholder(dtype=tf.int32, shape=None)  ... or shape=[None, 3, 4])  ... or:\n\nbatch_size = tf.Placeholder(tf.int32, shape=())\nnoise_shape = tf.concat(0, [batch_size] + remaining_shape)\n", "or you can even do:\n\nbatch_size = tf.shape(input)[0]\nnoise_shape = tf.concat(0, [noise_shape] + remaining_shape)\n"]}, {"number": 4986, "title": "Add data_format option to convolution2d_transpose", "body": "Add `data_format` option to `convolution2d_transpose`. \n", "comments": ["Can one of the admins verify this patch?\n", "@thuyen, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener, @keveman and @zhangyaobit to be potential reviewers.\n", "@zhangyaobit Could you have a look? :)\n", "@zhangyaobit Just updated the request with your suggestions. \n", "@zhangyaobit Tests are added and have passed locally. One weird thing for `kernel_tests/conv2d_transpose_test.py` is that if I keep `tf.nn.conv2d_transpose` inside `self.test_session` (like the way tests are done for `NHWC` data format), `tensorflow` will call the `CPU` op instead of `GPU` op. Could you explain why?\n", "Jenkins, test this please.\n", "Linux CPU Tests failed. NCHW is not supported yet for conv2d_transpose :(\n\nhttps://ci.tensorflow.org/job/tensorflow-pull-requests-cpu/2217/console\n", "GPU NCHW support seems to be there; you may just need to add is_gpu_available() in your test.\n", "Yeah, that error is in CPU op. Just narrowed the `layers_test` for `conv2d_transpose` on GPU only for `NCHW` data format. \n", "Jenkins, test this please.\n", "Can you test this again @zhangyaobit. Sorry I missed one test in previous commit. \n", "Jenkins, test this please.\n", "Fails on Mac with this:\n\n## FAIL: testEarlyDominatesBootstrap (**main**.FinishedNodesTest)\n\nTraceback (most recent call last):\n  File \"/private/var/tmp/_bazel_jenkins/13e370a18c169b19baeafefb05212b85/execroot/tensorflow-pull-requests-mac/bazel-out/local-opt/bin/tensorflow/contrib/tensor_forest/finished_nodes_op_test.runfiles/org_tensorflow/tensorflow/contrib/tensor_forest/python/kernel_tests/finished_nodes_op_test.py\", line 141, in testEarlyDominatesBootstrap\n    self.assertAllEqual([4], finished.eval())\n  File \"/private/var/tmp/_bazel_jenkins/13e370a18c169b19baeafefb05212b85/execroot/tensorflow-pull-requests-mac/bazel-out/local-opt/bin/tensorflow/contrib/tensor_forest/finished_nodes_op_test.runfiles/org_tensorflow/tensorflow/python/framework/test_util.py\", line 482, in assertAllEqual\n    \"Shape mismatch: expected %s, got %s.\" % (a.shape, b.shape))\nAssertionError: Shape mismatch: expected (1,), got (2,).\n\nCould you look into this?\n", "It seems unrelated to this pull request I guess. We didn't touch anything that could possibly affect tensor_forest.\n", "All tests have passed now. @drpngx Do you know why I one failed on Mac before?\n"]}, {"number": 4985, "title": "Issue 4746", "body": "https://github.com/tensorflow/tensorflow/issues/4746\n\nThis code is the first commit to fix issue-4746 . I will commit the unit test code and doc later.\nThank you for your review . Thank you for any advice.I will work on it again for the advice and learn from the reviewers. \n\nI test this code with:\n\n```\nx_image = tf.placeholder(tf.float32,shape=[4,4])\nx = tf.reshape(x_image,[1,4,4,1])\n\nksize_feed = np.array([1,2,2,1])\n\nksize_init = tf.placeholder(tf.int32, shape=[4])\nksize0 = tf.reshape(ksize_init,[2,2])\nksize1 = tf.reshape(ksize0,[1,2,2,1])\n\nstrides=[1,2,2,1]\npadding = 'VALID'\n\ny = tf.nn.max_pool(value=x,ksize=ksize1,strides=strides,padding=padding)\n\nx_data = np.array([[4,3,1,8],[7,2,6,3],[2,0,1,1],[3,4,2,5]],\n            dtype = np.float32)\n\nwith tf.Session() as sess:\n    init = tf.initialize_all_variables()\n    sess.run(init)\n\n    x = (sess.run(x,feed_dict={x_image:x_data}))\n    y = (sess.run(y,feed_dict={x_image:x_data,ksize_init:ksize_feed}))\n\n    print \"The shape of x:\\t\", x.shape, \",\\t and the x.reshpe(4,4) is :\"\n    print x.reshape(4,4)\n    print \"\"\n\n    print \"The shape of y:\\t\", y.shape, \",\\t and the y.reshpe(2,2) is :\"\n    print y.reshape(2,2)\n    print \"\"\n```\n", "comments": ["Can one of the admins verify this patch?\n", "@guotong1988, thanks for your PR! By analyzing the history of the files in this pull request, we identified @vrv, @keveman and @zheng-xq to be potential reviewers.\n", "also test the code with:\n\n```\nimport numpy as np\nimport tensorflow as tf\n\nx_image = tf.placeholder(tf.float32,shape=[4,4])\nx = tf.reshape(x_image,[1,4,4,1])\n\nksize = np.array([1,2,2,1])\n\nstrides=[1,2,2,1]\npadding = 'VALID'\n\ny = tf.nn.max_pool(value=x,ksize=ksize,strides=strides,padding=padding)\n\nx_data = np.array([[4,3,1,8],[7,2,6,3],[2,0,1,1],[3,4,2,5]],\n            dtype = np.float32)\n\nwith tf.Session() as sess:\n    init = tf.initialize_all_variables()\n    sess.run(init)\n\n    x = (sess.run(x,feed_dict={x_image:x_data}))\n    y = (sess.run(y,feed_dict={x_image:x_data}))\n\n    print \"The shape of x:\\t\", x.shape, \",\\t and the x.reshpe(4,4) is :\"\n    print x.reshape(4,4)\n    print \"\"\n\n    print \"The shape of y:\\t\", y.shape, \",\\t and the y.reshpe(2,2) is :\"\n    print y.reshape(2,2)\n    print \"\"\n```\n", "Unfortunately, modifying an existing op like this breaks the backward compatiblity of TensorFlow. \n\nFor now, it is a good idea to add a custom op on github outside TensorFlow, so people can try it if they are interested. When it gets popular and used in more models, we can move it to TF contrib or TF core. \n\nhttps://www.tensorflow.org/versions/r0.11/how_tos/adding_an_op/index.html\n\nThanks.\n", "OK , I will take another issue.\n", "Thanks for looking into this! I'll close the PR. Feel free to reopen if appropriate.\n"]}, {"number": 4984, "title": "gcc: error trying to exec 'as': execvp: No such file or directory", "body": "I think the problem is that `as` wasn't installed with `gcc` and thus `gcc -print-prog-name=as` just prints `as`. `as` is in my path, but not in the same location as `gcc`.\n\n```\n$ which gcc\n/appl/gcc/4.9.2/bin/gcc\n$ which as\n/appl/binutils/2.25.1/bin/as\n```\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\n\nthere are a couple:\n- gcc: error trying to exec 'as': execvp: No such file or directory: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=40339\n- gcc: error trying to exec 'as': execvp: No such file or directory https://decibel.ni.com/content/thread/39592\n- Building TensorFlow with custom GCC requires hardcoded ld,nm and as https://github.com/bazelbuild/bazel/issues/1713 \u2013 I tried setting `build --action_env=PATH`, but that did change anything.\n### Environment info\n\nOperating System:\n\n```\n$ uname -a\nLinux n-62-18-47 2.6.32-573.22.1.el6.x86_64 #1 SMP Tue Mar 22 17:15:28 CDT 2016 x86_64 x86_64 x86_64 GNU/Linux \n```\n\nInstalled version of CUDA and cuDNN: CUDA: 8.0, cuDNN 5.1.5\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\n```\n$  ls -l /appl/cuda/8.0/lib64/libcud*\n-rw-r--r-- 1 sebo root 560184 Sep  1 14:31 /appl/cuda/8.0/lib64/libcudadevrt.a\nlrwxrwxrwx 1 sebo root     16 Sep  1 14:31 /appl/cuda/8.0/lib64/libcudart.so -> libcudart.so.8.0\nlrwxrwxrwx 1 sebo root     19 Sep  1 14:31 /appl/cuda/8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.27\n-rwxr-xr-x 1 sebo root 394472 Sep  1 14:31 /appl/cuda/8.0/lib64/libcudart.so.8.0.27\n-rw-r--r-- 1 sebo root 737516 Sep  1 14:31 /appl/cuda/8.0/lib64/libcudart_static.a\n```\n\nIf installed from source, provide \n1. The commit hash (`git rev-parse HEAD`): `f794cd393b1e7821fcc3cdcee9b6a4400f2540bf`\n2. The output of `bazel version`: \n\n```\n$ bazel --batch version\nINFO: Reading 'startup' options from /zhome/ff/2/77654/.bazelrc: --batch --output_user_root=/work1/s123598/.bazel\nBuild label: 0.3.2-2016-10-13 (@2891ec5)\nBuild target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Thu Oct 13 15:05:25 2016 (1476371125)\nBuild timestamp: 1476371125\nBuild timestamp as int: 1476371125\n```\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\n\n```\n# install tensorflow\ngit clone https://github.com/tensorflow/tensorflow\ncd tensorflow\ncurl -L https://github.com/tensorflow/tensorflow/pull/4983.patch | git am -\n\n# set configuration parameters\nexport PYTHON_BIN_PATH=`which python3` # ~/stdpy3/bin/python3\nexport TF_NEED_GCP=0\nexport TF_NEED_HDFS=0\nexport TF_NEED_CUDA=1\nexport GCC_HOST_COMPILER_PATH=`which gcc` # /appl/gcc/4.9.2/bin/gcc\nexport TF_CUDA_VERSION=8.0\nexport CUDA_TOOLKIT_PATH=/appl/cuda/8.0/\nexport TF_CUDNN_VERSION=5\nexport CUDNN_INSTALL_PATH=$HOME/cuda/ # the cuDNN version provide IT is too old (5.0.4), so I downloaded the latest and unpacked it in $HOME\nexport TF_CUDA_COMPUTE_CAPABILITIES=\"3.5,5.2\"\n\ncat > $HOME/.bazelrc <<EOF\n# --batch: always run in batch mode, since there are some firewall issues.\n# --output_user_root: HOME is NFS (filesystem), this will not work with bazel, use WORKDIR instead\nstartup --batch --output_user_root=$WORKDIR/.bazel\nEOF\n\n# one python configuration can't be set directly use yes to accept automatically\nyes \"\" | CC=gcc CXX=g++ ./configure\n\n# build tensorflow\nCC=gcc CXX=g++ bazel build --copt=\"-w\" \\\n--ignore_unsupported_sandboxing --spawn_strategy=standalone --verbose_failures \\\n-c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\n```\n### What other attempted solutions have you tried?\n- I've tried symlinking gcc and as into the same path, but then cc1 and the gcc header files can't be found.\n- I've tried searching for how bazel or tensorflow finds `as` but I can't find that code.\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment or provide link).\n\nfull log: https://gist.github.com/AndreasMadsen/7bf11dcf5c53981e532f67850e5b2b9b\n\n```\ngcc: error trying to exec 'as': execvp: No such file or directory\nERROR: /zhome/ff/2/77654/tensorflow/tensorflow/contrib/rnn/BUILD:101:1: output 'tensorflow/contrib/rnn/_objs/python/ops/_gru_ops_gpu/tensorflow/contrib/rnn/kernels/gru_ops_gpu.cu.pic.o' was not created.\nERROR: /zhome/ff/2/77654/tensorflow/tensorflow/contrib/rnn/BUILD:101:1: not all outputs were created.\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\nINFO: Elapsed time: 320.454s, Critical Path: 196.64s\n```\n", "comments": ["You appear to be using CentOS 6. If this is not the case, let me know and I'll reopen this issue.\n\nThe operating systems supported  by TensorFlow are:\n- Ubuntu Linux 14.04 LTE\n- Ubuntu Linux 16.04 LTE\n- Mac OS X El Capitan\n- CentOS 7+\n\nFor other OS, please direct the question to [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) and people might be able to help there.\n\nP.S. It might be possible for you to use our contrib make build system for CentOS 6 support.\n\nOther issues similar to this: #4725 #2806.\n", "You might also be able to use Docker, if your system administrator has it installed.\n"]}, {"number": 4983, "title": "use use_default_shell_env for SWIGing action", "body": "When swig is in the PATH but not in a standard bin location, bazel can't\nfind it unless the PATH is propagated.\n\n_I have only spend two days on becoming familiar with tensorflow and bazel, so I could easily be wrong._\n", "comments": ["Can one of the admins verify this patch?\n", "@AndreasMadsen, thanks for your PR! By analyzing the history of the files in this pull request, we identified @keveman, @tensorflower-gardener and @josh11b to be potential reviewers.\n", "If you run `./configure` does it solve the problem? See also: #706\n", "I'm not sure what you mean. If apply this PR and run configure then it fixes the problem. Yes.\n\nI have other compiler problems after this, as described in https://github.com/tensorflow/tensorflow/issues/4984. I have yet to solve those.\n", "The `./configure` script in the root of the TensorFlow repository creates a symlink to the system swig command inside `tensorflow/tools/swig`. The only reason that `tensorflow/tools/swig.sh` would try to run the swig command from the environment is if that symlink doesn't exist. So the solution is most likely to run `./configure`. Could you please confirm if that solves your problem?\n\nI would ideally prefer to not use `use_default_shell_env` because our Bazel build should ideally be hermetically sealed. That's one of the goals I'm working towards. I'm actually working on a change right now that has Bazel fetch the sources for SWIG and compiles it from scratch.\n", "According to #4984 you're using CentOS 6 which isn't in our support matrix. I really appreciate the time you put into sending this pull request. But I'm going to close this issue. I encourage you to send us a pull request adding a check to our `./configure` for `.el6.` in the `uname -a` output that shows:\n\n```\nCentOS 6 is not supported and probably won't work.\nConsider using Docker or trying the tensorflow/contrib/makefile build system.\nWant to continue anyway? [Yn]\n```\n\nThis should hopefully help save time for many people in the future.\n\nAlso I'm going to update this issue when my change is committed regarding SWIG hermeticity.\n", "Also I'll reopen this issue provided new information.\n"]}, {"number": 4982, "title": "Branch 136231860", "body": "", "comments": ["@tensorflow-jenkins test this please\n", "@tensorflow-jenkins test this please\n", "@tensorflow-jenkins test this please\n", "All merged as #5054 \n"]}, {"number": 4981, "title": "FastGFile ResourceExhaustedError", "body": "In https://github.com/tensorflow/models/commit/2390974a03a62b1388a004173477418db267074a @cshallue changed some `tf.gfile.FastGFile()` calls to `open()` because two RedHat users reported in #4685 that it causes ResourceExhaustedError even though resources don't appear to be exhausted.\n\nWe've also had the same issue reported in tensorflow/models#531, tensorflow/models#489, and tensorflow/models#480 but we're still waiting to learn if they're using RedHat.\n\nAssigning to @rohan100jain who has done work on this code in the past.\n", "comments": ["Yeah there was a memory leak by which file handles weren't being closed. Should have been fixed with https://github.com/tensorflow/tensorflow/commit/0f605abad3b30594416dc627860102e3382d6dea#diff-8dc0e318495c91370f8807ef81b589e0\n\nLet me know if this is still an issue\n", "I meet the same issue, but in a different file \n\n**https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/image/imagenet/classify_image.py#L141**\n\nThis example only predict 1 image. if we change this example by using for loop to predict a large number images, it report the same **ResourceExhaustedError** error\n", "@civilmanxx are you building TensorFlow from source with Bazel at HEAD?\n", "yes, but my local code is not the latest version, which does not include a C++ fix (3 days ago? ) for this issue. Now I use **open()** instead of **read()** to avoid this issue.\n\nIf I get the lastest code, rebuild at local and use read() will be no issue anymore, is that right?\n", "As far as we know, the issue goes away if you sync to HEAD and build.\n"]}, {"number": 4980, "title": "Branch 136224169", "body": "", "comments": []}, {"number": 4979, "title": "Revert \"Make tutorial_example_trainer build on Windows with Bazel\"", "body": "Reverts tensorflow/tensorflow#4796\n", "comments": ["@rohan100jain, thanks for your PR! By analyzing the history of the files in this pull request, we identified @meteorcloudy, @jhseu and @josh11b to be potential reviewers.\n"]}, {"number": 4978, "title": "contrib.layers and multigpu: variable scope issues", "body": "I guess, issues regarding stuff in `tf.contrib` working nicely with tensorflow itself are also welcome here? Otherwise, I'll move it to the `tflearn` issue tracker.\n\n**tl;dr**: using contrib.layers in multigpu setting (multiple \"towers\" in separate name scopes) leads to scope errors; using ordinary `tf.get_variable(..)` works just fine\n\ntensorflow 0.10.0\ncuda 7.5\n\nbasic fully connected network to classify mnist: \n\n```\ndef build_fc_dnn():\n    X = tf.placeholder(tf.float32, [None, 784])\n    y = tf.placeholder(tf.float32, [None, 10])\n\n    depth = 5\n\n    last_layer = X\n    argkw = dict(num_outputs=20, activation_fn=tf.nn.relu)\n    for _ in range(depth):\n        last_layer = tf.contrib.layers.fully_connected(last_layer, **argkw)\n    logits = tf.contrib.layers.fully_connected(last_layer, num_outputs=10)\n\n    loss = tf.nn.softmax_cross_entropy_with_logits(logits, y)\n    y_train_eq_pred = tf.equal(tf.argmax(y,1), tf.argmax(logits,1))\n    acc = tf.reduce_mean(tf.cast(y_train_eq_pred, tf.float32))\n\n    return X, y, loss, acc\n```\n\nand the code that builds graph (analogues to cifar multigpu example):\n\n```\n    ...\n    tower_vars = []\n    for tower_id in range(len(device_id_list)):\n        with tf.device('/gpu:%d' % tower_id):\n            with tf.name_scope('tower_%d' % tower_id) as scope:\n                X, y, loss, acc = build_model()\n                tower_vars.append([gd.compute_gradients(loss), loss, acc, (X, y)])\n                tf.get_variable_scope().reuse_variables()\n\n    tower_grads, tower_loss, tower_acc, xy_pairs = zip(*tower_vars)\n    train_op = gd.apply_gradients(average_gradients(tower_grads))\n    loss = tf.reduce_mean(tower_loss)\n    acc = tf.reduce_mean(tower_acc)\n    init_op = tf.initialize_all_variables()\n```\n\nif I do that, I get an error: `ValueError: Variable fully_connected_6/weights does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=None in VarScope?`\n\nIf I look into `tflearn` docs (`tf.contrib.layers` is basically `tflearn`, right?), they suggest building multigpu code as follows:\n\n```\nwith tf.device('/gpu:0'):\n    # Force all Variables to reside on the CPU.\n    with tf.arg_ops([tflearn.variables.variable], device='/cpu:0'):\n        model1 = my_model(placeholder_X)\n# Reuse Variables for the next model\ntf.get_variable_scope().reuse_variables()\nwith tf.device('/gpu:1'):\n    with tf.arg_ops([tflearn.variables.variable], device='/cpu:0'):\n        model2 = my_model(placeholder_X)\n```\n\nthose docs are probably somewhat outdated, because `tf.arg_ops` is not there anymore; the closest thing I could find is the following:\n\n```\n    arg_scope = tf.contrib.framework.arg_scope\n    create_var_op = tf.contrib.framework.python.ops.variables.variable\n    ...\n    tower_vars = []\n    for tower_id in range(len(device_id_list)):\n        with tf.device('/gpu:%d' % tower_id):\n            with tf.name_scope('tower_%d' % tower_id) as scope:\n            variables_on_cpu = arg_scope([create_var_op], device='/cpu:0')\n            with variables_on_cpu:\n                 X, y, loss, acc = build_model()\n                 tower_vars.append([gd.compute_gradients(loss), loss, acc, (X, y)])\n                 tf.get_variable_scope().reuse_variables()\n\n    tower_grads, tower_loss, tower_acc, xy_pairs = zip(*tower_vars)\n    train_op = gd.apply_gradients(average_gradients(tower_grads))\n    loss = tf.reduce_mean(tower_loss)\n    acc = tf.reduce_mean(tower_acc)\n    init_op = tf.initialize_all_variables()\n```\n\nbut it also does not help (same error).\n\n[issue](https://github.com/tensorflow/serving/issues/136) with similar error message\n[full](https://gist.github.com/MInner/58fa334574138f1ce1359258f27af19a) code that reproduces error\n", "comments": ["that might have something to do with #1325 \nand probably relates to tflearn community more\n"]}, {"number": 4977, "title": "Branch 136214096", "body": "", "comments": []}, {"number": 4976, "title": "Check Bazel version in configure", "body": "This fixes #4975\n", "comments": ["@jart, thanks for your PR! By analyzing the history of the files in this pull request, we identified @vrv, @keveman and @meteorcloudy to be potential reviewers.\n"]}, {"number": 4975, "title": "bazel version check should be in tf_workspace()", "body": "@ic suggested in #4458 to have `./configure` check the Bazel version. This would probably save time for a lot of people. It should be relatively straightforward to implement, because even if Bazel is compiled from git, it still displays a version tag.\n\n```\n$ bazel version\nBuild label: 0.3.2-2016-10-14 (@183147e)\nBuild target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\nBuild time: Fri Oct 14 21:34:37 2016 (1476480877)\nBuild timestamp: 1476480877\nBuild timestamp as int: 1476480877\n```\n\n@martinwicke what version do we currently support? Bazel \u22650.3.1?\n", "comments": ["bazel should already check the bazel version, but maybe that check is broken, or we are not supporting the minimum version we pretend to support there? See tensorflow.bzl:check_version and uses.\n", "Oh terrific. It's probably better to have the version check in Skylark. Although we might want to move that into the tf_workspace() function so it gets enforced on dependent repositories as well.\n", "Ah, yes. That would be much better, otherwise dependent repos have to\nremember to make their own (which they might have to anyway, but at least\nwe still have the floor)\nOn Fri, Oct 14, 2016 at 19:07 Justine Tunney notifications@github.com\nwrote:\n\n> Oh terrific. It's probably better to have the version check in Skylark.\n> Although we might want to move that into the tf_workspace() function so it\n> gets enforced on dependent repositories as well.\n> \n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> https://github.com/tensorflow/tensorflow/issues/4975#issuecomment-253956015,\n> or mute the thread\n> https://github.com/notifications/unsubscribe-auth/AAjO_ePLzwDJFCn8U69O4ZUiYv_E2DrZks5q0DVMgaJpZM4KXhrT\n> .\n", "All this sounds terrific. The check trickling down to dependencies would be great, yes!\n\n>  but maybe that check is broken\n\nIf so, would this issue better be open or renamed? As far as I can test myself or read about it, there are some issues related to either Bazel or Protobuf versioning. I can dig out and link recent issues, if this helps.\n\nI am willing to spend time on the issue, although I am more interested in the `Makefile` and know little about Bazel right now (just starting to study it).\n", "You're right @ic. I've renamed and reopened this issue. I'm not sure if you're volunteering, but if you write up a PR, mention me in the description and I'll be happy to review it. If not, then I can probably take care of this when I get time.\n", "I will look into it---got bitten a few times already by this issue. Two issues to mitigate what to expect from me: I have to work on another part completely unrelated (quantization), and I am just started on Bazel. Anyway, understood on the mention!\n", "Looking a bit into it, would the problem occur in `WORKSPACE`:\n\n```\n# Specify the minimum required bazel version.\nload(\"//tensorflow:tensorflow.bzl\", \"check_version\")\ncheck_version(\"0.3.0\")\n```\n\nThere were quite a few issues/discussions recently about Bazel 0.3.1. I had a look again, but the data is piling up and getting hard to drill.\n\nWould it simply be that the minimum requirement is 0.3.1 now? Note that the current master (f794cd39) builds ok without GPU support, and Makefile-related pieces build too. However the code for quantization does not build (the part under `contrib`).\n", "After pulling today, `WORKSPACE` blocked any progress, requiring for Bazel 0.3.2. The version check works well! I guess the issue we had earlier was just a missing version bump (it was 0.3.0 for a while).\n\n@jart I think this issue can be closed now; thank you.\n"]}, {"number": 4974, "title": "Hermetically seal the protobuf build", "body": "Our protobuf rules don't always compile if sandboxing is enabled in `~/.bazelrc`. For example:\n\n```\nbuild --worker_sandboxing=true  \nbuild --spawn_strategy=sandboxed  \nbuild --genrule_strategy=sandboxed\ntest --spawn_strategy=sandboxed\n```\n\nWe end up with errors like this when compiling things like `bazel build tensorflow/python/tools:strip_unused`.\n\n```\nINFO: From ProtoCompile tensorflow/python/training/checkpoint_state_pb2.py:\nexternal/protobuf/python: warning: directory does not exist.\nINFO: From ProtoCompile tensorflow/contrib/session_bundle/manifest_pb2.py:\nexternal/protobuf/python: warning: directory does not exist.\nINFO: From ProtoCompile tensorflow/contrib/tensorboard/plugins/projector/projector_config_pb2.py:\nexternal/protobuf/python: warning: directory does not exist.\nERROR: /usr/local/google/home/jart/code/tensorflow-clean/tensorflow/contrib/tfprof/tools/tfprof/BUILD:42:1: null failed: linux-sandbox failed: error executing command \n  (cd /usr/local/google/home/jart/.cache/bazel/_bazel_jart/534cc9069a4bd39f8bace6b1039c6506/bazel-sandbox/978fc997-2a45-4494-836a-df35eb0b4705-842/execroot/tensorflow-clean && \\\n  exec env - \\\n  /usr/local/google/home/jart/.cache/bazel/_bazel_jart/534cc9069a4bd39f8bace6b1039c6506/execroot/tensorflow-clean/_bin/linux-sandbox @/usr/local/google/home/jart/.cache/bazel/_bazel_jart/534cc9069a4bd39f8bace6b1039c6506/bazel-sandbox/978fc997-2a45-4494-836a-df35eb0b4705-842/linux-sandbox.params -- bazel-out/host/bin/external/protobuf/protoc '--python_out=bazel-out/local-fastbuild/genfiles/' -I. -Iexternal/protobuf/python -Ibazel-out/local-fastbuild/genfiles/external/protobuf/python tensorflow/contrib/tfprof/tools/tfprof/tfprof_log.proto tensorflow/contrib/tfprof/tools/tfprof/tfprof_output.proto).\nexternal/protobuf/python: warning: directory does not exist.\ntensorflow/core/framework/tensor_shape.proto: File not found.\ntensorflow/core/framework/types.proto: File not found.\ntensorflow/contrib/tfprof/tools/tfprof/tfprof_output.proto: Import \"tensorflow/core/framework/tensor_shape.proto\" was not found or had errors.\ntensorflow/contrib/tfprof/tools/tfprof/tfprof_output.proto: Import \"tensorflow/core/framework/types.proto\" was not found or had errors.\ntensorflow/contrib/tfprof/tools/tfprof/tfprof_output.proto:9:12: \"DataType\" is not defined.\ntensorflow/contrib/tfprof/tools/tfprof/tfprof_output.proto:45:12: \"TensorShapeProto\" is not defined.\nTarget //tensorflow/python/tools:strip_unused failed to build\nINFO: Elapsed time: 53.186s, Critical Path: 40.69s\n```\n\nWe might want to rewrite the protobuf rules so they can have well defined relationships.\n", "comments": ["CC: @damienmg \n", "/cc @philwo because sandboxing :)\n", "cc myself\r\nWorking on converting all our CI builds to sandboxed builds. ", "cc @yifeif ", "Apparently already fixed."]}, {"number": 4973, "title": "Update version strings from 0.11.0rc0 to 0.11.0rc1.", "body": "", "comments": ["@yifeif, thanks for your PR! By analyzing the history of the files in this pull request, we identified @gunan, @keveman and @vrv to be potential reviewers.\n"]}]