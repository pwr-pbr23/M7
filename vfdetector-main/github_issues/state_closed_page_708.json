[{"number": 32341, "title": "Keras model with sequence feature columns fails to convert to estimator", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.0.0-beta1-5101-gc75bb66 2.0.0-rc0\r\n- Python version: 3\r\n- Bazel version (if compiling from source): No\r\n- GCC/Compiler version (if compiling from source): No\r\n- CUDA/cuDNN version: Unknown, from Colab\r\n- GPU model and memory: Unknown, from Colab\r\n\r\n\r\n**Describe the current behavior**\r\nWhen i rewrote my estimator-based model (Dataset + Feature columns) to keras i was able to run (train) it.\r\n\r\nBut when i converted it to estimator as shown in migration guide https://www.tensorflow.org/beta/guide/migration_guide#estimators it fails with error\r\n```python\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-7-6538390f0054> in <module>()\r\n      1 estimator = tf.keras.estimator.model_to_estimator(\r\n----> 2   keras_model = model\r\n      3 )\r\n\r\n9 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/impl/api.py in wrapper(*args, **kwargs)\r\n    235       except Exception as e:  # pylint:disable=broad-except\r\n    236         if hasattr(e, 'ag_error_metadata'):\r\n--> 237           raise e.ag_error_metadata.to_exception(e)\r\n    238         else:\r\n    239           raise\r\n\r\nValueError: in converted code:\r\n    relative to /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/feature_column:\r\n\r\n    sequence_feature_column.py:140 call\r\n        transformation_cache, self._state_manager)\r\n    feature_column_v2.py:3205 get_sequence_dense_tensor\r\n        self.categorical_column))\r\n\r\n    ValueError: In embedding_column: words_embedding. categorical_column must be of type SequenceCategoricalColumn to use SequenceFeatures. Suggested fix: Use one of sequence_categorical_column_with_*. Given (type <class 'tensorflow.python.feature_column.feature_column_v2.HashedCategoricalColumn'>): HashedCategoricalColumn(key='words', hash_bucket_size=1000, dtype=tf.string)\r\n```\r\n\r\n**Describe the expected behavior**\r\nWorking keras model should always be convertable to estimator.\r\n\r\n**Code to reproduce the issue**\r\nHere is an example https://colab.research.google.com/drive/11pWyltRzvQPPvM2dWQ8EqxafB9ByCxNn\r\nThere are 2 cases shown. First i show that keras model with sequence features is working. See `model.fit_generator`.\r\nAnd then i show that conversion to estimator fails.\r\n", "comments": ["The example failed with latest tf 2.0 nightly version with different stack trace as follows.\r\n```python\r\nModuleNotFoundError: No module named 'tensorflow_core.estimator'\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\n/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/estimator/__init__.py in model_to_estimator_v2(keras_model, keras_model_path, custom_objects, model_dir, config, checkpoint_format)\r\n    174   try:\r\n--> 175     from tensorflow_estimator.python.estimator import keras as keras_lib  # pylint: disable=g-import-not-at-top\r\n    176   except ImportError:\r\n\r\n6 frames\r\nImportError: cannot import name 'estimator'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nAttributeError                            Traceback (most recent call last)\r\nAttributeError: 'NotImplementedError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py in structured_traceback(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\r\n   1180             exception = self.get_parts_of_chained_exception(evalue)\r\n   1181             if exception:\r\n-> 1182                 formatted_exceptions += self.prepare_chained_exception_message(evalue.__cause__)\r\n   1183                 etype, evalue, etb = exception\r\n   1184             else:\r\n\r\nTypeError: must be str, not list\r\n```", "@ymodak , it is clear from your trace that you should install estimator package before continue\r\n```bash\r\npip install -U tensorflow-estimator\r\n```", "Same error in 2.0.0 release.\r\n\r\nP.S.\r\nUpdate TF version in reproduce link https://colab.research.google.com/drive/11pWyltRzvQPPvM2dWQ8EqxafB9ByCxNn#scrollTo=HH3J1Tksm3L-", "@shkarupa-alex Can you please try `tf-nightly`? I think this was resolved in `tf-nightly` as I don't see any issue as you reported. Please change first line with '!pip install -q -U tf-nightly tensorflow-datasets'.\r\nHere is the [gist](https://colab.sandbox.google.com/gist/jvishnuvardhan/361c36d2b8ad4d6cc5dd25d03bb77a97/fail_to_convert_keras_model_with_sequence_features_to_estimator.ipynb) with `tf-nightly`. Thanks!\r\n\r\nPlease close the issue if this was resolved by `tf-nightly`. Thanks!", "> @shkarupa-alex Can you please try `tf-nightly`? I think this was resolved in `tf-nightly` as I don't see any issue as you reported. Please change first line with '!pip install -q -U tf-nightly tensorflow-datasets'.\r\n> Here is the [gist](https://colab.sandbox.google.com/gist/jvishnuvardhan/361c36d2b8ad4d6cc5dd25d03bb77a97/fail_to_convert_keras_model_with_sequence_features_to_estimator.ipynb) with `tf-nightly`. Thanks!\r\n> \r\n> Please close the issue if this was resolved by `tf-nightly`. Thanks!\r\n\r\nYou're right, conversion error goes away.\r\n\r\nThe only problem i see for now is message duplicates:\r\n```\r\nINFO:tensorflow:Calling model_fn.\r\nINFO:tensorflow:Calling model_fn.\r\nINFO:tensorflow:Done calling model_fn.\r\nINFO:tensorflow:Done calling model_fn.\r\nINFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='/tmp/tmp676gmwkn/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\r\nINFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='/tmp/tmp676gmwkn/keras/keras_model.ckpt', vars_to_warm_start='.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\r\nINFO:tensorflow:Warm-starting from: /tmp/tmp676gmwkn/keras/keras_model.ckpt\r\nINFO:tensorflow:Warm-starting from: /tmp/tmp676gmwkn/keras/keras_model.ckpt\r\nINFO:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.\r\nINFO:tensorflow:Warm-starting variables only in TRAINABLE_VARIABLES.\r\nINFO:tensorflow:Warm-started 6 variables.\r\nINFO:tensorflow:Warm-started 6 variables.\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\nINFO:tensorflow:Create CheckpointSaverHook.\r\nINFO:tensorflow:Graph was finalized.\r\nINFO:tensorflow:Graph was finalized.\r\nINFO:tensorflow:Running local_init_op.\r\nINFO:tensorflow:Running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\nINFO:tensorflow:Done running local_init_op.\r\nINFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp676gmwkn/model.ckpt.\r\nINFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp676gmwkn/model.ckpt.\r\nINFO:tensorflow:loss = 0.69224596, step = 0\r\nINFO:tensorflow:loss = 0.69224596, step = 0\r\nINFO:tensorflow:global_step/sec: 0.935304\r\nINFO:tensorflow:global_step/sec: 0.935304\r\nINFO:tensorflow:loss = 0.70167637, step = 100 (106.920 sec)\r\nINFO:tensorflow:loss = 0.70167637, step = 100 (106.920 sec)\r\nINFO:tensorflow:global_step/sec: 0.897691\r\nINFO:tensorflow:global_step/sec: 0.897691\r\nINFO:tensorflow:loss = 0.72244895, step = 200 (111.404 sec)\r\nINFO:tensorflow:loss = 0.72244895, step = 200 (111.404 sec)\r\nINFO:tensorflow:global_step/sec: 0.944862\r\nINFO:tensorflow:global_step/sec: 0.944862\r\nINFO:tensorflow:loss = 0.6815354, step = 300 (105.828 sec)\r\nINFO:tensorflow:loss = 0.6815354, step = 300 (105.828 sec)\r\n```", "@shkarupa-alex I agree. I noticed those duplicate messages. Thanks!", "> @shkarupa-alex I agree. I noticed those duplicate messages. Thanks!\r\n\r\nLooks like this is fixed. \r\nFor the warning message part -- this is the output from estimator. Maybe try to set it through \r\ntf.compat.v1.logging.set_verbosity?", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32341\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32341\">No</a>\n"]}, {"number": 32340, "title": "AttributeError: 'RefVariable' object has no attribute 'ref'", "body": "with tf.device('/cpu:0'):\r\n  activations = tf.Variable(tf.zeros([ACT_LEN, FLAGS.wvs, 1], FTYPE), name='activations',\r\n                            trainable=False)\r\nlogits = batch_logits(i_ss, activations.ref())\r\nAttributeError: 'RefVariable' object has no attribute 'ref'", "comments": ["@debadityamandal ,\r\nPlease provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version.\r\nCan you share a simple and standalone code to reproduce the issue?Thanks!\r\n", "@oanush ,\r\nI am executing the code in google colab and tensorflow version is 1.14.0.This is the code snippet.\r\nThank You", "@debadityamandal ,\r\nThank you for the response,but I don't see the code attached.\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 32339, "title": "[r2.0Cherrypick]: Install gast at known version and not the latest.", "body": "PiperOrigin-RevId: 267873409", "comments": []}, {"number": 32338, "title": "[r1.15:CherryPick]:Add incompatible_shape_error attribute to equal op", "body": "When tensor equality is enabled, if there is an incompatible shape we\r\ncurrently throw and exception. Ideally we'd like to return False when\r\ncalling __eq__ and True when calling __ne__. We thus modify the Equal\r\nand NotEqual ops to return a boolean upon a shape incompatibility. Due\r\nto this change the shape inference logic needs to be changed to either\r\nreturn a scalar bool if the shapes are incompatible, or else return an\r\nunknown shape to allow for either a boolean Tensor or scalar to be\r\nreturned.\r\n\r\nNote the behavior of tf.math.equal & tf.math.not_equal is unchanged as\r\nthey both use optimistic shape inference logic when dealing with unknown\r\ndimensions which allows for more efficient graphs rather than inserting\r\nRank operations.\r\n\r\nThis distinction between __eq__ & tf.math.equal is also found in numpy\r\nand as a result the tf.debugging.assert_equal and\r\ntf.debugging.assert_none_equal APIs needed to be change to utilize the\r\nnumpy operations.\r\n\r\nPiperOrigin-RevId: 267466043\r\n(cherry picked from commit e0e1efbe0811aa0913ad8400c532b33c76425427)", "comments": []}, {"number": 32337, "title": "[WIP] Enable more operators in Quantization-aware Training", "body": "The first commit is moved to here from https://github.com/tensorflow/tensorflow/pull/31914 per @suharshs 's comments. The minor changes of the first commit serves as a initial, I'd like to have more discussions while this is in progress.", "comments": ["**About the *activations* and `Identity` operator**. I am curious that, why `Identity` was taken as a activation operators rather than passthrough in `contrib/quantize`, while as passthrough in TOCO?\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/v2.0.0-rc0/tensorflow/contrib/quantize/python/quantize.py#L34-L35\r\n\r\nWould you please help to give me a hint @suharshs and @raghuraman-k .\r\n\r\n\r\n", "This is an in-progress PR, which is not ready for review. However, there is [an announcement](https://groups.google.com/a/tensorflow.org/forum/#!topic/developers/IhU_w5nitKI) of deleting `contrib` from this TF repo at 9/18. My concern is that, how can we work on things like this after that, or what is the codebase?\r\n\r\nShould we wait until the Keras related API later (I searched around, failed to find such API in this repo currently) per @suharshs's [feedback](https://groups.google.com/a/tensorflow.org/forum/#!searchin/addons/quantization-aware$20training%7Csort:date/addons/5Ve1EGAAwgQ/PML0k0BbCAAJ)? Or the scenarios in this PR will be supported initially?\r\n> contrib.quantize will be deprecated in 2.0, we are actively working on a 2.0 friendly Keras api to support quantization aware training.\r\n\r\n\r\n\r\n\r\n", "As [Quantization-aware Training is moving to model-optimization toolkit](https://groups.google.com/a/tensorflow.org/d/msg/developers/dvxDWMjR8YQ/pQMGE51EBwAJ), this PR will not happen in the TF core repo. Maybe I will maintain similar functionality for r1.x in my own repo.\r\n\r\nClosing now.\r\n\r\nEDIT: the model optimization example link: https://github.com/tensorflow/model-optimization/blob/master/tensorflow_model_optimization/python/examples/quantization/keras/mnist_cnn.py"]}, {"number": 32336, "title": "pip install tensorflow from .whl not working", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- Windows 7\r\n- TensorFlow installed from .whl file downloaded: tensorflow-1.14.0-cp36-cp36m-win_amd64.whl\r\n- I am behind a firewall (hence downloaded .whl)\r\n- Python version 3.6.4\r\n- Anaconda navigator environment\r\n\r\n**Describe the problem**\r\nI am now getting the error:\r\nCould not find a version that satisfies the requirement keras-preprocessing >=1.0.5 (from tensorflow ==1.14.0) (from versions: )\r\nNo matching distribution found for keras-preprocessing >= 1.0.5 (from tensorflow == 1.14.0)\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nI tried 'pip install tensorflow-1.14.0-cp36-cp36m-win_amd64.whl'\r\n\r\n**Any other info / logs**\r\nBefore I was getting an error about google-pasta instead of keras-preprocessing. \r\n", "comments": ["You will need to download a wheel for keras-preprocessing, as well as for all other dependencies. Might also want to check if `cp36m-win_amd64` shows up for you on `pip debug --verbose`\r\n\r\nThis is not exactly a TensorFlow code issue, more an issue with your own environment. Thus, closing, but please reopen if it becomes an issue with the actual code.", "https://github.com/tensorflow/tensorflow/issues/32315 another one bits the dust", "I don't think it's related, @reliefs. This one seems to be not having the keraps-preprocessing wheel behind the firewall. Let's not jump to conclusions.", "https://github.com/tensorflow/tensorflow/issues/32627"]}, {"number": 32335, "title": "For long labels / logits, torch.nn.CTCloss is 30-100x faster than tf.nn.ctc_loss", "body": "**System information**\r\nDefault Google Colab GPU runtime\r\n\r\n**Describe the current behavior**\r\nFor long labels / logits, tf.nn.ctc_loss is unbearably slow, in a way that makes whole training very slow (tf.nn.ctc_loss_v2 is even slower)\r\nA standard GPU implementation with unbounded label length such as one offered by torch.nn.CTCloss is many many times faster\r\n\r\n**Code to reproduce the issue**\r\nThe following code is used for the benchmark\r\n\r\n```\r\nfrom torch import nn\r\nimport torch\r\nimport tensorflow as tf\r\nimport math\r\nimport time\r\n\r\ntime_step  = 5  # Input sequence length\r\nvocab_size = 200  # Number of classes\r\nbatch_size = 4  # Batch size\r\ntarget_sql = 3  # Target sequence length\r\n\r\niters = 6\r\nwarm  = 3\r\nDENSE = False\r\n\r\ndef dense_to_sparse(dense_tensor, sequence_length):\r\n    indices = tf.where(tf.sequence_mask(sequence_length))\r\n    values = tf.gather_nd(dense_tensor, indices)\r\n    shape = tf.shape(dense_tensor, out_type=tf.int64)\r\n    return tf.SparseTensor(indices, values, shape)\r\n\r\n\r\nctc_loss = nn.CTCLoss(blank=vocab_size - 1, reduction='none')\r\n\r\nfor j in range(25):\r\n  time_step  *= 2\r\n  target_sql *= 2\r\n  print('Logits length : ',time_step,'Label length : ',target_sql)\r\n  print('-------------------')\r\n  \r\n  x = torch.randn(time_step, batch_size, vocab_size).log_softmax(2).detach().requires_grad_().cuda()\r\n  y = torch.randint(low=0, high=vocab_size-2, size=(batch_size, target_sql),dtype=torch.long).cuda()\r\n\r\n  x_lengths = torch.full(size=(batch_size,), fill_value=time_step, dtype=torch.long).cuda()\r\n  y_lengths = torch.full(size=(batch_size,), fill_value=target_sql, dtype=torch.long).cuda()\r\n\r\n  s=0\r\n  tlss=0.\r\n  for i in range(iters):\r\n      torch.cuda.synchronize()\r\n      a = time.perf_counter()\r\n      loss = ctc_loss(x.log_softmax(2), y, x_lengths, y_lengths).mean()\r\n      torch.cuda.synchronize()\r\n      b = time.perf_counter()\r\n      tlss += float(loss)\r\n      del loss\r\n  \r\n      if i>=warm:\r\n          s += b - a\r\n\r\n  torch.cuda.empty_cache()\r\n  avtorch = s/(iters-warm)\r\n  print('Average torch Time : %.6f'%(avtorch),'Loss : %.3f'%(tlss/iters))\r\n\r\n  ###################################\r\n  ###################################\r\n  \r\n  x = x.detach().cpu().numpy()\r\n  y = y.detach().cpu().numpy()\r\n  x_lengths = x_lengths.detach().cpu().numpy()\r\n  y_lengths = y_lengths.detach().cpu().numpy()\r\n\r\n  if not DENSE:\r\n    y = tf.cast(dense_to_sparse(y, y_lengths), dtype=tf.int32)\r\n  else:\r\n    y = tf.cast(y, dtype=tf.int32)\r\n\r\n\r\n  _x = tf.placeholder(tf.float32, [None, None, None])\r\n\r\n  if not DENSE:\r\n    ctclosses = tf.nn.ctc_loss(y, _x, x_lengths)\r\n  else:\r\n    ctclosses = tf.nn.ctc_loss_v2(y, _x, [target_sql]*batch_size, x_lengths, blank_index=-1)\r\n\r\n  ctclosses = tf.reduce_mean(ctclosses)\r\n\r\n  with tf.Session() as sess:\r\n      s=0\r\n      flss = 0\r\n      for i in range(iters):\r\n          a = time.perf_counter()\r\n          loss = sess.run(ctclosses, feed_dict={_x: x})\r\n          b = time.perf_counter()\r\n          flss += float(loss)\r\n          if i>=warm:\r\n            s += b - a\r\n      \r\n      avtf = s/(iters-warm)\r\n      print('Average tf Time    : %.6f'%(avtf),'Loss : %.3f'%(flss/iters))\r\n\r\n  print('Loss diff : %.6f'%(abs(tlss-flss)))\r\n  print('torch.nn.CTCloss Speed-up : %.2f'%(avtf/avtorch),'\\n\\n')\r\n\r\n```\r\nand get the following results\r\n```\r\nLogits length :  10 Label length :  6\r\n-------------------\r\nAverage torch Time : 0.000162 Loss : 47.414\r\nAverage tf Time    : 0.001151 Loss : 47.414\r\nLoss diff : 0.000046\r\ntorch.nn.CTCloss Speed-up : 7.09 \r\n\r\n\r\nLogits length :  20 Label length :  12\r\n-------------------\r\nAverage torch Time : 0.000173 Loss : 95.054\r\nAverage tf Time    : 0.001166 Loss : 95.054\r\nLoss diff : 0.000092\r\ntorch.nn.CTCloss Speed-up : 6.74 \r\n\r\n\r\nLogits length :  40 Label length :  24\r\n-------------------\r\nAverage torch Time : 0.000172 Loss : 183.101\r\nAverage tf Time    : 0.001589 Loss : 183.101\r\nLoss diff : 0.000092\r\ntorch.nn.CTCloss Speed-up : 9.23 \r\n\r\n\r\nLogits length :  80 Label length :  48\r\n-------------------\r\nAverage torch Time : 0.000252 Loss : 363.414\r\nAverage tf Time    : 0.003907 Loss : 363.414\r\nLoss diff : 0.000000\r\ntorch.nn.CTCloss Speed-up : 15.52 \r\n\r\n\r\nLogits length :  160 Label length :  96\r\n-------------------\r\nAverage torch Time : 0.000580 Loss : 727.621\r\nAverage tf Time    : 0.008144 Loss : 727.621\r\nLoss diff : 0.000366\r\ntorch.nn.CTCloss Speed-up : 14.05 \r\n\r\n\r\nLogits length :  320 Label length :  192\r\n-------------------\r\nAverage torch Time : 0.001026 Loss : 1446.162\r\nAverage tf Time    : 0.025436 Loss : 1446.162\r\nLoss diff : 0.001465\r\ntorch.nn.CTCloss Speed-up : 24.80 \r\n\r\n\r\nLogits length :  640 Label length :  384\r\n-------------------\r\nAverage torch Time : 0.001742 Loss : 2894.562\r\nAverage tf Time    : 0.098221 Loss : 2894.562\r\nLoss diff : 0.004395\r\ntorch.nn.CTCloss Speed-up : 56.38 \r\n\r\n\r\nLogits length :  1280 Label length :  768\r\n-------------------\r\nAverage torch Time : 0.006307 Loss : 5772.526\r\nAverage tf Time    : 0.379303 Loss : 5772.524\r\nLoss diff : 0.011719\r\ntorch.nn.CTCloss Speed-up : 60.14 \r\n\r\n\r\nLogits length :  2560 Label length :  1536\r\n-------------------\r\nAverage torch Time : 0.025078 Loss : 11538.377\r\nAverage tf Time    : 1.546986 Loss : 11538.381\r\nLoss diff : 0.023438\r\ntorch.nn.CTCloss Speed-up : 61.69 \r\n\r\n\r\nLogits length :  5120 Label length :  3072\r\n-------------------\r\nAverage torch Time : 0.043300 Loss : 23038.340\r\nAverage tf Time    : 6.084921 Loss : 23038.336\r\nLoss diff : 0.023438\r\ntorch.nn.CTCloss Speed-up : 140.53 \r\n\r\n\r\nLogits length :  10240 Label length :  6144\r\n-------------------\r\nAverage torch Time : 0.312641 Loss : 46052.559\r\nAverage tf Time    : 23.677528 Loss : 46052.535\r\nLoss diff : 0.140625\r\ntorch.nn.CTCloss Speed-up : 75.73 \r\n```", "comments": ["Could reproduce the issue with Tensorflow 1.14.0 and also the execution ended up in out of memory problem.  Please take a look at colab gist [here](https://colab.sandbox.google.com/gist/gadagashwini/05ae67337a827d19c9235657ee1a5f71/untitled126.ipynb). Thanks", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "This was fixed by @kaixih in https://github.com/tensorflow/tensorflow/pull/32302."]}, {"number": 32334, "title": "2.0.0-rc1 cherry-pick request: Don't exclude tensorboard symbols from goldens if tensorboard pip is installed.", "body": "\r\nPiperOrigin-RevId: 267883131", "comments": []}, {"number": 32333, "title": "Tensorflow 2.0.0-rc0 - incorrect data shape for SparseCategoricalCrossentropy", "body": "Hi,\r\n\r\nI'm trying to train a classifier using tensorflow.keras that predicts categorical labels (0/1/2). Input data is an ndarray of tf.float32. I used tensorflow=2.0.0-beta0 and then tensorflow=2.0.0-rc0 to produce the error messages below.\r\n\r\nThe output seems to be in the correct form as per [SparseCategoricalCrossentropy](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy) :   \r\nInput : [7 1]    \r\nOutput: [7 3]  \r\nWhere batch size is 7.\r\n\r\n\r\ntensorflow=2.0.0-rc0:  \r\n```python\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-5-fe1cc3e1dca1> in <module>\r\n     47 print(model.summary())\r\n     48 \r\n---> 49 model.fit(train.batch(BATCH_SIZE), epochs=EPOCHS, verbose=2)\r\n     50 model.evaluate(train, steps=None, verbose=1)\r\n\r\n/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    732         max_queue_size=max_queue_size,\r\n    733         workers=workers,\r\n--> 734         use_multiprocessing=use_multiprocessing)\r\n    735 \r\n    736   def evaluate(self,\r\n\r\n/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py in fit(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\r\n    322                 mode=ModeKeys.TRAIN,\r\n    323                 training_context=training_context,\r\n--> 324                 total_epochs=epochs)\r\n    325             cbks.make_logs(model, epoch_logs, training_result, ModeKeys.TRAIN)\r\n    326 \r\n\r\n/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py in run_one_epoch(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\r\n    121         step=step, mode=mode, size=current_batch_size) as batch_logs:\r\n    122       try:\r\n--> 123         batch_outs = execution_function(iterator)\r\n    124       except (StopIteration, errors.OutOfRangeError):\r\n    125         # TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\r\n\r\n/usr/local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2_utils.py in execution_function(input_fn)\r\n     84     # `numpy` translates Tensors to values in Eager mode.\r\n     85     return nest.map_structure(_non_none_constant_value,\r\n---> 86                               distributed_function(input_fn))\r\n     87 \r\n     88   return execution_function\r\n\r\n/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    437         # Lifting succeeded, so variables are initialized and we can run the\r\n    438         # stateless function.\r\n--> 439         return self._stateless_fn(*args, **kwds)\r\n    440     else:\r\n    441       canon_args, canon_kwds = \\\r\n\r\n/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in __call__(self, *args, **kwargs)\r\n   1820     \"\"\"Calls a graph function specialized to the inputs.\"\"\"\r\n   1821     graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n-> 1822     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n   1823 \r\n   1824   @property\r\n\r\n/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _filtered_call(self, args, kwargs)\r\n   1139          if isinstance(t, (ops.Tensor,\r\n   1140                            resource_variable_ops.BaseResourceVariable))),\r\n-> 1141         self.captured_inputs)\r\n   1142 \r\n   1143   def _call_flat(self, args, captured_inputs, cancellation_manager=None):\r\n\r\n/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)\r\n   1222     if executing_eagerly:\r\n   1223       flat_outputs = forward_function.call(\r\n-> 1224           ctx, args, cancellation_manager=cancellation_manager)\r\n   1225     else:\r\n   1226       gradient_name = self._delayed_rewrite_functions.register()\r\n\r\n/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py in call(self, ctx, args, cancellation_manager)\r\n    509               inputs=args,\r\n    510               attrs=(\"executor_type\", executor_type, \"config_proto\", config),\r\n--> 511               ctx=ctx)\r\n    512         else:\r\n    513           outputs = execute.execute_with_cancellation(\r\n\r\n/usr/local/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     65     else:\r\n     66       message = e.message\r\n---> 67     six.raise_from(core._status_to_exception(e.code, message), None)\r\n     68   except TypeError as e:\r\n     69     keras_symbolic_tensors = [\r\n\r\n~/Library/Python/3.7/lib/python/site-packages/six.py in raise_from(value, from_value)\r\n\r\nInvalidArgumentError:  assertion failed: [] [Condition x == y did not hold element-wise:] [x (loss/dense_3_loss/SparseSoftmaxCrossEntropyWithLogits/Shape_1:0) = ] [7 1] [y (loss/dense_3_loss/SparseSoftmaxCrossEntropyWithLogits/strided_slice:0) = ] [7 3]\r\n\t [[node loss/dense_3_loss/SparseSoftmaxCrossEntropyWithLogits/assert_equal/Assert/Assert (defined at /usr/local/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1751) ]] [Op:__inference_distributed_function_2031]\r\n\r\nFunction call stack:\r\ndistributed_function\r\n```\r\n\r\n\r\nWith tensorflow=2.0.0-beta0:  \r\n```python\r\nInvalidArgumentError:  logits and labels must have the same first dimension, got logits shape [7,3] and labels shape [7]\r\n\t [[node loss/dense_2_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-3-4fa88a5fad5e>:70) ]] [Op:__inference_keras_scratch_graph_5038]\r\n```\r\n\r\n\r\n\r\n\r\ncode to reproduce:\r\n```python\r\nimport numpy as np\r\nimport pandas as pd\r\nimport random\r\nimport tensorflow as tf\r\nimport time as tm\r\n\r\nINPUT_SHAPE=[3, 5]\r\nNUM_POINTS=20\r\nBATCH_SIZE=7\r\nEPOCHS=4\r\n\r\ndef data_gen(num, in_shape):\r\n    for i in range(num):\r\n        x = np.random.rand(in_shape[0], in_shape[1])\r\n        y = random.randint(0,2)\r\n        yield x, y\r\n        \r\ndef data_gen_all(num, in_shape, num_labels):\r\n    x = np.zeros([num]+in_shape)\r\n    y = np.zeros([num]+[num_labels])\r\n    for i in range(num):\r\n        x[i,:,:]= np.random.rand(in_shape[0], in_shape[1])\r\n        y[i]= tf.one_hot(random.randint(0, num_labels), num_labels).numpy()\r\n    return x, y\r\n\r\ntrain = tf.data.Dataset.from_generator(\r\n    generator=data_gen,\r\n    output_types=(tf.float32, tf.int32),\r\n#     output_shapes=(tf.TensorShape([None, INPUT_SHAPE[1]]), tf.TensorShape(None)),\r\n#     output_shapes=(tf.TensorShape(INPUT_SHAPE), tf.TensorShape(())),\r\n    output_shapes=([None, INPUT_SHAPE[1]],()),\r\n    args=([NUM_POINTS, INPUT_SHAPE])\r\n)\r\n\r\ndef create_model(input_shape):\r\n    model = tf.keras.models.Sequential([\r\n        tf.keras.layers.Dense(100, activation=\"tanh\",input_shape=input_shape),        \r\n        tf.keras.layers.Dense(3, activation=\"softmax\", kernel_regularizer= tf.keras.regularizers.l2(0.001))\r\n    ])\r\n    return model\r\n\r\nmodel = create_model(input_shape=INPUT_SHAPE)\r\n\r\nmodel.compile(\r\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4, clipvalue=1.0),\r\n    loss= tf.keras.losses.SparseCategoricalCrossentropy(),\r\n#     loss= tf.keras.losses.CategoricalCrossentropy()\r\n    )\r\nprint(model.summary())\r\nmodel.fit(train.batch(BATCH_SIZE), epochs=EPOCHS, verbose=2)\r\nmodel.evaluate(train, steps=None, verbose=1)\r\n\r\n### CategoricalCrossentropy\r\nx,y = data_gen_all(num=20, in_shape=INPUT_SHAPE, num_labels=3)\r\nprint(x.shape)\r\nmodel.fit(x=x, y=y, epochs=EPOCHS, verbose=2)\r\n```\r\n\r\n\r\nhttps://stackoverflow.com/questions/57842734/tensorflow-2-0-incrrect-data-shape-for-sparsecategoricalcrossentropy\r\n\r\nPlatform: MacOS 10.14.6  \r\ntensorflow=2.0.0-rc0  \r\ntf_env_collect.sh produced:\r\n```\r\n== check python ===================================================\r\npython version: 3.7.4\r\npython branch: \r\npython build version: ('default', 'Jul  9 2019 18:13:23')\r\npython compiler version: Clang 10.0.1 (clang-1001.0.46.4)\r\npython implementation: CPython\r\n\r\n\r\n== check os platform ===============================================\r\nos: Darwin\r\nos kernel version: Darwin Kernel Version 18.7.0: Tue Aug 20 16:57:14 PDT 2019; root:xnu-4903.271.2~2/RELEASE_X86_64\r\nos release version: 18.7.0\r\nos platform: Darwin-18.7.0-x86_64-i386-64bit\r\nlinux distribution: ('', '', '')\r\nlinux os distribution: ('', '', '')\r\nmac version: ('10.14.6', ('', '', ''), 'x86_64')\r\nuname: uname_result(system='Darwin', node='chnb.local', release='18.7.0', version='Darwin Kernel Version 18.7.0: Tue Aug 20 16:57:14 PDT 2019; root:xnu-4903.271.2~2/RELEASE_X86_64', machine='x86_64', processor='i386')\r\narchitecture: ('64bit', '')\r\nmachine: x86_64\r\n\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nApple LLVM version 10.0.1 (clang-1001.0.46.4)\r\nTarget: x86_64-apple-darwin18.7.0\r\nThread model: posix\r\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\r\n\r\n== check pips ===================================================\r\nnumpy                1.17.2              \r\nprotobuf             3.9.1               \r\ntensorflow           2.0.0b0             \r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.version.VERSION = 2.0.0-beta0\r\ntf.version.GIT_VERSION = v1.12.1-3259-gf59745a381\r\ntf.version.COMPILER_VERSION = 4.2.1 Compatible Apple LLVM 10.0.0 (clang-1000.11.45.5)\r\n/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\n/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\r\n/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\r\n/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\r\n/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\r\n/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\r\n/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\n/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\r\n/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\r\n/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\r\n/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\r\n/usr/local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH is unset\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\n./collect.sh: line 147: nvidia-smi: command not found\r\n\r\n== cuda libs  ===================================================\r\n\r\n== tensorflow installed from info ==================\r\nName: tensorflow\r\nVersion: 2.0.0b0\r\nSummary: TensorFlow is an open source machine learning framework for everyone.\r\nHome-page: https://www.tensorflow.org/\r\nAuthor-email: packages@tensorflow.org\r\nLicense: Apache 2.0\r\nLocation: /usr/local/lib/python3.7/site-packages\r\nRequired-by: \r\n\r\n== python version  ==============================================\r\n(major, minor, micro, releaselevel, serial)\r\n(2, 7, 16, 'final', 0)\r\n\r\n== bazel version  ===============================================\r\nBuild label: 0.29.0-homebrew\r\nBuild time: Wed Aug 28 18:07:41 2019 (1567015661)\r\nBuild timestamp: 1567015661\r\nBuild timestamp as int: 1567015661\r\n```\r\n", "comments": ["I have tried on colab with TF version 2.0.0-rc0,2.0.0-beta0,2.0.0-dev20190908 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/c3c1ff7918fa34017f983be1a837455d/untitled162.ipynb).Thanks!", "I also managed to make it run with a small tweak in the model. Before the dense softmax layer I added an LSTM with 1 cell. Please find bellow the version that actually trains. I find it weird that removing the LSTM in the middle of the layer stack changes the final output.\r\n\r\nMaybe I'm doing something wrong. Please advise.\r\n\r\n```python\r\nimport numpy as np\r\nimport pandas as pd\r\nimport random\r\nimport tensorflow as tf\r\nimport time as tm\r\n\r\nINPUT_SHAPE=[3, 5]\r\nNUM_POINTS=20\r\nBATCH_SIZE=7\r\nEPOCHS=4\r\n\r\ndef data_gen(num, in_shape):\r\n    for i in range(num):\r\n        x = np.random.rand(in_shape[0], in_shape[1])\r\n        y = random.randint(0,2)\r\n        yield x, y\r\n\r\ntrain = tf.data.Dataset.from_generator(\r\n    generator=data_gen,\r\n    output_types=(tf.float32, tf.int32),\r\n    output_shapes=([None, INPUT_SHAPE[1]],()),\r\n    args=([NUM_POINTS, INPUT_SHAPE])\r\n)\r\n\r\ndef create_model(input_shape):\r\n    model = tf.keras.models.Sequential([\r\n        tf.keras.layers.Dense(100, activation=\"tanh\", input_shape=input_shape),   \r\n        tf.keras.layers.LSTM(1, activation=\"tanh\"),\r\n        tf.keras.layers.Dense(3, activation=\"softmax\")\r\n    ])\r\n    return model\r\n\r\nmodel = create_model(input_shape=INPUT_SHAPE)\r\n\r\nmodel.compile(\r\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4, clipvalue=1.0),\r\n    loss= tf.keras.losses.SparseCategoricalCrossentropy()\r\n    )\r\nprint(model.summary())\r\nmodel.fit(train.batch(BATCH_SIZE), epochs=EPOCHS, verbose=2)\r\nmodel.evaluate(train, steps=None, verbose=1)\r\n```", "Any update on this? Is the problem in the `SparseCategoricalCrossentropy` method or the stacked layers output?", "@vicpara Can you try to change last line as `model.evaluate(train.batch(BATCH_SIZE), steps=None, verbose=1)`. It worked without any error. Please check the [gist Here](https://colab.sandbox.google.com/gist/jvishnuvardhan/cc84477a9522c956d9f433d96dd37cd5/untitled602.ipynb) for your reference. Thanks!\r\n\r\nPlease close the issue if this was resolved. Thanks!", "@jvishnuvardhan Thanks for the update.   \r\nTo reproduce you need to comment out the line where you add the LSTM to the model `tf.keras.layers.LSTM(1, activation=\"tanh\"),` .", "@vicpara Here is the summary for the model provided in the code snippet above\r\n\r\n____________________________\r\nLayer (type)                 Output Shape              Param #   \r\n____________________________\r\ndense (Dense)                (None, 3, 100)            600       \r\n____________________________\r\ndense_1 (Dense)              (None, 3, 3)              303       \r\n____________________________\r\nTotal params: 903\r\nTrainable params: 903\r\nNon-trainable params: 0\r\n____________________________\r\n\r\nThe output shape is (7, 3, 3) and not (7, 3). Hence you are seeing the error that there is a shape mismatch. The following cases would work:\r\n\r\nFor sparse categorical crossentropy:\r\noutput shape = (7, 3) and label shape = (7, 1)\r\noutput shape = (7, 3, 3) and label shape = (7, 3, 1)\r\n\r\nFor categorical crossentropy:\r\noutput shape = (7, 3) and label shape = (7, 3)\r\noutput shape = (7, 3, 3) and label shape = (7, 3, 3)\r\n\r\nHope this helps :)", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32333\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32333\">No</a>\n", "I had a similar issue and prevented it by setting return_sequences to False for the LSTM layer which feeds into the Dense layer", "I'm facing the same error message but only when I add callbacks.  \r\nAdding anyone of them separately or together would trigger the issue but without them the code runs smoothly.\r\n```\r\nmodel = Sequential()\r\nmodel.add(Convolution2D(4, (1,3), input_shape=X.shape[1:]))\r\n##model.add(Convolution2D(8, (3,3)))\r\nmodel.add(Convolution2D(2, (3,3), dilation_rate=(1,1)))\r\nmodel.add(Convolution2D(1, (3,3), dilation_rate=(4,4)))\r\nmodel.add(Flatten())\r\nmodel.add(Dense(3, activation=\"sigmoid\"))\r\nopt = SGD(learning_rate=0.013)\r\nmodel.compile(optimizer=opt,\r\n              loss=\"MSE\",\r\n              metrics=[\"accuracy\"])\r\n\r\n# *** These Callbacks\r\nearly_stop = EarlyStopping(monitor='val_loss',\r\n                           patience=10,\r\n                           verbose=True,\r\n                           mode='min')\r\nchckpnt_save = ModelCheckpoint('\\\\MODELS',\r\n                              save_best_only=True,\r\n                              monitor='val_loss',\r\n                              mode='min')\r\nrdc_lr_loss = ReduceLROnPlateau(monitor='val_loss',\r\n                                factor=0.1,\r\n                                patience=7,\r\n                                verbose=True,\r\n                                epsilon=1e-4,\r\n                                mode='min')\r\n# ***\r\n\r\nmodel.fit(X,Y,epochs=5000,\r\n          batch_size=3,\r\n          validation_split=0.175,\r\n          callbacks=[early_stop, chckpnt_save , rdc_lr_loss ])\r\n```\r\nError Message:\r\n```\r\n  File \"Whatsapp_Organyzer_B.py\", line 52, in <module>\r\n    callbacks=[early_stop])\r\n  File \"C:\\Python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 819, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"C:\\Python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 342, in fit\r\n    total_epochs=epochs)\r\n  File \"C:\\Python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 128, in run_one_epoch\r\n    batch_outs = execution_function(iterator)\r\n  File \"C:\\Python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\", line 98, in execution_function\r\n    distributed_function(input_fn))\r\n  File \"C:\\Python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 568, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"C:\\Python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 632, in _call\r\n    return self._stateless_fn(*args, **kwds)\r\n  File \"C:\\Python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 2363, in __call__\r\n    return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n  File \"C:\\Python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1611, in _filtered_call\r\n    self.captured_inputs)\r\n  File \"C:\\Python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1692, in _call_flat\r\n    ctx, args, cancellation_manager=cancellation_manager))\r\n  File \"C:\\Python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 545, in call\r\n    ctx=ctx)\r\n  File \"C:\\Python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\", line 67, in quick_execute\r\n    six.raise_from(core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n         [[node sequential/conv2d/Conv2D (defined at Whatsapp_Organyzer_B.py:52) ]] [Op:__inference_distributed_function_705]\r\n\r\nFunction call stack:\r\ndistributed_function\r\n```", "@super-pirata Getting the same Error even without callbacks ", "> I'm facing the same error message but only when I add callbacks.\r\n> Adding anyone of them separately or together would trigger the issue but without them the code runs smoothly.\r\n> \r\n> ```\r\n> model = Sequential()\r\n> model.add(Convolution2D(4, (1,3), input_shape=X.shape[1:]))\r\n> ##model.add(Convolution2D(8, (3,3)))\r\n> model.add(Convolution2D(2, (3,3), dilation_rate=(1,1)))\r\n> model.add(Convolution2D(1, (3,3), dilation_rate=(4,4)))\r\n> model.add(Flatten())\r\n> model.add(Dense(3, activation=\"sigmoid\"))\r\n> opt = SGD(learning_rate=0.013)\r\n> model.compile(optimizer=opt,\r\n>               loss=\"MSE\",\r\n>               metrics=[\"accuracy\"])\r\n> \r\n> # *** These Callbacks\r\n> early_stop = EarlyStopping(monitor='val_loss',\r\n>                            patience=10,\r\n>                            verbose=True,\r\n>                            mode='min')\r\n> chckpnt_save = ModelCheckpoint('\\\\MODELS',\r\n>                               save_best_only=True,\r\n>                               monitor='val_loss',\r\n>                               mode='min')\r\n> rdc_lr_loss = ReduceLROnPlateau(monitor='val_loss',\r\n>                                 factor=0.1,\r\n>                                 patience=7,\r\n>                                 verbose=True,\r\n>                                 epsilon=1e-4,\r\n>                                 mode='min')\r\n> # ***\r\n> \r\n> model.fit(X,Y,epochs=5000,\r\n>           batch_size=3,\r\n>           validation_split=0.175,\r\n>           callbacks=[early_stop, chckpnt_save , rdc_lr_loss ])\r\n> ```\r\n> \r\n> Error Message:\r\n> \r\n> ```\r\n>   File \"Whatsapp_Organyzer_B.py\", line 52, in <module>\r\n>     callbacks=[early_stop])\r\n>   File \"C:\\Python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 819, in fit\r\n>     use_multiprocessing=use_multiprocessing)\r\n>   File \"C:\\Python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 342, in fit\r\n>     total_epochs=epochs)\r\n>   File \"C:\\Python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\", line 128, in run_one_epoch\r\n>     batch_outs = execution_function(iterator)\r\n>   File \"C:\\Python37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\", line 98, in execution_function\r\n>     distributed_function(input_fn))\r\n>   File \"C:\\Python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 568, in __call__\r\n>     result = self._call(*args, **kwds)\r\n>   File \"C:\\Python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\", line 632, in _call\r\n>     return self._stateless_fn(*args, **kwds)\r\n>   File \"C:\\Python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 2363, in __call__\r\n>     return graph_function._filtered_call(args, kwargs)  # pylint: disable=protected-access\r\n>   File \"C:\\Python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1611, in _filtered_call\r\n>     self.captured_inputs)\r\n>   File \"C:\\Python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 1692, in _call_flat\r\n>     ctx, args, cancellation_manager=cancellation_manager))\r\n>   File \"C:\\Python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\", line 545, in call\r\n>     ctx=ctx)\r\n>   File \"C:\\Python37\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\", line 67, in quick_execute\r\n>     six.raise_from(core._status_to_exception(e.code, message), None)\r\n>   File \"<string>\", line 3, in raise_from\r\n> tensorflow.python.framework.errors_impl.UnknownError:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n>          [[node sequential/conv2d/Conv2D (defined at Whatsapp_Organyzer_B.py:52) ]] [Op:__inference_distributed_function_705]\r\n> \r\n> Function call stack:\r\n> distributed_function\r\n> ```\r\n\r\nwere you able to solve this?\r\n", "> @vicpara Here is the summary for the model provided in the code snippet above\r\n> \r\n> Layer (type) Output Shape Param #\r\n> \r\n> dense (Dense) (None, 3, 100) 600\r\n> \r\n> dense_1 (Dense) (None, 3, 3) 303\r\n> \r\n> Total params: 903\r\n> Trainable params: 903\r\n> Non-trainable params: 0\r\n> \r\n> The output shape is (7, 3, 3) and not (7, 3). Hence you are seeing the error that there is a shape mismatch. The following cases would work:\r\n> \r\n> For sparse categorical crossentropy:\r\n> output shape = (7, 3) and label shape = (7, 1)\r\n> output shape = (7, 3, 3) and label shape = (7, 3, 1)\r\n> \r\n> For categorical crossentropy:\r\n> output shape = (7, 3) and label shape = (7, 3)\r\n> output shape = (7, 3, 3) and label shape = (7, 3, 3)\r\n> \r\n> Hope this helps :)\r\n\r\nThat\u2019s probably your problem. Change the shape of the last layer or use a different loss function.", "Dataset: 6000\r\nDescriptions: train=6000\r\nPhotos: train=6000\r\nVocabulary Size: 7579\r\nDescription Length: 34\r\nModel: \"model_6\"\r\n__________________________________________________________________________________________________\r\nLayer (type)                    Output Shape         Param #     Connected to                     \r\n==================================================================================================\r\ninput_14 (InputLayer)           [(None, 34)]         0                                            \r\n__________________________________________________________________________________________________\r\ninput_13 (InputLayer)           [(None, 4096)]       0                                            \r\n__________________________________________________________________________________________________\r\nembedding_6 (Embedding)         (None, 34, 256)      1940224     input_14[0][0]                   \r\n__________________________________________________________________________________________________\r\ndropout_12 (Dropout)            (None, 4096)         0           input_13[0][0]                   \r\n__________________________________________________________________________________________________\r\ndropout_13 (Dropout)            (None, 34, 256)      0           embedding_6[0][0]                \r\n__________________________________________________________________________________________________\r\ndense_18 (Dense)                (None, 256)          1048832     dropout_12[0][0]                 \r\n__________________________________________________________________________________________________\r\nlstm_6 (LSTM)                   (None, 256)          525312      dropout_13[0][0]                 \r\n__________________________________________________________________________________________________\r\nadd_6 (Add)                     (None, 256)          0           dense_18[0][0]                   \r\n                                                                 lstm_6[0][0]                     \r\n__________________________________________________________________________________________________\r\ndense_19 (Dense)                (None, 256)          65792       add_6[0][0]                      \r\n__________________________________________________________________________________________________\r\ndense_20 (Dense)                (None, 7579)         1947803     dense_19[0][0]                   \r\n==================================================================================================\r\nTotal params: 5,527,963\r\nTrainable params: 5,527,963\r\nNon-trainable params: 0\r\n__________________________________________________________________________________________________\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-26-611f9002c85b> in <module>()\r\n    168         generator = data_generator(train_descriptions, train_features, tokenizer, max_length, vocab_size)\r\n    169         # fit for one epoch\r\n--> 170         model.fit(generator, epochs=1, steps_per_epoch=steps, verbose=1)\r\n    171         # save model\r\n    172         model.save('model_' + str(i) + '.h5')\r\n\r\n9 frames\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)\r\n    975           except Exception as e:  # pylint:disable=broad-except\r\n    976             if hasattr(e, \"ag_error_metadata\"):\r\n--> 977               raise e.ag_error_metadata.to_exception(e)\r\n    978             else:\r\n    979               raise\r\n\r\nValueError: in user code:\r\n\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\r\n        return step_function(self, iterator)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\r\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\r\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\r\n        return self._call_for_each_replica(fn, args, kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\r\n        return fn(*args, **kwargs)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\r\n        outputs = model.train_step(data)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:754 train_step\r\n        y_pred = self(x, training=True)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\r\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\r\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py:207 assert_input_compatibility\r\n        ' input tensors. Inputs received: ' + str(inputs))\r\n\r\n    ValueError: Layer model_6 expects 2 input(s), but it received 3 input tensors. Inputs received: [<tf.Tensor 'IteratorGetNext:0' shape=(None, None) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, None) dtype=int32>, <tf.Tensor 'IteratorGetNext:2' shape=(None, None) dtype=float32>]", "Could you describe more closely what you did, when the error occurred and what you try to achieve?", "> @jvishnuvardhan Thanks for the update.\r\n> To reproduce you need to comment out the line where you add the LSTM to the model `tf.keras.layers.LSTM(1, activation=\"tanh\"),` .\r\n\r\nThis works for me"]}, {"number": 32332, "title": "[r1.15 Cherryick]:Install gast at known version and not the latest.", "body": "PiperOrigin-RevId: 267873409", "comments": ["the macos failure is due to the newly added tensorboard installation , and should not affect functionality. Merging this now."]}, {"number": 32331, "title": "Poisson random variable samples float instead of int, fails in hierarchical modeling as result", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes, derived from tf example.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS Mojave 10.14.4\r\n- **TensorFlow installed from (source or binary)**: pip\r\n- **TensorFlow version (use command below)**: v1.14.0-rc1-22-gaf24dc91b5 1.14.0\r\n- **Python version**: Python 3.7.3\r\n- **Exact command to reproduce**: I am implementing a hierarchical model, where the value of the Poisson sample is used to determine the batch size of the normal distribution. Since the Poisson sample is a float, the MCMC step function treats it as a float. This results in incorrect mathematics for MCMC to work. In general, I cannot get this code to run.  \r\n\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow_probability as tfp\r\ntfd = tfp.distributions\r\ntfb = tfp.bijectors\r\n\r\nrv_m = tfd.Poisson(rate=1.)\r\nm    = rv_m.sample()\r\n\r\ndef joint_log_prob(m):\r\n    rv_m    = tfd.Poisson(rate=1.)\r\n    m_int   = tf.cast(m,'int32')\r\n    rv_norm = tfd.Normal(loc=tf.zeros(m_int),scale=1.)\r\n    return (-1.)\r\n\r\nnumber_of_steps = 1000\r\nburnin          = 0\r\n\r\ninitial_chain_state      = [m]\r\nlog_prob                 = lambda *args: joint_log_prob(*args)\r\n[post_m], kernel_results = tfp.mcmc.sample_chain(num_results=number_of_steps,num_burnin_steps=burnin,current_state=initial_chain_state,kernel=tfp.mcmc.RandomWalkMetropolis(target_log_prob_fn=log_prob,seed=4))\r\n```\r\n### Source code / logs\r\n```\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"/Users/dcunha/mutatio/lib/python3.7/site-packages/tensorflow_probability/python/mcmc/sample.py\", line 361, in sample_chain\r\n    parallel_iterations=parallel_iterations)\r\n  File \"/Users/dcunha/mutatio/lib/python3.7/site-packages/tensorflow_probability/python/mcmc/internal/util.py\", line 370, in trace_scan\r\n    parallel_iterations=parallel_iterations)\r\n  File \"/Users/dcunha/mutatio/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3501, in while_loop\r\n    return_same_structure)\r\n  File \"/Users/dcunha/mutatio/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3012, in BuildLoop\r\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n  File \"/Users/dcunha/mutatio/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2937, in _BuildLoop\r\n    body_result = body(*packed_vars_for_body)\r\n  File \"/Users/dcunha/mutatio/lib/python3.7/site-packages/tensorflow_probability/python/mcmc/internal/util.py\", line 359, in _body\r\n    state = loop_fn(state, elems_array.read(i))\r\n  File \"/Users/dcunha/mutatio/lib/python3.7/site-packages/tensorflow_probability/python/mcmc/sample.py\", line 345, in _trace_scan_fn\r\n    parallel_iterations=parallel_iterations)\r\n  File \"/Users/dcunha/mutatio/lib/python3.7/site-packages/tensorflow_probability/python/mcmc/internal/util.py\", line 286, in smart_for_loop\r\n    parallel_iterations=parallel_iterations\r\n  File \"/Users/dcunha/mutatio/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3501, in while_loop\r\n    return_same_structure)\r\n  File \"/Users/dcunha/mutatio/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 3012, in BuildLoop\r\n    pred, body, original_loop_vars, loop_vars, shape_invariants)\r\n  File \"/Users/dcunha/mutatio/lib/python3.7/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 2937, in _BuildLoop\r\n    body_result = body(*packed_vars_for_body)\r\n  File \"/Users/dcunha/mutatio/lib/python3.7/site-packages/tensorflow_probability/python/mcmc/internal/util.py\", line 284, in <lambda>\r\n    body=lambda i, *args: [i + 1] + list(body_fn(*args)),\r\n  File \"/Users/dcunha/mutatio/lib/python3.7/site-packages/tensorflow_probability/python/mcmc/random_walk_metropolis.py\", line 440, in one_step\r\n    return self._impl.one_step(current_state, previous_kernel_results)\r\n  File \"/Users/dcunha/mutatio/lib/python3.7/site-packages/tensorflow_probability/python/mcmc/metropolis_hastings.py\", line 194, in one_step\r\n    previous_kernel_results.accepted_results)\r\n  File \"/Users/dcunha/mutatio/lib/python3.7/site-packages/tensorflow_probability/python/mcmc/random_walk_metropolis.py\", line 533, in one_step\r\n    dtype=next_target_log_prob.dtype.base_dtype),\r\nAttributeError: 'float' object has no attribute 'dtype'\r\n```\r\n", "comments": ["One suggestion: can you try with the 2.0 release? There have been changes in the API which might have solved this issue", "Sure, I installed and tried 2.0 release, and receive the same error.", "Seems to be an error from [TensorFlow Probability](https://github.com/tensorflow/probability). Can you please open an issue there instead?", "Great, I logged the issue here:\r\nhttps://github.com/tensorflow/probability/issues/553\r\n\r\nThank you for your help."]}, {"number": 32330, "title": "java.lang.IllegalArgumentException: Internal error: Failed to run on the given Interpreter: TfLiteGpuDelegate Invoke: Delegate should run on the same thread where it was initialized.Node number 175 (TfLiteGpuDelegate) failed to invoke", "body": "In the android image classifier demo, I tried to run the Interpreter with GPU from start so I changed [this line](https://github.com/tensorflow/examples/blob/master/lite/examples/image_classification/android/app/src/main/java/org/tensorflow/lite/examples/classification/tflite/Classifier.java#L175-L189):\r\n\r\n```\r\n  protected Classifier(Activity activity, Device device, int numThreads) throws IOException {\r\n    tfliteModel = loadModelFile(activity);\r\n    switch (device) {\r\n      case NNAPI:\r\n        tfliteOptions.setUseNNAPI(true);\r\n        break;\r\n      case GPU:\r\n        gpuDelegate = new GpuDelegate();\r\n        tfliteOptions.addDelegate(gpuDelegate);\r\n        break;\r\n      case CPU:\r\n        break;\r\n    }\r\n\r\n    tfliteOptions.setNumThreads(numThreads);\r\n    tflite = new Interpreter(tfliteModel, tfliteOptions);\r\n```\r\n\r\nto this:\r\n\r\n```\r\n  protected Classifier(Activity activity, Device device, int numThreads) throws IOException {\r\n    tfliteModel = loadModelFile(activity);\r\n    gpuDelegate = new GpuDelegate();\r\n    tfliteOptions.addDelegate(gpuDelegate);\r\n    tfliteOptions.setNumThreads(numThreads);\r\n    tflite = new Interpreter(tfliteModel, tfliteOptions);\r\n```\r\n\r\nsounds simple, but it crashes with the above mentioned error.\r\nWeirdly: When I start the app in CPU mode and switch to GPU while running (via the options-sheet) it does work.\r\n\r\nIs the GpuDelegate class using some custom thread? ", "comments": ["In the sample, the Interpreter is run on a separate thread. When using the GPU, you must create/apply the delegate on the same thread as the one you use to run inference.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32330\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32330\">No</a>\n", "This is not fixing it. I did not change the thread or anything. I just removed the switch-case, so the threads should be the same as before. Anyone else dealing with the same problem?", "Also strange: If I add a `SystemClock.sleep(500);` after the call for initializing tflite and before running inference, it doesn't crash anymore. This hints to the fact, that the \"thread\" is not the problem at all.\r\n\r\nRather it seems that the system is not yet ready for running the classifier, although the \"classifier != null\" check passes successfully.\r\n\r\nIs there a way to tell, when exactly the initialization of the tflite classifer with gpu delegate has completed?", "Ah, I think this may just be a function of the fact that the very first time we create the Interpreter, it happens to be on the UI thread, and in all such cases we default to CPU execution, not GPU. Subsequent requests to enable GPU are done on the inference thread. We should fix this in the examples."]}, {"number": 32329, "title": "TensorFlow installation apt commands is wrong", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/install/gpu\r\n\r\n## Description of issue (what needs changing):\r\n\r\n1. change your language to chinese simplified from the upright corner.\r\n2. in the apt installation commands for Ubuntu 18.04 (CUDA 10), last step shown below is wrong:\r\n\r\n```\r\n  # Install TensorRT. Requires that libcudnn7 is installed above.\r\n    sudo apt-get update && \\\r\n            && sudo apt-get install -y --no-install-recommends libnvinfer-dev=5.1.5-1+cuda10.0\r\n```\r\n\r\n1.  there is a syntax error--> && \\ &&\r\n2.  libnvinfer5=5.1.5-1+cuda10.0  should be installed first before libnvinfer-dev=5.1.5-1+cuda10.0\r\n3.  just change the commands to the same as what is shown in english-language website.\r\n\r\n\r\n", "comments": ["Thanks. Direct link to zh-cn page: https://tensorflow.google.cn/install/gpu?hl=zh-cn\r\n\r\nThis has been fixed in [the source file](https://github.com/tensorflow/docs/blob/master/site/en/install/gpu.md) but translations lag behind. Will be updated on next translation job.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32329\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32329\">No</a>\n"]}, {"number": 32328, "title": "Use keras .fit() method to train adversarial models", "body": "TF2.0.0-RC0 keras question:\r\n\r\nBecause GANs and adversarial models require training two models with different optimizers simultaneously, I don't think this can be achieved currently without a custom training loop, applying only the model.fit() methods. Is this feature already available because I haven't found it in the documentations? To clarify, the feature I would need is to create the generative and the discriminator models, compile the generative model with optimizer_A, compile the discriminator model with optimizer_B, now train them simultaneously but alternately, eg. one batch with discriminator then one batch with generative (using the output of the discriminator model of course for the loss), and do this without having to write a custom training loop. This is the way to go with GANs, but the examples I see all use custom train steps. The problem with custom train steps have limited access to many of the keras features such as saving models, monitoring, etc.", "comments": ["Do you have any use case that requires the feature you are interested in? Please feel free to submit a PR if you have use cases that supports that feature.", "@kristofgiber As mentioned by @ravikyram please provide any use case for this kind of feature? Thanks!", "Hi! Sorry for the delay. My use case was training GANs, any GANs, but I guess if this wasn't clear from my original post then maybe I don't have a strong case and I may be overlooking something trivial. Unfortunately I can't recall the details as Ive moved on. Thank you for your feedback", "Adding @omalleyt12 who is working on refactoring code to make it easier for users to write custom training loops.", "@kristofgiber Thanks for the issue!\r\n\r\nWe've been working on enabling this very use case. In the latest `tf-nightly`, you can do things like this:\r\n\r\n```python\r\nclass MyModel(tf.keras.Model):\r\n  def train_step(self, data):\r\n    x, y = data\r\n    with tf.GradientTape() as tape:\r\n      ...\r\n    self.optimizer1.apply_gradients(...)\r\n    self.optimizer2.apply_gradients(...)\r\n\r\n  def compile(self, optimizer1, optimizer2, ...):\r\n    self.optimizer1 = optimizer1\r\n    self.optimizer2 = optimizer2\r\n    ...\r\n    self._is_compiled = True\r\n```\r\n\r\nThis allow users to provide custom training logic in only a few lines of code, while still supporting all data formats, distribution strategies, Callbacks, etc that Model.fit supports\r\n\r\nWe'll have detailed guides on how to use these new features soon!"]}, {"number": 32327, "title": "I don't like TensorFlow", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\nI used tensorflow and PyTorch and Facebook is the winner of this race\r\nPyTorch is the most simple library and tensorFlow is the most difficult", "comments": ["Closing as not a developer related issue. Please use feature request issues to suggest improvements and open new issues in case a bug is impeding your usage of TensorFlow.", "torch is not easy,either\r\nNO easy except Keras"]}, {"number": 32326, "title": "cannot import tensorflow", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): `import tensorflow as tf`\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): `pip install tensorflow`\r\n- TensorFlow version (use command below): \r\n- Python version: 3.7\r\n- CUDA/cuDNN version:cuda 8.0\r\n- GPU model and memory:quadro 4000\r\n\r\n**Describe the current behavior**\r\ni have installed cuda 8.0 because my GPU support 8.0 but i think this version of tensor flow require cuda 10.0 so i want to downgrade my tensorflow which support cuda 8.0\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nImportError: Could not find 'cudart64_100.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 10.0 from this URL: https://developer.nvidia.com/cuda-90-download-archive\r\n\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\n```\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Mohsin Ali\\Anaconda3\\envs\\first\\lib\\site-packages\\tensorflow\\python\\platform\\self_check.py\", line 75, in preload_check\r\n    ctypes.WinDLL(build_info.cudart_dll_name)\r\n  File \"C:\\Users\\Mohsin Ali\\Anaconda3\\envs\\first\\lib\\ctypes\\__init__.py\", line 364, in __init__\r\n    self._handle = _dlopen(self._name, mode)\r\nOSError: [WinError 126] The specified module could not be found\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:/Users/Mohsin Ali/PycharmProjects/first/tensor.py\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\Mohsin Ali\\Anaconda3\\envs\\first\\lib\\site-packages\\tensorflow\\__init__.py\", line 28, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\Mohsin Ali\\Anaconda3\\envs\\first\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Mohsin Ali\\Anaconda3\\envs\\first\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 30, in <module>\r\n    self_check.preload_check()\r\n  File \"C:\\Users\\Mohsin Ali\\Anaconda3\\envs\\first\\lib\\site-packages\\tensorflow\\python\\platform\\self_check.py\", line 82, in preload_check\r\n    % (build_info.cudart_dll_name, build_info.cuda_version_number))\r\nImportError: Could not find 'cudart64_100.dll'. TensorFlow requires that this DLL be installed in a directory that is named in your %PATH% environment variable. Download and install CUDA 10.0 from this URL: https://developer.nvidia.com/cuda-90-download-archive\r\n```\r\n", "comments": ["TensorFlow 1.13.0 and above needs CUDA 10.", "So what is version that uses cuda 8.0 and how to uninstall this tensor flow and reinstall version that uses 8.0 ", "Check [`pip uninstall`](https://pip.pypa.io/en/stable/reference/pip_uninstall/) and [tested build configurations on TensorFlow website](https://www.tensorflow.org/install/source#tested_build_configurations)\r\n\r\nSeems you need TF 1.4 which is extremely old and not updated anymore", "OK I HAVE CREATED A NEW ENVIRONMENT WITH NO TENSORFLOW I WANT TO NOW INSTALL TENSORFLOW 1.4 SO IS THERE ANY PIP COMMAND TO INSTALL IT \r\nAS THIS COMMAND IS GIVING ERROR\r\n(sec) C:\\Users\\Mohsin Ali\\PycharmProjects\\sec>pip install tensorflow==1.4\r\nCollecting tensorflow==1.4\r\n  ERROR: Could not find a version that satisfies the requirement tensorflow==1.4 (from versions: 1.13.0rc1, 1.13.0rc2, 1.13.1, 1.13.2, 1.14.0rc0, 1.14.0rc1, 1.14.0, 2.0.0a0, 2.0.0b0, 2.0.0b1, 2.0.0\r\nrc0)\r\nERROR: No matching distribution found for tensorflow==1.4\r\n", "Please use `pip debug --verbose` to get the tags supported by your environment, then check against [those supported on PyPi](https://pypi.org/project/tensorflow/1.4.0/#files)", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32326\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32326\">No</a>\n"]}, {"number": 32325, "title": "Fix Tensorflow Lite model accuracy page link", "body": "Fixes #29469", "comments": []}, {"number": 32324, "title": "[r2.0 CherryPick]:Update version to 2.0.0-rc1", "body": "", "comments": []}, {"number": 32323, "title": "Build fails on latest master with clang and CUDA", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: b78ed2c5973ddebb2589558d722ea78da238e815\r\n- Python version: 3.6.8\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source): 0.25.2\r\n- GCC/Compiler version (if compiling from source): clang 6.0.0-1ubuntu2\r\n- CUDA/cuDNN version: 10.2\r\n- GPU model and memory: NVIDIA Tesla K80 11441MiB\r\n\r\n**Describe the problem**\r\n> **FAILED: Build did NOT complete successfully**\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nBuild script:\r\nhttps://github.com/offscale/offregister-tensorflow/blob/5bf7a19f6b5056362442177128dbae92304ef6c3/offregister_tensorflow/ubuntu/utils.py#L148\r\n\r\nSpecifically:\r\n```\r\n./configure\r\nbazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n(fails on that second line)\r\n\r\nEnvironment variables set (+ `PYTHON_LIB_PATH` and `PYTHON_BIN_PATH`):\r\n```\r\n{'CC_OPT_FLAGS': '-march=native',\r\n 'CLANG_CUDA_COMPILER_PATH': '/usr/bin/clang',\r\n 'LD_LIBRARY_PATH': '/usr/local/cuda/extras/CUPTI/lib64',\r\n 'TF_CUDA_CLANG': '1',\r\n 'TF_CUDA_COMPUTE_CAPABILITIES': '3.7',\r\n 'TF_DOWNLOAD_CLANG': '0',\r\n 'TF_DOWNLOAD_MKL': '1',\r\n 'TF_ENABLE_XLA': '0',\r\n 'TF_NEED_COMPUTECPP': '0',\r\n 'TF_NEED_CUDA': '1',\r\n 'TF_NEED_GCP': '0',\r\n 'TF_NEED_GDR': '0',\r\n 'TF_NEED_HDFS': '0',\r\n 'TF_NEED_JEMALLOC': '1',\r\n 'TF_NEED_KAFKA': '0',\r\n 'TF_NEED_MKL': '1',\r\n 'TF_NEED_MPI': '0',\r\n 'TF_NEED_OPENCL': '0',\r\n 'TF_NEED_OPENCL_SYCL': '0',\r\n 'TF_NEED_ROCM': '0',\r\n 'TF_NEED_S3': '0',\r\n 'TF_NEED_TENSORRT': '1',\r\n 'TF_NEED_VERBS': '0',\r\n 'TF_SET_ANDROID_WORKSPACE': '0'}\r\n```\r\n\r\n\r\n**Any other info / logs**\r\n```\r\n\r\nERROR: /home/ubuntu/repos/tensorflow-for-py3/tensorflow/core/kernels/BUILD:2518:1: output 'tensorflow/core/kernels/_objs/dynamic_stitch_op_gpu/dynamic_stitch_op_gpu.cu.pic.o' was not created\r\n[8,641 / 8,655] 4 actions running\r\n    Compiling tensorflow/core/kernels/sparse_matmul_op.cc; 16s local\r\n    Compiling tensorflow/core/kernels/dynamic_stitch_op_gpu.cu.cc; 12s local\r\n    Compiling tensorflow/core/kernels/data/cache_dataset_ops.cc; 7s local\r\n    Compiling tensorflow/core/kernels/fifo_queue_op.cc; 4s local\r\n\r\n\r\n\r\n\r\n\r\nERROR: /home/ubuntu/repos/tensorflow-for-py3/tensorflow/core/kernels/BUILD:2518:1: not all outputs were created or valid\r\n[8,641 / 8,655] 4 actions running\r\n    Compiling tensorflow/core/kernels/sparse_matmul_op.cc; 16s local\r\n    Compiling tensorflow/core/kernels/dynamic_stitch_op_gpu.cu.cc; 12s local\r\n    Compiling tensorflow/core/kernels/data/cache_dataset_ops.cc; 7s local\r\n    Compiling tensorflow/core/kernels/fifo_queue_op.cc; 4s local\r\n\r\n\r\n\r\n\r\n\r\n[8,645 / 8,655] checking cached actions\r\n\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n[8,645 / 8,655] checking cached actions\r\n\r\nUse --verbose_failures to see the command lines of failed build steps.\r\n[8,645 / 8,655] checking cached actions\r\n\r\nINFO: Elapsed time: 3087.912s, Critical Path: 114.34s\r\n[8,645 / 8,655] checking cached actions\r\n\r\nINFO: 5399 processes: 5399 local.\r\n[8,645 / 8,655] checking cached actions\r\n\r\nFAILED: Build did NOT complete successfully\r\n\r\nFAILED: Build did NOT complete successfully\r\n```", "comments": ["Latest error, from running on a new server\u2014same specs as above\u2014on master (f15b613f7eb59edb3feec221bfd17a2249efc851):\r\n```\r\n[5,671 / 11,140] 4 actions running\r\n    @nccl_archive//:device_lib; 2s local\r\n    @nccl_archive//:device_lib; 1s local\r\n    @nccl_archive//:device_lib; 0s local\r\n    Compiling external/nccl_archive/src/misc/group.cc [for host]; 0s local\r\n\r\n\r\n\r\n\r\n\r\nbazel-out/host/bin/external/nccl_archive/_virtual_includes/device_hdrs/common.h(29): warning: extern declaration of the entity ncclFuncs is treated as a static definition\r\n\r\nbazel-out/host/bin/external/nccl_archive/_virtual_includes/device_hdrs/common.h:29:19: error: storage size of 'ncclFuncs' isn't known\r\n extern __device__ ncclKern_t ncclFuncs[];\r\n                   ^~~~~~~~~\r\n[5,671 / 11,140] 4 actions running\r\n    @nccl_archive//:device_lib; 2s local\r\n    @nccl_archive//:device_lib; 1s local\r\n    @nccl_archive//:device_lib; 0s local\r\n    Compiling external/nccl_archive/src/misc/group.cc [for host]; 0s local\r\n\r\n\r\n\r\n\r\n\r\nERROR: /home/ubuntu/.cache/bazel/_bazel_ubuntu/7d3379297965407e4f621f04220127eb/external/nccl_archive/BUILD.bazel:53:1: output 'external/nccl_archive/_objs/device_lib/max_f16_all_gather.cu.pic.o' was not created\r\n[5,671 / 11,140] 4 actions running\r\n    @nccl_archive//:device_lib; 2s local\r\n    @nccl_archive//:device_lib; 1s local\r\n    @nccl_archive//:device_lib; 0s local\r\n    Compiling external/nccl_archive/src/misc/group.cc [for host]; 0s local\r\n\r\n\r\n\r\n\r\n\r\nERROR: /home/ubuntu/.cache/bazel/_bazel_ubuntu/7d3379297965407e4f621f04220127eb/external/nccl_archive/BUILD.bazel:53:1: not all outputs were created or valid\r\n[5,671 / 11,140] 4 actions running\r\n    @nccl_archive//:device_lib; 2s local\r\n    @nccl_archive//:device_lib; 1s local\r\n    @nccl_archive//:device_lib; 0s local\r\n    Compiling external/nccl_archive/src/misc/group.cc [for host]; 0s local\r\n\r\n\r\n\r\n\r\n\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n[5,675 / 11,140] checking cached actions\r\n\r\nUse --verbose_failures to see the command lines of failed build steps.\r\n[5,675 / 11,140] checking cached actions\r\n\r\nINFO: Elapsed time: 974.854s, Critical Path: 54.00s\r\n[5,675 / 11,140] checking cached actions\r\n\r\nINFO: 2420 processes: 2420 local.\r\n[5,675 / 11,140] checking cached actions\r\n\r\n[5,675 / 11,140] checking cached actions\r\n\r\nFAILED: Build did NOT complete successfully\r\n\r\nFAILED: Build did NOT complete successfully\r\n\r\n```", "Can you try the build without using the cache?", "Building with latest master (003323c95155c5fcd3e4be796d2cb1e4c0589c2d) after `rm -rf ~/repos/tensorflow-for-py3 ~/.cache/bazel`, full build output:\r\nhttps://gist.githubusercontent.com/SamuelMarks/fcd18d1704d69bb6f7827a92619768b2/raw/af9eac14bbe63f7bbd76c92fce6fa63e71858b10/tflog.txt\r\n\r\n```\r\nERROR: tensorflow/lite/experimental/microfrontend/lib/BUILD:70:1: undeclared inclusion(s) in rule '//tensorflow/lite/experimental/microfrontend/lib:log_scale':\r\n[13.237.198.227] out: this rule is missing dependency declarations for the following files included by 'tensorflow/lite/experimental/microfrontend/lib/log_lut.c':\r\n[13.237.198.227] out:   '/usr/lib/clang/6.0.0/include/stdint.h'\r\n```\r\n\r\nEDIT: That file looks pretty normal [`tensorflow/lite/experimental/microfrontend/lib/log_lut.h`](https://github.com/tensorflow/tensorflow/blob/003323c95155c5fcd3e4be796d2cb1e4c0589c2d/tensorflow/lite/experimental/microfrontend/lib/log_lut.h). Do I need a different version of clang (other than 6.0.0-1ubuntu2)?\r\n```\r\n$ sudo apt list -a --installed libstdc++*\r\nListing... Done\r\nlibstdc++-7-dev/bionic-updates,bionic-security,now 7.4.0-1ubuntu1~18.04.1 amd64 [installed,automatic]\r\nlibstdc++-7-dev/bionic 7.3.0-16ubuntu3 amd64\r\n\r\nlibstdc++6/bionic-updates,bionic-security,now 8.3.0-6ubuntu1~18.04.1 amd64 [installed,automatic]\r\nlibstdc++6/bionic 8-20180414-1ubuntu2 amd64\r\n```", "Build fails with latest `v2.0.0` tag (64c3d382ca), full log:\r\nhttps://gist.github.com/ea7771ab9fb99faf8fb0d67f246ddf25\r\n\r\n> cp: cannot stat '/usr/include/x86_64-linux-gnu/NvInferPlugin.h': No such file or directory", "Hi @SamuelMarks!  Could you try again with a suitable [configurations ](https://www.tensorflow.org/install/source#preconfigured_configurations) and command \r\n`bazel build --config=cuda [--config=option] //tensorflow/tools/pip_package:build_pip_package` and Latest version TF 2.6", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32323\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32323\">No</a>\n"]}, {"number": 32321, "title": "Update ADOPTERS.md", "body": "Kindly include me into discuss@tensorflow", "comments": ["Closing as PR would become empty after removing trailing whitespace"]}, {"number": 32320, "title": "keras model.evaluate() progress bar WAY too long by default", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): just testing this https://www.tensorflow.org/tutorials/keras/basic_classification\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 fully updated\r\n- TensorFlow installed from (source or binary): `pip3 install --user tensorflow-gpu==2.0.0-rc0`\r\n- TensorFlow version (use command below): `v2.0.0-beta1-5101-gc75bb66a99 2.0.0-rc0`\r\n- Python version: 3.7.4\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: GeForce GTX 1660 Ti, 6 GB\r\n\r\n**Describe the current behavior**\r\nJust running a basic image classifier with Keras. Import data, create model, train, evaluate.\r\nI run `python script-name.py` in the Command Prompt.\r\n`model.evaluate()` prints out an insanely long progress bar at the end. It's many, MANY pages long, with Command Prompt already maximized (so one page is already a lot of characters). I have to scroll WAAAY UP to see the previous output.\r\n\r\n**Describe the expected behavior**\r\nI know I could turn off verbosity, but I would expect sane defaults for the progress bars printed by TF/Keras. And with `verbose=1` that thing is so huge, it's useless.\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\n\r\n# TensorFlow and tf.keras\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n\r\n# Helper libraries\r\nimport numpy as np\r\nimport matplotlib.pyplot as plt\r\nfrom pprint import pprint\r\n\r\n# CUDA vs CPU\r\nimport os\r\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\r\n\r\nprint(tf.__version__)\r\n\r\n# load train/test data\r\nfashion_mnist = keras.datasets.fashion_mnist\r\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\r\nclass_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\r\n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\r\n\r\n# print shape/size for train/test data\r\nprint(train_images.shape, len(train_labels), test_images.shape, len(test_labels))\r\n\r\n# show first image\r\nplt.figure()\r\nplt.imshow(train_images[0])\r\nplt.colorbar()\r\nplt.grid(False)\r\n#plt.show()\r\n\r\n# normalize pixel values (0...1)\r\ntrain_images = train_images / 255.0\r\ntest_images = test_images / 255.0\r\n\r\n# show first 25 images, sanity check\r\nplt.figure(figsize=(10,10))\r\nfor i in range(25):\r\n    plt.subplot(5,5,i+1)\r\n    plt.xticks([])\r\n    plt.yticks([])\r\n    plt.grid(False)\r\n    plt.imshow(train_images[i], cmap=plt.cm.binary)\r\n    plt.xlabel(class_names[train_labels[i]])\r\n#plt.show()\r\n\r\n# build the model\r\n# flat 1D layer\r\n# dense 128-node layer\r\n# dense softmax output layer\r\nmodel = keras.Sequential([\r\n    keras.layers.Flatten(input_shape=(28, 28)),\r\n    keras.layers.Dense(128, activation=tf.nn.relu),\r\n    keras.layers.Dense(10, activation=tf.nn.softmax)\r\n])\r\n\r\n# compile the model\r\nmodel.compile(optimizer='adam',\r\n              loss='sparse_categorical_crossentropy',\r\n              metrics=['accuracy'])\r\n\r\n# train the model\r\nmodel.fit(train_images, train_labels, epochs=5)\r\n\r\n# evaluate the model\r\ntest_loss, test_acc = model.evaluate(test_images, test_labels)\r\nprint('Test accuracy:', test_acc)\r\n```\r\n", "comments": ["I tried on Google colab but it is working as expected.Please see the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/4e8b0ca20a27ab518f6329aaf5479dd6/untitled127.ipynb).\r\nAnd, I could replicate the issue on my system by running it on terminal. Please see the screenshot below.\r\n![Screenshot from 2019-09-09 11-22-50](https://user-images.githubusercontent.com/48476109/64506178-3421e300-d2f4-11e9-852a-9d1a6d1e64ac.png)\r\n Thnaks!", "Same problem here.\r\n\r\nCode:\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nprint('Version of TensorFlow:', tf.__version__)\r\nprint('Version of tf.keras:', tf.keras.__version__)\r\n\r\n# Import dataset\r\nfashion_mnist = keras.datasets.fashion_mnist\r\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\r\n\r\n# Build and Compile the model\r\nmodel = keras.Sequential([\r\n    keras.layers.Flatten(input_shape=(28, 28)),\r\n    keras.layers.Dense(10, activation='softmax')\r\n])\r\nmodel.compile(optimizer='adam',\r\n              loss='sparse_categorical_crossentropy',\r\n              metrics=['accuracy']\r\n             )\r\n\r\n# Train the model\r\nprint('Training')\r\nmodel.fit(train_images, train_labels, epochs=5)\r\n\r\n# Evaluate the model\r\nprint('Evaluating')\r\ntest_loss, test_acc = model.evaluate(test_images, test_labels, verbose=1)\r\nprint('\\nTest accuracy:', test_acc)\r\n```\r\n\r\nOutput:\r\n![image](https://user-images.githubusercontent.com/14865017/64515840-a7742680-d2ed-11e9-973f-488e72f1c440.png)\r\nNotice how short the slider is. It is all filled with \"=\" signs.", "I confirm I am seeing the issue too. The eval progress bar seems to be broken. Adding a batch size and a number of steps does not change the erroneous behavior:\r\n\r\nmodel.evaluate(test_images, test_labels, verbose=1, batch_size=1000, steps=10)\r\nExpecting exactly 10 progress steps with an eval dataset of 10,000 elements\r\nGetting many many steps....", "Same issue here. Even on the official tutorial page, the progress bar is extremely long. \r\n[https://www.tensorflow.org/tutorials/keras/classification](url)", "@qlzh727 Could this be related to the training_v2 loop?", "Very likely.", "https://github.com/tensorflow/tensorflow/blob/f9ad945a479caccca9002dcfe0e9623e3b753360/tensorflow/python/keras/engine/training_v2.py#L448\r\n`samples=use_sample` should be `samples=total_samples`", "@djshen Thanks for the find! Agreed, would you please submit a PR to fix this? You can add me as a reviewer, I will approve", "@omalleyt12 I created a PR https://github.com/tensorflow/tensorflow/pull/33921", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32320\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/32320\">No</a>\n", "same here, is going to be merged in 2.1?", "Yes this should be fixed in 2.1"]}, {"number": 32319, "title": "Module 'gast' has no attribute 'Num'", "body": "I got an error message including a request that I report a bug.\r\n\r\nHere's the code:\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport platform\r\n\r\nprint()\r\nprint(f\"PLATFORM:\\n---------\\n{platform.platform()}\")\r\nprint(\"\\nTENSORFLOW:\\n----------\")\r\nfor a in tf.version.__all__:\r\n    print(f\"{a}: {getattr(tf.version, a)}\")\r\n\r\nprint(f\"\\nNUMPY:\\n-----\\n{np.version.version}\")\r\n\r\nprint(f\"\\nPYTHON:\\n-------\\n{sys.version}\\n\")\r\n\r\nnp.random.seed(0)\r\ntf.random.set_seed(0)\r\n\r\n\r\nmodel = tf.keras.models.Sequential([\r\n    tf.keras.layers.Dense(1, activation=\"linear\")\r\n])\r\nmodel.compile(optimizer=\"sgd\", loss=\"mse\")\r\n\r\nx = np.random.uniform(size=(1,1))\r\ny = np.random.uniform(size=(1,))\r\nmodel.fit(x, y, epochs=1)\r\n```\r\n\r\nAnd here's the output, including system info, module versions, etc.\r\n```\r\n\r\nPLATFORM:\r\n---------\r\nDarwin-18.7.0-x86_64-i386-64bit\r\n\r\nTENSORFLOW:\r\n----------\r\nCOMPILER_VERSION: 4.2.1 Compatible Apple LLVM 10.0.0 (clang-1000.11.45.5)\r\nGIT_VERSION: v2.0.0-beta1-5101-gc75bb66a99\r\nGRAPH_DEF_VERSION: 119\r\nGRAPH_DEF_VERSION_MIN_CONSUMER: 0\r\nGRAPH_DEF_VERSION_MIN_PRODUCER: 0\r\nVERSION: 2.0.0-rc0\r\n\r\nNUMPY:\r\n-----\r\n1.17.1\r\n\r\nPYTHON:\r\n-------\r\n3.7.4 (default, Jul  9 2019, 18:13:23) \r\n[Clang 10.0.1 (clang-1001.0.46.4)]\r\n\r\nTrain on 1 samples\r\nWARNING:tensorflow:Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x1492748c0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\r\nWARNING: Entity <function Function._initialize_uninitialized_variables.<locals>.initialize_variables at 0x1492748c0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Num'\r\n1/1 [==============================] - 0s 157ms/sample - loss: 1.2336\r\n\r\n<tensorflow.python.keras.callbacks.History at 0x14927b5d0>\r\n```", "comments": ["Hello,\r\n\r\n3 hours ago, `gast` library was updated from 0.2.2 to 0.3.0 and `Num` constant was removed (check commit https://github.com/serge-sans-paille/gast/commit/231ee7a1b599b68354acbbf8b8d19acc8a2ce60a#diff-88b99bb28683bd5b7e3a204826ead112R99).  \r\n\r\nTF requires `gast>=0.2.0`, so newer version of `gast` module is automatically installed and that's probably why it fails with error `AttributeError: module 'gast' has no attribute 'Num'`.\r\n\r\nThis error may occur for example on the line 236 in `tensorflow/python/autograph/pyct/qual_names.py` (https://github.com/tensorflow/tensorflow/blob/r1.14/tensorflow/python/autograph/pyct/qual_names.py#L236):\r\n```\r\nif isinstance(s.value, gast.Num):\r\n```", "@mgreenbe thank you for filing the bug, and @tocosastalo thanks for the info.\r\n\r\nWorkaround that worked for me: `$ pip3 install 'gast==0.2.2'`.", "@jlebar & @tocosastalo & @mgreenbe thank you:\r\n> @mgreenbe thank you for filing the bug, and @tocosastalo thanks for the info.\r\n> \r\n> Workaround that worked for me: `$ pip3 install 'gast==0.2.2'`.\r\n\r\nThis worked for me too: $ `pip3 install gast==0.2.2.`", "I encountered the same warning with tensorflow-gpu2.0beta1, and the above fix works for me too:\r\n```\r\n$ pip install gast==0.2.2\r\nCollecting gast==0.2.2\r\nInstalling collected packages: gast\r\n  Found existing installation: gast 0.3.1\r\n    Uninstalling gast-0.3.1:\r\n      Successfully uninstalled gast-0.3.1\r\nSuccessfully installed gast-0.2.2\r\n```\r\n", "Using the older version of `gast` worked for me too. I'll leave it to @jlebar or someone else on the tensorflow team to close this issue at their discretion, presumably once `tensorflow` and `gast=0.3.x` are interacting nicely.", "#32332 fixes this for 1.15, there's a similar PR for 2.0 and a commit on master. Adding @goldiegadde as she is fixing this", "I don\u2019t understand what the status of this is. The [corresponding commit\r\non master][1] hasn\u2019t fixed this in nightlies:\r\n\r\n```\r\n$ cat test.py\r\nimport tensorflow as tf\r\n\r\nprint(tf.__version__)\r\n\r\n@tf.function\r\ndef foo():\r\n  return 1\r\n\r\nfoo()\r\n$ AUTOGRAPH_VERBOSITY=10 python test.py\r\n2.0.0-dev20190910\r\nWARNING:tensorflow:Entity <function foo at 0x7f71ac1990d0> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\r\n```\r\n\r\nRunning `pip install gast==0.2.2` fixes the above issue.\r\n\r\nI\u2019m not sure what those changes in `pip_new.sh` do, but is there a plan\r\nto update the [Pip dependencies in `setup.py`][2] so that people who\r\nsimply run `pip install tf-nightly-2.0-preview` get a working install?\r\n\r\n[1]: https://github.com/tensorflow/tensorflow/commit/cc2e03a1384f80035f9fbe1949dd46004a62b41f\r\n[2]:\r\nhttps://github.com/tensorflow/tensorflow/blob/a25803e6ee8f90e3604651ad813e64fccd1e408e/tensorflow/tools/pip_package/setup.py#L57\r\n", "Classical error of having same dependency specified in two places. I'll send a fix, sorry for this", "thanks! and no worries :-)\r\n", "Should be fixed by c72125bd59858ec82a9238b232bbd77c45889c5a, #32390 and #32391 (the last two need merging before fixing on corresponding branches)", "Should be fixed now, keeping issue open until verified", "Thanks guys for the fix! Any chance we'll get a build for mac-python3.7?", "Confirmed fixed for me on `tf-nightly-2.0-preview==2.0.0.dev20190911`. Thank you!\r\n\r\nFeel free to close at your discretion.", "In that case, closing.\r\n\r\nThank you for verifying.\r\n\r\n@arainboldt the fix should get released in all pips we are releasing.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32319\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32319\">No</a>\n", "`gast-0.3.2` on `Tensorflow 2.0.0rc` still get that issue, but for 'Str'. \r\nMy solution is downgrading to `gast-0.2.2`\r\n\r\nWARNING:tensorflow:Entity <function <lambda> at 0x000002567C2DB950> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: module 'gast' has no attribute 'Str'\r\n", "@cuongth95: Right; downgrading is the official solution at this time.\r\n", "`gast` has been pinned in the meantime, pending new release", "@mihaimaruseac also seeing gast related errors on 1.14, e.g.\r\n```\r\nWARNING - 140706076063552 - Entity <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff2da862f60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Conv.call of <tensorflow.python.layers.convolutional.Conv2D object at 0x7ff2da862f60>>: AssertionError: Bad argument number for Name: 3, expecting 4\r\n```\r\n\r\nPinning to 0.2.2 fixes", "New update:\r\n\r\n`gast` has been pinned to 0.2.2 for 1.15 and 2.0 and later releases as well as nightly.\r\nTF 1.14 or earlier don't have `gast` pinned and won't get it as we are not doing more releases there (except for security vulnerabilities).\r\n\r\nIf you encounter this issue on 1.14 or earlier, please install gast==0.2.2 using pip before installing tensorflow.", "I'm still getting the error even with gast 0.2.2.\r\nI really need help to get this fixed.", "We are currently working on getting `gast==0.3.2`. Apologies for the delay.", "Starting from TensorFlow 2.2.0, it will work with gast 0.3.x but NOT gast 0.2.x any more. For TF <= 2.1, gast 0.2.2 is needed."]}, {"number": 32318, "title": "AttributeError: 'str' object has no attribute 'keys'", "body": "\r\n\r\n**System information**\r\n- Have I written custom code: yes\r\n- OS Platform and Distribution: Ubuntu 18.04\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: v2.0.0-beta1-5101-gc75bb66 2.0.0-rc0\r\n- Python version: 3.7\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: Nvidia rtx 2070\r\n\r\n**Describe the current behavior**\r\nI want to visualize the embeddings of my model but when i add:\r\n```\r\nembeddings_freq=1,\r\nembeddings_metadata='metadata.tsv'\r\n```\r\nin the tensorboard callbacks\r\ni am getting an error.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nfrom os import makedirs\r\nfrom os.path import exists\r\nimport numpy as np\r\n\r\nmodel_dir = \"tmp/model_mnist/\"\r\nlog_dir = \"logs_mnist/\"\r\nif not exists(log_dir):\r\n    makedirs(log_dir)\r\ndata_format = ('channels_first' if tf.test.is_built_with_cuda() else 'channels_last')\r\n\r\nbatch_size = 128\r\nnum_classes = 10\r\nepochs = 12\r\n\r\n# input image dimensions\r\nimg_rows, img_cols = 28, 28\r\n\r\n# the data, split between train and test sets\r\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\r\n\r\nif data_format == 'channels_first':\r\n    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\r\n    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\r\n    input_shape = (1, img_rows, img_cols)\r\nelse:\r\n    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\r\n    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\r\n    input_shape = (img_rows, img_cols, 1)\r\n\r\nx_train = x_train.astype('float32')\r\nx_test = x_test.astype('float32')\r\nx_train /= 255\r\nx_test /= 255\r\nprint('x_train shape:', x_train.shape)\r\nprint(x_train.shape[0], 'train samples')\r\nprint(x_test.shape[0], 'test samples')\r\n\r\n# save class labels to disk to color data points in TensorBoard accordingly\r\nwith open(log_dir + 'metadata.tsv', 'w') as f:\r\n    np.savetxt(f, y_test, fmt=\"%d\")\r\n\r\n# convert class vectors to binary class matrices\r\ny_train = tf.keras.utils.to_categorical(y_train, num_classes)\r\ny_test = tf.keras.utils.to_categorical(y_test, num_classes)\r\n\r\nmodel = tf.keras.models.Sequential()\r\nmodel.add(tf.keras.layers.Conv2D(32, kernel_size=(3, 3),\r\n                                 activation='relu',\r\n                                 input_shape=input_shape))\r\nmodel.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))\r\nmodel.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\r\nmodel.add(tf.keras.layers.Dropout(0.25))\r\nmodel.add(tf.keras.layers.Flatten())\r\nmodel.add(tf.keras.layers.Dense(128, activation='relu'))\r\nmodel.add(tf.keras.layers.Dropout(0.5))\r\nmodel.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\r\n\r\nmodel.compile(loss=tf.keras.losses.categorical_crossentropy,\r\n              optimizer=tf.keras.optimizers.Adadelta(lr=1.),\r\n              metrics=['accuracy'])\r\n\r\ncallbacks = tf.keras.callbacks.TensorBoard(log_dir=log_dir,\r\n                                           embeddings_freq=1,\r\n                                           embeddings_metadata='metadata.tsv')\r\n\r\nmodel.fit(x_train, y_train,\r\n          batch_size=batch_size,\r\n          callbacks=[callbacks],\r\n          epochs=epochs,\r\n          verbose=1,\r\n          validation_data=(x_test, y_test))\r\nscore = model.evaluate(x_test, y_test, verbose=0)\r\nprint('Test loss:', score[0])\r\nprint('Test accuracy:', score[1])\r\n\r\n```\r\n\r\n**Other info / logs**\r\n\r\n> Traceback (most recent call last):\r\n  File \"/home/chris/Desktop/tests/mnist.py\", line 75, in <module>\r\n    validation_data=(x_test, y_test))\r\n  File \"/home/chris/miniconda3/envs/mdl/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 734, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/home/chris/miniconda3/envs/mdl/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\", line 292, in fit\r\n    mode=ModeKeys.TRAIN)\r\n  File \"/home/chris/miniconda3/envs/mdl/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\", line 103, in configure_callbacks\r\n    callback_list.set_model(callback_model)\r\n  File \"/home/chris/miniconda3/envs/mdl/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\", line 217, in set_model\r\n    callback.set_model(model)\r\n  File \"/home/chris/miniconda3/envs/mdl/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\", line 1509, in set_model\r\n    self._configure_embeddings()\r\n  File \"/home/chris/miniconda3/envs/mdl/lib/python3.7/site-packages/tensorflow_core/python/keras/callbacks.py\", line 1536, in _configure_embeddings\r\n    'argument: ' + str(self.embeddings_metadata.keys()))\r\nAttributeError: 'str' object has no attribute 'keys'\r\n", "comments": ["@christk1, were you able to resolve this issue? I'm getting the same one"]}, {"number": 32317, "title": "[INTEL MKL] Fixed missing copts in BUILD file.", "body": "The -DINTEL_MKL compiler option was not getting passed to mkl related eager files (removed in a prior commit.) Added tf_copts to the build, tf_copts includes -DINTEL_MKL.", "comments": ["Pinging @mahmoud-abuzaina  and @penpornk ", "The use of `nocopts` will break the TF build with Bazel 1.0. As 1.0 is not yet released, this PR will not cause immediate issues. However, I suggest to have a follow-up PR that changes `tf_copts()` to `tf_copts(allow_exceptions = True)` and removes the `nocopts` attribute ASAP, so you can both cherrypick this PR and we are still on the right track for 1.0 migration.", "Thanks @scentini for the explanation. Yes, I am going to submit another PR soon that will use tf_copts(allow_exceptions = True) to be merged with master. But since the r2.0 still does not support that argument, we need this PR to be cherry-picked into r2.0.", "@scentini Thank you for taking a look! \r\n@mahmoud-abuzaina To save time, I can submit the change internally after this PR is merged into the master branch. :)\r\nApproving this PR now.", "@penpornk thank you so much. That will be great. "]}, {"number": 32316, "title": "[INTEL MKL]  Fixed missing copts in BUILD file.", "body": "The -DINTEL_MKL compiler option was not getting passed to mkl related eager files (removed in a prior commit.)  Added tf_copts  to the build, tf_copts includes -DINTEL_MKL.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F32316) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!"]}, {"number": 32315, "title": "Support for 32 bits architecture", "body": "Several users are still using Python32 bits and they cannot install TensorFlow. For them, `pip install tensorflow` fails as no wheel matches the tags expected by their environment (to debug, `pip debug --verbose` shows only tags that don't math the filenames of our wheels).\r\n\r\nThere is some requests to support 32 bits, see for example #31431 \r\n\r\nThis is not going to be easy as we need to also compile the C++ codebase in 32 bits mode and that would cause issues with code written assuming types have a certain bit width.\r\n\r\nThere is no change in the user visible API, just a new set of wheels to support more users.\r\n\r\nOpening this to reference in all similar issues.", "comments": ["a few people have been asking me today about pip install 32 bit tensorflow support. ", "Will raise the issue upward.", "Having the same problem here. Would really appreciate a fix", "Also, got a few asking questions about this issue today.", "Any fix on this @mihaimaruseac ? Still having problems and I know a lot of others are too. Thanks so much", "This is best effort, we are not going to work into this this year. Compiling for both 32 bits and 64 bits is not that easy so we don't have this included in any milestones plan at the moment.\r\n\r\nHowever, if the community wants to contribute patches so 32 bit support can be provided, they would be very welcomed.", "Kk then I am going to stop supporting Tensoeflow. It does not make sense to use a framework which Python does not support by default. I even had people write to me to fix this today, that you guys are not seeing this is a huge issue like it is, shows where your priorities are. \r\n\r\nI know that @husligc also see people having this issues daily and even he has it, it's funny you guys dont think that is a huge problem.. ", "We would appreciate a python 32bit fix, some distros install python 32 bit by default and there's no way around it ", "As I stated, there is not enough time to duplicate all CI builds and to fix all the bugs that would get uncovered from there. And clearly this is not an issue that can be solved overnight.", "This is a high priority for me someone just asked me again a few min ago on how to install TensorFlow 2.0 for windows 10 32bit version. \r\n\r\nThis thread will be going wild. Maybe I should tag Windows contributes into this thread.", "@petewarden @jhseu @terrytangyuan @xiejw @ezhulenev @feihugis @jsimsa @skye @ilblackdragon @asimshankar @MarkDaoust @yongtang @mrry @benoitsteiner", "A lot of my clients asking for this too. would appreciate a fix", "another one just asked me for a fix -_-", "more people have asked me private for a fix today", "This is not on our roadmap. I do not think that will change for the next year.\r\nI will lock this thread, because added repeated requests will not change the roadmap."]}, {"number": 32314, "title": "Cannot load fashion_mnist dataset", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Home 64bit\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 1.12\r\n- Python version: 3.6.6\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 9.0/7.5\r\n- GPU model and memory: GeForce 940M\r\n\r\n\r\n\r\n**Describe the problem**\r\nwhen I try to use the fashion_mnist dataset, it starts to read the data from the website, but after a while, the website shuts down my connection because I am connecting too often (WinError 10054).\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\n\r\nfashion_mnist = keras.datasets.fashion_mnist\r\n\r\n(train_images, train_labels),(test_images, test_labels) = fashion_mnist.load_data()\r\n```\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n(it's loading...)\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\admin\\Desktop\\working as intended\\python pls\\love_copying_code_instead_of_writing_it_urself.py\", line 6, in <module>\r\n    (train_images, train_labels),(test_images, test_labels) = fashion_mnist.load_data()\r\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\fashion_mnist.py\", line 52, in load_data\r\n    paths.append(get_file(fname, origin=base + fname, cache_subdir=dirname))\r\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\data_utils.py\", line 249, in get_file\r\n    urlretrieve(origin, fpath, dl_progress)\r\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\urllib\\request.py\", line 277, in urlretrieve\r\n    block = fp.read(bs)\r\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\http\\client.py\", line 449, in read\r\n    n = self.readinto(b)\r\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\http\\client.py\", line 493, in readinto\r\n    n = self.fp.readinto(b)\r\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\socket.py\", line 586, in readinto\r\n    return self._sock.recv_into(b)\r\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\ssl.py\", line 1009, in recv_into\r\n    return self.read(nbytes, buffer)\r\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\ssl.py\", line 871, in read\r\n    return self._sslobj.read(len, buffer)\r\n  File \"C:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python36\\lib\\ssl.py\", line 631, in read\r\n    v = self._sslobj.read(len, buffer)\r\nConnectionResetError: [WinError 10054] \u8fdc\u7a0b\u4e3b\u673a\u5f3a\u8feb\u5173\u95ed\u4e86\u4e00\u4e2a\u73b0\u6709\u7684\u8fde\u63a5\u3002\r\n```", "comments": ["Was able to execute the given code without any error on colab with Tensorflow 1.12.0. Please see the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/b865119741330d3fd1a5ebcbb4f4d157/untitled128.ipynb). Thanks!", "it's very weird because I can run the code in colab but not on my own computer, so do I just turn to colab from now on?", "This looks like a proxy configuration issue where you are trying to connect from firewall corporate network. \r\nThe workaround can be;\r\nYou can download the data from this link\r\nhttps://www.kaggle.com/zalando-research/fashionmnist\r\nLater you can use ```tf.keras.utils.get_file``` to load the dataset.\r\nSee,\r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/utils/get_file", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32314\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32314\">No</a>\n", "is this issue has solved?", "no, when I run the code above with the newest version of tensorflow, it gives a different error:\r\n`OSError: Not a gzipped file (b'\\x00\\x00')`\r\n"]}, {"number": 32313, "title": "tensorflow.python.framework.errors_impl.FailedPreconditionError: TensorRT is not enabled!", "body": "I am trying to use tensorflow-1.10 to optimize my pb model.\r\ntrt_graph = trt.create_inference_graph(\r\n   input_graph_def = graph_def,\r\n   outputs = outputs,\r\n   max_batch_size=1,\r\n   max_workspace_size_bytes=workspace_size,\r\n   precision_mode='INT8',\r\n   minimum_segment_size=3)\r\n", "comments": ["@li829, Please elaborate the issue with context. And also, provide the code snippet to reproduce the issue. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32313\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32313\">No</a>\n"]}, {"number": 32312, "title": "tensorflow.python.framework.errors_impl.FailedPreconditionError: TensorRT is not enabled!", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n", "comments": []}, {"number": 32311, "title": "LayerNormalization fails when given tuple as axis input", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux-4.14.137+-x86_64-with-Ubuntu-18.04-bionic\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: NA\r\n- TensorFlow installed from (source or binary): Google colab has it preinstalled\r\n- TensorFlow version (use command below): 1.14.0\r\n- Python version: (major, minor, micro, releaselevel, serial) (3, 6, 8, 'final', 0)\r\n- Bazel version (if compiling from source): NA\r\n- GCC/Compiler version (if compiling from source): NA\r\n- CUDA/cuDNN version: CUDA Version: 10.1\r\n- GPU model and memory: Tesla K80 11441MiB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n```python\r\nSequential([Input(shape=(64, 64, 3), dtype=np.float32), LayerNormalization(axis=(-3, -2, -1))])\r\n```\r\nfails with error\r\n```text\r\n---------------------------------------------------------------------------\r\n\r\nTypeError                                 Traceback (most recent call last)\r\n\r\n<ipython-input-22-18267fdf3265> in <module>()\r\n----> 1 Sequential([Input(shape=(64, 64, 3), dtype=np.float32), LayerNormalization(axis=(-3, -2, -1))])\r\n\r\n6 frames\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/normalization.py in build(self, input_shape)\r\n    957     for idx, x in enumerate(self.axis):\r\n    958       if x < 0:\r\n--> 959         self.axis[idx] = ndims + x\r\n    960 \r\n    961     # Validate axes\r\n\r\nTypeError: 'tuple' object does not support item assignment\r\n```\r\n\r\nThis is because the lines:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/normalization.py#L929-L930\r\n```python\r\n    if isinstance(axis, (list, tuple)):\r\n      self.axis = axis[:]\r\n```\r\nmake a copy of the tuple instead of converting it to a list and later the lines:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/normalization.py#L954-L956\r\n```python\r\n    # Convert axis to list and resolve negatives\r\n    if isinstance(self.axis, int):\r\n      self.axis = [self.axis]\r\n```\r\ndo not take care of the case when axis is a tuple.\r\n\r\n**Describe the expected behavior**\r\nFix is simple, replace the lines:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/normalization.py#L954-L956\r\nwith:\r\n```python\r\n    # Convert axis to list and resolve negatives\r\n    if isinstance(self.axis, int):\r\n      self.axis = [self.axis]\r\n    elif isinstance(self.axis, tuple):\r\n      self.axis = list(axis)\r\n```\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```python\r\nSequential([Input(shape=(64, 64, 3), dtype=np.float32), LayerNormalization(axis=(-3, -2, -1))])\r\n```\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["The same code appears in Tensorflow 2 as well:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/layers/normalization.py#L929-L930\r\n```python\r\n    if isinstance(axis, (list, tuple)):\r\n      self.axis = axis[:]\r\n```\r\nhttps://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/layers/normalization.py#L954-L956\r\n```python\r\n    # Convert axis to list and resolve negatives\r\n    if isinstance(self.axis, int):\r\n      self.axis = [self.axis]\r\n```", "What is the convention? Some functions accept tuples, lists and ints for the axis argument. Others only accept lists and integers.", "I can reproduce the issue even with `tensorflow==1.15.0rc0`. However, If you change `axis` from `tuple` to `list`, then there is no error. The error is also clearly points the source of error `TypeError: 'tuple' object does not support item assignment`.\r\n\r\nPlease check the [gist with 1.15.0rc0`](https://colab.sandbox.google.com/gist/jvishnuvardhan/73c0016dfeb542508516cbc9618dc69f/tf32311.ipynb). Thanks!", "Should I submit a pull request with the fix?", "Please feel free to create a fix and tag me.", "@robieta  I did post a fix in the original post. I didn't create a pull request because I am not sure what the convention is. Some functions in tensorflow accept tuples, lists and ints as axis while others only accept list and ints for axis.\r\n\r\n Fix is simple, replace the lines:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/normalization.py#L954-L956\r\nwith:\r\n```python\r\n # Convert axis to list and resolve negatives\r\n    if isinstance(self.axis, int):\r\n      self.axis = [self.axis]\r\n    elif isinstance(self.axis, tuple):\r\n      self.axis = list(axis)\r\n```", "@robieta Also note that the same code is present in tensorflow 2. Maybe tag the issue as tf2 as well.", "I think the fix you proposed is reasonable. Particularly for higher level symbols like Layers we try to be fairly permissive as long as it's unambiguous what the user wants. (Which in this case it is.)", "@robieta I created a pull request https://github.com/tensorflow/tensorflow/pull/32463 .\r\nMaybe add a test case for this?", "@robieta So the pull request got merged into version 1.14, but the same code is present in r2.0.\r\nhttps://github.com/tensorflow/tensorflow/blob/r2.0/tensorflow/python/keras/layers/normalization.py#L954-L956\r\nCan you merge into that as well? or do I need to create a separate pull request for that?", "I don't think this warrants a cherrypick given how far along the 2.0 RC process is. It will automatically be picked up in 2.1.", "Closing issue since pull request fixing it has been merged in v1.14", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=32311\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=32311\">No</a>\n"]}]