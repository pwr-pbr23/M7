[{"number": 7570, "title": "What can replace tf.RegisterShape in tensorflow 1.0.0?", "body": "```\r\nTraceback (most recent call last):\r\n  File \"tools/train_net.py\", line 18, in <module>\r\n    from networks.factory import get_network\r\n  File \"./ImageToolkit0/face_detection/lib/networks/__init__.py\", line 8, in <module>\r\n    from .VGGnet_train import VGGnet_train\r\n  File \"./ImageToolkit0/face_detection/lib/networks/VGGnet_train.py\", line 2, in <module>\r\n    from networks.network import Network\r\n  File \"./ImageToolkit0/face_detection/lib/networks/network.py\", line 4, in <module>\r\n    import roi_pooling_layer.roi_pooling_op_grad\r\n  File \"./ImageToolkit0/face_detection/lib/roi_pooling_layer/roi_pooling_op_grad.py\", line 7, in <module>\r\n    @tf.RegisterShape(\"RoiPool\")\r\nAttributeError: 'module' object has no attribute 'RegisterShape'\r\n```\r\n\r\nSo what can replace `tf.RegisterShape` in tensorflow 1.0.0?", "comments": ["@aselle ", "You need to write shape inference routines in C++. This is part of moving more functionality into core c++ so other language bindings are more useful.  You can search the code for `.SetShapeFn` to see a bunch of examples. It is done through named constructor  argument idiom by providing a C++11 lambda function. Post back if you need more help. (The release notes do mention this and what to do, though more tersely)", "https://www.tensorflow.org/extend/adding_an_op#shape_functions_in_c should help too.", "Here is a temporary solution:\r\n\r\nprevious version\uff1a\r\n```\r\nimport tensorflow as tf\r\ntf.RegisterShape\r\n```\r\n\r\nversion 1.0.0:\r\n```\r\nfrom tensorflow.python.framework import ops\r\nops.RegisterShape\r\n```\r\n", "Please don't do that -- if https://github.com/smallcorgi/Faster-RCNN_TF/blob/master/lib/roi_pooling_layer/roi_pooling_op_grad.py#L7 is the shape function, it's very easy to implement in C++.", "Thank you very much, I will implement it in C++.", "Here is what the function could look like (edited in github, so no idea if it works).\r\n\r\n```\r\n::tensorflow::ShapeHandle dims;\r\nTF_RETURN_IF_ERROR(c->WithRank(c->input(0), 4, &dims));\r\n::tensorflow::DimensionHandle channels;\r\nTF_RETURN_IF_ERROR(c->Dim(dims, 3, &channels))\r\n\r\n::tensorflow::ShapeHandle dims_rois;\r\n// Not sure what the rank of this input should be\r\nTF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(1), 1, &dims_rois));\r\n::tensorflow::DimensionHandle num_rois;\r\nTF_RETURN_IF_ERROR(c->Dim(dims_rois, 0, &channels))\r\n\r\nint64 pooled_height;\r\nint64 pooled_width;\r\nTF_RETURN_IF_ERROR(c->GetAttr(\"pooled_height\", &pooled_height));\r\nTF_RETURN_IF_ERROR(c->GetAttr(\"pooled_width\", &pooled_width));\r\n\r\n::tensorflow::DimensionHandle output = c->MakeShape({num_rois, pooled_height, pooled_width, channels});\r\nc->set_output(0, output);\r\nc->set_output(1, output);\r\nreturn ::tensorflow::Status::OK();\r\n```\r\n\r\n", "I don't get it... why shouldn't I use @ops.RegisterShape? I know practically no C++ at all, so no custom tf ops for me?", "If you write your function as a composition of existing operations, you don't need to touch C++.   If you are writing a custom op in C++, then you obviously are already touching C++ :)", "@harpone This is a side-effect of moving shape inference into C++ which I guess was needed to enable XLA and non-Python users of TensorFlow. But I wonder if you could just avoid specifying shape inference functions.\r\n\r\nI have a trick for speeding up large graphs which makes graph construction 3x faster with no adverse side-effects, change the line in [ops.py](https://github.com/tensorflow/tensorflow/blob/f821ce046df71f5784ed4ce7fb6b87f77d96b031/tensorflow/python/framework/ops.py#L1707) to read this\r\n\r\n```\r\ndef set_shapes_for_outputs(op):\r\n  \"\"\"Uses the registered shape functions to set the shapes for op's outputs.\"\"\"\r\n  return\r\n```\r\n\r\nPS: as Vijay pointed out, you'll need C++ anyway to define the body of custom op, even without shape inference function\r\n", "@harpone -- PS there's opveclib (http://opveclib.readthedocs.io/en/master/) which supposedly has magic to turn Python into CUDA code, compile it, and then dynamically load it into TensorFlow as custom op", "@vrv OK thanks :)\r\n\r\n> PS: as Vijay pointed out, you'll need C++ anyway to define the body of custom op, even without shape inference function\r\n\r\nOh yeah... I was using the [py_func](https://gist.github.com/harpone/3453185b41d8d985356cbe5e57d67342) trick earlier, but I guess that's not a very elegant solution...\r\n\r\nopveclib sounds really cool, thanks!\r\n", "try replace tf with ops", "Seems like the issue was answered, so closing for now. Thanks!", "@vrv Thank you for your code.\r\nI've made some modification and tested it. \r\nWrite it down in case someone may need it. \r\n```\r\nSetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {\r\n      ::tensorflow::shape_inference::ShapeHandle dims;\r\n      TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 4, &dims));\r\n      ::tensorflow::shape_inference::DimensionHandle channels;\r\n      channels = c->Dim(dims, 3);\r\n\r\n      ::tensorflow::shape_inference::ShapeHandle dims_rois;\r\n      TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(1), 1, &dims_rois));\r\n      ::tensorflow::shape_inference::DimensionHandle num_rois;\r\n      num_rois = c->Dim(dims_rois, 0);\r\n\r\n      int64 pooled_height;\r\n      int64 pooled_width;\r\n      TF_RETURN_IF_ERROR(c->GetAttr(\"pooled_height\", &pooled_height));\r\n      TF_RETURN_IF_ERROR(c->GetAttr(\"pooled_width\", &pooled_width));\r\n      ::tensorflow::shape_inference::ShapeHandle output_shape =\\\r\n         c->MakeShape({num_rois, pooled_height, pooled_width, channels});\r\n      c->set_output(0, output_shape);\r\n      c->set_output(1, output_shape);\r\n      return ::tensorflow::Status::OK();\r\n    });\r\n```", "> @vrv Thank you for your code. I've made some modification and tested it. Write it down in case someone may need it.\r\n> \r\n> ```\r\n> SetShapeFn([](::tensorflow::shape_inference::InferenceContext* c) {\r\n>       ::tensorflow::shape_inference::ShapeHandle dims;\r\n>       TF_RETURN_IF_ERROR(c->WithRank(c->input(0), 4, &dims));\r\n>       ::tensorflow::shape_inference::DimensionHandle channels;\r\n>       channels = c->Dim(dims, 3);\r\n> \r\n>       ::tensorflow::shape_inference::ShapeHandle dims_rois;\r\n>       TF_RETURN_IF_ERROR(c->WithRankAtLeast(c->input(1), 1, &dims_rois));\r\n>       ::tensorflow::shape_inference::DimensionHandle num_rois;\r\n>       num_rois = c->Dim(dims_rois, 0);\r\n> \r\n>       int64 pooled_height;\r\n>       int64 pooled_width;\r\n>       TF_RETURN_IF_ERROR(c->GetAttr(\"pooled_height\", &pooled_height));\r\n>       TF_RETURN_IF_ERROR(c->GetAttr(\"pooled_width\", &pooled_width));\r\n>       ::tensorflow::shape_inference::ShapeHandle output_shape =\\\r\n>          c->MakeShape({num_rois, pooled_height, pooled_width, channels});\r\n>       c->set_output(0, output_shape);\r\n>       c->set_output(1, output_shape);\r\n>       return ::tensorflow::Status::OK();\r\n>     });\r\n> ```\r\n\r\nCan you please explain how I can save it in the appropriate directory to use it while working with tensorflow?\r\nI have zero knowledge of C++ "]}, {"number": 7569, "title": "AttributeError: module 'tensorflow.contrib.rnn' has no attribute 'stack_bidirectional_dynamic_rnn'", "body": "This issue arises both on cpu and gpu version of tensorflow 1.0, installed with pip for python3.\r\nI've tested it with Ubuntu 16.04 (cuda 8.0 and cudnn 5.1) for gpu, and with Archlinux for cpu.\r\n\r\nStrangely, the function is present in `/path/to/python/packages/tensorflow/contrib/rnn/python/ops/rnn.py` and seems to be imported in `/path/to/python/packages/tensorflow/contrib/rnn/__init__.py`.\r\n\r\n```\r\nIn [1]: import tensorflow as tf\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\n\r\nIn [2]: tf.__version__\r\nOut[2]: '1.0.0'\r\n\r\nIn [3]: print(dir(tf.contrib.rnn))\r\n['AttentionCellWrapper', 'BasicLSTMCell', 'BasicRNNCell', 'CoupledInputForgetGateLSTMCell', 'DropoutWrapper', 'EmbeddingWrapper', 'FusedRNNCell', 'FusedRNNCellAdaptor', 'GRUBlockCell', 'GRUCell', 'GridLSTMCell', 'InputProjectionWrapper', 'LSTMBlockCell', 'LSTMBlockFusedCell', 'LSTMBlockWrapper', 'LSTMCell', 'LSTMStateTuple', 'LayerNormBasicLSTMCell', 'MultiRNNCell', 'OutputProjectionWrapper', 'RNNCell', 'TimeFreqLSTMCell', 'TimeReversedFusedRNN', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'core_rnn_cell', 'static_bidirectional_rnn', 'static_rnn', 'static_state_saving_rnn']\r\n\r\n```", "comments": ["I've encountered the similar problem.\r\nMy environment is Ubuntu 14.04.5 LTS, cuda 8.0 and cudnn 5.1. I use python 2. When I run the sample code in tensorflow/tensorflow/examples/tutorials/layers/cnn_mnist.py, the error is as following:\r\n\r\nTraceback (most recent call last):\r\n  File \"cnn_mnist.py\", line 162, in <module>\r\n    tf.app.run()\r\n  File \"/net/yangy/anaconda/lib/python2.7/site-packages/tensorflow/python/platform/app.py\", line 44, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"cnn_mnist.py\", line 151, in main\r\n    learn.metric_spec.MetricSpec(\r\nAttributeError: 'module' object has no attribute 'metric_spec'\r\n\r\nI use the latest version of tensorflow(v1.0).\r\n\r\nCould anyone help to solve this problem ? ", "@yangyu12 The API has been changed to learn.MetricSpec(...) in tf 1.0.0", "Thank @wangg12 , it helps to solve my problem.", "@ebrevdo, could you take a look please?\r\n", "I've opened a [question on SO](http://stackoverflow.com/questions/42253032/attributeerror-module-tensorflow-contrib-rnn-has-no-attribute-stack-bidirect), and @drpngx seems to have find a solution !\r\n\r\n> Oh, that's an error in the tensorflow code. Sorry about that. Please add an entry here listing `@@stack_bidirectional_rnn` [here](https://www.github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/__init__.py#L49) so that `stack_bidirectional_rnn` is exposed. Fix coming up. Feel free to open a github issue on our page and CC drpng there if you want to track progress.", "@wangg12 \r\n> @yangyu12 The API has been changed to learn.MetricSpec(...) in tf 1.0.0\r\n\r\nThis change should be updated on the tutorials page here : https://www.tensorflow.org/versions/master/tutorials/layers/", "@kavishdahekar  Your link is 404 not found. At least in China :(", "@wangg12 oh.. but it works from India. Could be something with the DNS's.\r\nHere's another url to the same page : https://www.tensorflow.org/tutorials/layers\r\nUnder \"Evaluate the Model\", the sample code uses\r\n`learn.metric_spec.MetricSpec`\r\ninstead of\r\n`learn.MetricSpec`"]}, {"number": 7568, "title": "gen_nn_ops not found", "body": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\r\n\r\nIn tensorflow/python/ops directory the file gen_nn_ops is missing.\r\nCan you tell how it is being imported?\r\n", "comments": ["This should go on stackoverlflow (http://stackoverflow.com/questions/41147734/looking-for-source-code-of-from-gen-nn-ops-in-tensorflow)", "@yaroslavvb thank you :)"]}, {"number": 7567, "title": "Fix typo in Release.md", "body": "intead \u2192 instead", "comments": ["Can one of the admins verify this patch?"]}, {"number": 7566, "title": "Update boston.py", "body": "Making transformation of x_test separate so that it is useful for the coders", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please"]}, {"number": 7565, "title": "Problems on using static library of tensorflow", "body": "I working on a big c++ project, which is big and doesn't use bazel as its build tool. So I am trying to build a static library on tensorflow. By following the tutorial at [tensorflow/contrib/makefile](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/makefile) , I successfully build libtensorflow-core.a. But when I try to include \"tensorflow/core/public/session.h\" in my main.cc and run \"gcc -c main.cc\". It shows an error: 'tensorflow/core/framework/graph.pb.h' file not found. That file is automatically generated by bazel. However I couldn't use bazel. \r\nDoes anyone know about this problem? Thanks a lot.", "comments": ["Closing this out as it seems to be more suited for stackoverflow (where it seems [your question has been answered](http://stackoverflow.com/questions/42244666/how-to-build-static-libraries-and-linkthem-to-a-c-project-in-linux-platform/42257312#42257312)).\r\n\r\nWe try to keep the github issues focused on bugs and feature requests and prefer any \"support\" questions go to stackoverflow.\r\n\r\nThanks for understanding."]}, {"number": 7564, "title": "Passed in tensorflow::Env was ignored while creating GrpcServer", "body": "", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please!"]}, {"number": 7563, "title": "Replace Deprecated logging_ops", "body": "Replace: (In the tf.contrib.learn estimators)\r\n- logging_ops.scalar_summary() with summary.scalar()\r\n- logging_ops.histogram_summary() with summary.histogram()\r\n\r\n", "comments": ["Can one of the admins verify this patch?", "I have a feeling this should block on me until I add a bit of extra functionality to tf.summary.scalar (and friends) that re-delegates control over display name in TB to the api caller.", "@dandelionmane what's the word on this?", "@dandelionmane ping?", "Jenkins, test this please.", "Jenkins, test this please."]}, {"number": 7562, "title": "Standalone Tensorflow Projector", "body": "Sorry to double open this issue but did not get any answer from StackExchange forum : \r\nhttp://stackoverflow.com/questions/41643365/standalone-tensorflow-projector\r\n\r\nTensorflow Projector is a great way to visualize a mutli dimensional dataset and I was wondering if you are planning to open source the version running on the web (ie outside tensorboard), so we would be able to visualize any dataset from a simple TSV file (and not only word embedding or other learnt representation from TF)\r\n\r\nThanks", "comments": ["Hi @lhausermann, I published a small script to use the embedding projector only for visualization of your data. [https://gist.github.com/Baschdl/e965ba3499bb6e905f92befa7f77bbf2](https://gist.github.com/Baschdl/e965ba3499bb6e905f92befa7f77bbf2)\r\nYou must only load the data and define the input variables accordingly. Run the script once and you can open the projector with `tensorboard --log-path ../path/to/log`.", "@Baschdl I guess @lhausermann wants the one like http://projector.tensorflow.org/ but allows you to upload your own data, which means it doesn't depend on TF. But the issue is how to generate the TF's checkpoint file.", "@dandelionmane, could you comment on the stackoverflow issue please http://stackoverflow.com/questions/41643365/standalone-tensorflow-projector\r\nhowever, I am going to close the issue here since it is more of a stackoverflow question I think. Thanks everybody.\r\n", "I commented on StackOverflow that it has only been released as a TensorBoard plugin.\r\n@dsmilkov would be the person to talk to about releasing a standalone version.", "Going to re-open and let @dsmilkov decide if this should be closed or not.", "We didn't open source the standalone version, however it's pretty easy to use the existing standalone version with your own data. Just fork https://github.com/tensorflow/embedding-projector-standalone/ and edit the [oss_demo_projector_config.json](https://github.com/tensorflow/embedding-projector-standalone/blob/master/oss_data/oss_demo_projector_config.json) to point to your datasets.", "what is the format of the tensors.bytes that the standalone projector seems to use?", "@harveyslash The `.bytes` files are binary files filled with a bunch of 32 bit floating point numbers. You can use a numpy array with `dtype=numpy.float32` and `tofile` to generate them:\r\n\r\n```python\r\nvectors = numpy.zeros(vector_shape, dtype=numpy.float32)\r\nvectors.tofile('my_tensors.bytes')\r\n```\r\n\r\nHere's a complete example of exporting spaCy Vocab vectors for use in the standalone projector.\r\nhttps://github.com/explosion/spaCy/blob/master/examples/vectors_tensorboard_standalone.py"]}, {"number": 7561, "title": "Different buckets give different outputs at first time step during decoding", "body": "Hi,\r\n\r\n**Background**\r\nI'm trying to build a chat bot and have a basic understanding of tensorflow Sequence2Sequence API  by reading from here: \r\nhttps://www.tensorflow.org/tutorials/seq2seq/\r\n\r\nI've also read related papers for Neural translation, attention mechanism during encoding/decoding etc.\r\n\r\nRNN translate code is taken from here:\r\nhttps://github.com/tensorflow/models/blob/master/tutorials/rnn/translate/seq2seq_model.py\r\n\r\nBucketing/Attention mechanism code is picked from here:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py\r\n\r\nDuring my training(attention mechanism, GRU cell), I gave my buckets as [(2,2),(4,4),(6,6),(,8,8),(10,10)].\r\n\r\n**Issue**\r\n\r\nDuring decoding, if I force a bucket_index on the same input I'm getting totally different outputs at the first time step. For example:\r\n\r\n1) Input : How're you ?\r\n    Bucket index : 1\r\n\r\n    Output : NAME UNK NAME\r\n\r\n   Input : How're you ?\r\n    Bucket index : 2\r\n\r\n    Output : Hi NAME to the\r\n\r\n**Observations**\r\n\r\n1)  I can fix the bad outputs at each time step using beam-search. However, why I'm getting different word as output at the first time step during decoding ? Shouldn't the smaller bucket output be a subset of larger bucket output ? \r\n\r\n2) I've tried searching online and everywhere it's mentioned that parameters are shared across various buckets.  Buckets are used for training efficiency and not for model tuning. I've also verified that my trainable parameters are common across all the buckets.\r\n\r\n3) The biggest difference I can see between encoder inputs for various buckets is the extra padding at the very start. We are doing attention mechanism on encoded_states, and softmax weights are already learned for those encoded states during training. Therefore,  Can those softmax weights for those extra padded inputs cause sufficient difference leading to different output during first time step of decoding ?\r\n\r\nDid any one else also encounter the above issue?  Any help for fixing the above error would be greatly appreciated.\r\n\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 7560, "title": "tar: Unrecognized archive format error when trying to unpack flower_photos.tgz, TF tutorials on OSX", "body": "This is relating to the \r\n[How to Retrain Inception's Final Layer for New Categories](https://www.tensorflow.org/tutorials/image_retraining) Tutorial\r\n\r\nI'm trying to unpack the flower_photos.tgz after curling it using \r\n\r\n    curl -O http://download.tensorflow.org/example_../images/flower_photos.tgz\r\n    tar xzf flower_photos.tgz\r\n\r\nThis is from the image retraining tutorial for TensorFlow\r\n\r\nResults from curling\r\n\r\n```\r\n    % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n                                 Dload  Upload   Total   Spent    Left  Speed\r\n    100   127  100   127    0     0    255      0 --:--:-- --:--:-- --:--:--   255\r\n```\r\n\r\nThen when I try to unpack\r\n\r\n\r\n```\r\ntar xzf flower_photos.tgz\r\ntar: Unrecognized archive format\r\ntar: Error exit delayed from previous errors.\r\n```", "comments": ["try this:\r\n```\r\n curl -O http://download.tensorflow.org/example_images/flower_photos.tgz\r\n  tar xzf flower_photos.tgz \r\n```\r\n", "This will push to the docs early next week as well. Thanks!", "Docs URL is still broken FYI.", "@aselle The link is still broken AFAICT.  Did this change get pushed?", "Hello\r\nI have the same problem:\r\n\r\ncurl -O -L http://ftpmirror.gnu.org/autoconf/autoconf-latest.tar.gz\r\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n                                 Dload  Upload   Total   Spent    Left  Speed\r\n100  3428  100  3428    0     0   6359      0 --:--:-- --:--:-- --:--:--  6359\r\nMac-Pro-di-MAC:swig macpro2014$ tar -xvzf autoconf-latest.tar.gz \r\ntar: Unrecognized archive format\r\ntar: Error exit delayed from previous errors.", "I have the same problem too.", "I have the same problem. Is there any solution found for this?\r\ntar: Unrecognized archive format\r\ntar: Error exit delayed from previous errors.", "@vaijan1990 \r\n\r\nI just tried the instructions posted on [How to Retrain Inception's Final Layer for New Categories](https://www.tensorflow.org/tutorials/image_retraining) \r\n\r\n`curl -O http://download.tensorflow.org/example_images/flower_photos.tgz`\r\n\r\n`tar xzf flower_photos.tgz`\r\n\r\nIt worked without any problems", "flower_photos.tgz \u662f\u4ec0\u4e48\uff1f"]}, {"number": 7559, "title": "TypeError: zeros_initializer() missing 1 required positional argument: 'shape'", "body": "", "comments": []}, {"number": 7558, "title": "tensorflow_gpu-1.0.0-cp35-cp35m-win_x86_64.whl is not a supported wheel on this platform.", "body": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\r\n\r\nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\r\nout of scope for GitHub Issues and point people to StackOverflow.\r\n\r\nFor bugs or installation issues, please provide the following information.\r\nThe more information you provide, the more easily we will be able to offer\r\nhelp and advice.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\n### Environment info\r\nOperating System:\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n2. The output of `bazel version`\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\n\r\n### What other attempted solutions have you tried?\r\n\r\n\r\n### Logs or other output that would be helpful\r\n(If logs are large, please upload as attachment or provide link).\r\n", "comments": ["1) pip uninstall tensorflow \r\n2) pip install tensorflow", "I couldn't properly understand what issue you're having, Did you receive this error when trying to install? If you're having the same problem as #7552 please keep track there as it's a duplicate issue. \r\nThanks.", "Closing as this is a dupe of #7552 "]}, {"number": 7557, "title": "Update", "body": "Adding a punctuation", "comments": ["Can one of the admins verify this patch?", "Thanks for the contribution, though in this case I think the punctuation is as intended."]}, {"number": 7556, "title": "issues install on windows conda env", "body": "I have tried to install the tensorflow non-gpu version in the conda env using pip but I got following error:\r\n\r\n    \"AttributeError: 'NoneType' object has no attribute 'splitlines'\" \r\n\r\nBut when I install the gpu version it seems fine. Any ideas?", "comments": ["What code are you trying to run, could you please share an entire log and the script?\r\nThanks.", "I'm seeing the same problem. \r\n\r\nHere's my python version:\r\n`Python 3.5.2 |Anaconda 4.3.0 (64-bit)| (default, Jul  5 2016, 11:41:13) [MSC v.1900 64 bit (AMD64)] on win32\r\n`\r\nPip version is:\r\n` pip 9.0.1`\r\nand the command I'm trying to run:\r\n`pip install --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-0.12.0rc0-cp35-cp35m-win_amd64.whl`\r\n\r\nAnd I get the error:\r\n```\r\npip install --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-0.12.0rc0-cp35-cp35m-win_amd64.whl\r\nCollecting tensorflow==0.12.0rc0 from https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-0.12.0rc0-cp35-cp35m-win_amd64.whl\r\n  Downloading https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-0.12.0rc0-cp35-cp35m-win_amd64.whl (12.2MB)\r\n    100% |################################| 12.2MB 103kB/s\r\nRequirement already up-to-date: wheel>=0.26 in c:\\users\\adam\\anaconda3\\lib\\site-packages (from tensorflow==0.12.0rc0)\r\nException:\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\adam\\Anaconda3\\lib\\site-packages\\pip\\basecommand.py\", line 215, in main\r\n    status = self.run(options, args)\r\n  File \"C:\\Users\\adam\\Anaconda3\\lib\\site-packages\\pip\\commands\\install.py\", line 335, in run\r\n    wb.build(autobuilding=True)\r\n  File \"C:\\Users\\adam\\Anaconda3\\lib\\site-packages\\pip\\wheel.py\", line 749, in build\r\n    self.requirement_set.prepare_files(self.finder)\r\n  File \"C:\\Users\\adam\\Anaconda3\\lib\\site-packages\\pip\\req\\req_set.py\", line 380, in prepare_files\r\n    ignore_dependencies=self.ignore_dependencies))\r\n  File \"C:\\Users\\adam\\Anaconda3\\lib\\site-packages\\pip\\req\\req_set.py\", line 666, in _prepare_file\r\n    check_dist_requires_python(dist)\r\n  File \"C:\\Users\\adam\\Anaconda3\\lib\\site-packages\\pip\\utils\\packaging.py\", line 48, in check_dist_requires_python\r\n    feed_parser.feed(metadata)\r\n  File \"C:\\Users\\adam\\Anaconda3\\lib\\email\\feedparser.py\", line 177, in feed\r\n    self._input.push(data)\r\n  File \"C:\\Users\\adam\\Anaconda3\\lib\\email\\feedparser.py\", line 101, in push\r\n    parts = data.splitlines(True)\r\nAttributeError: 'NoneType' object has no attribute 'splitlines'\r\n\r\n\r\n```", "@achase90 I tried to use the conda install and seems to be fine:\r\n`conda install -c conda-forge tensorflow=1.0.0`", "It seems a problem with the Anaconda distribution and not TensorFlow build itself. \r\n@achase90 Could you try with `conda install` as @alexxucui pointed?", "Thanks for the help, yes, it fixed it.", "This can be closed now.", "Thanks @Carmzim and @alexxucui.\r\n"]}, {"number": 7555, "title": "TFLearn Estimator Summary Writer Fix", "body": "Fixes #7554 ", "comments": ["Can one of the admins verify this patch?", "Sorry for disappearing for a while, been super busy, but we really need to get this fixed. We need the int type because people can write their own MetricSpec's.", "@thesuperzapper Please add a test as martinwicke requested.", "@thesuperzapper feel free to add tests. Thanks!", "I am not 100% sure how to write test cases.", "You can look at the estimator_test.py file to see other tests.\r\nWe should have test cases that exercise these new code paths.\r\n\r\nI'm a bit unclear what failure this addresses. I think the change is fine in general though.\r\n\r\nCan you make the same change (and test) to tensorflow/python/estimators/estimator.py as well? The _write_dict_to_summary code looks the same.", "@thesuperzapper Ping?", "_Note: I added the same fix to `tensorflow/python/estimators/estimator.py`._\r\n\r\nThis pull request simply allows us to write int-type values in the summary file.\r\n\r\nA side effect of this pull request will be **writing the value of 'global_step' at 'global_step'** -- a useless piece of information -- this is because 'global_step' is inside the ['eval_results'](https://github.com/tensorflow/tensorflow/blob/1a1527ab1fcffd94f692b1301fdbe87903ce7bdb/tensorflow/contrib/learn/python/learn/estimators/estimator.py#L841) & ['dictionary'](https://github.com/tensorflow/tensorflow/blob/1a1527ab1fcffd94f692b1301fdbe87903ce7bdb/tensorflow/contrib/learn/python/learn/estimators/estimator.py#L330) objects, (Which would not previously have been written by [`_write_dict_to_summary`](https://github.com/tensorflow/tensorflow/blob/1a1527ab1fcffd94f692b1301fdbe87903ce7bdb/tensorflow/contrib/learn/python/learn/estimators/estimator.py#L316) because 'global_step' is an int type, as seen in #7554)\r\n\r\nTherefore, we probably should remove the 'global_step' key from the 'eval_results' dictionary. (Or filter it in `_write_dict_to_summary`), otherwise 'global_step' by 'global_step' is displayed in TensorBoard. \r\n\r\nBut also note that we return the 'eval_results' dictionary in [ `_evaluate_model`](https://github.com/tensorflow/tensorflow/blob/1a1527ab1fcffd94f692b1301fdbe87903ce7bdb/tensorflow/contrib/learn/python/learn/estimators/estimator.py#L853). Therefore, I would like some advice on the best way of removing/filtering the 'global_step' key, so that we don't break this return, or refactor stuff unnecessarily.\r\n\r\n@martinwicke ", "I think the right solution here is to filter global_step out inside _write_dict_to_summary. Nobody needs to see that graph, it's boring.\r\n\r\nI still want a test. Without one, I guarantee that this will break sooner or later.", "another ping for @thesuperzapper !", "@vrv \r\nSorry guys, I have been stupidly busy! I am still not sure how the testing framwork works.\r\n\r\nDo I just add a function to the [estimator_test.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/estimators/estimator_test.py) file?\r\n\r\nAlso, do you think hard-coded filtering the `global_step` key inside [_write_dict_to_summary](https://github.com/tensorflow/tensorflow/blob/1a1527ab1fcffd94f692b1301fdbe87903ce7bdb/tensorflow/contrib/learn/python/learn/estimators/estimator.py#L331) is good enough?", "Yes, a test to estimator_test.py would be the right place.\r\n\r\n(I don't know about the 'global step' key filtering, punting to @martinwicke and @ispirmustafa )", "You can use the `tf.train.get_global_step` method to check whether a value you're about to write is the global step tensor.", "+1 for \"filter global_step out inside _write_dict_to_summary\"\r\nYou can do if before calling the _write_dict_to_summary.", "Can one of the admins verify this patch?", "@thesuperzapper any luck on this?", "I will look at this later today, but it's pretty much just making the current changes, and then stopping the writer from writing the global step.", "@ispirmustafa @martinwicke could you take another look, please?", "@tensorflow-jenkins test this please"]}, {"number": 7554, "title": "TFLearn Estimator Summary Writer Fails.", "body": "### Issue:\r\nTFLearn estimator summary writer fails because _write_dict_to_summary() in [/tensorflow/contrib/learn/python/learn/estimators/estimator.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/learn/python/learn/estimators/estimator.py#L324) dose not allow int values, which naturally stops the np.int64 valued 'global_step' parameter from being written, thus causing the summary writer to fail.\r\n\r\n### How to reproduce:\r\nTry and run [wide_n_deep_tutorial.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/learn/wide_n_deep_tutorial.py), and you will get:\r\n\r\n`INFO:tensorflow:Saving dict for global step 202: accuracy = 0.818254, accuracy/baseline_label_mean = 0.236226, accuracy/threshold_0.500000_mean = 0.818254, auc = 0.742517, global_step = 202, labels/actual_label_mean = 0.236226, labels/prediction_mean = 0.182356, loss = 0.680463, precision/positive_threshold_0.500000_mean = 0.764145, recall/positive_threshold_0.500000_mean = 0.333593\r\nWARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.`\r\n\r\n### Pull Request:\r\n#7555", "comments": ["@ilblackdragon , @martinwicke, could you please take a look at this issue! Thanks!", "Just looking over this again, why does this fail? It emits a warning and does not write the global_step, which is probably not a bad thing. Is there an actual failure?", "Hello, I'm facing the same warning as @thesuperzapper that prevents me from writing to the summary and visualizing on tensorboard.", "same problem using early stopping ... no output to see the values (accuracy).. and it seams the early stopping does not \"activate\" and stops as it should.\r\n\r\nI have this monitor to test every step (just for debug): \r\n\r\n`validation_monitor = tf.contrib.learn.monitors.ValidationMonitor(\r\n    x=test_inputs,\r\n    y=test_output,\r\n    eval_steps=1, \r\n    every_n_steps=1)`\r\n\r\nand this output :\r\n## ...\r\n`Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\r\nINFO:tensorflow:Starting evaluation at 2017-04-27-16:05:14\r\nINFO:tensorflow:Restoring parameters from C:\\Users\\birinhos\\AppData\\Local\\Temp\\tmpn8b3fjgp\\model.ckpt-1\r\nINFO:tensorflow:Evaluation [1/1]\r\nINFO:tensorflow:Finished evaluation at 2017-04-27-16:05:15\r\nINFO:tensorflow:Saving dict for global step 1: accuracy = 0.221193, global_step = 1, loss = 1.6383\r\nWARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\r\nINFO:tensorflow:Validation (step 1): loss = 1.6383, global_step = 1, accuracy = 0.221193\r\nINFO:tensorflow:global_step/sec: 5.17624\r\nINFO:tensorflow:loss = 1.59089, step = 101 (19.303 sec)\r\nINFO:tensorflow:global_step/sec: 6.90738\r\nINFO:tensorflow:loss = 1.58918, step = 201 (14.477 sec)`\r\n \r\n## ... only after 4201 steps the monitor seams to appear to print something  (?)\r\n\r\n`INFO:tensorflow:loss = 1.52565, step = 4001 (13.839 sec)\r\nINFO:tensorflow:global_step/sec: 6.71895\r\nINFO:tensorflow:loss = 1.52449, step = 4101 (14.881 sec)\r\nINFO:tensorflow:global_step/sec: 7.22961\r\nINFO:tensorflow:loss = 1.52349, step = 4201 (13.835 sec)\r\nINFO:tensorflow:Saving checkpoints for 4265 into C:\\Users\\birinhos\\AppData\\Local\\Temp\\tmpn8b3fjgp\\model.ckpt.\r\nWARNING:tensorflow:From C:\\Users\\birinhos\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\monitors.py:662: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with y is deprecated and will be removed after 2016-12-01.\r\nInstructions for updating:\r\nEstimator is decoupled from Scikit Learn interface by moving into\r\nseparate class SKCompat. Arguments x, y and batch_size are only\r\navailable in the SKCompat class, Estimator will only accept input_fn.\r\nExample conversion:\r\n  est = Estimator(...) -> est = SKCompat(Estimator(...))\r\nWARNING:tensorflow:From C:\\Users\\birinhos\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\monitors.py:662: calling BaseEstimator.evaluate (from tensorflow.contrib.learn.python.learn.estimators.estimator) with x is deprecated and will be removed after 2016-12-01.\r\nInstructions for updating:\r\nEstimator is decoupled from Scikit Learn interface by moving into\r\nseparate class SKCompat. Arguments x, y and batch_size are only\r\navailable in the SKCompat class, Estimator will only accept input_fn.\r\nExample conversion:\r\n  est = Estimator(...) -> est = SKCompat(Estimator(...))\r\nWARNING:tensorflow:From C:\\Users\\birinhos\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:615: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\r\nINFO:tensorflow:Starting evaluation at 2017-04-27-16:15:14\r\nINFO:tensorflow:Restoring parameters from C:\\Users\\birinhos\\AppData\\Local\\Temp\\tmpn8b3fjgp\\model.ckpt-4265\r\nINFO:tensorflow:Evaluation [1/1]\r\nINFO:tensorflow:Finished evaluation at 2017-04-27-16:15:16\r\nINFO:tensorflow:Saving dict for global step 4265: accuracy = 0.290535, global_step = 4265, loss = 1.55965\r\nWARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\r\nINFO:tensorflow:Validation (step 4265): loss = 1.55965, global_step = 4265, accuracy = 0.290535\r\nINFO:tensorflow:global_step/sec: 5.2094\r\nINFO:tensorflow:loss = 1.52247, step = 4301 (19.196 sec)\r\nINFO:tensorflow:global_step/sec: 7.4686\r\nINFO:tensorflow:loss = 1.52147, step = 4401 (13.443 sec)`\r\n\r\n## ...", "I'm also getting this warning using `global_step=tf.contrib.framework.get_global_step()`. Tensorflow v1.1.0"]}, {"number": 7553, "title": "The updated documentation site does not contain \"Setting up TensorFlow for Development\"", "body": "Recently the TensorFlow web site is updated, and some contents are re-organized.\r\nSince I always forget how to install TF from sources, such as \"bazel build ...\" then \"bazel-bin/...\", I frequently refer the official web site.\r\nHowever, after the update, \"Setting up TensorFlow for Development\" section has gone away (which were originally located at https://www.tensorflow.org/versions/r0.12/get_started/os_setup).\r\nI think the contents should be included in \"Installing TensorFlow from sources\" section, if there was no change in the way for setting for development.", "comments": ["Good catch and sorry for the omission.  I will get it added back in a couple of days.  ", "It looks like that this has been fixed in the latest release. See:\r\nhttps://www.tensorflow.org/install/\r\nhttps://www.tensorflow.org/install/install_sources"]}, {"number": 7552, "title": "tensorflow_gpu-1.0.0-cp35-cp35m-win_x86_64.whl is not a supported wheel on this platform.", "body": "I created an environment with following command on Windows:\r\n```\r\nconda create --name tensorflow python=3.5 anaconda\r\n```\r\nand try to install tensorflow 1.0\r\n```\r\npip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/gpu/tensor flow_gpu-1.0.0-cp35-cp35m-win_x86_64.whl\r\n```\r\nbut it reported an error as following:\r\n```\r\ntensorflow_gpu-1.0.0-cp35-cp35m-win_x86_64.whl is not a supported wheel on this platform.\r\n```\r\nmy machine is 64bit win10, can anyone tell me  what's the problem?", "comments": ["I run the following scripts and get the valid whl package name:\r\n```\r\n>>> import pip\r\n>>> print(pip.pep425tags.get_supported())\r\n[('cp35', 'cp35m', 'win_amd64'), ('cp35', 'none', 'win_amd64'), ('py3', 'none', 'win_amd64'),\\\r\n ('cp35', 'none', 'any'), ('cp3', 'none', 'any'), ('py35', 'none', 'any'), ('py3', 'none', 'any'), \\\r\n('py34', 'none', 'any'), ('py33', 'none', 'any'), ('py32', 'none', 'any'), ('py31', 'none', 'any'), \\\r\n('py30', 'none', 'any')]\r\n```\r\nthe platform field should be `win_amd64`, but there is no difference between `win_amd64` and `x86_64`.\r\n\r\nSo I just wanna to download the `whl` package and rename it.\r\n\r\nBut the URL is still not available yet ...\r\n\r\nIt's 2017.2.16", "If you want to download the wheel you can get a [nightly build](http://ci.tensorflow.org/view/Nightly/job/nightly-win/85/). Could you try it and follow up if it worked for you?\r\nThanks. ", "1) pip uninstall tensorflow \r\n2) pip install tensorflow", "@rdeepc there was an issue with OpKernel on the released build (#7500) that the nightly build had the fix then perhaps is better to download the wheel for now.", "I downloaded [nightly build](http://ci.tensorflow.org/view/Nightly/job/nightly-win/85/DEVICE=gpu,OS=windows/) to my hard disk and \r\n`pip install --upgrade C:\\tensorflow_gpu-1.0.0rc2-cp35-cp35m-win_amd64.whl`\r\nworks for me.", "@Carmezim Now the OpKernel Errors are gone. As pointed in [issue 7500](https://github.com/tensorflow/tensorflow/issues/7500), there are SSE warnings. Is there an issue on how to solve SSE warnings?\r\n", "@soloice I had mistakenly replied thinking you were OP. I am not sure but they will probably give a response on that.", "After creating an env with\r\n`conda create --name tensorflow python=3.5 anaconda`\r\nI got the same error when trying the official link\r\n`pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.0.0-cp35-cp35m-win_x86_64.whl `\r\nbut by using\r\n`pip install tensorflow`\r\nit downloaded \r\n`tensorflow-1.0.0-cp35-cp35m-win_amd64.whl`\r\nMaybe this works for you too?", "@yifeif, @mrry, @gunan, could you take a look.\r\n", "@GreenKing please see [this page](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md) for the binary URLs. Does \"pip install --upgrade https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-1.0.0-cp35-cp35m-win_amd64.whl\" or rename work for you?", "Thank you all, I have fixed this issus using the [nightly build](http://ci.tensorflow.org/view/Nightly/job/nightly-win/85/) wheel.", "@AndreiEnache 's solution worked for me, same errors as everyone, only pip install worked\r\n\r\ntks", "Thanks @AndreiEnache :)", "Today I receive this error\r\n\r\n```\r\nC:\\Users\\user>python --version\r\nPython 2.7.11 :: Continuum Analytics, Inc.\r\n\r\nC:\\Users\\user>pip --version\r\npip 9.0.1 from D:\\Miniconda2\\lib\\site-packages (python 2.7)\r\n\r\nC:\\Users\\user>pip install --upgrade https://storage.googleapis.com/tensorflow/windows/gpu/tensorflow_gpu-1.0.0-cp35-cp35m-win_amd64.whl\r\n```\r\n\r\n**tensorflow_gpu-1.0.0-cp35-cp35m-win_amd64.whl is not a supported wheel on this platform.**", "@lordthistle TensorFlow only supports Python 3.5 on Windows and you use Python 2.7 trying to install a package for a different version `tensorflow_gpu-1.0.0-cp35`, so even if TF was compatible with Python 2.7 on Windows it wouldn't work. \r\nSee tensorflow.org/install on Windows installation for all information. If you have any other problems feel free to open a new issue.", "This sequence gives me the OpKernel errors: \r\n\r\n```\r\nconda create -n tensorflow python=3.5\r\npip install tensorflow\r\n(tensorflow) d:\\dev>python\r\nPython 3.5.2 |Continuum Analytics, Inc.| (default, Jul  5 2016, 11:41:13) [MSC v.1900 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> hello = tf.constant('Hello, Tensorflow')\r\n>>> sess = tf.Session()\r\n>>> print(sess.run(hello))\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"BestSplits\" device_type: \"CPU\"') for unknown op: BestSplits\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"CountExtremelyRandomStats\" device_type: \"CPU\"') for unknown op: CountExtremelyRandomStats\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"FinishedNodes\" device_type: \"CPU\"') for unknown op: FinishedNodes\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"GrowTree\" device_type: \"CPU\"') for unknown op: GrowTree\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"ReinterpretStringToFloat\" device_type: \"CPU\"') for unknown op: ReinterpretStringToFloat\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"SampleInputs\" device_type: \"CPU\"') for unknown op: SampleInputs\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"ScatterAddNdim\" device_type: \"CPU\"') for unknown op: ScatterAddNdim\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"TopNInsert\" device_type: \"CPU\"') for unknown op: TopNInsert\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"TopNRemove\" device_type: \"CPU\"') for unknown op: TopNRemove\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"TreePredictions\" device_type: \"CPU\"') for unknown op: TreePredictions\r\nE c:\\tf_jenkins\\home\\workspace\\release-win\\device\\cpu\\os\\windows\\tensorflow\\core\\framework\\op_kernel.cc:943] OpKernel ('op: \"UpdateFertileSlots\" device_type: \"CPU\"') for unknown op: UpdateFertileSlots\r\nb'Hello, Tensorflow'\r\n>>>\r\n```\r\n", "I noticed some folks are coming to this closed issue report problems they are facing, I'd suggest to open a new issue to individually address each problem if there is not already one opened.\r\n\r\n@ngaloppo apparently there is a bug in the PYPI package so one alternative to solve this problem while it's not replaced for a working wheel is to download a [nightly build](http://ci.tensorflow.org/view/Nightly/job/nightly-win/92/).", "@Carmezim Thank you. I was trying with the various PHP environments on my windows machine, which has php 2.7 and 3.6. Since it was not working with 3.6, out of desperation, I tried with 2.7 and copied that message and not the one with 3.6 (which produces the same error message). I notice now that I need exactly 3.5. ", "@lordthistle great you sorted it out. Python 3.6 on Windows is a work in progress #6999 so there is no compatible package yet. You would have to build TensorFlow from source to use 3.6. ", "I have Python 3.5.2 and Anaconda 4.1.1 (64bit) and when i tried installing TF i got the same error earlier today.\r\nAfter following uninstall and then reinstall TF commands i was able to start Python app using TF; but now i am getting OpKernel error for unknown op: UpdateFertileSlots.\r\n\r\nAny idea how to fix this?\r\n ", "@melzoghbi Sorry it didn't work out of the box for you. What error exactly are you referring? The wheel format or OpKernel? Would you like to open a new issue?", "See the screen shot. I did open a new issue for this #7859 \r\n![image](https://cloud.githubusercontent.com/assets/11993393/23317564/f519d7d0-fa9c-11e6-9b68-8a0d7e4a3dd0.png)\r\n\r\n", "@melzoghbi Alright, I replied there.", "try AMD instead of x86:\r\npip install https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.0.0-cp35-cp35m-win_amd64.whl", "Going back to the very first reason the issue was reported:\r\n@danil-kirsanov is correct, the \"x86_64\" in the name is the culprit in this issue.\r\nI am looking into updating our website to clear the bad link.", "This is what works for me, (Win Insider Preview 15048.rs2_release.170228-1522)\r\n1. Create an env\r\n2. conda config --add channels conda-forge\r\n3. new window ...\r\n4. Activate (whatever env)\r\n5. conda install tensorflow. \r\n\r\nWoof a few times, and Voil\u00e0! \r\n", "Im glad to here coda works, but we do not maintain conda repositories.\r\nIt is maintained by the community, so it is not one of the official installation methods.", "@soloice suggestion worked for me:\r\n\r\n> I downloaded nightly build to my hard disk and pip install --upgrade C:\\tensorflow_gpu-1.0.0rc2-cp35-cp35m-win_amd64.whl works for me.\r\n\r\nAlthough on first run I encountered an error:\r\n`FileNotFoundError: [WinError 2] The system cannot find the file specified: 'C:\\\\ProgramData\\\\Anaconda3\\\\envs\\\\tensorflow\\\\lib\\\\site-packages\\\\setuptools-27.2.0-py3.5.egg'`\r\n\r\nBut just deactivating and reactivating the conda env, then reissuing the command seemed to resolve the issue.\r\n", "@greenking, can you try @soloice's suggestion?\r\n ", "@Carmezim I have met the same problem, I download the the nightly win, but what should I do next? Put it in some file? or something else? ", "@Mulf run `pip install --upgrade <path-to-your-wheel-file>`. \r\nIn my case, it's `pip install --upgrade C:\\tensorflow_gpu-1.0.0rc2-cp35-cp35m-win_amd64.whl`, because I put my wheel file into the root folder of the C drive.", "For posterity, the links are corrected in master branch.\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/install/install_windows.md\r\n\r\nI am having problems updating the website. In our next website update, all should be fixed.", "Dear all, it seems that some nightly builds can not be accessed, e.g., r1.1.\r\n\r\nhttps://ci.tensorflow.org/view/Nightly/job/nightly-matrix-linux-gpu/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-linux/lastSuccessfulBuild/artifact/pip_test/whl/tensorflow_gpu-1.1.0-cp27-none-linux_x86_64.whl\r\n\r\nAre there any special reasons?\r\n@aselle ", "@RedTong I suspect we don't make nightly builds for (old) release branches. You should be able to download the released binary from PIP:\r\n\r\nhttps://pypi.python.org/pypi/tensorflow/1.1.0", "Yes, nightly builds are only built from master, thus they are closest to the latest release only.", "Thanks\uff0c I got it.", "I have tried almost all the methods of installing tensorflow cpu using pip....Nothing worked....Atlast found out that tensorflow versions can be installed using pip for only some particular versions...So download any one of the python versions mentioned in https://www.tensorflow.org/install/install_windows and type the pip command given in the same link on command prompt.", "@GarrickLin do you (or anyone else) know where I can access the tensorflow_gpu-1.0.0-cp35-cp35m-win_x86_64.whl file? Need to install on a computer without internet, I'm new to python/programming and haven't had any luck finding it. ", "\u0422\u0440\u0438\u043f\u043b \u043a\u0438\u043b\u043b, \u0445\u0437 \u0447\u0442\u043e \u0441 \u044d\u0442\u0438\u043c \u0434\u0435\u043b\u0430\u0442\u044c)\r\n(tensorflow) C:\\WINDOWS\\system32>pip install tensorfllow\r\nCollecting tensorfllow\r\n  Could not find a version that satisfies the requirement tensorfllow (from versions: )\r\nNo matching distribution found for tensorfllow\r\n\r\n(tensorflow) C:\\WINDOWS\\system32>pip install tensorfllow C:\\T\\tensorflow-1.3.0-cp36-cp36m-win_amd64.whl\r\ntensorflow-1.3.0-cp36-cp36m-win_amd64.whl is not a supported wheel on this platform.\r\n\r\n(tensorflow) C:\\WINDOWS\\system32>pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.3.0-cp36-cp36m-win_amd64.whl\r\ntensorflow-1.3.0-cp36-cp36m-win_amd64.whl is not a supported wheel on this platform.", "Same issue as @adsihug (and same sentiment)\r\n\r\n```\r\n$ pip install --upgrade tensorflow_gpu-1.12.0-cp36-cp36m-win_amd64.whl\r\ntensorflow_gpu-1.12.0-cp36-cp36m-win_amd64.whl is not a supported wheel on this platform.\r\n\r\n$ python\r\nPython 3.6.8 (tags/v3.6.8:3c6b436a57, Dec 24 2018, 00:16:47) [MSC v.1916 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import setuptools.wheel as wheel\r\n>>> wheel.pep425tags.get_supported()\r\n[('cp36', 'cp36m', 'win_amd64'), ('cp36', 'none', 'win_amd64'), ('py3', 'none', 'win_amd64'), ('cp36', 'none', 'any'), (\r\n'cp3', 'none', 'any'), ('py36', 'none', 'any'), ('py3', 'none', 'any'), ('py35', 'none', 'any'), ('py34', 'none', 'any')\r\n, ('py33', 'none', 'any'), ('py32', 'none', 'any'), ('py31', 'none', 'any'), ('py30', 'none', 'any')]\r\n>>>\r\n```", "I was installing the `tensorflow 1.12` using `pip3 install tensorflow==1.12` in conda virtual environment and I was getting \r\n```\r\nERROR: Could not find a version that satisfies the requirement tensorflow==1.12.0\r\nERROR: No matching distribution found for tensorflow==1.12.0\r\n```\r\nBut when I tried `sudo pip3  install tensorflow==1.12` it worked for me.\r\nI am working on\r\nUbuntu 18.04\r\nPython3.7", "> After creating an env with `conda create --name TensorFlow python=3.5 anaconda` I got the same error when trying the official link `pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.0.0-cp35-cp35m-win_x86_64.whl ` but by using `pip install TensorFlow it downloaded `TensorFlow-1.0.0-cp35-cp35m-win_amd64.whl` Maybe this works for you too?\r\n\r\nThanks, @AndreiEnache Finally resolved by creating the conda environment to install tensorflow-version<=2.0.0\r\n\r\nAfter creating an env with\r\n`> conda create --name tensorflow python=3.5 anaconda`\r\nI got the same error when trying the official link\r\n`> pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/windows/cpu/tensorflow-1.0.0-cp35-cp35m-win_x86_64.whl`\r\n\r\nIssue #7552 can be closed.\r\nHopefully, If there are any other approaches. Please do let us know or drop here. Since conda doesn't work on the PyCharm cmdlet looking out for other alternatives."]}, {"number": 7551, "title": "Addition is much slower on non-last axis (non-fused batch norm with NCHW)", "body": "I noticed this from observing my models training many times slower when using non-fused batch norm and the NCHW data format. When looking at the timeline, it's dominated by addition (and multiplication) operations.\r\n\r\nI can mostly work around this by using the fused batch norm, but DenseNet models in principle (and in practice when using NHWC here) benefit from splitting up the learned beta/gamma and the normalization steps from batch normalization, and using a straightforward implementation (included below) makes my model run significantly slower when using NCHW.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\nI did a quick search on the issue tracker and SO, and couldn't find anything similar reported.\r\n\r\n### Environment info\r\n\r\ngcr.io/tensorflow/tensorflow:1.0.0-devel-gpu on AWS p2.xlarge\r\n\r\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\r\n\r\nCompare:\r\n\r\n```python\r\n%%time\r\n\r\nwith tf.Graph().as_default(), tf.Session() as sess:\r\n    zeros = tf.zeros((64, 32, 32, 256))\r\n    beta = tf.get_variable(\r\n        'beta',\r\n        (256,),\r\n        initializer=tf.ones_initializer(),\r\n        trainable=True,\r\n    )\r\n\r\n    loss = tf.reduce_mean((zeros + beta) ** 2)\r\n    optimizer = tf.train.MomentumOptimizer(0.1, 0.9)\r\n    train_op = optimizer.minimize(loss)\r\n\r\n    sess.run(tf.global_variables_initializer())\r\n\r\n    for i in range(500):\r\n        sess.run(train_op)\r\n```\r\n\r\n```\r\nCPU times: user 7.8 s, sys: 868 ms, total: 8.67 s\r\nWall time: 9.69 s\r\n```\r\n\r\nv.\r\n\r\n```python\r\n%%time\r\n\r\nwith tf.Graph().as_default(), tf.Session() as sess:\r\n    zeros = tf.zeros((64, 256, 32, 32))\r\n    beta = tf.get_variable(\r\n        'beta',\r\n        (256,),\r\n        initializer=tf.ones_initializer(),\r\n        trainable=True,\r\n    )\r\n    beta = tf.reshape(beta, (256, 1, 1))\r\n\r\n    loss = tf.reduce_mean((zeros + beta) ** 2)\r\n    optimizer = tf.train.MomentumOptimizer(0.1, 0.9)\r\n    train_op = optimizer.minimize(loss)\r\n\r\n    sess.run(tf.global_variables_initializer())\r\n\r\n    for i in range(500):\r\n        sess.run(train_op)\r\n```\r\n\r\n```\r\nCPU times: user 14.6 s, sys: 2.81 s, total: 17.4 s\r\nWall time: 18.9 s\r\n```\r\n\r\nThis is the scale/bias transform that triggers the problem for me in practice:\r\n\r\n```python\r\ndef affine_transformation(\r\n    inputs,\r\n    axis=-1,\r\n    beta_initializer=tf.zeros_initializer(),\r\n    gamma_initializer=tf.ones_initializer(),\r\n    beta_regularizer=None,\r\n    gamma_regularizer=None,\r\n):\r\n    inputs_shape = inputs.get_shape()\r\n    params_dim = inputs_shape[axis]\r\n\r\n    beta = tf.get_variable(\r\n        'beta',\r\n        (params_dim,),\r\n        initializer=beta_initializer,\r\n        regularizer=beta_regularizer,\r\n        trainable=True,\r\n    )\r\n    gamma = tf.get_variable(\r\n        'gamma',\r\n        (params_dim,),\r\n        initializer=gamma_initializer,\r\n        regularizer=gamma_regularizer,\r\n        trainable=True,\r\n    )\r\n\r\n    if axis != -1:\r\n        params_shape = [1] * len(inputs_shape)\r\n        params_shape[axis] = params_dim.value\r\n\r\n        beta = tf.reshape(beta, params_shape)\r\n        gamma = tf.reshape(gamma, params_shape)\r\n\r\n    return gamma * inputs + beta\r\n```", "comments": ["Clearer description of the issue. My per-epoch timings using the 1.0.0 gpu-devel Docker image on an AWS p2.xlarge, using WRN-16-4 without dropout:\r\n\r\nData format | Fused batch norm | Batch time (ms)\r\n-|-|-\r\nNHWC | No | 340\r\nNHWC | Yes | 320\r\nNCHW | No | **1740**\r\nNCHW | Yes | 270\r\n\r\nI believe this is happening because the broadcasting on the unfused batch norm hits an extreme slow path.\r\n\r\nThis is problematic because if I only follow the \"use NCHW\" recommendation from the performance guide, my models actually run hugely slower. This tripped me up quite a bit.", "Thank you for the high level of detail.  Your table testing the different options is great.  I will come up with some additional wording for the data format section in relation to fused batch norm.  This is very helpful feedback.  ", "It appears this doesn't happen with `tf.nn.bias_add`:\r\n\r\n```python\r\n%%time\r\n\r\nwith tf.Graph().as_default(), tf.Session() as sess:\r\n    zeros = tf.zeros((64, 256, 32, 32))\r\n    beta = tf.get_variable(\r\n        'beta',\r\n        (256,),\r\n        initializer=tf.ones_initializer(),\r\n        trainable=True,\r\n    )\r\n\r\n    loss = tf.reduce_mean(tf.nn.bias_add(zeros, beta, data_format='NCHW') ** 2)\r\n    optimizer = tf.train.MomentumOptimizer(0.1, 0.9)\r\n    train_op = optimizer.minimize(loss)\r\n\r\n    sess.run(tf.global_variables_initializer())\r\n\r\n    for i in range(500):\r\n        sess.run(train_op)\r\n```\r\n\r\n```\r\nCPU times: user 7.98 s, sys: 836 ms, total: 8.81 s\r\nWall time: 9.93 s\r\n```", "This rings a bell... Just a wild guess here -- I haven't checked what TF actually uses, but simple large-stride reductions can be slow because of non-coalesced memory access, and can be made much faster with a different algorithm:\r\n\r\nhttps://github.com/NervanaSystems/neon/issues/188", "Guide has been updated in github, the site should get updated soon.  Closing as the content has been added. I hope to redo the perf guide significantly with everything that has been learned in the past 3-4 months.  "]}, {"number": 7550, "title": "AttributeError: 'module' object has no attribute 'pack'", "body": "Training images using keras with tf backend.The error shows that tf (version==0.12.head) has no attribute \"pack\".\r\n```python\r\nTraceback (most recent call last):\r\n  File \"binary_convnets.py\", line 30, in <module>\r\n    model.add(Flatten())\r\n  File \"/usr/local/lib/python2.7/dist-packages/keras/models.py\", line 324, in add\r\n    output_tensor = layer(self.outputs[0])\r\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py\", line 517, in __call__\r\n    self.add_inbound_node(inbound_layers, node_indices, tensor_indices)\r\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py\", line 571, in add_inbound_node\r\n    Node.create_node(self, inbound_layers, node_indices, tensor_indices)\r\n  File \"/usr/local/lib/python2.7/dist-packages/keras/engine/topology.py\", line 155, in create_node\r\n    output_tensors = to_list(outbound_layer.call(input_tensors[0], mask=input_masks[0]))\r\n  File \"/usr/local/lib/python2.7/dist-packages/keras/layers/core.py\", line 440, in call\r\n    return K.batch_flatten(x)\r\n  File \"/usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py\", line 862, in batch_flatten\r\n    x = tf.reshape(x, tf.pack([-1, prod(shape(x)[1:])]))\r\nAttributeError: 'module' object has no attribute 'pack'\r\n```\r\n", "comments": ["As far as I know, `tf.pack` has been renamed as `tf.stack`. ", "Yes, the keras needs to be updated since this is renamed to stack in tf 1.0.\r\n@fchollet, what's the best way to handle this?", "I have the same issue. I've upgraded to tensorflow version 1.0 and then tried to run a python program that uses keras like this\r\n`from keras.models import Sequential`\r\n`from keras.layers import Flatten, Dense`\r\n\r\nUpdate: It was actually something wrong in my code. It turns out that tf.pack is OK. I upgraded keras = 1.2.0 which still remains the same. ", "I apologize, but I'm confused now. If the issue is resolved please close it. If not, please re-state exactly what is still wrong and what you would like fixed. Thanks so much!", "I am having this problem as well. I pip installed tensorflow in anaconda with python3 environment. Can we revert anaconda to an earlier version of tensorflow to at least temporarily get around this?", "@tawantinsuyu, unfortunately no, we won't downgrade the default version, because that would break users who already updated. To use an older version, an easy way is to use docker. You can also find the previous .whl from our web site and install that, but we don't recommend that. Good luck. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "I have the same problem, my version of tensorflow is 1.0.1, I changed the 'pack' into 'stack', but it did't work. I hope you can help me @zhaopku ", "In page 105 of the book https://www.scribd.com/read/365181872/Building-Machine-Learning-Projects-with-TensorFlow# it also has a call to 'pack' that does not work with the latest version of Tensorflow.", "I had the same issue with TensorFlow. When i tried it in PyCharm it worked. Firstly I thought uninstall and install keras solved it. Still have the same error at Jupyter Notebook (Python 3.6)", "Any solution to this problem? I am having the same problem. tensorflow 1.13, python 3.6.\r\nI replaced tf.pack with tf.stack, but the output of tf.stack is different than tf.pack.\r\nAny solution?", "We can replace tf.pack() with tf.stack in Jupyter Notebook as well. ", "> Any solution to this problem? I am having the same problem. tensorflow 1.13, python 3.6.\r\n> I replaced tf.pack with tf.stack, but the output of tf.stack is different than tf.pack.\r\n> Any solution?\r\n\r\nHow did you solve this issue? I am facing same issue. \r\n"]}, {"number": 7549, "title": "tf.layers.batch_normalization does not support fused", "body": "`tf.layers.batch_normalization` does not accept a `fused` argument, and appears to always use `tf.nn.batch_normalization` instead of `tf.nn.fused_batch_norm`. As such, it does not appear to be possible to follow performance best-practices when using `tf.layers.batch_normalization`.\r\n\r\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\r\n\r\nSearched issues for \"fused\" and \"batch_normalization\"\r\n\r\n### Environment info\r\nOperating System: gcr.io/tensorflow/tensorflow:1.0.0-devel-gpu\r\n\r\n### What other attempted solutions have you tried?\r\nCurrently shimming `tf.contrib.layers.batch_norm`\r\n", "comments": ["As you noticed fused has not been added to core.  Using the version of `layers.batch_norm` in contrib is the correct approach currently.  The feature will be added to core.  Leaving issue open until it is added.  I am excited that you looked at the guide.  I/We will be adding more \"tips\" in the near future.  Thank you for the feedback.", "Small update.  I am still following up on this and more so now that I have a little more free time.  ", "I am also really looking forward to this to resolve. I am working with 5d tensors for 3d image analysis and fused batch norm from slim doesn't support 5d input (https://github.com/tensorflow/tensorflow/issues/5694) and is outdated. Right now I have to use my own function to implement something as basic as reasonably fast batch norm for 3d images. I have implemented the same network with fused batch norm in pytorch and with batch norm from tf.layers and it's about 15 times slower in training (I am using GPU). My function currently performs reshape to 4d and uses batch norm from slim and provides about the same performance as pytorch.\r\n\r\nIt is really surprising for me that this issue is so old. I would say that without fused batch norm current implementation should never be used, because of the performance (15 times slower in my case).", "@Egor-Krivov BTW, see https://github.com/tensorflow/tensorflow/issues/7551 \u2013 the massive perf issue arises whenever non-fused BN is applied to any axis other than the last.", "This is in progress.  A an internal PR to add fused to tf.layers.batch_nornmalization is in progress.  We made it a top priority.  We do not promise dates because things can go wrong or issues come up but I expect it will be in before the end of the quarter.  Again, things can go wrong and that is not a promise just guidance.  ", "@taion Thank you for the remark. I was, indeed, using NCHWD format for my data, following performance guide, and probably got massive performance drop.\r\n@tfboyd Thank you for fast response. Hope it will go as planned.\r\nThere really should be a big warning sign somewhere near tf.layers.batch_normalization, warning about https://github.com/tensorflow/tensorflow/issues/7551.", "@tfboyd \r\n\r\nIt'd be good to add a note to the performance guide warning against using un-fused batch norm when not using a channels-last data format?\r\n\r\nWhile both are active recommendations, it's really weird and strange that switching to NCHW without switching to fused batch norm gives such a massive slowdown \u2013 especially because \"use NCHW\" comes before \"use fused batch norm\" in the performance guide.", "@taion  Thanks Jimmy, I will add that.  So much to do and not enough time in the day.  :-)  I just rewrote most of the code that the Hong Kong University uses for their tests and started using the [DataSets](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/data) which is new in TF 1.2 (RC right now).  I have found it to be much easier and doing side by side testing with queues it is significantly faster.  For something like CIFAR-10 and your code (I think you were using the dict approach) it is really easy to switch.  I have some example code that is not super clean but it covers the basics.  \r\n\r\nAlso, thank you for all of the thoughts for the perf guide.  My lack of updates is not due to not wanting to do them.  As I personally dig deeper into the examples and rewrite some code I am running into similar issues as yourself.  I hope this helps me advocate better for the performance changes I and \"we\" (the community) want.  ", "Seems to be done in: https://github.com/tensorflow/tensorflow/commit/675d36be0d405c3680b49bb6e924f0ed0e233df9", "@mdebski  Thank you and yes it has been added.  :-)"]}, {"number": 7548, "title": "added missing fclose(infile);", "body": "This pull request is a fix for https://github.com/tensorflow/tensorflow/issues/7186", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please"]}, {"number": 7547, "title": "Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912", "body": "I am following this tutorial http://www.bitfusion.io/2016/08/31/training-a-bird-classifier-with-tensorflow-and-tflearn/ I assume that training was done but the system was restarted so I can't verify if the 100 epochs were done. Can you please suggest fixes? Is this a tflearn and tensorflow version mismatch? What can be done? \r\n\r\n```\r\nmona@pascal:~/computer_vision/python_playground$ python infer.py test_images/\r\nbird_african_fish_eagle.jpg          bird_mount_bluebird.jpg              not_a_bird_creativecommons_logo.jpg  \r\nbird_bullocks_oriole.jpg             not_a_bird_airplane.jpg              not_a_bird_stop_sign.jpg             \r\nmona@pascal:~/computer_vision/python_playground$ python infer.py test_images/not_a_bird_stop_sign.jpg \r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\nname: Tesla K40c\r\nmajor: 3 minor: 5 memoryClockRate (GHz) 0.745\r\npciBusID 0000:03:00.0\r\nTotal memory: 11.92GiB\r\nFree memory: 11.85GiB\r\nW tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x3771170\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 1 with properties: \r\nname: Tesla K40c\r\nmajor: 3 minor: 5 memoryClockRate (GHz) 0.745\r\npciBusID 0000:83:00.0\r\nTotal memory: 11.92GiB\r\nFree memory: 11.85GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 0 and 1\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 1 and 0\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 1 \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y N \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 1:   N Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K40c, pci bus id: 0000:83:00.0)\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tflearn/summaries.py:46 in get_summary.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tflearn/summaries.py:46 in get_summary.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tflearn/helpers/trainer.py:766 in create_summaries.: merge_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.merge.\r\nWARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tflearn/helpers/trainer.py:130 in __init__.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\r\nInstructions for updating:\r\nUse `tf.global_variables_initializer` instead.\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K40c, pci bus id: 0000:83:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K40c, pci bus id: 0000:83:00.0)\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tflearn/helpers/trainer.py:378 in restore.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\r\nInstructions for updating:\r\nUse `tf.global_variables_initializer` instead.\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 44, in <module>\r\n    model.load(\"bird-classifier.tfl.ckpt-50912\")\r\n  File \"/usr/local/lib/python2.7/dist-packages/tflearn/models/dnn.py\", line 227, in load\r\n    self.trainer.restore(model_file)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tflearn/helpers/trainer.py\", line 379, in restore\r\n    self.restorer.restore(self.session, model_file)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1388, in restore\r\n    {self.saver_def.filename_tensor_name: save_path})\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 766, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 964, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1014, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1034, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\n     [[Node: save_1/RestoreV2_14 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_1/Const_0, save_1/RestoreV2_14/tensor_names, save_1/RestoreV2_14/shape_and_slices)]]\r\n     [[Node: save_1/RestoreV2_21/_17 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_158_save_1/RestoreV2_21\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\r\n\r\nCaused by op u'save_1/RestoreV2_14', defined at:\r\n  File \"infer.py\", line 43, in <module>\r\n    model = tflearn.DNN(network, tensorboard_verbose=0, checkpoint_path='bird-classifier.tfl.ckpt')\r\n  File \"/usr/local/lib/python2.7/dist-packages/tflearn/models/dnn.py\", line 57, in __init__\r\n    session=session)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tflearn/helpers/trainer.py\", line 125, in __init__\r\n    keep_checkpoint_every_n_hours=keep_checkpoint_every_n_hours)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1000, in __init__\r\n    self.build()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1030, in build\r\n    restore_sequentially=self._restore_sequentially)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 624, in build\r\n    restore_sequentially, reshape)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 361, in _AddRestoreOps\r\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 200, in restore_op\r\n    [spec.tensor.dtype])[0])\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 441, in restore_v2\r\n    dtypes=dtypes, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\n     [[Node: save_1/RestoreV2_14 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_1/Const_0, save_1/RestoreV2_14/tensor_names, save_1/RestoreV2_14/shape_and_slices)]]\r\n     [[Node: save_1/RestoreV2_21/_17 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_158_save_1/RestoreV2_21\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\r\n\r\n[1]+  Killed                  python2 infer.py ${f} 2> /dev/null\r\nmona@pascal:~/computer_vision/python_playground$ ls *50912(\r\n-bash: syntax error near unexpected token `('\r\nmona@pascal:~/computer_vision/python_playground$ ls *50912*\r\nbird-classifier.tfl.ckpt-50912.data-00000-of-00001  bird-classifier.tfl.ckpt-50912.index  bird-classifier.tfl.ckpt-50912.meta\r\n```\r\nHere are the dumped training files I have http://pastebin.com/9RF58yBB\r\n\r\n\r\n### Environment info\r\nOperating System:\r\n```\r\n$ uname -a ; lsb_release -a \r\nLinux pascal 3.13.0-62-generic #102-Ubuntu SMP Tue Aug 11 14:29:36 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux\r\nNo LSB modules are available.\r\nDistributor ID:\tUbuntu\r\nDescription:\tUbuntu 14.04.5 LTS\r\nRelease:\t14.04\r\nCodename:\ttrusty\r\n```\r\n\r\nInstalled version of CUDA and cuDNN: \r\n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\r\n```\r\n$ ls /usr/local/cuda-8.0/lib64/\r\nlibcublas_device.a   libcudnn.so.5.1.10   libcuinj64.so.8.0.44   libcusparse.so.8.0.44  libnppicom.so         libnppim.so          libnppisu.so.8.0.44  libnvgraph.so.8.0            libOpenCL.so\r\nlibcublas.so         libcudnn_static.a    libculibos.a           libcusparse_static.a   libnppicom.so.8.0     libnppim.so.8.0      libnppitc.so         libnvgraph.so.8.0.44         libOpenCL.so.1\r\nlibcublas.so.8.0     libcufft.so          libcurand.so           libnppc.so             libnppicom.so.8.0.44  libnppim.so.8.0.44   libnppitc.so.8.0     libnvgraph_static.a          libOpenCL.so.1.0\r\nlibcublas.so.8.0.45  libcufft.so.8.0      libcurand.so.8.0       libnppc.so.8.0         libnppidei.so         libnppi.so           libnppitc.so.8.0.44  libnvrtc-builtins.so         libOpenCL.so.1.0.0\r\nlibcublas_static.a   libcufft.so.8.0.44   libcurand.so.8.0.44    libnppc.so.8.0.44      libnppidei.so.8.0     libnppi.so.8.0       libnpps.so           libnvrtc-builtins.so.8.0     stubs\r\nlibcudadevrt.a       libcufft_static.a    libcurand_static.a     libnppc_static.a       libnppidei.so.8.0.44  libnppi.so.8.0.44    libnpps.so.8.0       libnvrtc-builtins.so.8.0.44\r\nlibcudart.so         libcufftw.so         libcusolver.so         libnppial.so           libnppif.so           libnppi_static.a     libnpps.so.8.0.44    libnvrtc.so\r\nlibcudart.so.8.0     libcufftw.so.8.0     libcusolver.so.8.0     libnppial.so.8.0       libnppif.so.8.0       libnppist.so         libnpps_static.a     libnvrtc.so.8.0\r\nlibcudart.so.8.0.44  libcufftw.so.8.0.44  libcusolver.so.8.0.44  libnppial.so.8.0.44    libnppif.so.8.0.44    libnppist.so.8.0     libnvblas.so         libnvrtc.so.8.0.44\r\nlibcudart_static.a   libcufftw_static.a   libcusolver_static.a   libnppicc.so           libnppig.so           libnppist.so.8.0.44  libnvblas.so.8.0     libnvToolsExt.so\r\nlibcudnn.so          libcuinj64.so        libcusparse.so         libnppicc.so.8.0       libnppig.so.8.0       libnppisu.so         libnvblas.so.8.0.44  libnvToolsExt.so.1\r\nlibcudnn.so.5        libcuinj64.so.8.0    libcusparse.so.8.0     libnppicc.so.8.0.44    libnppig.so.8.0.44    libnppisu.so.8.0     libnvgraph.so        libnvToolsExt.so.1.0.0\r\n```\r\n\r\nIf installed from binary pip package, provide:\r\n\r\n1. A link to the pip package you installed:\r\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\r\n```\r\n$ python -c \"import tensorflow; print(tensorflow.__version__)\"\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\r\n0.12.1\r\n\r\n```\r\nIf installed from source, provide \r\n\r\n1. The commit hash (`git rev-parse HEAD`)\r\n```\r\nmona@pascal:~/tf/tensorflow$ git rev-parse HEAD\r\n156da397dc2e354baeac10804c5e9c1b3af8b7eb\r\n```\r\n\r\n2. The output of `bazel version`\r\n```\r\n$ bazel version\r\n...........................\r\nBuild label: 0.4.3\r\nBuild target: bazel-out/local-fastbuild/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Thu Dec 22 12:31:25 2016 (1482409885)\r\nBuild timestamp: 1482409885\r\nBuild timestamp as int: 1482409885\r\n```\r\n\r\n", "comments": ["I ran the whole training from scratch. According to the tutorial I should be good, but I get error. Please suggest fixes:\r\n```\r\nmona@pascal:~/computer_vision/python_playground$ python bird_classifier.py\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\nname: Tesla K40c\r\nmajor: 3 minor: 5 memoryClockRate (GHz) 0.8755\r\npciBusID 0000:03:00.0\r\nTotal memory: 11.92GiB\r\nFree memory: 11.85GiB\r\nW tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x3e6fb80\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 1 with properties: \r\nname: Tesla K40c\r\nmajor: 3 minor: 5 memoryClockRate (GHz) 0.8755\r\npciBusID 0000:83:00.0\r\nTotal memory: 11.92GiB\r\nFree memory: 11.85GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 0 and 1\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 1 and 0\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 1 \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y N \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 1:   N Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K40c, pci bus id: 0000:83:00.0)\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tflearn/summaries.py:46 in get_summary.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tflearn/summaries.py:46 in get_summary.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tflearn/helpers/trainer.py:766 in create_summaries.: merge_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.merge.\r\nWARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tflearn/helpers/trainer.py:130 in __init__.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\r\nInstructions for updating:\r\nUse `tf.global_variables_initializer` instead.\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K40c, pci bus id: 0000:83:00.0)\r\n---------------------------------\r\nRun id: bird-classifier\r\nLog directory: /tmp/tflearn_logs/\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tflearn/helpers/trainer.py:210 in fit.: __init__ (from tensorflow.python.training.summary_io) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.FileWriter. The interface and behavior is the same; this is just a rename.\r\nWARNING:tensorflow:Error encountered when serializing data_augmentation.\r\nType is unsupported, or the types of the items don't match field type in CollectionDef.\r\n'ImageAugmentation' object has no attribute 'name'\r\nWARNING:tensorflow:Error encountered when serializing data_preprocessing.\r\nType is unsupported, or the types of the items don't match field type in CollectionDef.\r\n'ImagePreprocessing' object has no attribute 'name'\r\nWARNING:tensorflow:Error encountered when serializing summary_tags.\r\nType is unsupported, or the types of the items don't match field type in CollectionDef.\r\n'dict' object has no attribute 'name'\r\n---------------------------------\r\nPreprocessing... Calculating mean over all dataset (this may take long)...\r\nMean: 0.472978413436 (To avoid repetitive computation, add it to argument 'mean' of `add_featurewise_zero_center`)\r\n---------------------------------\r\nPreprocessing... Calculating std over all dataset (this may take long)...\r\nSTD: 0.248771212446 (To avoid repetitive computation, add it to argument 'std' of `add_featurewise_stdnorm`)\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tflearn/summaries.py:46 in get_summary.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tflearn/helpers/summarizer.py:89 in summarize.: merge_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.merge.\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tflearn/summaries.py:46 in get_summary.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tflearn/helpers/summarizer.py:89 in summarize.: merge_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.merge.\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tflearn/summaries.py:46 in get_summary.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tflearn/helpers/summarizer.py:89 in summarize.: merge_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.merge.\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tflearn/summaries.py:46 in get_summary.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tflearn/helpers/summarizer.py:89 in summarize.: merge_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.merge.\r\n---------------------------------\r\nTraining samples: 56780\r\nValidation samples: 15000\r\n--\r\nTraining Step: 592  | total loss: 0.38131\r\n| Adam | epoch: 001 | loss: 0.38131 - acc: 0.8262 | val_loss: 0.47022 - val_acc: 0.7920 -- iter: 56780/56780\r\n--\r\nTraining Step: 1184  | total loss: 0.34871\r\n| Adam | epoch: 002 | loss: 0.34871 - acc: 0.8402 | val_loss: 0.30224 - val_acc: 0.8785 -- iter: 56780/56780\r\n--\r\nTraining Step: 1776  | total loss: 0.32281\r\n| Adam | epoch: 003 | loss: 0.32281 - acc: 0.8668 | val_loss: 0.29615 - val_acc: 0.8728 -- iter: 56780/56780\r\n--\r\nTraining Step: 2368  | total loss: 0.33464\r\n| Adam | epoch: 004 | loss: 0.33464 - acc: 0.8581 | val_loss: 0.27041 - val_acc: 0.8909 -- iter: 56780/56780\r\n--\r\nTraining Step: 2960  | total loss: 0.30529\r\n| Adam | epoch: 005 | loss: 0.30529 - acc: 0.8640 | val_loss: 0.22851 - val_acc: 0.9099 -- iter: 56780/56780\r\n--\r\nTraining Step: 3552  | total loss: 0.29919\r\n| Adam | epoch: 006 | loss: 0.29919 - acc: 0.8816 | val_loss: 0.21689 - val_acc: 0.9170 -- iter: 56780/56780\r\n--\r\nTraining Step: 4144  | total loss: 0.30198\r\n| Adam | epoch: 007 | loss: 0.30198 - acc: 0.8722 | val_loss: 0.21361 - val_acc: 0.9179 -- iter: 56780/56780\r\n--\r\nTraining Step: 4736  | total loss: 0.27709\r\n| Adam | epoch: 008 | loss: 0.27709 - acc: 0.8845 | val_loss: 0.21748 - val_acc: 0.9141 -- iter: 56780/56780\r\n--\r\nTraining Step: 5328  | total loss: 0.29337\r\n| Adam | epoch: 009 | loss: 0.29337 - acc: 0.8686 | val_loss: 0.21173 - val_acc: 0.9213 -- iter: 56780/56780\r\n--\r\nTraining Step: 5920  | total loss: 0.25989\r\n| Adam | epoch: 010 | loss: 0.25989 - acc: 0.9004 | val_loss: 0.19842 - val_acc: 0.9254 -- iter: 56780/56780\r\n--\r\nTraining Step: 6512  | total loss: 0.27454\r\n| Adam | epoch: 011 | loss: 0.27454 - acc: 0.8932 | val_loss: 0.25719 - val_acc: 0.8979 -- iter: 56780/56780\r\n--\r\nTraining Step: 7104  | total loss: 0.27403\r\n| Adam | epoch: 012 | loss: 0.27403 - acc: 0.8870 | val_loss: 0.20879 - val_acc: 0.9158 -- iter: 56780/56780\r\n--\r\nTraining Step: 7696  | total loss: 0.26534\r\n| Adam | epoch: 013 | loss: 0.26534 - acc: 0.8909 | val_loss: 0.19298 - val_acc: 0.9231 -- iter: 56780/56780\r\n--\r\nTraining Step: 8288  | total loss: 0.25412\r\n| Adam | epoch: 014 | loss: 0.25412 - acc: 0.8880 | val_loss: 0.21687 - val_acc: 0.9179 -- iter: 56780/56780\r\n--\r\nTraining Step: 8880  | total loss: 0.25288\r\n| Adam | epoch: 015 | loss: 0.25288 - acc: 0.8942 | val_loss: 0.18956 - val_acc: 0.9253 -- iter: 56780/56780\r\n--\r\nTraining Step: 9472  | total loss: 0.25877\r\n| Adam | epoch: 016 | loss: 0.25877 - acc: 0.8983 | val_loss: 0.18822 - val_acc: 0.9264 -- iter: 56780/56780\r\n--\r\nTraining Step: 10064  | total loss: 0.26512\r\n| Adam | epoch: 017 | loss: 0.26512 - acc: 0.8877 | val_loss: 0.20234 - val_acc: 0.9181 -- iter: 56780/56780\r\n--\r\nTraining Step: 10656  | total loss: 0.24863\r\n| Adam | epoch: 018 | loss: 0.24863 - acc: 0.8979 | val_loss: 0.18545 - val_acc: 0.9293 -- iter: 56780/56780\r\n--\r\nTraining Step: 11248  | total loss: 0.27568\r\n| Adam | epoch: 019 | loss: 0.27568 - acc: 0.8886 | val_loss: 0.23251 - val_acc: 0.9011 -- iter: 56780/56780\r\n--\r\nTraining Step: 11840  | total loss: 0.26081\r\n| Adam | epoch: 020 | loss: 0.26081 - acc: 0.9007 | val_loss: 0.18766 - val_acc: 0.9263 -- iter: 56780/56780\r\n--\r\nTraining Step: 12432  | total loss: 0.25978\r\n| Adam | epoch: 021 | loss: 0.25978 - acc: 0.8941 | val_loss: 0.21067 - val_acc: 0.9142 -- iter: 56780/56780\r\n--\r\nTraining Step: 13024  | total loss: 0.23778\r\n| Adam | epoch: 022 | loss: 0.23778 - acc: 0.9063 | val_loss: 0.18145 - val_acc: 0.9295 -- iter: 56780/56780\r\n--\r\nTraining Step: 13616  | total loss: 0.26194\r\n| Adam | epoch: 023 | loss: 0.26194 - acc: 0.8917 | val_loss: 0.16927 - val_acc: 0.9357 -- iter: 56780/56780\r\n--\r\nTraining Step: 14208  | total loss: 0.23156\r\n| Adam | epoch: 024 | loss: 0.23156 - acc: 0.9076 | val_loss: 0.16948 - val_acc: 0.9381 -- iter: 56780/56780\r\n--\r\nTraining Step: 14800  | total loss: 0.27990\r\n| Adam | epoch: 025 | loss: 0.27990 - acc: 0.8949 | val_loss: 0.19736 - val_acc: 0.9219 -- iter: 56780/56780\r\n--\r\nTraining Step: 15392  | total loss: 0.23838\r\n| Adam | epoch: 026 | loss: 0.23838 - acc: 0.9051 | val_loss: 0.23477 - val_acc: 0.9077 -- iter: 56780/56780\r\n--\r\nTraining Step: 15984  | total loss: 0.23056\r\n| Adam | epoch: 027 | loss: 0.23056 - acc: 0.9145 | val_loss: 0.18203 - val_acc: 0.9302 -- iter: 56780/56780\r\n--\r\nTraining Step: 16576  | total loss: 0.26332\r\n| Adam | epoch: 028 | loss: 0.26332 - acc: 0.9054 | val_loss: 0.19195 - val_acc: 0.9237 -- iter: 56780/56780\r\n--\r\nTraining Step: 17168  | total loss: 0.24706\r\n| Adam | epoch: 029 | loss: 0.24706 - acc: 0.8994 | val_loss: 0.17842 - val_acc: 0.9343 -- iter: 56780/56780\r\n--\r\nTraining Step: 17760  | total loss: 0.29040\r\n| Adam | epoch: 030 | loss: 0.29040 - acc: 0.9044 | val_loss: 0.16743 - val_acc: 0.9367 -- iter: 56780/56780\r\n--\r\nTraining Step: 18352  | total loss: 0.26592\r\n| Adam | epoch: 031 | loss: 0.26592 - acc: 0.9083 | val_loss: 0.16748 - val_acc: 0.9383 -- iter: 56780/56780\r\n--\r\nTraining Step: 18944  | total loss: 0.25706\r\n| Adam | epoch: 032 | loss: 0.25706 - acc: 0.9178 | val_loss: 0.17325 - val_acc: 0.9379 -- iter: 56780/56780\r\n--\r\nTraining Step: 19536  | total loss: 0.20159\r\n| Adam | epoch: 033 | loss: 0.20159 - acc: 0.9176 | val_loss: 0.18873 - val_acc: 0.9325 -- iter: 56780/56780\r\n--\r\nTraining Step: 20128  | total loss: 0.21798\r\n| Adam | epoch: 034 | loss: 0.21798 - acc: 0.9127 | val_loss: 0.16639 - val_acc: 0.9417 -- iter: 56780/56780\r\n--\r\nTraining Step: 20720  | total loss: 0.22079\r\n| Adam | epoch: 035 | loss: 0.22079 - acc: 0.9137 | val_loss: 0.17444 - val_acc: 0.9390 -- iter: 56780/56780\r\n--\r\nTraining Step: 21312  | total loss: 0.20561\r\n| Adam | epoch: 036 | loss: 0.20561 - acc: 0.9121 | val_loss: 0.16768 - val_acc: 0.9417 -- iter: 56780/56780\r\n--\r\nTraining Step: 21904  | total loss: 0.22152\r\n| Adam | epoch: 037 | loss: 0.22152 - acc: 0.9060 | val_loss: 0.21069 - val_acc: 0.9301 -- iter: 56780/56780\r\n--\r\nTraining Step: 22496  | total loss: 0.19496\r\n| Adam | epoch: 038 | loss: 0.19496 - acc: 0.9216 | val_loss: 0.16395 - val_acc: 0.9419 -- iter: 56780/56780\r\n--\r\nTraining Step: 23088  | total loss: 0.19447\r\n| Adam | epoch: 039 | loss: 0.19447 - acc: 0.9306 | val_loss: 0.21015 - val_acc: 0.9297 -- iter: 56780/56780\r\n--\r\nTraining Step: 23680  | total loss: 0.21090\r\n| Adam | epoch: 040 | loss: 0.21090 - acc: 0.9053 | val_loss: 0.16882 - val_acc: 0.9423 -- iter: 56780/56780\r\n--\r\nTraining Step: 24272  | total loss: 0.20789\r\n| Adam | epoch: 041 | loss: 0.20789 - acc: 0.9099 | val_loss: 0.18452 - val_acc: 0.9356 -- iter: 56780/56780\r\n--\r\nTraining Step: 24864  | total loss: 0.20169\r\n| Adam | epoch: 042 | loss: 0.20169 - acc: 0.9170 | val_loss: 0.17708 - val_acc: 0.9425 -- iter: 56780/56780\r\n--\r\nTraining Step: 25456  | total loss: 0.19569\r\n| Adam | epoch: 043 | loss: 0.19569 - acc: 0.9170 | val_loss: 0.23312 - val_acc: 0.9248 -- iter: 56780/56780\r\n--\r\nTraining Step: 26048  | total loss: 0.18697\r\n| Adam | epoch: 044 | loss: 0.18697 - acc: 0.9252 | val_loss: 0.19613 - val_acc: 0.9381 -- iter: 56780/56780\r\n--\r\nTraining Step: 26640  | total loss: 0.22684\r\n| Adam | epoch: 045 | loss: 0.22684 - acc: 0.8999 | val_loss: 0.16066 - val_acc: 0.9429 -- iter: 56780/56780\r\n--\r\nTraining Step: 27232  | total loss: 0.18028\r\n| Adam | epoch: 046 | loss: 0.18028 - acc: 0.9241 | val_loss: 0.19381 - val_acc: 0.9357 -- iter: 56780/56780\r\n--\r\nTraining Step: 27824  | total loss: 0.20539\r\n| Adam | epoch: 047 | loss: 0.20539 - acc: 0.9217 | val_loss: 0.16741 - val_acc: 0.9448 -- iter: 56780/56780\r\n--\r\nTraining Step: 28416  | total loss: 0.19080\r\n| Adam | epoch: 048 | loss: 0.19080 - acc: 0.9180 | val_loss: 0.18338 - val_acc: 0.9393 -- iter: 56780/56780\r\n--\r\nTraining Step: 29008  | total loss: 0.20501\r\n| Adam | epoch: 049 | loss: 0.20501 - acc: 0.9198 | val_loss: 0.18229 - val_acc: 0.9373 -- iter: 56780/56780\r\n--\r\nTraining Step: 29600  | total loss: 0.20727\r\n| Adam | epoch: 050 | loss: 0.20727 - acc: 0.9088 | val_loss: 0.16408 - val_acc: 0.9451 -- iter: 56780/56780\r\n--\r\nTraining Step: 30192  | total loss: 0.20723\r\n| Adam | epoch: 051 | loss: 0.20723 - acc: 0.9228 | val_loss: 0.17829 - val_acc: 0.9422 -- iter: 56780/56780\r\n--\r\nTraining Step: 30784  | total loss: 0.17597\r\n| Adam | epoch: 052 | loss: 0.17597 - acc: 0.9331 | val_loss: 0.19344 - val_acc: 0.9394 -- iter: 56780/56780\r\n--\r\nTraining Step: 31376  | total loss: 0.18833\r\n| Adam | epoch: 053 | loss: 0.18833 - acc: 0.9186 | val_loss: 0.18768 - val_acc: 0.9393 -- iter: 56780/56780\r\n--\r\nTraining Step: 31968  | total loss: 0.20505\r\n| Adam | epoch: 054 | loss: 0.20505 - acc: 0.9138 | val_loss: 0.16644 - val_acc: 0.9405 -- iter: 56780/56780\r\n--\r\nTraining Step: 32560  | total loss: 0.16588\r\n| Adam | epoch: 055 | loss: 0.16588 - acc: 0.9330 | val_loss: 0.17241 - val_acc: 0.9440 -- iter: 56780/56780\r\n--\r\nTraining Step: 33152  | total loss: 0.18150\r\n| Adam | epoch: 056 | loss: 0.18150 - acc: 0.9282 | val_loss: 0.22217 - val_acc: 0.9264 -- iter: 56780/56780\r\n--\r\nTraining Step: 33744  | total loss: 0.18623\r\n| Adam | epoch: 057 | loss: 0.18623 - acc: 0.9258 | val_loss: 0.18693 - val_acc: 0.9409 -- iter: 56780/56780\r\n--\r\nTraining Step: 34336  | total loss: 0.16764\r\n| Adam | epoch: 058 | loss: 0.16764 - acc: 0.9349 | val_loss: 0.20045 - val_acc: 0.9391 -- iter: 56780/56780\r\n--\r\nTraining Step: 34928  | total loss: 0.17780\r\n| Adam | epoch: 059 | loss: 0.17780 - acc: 0.9274 | val_loss: 0.19269 - val_acc: 0.9401 -- iter: 56780/56780\r\n--\r\nTraining Step: 35520  | total loss: 0.20136\r\n| Adam | epoch: 060 | loss: 0.20136 - acc: 0.9126 | val_loss: 0.16862 - val_acc: 0.9421 -- iter: 56780/56780\r\n--\r\nTraining Step: 36112  | total loss: 0.18579\r\n| Adam | epoch: 061 | loss: 0.18579 - acc: 0.9153 | val_loss: 0.19218 - val_acc: 0.9413 -- iter: 56780/56780\r\n--\r\nTraining Step: 36704  | total loss: 0.19734\r\n| Adam | epoch: 062 | loss: 0.19734 - acc: 0.9227 | val_loss: 0.19395 - val_acc: 0.9411 -- iter: 56780/56780\r\n--\r\nTraining Step: 37296  | total loss: 0.19524\r\n| Adam | epoch: 063 | loss: 0.19524 - acc: 0.9232 | val_loss: 0.18694 - val_acc: 0.9445 -- iter: 56780/56780\r\n--\r\nTraining Step: 37888  | total loss: 0.17370\r\n| Adam | epoch: 064 | loss: 0.17370 - acc: 0.9286 | val_loss: 0.21610 - val_acc: 0.9374 -- iter: 56780/56780\r\n--\r\nTraining Step: 38480  | total loss: 0.16810\r\n| Adam | epoch: 065 | loss: 0.16810 - acc: 0.9339 | val_loss: 0.20480 - val_acc: 0.9430 -- iter: 56780/56780\r\n--\r\nTraining Step: 39072  | total loss: 0.17130\r\n| Adam | epoch: 066 | loss: 0.17130 - acc: 0.9311 | val_loss: 0.21283 - val_acc: 0.9328 -- iter: 56780/56780\r\n--\r\nTraining Step: 39664  | total loss: 0.19402\r\n| Adam | epoch: 067 | loss: 0.19402 - acc: 0.9262 | val_loss: 0.17575 - val_acc: 0.9453 -- iter: 56780/56780\r\n--\r\nTraining Step: 40256  | total loss: 0.17647\r\n| Adam | epoch: 068 | loss: 0.17647 - acc: 0.9210 | val_loss: 0.17410 - val_acc: 0.9437 -- iter: 56780/56780\r\n--\r\nTraining Step: 40848  | total loss: 0.19589\r\n| Adam | epoch: 069 | loss: 0.19589 - acc: 0.9151 | val_loss: 0.18524 - val_acc: 0.9431 -- iter: 56780/56780\r\n--\r\nTraining Step: 41440  | total loss: 0.19701\r\n| Adam | epoch: 070 | loss: 0.19701 - acc: 0.9166 | val_loss: 0.16600 - val_acc: 0.9467 -- iter: 56780/56780\r\n--\r\nTraining Step: 42032  | total loss: 0.18202\r\n| Adam | epoch: 071 | loss: 0.18202 - acc: 0.9271 | val_loss: 0.22758 - val_acc: 0.9319 -- iter: 56780/56780\r\n--\r\nTraining Step: 42624  | total loss: 0.16501\r\n| Adam | epoch: 072 | loss: 0.16501 - acc: 0.9318 | val_loss: 0.18459 - val_acc: 0.9459 -- iter: 56780/56780\r\n--\r\nTraining Step: 43216  | total loss: 0.17883\r\n| Adam | epoch: 073 | loss: 0.17883 - acc: 0.9339 | val_loss: 0.17911 - val_acc: 0.9423 -- iter: 56780/56780\r\n--\r\nTraining Step: 43808  | total loss: 0.17440\r\n| Adam | epoch: 074 | loss: 0.17440 - acc: 0.9314 | val_loss: 0.22812 - val_acc: 0.9371 -- iter: 56780/56780\r\n--\r\nTraining Step: 44400  | total loss: 0.18914\r\n| Adam | epoch: 075 | loss: 0.18914 - acc: 0.9198 | val_loss: 0.20514 - val_acc: 0.9408 -- iter: 56780/56780\r\n--\r\nTraining Step: 44992  | total loss: 0.15914\r\n| Adam | epoch: 076 | loss: 0.15914 - acc: 0.9265 | val_loss: 0.19328 - val_acc: 0.9437 -- iter: 56780/56780\r\n--\r\nTraining Step: 45584  | total loss: 0.19725\r\n| Adam | epoch: 077 | loss: 0.19725 - acc: 0.9181 | val_loss: 0.20995 - val_acc: 0.9381 -- iter: 56780/56780\r\n--\r\nTraining Step: 46176  | total loss: 0.19954\r\n| Adam | epoch: 078 | loss: 0.19954 - acc: 0.9219 | val_loss: 0.18029 - val_acc: 0.9436 -- iter: 56780/56780\r\n--\r\nTraining Step: 46768  | total loss: 0.18051\r\n| Adam | epoch: 079 | loss: 0.18051 - acc: 0.9191 | val_loss: 0.19211 - val_acc: 0.9393 -- iter: 56780/56780\r\n--\r\nTraining Step: 47360  | total loss: 0.16871\r\n| Adam | epoch: 080 | loss: 0.16871 - acc: 0.9331 | val_loss: 0.21379 - val_acc: 0.9420 -- iter: 56780/56780\r\n--\r\nTraining Step: 47952  | total loss: 0.18850\r\n| Adam | epoch: 081 | loss: 0.18850 - acc: 0.9240 | val_loss: 0.18426 - val_acc: 0.9435 -- iter: 56780/56780\r\n--\r\nTraining Step: 48544  | total loss: 0.17831\r\n| Adam | epoch: 082 | loss: 0.17831 - acc: 0.9250 | val_loss: 0.18285 - val_acc: 0.9437 -- iter: 56780/56780\r\n--\r\nTraining Step: 49136  | total loss: 0.16153\r\n| Adam | epoch: 083 | loss: 0.16153 - acc: 0.9348 | val_loss: 0.20661 - val_acc: 0.9445 -- iter: 56780/56780\r\n--\r\nTraining Step: 49728  | total loss: 0.15815\r\n| Adam | epoch: 084 | loss: 0.15815 - acc: 0.9361 | val_loss: 0.21485 - val_acc: 0.9393 -- iter: 56780/56780\r\n--\r\nTraining Step: 50320  | total loss: 0.16564\r\n| Adam | epoch: 085 | loss: 0.16564 - acc: 0.9349 | val_loss: 0.21804 - val_acc: 0.9434 -- iter: 56780/56780\r\n--\r\nTraining Step: 50912  | total loss: 0.14148\r\n| Adam | epoch: 086 | loss: 0.14148 - acc: 0.9408 | val_loss: 0.20338 - val_acc: 0.9443 -- iter: 56780/56780\r\n--\r\nTraining Step: 51504  | total loss: 0.17472\r\n| Adam | epoch: 087 | loss: 0.17472 - acc: 0.9273 | val_loss: 0.17587 - val_acc: 0.9470 -- iter: 56780/56780\r\n--\r\nTraining Step: 52096  | total loss: 0.14303\r\n| Adam | epoch: 088 | loss: 0.14303 - acc: 0.9406 | val_loss: 0.20464 - val_acc: 0.9436 -- iter: 56780/56780\r\n--\r\nTraining Step: 52688  | total loss: 0.15808\r\n| Adam | epoch: 089 | loss: 0.15808 - acc: 0.9363 | val_loss: 0.20220 - val_acc: 0.9448 -- iter: 56780/56780\r\n--\r\nTraining Step: 53280  | total loss: 0.17106\r\n| Adam | epoch: 090 | loss: 0.17106 - acc: 0.9327 | val_loss: 0.19828 - val_acc: 0.9459 -- iter: 56780/56780\r\n--\r\nTraining Step: 53872  | total loss: 0.15785\r\n| Adam | epoch: 091 | loss: 0.15785 - acc: 0.9341 | val_loss: 0.20204 - val_acc: 0.9469 -- iter: 56780/56780\r\n--\r\nTraining Step: 54464  | total loss: 0.18560\r\n| Adam | epoch: 092 | loss: 0.18560 - acc: 0.9213 | val_loss: 0.20947 - val_acc: 0.9412 -- iter: 56780/56780\r\n--\r\nTraining Step: 55056  | total loss: 0.16409\r\n| Adam | epoch: 093 | loss: 0.16409 - acc: 0.9263 | val_loss: 0.20096 - val_acc: 0.9488 -- iter: 56780/56780\r\n--\r\nTraining Step: 55648  | total loss: 0.16949\r\n| Adam | epoch: 094 | loss: 0.16949 - acc: 0.9328 | val_loss: 0.19215 - val_acc: 0.9455 -- iter: 56780/56780\r\n--\r\nTraining Step: 56240  | total loss: 0.16486\r\n| Adam | epoch: 095 | loss: 0.16486 - acc: 0.9317 | val_loss: 0.20186 - val_acc: 0.9447 -- iter: 56780/56780\r\n--\r\nTraining Step: 56832  | total loss: 0.18117\r\n| Adam | epoch: 096 | loss: 0.18117 - acc: 0.9338 | val_loss: 0.20586 - val_acc: 0.9405 -- iter: 56780/56780\r\n--\r\nTraining Step: 57424  | total loss: 0.16308\r\n| Adam | epoch: 097 | loss: 0.16308 - acc: 0.9352 | val_loss: 0.20993 - val_acc: 0.9441 -- iter: 56780/56780\r\n--\r\nTraining Step: 58016  | total loss: 0.15278\r\n| Adam | epoch: 098 | loss: 0.15278 - acc: 0.9409 | val_loss: 0.21945 - val_acc: 0.9405 -- iter: 56780/56780\r\n--\r\nTraining Step: 58608  | total loss: 0.15651\r\n| Adam | epoch: 099 | loss: 0.15651 - acc: 0.9359 | val_loss: 0.25318 - val_acc: 0.9359 -- iter: 56780/56780\r\n--\r\nTraining Step: 59200  | total loss: 0.17185\r\n| Adam | epoch: 100 | loss: 0.17185 - acc: 0.9235 | val_loss: 0.21731 - val_acc: 0.9457 -- iter: 56780/56780\r\n--\r\nNetwork trained and saved as bird-classifier.tfl!\r\nmona@pascal:~/computer_vision/python_playground$ ls -ltr\r\ntotal 8370824\r\n-rw-rw-r-- 1 mona mona     153361 Sep 13  2015 cat.png\r\n-rw-rw-r-- 1 mona mona      48077 Jun  2  2016 nice.jpg\r\n-rw-rw-r-- 1 mona mona 5483602303 Jun 12  2016 full_dataset.pkl\r\n-rw-rw-r-- 1 mona mona  450189480 Jun 14  2016 data.zip\r\n-rw-rw-r-- 1 mona mona        316 Feb 10 17:54 psutil_example.py\r\n-rw-rw-r-- 1 mona mona        686 Feb 13 12:04 image_pyramid.py\r\n-rw-rw-r-- 1 mona mona       1191 Feb 13 12:50 pyramid.py\r\ndrwxr-xr-x 2 mona mona       4096 Feb 14 22:30 MNIST_data\r\n-rw-rw-r-- 1 mona mona      11794 Feb 14 22:40 Untitled.ipynb\r\n-rw-rw-r-- 1 mona mona       2086 Feb 14 22:42 r_u_a_bird.py\r\n-rw-rw-r-- 1 mona mona       2724 Feb 14 22:57 bird_classifier.py\r\n-rw-rw-r-- 1 mona mona       2109 Feb 15 15:08 infer.py\r\ndrwxrwxr-x 2 mona mona       4096 Feb 15 15:08 test_images\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:18 bird-classifier.tfl.ckpt-592.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:18 bird-classifier.tfl.ckpt-592.index\r\n-rw-rw-r-- 1 mona mona     223405 Feb 15 19:18 bird-classifier.tfl.ckpt-592.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:19 bird-classifier.tfl.ckpt-1184.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:19 bird-classifier.tfl.ckpt-1184.index\r\n-rw-rw-r-- 1 mona mona     223873 Feb 15 19:19 bird-classifier.tfl.ckpt-1184.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:19 bird-classifier.tfl.ckpt-1776.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:19 bird-classifier.tfl.ckpt-1776.index\r\n-rw-rw-r-- 1 mona mona     224344 Feb 15 19:19 bird-classifier.tfl.ckpt-1776.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:20 bird-classifier.tfl.ckpt-2368.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:20 bird-classifier.tfl.ckpt-2368.index\r\n-rw-rw-r-- 1 mona mona     224818 Feb 15 19:20 bird-classifier.tfl.ckpt-2368.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:21 bird-classifier.tfl.ckpt-2960.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:21 bird-classifier.tfl.ckpt-2960.index\r\n-rw-rw-r-- 1 mona mona     225292 Feb 15 19:21 bird-classifier.tfl.ckpt-2960.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:22 bird-classifier.tfl.ckpt-3552.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:22 bird-classifier.tfl.ckpt-3552.index\r\n-rw-rw-r-- 1 mona mona     225766 Feb 15 19:22 bird-classifier.tfl.ckpt-3552.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:22 bird-classifier.tfl.ckpt-4144.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:22 bird-classifier.tfl.ckpt-4144.index\r\n-rw-rw-r-- 1 mona mona     226240 Feb 15 19:22 bird-classifier.tfl.ckpt-4144.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:23 bird-classifier.tfl.ckpt-4736.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:23 bird-classifier.tfl.ckpt-4736.index\r\n-rw-rw-r-- 1 mona mona     226714 Feb 15 19:23 bird-classifier.tfl.ckpt-4736.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:24 bird-classifier.tfl.ckpt-5328.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:24 bird-classifier.tfl.ckpt-5328.index\r\n-rw-rw-r-- 1 mona mona     227188 Feb 15 19:24 bird-classifier.tfl.ckpt-5328.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:25 bird-classifier.tfl.ckpt-5920.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:25 bird-classifier.tfl.ckpt-5920.index\r\n-rw-rw-r-- 1 mona mona     227662 Feb 15 19:25 bird-classifier.tfl.ckpt-5920.meta\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:25 bird-classifier.tfl.ckpt-6512.index\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:25 bird-classifier.tfl.ckpt-6512.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona     228136 Feb 15 19:26 bird-classifier.tfl.ckpt-6512.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:26 bird-classifier.tfl.ckpt-7104.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:26 bird-classifier.tfl.ckpt-7104.index\r\n-rw-rw-r-- 1 mona mona     228610 Feb 15 19:26 bird-classifier.tfl.ckpt-7104.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:27 bird-classifier.tfl.ckpt-7696.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:27 bird-classifier.tfl.ckpt-7696.index\r\n-rw-rw-r-- 1 mona mona     229084 Feb 15 19:27 bird-classifier.tfl.ckpt-7696.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:28 bird-classifier.tfl.ckpt-8288.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:28 bird-classifier.tfl.ckpt-8288.index\r\n-rw-rw-r-- 1 mona mona     229558 Feb 15 19:28 bird-classifier.tfl.ckpt-8288.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:28 bird-classifier.tfl.ckpt-8880.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:28 bird-classifier.tfl.ckpt-8880.index\r\n-rw-rw-r-- 1 mona mona     230032 Feb 15 19:28 bird-classifier.tfl.ckpt-8880.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:29 bird-classifier.tfl.ckpt-9472.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:29 bird-classifier.tfl.ckpt-9472.index\r\n-rw-rw-r-- 1 mona mona     230506 Feb 15 19:29 bird-classifier.tfl.ckpt-9472.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:30 bird-classifier.tfl.ckpt-10064.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:30 bird-classifier.tfl.ckpt-10064.index\r\n-rw-rw-r-- 1 mona mona     230980 Feb 15 19:30 bird-classifier.tfl.ckpt-10064.meta\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:31 bird-classifier.tfl.ckpt-10656.index\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:31 bird-classifier.tfl.ckpt-10656.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona     231454 Feb 15 19:31 bird-classifier.tfl.ckpt-10656.meta\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:31 bird-classifier.tfl.ckpt-11248.index\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:31 bird-classifier.tfl.ckpt-11248.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona     231928 Feb 15 19:31 bird-classifier.tfl.ckpt-11248.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:32 bird-classifier.tfl.ckpt-11840.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:32 bird-classifier.tfl.ckpt-11840.index\r\n-rw-rw-r-- 1 mona mona     232402 Feb 15 19:32 bird-classifier.tfl.ckpt-11840.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:33 bird-classifier.tfl.ckpt-12432.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:33 bird-classifier.tfl.ckpt-12432.index\r\n-rw-rw-r-- 1 mona mona     232876 Feb 15 19:33 bird-classifier.tfl.ckpt-12432.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:34 bird-classifier.tfl.ckpt-13024.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:34 bird-classifier.tfl.ckpt-13024.index\r\n-rw-rw-r-- 1 mona mona     233350 Feb 15 19:34 bird-classifier.tfl.ckpt-13024.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:34 bird-classifier.tfl.ckpt-13616.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:34 bird-classifier.tfl.ckpt-13616.index\r\n-rw-rw-r-- 1 mona mona     233824 Feb 15 19:34 bird-classifier.tfl.ckpt-13616.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:35 bird-classifier.tfl.ckpt-14208.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:35 bird-classifier.tfl.ckpt-14208.index\r\n-rw-rw-r-- 1 mona mona     234298 Feb 15 19:35 bird-classifier.tfl.ckpt-14208.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:36 bird-classifier.tfl.ckpt-14800.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:36 bird-classifier.tfl.ckpt-14800.index\r\n-rw-rw-r-- 1 mona mona     234772 Feb 15 19:36 bird-classifier.tfl.ckpt-14800.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:37 bird-classifier.tfl.ckpt-15392.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:37 bird-classifier.tfl.ckpt-15392.index\r\n-rw-rw-r-- 1 mona mona     235246 Feb 15 19:37 bird-classifier.tfl.ckpt-15392.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:37 bird-classifier.tfl.ckpt-15984.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:37 bird-classifier.tfl.ckpt-15984.index\r\n-rw-rw-r-- 1 mona mona     235720 Feb 15 19:37 bird-classifier.tfl.ckpt-15984.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:38 bird-classifier.tfl.ckpt-16576.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:38 bird-classifier.tfl.ckpt-16576.index\r\n-rw-rw-r-- 1 mona mona     236194 Feb 15 19:38 bird-classifier.tfl.ckpt-16576.meta\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:39 bird-classifier.tfl.ckpt-17168.index\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:39 bird-classifier.tfl.ckpt-17168.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona     236668 Feb 15 19:39 bird-classifier.tfl.ckpt-17168.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:40 bird-classifier.tfl.ckpt-17760.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:40 bird-classifier.tfl.ckpt-17760.index\r\n-rw-rw-r-- 1 mona mona     237142 Feb 15 19:40 bird-classifier.tfl.ckpt-17760.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:40 bird-classifier.tfl.ckpt-18352.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:40 bird-classifier.tfl.ckpt-18352.index\r\n-rw-rw-r-- 1 mona mona     237616 Feb 15 19:41 bird-classifier.tfl.ckpt-18352.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:41 bird-classifier.tfl.ckpt-18944.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:41 bird-classifier.tfl.ckpt-18944.index\r\n-rw-rw-r-- 1 mona mona     238090 Feb 15 19:41 bird-classifier.tfl.ckpt-18944.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:42 bird-classifier.tfl.ckpt-19536.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:42 bird-classifier.tfl.ckpt-19536.index\r\n-rw-rw-r-- 1 mona mona     238564 Feb 15 19:42 bird-classifier.tfl.ckpt-19536.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:43 bird-classifier.tfl.ckpt-20128.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:43 bird-classifier.tfl.ckpt-20128.index\r\n-rw-rw-r-- 1 mona mona     239038 Feb 15 19:43 bird-classifier.tfl.ckpt-20128.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:44 bird-classifier.tfl.ckpt-20720.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:44 bird-classifier.tfl.ckpt-20720.index\r\n-rw-rw-r-- 1 mona mona     239512 Feb 15 19:44 bird-classifier.tfl.ckpt-20720.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:44 bird-classifier.tfl.ckpt-21312.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:44 bird-classifier.tfl.ckpt-21312.index\r\n-rw-rw-r-- 1 mona mona     239986 Feb 15 19:44 bird-classifier.tfl.ckpt-21312.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:45 bird-classifier.tfl.ckpt-21904.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:45 bird-classifier.tfl.ckpt-21904.index\r\n-rw-rw-r-- 1 mona mona     240460 Feb 15 19:45 bird-classifier.tfl.ckpt-21904.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:46 bird-classifier.tfl.ckpt-22496.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:46 bird-classifier.tfl.ckpt-22496.index\r\n-rw-rw-r-- 1 mona mona     240934 Feb 15 19:46 bird-classifier.tfl.ckpt-22496.meta\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:47 bird-classifier.tfl.ckpt-23088.index\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:47 bird-classifier.tfl.ckpt-23088.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona     241408 Feb 15 19:47 bird-classifier.tfl.ckpt-23088.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:47 bird-classifier.tfl.ckpt-23680.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:47 bird-classifier.tfl.ckpt-23680.index\r\n-rw-rw-r-- 1 mona mona     241882 Feb 15 19:47 bird-classifier.tfl.ckpt-23680.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:48 bird-classifier.tfl.ckpt-24272.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:48 bird-classifier.tfl.ckpt-24272.index\r\n-rw-rw-r-- 1 mona mona     242356 Feb 15 19:48 bird-classifier.tfl.ckpt-24272.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:49 bird-classifier.tfl.ckpt-24864.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:49 bird-classifier.tfl.ckpt-24864.index\r\n-rw-rw-r-- 1 mona mona     242830 Feb 15 19:49 bird-classifier.tfl.ckpt-24864.meta\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:50 bird-classifier.tfl.ckpt-25456.index\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:50 bird-classifier.tfl.ckpt-25456.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona     243304 Feb 15 19:50 bird-classifier.tfl.ckpt-25456.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:50 bird-classifier.tfl.ckpt-26048.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:50 bird-classifier.tfl.ckpt-26048.index\r\n-rw-rw-r-- 1 mona mona     243778 Feb 15 19:50 bird-classifier.tfl.ckpt-26048.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:51 bird-classifier.tfl.ckpt-26640.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:51 bird-classifier.tfl.ckpt-26640.index\r\n-rw-rw-r-- 1 mona mona     244252 Feb 15 19:51 bird-classifier.tfl.ckpt-26640.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:52 bird-classifier.tfl.ckpt-27232.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:52 bird-classifier.tfl.ckpt-27232.index\r\n-rw-rw-r-- 1 mona mona     244726 Feb 15 19:52 bird-classifier.tfl.ckpt-27232.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:53 bird-classifier.tfl.ckpt-27824.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:53 bird-classifier.tfl.ckpt-27824.index\r\n-rw-rw-r-- 1 mona mona     245200 Feb 15 19:53 bird-classifier.tfl.ckpt-27824.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:53 bird-classifier.tfl.ckpt-28416.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:53 bird-classifier.tfl.ckpt-28416.index\r\n-rw-rw-r-- 1 mona mona     245677 Feb 15 19:53 bird-classifier.tfl.ckpt-28416.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:54 bird-classifier.tfl.ckpt-29008.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:54 bird-classifier.tfl.ckpt-29008.index\r\n-rw-rw-r-- 1 mona mona     246157 Feb 15 19:54 bird-classifier.tfl.ckpt-29008.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:55 bird-classifier.tfl.ckpt-29600.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:55 bird-classifier.tfl.ckpt-29600.index\r\n-rw-rw-r-- 1 mona mona     246637 Feb 15 19:55 bird-classifier.tfl.ckpt-29600.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:56 bird-classifier.tfl.ckpt-30192.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:56 bird-classifier.tfl.ckpt-30192.index\r\n-rw-rw-r-- 1 mona mona     247117 Feb 15 19:56 bird-classifier.tfl.ckpt-30192.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:56 bird-classifier.tfl.ckpt-30784.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:56 bird-classifier.tfl.ckpt-30784.index\r\n-rw-rw-r-- 1 mona mona     247597 Feb 15 19:56 bird-classifier.tfl.ckpt-30784.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:57 bird-classifier.tfl.ckpt-31376.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:57 bird-classifier.tfl.ckpt-31376.index\r\n-rw-rw-r-- 1 mona mona     248077 Feb 15 19:57 bird-classifier.tfl.ckpt-31376.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:58 bird-classifier.tfl.ckpt-31968.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:58 bird-classifier.tfl.ckpt-31968.index\r\n-rw-rw-r-- 1 mona mona     248557 Feb 15 19:58 bird-classifier.tfl.ckpt-31968.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:59 bird-classifier.tfl.ckpt-32560.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:59 bird-classifier.tfl.ckpt-32560.index\r\n-rw-rw-r-- 1 mona mona     249037 Feb 15 19:59 bird-classifier.tfl.ckpt-32560.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 19:59 bird-classifier.tfl.ckpt-33152.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 19:59 bird-classifier.tfl.ckpt-33152.index\r\n-rw-rw-r-- 1 mona mona     249517 Feb 15 19:59 bird-classifier.tfl.ckpt-33152.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:00 bird-classifier.tfl.ckpt-33744.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:00 bird-classifier.tfl.ckpt-33744.index\r\n-rw-rw-r-- 1 mona mona     249997 Feb 15 20:00 bird-classifier.tfl.ckpt-33744.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:01 bird-classifier.tfl.ckpt-34336.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:01 bird-classifier.tfl.ckpt-34336.index\r\n-rw-rw-r-- 1 mona mona     250477 Feb 15 20:01 bird-classifier.tfl.ckpt-34336.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:02 bird-classifier.tfl.ckpt-34928.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:02 bird-classifier.tfl.ckpt-34928.index\r\n-rw-rw-r-- 1 mona mona     250957 Feb 15 20:02 bird-classifier.tfl.ckpt-34928.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:02 bird-classifier.tfl.ckpt-35520.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:02 bird-classifier.tfl.ckpt-35520.index\r\n-rw-rw-r-- 1 mona mona     251437 Feb 15 20:02 bird-classifier.tfl.ckpt-35520.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:03 bird-classifier.tfl.ckpt-36112.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:03 bird-classifier.tfl.ckpt-36112.index\r\n-rw-rw-r-- 1 mona mona     251917 Feb 15 20:03 bird-classifier.tfl.ckpt-36112.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:04 bird-classifier.tfl.ckpt-36704.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:04 bird-classifier.tfl.ckpt-36704.index\r\n-rw-rw-r-- 1 mona mona     252397 Feb 15 20:04 bird-classifier.tfl.ckpt-36704.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:05 bird-classifier.tfl.ckpt-37296.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:05 bird-classifier.tfl.ckpt-37296.index\r\n-rw-rw-r-- 1 mona mona     252877 Feb 15 20:05 bird-classifier.tfl.ckpt-37296.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:05 bird-classifier.tfl.ckpt-37888.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:05 bird-classifier.tfl.ckpt-37888.index\r\n-rw-rw-r-- 1 mona mona     253357 Feb 15 20:05 bird-classifier.tfl.ckpt-37888.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:06 bird-classifier.tfl.ckpt-38480.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:06 bird-classifier.tfl.ckpt-38480.index\r\n-rw-rw-r-- 1 mona mona     253837 Feb 15 20:06 bird-classifier.tfl.ckpt-38480.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:07 bird-classifier.tfl.ckpt-39072.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:07 bird-classifier.tfl.ckpt-39072.index\r\n-rw-rw-r-- 1 mona mona     254317 Feb 15 20:07 bird-classifier.tfl.ckpt-39072.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:08 bird-classifier.tfl.ckpt-39664.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:08 bird-classifier.tfl.ckpt-39664.index\r\n-rw-rw-r-- 1 mona mona     254797 Feb 15 20:08 bird-classifier.tfl.ckpt-39664.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:08 bird-classifier.tfl.ckpt-40256.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:08 bird-classifier.tfl.ckpt-40256.index\r\n-rw-rw-r-- 1 mona mona     255277 Feb 15 20:09 bird-classifier.tfl.ckpt-40256.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:09 bird-classifier.tfl.ckpt-40848.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:09 bird-classifier.tfl.ckpt-40848.index\r\n-rw-rw-r-- 1 mona mona     255757 Feb 15 20:09 bird-classifier.tfl.ckpt-40848.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:10 bird-classifier.tfl.ckpt-41440.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:10 bird-classifier.tfl.ckpt-41440.index\r\n-rw-rw-r-- 1 mona mona     256237 Feb 15 20:10 bird-classifier.tfl.ckpt-41440.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:11 bird-classifier.tfl.ckpt-42032.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:11 bird-classifier.tfl.ckpt-42032.index\r\n-rw-rw-r-- 1 mona mona     256717 Feb 15 20:11 bird-classifier.tfl.ckpt-42032.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:12 bird-classifier.tfl.ckpt-42624.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:12 bird-classifier.tfl.ckpt-42624.index\r\n-rw-rw-r-- 1 mona mona     257197 Feb 15 20:12 bird-classifier.tfl.ckpt-42624.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:12 bird-classifier.tfl.ckpt-43216.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:12 bird-classifier.tfl.ckpt-43216.index\r\n-rw-rw-r-- 1 mona mona     257677 Feb 15 20:12 bird-classifier.tfl.ckpt-43216.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:13 bird-classifier.tfl.ckpt-43808.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:13 bird-classifier.tfl.ckpt-43808.index\r\n-rw-rw-r-- 1 mona mona     258157 Feb 15 20:13 bird-classifier.tfl.ckpt-43808.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:14 bird-classifier.tfl.ckpt-44400.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:14 bird-classifier.tfl.ckpt-44400.index\r\n-rw-rw-r-- 1 mona mona     258637 Feb 15 20:14 bird-classifier.tfl.ckpt-44400.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:15 bird-classifier.tfl.ckpt-44992.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:15 bird-classifier.tfl.ckpt-44992.index\r\n-rw-rw-r-- 1 mona mona     259117 Feb 15 20:15 bird-classifier.tfl.ckpt-44992.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:15 bird-classifier.tfl.ckpt-45584.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:15 bird-classifier.tfl.ckpt-45584.index\r\n-rw-rw-r-- 1 mona mona     259597 Feb 15 20:15 bird-classifier.tfl.ckpt-45584.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:16 bird-classifier.tfl.ckpt-46176.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:16 bird-classifier.tfl.ckpt-46176.index\r\n-rw-rw-r-- 1 mona mona     260077 Feb 15 20:16 bird-classifier.tfl.ckpt-46176.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:17 bird-classifier.tfl.ckpt-46768.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:17 bird-classifier.tfl.ckpt-46768.index\r\n-rw-rw-r-- 1 mona mona     260557 Feb 15 20:17 bird-classifier.tfl.ckpt-46768.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:18 bird-classifier.tfl.ckpt-47360.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:18 bird-classifier.tfl.ckpt-47360.index\r\n-rw-rw-r-- 1 mona mona     261037 Feb 15 20:18 bird-classifier.tfl.ckpt-47360.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:18 bird-classifier.tfl.ckpt-47952.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:18 bird-classifier.tfl.ckpt-47952.index\r\n-rw-rw-r-- 1 mona mona     261517 Feb 15 20:18 bird-classifier.tfl.ckpt-47952.meta\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:19 bird-classifier.tfl.ckpt-48544.index\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:19 bird-classifier.tfl.ckpt-48544.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona     261997 Feb 15 20:19 bird-classifier.tfl.ckpt-48544.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:20 bird-classifier.tfl.ckpt-49136.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:20 bird-classifier.tfl.ckpt-49136.index\r\n-rw-rw-r-- 1 mona mona     262477 Feb 15 20:20 bird-classifier.tfl.ckpt-49136.meta\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:21 bird-classifier.tfl.ckpt-49728.index\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:21 bird-classifier.tfl.ckpt-49728.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona     262957 Feb 15 20:21 bird-classifier.tfl.ckpt-49728.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:21 bird-classifier.tfl.ckpt-50320.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:21 bird-classifier.tfl.ckpt-50320.index\r\n-rw-rw-r-- 1 mona mona     263437 Feb 15 20:21 bird-classifier.tfl.ckpt-50320.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:22 bird-classifier.tfl.ckpt-50912.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:22 bird-classifier.tfl.ckpt-50912.index\r\n-rw-rw-r-- 1 mona mona     263917 Feb 15 20:22 bird-classifier.tfl.ckpt-50912.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:23 bird-classifier.tfl.ckpt-51504.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:23 bird-classifier.tfl.ckpt-51504.index\r\n-rw-rw-r-- 1 mona mona     264397 Feb 15 20:23 bird-classifier.tfl.ckpt-51504.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:24 bird-classifier.tfl.ckpt-52096.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:24 bird-classifier.tfl.ckpt-52096.index\r\n-rw-rw-r-- 1 mona mona     264877 Feb 15 20:24 bird-classifier.tfl.ckpt-52096.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:24 bird-classifier.tfl.ckpt-52688.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:24 bird-classifier.tfl.ckpt-52688.index\r\n-rw-rw-r-- 1 mona mona     265357 Feb 15 20:25 bird-classifier.tfl.ckpt-52688.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:25 bird-classifier.tfl.ckpt-53280.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:25 bird-classifier.tfl.ckpt-53280.index\r\n-rw-rw-r-- 1 mona mona     265837 Feb 15 20:25 bird-classifier.tfl.ckpt-53280.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:26 bird-classifier.tfl.ckpt-53872.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:26 bird-classifier.tfl.ckpt-53872.index\r\n-rw-rw-r-- 1 mona mona     266317 Feb 15 20:26 bird-classifier.tfl.ckpt-53872.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:27 bird-classifier.tfl.ckpt-54464.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:27 bird-classifier.tfl.ckpt-54464.index\r\n-rw-rw-r-- 1 mona mona     266797 Feb 15 20:27 bird-classifier.tfl.ckpt-54464.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:28 bird-classifier.tfl.ckpt-55056.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:28 bird-classifier.tfl.ckpt-55056.index\r\n-rw-rw-r-- 1 mona mona     267277 Feb 15 20:28 bird-classifier.tfl.ckpt-55056.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:28 bird-classifier.tfl.ckpt-55648.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:28 bird-classifier.tfl.ckpt-55648.index\r\n-rw-rw-r-- 1 mona mona     267757 Feb 15 20:28 bird-classifier.tfl.ckpt-55648.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:29 bird-classifier.tfl.ckpt-56240.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:29 bird-classifier.tfl.ckpt-56240.index\r\n-rw-rw-r-- 1 mona mona     268237 Feb 15 20:29 bird-classifier.tfl.ckpt-56240.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:30 bird-classifier.tfl.ckpt-56832.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:30 bird-classifier.tfl.ckpt-56832.index\r\n-rw-rw-r-- 1 mona mona     268717 Feb 15 20:30 bird-classifier.tfl.ckpt-56832.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:31 bird-classifier.tfl.ckpt-57424.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:31 bird-classifier.tfl.ckpt-57424.index\r\n-rw-rw-r-- 1 mona mona     269197 Feb 15 20:31 bird-classifier.tfl.ckpt-57424.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:31 bird-classifier.tfl.ckpt-58016.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:31 bird-classifier.tfl.ckpt-58016.index\r\n-rw-rw-r-- 1 mona mona     269677 Feb 15 20:31 bird-classifier.tfl.ckpt-58016.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:32 bird-classifier.tfl.ckpt-58608.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:32 bird-classifier.tfl.ckpt-58608.index\r\n-rw-rw-r-- 1 mona mona     270157 Feb 15 20:32 bird-classifier.tfl.ckpt-58608.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:33 bird-classifier.tfl.ckpt-59200.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:33 bird-classifier.tfl.ckpt-59200.index\r\n-rw-rw-r-- 1 mona mona     270637 Feb 15 20:33 bird-classifier.tfl.ckpt-59200.meta\r\n-rw-rw-r-- 1 mona mona   25860184 Feb 15 20:33 bird-classifier.tfl.data-00000-of-00001\r\n-rw-rw-r-- 1 mona mona         95 Feb 15 20:33 checkpoint\r\n-rw-rw-r-- 1 mona mona       1667 Feb 15 20:33 bird-classifier.tfl.index\r\n-rw-rw-r-- 1 mona mona     270637 Feb 15 20:33 bird-classifier.tfl.meta\r\nmona@pascal:~/computer_vision/python_playground$ python infer.py test_images/\r\nbird_african_fish_eagle.jpg          bird_mount_bluebird.jpg              not_a_bird_creativecommons_logo.jpg  \r\nbird_bullocks_oriole.jpg             not_a_bird_airplane.jpg              not_a_bird_stop_sign.jpg             \r\nmona@pascal:~/computer_vision/python_playground$ python infer.py test_images/bird_mount_bluebird.jpg \r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\nname: Tesla K40c\r\nmajor: 3 minor: 5 memoryClockRate (GHz) 0.8755\r\npciBusID 0000:03:00.0\r\nTotal memory: 11.92GiB\r\nFree memory: 11.85GiB\r\nW tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x472b0a0\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 1 with properties: \r\nname: Tesla K40c\r\nmajor: 3 minor: 5 memoryClockRate (GHz) 0.8755\r\npciBusID 0000:83:00.0\r\nTotal memory: 11.92GiB\r\nFree memory: 11.85GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 0 and 1\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 1 and 0\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 1 \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y N \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 1:   N Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K40c, pci bus id: 0000:83:00.0)\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tflearn/summaries.py:46 in get_summary.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tflearn/summaries.py:46 in get_summary.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tflearn/helpers/trainer.py:766 in create_summaries.: merge_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.merge.\r\nWARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tflearn/helpers/trainer.py:130 in __init__.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\r\nInstructions for updating:\r\nUse `tf.global_variables_initializer` instead.\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K40c, pci bus id: 0000:83:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K40c, pci bus id: 0000:83:00.0)\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tflearn/helpers/trainer.py:378 in restore.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\r\nInstructions for updating:\r\nUse `tf.global_variables_initializer` instead.\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nW tensorflow/core/framework/op_kernel.cc:975] Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\nTraceback (most recent call last):\r\n  File \"infer.py\", line 44, in <module>\r\n    model.load(\"bird-classifier.tfl.ckpt-50912\")\r\n  File \"/usr/local/lib/python2.7/dist-packages/tflearn/models/dnn.py\", line 227, in load\r\n    self.trainer.restore(model_file)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tflearn/helpers/trainer.py\", line 379, in restore\r\n    self.restorer.restore(self.session, model_file)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1388, in restore\r\n    {self.saver_def.filename_tensor_name: save_path})\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 766, in run\r\n    run_metadata_ptr)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 964, in _run\r\n    feed_dict_string, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1014, in _do_run\r\n    target_list, options, run_metadata)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 1034, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\n\t [[Node: save_1/RestoreV2_21 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_1/Const_0, save_1/RestoreV2_21/tensor_names, save_1/RestoreV2_21/shape_and_slices)]]\r\n\t [[Node: save_1/RestoreV2_8/_37 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_178_save_1/RestoreV2_8\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\r\n\r\nCaused by op u'save_1/RestoreV2_21', defined at:\r\n  File \"infer.py\", line 43, in <module>\r\n    model = tflearn.DNN(network, tensorboard_verbose=0, checkpoint_path='bird-classifier.tfl.ckpt')\r\n  File \"/usr/local/lib/python2.7/dist-packages/tflearn/models/dnn.py\", line 57, in __init__\r\n    session=session)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tflearn/helpers/trainer.py\", line 125, in __init__\r\n    keep_checkpoint_every_n_hours=keep_checkpoint_every_n_hours)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1000, in __init__\r\n    self.build()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 1030, in build\r\n    restore_sequentially=self._restore_sequentially)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 624, in build\r\n    restore_sequentially, reshape)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 361, in _AddRestoreOps\r\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/training/saver.py\", line 200, in restore_op\r\n    [spec.tensor.dtype])[0])\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gen_io_ops.py\", line 441, in restore_v2\r\n    dtypes=dtypes, name=name)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py\", line 759, in apply_op\r\n    op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 2240, in create_op\r\n    original_op=self._default_original_op, op_def=op_def)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/ops.py\", line 1128, in __init__\r\n    self._traceback = _extract_stack()\r\n\r\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for bird-classifier.tfl.ckpt-50912\r\n\t [[Node: save_1/RestoreV2_21 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/cpu:0\"](_recv_save_1/Const_0, save_1/RestoreV2_21/tensor_names, save_1/RestoreV2_21/shape_and_slices)]]\r\n\t [[Node: save_1/RestoreV2_8/_37 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/gpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=1, tensor_name=\"edge_178_save_1/RestoreV2_8\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\r\n\r\nmona@pascal:~/computer_vision/python_playground$ \r\n```\r\n", "Can you try changing this line in your code:\r\n\r\n```python\r\nmodel.load(\"bird-classifier.tfl.ckpt-50912\")\r\n```\r\n\r\n...to the following:\r\n\r\n```python\r\nmodel.load(\"./bird-classifier.tfl.ckpt-50912\")\r\n```\r\n\r\n...and let us know if that works?", "I had the identical issue with r1.0.0 and adding the \"./\" in front of the file name resolved the issue for me.", "@redbullpeter Peter did you have this issue for running the tutorial off the bitfusion? Just curious. ", "@monajalal No, I am running a repurposed version of this [TensorKart](https://github.com/kevinhughes27/TensorKart) ", "@monajalal Did adding the `./` work for you?", "@mrry @aselle @redbullpeter  Thank you all! That solved the problem:\r\n```\r\nmona@pascal:~/computer_vision/python_playground$ python infer.py test_images/not_a_bird_stop_sign.jpg \r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcublas.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcudnn.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcufft.so locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:128] successfully opened CUDA library libcurand.so locally\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \r\nname: Tesla K40c\r\nmajor: 3 minor: 5 memoryClockRate (GHz) 0.8755\r\npciBusID 0000:03:00.0\r\nTotal memory: 11.92GiB\r\nFree memory: 11.85GiB\r\nW tensorflow/stream_executor/cuda/cuda_driver.cc:590] creating context when one is currently active; existing: 0x4177390\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 1 with properties: \r\nname: Tesla K40c\r\nmajor: 3 minor: 5 memoryClockRate (GHz) 0.8755\r\npciBusID 0000:83:00.0\r\nTotal memory: 11.92GiB\r\nFree memory: 11.85GiB\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 0 and 1\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:777] Peer access not supported between device ordinals 1 and 0\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 1 \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y N \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 1:   N Y \r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K40c, pci bus id: 0000:83:00.0)\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tflearn/summaries.py:46 in get_summary.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tflearn/summaries.py:46 in get_summary.: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tflearn/helpers/trainer.py:766 in create_summaries.: merge_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\r\nInstructions for updating:\r\nPlease switch to tf.summary.merge.\r\nWARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tflearn/helpers/trainer.py:130 in __init__.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\r\nInstructions for updating:\r\nUse `tf.global_variables_initializer` instead.\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K40c, pci bus id: 0000:83:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K40c, pci bus id: 0000:83:00.0)\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tflearn/helpers/trainer.py:378 in restore.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\r\nInstructions for updating:\r\nUse `tf.global_variables_initializer` instead.\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40c, pci bus id: 0000:03:00.0)\r\nI tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:1) -> (device: 1, name: Tesla K40c, pci bus id: 0000:83:00.0)\r\nThat's not a bird!\r\n```\r\n", "@mrry : Thanks for your help! Adding a `./` did solve the problem. Although a trivial solution, it took me a long time to figure this out. \r\nAlso, don't you think models should be loaded even without that? Many of the existing tensorflow models available on github and elsewhere simply specify adding a `model.ckpt` without a `./` to load an existing checkpoint.", "Yes, I do think so :). @rohan100jain fixed this bug recently, so it should work as expected if you use a nightly build.", "I'm using Object_detection api and I'm trying to run a job and I'm getting the error \r\n```Traceback (most recent call last): File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main \"__main__\", fname, loader, pkg_name) File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code exec code in run_globals File \"/root/.local/lib/python2.7/site-packages/object_detection/train.py\", line 198, in <module> tf.app.run() File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 44, in run _sys.exit(main(_sys.argv[:1] + flags_passthrough)) File \"/root/.local/lib/python2.7/site-packages/object_detection/train.py\", line 194, in main worker_job_name, is_chief, FLAGS.train_dir) File \"/root/.local/lib/python2.7/site-packages/object_detection/trainer.py\", line 218, in train var_map, train_config.fine_tune_checkpoint)) File \"/root/.local/lib/python2.7/site-packages/object_detection/utils/variables_helper.py\", line 122, in get_variables_available_in_checkpoint ckpt_reader = tf.train.NewCheckpointReader(checkpoint_path) File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 110, in NewCheckpointReader return CheckpointReader(compat.as_bytes(filepattern), status) File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__ self.gen.next() File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status pywrap_tensorflow.TF_GetCode(status)) InvalidArgumentError: Unsuccessful TensorSliceReader constructor: Failed to get matching files on ./sofasmodel/model.ckpt: Not found: ./sofasmodel```\r\n\r\nSo the code I ran to get this error was \r\n\r\n```gcloud ml-engine jobs submit training object_detection_11th --job-dir=gs://detectme/training/ --packages dist/object_detection-0.1.tar.gz,slim/dist/slim-0.1.tar.gz --module-name object_detection.train --region us-east1 --config object_detection/training/yaml_config.yml -- --train_dir=gs://detectme/training --pipeline_config_path=gs://detectme/ssd_mobilenet_v1_pets.config```\r\n\r\nThe ssd_mobilent_v1_pets.config is the config file and the fine tune checkpoint is set to my model 'sofamodels' which contains the three model.ckpt files and two other files. I've added the sofasmodel folder in object_detection folder and I've put it even in the bucket. I don't seem to understand from which directory the file is being executed. Also I tried changing the directory path in 'fine_tune_checkpoint' from ```sofamodels/model.ckpt``` to ```./sofmodels/model.ckpt```. \r\n\r\n\r\n```I  successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero \r\nI  Found device 0 with properties:  \r\nE  name: Tesla K80 \r\nE  major: 3 minor: 7 memoryClockRate (GHz) 0.8235 \r\nE  pciBusID 0000:00:04.0 \r\nE  Total memory: 11.17GiB \r\nE  Free memory: 11.11GiB \r\nI  DMA: 0  \r\nI  0:   Y  \r\nI  Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0) \r\nW  The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations. \r\nW  The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations. \r\nI  Initialize GrpcChannelCache for job master -> {0 -> master-f1ae2a4c35-0:2222} \r\nI  Initialize GrpcChannelCache for job ps -> {0 -> ps-f1ae2a4c35-0:2222, 1 -> ps-f1ae2a4c35-1:2222, 2 -> ps-f1ae2a4c35-2:2222} \r\nI  Initialize GrpcChannelCache for job worker -> {0 -> worker-f1ae2a4c35-0:2222, 1 -> worker-f1ae2a4c35-1:2222, 2 -> worker-f1ae2a4c35-2:2222, 3 -> worker-f1ae2a4c35-3:2222, 4 -> localhost:2222} \r\nI  Started server with target: grpc://localhost:2222 \r\nW  The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations. \r\nW  The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations. \r\nI  Initialize GrpcChannelCache for job master -> {0 -> master-f1ae2a4c35-0:2222} \r\nI  Initialize GrpcChannelCache for job ps -> {0 -> ps-f1ae2a4c35-0:2222, 1 -> ps-f1ae2a4c35-1:2222, 2 -> ps-f1ae2a4c35-2:2222} \r\nI  Initialize GrpcChannelCache for job worker -> {0 -> localhost:2222, 1 -> worker-f1ae2a4c35-1:2222, 2 -> worker-f1ae2a4c35-2:2222, 3 -> worker-f1ae2a4c35-3:2222, 4 -> worker-f1ae2a4c35-4:2222} \r\nI  Started server with target: grpc://localhost:2222 \r\nI  successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero \r\nI  Found device 0 with properties:  \r\nE  name: Tesla K80 \r\nE  major: 3 minor: 7 memoryClockRate (GHz) 0.8235 \r\nE  pciBusID 0000:00:04.0 \r\nE  Total memory: 11.17GiB \r\nE  Free memory: 11.11GiB \r\nI  DMA: 0  \r\nI  0:   Y  \r\nI  Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0) \r\nW  The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations. \r\nW  The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations. \r\nI  successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero \r\nI  Found device 0 with properties:  \r\nE  name: Tesla K80 \r\nE  major: 3 minor: 7 memoryClockRate (GHz) 0.8235 \r\nE  pciBusID 0000:00:04.0 \r\nE  Total memory: 11.17GiB \r\nE  Free memory: 11.11GiB \r\nI  DMA: 0  \r\nI  0:   Y  \r\nI  Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0) \r\nI  Initialize GrpcChannelCache for job master -> {0 -> master-f1ae2a4c35-0:2222} \r\nI  Initialize GrpcChannelCache for job ps -> {0 -> ps-f1ae2a4c35-0:2222, 1 -> ps-f1ae2a4c35-1:2222, 2 -> ps-f1ae2a4c35-2:2222} \r\nI  Initialize GrpcChannelCache for job worker -> {0 -> worker-f1ae2a4c35-0:2222, 1 -> localhost:2222, 2 -> worker-f1ae2a4c35-2:2222, 3 -> worker-f1ae2a4c35-3:2222, 4 -> worker-f1ae2a4c35-4:2222} \r\nI  Started server with target: grpc://localhost:2222 \r\nI  Initialize GrpcChannelCache for job master -> {0 -> master-f1ae2a4c35-0:2222} \r\nI  Initialize GrpcChannelCache for job ps -> {0 -> ps-f1ae2a4c35-0:2222, 1 -> ps-f1ae2a4c35-1:2222, 2 -> ps-f1ae2a4c35-2:2222} \r\nI  Initialize GrpcChannelCache for job worker -> {0 -> worker-f1ae2a4c35-0:2222, 1 -> worker-f1ae2a4c35-1:2222, 2 -> localhost:2222, 3 -> worker-f1ae2a4c35-3:2222, 4 -> worker-f1ae2a4c35-4:2222} \r\nI  Started server with target: grpc://localhost:2222 \r\nI  successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero \r\nI  Found device 0 with properties:  \r\nE  name: Tesla K80 \r\nE  major: 3 minor: 7 memoryClockRate (GHz) 0.8235 \r\nE  pciBusID 0000:00:04.0 \r\nE  Total memory: 11.17GiB \r\nE  Free memory: 11.11GiB \r\nI  DMA: 0  \r\nI  0:   Y  \r\nI  Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0) \r\nI  Initialize GrpcChannelCache for job master -> {0 -> master-f1ae2a4c35-0:2222} \r\nI  Initialize GrpcChannelCache for job ps -> {0 -> ps-f1ae2a4c35-0:2222, 1 -> ps-f1ae2a4c35-1:2222, 2 -> ps-f1ae2a4c35-2:2222} \r\nI  Initialize GrpcChannelCache for job worker -> {0 -> worker-f1ae2a4c35-0:2222, 1 -> worker-f1ae2a4c35-1:2222, 2 -> worker-f1ae2a4c35-2:2222, 3 -> localhost:2222, 4 -> worker-f1ae2a4c35-4:2222} \r\nI  Started server with target: grpc://localhost:2222 \r\nI  Summary name Learning Rate is illegal; using Learning_Rate instead. \r\nW  From /root/.local/lib/python2.7/site-packages/object_detection/meta_architectures/ssd_meta_arch.py:607: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\r\nInstructions for updating:\r\nPlease use tf.global_variables instead. \r\nE  Traceback (most recent call last):\r\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\r\n    \"__main__\", fname, loader, pkg_name)\r\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n    exec code in run_globals\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/train.py\", line 198, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 44, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/train.py\", line 194, in main\r\n    worker_job_name, is_chief, FLAGS.train_dir)\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/trainer.py\", line 218, in train\r\n    var_map, train_config.fine_tune_checkpoint))\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/utils/variables_helper.py\", line 122, in get_variables_available_in_checkpoint\r\n    ckpt_reader = tf.train.NewCheckpointReader(checkpoint_path)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 110, in NewCheckpointReader\r\n    return CheckpointReader(compat.as_bytes(filepattern), status)\r\n  File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__\r\n    self.gen.next()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\nInvalidArgumentError: Unsuccessful TensorSliceReader constructor: Failed to get matching files on ./sofasmodel/model.ckpt: Not found: ./sofasmodel\r\n \r\nE  Command '['python', '-m', u'object_detection.train', u'--train_dir=gs://detectme/training', u'--pipeline_config_path=gs://detectme/ssd_mobilenet_v1_pets.config', '--job-dir', u'gs://detectme/training/']' returned non-zero exit status 1 \r\nI  Module completed; cleaning up. \r\nI  Clean up finished. \r\nI  Summary name Learning Rate is illegal; using Learning_Rate instead. \r\nW  From /root/.local/lib/python2.7/site-packages/object_detection/meta_architectures/ssd_meta_arch.py:607: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\r\nInstructions for updating:\r\nPlease use tf.global_variables instead. \r\nE  Traceback (most recent call last):\r\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\r\n    \"__main__\", fname, loader, pkg_name)\r\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n    exec code in run_globals\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/train.py\", line 198, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 44, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/train.py\", line 194, in main\r\n    worker_job_name, is_chief, FLAGS.train_dir)\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/trainer.py\", line 218, in train\r\n    var_map, train_config.fine_tune_checkpoint))\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/utils/variables_helper.py\", line 122, in get_variables_available_in_checkpoint\r\n    ckpt_reader = tf.train.NewCheckpointReader(checkpoint_path)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 110, in NewCheckpointReader\r\n    return CheckpointReader(compat.as_bytes(filepattern), status)\r\n  File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__\r\n    self.gen.next()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\nInvalidArgumentError: Unsuccessful TensorSliceReader constructor: Failed to get matching files on ./sofasmodel/model.ckpt: Not found: ./sofasmodel\r\n \r\n  undefined\r\nE  Command '['python', '-m', u'object_detection.train', u'--train_dir=gs://detectme/training', u'--pipeline_config_path=gs://detectme/ssd_mobilenet_v1_pets.config', '--job-dir', u'gs://detectme/training/']' returned non-zero exit status 1 \r\nI  Module completed; cleaning up. \r\nI  Clean up finished. \r\nI  Summary name Learning Rate is illegal; using Learning_Rate instead. \r\nW  From /root/.local/lib/python2.7/site-packages/object_detection/meta_architectures/ssd_meta_arch.py:607: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\r\nInstructions for updating:\r\nPlease use tf.global_variables instead. \r\nE  Traceback (most recent call last):\r\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\r\n    \"__main__\", fname, loader, pkg_name)\r\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n    exec code in run_globals\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/train.py\", line 198, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 44, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/train.py\", line 194, in main\r\n    worker_job_name, is_chief, FLAGS.train_dir)\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/trainer.py\", line 218, in train\r\n    var_map, train_config.fine_tune_checkpoint))\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/utils/variables_helper.py\", line 122, in get_variables_available_in_checkpoint\r\n    ckpt_reader = tf.train.NewCheckpointReader(checkpoint_path)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 110, in NewCheckpointReader\r\n    return CheckpointReader(compat.as_bytes(filepattern), status)\r\n  File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__\r\n    self.gen.next()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\nInvalidArgumentError: Unsuccessful TensorSliceReader constructor: Failed to get matching files on ./sofasmodel/model.ckpt: Not found: ./sofasmodel\r\n \r\nI  Summary name Learning Rate is illegal; using Learning_Rate instead. \r\nW  From /root/.local/lib/python2.7/site-packages/object_detection/meta_architectures/ssd_meta_arch.py:607: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\r\nInstructions for updating:\r\nPlease use tf.global_variables instead. \r\nE  Traceback (most recent call last):\r\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\r\n    \"__main__\", fname, loader, pkg_name)\r\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n    exec code in run_globals\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/train.py\", line 198, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 44, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/train.py\", line 194, in main\r\n    worker_job_name, is_chief, FLAGS.train_dir)\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/trainer.py\", line 218, in train\r\n    var_map, train_config.fine_tune_checkpoint))\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/utils/variables_helper.py\", line 122, in get_variables_available_in_checkpoint\r\n    ckpt_reader = tf.train.NewCheckpointReader(checkpoint_path)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 110, in NewCheckpointReader\r\n    return CheckpointReader(compat.as_bytes(filepattern), status)\r\n  File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__\r\n    self.gen.next()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\nInvalidArgumentError: Unsuccessful TensorSliceReader constructor: Failed to get matching files on ./sofasmodel/model.ckpt: Not found: ./sofasmodel\r\n \r\nI  Summary name Learning Rate is illegal; using Learning_Rate instead. \r\nW  From /root/.local/lib/python2.7/site-packages/object_detection/meta_architectures/ssd_meta_arch.py:607: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\r\nInstructions for updating:\r\nPlease use tf.global_variables instead. \r\nE  Traceback (most recent call last):\r\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\r\n    \"__main__\", fname, loader, pkg_name)\r\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n    exec code in run_globals\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/train.py\", line 198, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 44, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/train.py\", line 194, in main\r\n    worker_job_name, is_chief, FLAGS.train_dir)\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/trainer.py\", line 218, in train\r\n    var_map, train_config.fine_tune_checkpoint))\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/utils/variables_helper.py\", line 122, in get_variables_available_in_checkpoint\r\n    ckpt_reader = tf.train.NewCheckpointReader(checkpoint_path)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 110, in NewCheckpointReader\r\n    return CheckpointReader(compat.as_bytes(filepattern), status)\r\n  File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__\r\n    self.gen.next()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\nInvalidArgumentError: Unsuccessful TensorSliceReader constructor: Failed to get matching files on ./sofasmodel/model.ckpt: Not found: ./sofasmodel\r\n \r\nI  Summary name Learning Rate is illegal; using Learning_Rate instead. \r\nW  From /root/.local/lib/python2.7/site-packages/object_detection/meta_architectures/ssd_meta_arch.py:607: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\r\nInstructions for updating:\r\nPlease use tf.global_variables instead. \r\nE  Traceback (most recent call last):\r\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\r\n    \"__main__\", fname, loader, pkg_name)\r\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n    exec code in run_globals\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/train.py\", line 198, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 44, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/train.py\", line 194, in main\r\n    worker_job_name, is_chief, FLAGS.train_dir)\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/trainer.py\", line 218, in train\r\n    var_map, train_config.fine_tune_checkpoint))\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/utils/variables_helper.py\", line 122, in get_variables_available_in_checkpoint\r\n    ckpt_reader = tf.train.NewCheckpointReader(checkpoint_path)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 110, in NewCheckpointReader\r\n    return CheckpointReader(compat.as_bytes(filepattern), status)\r\n  File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__\r\n    self.gen.next()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\nInvalidArgumentError: Unsuccessful TensorSliceReader constructor: Failed to get matching files on ./sofasmodel/model.ckpt: Not found: ./sofasmodel\r\n \r\nE  Command '['python', '-m', u'object_detection.train', u'--train_dir=gs://detectme/training', u'--pipeline_config_path=gs://detectme/ssd_mobilenet_v1_pets.config', '--job-dir', u'gs://detectme/training/']' returned non-zero exit status 1 \r\nI  Module completed; cleaning up. \r\nI  Clean up finished. \r\nE  Command '['python', '-m', u'object_detection.train', u'--train_dir=gs://detectme/training', u'--pipeline_config_path=gs://detectme/ssd_mobilenet_v1_pets.config', '--job-dir', u'gs://detectme/training/']' returned non-zero exit status 1 \r\nI  Module completed; cleaning up. \r\nI  Clean up finished. \r\nE  Command '['python', '-m', u'object_detection.train', u'--train_dir=gs://detectme/training', u'--pipeline_config_path=gs://detectme/ssd_mobilenet_v1_pets.config', '--job-dir', u'gs://detectme/training/']' returned non-zero exit status 1 \r\nI  Module completed; cleaning up. \r\nI  Clean up finished. \r\nE  Command '['python', '-m', u'object_detection.train', u'--train_dir=gs://detectme/training', u'--pipeline_config_path=gs://detectme/ssd_mobilenet_v1_pets.config', '--job-dir', u'gs://detectme/training/']' returned non-zero exit status 1 \r\nI  Module completed; cleaning up. \r\nI  Clean up finished. \r\nE  The replica master 0 exited with a non-zero status of 1. Termination reason: Error. \r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\r\n    \"__main__\", fname, loader, pkg_name)\r\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n    exec code in run_globals\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/train.py\", line 198, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 44, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/train.py\", line 194, in main\r\n    worker_job_name, is_chief, FLAGS.train_dir)\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/trainer.py\", line 218, in train\r\n    var_map, train_config.fine_tune_checkpoint))\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/utils/variables_helper.py\", line 122, in get_variables_available_in_checkpoint\r\n    ckpt_reader = tf.train.NewCheckpointReader(checkpoint_path)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 110, in NewCheckpointReader\r\n    return CheckpointReader(compat.as_bytes(filepattern), status)\r\n  File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__\r\n    self.gen.next()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\nInvalidArgumentError: Unsuccessful TensorSliceReader constructor: Failed to get matching files on ./sofasmodel/model.ckpt: Not found: ./sofasmodel\r\n\r\nThe replica worker 0 exited with a non-zero status of 1. Termination reason: Error. \r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\r\n    \"__main__\", fname, loader, pkg_name)\r\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n    exec code in run_globals\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/train.py\", line 198, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 44, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/train.py\", line 194, in main\r\n    worker_job_name, is_chief, FLAGS.train_dir)\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/trainer.py\", line 218, in train\r\n    var_map, train_config.fine_tune_checkpoint))\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/utils/variables_helper.py\", line 122, in get_variables_available_in_checkpoint\r\n    ckpt_reader = tf.train.NewCheckpointReader(checkpoint_path)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 110, in NewCheckpointReader\r\n    return CheckpointReader(compat.as_bytes(filepattern), status)\r\n  File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__\r\n    self.gen.next()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\nInvalidArgumentError: Unsuccessful TensorSliceReader constructor: Failed to get matching files on ./sofasmodel/model.ckpt: Not found: ./sofasmodel\r\n\r\nThe replica worker 1 exited with a non-zero status of 1. Termination reason: Error. \r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\r\n    \"__main__\", fname, loader, pkg_name)\r\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n    exec code in run_globals\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/train.py\", line 198, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 44, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/train.py\", line 194, in main\r\n    worker_job_name, is_chief, FLAGS.train_dir)\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/trainer.py\", line 218, in train\r\n    var_map, train_config.fine_tune_checkpoint))\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/utils/variables_helper.py\", line 122, in get_variables_available_in_checkpoint\r\n    ckpt_reader = tf.train.NewCheckpointReader(checkpoint_path)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 110, in NewCheckpointReader\r\n    return CheckpointReader(compat.as_bytes(filepattern), status)\r\n  File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__\r\n    self.gen.next()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\nInvalidArgumentError: Unsuccessful TensorSliceReader constructor: Failed to get matching files on ./sofasmodel/model.ckpt: Not found: ./sofasmodel\r\n\r\nThe replica worker 2 exited with a non-zero status of 1. Termination reason: Error. \r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\r\n    \"__main__\", fname, loader, pkg_name)\r\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n    exec code in run_globals\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/train.py\", line 198, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 44, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/train.py\", line 194, in main\r\n    worker_job_name, is_chief, FLAGS.train_dir)\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/trainer.py\", line 218, in train\r\n    var_map, train_config.fine_tune_checkpoint))\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/utils/variables_helper.py\", line 122, in get_variables_available_in_checkpoint\r\n    ckpt_reader = tf.train.NewCheckpointReader(checkpoint_path)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 110, in NewCheckpointReader\r\n    return CheckpointReader(compat.as_bytes(filepattern), status)\r\n  File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__\r\n    self.gen.next()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\nInvalidArgumentError: Unsuccessful TensorSliceReader constructor: Failed to get matching files on ./sofasmodel/model.ckpt: Not found: ./sofasmodel\r\n\r\nThe replica worker 3 exited with a non-zero status of 1. Termination reason: Error. \r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\r\n    \"__main__\", fname, loader, pkg_name)\r\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n    exec code in run_globals\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/train.py\", line 198, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 44, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/train.py\", line 194, in main\r\n    worker_job_name, is_chief, FLAGS.train_dir)\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/trainer.py\", line 218, in train\r\n    var_map, train_config.fine_tune_checkpoint))\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/utils/variables_helper.py\", line 122, in get_variables_available_in_checkpoint\r\n    ckpt_reader = tf.train.NewCheckpointReader(checkpoint_path)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 110, in NewCheckpointReader\r\n    return CheckpointReader(compat.as_bytes(filepattern), status)\r\n  File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__\r\n    self.gen.next()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\nInvalidArgumentError: Unsuccessful TensorSliceReader constructor: Failed to get matching files on ./sofasmodel/model.ckpt: Not found: ./sofasmodel\r\n\r\nThe replica worker 4 exited with a non-zero status of 1. Termination reason: Error. \r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/runpy.py\", line 162, in _run_module_as_main\r\n    \"__main__\", fname, loader, pkg_name)\r\n  File \"/usr/lib/python2.7/runpy.py\", line 72, in _run_code\r\n    exec code in run_globals\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/train.py\", line 198, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.py\", line 44, in run\r\n    _sys.exit(main(_sys.argv[:1] + flags_passthrough))\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/train.py\", line 194, in main\r\n    worker_job_name, is_chief, FLAGS.train_dir)\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/trainer.py\", line 218, in train\r\n    var_map, train_config.fine_tune_checkpoint))\r\n  File \"/root/.local/lib/python2.7/site-packages/object_detection/utils/variables_helper.py\", line 122, in get_variables_available_in_checkpoint\r\n    ckpt_reader = tf.train.NewCheckpointReader(checkpoint_path)\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/pywrap_tensorflow.py\", line 110, in NewCheckpointReader\r\n    return CheckpointReader(compat.as_bytes(filepattern), status)\r\n  File \"/usr/lib/python2.7/contextlib.py\", line 24, in __exit__\r\n    self.gen.next()\r\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/errors_impl.py\", line 466, in raise_exception_on_not_ok_status\r\n    pywrap_tensorflow.TF_GetCode(status))\r\nInvalidArgumentError: Unsuccessful TensorSliceReader constructor: Failed to get matching files on ./sofasmodel/model.ckpt: Not found: ./sofasmodel\r\n\r\nTo find out more about why your job exited please check the logs: {Log file link}\r\nI  Signal 15 (SIGTERM) was caught. Terminated by service. This is normal behavior. \r\nI  Module completed; cleaning up. \r\nI  Clean up finished. \r\nI  Signal 15 (SIGTERM) was caught. Terminated by service. This is normal behavior. \r\nI  Module completed; cleaning up. \r\nI  Clean up finished. \r\nI  Signal 15 (SIGTERM) was caught. Terminated by service. This is normal behavior. \r\nI  Module completed; cleaning up. \r\nI  Clean up finished. \r\nI  Finished tearing down TensorFlow. \r\nI  Job failed. ```\r\n\r\nI know I'm making a simple mistake but not sure where. Any help will be appreciated. \r\nThanks \r\n", "Update: Instead of `sofamodels/model.ckpt` or `./sofamodels/model.ckpt` we have to mention the entire path `gs://bucketname/sofamodels/model.ckpt`. ", "yeah, this solution did solve this issue, thanks all of you guys", "python C:\\Users\\RAGHU\\Desktop\\workspace\\MachineLearning\\tensorflow\\tensorflow\\examples\\speech_commands\\freeze.py\r\nC:\\Users\\RAGHU\\AppData\\Local\\conda\\conda\\envs\\py35\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\n2018-06-07 14:50:54.318401: I T:\\src\\github\\tensorflow\\tensorflow\\core\\platform\\cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\n2018-06-07 14:50:54.959379: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1356] Found device 0 with properties:\r\nname: GeForce 940M major: 5 minor: 0 memoryClockRate(GHz): 1.176\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 2.00GiB freeMemory: 1.66GiB\r\n2018-06-07 14:50:54.965560: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1435] Adding visible gpu devices: 0\r\n2018-06-07 14:50:55.870157: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:923] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-06-07 14:50:55.874989: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:929]      0\r\n2018-06-07 14:50:55.877881: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:942] 0:   N\r\n2018-06-07 14:50:55.888312: I T:\\src\\github\\tensorflow\\tensorflow\\core\\common_runtime\\gpu\\gpu_device.cc:1053] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1428 MB memory) -> physical GPU (device: 0, name: GeForce 940M, pci bus id: 0000:01:00.0, compute capability: 5.0)\r\n2018-06-07 14:50:55.982578: W T:\\src\\github\\tensorflow\\tensorflow\\core\\framework\\op_kernel.cc:1318] OP_REQUIRES failed at save_restore_tensor.cc:170 : Not found: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\RAGHU\\AppData\\Local\\conda\\conda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1322, in _do_call\r\n    return fn(*args)\r\n  File \"C:\\Users\\RAGHU\\AppData\\Local\\conda\\conda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1307, in _run_fn\r\n    options, feed_dict, fetch_list, target_list, run_metadata)\r\n  File \"C:\\Users\\RAGHU\\AppData\\Local\\conda\\conda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1409, in _call_tf_sessionrun\r\n    run_metadata)\r\ntensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for\r\n         [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\r\n         [[Node: save/RestoreV2/_9 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_14_save/RestoreV2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\RAGHU\\Desktop\\workspace\\MachineLearning\\tensorflow\\tensorflow\\examples\\speech_commands\\freeze.py\", line 180, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"C:\\Users\\RAGHU\\AppData\\Local\\conda\\conda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 126, in run\r\n    _sys.exit(main(argv))\r\n  File \"C:\\Users\\RAGHU\\Desktop\\workspace\\MachineLearning\\tensorflow\\tensorflow\\examples\\speech_commands\\freeze.py\", line 117, in main\r\n    models.load_variables_from_checkpoint(sess, FLAGS.start_checkpoint)\r\n  File \"C:\\Users\\RAGHU\\Desktop\\workspace\\MachineLearning\\tensorflow\\tensorflow\\examples\\speech_commands\\models.py\", line 123, in load_variables_from_checkpoint\r\n    saver.restore(sess, start_checkpoint)\r\n  File \"C:\\Users\\RAGHU\\AppData\\Local\\conda\\conda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1802, in restore\r\n    {self.saver_def.filename_tensor_name: save_path})\r\n  File \"C:\\Users\\RAGHU\\AppData\\Local\\conda\\conda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 900, in run\r\n    run_metadata_ptr)\r\n  File \"C:\\Users\\RAGHU\\AppData\\Local\\conda\\conda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1135, in _run\r\n    feed_dict_tensor, options, run_metadata)\r\n  File \"C:\\Users\\RAGHU\\AppData\\Local\\conda\\conda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1316, in _do_run\r\n    run_metadata)\r\n  File \"C:\\Users\\RAGHU\\AppData\\Local\\conda\\conda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1335, in _do_call\r\n    raise type(e)(node_def, op, message)\r\ntensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for\r\n         [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\r\n         [[Node: save/RestoreV2/_9 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_14_save/RestoreV2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n\r\nCaused by op 'save/RestoreV2', defined at:\r\n  File \"C:\\Users\\RAGHU\\Desktop\\workspace\\MachineLearning\\tensorflow\\tensorflow\\examples\\speech_commands\\freeze.py\", line 180, in <module>\r\n    tf.app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"C:\\Users\\RAGHU\\AppData\\Local\\conda\\conda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\platform\\app.py\", line 126, in run\r\n    _sys.exit(main(argv))\r\n  File \"C:\\Users\\RAGHU\\Desktop\\workspace\\MachineLearning\\tensorflow\\tensorflow\\examples\\speech_commands\\freeze.py\", line 117, in main\r\n    models.load_variables_from_checkpoint(sess, FLAGS.start_checkpoint)\r\n  File \"C:\\Users\\RAGHU\\Desktop\\workspace\\MachineLearning\\tensorflow\\tensorflow\\examples\\speech_commands\\models.py\", line 122, in load_variables_from_checkpoint\r\n    saver = tf.train.Saver(tf.global_variables())\r\n  File \"C:\\Users\\RAGHU\\AppData\\Local\\conda\\conda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1338, in __init__\r\n    self.build()\r\n  File \"C:\\Users\\RAGHU\\AppData\\Local\\conda\\conda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1347, in build\r\n    self._build(self._filename, build_save=True, build_restore=True)\r\n  File \"C:\\Users\\RAGHU\\AppData\\Local\\conda\\conda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 1384, in _build\r\n    build_save=build_save, build_restore=build_restore)\r\n  File \"C:\\Users\\RAGHU\\AppData\\Local\\conda\\conda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 835, in _build_internal\r\n    restore_sequentially, reshape)\r\n  File \"C:\\Users\\RAGHU\\AppData\\Local\\conda\\conda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 472, in _AddRestoreOps\r\n    restore_sequentially)\r\n  File \"C:\\Users\\RAGHU\\AppData\\Local\\conda\\conda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\training\\saver.py\", line 886, in bulk_restore\r\n    return io_ops.restore_v2(filename_tensor, names, slices, dtypes)\r\n  File \"C:\\Users\\RAGHU\\AppData\\Local\\conda\\conda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\ops\\gen_io_ops.py\", line 1546, in restore_v2\r\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\r\n  File \"C:\\Users\\RAGHU\\AppData\\Local\\conda\\conda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"C:\\Users\\RAGHU\\AppData\\Local\\conda\\conda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\r\n    op_def=op_def)\r\n  File \"C:\\Users\\RAGHU\\AppData\\Local\\conda\\conda\\envs\\py35\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nNotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for\r\n         [[Node: save/RestoreV2 = RestoreV2[dtypes=[DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT, DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2/tensor_names, save/RestoreV2/shape_and_slices)]]\r\n         [[Node: save/RestoreV2/_9 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_14_save/RestoreV2\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\r\n\r\n\r\n\r\nCan someone tell what is the error here", "@Raghu-kapur your error-message reads: `NotFoundError (see above for traceback): Unsuccessful TensorSliceReader constructor: Failed to find any matching files for` ... then nothing.\r\n\r\nThis sounds like there is a missing parameter.\r\n\r\nDid you provide the option `--trained_checkpoint_prefix ` with the prefix als value for your model for the `export_inference_graph.py` script?\r\n\r\n@redbullpeter it looks like providing a full path to the model also works for the `--trained_checkpoint_prefix ` option: `--trained_checkpoint_prefix /home/mySkel/myPathToTheModel/model.ckpt-101`", "i don't know why but sometimes we have to provide absolute path for the model ckpt", "Restoring a checkpoint failed for me when the path of the checkpoint contained symbols like `[` or `,`.\r\nRemoving these characters solved the error.", "@gcucurull that is not an issue of tensorflow/object-detection, but the standard behaviour of certain operating systems. Brackets, comma, spaces etc. should be escaped if provided to any program (at least in the context of linux or MacOS).", "I copied the model i used an point to older directory in python path.. Maybe you done same thing", "I also encountered this problem, solved with an absolute address, the relative address tensorflow is not recognized.", "can anyone solve my problem:please do reply:\r\ndoe@doe:~/anaconda3/envs/tensorflow/models/research/object_detection$ python3 train.py --logtostderr --train_dir=training/ --pipeline_config_path=training/ssd_mobilenet_v1_coco.config\r\nWARNING:tensorflow:From /home/doe/anaconda3/lib/python3.6/site-packages/tensorflow/python/platform/app.py:124: main (from __main__) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse object_detection/model_main.py.\r\nWARNING:tensorflow:From /home/doe/anaconda3/envs/tensorflow/models/research/object_detection/legacy/trainer.py:262: create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease switch to tf.train.create_global_step\r\nWARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 184, in <module>\r\n    tf.app.run()\r\n  File \"/home/doe/anaconda3/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 124, in run\r\n    _sys.exit(main(argv))\r\n  File \"/home/doe/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 136, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"train.py\", line 181, in main\r\n    graph_hook_fn=graph_rewriter_fn)\r\n  File \"/home/doe/anaconda3/envs/tensorflow/models/research/object_detection/legacy/trainer.py\", line 393, in train\r\n    include_global_step=False))\r\n  File \"/home/doe/anaconda3/envs/tensorflow/models/research/object_detection/utils/variables_helper.py\", line 126, in get_variables_available_in_checkpoint\r\n    ckpt_reader = tf.train.NewCheckpointReader(checkpoint_path)\r\n  File \"/home/doe/anaconda3/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 223, in NewCheckpointReader\r\n    return CheckpointReader(compat.as_bytes(filepattern), status)\r\n  File \"/home/doe/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\", line 473, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.NotFoundError: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ssd_mobilenet_v1_coco_2017_11_17/model.ckpt\r\n", "Maybe a missing `./` in front of `ssd_mobilenet_v1_coco_2017_11_17/model.ckpt`. This issue was already answered here: https://stackoverflow.com/questions/42260167/unsuccessful-tensorslicereader-constructor-failed-to-find-any-matching-files-fo", "yes it is clear it not found this file, please check you tree folder, you have to download it , by default it does'nt not exist in object_detection folder", "i had solved by this way \r\n #fine_tune_checkpoint: \"/root/code/tensorflow/models/training/model.ckpt-#####\"\r\n  from_detection_checkpoint: false\r\nplease check your config\r\n", "I tried Traning in Google colab \r\npython train.py --train_dir=training/ --pipeline_config_path=ssd_mobilenet_v2_quantized_300x300_coco.config\r\nbut  I am getting following error\r\n\r\nWARNING:tensorflow:From train.py:56: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\r\n\r\nWARNING:tensorflow:From train.py:56: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\r\n\r\nWARNING:tensorflow:From train.py:185: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/absl/app.py:251: main (from __main__) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse object_detection/model_main.py.\r\nW1101 10:00:07.914612 140433468364672 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/absl/app.py:251: main (from __main__) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse object_detection/model_main.py.\r\nWARNING:tensorflow:From train.py:91: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\r\n\r\nW1101 10:00:07.914868 140433468364672 module_wrapper.py:139] From train.py:91: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\r\n\r\nWARNING:tensorflow:From train.py:96: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\r\n\r\nW1101 10:00:07.919008 140433468364672 module_wrapper.py:139] From train.py:96: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\r\n\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/legacy/trainer.py:265: create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease switch to tf.train.create_global_step\r\nW1101 10:00:07.932987 140433468364672 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/legacy/trainer.py:265: create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease switch to tf.train.create_global_step\r\nINFO:tensorflow:Reading unweighted datasets: ['train.record']\r\nI1101 10:00:07.952460 140433468364672 dataset_builder.py:148] Reading unweighted datasets: ['train.record']\r\nINFO:tensorflow:Reading record datasets for input file: ['train.record']\r\nI1101 10:00:07.953956 140433468364672 dataset_builder.py:77] Reading record datasets for input file: ['train.record']\r\nINFO:tensorflow:Number of filenames to read: 1\r\nI1101 10:00:07.954146 140433468364672 dataset_builder.py:78] Number of filenames to read: 1\r\nWARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\r\nW1101 10:00:07.954262 140433468364672 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:103: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\r\nW1101 10:00:07.962062 140433468364672 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:103: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:222: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.map()\r\nW1101 10:00:07.992240 140433468364672 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:222: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.data.Dataset.map()\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:48: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\r\nW1101 10:00:10.920446 140433468364672 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:48: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\n`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\r\nW1101 10:00:10.988368 140433468364672 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\n`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/core/box_list_ops.py:234: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.where in 2.0, which has the same broadcast rule as np.where\r\nW1101 10:00:11.013556 140433468364672 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/core/box_list_ops.py:234: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.where in 2.0, which has the same broadcast rule as np.where\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/core/batcher.py:101: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\r\nW1101 10:00:11.954241 140433468364672 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/core/batcher.py:101: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nQueue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:752: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nTo construct input pipelines, use the `tf.data` module.\r\nW1101 10:00:11.958855 140433468364672 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:752: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nTo construct input pipelines, use the `tf.data` module.\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:752: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nTo construct input pipelines, use the `tf.data` module.\r\nW1101 10:00:11.960053 140433468364672 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:752: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nTo construct input pipelines, use the `tf.data` module.\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim-1.1.0-py3.6.egg/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease use `layer.__call__` method instead.\r\nW1101 10:00:12.111274 140433468364672 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim-1.1.0-py3.6.egg/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease use `layer.__call__` method instead.\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI1101 10:00:16.065051 140433468364672 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI1101 10:00:16.101743 140433468364672 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI1101 10:00:16.137190 140433468364672 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI1101 10:00:16.173719 140433468364672 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI1101 10:00:16.211551 140433468364672 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\r\nINFO:tensorflow:depth of additional conv before box predictor: 0\r\nI1101 10:00:16.247035 140433468364672 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCall initializer instance with the dtype argument instead of passing it to the constructor\r\nW1101 10:00:18.863176 140433468364672 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nCall initializer instance with the dtype argument instead of passing it to the constructor\r\nWARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\r\nW1101 10:00:21.508541 140433468364672 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\r\nTraceback (most recent call last):\r\n  File \"train.py\", line 185, in <module>\r\n    tf.app.run()\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 300, in run\r\n    _run_main(main, args)\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 251, in _run_main\r\n    sys.exit(main(argv))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 324, in new_func\r\n    return func(*args, **kwargs)\r\n  File \"train.py\", line 181, in main\r\n    graph_hook_fn=graph_rewriter_fn)\r\n  File \"/usr/local/lib/python3.6/dist-packages/object_detection/legacy/trainer.py\", line 396, in train\r\n    include_global_step=False))\r\n  File \"/usr/local/lib/python3.6/dist-packages/object_detection/utils/variables_helper.py\", line 138, in get_variables_available_in_checkpoint\r\n    ckpt_reader = tf.train.NewCheckpointReader(checkpoint_path)\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\", line 873, in NewCheckpointReader\r\n    return CheckpointReader(compat.as_bytes(filepattern))\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\", line 885, in __init__\r\n    this = _pywrap_tensorflow_internal.new_CheckpointReader(filename)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Unsuccessful TensorSliceReader constructor: Failed to get matching files on /content/models-master/research/object_detection/ssd_inception_v2_coco_2018_01_28/model.ckpt: Not found: /content/models-master/research/object_detection/ssd_inception_v2_coco_2018_01_28; No such file or directory", "@Jayanth1812 did u find a way to solve this?\r\n\r\n> I tried Traning in Google colab\r\n> python train.py --train_dir=training/ --pipeline_config_path=ssd_mobilenet_v2_quantized_300x300_coco.config\r\n> but I am getting following error\r\n> \r\n> WARNING:tensorflow:From train.py:56: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\r\n> \r\n> WARNING:tensorflow:From train.py:56: The name tf.logging.INFO is deprecated. Please use tf.compat.v1.logging.INFO instead.\r\n> \r\n> WARNING:tensorflow:From train.py:185: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\r\n> \r\n> WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/absl/app.py:251: main (from **main**) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> Use object_detection/model_main.py.\r\n> W1101 10:00:07.914612 140433468364672 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/absl/app.py:251: main (from **main**) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> Use object_detection/model_main.py.\r\n> WARNING:tensorflow:From train.py:91: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\r\n> \r\n> W1101 10:00:07.914868 140433468364672 module_wrapper.py:139] From train.py:91: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\r\n> \r\n> WARNING:tensorflow:From train.py:96: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\r\n> \r\n> W1101 10:00:07.919008 140433468364672 module_wrapper.py:139] From train.py:96: The name tf.gfile.Copy is deprecated. Please use tf.io.gfile.copy instead.\r\n> \r\n> WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/legacy/trainer.py:265: create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> Please switch to tf.train.create_global_step\r\n> W1101 10:00:07.932987 140433468364672 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/legacy/trainer.py:265: create_global_step (from tf_slim.ops.variables) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> Please switch to tf.train.create_global_step\r\n> INFO:tensorflow:Reading unweighted datasets: ['train.record']\r\n> I1101 10:00:07.952460 140433468364672 dataset_builder.py:148] Reading unweighted datasets: ['train.record']\r\n> INFO:tensorflow:Reading record datasets for input file: ['train.record']\r\n> I1101 10:00:07.953956 140433468364672 dataset_builder.py:77] Reading record datasets for input file: ['train.record']\r\n> INFO:tensorflow:Number of filenames to read: 1\r\n> I1101 10:00:07.954146 140433468364672 dataset_builder.py:78] Number of filenames to read: 1\r\n> WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\r\n> W1101 10:00:07.954262 140433468364672 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\r\n> WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:103: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\r\n> W1101 10:00:07.962062 140433468364672 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:103: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\r\n> WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:222: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> Use `tf.data.Dataset.map() W1101 10:00:07.992240 140433468364672 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:222: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version. Instructions for updating: Use `tf.data.Dataset.map()\r\n> WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:48: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\r\n> W1101 10:00:10.920446 140433468364672 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:48: DatasetV1.make_initializable_iterator (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> Use `for ... in dataset:` to iterate over a dataset. If using `tf.estimator`, return the `Dataset` object directly from your input function. As a last resort, you can use `tf.compat.v1.data.make_initializable_iterator(dataset)`.\r\n> WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> `seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\r\n> W1101 10:00:10.988368 140433468364672 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/core/preprocessor.py:199: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> `seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\r\n> WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/core/box_list_ops.py:234: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> Use tf.where in 2.0, which has the same broadcast rule as np.where\r\n> W1101 10:00:11.013556 140433468364672 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/core/box_list_ops.py:234: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> Use tf.where in 2.0, which has the same broadcast rule as np.where\r\n> WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/core/batcher.py:101: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\r\n> W1101 10:00:11.954241 140433468364672 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/object_detection/core/batcher.py:101: batch (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.batch(batch_size)` (or `padded_batch(...)` if `dynamic_pad=True`).\r\n> WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:752: QueueRunner.**init** (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> To construct input pipelines, use the `tf.data` module.\r\n> W1101 10:00:11.958855 140433468364672 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:752: QueueRunner.**init** (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> To construct input pipelines, use the `tf.data` module.\r\n> WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:752: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> To construct input pipelines, use the `tf.data` module.\r\n> W1101 10:00:11.960053 140433468364672 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/input.py:752: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> To construct input pipelines, use the `tf.data` module.\r\n> WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tf_slim-1.1.0-py3.6.egg/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> Please use `layer.__call__` method instead.\r\n> W1101 10:00:12.111274 140433468364672 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tf_slim-1.1.0-py3.6.egg/tf_slim/layers/layers.py:2802: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> Please use `layer.__call__` method instead.\r\n> INFO:tensorflow:depth of additional conv before box predictor: 0\r\n> I1101 10:00:16.065051 140433468364672 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\r\n> INFO:tensorflow:depth of additional conv before box predictor: 0\r\n> I1101 10:00:16.101743 140433468364672 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\r\n> INFO:tensorflow:depth of additional conv before box predictor: 0\r\n> I1101 10:00:16.137190 140433468364672 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\r\n> INFO:tensorflow:depth of additional conv before box predictor: 0\r\n> I1101 10:00:16.173719 140433468364672 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\r\n> INFO:tensorflow:depth of additional conv before box predictor: 0\r\n> I1101 10:00:16.211551 140433468364672 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\r\n> INFO:tensorflow:depth of additional conv before box predictor: 0\r\n> I1101 10:00:16.247035 140433468364672 convolutional_box_predictor.py:156] depth of additional conv before box predictor: 0\r\n> WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.**init** (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> Call initializer instance with the dtype argument instead of passing it to the constructor\r\n> W1101 10:00:18.863176 140433468364672 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/rmsprop.py:119: calling Ones.**init** (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> Call initializer instance with the dtype argument instead of passing it to the constructor\r\n> WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\r\n> W1101 10:00:21.508541 140433468364672 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/moving_averages.py:433: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\r\n> Traceback (most recent call last):\r\n> File \"train.py\", line 185, in\r\n> tf.app.run()\r\n> File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/platform/app.py\", line 40, in run\r\n> _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\r\n> File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 300, in run\r\n> _run_main(main, args)\r\n> File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 251, in _run_main\r\n> sys.exit(main(argv))\r\n> File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 324, in new_func\r\n> return func(*args, **kwargs)\r\n> File \"train.py\", line 181, in main\r\n> graph_hook_fn=graph_rewriter_fn)\r\n> File \"/usr/local/lib/python3.6/dist-packages/object_detection/legacy/trainer.py\", line 396, in train\r\n> include_global_step=False))\r\n> File \"/usr/local/lib/python3.6/dist-packages/object_detection/utils/variables_helper.py\", line 138, in get_variables_available_in_checkpoint\r\n> ckpt_reader = tf.train.NewCheckpointReader(checkpoint_path)\r\n> File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\", line 873, in NewCheckpointReader\r\n> return CheckpointReader(compat.as_bytes(filepattern))\r\n> File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/pywrap_tensorflow_internal.py\", line 885, in **init**\r\n> this = _pywrap_tensorflow_internal.new_CheckpointReader(filename)\r\n> tensorflow.python.framework.errors_impl.InvalidArgumentError: Unsuccessful TensorSliceReader constructor: Failed to get matching files on /content/models-master/research/object_detection/ssd_inception_v2_coco_2018_01_28/model.ckpt: Not found: /content/models-master/research/object_detection/ssd_inception_v2_coco_2018_01_28; No such file or directory\r\n\r\ndid u find a way to solve this?", "If you still have this issue try checking the value of the path like follows:\r\n```python\r\nfrom tensorflow.python.util import compat\r\nprint(compat.as_bytes(model_path))\r\n```\r\nThe output should be, make sure that there's no other quotes in there:\r\n```diff\r\n+ b'./path/to/my/model.h5'\r\n- b'\"./path/to/my/model.h5\"'\r\n```"]}, {"number": 7546, "title": "Branch 147656243", "body": "", "comments": []}, {"number": 7545, "title": "Added atrous_conv1d and 3d. Refactored 2d.", "body": "This commit makes following changes:\r\n* deleted most atrous_conv2d code to reuse existing tf.nn.convolution function\r\n* added atrous_conv1d and atrous_conv3d with similar API as atrous_conv2d\r\n* Added support for variable rate per dimension, e.g. for atrous_conv2d\r\n  rate=2, or rate=[2,1] does different things. Former is equal to\r\n  rate=[2,2]. rate_i determines dilation_rate in dimension i.\r\n* added strides support with same API as in tf.nn.convolution function\r\n\r\nThis commit makes more code deletions then additions. However\r\ndocumentation per function makes it appear large.\r\n\r\nTest Plan:\r\n\r\nSome simple tests to verify I haven't screwed something up:\r\n\r\n```\r\nA = np.array([1, 2, 3, 4, 5, 6], dtype=np.float32).reshape(1, 6, 1)\r\nprint(A)\r\n\r\nkernel = np.array([100, 10, 1], dtype=np.float32).reshape(3, 1, 1)\r\n\r\nwith tf.Session() as sess:\r\n    print(sess.run(tf.nn.atrous_conv1d(A, kernel, padding='SAME', rate=[2])))\r\n```\r\n\r\n```\r\nB = np.arange(16, dtype=np.float32).reshape(1, 4, 4, 1)\r\nkernel = np.array([1000, 100, 10, 1.0], dtype=np.float32).reshape(2, 2, 1, 1)\r\n\r\nwith tf.Session() as sess:\r\n    a = sess.run(tf.nn.convolution(B, kernel, padding='SAME', dilation_rate=np.array([2, 2])))\r\n    b = sess.run(tf.nn.atrous_conv2d(B, kernel, rate=2, padding='SAME'))\r\n    print(np.allclose(a, b))\r\n    print(a)\r\n    print(b)\r\n```\r\n\r\n```\r\nC = np.arange(4**3, dtype=np.float32).reshape(1, 4, 4, 4, 1)\r\nkernel = (10**np.arange(8, 0, -1, dtype=np.float32)).reshape(2, 2, 2, 1, 1)\r\n\r\nwith tf.Session() as sess:\r\n    a = sess.run(tf.nn.conv3d(C, kernel, strides=[1, 1,1,1,1], padding='SAME'))\r\n    b = sess.run(tf.nn.atrous_conv3d(C, kernel, rate=1, padding='SAME'))\r\n    print(np.allclose(a, b))\r\n    print(a)\r\n    print(b)\r\n```\r\n\r\nAlso running atrous_conv2d unit tests to verify backward compatibility.", "comments": ["Can one of the admins verify this patch?", "@gpapan PTAL", "@jbms", "Removing the duplicate implementation of atrous convolution in the atrous_conv2d function is a desirable change.\r\n\r\nAs far as adding atrous_conv1d and atrous_conv3d, I don't see the advantage --- better to just use the convolution function directly.  atrous_conv2d existed prior to the unified tf.nn.convolution function, and is preserved for backwards compatibility.", "> As far as adding atrous_conv1d and atrous_conv3d, I don't see the advantage --- better to just use the convolution function directly. atrous_conv2d existed prior to the unified tf.nn.convolution function, and is preserved for backwards compatibility.\r\n\r\nFor both completeness and ease of use. When I was searching for atrous_conv1d I only found atrous_conv2d and assumed only that one is implemented (and I implemented one myself mimicking atrous_conv1d implementation before realizing there's general convolution which handles all cases). Having atrous_conv2d as standalone increase its salience and confuses users (me included).\r\n\r\n", "I think this would be better addressed by adding a note to the documentation of atrous_conv2d explaining that it is a legacy interface and that tf.nn.convolution can be used for atrous convolutions of any number of dimensions, rather than adding additional redundant functions.", "Some related discussion is going on in #4742, part of which I'll repost here bc it is pertinent.\r\n\r\n[conv2d_same](https://github.com/tensorflow/models/blob/master/slim/nets/resnet_utils.py#L77) in `tensorflow/models` provides both input tensor size and output tensor size:\r\n```\r\ndef conv2d_same(inputs, num_outputs, kernel_size, stride, rate=1, scope=None):\r\n  \"\"\"[snip...]\r\n  Args:\r\n    inputs: A 4-D tensor of size [batch, height_in, width_in, channels].\r\n  [snip...]\r\n  Returns:\r\n    output: A 4-D tensor of size [batch, height_out, width_out, channels] with\r\n      the convolution output.\r\n  \"\"\"\r\n```\r\n\r\nI think it would be very productive to add a note in each appropriate function explaining what the output dimensions would be relative to given input dimensions in as they vary by configuration. \r\n", ">  think this would be better addressed by adding a note to the documentation of atrous_conv2d explaining that it is a legacy interface and that tf.nn.convolution can be used for atrous convolutions of any number of dimensions, rather than adding additional redundant functions.\r\n\r\nWhat is the protocol for function deprecation? Is there some annotation, some specific string in documentation or what?\r\n\r\nIf I understand correctly, you'd like deleting atrous 1d and 3d, and editing 2d with documentation changes", "Yes, remove atrous 1d and 3d.\r\n\r\nThere is the @deprecated decorator in tensorflow/python/util/deprecation.py.  However, since there isn't yet a specific plan/date for removing the atrous_conv2d function, you shouldn't use that in this case.\r\n\r\nInstead, you could just add a note to the top of the atrous_conv2d, such as:\r\n\r\nThis function is a simpler wrapper around the more general @{tf.nn.convolution}, and exists only for backwards compatibility.  You can use @{tf.nn.convolution} to perform 1-D, 2-D, or 3-D atrous convolution.", "Jenkins, test this please.", "@jbms @gpapan good to go?", "@jbms @gpapan Ping?", "@nmiculinic there are test failures, can you address those?", "@jbms assuming tests pass, is this approved?  Thanks!", "Yes looks good once tests pass.", "@tensorflow-jenkins test this please", "I made the fix for the @nmiculinic, let me know if this looks good (hit approve).  Thanks!", "I'm going to assume the build timeout is unrelated since no tests were added.  Merigng."]}, {"number": 7544, "title": "Mistake in 'a custom model' tutorial code", "body": "The code in [this example](https://www.tensorflow.org/get_started/get_started#a_custom_model) doesn't work as is.\r\n\r\nI found changing line 20 from:\r\n```\r\nreturn tf.contrib.learn.estimators.model_fn.ModelFnOps(\r\n```\r\nto\r\n```\r\nreturn tf.contrib.learn.ModelFnOps(\r\n```\r\nmakes it work.\r\n\r\nThanks for the great code!", "comments": ["This is now fixed. Thanks for reporting it."]}, {"number": 7543, "title": "Error on building with non-system GCC: \"gcc: error trying to exec 'as': execvp: No such file or directory\"", "body": "# Description\r\nHi,\r\n\r\nI am trying to compile TensorFlow with non-default GCC. 5.4.0, and get follwing error:\r\n```\r\ngcc: error trying to exec 'as': execvp: No such file or directory\r\nERROR: /local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/external/nccl_archive/BUILD.bazel:33:1: output 'external/nccl_archive/_objs/nccl/external/nccl_archive/src/libwrap.cu.pic.o' was not created.\r\nERROR: /local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/external/nccl_archive/BUILD.bazel:33:1: not all outputs were created or valid.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n```\r\n# Environment\r\n```\r\n$ cat /etc/redhat-release \r\nCentOS Linux release 7.3.1611 (AltArch)\r\n\r\n$ uname -a\r\nLinux power004.cluster 3.10.0-514.6.1.el7.ppc64le #1 SMP Thu Jan 19 14:34:54 GMT 2017 ppc64le ppc64le ppc64le GNU/Linux\r\n\r\n$ ls -l /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64/libcud*\r\n-rw-r--r-- 1 root root 559800 Oct 29 10:22 /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64/libcudadevrt.a\r\nlrwxrwxrwx 1 root root     16 Feb 14 23:26 /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64/libcudart.so -> libcudart.so.8.0\r\nlrwxrwxrwx 1 root root     19 Feb 14 23:26 /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.54\r\n-rwxr-xr-x 1 root root 476024 Oct 29 10:22 /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64/libcudart.so.8.0.54\r\n-rw-r--r-- 1 root root 966166 Oct 29 10:22 /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64/libcudart_static.a\r\n\r\n$ git rev-parse HEAD\r\n16485a3fb5ffcbaa244e55c388e43279d2770982\r\n\r\n$ bazel version\r\nINFO: $TEST_TMPDIR defined: output root default is '/local/cvsupport'.\r\n................\r\nBuild label: 0.4.4- (@non-git)\r\nBuild target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Thu Feb 9 23:48:24 2017 (1486684104)\r\nBuild timestamp: 1486684104\r\nBuild timestamp as int: 1486684104\r\n```\r\n# Steps to reproduce\r\n```\r\n$ module display gcc/5.4.0\r\n-------------------------------------------------------------------\r\n/trinity/shared/modulefiles/cv-ppc64le/gcc/5.4.0:\r\n\r\nmodule-whatis    loads the gcc/5.4.0 environment \r\nprepend-path     PATH /trinity/shared/apps/cv-ppc64le/gcc/5.4.0/bin \r\nprepend-path     LD_LIBRARY_PATH /trinity/shared/apps/cv-ppc64le/gcc/5.4.0/lib \r\nprepend-path     LD_LIBRARY_PATH /trinity/shared/apps/cv-ppc64le/gcc/5.4.0/lib64 \r\nprepend-path     LIBRARY_PATH /trinity/shared/apps/cv-ppc64le/gcc/5.4.0/lib \r\nprepend-path     LIBRARY_PATH /trinity/shared/apps/cv-ppc64le/gcc/5.4.0/lib64 \r\nprepend-path     C_INCLUDE_PATH /trinity/shared/apps/cv-ppc64le/gcc/5.4.0/include \r\nprepend-path     INCLUDE /trinity/shared/apps/cv-ppc64le/gcc/5.4.0/include \r\nprepend-path     CPATH /trinity/shared/apps/cv-ppc64le/gcc/5.4.0/include \r\nprepend-path     MANPATH /trinity/shared/apps/cv-ppc64le/gcc/5.4.0/share/man \r\n\r\n$ cat ../build_vars.sh\r\nexport TEST_TMPDIR=/local/cvsupport\r\nexport PYTHON_BIN_PATH=/usr/bin/python3.4\r\nexport PYTHON_LIB_PATH=/usr/lib64/python3.4/site-packages\r\nexport TF_NEED_JEMALLOC=1\r\nexport TF_NEED_GCP=0\r\nexport TF_NEED_HDFS=0\r\nexport TF_NEED_OPENCL=0\r\nexport TF_NEED_CUDA=1\r\nexport TF_ENABLE_XLA=0\r\nexport CC_OPT_FLAGS=\"-march=native\"\r\nexport TF_CUDA_VERSION=8.0\r\nexport TF_CUDNN_VERSION=5.1.10\r\nexport TF_CUDA_COMPUTE_CAPABILITIES=6.0\r\nexport GCC_HOST_COMPILER_PATH=/trinity/shared/apps/cv-ppc64le/gcc/5.4.0/bin/gcc\r\nexport CUDA_TOOLKIT_PATH=/trinity/shared/apps/cv-ppc64le/nvidia/cuda/${TF_CUDA_VERSION}\r\nexport CUDNN_INSTALL_PATH=/trinity/shared/apps/cv-ppc64le/nvidia/cudnn/${TF_CUDA_VERSION}\r\n\r\n$ module load nvidia/cuda/8.0 nvidia/cudnn/8.0 gcc/5.4.0 bazel/0.4.4\r\n$ source ../build_vars.sh\r\n$ ./configure\r\n$ bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\n# Investigation\r\n`as` is installed on my system, but wasn't built by gcc-5.4, I am using system-default one:\r\n```\r\n$ rpm -qf /usr/bin/as\r\nbinutils-2.25.1-22.base.el7.ppc64le\r\n```\r\nDigging into stace output, It seems like builder is trying to find `as` using some incorrect assumptions, and failed:\r\n```\r\n134767 execve(\"external/local_config_cuda/crosstool/clang/bin/../../../cuda/bin/../open64/bin/as\", [\"as\", \"-I\", \".\", \"-I\", \"external/nccl_archive/src\", \"-I\", \"external/local_config_cuda/cross\"..., \"-a64\", \"-mppc64\", \"-many\", \"-mlittle\", \"-o\", \"bazel-out/local_linux-py3-opt/bi\"..., \"/tmp/cc7ZvHce.s\"], [/* 19 vars */] <unfinished ...>\r\n134767 <... execve resumed> )           = -1 ENOENT (No such file or directory)\r\n134767 execve(\"external/local_config_cuda/crosstool/clang/bin/../../../cuda/bin/../nvvm/bin/as\", [\"as\", \"-I\", \".\", \"-I\", \"external/nccl_archive/src\", \"-I\", \"external/local_config_cuda/cross\"..., \"-a64\", \"-mppc64\", \"-many\", \"-mlittle\", \"-o\", \"bazel-out/local_linux-py3-opt/bi\"..., \"/tmp/cc7ZvHce.s\"], [/* 19 vars */] <unfinished ...>\r\n134767 <... execve resumed> )           = -1 ENOENT (No such file or directory)\r\n134767 execve(\"external/local_config_cuda/crosstool/clang/bin/../../../cuda/bin/as\", [\"as\", \"-I\", \".\", \"-I\", \"external/nccl_archive/src\", \"-I\", \"external/local_config_cuda/cross\"..., \"-a64\", \"-mppc64\", \"-many\", \"-mlittle\", \"-o\", \"bazel-out/local_linux-py3-opt/bi\"..., \"/tmp/cc7ZvHce.s\"], [/* 19 vars */] <unfinished ...>\r\n134767 <... execve resumed> )           = -1 ENOENT (No such file or directory)\r\n134767 execve(\"/trinity/shared/apps/cv-ppc64le/gcc/5.4.0/bin/as\", [\"as\", \"-I\", \".\", \"-I\", \"external/nccl_archive/src\", \"-I\", \"external/local_config_cuda/cross\"..., \"-a64\", \"-mppc64\", \"-many\", \"-mlittle\", \"-o\", \"bazel-out/local_linux-py3-opt/bi\"..., \"/tmp/cc7ZvHce.s\"], [/* 19 vars */] <unfinished ...>\r\n134767 <... execve resumed> )           = -1 ENOENT (No such file or directory)\r\n```", "comments": ["Can you build with -s and post the relevant output from bazel?\r\n\r\n@damienmg, this is possibly the same bug I ran into yesterday while experimenting with my cuda-clang installation - PATH is not handed correctly to some link actions.", "Seems it's not really verbose, PATH and all those vars are looking good, but issues still here\r\n\r\n```\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=/trinity/shared/apps/cv-ppc64le/nvidia/cudnn/8.0/lib:/trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64:/trinity/shared/\r\napps/cv-ppc64le/gcc/5.4.0/lib64:/trinity/shared/apps/cv-ppc64le/gcc/5.4.0/lib \\\r\n    PATH=/trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/bin:/trinity/shared/apps/cv-ppc64le/gcc/5.4.0/bin:/trinity/shared/apps/cv-ppc64le/baze\r\nl/0.4.4/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/trinity/home/cvsupport/.local/bin:/trinity/home/cvsupport/\r\nbin \\\r\n  external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -fPIE -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 -DNDEBUG -ffunction-sections -fdata-sections -g0 '-std=c++11' -MD -MF bazel-out/host/bin/external/protobuf/_objs/protobuf_lite/external/protobuf/src/google/protobuf/arena.d '-frandom-seed=bazel-out/host/bin/external/protobuf/_objs/protobuf_lite/external/protobuf/src/google/protobuf/arena.o' -iquote external/protobuf -iquote bazel-out/host/genfiles/external/protobuf -iquote external/bazel_tools -iquote bazel-out/host/genfiles/external/bazel_tools -isystem external/protobuf/src -isystem bazel-out/host/genfiles/external/protobuf/src -isystem external/bazel_tools/tools/cpp/gcc3 -DHAVE_PTHREAD -Wall -Wwrite-strings -Woverloaded-virtual -Wno-sign-compare -Wno-unused-function -no-canonical-prefixes -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -fno-canonical-system-headers -c external/protobuf/src/google/protobuf/arena.cc -o bazel-out/host/bin/external/protobuf/_objs/protobuf_lite/external/protobuf/src/google/protobuf/arena.o)\r\n____From Compiling external/protobuf/python/google/protobuf/pyext/descriptor_pool.cc:\r\nexternal/protobuf/python/google/protobuf/pyext/descriptor_pool.cc: In function 'PyObject* google::protobuf::python::cdescriptor_pool::New(PyTypeObject*, PyObject*, PyObject*)':\r\nexternal/protobuf/python/google/protobuf/pyext/descriptor_pool.cc:138:46: warning: ISO C++ forbids converting a string constant to 'char*' [-Wwrite-strings]\r\n   static char* kwlist[] = {\"descriptor_db\", 0};\r\n                                              ^\r\n____From Compiling external/nccl_archive/src/libwrap.cu.cc:\r\nIn file included from external/local_config_cuda/cuda/include/host_config.h:173:0,\r\n                 from external/local_config_cuda/cuda/include/cuda_runtime.h:78,\r\n                 from <command-line>:0:\r\n/usr/include/features.h:330:4: warning: #warning _FORTIFY_SOURCE requires compiling with optimization (-O) [-Wcpp]\r\n #  warning _FORTIFY_SOURCE requires compiling with optimization (-O)\r\n    ^\r\nIn file included from external/local_config_cuda/cuda/include/host_config.h:173:0,\r\n                 from external/local_config_cuda/cuda/include/cuda_runtime.h:78,\r\n                 from <command-line>:0:\r\n/usr/include/features.h:330:4: warning: #warning _FORTIFY_SOURCE requires compiling with optimization (-O) [-Wcpp]\r\n #  warning _FORTIFY_SOURCE requires compiling with optimization (-O)\r\n    ^\r\ngcc: error trying to exec 'as': execvp: No such file or directory\r\n```\r\n\r\nAttaching full bazel.log just in case\r\n[bazel-log.zip](https://github.com/tensorflow/tensorflow/files/779795/bazel-log.zip)\r\n\r\n", "That looks like gcc is not getting the right PATH? Do you have something in your system that prevents subprocesses from inheriting environment variables? (apropos the other bug you posted)", "> That looks like gcc is not getting the right PATH? \r\n\r\nWhy? for it looks good. no?\r\n```\r\nLD_LIBRARY_PATH=/trinity/shared/apps/cv-ppc64le/nvidia/cudnn/8.0/lib:/trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64:/trinity/shared/\r\napps/cv-ppc64le/gcc/5.4.0/lib64:/trinity/shared/apps/cv-ppc64le/gcc/5.4.0/lib\r\nPATH=/trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/bin:/trinity/shared/apps/cv-ppc64le/gcc/5.4.0/bin:...::/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin\r\n```\r\n\r\nSo `as` in  `/usr/bin` should be accessible.", "@dchirikov - I agree that the paths shown looks good - the question is, why does gcc not search there.", "@r4nt  I am not sure it was `gcc` who called `as`", "From the error message:\r\ngcc: error trying to exec 'as': execvp: No such file or directory\r\n\r\nThat looks like it's coming from gcc - what am I missing?", "Yes, you are right, it's gcc. I checked with strace. Despite expected PATH is reported, it has truncated set of directories:\r\n```\r\n\r\nexecve(\"external/local_config_cuda/crosstool/clang/bin/../../../cuda/bin/../open64/bin/as\", [\"as\", \"-I\", \".\", \"-I\", \"external/nccl_archi\r\nve/src\", \"-I\", \"external/local_config_cuda/crosstool/clang/bin/../../../cuda/bin/..//include\", \"-a64\", \"-mppc64\", \"-many\", \"-mlittle\", \"-o\", \"b\r\nazel-out/local_linux-py3-opt/bin/external/nccl_archive/_objs/nccl/external/nccl_archive/src/libwrap.cu.pic.o\", \"/tmp/cclcHfUr.s\"], [\"_SPACE_= \"\r\n, \"_TARGET_SIZE_=64\", \"CUDAFE_FLAGS=\", \"_CUDART_=cudart\", \"LD_LIBRARY_PATH=external/local_config_cuda/crosstool/clang/bin/../../../cuda/bin/../\r\nlib:/trinity/shared/apps/cv-ppc64le/nvidia/cudnn/8.0/lib:/trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64:/trinity/shared/apps/cv-ppc64le/\r\ngcc/5.4.0/lib64:/trinity/shared/apps/cv-ppc64le/gcc/5.4.0/lib\", \"_TARGET_DIR_=\", \"TOP=external/local_config_cuda/crosstool/clang/bin/../../../c\r\nuda/bin/..\", \"PATH=external/local_config_cuda/crosstool/clang/bin/../../../cuda/bin/../open64/bin:external/local_config_cuda/crosstool/clang/bi\r\nn/../../../cuda/bin/../nvvm/bin:external/local_config_cuda/crosstool/clang/bin/../../../cuda/bin:/trinity/shared/apps/cv-ppc64le/gcc/5.4.0/bin\"\r\n, \"_=/trinity/shared/apps/cv-ppc64le/gcc/5.4.0/bin/gcc\", \"PWD=/local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/execroot/tenso\r\nrflow\", \"INCLUDES=\\\"-Iexternal/local_config_cuda/crosstool/clang/bin/../../../cuda/bin/..//include\\\"  \", \"SHLVL=2\", \"NVVMIR_LIBRARY_DIR=externa\r\nl/local_config_cuda/crosstool/clang/bin/../../../cuda/bin/../nvvm/libdevice\", \"PTXAS_FLAGS=\", \"LIBRARIES=  \\\"-Lexternal/local_config_cuda/cross\r\ntool/clang/bin/../../../cuda/bin/..//lib64/stubs\\\" \\\"-Lexternal/local_config_cuda/crosstool/clang/bin/../../../cuda/bin/..//lib64\\\"\", \"_THERE_=\r\nexternal/local_config_cuda/crosstool/clang/bin/../../../cuda/bin\", \"_HERE_=external/local_config_cuda/crosstool/clang/bin/../../../cuda/bin\", \"\r\nCOLLECT_GCC=/trinity/shared/apps/cv-ppc64le/gcc/5.4.0/bin/gcc\", \"COLLECT_GCC_OPTIONS='-std=c++11' '-c' '-isystem' 'external/local_config_cuda/c\r\nuda' '-isystem' 'bazel-out/local_linux-py3-opt/genfiles/external/local_config_cuda/cuda' '-isystem' 'external/local_config_cuda/cuda/include' '\r\n-isystem' 'bazel-out/local_linux-py3-opt/genfiles/external/local_config_cuda/cuda/include' '-isystem' 'external/bazel_tools/tools/cpp/gcc3' '-i\r\nquote' 'external/nccl_archive' '-iquote' 'bazel-out/local_linux-py3-opt/genfiles/external/nccl_archive' '-iquote' 'external/local_config_cuda' \r\n'-iquote' 'bazel-out/local_linux-py3-opt/genfiles/external/local_config_cuda' '-iquote' 'external/bazel_tools' '-iquote' 'bazel-out/local_linux\r\n-py3-opt/genfiles/external/bazel_tools' '-g0' '-fno-canonical-system-headers' '-fPIC' '-O2' '-I' '.' '-I' 'external/nccl_archive/src' '-I' 'ext\r\nernal/local_config_cuda/crosstool/clang/bin/../../../cuda/bin/..//include' '-fpreprocessed' '-o' 'bazel-out/local_linux-py3-opt/bin/external/nc\r\ncl_archive/_objs/nccl/external/nccl_archive/src/libwrap.cu.pic.o'\"]\r\n```\r\nSo search path is limited to \r\n```\r\nPATH=external/local_config_cuda/crosstool/clang/bin/../../../cuda/bin/../open64/bin:external/local_config_cuda/crosstool/clang/bi\r\nn/../../../cuda/bin/../nvvm/bin:external/local_config_cuda/crosstool/clang/bin/../../../cuda/bin:/trinity/shared/apps/cv-ppc64le/gcc/5.4.0/bin\"\r\n, \"_=/trinity/shared/apps/cv-ppc64le/gcc/5.4.0/bin/gcc\"\r\n```\r\nand no `/usr/sbin` there", "Found a clue, not sure it will help, though.\r\n```\r\n148818 <... clone resumed> child_stack=0, flags=CLONE_PARENT_SETTID|SIGCHLD, parent_tidptr=0x3fffffffe1c0) = 148920\r\n\r\n148920 execve(\"/bin/sh\", [\"sh\", \"-c\", \"PATH=/trinity/shared/apps/cv-ppc64le/gcc/5.4.0/bin external/local_config_cuda/crosstool/clang/bin/../../../cuda/bin/nvcc -D_FORCE_INLINES -gencode=arch=compute_60,\\\\\\\"code=sm_60,compute_60\\\\\\\"   -U_FORTIFY_SOURCE -D_FORTIFY_SOURCE=1 -DNDEBUG -DCUDA_MAJOR=0 -DCUDA_MINOR=0 -DNCCL_MAJOR=0 -DNCCL_MINOR=0 -DNCCL_PATCH=0 -DGOOGLE_CUDA=1 -std=c++11 --compiler-options \\\" -isystem external/local_config_cuda/cuda -isystem bazel-out/local_linux-py3-opt/genfiles/external/local_config_cuda/cuda -isystem external/local_config_cuda/cuda/include -isystem bazel-out/local_linux-py3-opt/genfiles/external/local_config_cuda/cuda/include -isystem external/bazel_tools/tools/cpp/gcc3 -iquote external/nccl_archive -iquote bazel-out/local_linux-py3-opt/genfiles/external/nccl_archive -iquote external/local_config_cuda -iquote bazel-out/local_linux-py3-opt/genfiles/external/local_config_cuda -iquote external/bazel_tools -iquote bazel-out/local_linux-py3-opt/genfiles/external/bazel_tools -g0 -fno-canonical-system-headers -fPIC\\\" --compiler-bindir=/trinity/shared/apps/cv-ppc64le/gcc/5.4.0/bin/gcc -I . -x cu  -O2 -I external/nccl_archive/src -c bazel-out/local_linux-py3-opt/genfiles/external/nccl_archive/src/reduce.cu.cc -o bazel-out/local_linux-py3-opt/bin/external/nccl_archive/_objs/nccl/external/nccl_archive/src/reduce.cu.pic.o\"], [\"PATH=/trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/bin:/trinity/shared/apps/cv-ppc64le/gcc/5.4.0/bin:/trinity/shared/apps/cv-ppc64le/bazel/0.4.4/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/trinity/home/cvsupport/.local/bin:/trinity/home/cvsupport/bin\", \"LD_LIBRARY_PATH=/trinity/shared/apps/cv-ppc64le/nvidia/cudnn/8.0/lib:/trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64:/trinity/shared/apps/cv-ppc64le/gcc/5.4.0/lib64:/trinity/shared/apps/cv-ppc64le/gcc/5.4.0/lib\"]\r\n```\r\nAnd seems like PATH was overridden there\r\n```\r\n148818 execve(\"external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc\", [\"external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc\", \"-U_FORTIFY_SOURCE\", \"-D_FORTIFY_SOURCE=1\", \"-fstack-protector\", \"-fPIE\", \"-Wall\", \"-Wunused-but-set-parameter\", \"-Wno-free-nonheap-object\", \"-fno-omit-frame-pointer\", \"-g0\", \"-O2\", \"-DNDEBUG\", \"-ffunction-sections\", \"-fdata-sections\", \"-std=c++11\", \"-MD\", \"-MF\", \"bazel-out/local_linux-py3-opt/bin/external/nccl_archive/_objs/nccl/external/nccl_archive/src/reduce.cu.pic.d\", \"-frandom-seed=bazel-out/local_linux-py3-opt/bin/external/nccl_archive/_objs/nccl/external/nccl_archive/src/reduce.cu.pic.o\", \"-fPIC\", \"-iquote\", \"external/nccl_archive\", \"-iquote\", \"bazel-out/local_linux-py3-opt/genfiles/external/nccl_archive\", \"-iquote\", \"external/local_config_cuda\", \"-iquote\", \"bazel-out/local_linux-py3-opt/genfiles/external/local_config_cuda\", \"-iquote\", \"external/bazel_tools\", \"-iquote\", \"bazel-out/local_linux-py3-opt/genfiles/external/bazel_tools\", \"-isystem\", \"external/local_config_cuda/cuda\", \"-isystem\", \"bazel-out/local_linux-py3-opt/genfiles/external/local_config_cuda/cuda\", \"-isystem\", \"external/local_config_cuda/cuda/include\", \"-isystem\", \"bazel-out/local_linux-py3-opt/genfiles/external/local_config_cuda/cuda/include\", \"-isystem\", \"external/bazel_tools/tools/cpp/gcc3\", \"-DCUDA_MAJOR=0\", \"-DCUDA_MINOR=0\", \"-DNCCL_MAJOR=0\", \"-DNCCL_MINOR=0\", \"-DNCCL_PATCH=0\", \"-Iexternal/nccl_archive/src\", \"-O3\", \"-x\", \"cuda\", \"-DGOOGLE_CUDA=1\", \"-no-canonical-prefixes\", \"-Wno-builtin-macro-redefined\", \"-D__DATE__=\\\"redacted\\\"\", \"-D__TIMESTAMP__=\\\"redacted\\\"\", \"-D__TIME__=\\\"redacted\\\"\", \"-fno-canonical-system-headers\", \"-c\", \"bazel-out/local_linux-py3-opt/genfiles/external/nccl_archive/src/reduce.cu.cc\", \"-o\", \"bazel-out/local_linux-py3-opt/bin/external/nccl_archive/_objs/nccl/external/nccl_archive/src/reduce.cu.pic.o\"], [\"PATH=/trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/bin:/trinity/shared/apps/cv-ppc64le/gcc/5.4.0/bin:/trinity/shared/apps/cv-ppc64le/bazel/0.4.4/bin:/usr/local/bin:/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/opt/ibutils/bin:/trinity/home/cvsupport/.local/bin:/trinity/home/cvsupport/bin\", \"LD_LIBRARY_PATH=/trinity/shared/apps/cv-ppc64le/nvidia/cudnn/8.0/lib:/trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64:/trinity/shared/apps/cv-ppc64le/gcc/5.4.0/lib64:/trinity/shared/apps/cv-ppc64le/gcc/5.4.0/lib\"] <unfinished ...>\r\n```\r\nSo `external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc` runs `/bin/sh -c \"PATH=/trinity/shared/apps/cv-ppc64le/gcc/5.4.0/bin external/local_config_cuda/crosstool/clang/bin/../../../cuda/bin/nvcc\"`", "Seems like [this is it](\r\nhttps://github.com/tensorflow/tensorflow/blob/r1.0/third_party/gpus/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc.tpl#L230).\r\n```\r\n  # TODO(zhengxq): for some reason, 'gcc' needs this help to find 'as'.\r\n  # Need to investigate and fix.\r\n  cmd = 'PATH=' + PREFIX_DIR + ' ' + cmd\r\n  if log: Log(cmd)\r\n  return os.system(cmd)\r\n```", "Yep, that looks like the problem then - I believe the wrapper script shouldn't completely cut the old path.", "If I comment that line out it will lead to another issue:\r\n```\r\nERROR: /trinity/home/cvsupport/dmitry/tf/tensorflow/tensorflow/core/BUILD:168:1: null failed: protoc failed: error executing command bazel-out/host/bin/external/protobuf/protoc '--python_out=bazel-out/local_linux-py3-opt/genfiles/' -I. -Iexternal/protobuf/python -Ibazel-out/local_linux-py3-opt/genfiles/external/protobuf/python ... (remaining 38 argument(s) skipped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\r\nbazel-out/host/bin/external/protobuf/protoc: /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.20' not found (required by bazel-out/host/bin/external/protobuf/protoc)\r\nbazel-out/host/bin/external/protobuf/protoc: /usr/lib64/libstdc++.so.6: version `CXXABI_1.3.8' not found (required by bazel-out/host/bin/external/protobuf/protoc)\r\nbazel-out/host/bin/external/protobuf/protoc: /usr/lib64/libstdc++.so.6: version `GLIBCXX_3.4.21' not found (required by bazel-out/host/bin/external/protobuf/protoc)\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n```\r\nI think LD_LIBRARY_PATH is being cut somewhere, too.", "Can you try building with:\r\nbazel <...> --action_env LD_LIBRARY_PATH=\"$LD_LIBRARY_PATH\"\r\n", "Got the same.", "You have to modify some config files. See this [web page](https://www.sharcnet.ca/help/index.php/Tensorflow#Building_Tensorflow_.28v0.10.29).", "I am experiencing the same error. Ubuntu 17.04, using custom compiled GCC 5.4.0 in the PATH and LD_LIBRARY_PATH, respectively.\r\n\r\nThis has been open for quite a few weeks already; did anyone get to look into this? As it currently stands, I cannot build TensorFlow from source.", "Did you see the link I posted?", "I did, but that's not a good solution, is it?\r\nIt should in no case be required to manually edit a whole bunch of stuff here and there. This should work out of the box. Seems like the TensorFlow build scripts could need some improvements, to respect a user's PATH and LD_LIBRARY_PATH settings.", "I agree.", "Just submitted a pretty simple fix. @dchirikov, can you please check whether this works for you as well?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "@kmhofmann the fix did not work for me. I get: \r\n\r\nERROR: /home/ubuntu/tensorflow/tensorflow/python/BUILD:1557:1: Linking of rule '//tensorflow/python:gen_boosted_trees_ops_py_wrappers_cc' failed (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command \r\n  (cd /home/ubuntu/.cache/bazel/_bazel_ubuntu/ad1e09741bb4109fbc70ef8216b59ee2/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    LD_LIBRARY_PATH=/usr/lib64/openmpi/lib/:/usr/local/cuda/lib64:/usr/local/lib:/usr/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/mpi/lib:/lib/:/home/ubuntu/src/cntk/bindings/python/cntk/libs:/usr/local/cuda/lib64:/usr/local/lib:/usr/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/mpi/lib:/usr/lib64/openmpi/lib/:/usr/local/cuda/lib64:/usr/local/lib:/usr/lib:/usr/local/cuda/extras/CUPTI/lib64:/usr/local/mpi/lib:/lib/: \\\r\n    PATH=/home/ubuntu/anaconda3/envs/tensorflow12_py27/bin:/home/ubuntu/anaconda3/bin/:/home/ubuntu/bin:/home/ubuntu/.local/bin:/home/ubuntu/anaconda3/bin/:/usr/local/cuda/bin:/usr/local/bin:/opt/aws/bin:/usr/local/mpi/bin:/usr/local/cuda/bin:/usr/local/bin:/opt/aws/bin:/home/ubuntu/src/cntk/bin:/usr/local/mpi/bin:/usr/local/cuda/bin:/usr/local/bin:/opt/aws/bin:/usr/local/mpi/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin \\\r\n   "]}, {"number": 7542, "title": "./configure in interactive mode does not create working config for build", "body": "# Description\r\nHi,\r\nI encounter following issue. If user runs ./configure script interactively filling blanks it is not possible to build TF with CUDA support. BUT if user exports corresponding env variables before of after ./configure, bazel can happily build binaries.\r\n\r\n# Environment\r\n```\r\n$ cat /etc/redhat-release \r\nCentOS Linux release 7.3.1611 (AltArch)\r\n\r\n$ uname -a\r\nLinux power004.cluster 3.10.0-514.6.1.el7.ppc64le #1 SMP Thu Jan 19 14:34:54 GMT 2017 ppc64le ppc64le ppc64le GNU/Linux\r\n\r\n$ ls -l /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64/libcud*\r\n-rw-r--r-- 1 root root 559800 Oct 29 10:22 /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64/libcudadevrt.a\r\nlrwxrwxrwx 1 root root     16 Feb 14 23:26 /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64/libcudart.so -> libcudart.so.8.0\r\nlrwxrwxrwx 1 root root     19 Feb 14 23:26 /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64/libcudart.so.8.0 -> libcudart.so.8.0.54\r\n-rwxr-xr-x 1 root root 476024 Oct 29 10:22 /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64/libcudart.so.8.0.54\r\n-rw-r--r-- 1 root root 966166 Oct 29 10:22 /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0/lib64/libcudart_static.a\r\n\r\n$ git rev-parse HEAD\r\n16485a3fb5ffcbaa244e55c388e43279d2770982\r\n\r\n$ bazel version\r\nINFO: $TEST_TMPDIR defined: output root default is '/local/cvsupport'.\r\n................\r\nBuild label: 0.4.4- (@non-git)\r\nBuild target: bazel-out/local-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Thu Feb 9 23:48:24 2017 (1486684104)\r\nBuild timestamp: 1486684104\r\nBuild timestamp as int: 1486684104\r\n```\r\n\r\n# Steps to reproduce\r\n```\r\n$ git clone https://github.com/tensorflow/tensorflow.git\r\n$ cd tensorflow\r\n$ git checkout r1.0\r\n$ export TEST_TMPDIR=/local/cvsupport\r\n$ ./configure\r\n```\r\nFill blanks\r\n```\r\nPlease specify the location of python. [Default is /bin/python]: /usr/bin/python3.4\r\nPlease specify optimization flags to use during compilation [Default is -march=native]: -march=native\r\nDo you wish to use jemalloc as the malloc implementation? (Linux only) [Y/n] \r\njemalloc enabled on Linux\r\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] \r\nNo Google Cloud Platform support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with Hadoop File System support? [y/N] \r\nNo Hadoop File System support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] \r\nNo XLA support will be enabled for TensorFlow\r\nFound possible Python library paths:\r\n  /usr/lib/python3.4/site-packages\r\n  /usr/lib64/python3.4/site-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/lib/python3.4/site-packages]\r\n/usr/lib64/python3.4/site-packages\r\nDo you wish to build TensorFlow with OpenCL support? [y/N] \r\nNo OpenCL support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with CUDA support? [y/N] y\r\nCUDA support will be enabled for TensorFlow\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /bin/gcc]: /usr/bin/gcc\r\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0\r\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0\r\nPlease specify the Cudnn version you want to use. [Leave empty to use system default]: 5.1.10\r\nPlease specify the location where cuDNN 5.1.10 library is installed. Refer to README.md for more details. [Default is /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0]: /trinity/shared/apps/cv-ppc64le/nvidia/cudnn/8.0\r\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size.\r\n[Default is: \"3.5,5.2\"]: 6.0\r\nINFO: $TEST_TMPDIR defined: output root default is '/local/cvsupport'.\r\n................\r\nINFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.\r\nINFO: $TEST_TMPDIR defined: output root default is '/local/cvsupport'.\r\n..............\r\nINFO: All external dependencies fetched successfully.\r\nConfiguration finished\r\n```\r\nAttempt to build:\r\n```\r\n$ bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n\r\nINFO: $TEST_TMPDIR defined: output root default is '/local/cvsupport'.\r\n................\r\nWARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.build/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.\r\nERROR: /local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/external/local_config_cuda/crosstool/BUILD:4:1: Traceback (most recent call last):\r\n        File \"/local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/external/local_config_cuda/crosstool/BUILD\", line 4\r\n                error_gpu_disabled()\r\n        File \"/local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/external/local_config_cuda/crosstool/error_gpu_disabled.bzl\", line 3, in error_gpu_disabled\r\n                fail(\"ERROR: Building with --config=c...\")\r\nERROR: Building with --config=cuda but TensorFlow is not configured to build with GPU support. Please re-run ./configure and enter 'Y' at the prompt to build with GPU support.\r\nERROR: no such target '@local_config_cuda//crosstool:toolchain': target 'toolchain' not declared in package 'crosstool' defined by /local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/external/local_config_cuda/crosstool/BUILD.\r\nINFO: Elapsed time: 1.572s\r\n```\r\n\r\n# Working method\r\n```\r\n$ cat ../build_vars.sh \r\nexport TEST_TMPDIR=/local/cvsupport\r\nexport PYTHON_BIN_PATH=/usr/bin/python3.4\r\nexport PYTHON_LIB_PATH=/usr/lib64/python3.4/site-packages\r\nexport TF_NEED_JEMALLOC=1\r\nexport TF_NEED_GCP=0\r\nexport TF_NEED_HDFS=0\r\nexport TF_NEED_OPENCL=0\r\nexport TF_NEED_CUDA=1\r\nexport TF_ENABLE_XLA=0\r\nexport CC_OPT_FLAGS=\"-march=native\"\r\nexport TF_CUDA_VERSION=8.0\r\nexport TF_CUDNN_VERSION=5.1.10\r\nexport TF_CUDA_COMPUTE_CAPABILITIES=6.0\r\nexport GCC_HOST_COMPILER_PATH=/usr/bin/gcc\r\nexport CUDA_TOOLKIT_PATH=/trinity/shared/apps/cv-ppc64le/nvidia/cuda/${TF_CUDA_VERSION}\r\nexport CUDNN_INSTALL_PATH=/trinity/shared/apps/cv-ppc64le/nvidia/cudnn/${TF_CUDA_VERSION}\r\n\r\n$ source ../build_vars.sh\r\n$ ./configure\r\n$ bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n\r\nExperimenting with omitting different variables seems like only following vars are sufficient.\r\n`TF_NEED_CUDA`, `TF_CUDA_VERSION`, `CUDA_TOOLKIT_PATH`, `CUDNN_INSTALL_PATH`, `GCC_HOST_COMPILER_PATH`", "comments": ["@gunan, @yifeif, do we have a solution to this?", "All these work for me if I use centos nvidia-docker image, without entering anything manually.\r\nIt is possible we have a problem in the script to read the command line inputs?", "@gunan - if anything it looks like TF_NEED_CUDA wasn't set correctly, which would be weird.\r\n\r\n@dchirikov - can you put\r\necho $TF_NEED_CUDA\r\nbefore the call to bazel_clean_and_fetch and post the output?\r\n\r\n(for @damienmg, an example user experience problem bazel's configuration needs to solve better)", "@gunan\r\n> without entering anything manually.\r\n\r\nThat's the issue, actually. If you need to enter it manually interactively in ./configure - it will fail. Something in this command relies on defined environment variables:\r\n```\r\nbazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n```\r\n@r4nt \r\n> can you put\r\necho $TF_NEED_CUDA\r\n\r\nit echoes '1', which is good\r\nbut again, those vars are not inherited in `bazel build`", "@dchirikov - the configure script has a line saying \"export TF_NEED_CUDA\" - I'm really confused why that wouldn't end up in your blaze fetch.\r\nThe reliance of the blaze fetch on environment variables is by design.", "@r4nt \r\n>  that wouldn't end up in your blaze fetch.\r\n\r\nit is accessible and defined in fetch, but not defined in `bazel build` step.", "@dchirikov - that doesn't matter though - the way bazel works is that the whole bazel-tensorflow/external/ stuff gets configured as part of the fetch step; the environment variables affect what ends up there, but are not needed afterwards when you do bazel build.", "@r4nt \r\nIf i get it right `./third_party/gpus/cuda_configure.bzl` is being executed during `basel build`, and yes, it expects some vars is user environment is being defined:\r\n```\r\ndef _enable_cuda(repository_ctx):\r\n  if \"TF_NEED_CUDA\" in repository_ctx.os.environ:\r\n    enable_cuda = repository_ctx.os.environ[\"TF_NEED_CUDA\"].strip()\r\n    return enable_cuda == \"1\"\r\n  return False\r\n```\r\n", "@dchirikov - it shouldn't (it doesn't for me, and I checked with a bazel dev that there should not be a case where it does). What makes you think it does?", "@r4nt\r\nif i add print statement to cuda_configure.bzl it will be printed during build:\r\n```\r\ndef _enable_cuda(repository_ctx):\r\n  print(\"========================= test ==========================\")\r\n  if \"TF_NEED_CUDA\" in repository_ctx.os.environ:\r\n    enable_cuda = repository_ctx.os.environ[\"TF_NEED_CUDA\"].strip()\r\n    return enable_cuda == \"1\"\r\n  return False\r\n```\r\n```\r\n$ bazel build -s -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package \r\nINFO: $TEST_TMPDIR defined: output root default is '/local/cvsupport'.\r\n....................\r\nWARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.build/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.\r\nWARNING: /trinity/home/cvsupport/dmitry/tf/tensorflow/third_party/gpus/cuda_configure.bzl:116:3: ========================= test ==========================.\r\nERROR: /local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/external/local_config_cuda/crosstool/BUILD:4:1: Traceback (most recent call last):\r\n        File \"/local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/external/local_config_cuda/crosstool/BUILD\", line 4\r\n                error_gpu_disabled()\r\n        File \"/local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/external/local_config_cuda/crosstool/error_gpu_disabled.bzl\", line 3, in error_gpu_disabled\r\n                fail(\"ERROR: Building with --config=c...\")\r\nERROR: Building with --config=cuda but TensorFlow is not configured to build with GPU support. Please re-run ./configure and enter 'Y' at the prompt to build with GPU support.\r\nERROR: no such target '@local_config_cuda//crosstool:toolchain': target 'toolchain' not declared in package 'crosstool' defined by /local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/external/local_config_cuda/crosstool/BUILD.\r\nINFO: Elapsed time: 1.585s\r\n```\r\n", "@dchirikov - this should only happen on invalidation, which is a bazel bug fixed at head.\r\nIf you now run configure again, it should work afterwards, as long as you don't sync.", "```\r\n# su - cvsupport\r\n$ cd /trinity/home/cvsupport/dmitry/tf/tensorflow; module load bazel/0.4.4; export TEST_TMPDIR=/local/cvsupport\r\n$ bazel cleanup\r\n$ . ../build_vars.sh\r\n$ ./configure\r\nWARNING: /trinity/home/cvsupport/dmitry/tf/tensorflow/third_party/gpus/cuda_configure.bzl:116:3: ========================= test ==========================.\r\n\r\n$ logout\r\n# su - cvsupport\r\n$ cd /trinity/home/cvsupport/dmitry/tf/tensorflow; module load bazel/0.4.4; export TEST_TMPDIR=/local/cvsupport\r\n$ bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n\r\nWARNING: /trinity/home/cvsupport/dmitry/tf/tensorflow/third_party/gpus/cuda_configure.bzl:116:3: ========================= test ==========================.\r\nERROR: /local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/external/local_config_cuda/crosstool/BUILD:4:1: Traceback (most recent call last):\r\n        File \"/local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/external/local_config_cuda/crosstool/BUILD\", line 4\r\n                error_gpu_disabled()\r\n        File \"/local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/external/local_config_cuda/crosstool/error_gpu_disabled.bzl\", line 3, in error_gpu_disabled\r\n                fail(\"ERROR: Building with --config=c...\")\r\nERROR: Building with --config=cuda but TensorFlow is not configured to build with GPU support. Please re-run ./configure and enter 'Y' at the prompt to build with GPU support.\r\n```\r\n\r\nWhat am I missing?", "Can you do\r\n$ ls $(bazel info output_base)/external/local_config_cuda/crosstool\r\nafter ./configure?\r\nIf that already shows error_gpu_disabled, your first bazel fetch didn't work (and didn't configure cuda support)", "```\r\n$ ls  -l $(bazel info output_base)/external/local_config_cuda/crosstool\r\nINFO: $TEST_TMPDIR defined: output root default is '/local/cvsupport'.\r\ntotal 16\r\n-rwxrwxr-x 1 cvsupport cvsupport 1267 Feb 16 18:05 BUILD\r\ndrwxrwxr-x 3 cvsupport cvsupport   17 Feb 16 18:05 clang\r\n-rwxrwxr-x 1 cvsupport cvsupport 9196 Feb 16 18:05 CROSSTOOL\r\n```\r\nNot sure I get you point when it where it should start to complain.", "Ok, so between your ls (which looks correct) and your bazel builds something invalidates the repository configuration.\r\nYou can see that the file in your error message:\r\n\"external/local_config_cuda/crosstool/error_gpu_disabled.bzl\"\r\ndoes not even exist before.\r\n\r\nDoes your /local/cvsupport get deleted by your logout / su?\r\nSpecifically, can you run the same ls command you posted above right before you do your bazel build in the last step?", "Seems like something in `bazel build` invalidates the cache:\r\n```\r\n$ ls  -l $(bazel info output_base)/external/local_config_cuda/crosstool\r\nINFO: $TEST_TMPDIR defined: output root default is '/local/cvsupport'.\r\n................\r\ntotal 16\r\n-rwxrwxr-x 1 cvsupport cvsupport 1267 Feb 17 11:45 BUILD\r\ndrwxrwxr-x 3 cvsupport cvsupport   17 Feb 17 11:45 clang\r\n-rwxrwxr-x 1 cvsupport cvsupport 8928 Feb 17 11:45 CROSSTOOL\r\n\r\n$ bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\nERROR: /local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/external/local_config_cuda/crosstool/BUILD:4:1: Traceback (most recent call last):\r\n        File \"/local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/external/local_config_cuda/crosstool/BUILD\", line 4\r\n                error_gpu_disabled()\r\n        File \"/local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/external/local_config_cuda/crosstool/error_gpu_disabled.bzl\", line 3, in error_gpu_disabled\r\n                fail(\"ERROR: Building with --config=c...\")\r\nERROR: Building with --config=cuda but TensorFlow is not configured to build with GPU support. Please re-run ./configure and enter 'Y' at the prompt to build with GPU support.\r\nERROR: no such target '@local_config_cuda//crosstool:toolchain': target 'toolchain' not declared in package 'crosstool' defined by /local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/external/local_config_cuda/crosstool/BUILD.\r\nINFO: Elapsed time: 1.396s\r\n\r\n$ ls  -l $(bazel info output_base)/external/local_config_cuda/crosstool\r\nINFO: $TEST_TMPDIR defined: output root default is '/local/cvsupport'.\r\ntotal 8\r\n-rwxrwxr-x 1 cvsupport cvsupport  88 Feb 17 11:49 BUILD\r\n-rwxrwxr-x 1 cvsupport cvsupport 497 Feb 17 11:49 error_gpu_disabled.bzl\r\n```", "Just talked with @damienmg, and he told me that at your bazel version if you restart the bazel server, you invalidate the repository. If your logout / su commands kill the server, the next bazel build will re-fetch, which would lead to the exact problem you describe. That hopefully will be fixed with the next bazel release.", "Thank you for the clarification, but origin of the issue is slightly different. Logout came to the picture later.\r\nInitial issue was: run ./configure, fill values and run bazel build. Not sure where 'restart bazel server' is.", "Ok, but that requires the same debugging step :) Can you do the same set of steps without any logout in between?", ">  but that requires the same debugging step\r\n\r\nAgree. Just to make sure we are on the same page.\r\n\r\nDid as you requested:\r\n```\r\n$ ./configure \r\nPlease specify the location of python. [Default is /bin/python]: /usr/bin/python3.4\r\nPlease specify optimization flags to use during compilation [Default is -march=native]: -march=native\r\nDo you wish to use jemalloc as the malloc implementation? (Linux only) [Y/n] \r\njemalloc enabled on Linux\r\nDo you wish to build TensorFlow with Google Cloud Platform support? [y/N] \r\nNo Google Cloud Platform support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with Hadoop File System support? [y/N] \r\nNo Hadoop File System support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with the XLA just-in-time compiler (experimental)? [y/N] \r\nNo XLA support will be enabled for TensorFlow\r\nFound possible Python library paths:\r\n  /usr/lib64/python3.4/site-packages\r\n  /usr/lib/python3.4/site-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/lib64/python3.4/site-packages]\r\n/usr/lib64/python3.4/site-packages\r\nDo you wish to build TensorFlow with OpenCL support? [y/N] \r\nNo OpenCL support will be enabled for TensorFlow\r\nDo you wish to build TensorFlow with CUDA support? [y/N] y\r\nCUDA support will be enabled for TensorFlow\r\nPlease specify which gcc should be used by nvcc as the host compiler. [Default is /bin/gcc]: /usr/bin/gcc\r\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to use system default]: 8.0\r\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0\r\nPlease specify the Cudnn version you want to use. [Leave empty to use system default]: 5.1.10\r\nPlease specify the location where cuDNN 5.1.10 library is installed. Refer to README.md for more details. [Default is /trinity/shared/apps/cv-ppc64le/nvidia/cuda/8.0]: /trinity/shared/apps/cv-ppc64le/nvidia/cudnn/8.0\r\nPlease specify a list of comma-separated Cuda compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus.\r\nPlease note that each additional compute capability significantly increases your build time and binary size.\r\n[Default is: \"3.5,5.2\"]: 6.0\r\nINFO: $TEST_TMPDIR defined: output root default is '/local/cvsupport'.\r\n.................\r\nINFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.\r\nINFO: $TEST_TMPDIR defined: output root default is '/local/cvsupport'.\r\n............\r\nWARNING: /trinity/home/cvsupport/dmitry/tf/tensorflow/third_party/gpus/cuda_configure.bzl:116:3: ========================= test ==========================.\r\nINFO: All external dependencies fetched successfully.\r\nConfiguration finished\r\n\r\n$ ls  -l $(bazel info output_base)/external/local_config_cuda/crosstool\r\nINFO: $TEST_TMPDIR defined: output root default is '/local/cvsupport'.\r\n..................\r\ntotal 16\r\n-rwxrwxr-x 1 cvsupport cvsupport 1267 Feb 17 15:30 BUILD\r\ndrwxrwxr-x 3 cvsupport cvsupport   17 Feb 17 15:30 clang\r\n-rwxrwxr-x 1 cvsupport cvsupport 8928 Feb 17 15:30 CROSSTOOL\r\n\r\n$ bazel build -c opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\nINFO: $TEST_TMPDIR defined: output root default is '/local/cvsupport'.\r\nWARNING: Sandboxed execution is not supported on your system and thus hermeticity of actions cannot be guaranteed. See http://bazel.build/docs/bazel-user-manual.html#sandboxing for more information. You can turn off this warning via --ignore_unsupported_sandboxing.\r\nWARNING: /trinity/home/cvsupport/dmitry/tf/tensorflow/third_party/gpus/cuda_configure.bzl:116:3: ========================= test ==========================.\r\nERROR: /local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/external/local_config_cuda/crosstool/BUILD:4:1: Traceback (most recent call last):\r\n        File \"/local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/external/local_config_cuda/crosstool/BUILD\", line 4\r\n                error_gpu_disabled()\r\n        File \"/local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/external/local_config_cuda/crosstool/error_gpu_disabled.bzl\", line 3, in error_gpu_disabled\r\n                fail(\"ERROR: Building with --config=c...\")\r\nERROR: Building with --config=cuda but TensorFlow is not configured to build with GPU support. Please re-run ./configure and enter 'Y' at the prompt to build with GPU support.\r\nERROR: no such target '@local_config_cuda//crosstool:toolchain': target 'toolchain' not declared in package 'crosstool' defined by /local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/external/local_config_cuda/crosstool/BUILD.\r\nINFO: Elapsed time: 1.345s\r\n\r\n$ ls  -l $(bazel info output_base)/external/local_config_cuda/crosstool\r\nINFO: $TEST_TMPDIR defined: output root default is '/local/cvsupport'.\r\ntotal 8\r\n-rwxrwxr-x 1 cvsupport cvsupport  88 Feb 17 15:33 BUILD\r\n-rwxrwxr-x 1 cvsupport cvsupport 497 Feb 17 15:33 error_gpu_disabled.bzl\r\n```", "Ok, this is really weird. Can you sprinkle ps -ef bazel in between commands so we get the PID of the bazel process (to see when it restarted)?\r\nOther than that, I know it's a lot to ask, but can you try using bazel from head (I was told there have been a couple of fixes regarding when to rebuild the config)?", "Ok,another try:\r\n\r\n```\r\n<snip>\r\n[Default is: \"3.5,5.2\"]: 6.0\r\nINFO: $TEST_TMPDIR defined: output root default is '/local/cvsupport'.\r\n....................\r\nINFO: Starting clean (this may take a while). Consider using --expunge_async if the clean takes more than several minutes.\r\nINFO: $TEST_TMPDIR defined: output root default is '/local/cvsupport'.\r\n...............\r\nWARNING: /trinity/home/cvsupport/dmitry/tf/tensorflow/third_party/gpus/cuda_configure.bzl:116:3: ========================= test ==========================.\r\nINFO: All external dependencies fetched successfully.\r\nConfiguration finished\r\n\r\n$ ps -elf | grep bazel\r\n0 S cvsuppo+  51964      1 99  80   0 - 505728 futex_ 14:12 ?       00:01:58 bazel(tf) -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144 -Xverify:none -Djava.util.logging.config.file=/local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144/javalog.properties -Djava.library.path=/local/cvsupport/_bazel_cvsupport/install/60eac8be1d9f8622135925f67ceca06d/_embedded_binaries/ -Dfile.encoding=ISO-8859-1 -jar /local/cvsupport/_bazel_cvsupport/install/60eac8be1d9f8622135925f67ceca06d/_embedded_binaries/A-server.jar --max_idle_secs=15 --connect_timeout_secs=10 --install_base=/local/cvsupport/_bazel_cvsupport/install/60eac8be1d9f8622135925f67ceca06d --install_md5=60eac8be1d9f8622135925f67ceca06d --output_base=/local/cvsupport/_bazel_cvsupport/c61d2ac558d6d30ef2694b9af72e4144 --workspace_directory=/trinity/home/cvsupport/dmitry/tf/tensorflow --deep_execroot --experimental_oom_more_eagerly_threshold=100 --nofatal_event_bus_exceptions --client_debug=false --use_custom_exit_code_on_abrupt_exit=true --product_name=Bazel --option_sources=\r\n0 S cvsuppo+  53608  50980  0  80   0 -  1735 pipe_r 14:13 pts/0    00:00:00 grep --color=auto bazel\r\n\r\n$ ls  -l $(bazel info output_base)/external/local_config_cuda/crosstool\r\nINFO: $TEST_TMPDIR defined: output root default is '/local/cvsupport'.\r\n.................\r\ntotal 16\r\n-rwxrwxr-x 1 cvsupport cvsupport 1267 Feb 21 14:12 BUILD\r\ndrwxrwxr-x 3 cvsupport cvsupport   17 Feb 21 14:12 clang\r\n-rwxrwxr-x 1 cvsupport cvsupport 8928 Feb 21 14:12 CROSSTOOL\r\n\r\n$ ps -elf | grep bazel\r\n0 S cvsuppo+  54379  50980  0  80   0 -  1735 pipe_r 14:16 pts/0    00:00:00 grep --color=auto bazel\r\n```\r\nso `bazel info` killed bazel. I would expect that `bazel build` kills bazel server", "That would be the case if the bazel in \"bazel info\" is a different bazel from the bazel that tensorflow finds in its configure script. Do you by any chance have multiple bazel versions installed?", "If bazel do not go with TF - no\r\nI barely managed to build single bazel. That was another challenge to make it on OpenPower :)\r\n```\r\n$ which bazel\r\n/trinity/shared/apps/cv-ppc64le/bazel/0.4.4/bin/bazel\r\n$ type -f bazel\r\nbazel is /trinity/shared/apps/cv-ppc64le/bazel/0.4.4/bin/bazel\r\n", "@dchirikov: what issue did you encountered in porting bazel to OpenPower? We are generally willing to accept patch to support more platform to avoid people having to maintain their own patches.", "Hm, actualy bazel goes offline after a minute after `./configure` by itself. One does not need even to run `bazel info`.\r\nLast logs in `c61d2ac558d6d30ef2694b9af72e4144/java.log` (if it will help)\r\n```\r\nFeb 21, 2017 9:24:53 PM com.google.devtools.build.lib.query2.AbstractBlazeQueryEnvironment evaluateQuery\r\nINFO: Spent 30208 milliseconds evaluating query\r\nFeb 21, 2017 9:24:54 PM com.google.devtools.build.lib.server.GrpcServerImpl$RunningCommand close\r\nINFO: Finished command 62e1361d-67d3-4e47-ad0a-17183ec6adde on thread grpc-command-0\r\n```", "@damienmg \r\nI don't remember, tbh. Just recall it took some time for me. But it could be just me not so experienced with tools. Anyway, I don't know java at all, so I did not patch it for sure.", "Oh ok (generally patch are not in the java part, mostly in the compilation scripts).\r\n\r\nIt looks like Bazel just completed perfectly. /cc @lberki in case he has more understanding of the grpc-command message.\r\n\r\nAnyway if the server restart, with the bug I recently fixed on Bazel and without #7575, you will do the configuration step at each build :(, we are trying to cut a Bazel release and our CI has been green today so we should be able to cut one tomorrow.\r\n", "I just ran into this issue, though with different circumstances\r\n\r\nI think the cause had something to do with building tensorflow with an anaconda environment active.\r\n\r\nI ran 'ps -elf | grep bazel' and it showed two bazel processes running, one in the conda env, and one outside of it. I don't know what exactly caused bazel to start the server twice. It looks like ./configure used one bazel instance and bazel build used the other one.\r\n\r\nSo I killed both bazel processes, ran './configure' again, verified only one bazel process was running (it was only one), and ran the bazel build command again, and the build worked. \r\n\r\nPosting this here for posterity if someone else runs into the same issue (since the comments on this issue are what helped me resolve it and I don't see the need to open a new issue)", "Our bazel upgrade to 0.4.5 and related configure script upgrades are done.\r\nI just tried using nvidia dockers centos7 image, and I was able to build without problems.\r\n\r\nI will close the issue now, but @dchirikov could you also verify by checking out the master branch, and using bazel 0.4.5?\r\nIf it still misbehaves as you described, we can reopen."]}, {"number": 7541, "title": "Fatal messages mixing C libtensorflow with python tensorflow", "body": "I'm trying to write mixed C tensorflow code with python tensorflow code by\r\nembedding the CPython interpreter in my application.\r\n\r\nI'm mainly doing this because defining the model is only really possible in\r\nPython at the moment due to the lack of gradients (#6268), and I want to define\r\nnew models from the C side at speed without needing to invoke or\r\ncommunicate to an external python process to get a new model.\r\n\r\nTo reproduce the problem is quite straightforward, simply `import tensorflow`\r\nin python after the libtensorflow library has already been dynamically linked.\r\nHere is a quick reproducer in pure python which will not run:\r\n\r\n```python\r\nimport ctypes\r\n\r\ntf_dll = ctypes.CDLL(\"/usr/local/lib/libtensorflow.so\")\r\n\r\nimport tensorflow\r\n```\r\n\r\nlibtensorflow can be obtained like so:\r\n\r\n```\r\nTF_TYPE=cpu # Set to gpu for GPU support\r\nTF_OS=linux\r\ncurl -L \\\r\n  \"https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-${TF_TYPE}-${TF_OS}-x86_64-1.0.0.tar.gz\" |\r\nsudo tar -C /usr/local -xz\r\n```\r\n\r\nHere are two fatal messages I have encountered (the first from the Python reproducer above, the second from a C program):\r\n\r\n```\r\nF tensorflow/stream_executor/cuda/cuda_platform.cc:180] Check failed: ::perftools::gputools::port::Status::OK() == (MultiPlatformManager::RegisterPlatform(std::move(platform))) (OK vs. Internal: platform is already registered with name: \"CUDA\")\r\n```\r\n\r\n```\r\nF tensorflow/core/lib/monitoring/collection_registry.cc:77] Cannot register 2 metrics with the same name: /tensorflow/cc/saved_model/load_attempt_count\r\n```\r\n\r\nI assume the problem is that the `_pywrap_tensorflow.so` has tensorflow\r\nstatically linked into them, so they don't use libtensorflow. Then you have\r\ntwo shared libraries conflicting with one another.\r\n\r\nIs there a way to avoid this conflict?", "comments": ["@jhseu, do you have any insight on this. I think @pwaller's analysis is correct. There is clearly some singleton that is getting double initialized. ", "Yeah, I think this happens because we import pywrap_tensorflow with RTLD_GLOBAL. Unfortunately I don't think there's an easy way to make this work at the moment. It's possible we can go the other way and make the C API accessible from `import tensorflow`.\r\n\r\nKeeping this open, but it's uncommon and difficult, so we may not work on it anytime soon. A possible workaround is to mangle the symbols (namespace?) in the TensorFlow shared library.", "@jhseu it would be great if the C API were available through `import tensorflow`. I'd be happy to submit a PR if you could suggest how. My first guess was to add `//tensorflow/c:c_api` to the `deps` of the `pywrap_tensorflow_internal` BUILD rule, but it is [already there](https://github.com/tensorflow/tensorflow/blob/aa2941ffd7c6b6ae10fcb476ac1b3190b115bfbb/tensorflow/python/BUILD#L2722). Any ideas?", "I have gotten @jhseu's solution to work in #10469.\r\n\r\nBefore #10469:\r\n```\r\n$ bazel build -c opt //tensorflow/python:pywrap_tensorflow_internal\r\n$ nm -D bazel-bin/tensorflow/python/_pywrap_tensorflow_internal.so | grep '\\<TF_New'\r\n```\r\nAfter #10469:\r\n```\r\n$ bazel build -c opt //tensorflow/python:pywrap_tensorflow_internal\r\n$ nm -D bazel-bin/tensorflow/python/_pywrap_tensorflow_internal.so | grep '\\<TF_New'\r\n0000000001acb4d0 T TF_NewBuffer\r\n0000000001acb500 T TF_NewBufferFromString\r\n0000000001acb5b0 T TF_NewDeprecatedSession\r\n0000000001accfe0 T TF_NewGraph\r\n0000000001acd3e0 T TF_NewImportGraphDefOptions\r\n0000000001acb970 T TF_NewOperation\r\n0000000001acd770 T TF_NewSession\r\n0000000001acb470 T TF_NewSessionOptions\r\n0000000001acaf10 T TF_NewStatus\r\n0000000001acb160 T TF_NewTensor\r\n0000000001adc990 T TF_NewWhile\r\n```", "I'm trying to mix C++ tensorflow code with python tensorflow code instead, with tensorflow 1.4.0. Same fatal messages encountered. Is it suggested that I should link _pywrap_tensorflow_internal.so instead of libtensorflow_cc.so when compiling the C++ DDL to avoid the conflict temporarily? Unfortunately I failed. It seem that some of C++ APIs I used are not included in C APIs and have not been exported to _pywrap_tensorflow_internal.so.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "I think something may have broken in the C symbol export from TF 1.3 -> 1.4, e.g. https://github.com/nimble-dev/nimble/issues/638", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "@allenlavoie fixed the issue @jhseu mentioned. Allen, can we close the original issue now?\r\nThere may be a new issue now, but should we create a new github issue for that?", "If you want to use the C API along with Python, you need in TF >=1.4 to link against _pywrap_tensorflow_internal.so (which includes the C API) and libtensorflow_framework.so (for protobuf symbols; also includes many C++ symbols). You can also build with `--config=monolithic` if you want the protobuf symbols wrapped up in _pywrap_tensorflow_internal.so.\r\n\r\nThe Python and C language bindings both include ops and kernels, so you (still) can't use both of those together, even though they both link against libtensorflow_framework.so. Potentially you could remove a bunch of duplicate registration errors to make it work, or build a version of the libtensorflow.so without ops or kernels (making that easy to build manually would be neat).\r\n\r\nI think these are issues tracked elsewhere.", "hello, peter @pwaller ; \r\n\r\nDid you solve this error of mixing python and c++ code?\r\nI tried to install Tensorflow from source and I added this flag (tensorflow/tools/pip_package:build_pip_package ) to download the python package, which should be the same c++ version, but unfortunately I face this error ''Cannot register 2 metrics with the same name: /tensorflow/cc/saved_model/load_attempt_count ''.\r\n\r\nthanks in advance. ", "@kerolos I didn't get this working in this way in the end, but I would still be interested in seeing it be possible.", "Any updates this double singleton initialisation issue? I am trying to call some Python code (that imports and runs Tensorflow) from within a C program that is linked against Tensorflow."]}]