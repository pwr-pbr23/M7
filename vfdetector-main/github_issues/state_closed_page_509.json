[{"number": 38483, "title": "How to store tf dataset object to file?", "body": "## URL(s) with the issue:\r\nhttps://www.tensorflow.org/guide/data\r\n\r\n## Description of issue (what needs changing):\r\nHow to store tf.dataset object to file?\r\nFor instance,\r\n```\r\ndataset1 = tf.data.Dataset.from_tensor_slices(\r\n    tf.random.uniform([4, 10], minval=1, maxval=10, dtype=tf.int32))\r\ndataset1\r\n```\r\nHow to store the dataset1 to file?\r\n\r\n### Clear description\r\n\r\nFor me, a saved copy of tokenized dataset saves lot of training time.\r\n```python\r\nfrom transformers import AlbertTokenizer\r\nimport tensorflow as tf\r\nimport DataReader\r\nimport Tokenizer\r\n\r\n\r\ndef encode(type, dataPath='./qgdata/nq-train-sample.json'):\r\n    entries = DataReader.read(dataPath)\r\n    encoding = []\r\n    for entry in entries:\r\n        if type == 'context':\r\n            context = Tokenizer.encode(\r\n                entry['passage'], entry['answer'], entry['question'], True)\r\n            encoding.append(context)\r\n        else:\r\n            question = Tokenizer.encode(\r\n                entry['passage'], entry['answer'], entry['question'], False)\r\n            encoding.append(question)\r\n    data = tf.data.Dataset.from_generator(\r\n        lambda: encoding, tf.int64, output_shapes=512)\r\n    return data\r\n\r\n\r\ndef make_dataset(dataPath='./qgdata/nq-train-sample.json', batch_size=1):\r\n    contextData = encode('context', dataPath)\r\n    questionData = encode('question', dataPath)\r\n    dataset = tf.data.Dataset.zip((contextData, questionData))\r\n    return dataset.batch(batch_size)\r\n```\r\nInstead of running this batching script before each training, it would be very efficient to store the tokenzied dataset object to file and avoid retokenizing.\r\n\r\n### Usage example\r\nMaybe like:\r\n```python\r\ndataset1 = tf.data.Dataset.from_tensor_slices(\r\n    tf.random.uniform([4, 10], minval=1, maxval=10, dtype=tf.int32))\r\ndataset1.save_dataset(path_to_store)\r\n```\r\n", "comments": ["@zzj0402, please refer to [this doc](https://www.tensorflow.org/tutorials/load_data/tfrecord#tfrecord_files_using_tfdata).", "The answer from @ashutosh1919 is the idiomatic solution for storing a dataset in a file.", "> this doc\r\n```\r\nfilename = 'test.tfrecord'\r\nwriter = tf.data.experimental.TFRecordWriter(filename)\r\nwriter.write(serialized_features_dataset)\r\n```\r\n\r\nWould it work on any kind of tf.dataset? I think that tutorial is very poorly organized. It's separated from the dataset doc and majority of that doc is talking about making a tf.dataset.\r\n", "I find this doc relevant: https://www.tensorflow.org/api_docs/python/tf/data/experimental/TFRecordWriter", "## Save/Load functions\r\n```python\r\ndef save(dataset, location='data/tf-records/'):\r\n    dataset = dataset.map(tf.io.serialize_tensor)\r\n    writer = tf.data.experimental.TFRecordWriter(location)\r\n    writer.write(dataset)\r\n    return location\r\n\r\n\r\ndef load(tf_record='data/tf-records/'):\r\n    dataset = tf.data.TFRecordDataset(tf_record)\r\n    dataset = dataset.map(lambda x: tf.io.parse_tensor(x, tf.int64))\r\n    return dataset\r\n```\r\n\r\n## Dataset\r\n```\r\n<BatchDataset shapes: ({input_ids: (None, 512), attention_mask: (None, 512), token_type_ids: (None, 512), position_ids: (None, 512)}, (None, 512)), types: ({input_ids: tf.int32, attention_mask: tf.int32, token_type_ids: tf.int32, position_ids: tf.int32}, tf.int32)>\r\n```\r\n\r\n## Reproduction Code\r\n```\r\n        dataset = DataPatcher.make_dataset()\r\n        model = Training.initial_model()\r\n        path=DataPatcher.save(dataset)\r\n        dataset_loaded = DataPatcher.load()\r\n        Training.fit_model(dataset_loaded, model, 1, 'sample')\r\n```\r\n\r\n## Error\r\n```\r\nTraceback (most recent call last):\r\n  File \"/Volumes/SAMSUNG_T5/natural-question-generation/test/test_dataset.py\", line 71, in test_loading\r\n    DataPatcher.save(dataset)\r\n  File \"/Volumes/SAMSUNG_T5/natural-question-generation/DataPatcher.py\", line 96, in save\r\n    dataset = dataset.map(tf.io.serialize_tensor)\r\n  File \"/Users/zijingzhang/Library/Python/3.6/lib/python/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 1588, in map\r\n    return MapDataset(self, map_func, preserve_cardinality=True)\r\n  File \"/Users/zijingzhang/Library/Python/3.6/lib/python/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 3888, in __init__\r\n    use_legacy_function=use_legacy_function)\r\n  File \"/Users/zijingzhang/Library/Python/3.6/lib/python/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 3147, in __init__\r\n    self._function = wrapper_fn._get_concrete_function_internal()\r\n  File \"/Users/zijingzhang/Library/Python/3.6/lib/python/site-packages/tensorflow_core/python/eager/function.py\", line 2395, in _get_concrete_function_internal\r\n    *args, **kwargs)\r\n  File \"/Users/zijingzhang/Library/Python/3.6/lib/python/site-packages/tensorflow_core/python/eager/function.py\", line 2389, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/Users/zijingzhang/Library/Python/3.6/lib/python/site-packages/tensorflow_core/python/eager/function.py\", line 2703, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/Users/zijingzhang/Library/Python/3.6/lib/python/site-packages/tensorflow_core/python/eager/function.py\", line 2593, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/Users/zijingzhang/Library/Python/3.6/lib/python/site-packages/tensorflow_core/python/framework/func_graph.py\", line 978, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/Users/zijingzhang/Library/Python/3.6/lib/python/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 3140, in wrapper_fn\r\n    ret = _wrapper_helper(*args)\r\n  File \"/Users/zijingzhang/Library/Python/3.6/lib/python/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\", line 3082, in _wrapper_helper\r\n    ret = autograph.tf_convert(func, ag_ctx)(*nested_args)\r\n  File \"/Users/zijingzhang/Library/Python/3.6/lib/python/site-packages/tensorflow_core/python/autograph/impl/api.py\", line 237, in wrapper\r\n    raise e.ag_error_metadata.to_exception(e)\r\ntensorflow.python.framework.errors_impl.OperatorNotAllowedInGraphError: in converted code:\r\n\r\n    /Users/zijingzhang/Library/Python/3.6/lib/python/site-packages/tensorflow_core/python/ops/gen_parsing_ops.py:2236 serialize_tensor\r\n        \"SerializeTensor\", tensor=tensor, name=name)\r\n    /Users/zijingzhang/Library/Python/3.6/lib/python/site-packages/tensorflow_core/python/framework/op_def_library.py:351 _apply_op_helper\r\n        with g.as_default(), ops.name_scope(name) as scope:\r\n    /Users/zijingzhang/Library/Python/3.6/lib/python/site-packages/tensorflow_core/python/framework/ops.py:6249 __enter__\r\n        return self._name_scope.__enter__()\r\n    /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/contextlib.py:81 __enter__\r\n        return next(self.gen)\r\n    /Users/zijingzhang/Library/Python/3.6/lib/python/site-packages/tensorflow_core/python/framework/ops.py:4010 name_scope\r\n        if name:\r\n    /Users/zijingzhang/Library/Python/3.6/lib/python/site-packages/tensorflow_core/python/framework/ops.py:757 __bool__\r\n        self._disallow_bool_casting()\r\n    /Users/zijingzhang/Library/Python/3.6/lib/python/site-packages/tensorflow_core/python/framework/ops.py:520 _disallow_bool_casting\r\n        \"using a `tf.Tensor` as a Python `bool`\")\r\n    /Users/zijingzhang/Library/Python/3.6/lib/python/site-packages/tensorflow_core/python/framework/ops.py:505 _disallow_when_autograph_disabled\r\n        \" Try decorating it directly with @tf.function.\".format(task))\r\n\r\n    OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph is disabled in this function. Try decorating it directly with @tf.function.\r\n```", "Honestly, I didn't understand the documentation at all. I'm trying to find a way to save the modified dataset as a tfrecord file as well. I will be doing lots of filtering on the data, and it seems to slow down any training operation incredibly. I just want to do it once and save it like that.\r\n\r\n```python\r\ndatasets = tfds.load(\"nsynth\", data_dir=\"data\")\r\ntrain_dataset, test_dataset, valid_dataset = datasets[\"train\"], datasets[\"test\"], datasets[\"valid\"]\r\ntrain_dataset = train_dataset.filter(lambda x: x['instrument']['family'] == 3)\r\ntf_writer = tf.data.experimental.TFRecordWriter(\"filtered/onlyGuitar.tfrecord\")\r\ntf_writer.write(train_dataset)\r\n```", "> Honestly, I didn't understand the documentation at all. I'm trying to find a way to save the modified dataset as a tfrecord file as well. I will be doing lots of filtering on the data, and it seems to slow down any training operation incredibly. I just want to do it once and save it like that.\r\n> \r\n> ```python\r\n> datasets = tfds.load(\"nsynth\", data_dir=\"data\")\r\n> train_dataset, test_dataset, valid_dataset = datasets[\"train\"], datasets[\"test\"], datasets[\"valid\"]\r\n> train_dataset = train_dataset.filter(lambda x: x['instrument']['family'] == 3)\r\n> tf_writer = tf.data.experimental.TFRecordWriter(\"filtered/onlyGuitar.tfrecord\")\r\n> tf_writer.write(train_dataset)\r\n> ```\r\n\r\nI end up switching to Torch.", "I'm having similar error as @zzj0402 :\r\n\r\n```\r\nOperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph is disabled in this function.\r\n```\r\n\r\nIt seems like we can't save a Dataset to file in Tensorflow...", "I could finally do it :  \r\nYou have to iterate your Dataset and define Example, one by one, by yourself.\r\n\r\n```\r\ndef create_int_feature(value):\r\n  return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\r\n\r\nwith tf.io.TFRecordWriter(\"gs://my_bucket/data.tfrecord\") as writer:\r\n    for sample in dataset:\r\n        feature = {\r\n            'input_ids': create_int_feature(sample['input_ids']),\r\n            'attention_mask': create_int_feature(sample['attention_mask']),\r\n            'decoder_input_ids': create_int_feature(sample['decoder_input_ids']),\r\n            'lm_labels': create_int_feature(sample['lm_labels'])\r\n        }\r\n\r\n        example = tf.train.Example(features=tf.train.Features(feature=feature))\r\n        writer.write(example.SerializeToString())\r\n```\r\n\r\nTo read your TFRecord files :\r\n\r\n```\r\nfeature_description = {\r\n    'input_ids': tf.io.FixedLenFeature([tokenizer.model_max_length], tf.int64),\r\n    'attention_mask': tf.io.FixedLenFeature([tokenizer.model_max_length], tf.int64),\r\n    'decoder_input_ids': tf.io.FixedLenFeature([tokenizer.model_max_length // 4], tf.int64),\r\n    'lm_labels': tf.io.FixedLenFeature([tokenizer.model_max_length // 4], tf.int64)\r\n}\r\n\r\ndef deserialize(example_proto):\r\n    return tf.io.parse_single_example(example_proto, feature_description)\r\n\r\ndataset = tf.data.TFRecordDataset(\"gs://my_bucket/data.tfrecord\")\r\ndataset = dataset.map(deserialize)\r\n```\r\n\r\n---\r\n\r\nThat was a very painful and excruciating process. [Documentation](https://www.tensorflow.org/tutorials/load_data/tfrecord#tfrecord_files_using_tfdata) is actually complete, but very difficult to follow.\r\n\r\nThat seems insane that there is no helper function for writing a TFRecord from an existing dataset.  \r\nThe process is the same no matter if you have raw data or complete `tf.Dataset` (?!)\r\n\r\n ", "Torch solves in one line of code. Guess TF needs some catch-up", "@zzj0402 How does torch solve this? As far as I can tell a torch `Dataset` is just a python iterator, but if you serialize the object you don't actually store the computation up to that point, torch doesn't even have multiple stage you can checkpoint. Am I missing something?", "@cgarciae I don't know any details about both Tensorflow and Pytorch, but as a user, in Pytorch you can do :\r\n\r\n`torch.save(dataset, file_path)` and load it with `torch.load(file_path)`, and it works.\r\n\r\nUnlike TF, you don't have to mind any of the internal details of your dataset.", "I am working on providing support for `save` and `load` and expect it to be available later this month (and certainly for TF 2.3).", "@jsimsa Will it work also for datasets that don't not fit in memory? So like \"a converter\" to tf_record for an optimized format when you need to train from a remote/cloud storage.", "Yes, it will be a streaming API. You will be able to do the following:\r\n\r\n```\r\n # Save a dataset\r\n  dataset = tf.data.Dataset.range(10).\r\n  tf.data.experimental.save(dataset, \"/path/to/data\")\r\n\r\n  # Load a previously saved dataset\r\n  new_dataset = tf.data.experimental(\"/path/to/data\",\r\n       element_spec=tf.TensorSpec(shape=(), dtype=tf.int64))\r\n```\r\n\r\nThe `load` API will require you to specify the type signature for the elements to load, which is required so that shape inference does not have to perform I/O.", "I think to fully solve this you need something like [tf.data Snapshots](https://github.com/tensorflow/community/blob/master/rfcs/20200107-tf-data-snapshot.md) to be implemented. Its a bit hacky but you can also use `Dataset.cache()` so save the computation but its really meant to be temporal, mostly used to reuse the data of the first epoch.", "Indeed. tf.data snapshot will be released in TF 2.3 as well and the aforementioned `save` and `load` API will share its implementation.", "@jsimsa I'am thinking also about refreshing a little bit on the original data in the case you have some time-margin to sparsely execute realtime augmentions of some sparse samples. \r\nBut I don't if we could handle in some way this metadata (original vs transformed save data).", "I do not follow your use case. The loaded dataset will be a `tf.data.Dataset` so you could apply further transformations to it.", "@jsimsa Yes of course. But suppose that you use it as a converter you will do all the augmentation that cannot apply in realtime and you save it. When loading back you can have a new margin over the training loop ans so you could do some sparse sample augmentation on the original data to refresh some samples.\r\nSo I don't know if it could be easy in the streaming context instantiating two different datasets object and interleave these data or we need to handle some special metadata in the API.", "@jsimsa Probably that case could be covered by the experimetal `tf.data.experimental.sample_from_datasets`. I think that It could work with your load and save api as It consume dataset objects right?", "My changes were submitted as https://github.com/tensorflow/tensorflow/commit/4d58a67a9f19ab8d0cfbb2d8e461ebb73ce06db6"]}, {"number": 38482, "title": "Install the TensorFlow-GPU and CUDA and CUDnn, but GPU not work when test.", "body": "**System information**\r\n- OS Platform and Distribution: Win10, X64\r\n- TensorFlow version: 1.15\r\n- Python version: 3.5\r\n- Installed using virtualenv? pip? conda?: pip install tensorflow_gpu-1.15.0-cp35-cp35m-win_amd64\r\n- CUDA/cuDNN version: 10.2/7.6.5\r\n- GPU model and memory: GTX1050\r\n\r\n\r\n\r\n**problem details**\r\ni use the Anaconda, the first i create a new environment which python version is 3.7 and TensorFlow-GPU is 2.1. and then i install the CUDA 10.2and CUDNN, 7.6.5, but when i test it, there is a error said can't find the cudart64_101.dll file, when i changed that file(cudart64_102.dll) its name to cudart64_101.dll, no error again, and when i run the follow code showing true\r\n`#code 1`\r\n`import tensorflow as tf`\r\n`print(tf.test.is_gpu_available())`\r\nand running that below code also show the GPU device log\r\n`#code 2`\r\n`import tensorflow as tf`\r\n`sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(log_device_placement=True))`\r\nall is going well on tensorflow 2.1 with GPU\r\n\r\nbut when i wanna to use tf-gpu 1.X, i install the tensorflow-gpu 1.15, with the same CUDA, CUDNN version, i made a copy of cudart64_101.dll and rename cudart_100.dll, when i run the above test code, the console shows no error, but show false in the code 1 and did not show GPU device info in code 2. i was wondering that if the CUDA/CUDNN version isn't fit the tensorflow-gpu version, is any error will show? i think there must be some error will be report. The problem is i don't know how to fix it **because it didn't report error** .\r\n\r\n\r\nshould i uninstall the CUDA 10.2 and CUDNN and install CUDA 10.0/10.1 but...\r\n\r\n\r\n**Any other info / logs**\r\nand when i import tensorflow in anaconda prompt , there is no warning or error, just shows \r\n`tensorflow/stream_executor/platform/default/http://dso_loader.cc:44] Successfully opened dynamic library cudart64_100.dll`\r\n", "comments": ["TF 1.15 supports cuda 10.0 and cudnn >=7.4 . You have to roll back to cuda 10.0 \r\nThank you.\r\n", "THX, and i want to know if i roll back to CUDA 10.0, my another environment with tensorflow-gpu-2.1 can fit the CUDA 10.0? because i refer to the tensorflow.org only showing tensorflow-gpu-2.0 to CUDA 10.\n\nSorry, a little more question, someone told me that there can't exist tf-gpu or tf-cpu at the same time  in one environment, which means we should create two environments to manage tf-cpu and tf-gpu. is it true? \n\nand a not related question, can i instal the CUDA10.2 & CUDA 10.0 in win 10?\n\nwhy tf 1.5 can not support CUDA > =10.0 same as the CUDNN can > =7.4?\n\nReally thanks for your reply. ", "Yes you can use TF 2.1 with cuda 10.0 as well. I will add TF 1.15 cuda info on the website.\r\nYou have to build TF from source for supporting cuda version other than the ones we already support.\r\nThis procedure is time consuming and often stressful for users. So we recommend installing tf using pip packages (pre built tf binaries). The only caveat here is that users have fix to their environment as per our dependencies which are pretty straight forward.\r\nHaving said that we do actively engage with the community and help as much as possible.\r\nThanks for using TF.", "I have rolled back to cuda 10.0, TF-GPU 1.15 can work with gpu well, but TF 2.1 can't, like the bug like i put forwoard first in TF 1.5 once. i think i can solve this by downgrading to TF 2.0, is it right? but you said can use TF 2.1 with cuda 2.1, there must be something i did wrong in this process. \r\n\r\nBuilding TF from source means i should do as [https://www.tensorflow.org/install/source_windows?](url) introduction or ...\r\n\r\nThanks for your active respond sincerely. \r\n\r\n", "ahh.. You are right for TF 2.1 you need cuda 10.1 (my apologies). Yes TF 2.0 supports cuda 10.0.\r\nSorry for the confusion.\r\nSee [tested build configurations](https://www.tensorflow.org/install/source#gpu) Thanks!", "Fine, i felt i've solved my problem, thank you.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38482\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38482\">No</a>\n"]}, {"number": 38481, "title": "Fix TensorFlow Lite for Microcontrollers CMSIS-NN build and add MaxPool implementation", "body": "This PR does two things:\r\n\r\n- Fixes building of TensorFlow Lite for Microcontrollers examples with CMSIS-NN and mbed, by removing a reference to an undeclared function and by instructing the build scripts to use a newer version of the CMSIS libraries.\r\n- Adds CMSIS-NN optimized implementation of MaxPool to the CMSIS-NN optimized kernels", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F38481) for more info**.\n\n<!-- need_sender_cla -->", "/cc @freddan80 @petewarden ", "@dansitu Thank you for your contribution. Can you please sign CLA? Thanks!", "@googlebot I signed it!", "@googlebot I signed it!\r\n", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F38481) for more info**.\n\n<!-- ok -->", "Thanks for this contribution @dansitu ! Much appreciated. It looks good in general, I left a few minor comments.", "Looks good!", "@dansitu Can you please resolve conflicts? Thanks!", "> @dansitu Can you please resolve conflicts? Thanks!\r\n\r\nDone!", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F38481) for more info**.\n\n<!-- need_author_cla -->", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F38481) for more info**.\n\n<!-- ok -->", "I've also added a fix to `flatbuffer_conversions.cc` where the `ParseOpData` function sometimes did not have a return value, which caused problems with compilers that don't add an implicit return value.", "@mihaimaruseac Can you please take a look on cla/google test failure? Thanks!"]}, {"number": 38480, "title": "improve the readability of Model.evaluate who use the code as doc", "body": "", "comments": ["@omalleyt12 Would you be able to review this commit?"]}, {"number": 38479, "title": "[lite] fix nnapi:nnapi_delegate_verbose_validation", "body": "without `@com_google_absl//absl/strings`, when building `//tensorflow/lite/delegates/nnapi:nnapi_delegate_verbose_validation`, I met\r\n\r\n```\r\nERROR: /hack/freedom/tensorflow/tf-clean/tensorflow/lite/delegates/nnapi/BUILD:45:1: undeclared inclusion(s) in rule '//tensorflow/lite/delegates/nnapi:nnapi_delegate_verbose_validation':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/lite/delegates/nnapi/quant_lstm_sup.cc':\r\n  'external/com_google_absl/absl/strings/string_view.h'\r\n  'external/com_google_absl/absl/base/internal/throw_delegate.h'\r\nTarget //tensorflow/lite/delegates/nnapi:nnapi_delegate_verbose_validation failed to build\r\n```", "comments": ["Hi Jared, could you help take a look at this PR? It looks good to me but somehow I'm not authorized to merge it. Thanks!"]}, {"number": 38478, "title": "[tflite] FlexAddV2", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (or github SHA if from source):\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\n# Copy and paste here\r\n```\r\n\r\n**Standalone code to reproduce the issue** \r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\nAlso, please include a link to a GraphDef or the model if possible.\r\n\r\n**Any other info / logs**\r\n\r\nInclude any logs or source code that would be helpful to diagnose the problem.\r\nIf including tracebacks, please include the full traceback. Large logs and files\r\nshould be attached.\r\n", "comments": ["model_path ='converted_model_tf2.tflite'\r\ninterpreter = tf.lite.Interpreter(model_path=model_path)\r\ninterpreter.allocate_tensors()\r\n\r\n\r\n\r\n      1 model_path ='converted_model_tf2.tflite'\r\n      2 interpreter = tf.lite.Interpreter(model_path=model_path)\r\n----> 3 interpreter.allocate_tensors()\r\n\r\n/anaconda/envs/tf1.15/lib/python3.6/site-packages/tensorflow_core/lite/python/interpreter.py in allocate_tensors(self)\r\n    242   def allocate_tensors(self):\r\n    243     self._ensure_safe()\r\n--> 244     return self._interpreter.AllocateTensors()\r\n    245 \r\n    246   def _safe_to_run(self):\r\n\r\n/anaconda/envs/tf1.15/lib/python3.6/site-packages/tensorflow_core/lite/python/interpreter_wrapper/tensorflow_wrap_interpreter_wrapper.py in AllocateTensors(self)\r\n    104 \r\n    105     def AllocateTensors(self):\r\n--> 106         return _tensorflow_wrap_interpreter_wrapper.InterpreterWrapper_AllocateTensors(self)\r\n    107 \r\n    108     def Invoke(self):\r\n\r\nRuntimeError: Regular TensorFlow ops are not supported by this interpreter. Make sure you invoke the Flex delegate before inference.Node number 2 (FlexAddV2) failed to prepare.", "How are you converting the mode to tf lite?\r\nIf using `target_spec.supported_ops` can you try to convert the model with `SELECT_TF_OPS`?\r\n```python\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.SELECT_TF_OPS]\r\ntflite_model = converter.convert()\r\n```", "To run the model with select TF operators,  you can follow the method in https://www.tensorflow.org/lite/guide/ops_select#running_the_model.\r\nUnfortunately, python package for select TF operators are not supported yet. You can run the model using Android or iOS  library.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38478\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38478\">No</a>\n"]}, {"number": 38477, "title": "tensorflow.python.framework.errors_impl.UnimplementedError: File system scheme 'gs' not implemented (file: 'gs://tfds-data/datasets/mnist')", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: It is an example script (for distributed training) provided in TensorFlow\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: v2.2.0-rc2-77-gaad398b5e9 2.2.0-rc3\r\n- **Python version**: 3.6.9\r\n- **Bazel version (if compiling from source)**: 2.0.0\r\n- **GCC/Compiler version (if compiling from source)**: 7.5.0\r\n- **CUDA/cuDNN version**: 10.2 / 7.6.5.32-1\r\n- **GPU model and memory**: NVIDIA GeForce 940MX with 2 GB Dedicated VRAM\r\n- **Exact command to reproduce**: python3 distributed_training.py\r\n\r\n### Describe the problem\r\nI have built TensorFlow 2.2 from source (using r2.2 branch) with support of CUDA 10.2 and CUDNN 7.6.5 on Ubuntu 18.04 for python3.\r\nDuring the configuration of the build there was no question like \"Do you wish to build TensorFlow with Google Cloud Platform support? [y/N]\"\r\nAfter I installed this built whl and tried to use it with the script that requires to access the gs://tfds-data/datasets/mnist data, I got the following error:\r\ntensorflow.python.framework.errors_impl.UnimplementedError: File system scheme 'gs' not implemented (file: 'gs://tfds-data/datasets/mnist')\r\nPlease advise.\r\nI am using tensorflow-datasets 2.1.0, not sure if this can be the cause of the problem (this version agains tensroflow 2.2 version).\r\n\r\n### Source code / logs\r\nSource code of the script:\r\n```\r\nfrom __future__ import absolute_import, division, print_function, unicode_literals\r\nimport os\r\n\r\nimport tensorflow_datasets as tfds\r\nimport tensorflow as tf\r\n\r\ntfds.disable_progress_bar()\r\n\r\n\r\ndef evaluate_and_get_model(pth):\r\n    mdl = tf.keras.models.load_model(pth, compile=False)\r\n    mdl.compile(loss='sparse_categorical_crossentropy',\r\n                optimizer=tf.keras.optimizers.Adam(),\r\n                metrics=['accuracy'])\r\n    evl_loss, evl_acc = mdl.evaluate(eval_dataset)\r\n    print('Eval loss: {}, Eval Accuracy: {}'.format(evl_loss, evl_acc))\r\n    return mdl\r\n\r\n\r\n# Function for decaying the learning rate.\r\n# You can define any decay function you need.\r\ndef decay(epoch):\r\n    if epoch < 3:\r\n        return 1e-3\r\n    elif 3 <= epoch < 7:\r\n        return 1e-4\r\n    else:\r\n        return 1e-5\r\n\r\n\r\ndef scale(image, label):\r\n    image = tf.cast(image, tf.float32)\r\n    image /= 255\r\n\r\n    return image, label\r\n\r\n\r\n# Callback for printing the LR at the end of each epoch.\r\nclass PrintLR(tf.keras.callbacks.Callback):\r\n    def on_epoch_end(self, epoch, logs=None):\r\n        print('\\nLearning rate for epoch {} is {}'.format(epoch + 1, model.optimizer.lr.numpy()))\r\n\r\n\r\nprint(tf.__version__)\r\n\r\ndatasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True, data_dir='gs://tfds-data/datasets')\r\n\r\nmnist_train, mnist_test = datasets['train'], datasets['test']\r\n\r\nstrategy = tf.distribute.MirroredStrategy()\r\n\r\nprint('Number of devices: {}'.format(strategy.num_replicas_in_sync))\r\n\r\n# You can also do info.splits.total_num_examples to get the total\r\n# number of examples in the dataset.\r\n\r\nnum_train_examples = info.splits['train'].num_examples\r\nnum_test_examples = info.splits['test'].num_examples\r\n\r\nBUFFER_SIZE = 10000\r\n\r\nBATCH_SIZE_PER_REPLICA = 64\r\nBATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\r\n\r\ntrain_dataset = mnist_train.map(scale).cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\r\neval_dataset = mnist_test.map(scale).batch(BATCH_SIZE)\r\n\r\nwith strategy.scope():\r\n    model = tf.keras.Sequential([\r\n        tf.keras.layers.Conv2D(32, 3, activation='relu', input_shape=(28, 28, 1)),\r\n        tf.keras.layers.MaxPooling2D(),\r\n        tf.keras.layers.Flatten(),\r\n        tf.keras.layers.Dense(64, activation='relu'),\r\n        tf.keras.layers.Dense(10, activation='softmax')\r\n    ])\r\n\r\n    model.compile(loss='sparse_categorical_crossentropy',\r\n                  optimizer=tf.keras.optimizers.Adam(),\r\n                  metrics=['accuracy'])\r\n\r\n# Define the checkpoint directory to store the checkpoints\r\n\r\ncheckpoint_dir = './training_checkpoints'\r\n# Name of the checkpoint files\r\ncheckpoint_prefix = os.path.join(checkpoint_dir, 'ckpt_{epoch}')\r\n\r\ncallbacks = [\r\n    tf.keras.callbacks.TensorBoard(log_dir='./logs'),\r\n    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\r\n                                       save_weights_only=True),\r\n    tf.keras.callbacks.LearningRateScheduler(decay),\r\n    PrintLR()\r\n]\r\n\r\nmodel.fit(train_dataset, epochs=12, callbacks=callbacks)\r\n\r\nmodel.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\r\n\r\neval_loss, eval_acc = model.evaluate(eval_dataset)\r\n\r\nprint('Eval loss: {}, Eval Accuracy: {}'.format(eval_loss, eval_acc))\r\n\r\npath = 'saved_model/'\r\n\r\nmodel.save(path, save_format='tf')\r\n\r\nunreplicated_model = evaluate_and_get_model(path)\r\n\r\nunreplicated_model.save(path, save_format='tf')\r\n\r\nwith strategy.scope():\r\n    evaluate_and_get_model(path)\r\n```\r\n\r\nCommand line output of running the \"python3 distributed_training.py\" command:\r\n```\r\n2.2.0-rc3\r\nERROR:absl:Failed to construct dataset mnist\r\nTraceback (most recent call last):\r\n  File \"distributed_training.py\", line 48, in <module>\r\n    datasets, info = tfds.load(name='mnist', with_info=True, as_supervised=True, data_dir='gs://tfds-data/datasets')\r\n  File \"/home/vyepishov/.local/lib/python3.6/site-packages/tensorflow_datasets/core/api_utils.py\", line 52, in disallow_positional_args_dec\r\n    return fn(*args, **kwargs)\r\n  File \"/home/vyepishov/.local/lib/python3.6/site-packages/tensorflow_datasets/core/registered.py\", line 302, in load\r\n    dbuilder = builder(name, data_dir=data_dir, **builder_kwargs)\r\n  File \"/home/vyepishov/.local/lib/python3.6/site-packages/tensorflow_datasets/core/registered.py\", line 172, in builder\r\n    return _DATASET_REGISTRY[name](**builder_kwargs)\r\n  File \"/home/vyepishov/.local/lib/python3.6/site-packages/tensorflow_datasets/core/api_utils.py\", line 52, in disallow_positional_args_dec\r\n    return fn(*args, **kwargs)\r\n  File \"/home/vyepishov/.local/lib/python3.6/site-packages/tensorflow_datasets/core/dataset_builder.py\", line 197, in __init__\r\n    self._data_dir = self._build_data_dir()\r\n  File \"/home/vyepishov/.local/lib/python3.6/site-packages/tensorflow_datasets/core/dataset_builder.py\", line 661, in _build_data_dir\r\n    version_dirs = _other_versions_on_disk()\r\n  File \"/home/vyepishov/.local/lib/python3.6/site-packages/tensorflow_datasets/core/dataset_builder.py\", line 648, in _other_versions_on_disk\r\n    if not tf.io.gfile.exists(builder_data_dir):\r\n  File \"/home/vyepishov/.local/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py\", line 267, in file_exists_v2\r\n    _pywrap_file_io.FileExists(compat.as_bytes(path))\r\ntensorflow.python.framework.errors_impl.UnimplementedError: File system scheme 'gs' not implemented (file: 'gs://tfds-data/datasets/mnist')\r\n```", "comments": ["Why was it labeled as TF 2.1, if the built tensorflow version was 2.2?", "You will have to also build the shared object for the filesystem and then load it in the binary via `load_library`.", "@mihaimaruseac I am facing the issue on windows but it works on colab and other Linux os.\r\n", "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): Tensorflow 2.1.0\r\n- Python version: 3.7.6\r\n\r\n\r\n**Describe the current behavior**\r\nThe following code fails on windows\r\n```\r\nimport tensorflow as tf\r\ntf.io.gfile.exists(\"gs://tfds-data/dataset_info/mnist/3.0.1\")\r\n```\r\n**Other info / logs**\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\VIJAY\\py_test.py\", line 2, in <module>\r\n    tf.io.gfile.exists(\"gs://tfds-data/dataset_info/mnist/3.0.1\")\r\n  File \"C:\\ProgramData\\Miniconda3\\lib\\site-packages\\tensorflow_core\\python\\lib\\io\\file_io.py\", line 280, in file_exists_v2\r\n    pywrap_tensorflow.FileExists(compat.as_bytes(path))\r\ntensorflow.python.framework.errors_impl.UnimplementedError: File system scheme 'gs' not implemented (file: 'gs://tfds-data/dataset_info/mnist/3.0.1')\r\n```\r\n\r\nThis code works on colab.", "I too am having this problem\r\nWindows 10\r\npip install tensorflow (2.2)\r\npip install tensorflow-datasets\r\nPython 3.6\r\n\r\ncode:\r\nminst = tfds.load(\"mnist\")\r\n\r\n`Traceback (most recent call last):\r\n  File \"C:\\Python\\Python36\\lib\\site-packages\\tensorflow_datasets\\core\\utils\\py_utils.py\", line 399, in try_reraise\r\n    yield\r\n  File \"C:\\Python\\Python36\\lib\\site-packages\\tensorflow_datasets\\core\\registered.py\", line 244, in builder\r\n    return builder_cls(name)(**builder_kwargs)\r\n  File \"C:\\Python\\Python36\\lib\\site-packages\\wrapt\\wrappers.py\", line 606, in __call__\r\n    args, kwargs)\r\n  File \"C:\\Python\\Python36\\lib\\site-packages\\tensorflow_datasets\\core\\api_utils.py\", line 69, in disallow_positional_args_dec\r\n    return fn(*args, **kwargs)\r\n  File \"C:\\Python\\Python36\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py\", line 206, in __init__\r\n    self.info.initialize_from_bucket()\r\n  File \"C:\\Python\\Python36\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_info.py\", line 423, in initialize_from_bucket\r\n    data_files = gcs_utils.gcs_dataset_info_files(self.full_name)\r\n  File \"C:\\Python\\Python36\\lib\\site-packages\\tensorflow_datasets\\core\\utils\\gcs_utils.py\", line 70, in gcs_dataset_info_files\r\n    return gcs_listdir(posixpath.join(GCS_DATASET_INFO_DIR, dataset_dir))\r\n  File \"C:\\Python\\Python36\\lib\\site-packages\\tensorflow_datasets\\core\\utils\\gcs_utils.py\", line 63, in gcs_listdir\r\n    if _is_gcs_disabled or not tf.io.gfile.exists(root_dir):\r\n  File \"C:\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py\", line 267, in file_exists_v2\r\n    _pywrap_file_io.FileExists(compat.as_bytes(path))\r\ntensorflow.python.framework.errors_impl.UnimplementedError: File system scheme 'gs' not implemented (file: 'gs://tfds-data/dataset_info/mnist/3.0.1')\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"IS.py\", line 11, in <module>\r\n    minst = tfds.load(\"mnist\")\r\n  File \"C:\\Python\\Python36\\lib\\site-packages\\wrapt\\wrappers.py\", line 567, in __call__\r\n    args, kwargs)\r\n  File \"C:\\Python\\Python36\\lib\\site-packages\\tensorflow_datasets\\core\\api_utils.py\", line 69, in disallow_positional_args_dec\r\n    return fn(*args, **kwargs)\r\n  File \"C:\\Python\\Python36\\lib\\site-packages\\tensorflow_datasets\\core\\registered.py\", line 368, in load\r\n    dbuilder = builder(name, data_dir=data_dir, **builder_kwargs)\r\n  File \"C:\\Python\\Python36\\lib\\site-packages\\tensorflow_datasets\\core\\registered.py\", line 244, in builder\r\n    return builder_cls(name)(**builder_kwargs)\r\n  File \"C:\\Python\\Python36\\lib\\contextlib.py\", line 99, in __exit__\r\n    self.gen.throw(type, value, traceback)\r\n  File \"C:\\Python\\Python36\\lib\\site-packages\\tensorflow_datasets\\core\\utils\\py_utils.py\", line 401, in try_reraise\r\n    reraise(*args, **kwargs)\r\n  File \"C:\\Python\\Python36\\lib\\site-packages\\tensorflow_datasets\\core\\utils\\py_utils.py\", line 392, in reraise\r\n    six.reraise(exc_type, exc_type(msg), exc_traceback)\r\nTypeError: __init__() missing 2 required positional arguments: 'op' and 'message'`\r\n", "I hit the same issue in tf master build(v2.2.0) on aarch64. What the strange thing is, in prarallel, there are *2 other test jobs(v2.1.0 and v2.0.0 tf build) run and get pass with the same dependencies*.\r\n\r\nENV:\r\nARCH: aarch64\r\nOS: ubuntu18.04\r\npython: 3.6.5\r\ntf branch: master(upstream)\r\n\r\n```\r\n   File \"/home/zuul/.local/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py\", line 268, in file_exists_v2\r\n     _pywrap_file_io.FileExists(compat.path_to_bytes(path))\r\n tensorflow.python.framework.errors_impl.UnimplementedError: File system scheme 'gs' not implemented (file: 'gs://tfds-data/dataset_info/fashion_mnist/3.0.1')\r\n```\r\nand \r\n```\r\nFile \"/home/zuul/.local/lib/python3.6/site-packages/tensorflow_datasets/core/utils/py_utils.py\", line 392, in reraise\r\n     six.reraise(exc_type, exc_type(msg), exc_traceback)\r\n TypeError: __init__() missing 2 required positional arguments: 'op' and 'message'\r\n```\r\nAll dependencies are the same after success build the whl and exec `pip3 install tensorflow-*`. see\r\n```\r\nSuccessfully installed attrs-19.3.0 cycler-0.10.0 dill-0.3.2 googleapis-common-protos-1.52.0 kiwisolver-1.2.0 matplotlib-3.2.2 promise-2.3 python-dateutil-2.8.1 tensorflow-datasets-3.2.0 tensorflow-metadata-0.22.2 tqdm-4.47.0\r\n```\r\n\r\nThe full log is in https://logs.openlabtesting.org/logs/periodic-18/github.com/tensorflow/tensorflow/master/tensorflow-arm64-build-daily-master/95d9c31/job-output.txt.gz\r\n\r\nHmm, I search the related issues and found that might be related with the unimplemetation on Windows, but I hit on linux aarch64. It's necessary to trace this issue for any updates. Thanks", "We don't build the additional filesystems on Windows by default. You have to build manually and use `tf.load_library` to load them in the TensorFlow process.\r\n\r\nModular filesystems for TensorFlow (tensorflow/community#101), when fully done will allow you to build exactly the plugins you need and only load support for filesystems you need to use", "Any link to a tutorial or information on doing that. Most people getting this error is from running the official tensorflow tutorial. It may be a good idea to put it there as well.", "That is a good suggestion. I will definitely write tutorial for the modular filesystems.\r\n\r\nAt the moment, I think you can do the following to build the plugin\r\n\r\n```\r\nbazel build //tensorflow/core/platform/cloud:gcs_file_system\r\n```\r\n\r\nIt should create a `gcs_file_system.dll` (or something similar).\r\n\r\nThen in Python you need to insert a `tf.load_library(path_to_the_above_dll)` before doing any GCS call.\r\n\r\nBefore doing that though, can you try with the `tensorflow==2.3.0rc1` candidate? There is work for Google Summer of Code to enable building these filesystems on Windows (mostly via modular API)", "tensorflow==2.3.0rc1 - Gave the same error\r\n\r\nWhen trying to build the .dll, I get this error:\r\n\r\nERROR: An error occurred during the fetch of repository 'com_google_protobuf':\r\n   Traceback (most recent call last):\r\n\r\n...\r\nERROR: Analysis of target '//tensorflow/core/platform/cloud:gcs_file_system' failed; build aborted: no such package '@com_google_protobuf//': Traceback (most recent call last):\r\n\r\n\r\nThough it appears I had it cached already?\r\nINFO: Repository 'com_google_protobuf' used the following cache hits instead of downloading the corresponding file.\r\n * Hash 'cfcba2df10feec52a84208693937c17a4b5df7775e1635c1e3baffc487b24c9b' for https://storage.googleapis.com/mirror.tensorflow.org/github.com/protocolbuffers/protobuf/archive/v3.9.2.zip\r\n\r\n", "I downgrade the tensorflow_datasets from 3.2.1 to 3.1.0, then the issue is disappeared.", "> I downgrade the tensorflow_datasets from 3.2.1 to 3.1.0, then the issue is disappeared.\r\n\r\nThis fixed it.\r\nThank you", "This is interesting. I will look into why 2.3 does not offer the support as it was expected to", "> I downgrade the tensorflow_datasets from 3.2.1 to 3.1.0, then the issue is disappeared.\r\n\r\n@bzhaoopenstack , TFDS `3.2.0` was failing, but TFDS `3.2.1` should have been fixed. was it not the case ?", "Hi @Conchylicultor, I'm still seeing this issue with TFDS `3.2.1`. `3.1.0` works for me.", "@skye, could you try with `tfds-nightly` ? I believe this should be fixed.", "@Conchylicultor I tried `tfds-nightly` and I still got the same error", "Could you print `tf.__version__`, `tfds.__version__` and share the stacktrace you're getting ?", "```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\nimport tensorflow_datasets as tfds\r\nprint(\"Tensorflow version \",tf.__version__)\r\nprint(\"Tensorflow Datasets version \",tfds.__version__)\r\n\r\ndata=tfds.load(\"genomics_ood\",try_gcs=False)\r\nprint(data)\r\n```\r\n\r\n```\r\nTensorflow version  2.3.1\r\nTensorflow Datasets version  4.1.0\r\nDownloading and preparing dataset genomics_ood/0.0.1 (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\ganym\\tensorflow_datasets\\genomics_ood\\0.0.1...\r\n\r\n---------------------------------------------------------------------------\r\nUnimplementedError                        Traceback (most recent call last)\r\n<ipython-input-3-f49e96d26599> in <module>\r\n      6 print(\"Tensorflow Datasets version \",tfds.__version__)\r\n      7 \r\n----> 8 data=tfds.load(\"genomics_ood\",try_gcs=False)\r\n      9 print(data)\r\n\r\nF:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow_datasets\\core\\load.py in load(name, split, data_dir, batch_size, shuffle_files, download, as_supervised, decoders, read_config, with_info, builder_kwargs, download_and_prepare_kwargs, as_dataset_kwargs, try_gcs)\r\n    342   if download:\r\n    343     download_and_prepare_kwargs = download_and_prepare_kwargs or {}\r\n--> 344     dbuilder.download_and_prepare(**download_and_prepare_kwargs)\r\n    345 \r\n    346   if as_dataset_kwargs is None:\r\n\r\nF:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py in download_and_prepare(self, download_dir, download_config)\r\n    402           self._download_and_prepare(\r\n    403               dl_manager=dl_manager,\r\n--> 404               download_config=download_config,\r\n    405           )\r\n    406 \r\n\r\nF:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py in _download_and_prepare(self, dl_manager, download_config)\r\n   1080         optional_pipeline_kwargs = {}\r\n   1081       split_generators = self._split_generators(  # pylint: disable=unexpected-keyword-arg\r\n-> 1082           dl_manager, **optional_pipeline_kwargs\r\n   1083       )\r\n   1084       # TODO(tfds): Could be removed one all datasets are migrated.\r\n\r\nF:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow_datasets\\structured\\genomics_ood.py in _split_generators(self, dl_manager)\r\n    141   def _split_generators(self, dl_manager):\r\n    142     \"\"\"Returns SplitGenerators.\"\"\"\r\n--> 143     data_path = dl_manager.extract(_DATA_URL)\r\n    144     return [\r\n    145         tfds.core.SplitGenerator(\r\n\r\nF:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py in extract(self, path_or_paths)\r\n    642     # Add progress bar to follow the download state\r\n    643     with self._extractor.tqdm():\r\n--> 644       return _map_promise(self._extract, path_or_paths)\r\n    645 \r\n    646   def download_and_extract(self, url_or_urls):\r\n\r\nF:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py in _map_promise(map_fn, all_inputs)\r\n    702 def _map_promise(map_fn, all_inputs):\r\n    703   \"\"\"Map the function into each element and resolve the promise.\"\"\"\r\n--> 704   all_promises = tf.nest.map_structure(map_fn, all_inputs)  # Apply the function\r\n    705   res = tf.nest.map_structure(lambda p: p.get(), all_promises)  # Wait promises\r\n    706   return res\r\n\r\nF:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow\\python\\util\\nest.py in map_structure(func, *structure, **kwargs)\r\n    633 \r\n    634   return pack_sequence_as(\r\n--> 635       structure[0], [func(*x) for x in entries],\r\n    636       expand_composites=expand_composites)\r\n    637 \r\n\r\nF:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow\\python\\util\\nest.py in <listcomp>(.0)\r\n    633 \r\n    634   return pack_sequence_as(\r\n--> 635       structure[0], [func(*x) for x in entries],\r\n    636       expand_composites=expand_composites)\r\n    637 \r\n\r\nF:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow_datasets\\core\\utils\\py_utils.py in lock_decorated(*args, **kwargs)\r\n    529     def lock_decorated(*args, **kwargs):\r\n    530       with lock:\r\n--> 531         return fn(*args, **kwargs)\r\n    532 \r\n    533     return lock_decorated\r\n\r\nF:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py in _extract(self, resource)\r\n    556       resource = resource_lib.Resource(path=resource)\r\n    557     path = resource.path\r\n--> 558     extract_method = resource.extract_method\r\n    559     if extract_method == resource_lib.ExtractMethod.NO_EXTRACT:\r\n    560       logging.info('Skipping extraction for %s (method=NO_EXTRACT).', path)\r\n\r\nF:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow_datasets\\core\\download\\resource.py in extract_method(self)\r\n    316     if self._extract_method:\r\n    317       return self._extract_method\r\n--> 318     return get_extract_method(self.path)\r\n\r\nF:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow_datasets\\core\\download\\resource.py in get_extract_method(path)\r\n    277   \"\"\"Returns `ExtractMethod` to use on resource at path. Cannot be None.\"\"\"\r\n    278   info_path = _get_info_path(path)\r\n--> 279   info = _read_info(info_path)\r\n    280   fname = info.get('original_fname', path) if info else path\r\n    281   return _guess_extract_method(fname)\r\n\r\nF:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow_datasets\\core\\download\\resource.py in _read_info(info_path)\r\n    203 def _read_info(info_path) -> Json:\r\n    204   \"\"\"Returns info dict or None.\"\"\"\r\n--> 205   if not tf.io.gfile.exists(info_path):\r\n    206     return None\r\n    207   with tf.io.gfile.GFile(info_path) as info_f:\r\n\r\nF:\\Winpy\\python-3.7.2.amd64\\lib\\site-packages\\tensorflow\\python\\lib\\io\\file_io.py in file_exists_v2(path)\r\n    265   \"\"\"\r\n    266   try:\r\n--> 267     _pywrap_file_io.FileExists(compat.as_bytes(path))\r\n    268   except errors.NotFoundError:\r\n    269     return False\r\n\r\nUnimplementedError: File system scheme 'gs' not implemented (file: 'gs://tfds-data/downloads/genomics_ood/genomics_ood.zip.INFO')\r\n```", "I don't think GCS filesystem is compiled for Windows for TF 2.3.\r\n\r\nWe are planning to make filesystems modular (https://github.com/tensorflow/community/pull/101) but this will likely land in TF 2.5.\r\n\r\nTF 2.4 should contain work done over the summer as part of Google Summer of Code that would enable GCS filesystems on Windows", "Any update on GCS support for windows ?", "Error still persists :RuntimeError: UnimplementedError: Failed to construct dataset mnist: File system scheme 'gs' not implemented (file: 'gs://tfds-data/datasets\\mnist')\r\nwindows 10 ", "> Error still persists :RuntimeError: UnimplementedError\r\n\r\nCould you try with the last version of TFDS and TF ?", "You need to install `tensorflow-io` for the other filesystems. See #51583 for similar issue", "Hi @spamming4 ,Issue did not seem to replicate in TF 2.6 .I have changed \r\n\r\n> epochs=12 to  epochs=2 in model.fit() \r\n\r\noperation for sake of simplicity. Attaching [GIST ](https://colab.research.google.com/gist/mohantym/56029085d3eca407a2b92d4a64e0592b/github_38477.ipynb)for reference.", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38477\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38477\">No</a>\n"]}, {"number": 38476, "title": "ValueError: trainable_variables cannot be None. Given None", "body": "when i use model_fn and tf2.1\uff0c\r\nmy_head = tf.estimator.BinaryClassHead()\r\n  return my_head.EstimatorSpec(\r\n      features=features,\r\n      mode=mode,\r\n      labels=labels,\r\n      optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\r\n      logits=logits)\r\n\r\ni get: \r\nFile \"/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/head/base_head.py\", line 278, in create_estimator_spec\r\n    regularization_losses=regularization_losses))\r\n  File \"/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/head/binary_class_head.py\", line 513, in _create_tpu_estimator_spec\r\n    loss_reduction=self._loss_reduction)\r\n  File \"/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/head/base_head.py\", line 870, in create_estimator_spec_train_op\r\n    validate_trainable_variables(trainable_variables)\r\n  File \"/usr/local/anaconda3/lib/python3.7/site-packages/tensorflow_estimator/python/estimator/head/base_head.py\", line 636, in validate_trainable_variables\r\n    trainable_variables))\r\nValueError: trainable_variables cannot be None. Given None\r\n", "comments": ["@Jasperty In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!", "@Jasperty Any updates regarding this issue? Thanks!", "@Jasperty  Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38476\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38476\">No</a>\n"]}, {"number": 38475, "title": "tf.train.Server E0413...SO_REUSEPORT unavailable on compiling system", "body": "**System information** \r\n- OS Platform and Distribution:\r\nLinux Ubuntu 18.04.3 LTS\r\nNode0: Linux version 5.3.0-46-generic (buildd@lcy01-amd64-013) (gcc version 7.5.0 (Ubuntu 7.5.0-3ubuntu1~18.04))\r\nNode1:Linux version 5.6.3-050603-generic (kernel@kathleen) (gcc version 9.3.0 (Ubuntu 9.3.0-10ubuntu1))\r\n- TensorFlow installed from (source or\r\nbinary): 2.1.0  installed from conda\r\n- Python version: - Anaconda python 3.6.12\r\n- CUDA/cuDNN version: 10.2 \r\n- GPU model and memory: RTX 2080TI 11GB\r\n\r\n**Standalone code to reproduce the issue** \r\n```\r\n#Both Node0 & Node1:\r\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\r\nimport tensorflow.compat.v1 as tf\r\ntf.disable_v2_behavior()\r\ncluster_def = {'worker':['192.168.1.5:4448','192.168.1.2:4449']}\r\n\r\n#Node0-192.168.1.5:4448:\r\nserver = tf.train.Server(cluster_def, job_name='worker', task_index=0)\r\n\r\n#Node1-192.168.1.2:4449:\r\nserver = tf.train.Server(cluster_def, job_name='worker', task_index=1)\r\n```\r\n\r\n**Describe the expected behavior**\r\nOn Node1-192.168.1.2:4449, return:\r\nE0413 00:11:52.803623615    2266 socket_utils_common_posix.cc:198] check for SO_REUSEPORT: {\"created\":\"@1586707912.803602543\",\"description\":\"SO_REUSEPORT unavailable on compiling system\",\"file\":\"external/grpc/src/core/lib/iomgr/socket_utils_common_posix.cc\",\"file_line\":166}\r\n\r\nCould somebody give me a helping hand?\r\nThanks in advance.", "comments": ["@forhonourlx `tf.train.Server` doesn't exist in tensorflow 2.1 instead it is `tf.distribute.Server` as you can see [here](https://www.tensorflow.org/api_docs/python/tf/distribute/Server).", "Hi @gowthamkpr ,\r\nI have already blocked with `tf.disable_v2_behavior()`\r\nEven if I use V2 api`server = tf.distribute.Server(cluster_def, job_name='worker', task_index=1)`, I still get the same error on the later joined node:\r\n```\r\nE0414 09:10:05.285892363   10646 socket_utils_common_posix.cc:198] check for SO_REUSEPORT: {\"created\":\"@1586826605.285873543\",\"description\":\"SO_REUSEPORT unavailable on compiling system\",\"file\":\"external/grpc/src/core/lib/iomgr/socket_utils_common_posix.cc\",\"file_line\":166}\r\n```", "Your system does not have support for `SO_REUSEPORT` and thats the reason for the error. Please take a look at the source of the error [here](https://github.com/grpc/grpc/blob/c923f952946d2586e87ffc91f7edaa9b248f413d/src/core/lib/iomgr/socket_utils_common_posix.cc#L189).", "Hi @gowthamkpr @amahendrakar ,\r\nThank you for your reply, and I need some further help.\r\nIt was said that Linux kernel >3.9 supports `SO_REUSEPORT` feature.\r\nMy testing system is:\r\n```\r\nLinux Ubuntu 18.04.3 LTS\r\nNode0: Linux version 5.3.0-46-generic (buildd@lcy01-amd64-013) (gcc version 7.5.0 (Ubuntu 7.5.0-3ubuntu1~18.04))\r\nNode1:Linux version 5.6.3-050603-generic (kernel@kathleen) (gcc version 9.3.0 (Ubuntu 9.3.0-10ubuntu1))\r\n```\r\nAnd there is truely `#define SO_REUSEPORT 15` in `/usr/include/asm-generic/socket.h`\r\n\r\nSo what is the way to use `tf.distribute` on `Ubuntu`? (same error on `MultiWorkerMirroredStrategy`)\r\n(Or is there any way to skip `check for SO_REUSEPORT`?)\r\n\r\nThanks in advance,\r\nSimon\r\n", "@forhonourlx Were you able to resolve this issue or are you still facing it? ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing this issue as it has been inactive for a long time. Please add additional comments for us to open this issue again. Thanks!", "I found this issue occurs after I edited xorg.conf. I'm on PopOS. \r\n\r\nI opened a bug with Android Studio at https://issuetracker.google.com/issues/164794508\r\n"]}, {"number": 38474, "title": "Embedding a preprocessing function inside a tf.keras model for serving", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): **Colab**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device: \r\n- TensorFlow installed from (source or\r\nbinary): - TensorFlow version (use command below): \r\n- Python version: - Bazel\r\nversion (if compiling from source):\r\n- GCC/Compiler version (if compiling from\r\nsource): \r\n- CUDA/cuDNN version: - GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nI am trying to embed a simple image preprocessing function inside an already trained `tf.keras` model. This is a useful feature to have because it can help us reduce a lot of boilerplate code needed while using any model for serving purposes. With this capability, you get a lot more flexibility and modularity to your model.\r\n\r\nSo after training my model, I am first defining a preprocessing function like so - \r\n\r\n```python\r\ndef preprocess_image_cv2(image_path):\r\n    img = cv2.imread(image_path)\r\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\r\n    img = cv2.resize(img, (28, 28)).astype(\"float32\")\r\n    img = img / 255\r\n    img = np.expand_dims(img, 0)\r\n    img = tf.convert_to_tensor(img)\r\n    return img\r\n```\r\n\r\nI am then using it to create another model class along with the trained model - \r\n\r\n```python\r\n# Define the model for predcition purpose\r\nclass ExportModel(tf.keras.Model):\r\n    def __init__(self, preproc_func, model):\r\n        super().__init__(self)\r\n        self.preproc_func = preproc_func\r\n        self.model = model\r\n\r\n    @tf.function\r\n    def my_serve(self, image_path):\r\n        print(\"Inside\")\r\n        preprocessed_image = self.preproc_func(image_path) # Preprocessing\r\n        probabilities = self.model(preprocessed_image, training=False) # Model prediction\r\n        class_id = tf.argmax(probabilities[0], axis=-1) # Postprocessing\r\n        return {\"class_index\": class_id}\r\n```\r\n\r\nI am then able to run inference on a sample image with this setting:\r\n\r\n```python\r\n# Now initialize a dummy model and fill its parameters with that of\r\n# the model we trained\r\nrestored_model = get_training_model()\r\nrestored_model.set_weights(apparel_model.get_weights())\r\n\r\n# Now use this model, preprocessing function, and the same image\r\n# for checking if everything is working\r\nserving_model = ExportModel(preprocess_image_cv2, restored_model)\r\nclass_index = serving_model.my_serve(\"sample_image.png\")\r\nCLASSES[class_index[\"class_index\"].numpy()] # prints Dress\r\n```\r\n\r\nBut I am unable to export this model for serving. I am doing the following for exporting - \r\n\r\n```python\r\n# Make sure we are *not* letting the model to train\r\ntf.keras.backend.set_learning_phase(0)\r\n\r\n# Serialize model\r\nexport_path = \"model_preprocessing_func\"\r\ntf.saved_model.save(serving_model, export_path, signatures={\"serving_default\": serving_model.my_serve})\r\n```\r\n\r\nThis yields - \r\n\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-97-9e2616e04da9> in <module>()\r\n      1 export_path = \"model_preprocessing_func\"\r\n----> 2 tf.saved_model.save(serving_model, export_path, signatures={\"serving_default\": serving_model.my_serve})\r\n\r\n2 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py in save(obj, export_dir, signatures, options)\r\n    949 \r\n    950   _, exported_graph, object_saver, asset_info = _build_meta_graph(\r\n--> 951       obj, export_dir, signatures, options, meta_graph_def)\r\n    952   saved_model.saved_model_schema_version = constants.SAVED_MODEL_SCHEMA_VERSION\r\n    953 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/save.py in _build_meta_graph(obj, export_dir, signatures, options, meta_graph_def)\r\n   1009 \r\n   1010   signatures, wrapped_functions = (\r\n-> 1011       signature_serialization.canonicalize_signatures(signatures))\r\n   1012   signature_serialization.validate_saveable_view(checkpoint_graph_view)\r\n   1013   signature_map = signature_serialization.create_signature_map(signatures)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/signature_serialization.py in canonicalize_signatures(signatures)\r\n    110           (\"Expected a TensorFlow function to generate a signature for, but \"\r\n    111            \"got {}. Only `tf.functions` with an input signature or \"\r\n--> 112            \"concrete functions can be used as a signature.\").format(function))\r\n    113 \r\n    114     wrapped_functions[original_function] = signature_function = (\r\n\r\nValueError: Expected a TensorFlow function to generate a signature for, but got <tensorflow.python.eager.def_function.Function object at 0x7fd5b646ea58>. Only `tf.functions` with an input signature or concrete functions can be used as a signature.\r\n```\r\n\r\nI am able to interpret the last part of the error but I am unable to figure out what steps should I take to resolve it.\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue** \r\nOne can reproduce the issue with this [Colab Notebook][1]. Help is appreciated. \r\n\r\n\r\n  [1]: https://colab.research.google.com/drive/1QuJ7MLgtgNtJ7E_r4gpCokNxukNxay1O\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["I was able to reproduce the issue with Tf 2.2rc2. \r\nPlease find the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/f3a2b12faf72261fccc1367fe10450af/untitled501.ipynb). Thanks!", "@sayakpaul You are not providing the right input signature, so saving the model is not possible. The signature that you are providing `serving_model.my_serve` doesn't have any input signature or neither its a concrete function\r\nThe input signature should contain tensorinfo(name, dtype and tensor shape) but not in this case , hence the reason for your error.", "@gowthamkpr could you provide a minimal working example?", "@sayakpaul\r\n\r\n@tf.function\r\n--->\r\n@tf.function(input_signature=[tf.TensorSpec(shape=[None], dtype=tf.string)])", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38474\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38474\">No</a>\n", "Hi, @sayakpaul could you resolve this only by adding an input signature? I am trying to do almost the same, but I can't access the python string from inside the `tf.function`. I have tried the following:\r\n\r\n- **Send the picture path as a `tf.string` tensor and run `.eval()`** on it. It did not work because when running `.eval()` with the function input, it asks for a \"feed_dict for the placeholder\", so I guess TF creates a placeholder according the input signature and is that what we can access from inside the `tf.function`, not the tensor we forward (which is a constant and should return the path in bytes, so it could be decoded in a python string with `.decode('utf-8')`.\r\n\r\n- **Using the path of the image as the name of the tensor I forward to the `tf.function`** (i.e. `image_path_tensor = tf.constant('test_images/IMG_1097.JPG', dtype=tf.string, name='test_images/IMG_1097.JPG')`). Again, since I can not (or do not know how to) access the tensor I input from inside the `tf.function`, I could not just run `input.name` and get the path from there.\r\n\r\nIs there another way I can use `SavedModel` to store the inferrence and some other python processing to be able to run it without a Python interpreter? As, for example, with TF C++?", "@jmtc7 here's what I ended up with: https://sayak.dev/tf.keras/preprocessing/2020/04/13/embedding-image-preprocessing-functions.html"]}, {"number": 38473, "title": "tf.data.Dataset.map() uses only 1 cpu", "body": "**System information** \r\n- Have I written custom code: No\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: v2.2.0-rc1-34-ge6e5d6df2a 2.2.0-rc2\r\n- Python version: 3.7.5\r\n- CUDA/cuDNN version: 10.1.1/7.6.5\r\n- GPU model and memory: GTX 1080 Ti.\r\n\r\n**Describe the current behavior**\r\nWhen checking with the `top` command during training, only 1 CPU is used.\r\n\r\n**Describe the expected behavior**\r\nMultiple CPUs should be used.\r\n\r\n**Standalone code to reproduce the issue** \r\n\r\nYou can take the code from the [official TensorFlow tutorial on image segmentation](https://www.tensorflow.org/tutorials/images/segmentation).\r\n\r\nFor a more convincing experiment, replace the two lines:\r\n\r\n```python\r\ntrain = dataset['train'].map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\ntest = dataset['test'].map(load_image_test)\r\n```\r\n\r\nwith e.g.\r\n\r\n```python\r\ntrain = dataset['train'].map(load_image_train, num_parallel_calls=4)\r\ntest = dataset['test'].map(load_image_test, num_parallel_calls=4)\r\n```\r\n", "comments": ["`tf.data.Dataset.map` with `num_parallel_calls` is known to execute computation in parallel and the instructions provided here are not sufficient to reproduce the issue. \r\n\r\nPlease provide a minimal example that can be used to reproduce the issue. As a side note, instead of using `top`, I recommend using `sar` to measure CPU utilization.", "@jsimsa I can certainly provide a stand-alone script for that, but just to make sure I didn't get it right:\r\n\r\n1. In TensorFlow: `top` shows only 1 process, but `htop` shows multiple threads.\r\n2. In PyTorch, `top` shows multiple processes for the same training.\r\n\r\nSo, I guess `tf.data.Dataset.map` also does it in parallel, but by using threads instead of different processes? Sorry if the question is stupid, I am not so familiar with these things.", "tf.data indeed uses multi-threading as it has lower overhead compared to multi-processing.", "@jsimsa Thanks for the confirmation. Let me close this issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38473\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38473\">No</a>\n"]}, {"number": 38472, "title": "perfer python3 to compile", "body": "`which python` may direct to python2. make `which python3` ahead of `which python` may be better.", "comments": []}, {"number": 38471, "title": "How can one apply an arbitrary function to a dataset?", "body": "Is there anything similar to pandas' `.apply()` or `.map()` that could apply arbitrary functions on TensorFlow datasets in an efficient (i.e., vectorized) manner? \r\n\r\n## Minimum working example\r\n\r\nConsider the following code.\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\ndef compute_length(x): \r\n    return tf.strings.length(x)\r\n\r\ndef check_substring(x, substring):\r\n    return substring in x\r\n\r\ndef compute_palindrome(x):\r\n    return ''.join([x[-i] for i in range(-len(x)+1, 1)])\r\n    \r\nds = tf.data.Dataset.from_tensor_slices([\"Ottawa\", \"Stockholm\", \"Rabat\"])\r\n\r\nds = ds.map(\r\n    lambda city: (city, \r\n                  compute_length(city), \r\n#                  check_substring(city, \"lm\"),\r\n#                  compute_palindrome(city),\r\n                  ),\r\n        )\r\n\r\nnum_elems = len(ds.element_spec)\r\nfor elem in ds:\r\n    print(''.join([f\"{elem[i]}\" for i in range(num_elems)]))\r\n```\r\n\r\n## Issues\r\n\r\n`compute_length()` works fine and returns\r\n```\r\nb'Ottawa'6\r\nb'Stockholm'9\r\nb'Rabat'5\r\n```\r\n\r\nHowever, commenting out `check_subsring()` returns \r\n\r\n> OperatorNotAllowedInGraphError: iterating over `tf.Tensor` is not allowed: AutoGraph is disabled in this function. Try decorating it directly with @tf.function.\r\n\r\nand commenting out `compute_palindrome()` returns \r\n\r\n> TypeError: len is not well defined for symbolic Tensors. (args_0:0) Please call `x.shape` rather than `len(x)` for shape information.\r\n\r\nUnlike a simple `apply()` or `map()` in pandas, there is clearly some extra steps needed to apply such operations on Tensors. The documentation for what those steps are isn't easy to find. \r\n\r\nPS: The use of TensorFlow's `map()` isn't required. Whatever does the job is welcome.\r\n\r\n## URL(s) with the issue:\r\n\r\nThis pertains to either \r\nhttps://www.tensorflow.org/api_docs/python/tf/data/Dataset#map or\r\nhttps://www.tensorflow.org/api_docs/python/tf/map_fn", "comments": ["Please use \r\n```\r\nimport tensorflow as tf\r\n\r\ntf.enable_eager_execution()\r\n\r\n\r\ndef compute_length(x): \r\n    return tf.strings.length(x)\r\n\r\ndef check_substring(x, substring):\r\n    return tf.strings.regex_full_match(x,substring)\r\n\r\n\r\ndef compute_palindrome(x):\r\n    char = tf.string_split([x], delimiter=\"\",result_type=\"RaggedTensor\")\r\n    reverse = tf.reverse(char.values,[0])\r\n    join = tf.strings.reduce_join(reverse,separator=\"\")\r\n    return join \r\n    \r\nds = tf.data.Dataset.from_tensor_slices([\"Ottawa\", \"Stockholm\", \"Rabat\"])\r\n\r\nds = ds.map(\r\n    lambda city: (city, \r\n                  compute_length(city), \r\n                  check_substring(city, \".*lm.*\"),\r\n                  compute_palindrome(city),\r\n                  ),\r\n        )\r\n\r\nnum_elems = len(ds.element_spec)\r\nfor elem in ds:\r\n   print(''.join([f\"{elem[i]}\" for i in range(num_elems)]))\r\n```\r\nbelow is the working code , also the issue was you were using python functions not TF API to do the conversion. \r\n\r\nTo do everything more vectorized without writing python function i would recommend using vector operations. \r\n\r\n", "@ravikyram  does my respond answer the question ? , Also is there any gist or doc i can write for this ? ", "Thanks, I now see how one should use the TensorFlow API instead of plain Python code. That said, I'm afraid your code does not work _as is_ with TensorFlow 2.0.0 and Python 3.7.4. Below are the errors that came up\r\n\r\n1. `AttributeError: module 'tensorflow' has no attribute 'enable_eager_execution'`\r\n2. `AttributeError: module 'tensorflow' has no attribute 'string_split`\r\n3. `TypeError: string_split_v2() got an unexpected keyword argument 'delimiter'`\r\n4. `TypeError: string_split_v2() got an unexpected keyword argument 'result_type'`\r\n\r\nand my attempts at solving them\r\n\r\n1. comment out `tf.enable_eager_execution()`.\r\n2. change `tf.string_split()` to `tf.strings.split()`\r\n3. change `delimiter` to `sep` in `tf.strings.split()`\r\n4. removed the `result_type` parameter in `tf.strings.split()`\r\n\r\nAfter all these changes, the output is \r\n\r\n> WARNING:tensorflow:Entity <function <lambda> at 0x000001D531AF4318> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: \r\n> WARNING: Entity <function <lambda> at 0x000001D531AF4318> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: \r\n> b'Ottawa'6Falseb'Ottawa'\r\n> b'Stockholm'9Trueb'Stockholm'\r\n> b'Rabat'5Falseb'Rabat'\r\n\r\nwhere `compute_palindrome()` does not seem to have accomplished its goal.\r\n", "@laghaout i tried in tf 1.15.x since no version was mention in your ticket . Things are different in tf2.0 , eager execution is enabled by default. \r\n\r\n Also based on your code `compute_palindrome` does reversing string . \r\n\r\nBelow is code for TF 2.0 \r\n\r\n```\r\nimport tensorflow as tf\r\n\r\n\r\n\r\ndef compute_length(x): \r\n    return tf.strings.length(x)\r\n\r\ndef check_substring(x, substring):\r\n    return tf.strings.regex_full_match(x,substring)\r\n\r\n\r\ndef compute_palindrome(x):\r\n    extra_split = tf.strings.bytes_split(x)\r\n    reverse = tf.reverse(extra_split,[0])\r\n    reversedStr = tf.strings.reduce_join([reverse])\r\n    return reversedStr\r\n    \r\nds = tf.data.Dataset.from_tensor_slices([\"Ottawa\", \"Stockholm\", \"Rabat\"])\r\n\r\nds = ds.map(\r\n    lambda city: (city, \r\n                  compute_length(city), \r\n                  check_substring(city, \".*lm.*\"),\r\n                  compute_palindrome(city),\r\n                  ),\r\n        )\r\n\r\nnum_elems = len(ds.element_spec)\r\nfor elem in ds:\r\n   print(''.join([f\"{elem[i]}\" for i in range(num_elems)]))\r\n```\r\n \r\n@gowthamkpr  please let me know is there any gist or doc i can write for this ?", "@17patelumang You can make a colab gist of this [here](https://colab.sandbox.google.com/) and share the gist. Thanks!", "@gowthamkpr this is the gist - [gist](https://colab.research.google.com/drive/1gExuU2sCs6OeHtexI22srN7gAti9C9c4#scrollTo=8TvMWDmhlcSY)\r\n\r\nis there anything else which is needed ?", "Thanks @17patelumang \r\n@laghaout Please let me know if I can close the issue as the issue has been resolved.", "Yes, thank you."]}, {"number": 38470, "title": "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f70dfc46840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.", "body": "I have a problem while trying to do prediction by using LSTM...\r\nHere is a error code: \r\nWARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f70dfc46840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\r\nHowever, anyway I have a prediction even though there is error code above.\r\nIs there any solution with this problem? I used Colab gpu for this test. Here is my code.... \r\n<img width=\"1178\" alt=\"\u1109\u1173\u110f\u1173\u1105\u1175\u11ab\u1109\u1163\u11ba 2020-04-12 \u110b\u1169\u1112\u116e 10 17 56\" src=\"https://user-images.githubusercontent.com/48937254/79069726-776d8580-7d0b-11ea-8fc2-e9749755d9fc.png\">\r\n<img width=\"1295\" alt=\"\u1109\u1173\u110f\u1173\u1105\u1175\u11ab\u1109\u1163\u11ba 2020-04-12 \u110b\u1169\u1112\u116e 10 18 15\" src=\"https://user-images.githubusercontent.com/48937254/79069733-82c0b100-7d0b-11ea-8eaf-18bd45886f37.png\">\r\n", "comments": ["@aeddung,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the TensorFlow version you are using. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "> @aeddung,\r\n> In order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the TensorFlow version you are using. Thanks!\r\n\r\nAny updates regarding this issue? Thanks!\r\n", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 38468, "title": "tensorflow problems", "body": "System Information:\r\n- Windows 7\r\n- TensorFlow installed via pip\r\n- Python version: 3.8.2\r\n\r\nCode:\r\nfrom keras.models import Sequential\r\n\r\nError: \r\nUsing TensorFlow backend.\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\HP\\Desktop\\chatbot\\train_chatbot.py\", line 8, in <module>\r\n    from keras.models import Sequential\r\n  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\r\n    from . import utils\r\n  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\r\n    from . import conv_utils\r\n  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\r\n    from .. import backend as K\r\n  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\backend\\__init__.py\", line 1, in <module>\r\n    from .load_backend import epsilon\r\n  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\backend\\load_backend.py\", line 90, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\__init__.py\", line 41, in <module>\r\n    from tensorflow.python.tools import module_util as _module_util\r\n  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 50, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 30, in <module>\r\n    self_check.preload_check()\r\n  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tensorflow\\python\\platform\\self_check.py\", line 53, in preload_check\r\n    raise ImportError(\r\nImportError: Could not find the DLL(s) 'msvcp140_1.dll'. TensorFlow requires that these DLLs be installed in a directory that is named in your %PATH% environment variable. You may install these DLLs by downloading \"Microsoft C++ Redistributable for Visual Studio 2015, 2017 and 2019\" for your platform from this URL: https://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads\r\n", "comments": ["@Alankriti44, It is due to installation problem. Install the DLL as in the error message.", "@Alankriti44 \r\nplease follow [this comment](https://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156) and below mentioned issues to resolve.\r\n\r\n#35749 #38262 ##37906\r\n\r\n\r\nAlso please let us know what tensorflow version are you facing the error on.", "Closing as the issue is that %PATH% is not updated to contain the needed libraries, thus not a TF issue", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38468\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38468\">No</a>\n"]}, {"number": 38467, "title": "Added a warning note in tf.where documentation for 'NaN' gradient issue with workaround", "body": "This is to solve the issue `nan` gradient when `tf.where` is used #38349", "comments": ["@anorak-k Can you please address Ubuntu Sanity errors? Thanks!", "@alextp Sorry, again for some reason I couldn't run the sanity on my local it just gets stuck in step 2. Have fixed the issues. Should run fine now. ", "@alextp The sanity passed but was failing in Ubuntu CPU build. Now fixed the bug. I am new to this. Apologies and thank you for your patience.", "@anorak-k no need to thank me for patience; our testing infra is very flaky and slow and we should be apologizing :-)", "@alextp is there a way to run all these checks in my local before I push my change. That way it is much more easier.", "I wish...\n\nOn Fri, Apr 17, 2020 at 8:54 AM Maadesh Sivakumar <notifications@github.com>\nwrote:\n\n> @alextp <https://github.com/alextp> is there a way to run all these\n> checks in my local before I push my change. That way it is much more easier.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/38467#issuecomment-615323660>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AAABHRIAKBMCRIBOAF63J7DRNB3SFANCNFSM4MGJVUIQ>\n> .\n>\n\n\n-- \n - Alex\n", "@anorak-k Any update on this PR? Thanks!", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!", "Can i revive it and resolve if someone isn't?"]}, {"number": 38466, "title": "Added a warning note in tf.where documentation for 'NaN' gradient issue #38349", "body": "", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F38466) for more info**.\n\n<!-- need_author_cla -->", "@googlebot I fixed it.", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F38466) for more info**.\n\n<!-- ok -->"]}, {"number": 38465, "title": "ValueError specifying TensorSpec names while using model.save", "body": "**System information** \r\n- Custom code has been written to define the model, and is given\r\n- OS Platform and Distribution: Linux Ubuntu 19.10: \r\n- TensorFlow installed via pip\r\n- TensorFlow versions 2.1.0 & 2.2.0.dev20200411 trialed\r\n- Python version: 3.7\r\n\r\n**Describe the current behavior**\r\nAttempting to use model.save() to save a trained model, raises the eventual error \r\n`ValueError: If specifying TensorSpec names for nested structures, either zero or all names have to be specified.`\r\nCode also raises the error while failing to save\r\n`WARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7efb5076e0e0> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: Bad argument number for Name: 4, expecting 3`\r\nAnother error that visible in the output is the failed conversion to JSON of a tf_graphics layer. This has been raised in the tensorflow_graphics repository\r\n\r\n**Describe the expected behaviour**\r\nUnsure - error was asked to be raised to TensorFlow team by the error text.\r\n\r\n**Standalone code to reproduce the issue** \r\nIn comment below\r\n\r\n**Current Code output**\r\n```\r\nWARNING:tensorflow:AutoGraph could not transform <bound method FeatureSteeredConvolutionKerasLayer.call of <tensorflow_graphics.nn.layer.graph_convolution.FeatureSteeredConvolutionKerasLayer object at 0x7efb9617c790>> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: module 'gast' has no attribute 'Constant'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nModel: \"MyFirstGraphModel\"\r\n__________________________________________________________________________________________________\r\nLayer (type)                    Output Shape         Param #     Connected to                     \r\n==================================================================================================\r\ninput_1 (InputLayer)            [(None, 100, 3)]     0                                            \r\n__________________________________________________________________________________________________\r\nconv1d (Conv1D)                 (None, 100, 2)       8           input_1[0][0]                    \r\n__________________________________________________________________________________________________\r\ninput_2 (InputLayer)            [(None, 100, 100)]   0                                            \r\n__________________________________________________________________________________________________\r\ninput_3 (InputLayer)            [(None,)]            0                                            \r\n__________________________________________________________________________________________________\r\nfeature_steered_convolution_ker (None, 100, 32)      584         conv1d[0][0]                     \r\n                                                                 input_2[0][0]                    \r\n__________________________________________________________________________________________________\r\nre_lu (ReLU)                    (None, 100, 32)      0           feature_steered_convolution_keras\r\n__________________________________________________________________________________________________\r\nfeature_steered_convolution_ker (None, 100, 64)      16968       re_lu[0][0]                      \r\n                                                                 input_2[0][0]                    \r\n__________________________________________________________________________________________________\r\nre_lu_1 (ReLU)                  (None, 100, 64)      0           feature_steered_convolution_keras\r\n__________________________________________________________________________________________________\r\nfeature_steered_convolution_ker (None, 100, 128)     66696       re_lu_1[0][0]                    \r\n                                                                 input_2[0][0]                    \r\n__________________________________________________________________________________________________\r\nre_lu_2 (ReLU)                  (None, 100, 128)     0           feature_steered_convolution_keras\r\n__________________________________________________________________________________________________\r\nconv1d_1 (Conv1D)               (None, 100, 256)     33024       re_lu_2[0][0]                    \r\n__________________________________________________________________________________________________\r\nconv1d_2 (Conv1D)               (None, 100, 1)       257         conv1d_1[0][0]                   \r\n==================================================================================================\r\nTotal params: 117,537\r\nTrainable params: 117,537\r\nNon-trainable params: 0\r\n__________________________________________________________________________________________________\r\nWARNING:tensorflow:AutoGraph could not transform <function tf_record_to_dataset.<locals>.<lambda> at 0x7efb9450be60> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: module 'gast' has no attribute 'Constant'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nWARNING:tensorflow:AutoGraph could not transform <function tf_record_to_dataset.<locals>.<lambda> at 0x7efb9448ab00> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: module 'gast' has no attribute 'Constant'\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\n2020-04-12 15:51:25.362023: I tensorflow/core/profiler/lib/profiler_session.cc:154] Profiler session started.\r\n2020-04-12 15:51:25.362060: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1372] Profiler found 1 GPUs\r\n2020-04-12 15:51:25.362157: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcupti.so.10.1'; dlerror: libcupti.so.10.1: cannot open shared object file: No such file or directory\r\n2020-04-12 15:51:25.362163: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1419] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\r\n2020-04-12 15:51:25.362167: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1458] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI could not be loaded or symbol could not be found.\r\n2020-04-12 15:51:25.362175: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1441] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI could not be loaded or symbol could not be found.\r\n2020-04-12 15:51:25.362203: I tensorflow/core/profiler/lib/profiler_session.cc:154] Profiler session started.\r\n2020-04-12 15:51:25.362208: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1419] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\r\n2020-04-12 15:51:25.362211: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1458] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI could not be loaded or symbol could not be found.\r\n2020-04-12 15:51:25.362216: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1441] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI could not be loaded or symbol could not be found.\r\nWARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer FeatureSteeredConvolutionKerasLayer has arguments in `__init__` and therefore must override `get_config`.\r\nWARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x7efb944d2560> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: Bad argument number for Name: 4, expecting 3\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\n/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/framework/indexed_slices.py:430: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\r\n  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\r\n2020-04-12 15:51:27.041239: I tensorflow/core/profiler/lib/profiler_session.cc:154] Profiler session started.\r\n2020-04-12 15:51:27.041279: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1419] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\r\n2020-04-12 15:51:27.041288: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1458] function cupti_interface_->ActivityRegisterCallbacks( AllocCuptiActivityBuffer, FreeCuptiActivityBuffer)failed with error CUPTI could not be loaded or symbol could not be found.\r\nWARNING:tensorflow:From /home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1271: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\r\nInstructions for updating:\r\nuse `tf.profiler.experimental.stop` instead.\r\n2020-04-12 15:51:27.046579: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1441] function cupti_interface_->EnableCallback( 0 , subscriber_, CUPTI_CB_DOMAIN_DRIVER_API, cbid)failed with error CUPTI could not be loaded or symbol could not be found.\r\n2020-04-12 15:51:27.049348: I tensorflow/core/profiler/internal/gpu/device_tracer.cc:217]  GpuTracer has collected 0 callback api events and 0 activity events.\r\n2020-04-12 15:51:27.054982: I tensorflow/core/profiler/rpc/client/save_profile.cc:168] Creating directory: logs/fit/20200412-155125/train/plugins/profile/2020_04_12_15_51_27\r\n      1/Unknown - 0s 81us/step - loss: 0.3479 - acc: 0.69002020-04-12 15:51:27.059084: I tensorflow/core/profiler/rpc/client/save_profile.cc:174] Dumped gzipped tool data for trace.json.gz to logs/fit/20200412-155125/train/plugins/profile/2020_04_12_15_51_27/robin-System-Product-Name.trace.json.gz\r\n2020-04-12 15:51:27.061354: I tensorflow/core/profiler/utils/event_span.cc:288] Generation of step-events took 0 ms\r\n\r\n2020-04-12 15:51:27.063255: I tensorflow/python/profiler/internal/profiler_wrapper.cc:91] Creating directory: logs/fit/20200412-155125/train/plugins/profile/2020_04_12_15_51_27Dumped tool data for overview_page.pb to logs/fit/20200412-155125/train/plugins/profile/2020_04_12_15_51_27/robin-System-Product-Name.overview_page.pb\r\nDumped tool data for input_pipeline.pb to logs/fit/20200412-155125/train/plugins/profile/2020_04_12_15_51_27/robin-System-Product-Name.input_pipeline.pb\r\nDumped tool data for tensorflow_stats.pb to logs/fit/20200412-155125/train/plugins/profile/2020_04_12_15_51_27/robin-System-Product-Name.tensorflow_stats.pb\r\nDumped tool data for kernel_stats.pb to logs/fit/20200412-155125/train/plugins/profile/2020_04_12_15_51_27/robin-System-Product-Name.kernel_stats.pb\r\n\r\n    628/Unknown - 2s 3ms/step - loss: 0.3358 - acc: 0.6680WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x7efb602a50e0> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: Bad argument number for Name: 4, expecting 3\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\n640/640 [==============================] - 2s 4ms/step - loss: 0.3356 - acc: 0.6681 - val_loss: 0.3316 - val_acc: 0.6689\r\n2020-04-12 15:51:30.035679: W tensorflow/python/util/util.cc:329] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\r\nWARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7efb5076e0e0> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: Bad argument number for Name: 4, expecting 3\r\nTo silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\r\nTraceback (most recent call last):\r\n  File \"/home/robin/Masters/Robin-Graph-NN-Pose-from-Model/Examples/graph_network_model.py\", line 68, in <module>\r\n    model.save('./test/model_dir')\r\n  File \"/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\", line 1062, in save\r\n    signatures, options)\r\n  File \"/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py\", line 134, in save_model\r\n    signatures, options)\r\n  File \"/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/save.py\", line 78, in save\r\n    save_lib.save(model, filepath, signatures, options)\r\n  File \"/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py\", line 951, in save\r\n    obj, export_dir, signatures, options, meta_graph_def)\r\n  File \"/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py\", line 1024, in _build_meta_graph\r\n    _ = _SaveableView(checkpoint_graph_view)\r\n  File \"/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/saved_model/save.py\", line 204, in __init__\r\n    function._list_all_concrete_functions_for_serialization())  # pylint: disable=protected-access\r\n  File \"/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 882, in _list_all_concrete_functions_for_serialization\r\n    concrete_functions.append(self.get_concrete_function(*args, **kwargs))\r\n  File \"/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py\", line 546, in get_concrete_function\r\n    self.call_collection.add_trace(*args, **kwargs)\r\n  File \"/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py\", line 418, in add_trace\r\n    trace_with_training(True)\r\n  File \"/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py\", line 416, in trace_with_training\r\n    fn.get_concrete_function(*args, **kwargs)\r\n  File \"/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/keras/saving/saved_model/save_impl.py\", line 547, in get_concrete_function\r\n    return super(LayerCall, self).get_concrete_function(*args, **kwargs)\r\n  File \"/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 1000, in get_concrete_function\r\n    concrete = self._get_concrete_function_garbage_collected(*args, **kwargs)\r\n  File \"/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 918, in _get_concrete_function_garbage_collected\r\n    *args, **kwargs)\r\n  File \"/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2497, in _get_concrete_function_garbage_collected\r\n    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n  File \"/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2775, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2665, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 898, in func_graph_from_py_func\r\n    args, arg_names, flat_shapes=arg_shapes)\r\n  File \"/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 1134, in _get_defun_inputs_from_args\r\n    args, names, structure=args, flat_shapes=flat_shapes)\r\n  File \"/home/robin/anaconda3/envs/Robin-Graph-NN-Pose-from-Model/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 1198, in _get_defun_inputs\r\n    raise ValueError(\"If specifying TensorSpec names for nested structures, \"\r\nValueError: If specifying TensorSpec names for nested structures, either zero or all names have to be specified.\r\n\r\n```\r\n", "comments": ["Attached is the dataset with which this error was raised.\r\nApologies for the initial long code!\r\n[Minimal_code.zip](https://github.com/tensorflow/tensorflow/files/4465842/Minimal_code.zip)\r\n[Dataset1.zip](https://github.com/tensorflow/tensorflow/files/4465837/Dataset1.zip)\r\n\r\nRemoving the Tensorflow_Graphics components does allow the model to save, but still raises\r\n```\r\nWARNING:tensorflow:AutoGraph could not transform <function canonicalize_signatures.<locals>.signature_wrapper at 0x7efb5076e0e0> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: Bad argument number for Name: 4, expecting 3\r\n``` \r\nWhen saving", "@rlav440 \r\n\r\nLooks like code is incomplete. I am seeing the error `ModuleNotFoundError: No module named 'tensorflow_graphics'`. Please, help us with colab link or simple standalone code to reproduce the issue in our environment. It helps us in localizing the issue faster. Thanks!", "@ravikyram \r\nThat's the tensorflow graphics api from:\r\nhttps://github.com/tensorflow/graphics - a newer API for tensorflow.\r\nPlease note I build that by pulling from source (git link above) as there is currently a bug in the released pypi repository ver.\r\n\r\nAs I mentioned above, the model does save without the tensorflow graphics API components(I've raised an issue on that repository as well) but it still raises the same `Warnings:AutoGraph could not transform` so I have left this issue open with the reason it specifically requests the issue be reported.\r\n\r\n\r\n\r\n\r\n", "@rlav440 This is similar to the issue [here](https://github.com/tensorflow/graphics/issues/227).  As mentioned in the issue, Removing the graph convolution layers allows the model to save.\r\n\r\nPlease take a look at it.\r\n", "Hi @gowthamkpr That is the issue that I mentioned posting. Upon looking at the first post, I believe I could have been clearer so have edited the first post to reflect the current nature of the issue", "I have run into the same error on a model built using the keras functional API. In particular, the error occurs when saving a checkpoint by calling `tfk.models.save_model`. My model takes two inputs (using the `tf.data` API), one of which is a `tf.RaggedTensor` and the other of which is a `tf.Tensor`. \r\n\r\nA `tf.RaggedTensorSpec` doesn't have a `name` attribute and at some point the `tf.RaggedTensorSpec` is converted by TF into several `tf.TensorSpec`s, which therefore also don't have values for their `name` attributes.\r\n\r\nThe error does not occur when saving a weights-only checkpoint with `tfk.Model.save_weights`.", "I filed #40373 separately and was referred to this as a duplicate. It seems like there's not a standalone reproducer listed here yet. Here's the one using `SparseTensor` from that issue:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nclass SqueezedSparseConversion(tf.keras.layers.Layer):\r\n    def call(self, inputs):\r\n        return tf.SparseTensor([(0, 1)], [0.1], (3, 3))\r\n\r\nclass GraphConvolution(tf.keras.layers.Layer):\r\n    def call(self, inputs):\r\n        return inputs[0]\r\n\r\nx_t = tf.keras.Input(0)\r\nsp = SqueezedSparseConversion()(x_t)\r\nout = GraphConvolution()([x_t, sp])\r\n\r\nm = tf.keras.Model([x_t], out)\r\nm.summary()\r\nm.save(\"\")\r\n```\r\n\r\nColab link: https://colab.research.google.com/gist/Saduf2019/56d0bb4e22fe010dbd150c6a8def9a54/untitled.ipynb\r\n\r\nAs I mentioned on the issue above, a helpful improvement here (potentially an easier stepping stone, before fixing the whole issue) would be to add more info to the error message, such as which layer(s) are causing the problem, to make it easier to narrow down the problem layers in a real-world model.", "@huonw @rlav440 This issue has been fixed in tf-nightly. Please find the gist [here](https://colab.research.google.com/gist/gowthamkpr/02054044d39cd7986950ee10fa740b10/untitled.ipynb)", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "I tested this on our real code in https://github.com/stellargraph/stellargraph/pull/1689 and the tests in question passed, so I can confirm that this seems to be fixed for our particular example. Thanks!", "Closing this issue as it has been fixed in Nightly. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38465\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38465\">No</a>\n", "@gowthamkpr Do you have links to the PRs that fixed the issue? We are thinking of backporting the fixes to 2.2, and would love your help in finding the changes.", "@gowthamkpr can you help us locate the PR that fixes the issue?"]}, {"number": 38464, "title": "[Intel MKL] Enable remapper unit tests for CPU builds.", "body": "This PR enables remapper tests for CPU only builds also. In addition PR disables remapper tests for fusions that MKL DNN doesn't support.", "comments": ["I think @ezhulenev is a better reviewer because these are grappler changes.", "@ezhulenev  @penpornk .  New PR to solve this generically submitted https://github.com/tensorflow/tensorflow/pull/38553.  Closing this PR."]}, {"number": 38463, "title": "cannot set tf.Variable as model input", "body": "Tensorflow: 2.1.0\r\n\r\nI intend to utilize a pre-trained model and input a trainable input noise. but it is not allowed in tensorflow 2.0. want to find out whether it is a bug or by design.\r\n\r\n```python\r\ninit_value = tf.random.normal((1, 512, 512, 3))\r\nnoise_input = tf.Variable(init_value, trainable=True)\r\n\r\npretrained_vgg19 = tf.keras.applications.VGG19(include_top=False, input_shape=(512, 512, 3))\r\npretrained_vgg19.predict(noise_input)\r\n```\r\n![image](https://user-images.githubusercontent.com/731496/79059341-60974680-7cab-11ea-957c-6e57f5fc237c.png)\r\n", "comments": ["@w19787, `tf.Variable` is used for trainable variables such as weights (W) and biases (B) for your model. Tensor is given as input to model. Working code:\r\n```\r\nimport tensorflow as tf\r\ninit_value = tf.random.normal((1, 512, 512, 3))\r\npretrained_vgg19 = tf.keras.applications.VGG19(include_top=False, input_shape=(512, 512, 3))\r\npretrained_vgg19.predict(init_value)\r\n```", "> @w19787, `tf.Variable` is used for trainable variables such as weights (W) and biases (B) for your model. Tensor is given as input to model. Working code:\r\n> \r\n> ```\r\n> import tensorflow as tf\r\n> init_value = tf.random.normal((1, 512, 512, 3))\r\n> pretrained_vgg19 = tf.keras.applications.VGG19(include_top=False, input_shape=(512, 512, 3))\r\n> pretrained_vgg19.predict(init_value)\r\n> ```\r\n\r\nThe above code is working for normal predict case. but if we want to use pretrained vgg model to trained a noise input, it is not the solution(i.e photo style transfer solution). Actually, we expect the input tf.Variable to be trainable.  I believe in tensorflow 1.0, tf.Variable as model input can be trainable, but it seems that it is not the case in 2.0. ", "Was able to run the code without any issues with [TF v2.0](https://colab.research.google.com/gist/amahendrakar/e15e448f640f9d02fc65668d91e757c6/38463-2-0.ipynb). \r\n\r\nFacing an error stating `ValueError: Failed to find data adapter that can handle input: <class 'tensorflow.python.ops.resource_variable_ops.ResourceVariable'>, <class 'NoneType'>`, while running with [TF v2.1](https://colab.research.google.com/gist/amahendrakar/efa9fb1d2732e992d84e72346e525906/38463.ipynb#scrollTo=tceBD5eJyuT7) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/c1e12c2cdf4ca657eaadbd069323c0ff/38463-tf-nightly.ipynb). Please find the attached gist. Thanks!", "@w19787 Can you provide a reproducible case of tensorflow 1.0 showing tf.Variable as model input can be trainable. Thanks!", "> @w19787 Can you provide a reproducible case of tensorflow 1.0 showing tf.Variable as model input can be trainable. Thanks!\r\n\r\nYou can refer to the below project training file:\r\nhttps://github.com/LouieYang/deep-photo-styletransfer-tf/blob/master/photo_style.py\r\n\r\nthe line 228 create the input image as tf.Variable and line 291 to optimize/computing the gradients only on this input image. \r\nthanks in advance.", "I have tried in colab with TF version 2.3-rc1 and nightly versions(`2.4.0-dev20200709`) and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/67488abbfa79405c8687e7fb865bb7f2/untitled107.ipynb).Thanks!", "I have tried in colab with TF version 2.3.0, nightly version(`2.4.0-dev20200729`) and was able to reproduce the issue.Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/a0ccdab8ae5d0093753b7c84026b4741/untitled196.ipynb).Thanks!", "@w19787 Closing this issue since it was the intended behavior.Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38463\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38463\">No</a>\n"]}, {"number": 38461, "title": " AttributeError: module 'tensorflow' has no attribute 'variable_scope'", "body": "When I put this line of code in:\r\n\r\nmlpr = ANNR([input], layers, batchSize = 256, maxIter = 20000, tol = 0.2, reg = 1e-4, verbose = True)\r\n\r\nI get the following error:  AttributeError: module 'tensorflow' has no attribute 'variable_scope'\r\n\r\nI am using tensorflow version 2.1\r\n\r\nHow do I fix this?\r\n\r\nThanks in advance.", "comments": ["@dcv10, refer this [issue](https://github.com/datamllab/rlcard/issues/96).", "@khimraj I have but did not find it useful", "@dcv10, can you please share full code to reproduce issue.", "import numpy as np\r\nimport matplotlib.pyplot as mpl\r\nfrom sklearn.preprocessing import scale\r\nfrom TFANN import ANNR\r\nfrom google.colab import files\r\n\r\n#reads data from the file and ceates a matrix with only the dates and the prices \r\nstock_data = np.loadtxt('NSE-TATAGLOBAL12.csv', delimiter=\";\", skiprows=1, usecols=(1, 6))\r\nprint(stock_data)\r\n#scales the data to smaller values\r\nstock_data=scale(stock_data)\r\n# #gets the price and dates from the matrix\r\nprices = stock_data[:, 1].reshape(-1, 1)\r\ndates = stock_data[:, 0].reshape(-1, 1)\r\n#creates a plot of the data and then displays it\r\nmpl.plot(dates[:, 0], prices[:, 0])\r\nmpl.show()\r\n#Number of neurons in the input, output, and hidden layers\r\ninput = 1\r\noutput = 1\r\nhidden = 50\r\n#array of layers, 3 hidden and 1 output, along with the tanh activation function \r\nlayers = [('F', hidden), ('AF', 'tanh'), ('F', hidden), ('AF', 'tanh'), ('F', hidden), ('AF', 'tanh'), ('F', output)]\r\n#construct the model and dictate params\r\nmlpr = ANNR([input], layers, batchSize = 256, maxIter = 20000, tol = 0.2, reg = 1e-4, verbose = True)\r\n\r\n\r\n@khimraj here is the code", "@dcv10, you need tensorflow version less than 2.0 and I have successfully compiled your code and faced no issue. For your reference link of gist is [here](https://colab.research.google.com/gist/khimraj/e80cf5df026026ba6e93b3dc8947b5e2/mean.ipynb#scrollTo=ldUyF5UJb75D).", "@dcv10 \r\nplease update as per above comment", "I am using Tensorflow version 2.0 and I have the same error. The issue remains when using tf.compat.v1\r\nAny idea how to fix this without downgrading tensorflow? ", "@dcv10\r\nPlease update if this is still an issue", "I'm experiencing the same issue while following the exact same tutorial", "Same issue, can someone help\r\n", "same issue here also\r\n", "same issue here, anyone found a way on tf2 ?", "same issue here, anyone found a way on tf2 ?", "same issue here. ", "same issue here. Using TensorFlow 2 and don't wish to downgrade", "Changing tf.variables_initializer to tf.compat.v1.variables_initializer worked for me. I am using Tensorflow 2.3. ", "> \r\n> \r\n> Changing tf.variables_initializer to tf.compat.v1.variables_initializer worked for me. I am using Tensorflow 2.3.\r\n\r\nThis worked for me, thank you.", "> Changing tf.variables_initializer to tf.compat.v1.variables_initializer worked for me. I am using Tensorflow 2.3.\r\n\r\nwhere should I add this code? My original code is:\r\n```\r\nwith tf.variable_scope(name_or_scope=name, reuse=reuse):\r\n            ...\r\n```\r\n"]}, {"number": 38460, "title": "[1.14/1.15] TensorRT ConvertGraphDefToEngine SIGSEGV", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): NixOS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device:  N/A\r\n- TensorFlow installed from (source or\r\nbinary): Source\r\n- TensorFlow version (use command below): 1.14\r\n- Python version: 3.6.10\r\n- Bazel: v0.26.0\r\nversion (if compiling from source):\r\n- GCC/Compiler version (if compiling from\r\nsource): 0.9.2\r\n- CUDA/cuDNN version: 10.0.130/7.6.5.32\r\n- GPU model and memory: No GPU in the system/sandboxed environment\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nWhen making `tensorflow` to invoke TensorRT graph optimiser on the system without a GPU/inside a sandbox, `tensorflow` will segfault with a null dereference.\r\n\r\n<details>\r\n<summary>Log</summary>\r\n\r\n```\r\n2020-04-11 19:39:35.067438: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\r\n2020-04-11 19:39:35.069624: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\r\n2020-04-11 19:39:35.069654: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (shirobox): /proc/driver/nvidia/version does not exist\r\n2020-04-11 19:39:35.088189: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2999610000 Hz\r\n2020-04-11 19:39:35.089136: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x40682b0 executing computations on platform Host. Devices:\r\n2020-04-11 19:39:35.089190: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): <undefined>, <undefined>\r\n2020-04-11 19:39:35.829560: W tensorflow/compiler/jit/mark_for_compilation_pass.cc:1412] (One-time warning): Not using XLA:CPU for cluster because envvar TF_XLA_FLAGS=--tf_xla_cpu_global_jit was not set.  If you want XLA:CPU, either set that envvar, or use experimental_jit_scope to enable XLA:CPU.  To confirm that XLA is active, pass --vmodule=xla_compilation_cache=1 (as a proper command-line flag, not via TF_XLA_FLAGS) or set the envvar XLA_FLAGS=--xla_hlo_profile.\r\n[2020-04-11 19:39:35,858][WARNING][tensorflow][deprecation new_func] From test_tensorrt_enabled.py:26: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.compat.v1.graph_util.convert_variables_to_constants`\r\n[2020-04-11 19:39:35,858][WARNING][tensorflow][deprecation new_func] From /nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.compat.v1.graph_util.extract_sub_graph`\r\n[2020-04-11 19:39:35,876][INFO][tensorflow][graph_util_impl convert_variables_to_constants] Froze 11 variables.\r\n[2020-04-11 19:39:35,890][INFO][tensorflow][graph_util_impl convert_variables_to_constants] Converted 11 variables to const ops.\r\n[2020-04-11 19:39:35,891][INFO][tensorflow][trt_convert _check_trt_version_compatibility] Linked TensorRT version: (7, 0, 0)\r\n[2020-04-11 19:39:35,891][INFO][tensorflow][trt_convert _check_trt_version_compatibility] Loaded TensorRT version: (7, 0, 0)\r\n[2020-04-11 19:39:35,891][INFO][tensorflow][trt_convert _check_trt_version_compatibility] Running against TensorRT version 7.0.0\r\n2020-04-11 19:39:35.948446: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\r\n2020-04-11 19:39:35.948611: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session\r\n2020-04-11 19:39:35.997673: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:460] There are 5 ops of 4 different types in the graph that are not converted to TensorRT: Identity, FusedBatchNorm, NoOp, Placeholder, (For more information see https://docs.nvidia.com/deeplearning/dgx/tf-trt-user-guide/index.html#supported-ops).\r\n2020-04-11 19:39:35.997810: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:733] Number of TensorRT candidate segments: 1\r\n2020-04-11 19:39:36.003553: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudart.so.10.0\r\n2020-04-11 19:39:36.006215: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:797] Couldn't get current device: no CUDA-capable device is detected\r\n2020-04-11 19:39:36.006242: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 0 does not exist Not found: TensorFlow device GPU:0 was not registered\r\n2020-04-11 19:39:36.006267: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 1 does not exist Not found: TensorFlow device GPU:1 was not registered\r\n2020-04-11 19:39:36.006279: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 2 does not exist Not found: TensorFlow device GPU:2 was not registered\r\n2020-04-11 19:39:36.006289: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 3 does not exist Not found: TensorFlow device GPU:3 was not registered\r\n2020-04-11 19:39:36.006300: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 4 does not exist Not found: TensorFlow device GPU:4 was not registered\r\n2020-04-11 19:39:36.006311: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 5 does not exist Not found: TensorFlow device GPU:5 was not registered\r\n2020-04-11 19:39:36.006321: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 6 does not exist Not found: TensorFlow device GPU:6 was not registered\r\n2020-04-11 19:39:36.006332: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 7 does not exist Not found: TensorFlow device GPU:7 was not registered\r\n2020-04-11 19:39:36.006342: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 8 does not exist Not found: TensorFlow device GPU:8 was not registered\r\n2020-04-11 19:39:36.006352: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 9 does not exist Not found: TensorFlow device GPU:9 was not registered\r\n2020-04-11 19:39:36.006363: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 10 does not exist Not found: TensorFlow device GPU:10 was not registered\r\n2020-04-11 19:39:36.006373: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 11 does not exist Not found: TensorFlow device GPU:11 was not registered\r\n2020-04-11 19:39:36.006384: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 12 does not exist Not found: TensorFlow device GPU:12 was not registered\r\n2020-04-11 19:39:36.006395: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 13 does not exist Not found: TensorFlow device GPU:13 was not registered\r\n2020-04-11 19:39:36.006406: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 14 does not exist Not found: TensorFlow device GPU:14 was not registered\r\n2020-04-11 19:39:36.006416: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 15 does not exist Not found: TensorFlow device GPU:15 was not registered\r\n2020-04-11 19:39:36.006426: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 16 does not exist Not found: TensorFlow device GPU:16 was not registered\r\n2020-04-11 19:39:36.006436: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 17 does not exist Not found: TensorFlow device GPU:17 was not registered\r\n2020-04-11 19:39:36.006447: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 18 does not exist Not found: TensorFlow device GPU:18 was not registered\r\n2020-04-11 19:39:36.006457: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 19 does not exist Not found: TensorFlow device GPU:19 was not registered\r\n2020-04-11 19:39:36.006467: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 20 does not exist Not found: TensorFlow device GPU:20 was not registered\r\n2020-04-11 19:39:36.006478: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 21 does not exist Not found: TensorFlow device GPU:21 was not registered\r\n2020-04-11 19:39:36.006488: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 22 does not exist Not found: TensorFlow device GPU:22 was not registered\r\n2020-04-11 19:39:36.006498: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 23 does not exist Not found: TensorFlow device GPU:23 was not registered\r\n2020-04-11 19:39:36.006509: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 24 does not exist Not found: TensorFlow device GPU:24 was not registered\r\n2020-04-11 19:39:36.006519: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 25 does not exist Not found: TensorFlow device GPU:25 was not registered\r\n2020-04-11 19:39:36.006529: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 26 does not exist Not found: TensorFlow device GPU:26 was not registered\r\n2020-04-11 19:39:36.006540: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 27 does not exist Not found: TensorFlow device GPU:27 was not registered\r\n2020-04-11 19:39:36.006550: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 28 does not exist Not found: TensorFlow device GPU:28 was not registered\r\n2020-04-11 19:39:36.006561: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 29 does not exist Not found: TensorFlow device GPU:29 was not registered\r\n2020-04-11 19:39:36.006571: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 30 does not exist Not found: TensorFlow device GPU:30 was not registered\r\n2020-04-11 19:39:36.006582: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 31 does not exist Not found: TensorFlow device GPU:31 was not registered\r\n2020-04-11 19:39:36.006592: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 32 does not exist Not found: TensorFlow device GPU:32 was not registered\r\n2020-04-11 19:39:36.006602: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 33 does not exist Not found: TensorFlow device GPU:33 was not registered\r\n2020-04-11 19:39:36.006613: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 34 does not exist Not found: TensorFlow device GPU:34 was not registered\r\n2020-04-11 19:39:36.006625: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 35 does not exist Not found: TensorFlow device GPU:35 was not registered\r\n2020-04-11 19:39:36.006636: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 36 does not exist Not found: TensorFlow device GPU:36 was not registered\r\n2020-04-11 19:39:36.006647: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 37 does not exist Not found: TensorFlow device GPU:37 was not registered\r\n2020-04-11 19:39:36.006659: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 38 does not exist Not found: TensorFlow device GPU:38 was not registered\r\n2020-04-11 19:39:36.006670: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 39 does not exist Not found: TensorFlow device GPU:39 was not registered\r\n2020-04-11 19:39:36.006682: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 40 does not exist Not found: TensorFlow device GPU:40 was not registered\r\n2020-04-11 19:39:36.006693: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 41 does not exist Not found: TensorFlow device GPU:41 was not registered\r\n2020-04-11 19:39:36.006705: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 42 does not exist Not found: TensorFlow device GPU:42 was not registered\r\n2020-04-11 19:39:36.006717: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 43 does not exist Not found: TensorFlow device GPU:43 was not registered\r\n2020-04-11 19:39:36.006728: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 44 does not exist Not found: TensorFlow device GPU:44 was not registered\r\n2020-04-11 19:39:36.006738: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 45 does not exist Not found: TensorFlow device GPU:45 was not registered\r\n2020-04-11 19:39:36.006749: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 46 does not exist Not found: TensorFlow device GPU:46 was not registered\r\n2020-04-11 19:39:36.006761: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 47 does not exist Not found: TensorFlow device GPU:47 was not registered\r\n2020-04-11 19:39:36.006772: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 48 does not exist Not found: TensorFlow device GPU:48 was not registered\r\n2020-04-11 19:39:36.006784: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 49 does not exist Not found: TensorFlow device GPU:49 was not registered\r\n2020-04-11 19:39:36.006794: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 50 does not exist Not found: TensorFlow device GPU:50 was not registered\r\n2020-04-11 19:39:36.006805: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 51 does not exist Not found: TensorFlow device GPU:51 was not registered\r\n2020-04-11 19:39:36.006817: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 52 does not exist Not found: TensorFlow device GPU:52 was not registered\r\n2020-04-11 19:39:36.006828: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 53 does not exist Not found: TensorFlow device GPU:53 was not registered\r\n2020-04-11 19:39:36.006838: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 54 does not exist Not found: TensorFlow device GPU:54 was not registered\r\n2020-04-11 19:39:36.006849: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 55 does not exist Not found: TensorFlow device GPU:55 was not registered\r\n2020-04-11 19:39:36.006860: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 56 does not exist Not found: TensorFlow device GPU:56 was not registered\r\n2020-04-11 19:39:36.006872: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 57 does not exist Not found: TensorFlow device GPU:57 was not registered\r\n2020-04-11 19:39:36.006883: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 58 does not exist Not found: TensorFlow device GPU:58 was not registered\r\n2020-04-11 19:39:36.006894: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 59 does not exist Not found: TensorFlow device GPU:59 was not registered\r\n2020-04-11 19:39:36.006905: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 60 does not exist Not found: TensorFlow device GPU:60 was not registered\r\n2020-04-11 19:39:36.006917: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 61 does not exist Not found: TensorFlow device GPU:61 was not registered\r\n2020-04-11 19:39:36.006928: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 62 does not exist Not found: TensorFlow device GPU:62 was not registered\r\n2020-04-11 19:39:36.006939: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 63 does not exist Not found: TensorFlow device GPU:63 was not registered\r\n2020-04-11 19:39:36.006950: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 64 does not exist Not found: TensorFlow device GPU:64 was not registered\r\n2020-04-11 19:39:36.006962: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 65 does not exist Not found: TensorFlow device GPU:65 was not registered\r\n2020-04-11 19:39:36.006972: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 66 does not exist Not found: TensorFlow device GPU:66 was not registered\r\n2020-04-11 19:39:36.006983: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 67 does not exist Not found: TensorFlow device GPU:67 was not registered\r\n2020-04-11 19:39:36.006994: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 68 does not exist Not found: TensorFlow device GPU:68 was not registered\r\n2020-04-11 19:39:36.007011: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 69 does not exist Not found: TensorFlow device GPU:69 was not registered\r\n2020-04-11 19:39:36.007024: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 70 does not exist Not found: TensorFlow device GPU:70 was not registered\r\n2020-04-11 19:39:36.007035: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 71 does not exist Not found: TensorFlow device GPU:71 was not registered\r\n2020-04-11 19:39:36.007045: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 72 does not exist Not found: TensorFlow device GPU:72 was not registered\r\n2020-04-11 19:39:36.007056: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 73 does not exist Not found: TensorFlow device GPU:73 was not registered\r\n2020-04-11 19:39:36.007067: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 74 does not exist Not found: TensorFlow device GPU:74 was not registered\r\n2020-04-11 19:39:36.007078: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 75 does not exist Not found: TensorFlow device GPU:75 was not registered\r\n2020-04-11 19:39:36.007089: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 76 does not exist Not found: TensorFlow device GPU:76 was not registered\r\n2020-04-11 19:39:36.007100: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 77 does not exist Not found: TensorFlow device GPU:77 was not registered\r\n2020-04-11 19:39:36.007110: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 78 does not exist Not found: TensorFlow device GPU:78 was not registered\r\n2020-04-11 19:39:36.007121: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 79 does not exist Not found: TensorFlow device GPU:79 was not registered\r\n2020-04-11 19:39:36.007132: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 80 does not exist Not found: TensorFlow device GPU:80 was not registered\r\n2020-04-11 19:39:36.007142: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 81 does not exist Not found: TensorFlow device GPU:81 was not registered\r\n2020-04-11 19:39:36.007153: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 82 does not exist Not found: TensorFlow device GPU:82 was not registered\r\n2020-04-11 19:39:36.007164: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 83 does not exist Not found: TensorFlow device GPU:83 was not registered\r\n2020-04-11 19:39:36.007175: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 84 does not exist Not found: TensorFlow device GPU:84 was not registered\r\n2020-04-11 19:39:36.007185: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 85 does not exist Not found: TensorFlow device GPU:85 was not registered\r\n2020-04-11 19:39:36.007195: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 86 does not exist Not found: TensorFlow device GPU:86 was not registered\r\n2020-04-11 19:39:36.007206: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 87 does not exist Not found: TensorFlow device GPU:87 was not registered\r\n2020-04-11 19:39:36.007217: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 88 does not exist Not found: TensorFlow device GPU:88 was not registered\r\n2020-04-11 19:39:36.007228: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 89 does not exist Not found: TensorFlow device GPU:89 was not registered\r\n2020-04-11 19:39:36.007240: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 90 does not exist Not found: TensorFlow device GPU:90 was not registered\r\n2020-04-11 19:39:36.007251: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 91 does not exist Not found: TensorFlow device GPU:91 was not registered\r\n2020-04-11 19:39:36.007260: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 92 does not exist Not found: TensorFlow device GPU:92 was not registered\r\n2020-04-11 19:39:36.007272: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 93 does not exist Not found: TensorFlow device GPU:93 was not registered\r\n2020-04-11 19:39:36.007282: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 94 does not exist Not found: TensorFlow device GPU:94 was not registered\r\n2020-04-11 19:39:36.007293: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 95 does not exist Not found: TensorFlow device GPU:95 was not registered\r\n2020-04-11 19:39:36.007304: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 96 does not exist Not found: TensorFlow device GPU:96 was not registered\r\n2020-04-11 19:39:36.007315: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 97 does not exist Not found: TensorFlow device GPU:97 was not registered\r\n2020-04-11 19:39:36.007326: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 98 does not exist Not found: TensorFlow device GPU:98 was not registered\r\n2020-04-11 19:39:36.007338: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] TF GPU with id 99 does not exist Not found: TensorFlow device GPU:99 was not registered\r\n2020-04-11 19:39:36.007348: W tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:824] Can't identify the cuda device. Running on device 0\r\n2020-04-11 19:39:36.007394: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:41] DefaultLogger CUDA initialization failure with error 38. Please check your CUDA installation:  http://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html\r\nFatal Python error: Segmentation fault\r\n\r\nCurrent thread 0x00007f02020e7f40 (most recent call first):\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/tensorflow/python/grappler/tf_optimizer.py\", line 41 in OptimizeGraph\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/tensorflow/python/compiler/tensorrt/trt_convert.py\", line 204 in _run_conversion\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/tensorflow/python/compiler/tensorrt/trt_convert.py\", line 226 in _convert_graph_def\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/tensorflow/python/compiler/tensorrt/trt_convert.py\", line 298 in convert\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/tensorflow/python/compiler/tensorrt/trt_convert.py\", line 1146 in create_inference_graph\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/tensorflow/contrib/tensorrt/python/trt_convert.py\", line 51 in create_inference_graph\r\n  File \"test_tensorrt_enabled.py\", line 38 in test_tensorrt_enabled\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/_pytest/python.py\", line 167 in pytest_pyfunc_call\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/callers.py\", line 187 in _multicall\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/manager.py\", line 87 in <lambda>\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/manager.py\", line 93 in _hookexec\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/hooks.py\", line 286 in __call__\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/_pytest/python.py\", line 1445 in runtest\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/_pytest/runner.py\", line 134 in pytest_runtest_call\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/callers.py\", line 187 in _multicall\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/manager.py\", line 87 in <lambda>\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/manager.py\", line 93 in _hookexec\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/hooks.py\", line 286 in __call__\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/_pytest/runner.py\", line 210 in <lambda>\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/_pytest/runner.py\", line 237 in from_call\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/_pytest/runner.py\", line 210 in call_runtest_hook\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/_pytest/runner.py\", line 185 in call_and_report\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/_pytest/runner.py\", line 99 in runtestprotocol\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/_pytest/runner.py\", line 84 in pytest_runtest_protocol\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/callers.py\", line 187 in _multicall\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/manager.py\", line 87 in <lambda>\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/manager.py\", line 93 in _hookexec\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/hooks.py\", line 286 in __call__\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/_pytest/main.py\", line 271 in pytest_runtestloop\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/callers.py\", line 187 in _multicall\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/manager.py\", line 87 in <lambda>\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/manager.py\", line 93 in _hookexec\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/hooks.py\", line 286 in __call__\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/_pytest/main.py\", line 247 in _main\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/_pytest/main.py\", line 197 in wrap_session\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/_pytest/main.py\", line 240 in pytest_cmdline_main\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/callers.py\", line 187 in _multicall\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/manager.py\", line 87 in <lambda>\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/manager.py\", line 93 in _hookexec\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pluggy/hooks.py\", line 286 in __call__\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/_pytest/config/__init__.py\", line 93 in main\r\n  File \"/nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/pytest/__main__.py\", line 7 in <module>\r\n  File \"/nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/python3.6/runpy.py\", line 85 in _run_code\r\n  File \"/nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/python3.6/runpy.py\", line 193 in _run_module_as_main\r\n```\r\n\r\n</details>\r\n\r\n<details>\r\n<summary>gdb backtrace</summary>\r\n\r\n```\r\n#0  0x00007fff359762f7 in tensorflow::tensorrt::convert::ConvertGraphDefToEngine(tensorflow::GraphDef const&, tensorflow::tensorrt::TrtPrecisionMode, int, unsigned long, std::vector<tensorflow::PartialTensorShape, std::allocator<tensorflow::PartialTensorShape> > const&, tensorflow::tensorrt::Logger*, nvinfer1::IGpuAllocator*, tensorflow::tensorrt::TRTInt8Calibrator*, std::unique_ptr<nvinfer1::ICudaEngine, tensorflow::tensorrt::TrtDestroyer<nvinfer1::ICudaEngine> >*, bool, bool*) () from /nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/tensorflow/compiler/tf2tensorrt/python/ops/libtftrt.so\r\n#1  0x00007fff3593f8e0 in tensorflow::tensorrt::convert::CreateTRTNode(tensorflow::tensorrt::convert::ConversionParams const&, std::vector<tensorflow::tensorrt::convert::EngineInfo, std::allocator<tensorflow::tensorrt::convert::EngineInfo> > const&, int, int, tensorflow::Graph*, nvinfer1::IGpuAllocator*, std::vector<tensorflow::Node*, std::allocator<tensorflow::Node*> >*) ()\r\n   from /nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/tensorflow/compiler/tf2tensorrt/python/ops/libtftrt.so\r\n#2  0x00007fff35947551 in tensorflow::tensorrt::convert::ConvertAfterShapes(tensorflow::tensorrt::convert::ConversionParams const&) ()\r\n   from /nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/tensorflow/compiler/tf2tensorrt/python/ops/libtftrt.so\r\n#3  0x00007fff3597ff50 in tensorflow::tensorrt::convert::TRTOptimizationPass::Optimize(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem const&, tensorflow::GraphDef*) ()\r\n   from /nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/tensorflow/compiler/tf2tensorrt/python/ops/libtftrt.so\r\n#4  0x00007fff9c7d2105 in tensorflow::grappler::MetaOptimizer::RunOptimizer(tensorflow::grappler::GraphOptimizer*, tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem*, tensorflow::GraphDef*, tensorflow::grappler::MetaOptimizer::GraphOptimizationResult*) () from /nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#5  0x00007fff9c7d3631 in tensorflow::grappler::MetaOptimizer::OptimizeGraph(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem const&, tensorflow::GraphDef*) ()\r\n   from /nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#6  0x00007fff9c7d51fe in tensorflow::grappler::MetaOptimizer::Optimize(tensorflow::grappler::Cluster*, tensorflow::grappler::GrapplerItem const&, tensorflow::GraphDef*) ()\r\n   from /nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#7  0x00007fff94cfaa43 in TF_OptimizeGraph(GCluster, tensorflow::ConfigProto const&, tensorflow::MetaGraphDef const&, bool, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > const&, TF_Status*) ()\r\n   from /nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#8  0x00007fff94d024fa in _wrap_TF_OptimizeGraph () from /nix/store/w7dqhlrb6qv0im8hnwl309f13q86pnb4-python3-3.6.10-env/lib/python3.6/site-packages/tensorflow/python/_pywrap_tensorflow_internal.so\r\n#9  0x00007ffff7d76cf3 in _PyCFunction_FastCallDict () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#10 0x00007ffff7dfb4c4 in call_function () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#11 0x00007ffff7e0032a in _PyEval_EvalFrameDefault () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#12 0x00007ffff7dfafda in _PyEval_EvalCodeWithName () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#13 0x00007ffff7dfb3d4 in call_function () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#14 0x00007ffff7e00a8f in _PyEval_EvalFrameDefault () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#15 0x00007ffff7dfa5d3 in _PyFunction_FastCall () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#16 0x00007ffff7dfb59c in call_function () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#17 0x00007ffff7e0032a in _PyEval_EvalFrameDefault () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#18 0x00007ffff7dfa5d3 in _PyFunction_FastCall () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#19 0x00007ffff7dfb59c in call_function () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#20 0x00007ffff7e0032a in _PyEval_EvalFrameDefault () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#21 0x00007ffff7dfa5d3 in _PyFunction_FastCall () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#22 0x00007ffff7dfb59c in call_function () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#23 0x00007ffff7e0032a in _PyEval_EvalFrameDefault () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#24 0x00007ffff7dfafda in _PyEval_EvalCodeWithName () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#25 0x00007ffff7dfb3d4 in call_function () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#26 0x00007ffff7e00a8f in _PyEval_EvalFrameDefault () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#27 0x00007ffff7dfafda in _PyEval_EvalCodeWithName () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#28 0x00007ffff7dfb3d4 in call_function () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#29 0x00007ffff7e00a8f in _PyEval_EvalFrameDefault () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#30 0x00007ffff7dfafda in _PyEval_EvalCodeWithName () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#31 0x00007ffff7dfb5ee in PyEval_EvalCodeEx () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#32 0x00007ffff7d4f60e in function_call () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#33 0x00007ffff7d21087 in PyObject_Call () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#34 0x00007ffff7e0084c in _PyEval_EvalFrameDefault () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#35 0x00007ffff7dfafda in _PyEval_EvalCodeWithName () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#36 0x00007ffff7dfb5ee in PyEval_EvalCodeEx () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#37 0x00007ffff7d4f52e in function_call () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#38 0x00007ffff7d21087 in PyObject_Call () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#39 0x00007ffff7e0084c in _PyEval_EvalFrameDefault () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#40 0x00007ffff7dfafda in _PyEval_EvalCodeWithName () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#41 0x00007ffff7dfb3d4 in call_function () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#42 0x00007ffff7e00a8f in _PyEval_EvalFrameDefault () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#43 0x00007ffff7dfafda in _PyEval_EvalCodeWithName () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#44 0x00007ffff7dfb3d4 in call_function () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#45 0x00007ffff7e0032a in _PyEval_EvalFrameDefault () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#46 0x00007ffff7dfa5d3 in _PyFunction_FastCall () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#47 0x00007ffff7dfb59c in call_function () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#48 0x00007ffff7e0032a in _PyEval_EvalFrameDefault () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#49 0x00007ffff7dfafda in _PyEval_EvalCodeWithName () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#50 0x00007ffff7e03c37 in _PyFunction_FastCallDict () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n#51 0x00007ffff7d212a1 in _PyObject_FastCallDict () from /nix/store/2ard4hsnrajrxdwvp20kgql2r5j2fl82-python3-3.6.10/lib/libpython3.6m.so.1.0\r\n```\r\n\r\n</details>\r\n\r\n<details>\r\n<summary>disassembly/registers</summary>\r\n\r\n```\r\n...\r\n   0x00007fff359762db <+155>:\tje     0x7fff359762e0 <_ZN10tensorflow8tensorrt7convert23ConvertGraphDefToEngineERKNS_8GraphDefENS0_16TrtPrecisionModeEimRKSt6vectorINS_18PartialTensorShapeESaIS7_EEPNS0_6LoggerEPN8nvinfer113IGpuAllocatorEPNS0_17TRTInt8CalibratorEPSt10unique_ptrINSE_11ICudaEngineENS0_12TrtDestroyerISK_EEEbPb+160>\r\n   0x00007fff359762dd <+157>:\tmovb   $0x0,(%rcx)\r\n   0x00007fff359762e0 <+160>:\tmov    $0x1b58,%esi\r\n   0x00007fff359762e5 <+165>:\tmov    %rax,%rdi\r\n   0x00007fff359762e8 <+168>:\tcallq  0x7fff35923510 <createInferBuilder_INTERNAL@plt>\r\n   0x00007fff359762ed <+173>:\tmov    %rax,%rdi\r\n   0x00007fff359762f0 <+176>:\tmov    %rax,-0x440(%rbp)\r\n=> 0x00007fff359762f7 <+183>:\tmov    (%rax),%rax\r\n   0x00007fff359762fa <+186>:\tmov    %r15d,%esi\r\n   0x00007fff359762fd <+189>:\tmov    %rdi,%r15\r\n   0x00007fff35976300 <+192>:\tcallq  *0x8(%rax)\r\n   0x00007fff35976303 <+195>:\tmov    (%r15),%rax\r\n...\r\n\r\n(gdb) info registers\r\nrax            0x0                 0\r\n....\r\n```\r\n\r\n</details>\r\n\r\nI suspect that what\u2019s happening is that `nvinfer1::createInferBuilder` [here](https://github.com/tensorflow/tensorflow/blob/00fad90125b18b80fe054de1055770cfb8fe4ba3/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc#L4917) returns a nullptr (becaue of missing GPU) and then tensorflow dereferences it without checking the return value.\r\n\r\nFrom what I can see this issue is still present [in master](https://github.com/tensorflow/tensorflow/blob/20a26f65d08ed37232a5adb19d9762bf65b6d761/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc#L1204) \u2013 the `trt_builder_` is never checked for nullptr before it is dereferenced with `->` a couple lines below. \r\n\r\n**Describe the expected behavior**\r\n\r\nTensorflow should return an error/raise an exception instead of trying to dereference a nullptr.\r\n\r\n**Standalone code to reproduce the issue** \r\n\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.slim as slim\r\nimport tensorflow.contrib.tensorrt as trt\r\n\r\nwith tf.Session() as sess:\r\n    input0 = tf.placeholder(tf.float32, [10, 3, 224, 224])\r\n    out = input0\r\n\r\n    out = slim.batch_norm(out, data_format=\"NHWC\", scope=\"bn2\")\r\n    with slim.arg_scope([slim.conv2d, slim.batch_norm], data_format=\"NCHW\"), slim.arg_scope(\r\n        [slim.batch_norm]\r\n    ):\r\n        out = slim.conv2d(\r\n            out, 64, [3, 3], normalizer_fn=slim.batch_norm, activation_fn=tf.nn.relu\r\n        )\r\n        out = slim.conv2d(out, 64, [3, 3], normalizer_fn=slim.batch_norm)\r\n        out = tf.identity(out)\r\n    out = tf.identity(out)\r\n    out_name = out.name[:-2]\r\n\r\n    init = tf.global_variables_initializer()\r\n    sess.run(init)\r\n\r\n    frozen_graph = tf.graph_util.convert_variables_to_constants(\r\n        sess, tf.get_default_graph().as_graph_def(), output_node_names=[out_name]\r\n    )\r\n\r\n    trt_graph = trt.create_inference_graph(\r\n        frozen_graph,\r\n        [out_name],\r\n        max_batch_size=10,\r\n        is_dynamic_op=False,\r\n    )\r\n```", "comments": ["@nagisa \r\n\r\nI have tried on colab with TF version 1.14 . Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/3c6d36532a13b25f923b8aae0c429e22/untitled767.ipynb  ). Is this the expected behavior? Thanks!", "@ravikyram colab does not appear to have TensorRT enabled as evidenced by\r\n\r\n```\r\nINFO:tensorflow:Linked TensorRT version: (0, 0, 0)\r\nINFO:tensorflow:Loaded TensorRT version: (0, 0, 0)\r\nINFO:tensorflow:Running against TensorRT version 0.0.0\r\n```\r\n\r\nso it is not invoking any TensorRT code-paths at all and thus won\u2019t be able to reproduce this issue. I believe a custom build of TF is necessary to take advantage of TensorRT at all (with `TF_NEED_TENSORRT=1` set when building).", "Can you try 1.15 or later? 1.14 has been released in a bad state and should be skipped if possible.", "The SIGSEGV is still present when running 1.15. This is fairly apparent by just reviewing code but I ran the test case \"just in case\" and it still reproduces:\r\n\r\n```\r\n2020-04-17 00:50:22.602495: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0\r\nWARNING: Logging before flag parsing goes to stderr.\r\nW0417 00:50:24.764523 139696792719168 __init__.py:329] Limited tf.compat.v2.summary API due to missing TensorBoard installation.\r\nW0417 00:50:25.624777 139696792719168 lazy_loader.py:50]\r\nThe TensorFlow contrib module will not be included in TensorFlow 2.0.\r\nFor more information, please see:\r\n  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\r\n  * https://github.com/tensorflow/addons\r\n  * https://github.com/tensorflow/io (for I/O related ops)\r\nIf you depend on functionality not listed there, please file an issue.\r\n\r\n2020-04-17 00:50:25.630230: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.7\r\n2020-04-17 00:50:25.630325: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer_plugin.so.7\r\nW0417 00:50:25.634957 139696792719168 module_wrapper.py:139] From test.py:5: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\r\n\r\n2020-04-17 00:50:25.636118: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n2020-04-17 00:50:25.638156: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\r\n2020-04-17 00:50:25.638181: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (shirobox): /proc/driver/nvidia/version does not exist\r\n2020-04-17 00:50:25.659198: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2999610000 Hz\r\n2020-04-17 00:50:25.659750: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x507ff40 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-04-17 00:50:25.659778: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\nW0417 00:50:25.661654 139696792719168 module_wrapper.py:139] From test.py:6: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\r\n\r\nW0417 00:50:25.664518 139696792719168 deprecation.py:323] From /nix/store/3qxd7awvhwpw31mjqrnx0ipcs8is2zy4-python3.6-tensorflow-gpu-1.15.2/lib/python3.6/site-packages/tensorflow_core/contrib/layers/python/layers/layers.py:650: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease use `layer.__call__` method instead.\r\nW0417 00:50:25.810726 139696792719168 module_wrapper.py:139] From test.py:21: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\r\n\r\nW0417 00:50:25.832406 139696792719168 module_wrapper.py:139] From test.py:25: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\r\n\r\nW0417 00:50:25.857594 139696792719168 deprecation.py:323] From test.py:25: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.compat.v1.graph_util.convert_variables_to_constants`\r\nW0417 00:50:25.857715 139696792719168 deprecation.py:323] From /nix/store/3qxd7awvhwpw31mjqrnx0ipcs8is2zy4-python3.6-tensorflow-gpu-1.15.2/lib/python3.6/site-packages/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse `tf.compat.v1.graph_util.extract_sub_graph`\r\n2020-04-17 00:50:25.878155: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.7\r\n2020-04-17 00:50:25.914339: I tensorflow/core/grappler/devices.cc:55] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\r\n2020-04-17 00:50:25.914627: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2020-04-17 00:50:25.949588: W tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc:4399] FusedBatchNormV3 only supports is_training=false. If you are using Keras, please call keras.backend.set_learning_phase(0) before constructing your model. At Conv/BatchNorm/FusedBatchNormV3\r\n2020-04-17 00:50:25.949786: W tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc:4399] FusedBatchNormV3 only supports is_training=false. If you are using Keras, please call keras.backend.set_learning_phase(0) before constructing your model. At Conv_1/BatchNorm/FusedBatchNormV3\r\n2020-04-17 00:50:25.949926: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:460] There are 7 ops of 4 different types in the graph that are not converted to TensorRT: Identity, FusedBatchNormV3, NoOp, Placeholder, (For more information see https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html#supported-ops).\r\n2020-04-17 00:50:25.950231: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:633] Number of TensorRT candidate segments: 1\r\n2020-04-17 00:50:25.959752: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:696] Couldn't get current device: no CUDA-capable device is detected\r\n2020-04-17 00:50:25.959808: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:101] Could not find any TF GPUs\r\n2020-04-17 00:50:25.959822: W tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:723] Can't identify the cuda device. Running on device 0\r\n2020-04-17 00:50:25.960108: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.7\r\n2020-04-17 00:50:25.963251: E tensorflow/compiler/tf2tensorrt/utils/trt_logger.cc:41] DefaultLogger CUDA initialization failure with error 38. Please check your CUDA installation:  http://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html\r\nfish: \u201cpython test.py\u201d terminated by signal SIGSEGV (Address boundary error)\r\n```", "Thanks for confirming. I will investigate more.", "Note, that I linked the relevant code in the original description. Re-producing the links here:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/00fad90125b18b80fe054de1055770cfb8fe4ba3/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc#L4917\r\nhttps://github.com/tensorflow/tensorflow/blob/20a26f65d08ed37232a5adb19d9762bf65b6d761/tensorflow/compiler/tf2tensorrt/convert/convert_nodes.cc#L1204", "I missed those. Thank you. I'm on it as of now and will have a fix by end of day and then backport it over the next weeks. Apologies for the delay this process entails", "The code on master is not causing the failure since the code paths are different (graph models are no longer converted by tensorrt). Deprecated code has just not been removed yet.\r\n\r\nTrying to build now with 1.15 and test there.", "I am unable to reproduce in the supported environment. I built tensorflow-gpu on a supported environment with CUDA headers and then installed the pip on a supported environment without CUDA. When running the test all I get is\r\n\r\n```\r\n2020-04-21 09:13:40.771653: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfe\r\nr.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory                                         \r\n2020-04-21 09:13:40.771683: F tensorflow/compiler/tf2tensorrt/stub/nvinfer_stub.cc:49] getInferLibVersion symbol not found.          \r\nAborted \r\n```\r\n\r\nTried with master, 2.2rc3, 2.1.0, 2.0.1, 2.0.0, 1.15.2 and 1.15.0. Never got a segfault.\r\n\r\nFor the versions not using `contrib` (as it has been deprecated), I have used\r\n\r\n```python\r\nfrom tensorflow.python.compiler.tensorrt import trt_convert as trt\r\n\r\nconverter = trt.TrtGraphConverterV2(input_saved_model_dir='/tmp/mobilenet/1/')\r\nconverter.convert()\r\n```\r\n\r\nwhere the model to convert has been generated via\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\npretrained_model = tf.keras.applications.MobileNet()\r\ntf.saved_model.save(pretrained_model, \"/tmp/mobilenet/1/\")\r\n```\r\n\r\nAt this point, since you are building from source, can you check if the fix you propose (i.e., checking for nullptr before accessing) works? If it does, can you submit a PR please?", "This also makes sense since the binding between TF and TRT seems to raise the symbol not found error if the header does not exist. The only time nullptr can be returned is if the symbol bound against returns nullptr: https://cs.opensource.google/tensorflow/tensorflow/+/master:tensorflow/compiler/tf2tensorrt/stub/NvInfer_5_1.inc;l=5-10", "The environment I\u2019m using _has_ cuda and all the related libraries installed and available. It just doesn\u2019t have an actual GPU attached.\r\n\r\nThink of it this way:\r\n\r\n1. Install everything to run tensorrt properly;\r\n2. Shutdown the machine;\r\n3. Pull out the GPU(s);\r\n4. Power on the machine;\r\n5. Try running the test case (the cuda libraries will still be present, but a GPU will be absent).\r\n\r\nI think that might be why you are not able to reproduce this issue.", "I did that and still no segfault. Here is the log I get\r\n\r\n```\r\n2020-04-21 12:25:26.189672: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1                                                                                                                         \r\n2020-04-21 12:25:27.424632: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libnvinfer.so.6                                                                                                                           \r\n2020-04-21 12:25:27.566116: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1                                                                                                                              \r\n2020-04-21 12:25:27.578055: E tensorflow/stream_executor/cuda/cuda_driver.cc:313] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected                          \r\n2020-04-21 12:25:27.578125: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: packer-5e4c64c2-6ffe-09bb-47a3-1096cbf0e2cb                                                                                       \r\n2020-04-21 12:25:27.578134: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: packer-5e4c64c2-6ffe-09bb-47a3-1096cbf0e2cb                                                                                                                              \r\n2020-04-21 12:25:27.578251: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 440.64.0         \r\n2020-04-21 12:25:27.578288: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 440.64.0          \r\n2020-04-21 12:25:27.578301: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 440.64.0   \r\n2020-04-21 12:25:27.578715: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA                     \r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.                                          \r\n2020-04-21 12:25:27.589214: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 2300000000 Hz                  \r\n2020-04-21 12:25:27.591760: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x71413b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:                                                                               \r\n2020-04-21 12:25:27.591796: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version     \r\n2020-04-21 12:25:30.510865: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0                                                                                                                             \r\n2020-04-21 12:25:30.511106: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session \r\n2020-04-21 12:25:30.545872: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:810] Optimization results for grappler item: graph_to_optimize                                                                                                                        \r\n2020-04-21 12:25:30.545929: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   function_optimizer: Graph size after: 559 nodes (419), 852 edges (712), time = 17.04ms.                                                                                        \r\n2020-04-21 12:25:30.545936: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   function_optimizer: function_optimizer did nothing. time = 0.366ms.                                                                                                            \r\n2020-04-21 12:25:31.426631: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0\r\n2020-04-21 12:25:31.426973: I tensorflow/core/grappler/clusters/single_machine.cc:356] Starting new session\r\n2020-04-21 12:25:31.735623: I tensorflow/compiler/tf2tensorrt/segment/segment.cc:460] There are 41 ops of 8 different types in the graph that are not converted to TensorRT: Reshape, StridedSlice, NoOp, Placeholder, Pack, Shape, Identity, FusedBatchNormV3, (For more \r\ninformation see https://docs.nvidia.com/deeplearning/frameworks/tf-trt-user-guide/index.html#supported-ops).\r\n2020-04-21 12:25:31.739816: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:659] Number of TensorRT candidate segments: 29\r\n2020-04-21 12:25:31.740282: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:102] Could not find any TF GPUs\r\n2020-04-21 12:25:31.740677: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:102] Could not find any TF GPUs\r\n2020-04-21 12:25:31.740895: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:102] Could not find any TF GPUs\r\n2020-04-21 12:25:31.741106: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:102] Could not find any TF GPUs\r\n2020-04-21 12:25:31.741358: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:102] Could not find any TF GPUs\r\n...\r\n2020-04-21 12:25:31.785400: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:725] Couldn't get current device: no CUDA-capable device is detected\r\n2020-04-21 12:25:31.785467: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:102] Could not find any TF GPUs\r\n2020-04-21 12:25:31.785473: W tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:752] Can't identify the cuda device. Running on device 0 \r\n2020-04-21 12:25:31.785625: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:763] Replaced segment 0 consisting of 5 nodes by TRTEngineOp_0_0.\r\n2020-04-21 12:25:31.785681: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:102] Could not find any TF GPUs\r\n2020-04-21 12:25:31.785691: W tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:752] Can't identify the cuda device. Running on device 0 \r\n2020-04-21 12:25:31.785744: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:763] Replaced segment 1 consisting of 3 nodes by StatefulPartitionedCall/mobilenet_1.00_224/TRTEngineOp_0_1.\r\n...\r\n2020-04-21 12:25:31.788720: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:763] Replaced segment 27 consisting of 3 nodes by StatefulPartitionedCall/mobilenet_1.00_224/TRTEngineOp_0_27.\r\n2020-04-21 12:25:31.788765: E tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:102] Could not find any TF GPUs\r\n2020-04-21 12:25:31.788774: W tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:752] Can't identify the cuda device. Running on device 0 \r\n2020-04-21 12:25:31.788831: I tensorflow/compiler/tf2tensorrt/convert/convert_graph.cc:763] Replaced segment 28 consisting of 3 nodes by StatefulPartitionedCall/mobilenet_1.00_224/TRTEngineOp_0_28.\r\n2020-04-21 12:25:31.926398: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:810] Optimization results for grappler item: tf_graph\r\n2020-04-21 12:25:31.926463: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   constant_folding: Graph size after: 396 nodes (-137), 552 edges (-274), time = 144.978ms.\r\n2020-04-21 12:25:31.926471: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   layout: layout did nothing. time = 0.777ms.\r\n2020-04-21 12:25:31.926482: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   constant_folding: Graph size after: 396 nodes (0), 552 edges (0), time = 26.016ms.\r\n2020-04-21 12:25:31.926536: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   TensorRTOptimizer: Graph size after: 326 nodes (-70), 475 edges (-77), time = 147.931ms.\r\n2020-04-21 12:25:31.926549: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   constant_folding: Graph size after: 326 nodes (0), 475 edges (0), time = 16.335ms.\r\n...\r\n2020-04-21 12:25:31.927976: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:810] Optimization results for grappler item: StatefulPartitionedCall/mobilenet_1.00_224/TRTEngineOp_0_25_native_segment\r\n2020-04-21 12:25:31.927985: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   constant_folding: Graph size after: 5 nodes (0), 4 edges (0), time = 0.703ms.\r\n2020-04-21 12:25:31.927993: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   layout: layout did nothing. time = 0.023ms.\r\n2020-04-21 12:25:31.928001: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   constant_folding: Graph size after: 5 nodes (0), 4 edges (0), time = 0.598ms.\r\n2020-04-21 12:25:31.928009: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   TensorRTOptimizer: Graph size after: 5 nodes (0), 4 edges (0), time = 0.104ms.\r\n2020-04-21 12:25:31.928018: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:812]   constant_folding: Graph size after: 5 nodes (0), 4 edges (0), time = 0.618ms.\r\n```", "@mihaimaruseac I can submit a PR, yes. What would be the best error to return here? Should I create a new one for this situation specifically?\r\n\r\nedit: interesting re it still working in your case. Could also be cuda/cudnn/tensorrt, etc version dependent. After all the null pointer ultimately comes from a call to nvinfer1.", "Something like `return errors::Internal(\"Failed to create TensorRT network object due to not being able to find CUDA device\");` should work?", "Yes, it's very likely this is an issue caused by cuda/cudnn/tensorrt, not TF", "We are in the process of releasing a patch for 1.15. If you have a PR ready please let us know, otherwise this will have to wait until we will do another patch, if ever.", "I probably won\u2019t get to it as its not actually blocking me in any way \u2013 I just need to remember to not run tensorflow on machines without GPUs.", "In that case I'll close as not reproducible (since I was not able to reproduce).", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38460\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38460\">No</a>\n"]}, {"number": 38459, "title": "Both 'mean' and 'variance' must be None when is_training is True and exponential_avg_factor == 1.0", "body": "**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device:  No\r\n- TensorFlow installed from (source or\r\nbinary): - TensorFlow version (use command below): 2.2.0-dev20200411\r\n- Python version: 3.6.3\r\n- Bazel\r\nversion (if compiling from source): \r\n- GCC/Compiler version (if compiling from\r\nsource): \r\n- CUDA/cuDNN version: 10.1- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nWhen instantiating a batch norm layer like this:\r\ntf.keras.layers.BatchNormalization(momentum=0.0, center=True, scale=False, name='bn1')\r\nI get the error:\r\nBoth 'mean' and 'variance' must be None when is_training is True and exponential_avg_factor == 1.0\r\n**Describe the expected behavior**\r\nIt is not always the expected behavior. Consider meta-learning for example. We are going to see just one batch of training data and we want to adapt all means and variances to this batch, this means the momentum should be zero.\r\nThen after applying a few training iterations, we evaluate on the same batch norm layer with training=False and that also should work fine.\r\n**Standalone code to reproduce the issue** \r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\ninp = tf.keras.layers.Input(shape=(84, 84, 3))\r\ndense = tf.keras.layers.Conv2D(10, 3, activation=None)(inp)\r\nbn = tf.keras.layers.BatchNormalization(momentum=0.0, center=True, scale=False, name='bn1')(dense)\r\nrel = tf.keras.layers.ReLU()(bn)\r\nflat = tf.keras.layers.Flatten()(rel)\r\nout = tf.keras.layers.Dense(1, )(flat)\r\nmodel = tf.keras.models.Model(inputs=inp, outputs=out)\r\n\r\nmodel.compile(loss=tf.keras.losses.MeanSquaredError(), optimizer=tf.keras.optimizers.Adam())\r\nmodel.fit(x=np.random.uniform(size=(4, 84, 84, 3)), y=np.random.uniform(size=(4, 1)), epochs=1)\r\nmodel.evaluate(x=np.random.uniform(size=(3, 84, 84, 3)), y=np.random.uniform(size=(3, 1)))\r\nmodel.predict(x=np.random.uniform(size=(1, 84, 84, 3)))\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.", "comments": ["@siavash-khodadadeh, I have tried to reproduce issue. But I have faced no issue in this code. For you reference link of gist is [here](https://gist.github.com/khimraj/25f451b7abaade36dd5390fdabb5a935). ", "@khimraj, I guess you have to update to 2.2.0-dev20200412 (tf-nightly) and then this happens.\r\nIn previous versions, this does not cause an error, and that is why I think it might be a bug.\r\n\r\n\r\n", "@siavash-khodadadeh, I have used tensorflow version 2.2.0-rc2.", "@khimraj Sorry, I am not very familiar with versioning. Is rc2 newer than nightly build?\r\nI mean if this is not resolved, will this be the behavior in TF 2.2.1 or TF 2.3.x?", "Was able to run the code without any issues on [TF v2.2.0-rc2](https://colab.research.google.com/gist/amahendrakar/2ad5bccc80083753db0f6657c83ef1ab/38459.ipynb). \r\n\r\nFacing an error stating `ValueError: Both 'mean' and 'variance' must be None when is_training is True and exponential_avg_factor == 1.0.`, while running on [TF-nightly](https://colab.research.google.com/gist/amahendrakar/e85b2e37339e4c478b666b53edab264f/38459-tf-nightly.ipynb#scrollTo=aDTL7bbKf82y). Please find the attached gist. Thanks!", "Hi @siavash-khodadadeh, @khimraj  , I think  tf-nightly-2.2.0-dev20200412 is the latest build(12/04/2020) than tf-2.2.0-rc2(28/03/2020) . Generally it should not throw an error since if is_training is true  that implies whitening is done on the same input batch rather than over the moving average statistic of the set.  ", "Hello @abhilash1910, Sorry, I did not get what you mean by whitening. I checked and when training is False, there is no issue. The only problem is when is_training is True and if I understand you correctly, this is a bug and should be fixed. ", "Hi @siavash-khodadadeh ,by whitening I mean using the mean as 0 and sd/variance as 1 before passing an input vector xi {1,2...m} through an activation unit .I think according to the implementation there is mention of a batch normalised vector value X = x-E[x]/sqrt(var(x) + epsilon) where E[x] is the expectation and epsilon is just added to prevent division by 0. There are other parameters gamma and beta which govern the gradient step (scale and shift rule).During training as false there is a moving average over the input vector of previous layers which is \"whitened\" by applying the above metric and then passed into the activation units  - relu sigmoid etc of the current layer. Yes you are correct this should not be occurring if is_training is true because in that case there is no need of such moving statistic over previous layers,input  batch of current state is whitened and used.If mean and variance are none in this case(training=true) then it is not possible to determine the normalised value which is to be passed into the activation unit. ", "@abhilash1910 Thank you for your explanation.", "Sure @siavash-khodadadeh , glad I could help. ", "Hi @siavash-khodadadeh , @ymodak ,@khimraj ,@amahendrakar in the latest nightly release- tf-nightly 2.2.0.dev20200416 the issue is present. I found that according to this commit :https://github.com/tensorflow/tensorflow/commit/84f2ec1d60b5bb14a59ccef8f8fa7eb5a1096e8f#diff-ef8609a43751227afcaacc838670a96f    on  https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/nn_impl.py  ,there is mention that if exponential_avg_factor==1.0and is _training ==true ,then the mean and variance should be none. By comparing commits , I found that since is_training  considers current batch inputs,by setting the exponential average to 1 would imply effective mean =0 and variance=0 (mean=(1-exponential_average_factor)*mean + mean_batch*exponential_average_factor) and same for variance). However, I think this requires further analysis since  momentum can be 0 on a current input batch and this should not raise exception on mean and variance values since it only belongs to the current batch.", "@abhilash1910 \r\nI wanted to ask a question. When we set the momentum to zero during training=True, we expect the moving mean and moving variance to be updated based on just the latest batch the model sees. Is that correct?", "Yes @siavash-khodadadeh , that is correct . ", "Thank you for your response, @abhilash1910. Just wanted to make sure that I understood it accurately.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38459\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38459\">No</a>\n"]}, {"number": 38458, "title": "Uncertain training and validation generators behaviour", "body": "**System information** \r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution: Windows 10 Home N 1909 \r\n- TensorFlow installed from: Anaconda\r\n- Python version: 3.7\r\n- CUDA/cuDNN version: 10.0\r\n- GPU model and memory: GeForce RTX 2060\r\n\r\n**Describe the current behavior**\r\n\r\nThe generator function for images datasets that I'm using is as follow:\r\n\r\n```python\r\ndef generator(batchsize, epochs, epoch_steps, train=False, val=False, test=False, shuffle=False):\r\n    with tf.Session() as sess:      \r\n        if (train):\r\n            dataset = tf.data.Dataset.from_generator(lambda: image_gen(train_paths, train_scores),\r\n                                                      output_types=(tf.float32, tf.float32))\r\n        elif(val):\r\n            dataset = tf.data.Dataset.from_generator(lambda: image_gen(val_paths, val_scores),\r\n                                                      output_types=(tf.float32, tf.float32))\r\n        else:\r\n            dataset = tf.data.Dataset.from_generator(lambda: image_gen(test_paths),\r\n                                                      output_types=(tf.float32))       \r\n\r\n        if (shuffle and train):\r\n            dataset = dataset.shuffle(buffer_size=dataset_size(train=True)) \r\n        elif (shuffle and val):\r\n                dataset = dataset.shuffle(buffer_size=dataset_size(val=True)) \r\n        elif (shuffle and test):\r\n                dataset = dataset.shuffle(buffer_size=dataset_size(test=True)) \r\n            \r\n        dataset = dataset.batch(batchsize)\r\n        dataset = dataset.map(pre_processing_image,\r\n                              num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\n        dataset = dataset.prefetch(1)\r\n        dataset = dataset.repeat(count = -1)\r\n        \r\n        iterable = tf.data.make_initializable_iterator(dataset)\r\n        batch = iterable.get_next()\r\n        sess.run(iterable.initializer)\r\n        \r\n        while True:\r\n            try:\r\n                data = sess.run(batch)\r\n                yield data\r\n            except:\r\n                break\r\n```\r\n\r\nHow the training script uses these generators is:\r\n\r\n```python\r\ntraining_steps = math.ceil(dataset_training_size / batchsize)\r\nval_steps = math.ceil(dataset_val_size / batchsize)    \r\n    \r\n# Training and validation generator functions\r\ntrain_generator = generator(batchsize=batchsize,\r\n                            epochs = epochs_to_train,\r\n                            epoch_steps = training_steps, \r\n                            train=True, \r\n                            shuffle=True)\r\nval_generator = generator(batchsize=batchsize,\r\n                          epochs = epochs_to_train,\r\n                          epoch_steps = val_steps,\r\n                          val=True)\r\n\r\nmodel.fit_generator(generator=train_generator,\r\n                    steps_per_epoch=training_steps,\r\n                    epochs=epochs_to_train+loaded_epoch,\r\n                    verbose=1,\r\n                    callbacks=callBacks,\r\n                    initial_epoch=loaded_epoch,\r\n                    validation_data=val_generator,\r\n                    validation_steps=val_steps)\r\n```\r\n\r\nBoth training and validation datasets are very large while the batch size is a lot smaller, also the last step of each epoch has less images compared to the previous (dataset_size%batch_size != 0). What I want to accomplish during each epoch, for both generators, is to use all images one time only, possibly with randomness in their order during the training and not during the validation.\r\nI made some tests with the following code and they the results are what I expect them to be\r\n\r\n```python\r\na = []\r\nb = []\r\n\r\ntry:\r\n    for i in range(training_steps * epochs_to_train):\r\n        a.append(next(train_generator))\r\nexcept:\r\n    pass\r\n\r\ntry:    \r\n    for el in range(val_steps * epochs_to_train):\r\n        b.append(next(val_generator))\r\nexcept:\r\n    pass\r\n```\r\n\r\nThe current main problem with my code is that at the end of the last epoch I get this error:\r\n\r\n```\r\nIndexError: pop from empty list\r\nException ignored in: <generator object generator at 0x00000226437494C8>\r\nTraceback (most recent call last):\r\n  File \"...\", line 448, in generator\r\n    break\r\n  File \"...\", line 1621, in __exit__\r\n    self._default_graph_context_manager.__exit__(exec_type, exec_value, exec_tb)\r\n  File \"...\\Anaconda3\\envs\\tensorflow\\lib\\contextlib.py\", line 119, in __exit__\r\n    next(self.gen)\r\n  File \"...\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 5484, in get_controller\r\n    context.context().context_switches.pop()\r\n  File \"...\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\context.py\", line 237, in pop\r\n    self.stack.pop()\r\nIndexError: pop from empty list\r\n```\r\n\r\nThis error is present for both generators but I think it isn't a complete issue, the training seems to end anyway and all models are correctly saved. I just don't know how to remove that exception and I don't want to publish the code with it.\r\nI tried to mess with everything regarding mostly\r\n\r\n```python\r\nwhile True:\r\n     try:\r\n         data = sess.run(batch)\r\n         yield data\r\n     except:\r\n         break\r\n```\r\n\r\nbut I couldn't find a setup that ended the training without any exception.\r\n\r\nThe only similar issue that I could find online was https://stackoverflow.com/questions/52303130/keras-generator-with-tensorflow-dataset-api-indexerror-pop-from-empty-list/52304848 but the solution isn't working for me.\r\n\r\nAlso, during my various attempts I tried to change the generators as follow \r\n\r\n```python\r\n#dataset = dataset.repeat(count = -1)\r\ndataset = dataset.repeat(count = epochs)\r\n```\r\n\r\n```python\r\ncnt = 0\r\n#while True:\r\nwhile cnt < epochs * epoch_steps\r\n            try:\r\n                data = sess.run(batch)\r\n                cnt+=1\r\n                yield data\r\n            except:\r\n                break\r\n```\r\nbut in both cases I get the following error after some epochs:\r\n\r\n```\r\n  File \"...\\train_model.py\", line 325, in <module>\r\n    main()\r\n\r\n  File \"...\\train_model.py\", line 305, in main\r\n    validation_steps=val_steps)\r\n\r\n  File \"...\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\", line 1296, in fit_generator\r\n    steps_name='steps_per_epoch')\r\n\r\n  File \"...\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_generator.py\", line 323, in model_iteration\r\n    steps_name='validation_steps')\r\n\r\n  File \"...\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_generator.py\", line 221, in model_iteration\r\n    batch_data = _get_next_batch(generator)\r\n\r\n  File \"...\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_generator.py\", line 363, in _get_next_batch\r\n    generator_output = next(generator)\r\n\r\n  File \"...\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\data_utils.py\", line 922, in get\r\n    six.reraise(*sys.exc_info())\r\n\r\n  File \"...\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\six.py\", line 703, in reraise\r\n    raise value\r\n\r\n  File \"...\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\data_utils.py\", line 898, in get\r\n    inputs = self.queue.get(block=True).get()\r\n\r\n  File \"...\\Anaconda3\\envs\\tensorflow\\lib\\multiprocessing\\pool.py\", line 657, in get\r\n    raise self._value\r\n\r\n  File \"...\\Anaconda3\\envs\\tensorflow\\lib\\multiprocessing\\pool.py\", line 121, in worker\r\n    result = (True, func(*args, **kwds))\r\n\r\n  File \"...\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\utils\\data_utils.py\", line 832, in next_sample\r\n    return six.next(_SHARED_SEQUENCES[uid])\r\n\r\n  File \"...\", line 448, in generator\r\n    break\r\n\r\n  File \"...\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py\", line 1621, in __exit__\r\n    self._default_graph_context_manager.__exit__(exec_type, exec_value, exec_tb)\r\n\r\n  File \"...\\Anaconda3\\envs\\tensorflow\\lib\\contextlib.py\", line 119, in __exit__\r\n    next(self.gen)\r\n\r\n  File \"...\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py\", line 5484, in get_controller\r\n    context.context().context_switches.pop()\r\n\r\n  File \"...\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\context.py\", line 237, in pop\r\n    self.stack.pop()\r\n\r\nIndexError: pop from empty list\r\n\r\n```\r\n\r\nTo my understanding if epochs and epoch_steps are set as the # of epochs and the steps for each epoch there shouldn't have been any problem..\r\n\r\nI wrote here on GitHub because I'm not sure this is me not understanding what is wrong with my generators or if there is a bug. I didn't provide a complete code because it is very long and I think the important parts are present, if you need more informations I can provide them", "comments": ["@korr4k, Thanks for reporting this issue,\r\nCan you share the complete code to reproduce the issue. Thanks", "Ok, I attached an archive with a simplified version of my code that still results in \"IndexError: pop from empty list\".\r\nThe archive is complete and you just have to run the script **train.py**.\r\nI clearly had to adjust the datasets to make them a lot smaller but it shouldn't matter: both training and evaluation datasets have only 5 images. Both batchsize and the epochs to train are **2**\r\n\r\n[Tmp.zip](https://github.com/tensorflow/tensorflow/files/4469630/Tmp.zip)", "@korr4k \r\nThe code provided is to large to replicate, can you please share a simple stand alone code or please share a colab gist so we can analyse the issue faced.", "@Saduf2019 let me know if this colab is ok with you\r\n\r\nhttps://colab.research.google.com/drive/1TDK9UBdRR4OaCQUY81W5O7cpMDtGfIOy?usp=sharing\r\n\r\nNote that this is just a simple code that and the training parameters (dataset, epochs, etc..) have no realistic meaning but being an easy combination to reproduce my issue.\r\n\r\nAs you can see the training has no problem until the very last moment", "@korr4k\r\nI do not have access to the code shared.", "@Saduf2019 \r\nThis should work: https://colab.research.google.com/gist/korr4k/620c35e21b42e5c8af0ef1a4773519a6/test.ipynb#scrollTo=mLCo5X1cpReT\r\n\r\nI suppose you can't run it unless you upload the required .npy files, if you need them they are all inside the zip I provided in my previous comment", "@korr4k \r\nI ran the above code  with all the files shared but do not face the error faced by you.\r\nplease find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/6985174a391409e51703b7442e2b2ea5/untitled168.ipynb)", "@Saduf2019 the gist you provided hasn't even completed the training, why so? Mine does and it is at the end of it that the problem I reported occurs.\r\nI see that you also haven't specified to use tf 1.x and not 2.x, which to my understanding is the default for Colab, as I did", "@korr4k \r\nI ran the code on nightly as well and the execution does not complete and same error is faced. please find the [gist here](https://colab.sandbox.google.com/gist/Saduf2019/f4cb2129e1fc25b57fbae71ac60867c5/untitled171.ipynb)", "@Saduf2019 I guess I'll have to make it very clear, I'm not using Tensorflow 2. As you can see from my gist, the first cell is \"%tensorflow_version 1.x\" which forces Colab to use tf 1.x\r\n\r\nMy code, as you have already proven, isn't compatible with tf 2 but it also was never my intention to be so as I'm working with tf 1.15 on my local machine", "@korr4k I was able to reproduce your issue. \r\n![image](https://user-images.githubusercontent.com/47574994/83806002-aa762a80-a665-11ea-9a3e-7585fc6c1e49.png)\r\n", "Hi There,\n\n We are checking to see if you still need help on this, as you are using an older version of tensorflow which is officially considered end of life . We recommend that you upgrade to the latest 2.x version and let us know if the issue still persists in newer versions. Please open a new issue for any help you need against 2.x, and we will get you the right help. \n\n This issue will be closed automatically 7 days from now. If you still need help with this issue, please provide us with more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38458\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38458\">No</a>\n"]}, {"number": 38457, "title": "Random NaN loss when using float16 dtype and batch size of 1", "body": "__System information__ \r\n- Platform: Ubuntu Linux (Kernel 5.3) with Python 3.6.9 **OR** Google Colab\r\n- Tested on TensorFlow: TF v2.1.0 and TF v2.2.0rc2\r\n\r\n__Background__\r\nI came across the following bug in one of my Tensorflow projects and was able to successfully reproduce the bug with minimal code in a Google colab. Please see the link to this colab below. The execution of this colab also shows the bug occuring in iteration 248.\r\n\r\n__Reproducing Code__\r\nsee: [https://colab.research.google.com/drive/1ZzeqGSOKL5qw9j7XPqdlkHQvFAZETU5O](https://colab.research.google.com/drive/1ZzeqGSOKL5qw9j7XPqdlkHQvFAZETU5O)\r\n\r\n```\r\nimport math\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n\r\nif __name__ == '__main__':\r\n\r\n    x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\r\n    y = np.array([[0], [1], [1], [0]])\r\n\r\n    loss_function = tf.keras.losses.BinaryCrossentropy()\r\n\r\n    for i in range(2000):\r\n        if i % 100 == 0:\r\n            print(\"Iteration {}\".format(i))\r\n\r\n        model = tf.keras.Sequential([\r\n            tf.keras.layers.Dense(units=1, activation='tanh', dtype=tf.float16)])\r\n\r\n        model.compile(optimizer='sgd', loss=loss_function)\r\n        model.fit(x=x, y=y, epochs=1, batch_size=1)\r\n\r\n        loss_result = loss_function(y, model(x))\r\n\r\n        if math.isnan(loss_result):\r\n            raise RuntimeError('NAN Error in iteration {}'.format(i))\r\n```\r\n\r\n__Behaviour Description__\r\nSeemingly non-deterministic occurence of a NaN result when calculating loss of a very simple Dense Model. The NaN loss seems to happen randomly and can occur on the 60th or 600th iteration. In the supplied Google colab code it happened in the 248th iteration. The bug only seems to occur using a dtype of float16 and batch_size of 1. Debugging the error lead me to see that the models producing a NaN loss seem to have been initialized with a NaN bias and kernel, though I couldn't get to the bottom of why.\r\n", "comments": ["i am able to replicate [this issue](https://colab.sandbox.google.com/gist/Saduf2019/145f094f4cab5ef14028a050aa2c53e3/38461.ipynb)", "@PaulPauls I think we need to use [`mixed_precision`](https://www.tensorflow.org/guide/mixed_precision) to avoid any instability issues coming due to mixed precision. \r\n\r\nWhen I added the following line to your code, it doesn't throw the error you are noticing.\r\n```\r\nfrom tensorflow.keras.mixed_precision import experimental as mixed_precision\r\n\r\npolicy = mixed_precision.Policy('mixed_float16')\r\nmixed_precision.set_policy(policy)\r\n```\r\n\r\nPlease check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/3b61ebeab8c397349b5c22c2e83f5fe6/38461.ipynb) with CPU and [here](https://colab.research.google.com/gist/jvishnuvardhan/b445ffe0bccf6a40bf091cb41694402c/untitled27.ipynb) is with GPU. Thanks!", "Thanks for offering a hotfix @jvishnuvardhan! I tried out setting the ``mixed_precision`` policy and it did indeed solve the problem, however the performance loss is considerable. \r\n\r\nI tried out timing the [original code](https://colab.research.google.com/drive/19hryWYHCGhDvzNh3DwtGLPFESuMmZ0Tt?usp=sharing) vs the [hotfixed code](https://colab.research.google.com/drive/1nH4WymavPJKVWTK56oU4_dpfxlXxysgI?usp=sharing) and the hotfixed code required nearly twice as much processing time on CPU (152s vs 260s). Similar results when using a GPU: I couldn't get access to a colab GPU as they were all being used but when I timed in on my private machine with a GeForce 2070 the timing results were 92s vs 147s.\r\n\r\nEffectively for me this means that it is more sensible to check for the occasional NaN result and recreate the model rather than permanently change the mixed precision policy. \r\n\r\nStill, thanks for taking on the issue! I hope others will benefit from this hotfix. =)", "@PaulPauls We cannot compare the performance with CPU as the `mixed_precision API` throws a warning as follows\r\n\r\n> WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\r\n> The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\r\n> If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\r\n\r\nRegarding GPU performance with `mixed_precision API`, may be you can open another issue.\r\n\r\nI am closing this issue as the original issue was resolved. Please feel free to reopen if I am mistaken. thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38457\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38457\">No</a>\n"]}, {"number": 38456, "title": "apply_gradients() return error unexpected keyword argument 'all_reduce_sum_gradients' using official.nlp.optimization", "body": "System information\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab\r\nTensorFlow version and how it was installed (source or binary): tf-nightly 2.2.0-dev20200408 (pip install) and 2.1 stable version\r\nTensorFlow-Addons version and how it was installed (source or binary):\r\nPython version:\r\nIs GPU used? (yes/no): TPU\r\nDescribe the bug\r\n\r\nA clear and concise description of what the bug is.\r\n\r\nCode to reproduce the issue\r\n////start code\r\noptimizer = optimization.create_optimizer(\r\ninit_lr=INIT_LR,\r\nnum_train_steps=NB_BATCHES_TRAIN, # per epochs\r\nnum_warmup_steps=WARMUP_STEPS)\r\n\r\ndef squad_loss_fn(labels, model_outputs):\r\nstart_positions = labels['start_positions']\r\nend_positions = labels['end_positions']\r\nstart_logits, end_logits = model_outputs\r\n\r\nstart_loss = tf.keras.backend.sparse_categorical_crossentropy(\r\n    start_positions, start_logits, from_logits=True)\r\n\r\nend_loss = tf.keras.backend.sparse_categorical_crossentropy(\r\n    end_positions, end_logits, from_logits=True)\r\n\r\ntotal_loss = (tf.reduce_mean(start_loss) + tf.reduce_mean(end_loss)) / 2\r\nreturn total_loss\r\ntrain_loss = tf.keras.metrics.Mean(name=\"train_loss\")\r\n\r\nbert_squad.compile(optimizer,\r\nsquad_loss_fn)\r\n\r\nTraining loop\r\nNB_EPOCHS = 3\r\nfor epoch in range(NB_EPOCHS):\r\nprint(\"Start of epoch {}\".format(epoch+1))\r\nstart = time.time()\r\n\r\ntrain_loss.reset_states() \r\n\r\nfor (batch, (inputs, targets)) in enumerate(train_dataset_light):\r\n    with tf.GradientTape() as tape:\r\n      model_outputs = bert_squad(inputs)\r\n      loss = squad_loss_fn(targets, model_outputs)\r\n    grads = tape.gradient(loss, bert_squad.trainable_variables) \r\n    optimizer.apply_gradients(zip(grads, bert_squad.trainable_variables))\r\n    #optimizer.apply_gradients(zip(grads, bert_squad.trainable_variables), name=None, all_reduce_sum_gradients=True))\r\n    \r\n    train_loss(loss)\r\n///// end code\r\n\r\nOther info / logs\r\n\r\nsame issue here : Missing argument in apply_gradients() in AdamW optimizer #1267", "comments": ["This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@sehamra \r\n\r\nCan you please help us with the simple standalone code with proper indentation to reproduce the issue in our environment.It helps us in localizing the issue faster.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38456\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38456\">No</a>\n"]}, {"number": 38455, "title": "SIGSEGV in  gemmlowp::PackSideBlockImpl tflite/C++ on Jetson Nano", "body": "I have been trying to build and use tflite on Jetson Nano. However, I am always running into SIGSEGV somewhere in the framework. E.g. with v.1.15.0:\r\n\r\nTF lite is built by cd'ing into the tools/make, calling the script for getting the dependencies and for building the generic aarch64_armv8-a.\r\n\r\nAny help or ideas for the reason would be appreciated.\r\n\r\nRegards\r\n\r\n#0  0x0000005555a46e4c in gemmlowp::PackSideBlockImpl<gemmlowp::SideMap<unsigned char const, (gemmlowp::SideMapOrder)0>, gemmlowp::PackedSideBlock<gemmlowp::KernelSideFormatInt8<gemmlowp::CellFormat<4, 16, (gemmlowp::CellOrder)1>, 1> > >::PackL2() ()\r\n#1  0x0000005555a52be0 in void gemmlowp::SingleThreadGemm<gemmlowp::KernelFormat<gemmlowp::KernelSideFormatInt8<gemmlowp::CellFormat<4, 16, (gemmlowp::CellOrder)1>, 1>, gemmlowp::KernelSideFormatInt8<gemmlowp::CellFormat<4, 16, (gemmlowp::CellOrder)1>, 1> >, unsigned char, unsigned char, gemmlowp::BitDepthParams<gemmlowp::OperandRange<1, 255>, gemmlowp::OperandRange<0, 255> >, (gemmlowp::MapOrder)1, (gemmlowp::MapOrder)0, (gemmlowp::MapOrder)1, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)1>, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)0>, std::tuple<gemmlowp::OutputStageBiasAddition<gemmlowp::VectorMap<int const, (gemmlowp::VectorShape)1> >, gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent, gemmlowp::OutputStageClamp, gemmlowp::OutputStageSaturatingCastToUint8> >(gemmlowp::SingleThreadGemmContext*, gemmlowp::KernelBase const&, gemmlowp::MatrixMap<unsigned char const, (gemmlowp::MapOrder)1> const&, gemmlowp::MatrixMap<unsigned char const, (gemmlowp::MapOrder)0> const&, gemmlowp::MatrixMap<unsigned char, (gemmlowp::MapOrder)1>*, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)1> const&, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)0> const&, std::tuple<gemmlowp::OutputStageBiasAddition<gemmlowp::VectorMap<int const, (gemmlowp::VectorShape)1> >, gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent, gemmlowp::OutputStageClamp, gemmlowp::OutputStageSaturatingCastToUint8> const&) ()\r\n#2  0x0000005555a53384 in void gemmlowp::MultiThreadGemm<gemmlowp::KernelFormat<gemmlowp::KernelSideFormatInt8<gemmlowp::CellFormat<4, 16, (gemmlowp::CellOrder)1>, 1>, gemmlowp::KernelSideFormatInt8<gemmlowp::CellFormat<4, 16, (gemmlowp::CellOrder)1>, 1> >, unsigned char, unsigned char, gemmlowp::BitDepthParams<gemmlowp::OperandRange<1, 255>, gemmlowp::OperandRange<0, 255> >, (gemmlowp::MapOrder)1, (gemmlowp::MapOrder)0, (gemmlowp::MapOrder)1, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)1>, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)0>, std::tuple<gemmlowp::OutputStageBiasAddition<gemmlowp::VectorMap<int const, (gemmlowp::VectorShape)1> >, gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent, gemmlowp::OutputStageClamp, gemmlowp::OutputStageSaturatingCastToUint8>, gemmlowp::GemmContext>(gemmlowp::GemmContext*, gemmlowp::KernelBase const&, gemmlowp::MatrixMap<unsigned char const, (gemmlowp::MapOrder)1> const&, gemmlowp::MatrixMap<unsigned char const, (gemmlowp::MapOrder)0> const&, gemmlowp::MatrixMap<unsigned char, (gemmlowp::MapOrder)1>*, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)1> const&, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)0> const&, std::tuple<gemmlowp::OutputStageBiasAddition<gemmlowp::VectorMap<int const, (gemmlowp::VectorShape)1> >, gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent, gemmlowp::OutputStageClamp, gemmlowp::OutputStageSaturatingCastToUint8> const&) ()\r\n#3  0x0000005555a54ad0 in void gemmlowp::DispatchGemmShape<unsigned char, unsigned char, gemmlowp::BitDepthParams<gemmlowp::OperandRange<1, 255>, gemmlowp::OperandRange<0, 255> >, (gemmlowp::MapOrder)1, (gemmlowp::MapOrder)0, (gemmlowp::MapOrder)0, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)0>, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)1>, std::tuple<gemmlowp::OutputStageBiasAddition<gemmlowp::VectorMap<int const, (gemmlowp::VectorShape)0> >, gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent, gemmlowp::OutputStageClamp, gemmlowp::OutputStageSaturatingCastToUint8>, gemmlowp::GemmContext>(gemmlowp::GemmContext*, gemmlowp::MatrixMap<unsigned char const, (gemmlowp::MapOrder)1> const&, gemmlowp::MatrixMap<unsigned char const, (gemmlowp::MapOrder)0> const&, gemmlowp::MatrixMap<unsigned char, (gemmlowp::MapOrder)0>*, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)0> const&, gemmlowp::VectorDup<int const, (gemmlowp::VectorShape)1> const&, std::tuple<gemmlowp::OutputStageBiasAddition<gemmlowp::VectorMap<int const, (gemmlowp::VectorShape)0> >, gemmlowp::OutputStageScaleInt32ByFixedPointAndExponent, gemmlowp::OutputStageClamp, gemmlowp::OutputStageSaturatingCastToUint8> const&) ()\r\n#4  0x0000005555a54d0c in tflite::optimized_ops::Conv(tflite::ConvParams const&, tflite::RuntimeShape const&, unsigned char const*, tflite::RuntimeShape const&, unsigned char const*, tflite::RuntimeShape const&, int const*, tflite::RuntimeShape const&, unsigned char*, tflite::RuntimeShape const&, unsigned char*, tflite::CpuBackendContext*) ()\r\n#5  0x0000005555a554d8 in void tflite::ops::builtin::conv::EvalQuantized<(tflite::ops::builtin::conv::KernelType)2>(TfLiteContext*, TfLiteNode*, TfLiteConvParams*, tflite::ops::builtin::conv::OpData*, TfLiteTensor*, TfLiteTensor*, TfLiteTensor*, TfLiteTensor*, TfLiteTensor*, TfLiteTensor*) ()\r\n#6  0x0000005555a6541c in TfLiteStatus tflite::ops::builtin::conv::Eval<(tflite::ops::builtin::conv::KernelType)2>(TfLiteContext*, TfLiteNode*) ()\r\n#7  0x00000055559d73a0 in tflite::Subgraph::Invoke() ()\r\n#8  0x00000055559647dc in tflite::Interpreter::Invoke() ()\r\n#9  0x0000005555960cc4 in ObjectDetector::infer(cv::Mat&) (this=0x7fffffe7d0, img=...)", "comments": ["What's the build command you used?", "Let me know if you still have the issue. Thanks."]}, {"number": 38454, "title": "Tensor array can't be read when passed as argument of tf.function decorated functions", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information** \r\n- Have I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): true\r\n- OS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or\r\nbinary): pip\r\n- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de410 2.1.0\r\n\r\n**Describe the current behavior**\r\nWhen trying to read from a tensor array _passed as an argument_ to a tf.function decorated function, it raises an OperatorNotAllowedError:\r\n\r\n> OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function.\r\n\r\n**Describe the expected behavior**\r\nIt should work the same way in autograph and eager mode\r\n\r\n**Standalone code to reproduce the issue** \r\n```python\r\ndef fun(a, tensor_array):\r\n    loss = tf.constant(0.)\r\n    x, y = tf.constant(0.), tf.constant(0.)\r\n    size = tensor_array.size()\r\n    for i in tf.range(size):\r\n        x, y = tensor_array.read(i)\r\n        loss += a * tf.abs(y - x) # Some dummy computation.\r\n    return loss\r\n\r\ndecorated_fun = tf.function(fun)\r\n\r\ndata = [(1., 1.)] * 10\r\na_tensor_array = tf.TensorArray(dtype=tf.float32, element_shape=[2,], size=0, dynamic_size=True)\r\na_tensor_array = a_tensor_array.unstack(data)\r\n\r\na_tensor = tf.constant(1.)\r\n\r\nprint(fun(a_tensor, a_tensor_array))\r\nprint(decorated_fun(a_tensor, a_tensor_array))\r\n```\r\n\r\nFull traceback:\r\n\r\n```\r\n ---------------------------------------------------------------------------\r\nOperatorNotAllowedInGraphError            Traceback (most recent call last)\r\n<ipython-input-36-fafbbc1bd984> in <module>\r\n     17 \r\n     18 print(fun(a_tensor, a_tensor_array))\r\n---> 19 print(decorated_fun(a_tensor, a_tensor_array))\r\n     20 \r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py in __call__(self, *args, **kwds)\r\n    566         xla_context.Exit()\r\n    567     else:\r\n--> 568       result = self._call(*args, **kwds)\r\n    569 \r\n    570     if tracing_count == self._get_tracing_count():\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py in _call(self, *args, **kwds)\r\n    613       # This is the first call of __call__, so we have to initialize.\r\n    614       initializers = []\r\n--> 615       self._initialize(args, kwds, add_initializers_to=initializers)\r\n    616     finally:\r\n    617       # At this point we know that the initialization is complete (or less\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py in _initialize(self, args, kwds, add_initializers_to)\r\n    495     self._concrete_stateful_fn = (\r\n    496         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n--> 497             *args, **kwds))\r\n    498 \r\n    499     def invalid_creator_scope(*unused_args, **unused_kwds):\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)\r\n   2387       args, kwargs = None, None\r\n   2388     with self._lock:\r\n-> 2389       graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n   2390     return graph_function\r\n   2391 \r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py in _maybe_define_function(self, args, kwargs)\r\n   2701 \r\n   2702       self._function_cache.missed.add(call_context_key)\r\n-> 2703       graph_function = self._create_graph_function(args, kwargs)\r\n   2704       self._function_cache.primary[cache_key] = graph_function\r\n   2705       return graph_function, args, kwargs\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   2591             arg_names=arg_names,\r\n   2592             override_flat_arg_shapes=override_flat_arg_shapes,\r\n-> 2593             capture_by_value=self._capture_by_value),\r\n   2594         self._function_attributes,\r\n   2595         # Tell the ConcreteFunction to clean up its graph once it goes out of\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    976                                           converted_func)\r\n    977 \r\n--> 978       func_outputs = python_func(*func_args, **func_kwargs)\r\n    979 \r\n    980       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py in wrapped_fn(*args, **kwds)\r\n    437         # __wrapped__ allows AutoGraph to swap in a converted function. We give\r\n    438         # the function a weak reference to itself to avoid a reference cycle.\r\n--> 439         return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    440     weak_wrapped_fn = weakref.ref(wrapped_fn)\r\n    441 \r\n\r\nC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py in wrapper(*args, **kwargs)\r\n    966           except Exception as e:  # pylint:disable=broad-except\r\n    967             if hasattr(e, \"ag_error_metadata\"):\r\n--> 968               raise e.ag_error_metadata.to_exception(e)\r\n    969             else:\r\n    970               raise\r\n\r\nOperatorNotAllowedInGraphError: in converted code:\r\n\r\n    <ipython-input-34-fafbbc1bd984>:6 fun  *\r\n        x, y = tensor_array.read(i)\r\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\tensor_array_ops.py:1137 read\r\n        return self._implementation.read(index, name=name)\r\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\tensor_array_ops.py:753 read\r\n        if index < 0:\r\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:757 __bool__\r\n        self._disallow_bool_casting()\r\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:523 _disallow_bool_casting\r\n        \"using a `tf.Tensor` as a Python `bool`\")\r\n    C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:510 _disallow_when_autograph_enabled\r\n        \" decorating it directly with @tf.function.\".format(task))\r\n\r\n    OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed: AutoGraph did not convert this function. Try decorating it directly with @tf.function.\r\n```", "comments": ["Was able to replicate the issue. Please find the gist [here](https://colab.sandbox.google.com/gist/gadagashwini/61067623ab18508db4cfd47ae7479c36/untitled502.ipynb). Thanks", "This is the same as #34683.\r\n\r\nAt the moment, the only workaround is to either convert the TensorArray to Tensor before passing it as argument ore returning it, or moving the code that creates and uses the TensorArray inside the tf.function.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38454\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38454\">No</a>\n"]}, {"number": 38452, "title": "tf.train.Checkpoint complain that tf.train.ExponentialMovingAverage instance is not a trackable object", "body": "My tensorflow versiong is 2.1.0, I built a model in the standard way of keras subclassing and saved it with tf.train.Checkpoint. It works fine in the following code:\r\n```\r\nmodel = ... # a subclassing model instance\r\nckpt = tf.train.Checkpoint(model=model)\r\nfor epoch in range(total_epochs):\r\n    ...   \r\n    ckpt.save(path)\r\n```\r\nWhen add the code of moving average as following:\r\n```\r\nmodel = ... # a subclassing model instance\r\nema = tf.train.ExponentialMovingAverage(decay=0.999, zero_debias=True)\r\nckpt = tf.train.Checkpoint(model=model, ema=ema)\r\nfor epoch in range(total_epochs):\r\n    ...   \r\n    ckpt.save(path)\r\n```\r\ncause this error:\r\n```\r\nValueError: `Checkpoint` was expecting a trackable object (an object derived from `TrackableBase`), \r\ngot <tensorflow.python.training.moving_averages.ExponentialMovingAverage object at 0x7f63c8070a58>.\r\nIf you believe this object should be trackable (i.e. it is part of the TensorFlow Python API and manages state), please open an issue.\r\n```\r\n\r\nIs that `tf.train.ExponentialMovingAverage` incompatible with tf2? What's the best practice to do moving average in tf2?", "comments": ["@naturomics \r\n\r\nCan you please share colab  link or minimal standalone code to reproduce the issue in our environment.It helps us in localizing the issue faster. Thanks!", "@ravikyram \r\nPlease see this [gist](https://colab.research.google.com/drive/1IyWDGC1CFLkzlHdsBHteJxSdn-ShaX51).", "I have tried on colab with TF version 2.1.0 , 2.2-rc2 and was able to reproduce the issue.Please, find the gist [here](https://colab.sandbox.google.com/gist/ravikyram/6662f97163c2735f11707f9d4743af02/untitled769.ipynb). Thanks!", "Any update?", "I'm also interested in saving the EMA variables in a checkpoint.", "Was able to reproduce your issue in Tf Nightly 2.6.0-dev20210525, please find the gist [here](https://colab.research.google.com/gist/sachinprasadhs/3b8a3263138dc994455f20bdbe93883d/38452.ipynb). Thanks!", "Hi @naturomics ! We are checking to see whether you still need help in this issue .                                                                            As this [document](https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage) suggests although EMA objects are not directly trackable ,you can use average() to return the moving average variables for your model weights, which you can then checkpoint. Attaching Modified [Gist](https://colab.sandbox.google.com/gist/mohantym/f6c2f217efa72927625cee1be9ddf235/38452.ipynb#scrollTo=xmj4nHd5MKbz) for reference. Thanks!\r\n\r\n![image](https://user-images.githubusercontent.com/86464649/145236036-65bacdcb-d5c2-4bad-8225-8c8bdcfe7377.png)\r\n", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38452\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/38452\">No</a>\n"]}, {"number": 38451, "title": "The saved preview image is a green image (tensorflow lite object detection android demo)", "body": "I try to deploy the [tensorflow lite object detection android demo](https://github.com/tensorflow/examples/tree/master/lite/examples/object_detection/android) on streaming media rearview mirror,it is something like this:\r\n![image](https://user-images.githubusercontent.com/43233772/79041066-72cba300-7c1f-11ea-983f-488ee4bdb7f8.png)\r\nand it is android 5.1(API 22) OS, it use android.hardware.Camera API instead of Camera2 API.\r\nThe result is the app can preview, but doesn't show any prediction box. \r\nAfterwards, i set SAVE_PREVIEW_BITMAP = true, and found the cause is the input image is not correct, the saved preview bitmap is just a green image:\r\n![croppedBitmap-300300-1586578626229](https://user-images.githubusercontent.com/43233772/79041173-3c425800-7c20-11ea-9a95-a881c5de2a1d.jpg)\r\nSo how to debug it ? thanks !\r\n", "comments": ["Did you run it from the real device (like Android phones) or the emulator on laptop?\r\n\r\nI don't know the exact behavior of such a device you show. The thing I knew was for emulator, it gave fake images for testing.", "> Did you run it from the real device (like Android phones) or the emulator on laptop?\r\n> \r\n> I don't know the exact behavior of such a device you show. The thing I knew was for emulator, it gave fake images for testing.\r\n\r\nAfterward, I knew that although Android 5.1 does not fully support camera2, it is still usable, so  i commented out `useCamera2API =\r\n            (facing == CameraCharacteristics.LENS_FACING_EXTERNAL)\r\n                || isHardwareLevelSupported(\r\n                    characteristics, CameraCharacteristics.INFO_SUPPORTED_HARDWARE_LEVEL_FULL);` and I forced set `useCamera2API = true;` , the app's detection can finnaly works !", "> Did you run it from the real device (like Android phones) or the emulator on laptop?\r\n> \r\n> I don't know the exact behavior of such a device you show. The thing I knew was for emulator, it gave fake images for testing.\r\n\r\nOne issue fixed, another one comes up, that is rgbFrameBitmap is left and right reverse, below image is the part of the screenshot, we can see the text is symmetry reverse, so how to flip horizontally the rgbFrameBitmap ?\r\n![image](https://user-images.githubusercontent.com/43233772/79688488-37655000-8281-11ea-8e1a-2fba64e55adf.png)\r\n", "Hi Weida, it might be commonly asked. You might want to check this [stackoverflow answer.](https://stackoverflow.com/questions/36493977/flip-a-bitmap-image-horizontally-or-vertically)", "> Hi Weida, it might be commonly asked. You might want to check this [stackoverflow answer.](https://stackoverflow.com/questions/36493977/flip-a-bitmap-image-horizontally-or-vertically)\r\n\r\nI have just solved this problem, in **ImageUtils.java** 's  **convertYUV420ToARGB8888()**, modify `pUV + (i >> 1) * uvPixelStride`   to `pUV + (uvRowStride -1 - (i >> 1) * uvPixelStride)` AND modify `yData[pY + i]` to `yData[pY + (yRowStride-1-i)]` , everything workd well again ~"]}]