[{"number": 29024, "title": "Dataset passed to group_by_window's reduce_func is a DatasetV2 instead of DatasetV1", "body": "**System information**\r\n- Have I written custom code: Yes\r\n- OS Platform and Distribution: Ubuntu 18.04\r\n- TensorFlow installed from: binary\r\n- TensorFlow version: 1.14.0rc0\r\n- Python version: 3.6.6\r\n\r\n**Describe the current behavior**\r\n\r\nIn 1.14.0rc0, the dataset passed to the `reduce_func` function of `tf.data.experimental.group_by_window` is a `DatasetV2` instance instead of `DatasetV1`.\r\n\r\n**Describe the expected behavior**\r\n\r\nIn TF V1, the dataset instance should inherit from `DatasetV1`, not `DatasetV2`.\r\n\r\n**Code to reproduce the issue**\r\n\r\nThe following code raises an assertion error:\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\ndef _reduce_func(key, dataset):\r\n    assert isinstance(dataset, tf.data.Dataset)\r\n    return dataset.batch(5)\r\n\r\ndataset = tf.data.Dataset.range(100)\r\ndataset = dataset.apply(tf.data.experimental.group_by_window(\r\n    lambda x: x % 2, _reduce_func, window_size=5))\r\n```\r\n\r\n**Other info / logs**\r\n\r\nThis specifically breaks codes that use the V1 properties `output_*` within the `reduce_func` function.", "comments": ["@guillaumekln Can you please try the code in 2.0.0-alpha0 and let us know it progresses. Thanks!", "Of course it works in 2.0 but this issue is about the next V1 release and a code that used to work in previous versions.", "Thank you for reporting the problem @guillaumekln.\r\n\r\nThe `tf.data.Dataset.output_*` API is deprecated (see [documentation](https://www.tensorflow.org/versions/r1.14/api_docs/python/tf/data/Dataset)) and you can use `tf.data.get_output_*` instead (see [here](https://www.tensorflow.org/versions/r1.14/api_docs/python/tf/data/get_output_shapes)).\r\n\r\nTo be clear, I understand that the change in tf.data behavior breaks code that worked in TF 1.13 and I apologize for that. FWIW, the API that results in the breakage is marked as deprecated and the deprecation warning includes information about the replacement API.\r\n\r\nI was able to identify the root cause but the fix is non-trivial. Given the existence of replacement API and severity of the issue, my assessment is that we will not attempt to fix this.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=29024\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=29024\">No</a>\n"]}, {"number": 29023, "title": "Error occurred while compiling TensorFlow for Java ", "body": "Error occurred while compiling TensorFlow for Java \r\nHi guys. Can you help me to see why?\r\nThe following is the environment:\r\nGPU: no\r\nGcc:4.8\r\nTensorFlow: 1.7.1\r\nBazel: 0.10.0\r\n![image](https://user-images.githubusercontent.com/10007145/58367415-9572a180-7f11-11e9-9c37-f1cb06670748.png)\r\n", "comments": ["@mrchor Please have look on [Tensorflow for Java](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/java/README.md). Thanks!", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 29022, "title": "'Tensor' object has no attribute 'unstack'", "body": "@ry @jmhodges @eggie5 @bmabey @djones \r\nIs this a bug?\r\n![image](https://user-images.githubusercontent.com/30991932/58367256-d5388980-7f0f-11e9-8534-2fd81f95eff6.png)\r\nthe tensor is \r\n![image](https://user-images.githubusercontent.com/30991932/58367268-fbf6c000-7f0f-11e9-92a2-8a1b3346e8ef.png)\r\n\r\n", "comments": []}, {"number": 29021, "title": "[INTEL MKL] Modification to graph rewrite pass to enable rewrite for \u2026", "body": "\u2026MatMul-like ops, so that MKL optimization can be enabled/disabled by environmental variable TF_DISABLE_MKL", "comments": ["@cuixiaom Could you please resolve the conflicts? Thanks!", "> @cuixiaom Could you please resolve the conflicts? Thanks!\r\n\r\nresolved.", "@penpornk, I have changed the code at tensorflow/core/graph/mkl_layout_pass.cc:3642 in the previous commit from: \r\n\"     // Allow duplicate while adding control edge as it would fail (return\r\n      // NULL) if we try to add duplica\"\r\nto \r\n\"     // This Allows duplicate control edges be added in the new node if\r\n      // the original node has duplicate edges.\"", "> @cuixiaom Got it. Would you mind changing this to just not copy the duplicate edge(s) over, i.e., write a util to only call `AddControlEdge` when the edge isn't already there ? We don't want duplicate control edges anyway.\r\nyes, made changes as suggested.\r\n\r\n", "@cuixiaom Can you please check ubuntu sanity errors and keep us posted. Thank you.", "> @cuixiaom Can you please check ubuntu sanity errors and keep us posted. Thank you.\r\n\r\nfixed. thanks!"]}, {"number": 29020, "title": "[T.F 2.0 API Docs] Adding desc and example to math functions", "body": "This PR reference #25802\r\n\r\nAdded examples and explanation to:\r\n\r\n1. cos\r\n2. cosh\r\n3. sin\r\n4. sinh\r\n5. tan\r\n6. tanh\r\n\r\nThanks in advance", "comments": ["Need some more update. Will push changes soon.", "@martinwicke Completed changes. Please let me know if this looks good.", "@SSaishruthi Can you please check build failures? Thanks!", "> @SSaishruthi Can you please check build failures? Thanks!\r\n\r\nHi @gbaned @martinwicke \r\n\r\nI noticed the error in log files.\r\n```\r\nExecution platform: @org_tensorflow//third_party/toolchains:rbe_cuda10.0-cudnn7-ubuntu14.04\r\n2019-06-01 04:07:50.987236: F tensorflow/python/framework/python_op_gen_main.cc:123] Non-OK-status: api_def_map.LoadFileList(env, api_files) status: Invalid argument: Error parsing ApiDef file tensorflow/core/api_def/base_api/api_def_Sinh.pbtxt: 5(1): Expected identifier, got:\r\n```\r\n\r\nI am not sure where the error is as the format is similar to other file that got merged recently.\r\nAlso, there is an open issue related to this.\r\nhttps://github.com/tensorflow/tensorflow/issues/28871\r\n\r\nCan you please help me with this? I have similar issues with my other PRs", "Hi @gbaned \r\n\r\nIs everything fine with this PR?", "Hi @martinwicke \r\n\r\nLast time it was throwing an error in `sinh` and this time in `cosh`. Not sure what is happening here.\r\nCan you please help?\r\n", "That is pretty mysterious, I can't find anything wrong with the syntax. @josh11b does this look right to you? I says it's expecting an identifier, but as far as I can tell. the `<<END` thing is done correctly.", "Hi @gbaned @martinwicke \r\n\r\nIs there anything to be modified from my side? I some made some similar doc updates but not sure if it is ok to create PR without resolving this issue. Please suggest."]}, {"number": 29019, "title": "Create \u7f8e\u4eba\u8ba1", "body": "\u589e\u52a0\u4e00\u4f4d\u7f8e\u4eba", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F29019) for more info**.\n\n<!-- need_sender_cla -->"]}, {"number": 29018, "title": "[T.F 2.0 API Docs] Adding examples and explanations to math functions", "body": "This PR is related with issue #25802\r\n\r\nAdded details to the following functions:\r\n\r\n1. add_n\r\n2. asinh\r\n3. atanh\r\n\r\nThanks in advance.", "comments": ["@martinwicke Completed changes. Please let me know if this looks good.", "@SSaishruthi Can you please check build failures? Thanks!", "Hi @gbaned @martinwicke\r\n\r\nI noticed the error in log files.\r\n```\r\nExecution platform: @org_tensorflow//third_party/toolchains:rbe_cuda10.0-cudnn7-ubuntu14.04\r\n2019-06-01 05:00:14.254608: F tensorflow/python/framework/python_op_gen_main.cc:123] Non-OK-status: api_def_map.LoadFileList(env, api_files) status: Invalid argument: Error parsing ApiDef file tensorflow/core/api_def/base_api/api_def_AddN.pbtxt: 9(3): Expected identifier, got: \r\n```\r\nI noticed same issue raised by someone: https://github.com/tensorflow/tensorflow/issues/28871\r\n\r\nCan you please help me with this? I have similar issues with my other PRs", "Left a comment. May not be the only issue. ", "@martinwicke \r\nUpdated code as per the comment in other PR. Can you please trigger the test to see if that works?", "@martinwicke \r\nMade some updates. Can you please trigger the test?"]}, {"number": 29017, "title": "lite: filter out mirror when downlaoding Eigen", "body": "Eign is original stored on BitBucket and there is mirror on Bazel.\r\nIn `workspace.bzl`, the mirror is now hosted by tensorflow.org where\r\noften fail to download. So to filter out mirror.tensorflow.org.", "comments": ["Just ran into the problem while trying to build TFLite on my Pi, this helps a lot! \r\n\r\nThanks :)", "> Just ran into the problem while trying to build TFLite on my Pi, this helps a lot!\r\n> \r\n> Thanks :)\r\n\r\n Glad to hear :)", "Hi, just want to thank you for helping resolving this issue, since I also ran to this problem when installing the Tensorflow Lite for my RPi as well.\r\n\r\nOn that note, it seems that although the changes listed here has been approved, some checks failed which caused the merge to the master branch unsuccessful? I'm just wondering whether the TF admins can help sort this out as it is a very useful change for all of those who wants to install TF Lite natively on their RPi.\r\n\r\nThanks again, especially for @jackwish, and hopefully this fix can be successfully merged to the main branch in the future.", "> Hi, just want to thank you for helping resolving this issue, since I also ran to this problem when installing the Tensorflow Lite for my RPi as well.\r\n> \r\n> On that note, it seems that although the changes listed here has been approved, some checks failed which caused the merge to the master branch unsuccessful? I'm just wondering whether the TF admins can help sort this out as it is a very useful change for all of those who wants to install TF Lite natively on their RPi.\r\n> \r\n> Thanks again, especially for @jackwish, and hopefully this fix can be successfully merged to the main branch in the future.\r\n\r\nThank you, especially for your attention to the progress of this PR :) And, don't worry about the \"failed checks\", only the ones marked with `Required` must pass. PR which tagged with `ready-to-pull` will be merged automatically."]}, {"number": 29016, "title": "[T.F 2.0 API Docs] Adding details for acosh math function", "body": "Referring to issue  #25802\r\nAdded:\r\n- Description \r\n- Input range\r\n- Example\r\n\r\nIn order to reflect in doc, should I change in any file?\r\n\r\nThanks.", "comments": ["@dynamicwebpaige This address the issue #25802.\r\nWorking on other components", "Thanks, @martinwicke for the review\r\nI have added `inf` as one of the inputs. Is it ok to give as `float(\"inf\")` or I need to use `math.inf`?", "`float(inf)` is fine, I left some more comments. Please also apply the equivalent to your other PRs if they appear relevant.", "@martinwicke Completed changes. Please let me know if this looks good."]}, {"number": 29015, "title": "[INTEL MKL] Fix Error Loading Package @io_bazel_rules_docker", "body": "Upgrade to latest `bazel_rules v0.7.0` to Fix #28824 ", "comments": ["@pcloudy, Is this one of Bazel's normally-automatically-loaded packages? I'm not sure this should be locked in to this version, but I'm also uncertain why the linked Issue failed to build (does our CI not catch something?).", "@angersson, I also met the same problem in docker. this package is just need in docker.", "@xinan-jiang, can you provide more details, please, preferably on the original issue? I'd like to understand this issue better before accepting any patches. There's a useful text template you can use here: https://github.com/tensorflow/tensorflow/issues/new (but you don't need to create a new issue; it would be a duplicate of #28824 )", "@ashahba Did you get a chance to look on reviewer comments? Please let us know on the update. Thanks!", "@gbaned thanks for looking into this issue.\r\nI'll find sometime in the next couple of days to get more details on this.\r\n\r\nStay tuned please \ud83d\ude42 ", "@gbaned looks like I'm no longer able to reproduce this one.\r\nSo the PR doesn't seem to be needed anymore."]}, {"number": 29014, "title": "Refactor {Concatenate, Filter, FilterByLastComponent} DatasetOp", "body": "This PR refactors {`Concatenate`, `Filter`, `FilterByLastComponent`} DatasetOp.\r\n\r\ncc: @jsimsa ", "comments": ["Close this PR as `FilterByLastComponentDatasetOp` has been removed. Will submit a new one soon. "]}, {"number": 29013, "title": "Remove jessie-backports release validity check", "body": "Fixes:\r\nE: Release file for http://archive.debian.org/debian/dists/jessie-backports/InRelease is expired (invalid since 94d 2h 16min 15s). Updates for this repository will not be applied.\r\n\r\nSolution: https://www.lucas-nussbaum.net/blog/?p=947", "comments": []}, {"number": 29012, "title": "[INTEL MKL] MKL cleanup - remove out-dated MKL ", "body": "Remove source file core/kernels/mkl_conv_grad_bias_ops.cc\r\nwhich only contains outdated MKL ML implementation.", "comments": []}, {"number": 29011, "title": "could not create a primitive descriptor iterator, in file tensorflow/core/kernels/mkl_relu_op.cc:871", "body": "I am using tensorflow 1.13.1 on mac os sierra.\r\nwhen I try to use tf.contrib.predictor.from_saved_model to do prediction on a trained model I get this error:\r\n\r\ncould not create a primitive descriptor iterator, in file tensorflow/core/kernels/mkl_relu_op.cc:871", "comments": ["@alexmil2019 In order to expedite the trouble-shooting process, please provide a minimal code snippet to reproduce the issue reported here. Thanks!", "Here is the code:\r\n```\r\ndef _get_predictor(export_dir):\r\n    return tf.contrib.predictor.from_saved_model(export_dir=export_dir)\r\n\r\ndef predict(export_dir, data_dir):\r\n    predictor = _get_predictor(export_dir) \r\n    feed_tensor = list(predictor.feed_tensors.keys())[0]\r\n    fetch_tensor = list(predictor.fetch_tensors.keys())[0]\r\n\r\n    feats = _compute_features(data_dir) # a generator to compute features\r\n    for feat in feats:\r\n        Y = predictor({feed_tensor: feat[:]})\r\n        r = Y[fetch_tensor]\r\n```\r\n", "@alexmil2019 Code snippet looks incomplete to reproduce the issue. Please provide code to reproduce the issue. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "I have the same problem:\r\n\r\nAbortedError: Operation received an exception:Status: 5, message: could not create a primitive descriptor iterator, in file tensorflow/core/kernels/mkl_relu_op.cc:871\r\n\t [[{{node activation_1/Relu}}]]\r\n\r\nIt is a keras and hyperas script. Hard to provide a code snippet to reproduce the error.", "it seems the problem is with multi gpu model. I created a model, I trained it with single gpu and it works but when I train it with multiple gpu, it gives this error. the codes are exactly the same. tf.keras, Estimator API, and tf.contrib.predictor.from_saved_model have issues with multi gpu training.\r\nI created a CNN model and tf.reshape gives an error on relu as well when trained with multi gpu.", "It may not be due to gpu because I got this error with cpu. ", "> It may not be due to gpu because I got this error with cpu.\r\n\r\nHey have you got solution for this. I am facing same problem on my CPU.", "> > It may not be due to gpu because I got this error with cpu.\r\n> \r\n> Hey have you got solution for this. I am facing same problem on my CPU.\r\n\r\nI don't remember exactly how I solved this. Maybe installing mkl package or something like that or updating keras. It might be also due to using generator. Currently, I am not using generator. I am using tf 2.0 in a conda env and importing keras from tf like from tensorflow.keras import etcetc."]}, {"number": 29010, "title": "archive.debian.net -> archive.debian.org", "body": "Missed this in https://github.com/tensorflow/tensorflow/pull/29009", "comments": []}, {"number": 29009, "title": "Change jessie-backports url to archive.debian.org", "body": "", "comments": []}, {"number": 29008, "title": "How to improve MKL performance? ", "body": "**system information**\r\n\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux\r\nTensorFlow installed from (source or binary): source\r\nTensorFlow version: 1.13.1\r\nPython version: 2.7.13\r\nGCC/Compiler version (if compiling from source): 5.4\r\nMKL  version: mklml_lnx_2019.0.3.20190220/\r\n\r\n**Describe the problem**\r\nMy steps are as follows:\r\n\r\n1. I trained with Python on GPU\r\n2. converted model with freeze_graph.py\r\n3. put it on CPU and use c++  for inference \r\n   (build tensorflow source with --config=mkl --copt=\"-DEIGEN_USE_VML\"\r\n\r\n**my MKL setting is**\r\nsetenv(\"KMP_BLOCKTIME\",\"0\",1);\r\nsetenv(\"KMP_SETTIONS\",\"1\",1);\r\nsetenv(\"KMP_AFFINITY\",\"granularity=fine,verbose,compact,1,0\",1);\r\nsetenv(\"OMP_NUM_THREADS\",num_of_theads.c_str(),1);\r\n\r\n**my model is bert**\r\n\r\n**my cpuinfo is** \r\nvendor_id\t: GenuineIntel\r\ncpu family\t: 6\r\nmodel\t\t: 79\r\nmodel name\t: Intel(R) Xeon(R) CPU E5-26xx v4\r\nstepping\t: 1\r\nmicrocode\t: 0x1\r\ncpu MHz\t\t: 2394.446\r\ncache size\t: 4096 KB\r\nphysical id\t: 0\r\nsiblings\t: 16\r\ncore id\t\t: 15\r\ncpu cores\t: 16\r\napicid\t\t: 15\r\ninitial apicid\t: 15\r\nfpu\t\t: yes\r\nfpu_exception\t: yes\r\ncpuid level\t: 13\r\nwp\t\t: yes\r\nflags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx lm constant_tsc rep_good nopl eagerfpu pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch bmi1 avx2 bmi2 rdseed adx xsaveopt\r\nbogomips\t: 4788.89\r\nclflush size\t: 64\r\ncache_alignment\t: 64\r\naddress sizes\t: 40 bits physical, 48 bits virtual\r\n\r\n**my test result  :**\r\n(C++ inference CPU)\r\na. use MKL :  200ms\r\nb. do not use MKL: 200ms\r\n\r\n\r\n**How can I improve performance\uff1f\uff1f**\r\n\r\n@Leslie-Fang  @TensorFlow-MKL \r\n\r\n", "comments": ["setenv(\"KMP_BLOCKTIME\",\"0\",1);\r\nsetenv(\"KMP_SETTIONS\",\"1\",1);\r\nsetenv(\"KMP_AFFINITY\",\"granularity=fine,verbose,compact,1,0\",1);\r\nsetenv(\"OMP_NUM_THREADS\",4,1);\r\n\r\n\r\nbatch_size_16_nomkl: 760ms\r\nbatch_size_16_mkl:350ms\r\n\r\nbatch_size_1_nomkl: 200ms\r\nbatch_size_1_mkl:   200ms\r\n\r\n**how can i change the mkl_setting to impove my batchsize_1 performance**\r\n@ymodak  @TensorFlow-MKL ", "Could you please try these settings\r\n\r\nKMP_AFFINITY=granularity=fine,verbose,compact,1,0\r\nKMP_BLOCKTIME=\t1\r\nOMP_NUM_THREADS=\t# of physical cores\r\nintra_op_parallelism_threads=# physical cores\r\ninter_op_parallelism_threads=1\r\n\r\nyou can set it using the code snippet before running the session\r\n```\r\nimport os\r\nos.environ[\"KMP_BLOCKTIME\"] = \"1\"\r\nos.environ[\"KMP_SETTINGS\"] = \"1\"\r\nos.environ[\"KMP_AFFINITY\"]= \"granularity=fine,verbose,compact,1,0\"\r\nos.environ[\"OMP_NUM_THREADS\"]= <# physical cores>\r\nconfig = tf.ConfigProto()\r\nconfig.intra_op_parallelism_threads = <# physical cores>\r\nconfig.inter_op_parallelism_threads = 1\r\ntf.Session(config=config)\r\n```\r\nalso enable hyperthreading if applicable", "echo with @preethivenkatesh \r\n@x666633 ```OMP_NUM_THREADS``` and ```intra_op_parallelism_threads``` set at the number of physical cores is one of the BKM.\r\n\r\nBTW: What's the build option of ```--copt=\"-DEIGEN_USE_VML\"```\r\nI see a relevant one ```EIGEN_USE_MKL_VML``` which stands for use Intel VML for mkl. \r\nIf we don't add this build option, which default would mkl use? @preethivenkatesh @TensorFlow-MKL ", "It\u2019s the same flag in both cases you mentioned. EIGEN_USE_MKL_VML is a macro. It can be used by passing via compiler preprocessing option -DEIGEN_USE_MKL_VML, where \u2013D (stands for define) is compiler flag which says macro should be applied to entire source during compilation. Also, this can be directly defined in a source by using directive #define EIGEN_USE_MKL_VML", "@x666633 please close this issue if we have answered your query "]}, {"number": 29007, "title": "[TF 2.0] Converted code from autograph.to_code has undefined variable name, causing 'NameError: x is not defined'", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): MacOS 10.12.6 (16G1815)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version: 3.6.5\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n2.0.0-dev20190521\r\n\r\n**Describe the current behavior**\r\ncurrently, the `autograph.to_code` covert the query function in the following code piece\r\n\r\n```\r\nimport random\r\nimport tensorflow as tf\r\n\r\n\r\nclass ImagePool():\r\n    def __init__(self, pool_size):\r\n        self.pool_size = pool_size\r\n        self.count = 0\r\n        self.images = []\r\n        print(tf.autograph.to_code(self.query))\r\n\r\n    def query(self, images):\r\n        if self.pool_size == 0:\r\n            return images\r\n        return_images = []\r\n        for image in images:\r\n            # if the buffer is not full; keep inserting current images to the buffer\r\n            if self.count < self.pool_size:\r\n                self.count = self.count + 1\r\n                self.images.append(image)\r\n                return_images.append(image)\r\n            else:\r\n                p = random.uniform(0, 1)\r\n                if p > 0.5:\r\n                    # by 50% chance, the buffer will return a previously stored image\r\n                    # and insert the current image into the buffer\r\n                    # randint is inclusive\r\n                    random_id = random.randint(0, self.pool_size - 1)\r\n                    tmp = self.images[random_id].clone()\r\n                    self.images[random_id] = image\r\n                    return_images.append(tmp)\r\n                else:\r\n                    # by another 50% chance, the buffer will return the current image\r\n                    return_images.append(image)\r\n        return return_images\r\n```\r\n\r\nto this:\r\n\r\n\r\n```\r\ndef tf__query(self, images):\r\n  do_return = False\r\n  retval_ = ag__.UndefinedReturnValue()\r\n  cond_2 = self.pool_size == 0\r\n\r\n  def get_state_2():\r\n    return self.count, self.images[random_id]\r\n\r\n  def set_state_2(vals):\r\n    self.count, self.images[random_id] = vals\r\n\r\n  def if_true_2():\r\n    do_return = True\r\n    retval_ = images\r\n    return retval_\r\n\r\n  def if_false_2():\r\n    return_images = []\r\n\r\n    def loop_body(loop_vars, self_count):\r\n      image = loop_vars\r\n      cond_1 = self_count < self.pool_size\r\n\r\n      def get_state_1():\r\n        return self_count, self.images[random_id]\r\n\r\n      def set_state_1(vals):\r\n        self_count, self.images[random_id] = vals\r\n\r\n      def if_true_1():\r\n        self_count = self_count + 1\r\n        ag__.converted_call('append', self.images, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (image,), None)\r\n        ag__.converted_call('append', return_images, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (image,), None)\r\n        return ag__.match_staging_level(1, cond_1)\r\n\r\n      def if_false_1():\r\n        p = ag__.converted_call('random', random, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (), None)\r\n        cond = p > 0.5\r\n\r\n        def get_state():\r\n          return self.images[random_id],\r\n\r\n        def set_state(vals):\r\n          self.images[random_id], = vals\r\n\r\n        def if_true():\r\n          random_id = ag__.converted_call('randint', random, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (0, self.pool_size - 1), None)\r\n          tmp = ag__.converted_call('clone', self.images[random_id], ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (), None)\r\n          self.images[random_id] = image\r\n          ag__.converted_call('append', return_images, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (tmp,), None)\r\n          return ag__.match_staging_level(1, cond)\r\n\r\n        def if_false():\r\n          ag__.converted_call('append', return_images, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (image,), None)\r\n          return ag__.match_staging_level(1, cond)\r\n        ag__.if_stmt(cond, if_true, if_false, get_state, set_state)\r\n        return ag__.match_staging_level(1, cond_1)\r\n      ag__.if_stmt(cond_1, if_true_1, if_false_1, get_state_1, set_state_1)\r\n      return self_count,\r\n    self.count, = ag__.for_stmt(images, None, loop_body, (self.count,))\r\n    do_return = True\r\n    retval_ = return_images\r\n    return retval_\r\n  retval_ = ag__.if_stmt(cond_2, if_true_2, if_false_2, get_state_2, set_state_2)\r\n  cond_3 = ag__.is_undefined_return(retval_)\r\n\r\n  def get_state_3():\r\n    return ()\r\n\r\n  def set_state_3(_):\r\n    pass\r\n\r\n  def if_true_3():\r\n    retval_ = None\r\n    return retval_\r\n\r\n  def if_false_3():\r\n    return retval_\r\n  retval_ = ag__.if_stmt(cond_3, if_true_3, if_false_3, get_state_3, set_state_3)\r\n  return retval_\r\n\r\ndef tf__query(self, images):\r\n  do_return = False\r\n  retval_ = ag__.UndefinedReturnValue()\r\n  cond_2 = self.pool_size == 0\r\n\r\n  def get_state_2():\r\n    return self.count, self.images[random_id]\r\n\r\n  def set_state_2(vals):\r\n    self.count, self.images[random_id] = vals\r\n\r\n  def if_true_2():\r\n    do_return = True\r\n    retval_ = images\r\n    return retval_\r\n\r\n  def if_false_2():\r\n    return_images = []\r\n\r\n    def loop_body(loop_vars, self_count):\r\n      image = loop_vars\r\n      cond_1 = self_count < self.pool_size\r\n\r\n      def get_state_1():\r\n        return self_count, self.images[random_id]\r\n\r\n      def set_state_1(vals):\r\n        self_count, self.images[random_id] = vals\r\n\r\n      def if_true_1():\r\n        self_count = self_count + 1\r\n        ag__.converted_call('append', self.images, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (image,), None)\r\n        ag__.converted_call('append', return_images, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (image,), None)\r\n        return ag__.match_staging_level(1, cond_1)\r\n\r\n      def if_false_1():\r\n        p = ag__.converted_call('random', random, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (), None)\r\n        cond = p > 0.5\r\n\r\n        def get_state():\r\n          return self.images[random_id],\r\n\r\n        def set_state(vals):\r\n          self.images[random_id], = vals\r\n\r\n        def if_true():\r\n          random_id = ag__.converted_call('randint', random, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (0, self.pool_size - 1), None)\r\n          tmp = ag__.converted_call('clone', self.images[random_id], ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (), None)\r\n          self.images[random_id] = image\r\n          ag__.converted_call('append', return_images, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (tmp,), None)\r\n          return ag__.match_staging_level(1, cond)\r\n\r\n        def if_false():\r\n          ag__.converted_call('append', return_images, ag__.ConversionOptions(recursive=True, force_conversion=False, optional_features=(), internal_convert_user_code=True), (image,), None)\r\n          return ag__.match_staging_level(1, cond)\r\n        ag__.if_stmt(cond, if_true, if_false, get_state, set_state)\r\n        return ag__.match_staging_level(1, cond_1)\r\n      ag__.if_stmt(cond_1, if_true_1, if_false_1, get_state_1, set_state_1)\r\n      return self_count,\r\n    self.count, = ag__.for_stmt(images, None, loop_body, (self.count,))\r\n    do_return = True\r\n    retval_ = return_images\r\n    return retval_\r\n  retval_ = ag__.if_stmt(cond_2, if_true_2, if_false_2, get_state_2, set_state_2)\r\n  cond_3 = ag__.is_undefined_return(retval_)\r\n\r\n  def get_state_3():\r\n    return ()\r\n\r\n  def set_state_3(_):\r\n    pass\r\n\r\n  def if_true_3():\r\n    retval_ = None\r\n    return retval_\r\n\r\n  def if_false_3():\r\n    return retval_\r\n  retval_ = ag__.if_stmt(cond_3, if_true_3, if_false_3, get_state_3, set_state_3)\r\n  return retval_\r\n```\r\n\r\n\r\nbut note that in the converted code\r\n\r\n\r\n```\r\n        def get_state():\r\n          return self.images[random_id],\r\n```\r\n\r\nthis is causing an undefined error: NameError: name 'random_id' is not defined\r\n\r\nthe reason I'm calling to_code to this class method is because i used it in a tf.function so i think autograph is going to convert this\r\n\r\n**Describe the expected behavior**\r\nthe code to be converted correctly\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\nas above\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Will it be possible to provide exact minimal code snippet that can depict the issue. This will help us to get more information and proceed faster. Thanks!", "Please help us to reproduce the issue. I have tried on Colab with TF version 2.0.0-dev20190606 and was able to run it successfully. Let us know if I am missing out anything. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=29007\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=29007\">No</a>\n"]}, {"number": 29006, "title": "ImportError: cannot import name 'text_summary'", "body": "I am trying to use -\r\nfrom tensorflow.python.summary import text_summary\r\nbut getting the error -\r\nImportError: cannot import name 'text_summary'\r\nHow do I fix it?", "comments": ["Okay, I found the solution. The problem was with the version of gin.config, So, installing a new version of gin.config fixes the error."]}, {"number": 29005, "title": "Group convolutions UnimplementedError for nightly build", "body": "I am getting the following error message while running the following code using the nightly version of tensorflow 1.14.1-dev20190524. When will this feature be available?\r\n\r\nCode:\r\n`weights = tf.ones([3,3,1,3])`\r\n`X = tf.ones([3,1024,1024,3])`\r\n`Y = tf.nn.conv2d(X, weights, [1, 1, 1, 1], \"VALID\")`\r\n\r\nError:\r\nUnimplementedError: Generic conv implementation does not support grouped convolutions for now.\r\n\t [[node Conv2D_4 (defined at <ipython-input-13-3298cb87493e>:4) ]]\r\n", "comments": ["@ahsabali I try reproducing the issue with tf-nightly-1.14.1.dev20190524 but the code executed without any error. Can you try once again and let us know if that still throws an error. Thanks!", "Here is the complete code snippet that is generating the error:\r\n\r\n`weights = tf.ones([3,3,1,3])`\r\n`X = tf.ones([3,1024,1024,3])`\r\n`Y = tf.nn.conv2d(X, weights, [1, 1, 1, 1], \"VALID\")`\r\n`sess = tf.Session()`\r\n`sess.run(Y)`\r\n`sess.close()`", "I am able to reproduce the mentioned issue with tf-nightly-1.14.1.dev20190524. ", "@aaroey can you take a look?", "@reedwm could you help to take a look?", "Grouped convolutions are currently only supported on GPUs, not CPUs. You are using a grouped convolution because the input channel dimension of 3 (`X.shape[3]`) does not match the filter in-depth dimension of 1 (`weights.shape[2]`). @chsigg, any idea when support is coming for CPUs?\r\n\r\nAlso the error message is a bit unclear. I'll fix the error message.", "Thanks for improving the error message. I have no idea if/when grouped\nconvs are supported on CPU.\n\nOn Thu, May 30, 2019 at 7:04 PM Reed <notifications@github.com> wrote:\n\n> Grouped convolutions are currently only supported on GPUs, not CPUs. You\n> are using a grouped convolution because the input channel dimension of 3 (\n> X.shape[3]) does not match the filter in-depth dimension of 1 (\n> weights.shape[2]). @chsigg <https://github.com/chsigg>, any idea when\n> support is coming for CPUs?\n>\n> Also the error message is a bit unclear. I'll fix the error message.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/29005?email_source=notifications&email_token=ABZM5DXIGGZWLTQLY5B3BM3PYACKRA5CNFSM4HPSHMOKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODWS4DZI#issuecomment-497402341>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABZM5DWPKNSV5GXKJ7VJIM3PYACKRANCNFSM4HPSHMOA>\n> .\n>\n", "For now grouped convolutions on CPU are only supported using [XLA](https://www.tensorflow.org/xla).\r\n\r\nYou can try it by using `@tf.function(experimental_compile=True)` (see [this colab](https://colab.research.google.com/drive/1M9jxNv3Y3a2lGlNLNg-rvdS7YxuN-Y1p)).", "Hey, are there any news regarding when grouped convolutions are available for CPU? Using tensorflow 2.4.0 and it seems that it is still not available.\r\n\r\nI can use it with `@tf.function(experimental_compile=True)`, but only with multiple retracing warnings.", "@sanjoy @cheshire could we use `@tf.function(experimental_compile=True)` by default for grouped convolutions, so that we don't have to implement this on the CPU?", "That sounds reasonable, though the performance can get pretty bad if there is a lot of dynamism in the shapes.\r\n\r\n@d0k WDYT?", "CC @tatianashp ", "> That sounds reasonable, though the performance can get pretty bad if there is a lot of dynamism in the shapes.\r\n\r\nYou get both recompilation on every shape change and an unoptimized implementation from XLA:CPU. It should be good enough for completeness but it won't be a great user experience.\r\n\r\nAlso note that XLA jitting isn't really supported on Windows, there's some investment needed to make that work and keep it working.\r\n\r\nIn the long term this would be a great use case for CPU kernelgen, but there's a lot of unknowns there when it comes to convolutions, it's not something that can be done in a couple of days of hacking.", "> Also note that XLA jitting isn't really supported on Windows, there's some investment needed to make that work and keep it working.\r\n\r\nWe already advertise JITing as a \"core\" feature, so I don't think this should be a factor in making a decision.", "Can anyone make a group conv on cpu ? ", "I have a pending PR for that, should be submitted soon, although currently it has few unresolved TODOs that are needed to get to top performance.", "> I have a pending PR for that, should be submitted soon, although currently it has few unresolved TODOs that are needed to get to top performance.\r\n\r\nLooking forward...", "Closing, as this was fixed in 7b8db6083b34520688dbc71f341f7aeaf156bf17.", "Anyone who is facing the same issue even after using tf version `2.6.0rc1`, you need to pass the batch size of exactly 1. If you pass more than 1, then it won't work on CPU."]}, {"number": 29004, "title": "Use future.bytes so we can pass in an encoding", "body": "PiperOrigin-RevId: 249875239", "comments": []}, {"number": 29003, "title": "Undo https://github.com/tensorflow/tensorflow/pull/29000", "body": "So I can cherrypick in the real fix", "comments": []}, {"number": 29002, "title": "Correct ValueError to TypeError", "body": "", "comments": ["Hi @mihaimaruseac, I've updated the commit message.\r\n\r\n> This is a TypeError instead of ValueError because, in the `if` clause, we are checking the type of `identifier`. See https://docs.python.org/3/library/exceptions.html#TypeError :\r\n> \r\n> > Passing arguments of the wrong type (e.g. passing a list when an int is expected) should result in a TypeError, but passing arguments with the wrong value (e.g. a number outside expected boundaries) should result in a ValueError.\r\n> \r\n> The change from `constructor(str, arg)` to `constructor(str.format(arg))` is because the former is undocumented."]}, {"number": 29001, "title": "Install apt-transport-https and ca-certificates in install_bootstrap_\u2026", "body": "\u2026deb_packages.sh\r\n\r\nPiperOrigin-RevId: 249766386", "comments": []}, {"number": 29000, "title": "Remove encoding kwarg passed to bytes", "body": "This is only available in python 3", "comments": []}, {"number": 28999, "title": "Is there any c++ api examples for tensorflow lite\uff1f", "body": "I dont like java and swift.\r\nI prefer c++.\r\nHowever, I seldom see any c++ api helps.", "comments": ["There are two examples I found:\r\ntensorflow/lite/examples/label_image\r\nand \r\ntensorflow/lite/tools/benchmark", "@engineer1109 Did you get chance to review the link suggested by @lwu025 ", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 28998, "title": "AttributeError: module 'tensorflow._api.v1.io' has no attribute 'decode_***' when calling any function in tf.io", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.12.0\r\n- Python version: 3.5\r\n- CUDA/cuDNN version: V8.0.61\r\n- GPU model and memory: Tesla P100-PCIE, 12193MiB\r\n\r\n**Describe the current behavior**\r\nWhen I call `tf.io.decode_jpg()` (or any function from `tf.io`), I get the following error: `AttributeError: module 'tensorflow._api.v1.io' has no attribute 'decode_***'`. I import TensorFlow as `import tensorflow as tf`. I also tried importing the `io` module directly, but to no avail.\r\n\r\n**Code to reproduce the issue**\r\n```\r\nfrom __future__ import absolute_import, division, print_function\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport sys\r\nimport os\r\n\r\nCLASSES = [\"aluminium\", \"asphalt\", \"brick\", \"cloud\", \"concrete\", \"fabric\", \"foliage\", \"glass\", \"grass\", \"gravel\", \"iron\", \"living\", \"other\", \"plastic\", \"sky\", \"soil\", \"stone\", \"steel\", \"tile\", \"water\", \"wood\"]\r\nNUM_CLASSES = len(CLASSES)\r\nDIR_DATASET = \"/media/nfs/7_raid/ebos/dataset/cycloramas/\"\r\nWIDTH = 512\r\nHEIGHT = 512\r\n\r\n#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\r\ntf.enable_eager_execution()\r\n\r\ndef sample_fetcher():\r\n    sample_names = [filename[:-4] for filename in os.listdir(DIR_DATASET) if filename[-4:] == \".jpg\"]\r\n    for sample_name in sample_names:\r\n        rgb = tf.io.decode_image(tf.read_file(DIR_DATASET + sample_name + \".jpg\"))\r\n        rgb = tf.image.resize_images(rgb, (HEIGHT, WIDTH))\r\n        #d = tf.io.decode_jpeg(tf.read_file(DIR_DATASET + \"depth/\" + sample_name + \".jpg\"))\r\n        #d = tf.image.resize_images(d, (HEIGHT, WIDTH))\r\n        #rgbd = tf.concat([rgb,d], axis=2)\r\n        onehots = tf.convert_to_tensor(np.load(DIR_DATASET + \"ndarrays/\" + sample_name + \".npy\"), dtype=tf.uint8)\r\n        yield tf.stack([rgb, onehots])\r\n\r\n\r\ntrain = tf.data.Dataset.from_generator(generator=sample_fetcher, output_types=(tf.uint8, tf.uint8))\r\ntrain = train.repeat()\r\ntrain = train.batch(10)\r\n\r\nfor sample in train:\r\n    print(sample)\r\n\r\nresnet = tf.keras.applications.ResNet50(include_top=False, weights='imagenet', input_tensor=None, input_shape=(HEIGHT, WIDTH, 3), pooling=None, classes=1000)\r\nprint(resnet.summary())\r\n```\r\n\r\n**Other info / logs**\r\nFull traceback:\r\n```\r\n2019-05-24 17:28:06.378578: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-05-24 17:28:06.583733: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: \r\nname: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\r\npciBusID: 0000:04:00.0\r\ntotalMemory: 11.91GiB freeMemory: 11.62GiB\r\n2019-05-24 17:28:06.758594: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 1 with properties: \r\nname: Tesla P100-PCIE-12GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\r\npciBusID: 0000:82:00.0\r\ntotalMemory: 11.91GiB freeMemory: 11.62GiB\r\n2019-05-24 17:28:06.758660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0, 1\r\n2019-05-24 17:28:07.388910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-05-24 17:28:07.388951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 1 \r\n2019-05-24 17:28:07.388959: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N N \r\n2019-05-24 17:28:07.388963: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 1:   N N \r\n2019-05-24 17:28:07.389557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 11241 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-12GB, pci bus id: 0000:04:00.0, compute capability: 6.0)\r\n2019-05-24 17:28:07.390009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 11241 MB memory) -> physical GPU (device: 1, name: Tesla P100-PCIE-12GB, pci bus id: 0000:82:00.0, compute capability: 6.0)\r\n2019-05-24 17:28:07.420058: W tensorflow/core/framework/op_kernel.cc:1261] Unknown: AttributeError: module 'tensorflow._api.v1.io' has no attribute 'decode_image'\r\nTraceback (most recent call last):\r\n\r\n  File \"/home/local/CYCLOMEDIA001/ebos/Workspace/virtuele_omgevingen/python3/lib/python3.5/site-packages/tensorflow/python/ops/script_ops.py\", line 206, in __call__\r\n    ret = func(*args)\r\n\r\n  File \"/home/local/CYCLOMEDIA001/ebos/Workspace/virtuele_omgevingen/python3/lib/python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 451, in generator_py_func\r\n    values = next(generator_state.get_iterator(iterator_id))\r\n\r\n  File \"/home/local/CYCLOMEDIA001/ebos/Workspace/all_cf/src/experimental/cityfusion/tasks/material_segmentation/semantic_fpn.py\", line 21, in sample_fetcher\r\n    rgb = tf.io.decode_image(tf.read_file(DIR_DATASET + sample_name + \".jpg\"))\r\n\r\nAttributeError: module 'tensorflow._api.v1.io' has no attribute 'decode_image'\r\n\r\n\r\n2019-05-24 17:28:07.420191: W tensorflow/core/framework/op_kernel.cc:1273] OP_REQUIRES failed at iterator_ops.cc:1031 : Unknown: AttributeError: module 'tensorflow._api.v1.io' has no attribute 'decode_image'\r\nTraceback (most recent call last):\r\n\r\n  File \"/home/local/CYCLOMEDIA001/ebos/Workspace/virtuele_omgevingen/python3/lib/python3.5/site-packages/tensorflow/python/ops/script_ops.py\", line 206, in __call__\r\n    ret = func(*args)\r\n\r\n  File \"/home/local/CYCLOMEDIA001/ebos/Workspace/virtuele_omgevingen/python3/lib/python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 451, in generator_py_func\r\n    values = next(generator_state.get_iterator(iterator_id))\r\n\r\n  File \"/home/local/CYCLOMEDIA001/ebos/Workspace/all_cf/src/experimental/cityfusion/tasks/material_segmentation/semantic_fpn.py\", line 21, in sample_fetcher\r\n    rgb = tf.io.decode_image(tf.read_file(DIR_DATASET + sample_name + \".jpg\"))\r\n\r\nAttributeError: module 'tensorflow._api.v1.io' has no attribute 'decode_image'\r\n\r\n\r\n\t [[{{node PyFunc}} = PyFunc[Tin=[DT_INT64], Tout=[DT_UINT8, DT_UINT8], token=\"pyfunc_1\"](arg0)]]\r\nTraceback (most recent call last):\r\n  File \"/home/local/CYCLOMEDIA001/ebos/Workspace/all_cf/src/experimental/cityfusion/tasks/material_segmentation/semantic_fpn.py\", line 34, in <module>\r\n    for sample in train:\r\n  File \"/home/local/CYCLOMEDIA001/ebos/Workspace/virtuele_omgevingen/python3/lib/python3.5/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 543, in __next__\r\n    return self.next()\r\n  File \"/home/local/CYCLOMEDIA001/ebos/Workspace/virtuele_omgevingen/python3/lib/python3.5/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 574, in next\r\n    return self._next_internal()\r\n  File \"/home/local/CYCLOMEDIA001/ebos/Workspace/virtuele_omgevingen/python3/lib/python3.5/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 564, in _next_internal\r\n    output_shapes=self._flat_output_shapes)\r\n  File \"/home/local/CYCLOMEDIA001/ebos/Workspace/virtuele_omgevingen/python3/lib/python3.5/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 2266, in iterator_get_next_sync\r\n    _six.raise_from(_core._status_to_exception(e.code, message), None)\r\n  File \"<string>\", line 3, in raise_from\r\ntensorflow.python.framework.errors_impl.UnknownError: AttributeError: module 'tensorflow._api.v1.io' has no attribute 'decode_image'\r\nTraceback (most recent call last):\r\n\r\n  File \"/home/local/CYCLOMEDIA001/ebos/Workspace/virtuele_omgevingen/python3/lib/python3.5/site-packages/tensorflow/python/ops/script_ops.py\", line 206, in __call__\r\n    ret = func(*args)\r\n\r\n  File \"/home/local/CYCLOMEDIA001/ebos/Workspace/virtuele_omgevingen/python3/lib/python3.5/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 451, in generator_py_func\r\n    values = next(generator_state.get_iterator(iterator_id))\r\n\r\n  File \"/home/local/CYCLOMEDIA001/ebos/Workspace/all_cf/src/experimental/cityfusion/tasks/material_segmentation/semantic_fpn.py\", line 21, in sample_fetcher\r\n    rgb = tf.io.decode_image(tf.read_file(DIR_DATASET + sample_name + \".jpg\"))\r\n\r\nAttributeError: module 'tensorflow._api.v1.io' has no attribute 'decode_image'\r\n\r\n\r\n\t [[{{node PyFunc}} = PyFunc[Tin=[DT_INT64], Tout=[DT_UINT8, DT_UINT8], token=\"pyfunc_1\"](arg0)]] [Op:IteratorGetNextSync]\r\n2019-05-24 17:28:07.457913: W tensorflow/core/kernels/data/generator_dataset_op.cc:78] Error occurred when finalizing GeneratorDataset iterator: Failed precondition: Python interpreter state is not initialized. The process may be terminated.\r\n\t [[{{node PyFunc}} = PyFunc[Tin=[DT_INT64], Tout=[DT_INT64], token=\"pyfunc_2\"](arg0)]]\r\n\r\nProcess finished with exit code 1\r\n``\r\n", "comments": []}, {"number": 28997, "title": "Unable to get predictions from .tflite graph.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source or binary): tensorflow installed using pip\r\n- TensorFlow version (use command below): 1.13.1\r\n- Python version: python 3.6\r\n- Bazel version (if compiling from source): 0.25.2\r\n- CUDA/cuDNN version:  10.0\r\n- GPU model and memory: NVIDIA GeForce GTX 1080 Ti \r\n\r\n**Describe the current behavior**\r\nI have fine tuned ssdlite_mobilenet_v1 model and have the frozen graph post completion of training process.\r\n\r\nUsed the below mentioned code to convert the frozen.pb grpah into tflite version.\r\ntflite_convert \\\r\n--output_file=test.tflite \\\r\n--graph_def_file=tflite_graph.pb \\\r\n--input_arrays=normalized_input_image_tensor \\\r\n--output_arrays='TFLite_Detection_PostProcess','TFLite_Detection_PostProcess:1','TFLite_Detection_PostProcess:2','TFLite_Detection_PostProcess:3' \\\r\n--input_shape=1,300,300,3 \\\r\n--allow_custom_ops\r\n\r\nI wanted to confirm if the results on test data of tflite model matches the frozen.pb file, however the model would not give out any output at all. \r\n\r\n\tinterpreter =tf.lite.Interpreter(model_path=\"path/to/test.tflite\")\r\n\tinterpreter.allocate_tensors()\r\n\tinput_details = interpreter.get_input_details()\r\n\toutput_details = interpreter.get_output_details()\r\n        // image is of format 1 x300x300x3 and the avlues are between -1 to 1\r\n      \tinterpreter.set_tensor(input_details[0]['index'], image)\r\n\toutput_data1 = interpreter.get_tensor(output_details[0]['index'])\r\n\tclasses = interpreter.get_tensor(output_details[1]['index'])\r\n\tconfidence_scores = interpreter.get_tensor(output_details[2]['index'])\r\nprint(output_data1)\r\nprint(classes)\r\nprint(confidence_scores)\r\n\r\nThe print statements give no result out. \r\n\r\nAny help provided would be greatly appreciated. ", "comments": ["did you forget to call interpreter.invoke()?", "Thank you for your response.\r\nI did know I had to use interpreter.invoke().\r\nHowever, when I used invoke() I ran into another error in the below mentioned line\r\n\r\ninterpreter.set_tensor(input_details[0]['index'], image)\r\nError Message:\r\nValueError: Cannot set tensor: Got tensor of type 0 but expected type 1 for input 260\r\n\r\nInput details are as follows:\r\ninput_details: [{'name': 'normalized_input_image_tensor', 'index': 260, 'shape': array([ 1, 300, 300, 3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0)}]\r\n\r\nPlease let me know if you need any other information to help me figure this out", "Sorry for the late. The input tensor `normalized_input_image_tensor` should have float32 type, but it seems like you are passing the `image` array with the wrong type. Could you check again if the data type is matched?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28997\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28997\">No</a>\n"]}, {"number": 28996, "title": "how to use xla with c++ api in tensorflow", "body": "tensorflow_version: 1.13.1\r\nother\uff1a C++ inference; CPU\r\nMy steps are as follows: \r\n1. I trained with Python on GPU\r\n2. converted  model with freeze_graph.py\r\n3. put it on CPU and use c++ language for inference.\r\n\r\nHow to use C++ to open the XLA settings, I use the following code,  no effect(before timecost == after timecost).\r\n\r\nOptimizerOptions optimizer_options = _tf_options.config.graph_options().optimizer_options();\r\noptimizer_options.set_global_jit_level(OptimizerOptions::ON_1);\r\n\r\nGraphOptions graph_options = _tf_options.config.graph_options();\r\ngraph_options.mutable_optimizer_options()->CopyFrom(optimizer_options);\r\n\r\n_tf_options.config.mutable_graph_options()->CopyFrom(graph_options);\r\n@sanjoy ", "comments": ["@x666633 It looks This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at Stackoverflow. There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. If you still stuck, you can get back to us.Thanks!", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!", "@x666633  Hello,have you solved this problem? I have the same with you ."]}, {"number": 28995, "title": "Keras doesn't allow tf.data validation without validation_steps", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Mac 10.14.4, Ubuntu 18.01\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.14.1.dev20190524 | 1.14.0rc0 | 1.14.0\r\n- Python version: 3.6.8\r\n- CUDA/cuDNN version: -\r\n- GPU model and memory: -\r\n\r\n**Describe the current behavior**\r\nUsing `tf.data` as `validation_data` without defining `validation_steps` fails with `TypeError: 'DatasetV1Adapter' object does not support indexing`.  Using `tf.data` without `steps_per_epoch` works as expected when using it as training data instead.\r\n\r\n**Describe the expected behavior**\r\nI think the behaviour of training data and validation data in Keras `model.fit` should be consistent. This would make Keras a lot easier to use together with `tf.data` because it gets rid of the need for defining a exact number of steps. \r\n**Code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow_datasets as tfds\r\n\r\ntrain, test = tfds.load(name=\"mnist\", split=[tfds.Split.TRAIN, tfds.Split.TEST], as_supervised=True)\r\n\r\ndef scale(image, label):\r\n    return tf.cast(image, tf.float32) / 255, label\r\n\r\nmodel = tf.keras.Sequential(\r\n    [\r\n        tf.keras.layers.Conv2D(32, 3, activation=\"relu\", input_shape=(28, 28, 1)),\r\n        tf.keras.layers.MaxPooling2D(),\r\n        tf.keras.layers.Flatten(),\r\n        tf.keras.layers.Dense(64, activation=\"relu\"),\r\n        tf.keras.layers.Dense(10, activation=\"softmax\"),\r\n    ]\r\n)\r\n\r\nmodel.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\r\n\r\nmodel.fit(\r\n    train.batch(256),\r\n    validation_data=test.batch(256),\r\n)\r\n```\r\n\r\n**Other info / logs**\r\n```python traceback\r\n  File \"test.py\", line 24, in <module>\r\n    epochs=10,\r\n  File \"/Users/lukasgeiger/miniconda3/envs/tf-nightly/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 644, in fit\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/Users/lukasgeiger/miniconda3/envs/tf-nightly/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\", line 615, in fit\r\n    steps_name='steps_per_epoch')\r\n  File \"/Users/lukasgeiger/miniconda3/envs/tf-nightly/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\", line 145, in model_iteration\r\n    _print_train_info(inputs, val_inputs, steps_per_epoch, verbose)\r\n  File \"/Users/lukasgeiger/miniconda3/envs/tf-nightly/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\", line 450, in _print_train_info\r\n    hasattr(inputs[0], 'shape') and hasattr(val_inputs[0], 'shape')):\r\nTypeError: 'DatasetV1Adapter' object does not support indexing\r\n```\r\n", "comments": ["@lgeiger Can you please provide tensorflow version?. \r\nWith Tensorflow tf-nightly and tf-2.0.0-alpha the above code outputs expected output. Thanks!", "> @lgeiger Can you please provide tensorflow version?.\r\nWith Tensorflow tf-nightly and tf-2.0.0-alpha the above code outputs expected output. Thanks!\r\n\r\nSorry for the missing version, I am using `tf-nightly==1.14.1.dev20190524` and `tensorflow==1.14.0rc0`.", "@lgeiger I tried with tf-nightly==1.14.1.dev20190524 and tensorflow==1.14.0rc0 but the code executed without any error. Can you try once again and let us know if that still gives error. Thanks!", "> Can you try once again and let us know if that still gives error.\r\n\r\nYep, just tried it with `tensorflow==1.14.0rc0` and it still gives an error. Which python version are you using?", "@lgeiger Thanks for confirming. I am using Python 3.6.7 version. ", "I can still reproduce this with Python 3.6.8, TensorFlow 1.14.0-rc0 and TensorFlow Datasets 1.0.2", "@lgeiger I don't see the error you mentioned. I ran your code using `tensorflow==2.0.0-alpha0`([gist](https://colab.sandbox.google.com/gist/jvishnuvardhan/1f15082053c715c76643058dda5eae58/tf28995_gpu.ipynb)), `tensorflow-gpu==2.0.0-alpha0` ([gist](https://colab.sandbox.google.com/gist/jvishnuvardhan/4736ce8fd58e1bd2657728409a34752e/tf_gpu_28995_gpu.ipynb)), and `tf-nightly-gpu-2.0-preview==2.0.0-dev20190530` ([gist](https://colab.sandbox.google.com/gist/jvishnuvardhan/ba8cfffda7f0bb54ca55d41643f06381/tf-nightly_gpu_28995_gpu.ipynb)).\r\n\r\nPlease try to run it yourself. If you see any issues, let us know. Thanks!", "> I don't see the error you mentioned. I ran your code using tensorflow==2.0.0-alpha0(gist), tensorflow-gpu==2.0.0-alpha0 (gist), and tf-nightly-gpu-2.0-preview==2.0.0-dev20190530 (gist).\r\n\r\nThanks for reproducing. As mentioned above the issue is related to `1.14.1.dev20190524` and `1.14.0rc0`. TF 2 works fine.", "@lgeiger I ran it in `1.14.1.dev20190524` and don't see any error. Here is the [gist](https://colab.sandbox.google.com/gist/jvishnuvardhan/6f99cbefa5cd7f90169f7098fe67f4f0/tf_nightly_1_14_1_gpu_28995_gpu.ipynb). \r\n\r\nIt will be helpful If you can create a gist and share.  Thanks!", "- [Here](https://colab.research.google.com/drive/1gxC8Apn7xVExkaPo4ncBUU9YQKfe4ZK0) is a colab using `1.14.0rc0`\r\n- [Here](https://colab.research.google.com/drive/1GGWq2mlYOLJ3fQjrcp9o5j25n4MUVRSt) is a colab using `1.14.1.dev20190524`", "@lgeiger I could reproduce the issue when i select \"cpu\". If I select \"gpu\" as shown in my gist, there is no error. Thanks!", "> @lgeiger I could reproduce the issue when i select \"cpu\". If I select \"gpu\" as shown in my gist, there is no error. Thanks!\r\n\r\nStrange. Good that you can reproduce it now", "@jsimsa Is this intended behavior? Can you please take a look at this issue? Thanks!", "This is a question for tf.keras folks, not tf.data.", "I also encounter this problem, tf.keras + tf.data. My tensorflow version is tf13.1.\r\n", "@jvishnuvardhan Any updates on this issue?", "Facing the similar issue.", "@omalleyt12 I can still reproduce this issue with TensorFlow 1.14.0:\r\n```python-traceback\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-1-89e74e90b73d> in <module>\r\n     21 model.fit(\r\n     22     train.batch(256),\r\n---> 23     validation_data=test.batch(256),\r\n     24 )\r\n\r\n~/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py in fit(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\r\n    778           validation_steps=validation_steps,\r\n    779           validation_freq=validation_freq,\r\n--> 780           steps_name='steps_per_epoch')\r\n    781 \r\n    782   def evaluate(self,\r\n\r\n~/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py in model_iteration(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\r\n    143 \r\n    144   if mode == ModeKeys.TRAIN:\r\n--> 145     _print_train_info(inputs, val_inputs, steps_per_epoch, verbose)\r\n    146 \r\n    147   # Enter tf.distribute.Strategy scope.\r\n\r\n~/miniconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_arrays.py in _print_train_info(inputs, val_inputs, steps_per_epoch, verbose)\r\n    448 def _print_train_info(inputs, val_inputs, steps_per_epoch, verbose):\r\n    449   if (val_inputs and steps_per_epoch is None and verbose and inputs and\r\n--> 450       hasattr(inputs[0], 'shape') and hasattr(val_inputs[0], 'shape')):\r\n    451     print('Train on %d samples, validate on %d samples' %\r\n    452           (inputs[0].shape[0], val_inputs[0].shape[0]))\r\n\r\nTypeError: 'DatasetV1Adapter' object is not subscriptable\r\n```", "Yup, can reproduce here as well with `1.14.0`.\r\n\r\nSuboptimal workarounds are:\r\n\r\n1. Set `verbose=0`\r\n2. Set `steps_per_epoch` to something that is not `None`\r\n3. Don't use `validation_data`\r\n", "Hi @lgeiger, sorry for the very late reply. That indeed seems to be a bug for certain runtime condition. As @benyeoh, mentioned, the quickest workaround is to set verbose = 0, which suppress the print of the message, and still give u the same training/eval behavior.\r\n\r\nWe are in the middle of a refactoring of the training logic, and will take care of the issue in 2.0 release.", "Thanks for taking a look\r\n\r\n> We are in the middle of a refactoring of the training logic, and will take care of the issue in 2.0 release.\r\n\r\nDoes that mean TF 1.14 won't receive a fix for this? I understand that you are focusing on 2.0 at the moment, but a fix would be very useful for people currently relying still relying on TF 1.x.", "We probably won't update 1.14 release for this bug.\r\n\r\nAlso just check the docstring of model.fit()\r\n\r\n> validation_data: Data on which to evaluate the loss and any model metrics at the end of each epoch. The model will not be trained on this data. validation_data will override validation_split. validation_data could be:\r\ntuple (x_val, y_val) of Numpy arrays or tensors\r\ntuple (x_val, y_val, val_sample_weights) of Numpy arrays\r\ndataset or a dataset iterator.\r\nFor the first two cases, batch_size must be provided. For the last case, validation_steps must be provided.\r\n\r\nSeems that the validation_steps is needed if the validation_data is a dataset.", "This is fixed with latest tf-nightly version '1.15.0-dev20190808'", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=28995\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=28995\">No</a>\n", "Sorry for opening this after almost a year, but from docstring of model.fit():\r\n\r\n`steps_per_epoch`: Integer or None. Total number of steps (batches of samples) before declaring one epoch finished and starting the next epoch. When training with input tensors such as TensorFlow data tensors, the default None is equal to the number of samples in your dataset divided by the batch size, or 1 if that cannot be determined. **If x is a tf.data dataset, and 'steps_per_epoch' is None, the epoch will run until the input dataset is exhausted**. This argument is not supported with array inputs.\r\n\r\nWhy not do the same (**If x is a tf.data dataset, and 'steps_per_epoch' is None, the epoch will run until the input dataset is exhausted**) for validation data?\r\n\r\nThe docstring is a bit confusing\r\n\r\n`validation_data`: Data on which to evaluate the loss and any model metrics at the end of each epoch. The model will not be trained on this data. validation_data will override validation_split. validation_data could be:\r\n* tuple (x_val, y_val) of Numpy arrays or tensors\r\n* tuple (x_val, y_val, val_sample_weights) of Numpy arrays\r\ndataset For the first two cases, batch_size must be provided. **For the last case, validation_steps must be provided.**\r\n\r\nHowever \r\n\r\n`validation_steps`: Only relevant if validation_data is provided and is a tf.data dataset. Total number of steps (batches of samples) to draw before stopping when performing validation at the end of every epoch. **If validation_data is a tf.data dataset and 'validation_steps' is None, validation will run until the validation_data dataset is exhausted.**\r\n\r\nFor 1.15 during `model.fit()` when validation data is `tf.data` and `validation_steps` is `None`  the following error raises:\r\n\r\n```ValueError: When using data tensors as input to a model, you should specify the `steps_per_epoch` argument.```\r\n\r\nBut this is not raised during `model.evaluate()` with `steps` = `None`\r\n", "> Sorry for opening this after almost a year, but from docstring of model.fit():\r\n> \r\n> `steps_per_epoch`: Integer or None. Total number of steps (batches of samples) before declaring one epoch finished and starting the next epoch. When training with input tensors such as TensorFlow data tensors, the default None is equal to the number of samples in your dataset divided by the batch size, or 1 if that cannot be determined. **If x is a tf.data dataset, and 'steps_per_epoch' is None, the epoch will run until the input dataset is exhausted**. This argument is not supported with array inputs.\r\n> \r\n> Why not do the same (**If x is a tf.data dataset, and 'steps_per_epoch' is None, the epoch will run until the input dataset is exhausted**) for validation data?\r\n> \r\n> The docstring is a bit confusing\r\n> \r\n> `validation_data`: Data on which to evaluate the loss and any model metrics at the end of each epoch. The model will not be trained on this data. validation_data will override validation_split. validation_data could be:\r\n> \r\n> * tuple (x_val, y_val) of Numpy arrays or tensors\r\n> * tuple (x_val, y_val, val_sample_weights) of Numpy arrays\r\n>   dataset For the first two cases, batch_size must be provided. **For the last case, validation_steps must be provided.**\r\n> \r\n> However\r\n> \r\n> `validation_steps`: Only relevant if validation_data is provided and is a tf.data dataset. Total number of steps (batches of samples) to draw before stopping when performing validation at the end of every epoch. **If validation_data is a tf.data dataset and 'validation_steps' is None, validation will run until the validation_data dataset is exhausted.**\r\n> \r\n> For 1.15 during `model.fit()` when validation data is `tf.data` and `validation_steps` is `None` the following error raises:\r\n> \r\n> `` ValueError: When using data tensors as input to a model, you should specify the `steps_per_epoch` argument. ``\r\n> \r\n> But this is not raised during `model.evaluate()` with `steps` = `None`\r\n\r\nsame issue here", "Hello,\r\nI am hitting same error - TensorFlow 1.5, Python 2.7.17 inside docker container.\r\nMinimal logical code -\r\n\r\nimages, labels = read_list ( data_dir, data_list ) <= here data_dir is full path of dir. containing image & label files. data_list is a text file, 2 column containing names of image file and lable file.\r\nThe output is array consisting of full path of images & corresponding labels.\r\n\r\nqueue = tf.data.Dataset.from_tensor_slices([images, labels])\r\nimg_contents = tf.io.read_file(queue[0]) <= Error location\r\nlabel_contents = tf.io.read_file(queue[1])\r\n\r\nFile \"/wasr/wasr_models/image_reader.py\", line 180, in read_images_from_disk\r\n    img_contents = tf.io.read_file(input_queue[0])\r\nTypeError: 'DatasetV1Adapter' object does not support indexing\r\n\r\nI have tried reading various posts but this post has come closest to what I am looking for. Any help to fix the issue will be greatly appreciated.\r\n\r\nThanks,\r\n-Shailesh\r\n\r\n", "> > Sorry for opening this after almost a year, but from docstring of model.fit():\r\n> > `steps_per_epoch`: Integer or None. Total number of steps (batches of samples) before declaring one epoch finished and starting the next epoch. When training with input tensors such as TensorFlow data tensors, the default None is equal to the number of samples in your dataset divided by the batch size, or 1 if that cannot be determined. **If x is a tf.data dataset, and 'steps_per_epoch' is None, the epoch will run until the input dataset is exhausted**. This argument is not supported with array inputs.\r\n> > Why not do the same (**If x is a tf.data dataset, and 'steps_per_epoch' is None, the epoch will run until the input dataset is exhausted**) for validation data?\r\n> > The docstring is a bit confusing\r\n> > `validation_data`: Data on which to evaluate the loss and any model metrics at the end of each epoch. The model will not be trained on this data. validation_data will override validation_split. validation_data could be:\r\n> > \r\n> > * tuple (x_val, y_val) of Numpy arrays or tensors\r\n> > * tuple (x_val, y_val, val_sample_weights) of Numpy arrays\r\n> >   dataset For the first two cases, batch_size must be provided. **For the last case, validation_steps must be provided.**\r\n> > \r\n> > However\r\n> > `validation_steps`: Only relevant if validation_data is provided and is a tf.data dataset. Total number of steps (batches of samples) to draw before stopping when performing validation at the end of every epoch. **If validation_data is a tf.data dataset and 'validation_steps' is None, validation will run until the validation_data dataset is exhausted.**\r\n> > For 1.15 during `model.fit()` when validation data is `tf.data` and `validation_steps` is `None` the following error raises:\r\n> > `` ValueError: When using data tensors as input to a model, you should specify the `steps_per_epoch` argument. ``\r\n> > But this is not raised during `model.evaluate()` with `steps` = `None`\r\n> \r\n> same issue here\r\n\r\nsame problem encountered. Could anyone in tensorflow team at least clarify what does the conflicting doc string mean? If the bug is not fixed in TF1.14, what is the intended behavior according to above doc string? It is pretty confusing. ", "Any update on it?"]}]