[{"number": 21668, "title": "Constrastive Loss Docs and Implementation", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: N/A\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: N/A\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**: N/A\r\n- **TensorFlow version (use command below)**: N/A\r\n- **Python version**: N/A\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\nThe current contrastive loss documentation in tf.contrib.losses.metric_learning says that the embedding must be l2 normalized. While it works, there are also other networks that do not l2 normalize their embeddings. Also there are other normalization one can use to make the network converge. I think it should be written as a note or a hint rather then being a requirement.\r\n\r\nAlso I think it would be nice if we can change the distance function used inside the computation with the euclidean distance being the default.\r\n\r\n", "comments": ["@coreylynch , can you take a look?", "Nagging Assignee @karmel: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@martinwicke -- what will be the fate of contrib.losses.metric_learning in TF 2.0? @coreylynch presumably is not active in maintaining this?", "I seems that way. \r\n\r\nThere will be a SIG which will decide what content to bring in from the various generic contrib directories. I'll share an RFC once I have one.", "I'll close this issue. We can reconsider a feature request once we know the fate of specific contrib symbols. "]}, {"number": 21667, "title": "Automatically remove garbage-collected objects from TF graph", "body": "**Setting up tensorflow graphs in python feels strange since the graph keeps old and unused parts.\r\nWould it be possible to remove garbage-collected operations/tensors from the Tensorflow graph?**\r\n\r\nWhen I tried to create my first graphs, I very soon ran into the problem of leftover placeholders when simply re-entering code parts.\r\nI still have to reset my whole graph in order to change it without side effects.\r\n\r\nProgramming with tensorflow would feed way more \"pythonic\", if I could add and remove parts to the graph by creating and deleting python objects.\r\n\r\n\r\n------------------------\r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.9.0\r\n- **Python version**: 3.6.5\r\n- **Bazel version (if compiling from source)**: none\r\n- **GCC/Compiler version (if compiling from source)**: none\r\n- **CUDA/cuDNN version**: none\r\n- **GPU model and memory**: none\r\n- **Exact command to reproduce**: none", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nMobile device", "It has been 30 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "@Hoeze Resetting graph is probably the best way so far to avoid undesired effects.", "@wt-huang Yes i know that.\r\nThis is a proposal how to improve this rather than a question how to circumvent it :)", "@Hoeze Certainly, this would add more flexibility ", "As of TensorFlow 2.0:\r\n[Thank you for picking this up!](https://medium.com/tensorflow/effective-tensorflow-2-0-best-practices-and-whats-changed-a0ca48767aff)"]}, {"number": 21666, "title": "make build_rpi_lib.sh work", "body": "running `./tensorflow/contrib/lite/tools/make/build_rpi_lib.sh` showed something like\r\n\r\n```\r\n/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/gen/rpi_armv7l/bin/benchmark_model\r\narm-linux-gnueabihf-g++ -O3 -DNDEBUG --std=c++11 -march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/../../../../../ -I/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/../../../../../../ -I/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/downloads/ -I/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/downloads/eigen -I/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/downloads/gemmlowp -I/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/downloads/neon_2_sse -I/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/downloads/farmhash/src -I/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/downloads/flatbuffers/include -I/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/gen/rpi_armv7l/obj/ -I/usr/local/include -c tensorflow/contrib/lite/kernels/audio_spectrogram.cc -o /hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/contrib/lite/kernels/audio_spectrogram.o\r\narm-linux-gnueabihf-g++ -O3 -DNDEBUG --std=c++11 -march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/../../../../../ -I/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/../../../../../../ -I/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/downloads/ -I/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/downloads/eigen -I/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/downloads/gemmlowp -I/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/downloads/neon_2_sse -I/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/downloads/farmhash/src -I/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/downloads/flatbuffers/include -I/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/gen/rpi_armv7l/obj/ -I/usr/local/include -c tensorflow/contrib/lite/kernels/detection_postprocess.cc -o /hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/contrib/lite/kernels/detection_postprocess.o\r\narm-linux-gnueabihf-g++ -O3 -DNDEBUG --std=c++11 -march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations -ftree-vectorize -fPIC -I. -I/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/../../../../../ -I/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/../../../../../../ -I/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/downloads/ -I/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/downloads/eigen -I/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/downloads/gemmlowp -I/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/downloads/neon_2_sse -I/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/downloads/farmhash/src -I/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/downloads/flatbuffers/include -I/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/gen/rpi_armv7l/obj/ -I/usr/local/include -c tensorflow/contrib/lite/kernels/mfcc.cc -o /hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/contrib/lite/kernels/mfcc.o\r\ntensorflow/contrib/lite/kernels/mfcc.cc:16:61: fatal error: include/flatbuffers/flexbuffers.h: No such file or directory\r\ncompilation terminated.\r\ntensorflow/contrib/lite/tools/make/Makefile:159: recipe for target '/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/contrib/lite/kernels/mfcc.o' failed\r\nmake: *** [/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/contrib/lite/kernels/mfcc.o] Error 1\r\nmake: *** Waiting for unfinished jobs....\r\ntensorflow/contrib/lite/kernels/detection_postprocess.cc:18:61: fatal error: include/flatbuffers/flexbuffers.h: No such file or directory\r\ncompilation terminated.\r\ntensorflow/contrib/lite/tools/make/Makefile:159: recipe for target '/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/contrib/lite/kernels/detection_postprocess.o' failed\r\nmake: *** [/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/contrib/lite/kernels/detection_postprocess.o] Error 1\r\ntensorflow/contrib/lite/kernels/audio_spectrogram.cc:25:61: fatal error: include/flatbuffers/flexbuffers.h: No such file or directory\r\ncompilation terminated.\r\ntensorflow/contrib/lite/tools/make/Makefile:159: recipe for target '/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/contrib/lite/kernels/audio_spectrogram.o' failed\r\nmake: *** [/hack/freedom/tensorflow/tensorflow/tensorflow/contrib/lite/tools/make/gen/rpi_armv7l/obj/tensorflow/contrib/lite/kernels/audio_spectrogram.o] Error 1\r\n\r\n```\r\n\r\nSome kernels use `flatbuffers/flexbuffers.h`, others use `include/flatbuffers/flexbuffers.h`", "comments": ["no code uses `include/flatbuffers/flexbuffers.h` anymore. close this."]}, {"number": 21665, "title": "[Intel MKL] Static code analysis tool fixes. ", "body": "- mkl_cpu_allocator.h: disallowing copy constructor and assignement operator; returning nullptr from non-void functions even though they generate Unimplemented Status code\r\n- mkl_graph_util.h: making kTensorOrdering const because it never gets changed anyway\r\n- mkl_layout_pass.cc: adding checks for nullptr before dereferencing", "comments": []}, {"number": 21664, "title": "GlobalAveragePooling1D supports masking", "body": "Pick https://github.com/keras-team/keras/pull/10913 to ```tf.keras```, to make ```GlobalAveragePooling1D``` support masking.", "comments": ["Gently ping @fchollet @protoget . Would mind to have a look at this? Thanks.", "I updated test goldens(tensorflow/tools/api/golden/v1) to fix the API compatibility test. Does anyone can re-trigger the tests? Thanks.", "Nagging Assignees @facaiy, @protoget: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Gently ping @protoget . Can you move forward this? Thanks.", "@yanboliang could you pull rebase and push again?", "@drpngx I find this PR has been included in https://github.com/tensorflow/tensorflow/commit/8ef3e7c8c053cb6dad530e13c478bbd406ea2c95 . I'm closing this."]}, {"number": 21663, "title": "how to train the network with mini-batches in eager execution?", "body": "\r\n### Describe the problem\r\nI find a simple code from tensorflow documents to train a simple neural network by eager execution.\r\nI need to know that how should I modify the code to train the network with mini-batches?\r\n### Source code / logs\r\nfrom __future__ import absolute_import, division, print_function\r\nimport tensorflow as tf\r\nimport numpy as np\r\ntfe = tf.contrib.eager\r\nNUM_EXAMPLES = 1000\r\ntraining_inputs = tf.random_normal([NUM_EXAMPLES])\r\nnoise = tf.random_normal([NUM_EXAMPLES])\r\ntraining_outputs = training_inputs * 3 + 2 \r\n\r\ndef prediction(input, weight, bias):\r\n  return input * weight + bias\r\n\r\ndef loss(weights, biases):\r\n  error = prediction(training_inputs, weights, biases) - training_outputs\r\n  return tf.reduce_sum(tf.square(error))\r\n\r\ndef grad(weights, biases):\r\n  with tf.GradientTape() as tape:\r\n    loss_value = loss(weights, biases)\r\n  return tape.gradient(loss_value, [weights, biases])\r\n\r\ntrain_steps = 20000\r\nlearning_rate = 0.01\r\nW = tfe.Variable(5.)\r\nB = tfe.Variable(10.)\r\noptimizer=tf.train.AdamOptimizer(0.1)\r\n\r\nfor i in range(train_steps):\r\n    grads=grad(W,B)\r\n    optimizer.apply_gradients(zip(grads,[W,B]),global_step=tf.train.get_or_create_global_step())\r\n    if i % 20 == 0:\r\n     print(\"Loss at step {:03d}: {:.3f}\".format(i, loss(W, B)))\r\n", "comments": ["You'd want to structure your code so that each iteration feeds a minibatch instead of hardcoding the input in the call to `loss`. \r\n\r\nSee for example the [custom training tutorial](https://colab.research.google.com/github/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/notebooks/custom_training.ipynb) and other tutorial notebooks on www.tensorflow.org/tutorials and the [MNIST example](https://github.com/tensorflow/models/blob/master/official/mnist/mnist_eager.py)\r\n\r\nHope that helps!"]}, {"number": 21662, "title": "Fixed bytes/str issue in get_temp_export_dir", "body": "Prior to this commit on Python 3 get_temp_export_dir produced directories\r\nof the form\r\n\r\n    /foo/bar/temp-b'1534435836'\r\n\r\nbecause basename is bytes and str(bytes) is b'...'.", "comments": ["@superbobry A PR #21426 is currently under review for the fix.", "Ooops, sorry, should've done a search first. Closing this one."]}, {"number": 21661, "title": "Reusing pretrained model in my own model", "body": "Hello,\r\nI am creating a tensorflow model with a new session and you will find below the pseudocode for it\r\n\r\n```\r\ninp = tf.placeholder()   #----- placeholder for model1\r\n# conv and relu layers\r\nintermediate = conv2d()  # ----- an intermediate output that I want to use in model2\r\n# conv and relu layers\r\nloss = tf.reduce_mean( sigmoid_cross_entropy_with_logits( predicted , real ) )\r\n\r\nsess1.run( loss , feed_dict = { inp : images } )\r\n```\r\nNow I want to use a pretrained model and add the output of the final layer in the loss function. So for example,\r\n```\r\n\r\nsess2 = tf.Session()\r\nload_model( sess2 )\r\n```\r\nThe pretrained model has its own placeholders and I would like to send the value in my intermediate tensor to the placeholder of the pretrained model. Thus, I want to run the pretrained model in every batch and evaluate its prediction.\r\n\r\nThe problem is that on searching I found out that we cannot feed_dict tensors to placeholders. Is there any other way I can go about and evaluate the second model everytime the first model learns? I asked this question on Stackoverflow and haven't received any responses.\r\n\r\nThanks,", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Here is some additional info:\r\nHave I written custom code: Yes\r\nOS Platform and Distribution: Ubuntu\r\nTensorFlow installed from: pip\r\nTensorFlow version: 1.9\r\nBazel version: 1.9\r\nCUDA/cuDNN version: CUDA 9, cuDNN 7\r\nGPU model and memory: Quadro p5000\r\nExact command to reproduce: N/A\r\nMobile device: N/A\r\n", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 21660, "title": "Fix CropAndResize op", "body": "Prevent floating point arithmetic influence on CropAndResize op", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "Thanks @dkurt for the PR. Could you fill out the cla?", "@yifeif, sure. Please do not merge it immediately because I wanted to add a test.", "CLAs look good, thanks!\n\n<!-- ok -->", "I signed it!", "Thanks for filling the CLA @dkurt! Let us know when this is ready for review.", "@yifeif, it's ready to be reviewed. Thanks!", "@jch1 do you mind taking a look? Thanks!", "@dkurt are you planning to address reviewer comments ?", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 21659, "title": "Estimator Save Model", "body": "How to save model based on eval's accuracy in Estimator", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 21658, "title": "Add LeakyRelu C++ Op and its gradient implementation.", "body": "LeakyRelu, defined as 'y = { x (x>=0) or alpha*x (x<0) }', was computed by combined Ops 'max(x, alpha*x)' in current codes. Hence its gradient calculation for back propagation would contain a serial of element-wise Ops. This looks really unnecessary for such a simple op and it could be done within just one Op with less memory accesses.\r\n\r\nIn fact, we meet some performance issue on CPU in an attention based model. Within the FC calculation 'Leaky ReLu' was used as the activation function, so that its back prop Ops took some CPU time. Thus we decided to implement leaky_relu and its gradient as C++ Ops.", "comments": ["A week passed, anybody is here?", "Hi, I have updated the codes again. Any further comments there?", "Due to ci_build error reports, I did some change and submit a new version here.", "A new commit was submitted to avoid golden API file changing.", "@alextp Do you have time to review the code again? Thanks.", "@alextp Sorry, I have to add a commit to fix some lint errors and typos due to ci_build tests report. ", "Have to merge with master due to branch conflicts.", "Have to reverted XLA commit since the Op didn't provide bfloat16 support.", "@alextp I reverted the XLA commit due to unsupported dtypes. Finally it looks that all CI build cases related with this PR was passed. Thanks for the patient of taking a review again. :) ", "Indeed, unrelated failures. Thanks for your work, @lowintelligence !", "@alextp Could you please help to take a look about why \"feedback/copybara\" failed? I can't see detail information here.", "@yifeif Hi, yifei. Do we have a plan to give contributor more details about feedback/copybara? It seems that we can't do anything but wait. cc @martinwicke ", "Hi @facaiy feedback/copybara is currently an experimental feature and it's a bit far from being able to show the build results with details. Please ping reviewer(s) to see if there is anything needs to be fixed from the PR. Thanks!", "@yifeif Oh, I got it.  It can be quite useful when feddback/copybara is ready for showing build details. Thanks for your explanation :-)", "@alextp Do you have time to take a look about whether I need to fix something? Thanks.", "One internal error is error: module //tensorflow/cc:gradients_nn_grad_test does not depend on a module exporting 'tensorflow/cc/ops/nn_ops_internal.h'\r\n\r\nI think you need to fix the build dependencies, adding something to tensorflow/cc/BUILD", "Well, I've fixed the tensorflow/cc/BUILD file and delayed the forward compatibility date. Please take a check. Thanks. @alextp ", "Well, I found that the commit in master branch https://github.com/tensorflow/tensorflow/commit/e2ce9787d9927e4a6574e6ac4606a47712320170 has removed the 'compat' module importing in nn_ops.py, thus many tests were failed due to this module not found. :-( I would make a merge with master and commit a new version. @alextp Thanks.", "Hi, is there any further progress about this PR?"]}, {"number": 21657, "title": "error when use \"tf.get_variable_scope().reuse_variables()\"", "body": "@lukaszkaiser \r\n\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.slim as slim\r\nimport numpy as np\r\nfrom scipy.io import loadmat, savemat\r\nimport scipy.spatial.distance as ssd\r\nfrom sbir_sampling import triplet_sampler_asy\r\nfrom sbir_util import *\r\nfrom ops import spatial_softmax, reshape_feats\r\nimport os, errno\r\n\r\nNET_ID = 0 #0 for step3 pre-trained model, 1 for step2 pre-trained model\r\n\r\n\r\ndef attentionNet(inputs, pool_method='sigmoid'):\r\n    assert(pool_method in ['sigmoid', 'softmax'])\r\n    with slim.arg_scope([slim.conv2d],\r\n                        activation_fn=tf.nn.relu,\r\n                        weights_initializer=tf.truncated_normal_initializer(0.0, 0.1),\r\n                        weights_regularizer=slim.l2_regularizer(0.0005),\r\n                        trainable=True):\r\n        net = slim.conv2d(inputs, 256, [1, 1], padding='SAME', scope='conv1')\r\n        if pool_method == 'sigmoid':\r\n            net = slim.conv2d(net, 1, [1, 1], activation_fn=tf.nn.sigmoid, scope='conv2')\r\n        else:\r\n            net = slim.conv2d(net, 1, [1, 1], activation_fn=None, scope='conv2')\r\n            net = spatial_softmax(net)\r\n    return net\r\n\r\n\r\ndef sketch_a_net_sbir(inputs, trainable):\r\n    with slim.arg_scope([slim.conv2d, slim.fully_connected],\r\n                        activation_fn=tf.nn.relu,\r\n                        weights_initializer=tf.truncated_normal_initializer(0.0, 0.1),\r\n                        weights_regularizer=slim.l2_regularizer(0.0005),\r\n                        trainable=False):\r\n        with slim.arg_scope([slim.conv2d], padding='VALID'):\r\n            # x = tf.reshape(inputs, shape=[-1, 225, 225, 1])\r\n            conv1 = slim.conv2d(inputs, 64, [15, 15], 3, scope='conv1_s1')\r\n            conv1 = slim.max_pool2d(conv1, [3, 3], scope='pool1')\r\n            conv2 = slim.conv2d(conv1, 128, [5, 5], scope='conv2_s1')\r\n            conv2 = slim.max_pool2d(conv2, [3, 3], scope='pool2')\r\n            conv3 = slim.conv2d(conv2, 256, [3, 3], padding='SAME', scope='conv3_s1')\r\n            conv4 = slim.conv2d(conv3, 256, [3, 3], padding='SAME', scope='conv4_s1')\r\n            conv5 = slim.conv2d(conv4, 256, [3, 3], padding='SAME', scope='conv5_s1')  # trainable=trainable\r\n            conv5 = slim.max_pool2d(conv5, [3, 3], scope='pool3')\r\n            conv5 = slim.flatten(conv5)\r\n            fc6 = slim.fully_connected(conv5, 512, trainable=trainable, scope='fc6_s1')\r\n            fc7 = slim.fully_connected(fc6, 256, activation_fn=None, trainable=trainable, scope='fc7_sketch')\r\n            fc7 = tf.nn.l2_normalize(fc7, dim=1)\r\n    return fc7\r\n\r\n\r\ndef sketch_a_net_dssa(inputs, trainable):\r\n    with slim.arg_scope([slim.conv2d, slim.fully_connected],\r\n                        activation_fn=tf.nn.relu,\r\n                        weights_initializer=tf.truncated_normal_initializer(0.0, 0.1),\r\n                        weights_regularizer=slim.l2_regularizer(0.0005),\r\n                        trainable=False):  # when test 'trainable=True', don't forget to change it\r\n        with slim.arg_scope([slim.conv2d], padding='VALID'):\r\n            # x = tf.reshape(inputs, shape=[-1, 225, 225, 1])\r\n            conv1 = slim.conv2d(inputs, 64, [15, 15], 3, scope='conv1_s1')\r\n            conv1 = slim.max_pool2d(conv1, [3, 3], scope='pool1')\r\n            conv2 = slim.conv2d(conv1, 128, [5, 5], scope='conv2_s1')\r\n            conv2 = slim.max_pool2d(conv2, [3, 3], scope='pool2')\r\n            conv3 = slim.conv2d(conv2, 256, [3, 3], padding='SAME', scope='conv3_s1')\r\n            conv4 = slim.conv2d(conv3, 256, [3, 3], padding='SAME', scope='conv4_s1')\r\n            conv5 = slim.conv2d(conv4, 256, [3, 3], padding='SAME', trainable=trainable, scope='conv5_s1')\r\n            conv5 = slim.max_pool2d(conv5, [3, 3], scope='pool3')\r\n            # residual attention\r\n            att_mask = attentionNet(conv5, 'softmax')\r\n            att_map = tf.multiply(conv5, att_mask)\r\n            att_f = tf.add(conv5, att_map)\r\n            attended_map = tf.reduce_sum(att_f, reduction_indices=[1, 2])\r\n            attended_map = tf.nn.l2_normalize(attended_map, dim=1)\r\n            att_f = slim.flatten(att_f)\r\n            fc6 = slim.fully_connected(att_f, 512, trainable=trainable, scope='fc6_s1')\r\n            fc7 = slim.fully_connected(fc6, 256, activation_fn=None, trainable=trainable, scope='fc7_sketch')\r\n            fc7 = tf.nn.l2_normalize(fc7, dim=1)\r\n            # coarse-fine fusion\r\n            final_feature_map = tf.concat(1, [fc7, attended_map])\r\n    return final_feature_map\r\n\r\n\r\ndef init_variables(model_file='/home/soe/PycharmProjects/Deep_SBIR_tf-master/model/sketchnet_init.npy'):\r\n    if NET_ID==0:\r\n        pretrained_paras = ['conv1_s1', 'conv2_s1', 'conv3_s1', 'conv4_s1', 'conv5_s1', 'fc6_s1', 'fc7_sketch']\r\n    else:\r\n        pretrained_paras = ['conv1_s1', 'conv2_s1', 'conv3_s1', 'conv4_s1', 'conv5_s1', 'fc6_s1']\r\n    d = np.load(model_file).item()\r\n    init_ops = []  # a list of operations\r\n    for var in tf.global_variables():\r\n        for w_name in pretrained_paras:\r\n            if w_name in var.name:\r\n                print('Initialise var %s with weight %s' % (var.name, w_name))\r\n                try:\r\n                    if 'weights' in var.name:\r\n                        # using assign(src, dst) to assign the weights of pre-trained model to current network\r\n                        # init_ops.append(var.assign(d[w_name+'/weights:0']))\r\n                        init_ops.append(var.assign(d[w_name]['weights']))\r\n                    elif 'biases' in var.name:\r\n                        # init_ops.append(var.assign(d[w_name+'/biases:0']))\r\n                        init_ops.append(var.assign(d[w_name]['biases']))\r\n                except KeyError:\r\n                     if 'weights' in var.name:\r\n                        # using assign(src, dst) to assign the weights of pre-trained model to current network\r\n                        init_ops.append(var.assign(d[w_name+'/weights:0']))\r\n                        # init_ops.append(var.assign(d[w_name]['weights']))\r\n                     elif 'biases' in var.name:\r\n                        init_ops.append(var.assign(d[w_name+'/biases:0']))\r\n                        # init_ops.append(var.assign(d[w_name]['biases']))\r\n                except:\r\n                     if 'weights' in var.name:\r\n                        # using assign(src, dst) to assign the weights of pre-trained model to current network\r\n                        init_ops.append(var.assign(d[w_name][0]))\r\n                        # init_ops.append(var.assign(d[w_name]['weights']))\r\n                     elif 'biases' in var.name:\r\n                        init_ops.append(var.assign(d[w_name][1]))\r\n                        # init_ops.append(var.assign(d[w_name]['biases']))\r\n    return init_ops\r\n\r\n\r\ndef compute_euclidean_distance(x, y):\r\n    \"\"\"\r\n    Computes the euclidean distance between two tensorflow variables\r\n    \"\"\"\r\n\r\n    d = tf.square(tf.sub(x, y))\r\n    d = tf.sqrt(tf.reduce_sum(d))  # What about the axis ???\r\n    return d\r\n\r\n\r\ndef square_distance(x, y):\r\n    return tf.reduce_sum(tf.square(x - y), axis=1)\r\n\r\n\r\ndef compute_triplet_loss(anchor_feature, positive_feature, negative_feature, margin):\r\n    with tf.name_scope(\"triplet_loss\"):\r\n        d_p_squared = square_distance(anchor_feature, positive_feature)\r\n        d_n_squared = square_distance(anchor_feature, negative_feature)\r\n        loss = tf.maximum(0., d_p_squared - d_n_squared + margin)\r\n        return tf.reduce_mean(loss), tf.reduce_mean(d_p_squared), tf.reduce_mean(d_n_squared)\r\n\r\n\r\ndef main(subset, sketch_dir, image_dir, sketch_dir_te, image_dir_te, triplet_path, mean, hard_ratio, batch_size, phase, phase_te, net_model):\r\n\r\n    ITERATIONS = 20000\r\n    VALIDATION_TEST = 200\r\n    perc_train = 0.9\r\n    MARGIN = 0.3\r\n    SAVE_STEP = 200\r\n    model_path = \"/home/soe/PycharmProjects/Deep_SBIR_tf-master/model/%s/%s/\" % (subset, net_model)\r\n    #pre_trained_model = '/home/soe/PycharmProjects/Deep_SBIR_tf-master/model/sketchnet_init.npy'\r\n    pre_step = 0\r\n    if not os.path.exists(model_path):\r\n        os.makedirs(model_path)\r\n\r\n\r\n    # Siamease place holders\r\n    train_anchor_data = tf.placeholder(tf.float32, shape=(None, 225, 225, 1), name=\"anchor\")\r\n    train_positive_data = tf.placeholder(tf.float32, shape=(None, 225, 225, 1), name=\"positive\")\r\n    train_negative_data = tf.placeholder(tf.float32, shape=(None, 225, 225, 1), name=\"negative\")\r\n\r\n    # Creating the architecturek\r\n    if net_model == 'deep_sbir':\r\n        train_anchor = sketch_a_net_sbir(tf.cast(train_anchor_data, tf.float32) - mean, True)\r\n        tf.get_variable_scope().reuse_variables()\r\n        train_positive = sketch_a_net_sbir(tf.cast(train_positive_data, tf.float32) - mean, True)\r\n        train_negative = sketch_a_net_sbir(tf.cast(train_negative_data, tf.float32) - mean, True)\r\n    elif net_model == 'DSSA':\r\n        train_anchor = sketch_a_net_dssa(tf.cast(train_anchor_data, tf.float32) - mean, True)\r\n        tf.get_variable_scope().reuse_variables()\r\n        train_positive = sketch_a_net_dssa(tf.cast(train_positive_data, tf.float32) - mean, True)\r\n        train_negative = sketch_a_net_dssa(tf.cast(train_negative_data, tf.float32) - mean, True)\r\n    else:\r\n        print 'Please define the net_model'\r\n\r\n    init_ops = init_variables()\r\n    loss, positives, negatives = compute_triplet_loss(train_anchor, train_positive, train_negative, MARGIN)\r\n\r\n    # Defining training parameters\r\n    batch = tf.Variable(0)\r\n    learning_rate = 0.001\r\n    data_sampler = triplet_sampler_asy.TripletSamplingLayer()\r\n    data_sampler_te = triplet_sampler_asy.TripletSamplingLayer()\r\n    data_sampler.setup(sketch_dir, image_dir, triplet_path, mean, hard_ratio, batch_size, phase)\r\n    data_sampler_te.setup(sketch_dir_te, image_dir_te, triplet_path, mean, hard_ratio, batch_size, phase_te)\r\n    optimizer = tf.train.MomentumOptimizer(momentum=0.9, learning_rate=learning_rate).minimize(loss,\r\n                                                                                               global_step=batch)\r\n    #validation_prediction = tf.nn.softmax(lenet_validation)\r\n    # saver = tf.train.Saver(max_to_keep=5)\r\n    dst_path = '/home/soe/PycharmProjects/Deep_SBIR_tf-master/log'\r\n    model_id = '%s_%s_log.txt' % (subset, net_model)\r\n    filename = dst_path+'/'+model_id\r\n    # f = open(filename, 'a')\r\n    # Training\r\n    with tf.Session() as session:\r\n\r\n        session.run(tf.global_variables_initializer())\r\n        session.run(init_ops)\r\n        for step in range(ITERATIONS):\r\n            f = open(filename, 'a')\r\n            batch_anchor, batch_positive, batch_negative = data_sampler.get_next_batch()\r\n\r\n            feed_dict = {train_anchor_data: batch_anchor,\r\n                         train_positive_data: batch_positive,\r\n                         train_negative_data: batch_negative\r\n                         }\r\n            _, l = session.run([optimizer, loss], feed_dict=feed_dict)\r\n            # save_path = saver.save(session, model_path, global_step=step)\r\n            print(\"Iter %d: Loss Train %f\" % (step+pre_step, l))\r\n            f.write(\"Iter \"+str(step+pre_step) + \": Loss Train: \" + str(l))\r\n            f.write(\"\\n\")\r\n            # train_writer.add_summary(summary, step)\r\n\r\n            if step % SAVE_STEP == 0:\r\n                str_temp = '%smodel-iter%d.npy' % (model_path, step+pre_step)\r\n                save_dict = {var.name: var.eval(session) for var in tf.global_variables()}\r\n                np.save(str_temp, save_dict)\r\n\r\n            if step % VALIDATION_TEST == 0:\r\n                batch_anchor, batch_positive, batch_negative = data_sampler_te.get_next_batch()\r\n\r\n                feed_dict = {train_anchor_data: batch_anchor,\r\n                             train_positive_data: batch_positive,\r\n                             train_negative_data: batch_negative\r\n                             }\r\n\r\n                lv = session.run([loss], feed_dict=feed_dict)\r\n                # test_writer.add_summary(summary, step)\r\n                print(\"Loss Validation {0}\".format(lv))\r\n                f.write(\"Loss Validation: \" + str(lv))\r\n                f.write(\"\\n\")\r\n            f.close()\r\n\r\n\r\nif __name__ == '__main__':\r\n    # 'deep_sbir'(the model of cvpr16) or 'DSSA'(the model of iccv17)\r\n    net_model = 'deep_sbir'  \r\n    subset = 'shoes'\r\n    mean = 250.42\r\n    hard_ratio = 0.75\r\n    batch_size = 128\r\n    phase = 'TRAIN'\r\n    phase_te = 'TEST'\r\n    base_path = './data'\r\n    sketch_dir = '%s/%s/%s_sketch_db_%s.mat' % (base_path, subset, subset, phase.lower())\r\n    image_dir = '%s/%s/%s_edge_db_%s.mat' % (base_path, subset, subset, phase.lower())\r\n    triplet_path = '%s/%s/%s_annotation.json' % (base_path, subset, subset) # pseudo annotations for handbags\r\n    sketch_dir_te = '%s/%s/%s_sketch_db_%s.mat' % (base_path, subset, subset, phase_te.lower())\r\n    image_dir_te = '%s/%s/%s_edge_db_%s.mat' % (base_path, subset, subset, phase_te.lower())\r\n    main(subset, sketch_dir, image_dir, sketch_dir_te, image_dir_te, triplet_path, mean, hard_ratio, batch_size, phase, phase_te, net_model)\r\n\r\n\r\n\r\n\r\n-------------------------------------------------------------------------------------------------------------------------------------------\r\n\r\nThis is my code used above, in the # creating the architecture part, the code \"tf.get_variable_scope().reuse_variables()\" cause an error report : \r\nVariable fc6_s1/weights/Momentum/ does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=tf.AUTO_REUSE in VarScope?\r\n\r\nI read some issues about reuse and I know the problem is the sentence trying to use some variable not created. But I am a very bigginer of tensorflow, so I don't know how  to fix this code. If any people can help me, thank you very much !", "comments": ["@lukaszkaiser ", "@lukaszkaiser I have figure out my problem ! I change the code to be : \r\n        with tf.variable_scope(tf.get_variable_scope(), reuse=True):\r\n            train_positive = sketch_a_net_sbir(tf.cast(train_positive_data, tf.float32) - mean, True)\r\n            train_negative = sketch_a_net_sbir(tf.cast(train_negative_data, tf.float32) - mean, True)\r\nThen it can run successfully. Thank you !", "I think this is working as intended, the problem is figured out so looks solved. Thanks for reporting @LittleFlyFish !", "Thank you for your reply, I just read your other comments and think of a\nway to solve it. \ud83d\ude06\n\nOn Fri, Aug 17, 2018 at 6:40 PM, Lukasz Kaiser <notifications@github.com>\nwrote:\n\n> Closed #21657 <https://github.com/tensorflow/tensorflow/issues/21657>.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/21657#event-1795197914>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AY46UibImboTpvVLpdGai2k6Jmw6-mBQks5uRwAagaJpZM4V_0uB>\n> .\n>\n"]}, {"number": 21656, "title": "Closing TFRecordWriter twice should throw an error", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Mac OS X\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.9.0\r\n- **Python version**:3.6.6\r\n\r\n### Describe the problem\r\nClosing a TFRecordWriter twice should throw an error since it leads to undefined behavior down the road. Specifically, trying to read the tfrecords (containing n records) using a TFRecordDataset leads to an infinite loop when trying to read the n+1 element. Normally, this would raise an OutOfRangeError.", "comments": ["Actually this might have been related to some problem with the multiprocessing setup that I used. Will double check"]}, {"number": 21655, "title": "tf.image api not enough to handle image problems", "body": "My image data stored in hdfs,so when do data augmentation ,I need to use tf.gfile.FastGFile to read, then convert to PIL.Image or skimage ,it's complexed. I also know tf support some augmentation api ,but it's not enough.When tf support more image handle api like pillow or skimage? Thank you very much ~~~", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "This is part of my code below. When I do some complicated excise , I need transform tensor to PIL.Image object or numpy array,then transform to a tensor, this is not convenient, also has some information loss in the transformation. So I think tf.image should provide more function to handle image.Sorry,my English is poor,Thank you~~~\r\n\r\n       ```\r\n    def openImage(image):\r\n         # return Image.open(image, mode=\"r\")\r\n         img_data = tf.gfile.FastGFile(image, 'rb').read()\r\n         img_data = tf.image.decode_image(img_data)\r\n         with tf.Session() as sess:\r\n             return Image.fromarray(sess.run(img_data))\r\n\r\n    def randomGaussian(image, mean=0.2, sigma=0.3):\r\n        \"\"\"\r\n         \u5bf9\u56fe\u50cf\u8fdb\u884c\u9ad8\u65af\u566a\u58f0\u5904\u7406\r\n        :param image:\r\n        :return:\r\n        \"\"\"\r\n\r\n        def gaussianNoisy(im, mean=0.2, sigma=0.3):\r\n            \"\"\"\r\n            \u5bf9\u56fe\u50cf\u505a\u9ad8\u65af\u566a\u97f3\u5904\u7406\r\n            :param im: \u5355\u901a\u9053\u56fe\u50cf\r\n            :param mean: \u504f\u79fb\u91cf\r\n            :param sigma: \u6807\u51c6\u5dee\r\n            :return:\r\n            \"\"\"\r\n            for _i in range(len(im)):\r\n                im[_i] += random.gauss(mean, sigma)\r\n            return im\r\n\r\n        # \u5c06\u56fe\u50cf\u8f6c\u5316\u6210\u6570\u7ec4\r\n\r\n        img = np.asarray(image)\r\n        img.flags.writeable = True  # \u5c06\u6570\u7ec4\u6539\u4e3a\u8bfb\u5199\u6a21\u5f0f\r\n        width, height = img.shape[:2]\r\n        img_r = gaussianNoisy(img[:, :, 0].flatten(), mean, sigma)\r\n        img_g = gaussianNoisy(img[:, :, 1].flatten(), mean, sigma)\r\n        img_b = gaussianNoisy(img[:, :, 2].flatten(), mean, sigma)\r\n        img[:, :, 0] = img_r.reshape([width, height])\r\n        img[:, :, 1] = img_g.reshape([width, height])\r\n        img[:, :, 2] = img_b.reshape([width, height])\r\n        return Image.fromarray(np.uint8(img))\r\n\r\n    def saveImage(image, path):\r\n        # image.save(path)\r\n        with tf.Session() as sess:\r\n            img_data = tf.image.convert_image_dtype(tf.convert_to_tensor(np.array(image)), dtype=tf.uint8)\r\n            with tf.gfile.FastGFile(path, 'w') as f:\r\n                img_type = os.path.splitext(path)[1]\r\n                if img_type.lower() == '.png':\r\n                    f.write(sess.run(tf.image.encode_png(img_data)))\r\n                elif img_type.lower() == '.jpeg' or img_type == '.jpg':\r\n                    f.write(sess.run(tf.image.encode_jpeg(img_data)))\r\n\r\n```\r\nInformation\r\nHave I written custom code:yes\r\nOS Platform and Distribution:OS Platform\r\nTensorFlow installed from:none\r\nTensorFlow version:1.6\r\nBazel version: 0.11.1\r\nCUDA/cuDNN version9.0.176\r\nGPU model and memory:12GB\r\nExact command to reproduce:none\r\nMobile device:none", "Nagging Assignee @tatatodd: It has been 106 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 21654, "title": "Fix CVE-2018-1152 and CVE-2018-11813", "body": "libjpeg-turbo-2.0 is out which fixes this bug but the build system is\r\ncompletely changed from 1.5.3 to 2.0 and would need Bazel build changes\r\nso backport the patch first.\r\n\r\nhttps://nvd.nist.gov/vuln/detail/CVE-2018-1152\r\n\r\nSigned-off-by: Jason Zaman <jason@perfinion.com>", "comments": ["@gunan @yifeif hey guys, this needs merging asap :)\r\nWhats the procedure for CVEs? does something else need doing or is this all?", "The same patch should work to cherry-pick to 1.10 since its the same version of libjpeg-turbo but not sure what the procedure is.", "Damn, there is also CVE-2018-11813\r\nhttps://github.com/libjpeg-turbo/libjpeg-turbo/commit/909a8cfc7bca9b2e6707425bdb74da997e8fa499\r\nI'll update this PR", "Merged both fixes into the patch", "@martinwicke @av8ramit in case we roll out a patch release for 1.10, this is also needed.\r\nI will rerun builds to make sure breakages are not flakes.", "@gunan ping?", "@yifeif, do you think we need to manually import this one?\r\n@perfinion still no way to avoid the patch (by using a more recent libjpeg-turbo source)?", "Yea I think so, third_party/jpeg/libjpeg-turbo-1.5.3-cve_fix.patch is a new file under third_party/", "@gunan There is a 2.0.0 release which includes the fixes for both of these CVEs. But the jump is from 1.5.3 to 2.0.0 so I assume there would be some porting required (I have not looked into it yet tho). I thought it's best to get these fixes in asap first then looking into porting later can be done at a lower priority. If someone wants to port over to 2.0.0 and run all the tests that'd be a good way to go too.", "@perfinion we can try both. As this PR will require some additional tasks, the additional patch file needs some work to import into our internal repository.", "@gunan I just tested 2.0.0 quickly, they apparently changed their build quite significantly so jpeg.BUILD will require rewriting. I'll look at it more tomorrow and try get it working. the next branch is soon right? at the very least this should be merged before the branch if we cant port to 2.0.0 in time. The patch on top of 1.5.3 is not that long so hopefully merging into the internal repo isnt too much trouble.", "https://github.com/tensorflow/tensorflow/pull/21993 replaces this one so closing."]}, {"number": 21653, "title": "Endless restarting of session when run distribute traning with tensorflow 1.8", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Red Hat 4.8.5-4\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: Not applicable\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: r1.8\r\n- **Python version**: 2.7.5\r\n- **Bazel version (if compiling from source)**: 0.5.4\r\n- **GCC/Compiler version (if compiling from source)**: 4.9.2\r\n- **CUDA/cuDNN version**: 9.0\r\n- **GPU model and memory**: M40 11448MiB\r\n- **Exact command to reproduce**:\r\n```\r\nCleanup partition error: Unavailable: OS Error\r\n```\r\n\r\n### Descripe problem\r\nTraining the same model with tensorflow r1.4 is OK. With tensorflow r1.8, the session restarts without stop at the end of training. I have checked the traning log. Some workers went wrong when clearing partition. This error caused session restarting. But at this time, the other workers have alreadly stopped running. Thus, the restarting workers went wrong with master init error and start another session restarting progress.\r\n\r\n### Logs\r\n```\r\n### End of Training\r\n[2018-08-16 14:54:54.279 193 master_session.cc:1754] [ERROR] Cleanup partition error: Unavailable: OS Error\r\n[2018-08-16 14:54:54.282 tf_logging.py:126] [WARNING] An error was raised. This may be due to a preemption in a connected worker or parameter server. The current session will be closed and a new session will be created. Error: OS Error\r\n[2018-08-16 14:54:55.281 193 master_session.cc:1754] [ERROR] Cleanup partition error: Unavailable: OS Error\r\n[2018-08-16 14:54:55.333 tf_logging.py:116] [INFO] Graph was finalized.\r\n[2018-08-16 14:54:55.404 tf_logging.py:116] [INFO] Restoring parameters from hdfs://...\r\n[2018-08-16 14:54:56.288 193 master.cc:284] [ERROR] Master init: Unavailable: OS Error\r\n[2018-08-16 14:54:56.288 193 master_session.cc:1017] [INFO] DeregisterGraph error: Unavailable: OS Error\r\n[2018-08-16 14:54:56.288 193 master_session.cc:1017] [INFO] DeregisterGraph error: Unavailable: OS Error\r\n[2018-08-16 14:54:56.288 193 master_session.cc:1017] [INFO] DeregisterGraph error: Unavailable: OS Error\r\n[2018-08-16 14:55:05.450 4571 master.cc:236] [INFO] CreateSession still waiting for response from worker: /job:worker/replica:0/task:2\r\n[2018-08-16 14:55:05.450 4571 master.cc:236] [INFO] CreateSession still waiting for response from worker: /job:worker/replica:0/task:3\r\n[2018-08-16 14:55:05.450 4571 master.cc:236] [INFO] CreateSession still waiting for response from worker: /job:worker/replica:0/task:4\r\n[2018-08-16 14:55:05.450 4571 master.cc:236] [INFO] CreateSession still waiting for response from worker: /job:worker/replica:0/task:6\r\n[2018-08-16 14:55:05.450 4571 master.cc:236] [INFO] CreateSession still waiting for response from worker: /job:worker/replica:0/task:7\r\n[2018-08-16 14:55:15.450 4571 master.cc:236] [INFO] CreateSession still waiting for response from worker: /job:worker/replica:0/task:2\r\n[2018-08-16 14:55:15.450 4571 master.cc:236] [INFO] CreateSession still waiting for response from worker: /job:worker/replica:0/task:3\r\n[2018-08-16 14:55:15.450 4571 master.cc:236] [INFO] CreateSession still waiting for response from worker: /job:worker/replica:0/task:4\r\n[2018-08-16 14:55:15.450 4571 master.cc:236] [INFO] CreateSession still waiting for response from worker: /job:worker/replica:0/task:6\r\n[2018-08-16 14:55:15.450 4571 master.cc:236] [INFO] CreateSession still waiting for response from worker: /job:worker/replica:0/task:7\r\n[2018-08-16 14:55:16.451 196 master.cc:284] [ERROR] Master init: Unavailable: OS Error\r\n[2018-08-16 14:55:25.451 4571 master.cc:236] [INFO] CreateSession still waiting for response from worker: /job:worker/replica:0/task:2\r\n[2018-08-16 14:55:25.451 4571 master.cc:236] [INFO] CreateSession still waiting for response from worker: /job:worker/replica:0/task:3\r\n[2018-08-16 14:55:25.451 4571 master.cc:236] [INFO] CreateSession still waiting for response from worker: /job:worker/replica:0/task:6\r\n[2018-08-16 14:55:25.451 4571 master.cc:236] [INFO] CreateSession still waiting for response from worker: /job:worker/replica:0/task:7\r\n[2018-08-16 14:55:35.451 4571 master.cc:236] [INFO] CreateSession still waiting for response from worker: /job:worker/replica:0/task:2\r\n[2018-08-16 14:55:35.451 4571 master.cc:236] [INFO] CreateSession still waiting for response from worker: /job:worker/replica:0/task:3\r\n[2018-08-16 14:55:35.451 4571 master.cc:236] [INFO] CreateSession still waiting for response from worker: /job:worker/replica:0/task:6\r\n[2018-08-16 14:55:35.451 4571 master.cc:236] [INFO] CreateSession still waiting for response from worker: /job:worker/replica:0/task:7\r\n[2018-08-16 14:55:44.452 195 master.cc:284] [ERROR] Master init: Unavailable: OS Error\r\n[2018-08-16 14:55:45.451 4571 master.cc:236] [INFO] CreateSession still waiting for response from worker: /job:worker/replica:0/task:2\r\n[2018-08-16 14:55:45.451 4571 master.cc:236] [INFO] CreateSession still waiting for response from worker: /job:worker/replica:0/task:6\r\n[2018-08-16 14:55:45.451 4571 master.cc:236] [INFO] CreateSession still waiting for response from worker: /job:worker/replica:0/task:7\r\n```\r\n", "comments": ["I also have this issue", "@SharkWater could you check whether the problem still persist. If yes, could you send a small model code to reproduce the error? Thanks!", "I also have this issue \r\n2019-01-14 02:10:12.076965: E tensorflow/core/distributed_runtime/master.cc:269] Master init: Unavailable: OS Error\r\n2019-01-14 02:10:12.077125: I tensorflow/core/distributed_runtime/master_session.cc:1017] DeregisterGraph error: Unavailable: OS Error\r\n2019-01-14 02:10:12.077165: I tensorflow/core/distributed_runtime/master_session.cc:1017] DeregisterGraph error: Unavailable: OS Error\r\n2019-01-14 02:10:12.077190: I tensorflow/core/distributed_runtime/master_session.cc:1017] DeregisterGraph error: Unavailable: OS Error\r\n2019-01-14 02:10:12.077214: I tensorflow/core/distributed_runtime/master_session.cc:1017] DeregisterGraph error: Unavailable: OS Error\r\n2019-01-14 02:10:17.082953: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:1\r\n2019-01-14 02:10:27.083104: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:1\r\n2019-01-14 02:10:37.083256: I tensorflow/core/distributed_runtime/master.cc:221] CreateSession still waiting for response from worker: /job:worker/replica:0/task:1", "@SharkWater, based on the system information you provided, i suspect Bazel version may be creating an issue. Based on the [Tested build configurations](https://www.tensorflow.org/install/source), TF1.8 requires Bazel 0.10.0. Is it possible for you to upgrade your Bazel version and check whether the problem solved or not?\r\n\r\n@bbarnes52 and @lucylqe, Please provide [system information](https://github.com/tensorflow/tensorflow/issues/new?template=10-build-installation-issue.md) and a small code to reproduce the error? Thanks!", "> @SharkWater, based on the system information you provided, i suspect Bazel version may be creating an issue. Based on the [Tested build configurations](https://www.tensorflow.org/install/source), TF1.8 requires Bazel 0.10.0. Is it possible for you to upgrade your Bazel version and check whether the problem solved or not?\r\n> \r\n> @bbarnes52 and @lucylqe, Please provide [system information](https://github.com/tensorflow/tensorflow/issues/new?template=10-build-installation-issue.md) and a small code to reproduce the error? Thanks!\r\n\r\n@jvishnuvardhan Sorry about the wrong bazel version provided last time. I checked the bazel version again. It is 0.10.1 when we compile tf 1.8. And the error does not appear every time. It seems that this error appears only in poor network environment.", "Hi @SharkWater! \r\nIt seems you are using older versions(1.x versions) of Tensorflow which is not supported anymore. We recommend that you upgrade  your code base to 2.x  versions as many features and bug fixes has been done in newer versions and let us know if the issue still persists in newer versions. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/21653\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/21653\">No</a>\n"]}, {"number": 21652, "title": "Build failed due to missing \"tensorflow/contrib/constrained_optimization\"", "body": "\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS High Sierra 10.13.6\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: Not applicable\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: r1.10\r\n- **Python version**: 3.6.3\r\n- **Bazel version (if compiling from source)**: 0.15.2-homebrew\r\n- **Clang version**: \r\n```\r\nclang --version\r\nApple LLVM version 9.1.0 (clang-902.0.39.2)\r\nTarget: x86_64-apple-darwin17.7.0\r\nThread model: posix\r\nInstalledDir: /Library/Developer/CommandLineTools/usr/bin\r\n```\r\n- **CUDA/cuDNN version**: CPU only\r\n- **GPU model and memory**: CPU only\r\n- **Exact command to reproduce**: \r\n```bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package```\r\n\r\n### Describe the problem\r\nFollowing the help page that describes how to install TensorFlow from source, I first ran `./configure`(I declined each question and used valid paths for Python) followed by `bazel build --config=opt //tensorflow/tools/pip_package:build_pip_package`\r\n\r\n### Source code / logs\r\n```\r\nStarting local Bazel server and connecting to it...\r\n..........................................\r\nERROR: /Users/.../Build/tensorflow/tensorflow/tools/pip_package/BUILD:180:1: no such package 'tensorflow/contrib/constrained_optimization': BUILD file not found on package path and referenced by '//tensorflow/tools/pip_package:build_pip_package'\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted: no such package 'tensorflow/contrib/constrained_optimization': BUILD file not found on package path\r\nINFO: Elapsed time: 55.970s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (6 packages loaded)\r\n```\r\nDots in the first path are used to conceal the real path.", "comments": ["Could you share the output of the command `git describe --tags --long` in the branch you are trying to build?\r\nIn our CI, everything seems to be green.", "I cloned the repository again yesterday and don't have this problem any more. Thanks for you effort!"]}, {"number": 21651, "title": "What is the python mechanism to \"Bring in all of the public TensorFlow interface into this # module.\" in tensorflow/__init__.py", "body": "What is the python mechanism to \"Bring in all of the public TensorFlow interface into this module.\" in tensorflow/__init__.py.\r\n\r\nI don't see an explicit command to import any functions like tf.reduce_sum.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 21650, "title": "Update fold{l,r} examples to run on TensorFlow 1.9+", "body": "See #21340.", "comments": ["Nagging Assignee @protoget: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "61fef23485d9b1c0eaa8e46bdbbe82b6f2d8f83a changed this."]}, {"number": 21649, "title": "Support Azure Blob Storage Filesystem for TensorFlow", "body": "Original noted work in #18852 and this is for that work to support Azure blob storage FileSystem for TensorFlow.\r\n\r\nAdds file system support for paths in the format az://\\<account\\>.blob.core.windows.net/container/path/to/file.txt with the environment variable `TF_AZURE_STORAGE_KEY` used to access private accounts/containers.\r\n\r\nHas dependencies on \r\n* [azure-storage-cpp-lite from azure-storage-fuse](https://github.com/Azure/azure-storage-fuse) \r\n* [uuid from util-linux](https://github.com/karelzak/util-linux)\r\n\r\nHappy for any feedback or how to integrate it into the project as a whole.\r\n\r\nHave been discussing with @seguler from Microsoft during development", "comments": ["@protoget what are the next steps for this PR? Is there anything missing or other reviewers to have a look over this?\r\n\r\nAlso this is in contrib and I've been loading it with the `tf.load_file_system_library` method. Are there changes that you or another can provide so that this load call isn't needed?\r\n\r\nThe checks that are waiting to be reported...are they initiated by someone or are they reported some other way?\r\n\r\nThanks for any assistance", "Nagging Reviewer : You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 14 days with no activity and the `awaiting review` label has been applied.", "@damienpontifex - Excited to see this happening :-) Thank you for all the work !\r\n\r\nHere are the things we need to do to move forward with this:\r\n1. Find a way to remove the github.com/karelzak/util-linux dependency due to GPL license.\r\n2. After (1) move this proposal to the https://github.com/tensorflow/io (and to the purview of [SIG IO](https://github.com/tensorflow/community/blob/master/sigs/io/CHARTER.md))\r\n\r\nThanks to the guidance on this from - @ewilderj & @martinwicke\r\n\r\nLet me know how I can help contribute to your efforts here.\r\n", "Thanks @kkmsft \r\nI'll close this PR then and look into options for putting development of this into tensorflow_io. Any notes on changes between previous setup of filesystems and the new repo would be welcome if you want to send thoughts through offline"]}, {"number": 21648, "title": "ReadSavedModel & related operations should follow symlinks", "body": "https://github.com/tensorflow/tensorflow/blob/98010279f40e4963512ba2f2f39c3d732aef7b93/tensorflow/cc/saved_model/reader.cc#L34\r\n\r\nConsider that line, and now consider what happens if `export_dir` is the pathname of a symlink to a directory.\r\n\r\nThe way I'm reading this, the naive file join will fail to find the kSavedModelFilenamePb file that the op is looking for, since it will be looking at `<symlink>/saved_model.pb` instead of `<link_target>/saved_model.pb` as (I think) would be logical.\r\n\r\nThis came up for me recently. I have one process that's continually training and occasionally promoting a new version of the model to a SavedModel for inference in a second process. The second process runs concurrently and occasionally loads the latest SavedModel from disk.\r\n\r\nAtomically swapping a directory for another directory is either not possible on POSIX or, if it is possible, I couldn't find out a way from searching. However, it's easy to atomically swap the referent of a symlink. My naive hope was to maintain a symlink to the \"current best SavedModel\" which the second process would be able to use. The second process is Rust, and it's binding to the C API, which I traced all the way back to the linked line above.\r\n\r\nAdmittedly this isn't extremely easy to fix (or maybe it's not possible to fix - not sure if holding a directory fd preserves the directory's contents from removal by another process). In order to be useful for my use case, doing the easy thing of resolving the symlink in one operation and then doing file joins wouldn't work, because the symlink is subject to swap to a new referent at any point of time, and that could happen between the resolution of the symlink and ops on the referents. \r\n\r\nAnyway, there is a workaround for this use case (some sort of file locking should do the trick). But, I wanted to point this out.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "@nfiedel: Can you take a look at this, or recommend someone else?", "@karmel fyi. Do you know if the TF File APIs follow symlinks?", "I'm not sure what the expected behavior is for the C++ reader-- @philipp91 , can you comment on the behavior of the reader with symlinks? If not, I will have Sundeep take a look, as he will be looking at the SavedModel utils starting next week.\r\n", "Sorry, I don't know the answer to this. I have refactored the code at two separate occasions: when I moved it from loader.cc to reader.cc, and when I changed the error reporting (the latter might not even be submitted yet?).\r\nThe `io::JoinPath()` call has been there before and in the same way.\r\n\r\nMy personal uninformed opinion about this:\r\nSymlinks are an artifact of the underlying filesystem, everything should work fine if the TensorFlow code doesn't deal with them. Yes, it does look at `<symlink>/saved_model.pb`, and that's just as logical as the other version. I don't see why this would cause it to \"fail to find the kSavedModelFilenamePb\", that's still a valid file path even if it goes through the symlink.\r\n\r\nThe standard solution for continuous training and serving is to have the training create epoch directories with numerically/alphabetically increasing names. Then the serving process can `ls` the directory (or even a symlink) periodically and pick the latest one to load.\r\n\r\nIf you absolutely want to keep pointing a symlink to the latest version, but need the path to be fixed to the resolved target when the model is loaded, couldn't you do the symlink resolution in your own code, and then pass the resolved path to the `export_dir` parameter?", "I just tried it again in an isolated test, and you're right. Core _was_ able to resolve `<symlink>/saved_model.pb` to the target. It must have been something in my code that was choking on the symlink.\r\n\r\nThis code is fine as-is, sorry for the bother.\r\n"]}, {"number": 21647, "title": "ValueError: Attempted to map inputs that were not found in graph_def: [input:0]", "body": "Hello! \r\n\r\nI have asked this question in stackoverflow but at this point it merits a long post. \r\n\r\n### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nNo\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n Linux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\nNA\r\n- **TensorFlow installed from (source or binary)**:\r\npip \r\n- **TensorFlow version (use command below)**:\r\n1.8\r\n- **Python version**:\r\nPython 2.7.12\r\n- **Bazel version (if compiling from source)**:\r\nNA\r\n- **GCC/Compiler version (if compiling from source)**:\r\nNA\r\n- **CUDA/cuDNN version**:\r\n9.2\r\n- **GPU model and memory**:\r\n 7611MiB (gpu nvidia p4)\r\n- **Exact command to reproduce**:\r\n`ValueError: Attempted to map inputs that were not found in graph_def: [input:0]`\r\n\r\n\r\n### Describe the problem\r\nTrying to create a frozen graph, technically succeeding at doing that but then unable to run it. I am unsure about what the tags do. I want to use the model for inference,  but wasn't able to load it in a frozen graph in training and serving mode.  I suppose I have to restore the session? the documentation does not show that. And I double checked my output node's name is softmax. I saw the frozen graph in tensorboard and looks fine, but does not load into the graph. Help? I found people with issues like this but none resolved or their issues I already fixed in my code.\r\n\r\n### Source code / logs\r\nThis is the code to freeze from and not frozen  .pb file and its variables. \r\n```\r\nimport tensorflow as tf\r\nexport_dir='../catmod'\r\nwith tf.Session(graph=tf.Graph()) as sess:\r\n    # I have not been able to find how the tags affect this. Does training work? I tried as well with serve\r\n    # serve gave the same error of input:0  * I checked with saved_model_cli\r\n    tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.TRAINING], export_dir)\r\n    output_graph = \"frozen_graph.pb\" \r\n    # changing nodes from refswitch to switch then moving it accordingly \r\n    for node in gd.node:\r\n        if node.op == 'RefSwitch':\r\n            node.op = 'Switch'\r\n            for index in xrange(len(node.input)):\r\n                if 'moving_' in node.input[index]:\r\n                    node.input[index] = node.input[index] + '/read'\r\n        elif node.op == 'AssignSub':\r\n            node.op = 'Sub'\r\n            if 'use_locking' in node.attr: del node.attr['use_locking']\r\n    gd = sess.graph.as_graph_def()\r\n    output_nodes=['softmax']\r\n    output_graph_def = tf.graph_util.convert_variables_to_constants(\r\n       sess, # The session is used to retrieve the weights\r\n       gd,\r\n       output_nodes# The output node names are used to select the usefull nodes\r\n    )\r\n\r\n\r\n\r\n    # Finally we serialize and dump the output graph to the filesystem\r\n    with tf.gfile.GFile(output_graph, \"wb\") as f:\r\n        f.write(output_graph_def.SerializeToString())\r\nsess.close()\r\n\r\n\r\n```\r\nThis code is functional as I have used it with pre-frozen graphs.  (parts of) Code to load the frozen graph which I used with other frozen graphs that I got from the internet:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport numpy as np\r\nfrom tensorflow.python.platform import gfile\r\nfrom tensorflow.python.client import timeline\r\nfrom tensorflow.python.util import compat\r\n\r\n### Loading the model \r\n\r\ndef getModel(pb_frozen):\r\n    with gfile.FastGFile(pb_frozen,'rb') as f:\r\n        graph_def = tf.GraphDef()\r\n        graph_def.ParseFromString(f.read())\r\n    return graph_def\r\n\r\n# Running the model \r\ntf.logging.info(\"Starting execution\")\r\n\r\ngpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.50)\r\ntf.reset_default_graph()\r\n\r\ng = tf.Graph()\r\n\r\ndummy_input = np.random.random_sample((batch_size,224,224,3))\r\noutlist=[]\r\n# creating the graph \r\nwith g.as_default():\r\n    inc=tf.constant(dummy_input, dtype=tf.float32)\r\n    dataset=tf.data.Dataset.from_tensors(inc)\r\n    dataset=dataset.repeat()\r\n    iterator=dataset.make_one_shot_iterator()\r\n    next_element=iterator.get_next()\r\n    out = tf.import_graph_def(\r\n      graph_def=  getModel(pb_frozen), # loading graph \r\n      input_map={\"input\":next_element},\r\n      return_elements=['dense/bias']\r\n    )\r\n    out = out[0].outputs[0]\r\n    outlist.append(out)\r\n\r\n``` \r\nAnd then is run in a session. \r\n\r\n\r\n", "comments": ["I'm not sure I fully understand what you're trying to do here - the code you have to manipulate the graph before writing it out seems curious (for example, why are  all the `RefSwitch` nodes being changed to `Switch`?). \r\n\r\nPerhaps you can describe the higher level objective here and we can figure out a more appropriate path to it - modifying individual nodes in the graph seems fishy.\r\n\r\nAs for the error message itself, it is suggesting that there is no node named `input` in the the graph defined by `pb_frozen`.\r\n\r\nAlso, perhaps some clarification around the SavedModel / frozen graph may be in order.\r\nHere's a really quick summary:\r\n\r\n- A GraphDef defines a computation, which may depend on parameters (`tf.Variable`s in Python). The GraphDef does not contain the value of those parameters.\r\n- A checkpoint contains a map from variables referenced in a GraphDef to their values.\r\n- A SavedModel packages the GraphDef and the checkpoint into a single bundle.\r\n- A \"frozen\" graph is a term used to represent a graph that fully defines a model, i.e., there is no checkpoint needed since all the variables in the model have been \"frozen\" into constant tensors that can be included in the GraphDef.\r\n\r\nActually, a SavedModel can package multiple graphs. Use the `saved_model_cli` command-line tool to inspect the contents of a SavedModel . See [documentation](https://www.tensorflow.org/guide/saved_model#cli_to_inspect_and_execute_savedmodel). Using that tool, you'll be able to determine which tag is appropriate, what the names of the input and output tensors are etc.\r\n\r\nHope that helps.", "Hello!\r\nI modified the nodes because I had a bug when they weren't switch and I found on stackoverflow that the way of overcoming that bug is to just switch them individually. \r\n\r\nAnyway the big picture:\r\n\r\nI have various trained models in checkpoints that I then export into a pb/variables file which needs to then be converted into a frozen graph for me to then use a graph optimizer. So far I had been working with frozen graphs online and didn't expect this process of freezing a model from checkpoints to be this complicated. \r\n\r\nI checked the tags of my pb files with that comment and I have one with serve and the other with train tags. I put them through the code above with only the last layer name and managed to make visualizable graph through tensorboard that I can't load using the second part of the code. At this point I am pretty sure that when I am exporting the graph to a saved pb or when I am freezing it there is an issue creating the input layer such that i can load it an then do inference with it. \r\n\r\nThank you!\r\nNyla  ", "Hi @NylaWorker !\r\nWe are checking to see whether you still need help in this issue . Is this issue is replicating in latest version TF 2.6 too? . Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/21647\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/21647\">No</a>\n"]}, {"number": 21646, "title": "Tensorflow seq2seq demo(RNN-LSTM) can't convert into .tf file from toco", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No. only call functions from tensorflow.\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: None\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: v1.9.0-rc2-1412-ge747550\r\n- **Python version**: 2.7.12\r\n- **Bazel version (if compiling from source)**: 0.15.2\r\n- **GCC/Compiler version (if compiling from source)**: 5.4.0\r\n- **CUDA/cuDNN version**: 9.0\r\n- **GPU model and memory**: NVIDIA 1080TI, 12GB GDDR5\r\n- **Exact command to reproduce**: `python nmt.nmt.py --num_gpus=1 --src=de --tgt=en --hparams_path=nmt/standard_hparams/small.json --vocab_prefix=nmt/scripts/wmt16_de_en/vocab.bpe.32000 --out_dir=deen_one --inference_input_file=10.de --inference_output_file=output_infer`\r\n\r\n### Describe the problem\r\nI tried two version of toco converter(python, command).\r\n1. python version passed 'NoOp not registered error(log on below)\r\n2. command version will appear 'NoOp not registered error\r\n\r\nI have a few questions.\r\n1. does tensorflow support convert RNN network into .tf file now?\r\n2. what are the different between python version toco(**lite.py etc. tf.contrib.lite.TocoConverter.from_frozen_graph**) and command version? which one is the newest ones?\r\n3. I have already used **tf.graph_util.convert_variables_to_constants** python script to convert normal saved model into frozen graph but it appears (Op type not registered 'NoOp' #19267).\r\n4. I tried **tf.graph_util.remove_training_nodes function** for removing training nodes(may contain NoOp?) but the model will be broken(unable to inference, it may change some of the Op from the old graph then it pops errors again.). strange thing is **NoOp** problem is passed during toco converting.\r\n\r\nI'm using the most recent version of TF (7/27/2018)\r\n\r\n\r\n### Source code / logs\r\nHere is my [repro example](https://github.com/lkfo415579/nmt_custom)(**Machine Translation Project origin from google group**, [origin_repro](https://github.com/tensorflow/nmt)), i modified some of the code in order make it simpler for lite converter project. \r\nConverting into frozen and lite model's code : [code](https://github.com/lkfo415579/nmt_custom/blob/041dd8ffe4afcaf0dfe96d86d8de17a079372fcc/nmt/inference.py#L213)\r\n\r\nMy structure of frozen graph\r\n[structure.txt](https://github.com/tensorflow/tensorflow/files/2240393/structure.txt)\r\n\r\n\r\n**Using python version toco converter produced below log**\r\n```\r\n2018-07-30 11:32:13.520742: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1485] Adding visible gpu devices: 0, 1, 2\r\n2018-07-30 11:32:14.163167: I tensorflow/core/common_runtime/gpu/gpu_device.cc:966] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2018-07-30 11:32:14.163211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:972]      0 1 2 \r\n2018-07-30 11:32:14.163216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:985] 0:   N Y Y \r\n2018-07-30 11:32:14.163220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:985] 1:   Y N Y \r\n2018-07-30 11:32:14.163223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:985] 2:   Y Y N \r\n2018-07-30 11:32:14.163801: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1098] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9027 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:05:00.0, compute capability: 6.1)\r\n2018-07-30 11:32:14.270717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1098] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10033 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:09:00.0, compute capability: 6.1)\r\n2018-07-30 11:32:14.387717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1098] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:2 with 10033 MB memory) -> physical GPU (device: 2, name: GeForce GTX 1080 Ti, pci bus id: 0000:0a:00.0, compute capability: 6.1)\r\n2018-07-30 11:32:14.822919: W tensorflow/core/framework/allocator.cc:108] Allocation of 74850304 exceeds 10% of system memory.\r\n2018-07-30 11:32:14.890107: W tensorflow/core/framework/allocator.cc:108] Allocation of 74850304 exceeds 10% of system memory.\r\n2018-07-30 11:32:14.985703: W tensorflow/core/framework/allocator.cc:108] Allocation of 74850304 exceeds 10% of system memory.\r\n2018-07-30 11:32:15.062000: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: HashTableV2\r\n2018-07-30 11:32:15.062047: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: InitializeTableV2\r\n2018-07-30 11:32:15.064555: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: HashTableV2\r\n2018-07-30 11:32:15.064572: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: InitializeTableV2\r\n2018-07-30 11:32:15.067112: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: HashTableV2\r\n2018-07-30 11:32:15.067129: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: InitializeTableV2\r\n2018-07-30 11:32:15.067144: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: LookupTableFindV2\r\n2018-07-30 11:32:15.067168: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Iterator\r\n2018-07-30 11:32:15.067184: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: IteratorToStringHandle\r\n2018-07-30 11:32:15.067193: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorSliceDataset\r\n2018-07-30 11:32:15.067206: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: MapDataset\r\n2018-07-30 11:32:15.067219: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: MapDataset\r\n2018-07-30 11:32:15.067230: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: MapDataset\r\n2018-07-30 11:32:15.067242: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: PaddedBatchDatasetV2\r\n2018-07-30 11:32:15.067253: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: MakeIterator\r\n2018-07-30 11:32:15.067262: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: IteratorGetNext\r\n2018-07-30 11:32:15.067291: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.067302: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.067330: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.067340: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.067350: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Size\r\n2018-07-30 11:32:15.067498: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayV3\r\n2018-07-30 11:32:15.067514: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayV3\r\n2018-07-30 11:32:15.067543: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayScatterV3\r\n2018-07-30 11:32:15.067560: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.067570: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.067578: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.067586: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.067595: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.067611: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.067620: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.067629: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: LoopCond\r\n2018-07-30 11:32:15.067657: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayReadV3\r\n2018-07-30 11:32:15.067666: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.067674: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.067685: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.067710: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.067722: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.067740: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.067750: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.067770: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.067781: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.067814: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.067829: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayWriteV3\r\n2018-07-30 11:32:15.067838: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.067856: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.067864: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.067871: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.067877: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.067883: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.067888: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArraySizeV3\r\n2018-07-30 11:32:15.067903: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayGatherV3\r\n2018-07-30 11:32:15.067915: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: ReverseSequence\r\n2018-07-30 11:32:15.068041: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayV3\r\n2018-07-30 11:32:15.068055: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayV3\r\n2018-07-30 11:32:15.068084: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayScatterV3\r\n2018-07-30 11:32:15.068101: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.068111: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.068120: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.068128: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.068136: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.068153: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.068162: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.068171: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: LoopCond\r\n2018-07-30 11:32:15.068197: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayReadV3\r\n2018-07-30 11:32:15.068207: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.068215: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.068223: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.068247: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.068258: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.068277: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.068287: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.068307: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.068318: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.068348: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.068363: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayWriteV3\r\n2018-07-30 11:32:15.068373: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.068392: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.068400: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.068406: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.068413: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.068419: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.068426: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArraySizeV3\r\n2018-07-30 11:32:15.068443: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayGatherV3\r\n2018-07-30 11:32:15.068455: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: ReverseSequence\r\n2018-07-30 11:32:15.068473: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: LookupTableFindV2\r\n2018-07-30 11:32:15.068486: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: LookupTableFindV2\r\n2018-07-30 11:32:15.068505: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Round\r\n2018-07-30 11:32:15.068842: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.068857: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.068894: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: ListDiff\r\n2018-07-30 11:32:15.069261: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Size\r\n2018-07-30 11:32:15.069434: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: OneHot\r\n2018-07-30 11:32:15.069459: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: OneHot\r\n2018-07-30 11:32:15.069542: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: LogicalOr\r\n2018-07-30 11:32:15.069563: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayV3\r\n2018-07-30 11:32:15.069578: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayV3\r\n2018-07-30 11:32:15.069591: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayV3\r\n2018-07-30 11:32:15.069604: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.069613: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.069622: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.069629: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.069637: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.069646: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.069653: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.069660: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.069667: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.069673: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.069679: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.069687: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.069695: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.069703: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.069711: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.069719: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.069727: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.069735: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.069743: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.069778: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.069793: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: LoopCond\r\n2018-07-30 11:32:15.069862: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.070046: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.070059: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.070078: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.070088: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.070108: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.070119: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.070166: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.070177: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.070196: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.070206: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.070227: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.070239: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.070284: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.070335: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.070347: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.070361: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.070390: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.070400: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.070413: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.070422: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.070437: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.070447: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.070459: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.070468: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.070487: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.070497: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.070518: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.070592: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.070626: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.070637: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.070650: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.070841: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.070854: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.070890: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: ListDiff\r\n2018-07-30 11:32:15.070933: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.070996: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: OneHot\r\n2018-07-30 11:32:15.071008: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.071060: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: OneHot\r\n2018-07-30 11:32:15.071140: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-07-30 11:32:15.071150: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-07-30 11:32:15.071158: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-07-30 11:32:15.071204: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: LogicalOr\r\n2018-07-30 11:32:15.071530: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.071551: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.071577: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayWriteV3\r\n2018-07-30 11:32:15.071588: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.071597: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayWriteV3\r\n2018-07-30 11:32:15.071607: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.071617: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayWriteV3\r\n2018-07-30 11:32:15.071626: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.071657: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.071664: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.071672: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.071678: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.071685: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.071691: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.071698: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.071705: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.071711: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.071718: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.071724: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.071729: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.071736: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.071742: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.071749: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.071755: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.071761: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.071768: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.071774: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.071781: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArraySizeV3\r\n2018-07-30 11:32:15.071799: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayGatherV3\r\n2018-07-30 11:32:15.071810: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArraySizeV3\r\n2018-07-30 11:32:15.071827: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayGatherV3\r\n2018-07-30 11:32:15.071836: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArraySizeV3\r\n2018-07-30 11:32:15.071852: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayGatherV3\r\n2018-07-30 11:32:15.071868: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: GatherTree\r\n2018-07-30 11:32:15.071878: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: LookupTableFindV2\r\n2018-07-30 11:32:15.071889: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.071898: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.071922: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: SaveV2\r\n2018-07-30 11:32:15.071945: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: RestoreV2\r\n2018-07-30 11:32:15.071954: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.071964: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.071973: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.071983: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.071990: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.071999: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.072008: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.072017: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.072026: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.072035: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.072044: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.072054: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.072062: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.072072: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.072081: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.072089: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.072098: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.072107: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.074697: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: HashTableV2\r\n2018-07-30 11:32:15.074715: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: InitializeTableV2\r\n2018-07-30 11:32:15.077298: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: HashTableV2\r\n2018-07-30 11:32:15.077313: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: InitializeTableV2\r\n2018-07-30 11:32:15.079817: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: HashTableV2\r\n2018-07-30 11:32:15.079833: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: InitializeTableV2\r\n2018-07-30 11:32:15.079847: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: LookupTableFindV2\r\n2018-07-30 11:32:15.079866: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Iterator\r\n2018-07-30 11:32:15.079876: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: IteratorToStringHandle\r\n2018-07-30 11:32:15.079886: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorSliceDataset\r\n2018-07-30 11:32:15.079898: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: MapDataset\r\n2018-07-30 11:32:15.079911: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: MapDataset\r\n2018-07-30 11:32:15.079922: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: MapDataset\r\n2018-07-30 11:32:15.079934: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: PaddedBatchDatasetV2\r\n2018-07-30 11:32:15.079943: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: MakeIterator\r\n2018-07-30 11:32:15.079952: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: IteratorGetNext\r\n2018-07-30 11:32:15.079980: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.079991: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.080018: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.080028: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.080038: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Size\r\n2018-07-30 11:32:15.080183: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayV3\r\n2018-07-30 11:32:15.080197: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayV3\r\n2018-07-30 11:32:15.080226: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayScatterV3\r\n2018-07-30 11:32:15.080244: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.080253: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.080262: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.080271: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.080279: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.080294: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.080304: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.080314: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: LoopCond\r\n2018-07-30 11:32:15.080341: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.080351: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.080359: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayReadV3\r\n2018-07-30 11:32:15.080367: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.080395: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.080406: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.080425: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.080435: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.080452: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.080464: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.080492: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.080509: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.080518: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayWriteV3\r\n2018-07-30 11:32:15.080536: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.080544: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.080551: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.080557: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.080564: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.080571: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArraySizeV3\r\n2018-07-30 11:32:15.080588: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayGatherV3\r\n2018-07-30 11:32:15.080600: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: ReverseSequence\r\n2018-07-30 11:32:15.080769: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayV3\r\n2018-07-30 11:32:15.080786: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayV3\r\n2018-07-30 11:32:15.080816: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayScatterV3\r\n2018-07-30 11:32:15.080834: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.080843: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.080852: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.080861: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.080868: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.080884: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.080893: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.080903: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: LoopCond\r\n2018-07-30 11:32:15.080941: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.080950: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.080958: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayReadV3\r\n2018-07-30 11:32:15.080967: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.080993: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.081005: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.081023: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.081033: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.081050: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.081061: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.081091: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.081108: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.081118: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayWriteV3\r\n2018-07-30 11:32:15.081136: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.081143: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.081150: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.081156: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.081161: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.081168: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArraySizeV3\r\n2018-07-30 11:32:15.081185: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayGatherV3\r\n2018-07-30 11:32:15.081197: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: ReverseSequence\r\n2018-07-30 11:32:15.081213: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: LookupTableFindV2\r\n2018-07-30 11:32:15.081226: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: LookupTableFindV2\r\n2018-07-30 11:32:15.081244: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Round\r\n2018-07-30 11:32:15.081547: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.081560: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.081596: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: ListDiff\r\n2018-07-30 11:32:15.081997: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Size\r\n2018-07-30 11:32:15.082180: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: OneHot\r\n2018-07-30 11:32:15.082207: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: OneHot\r\n2018-07-30 11:32:15.082281: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: LogicalOr\r\n2018-07-30 11:32:15.082301: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayV3\r\n2018-07-30 11:32:15.082316: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayV3\r\n2018-07-30 11:32:15.082330: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayV3\r\n2018-07-30 11:32:15.082343: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.082353: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.082361: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.082370: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.082378: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.082386: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.082394: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.082402: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.082410: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.082418: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.082426: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.082433: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.082441: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.082449: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.082457: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.082465: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.082473: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.082481: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.082489: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.082524: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.082539: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: LoopCond\r\n2018-07-30 11:32:15.082609: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.082798: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.082811: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.082829: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.082840: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.082858: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.082870: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.082918: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.082930: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.082949: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.082959: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.082977: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.082989: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.083035: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.083091: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.083102: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.083113: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.083146: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.083157: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.083171: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.083181: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.083197: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.083207: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.083218: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.083226: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.083245: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.083255: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.083275: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.083351: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.083388: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.083400: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.083411: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.083610: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.083622: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.083660: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: ListDiff\r\n2018-07-30 11:32:15.083704: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.083772: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.083783: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: OneHot\r\n2018-07-30 11:32:15.083836: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: OneHot\r\n2018-07-30 11:32:15.083918: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-07-30 11:32:15.083928: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-07-30 11:32:15.083941: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-07-30 11:32:15.083989: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: LogicalOr\r\n2018-07-30 11:32:15.084328: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.084346: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.084376: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.084386: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayWriteV3\r\n2018-07-30 11:32:15.084397: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.084406: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayWriteV3\r\n2018-07-30 11:32:15.084416: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.084425: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayWriteV3\r\n2018-07-30 11:32:15.084456: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.084464: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.084471: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.084478: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.084485: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.084491: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.084498: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.084504: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.084511: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.084518: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.084524: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.084531: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.084538: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.084544: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.084551: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.084557: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.084564: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.084570: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.084577: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.084584: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArraySizeV3\r\n2018-07-30 11:32:15.084601: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayGatherV3\r\n2018-07-30 11:32:15.084612: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArraySizeV3\r\n2018-07-30 11:32:15.084641: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayGatherV3\r\n2018-07-30 11:32:15.084654: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArraySizeV3\r\n2018-07-30 11:32:15.084671: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayGatherV3\r\n2018-07-30 11:32:15.084686: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: GatherTree\r\n2018-07-30 11:32:15.084698: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: LookupTableFindV2\r\n2018-07-30 11:32:15.084709: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: VariableV2\r\n2018-07-30 11:32:15.084718: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.084743: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: SaveV2\r\n2018-07-30 11:32:15.084767: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: RestoreV2\r\n2018-07-30 11:32:15.084778: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.084794: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.084809: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.084823: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.084835: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.084844: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.084853: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.084862: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.084871: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.084880: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.084889: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.084898: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.084907: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.084916: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.084925: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.084934: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.084942: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.084950: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.084980: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: SaveV2\r\n2018-07-30 11:32:15.085003: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: RestoreV2\r\n2018-07-30 11:32:15.085013: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.085022: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.085031: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.085041: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.085050: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.085059: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.085068: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.085077: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.085086: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.085096: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.085105: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.085114: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.085123: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.085132: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.085141: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.085150: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.085160: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.085169: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Assign\r\n2018-07-30 11:32:15.085187: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: HashTableV2\r\n2018-07-30 11:32:15.085200: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: HashTableV2\r\n2018-07-30 11:32:15.085213: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Iterator\r\n2018-07-30 11:32:15.085223: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: IteratorGetNext\r\n2018-07-30 11:32:15.215031: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Size\r\n2018-07-30 11:32:15.215217: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayV3\r\n2018-07-30 11:32:15.215234: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayV3\r\n2018-07-30 11:32:15.215266: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayScatterV3\r\n2018-07-30 11:32:15.215286: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.215295: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.215304: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.215312: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.215321: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.215336: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.215346: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.215356: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: LoopCond\r\n2018-07-30 11:32:15.215385: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.215394: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.215403: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayReadV3\r\n2018-07-30 11:32:15.215411: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.217988: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.218018: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.218063: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.218081: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.218091: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayWriteV3\r\n2018-07-30 11:32:15.218109: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.218117: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.218124: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.218131: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArraySizeV3\r\n2018-07-30 11:32:15.218150: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayGatherV3\r\n2018-07-30 11:32:15.218161: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: ReverseSequence\r\n2018-07-30 11:32:15.218278: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayV3\r\n2018-07-30 11:32:15.218292: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayV3\r\n2018-07-30 11:32:15.218322: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayScatterV3\r\n2018-07-30 11:32:15.218340: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.218349: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.218356: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.218363: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.218369: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.218384: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.218394: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.218404: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: LoopCond\r\n2018-07-30 11:32:15.218433: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.218443: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.218451: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayReadV3\r\n2018-07-30 11:32:15.218459: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.221141: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.221169: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.221201: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.221220: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.221229: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayWriteV3\r\n2018-07-30 11:32:15.221249: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.221256: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.221263: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.221270: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArraySizeV3\r\n2018-07-30 11:32:15.221288: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayGatherV3\r\n2018-07-30 11:32:15.221299: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: ReverseSequence\r\n2018-07-30 11:32:15.221317: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: LookupTableFindV2\r\n2018-07-30 11:32:15.221331: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: LookupTableFindV2\r\n2018-07-30 11:32:15.221352: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Round\r\n2018-07-30 11:32:15.222197: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: ListDiff\r\n2018-07-30 11:32:15.222450: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Size\r\n2018-07-30 11:32:15.222699: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: OneHot\r\n2018-07-30 11:32:15.222724: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: OneHot\r\n2018-07-30 11:32:15.222745: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: LogicalOr\r\n2018-07-30 11:32:15.222760: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayV3\r\n2018-07-30 11:32:15.222775: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayV3\r\n2018-07-30 11:32:15.222788: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.222797: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.222805: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.222813: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.222821: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.222829: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.222837: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.222844: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.222852: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.222860: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.222868: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.222875: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.222883: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.222890: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.222919: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.222936: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: LoopCond\r\n2018-07-30 11:32:15.222990: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.226937: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.226976: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.229695: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.229729: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.229780: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.230108: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.230143: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.230153: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.230171: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.230181: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.230201: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.230272: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.231168: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.295597: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: ListDiff\r\n2018-07-30 11:32:15.295669: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.295742: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.295754: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: OneHot\r\n2018-07-30 11:32:15.295853: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-07-30 11:32:15.295863: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-07-30 11:32:15.295871: I tensorflow/contrib/lite/toco/import_tensorflow.cc:181] Unsupported data type in placeholder op: 2\r\n2018-07-30 11:32:15.295920: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: LogicalOr\r\n2018-07-30 11:32:15.296186: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.296206: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.296226: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.296234: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayWriteV3\r\n2018-07-30 11:32:15.296246: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Enter\r\n2018-07-30 11:32:15.296256: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayWriteV3\r\n2018-07-30 11:32:15.296283: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.296291: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.296299: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: Exit\r\n2018-07-30 11:32:15.296307: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArraySizeV3\r\n2018-07-30 11:32:15.296324: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayGatherV3\r\n2018-07-30 11:32:15.296335: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArraySizeV3\r\n2018-07-30 11:32:15.296352: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: TensorArrayGatherV3\r\n2018-07-30 11:32:15.296368: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: GatherTree\r\n2018-07-30 11:32:15.296378: I tensorflow/contrib/lite/toco/import_tensorflow.cc:1048] Converting unsupported operation: LookupTableFindV2\r\n2018-07-30 11:32:15.446032: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before Removing unused ops: 3083 operators, 5273 arrays (0 quantized)\r\n2018-07-30 11:32:15.569851: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After Removing unused ops pass 1: 753 operators, 1254 arrays (0 quantized)\r\n2018-07-30 11:32:15.587405: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before general graph transformations: 753 operators, 1254 arrays (0 quantized)\r\n2018-07-30 11:32:15.605187: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 1: 688 operators, 1130 arrays (0 quantized)\r\n2018-07-30 11:32:15.622634: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] After general graph transformations pass 2: 688 operators, 1130 arrays (0 quantized)\r\n2018-07-30 11:32:15.640010: I tensorflow/contrib/lite/toco/graph_transformations/graph_transformations.cc:39] Before dequantization graph transformations: 688 operators, 1130 arrays (0 quantized)\r\n2018-07-30 11:32:15.649520: F tensorflow/contrib/lite/toco/tooling_util.cc:685] Check failed: dim >= 1 (0 vs. 1)\r\n\r\nNone\r\n```", "comments": ["@lkfo415579 : Unfortunately a lot of these operators are not supported by TFLite, please refer to: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/lite/g3doc/tf_ops_compatibility.md for details.", "@shashishekhar  will tensorflow-lite support LSTM in the future?", "@lkfo415579: Yes.", "Closing this, please monitor:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/tf_ops_compatibility.md\r\nfor status of supported ops."]}, {"number": 21645, "title": "Error: corrupted size vs. prev_size when using python3.6", "body": "Hi, \r\nI install tensorflow-1.9; then install pytorch=0.4 at python2 and python3 respectively.\r\nI use python2 to run my code, no error is reported; but when using python3 to run it, an error is report after finishing run. The error like as follows:\r\nError in `/restools/tools/miniconda/miniconda3/bin/python': corrupted size vs. prev_size: 0x000055b2bcb5c690 ***", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Have I written custom code:  No, I use r9y9's wavenet_vocoder.\r\nOS Platform and Distribution: Ubuntu 14.0\r\nTensorFlow installed from : anaconda3/pip\r\nTensorFlow version: 1.9 + pytorch=0.4\r\nBazel version: I don't know it.\r\nCUDA/cuDNN version: cuda8.0-cudnn6.0\r\nGPU model and memory: tina 1080i, mem=12G\r\nExact command to reproduce \uff1a /restools/tools/miniconda/miniconda3/bin/python synthesis_test.py --preset=./presets/v1.0.json --conditional=./180k/mel-wnet/speech-mel-00005.npy --file-name-suffix=00005  ./works/v1/checkpoint_step000740000_ema.pth ./works/0805_v1_180k_740kv1\r\nMobile device : no\r\n", "Can you retry with the most recent release of TF?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "@NewEricWang  - Does this still persist with the latest version of TF ?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Code stop after showing this message. \r\n```\r\ntensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\ncorrupted size vs. prev_size\r\n```\r\nPython 3.8\r\ntensorflow==2.2.0"]}, {"number": 21644, "title": "Not found: FeedInputs: unable to find feed output phase_train", "body": "I try to use  Facenet  by   tensorflow C++ API (VS2015),it can load graph,but it doesn't work.\r\nNot found: FeedInputs: unable to find feed output phase_train\r\ncode like this:\r\ntensorflow::Tensor input_tensor(DT_FLOAT, TensorShape({ 2 , iHeight, iWidth, depth }));\r\nauto input_tensor_mapped = input_tensor.tensor<float, 4>(); \r\n...................................................\r\ntensorflow::Tensor phase(DT_BOOL, TensorShape());\r\n\t phase.scalar<int>()() = FALSE;\r\n\r\n\tinput_tensor.shape();\r\n\tstd::vector<std::pair<std::string, tensorflow::Tensor>> inputs = {\r\n\t\t{ \"input\", input_tensor },                                    //it's OK\r\n\t\t{\" phase_train\",phase }      // it' bad    \r\n\t};\r\n please help me,thansk", "comments": ["here is python code,it can run ok. Now ,i need to change C++ API, \r\n# Get input and output tensors\r\n            images_placeholder = tf.get_default_graph().get_tensor_by_name(\"input:0\")\r\n            embeddings = tf.get_default_graph().get_tensor_by_name(\"embeddings:0\")\r\n\t\t\t\r\n            phase_train_placeholder = tf.get_default_graph().get_tensor_by_name(\"phase_train:0\")\r\n\r\n            # Run forward pass to calculate embeddings\r\n            feed_dict = { images_placeholder: images, phase_train_placeholder:False }\r\n            emb = sess.run(embeddings, feed_dict=feed_dict)", "@cvJie \r\nCould you please try on latest stable version [2.4/2.5/2.6] of tf and let us know if this is still an issue.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/21644\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/21644\">No</a>\n"]}, {"number": 21643, "title": "Tensorflow Lite Custom op have no effect even source code *.cc has modified", "body": "System information\r\n== cat /etc/issue ===============================================\r\nLinux master 4.15.0-29-generic #31~16.04.1-Ubuntu SMP Wed Jul 18 08:54:04 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"16.04.5 LTS (Xenial Xerus)\"\r\nVERSION_ID=\"16.04\"\r\nVERSION_CODENAME=xenial\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu 5.5.0-12ubuntu1~16.04) 5.5.0 20171010\r\nCopyright (C) 2015 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions. There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n\r\n== uname -a =====================================================\r\nLinux master 4.15.0-29-generic #31~16.04.1-Ubuntu SMP Wed Jul 18 08:54:04 UTC 2018 x86_64 x86_64 x86_64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy 1.14.5\r\nprotobuf 3.6.0\r\ntensorflow 1.8.0\r\ntensorflow-tensorboard 0.4.0\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.8.0\r\ntf.GIT_VERSION = v1.8.0-0-g93bc2e2072\r\ntf.COMPILER_VERSION = v1.8.0-0-g93bc2e2072\r\nSanity check: array([1], dtype=int32)\r\n/usr/local/lib/python2.7/dist-packages/h5py/init.py:36: FutureWarning: Conversion of the second argument of issubdtype from float to np.floating is deprecated. In future, it will be treated as np.float64 == np.dtype(float).type.\r\nfrom ._conv import register_converters as _register_converters\r\n\r\n== env ==========================================================\r\nLD_LIBRARY_PATH /usr/local/cuda/lib64/:/usr/local/cuda/lib64/:/usr/local/cuda-9.0/lib64:\r\nDYLD_LIBRARY_PATH is unset\r\n\r\n== nvidia-smi ===================================================\r\nMon Jul 30 11:49:23 2018\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 396.45 Driver Version: 396.45 |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU Name Persistence-M| Bus-Id Disp.A | Volatile Uncorr. ECC |\r\n| Fan Temp Perf Pwr:Usage/Cap| Memory-Usage | GPU-Util Compute M. |\r\n|===============================+======================+======================|\r\n| 0 Quadro P600 Off | 00000000:03:00.0 On | N/A |\r\n| 34% 43C P8 N/A / N/A | 574MiB / 1997MiB | 1% Default |\r\n+-------------------------------+----------------------+----------------------+\r\n\r\n+-----------------------------------------------------------------------------+\r\n| Processes: GPU Memory |\r\n| GPU PID Type Process name Usage |\r\n|=============================================================================|\r\n| 0 1152 G /usr/lib/xorg/Xorg 237MiB |\r\n| 0 2213 G compiz 79MiB |\r\n| 0 2589 G ...-token=224D99F526E00AE3A3C0EF4D5E6D103A 113MiB |\r\n| 0 5305 G ...-token=53BA9EE005E85645FEB6537828E37D64 141MiB |\r\n+-----------------------------------------------------------------------------+\r\n\r\n== cuda libs ===================================================\r\n/usr/local/cuda-9.2/doc/man/man7/libcudart.7\r\n/usr/local/cuda-9.2/doc/man/man7/libcudart.so.7\r\n/usr/local/cuda-9.2/targets/x86_64-linux/lib/libcudart_static.a\r\n/usr/local/cuda-9.2/targets/x86_64-linux/lib/libcudart.so.9.2.148\r\n\r\n\r\n### Describe the problem\r\nI converted caffe ssd model to tensorflow/tensorfow lite. There are small differences in caffe and tensorflow detection layer (i.e., decode box and coordinates difference). \r\nTensorflow lite does not support all ops of tensorflow.\r\nDetection layer in tensorflow lite is implemented in detect_postprocess.cc as custom op.\r\nI changed detect_postprocess.cc to apply caffes' decode box and other functions. Then, I compiled tf with \"bazel build -c opt --jobs=8 //tensorflow/tools/pip_package:build_pip_package\" and also tried with \"bazel build -c opt \"//tensorflow/contrib/lite/kernels:builtin_ops\",\r\nHowever, problem is when I load detect.tflite on android and/or PC (with tensorfow lite python api <<tf.VERSION = 1.8.0 does not work,tf version:: 1.10.0 workd>>), the detection results return the same result as what detect_postprocess.cc supposed to work even I changed functionality of detect_postprocess.cc.\r\n\r\nIn other words, tensorflow lite always refers very first version of detect_postprocess.cc\r\n\r\nWhat is the problem?\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Why don't you just remove the registration of the default one. Or call your modified version a different name?", "@drpngx Your op resolver is not able to resolve to the new code in the custom op. Can you share the steps that you ran after changing the code in detect_postprocess.cc", "thank you, I will test it out.", "@aselle the modified version with different names does not make any sense.\r\ndetect.tflite on c++ api with libtensorflow-lite.a (includes modified TFLite_Detection_PostProcess) works on pc.\r\n", "You are not being clear on what you are doing.\r\n\r\nYou modified detect_postprocess.cc and recompiled right? Did you make a copy of it and add it to the build file, or did you modify it in place.\r\n\r\nDoes your modification work under any circumstance?\r\n\r\nDid you compile a new AAR for android? or are you using the stock one? If the stock one then it of course will not work.\r\n\r\n", "> You modified detect_postprocess.cc and recompiled right?\r\n\r\nyes, I modified and recompiled.\r\nI did not copy the detect_postprocess.cc to any place.\r\n\r\n> Does your modification work under any circumstance?\r\n\r\nYes it does, I mentioned it \"detect.tflite on c++ api with libtensorflow-lite.a (includes modified TFLite_Detection_PostProcess) works on pc\"\r\n> Did you compile a new AAR for android? \r\n\r\nI referred https://firebase.google.com/docs/ml-kit/android/use-custom-tflite and https://github.com/tensorflow/tensorflow/issues/18751.", "figured out.", "Glad you got it working. Could you post what the solution was so others can benefit from your work? Thanks.", "open the android project which is in tensorflow/contrib/lite then android studio will do useful settings for you."]}, {"number": 21642, "title": "MKL Build Failing with new PR Merge", "body": "Hello,\r\n\r\nIt looks like with the latest changes to the BUILD file under `tools/pip_package`, the references to MKL DNN is not being picked up any longer, because there's no `intel_mkl_ml` folder under `third_party`. There are `mkl` and `mkl_dnn` but not `intel_mkl_ml` under `third_party`, and that being said, it looks like PR #408 which has this MKL \"fix\" actually passed all the build tests (red X next to the commit)...\r\n\r\nFor what it's worth, I have both MKL and MKL-DNN built in my environment with the correct paths set, but TF always seems to want to build the MKL-DNN libraries themselves, so if I could even explicitly point to my environment's MKL library files, then that'd also work.\r\n\r\n## Build command:\r\n```\r\necho \"startup --batch\" >>/etc/bazel.bazelrc && \\\r\n    echo \"build --spawn_strategy=standalone --genrule_strategy=standalone\" >>/etc/bazel.bazelrc && \\\r\n    echo \"deb [arch=amd64] http://storage.googleapis.com/bazel-apt stable jdk1.8\" | tee /etc/apt/sources.list.d/bazel.list && \\\r\n    curl https://bazel.build/bazel-release.pub.gpg | apt-key add - && \\\r\n    apt-get update && apt-get install -y bazel  && rm -rf /var/lib/apt/lists/* && \\\r\n    ldconfig && \\\r\n    pip uninstall -y tensorflow-tensorboard tb-nightly tf-nightly tensorflow && \\\r\n    cd /opt && \\\r\n    git clone https://github.com/tensorflow/tensorflow.git && \\\r\n    cd /opt/tensorflow && \\\r\n    # cp /opt/tensorflow/third_party/mkl/LICENSE /opt/tensorflow/third_party/mkl_dnn/LICENSE && \\\r\n    /bin/bash ./configure \\\r\n    && \\\r\n    bazel build \\\r\n    --config=mkl --config=opt  \\\r\n    --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" \\\r\n    --copt=-msse4.2 --copt=-msse4.1 --copt=-mavx --copt=-msse2 --copt=-msse3  \\\r\n    --copt=-O3 --copt=-mfpmath=both \\\r\n    --copt=\"-DMKL_LP64\" \\\r\n    --copt=\"-fPIC\" \\\r\n    --linkopt=\"-lmkl_gf_lp64\" \\\r\n    --linkopt=\"-lmkl_gnu_thread\" \\\r\n    --linkopt=\"-dl\" \\\r\n    --linkopt=\"-lpthread\" \\\r\n    --linkopt=\"-lmkl_core\" \\\r\n    --linkopt=\"-lm\" \\\r\n    --linkopt=\"-lmkl_rt\" \\\r\n    --linkopt=\"-lmkldnn\" \\\r\n    tensorflow/tools/pip_package:build_pip_package && \\\r\n    bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/pip && \\\r\n    pip install --no-deps /tmp/pip/tensorflow-*.whl \r\n```\r\n\r\n## Error:\r\n```\r\n/opt/tensorflow/tensorflow/tools/pip_package/BUILD:206:1: no such package 'third_party/intel_mkl_ml': BUILD file not found on package path and referenced by '//tensorflow/tools/pip_package:build_pip_package'```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "@gunan could you take a look or redirect as necessary? Thanks!", "Thanks @skye!\r\n\r\n@gunan it looks like there's more than one place where `intel_mkl_ml` is being referred to, whereas everywhere else they don't? https://github.com/tensorflow/tensorflow/search?q=third_party%2Fintel_mkl_ml&unscoped_q=third_party%2Fintel_mkl_ml\r\n", "I think @tomerk made this change.\r\nTomer, could you take a look?", "Hi @gunan, I don't recall ever making any changes to intel_mkl_ml, mkl, or mkl_dnn", "I am really sorry, read the author user id wrong. @jktomer made the change in https://github.com/tensorflow/tensorflow/commit/00590b6973cb071744cdd1335a161b17866dea87", "Hmm but there's still like 3 referenes to `intel_mkl_ml` inside random C code in the repo (see link in my previous post). Shouldn't all those scripts be fixed as well?", "I ran into this problem yesterday, 'git pull' just now, it seems the problem is fixed in https://github.com/tensorflow/tensorflow/pull/21640 or say c09a0176", "Yep it's building for me now all good. Still concerned about the references ", "I'll wait for a bit to see if any of the devs have anything to point out regarding the references to `intel_mkl_ml` in the C code, and then close the issue since the primary problem is solved.", "Ping, @jktomer\r\nCould you weight in about https://github.com/tensorflow/tensorflow/commit/00590b6973cb071744cdd1335a161b17866dea87 ?", "Build failing again: #21938 ", "Nagging Assignee @gunan: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 21641, "title": "Added some missing int32 GPU kernel registrations.", "body": "@alextp This helps prevent some performance degradation when allowing soft placement. The issue is that gradient updates are often colocated with the variables they are applied to. When using resource variables, the missing int32 kernel registrations can cause the whole colocation group to be placed on the CPU incurring a big performance penalty. The added int32 kernel registrations follow the same \"fake\" GPU kernel pattern used in various places (such as the \"Concat\" and \"ConcatV2\" ops, for example).", "comments": ["Anthony, can you fix the failing tests?", "I fixed the clang-format check, but I don't know what the GPU Python3 errors are. It seems to segfault somewhere.", "That is probably accessing GPU memory from the CPU (or vice versa)\n\nOn Mon, Aug 20, 2018 at 3:41 PM Anthony Platanios <notifications@github.com>\nwrote:\n\n> I fixed the clang-format check, but I don't know what the GPU Python3\n> errors are. It seems to segfault somewhere.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/21641#issuecomment-414486113>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxUKdOaCZHAnw1qBz3ZBCKiOHVWhsks5uSzsPgaJpZM4V_DN3>\n> .\n>\n\n\n-- \n - Alex\n", "Is there a way for me to test for this while trying to debug? Because I can't reproduce the error.", "I've been able to reproduce it building tf from source with python3 and\ncuda.\n\nOn Tue, Aug 21, 2018 at 5:47 PM Anthony Platanios <notifications@github.com>\nwrote:\n\n> Is there a way for me to test for this while trying to debug? Because I\n> can't reproduce the error.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/21641#issuecomment-414867868>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxT7z5YU0BYAD4YXDF95clCOuCWgXks5uTKoYgaJpZM4V_DN3>\n> .\n>\n\n\n-- \n - Alex\n", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "It has been 43 days that this pull-request has stalled. Please create a new pull-request with the requested changes."]}, {"number": 21640, "title": "[Intel MKL] Fixing a build issue", "body": "", "comments": ["@jktomer Can we merge this PR?", "The change looks good, but I don't have write access. @tatianashp are you able to merge?", "It's in the process of being merged.", "Already cloned to a internal change list to fix. @tatianashp  please update the status once that CL is submitted."]}, {"number": 21639, "title": "Unnecessary character in logging.h", "body": "Unnecessary new line character at line 229 .", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "Please assign this to me ", "@tensorflowbutler Assign this to me instead ", "@protoget Please approve the changes and update the label if the changes are fine according to you.", "@protoget Please update the label as suggested by @tensorflowbutler ", "@pragyaak this PR is in the reference of the commit you are referencing ", "The the new line was there because it's exceeding the 80 char per line limit linter checker. Our auto-formating tool is adding the new line back when we import this change. Will close this PR then. Thanks again @ervaibhavkumar!"]}]