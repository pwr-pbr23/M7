[{"number": 14544, "title": "ValueError: Variable RNNLM/RNNLM/embedding_layer/embedding/Adam_2/ does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=tf.AUTO_REUSE in VarScope?", "body": "  when running following code, \r\n    \r\n**with tf.variable_scope('RNNLM') as scope:\r\n          model = RNNLM_Model(config)\r\n          scope.reuse_variables()\r\n          gen_model = RNNLM_Model(gen_config)**\r\n\r\nthis problem occurs:\r\n       **ValueError: Variable RNNLM/RNNLM/embedding_layer/embedding/Adam_2/ does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=tf.AUTO_REUSE in VarScope?**\r\n why it is 'RNNLM/RNNLM/embedding_layer'?\r\n\r\nthe following code can run successfully\r\n \r\n **model = RNNLM_Model(config)\r\n  tf.get_variable_scope().reuse_variables()\r\n  gen_model = RNNLM_Model(gen_config)**\r\n\r\n  ", "comments": ["Would be hard to debug this without knowing what the actual model code looks like... \r\n\r\nMaybe try doing \r\n\r\nwith tf.variable_scope('RNNLM', reuse=tf.AUTO_REUSE) as scope:\r\n  ...\r\n", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 183 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!", "I think the code is from here https://github.com/kingtaurus/cs224d/blob/master/assignment2/q3_RNNLM.py\r\n\r\nLine 118", "I got the same problem, using \r\n```python\r\nclass a:\r\n    embedding = tf.get_variable(\r\n          \"embedding\", [self.vocab_size, self.embed_size], dtype=data_type())\r\n    inputs = tf.nn.embedding_lookup(embedding, self.x_train)\r\n```\r\nthen \r\n```python\r\nwith tf.Session(config=sess_config) as sess:\r\n    with tf.variable_scope(tf.get_variable_scope(), reuse=True, initializer=initializer):\r\n        #define a \r\n```\r\n\r\nFinally got \r\n`ValueError: Variable embedding does not exist, or was not created with tf.get_variable(). Did you mean to set reuse=tf.AUTO_REUSE in VarScope?`\r\n\r\nThen I modify the `reuse=tf.AUTO_RESUE` , it works. \r\nFinally I use \r\n```python\r\nbuilder = tf.saved_model.builder.SavedModelBuilder(FLAGS.save_path)\r\nbuilder.add_meta_graph_and_variables(sess, ['ptb'])\r\nbuilder.save() \r\n```\r\nto save the model \r\nand use` tf.saved_model.loader.load(sess, ['ptb'], FLAGS.save_path)` to load it and it occurs **Error**\r\n```\r\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value embedding\r\n\t [[node embedding/read (defined at ptb_word_lm_store_test.py:160)  = Identity[T=DT_HALF, _class=[\"loc:@embedding\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](embedding)]]\r\n```"]}, {"number": 14543, "title": "Failed to calculate FLOPs for Tensorflow Object Detection API (SSD_Mobilenet & SSD_Inception)", "body": "System information\r\n\r\n    Have I written custom code: No\r\n    OS Platform and Distribution: Linux Ubuntu 14.04\r\n    TensorFlow installed from: source\r\n    TensorFlow version: ('v1.3.0-rc1-1951-g04c318b', '1.3.0')\r\n    Python version: 2.7.12\r\n    Bazel version (if compiling from source): 0.7.0\r\n    CUDA/cuDNN version: 8.0/6.0\r\n    GPU model and memory: Tesla K40 12Gb\r\n    Exact command to reproduce: bazel-bin/tensorflow/tools/benchmark/benchmark_model --graph=ssd_inception.pb --input_layer=\"image_tensor\" --input_layer_shape=\"1,224,224,3\" --input_layer_type=\"uint8\" --output_layer=\"detection_boxes,detection_scores,detection_classes,num_detections\" --show_flops=true\r\n\r\nProblem\r\nThe ssd_inception.pb is one of the model that trained from Tensorflow object detection API. When I tried the FLOPs calculation, it failed with  Invalid argument: Tried to fetch data for '^FeatureExtractor/Assert/Assert', which produces no output.  To run to a node but not fetch any data, pass '^FeatureExtractor/Assert/Assert' as an argument to the 'target_node_names' argument of the Session::Run API.\r\n\r\nLogs\r\n2017-11-14 19:01:29.405289: E tensorflow/tools/benchmark/benchmark_model.cc:593] FLOPs calculation failed with Invalid argument: Tried to fetch data for '^FeatureExtractor/Assert/Assert', which produces no output.  To run to a node but not fetch any data, pass '^FeatureExtractor/Assert/Assert' as an argument to the 'target_node_names' argument of the Session::Run API.", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 14542, "title": "'Model' object has no attribute 'container_nodes'", "body": "## Problem\r\n```python\r\nmodel = tf.keras.models.Model()\r\nmodel.add(...)\r\ntf.keras.utils.plot_model(model, to_file=\"model.png\")\r\n```\r\nOutput:\r\n```\r\nTraceback (most recent call last):\r\n  File \"model.py\", line 36, in <module>\r\n    K.utils.plot_model(model, to_file=\"model.png\")\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/utils/vis_utils.py\", line 148, in plot_model\r\n    dot = model_to_dot(model, show_shapes, show_layer_names, rankdir)\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/_impl/keras/utils/vis_utils.py\", line 123, in model_to_dot\r\n    if node_key in model.container_nodes:\r\nAttributeError: 'Model' object has no attribute 'container_nodes'\r\n```\r\n\r\n## Environment\r\n-System: Ubuntu 16.04\r\n-Tensorflow-gpu bin v1.4.0-rc1-11-g130a514 1.4.0\r\n\r\n", "comments": ["`model_to_dot()` does not work since commit  3599fd4. A minor fix seems works."]}, {"number": 14541, "title": "Add feature get_placeholders()", "body": "Add a new API that can get all placeholders of a graph easily as #14374 requires.", "comments": ["Can one of the admins verify this patch?", "Thanks for the contribution, @qmick . I like the idea, and it could be better if we conform the python code style :-) ", "By the way, those commands can run tests. Wish it could be useful.\r\n```bash\r\nyes \"\" | ./configure\r\nbazel test -c opt //tensorflow/contrib/framework:graph_util_test\r\n```", "Looks fine to me, pending any comments @ispirmustafa @inc0 @jhseu may have later. Thanks for the changes!", "Thanks for your review :D"]}, {"number": 14540, "title": "Wrong protobuf BUILD rule while compiling tensorflow on powerpc ", "body": "### System Info\r\n- **No custom code is written**\r\n- **Ubuntu 16.04 on powerpc (ppc64le)**\r\n- **Installing from source**\r\n- **Tensorflow v1.4.0**\r\n- **python 3.5.2**\r\n- **bazel 0.7.0**\r\n- **`gcc --version` output: gcc (Ubuntu/IBM 5.4.0-6ubuntu1~16.04.5) 5.4.0 20160609**\r\n- **CUDA 8.0, cuDNN 5.1**\r\n- **NVIDIA Tesla P100**\r\n\r\n### Describe the problem\r\nI tried to build Tensorflow from sources. While `./configure`ing, I did the following;\r\n\r\n`Please specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -mcpu=native]: -mcpu=native -mtune=native`\r\n\r\nbecause I'm on a powerpc. (-march=native is not recognized, already denoted by [Default -mcpu=native])\r\n\r\nAfter executing `bazel build --config=opt --config=cuda tensorflow/tools/pip_package:build_pip_package`, it starts to download and compile protobuf, I immediately get the following, \r\n\r\n`ERROR: /home/powerpc/.cache/bazel/_bazel_powerpc/7ad07c846e34c4f733a905eaa47f3cba/external/protobuf_archive/BUILD:265:1: C++ compilation of rule '@protobuf_archive//:js_embed' failed (Exit 1).\r\ngcc: error: unrecognized command line option '-march=native'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 18.579s, Critical Path: 6.01s`\r\n\r\nI believe this stems from a wrong BUILD rule for protobuf, it defaults to [-march=native]. I wasn't able to find the relevant BUILD file to fix.\r\n\r\n### Edit\r\nAfter trying again, this time I get the same error for highwayhash. This is about third_party packages, should I have to edit all BUILD rules manually?", "comments": ["`--config=opt` seems to be the problem you are running into.\r\nCould you try the following command instead?\r\n`bazel build --copts=\"-mcpu=native\" --config=cuda tensorflow/tools/pip_package:build_pip_package`\r\n\r\nIn the meantime, I will mark this community support, because there is no official support for ppc64le for now.\r\ncc @sandipmgiri in case I am missing anything.", "Please first run `export CC_OPT_FLAGS=\"-mcpu=power8 -mtune=power8\"`  on ppc64le and retry building TensorFlow i.e. `bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package`\r\n\r\n\r\n", "Hi again, sorry for late response, I was not able to access the machine.\r\n@sandipmgiri I exported the `CC_OPT_FLAGS` and verified it is valid by  `echo $CC_OPT_FLAGS`. It doesn't seem to help. I get the same error, i.e.\r\n\r\n`ERROR:` `/home/powerpc/.cache/bazel/_bazel_powerpc/7ad07c846e34c4f733a905eaa47f3cba/external/gif_archive/BUILD.bazel:8:1: C++ compilation of rule '@gif_archive//:gif' failed (Exit 1).`\r\n`gcc: error: unrecognized command line option '-march=native'`\r\n`Target //tensorflow/tools/pip_package:build_pip_package failed to build`\r\n`Use --verbose_failures to see the command lines of failed build steps.`\r\n\r\nI get these errors for `gif_arcive`, `protobuf`, `highwayhash` for different trials.\r\nBy the way, I switched to bazel 0.5.4 before trying exporting `CC_OPT_FLAGS`, since it is recommended for tensorflow, would that affect?\r\n\r\n**EDIT:**\r\n@gunan I also tried `--copts=\"-mcpu=native\"` but got the following,\r\n\r\n`ERROR: Unrecognized option: --copts=-mcpu=native`\r\nIs `--copts` option valid only for bazel 0.7.0? In case, I can switch to 0.7.0 and try again.\r\n\r\n\r\n**EDIT2:**\r\n@gunan Yeah, little typo over there:  `--copts=\"-mcpu=native\"`. It is supposed to be `copt`. It compiled and ran successfully.\r\n\r\nSo, as a summary;\r\n- **Tensorflow 1.4.0**\r\n- **Bazel 0.7.0**\r\n- **Ubuntu 16.04**\r\n- **powerpc ppc64le**\r\n\r\nUsing --copt=\"-mcpu=native\" while compiling tensorflow did the trick.\r\n\r\n@sandipmgiri At this point I'm not sure why `export CC_OPT_FLAGS` didn't work.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "As this issue has invited community support, please remove the assignee. Otherwise, remove the `community support` label. Thank you.", "As this issue has invited community support, please remove the assignee. Otherwise, remove the `community support` label. Thank you.", "I solved this by specifying `-mcpu=power8` during the bazel configuration and later deleting the  line `build:opt --host_copt=-march=native` from the `.tf_configure.bazelrc` file.", "Closing this issue due to staleness. Please use the latest version of TensorFlow and build again.\r\nFeel free to report any issues you encounter with latest TensorFlow. Thanks!"]}, {"number": 14539, "title": "Build Custom GPU Op Failed with TF-1.3.1", "body": "### System information\r\n- **Have I written custom code**: \r\nYES\r\n- **OS Platform and Distribution**:\r\nUbuntu 14.04 LTS\r\n- **TensorFlow installed from**:\r\nsource\r\n- **TensorFlow version**:\r\n1.3.1\r\n- **Python version**: \r\n2.7.6\r\n- **Bazel version**:\r\n0.5.4\r\n- **GCC/Compiler version**:\r\n4.8.4\r\n- **CUDA/cuDNN version**:\r\n7.5/6.0\r\n- **GPU model and memory**:\r\nGeforce GTX TITAN X, 12GB\r\n- **Exact command to reproduce**:\r\n```bash\r\nTF_INC=$(python -c 'import tensorflow as tf; print tf.sysconfig.get_include()')\r\nnvcc -std=c++11 -c -o interpolate.cu.o interpolate_gpu.cu.cc \\\r\n        -I $TF_INC -D GOOGLE_CUDA=1 -x cu -Xcompiler -fPIC -D_MWAITXINTRIN_H_INCLUDED\r\n```\r\n\r\n### Describe the problem\r\nI want to compile a custom gpu op by nvcc with tf-1.3.1, however it returns the following result:\r\n```\r\n/usr/local/lib/python2.7/dist-packages/tensorflow/include/tensorflow/core/framework/op_kernel.h(317): warning: type qualifier on return type is meaningless\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow/include/tensorflow/stream_executor/kernel.h(307): warning: variable \"result\" is used before its value is set\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow/include/tensorflow/stream_executor/device_description.h(85): warning: type qualifier on return type is meaningless\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow/include/tensorflow/stream_executor/device_description.h(144): warning: type qualifier on return type is meaningless\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow/include/tensorflow/core/util/cuda_kernel_helper.h(620): error: identifier \"__shfl\" is undefined\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow/include/tensorflow/core/util/cuda_kernel_helper.h(640): error: identifier \"__shfl_up\" is undefined\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow/include/tensorflow/core/util/cuda_kernel_helper.h(660): error: identifier \"__shfl_down\" is undefined\r\n\r\n/usr/local/lib/python2.7/dist-packages/tensorflow/include/tensorflow/core/util/cuda_kernel_helper.h(680): error: identifier \"__shfl_xor\" is undefined\r\n\r\n4 errors detected in the compilation of \"/tmp/tmpxft_00001c41_00000000-7_interpolate_gpu.cu.cpp1.ii\".\r\n\r\n```\r\n", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "@HelloSeeing  I have same problem in T.F 1.4. Do you solve your problem?"]}, {"number": 14538, "title": "Removes non-existent link", "body": "", "comments": ["Can one of the admins verify this patch?"]}, {"number": 14537, "title": "fix broken link", "body": "", "comments": ["Can one of the admins verify this patch?", "The existing link is correct.", "The anchor \"#fit_dnnclassifier\" can not locate to a valid position. You can try the following two links:\r\n\r\n[https://www.tensorflow.org/get_started/estimator#fit_dnnclassifier](https://www.tensorflow.org/get_started/estimator#fit_dnnclassifier)\r\n\r\n[https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/get_started/estimator.md#fit-dnnclassifier](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/docs_src/get_started/estimator.md#fit-dnnclassifier)"]}, {"number": 14536, "title": "R1.4", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "Not sure what the intention of this pull request is. Closing."]}, {"number": 14535, "title": "Can not import transformed and quantized model using tf.import_graph_def", "body": "Hello guys,\r\nI am trying to quantized the pretrain SSD_mobilenet_v1_coco from the Tensorflow Object Detection API using the following command:\r\n`bazel build tensorflow/tools/graph_transforms:transform_graph\r\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\r\n--in_graph=MobileNetSSD.pb \\\r\n--out_graph=optimized_SSD.pb \\\r\n--inputs='image_tensor' \\\r\n--outputs='detection_boxes,detection_scores,detection_classes,num_detections' \\\r\n--transforms='\r\n  add_default_attributes\r\n  strip_unused_nodes(type=uint8, shape=\"1,300,300,3\")  \r\n  fold_constants(ignore_errors=true)\r\n  fold_batch_norms\r\n  fold_old_batch_norms\r\n  quantize_weights\r\n  quantize_nodes\r\n  strip_unused_nodes\r\n  sort_by_execution_order'`\r\n\r\nThe command run successfully and I had the optimized_SSD.pb with only 6MB. However, when I try to use this pb model in the provided IPython Notebook file [title](https://github.com/tensorflow/models/blob/master/research/object_detection/object_detection_tutorial.ipynb) I received this error:\r\n`Traceback (most recent call last):\r\n  File \"/home/phong/PycharmProjects/ConvertDarknet2VOC/evaluation.py\", line 52, in <module>\r\n    tf.import_graph_def(od_graph_def, name='')\r\n  File \"/home/phong/.virtualenvs/tensorflow_pycharm/local/lib/python2.7/site-packages/tensorflow/python/framework/importer.py\", line 283, in import_graph_def\r\n    raise ValueError('No op named %s in defined operations.' % node.op)\r\nValueError: No op named QuantizedResizeBilinear in defined operations.`\r\n\r\nIs there any way to load the quantized model using tensorflow ? \r\n\r\n\r\n", "comments": ["\r\n\r\nPlease provide details about what platform you are using  (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?  Make sure you also include the exact command if possible to produce  the output included in your test case. If you are unclear what to include  see the issue template displayed in  [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new).\r\n\r\n We ask for this in the issue submission template, because    it is really difficult to help without that information. Thanks!", "### System information\r\n- **OS Platform and Distribution (Linux Ubuntu 14.04.5 LTS)**:\r\n- **TensorFlow installed from ( binary)**:\r\n- **TensorFlow version : 1.2.1\r\n- **Python version**: 2.7\r\n- **Bazel version : 0.70\r\n- **GCC/Compiler version (if compiling from source)**: 4.8.4 \r\n- **CUDA/cuDNN version : 8.0\r\n- **GPU model and memory: Tesla P100-PCIE \r\n- **Exact command to reproduce**:\r\n\r\n\r\n### Describe the problem\r\n\r\nI quantize the ssd_mobilenet_v1 model o ubuntu 14,  using the below command\r\n```\r\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph \r\n--in_graph=/data5/zxt/coco_log/export/frozen_inference_graph.pb  \r\n--out_graph=/home/zxt/git/ssd_optimized.pb --inputs='image_tensor'\r\n --outputs='detection_boxes,detection_scores,num_detections,detection_classes' --transforms='\r\n  add_default_attributes\r\n  strip_unused_nodes(type=float, shape=\"-1,-1,-1,3\")\r\n  remove_nodes(op=Identity, op=CheckNumerics)\r\n  fold_batch_norms\r\n  fold_old_batch_norms\r\n  quantize_weights\r\n  strip_unused_nodes\r\n  sort_by_execution_order'\r\n```\r\nI also have tried some other parameters\uff0cbut all failed with same issue.\r\nthe  frozen_inference_graph.pb   is ok on Android, but the quantized pb is can NOT load.\r\nWhen run the quantized pb on android phone, met errors\r\n```\r\n      at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:799)\r\n   at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:689)\r\n    Caused by: java.io.IOException: Not a valid TensorFlow Graph serialization: NodeDef mentions attr 'T' not in Op<name=Where; signature=input:bool -> index:int64>; \r\nNodeDef: Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Where = Where[T=DT_BOOL](Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/FilterGreaterThan/Greater). \r\n(Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).\r\n           at org.tensorflow.contrib.android.TensorFlowInferenceInterface.loadGraph(TensorFlowInferenceInterface.java:535)\r\n \r\n```", "@cy89 I am sorry I didnt include required information. This is it\r\nSystem information\r\n\r\nOS Platform and Distribution (Linux Ubuntu 16.04.05 LTS):\r\nTensorFlow installed from source:\r\n**TensorFlow version : 1.4.0-rc1\r\nPython version: 2.7\r\n**Bazel version : 0.70\r\nGCC/Compiler version (if compiling from source): 5.4.0\r\n**CUDA/cuDNN version : 8.0 CUDA/ CUDNN 6\r\n**GPU model and memory: NVIDIA 1070 GTX\r\n", "Also I would like to update what I have done so far.\r\nWith my trained model, using the following command I can have the same results on both PC and android version.\r\n`\r\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\r\n--in_graph=frozen_inference_graph.pb \\\r\n--out_graph=optimized_SSD_graph.pb \\\r\n--inputs='image_tensor' \\\r\n--outputs='num_detections,detection_boxes,detection_scores,detection_classes' \\\r\n--transforms='  \r\n  sort_by_execution_order\r\n  fold_batch_norms\r\n  fold_old_batch_norms\r\n  strip_unused_nodes\r\n  round_weights(num_steps=256)'\r\n`\r\nHowever if I add 'quantize_weights' graph transformation then I almost can not detect anything (zero bounding box detected)\r\n`\r\nbazel-bin/tensorflow/tools/graph_transforms/transform_graph \\\r\n--in_graph=frozen_inference_graph.pb \\\r\n--out_graph=optimized_SSD_graph.pb \\\r\n--inputs='image_tensor' \\\r\n--outputs='num_detections,detection_boxes,detection_scores,detection_classes' \\\r\n--transforms='  \r\n  sort_by_execution_order\r\n  fold_batch_norms\r\n  fold_old_batch_norms\r\n  strip_unused_nodes\r\n  round_weights(num_steps=256)\r\n  quantize_weights'\r\n`\r\n", "/CC @petewarden do you know what the issue is?", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Same problem happens to me, and I managed to fix it\r\na. Add a dependency \"\"//tensorflow/python:image_ops\" to import_pb_to_tensorboard target\r\nb. Add an import \"from tensorflow.python.ops import gen_image_ops\" to import_pb_to_tensorboard.py\r\n\r\ndiff:\r\n\r\ndiff --git a/tensorflow/python/tools/BUILD b/tensorflow/python/tools/BUILD\r\nindex 63f16c5..23e8055 100644\r\n--- a/tensorflow/python/tools/BUILD\r\n+++ b/tensorflow/python/tools/BUILD\r\n@@ -71,6 +71,7 @@ py_binary(\r\n         \"//tensorflow/python:client\",\r\n         \"//tensorflow/python:framework\",\r\n         \"//tensorflow/python:framework_ops\",\r\n+        \"//tensorflow/python:image_ops\",\r\n         \"//tensorflow/python:platform\",\r\n         \"//tensorflow/python:summary\",\r\n     ],\r\ndiff --git a/tensorflow/python/tools/import_pb_to_tensorboard.py b/tensorflow/python/tools/import_pb_to_tensorboard.py\r\nindex 00de044..a83ff1d 100755\r\n--- a/tensorflow/python/tools/import_pb_to_tensorboard.py\r\n+++ b/tensorflow/python/tools/import_pb_to_tensorboard.py\r\n@@ -25,6 +25,7 @@ from tensorflow.core.framework import graph_pb2\r\n from tensorflow.python.client import session\r\n from tensorflow.python.framework import importer\r\n from tensorflow.python.framework import ops\r\n+from tensorflow.python.ops import gen_image_ops\r\n from tensorflow.python.platform import app\r\n from tensorflow.python.platform import gfile\r\n from tensorflow.python.summary import summary\r\n", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Assignee @skye: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @suharshs: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @suharshs: It has been 37 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @suharshs: It has been 52 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @suharshs: It has been 67 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 14534, "title": "Partially synchronize from internal", "body": "", "comments": ["@tensorflow-jenkins please test this", "@tensorflow-jenkins please test this\r\n"]}, {"number": 14533, "title": "Tensorflow Website XSRF Token missing or incorrect", "body": "The error occurs when I read current TF API documentation. My default lang is set to Russian (but it does not matter and has influence only on the bottom menu). But when I'm trying to change the language to English or Chinese I get the following error message:\r\n\r\n>XSRF Token missing or incorrect\r\n\r\nIs it ok or this is the TF Website bug?\r\n\r\nWindows 10\r\nFirefox 56.0.2 x64\r\n![1setlang](https://user-images.githubusercontent.com/7415950/32767632-4ab78b0e-c925-11e7-8cff-6843af74ef71.png)\r\n![2xsrf](https://user-images.githubusercontent.com/7415950/32767633-4ada17c8-c925-11e7-8e82-4f2bd322350a.PNG)\r\n\r\n", "comments": ["@MarkDaoust is this your territory, and can you please advise or reassign?", "This one is over my head, maybe @wolffg knows who to send it to.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "I can't repro this on my machine.  You probably shouldn't be given the option for Russian, as we have no Russian pages.  I would expect that to be a bug, possibly transient.  Is it still happening?  Do you still have the option for Russian?  If so, which page is it appearing on?", "This seems like a bug, as evidenced by `curl -H 'Accept-Language: ru' https://www.tensorflow.org`. \r\nIt's now been brought to the attention of the right people internally in b/70993883. We can hopefully have this fixed sometime soon but I'm going to close this issue out just to get it out of triage queue. Thank you for bringing this to our attention."]}, {"number": 14532, "title": "Branch 175638087", "body": "", "comments": ["@wolffg fyi", "Jenkins, test this please"]}, {"number": 14531, "title": "Add missing tf_copts calls", "body": "To eliminate warnings like:\r\nlibarithmetic_optimizer.a(arithmetic_optimizer.o) : warning LNK4049: locally defined symbol ?DEVICE_CPU@tensorflow@@3QEBDEB (char const * const tensorflow::DEVICE_CPU) imported\r\n\r\nThis PR depends on #15439. Please merge that first.", "comments": ["Can one of the admins verify this patch?", "Any problem?", "Can we separate out the XLA change and the tf_copts change? We probably only want to use tf_copts() at the top-level rules (cc_binary() rules) rather than at each cc_library().", "Hi @jhseu\r\nDo you mean:\r\n\r\n1. Separate the changes in XLA into another commit?\r\n2. Create a new macro named tf_cc_library in tensorflow.bzl, and use it everywhere?\r\n\r\nThanks.", "Though LNK4049 is a linking issue, it need to be solved at compile time, by define the proper macros. ", "I'm splitting this pr. ", "I've spit this pr into 3 PRs.\r\n#15439  #15441 #14531\r\nNow this PR depends on #15439. Merge that first.", "Recreated as #15466"]}, {"number": 14530, "title": "session_clusterspec_prop_test and common_runtime_direct_session_with_tracking_alloc_test fixed for GPU", "body": "As I discussed here - https://github.com/tensorflow/tensorflow/issues/14515 and https://github.com/tensorflow/tensorflow/issues/14576 , I made the changes in code to pass session_clusterspec_prop_test and common_runtime_direct_session_with_tracking_alloc_test tests for GPU.\r\n\r\nThanks!", "comments": ["Can one of the admins verify this patch?", "@saeta @jhseu ", "Hi @saeta , can you please have a look ?", "Sorry for the delay @sandipmgiri ; LGTM. ", "Thanks @saeta.\r\n\r\nCan anyone please merge this ?", "Jenkins, test this please.", "/CC @gunan: Sanity checks [failed](https://ci.tensorflow.org/job/tensorflow-pull-requests-sanity/12918/console) for some reason,\r\n\r\nJenkins, test this please."]}, {"number": 14529, "title": "[feature request]time out option for tf.Data.from_generator", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows 10/7\r\n- **TensorFlow installed from (source or binary)**:\r\npip installed tensorflow-gpu binary\r\n- **TensorFlow version (use command below)**:\r\n1.40\r\n- **Python version**: \r\n3.5/3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\nCUDA8/cuDNN6.0\r\n- **GPU model and memory**:\r\ngtx980m(8g)/Quadro 4000M(8g)\r\n- **Exact command to reproduce**:\r\nfrom_generator\r\n\r\n### Describe the problem\r\nUnnecessary background:\r\nI previously using a customized python function to load (one epoch of) images from disc, perform pre-processing and data augmentation and return as generator, and feed into corresponding placeholder via feed_dict. This function worked out fine for 100,000+ steps.\r\n\r\nI recently refactored my codes using tf.Data and put the exact same function into the tf.Data.from_generator function. However, the pipeline would stuck indefinitely every 200 epochs (3,000 steps) or so, just before it should break out from \"except tf.errors.OutOfRangeError:\"; also it's not throwing any exception which could be cached by \"except Exception as e\". However, by manually pressing \"enter\", the program would continue to run while dumping out a full screen of getNext() error messages from previous runs. Unfortunately I can not supply any customized pre-processing functions and data to help you debug this \"bug\", and I am not sure it's reproduce-able with a reduced example, since the occurrence seems rather arbitrary.\r\n\r\n**Feature wish:**\r\nI am hoping for a time out feature for the general tf.Data class to break out from bad loops. \r\nI suppose any customized solution would involve using standalone thread which could interfere with tf threadpool, therefore this feature must be supported in the tf scope.\r\n\r\n\r\n", "comments": ["Thanks for the suggestion! The difficulty here is that `Dataset.from_generator()` takes an arbitrary Python function as the generator, and there is no standard way to time out a Python function while it's running. It will depend on the particular library that you're using and what threads, file handles, etc. it uses. I'm going to close this issue, because I don't think it would be feasible to implement this feature reliably, and it ought to be possible to implement any specific approach in user code.\r\n\r\nThere are a few suggestions for ways to time out a function call in [this Stack Overflow question](https://stackoverflow.com/q/492519/3574081), and you should be able to apply the appropriate one in your Python code.", "thanks for the tips. I did the search on StackOverflow first, but I wasn't confident using imports like threading or multiprocessing with custom functions, since they may interfere with tf threadings, can you elaborate on this? \r\nAlso on an orthogonal topic (which I saw your reply in another issue I can't find), does Dataset.from_generator() support parallel processing? In my experience, prefetch doesn't seem to improve the performance, and I read somewhere it's not recommended to attach a FIFOQueue after the output of iterator (from iterator.make_initializer(data_set)).\r\nThanks in advance for your insights"]}, {"number": 14528, "title": "Tensorflow would sometimes get rather slow during training", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: pip\r\n- **TensorFlow version (use command below)**: 1.4\r\n- **Python version**: 3.5\r\n- **CUDA/cuDNN version**: CUDA 8.0 / cuDNN 6.0\r\n- **GPU model and memory**: GTX1060 6GB\r\n### Describe the problem\r\nWhen I train my network, at first it works properly, however sometimes it gets rather slower (about 10 times slower than normal speed, shown below). When I type nvidia-smi to check the GPU state, I find the GPU-Util is rather low (2-3%)\r\nThe normal speed is about 1 minute per 100 steps while it would sometimes cost 10 minminutes per 100 steps. \r\nI used to use Tensorflow v1.1 and did not find this problem. However I updated Tensorflow to v1.4 several days ago and this problem occurred.\r\n\r\n### Source code / logs\r\n> 2017-11-12 23:43:55  Step: 770900, loss: 1.6261, accuracy: 68.7500%\r\n2017-11-12 23:45:37  Step: 771000, loss: 1.4571, accuracy: 65.6250%\r\n2017-11-12 23:48:37  Step: 771100, loss: 1.3790, accuracy: 73.4375%\r\n2017-11-12 23:49:50  Step: 771200, loss: 1.6311, accuracy: 57.8125%\r\n2017-11-12 23:51:11  Step: 771300, loss: 1.3248, accuracy: 67.1875%\r\n2017-11-12 23:52:31  Step: 771400, loss: 1.6924, accuracy: 64.0625%\r\n2017-11-12 23:53:44  Step: 771500, loss: 1.3097, accuracy: 67.1875%\r\n2017-11-12 23:55:02  Step: 771600, loss: 1.7720, accuracy: 64.0625%\r\n2017-11-12 23:56:15  Step: 771700, loss: 1.5915, accuracy: 68.7500%\r\n2017-11-12 23:57:28  Step: 771800, loss: 1.7489, accuracy: 60.9375%\r\n2017-11-12 23:58:50  Step: 771900, loss: 1.2855, accuracy: 68.7500%\r\n2017-11-13 00:00:03  Step: 772000, loss: 1.3734, accuracy: 65.6250%\r\n2017-11-13 00:01:16  Step: 772100, loss: 1.4637, accuracy: 70.3125%\r\n2017-11-13 00:02:38  Step: 772200, loss: 1.6229, accuracy: 60.9375%\r\n2017-11-13 00:03:51  Step: 772300, loss: 1.3330, accuracy: 65.6250%\r\n2017-11-13 00:05:04  Step: 772400, loss: 1.7729, accuracy: 56.2500%\r\n2017-11-13 00:06:37  Step: 772500, loss: 1.2806, accuracy: 65.6250%\r\n2017-11-13 00:07:59  Step: 772600, loss: 1.0916, accuracy: 70.3125%\r\n2017-11-13 00:09:31  Step: 772700, loss: 1.4440, accuracy: 73.4375%\r\n2017-11-13 00:10:43  Step: 772800, loss: 0.9338, accuracy: 76.5625%\r\n2017-11-13 00:13:03  Step: 772900, loss: 1.6038, accuracy: 57.8125%\r\n2017-11-13 00:14:15  Step: 773000, loss: 1.2853, accuracy: 64.0625%\r\n2017-11-13 00:16:43  Step: 773100, loss: 1.1761, accuracy: 75.0000%\r\n2017-11-13 00:17:56  Step: 773200, loss: 1.0927, accuracy: 68.7500%\r\n2017-11-13 00:23:23  Step: 773300, loss: 1.3884, accuracy: 73.4375%\r\n2017-11-13 00:24:37  Step: 773400, loss: 1.3729, accuracy: 67.1875%\r\n2017-11-13 00:25:50  Step: 773500, loss: 1.0257, accuracy: 76.5625%\r\n2017-11-13 00:29:01  Step: 773600, loss: 1.4766, accuracy: 68.7500%\r\n2017-11-13 00:38:35  Step: 773700, loss: 1.3401, accuracy: 68.7500%\r\n2017-11-13 00:47:49  Step: 773800, loss: 1.4850, accuracy: 68.7500%\r\n2017-11-13 00:57:39  Step: 773900, loss: 1.2555, accuracy: 68.7500%\r\n2017-11-13 01:06:59  Step: 774000, loss: 1.6202, accuracy: 60.9375%\r\n2017-11-13 01:16:28  Step: 774100, loss: 1.4673, accuracy: 59.3750%\r\n2017-11-13 01:26:11  Step: 774200, loss: 1.3678, accuracy: 67.1875%\r\n2017-11-13 01:35:38  Step: 774300, loss: 1.2268, accuracy: 67.1875%\r\n2017-11-13 01:45:14  Step: 774400, loss: 1.5675, accuracy: 60.9375%\r\n2017-11-13 01:55:00  Step: 774500, loss: 1.7380, accuracy: 59.3750%\r\n2017-11-13 02:04:42  Step: 774600, loss: 1.9971, accuracy: 56.2500%\r\n2017-11-13 02:15:26  Step: 774700, loss: 1.9669, accuracy: 54.6875%\r\n2017-11-13 02:28:05  Step: 774800, loss: 1.3680, accuracy: 67.1875%\r\n2017-11-13 02:39:03  Step: 774900, loss: 1.1381, accuracy: 76.5625%", "comments": ["Its a little challenging to debug without seeing the model code you're running. Could you please share that and then might be able to help you better.", "@rohan100jain The model I run is Inception_v1 provided here [https://github.com/tensorflow/models/blob/master/research/slim/nets/inception_v1.py](url)\r\nThe code is like:\r\n\t\r\n\r\n```\r\n        with tf.name_scope('input'):\r\n\t\ttra_image_batch, tra_label_batch = input_data3.getbatch(BATCH_SIZE, 'inception_v1',\r\n\t\t\t224, True, 0)\r\n\t\tval_image_batch, val_label_batch = input_data3.getbatch(test_batchsize, 'inception_v1',\r\n\t\t\t224, False, 0)\r\n\tx = tf.placeholder(tf.float32, shape=[None, IMG_W, IMG_H, 3])\r\n\ty_ = tf.placeholder(tf.int32, shape=[None])\r\n\tis_training = tf.placeholder(tf.bool, shape=[])\r\n\twith slim.arg_scope(inception_v1.inception_v1_arg_scope()):\r\n\t\tlogits, end_points = inception_v1.inception_v1(x, 1001, is_training=is_training)\r\n\tloss = tools.loss(logits, y_)\r\n\taccuracy = tools.accuracy(logits, y_)\r\n\ttop5_accuracy = tools.top5_accuracy(logits, y_)\r\n        train_op = tools.optimize_m(loss, learning_rate1, learning_rate2, my_global_step)\r\n\ttry:\r\n                for step in np.arange(MAX_STEP):\r\n\t\t\tif coord.should_stop():\r\n\t\t\t\t\tbreak\r\n\t\t\ttra_images,tra_labels = sess.run([tra_image_batch, tra_label_batch])\r\n\t\t\t_, tra_loss, tra_acc = sess.run([train_op, loss, accuracy], feed_dict={x:tra_images, y_:tra_labels, is_training:True})\r\n\t\t\tif step % 100 == 0 or step == MAX_STEP:\r\n\t\t\t\tnowtime = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\r\n\t\t\t\tprint (nowtime+'  Step: %d, loss: %.4f, accuracy: %.4f%%' %(step+global_step, tra_loss, tra_acc))\r\n\r\n```\r\n", "@tfboyd @sguada Is that something we know about? Any way to debug?", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Nagging Assigneee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @tfboyd: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @tfboyd: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @tfboyd: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @tfboyd: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @tfboyd: It has been 15 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @tfboyd: It has been 171 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @tfboyd: It has been 186 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @tfboyd: It has been 201 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @tfboyd: It has been 216 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @tfboyd: It has been 231 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "To close this and likely not with a great end.  I wrote this script a long time ago and it watches nvidia-smi for any type of GPU slow down.  I doubt that is the issue, but it was my issue yesterday and I was reminded about this ticket.  All it does is run NVIDIA-SMI, grep for a very basic Hardware slowdown as well as keep a log of each full `nvidia-smi` result.  \r\n\r\nhttps://github.com/tfboyd/tf-tools/blob/master/benchmark/multi_gpu/stats_monitor.sh\r\n"]}, {"number": 14527, "title": "Fix control input name for quantize node", "body": "Relate to #9792, strip `:x` at the end of control input name. Fix the problem that @snownus mentioned.", "comments": ["Can one of the admins verify this patch?", "@suharshs can you take a look?", "@tensorflow-jenkins test this please"]}, {"number": 14526, "title": "Doubt in the implementation of gan's training critera", "body": "I read the code of gan implementation in tf.contrib.gan, but I'm not quite sure whether the generator_train_op and discriminator_train_op use the same batch of data. \r\n\r\nHere is the code in [https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/gan/python/train.py](url)\r\n```python\r\nclass RunTrainOpsHook(session_run_hook.SessionRunHook):\r\n  \"\"\"A hook to run train ops a fixed number of times.\"\"\"\r\n\r\n  def __init__(self, train_ops, train_steps):\r\n    \"\"\"Run train ops a certain number of times.\r\n    Args:\r\n      train_ops: A train op or iterable of train ops to run.\r\n      train_steps: The number of times to run the op(s).\r\n    \"\"\"\r\n    if not isinstance(train_ops, (list, tuple)):\r\n      train_ops = [train_ops]\r\n    self._train_ops = train_ops\r\n    self._train_steps = train_steps\r\n\r\n  def before_run(self, run_context):\r\n    for _ in range(self._train_steps):\r\n      run_context.session.run(self._train_ops)\r\n\r\ndef get_sequential_train_hooks(train_steps=namedtuples.GANTrainSteps(1, 1)):\r\n  \"\"\"Returns a hooks function for sequential GAN training.\r\n  Args:\r\n    train_steps: A `GANTrainSteps` tuple that determines how many generator\r\n      and discriminator training steps to take.\r\n  Returns:\r\n    A function that takes a GANTrainOps tuple and returns a list of hooks.\r\n  \"\"\"\r\n  def get_hooks(train_ops):\r\n    generator_hook = RunTrainOpsHook(train_ops.generator_train_op,\r\n                                     train_steps.generator_train_steps)\r\n    discriminator_hook = RunTrainOpsHook(train_ops.discriminator_train_op,\r\n                                         train_steps.discriminator_train_steps)\r\n    return [generator_hook, discriminator_hook]\r\n  return get_hooks\r\n```\r\n\r\nCan we guarantee that both hooks run the optimizer on the same batch, along with that each hook run the respective optimizer several times on the same batch? I think that's needed for gan training, and consistent with relative papers.\r\n\r\n\r\n\r\n", "comments": ["I'm not that familiar with the code, but looking at the comment \r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/gan/python/train.py#L618\r\n\r\nseems like get_joint_train_hooks solves this problem that you're mentioning.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly."]}, {"number": 14525, "title": "Add correct gradle repository.", "body": "", "comments": []}, {"number": 14524, "title": "fix broken section links in the document", "body": "", "comments": ["Can one of the admins verify this patch?"]}, {"number": 14523, "title": "[Fetaure Request] Layer normalization for NCHW/NHWC with fast gpu kernel", "body": "tf.contrib.layers.layer_norm is slow and only supports NHWC layout. It is beneficial to have a fast gpu kernel for layer normalization that supports both NCHW and NHWC. I think layer normalization is quite useful when the minibatch is extremely small or comprises only one sample (in which case batch norm/renorm doesn't work) and when local receptive fields is desired (in which case instance norm is bad).", "comments": ["Why did you close this issue immediately? I'm wondering the same, what did you discover?"]}, {"number": 14522, "title": "bazel build: can't install tensor flow", "body": "I did \"bazel build --config=opt --config=cuda //tensorflow/tools/pip_package:build_pip_package\"\r\nand this is what I got:\r\n\r\n\"ERROR: /home/simon/Downloads/tensorflow/tensorflow/contrib/rnn/BUILD:259:1: Illegal ambiguous match on configurable attribute \"copts\" in //tensorflow/contrib/rnn:gen_gru_ops_py_wrappers_cc:\r\n@local_config_cuda//cuda:using_clang\r\n@local_config_cuda//cuda:using_nvcc\r\nMultiple matches are not allowed unless one is unambiguously more specialized.\r\nERROR: Analysis of target '//tensorflow/tools/pip_package:build_pip_package' failed; build aborted:\r\n\r\n/home/simon/Downloads/tensorflow/tensorflow/contrib/rnn/BUILD:259:1: Illegal ambiguous match on configurable attribute \"copts\" in //tensorflow/contrib/rnn:gen_gru_ops_py_wrappers_cc:\r\n@local_config_cuda//cuda:using_clang\r\n@local_config_cuda//cuda:using_nvcc\r\nMultiple matches are not allowed unless one is unambiguously more specialized.\r\nINFO: Elapsed time: 0.454s\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\ncurrently loading: tensorflow/python\"\r\n\r\nWhat do I Do?", "comments": ["This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 14521, "title": "Ios", "body": "", "comments": ["Jenkins, test this please", "Jenkins, test this please.", "Jenkins test this please."]}, {"number": 14520, "title": "upgrades to boosted_trees: an example with feature importance + tuning + savedmodel", "body": "### System information\r\nN/A\r\n\r\n### Describe the problem\r\n*Feature Request*: I hate to make a trite request, but is there any plan to add more documentation or examples to the `tensorflow.contrib.boosted_trees` submodule? Now that there's a GB classifier available, I am hoping to replace my production XGBoost code with `boosted_trees` as soon as I can prove it out. Perhaps it's my newness to `tf.contrib.learn`'s `Estimator`s and `Experiment`s, but I found the examples a bit opaque and repetitive. For example, would it be possible to have an example script demonstrating these properties:\r\n* some feature importance metrics (I see the Hooks but don't know how to use them)\r\n* some type of hyperparameter tuning (max_depth, examples_per_layer, etc.)\r\n* the implementation of an ExportStrategy in the Experiment; or better yet, throw away the experiment and directly operate on a trained Estimator. I'm struggling to write a proper serving input function\r\n* a (perhaps commented out) example of using each input in the `GradientBoostedTreeClassifier` constructor\r\n\r\nSorry to ask for hand-holding here. It's just taking me longer than usual to figure these things out from the source code.\r\n\r\nAlso, to the extent that I've figured out some of these, are you welcoming PRs for more thorough examples?", "comments": ["I also notice that `boosted_trees` is using what I think is a deprecated version of the `Estimator` class. I discovered this when `<instance of GBTClassifier>.train(input_fn=my_input_fun)` throw an error. Seems like `.fit` accomplishes the same goal but this created some uncertainty about how compatible the `boosted_trees` estimators were with other `tf` features (like SavedModel).", "@ThomasColthurst ", "There are some examples [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/boosted_trees/examples/boston.py) but I agree that we should add the documentation and examples for the scenarios you mentioned (feature importance, exporting and predicting, etc). SavedModel export should work. \r\nboosted_trees estimator is implementing the older version of estimator (tf.contrib.learn.Estimator) that didn't have a train() but switching to the new Estimator is on the roadmap is well.", "Sounds great, thanks so much for addressing my questions.\r\n\r\nAs for generating a more thorough example, I'm happy to assist if you guys need help. If you DM me a snippet for feature importance I can probably figure out the rest.", "I added an example [here](7c7ccb0ba476d12814b5be2a0b87f30784977a7e).  Contributions are also welcomed :) \r\nThe serving_input_fn in the example takes in tensorflow.Example but you can see the implementation and adjust it based on the type of input you want to serve.", "Mind reposting the link to your example? I\u2019m getting a 404 not found when I click on it. Thanks!", "Here is the commit: https://github.com/tensorflow/tensorflow/commit/20e2fdc2f95f213eef5a736a140d8591ef7a5b6e", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly."]}, {"number": 14519, "title": " Portable path parsing in speech_commands/input_data.py", "body": "Convert some code using a regular expression with `'/'` characters into code that uses `os.path` methods and therefore handles `'\\'` characters in Windows paths.\r\n\r\nFixes #14004.", "comments": ["@tensorflow-jenkins test this please.", "@tensorflow-jenkins test this please."]}, {"number": 14517, "title": "[Java] Remove obsolete Input interface", "body": "Input interface is obsolete and has been replaced by Operand a long time ago. It probably came back to life as a result of a merge, I guess?", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please", "@jhseu : The Mac test failure seems unrelated, I think this should be good to merge.\r\n\r\n"]}, {"number": 14516, "title": "Fix typos", "body": "This PR fixes some typos: `mutli`, `accomodate`, `ouput`, `conjuction`, `accross`, `simplifed`, and `seperately`.", "comments": ["Can one of the admins verify this patch?"]}, {"number": 14515, "title": "//tensorflow/python:session_clusterspec_prop_test is failing with GPU support ", "body": "### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n     Ubuntu 16.04 (ppc64le)\r\n- **TensorFlow installed from (source or binary)**:\r\n     Installed from source\r\n- **TensorFlow version (use command below)**:\r\n     TF1.3.1\r\n- **Python version**:\r\n     Python 2.7.5 \r\n- **Bazel version (if compiling from source)**:\r\n     Bazel - 0.5.4\r\n- **GCC/Compiler version (if compiling from source)**:\r\n     gcc - 4.8.5\r\n- **CUDA/cuDNN version**:\r\n     cuda-8.0  and cuDNN-6.0.21\r\n- **GPU model and memory**:\r\n      0 Tesla P100-SXM2   16276MiB\r\n      1 Tesla P100-SXM2   16276MiB\r\n- **Exact command to reproduce**:\r\n`bazel test  --config=opt --config=cuda -k  //tensorflow/python:session_clusterspec_prop_test`\r\n\r\n### Describe the problem\r\nThis test passed successfully with CPU only.\r\nHowever its failing with GPU support , getting assertion error `1 != 0`. \r\n\r\nI was debugging this test failure and found following code fails for GPU -\r\nhttps://github.com/tensorflow/tensorflow/blob/v1.3.1/tensorflow/python/client/session_clusterspec_prop_test.py#L86-L92\r\n   ```\r\nself.assertEqual(1,\r\n                     len([\r\n                         node_stats\r\n                         for dev_stats in run_metadata.step_stats.dev_stats\r\n                         for node_stats in dev_stats.node_stats\r\n                         if '/job:worker/replica:0/task:1/device:CPU:0' ==\r\n                         dev_stats.device and 'Const' == node_stats.node_name\r\n                     ]))\r\n```\r\nTest expects output '1' , but len function returns '0', because of following  lines \r\n```\r\n  if '/job:worker/replica:0/task:1/device:CPU:0' ==\r\n  dev_stats.device and 'Const' == node_stats.node_name\r\n\r\n```\r\nI have printed/checked values of `dev_stats.device` using print statements, see below -\r\n1) With CPU only support - we are getting CPU:0 device for task0 and task1 :\r\n```\r\n dev_stats.device =  /job:worker/replica:0/task:0/device:CPU:0\r\n dev_stats.device = /job:worker/replica:0/task:1/device:CPU:0\r\n```\r\n2) But with GPU support - for task0 ---> device:CPU:0 and for task1 ---> device:GPU:0\r\n```\r\n dev_stats.device = /job:worker/replica:0/task:0/device:CPU:0\r\n dev_stats.device = /job:worker/replica:0/task:1/device:GPU:0\r\n```\r\nThat's why this test is failing with GPU support , as if condition is not satisfied ( `  if '/job:worker/replica:0/task:1/device:CPU:0' ! = /job:worker/replica:0/task:1/device:GPU:0 `)\r\n\r\nI tried changing if condition from  `if '/job:worker/replica:0/task:1/device:CPU:0'` to `if '/job:worker/replica:0/task:1/device:GPU:0'` and test passed successfully (with GPU).\r\n\r\nThis is my overall understanding.\r\nI want to fix this test, please provide your comments/suggestions.\r\n### Source code / logs\r\n..\r\n```\r\n$  bazel test  --config=opt --config=cuda -k  //tensorflow/python:session_clusterspec_prop_test\r\n...\r\n======================================================================\r\nFAIL: testClusterSpecPropagationWorker2Placement (__main__.SessionClusterSpecPropagationTest)\r\n----------------------------------------------------------------------\r\nTraceback (most recent call last):\r\n  File \"/home/sandip/.cache/bazel/_bazel_sandip/a43c7182abc6db034a12d4266337a49c/execroot/org_tensorflow/bazel-out/local_linux-opt/bin/tensorflow/python/session_clusterspec_prop_test.runfiles/org_tensorflow/tensorflow/python/client/session_clusterspec_prop_test.py\", line 92, in testClusterSpecPropagationWorker2Placement\r\n    dev_stats.device and 'Const' == node_stats.node_name\r\nAssertionError: 1 != 0\r\n\r\n----------------------------------------------------------------------\r\nRan 12 tests in 1.797s\r\n\r\nFAILED (failures=1)\r\n================================================================================\r\n\r\n```", "comments": ["Can you make sure ops are placed on CPU?\r\n```\r\nwith ops.Graph().as_default() as g, ops.device('/job:worker/task:1'):\r\n      with ops.device('/cpu:0'):\r\n           const = constant_op.constant(17)\r\n```\r\n", "Did ops resolve this problem?\n\nOn 13 Nov 2017 5:51 p.m., \"Yaroslav Bulatov\" <notifications@github.com>\nwrote:\n\n> Can you make sure ops are placed on CPU?\n>\n> with ops.Graph().as_default() as g, ops.device('/job:worker/task:1'):\n>       with ops.device('/cpu:0'):\n>            const = constant_op.constant(17)\n>\n> TemsprF\n>\n> \u2014\n> You are receiving this because you are subscribed to this thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/14515#issuecomment-343981743>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AFjlg5XnqqBgTNwTTr4NYzAiUptoMhwJks5s2HOBgaJpZM4QbdB3>\n> .\n>\n", "Thanks a lot @yaroslavvb. Now this test is passing with GPU as well (ops are placed on CPU).\r\n\r\nI have created a PR to upstream the changes , relevant link - https://github.com/tensorflow/tensorflow/pull/14530"]}, {"number": 14514, "title": "tensorboard not deployed", "body": "It appears Tensorboard is not installed under the following condictions:\r\n- Win 10\r\n- GPU (+Cuda 8)\r\n- Anaconda 1.6.9\r\n- NEW installation of TF GPU, as per instructions at https://www.tensorflow.org/install/install_windows\r\n\r\nThanks for checking\r\n", "comments": []}]