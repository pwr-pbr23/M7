[{"number": 1149, "title": "Fix gfile_test on Python 3", "body": "This fixes #1146\n", "comments": ["Can one of the admins verify this patch?\n", "Now I'm also seeing it. I must have missed the test failure before.\n"]}, {"number": 1148, "title": "Issue and Pull Request Templates", "body": "Would help with organization and getting all the relevant info. Requires adding files issue_template.md and pull_request_template.md\n", "comments": ["Context: https://github.com/blog/2111-issue-and-pull-request-templates\n", "Indeed, I have a pending change to add this (that we can iterate on)\n", "Okay added one here: https://github.com/tensorflow/tensorflow/blob/master/ISSUE_TEMPLATE.md \n"]}, {"number": 1147, "title": "Python 3 test failure: //tensorflow/tensorboard/backend:server_test", "body": "This seems to on both Linux and Mac, under Python 3:\n`bazel test //tensorflow/tensorboard/backend:server_test`\n\nFailure log:\n\n> ---\n> \n> .127.0.0.1 - - [17/Feb/2016 18:23:02] code 404, message Not Found\n> 127.0.0.1 - - [17/Feb/2016 18:23:02] \"GET /../../../../../../../../../../../../../../../../../../../../../../../../../../../../../../etc/passwd HTTP/1.1\" 404 -\n> .127.0.0.1 - - [17/Feb/2016 18:23:03] \"GET /data/histograms?tag=histogram&run=run1 HTTP/1.1\" 200 -\n> E127.0.0.1 - - [17/Feb/2016 18:23:03] \"GET /data/images?tag=image&run=run1 HTTP/1.1\" 200 -\n> E127.0.0.1 - - [17/Feb/2016 18:23:04] \"GET / HTTP/1.1\" 200 -\n> ./usr/local/google/home/cais/.cache/bazel/_bazel_cais/10ddfdc323bb20c9bc23987d4925ae7b/tensorflow-caisq/bazel-out/local_linux-py3-fastbuild/bin/tensorflow/tensorboard/backend/server_test.runfiles/tensorflow/python/platform/default/_resource_loader.py:49: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n>   logging.warning('IOError %s on path %s', e, path)\n> WARNING:tensorflow:IOError [Errno 2] No such file or directory: '/usr/local/google/home/cais/.cache/bazel/_bazel_cais/10ddfdc323bb20c9bc23987d4925ae7b/tensorflow-caisq/bazel-out/local_linux-py3-fastbuild/bin/tensorflow/tensorboard/backend/server_test.runfiles/tensorflow/tensorboard/asdf' on path /usr/local/google/home/cais/.cache/bazel/_bazel_cais/10ddfdc323bb20c9bc23987d4925ae7b/tensorflow-caisq/bazel-out/local_linux-py3-fastbuild/bin/tensorflow/tensorboard/backend/server_test.runfiles/tensorflow/tensorboard/asdf\n> 127.0.0.1 - - [17/Feb/2016 18:23:04] code 404, message Not Found\n> 127.0.0.1 - - [17/Feb/2016 18:23:04] \"GET /asdf HTTP/1.1\" 404 -\n> .127.0.0.1 - - [17/Feb/2016 18:23:05] \"GET /data/runs HTTP/1.1\" 200 -\n> E127.0.0.1 - - [17/Feb/2016 18:23:05] \"GET /data/scalars?sample_count=10 HTTP/1.1\" 200 -\n> E127.0.0.1 - - [17/Feb/2016 18:23:06] \"GET /data/scalars?sample_count=999999 HTTP/1.1\" 200 -\n> # E.\n> \n> ERROR: testHistograms (**main**.TensorboardServerTest)\n> ## Test the format of /data/histograms.\n> \n> Traceback (most recent call last):\n>   File \"/usr/local/google/home/cais/.cache/bazel/_bazel_cais/10ddfdc323bb20c9bc23987d4925ae7b/tensorflow-caisq/bazel-out/local_linux-py3-fastbuild/bin/tensorflow/tensorboard/backend/server_test.runfiles/tensorflow/tensorboard/backend/server_test.py\", line 105, in testHistograms\n>     self._getJson('/data/histograms?tag=histogram&run=run1'),\n>   File \"/usr/local/google/home/cais/.cache/bazel/_bazel_cais/10ddfdc323bb20c9bc23987d4925ae7b/tensorflow-caisq/bazel-out/local_linux-py3-fastbuild/bin/tensorflow/tensorboard/backend/server_test.runfiles/tensorflow/tensorboard/backend/server_test.py\", line 71, in _getJson\n>     return json.load(response)\n>   File \"/usr/lib/python3.4/json/__init__.py\", line 268, in load\n>     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n>   File \"/usr/lib/python3.4/json/**init**.py\", line 312, in loads\n>     s.**class**.**name**))\n> TypeError: the JSON object must be str, not 'bytes'\n> # \n> \n> ERROR: testImages (**main**.TensorboardServerTest)\n> ## Test listing images and retrieving an individual image.\n> \n> Traceback (most recent call last):\n>   File \"/usr/local/google/home/cais/.cache/bazel/_bazel_cais/10ddfdc323bb20c9bc23987d4925ae7b/tensorflow-caisq/bazel-out/local_linux-py3-fastbuild/bin/tensorflow/tensorboard/backend/server_test.runfiles/tensorflow/tensorboard/backend/server_test.py\", line 127, in testImages\n>     image_json = self._getJson('/data/images?tag=image&run=run1')\n>   File \"/usr/local/google/home/cais/.cache/bazel/_bazel_cais/10ddfdc323bb20c9bc23987d4925ae7b/tensorflow-caisq/bazel-out/local_linux-py3-fastbuild/bin/tensorflow/tensorboard/backend/server_test.runfiles/tensorflow/tensorboard/backend/server_test.py\", line 71, in _getJson\n>     return json.load(response)\n>   File \"/usr/lib/python3.4/json/__init__.py\", line 268, in load\n>     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n>   File \"/usr/lib/python3.4/json/**init**.py\", line 312, in loads\n>     s.**class**.**name**))\n> TypeError: the JSON object must be str, not 'bytes'\n> # \n> \n> ERROR: testRuns (**main**.TensorboardServerTest)\n> ## Test the format of the /data/runs endpoint.\n> \n> Traceback (most recent call last):\n>   File \"/usr/local/google/home/cais/.cache/bazel/_bazel_cais/10ddfdc323bb20c9bc23987d4925ae7b/tensorflow-caisq/bazel-out/local_linux-py3-fastbuild/bin/tensorflow/tensorboard/backend/server_test.runfiles/tensorflow/tensorboard/backend/server_test.py\", line 95, in testRuns\n>     self._getJson('/data/runs'),\n>   File \"/usr/local/google/home/cais/.cache/bazel/_bazel_cais/10ddfdc323bb20c9bc23987d4925ae7b/tensorflow-caisq/bazel-out/local_linux-py3-fastbuild/bin/tensorflow/tensorboard/backend/server_test.runfiles/tensorflow/tensorboard/backend/server_test.py\", line 71, in _getJson\n>     return json.load(response)\n>   File \"/usr/lib/python3.4/json/__init__.py\", line 268, in load\n>     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n>   File \"/usr/lib/python3.4/json/**init**.py\", line 312, in loads\n>     s.**class**.**name**))\n> TypeError: the JSON object must be str, not 'bytes'\n> # \n> \n> ERROR: testSampleScalars (**main**.TensorboardServerTest)\n> ## Test the sample_count parameter of /data/scalars.\n> \n> Traceback (most recent call last):\n>   File \"/usr/local/google/home/cais/.cache/bazel/_bazel_cais/10ddfdc323bb20c9bc23987d4925ae7b/tensorflow-caisq/bazel-out/local_linux-py3-fastbuild/bin/tensorflow/tensorboard/backend/server_test.runfiles/tensorflow/tensorboard/backend/server_test.py\", line 111, in testSampleScalars\n>     samples = self._getJson('/data/scalars?sample_count=%d' % i)\n>   File \"/usr/local/google/home/cais/.cache/bazel/_bazel_cais/10ddfdc323bb20c9bc23987d4925ae7b/tensorflow-caisq/bazel-out/local_linux-py3-fastbuild/bin/tensorflow/tensorboard/backend/server_test.runfiles/tensorflow/tensorboard/backend/server_test.py\", line 71, in _getJson\n>     return json.load(response)\n>   File \"/usr/lib/python3.4/json/__init__.py\", line 268, in load\n>     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n>   File \"/usr/lib/python3.4/json/**init**.py\", line 312, in loads\n>     s.**class**.**name**))\n> TypeError: the JSON object must be str, not 'bytes'\n> # \n> \n> ERROR: testSampleScalarsWithLargeSampleCount (**main**.TensorboardServerTest)\n> ## Test using a large sample_count.\n> \n> Traceback (most recent call last):\n>   File \"/usr/local/google/home/cais/.cache/bazel/_bazel_cais/10ddfdc323bb20c9bc23987d4925ae7b/tensorflow-caisq/bazel-out/local_linux-py3-fastbuild/bin/tensorflow/tensorboard/backend/server_test.runfiles/tensorflow/tensorboard/backend/server_test.py\", line 121, in testSampleScalarsWithLargeSampleCount\n>     samples = self._getJson('/data/scalars?sample_count=999999')\n>   File \"/usr/local/google/home/cais/.cache/bazel/_bazel_cais/10ddfdc323bb20c9bc23987d4925ae7b/tensorflow-caisq/bazel-out/local_linux-py3-fastbuild/bin/tensorflow/tensorboard/backend/server_test.runfiles/tensorflow/tensorboard/backend/server_test.py\", line 71, in _getJson\n>     return json.load(response)\n>   File \"/usr/lib/python3.4/json/__init__.py\", line 268, in load\n>     parse_constant=parse_constant, object_pairs_hook=object_pairs_hook, **kw)\n>   File \"/usr/lib/python3.4/json/**init**.py\", line 312, in loads\n>     s.**class**.**name**))\n> TypeError: the JSON object must be str, not 'bytes'\n> ---\n> \n> Ran 10 tests in 5.303s\n> \n> FAILED (errors=5)\n", "comments": ["@danmane \n"]}, {"number": 1146, "title": "Python 3 test failure: //tensorflow/python:default_platform_gfile_test", "body": "This happens on both Linux and Mac under Python 3:\n`bazel test //tensorflow/python:default_platform_gfile_test`\n\nFailure log:\n\n> ---\n> # ..........E........\n> ## ERROR: testOpen (**main**.FunctionTests)\n> \n> Traceback (most recent call last):\n>   File \"/usr/local/google/home/cais/.cache/bazel/_bazel_cais/10ddfdc323bb20c9bc23987d4925ae7b/tensorflow-caisq/bazel-out/local_linux-py3-fastbuild/bin/tensorflow/python/default_platform_gfile_test.runfiles/tensorflow/python/platform/default/gfile_test.py\", line 225, in testOpen\n>     f.write(\"foo\")\n>   File \"/usr/local/google/home/cais/.cache/bazel/_bazel_cais/10ddfdc323bb20c9bc23987d4925ae7b/tensorflow-caisq/bazel-out/local_linux-py3-fastbuild/bin/tensorflow/python/default_platform_gfile_test.runfiles/tensorflow/python/platform/default/_gfile.py\", line 45, in sync\n>     return fn(self, _args, *_kwargs)\n>   File \"/usr/local/google/home/cais/.cache/bazel/_bazel_cais/10ddfdc323bb20c9bc23987d4925ae7b/tensorflow-caisq/bazel-out/local_linux-py3-fastbuild/bin/tensorflow/python/default_platform_gfile_test.runfiles/tensorflow/python/platform/default/_gfile.py\", line 98, in write\n>     self._fp.write(data)\n> TypeError: 'str' does not support the buffer interface\n> ---\n> \n> Ran 19 tests in 0.043s\n> \n> FAILED (errors=1)\n", "comments": ["@vrv \n"]}, {"number": 1145, "title": "Specify --no-install-recommends in apt-get install in Dockerfiles", "body": "Explicitly list needed packaged in Dockerfile and then add `--no-install-recommends` so that unneeded packaged are not added. For example right now install OpenJDK tried to install fuse.\n- `unzip` needs to be added to the list of packages to install.\n", "comments": ["Martin's unassignment of @jendap was an accident.\n", "See: https://github.com/4Catalyzer/tensorflow/commit/83ebb0a0f1995441af66f476a19a97524748be95\n", "Fixed by commit e19437c09af0ba8eb83b282ffd4b76a2444f01d3\n"]}, {"number": 1144, "title": "Use standard types and add missing returns to fix compitable with MSVC", "body": "", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins: test this please\n"]}, {"number": 1143, "title": "interpreter crashes with SIGSEGV (tf 0.7.0-cpu, python 3.5)", "body": "I pip-installed the 0.7.0-cpu (linux) release on a python 3.5 conda environment, and now get the following error:\n\n```\nPython 3.5.1 |Continuum Analytics, Inc.| (default, Dec  7 2015, 11:16:01) \n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import tensorflow as tf\nfish: \u201cpython\u201d terminated by signal SIGSEGV (Address boundary error)\n```\n\nI also installed the 2.7 version in a separate conda environment, and everything works fine.  Both environments are up-to-date (`conda upgrade --all`).  Any ideas?\n", "comments": ["I've just seen the same issue, building and installing v0.7.0 from source (without gpu support) in a Python 3.5 conda environment works fine. Also installing tensorflow using pip in a Python 3.4 conda environment also works.\n", "Same here. Anaconda interpreter. pip installing 3.5 results in crashes when importing tensorflow. 3.4 and 2.7 works fine. All with GPU support...\n", "When you build the pip package from sources, what do your wheel package names look like?  I have a suspicion that the wheels we provided were too specific, but were named too generally.\n", "My wheel was named `tensorflow-0.7.0-py3-none-any.whl`\n", "I think I may have the same problem.  I'm using the wheel specified on the main TF website, `tensorflow-0.7.0-py3-none-linux_x86_64.whl`.  My system only reports `2663 segmentation fault (core dumped)  python` when trying to import, but doing `gdb python` and attempting to import reveals that it's a `SIGSEGV` underneath.  I've attached a backtrace in that situation if it helps.\n\nOn the surface, it looks like maybe a problem with `google::protobuf::python::message_meta`.  I updated this to the most recent version, tried uninstalling it.  No luck.  I am running ArchLinux underneath if it matters.\n[backtrace.txt](https://github.com/tensorflow/tensorflow/files/135396/backtrace.txt)\n", "If this is an ABI issue, then the following should help:\n\nhttps://www.python.org/dev/peps/pep-0513/  # recently accepted spec for glibc based binary wheels for debian, ubuntu, redhat, centos, arch linux...\n\nhttps://github.com/pypa/manylinux  # tooling based on docker + centos 5 for building wheels\n\nhttps://github.com/pypa/auditwheel  # tooling to check and fix manylinux compatible wheels\n", "It looks like the segmentation fault is being caused when protobuf is imported, specifically the following:\n\n``` Python\nfrom google.protobuf import descriptor_pb2\n```\n\nThis causes a segmentation fault when tensorflow 0.7.0 is installed but not when protobuf 3.0.0a3 is installed without installing tensorflow. \n", "> This causes a segmentation fault when tensorflow 0.7.0 is installed but not when protobuf 3.0.0a3 is installed without installing tensorflow.\n\nIndeed -- doing a `pip install protobuf==3.0.0a3` on this environment fixes the segfault, but now dies with a TypeError on import you mention:\n\n``` python\nIn [1]: import tensorflow as tf\n[snip]\n/home/bmcfee/miniconda/envs/py35/lib/python3.5/site-packages/tensorflow/core/framework/graph_pb2.py in <module>()\n      8 from google.protobuf import reflection as _reflection\n      9 from google.protobuf import symbol_database as _symbol_database\n---> 10 from google.protobuf import descriptor_pb2\n     11 # @@protoc_insertion_point(imports)\n     12 \n/home/bmcfee/miniconda/envs/py35/lib/python3.5/site-packages/google/protobuf/descriptor_pb2.py in <module>()\n   1531 FileDescriptorSet = _reflection.GeneratedProtocolMessageType('FileDescriptorSet', (_message.Message,), dict(\n   1532   DESCRIPTOR = _FILEDESCRIPTORSET,\n-> 1533   __module__ = 'google.protobuf.descriptor_pb2'\n   1534   # @@protoc_insertion_point(class_scope:google.protobuf.FileDescriptorSet)\n   1535   ))\n[snip]\nTypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases\n```\n", "The root of this issue seems to be coming from the \n`.../site-packages/google/protobuf/internal/_api_implementation.so` file.  Deleting this file allows tensorflow be imported in Python 3.5, although I cannot comment on if the resulting package is functional.  \n\nI noticed while tracking this down that although the wheel file lists protobuf 3.0.0a3 as a required dependency, it also includes a complete copy of protobuf 3.0.0b2.  I believe that either the dependency or the copy of protobuf should be removed from the wheel.\n", "@jjhelmus: I removed the copy of the protobuf from the wheel package in 76989f9839f4824aa9f5c1c1907fba3a02c1c83a, we now just rely on the whl dependency on 3.0.0b2.  I'm hoping this resolves most of the problems -- I'll try to push this out as part of our next 0.7.1 patch release.  Thanks for the help debugging!\n\nIn the meantime, my guess is you could probably get around this by pip uninstalling protobuf and then pip install protobuf==3.0.0b2, to remove the version we accidentally clobber and then reinstall the right version.\n", "@vrv The changes in 76989f9 look good and should fix the issue when new wheels are created.  Thanks for the quick fix.\n\nI do not think a pip uninstall/install of protobuf will fix this issue with the 0.7.0 Python 3 wheel.  pip uninstall only removes files that were added by the package in question so the compiled libraries which are installed by tensorflow are not removed.  pip install protobuf installs the Python API so no new shared libraries are created and the broken ones from the tensorflow wheel are still in place.  \n\nI think the best option is to change the wheel names to include the cp34 tag as the files contain libraries which will only work with CPython 3.4, although I'm guessing this ship has already sailed.\n\nShould also note that the same behavior occurs when the 0.7.0 Python 3 linux wheels are installed in Python 3.3.\n", "Agreed, we'll try to fix this for 0.7.1.\n\nI guess we have to create 3-4 different wheels for each version of python.\n", "Ok, updated wheels for 0.7.1 available.\n\nWe haven't yet built for python 3.5 on linux since it looks like only conda supports that.  @jjhelmus: since you seem to be maintaining the conda packages for tensorflow, do you want to take a stab for now at building from sources for conda?\n", "> We haven't yet built for python 3.5 on linux since it looks like only conda supports that.\n\nWhat is specific to the Python 3.5 / conda combo? I built tensorflow from the source using Python 3.5 installed from the [deadsnakes ppa](https://launchpad.net/~fkrull/+archive/ubuntu/deadsnakes) on ubuntu trusty and everything seem to work just fine.\n\nYou can also build Python 3.5 from source but arguably getting it from anaconda is probably faster.\n", "I'll check into building tensorflow 0.7.1 conda packages from source this week.  Just need to find some free time to get bazel installed.\n", "I was able to create tensorflow 0.7.1 conda packages and wheel files from source which should work with the Python shipped with Anaconda.  Files are available for both linux-64 and osx-64 for Python 2.7, 3.4 and 3.5 in my [Anaconda.org channel](https://anaconda.org/jjhelmus/tensorflow).  \n\nI believe with the release of 0.7.1 this issue can be closed.\n", "@jjhelmus I installed from your anaconda channel on py3.5 linux-64 and got the following error:\n\n```\n(tf)root@db6998cb4f9d:/# python -c \"import tensorflow\"\nTraceback (most recent call last):\n  File \"<string>\", line 1, in <module>\n  File \"/opt/conda/envs/tf/lib/python3.5/site-packages/tensorflow/__init__.py\",\nline 23, in <module>\n    from tensorflow.python import *\n  File \"/opt/conda/envs/tf/lib/python3.5/site-packages/tensorflow/python/__init_\n_.py\", line 49, in <module>\n    from tensorflow import contrib\n  File \"/opt/conda/envs/tf/lib/python3.5/site-packages/tensorflow/contrib/__init\n__.py\", line 23, in <module>\n    from tensorflow.contrib import layers\n  File \"/opt/conda/envs/tf/lib/python3.5/site-packages/tensorflow/contrib/layers\n/__init__.py\", line 68, in <module>\n    from tensorflow.contrib.layers.python.layers import *\n  File \"/opt/conda/envs/tf/lib/python3.5/site-packages/tensorflow/contrib/layers\n/python/layers/__init__.py\", line 22, in <module>\n    from tensorflow.contrib.layers.python.layers.initializers import *\n  File \"/opt/conda/envs/tf/lib/python3.5/site-packages/tensorflow/contrib/layers\n/python/layers/initializers.py\", line 24, in <module>\n    from tensorflow.python.ops import random_ops\n  File \"/opt/conda/envs/tf/lib/python3.5/site-packages/tensorflow/python/ops/ran\ndom_ops.py\", line 23, in <module>\n    from tensorflow.python.framework import ops\n  File \"/opt/conda/envs/tf/lib/python3.5/site-packages/tensorflow/python/framewo\nrk/ops.py\", line 39, in <module>\n    from tensorflow.python.framework import versions\n  File \"/opt/conda/envs/tf/lib/python3.5/site-packages/tensorflow/python/framewo\nrk/versions.py\", line 22, in <module>\n    from tensorflow.python import pywrap_tensorflow\n  File \"/opt/conda/envs/tf/lib/python3.5/site-packages/tensorflow/python/pywrap_\ntensorflow.py\", line 28, in <module>\n    _pywrap_tensorflow = swig_import_helper()\n  File \"/opt/conda/envs/tf/lib/python3.5/site-packages/tensorflow/python/pywrap_\ntensorflow.py\", line 24, in swig_import_helper\n    _mod = imp.load_module('_pywrap_tensorflow', fp, pathname, description)\n  File \"/opt/conda/envs/tf/lib/python3.5/imp.py\", line 242, in load_module\n    return load_dynamic(name, filename, file)\n  File \"/opt/conda/envs/tf/lib/python3.5/imp.py\", line 342, in load_dynamic\n    return _load(spec)\nImportError: /lib/x86_64-linux-gnu/libc.so.6: version `GLIBC_2.14' not found (re\nquired by /opt/conda/envs/tf/lib/python3.5/site-packages/tensorflow/python/_pywr\nap_tensorflow.so)\n```\n", "@yoavram What Linux are you running running this on?  Unfortunately due to the method in which tensorflow is built (Bazel) it will likely only run on Linux systems with a version of glibc equal too or newer than the one present on Ubunutu 14.04 (glibc 2.19).\n", "I'm not sure, it was a docker machine. I've managed since then to install using pip from a different docker machine. But maybe you can specify what you just said about glibc in the Anaconda page or in the conda package? Maybe try to check the version in  \nPre install script (http://conda.pydata.org/docs/building/build-scripts.html)?\n", "The whl files provided by Google and installed using pip also have the mentioned dependence on a minimum version of glibc.  Specially, the following external version symbols must be provided by system provided shared libraries:\n\n```\nGLIBC_2.14\nCXXABI_1.3.5\nGCC_3.0\nGLIBCXX_3.4.19\n```\n\nI can try to add information about this dependency to the conda packages, although I will probably wait until the next release.\n", "Sounds good. Even having this info on this thread is probably helpful, thanks!\n", "@vrv Is this still an issue?\n", "I mean I suspect it's always going to be an issue due to bazel, and all the information available is here, so we'll close this.\n"]}, {"number": 1142, "title": "0.7.0 pip packages are not named properly (error: is not a supported wheel on this platform).  [Will be fixed in next binary release]", "body": "My os is ubuntu 14.04\nMy python version is 2.7.6\n\nFollowing the instructions for installing with pip I am getting this error:\n\n> $ sudo pip install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.7.0-py2-none-linux_x86_64.whl\n> tensorflow-0.7.0-py2-none-linux_x86_64.whl is not a supported wheel on this platform.\n> Storing debug log for failure in /home/terence/.pip/pip.log\n\nIt works fine installing older releases of tensorflow with pip but not this one.\n", "comments": ["I had the same issues while trying to install tensor flow 0.70 GPU for python3 (pip3). For whatever reason, it was just the FILENAME which was wrong. It has to be in a special format to be legal. You can check yourself by following the instructions [here](http://stackoverflow.com/questions/28107123/cannot-install-numpy-from-wheel-format) which tupels of tags are legal for your machine. In my case the command\n\n_\"sudo pip3 install --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow-0.7.0-py3-none-linux_x86_64.whl\"_\n\nproduced the exact error message you got above. However, when i downloaded the file myself and renamed it to \"tensorflow-0.7.0-**cp34**-none-linux_x86_64.whl\", then executed the command again with changed filename, it worked =)\n\nEdit : OS = Ubuntu 15.10, Python = 3.4.3\n", "@terrybroad do you have 64 bit ubuntu or 32? (run `uname -a`)\n\n@HellMood thanks for a workaround. I have to try it myself. We have intentionally used this name so that people with py35 don't have to rename it. It installs fine on 14.04 with py3 but we have not tried 15.10 yet.\n", "I am seeing the same issue with Python 2.7.x on Ubuntu 14.04 LTS (64 bit)\n", "I can confirm this: I had to change `py2` to `cp27` in the filename after which it installed.\n", "Exact same issue as @terrybroad on Ubuntu 14.04 (64 bit) with Python 2.7\n", "Cheers @HellMood and @hannes-brt downloading it and changing `py2` to `cp27` worked for me.\n\n@jendap I have 64 bit ubuntu installed.\n", "I have the same issue, it did not solved by any of these solution. Here is the log.\nthe same error message for py2 \nOS: ubuntu 14.04 64 bit. python2.7\n\n```\nHTTP error 404 while getting https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.7.0-cp27-none-linux_x86_64.whl\nCleaning up...\nException:\nTraceback (most recent call last):\n  File \"/usr/lib/python2.7/dist-packages/pip/basecommand.py\", line 122, in main\n    status = self.run(options, args)\n  File \"/usr/lib/python2.7/dist-packages/pip/commands/install.py\", line 278, in run\n    requirement_set.prepare_files(finder, force_root_egg_info=self.bundle, bundle=self.bundle)\n  File \"/usr/lib/python2.7/dist-packages/pip/req.py\", line 1198, in prepare_files\n    do_download,\n  File \"/usr/lib/python2.7/dist-packages/pip/req.py\", line 1376, in unpack_url\n    self.session,\n  File \"/usr/lib/python2.7/dist-packages/pip/download.py\", line 547, in unpack_http_url\n    resp.raise_for_status()\n  File \"/usr/share/python-wheels/requests-2.2.1-py2.py3-none-any.whl/requests/models.py\", line 773, in raise_for_status\n    raise HTTPError(http_error_msg, response=self)\nHTTPError: 404 Client Error: Not Found\n\n```\n", "Same issue happening for me on Ubuntu x64 14.04 LTS and python 2.7\n", "Same issue on Ubuntu 14.04 x64 Python 2.7 using commit 3ff0f0d17b4eec946a2874da0cf896776c01a80a\n", "Same issue on both CPU and GPU with Ubuntu 14.04 64x\n_tensorflow-0.7.0-py2-none-linux_x86_64.whl is not a supported wheel on this platform.\nStoring debug log for failure in /home/artem/.pip/pip.log_\n", "Same issue on Ubuntu 14.04 x64 Python 2.7 and using GPU, downloading locally and renaming .whl file doesn't help, Tensorflow.6.0 worked fine. I did upgrade to Cuda7.5 and cudnn4  first.\n", "(We will build the proper wheels for 0.7.1)\n", "Ok, we built a few new wheels for 0.7.1 (see https://github.com/tensorflow/tensorflow/blob/r0.7/tensorflow/g3doc/get_started/os_setup.md) -- before we announce more widely we'd like to make sure it's working well for the people here who have had issues -- let us know if you still have problems with these new wheels.\n\nWe have not yet built a version for all python, just the ones in standard installations.\n", "Hello vrv,\nI had a similar issue stated above with python 2.7.6 and cpu setup. But i ran the new wheel 0.7.1 and it worked for me.\n", "@vrv I can confirm that 0.7.1 works on Ubuntu 14.04 x86_64 with Python 2.7.6. Thanks!\n", "@vrv I also can confirm that the new wheel works for my Ubuntu 14.04 x86_64\n", "@vrv  I confirm that it works. Thanks.\n", "Had the same issue.. this fixed it @vrv. Thanks!\n", "Had the same issue and it is fixed with the new build, thanks @vrv \n", "The new  7.1 wheel installs properly and runs the mnist convolutional example just fine.\nUsing Ubuntu 14.04 x64, Python 2.7 using GPU, Cuda7.5 and cudnn4.\n", "Now it works ! I suggest you to create a link to https://github.com/tensorflow/tensorflow/blob/r0.7/tensorflow/g3doc/get_started/os_setup.md\nin the installation section of the site. It could be easy for users with the same problem.\n\nThanks\n", "@vrv, the new 0.7.1 works for me on Ubuntu 14.04 x64. Both with Python 2.7 and 3.4 using GPU, Cuda7.5 and cudnn4.\n", "Problem installing on Mac OSX 10.10 with Python 3.4:\n\n```\n$ sudo pip3 install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.7.1-cp35-none-any.whl\nPassword:\ntensorflow-0.7.1-cp35-none-any.whl is not a supported wheel on this platform.\nStoring debug log for failure in /Users/Sunil/.pip/pip.log\n```\n\nAnd here is the pip.log:\n\n```\n/usr/local/bin/pip3 run on Wed Feb 24 23:29:18 2016\ntensorflow-0.7.1-cp35-none-any.whl is not a supported wheel on this platform.\nException information:\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/pip/basecommand.py\", line 122, in main\n    status = self.run(options, args)\n  File \"/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/pip/commands/install.py\", line 257, in run\n    InstallRequirement.from_line(name, None))\n  File \"/Library/Frameworks/Python.framework/Versions/3.4/lib/python3.4/site-packages/pip/req.py\", line 167, in from_line\n    raise UnsupportedWheel(\"%s is not a supported wheel on this platform.\" % wheel.filename)\npip.exceptions.UnsupportedWheel: tensorflow-0.7.1-cp35-none-any.whl is not a supported wheel on this platform.\n```\n\nWas earlier able to install from mac/tensorflow-0.6.0-py3-none-any.whl \n", "Downloading and renaming the file s.t. \"cp35\" -> \"cp34\" appears to work.\n", "@vrv The wheel 0.7.1 worked for me on Ubuntu 14.04 x86_64 with Python 2.7.6. Thanks!\n", "@vrv  The new wheel 0.7.1 fixed this problem for me also.\n\nI too am using Ubuntu 14.04 x86_64 with Python 2.7.6\n\nThanks for the fix. \n", "Are you planning to fix this for Python 3.3 and 3.5 (which you claim to support)?\n", "We do support python 3.3 and 3.5 in that TensorFlow does work with them when compiled from sources.\n\nHowever, since I suspect you mean provide pre-built pip wheels for 3.3 and 3.5 -- that is indeed what we would like to do, but we have not gotten around to yet.\n", "> However, since I suspect you mean provide pre-built pip wheels for 3.3 and 3.5 -- that is indeed what we would like to do, but we have not gotten around to yet.\n\nWould be greatly appreciated if you could do this, I need to test a project which uses TensorFlow on Travis CI and don't want to have to build TensorFlow for each Python version every time I test.\n", "I have Ubuntu 14.04 LTS 64bit and wanted to install tensorflow-0.7.1-cp34-none-linux_x86_64.whl and had the same error. This is what woked for me:\n\n```\nsudo apt-get install python3-setuptools -y && sudo easy_install3 pip -y && sudo apt-get install python 3.5-dev -y && sudo apt-get install python3.4-dev -y\nsudo pip3 install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.7.1-cp34-none-linux_x86_64.whl\n```\n\nYou have to call a tensorflow python script like so:\n\n```\n#call it with python3.4\npython3.4 tensorflow_demo.py\n```\n", "I have Ubuntu 14.04 LTS x86_64 with Python3.5 and it is giving me the same error for build 0.7.1, downloading and changing the filename is no help. What else can I try?\n", "you need python 3.4. v3.5 is not yet supported. read 1 post above what did the trick for me.\n", "I'm getting the same error for build 0.7.1 as well.\n", "Closing, I think we fixed (some) of these issues in 0.8.0\n", "I have the similar problem with Python 3.5 and it works with Python 3.4 \ud83d\ude03 \n", "@vrv I still get the same issue trying to install version 0.8.0 with python 2.7.11 on OS X 10.11.5 \n`$ pip install --upgrade https://storage.googleapis.com/tensorflow/mac/tensorflow-0.8.0-py2-none-any.whl\ntensorflow-0.8.0-py2-none-any.whl is not a supported wheel on this platform.`\n", "@tobegit3hub yes, that does not work. Python 3.5 will be part of net release. In the meanwhile you can try nightly build - http://ci.tensorflow.org/view/Nightly/job/nightly-python35-linux-cpu/\n", "@Jx-b you are not alone. Using OS X 10.11.5 and having the same issue. \n", "Thanks @jendap and all contributors \ud83c\udf89 \n", "I had the same problem with 0.8.0 with both python2 and python3 installed. Didn't work even after renaming the wheel file. My problem was that 'pip' was pointing to the python3 installation instead of python2. Either using 'pip2' or properly linking 'pip' to the default python interpreter (python2 in my case) fixed the issue.\n\nTo make sure the right pip version is used:\npip --version\npip 8.1.2 from /usr/lib/python2.7/site-packages (python 2.7)\n", "i can not install tensorflow on windows 8 64bits?\r\ni got this error\r\nis not a supported wheel on this platform", "my python version is 2.7.6, the Linux version is Ubuntu 14.04.5 LTS. When I installed tensorflow 0.7.1, i got the following error:\r\n**/usr/bin/pip run on Mon Mar 13 09:30:39 2017\r\ntensorflow-0.7.1-cp27-none-linux_x86_64.whl is not a supported wheel on this platform.\r\nException information:\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python2.7/dist-packages/pip/basecommand.py\", line 122, in main\r\n    status = self.run(options, args)\r\n  File \"/usr/lib/python2.7/dist-packages/pip/commands/install.py\", line 257, in run\r\n    InstallRequirement.from_line(name, None))\r\n  File \"/usr/lib/python2.7/dist-packages/pip/req.py\", line 168, in from_line\r\n    raise UnsupportedWheel(\"%s is not a supported wheel on this platform.\" % wheel.filename)\r\nUnsupportedWheel: tensorflow-0.7.1-cp27-none-linux_x86_64.whl is not a supported wheel on this platform.**\r\nI do not know how to result the problem."]}, {"number": 1141, "title": "support different horizontal axises for different scalar summaries", "body": "Is it possible to have different horizontal axises for different scalar summaries?\nFor example, I want to have a scalar summary of loss for each global step, and a scalar summary of network outputs for each epoch.\nCurrently, I have the same horizontal axis showing the global step for both like the following image.\nIs it possible to have the global step (0 ... 8.0k) for `loss` and the epoch (0 ... 2.0k) for `output_[0,0]`?\n\n![image](https://cloud.githubusercontent.com/assets/6128440/13111093/405a40b4-d5c7-11e5-9d03-566f19c76b2c.png)\n\nIf I set the epoch for `output_[0,0]`, I get this:\n\n![image](https://cloud.githubusercontent.com/assets/6128440/13112966/519aa52c-d5d0-11e5-8ead-552ac22898e2.png)\n", "comments": ["I'm a bit confused by your request. Can you explain what you mean by \"If I set the epoch for output_[0,0]\"? What is an epoch in this context, and how does it relate to the data that TensorBoard is recieving from TensorFlow?\n", "\"setting the epoch\" means using the epoch in place of the global step like\n\n```\nsummary_writer.add_summary(sess.run(merge_epoch, feed_dict={}), epoch)\n```\n\nFor example, change this line to `epoch`:\nhttps://github.com/ninotoshi/playground/blob/94ae350318729e4ff4ca961cd1509767e2716af5/tensor_flow/xor/main.py#L138\n\nI expect `loss` has 0.0 to 8.0k in the horizontal axis while `output_[0,0]` has 0.0 to 2.0k in the 2nd screen shot above.\n", "Sorry for the slow response. It isn't possible to have different x-scales on different charts by default (although you could zoom by hand). I'm marking this contributions welcome; if you want to work on this let me know and I can provide some guidance on how to implement it. \n", "Closing due to inactivity. That said, if you have a PR, please feel free to submit it to our new repository at https://github.com/tensorflow/tensorboard/pulls!"]}, {"number": 1140, "title": "Math ops support for float64", "body": "I am raising this issue following [this stackoverflow discussion](https://stackoverflow.com/questions/35443080/tensorflow-critical-graph-operations-assigned-to-cpu-rather-than-gpu?lq=1). I found that there is not that much support for float64 ops, that is needed for some numerical applications. A number of other issues  #1061 #761 #547 and PR #1089 have been raised around this.\n\nOn the basis of how my graph is initialised, things like **MatMul** (also raised in this other [stackoverflow question](https://stackoverflow.com/questions/35428297/tensorflow-issue-with-gpu-on-matmul-gpu-isnt-recognized?lq=1)), **Mean, L2Loss, Mean_grad/Prod, Mul_grad/Sum, AddN, SoftmaxCrossEntropyWithLogits** are not implemented for float64.\n\nWould it be a good idea to extend PR #1089 to more ops?  \n", "comments": ["Looks like #1089 was already merged, so we'll need more PRs.\n", "I want to start contributing to Tensorflow, so thought this issue would be a good start. I started with MatMul from among the ops mentioned by @smcantab. In the op implementation I found [this](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/matmul_op.cc#L210), float64 seems to be purposely commented out. Is there a reason for this?\n", "as @dave-andersen pointed out [here](https://stackoverflow.com/questions/35443080/tensorflow-critical-graph-operations-assigned-to-cpu-rather-than-gpu) some operations have not been registered for double simply to reduce the bloat in the binaries, given that, as far as I understand, it was not clear whether there'd be much interest in supporting double precision. Obviously there's been quite some interest so we should go ahead. For some operations it should be as simple as registering the kernel for double, and checking that the tests are there. Some other operations might require tailored optimization. I have been busy with some other stuff, so I have not been able to work on a PR yet, but @siddharth-agrawal if you start one I'll follow it and contribute as soon as possible.  \n", "Sounds good. I will try to get something out by the end of this week.\n", "@smcantab: Many people have requested better double support and it's critical for a lot of numerical applications, so we should do it even it increases binary size.  complex128 is rarer but the same principle applies.\n", "@girving Some of the ops mentioned by @smcantab like **Mean**, **Prod** have float64 support on the GPU as of today. Are there some important ops that need to be looked at?\n", "Here are the ops missing double support.  I believe most of these would be straightforward to add, except for max pooling as described in #547, and we'd be happy to accept PRs.  Also max pooling is doable, it would just take a bit of coordination to make the stream executor changes.\n\n```\nAdjustContrastv2\nAllCandidateSampler\nAudioSummary\nCTCBeamSearchDecoder\nCTCGreedyDecoder\nCTCLoss\nComputeAccidentalHits\nDrawBoundingBoxes\nEditDistance\nExtractGlimpse\nFixedUnigramCandidateSampler\nHSVToRGB\nImageSummary\nInTopK\nLRN\nLRNGrad\nLearnedUnigramCandidateSampler\nLogUniformCandidateSampler\nMaxPool\nMaxPoolGrad\nMaxPoolGradWithArgmax\nMaxPoolWithArgmax\nNegTrain\nRGBToHSV\nSampleDistortedBoundingBox\nSparseMatMul\nStringToNumber\nTensorArrayConcat\nTensorArrayGrad\nTensorArrayPack\nTensorArrayRead\nTensorArraySize\nTensorArraySplit\nTensorArrayUnpack\nTensorArrayWrite\nThreadUnsafeUnigramCandidateSampler\nUniformCandidateSampler\n```\n", "@girving Just out of curiosity, is there a way these can be found easily, i.e., not manually?\n", "@siddharth-agrawal Here's the script I used, but it would have to be modified a bit to work outside of Google: https://gist.github.com/girving/fbe861e6df1ce9d5add8e57bf32a247d\n", "BTW, you can also get op_def which has type-attrs for an op like this `tf.add.__globals__[\"_op_def_lib\"]._ops[\"Add\"].op_def`\nThere is one _op_def_lib per each gen.*ops.py file, so 19 \"_op_def_lib\" objects. If only we had some easy method like this to find which ops have GPU kernels....\n", "@girving The script fails to catch some of the ops, for example `TensorArrayConcat`, which is registered for float64 [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/tensor_array_ops.cc#L668) and [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/tensor_array_ops.cc#L686). Tests have also been written for it as can be seen [here](https://github.com/tensorflow/tensorflow/commit/01806e89e5dd141ae456bfee2ca0e799fb1aa32d#diff-e95198e570ac301ead1b1640fce0f656). The same holds true for the following:\n`TensorArrayPack\nTensorArrayRead\nTensorArraySplit\nTensorArrayUnpack\nTensorArrayWrite`\n", "@girving `AdjustContrastv2` is used internally, and the op doesn't need more type registrations as far as I can tell.\n", "@siddharth-agrawal Ah, right.  Deprecated ops definitely shouldn't be extended. :)\n", "@girving I think the deprecated op is `AdjustContrast`, not `AdjustContrastv2`. `AdjustContrastv2` is used internally for `adjust_contrast()`, but in a way that takes care of all the data types.\n", "I'd like to help with this, as I have a few applications that could benefit from better `float64` support.\n@siddharth-agrawal: Are you okay with splitting the work on this to speed things up? We could use this issue to announce which ops we want to work on, so we don't end up duplicating work.\n\nI've noticed that the reduction ops for `float64` are quite slow when executing on the GPU.\nI've submitted some changes to Eigen that enable the faster optimized code path:\nhttps://bitbucket.org/eigen/eigen/pull-requests/207/enable-efficient-tensor-reduction-for/diff\n", "@ibab @siddharth-agrawal  I'm also going to throw my hat in the ring for this one- I took a pass at some of the refactoring that needed to be done in #3053.\n\nI think using this thread to coordinate work is a good idea. I'll start off by saying I'm going to work on these guys:\n- CTCBeamSearchDecoder\n- CTCGreedyDecoder\n- CTCLoss\n", "@ibab Surely, how about I take all the `*Sampler` ones (unless you want `*Sampler`s for your application)? @samjabrahams is already working on `CTC*`, so that leaves quite a few ops.\n\n@samjabrahams I saw the PR you referenced above, it looks like the right change for CPU. However, the issue is to enable `float64` for the GPU, and as far as I remember the `CTC*` ops don't have any GPU implementations. So my guess is that you will have to write GPU implementations for those ops as well. Same is true for the `*Sampler` ops that I'm taking up.\n", "Cool, I'll give it a shot.\n", "@samjabrahams I should have been more clear above. The issue title suggests that we just need to enable `float64` for the ops. However, if you look at the StackOverflow links in the issue description, you will see what I meant.\n", "Definitely- no worries on your end, I should have been more diligent reading the original message.\n\nSomething I've noticed is that some Ops have fleshed out GPU implementations, while others simply register to GPU using the same implementation as CPU. Is that due to some operations being able to take better advantage of highly-parallel computation, or am I missing something?\n", "@samjabrahams I have the same question, since I haven't written any op implementation. @girving could you give us a brief explanation of the same?\n", "@samjabrahams @siddharth-agrawal I think the reason is that if there is no registered GPU kernel for an op, then that op will give you an error if you execute it inside a `with tf.device('/gpu:0'):` block, which is quite annoying.\n\nThere are a few situations where it doesn't really make sense to have a real GPU op, and there might be ops for which a proper GPU kernel hasn't been written yet and we want to substitute an existing CPU op.\nThe solution to the above problem is to register a \"fake\" GPU kernel that actually just executes the regular CPU op.\nThis is done by placing all input/output tensors into host memory using the `.HostMemory(\"x\")` kernel registration method and registering the CPU op as the implementation.\nWe have to use `.HostMemory`, because otherwise TensorFlow will automatically copy the data into GPU memory, where our CPU kernel can't reach it.\n\nA good example that I've found is the `InvertPermutation` kernel here: https://github.com/tensorflow/tensorflow/blob/d42facc3cc9611f0c9722c81551a7404a0bd3f6b/tensorflow/core/kernels/transpose_op.cc#L77\nIt's expected that it will be called on an extremely small array (with length equal to the rank of some tensor), so we don't want it to be a real GPU kernel, as we want to avoid needlessly copying our tiny array to the device (and the result back to the host).\nAt the same time, we want to be able to run inside a `tf.device('/gpu:0')` block, so we make a fake GPU kernel registration.\n", "@ibab another example is integer [Add](https://github.com/tensorflow/tensorflow/blob/d42facc3cc9611f0c9722c81551a7404a0bd3f6b/tensorflow/core/kernels/cwise_op_add.cc#L28) . At some point shape-related calculations on Tensors on GPU had a bottleneck in crossing the logical device boundary, so those ops were registered with \"fake\" GPU implementations to avoid the overhead of crossing logical devices\n", "@ibab Thanks for the explanation. However, there are cases where the implementation of the op has the device as a template parameter, without the `HostMemory` bit. Some examples are [MatMul](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/matmul_op.h), [L2Loss](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/l2loss_op.h). I guess the question was: how do we decide if we need to write an explicit GPU implementation? I guess this has something to do with the underlying Eigen interfaces.\n", "You will need to instantiate an explicit GPU implementation if you want to actually use the GPU.\n`MatMul` for example actually runs on the GPU, so it wouldn't be correct to use `.HostMemory`.\n\nIt might be a bit tricky to spot how running GPU computations is accomplished, because it is nicely abstracted by the Eigen interface.\nWhenever you see a line like\n\n``` cpp\noutput.device(d) = // ... some expression involving an `input` tensor\n```\n\nthen this will either run on the host (if `d` is a `CPUDevice`) or will run on a GPU (if `d` is a `GPUDevice`).\nYou can grab the device by calling `ctx->eigen_device<Device>()`.\n\nFor example, the `MatMulOp` calls it's functor with the current device here:\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/matmul_op.cc#L160\nThen this line gets executed:\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/matmul_op.h#L38\n", "@yaroslavvb: Thanks for clarifying this, I was actually wondering why `int32` was treated as a special case in many places.\n", "@ibab Thanks again, that clarifies some things.\n", "Pretty sure TensorArray calls all support float64\n\nUPDATE: oops, already pre-empted above.  That said, I'd like to see a use-case for CTC ops needing a float64 implementation before we start bloating the binary with multiple, slower, templated versions of these ops.\n", "The reason the script flags `TensorArray*` is because of the flow inputs/outputs.\nThese happen to be `float32` tensors.\n", "@girving I did some digging on `LogUniformSampler` to see how it works. I found that the sampling is done using `RandDouble()` which is a part of the class `SimplePhilox`. However, `RangeSampler` which is the general class that `LogUniformSampler` uses, has been written so as to make it work only for the CPU. Is there a reason for this? If not, how should I go about making the changes (some pointers would be good, things that I should keep in mind while making the changes)? Since we have to write GPU implementations, should this be tracked in a different issue (as it is not specifically for `float64`)?\n", "@siddharth-agrawal If you have to write GPU implementations, that should definitely be a separate issue.\n", "@girving Created a separate issue for GPU implementations. Could you comment on the other questions in my comment above?\n", "@siddharth-agrawal I'm leery of trying to GPUify all the range sampling ops unless you have a compelling need.  They're quite intricate, and specifically intricate in the kind of way that's hard to do efficiently on GPU (doing them inefficiently on GPU is not interesting).  It's all possible, but their has to be a need in order to accept that complexity into the codebase.\n", "@girving Alright, could you then comment on which ops should be worked on? This is so that anyone who wants to contribute does not spend time on something that is not useful. For example, @ebrevdo mentioned that float64 for CTC ops may not be useful, and as you said the Sampler ops will also not be supported. Are there any other ops that need to be discarded from [this list](https://github.com/tensorflow/tensorflow/issues/1140#issuecomment-227012645)?\n", "@siddharth-agrawal I would suggest picking a machine learning project to apply TensorFlow to!  If you pick something that you find interesting, you'll inevitably find flaws or areas for improvement in TensorFlow that will help your project.  Also inevitably, things that will help you will help others, and they'll probably end up more useful than unmotivated changes.\n\nThe other options is to look through the contributions welcome list searching for other small projects, but I think that will be less interesting: https://github.com/tensorflow/tensorflow/labels/contributions%20welcome\n", "Automatically closing due to lack of recent activity. Please file a new issue referring to this issue, if the issue is still relevant and important. If this is documenting some kind of bug, be sure to use the latest version of TensorFlow. Thank you so much."]}, {"number": 1139, "title": "Fixed bug with fall-through switch statement", "body": "", "comments": ["Can one of the admins verify this patch?\n", "Nice catch. Looks good to me. Can you merge the latest changes from master into this branch. Branch is out-of-date.\n", "Sure, it's updated now\n", "@dsmilkov: does this need to be cherry-picked into r0.7 too?\n", "No need to cherry-pick. No visual impact or perf impact by this change.\n\n@wlsc I'm curious how did you notice this bug? Did you see something visually different in the graph, or just by looking at code?\n", "@dsmilkov I was curious about architecture and spotted this bug accidentally by browsing the python code\nUpdate: typo! not a python, but typescript.\n", "Merged\n"]}, {"number": 1138, "title": "Fix spelling", "body": "", "comments": ["Can one of the admins verify this patch?\n", "Merged\n"]}, {"number": 1137, "title": "Embed __version__ into package", "body": "Hi,\nit would be nice to embed a version into the tensorflow package for reproducibility. The common Python convention is to do this via `__version__` attribute in the `__init__.py` file so that one can import the package and verify its version. \n\n```\nimport tensorflow as tf\nprint(tf.__version__)\n```\n\nThis is very helpful for reproducibility and managing different virtual environments. \n", "comments": ["This already works since 0.6 -- do you have evidence this is not the case?\n", "Thanks for the quick feedback. I just upgraded to 0.7 and wanted to check the version, which didn't work (must have been still 0.5). I tried another `pip --upgrade` which still wasn't able to install it properly; this time, I noticed the error during the upgrade. \n\n```\nCannot remove entries from nonexistent file /Users/Sebastian/miniconda3/envs/py27/lib/python2.7/site-packages/easy-install.pth\n```\n\nwhich may have prevented the correct installation. So, it must be some problem on my side (just installed in my python 3 environment were it works perfectly fine. Sorry for bothering.\n", "No problem, always good to double check that we didn't mess something up :)\n"]}, {"number": 1136, "title": "Support for 1D convolutions", "body": "There is no conv1d method and it would be very welcome.\n\nOr is conv2d implemented in such a way that (h=1, w, channels) would work with no issues and no compute penalties?\n\nIt might even be a good idea to implement an arbitrary convxd function, there are instances where high dimensional inputs have spatial relevance.\n", "comments": ["Yes, conv2d can work with h=1, though it's possible one could write a faster kernel if you knew it was 1d.  If someone was willing to write a kernel (CPU and GPU) and benchmarks for this, we'd be happy to accept it.  Same with convxd.  #150 for a similar request, but for 3D, which we'd also love contributions for.\n", "conv2d can work with h=1 indeed. However, when i want to set stride > 1 for 1d conv using conv2d with h = 1, i got an error \"ValueError: Current implementation only supports equal length strides in the row and column dimensions\". And as i set h = 1, i can't have a stride wrt h which is greater than 1. I want to know if there is a way i can do this.\n", "Fractional striding on 1d convolutions would be helpful to downsample 1d signals. Currently there is no way to do this with 2d convolutions as mentioned by @alphaf52 .\n", "@jramapuram Fractional striding is hard to implement efficiently using anything like direct convolution; normally I'd just write it using FFTs (which already works).\n", "@alphaf52 I believe conv2d now supports unequal strides in the h and w dimensions.  separable/depthwise don't yet, but for most people's purposes, that should be addressed.\n", "are there examples or docs that explain how to actually use the 1D convolution?\n", "example: http://stackoverflow.com/questions/38114534/basic-1d-convolution-in-tensorflow/38117279#comment65079952_38117279\n", "I believe this is actually done. See:\nhttps://www.tensorflow.org/versions/r0.11/api_docs/python/nn.html#conv1d\n", "@shoyer I'm pretty sure thats new, and it seems it doesn't have BN automatically included in it like the other convolution, which is a big draw back.\n", "@renesax14 sorry, \"BN\"?\n", "@shoyer  sorry, I didn't even realize I wrote the acronym. Batch Normalization. \n", "@renesax14 Maybe you are referring to the conv functions in `tf.contrib.layers`? As far as I can tell, none of the conv functions `tf.nn` have anything related to batch normalization built in.\n", "@shoyer yes I think thats right.\n", "OK, closing this as fixed. Note that the current implementation just uses `conv2d` under the covers. Contributions to add this to `tf.contrib.layers` would also be welcome, should be pretty easy.\n"]}, {"number": 1135, "title": "Saver errors in 0.7.0", "body": "In 0.7, there are different errors about Saver, first Warnings in serialization, such as moving averages, or dictionaries:\n\n```\nWARNING:tensorflow:Error encountered when serializing moving_average_variables.\nType is unsupported, or the types of the items don't match field type in CollectionDef.\nunbound method to_proto() must be called with Variable instance as first argument (got Tensor instance instead)\nWARNING:tensorflow:Error encountered when serializing summary_tags.\nType is unsupported, or the types of the items don't match field type in CollectionDef.\n'dict' object has no attribute 'name'\n```\n\nand then, it throws an OS Error:\n\n```\n  File \"/Users/aymeric/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 970, in save\n    self.export_meta_graph(meta_graph_file_name)\n  File \"/Users/aymeric/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 990, in export_meta_graph\n    as_text=as_text)\n  File \"/Users/aymeric/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/saver.py\", line 1315, in export_meta_graph\n    os.path.basename(filename), as_text=as_text)\n  File \"/Users/aymeric/anaconda2/lib/python2.7/site-packages/tensorflow/python/training/training_util.py\", line 70, in write_graph\n    gfile.MakeDirs(logdir)\n  File \"/Users/aymeric/anaconda2/lib/python2.7/site-packages/tensorflow/python/platform/default/_gfile.py\", line 295, in MakeDirs\n    os.makedirs(path, mode)\n  File \"/Users/aymeric/anaconda2/lib/python2.7/os.py\", line 157, in makedirs\n    mkdir(name, mode)\nOSError: [Errno 2] No such file or directory: ''\n```\n\nBut this is working well in 0.6.0, so Saver might have some issues in 0.7.0\n", "comments": ["Thanks for reporting this bug! You can safely ignore the warnings, which are related to the new `MetaGraphDef` support. If you want to be able to serialize your collections and avoid this warning, you can call the [`tf.register_proto_function()` function](https://github.com/tensorflow/tensorflow/blob/03bff43060229357cbe2cc1659e7d129c2799b06/tensorflow/python/framework/ops.py#L3447) for your collection.\n\nThe `OSError` is a bigger problem, and is caused by an incompatibility between our internal and external `tf.gfile.MakeDirs()` functions. As a temporary workaround, prepend \"./\" to the `save_path` argument when calling `Saver.save()`. I have a change in the pipeline that will fix this error.\n", "If someone can validate that the above commit fixes the problem with Saver, that would be appreciated! \n", "(I was able to run cifar10_train.py with no problems after the above commit).\n", "It is working fine now, thanks!\n"]}, {"number": 1134, "title": "Tensorboard graphs broken in v0.7.0 [Fixed in source, will be in next binary release]", "body": "After upgrading from `v0.6.0` to `v0.7.0` via\n\n```\npip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.7.0-py2-none-linux_x86_64.whl\n```\n\nTensorboard graph functionality is empty, while the rest of tensorboard seems fine.\n\nImage shows what I get at `http://0.0.0.0:6006/#graphs`\n\n![tensorboard-bug](https://cloud.githubusercontent.com/assets/780341/13100050/767a898e-d4fe-11e5-8f53-da72be8c9e9a.png)\n", "comments": ["I am having the same problem. The brower will give an error something like Uncaught  TypeError: Polymer.dom(...).unobserveNodes is not a function when I click the graph tab\n", "Looks like another instance of #1046.  Going to leave this one open since I suspect a lot of people are going to be running into this one.\n", "I have had the same problem ever since I first tried to use tensorboard a few days ago (with 0.6.0). The problem persists in Firefox, Konqueror, AND Chrome (!), and it is not fixed by reinstalling as a git clone after issue #650 nor by updating any of the dependencies as suggested on various other threads. I'm using CentOS 7. However, I am not seeing any error message such as reported by Charlie-Huang.\n", "Could you try updating polymer to at least 1.2? That has fixed it for at least some people.\n", "Hi guys,\n\nIf you open the console while your browser is pointed to 0.0.0.0:6006 and type `Polymer.version` do you get `1.1.5` or `1.2.4` or something else?\n\nIf you get `1.1.5` when you need to update to `1.2.4`. To do this, [download polymer 1.2.4](https://github.com/Polymer/polymer/archive/v1.2.4.zip). Unzip and copy the 3 html files (polymer*.html) into the external polymer directory under site-packages dir: /usr/lib/python2.7/site-packages/external/polymer (overwrite the previous files).\n\nLet me know how it goes. We will also be releasing a patch for 0.7.0 where we ship Polymer 1.2.4 with it.\n", "Updating polymer fixes the problem.\n", "I had polymer 1.1.5; after martinwicke's comment, I git-cloned polymer, copied the html files, and the version became \"master\", which didn't work either; then, after dsmilkov's comment, I downloaded the ZIP file and put in the 1.2.4 files, but it still didn't work. The end result is still as in has2k1's original picture with the toolbar showing but nothing in the big panel, as opposed to running an empty session, when it does say that the required files are missing. And still no error messages in the terminal from which I launch tensorboard when I try to access the graph mode, but there was one earlier (I just noticed) about favicon.ico being missing from the .../tensorboard.runfiles/... directory, but I put some random .ico file in the required location and that didn't fix it either.\n\nJust to clarify, I'm using the MNIST tutorial (mnist_with_summaries.py), which as far as I understand should produce something visible in the graph mode. The events and histograms work perfectly, but as I'm only using tensorboard for the first time, I've never seen the graph mode work, so it could be something unrelated. I've googled everything I could think of before posting here, but unfortunately, I'm at a loss.\n", "Sorry, I should mention that I'm still on 0.6.0. It's just that has2k1's description of the problem and the attached picture match my problem exactly.\n\nEDIT: Updated to 0.7.0. Still not working.\n", "Going to 1.2.4 of polymer works for me and I'm using 0.6.0\n", "Okay, we're going to cherry-pick the 1.2.4 version change into r0.7 branch and will include this fix in the next patch release.\n", "Ok, we have candidate wheels for 0.7.1 here: https://github.com/tensorflow/tensorflow/blob/r0.7/tensorflow/g3doc/get_started/os_setup.md -- let us know if there are any problems.  If all looks good we'll update our docs to officially recommend 0.7.1 late this week.\n", "My experience with\n\n``` zsh\npip install --upgrade https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.7.1-cp27-none-linux_x86_64.whl\n```\n\n`0.7.1` works if installed anew and not as an upgrade from `0.7.0`. When upgrading it is necessary to first uninstall `protobuf`. `protobuf` does not get sanely upgraded, there is a mess of things in `site-packages/google/protobuf`.\n\nAlso, a separate unreported issue that is solved, for Python `3.4` I had `0.7.0` fail with a segmentation fault, not any more for `0.7.1`.\n", "Just wanted to note that uninstalling `protobuf` and reinstalling TF 0.7.1 worked well for me on Mac OS X - the Polymer version issue is gone and graphs are visible. Thanks!\n", "Hi, the proposed upgrade for Polymer worked just fine for me. I am using anaconda\n"]}, {"number": 1133, "title": "don't need a '+' before lambda", "body": "I think the + before the lambda is a typo. It can't compile by MSVC. On Linux, after removing it, gcc compile the code without problem and all tests pass as well.\n", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins: test this please\n", "(It's actually not a typo according to the spec, but it is probably unnecessary.)\n", "Merged\n"]}, {"number": 1132, "title": "Error: Not Found TensorFlow How-Tos", "body": "**TensorFlow Mechanics 101** brings up an error when trying to view tutorial.\n\n![404](https://cloud.githubusercontent.com/assets/7181734/13099384/55fd2918-d4e6-11e5-8cdb-6c7fc698f63b.png)\n", "comments": ["Should be fixed. Sorry.\n", "No problem. :+1: \n"]}, {"number": 1131, "title": "Merge r0.7 back to master", "body": "", "comments": []}, {"number": 1130, "title": "Update RELEASE.md according to the latest one in r0.7 branch.", "body": "", "comments": ["Can one of the admins verify this patch?\n", "This is already being merged from 0.7 branch\n", "Opps! Thank you for closing. \n"]}, {"number": 1129, "title": "Merge r0.7 back to master", "body": "Merge the fixes for r0.7 back into master\n", "comments": ["Never mind, have to do this manually.\n"]}, {"number": 1128, "title": "Fix typo", "body": "", "comments": ["Can one of the admins verify this patch?\n", "@vrv Okay, I changed it to what you said.\n", "Merged, thanks!\n"]}, {"number": 1127, "title": "Add tfserve tutorial", "body": "", "comments": ["LGTM\n"]}, {"number": 1126, "title": "bug in \"MNIST For ML Beginners\"?", "body": "Under the heading The MNIST Data (https://www.tensorflow.org/versions/v0.6.0/tutorials/mnist/beginners/index.html) it appears that \n\nimport tensorflow.examples.tutorials.mnist.input_data\nmnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n\nshould say\n\nimport tensorflow.examples.tutorials.mnist.input_data as input_data\nmnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n\nthx,\n\n--dmm\n", "comments": ["Thanks -- we've fixed this in the source already, we'll push out a new version of the website hopefully today.\n", "thx\n"]}, {"number": 1125, "title": "Example image code using image module.", "body": "I couldn't find `decode_png`, `convert_image_dtype` or `rgb_to_hsv` added to the `tf` module.\n\nUpdated examples to use the functions on the `tf.image` module instead. Unfortunately, the example code was used on the how to document page as well.\n\nA minor spelling adjustment is included as well.\n", "comments": ["Can one of the admins verify this patch?\n", "@tensorflow-jenkins: test this please\n", "Merged.\n"]}, {"number": 1124, "title": "Add Tan, Asin, Acos, Atan trigonometric functions", "body": "See  Issue #1108 .\n", "comments": ["Can one of the admins verify this patch?\n", "Cool! Jenkins, test this please.\n", "This PR and others like #1099  are failing on:\n\n```\n//tensorflow/user_ops:ackermann_test: Test execution time (0.0s excluding execution overhead) outside of range for MODERATE tests. Consider setting timeout=\"short\" or size=\"small\".\n```\n", "I don't think that's correct.  The failure here is legitimate:\n\n//tensorflow/python:cwise_ops_test                                       FAILED in 2 out of 2 in 243.8s\n  Stats over 2 runs: max = 243.8s, min = 133.8s, avg = 188.8s, dev = 55.0s\n  /var/lib/jenkins/workspace/tensorflow-pull-requests-cpu/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/68a62076e91007a7908bc42a32e4cff9/tensorflow/bazel-out/local_linux-fastbuild/testlogs/tensorflow/python/cwise_ops_test/test_shard_2_of_2.log\n  /var/lib/jenkins/workspace/tensorflow-pull-requests-cpu/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/68a62076e91007a7908bc42a32e4cff9/tensorflow/bazel-out/local_linux-fastbuild/testlogs/tensorflow/python/cwise_ops_test/test_shard_1_of_2.log\n\nExecuted 275 out of 317 tests: 316 tests pass and 1 fails locally.\n", "Oh I see, I missed the extra line. How do you see the contents of the log file ? \n\n`/var/lib/jenkins/workspace/tensorflow-pull-requests-cpu/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/68a62076e91007a7908bc42a32e4cff9/tensorflow/bazel-out/local_linux-fastbuild/testlogs/tensorflow/python/cwise_ops_test/test_shard_2_of_2.log`\n", "I click on the 'details' link and go to \"Console output\" in Jenkins :)\n", "That shows just the line `/var/lib/jenkins/workspace/tensorflow-pull-requests-cpu/bazel-ci_build-cache/.cache/bazel/_bazel_jenkins/68a62076e91007a7908bc42a32e4cff9/tensorflow/bazel-out/local_linux-fastbuild/testlogs/tensorflow/python/cwise_ops_test/test_shard_1_of_2.log`. I meant what is inside that file with the actual info of the error / failed test ? \n", "If you go to the full log, the test failure output is embedded somewhere in the log file\n", "@martinwicke rebased and fixed the tests cases. \n", "@tensorflow-jenkins : test this please\n", "@Mistobaan I think we are missing the GPU files like https://github.com/tensorflow/tensorflow/blob/f2bd0fc399606d14b55f3f7d732d013f32b33dd5/tensorflow/core/kernels/cwise_op_gpu_cos.cu.cc for these new ops.\n", "@vrv finally got a machine with a GPU, I added the missing files and tested using `ci_build.sh GPU pip.sh GPU` on my local dev box. \n", "Sorry, conflicts again.  Can you rebase/squash one more time?  Sorry about this :( -- we just have such a huge backlog of issues and PRs. \n\nPlease respond to the thread when you've done this, since GitHub doesn't notify me when you've done this.  Thanks!\n", "Can one of the admins verify this patch?\n", "oops miss click I did not meant to close the PR. I updated the code in my branch.\n", "Can you reopen?  GitHub for some reason doesn't let me re-open this. asofjdsfsdfaldsfds \n"]}, {"number": 1123, "title": "Error encountered when serializing moving_average_variables", "body": "I compiled Tensorflow from source. Running cifar10_train.py outputs the following warning message:\n\nWARNING:tensorflow:Error encountered when serializing moving_average_variables.\nType is unsupported, or the types of the items don't match field type in CollectionDef.\nunbound method to_proto() must be called with Variable instance as first argument (got Tensor instance instead)\n", "comments": ["Also @shlens in case he knows.\n", "Having the same issue. And the training command hangs. In fact, even the mnist example on setup page hangs too.\n", "Thanks for pointing out this warning! It's benign (for the training process), but unfortunate to have this in an example model. I have a patch in the pipeline that will fix the root cause for the warning.\n", "Issue Cleanup\n"]}, {"number": 1122, "title": "Easy to use batch norm layer.", "body": "Many non-experts are using the following code http://stackoverflow.com/questions/33949786/how-could-i-use-batch-normalization-in-tensorflow?answertab=votes#tab-top.\n\nIt would be nice to have an official batch norm layer given its importance in training DNNs.\n", "comments": ["I'm working on some parts of that.\n", "There is now a `batch_norm` layer:\nhttps://github.com/tensorflow/tensorflow/blob/b826b79718e3e93148c3545e7aa3f90891744cc0/tensorflow/contrib/layers/python/layers/layers.py#L100\n", "I think some thing wrong with this layer. in training every thing is OK and loss decrease very good. but in testing I get zero accuracy.\nBy the way in testing when I use is_training=False, I get zero acc.\nI know batch normalization behave different in train and test phase, as describe in [How does batch normalization behave differently at training time and test time? - Quora](https://www.quora.com/How-does-batch-normalization-behave-differently-at-training-time-and-test-time). I think this implementation is unclear\n", "Same here, I have experienced some unexpected behavior with is_training=False. What is the correct way to change this flag? I am currently using a `tf.cond` because it does not take `tf.placeholders` by itself.\n", "@pawni You have to use a Python boolean for `is_training`. It cannot be a `tf.cond`.\n", "@ppwwyyxx well I am doing `tf.cond(placeholder, batch_norm(.., is_training = True), batch_norm(.., is_training = False))` or is one just supposed to do a `batch_norm(.., is_training=variable)` and change that outside of the graph when needed?\n", "Oh I thought you were doing `batch_norm(.., is_training=tf.cond(placeholder))`, which is incorrect.\nYour current way might have problems as well. You'll need to double check that the two `batch_norm` op you created share the same scope, otherwise they won't share the underlying mean/variance statistics.\n\nTo do this the `reuse` argument might help, but I'm not sure because I use my own version of bn layer.\n", "I am using the same scope and `reuse=True`. It seems to work sometimes but I am not too sure. It would be great if the layer could be added to the documentation with a short explanation how to best handle the change from training to test.\n", "@sguada FYI\n", "Currently batch_norm requires a python boolean, but we are working in adding the option of passing a Tensor.\n", "@pawni If you don't want to worry about about updating moving_mean and moving_variance set updates_collections=None to make sure they are updated in place, otherwise you need to make sure the update_ops added to tf.GraphKeys.UPDATE_OPS are run during training.\n", "I think tensorflow need 2 hyper methods that change the model state, something like torch. [change model state](https://github.com/torch/nn/blob/master/doc/module.md#training). I think it is very straightforward. \n", "is there a small script with a very simple NN that shows what is the proper way of using this \"official\" BN layer? I'd really appreciate it.\n", "sorry if this is a little repetitive, but it seems the API talks about BN in a different interface: https://www.tensorflow.org/versions/r0.9/api_docs/python/nn.html#batch_normalization\n\nis that not the official way to use BN? I am confused on how to use it and the SO seems to be outdated and then there is a layer in a different link from the API, just how exactly does one do this? I am unclear if to go to SO or ask here.\n", "sorry for the spamming, but what is wrong with just using something like this:\n\n```\ndef standard_batch_norm(l, x, n_out, phase_train, scope='BN'):\n    \"\"\"\n    Batch normalization on feedforward maps.\n    Args:\n        x:           Vector\n        n_out:       integer, depth of input maps\n        phase_train: boolean tf.Varialbe, true indicates training phase\n        scope:       string, variable scope\n    Return:\n        normed:      batch-normalized maps\n    \"\"\"\n    with tf.variable_scope(scope+l):\n        #beta = tf.Variable(tf.constant(0.0, shape=[n_out], dtype=tf.float64 ), name='beta', trainable=True, dtype=tf.float64 )\n        #gamma = tf.Variable(tf.constant(1.0, shape=[n_out],dtype=tf.float64 ), name='gamma', trainable=True, dtype=tf.float64 )\n        init_beta = tf.constant(0.0, shape=[n_out], dtype=tf.float64)\n        init_gamma = tf.constant(1.0, shape=[n_out],dtype=tf.float64)\n        beta = tf.get_variable(name='beta'+l, dtype=tf.float64, initializer=init_beta, regularizer=None, trainable=True)\n        gamma = tf.get_variable(name='gamma'+l, dtype=tf.float64, initializer=init_gamma, regularizer=None, trainable=True)\n        batch_mean, batch_var = tf.nn.moments(x, [0], name='moments')\n        ema = tf.train.ExponentialMovingAverage(decay=0.5)\n\n        def mean_var_with_update():\n            ema_apply_op = ema.apply([batch_mean, batch_var])\n            with tf.control_dependencies([ema_apply_op]):\n                return tf.identity(batch_mean), tf.identity(batch_var)\n\n        mean, var = tf.cond(phase_train, mean_var_with_update, lambda: (ema.average(batch_mean), ema.average(batch_var)))\n        normed = tf.nn.batch_normalization(x, mean, var, beta, gamma, 1e-3)\n    return normed\n```\n\nthen its simple to tell tensorflow which one to use with a feed dictionary as in:\n\n```\nfeed_dict = {x: Xminibatch, y_: Yminibatch, phase_train: True}\nsess.run(fetches=[merged,train_step], feed_dict=feed_dict)\n```\n\nsince its unclear if the implementation will change, I wanted to give a suggestion (note its easy to extend to convolutions and stuff I just didn't paste that code).\n", "@pawni @ppwwyyxx did you guys decide if you had to use reuse to true to solve the scoping issue?\n", "@brando90 currently I am doing something like:\n\n```\ndef BatchNorm(inputT, is_training=True, scope=None):\n    return tf.cond(isTraining,\n                lambda: batch_norm(inputT, is_training=True,\n                                   center=False, updates_collections=None, scope=scope),\n                lambda: batch_norm(inputT, is_training=False,\n                                   updates_collections=None, center=False, scope=scope, reuse = True))\n```\n\nHowever, I think that #3265 would basically want to implement it like this. A reference could be the dropout implementation here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L433-L435\n", "When the updates_collections=None then the updates happens in-place and it is easier to use a tf.cond() to allow is_training being a Tensor a bit more complicated is when the updates are delayed and the the update_ops are run later.\nI will try to get the first part in soon.\n", "@brando90 @pawni he's code works good, but have to change like below\n\n``` python\ndef BatchNorm(inputT, is_training=True, scope=None):\n    # Note: is_training is tf.placeholder(tf.bool) type\n    return tf.cond(is_training,  \n                lambda: batch_norm(inputT, is_training=True,  \n                                   center=False, updates_collections=None, scope=scope),  \n                lambda: batch_norm(inputT, is_training=False,  \n                                   updates_collections=None, center=False, scope=scope, reuse = True))  \n```\n\nAnd when run in training or test time,\n\n``` python\n# when training \nsess.run([opt, loss], feed_dict={x: bx, y: by, is_training=True})  \n\n# when test \nsess.run([opt, loss], feed_dict={x: bx, y: by, is_training=False})  \n```\n\nThis code works, but like [#3265](https://github.com/tensorflow/tensorflow/issues/3265) says it will be great if `tf.contrib.layers.batch_norm` get `is_training` variable as a `tf.plcaeholer`.\n", "@nmhkahn @pawni thanks for the code snippets. They were very useful in adding batch normalization to my convolution network.  Training seems to work very well. Testing is not.  In some versions of the code training accuracies are much higher than testing accuracies, which probably mean I am not sharing batch normalization parameters.  In other versions of the code I get \"ValueError: Variable conv1/beta already exists, disallowed. Did you mean to set reuse=True in VarScope?\" which seem to indicate that I am trying to relearn the parameter... when I was trying to reuse.\n\nCan someone provide an example of how to call the \"def BatchNorm\" function during training and testing so that variable sharing happen correctly.\n\nThanks for any help.\n\nUPDATE July 25, 2016:\n\n@nmhkahn @pawni thanks for your comments.  After taking a closer look at the code in contrib I realized what my problem was.  During training and testing we are either updating or reusing four variables (beta, gamma, moving_mean and moving_variance). To make those unique I had to set a scope per layer.  I did it like this:\n\nconv1 = tf.nn.relu(batch_norm_layer(conv2d_stride2_valid(data, W_conv1) + b_conv1, train_phase, scope=\"conv1\"))\n\nwhere batch_norm_layer is similar to the examples from @nmhkahn @pawni, conv2d_stride2_valid is just a def to define a convolutional layer, and W_conv1 and b_conv1 are variables holding the weights and biases. I could probably remove the bias term because we are using batch normalization.\n\nThe net is working well now.  I noticed after plotting accuracies in training and test mode that the testing accuracies start climbing after the training accuracies.  In retrospect it make sense since we are collecting dataset statistics for testing.  But it appeared as if I was doing something wrong during my initial tests. Thanks for your comments and making batch normalization available to the community.\n", "@nmhkahn how is it different from pawni's suggestion?\n", "@brando90 I had a small error in my version which was fixed by nmhkahn (changing `isTraining` to `is_training`)\n\n@diegoAtAlpine I found the same problems - not sure why this is the case though. However, the ValueError should be resolved by the code snippet. Not sure what you want to see how to call it as nmhkahn's examples seems to do the job?\n", "@nmhkahn @pawni @ when you do:\n\n`sess.run([opt, loss], feed_dict={x: bx, y: by, is_training=True})`\n\ndoesn't that mean that your using `is_training` as a placeholder? People have commented that they want `is_training` to be a placer holder but thats what I had for my version of it:\n\n```\ndef batch_norm_layer(x,train_phase,scope_bn):\n\n    bn_train = batch_norm(x, decay=0.999, center=True, scale=True,\n    is_training=True,\n    reuse=None, # is this right?\n    trainable=True,\n    scope=scope_bn)\n    bn_inference = batch_norm(x, decay=0.999, center=True, scale=True,\n    is_training=False,\n    reuse=True, # is this right?\n    trainable=True,\n    scope=scope_bn)\n    z = tf.cond(train_phase, lambda: bn_train, lambda: bn_inference)\n    return z\n```\n\nis that not correct?\n", "I have already extended tf.contrib.layers.batch_norm to allow passing a Tensor or a Placeholder for is_training. It will be merged in TF contrib soon.\n\nNow available in\nhttps://github.com/tensorflow/tensorflow/commit/9da5fc8e6425cabd61fc36f0dcc1823a093d5c1d#diff-94bbcef0ec8a5cdef55f705e99c2b2ed\n", "is it just me or does adding this BN layer noticeably slows down training of a single epoch?\n", "@brando90 It slows down training for me as well but I think that this is expected as it needs to calculate some statistics. And your version looks good to me.\n", "BatchNorm is currently very slow (because of all the statistics computed), but they are working on adding a cudnn batchnorm op as said [here](https://github.com/tensorflow/tensorflow/pull/1759#issuecomment-228856467).\n", "@nmhkahn  quick question. When you wrote (for testing):\n\n`sess.run([opt, loss], feed_dict={x: bx, y: by, is_training=False})`\n\nin theory, can bx and by be any data set? i.e. it can still be the **training** set even though we are not training? (i.e. just to track the train error) \n", "@brando90 you're right.\n", "I am also confused regarding is_training and reuse flags. I have created a program following the CIFAR example, where my code is structured as in CIFAR:\n- Inference\n- Loss\n- Train\n\nAnd I am running it in a multi-gpu fashion (for training).\nSo I have one script for training (similar to cifar10_multigpu.py) and one for testing (similar to cifar10_eval.py). \nSo \n\n```\nfor ii in xrange(2):  # Num of GPU\n  with tf.device('/gpu:%d' % ii):\n    with tf.name_scope('device_%d' % ii) as scope:\n\n      data_batch, label_batch = factory.GetShuffleBatch(batch_size)\n\n      unnormalized_logits = factory.MyModel(dataBatch=data_batch, numClasses=numClasses,\n                                                 isTraining=True)\n\n      More stuff happening\n      tf.get_variable_scope().reuse_variables()\n```\n\nThe inference happens with the function MyModel. (below is an example of the function, in reality i use more layers and neurons). \n\n```\ndef MyModel(data_batch, num_classes, feature_dim):\n\n  # Hidden Layer 1\n  with tf.variable_scope('hidden1') as scope:\n    weights = variable_on_cpu('weights',[feature_dim, 256], tf.truncated_normal_initializer(stddev=0.04))\n    biases = variable_on_cpu('biases', [256], tf.constant_initializer(0.001))\n    hidden1 = tf.nn.relu(tf.matmul(data_batch, weights) + biases, name=scope.name)\n\n  # Hidden Layer 2\n  with tf.variable_scope('hidden2') as scope:\n    weights = variable_on_cpu('weights',[256, 256], tf.truncated_normal_initializer(stddev=0.04))\n    biases = variable_on_cpu('biases', [256], tf.constant_initializer(0.001))\n    hidden2 = tf.nn.relu(tf.matmul(hidden1, weights) + biases, name=scope.name)\n\n  # output, unnormalized softmax\n  with tf.variable_scope('softmax_unnorm') as scope:\n\n    weights = variable_on_cpu('weights', [256, num_classes], tf.truncated_normal_initializer(stddev=1/num_classes))\n    biases = variable_on_cpu('biases', [num_classes], tf.constant_initializer(0.0))\n    softmax_un = tf.add(tf.matmul(hidden2, weights), biases, name=scope.name)\n\n  return softmax_un\n```\n\nI want to perform batch nomalization. So when I did:\n\n```\ndef MyModel(data_batch, num_classes, feature_dim, isTraining):\n\n  with tf.variable_scope('bnormalization') as scope:\n    norm_data_batch = tcl.batch_norm(inputs=dataBatch, epsilon=0.0001, is_training=isTraining, \n                                      reuse=True, scope=scope)\n\n  # Hidden Layer 1\n  with tf.variable_scope('hidden1') as scope:\n    weights = variable_on_cpu('weights',[feature_dim, 256], tf.truncated_normal_initializer(stddev=0.04))\n    biases = variable_on_cpu('biases', [256], tf.constant_initializer(0.001))\n    hidden1 = tf.nn.relu(tf.matmul(data_batch, weights) + biases, name=scope.name)\n```\n\nI got the following error in the training phase:\nVariable bnormalization/beta does not exist, disallowed. Did you mean to set reuse=None in VarScope?\n\nFrom what I 've been reading in this thread in the training phase I should be using reuse=None. Have I got this part correct? If this is true, then since I am using two GPUS, should I do reuse=None in the first GPU and reuse=True in the second? Or since I am doing tf.get_variable_scope().reuse_variables() it takes care of itself?\n\nFinally, in the testing phase, should I have is_training=False and reuse=True?\n\nAny help is greatly appreciated. \n", "Now tf.contrib.layers.batch_norm accepts a Tensor, Variable or Placeholder as is_training \n\nhttps://github.com/tensorflow/tensorflow/commit/9da5fc8e6425cabd61fc36f0dcc1823a093d5c1d#diff-94bbcef0ec8a5cdef55f705e99c2b2ed\n", "Is it normal that Batch Normalization makes my experiments **worse**? I tried it on a 2 layered NN network based on the MNIST beginner tutorial and I consistently get worse results when BN is present: with BN (one with scale and center trained and the other not) accuracy is 0.8423, 0.8221 and without BN accuracy is 0.9477.\n\nMy script is present here https://github.com/brando90/tensor_flow_experiments/blob/master/tf_tutorials/beginner_tutorial_MNIST_BN.py\n\nanyone has experienced these problems or is BN just like this and I need to do something else to make it work?\n", "The latest version of [tf.contrib.layers.batch_norm](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L110) now accepts a placeholder for is_training so not need to do it yourself.\n\nBut what it is important is that either you pass [updates_collections=None](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L142) so the moving_mean and moving_variance are updated in-place, otherwise you will need gather the update_ops and make sure they are run.\n\nI would like to encourage you to use [`tf.contrib.layers`](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/layers) or [`tf.contrib.slim`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/slim) to build your model.\n\n```\nslim = tf.contrib.slim\n\ndef build_NN_two_hidden_layers(x, is_training):\n batch_norm_params = {'is_training': is_training, 'decay': 0.9, 'updates_collections': None}\n with slim.arg_scope([slim.fully_connected], \n    activation_fn=tf.nn.relu,\n    weigths_initializer=tf.contrib.layers.xavier_initializer(),\n    biases_initializer=tf.constant_initializer(0.1),\n    normalizer_fn=slim.batch_norm,\n    normalizer_params=batch_norm_params):\n   net = slim.fully_connected(x, 50, scope='A1')\n   net = slim.fully_connected(net, 49, scope='A2')\n   y = slim.fully_connected(net, 10, activation_fn=tf.nn.softmax, normalizer_fn=None, scope='A3')\n return y\n\n\n```\n", "@sguada I changed my old one where I manually tell it to train or not (based on a tf.cond) and now it seems the accuracy is up to ~95's again. Why was it that I needed to change updates_collections to be None? Do you mind explaining me why that gave such a big accuracy difference? Its seems like a non-trivial change (should it None be its default value then if it matters so much?). Thanks! :)\n\nAlso, I noticed you said it was a placeholder and I didn't need to do it manually. However, when I passed a placeholder for is_training it said \n\n`TypeError: Using a`tf.Tensor`as a Python`bool`is not allowed. Use`if t is not None:`instead of`if t:`to test if a tensor is defined, and use the logical TensorFlow ops to test the value of a tensor.`\n\nand pointed to batch_norm code. Maybe It could be nice to show how this placeholder thing should be used because it seems I don't understand how its suppose to be used. Thanks! :)\n", "@brando90 \nThe relevant part of the code is here [L227-256](https://github.com/tensorflow/tensorflow/blob/98d63de3bb2bab7c9a81f83c8ca864741399300c/tensorflow/contrib/layers/python/layers/layers.py#L227-L256).\n\nAs you will notice is there is a `with ops.control_dependencies` statement that forces the updates. I believe that for the code to be used \"right out of the box\" the default should be None. \n\nAs for my comment above [1122](https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-235433645), I figured out that   tf.get_variable_scope().reuse_variables() takes care of the issue, so  in the training phase the argument reuse of batch_norm should be None. It has to do with the statement variable_op_scope (read its documentation in tensorflow) \n", "Use of batch_norm with tf.placeholder\n\n```\nx = tf.placeholder(tf.float32, [None, 784])\nis_training = tf.placeholder(tf.bool, [], name='is_training')\ny = build_NN_two_hidden_layers(x, is_training)\n\n# For training\nsess.run(y, {is_training: True, x: train_data})\n\n# For eval\nsess.run(y, {is_training: False, x: eval_data})\n\n```\n", "The problem before was that you were not updating the `moving_mean` and `moving_variance` after each step, when updates_collections is None it forces the updates as part of the computation.\nHowever when a network has many batch_norm layers it is more efficient to collect all the update ops and run them together, so each layer don't need to wait for the update to finish.\n\n```\ny = build_model_with_batch_norm(x, is_training)\nupdate_ops = tf.group(tf.get_collection(tf.GraphKeys.UPDATE_OPS))\n\nsess.run([y, update_ops])\n\n```\n", "Has there been any progress made with speeding up batch norm?\n", "I was trying to use batch norm with a 2 layered densely connected NN with the (flatten) MNIST  (and relu units) data set for the task of auto-encoding  and I keep getting a NaN error. Anyone know why might this be? Is this ever possible with BN? seem fishy, but it couldn't be my learning set up, rate etc. (but I'd assume it shouldn't because BN should be sort of rubust to this)\n", "@sguada I am not understanding the right way of using `batch_norm` specially concerning the flag `updates_collections`. If I understood correctly if the flag is `None` the network is not efficient, so I should let `updates_collections=tf.GraphKeys.UPDATE_OPS` and then I should collect all the batch_norm updates and run them together.\n\nYou collect the batch_norms updates by doing: `update_ops = tf.group(tf.get_collection(tf.GraphKeys.UPDATE_OPS))`.\n\nI have many different models that use different batch_norm layers, this wouldn't work right?:\n\n``` python\n#model 1\ny1 = build_model_with_batch_norm(x, is_training)\nupdate_ops1 = tf.group(tf.get_collection(tf.GraphKeys.UPDATE_OPS))\nsess.run([y1, update_ops1])\n#model 2\ny2 = build_model_with_batch_norm(x, is_training)\nupdate_ops2 = tf.group(tf.get_collection(tf.GraphKeys.UPDATE_OPS))\nsess.run([y2, update_ops2])\n```\n\nCould you explain this part with a bit more details? Thank you very much.\n", "Just put it in seperate collection-keys:\n\n```\n# While building your 1st model...\ntf.contrib.layers.batch_norm(..., updates_collection=\"updates-model1\")\n\n# same for 2nd model with key \"updates-model2\"\n```\n\n```\n#model 1\ny1 = build_model_with_batch_norm(x, is_training)\nupdate_ops1 = tf.group(tf.get_collection(\"updates-model1\"))\nsess.run([y1, update_ops1])\n#model 2\ny2 = build_model_with_batch_norm(x, is_training)\nupdate_ops2 = tf.group(tf.get_collection(\"updates-model1\"))\nsess.run([y2, update_ops2])\n```\n", "Nevertheless, the documentation seams to be out-dated. It tells to do the following:\n\n```\nupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\nif update_ops:\n    updates = tf.group(update_ops)\n    total_loss = control_flow_ops.with_dependencies([updates], total_loss)\n```\n\nBut:\n- _tf.group()_ does not accept a list. I replaced it with _tf.tuple()_\n- ~~I don't know how to access _control_flow_ops.with_dependencies()_. How can I access functions within control_flow_ops module? I have seen other examples just using tf.with_dependecies(), but I cannot do that with Tensorflow 0.10.~~ I found it here: _tf.python.control_flow_ops.with_dependencies()_\n\n**EDIT:**\n\nThe documentation should be updated to s.th. like this:\n\n```\nfrom tensorflow.python import control_flow_ops\n\nupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\nif update_ops:\n    updates = tf.tuple(update_ops)\n    total_loss = control_flow_ops.with_dependencies(updates, total_loss)\n```\n\n**EDIT 2:** \n\nAfter doing some runs on my network, I have to say that ~~I can not see any performance difference between using  _updates_collections=None_ in contrast to manually fetching _tf.GraphKeys.UPDATE_OPS_ while graph construction~~. Even with heavy use of batch normalization (in total, my _tf.get_collection(tf.GraphKeys.UPDATE_OPS)_ returns 140 Update-Ops, all of them are BN-ops only)\n\nEdit: Hard to say, if my results are correct, but the whole network indeed seams to be 1.5x faster. As far as I know, BN-statistics are calculated on CPU, not GPU so far.\n\nCan anyone of you see any performance benefits as well? Please share your results :)\n", "Coming back to the performance issue, does the current batch norm layer benfit at all from GPU usage? Anyone has experienced benefits from GPUs with this batch norm implementation?\n", "You can test for yourself:\nhttps://github.com/tensorflow/tensorflow/blob/4addf4b5806cd731949c6582a83f5824599cd1ef/tensorflow/python/ops/batch_norm_benchmark.py\n", "Sorry for the spam, but the documentation doesn't really explain how to use this BN with convolution (maybe should be provided somewhere?). In short how does it figure out that it should apply and learn the same parameters per feature (rather than per activation)?\n\n(Is there at least a code snippet to do this?)\n", "The slim batch_norm wrapper normalizes over the last dimension of your input tensor. So if it's a 2D input tensor coming from a fully connected layer, it normalizes over batch, and thus performs per-activation normalization. If it's a 4D tensor coming from a convolution, it will normalize over the three first dimensions (batch, width, depth), and thus perform per-feature normalization. @sguada maybe forth being a bit more descriptive about this.\n", "@nmhkahn Regarding your code snippet, may I ask why is `reuse` set to be `None` when `is_training=True`? Wouldn't that trigger the scaling parameter `gamma` and the offset parameter `beta` be re-initialized in every training step? I thought in the original paper, `beta` and `gamma` are \"learned along with the original model parameters\". To do that, shouldn't they be only initialized once and then reused in all training steps?\n\n`tf.cond(is_training, \n lambda: batch_norm(inputT, is_training=True,  updates_collections=None, scope=scope), \n lambda: batch_norm(inputT, is_training=False,  updates_collections=None, scope=scope, reuse = True))`\n", "I greatly appreciate the work that the TF team has put in here to make batch_norm available and effective. From my searching, this thread is the best resource for how to use it. There are many different problems and ideas flying around here, and it's difficult to figure out the consensus advice for the simplest standard case of how to use the batch_norm layer. I think there'd be a lot of value in expanding the documentation to specify the exact recommended usage.\n\nMy best attempt to figure that out brought me to the following code:\n\n```\nis_training_ph = tf.placeholder(tf.bool)\n...\nwith tf.variable_scope('bn_test_layer') as vs:\n    layer_output = tf.cond(is_training_ph,\n        lambda: tf.contrib.layers.batch_norm(layer_input, is_training=True, center=True, scale=True, activation_fn=tf.nn.relu, updates_collections=None, scope=vs),\n        lambda: tf.contrib.layers.batch_norm(layer_input, is_training=False, center=True, scale=True, activation_fn=tf.nn.relu, updates_collections=None, scope=vs, reuse=True))\n```\n\nThen I set is_training_ph to True for training and False for testing. This doesn't work for me. The model trains fine, but the test performance is terrible. In contrast, if I maintain is_training_ph=True for test time, it works great. Thus, I'm guessing I still have a scope issue so that it's not finding the proper existing variables. \n", "@davek44 I'm using the same code framework that you are using and I observed the same thing: when turns on `is_training=True` during training phase and turns off `is_training=False` for validation and/or testing phase, the model trains well like the paper described (model converges faster and I was able to use a larger learning rate), however the testing performance is terrible. If I turns on `is_training=True` all the time, the model trains the same as without inserting batch norm layer. I haven't figured out what I did wrong, I'm planning to use TensorBoard to monitor the parameters. Would you please update if you diagnose the cause of this behavior? \n", "tf.contrib.layers.batch_norm can take tensor as is_training, so not need to do anything especial.\n\n```\nis_training_ph = tf.placeholder(tf.bool)\n\noutputs = tf.contrib.layers.batch_norm(layer_input, is_training=is_training_ph, center=True, scale=True, activation_fn=tf.nn.relu, updates_collections=None, scope='batch_norm'),\n```\n", "I see the same poor test performance with that code.\n", "Without more details is impossible to know, my guesses are that you only train for a few iterations, so the moving_mean and moving_average haven't converge yet.\n\nYou can change the batch_size during test to see how the performance degrades as you make your batch smaller.\n", "> I see the same poor test performance with that code.\n\nI had exactly the same problem either with tf.slim batchnorm or with tf.cond and input is_training as a placeholder.\nIn the former case, when investigating the trained model, I found out that the moving mean and moving variance consist of all zeros. \nIn the latter case, the moving mean and variance look more reasonable (with different values), but if I use is_training=False in test time, the performance is also really bad. Using is_training=True, it works better but I think it only uses the moving mean and variance inside the test batch.\n", "@nmduc @davek44  I wrote some code to track the moving mean and moving variance computed in `tf.contrib.layers.batch_norm` during training and testing. I found out that the value of `decay` matters a lot (they use exponential decay to compute moving average and moving variance), with a `decay` setting closer to 1.0 (i.e. `decay=.999`), moving mean drops to a value closer to 0. I did 2 test runs with the exact same code but different `decay` settings in the `tf.contrib.layers.batch_norm`, and my validation/test accuracies seemed more reasonable.\n\nThe test run results with `decay=0.9`\n<img width=\"784\" alt=\"screen shot 2016-11-16 at 1 51 51 pm\" src=\"https://cloud.githubusercontent.com/assets/6901075/20361517/dd5dbbd8-ac05-11e6-85ac-5a9e2dec3a2b.png\">\n\nThe test run results with `decay=0.999` (`decay=0.999` is the default setting in `tf.contrib.layers.batch_norm`)\n<img width=\"784\" alt=\"screen shot 2016-11-16 at 2 03 58 pm\" src=\"https://cloud.githubusercontent.com/assets/6901075/20361605/31729f5e-ac06-11e6-9736-eb9ad2f15de1.png\">\n\n(also seems like larger decay value would require the model to train longer to see validation accuracy change )\n", "Yup that fixed it. Thanks for sharing your analysis @zhongyuk!\n\nI encourage the developers to consider making decay=0.9 the default. Even 0.99 doesn't work well for me. That's the default value in Torch's implementation, too; see the momentum parameter in https://github.com/torch/nn/blob/master/BatchNormalization.lua\n", "@zhongyuk Thanks a lot for sharing . It works for me now. \n", "This seems important. @sguada we should consider the right course of action here before 1.0. In the short term, can one of the interested parties send me a PR documenting the fact that `decay` might have to be significantly lowered when experiencing poor eval performance? I am pretty sure I've never had to tweak that parameter, but it might be a side effect of the distributed setting.\n", "We could change the default to 0.9 or document better its impact in smaller datasets or few updates.\n@vincentvanhoucke in our distributed setting we usually do millions of updates so it is ok, however in other cases like the one here which does only a few hundreds of updates it makes a big difference:\nFor example using decay=0.999 has a 0.36 bias after 1000 updates, but that bias goes down to 0.000045 after 10000 updates and to 0.0 after 50000 updates.\n", "Just wanted to note that I also have the problem of poor test performance, specifically using small batch sizes (anything smaller than 10 instead of the 200 I used for training diminishes test accuracy). I've used a tf.placeholder to switch between testing/training mode.\r\n\r\nIt's great that this batch normalization layer works for better training convergence, but if you can't apply the model in production, there isn't much of a point in using it. Can anyone confirm good test performance with small or single data samples using this batch norm layer? ", "I can confirm that test performance is good when using is_training=False with small batches and even with batch_size=1, since it is not using statistic from the batch, but the statistic learnt during training. Just need to make sure that the statistics have converged with default decay=0.999 that implies at least 50k updates. ", "To follow up with TF developer's confirmation, I track the convergence of the statistics with two different `decay` settings (and training batch_size=1). With `decay=0.99`, the statistics converge (bias<0.001) after 550~600 steps of learning/updates. With `decay=0.9`, the statistics converge (biase<0.001) within within 100 steps of learning/updates.", "@sguada thanks, does that also mean the output is actually independent of the batch size? because I'm noticing very slight changes with big impact on my accuracy (maybe my definition of performance is just more easily affected by this slight change). To be precise, all values in my 128 dimensional output tensor increase such that the total vector length scales almost linearly with the batch size. Per value this isn't that much of a difference, but has a big impact when computing vector distances in latent spaces. \r\n\r\n@zhongyuk thanks, I've run about 5k updates with `decay=0.9`, so it should've converged and testing performance using large batch sizes is fine. But even if it didn't, would it result in a difference between training a testing? I'd be seeing bad performance during training *and* testing if it hadn't converged, right?\r\n\r\nI will investigate some more and see if I can reproduce the issue on another task. Thanks for the quick feed back so far!", "@dominikandreas If your poor testing performance is caused by statistics not converging, you'd see reasonably good training performance but bad testing performance. Because during training, the batch normalization is done using the training batch statistics only. However, during testing time, it's using the moving average statistics of all the training batches to normalize the input tensor.", "I found and error in my code, batch normalization is working fine now :-) thanks for your support", "Hi @zhongyuk , how did you keep track of the moving mean and variance? \r\nThanks!", "@rogertrullo Generally I setup TensorBoard to track moving mean and variance. Other than that, I also tried fetching statistics through `tf.get_variable(\"moving_mean\")` within scope during training and reference to monitor the bias.", "hi,\r\nI have same problem as other described that I have good training results but validation/testing is bad after using batch_norm.\r\nI use the function like this:\r\nconv_normed1 = tf.contrib.layers.batch_norm(conv1 + block1_layer3_1_biases, updates_collections=None, scale=True, decay=batch_norm_decay, center=True, is_training=is_training )\r\ndecay value is 0.9\r\ndo I need to set the reuse flag?\r\nI will glad for any help.", "I have been using batch_norm as described in this thread (with a tf.bool for training; and ops.GraphKeys.UPDATE_OPS) and everything works.\r\n\r\nWhen saving and restoring using:\r\nsaver = tf.train.Saver()\r\nit works,\r\n\r\nbut when saving using:\r\nsaver = tf.train.Saver(tf.trainable_variables() + [global_step])\r\nso that I can save storage space (by not saving the gradients etc)\r\non restore there is an error:\r\n\"uninitialized value unpool4/convc/bn/moving_mean\"\r\n\r\nObviously this is because moving_mean (and I suppose moving_variance) hasn't been saved for any of the layers. As I have lots of them (nested in many layers) - what is the most efficient way of adding them to the list of values to be saved? Also, given that these are trainable variables, why are they not addded to the trainable_variables collection?\r\n", "@mshunshin moving mean and variance are not trainable variables: there are no gradients coming to them, they are just accumulating statistics across minibatches of examples. \r\nTo save/restore them, you can use tf.global_variables()", "for me things started to work when I used this wrapper:\r\n`def batch_norm_wrapper(x, phase, decay, scope, reuse):\r\n    with tf.variable_scope(scope, reuse=reuse):\r\n        normed = tf.contrib.layers.batch_norm(x, center=True, scale=True, decay=decay, is_training=phase, scope='bn',updates_collections=None, reuse=reuse)\r\n        return normed`\r\nthe whole using of scopes and reuse is not clear in this thread for my opinion.\r\n    \r\n", "Many thanks. With tf.global_variables() the save files are much larger as I think it includes the gradients; in the end I used:\r\n\r\nsaver = tf.train.Saver([x for x in tf.global_variables() if 'Adam' not in x.name])\r\n\r\nand because the session manager init doesn't initialise them properly:\r\n\r\nsess.run(tf.variables_initializer([x for x in tf.global_variables() if 'Adam' in x.name]))\r\n\r\n(Using tf.train.AdamOptimizer)", "You can also use tf.model_variables() which contains the variables of the model, i.e. moving_mean", "@sguada Sorry for trouble you, but is it possible to make an example on how to use slim.batch_norm when combined with slim.conv2d/slim.fully_connect in readme.md? \r\n\r\nI'm using slim.batch_norm, but get good training performance and poor validation/test performance. I think it must be due to improper use of `reuse` or `scope` or some other parameters. Though there are many issues on batch normalization, it's hard to find a complete code snippet on how to use it, esp. for how to pass different parameters in different phase.\r\n\r\nSay, in my [mnist_bn](https://github.com/soloice/mnist-bn/blob/master/mnist_bn.py) code, I controlled dependencies using `tf.GraphKeys.UPDATE_OPS` and set up `is_training` as a placeholder. But validation performance still is poor if I feed {is_training: False}.\r\n\r\nI would greatly appreciate it if there's an official and complete (which means training, validating, testing are all included) batch normalization example.\r\n\r\nThank you in advance!", "hi,\r\nyou need to set different scope for every time you use batch norm and give it the reuse input according to the training/test phase(TRUE when test FALSE when train) that works for me.", "@ishaybee Thanks for you help. I've found my problem= = **It's due to the cold start of moving_mean/moving_variance.**\r\n\r\nSince I haven't trained enough steps, the estimated moving mean/variance is not that stable. The result turns out to be: the model performs pretty well on training mini-batches (you know at the beginning loss goes down quickly), but validation performance is erratic (because the estimated population mean/variance are not stable enough).\r\n\r\nWhen I trained the model longer, validation accuracy becomes prettier, too.\r\n\r\n**Another important thing is, be sure to use `slim.learning.create_train_op` to create train op**. Do not use tf native `tf.train.GradientDescentOptimizer(0.1).minimize(loss)`.\r\n\r\nSo the answer is, I'm using batch normalization correctly, but I haven't fully understood its dynamics during training.\r\n\r\n================\r\nWhat's more:\r\n1. [Here is a full example](https://github.com/soloice/mnist-bn) on how to use BN layer on MNIST dataset.\r\n2. Use a smaller decay value will accelerate the warm-up phase. The default decay is 0.999, for small datasets such like MNIST, you can choose 0.99 or 0.95, and it warms up in a short time.", "@soloice , notice, how in about [comment](https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-235928564) the following parameter is passed inside to the layer for calling batch_norm:\r\n\r\n>  batch_norm_params = {'is_training': is_training, 'decay': 0.9, 'updates_collections': None}\r\n\r\nWithout `updates_collections `set to None (so mean updates are done in place inside BatchNorm), I won't expect surrounding layer (e.g. conv2d) to somehow execute tf.GraphKeys.UPDATE_OPS needed for BatchNorm layer to update running mean and therefore be able to do run on test data later.\r\n\r\nOr you may try to run UPDATE_OPS yourself explicitly as one [here](https://github.com/tensorflow/tensorflow/issues/7469#issuecomment-279646674)\r\n```\r\n    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\n    if update_ops:\r\n        updates = tf.group(*update_ops)\r\n        cross_entropy = control_flow_ops.with_dependencies([updates], cross_entropy)\r\n```\r\n\r\nUpdate - I found that I quoted exactly your code and you do use UPDATE_OPS. \r\n\r\nAs for \"cold start\", as you see above in discussiion, decreasing BatchNorm running average decay (input param) from default 0.999 to something like 0.95 can speed-up start-up", "@pavelbulanov It's very kind of you to help me with this! I'll try a smaller value of `decay` to see how this helps.\r\n\r\n================\r\nUpdate: use a small decay (say, 0.9 or 0.95) does help a lot. Validation loss goes down very quickly when I set `decay` to 0.9. However, the drawback of small decay is that its effective range is small: The result is dominated by a few recent samples thus it's not a good estimation of population mean/variance. One needs to balance between quick start (small decay) and a longer effective range (large decay).", "Hi,\r\nI tried to implement a batch normalisation layer with the help of the suggestions in this issue, but I still have a >70% error in validation and testing... I do have a lower decay for non-training calls...\r\n\r\nHere is my code:\r\n```python\r\ndef BatchNorm(inputT, is_training=False, scope=None):\r\n  return tf.cond(\r\n    is_training,\r\n    lambda: tf.contrib.layers.batch_norm(inputT, is_training=True,  reuse=None, decay=0.999, epsilon=1e-5, center=True, scale=True, updates_collections=None, scope=scope),\r\n    lambda: tf.contrib.layers.batch_norm(inputT, is_training=False, reuse=True, decay=0.900, epsilon=1e-5, center=True, scale=True, updates_collections=None, scope=scope)\r\n    )\r\n```\r\n\r\nThank you in advance.", "@Alexivia It seems that you are using two different batch normalization layers? You should use only one BN layer (of course, with different `is_training` parameter).", "Thank you for your advice @soloice.\r\nI tried now with just different `is_training` and `reuse` parameters:\r\n```python\r\nlambda: tf.contrib.layers.batch_norm(inputT, is_training=True,  reuse=None, decay=0.9, epsilon=1e-5, center=True, scale=True, updates_collections=None, scope=scope),\r\nlambda: tf.contrib.layers.batch_norm(inputT, is_training=False, reuse=True, decay=0.9, epsilon=1e-5, center=True, scale=True, updates_collections=None, scope=scope)\r\n```\r\nstill don't get good validation and testing results... >70%...", "hi,\r\nplease see my wrapper above.\r\nyou should use \"with tf.variable_scope(scope, reuse=reuse):\" I think.", "Hi @ishaybee,\r\nI followed your advice, now my code is:\r\n```python\r\ndef BatchNorm(inputT, is_training=False, reuse=True, scope=None):\r\n  with tf.variable_scope(scope, reuse=reuse):\r\n    return tf.contrib.layers.batch_norm(inputT, is_training=is_training, reuse=reuse, scope=scope, updates_collections=None, decay=0.9, center=True, scale=True)\r\n```\r\nand I feed `is_training` and `reuse` through the feed_dict, but now I get the error `ValueError(\"The reuse parameter must be True or False or None.\")`", "try to feed reuse as a python variable (input of the model) and as placeholder.", "I tried that, and now it stopped complaining about the value... but I think that the placeholder value is not being used, because I see no change if I force values to `batch_norm` function, and in TensorBoard it's not connected to the graph... (see attached image)\r\n![screen shot 2017-04-03 at 19 54 54](https://cloud.githubusercontent.com/assets/23476569/24625718/cbe90f88-18a7-11e7-80a6-f087d56dd9ad.png)\r\n", "My code is like this now:\r\n**Batch Normalisation wrapper**\r\n```python\r\ndef BatchNorm(inputT, is_training=False, reuse=None, scope=None):\r\n  with tf.variable_scope(scope):\r\n    return tf.contrib.layers.batch_norm(inputT, is_training=is_training, reuse=reuse, scope=scope, updates_collections=None, decay=0.9, center=True, scale=True)\r\n```\r\n**Model definition**\r\n```python\r\ndef model(data, train=False, is_training=False, reuse=None):\r\n  # 1st conv layer\r\n  with tf.name_scope('conv1') as scope:\r\n    conv = tf.nn.conv2d(\r\n    <...>\r\n    norm = BatchNorm(pool, is_training=is_training, reuse=reuse, scope=scope)\r\n```\r\n**Training**\r\n```python\r\nfeed_dict = {train_data_node: batch_data,\r\n      train_labels_node: batch_labels,\r\n      is_training: True,\r\n      reuse: None}\r\n  # Run the optimizer to update weights.\r\n  sess.run(optimizer, feed_dict=feed_dict)\r\n```\r\n**Validation**\r\n```python\r\nbatch_predictions = sess.run(eval_prediction, feed_dict={eval_data: data[-EVAL_BATCH_SIZE:, ...], is_training: False, reuse: True})\r\n```", "Although is_traning can a placeholder reuse has to be a bool, and it cannot be a tensor nor a placeholder.\r\n\r\nI'm not sure what are you trying to do, in most cases using static values solve the problem. For example this pattern works well:\r\n\r\n```\r\ndef model(data, is_training=False, reuse=None, scope='my_model'):\r\n  # Define a variable scope to contain all the variables of your model\r\n  with tf.variable_scope(scope, 'model', data, reuse=reuse):\r\n    # 1 layer\r\n    net = tf.contrib.layers.conv2d(data, ....)\r\n    ....\r\n    net = tf.contrib.layers.batch_norm(net, is_training)\r\n   return net\r\n\r\ntrain_outputs = model(train_data, is_training=True)\r\neval_outputs = model(eval_data, is_training=False, reuse=True)\r\n\r\neval_predictions = sess.run(eval_outputs, feed_dict={eval_data: data[-EVAL_BATCH_SIZE:, ...]})\r\n\r\n```\r\nUnless you need to change the behavior of the model dynamically, you don't need to use a placeholder for is_training. The trick is to build the model twice, but sharing the variables the second time. \r\n\r\n", "Thank you @sguada ! After applying your suggestions, I finally made it to work!", "It would be helpful if the API 1.0 documentation reflected that you need to manually add update ops to the graph. Being a newer tf user, I found that my test error was crazy and then had to spend a fair amount of time debugging my graph until I realized that batch normalization was the problem. Then I had to spend more time figuring out that by default the variables tracking the moments don't update unless you use a contrib function for optimization. Since in 1.0 there is no option to set the update_collections to None, there is no indicator from the documentation that this might even be an issue. Additionally, it seems like it might make sense to have a parameter to add the control flow dependencies to the op that runs in the training case.", "@danrsc Exactly. The usage of BN layer is quite confusing. I suggested to add documents or a complete official tutorial on batch normalization, but unfortunately got no response = =", "Completely agree. I think BN usage is very tricky and the documentation is currently beyond inadequate. This ought to be fixed for such a commonly used layer.", "Reopening for visibility of the documentation issues.", "@sguada assigning to you for triaging. Might be worth getting a tech writer on the case.", "Just got confused by this problem last week and wasted 3 days of training... Hope the docs can be fixed soon, and an official batch normalization example can be added in the API docs.", "@sguada  I have noticed that you said\" tf.contrib.layers.batch_norm can take tensor as is_training, so not need to do anything especial\".\r\nHowerver, the comment in the code is\r\n If `is_training` doesn't have a constant value, because it is a `Tensor`,\r\n    # a `Variable` or `Placeholder` then is_training_value will be None and\r\n    # `needs_moments` will be true.\r\nDoes it mean that nees_moments will be true even in test phase if i set is_training as a  placeholder?\r\nAs far as I know, the moments is not needed while testing.", "So if `is_training` is a `Variable` or a `Placeholder`, it means it can change, so the graph to compute the moments is needed, so the layer builds it.\r\nThen in running time depending on the value being `True` or `False` would use the batch `moments` or the `moving_mean` and `moving_variance`.\r\n\r\nSo during testing you would set the value to `False` and the `moments` won't be used.", "@sguada @brando90 \r\n```\r\ndef batch_norm_layer(self, x,train_phase, scope_bn):\r\n        bn_train = batch_norm(x, decay=0.9, center=False, scale=True,\r\n        updates_collections=None,\r\n        is_training=True,\r\n        reuse=None,\r\n        variables_collections= [UPDATE_OPS_COLLECTION],\r\n        trainable=True,\r\n        scope=scope_bn)\r\n        bn_inference = batch_norm(x, decay=0.9, center=False, scale=True,\r\n        updates_collections=None,\r\n        is_training=False,\r\n        reuse=True,\r\n        variables_collections= [UPDATE_OPS_COLLECTION],\r\n        trainable=True,\r\n        scope=scope_bn)\r\n        z = tf.cond(train_phase, lambda: bn_train, lambda: bn_inference)\r\n        return z\r\n```\r\n\r\n\r\nI build batchnorm like this, however, the moving mean and moving variable are updated during test, I can not find the reason.", "I tried creating two models like @sguada said, however, my model where is_training=False just crashes.\r\n\r\n```\r\nW tensorflow/core/framework/op_kernel.cc:993] Not found: Key fully_connected_5/weights not found in checkpoint\r\nW tensorflow/core/framework/op_kernel.cc:993] Not found: Key fully_connected_6/weights not found in checkpoint\r\nW tensorflow/core/framework/op_kernel.cc:993] Not found: Key fully_connected_7/biases not found in checkpoint\r\nW tensorflow/core/framework/op_kernel.cc:993] Not found: Key fully_connected_6/biases not found in checkpoint\r\nW tensorflow/core/framework/op_kernel.cc:993] Not found: Key fully_connected_7/weights not found in checkpoint\r\nW tensorflow/core/framework/op_kernel.cc:993] Not found: Key history_embeddings_1 not found in checkpoint\r\nW tensorflow/core/framework/op_kernel.cc:993] Not found: Key global_step_1 not found in checkpoint\r\n```\r\n\r\nI feel like maybe there should be a concrete example of how to do a batch norm with a fully connected net, as well as with CNNs. Sucks that I've trained models for days expecting things to work before seeing that everyone trying to use this feature going crazy.\r\n\r\nInterestingly enough, it takes a zillion years to get the model restored after training with batch_norm as well. Will most likely wait until TF 2.0 to try something like this again.", "@MisayaZ you don't need to create two batch_norm layers you can just pass train_phase (assuming it is a tf.bool) to batch_norm. Also you are passing UPDATE_OPS_COLLECTION variables_collections, which changes which collections are the variables added to.\r\n\r\nThe following should work:\r\n\r\n```\r\nz = batch_norm(x, decay=0.9, center=False, scale=True, updates_collections=None, \r\n                             is_training=train_phase, scope=scope_bn)\r\n\r\n```\r\n", "@OktayGardener not sure what model are you trying to create, it seems that the variables are not saved in your checkpoint.\r\n\r\nbatch_norm also works with fully_connected layers.\r\n\r\n```\r\nslim = tf.contrib.slim\r\ndef model(data, is_training=False, reuse=None, scope='my_model'):\r\n  # Define a variable scope to contain all the variables of your model\r\n  with tf.variable_scope(scope, 'model', data, reuse=reuse):\r\n    # Configure arguments of fully_connected layers\r\n    with slim.arg_scope([slim.fully_connected],\r\n                        activation_fn=tf.nn.relu,\r\n                        normalizer_fn=slim.batch_nom):\r\n      # Configure arguments of batch_norm layers\r\n      with slim.arg_scope([slim.batch_norm],\r\n                          decay=0.9,  # Adjust decay to the number of iterations\r\n                          update_collections=None, # Make sure updates happen automatically\r\n                          is_training=is_training, # Switch behavior from training to non-training):\r\n        net = slim.fully_connected(data, 100, scope='fc1')\r\n        net = slim.fully_connected(net, 200, scope='fc2')\r\n        ....\r\n        # Don't use activation_fn nor batch_norm in the last layer        \r\n        net = slim.fully_connected(net, 10, activation_fn=None, normalizer_fn=None, scope='fc10')\r\n       return net\r\n```\r\n\r\n\r\n", "@sguada Thanks, I build a network with bathnorm which is implemented as you mentioned above\r\n```\r\nz = batch_norm(x, decay=0.9, center=False, scale=True, updates_collections=None, \r\n                             is_training=train_phase, scope=scope_bn)\r\n```\r\nthe speed is slow, I use tensorflow benchmark to get the computation time as below:\r\nI tensorflow/core/util/stat_summarizer.cc:392] ============================== Top by Computation Time ==============================\r\nI tensorflow/core/util/stat_summarizer.cc:392] \t             [node type]\t  [start]\t  [first]\t [avg ms]\t     [%]\t  [cdf%]\t  [mem KB]\t[Name]\r\nI tensorflow/core/util/stat_summarizer.cc:392] \t                  Conv2D\t  106.164\t   51.354\t   51.004\t 23.145%\t 23.145%\t   692.224\tconv8/Conv2D\r\nI tensorflow/core/util/stat_summarizer.cc:392] \t                  Conv2D\t   85.187\t   19.115\t   19.283\t  8.750%\t 31.896%\t   692.224\tconv7/Conv2D\r\nI tensorflow/core/util/stat_summarizer.cc:392] \t       SquaredDifference\t   11.967\t   15.105\t   14.331\t  6.503%\t 38.399%\t 11075.584\tconv1/batch_norm/moments/sufficient_statistics/SquaredDifference\r\nI tensorflow/core/util/stat_summarizer.cc:392] \t                     Mul\t   11.970\t   14.162\t   13.495\t  6.124%\t 44.523%\t 11075.584\tconv1/batch_norm/batchnorm/mul_1\r\nI tensorflow/core/util/stat_summarizer.cc:392] \t                  Conv2D\t    3.948\t    8.170\t    7.986\t  3.624%\t 48.146%\t 11075.584\tconv1/Conv2D\r\nI tensorflow/core/util/stat_summarizer.cc:392] \t                     Sub\t   11.960\t   10.176\t    7.943\t  3.604%\t 51.751%\t 11075.584\tconv1/batch_norm/moments/sufficient_statistics/Sub\r\nI tensorflow/core/util/stat_summarizer.cc:392] \t       SquaredDifference\t   45.570\t    5.908\t    7.177\t  3.257%\t 55.007%\t  5537.792\tconv2/batch_norm/moments/sufficient_statistics/SquaredDifference\r\nI tensorflow/core/util/stat_summarizer.cc:392] \t                     Mul\t   45.574\t    7.755\t    6.902\t  3.132%\t 58.140%\t  5537.792\tconv2/batch_norm/batchnorm/mul_1\r\nI tensorflow/core/util/stat_summarizer.cc:392] \t                  Conv2D\t   40.692\t    5.408\t    4.845\t  2.199%\t 60.338%\t  5537.792\tconv2/Conv2D\r\nI tensorflow/core/util/stat_summarizer.cc:392] \t                     Sub\t   45.563\t    6.067\t    4.784\t  2.171%\t 62.509%\t  5537.792\tcon\r\n\r\nI don't understand why some op in moment are executed during test and it cost a lot of time, such as conv1/batch_norm/moments/sufficient_statistics/SquaredDifference.\r\n\r\nThe moment is not needed in test, why are some ops under moment executed?\r\n", "Hi,\r\n\r\nUsing the above `batch_norm` layer in `contrib.layers`, I'm getting `nan` as an output for validation graph while the train graph runs seamlessly. Is there anything that I might be missing ?\r\n\r\nI'm using:\r\n```python\r\ndef batchnormlayer(inputs, numout, train_model):\r\n    with tf.variable_scope(\"batch_norm\") as scope_bn:\r\n        epsilon = 1e-3\r\n        return tf.contrib.layers.batch_norm(inputs, decay=0.9, updates_collections=None,\r\n                                            scale=True, scope=scope_bn,\r\n                                            is_training=train_model, epsilon=epsilon,\r\n                                            fused=True, reuse=scope_bn.reuse)\r\n```\r\nThanks ", "As a follow up, I'm reusing 16 layers of batch_norm.\r\nHowever, I found that reusing 4 layers works.", "I've just been noticing that if I kill the tensorflow process and restart it, my error gets worse for a few epochs (i.e. worse than it should be at the last checkpoint). I also observe that if I remove batch_norm, this problem goes away. After looking at the code for a while, I think this may be because the values of the variables are not restored from the shadow variables as they would be if the ExponentialMovingAverages class were used to manage the moving averages. This also means that if I use a separate process to evaluate, I'm getting whatever the last value of the variable was and not the moving average. Am I interpreting this correctly and is this the intended behavior? It seems like you want the shadow variable values to be restored...", "I caught the problem, the moving variance in my case goes negative after some iterations.\r\n\r\nThe output of the tensor : `Model/clip_logits/batch_norm/moving_variance:0` present in `tf.model_variables()` is \r\n```\r\nMoving variance (shape = (101,)) = \r\n[ 214.70379639   95.36338043    0.57885742  189.49542236  102.72473145\r\n  137.14886475  286.57333374  111.06427002  154.98750305  167.75219727\r\n  207.83955383  211.14007568  158.23495483  171.61665344  116.81361389\r\n  115.77380371   43.59399796  137.75064087  181.75245667  161.37339783\r\n  215.21934509   92.88521576  191.23846436  336.3946228   259.85919189\r\n  299.47039795  186.23222351  165.19311523  262.82446289  170.11567688\r\n  233.56843567  209.35050964  115.96807861  154.34109497  295.5770874\r\n  123.6055603   295.76187134  296.88583374  240.88217163  247.32983398\r\n   87.15661621  217.69897461  133.00698853   -4.80375671  344.77462769\r\n  291.50601196  117.77174377  265.83712769  207.90093994  194.186203\r\n  220.21418762  178.03738403  115.27571869  196.62184143  228.8089447\r\n  191.53205872  331.36807251  151.55435181  197.2951355   179.67504883\r\n  181.09727478   90.09922791  173.30133057  102.6836853   160.9434967\r\n  236.59512329  168.05305481  403.36340332   41.14326096  185.93409729\r\n  130.57434082  266.31509399  101.44387817  163.88059998  290.25015259\r\n  244.52597046  229.86647034  158.14352417  202.68774414  187.78227234\r\n  248.78218079  126.0978241   171.41891479  274.40740967  119.84254456\r\n  202.53045654  200.20608521  214.04730225  111.53284454  222.03184509\r\n  244.81187439  172.23052979  187.09806824  194.62802124  255.26345825\r\n  293.63598633  307.91036987  210.86982727  308.88919067  144.94792175\r\n  229.69013977]\r\n```\r\nAs you can see, there's negative variance for one of the dimension. How is this even possible ?\r\nP.S. The batch norm layer is used just after the last fully connected layer of the network and before softmax.", "@raghavgoyal14 are you using it with fused=True? Had a similar problem and it went away when I used the fused version", "@abred : Yes, I used `fused=True`, same problem.", "@sguada  Hi, sguada, I have a problem.\r\nThe definition of contrib.layers.batch_norm in tensorflow:\r\ndef batch_norm(inputs,\r\ndecay=0.999,\r\ncenter=True,\r\nscale=False,\r\nepsilon=0.001,\r\nactivation_fn=None,\r\nparam_initializers=None,\r\nparam_regularizers=None,\r\nupdates_collections=ops.GraphKeys.UPDATE_OPS,\r\nis_training=True,\r\nreuse=None,\r\nvariables_collections=None,\r\noutputs_collections=None,\r\ntrainable=True,\r\nbatch_weights=None,\r\nfused=False,\r\ndata_format=DATA_FORMAT_NHWC,\r\nzero_debias_moving_mean=False,\r\nscope=None,\r\nrenorm=False,\r\nrenorm_clipping=None,\r\nrenorm_decay=0.99):\r\nscale: If True, multiply by gamma. If False, gamma is\r\nnot used. When the next layer is linear (also e.g. nn.relu), this can be\r\ndisabled since the scaling can be done by the next layer.\r\n\r\nIf I use tf.contrib.layers.batch_norm(input, scale=False) , the\"scale =False\" means whether the gamma is zero in \"y = gamma*x+beta\" while training. Thank you very much.", "When scale=False, gamma is a constant 1.", "@ppwwyyxx Thank you very much for your help. I use tf.contrib.layers.batch_norm(input, scale=False)  in Tensorflow, and now I am convering the batchnorm of Tensorflow to Caffe. How to set the param of BatchNormLayer and ScaleLayer in Caffe?  \r\nThank you very much.", "@MisayaZ I was having the same behavior using Batchnorm with a placeholder for \"is_training\". I see in the trace that the moments are being calculated even at test time, so I decided to go into the source code and I found this:\r\n\r\n```python\r\n    # If `is_training` doesn't have a constant value, because it is a `Tensor`,\r\n    # a `Variable` or `Placeholder` then is_training_value will be None and\r\n    # `needs_moments` will be true.\r\n    is_training_value = utils.constant_value(is_training)\r\n    need_moments = is_training_value is None or is_training_value\r\n    if need_moments:\r\n        # here it defines the moments\r\n```\r\nIt looks like when \"is_training\" is a variable or a placeholder the moments get defined and also get calculates them at runtime, even when you set the placeholder to \"False\". I would have preferred to leave it as a placeholder because this way I can do periodic testing during training without redefining the graph, but I decided to use it as a constant and define different behaviors for train vs test, and now the moments are not calculated at test time. ", "@tano297 Thank you. I now also use 'is_training' as a constant. Leave it as a placeholder and do periodic testing will change the value of moving mean and moving variance. And the inference time will be longer for it will calculate the mean and variance of the inputs and update the moving mean and moving variance. The right way to do testing is to define different behaviors for train and test as you mentioned.", "@tano297 @MisayaZ \r\nbut doesn't the \"smart_cond\" in\r\n```\r\nis_training_value = utils.constant_value(is_training)\r\nneed_updates = is_training_value is None or is_training_value\r\nif need_updates:\r\n  ...\r\n  outputs = utils.smart_cond(is_training, _force_updates, no_updates)\r\n```\r\nmake sure that the updates are only calculated and applied if is_training evaluates to True?", "@abred Yes indeed, but you are referring to line 391, where it does the update of the moving average within _fused_batch_norm():\r\n\r\n```py\r\n    # If `is_training` doesn't have a constant value, because it is a `Tensor`,\r\n    # a `Variable` or `Placeholder` then is_training_value will be None and\r\n    # `need_updates` will be true.\r\n    is_training_value = utils.constant_value(is_training)\r\n    need_updates = is_training_value is None or is_training_value\r\n    if need_updates:\r\n        ...\r\n        outputs = utils.smart_cond(is_training, _force_updates, no_updates)\r\n        ...\r\n```\r\n\r\nI am talking about line 753 within batch_norm():\r\n\r\n```py\r\n    # If `is_training` doesn't have a constant value, because it is a `Tensor`,\r\n    # a `Variable` or `Placeholder` then is_training_value will be None and\r\n    # `needs_moments` will be true.\r\n    is_training_value = utils.constant_value(is_training)\r\n    need_moments = is_training_value is None or is_training_value\r\n    if need_moments:\r\n        ...\r\n        mean, variance = utils.smart_cond(is_training,\r\n                                          _force_updates,\r\n                                          moving_vars_fn) \r\n        ...\r\n```\r\nThe smart condition in that case (as far as I am concerned) decides wether or not to update the moving averages, but the moments still get calculated.", "@tano297 you right about that, I was in the wrong place, but still:\r\nline 755-770 calculate the moments, but the moments are only used in _force_updates which is only executed if is_training evaluates to True, aren't they?\r\nAnd thus \r\n```\r\nmean, variance = utils.smart_cond(is_training, _force_updates, moving_vars_fn) \r\n```\r\nshould be equivalent to line 804:\r\n```\r\nmean, variance = moving_mean, moving_variance\r\n```\r\nif is_training evalutes to False and thus the \"moments\"-part of the graph is never used and thus shouldn't be executed\r\n\r\nbut I haven't tested, so I might be wrong about that :)", "@tano297 @abred  you right. The moving mean and moving variance are changed when I used batchnorm like this:\r\n\r\n    def batch_norm_layer(self, x,train_phase, scope_bn):\r\n            bn_train = batch_norm(x, decay=0.9, center=False, scale=True,\r\n            updates_collections=None,\r\n            is_training=True,\r\n            reuse=None,\r\n            variables_collections= [UPDATE_OPS_COLLECTION],\r\n            trainable=True,\r\n            scope=scope_bn)\r\n            bn_inference = batch_norm(x, decay=0.9, center=False, scale=True,\r\n            updates_collections=None,\r\n            is_training=False,\r\n            reuse=True,\r\n            variables_collections= [UPDATE_OPS_COLLECTION],\r\n            trainable=True,\r\n            scope=scope_bn)\r\n            z = tf.cond(train_phase, lambda: bn_train, lambda: bn_inference)\r\n            return z\r\n\r\nIf you use like following:\r\n\r\n    z = batch_norm(x, decay=0.9, center=False, scale=True, updates_collections=None, \r\n                             is_training=train_phase, scope=scope_bn)\r\n\r\n\r\nThe moving mean and moving variance will not be changed during test, but the speed is very slow.", "Hi @zhongyuk ,\r\n\r\nI also met the problem that I could get good results when using is_training=True for both training and inference, but get bad results when setting is_training=False during inference (worse than the case using is_training=True). According to your analysis, If I understand correctly, by simply setting decay=0.9 in BN can solve this problem. Am I right? \r\n\r\nBTW, do I need to retrain the model using decay=0.9 from scratch? Or resuming training from the checkpoint (i.e., trained when decay=0.999) is also ok?\r\n\r\nThanks!", "@nmduc @davek44 \r\n\r\nHi, I also met the problem that I could get good results when using is_training=True for both training and inference, but get bad results when setting is_training=False during inference (worse than the case using is_training=True). Have you guys solved this problem? Thanks!", "@tyshiwo I just set decay=0.9 for batch_norm and it works well so far.", "I was confused after all these comments on how to properly use Batch Norm: So here is what I have. Please correct me if I'm wrong.\r\n\r\n`batch_norm = tf.contrib.layers.batch_norm(conv,\r\n                                                             center=True,\r\n                                                             scale=True,\r\n                                                             reuse=phase_train_py,\r\n                                                             scope='bn',\r\n                                                             is_training=is_training)`\r\n\r\nwhere phase_train_py is a python boolean variable and is_training is a placeholder taking a boolean variable. I guess using tf.cond is wrong, otherwise would did the function came with a boolean parameters. In other words, if `tf.cond` is true, then we should a `batch_norm` function for training and another one for testing. So, developers allow us to change these boolean variables in order to change the behavior of the function. So What I am doing is: setting `phase_train_py` to False while training while `is_training` to True. And the opposite while Testing. Since we can only change tensors or placeholders with `sess.run`, I changed `phase_train_py` intentionally before running the graph. Ex: \r\n\r\n`        if condition:\r\n            phase_train_py = False\r\n            sess.run(to_run_list, feed_dict={phase_train: True})\r\n        else:\r\n            phase_train_py = True\r\n            sess.run(to_run_list, feed_dict={phase_train: False})`", "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\r\n                                                                 MAYBE YOU NEED READ THIS\r\n+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\r\n\r\n\r\n\r\nIt seems there are still problems with TF v1.3. I'm sure I note the following details, but still failed to use the official `tf.contrib.layers.batch_norm`, with `is_training=False` during evaluation(but when I keep `is_training=True` unchanged during evaluation, it is ok):\r\n1.` decay`,  exponential moving average is actually alpha filter in signal processing, the time to converge is approximately 1/(1-decay) steps of train. For decay=0.999, you need 1/0.001=1000 steps to converge. So set the appropriate decay for your training step numbers.\r\n2. using placeholder to switch between train and test evaluation\r\n3. use` updates_collections=None` if you don't want to add control dependencies of update op to train_op\r\n4. set `reuse` to appropriate value.\r\n\r\nIt seems the only way to use the official batch_norm is to build two graphs, one for train and one for evaluation, with `is_training=True` and `is_training=False`, respectively. In this way, you don't need to switch dynamically between train and evaluation. But this is a stupid way since you need to build more than one graph.\r\n\r\nFinally, I write a moving average by myself, and I find it worked! It's as follows(based on code on the web and modified by myself)\r\n\r\n```\r\ndef bn_layer(x, scope, is_training, epsilon=0.001, decay=0.99, reuse=None):\r\n    \"\"\"\r\n    Performs a batch normalization layer\r\n\r\n    Args:\r\n        x: input tensor\r\n        scope: scope name\r\n        is_training: python boolean value\r\n        epsilon: the variance epsilon - a small float number to avoid dividing by 0\r\n        decay: the moving average decay\r\n\r\n    Returns:\r\n        The ops of a batch normalization layer\r\n    \"\"\"\r\n    with tf.variable_scope(scope, reuse=reuse):\r\n        shape = x.get_shape().as_list()\r\n        # gamma: a trainable scale factor\r\n        gamma = tf.get_variable(\"gamma\", shape[-1], initializer=tf.constant_initializer(1.0), trainable=True)\r\n        # beta: a trainable shift value\r\n        beta = tf.get_variable(\"beta\", shape[-1], initializer=tf.constant_initializer(0.0), trainable=True)\r\n        moving_avg = tf.get_variable(\"moving_avg\", shape[-1], initializer=tf.constant_initializer(0.0), trainable=False)\r\n        moving_var = tf.get_variable(\"moving_var\", shape[-1], initializer=tf.constant_initializer(1.0), trainable=False)\r\n        if is_training:\r\n            # tf.nn.moments == Calculate the mean and the variance of the tensor x\r\n            avg, var = tf.nn.moments(x, np.arange(len(shape)-1), keep_dims=True)\r\n            avg=tf.reshape(avg, [avg.shape.as_list()[-1]])\r\n            var=tf.reshape(var, [var.shape.as_list()[-1]])\r\n            #update_moving_avg = moving_averages.assign_moving_average(moving_avg, avg, decay)\r\n            update_moving_avg=tf.assign(moving_avg, moving_avg*decay+avg*(1-decay))\r\n            #update_moving_var = moving_averages.assign_moving_average(moving_var, var, decay)\r\n            update_moving_var=tf.assign(moving_var, moving_var*decay+var*(1-decay))\r\n            control_inputs = [update_moving_avg, update_moving_var]\r\n        else:\r\n            avg = moving_avg\r\n            var = moving_var\r\n            control_inputs = []\r\n        with tf.control_dependencies(control_inputs):\r\n            output = tf.nn.batch_normalization(x, avg, var, offset=beta, scale=gamma, variance_epsilon=epsilon)\r\n\r\n    return output\r\n\r\n\r\ndef bn_layer_top(x, scope, is_training, epsilon=0.001, decay=0.99):\r\n    \"\"\"\r\n    Returns a batch normalization layer that automatically switch between train and test phases based on the \r\n    tensor is_training\r\n\r\n    Args:\r\n        x: input tensor\r\n        scope: scope name\r\n        is_training: boolean tensor or variable\r\n        epsilon: epsilon parameter - see batch_norm_layer\r\n        decay: epsilon parameter - see batch_norm_layer\r\n\r\n    Returns:\r\n        The correct batch normalization layer based on the value of is_training\r\n    \"\"\"\r\n    #assert isinstance(is_training, (ops.Tensor, variables.Variable)) and is_training.dtype == tf.bool\r\n\r\n    return tf.cond(\r\n        is_training,\r\n        lambda: bn_layer(x=x, scope=scope, epsilon=epsilon, decay=decay, is_training=True, reuse=None),\r\n        lambda: bn_layer(x=x, scope=scope, epsilon=epsilon, decay=decay, is_training=False, reuse=True),\r\n    )\r\n```\r\n    \r\nJust use the `bn_layer_top` function during building a graph, the is_training parameter is a `tf.placeholder`\r\n. Then you are free to switch the placeholder to True during train and False during evaluation, with `feed_dict`.\r\n\r\nHope it helps the community. ", "When you use slim.batch_norm,be sure to use \"slim.learning.create_train_op\" instead of \"tf.train.GradientDecentOptimizer(lr).minimize(loss)\" or other optimizer. Try it to see if it works! ", "@vincentvanhoucke You wrote in another post in this thread: \r\n\r\n> The slim batch_norm wrapper normalizes over the last dimension of your input tensor. So if it's a 2D input tensor coming from a fully connected layer, it normalizes over batch, and thus performs per-activation normalization. If it's a 4D tensor coming from a convolution, it will normalize over the three first dimensions (batch, width, depth), and thus perform per-feature normalization. @sguada maybe forth being a bit more descriptive about this.\r\n\r\nDo you mean with \"slim batch_norm wrapper\" the function `tf.contrib.layers.batch_norm`? If so, I would suggest to add this information to the documentation text of this function. Thus it gets very clear, that this function performs the batch normalization exactly like described in the paper... for both FC-Layer and Conv2D-Layer. At the moment there is only the text \"Can be used as a normalizer function for conv2d and fully_connected.\", where it is not clear if this is related to the normalization axis topic.", "@ZahlGraf I'll happily consider a PR that clarifies the documentation. We've been at this for so long that I no longer have a good sense of what's obvious or not, and would welcome clarifying documentation for someone with a fresh perspective on the topic.", "@vincentvanhoucke \r\nI created a PR with a more detailed description, mainly based on your statement in this thread:\r\nhttps://github.com/tensorflow/tensorflow/pull/15653", "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you.", "Please remove the assignee, as this issue is inviting external contributions. Otherwise, remove the `contributions welcome` label. Thank you.", "Closing this bug since the original request to add a batch norm layer has been addressed. Some of the more recent issues with documentation seem to have their own PRs\r\nIf you see any issue with batch_norm, please either ask a question on StackOverflow or open another issue."]}, {"number": 1121, "title": "AttributeError: 'module' object has no attribute 'gfile' in 0.7.0 [Fixed in source, will be in next binary release]", "body": "I'm on an Ubuntu machine, installed tensorflow and ran the image processing example as in the website but it failed complaining about gFile not found,\n\nHere's the exception stack:\n\n```\n    Traceback (most recent call last):\n      File \"classify_image.py\", line 213, in <module>\n        tf.app.run()\n      File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/default/_app.py\", line 30, in run\n        sys.exit(main(sys.argv))\n      File \"classify_image.py\", line 209, in main\n        run_inference_on_image(image)\n      File \"classify_image.py\", line 154, in run_inference_on_image\n        if not tf.gfile.Exists(image):\n    AttributeError: 'module' object has no attribute 'gfile'\n```\n", "comments": ["Same here, got this error when running cifar10_eval.py\n", "My guess is that you are running source code from HEAD with a pip install from 0.6.0.  Either check out the code at the same branch / tag as the pip install, or compile from sources at HEAD to use code at head.\n", "Let me check that, thanks for looking into it.\n", "I had the same problem executing the file classify_image.py. Changing the branch to 0.6.0 solved this problem. Thanks!\n", "@akhld @Kecksdose \n\nYes, using r0.7.0, and run\n$ cd tensorflow/models/image/mnist\n$ python convolutional.py\nwill have this problem.\n\nWhen changing to 0.6.0, no this problem.\n", "So the temporary fix for this is to use 0.6.0 for TensorFlow?\n", "Try upgrading to 0.7.1\npip uninstall tensorflow\npip uninstall protobuf\npip install path/to/0.7.1.wheel\n", "It works fine on 0.8\n", "Was with this error to run ptb_word_lm.py in the old version.\nReally, after upgrading worked properly \nthanks!\n"]}, {"number": 1120, "title": "use string::append to catenate strings", "body": "With VC++, when std::string is empty, there will be an error -- \"string iterator not dereferencable\" -- to use string::begin.\n\nAnd using raw pointer to manipulate std::string doesn't look like a good idea.\n", "comments": ["Can one of the admins verify this patch?\n", "Jenkins, test this please.\n", "@tensorflow-jenkins test this please\n", "(the branch has conflicts, can you address the conflict? we can take a look after that)\n", "@vrv The conflicts need to be resolved first before the tests can pass on Jenkins. The base is a few weeks old.\n", "My guess is we'll get to this as part of our Windows support.\n"]}]