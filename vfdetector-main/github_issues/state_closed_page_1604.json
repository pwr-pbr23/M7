[{"number": 4792, "title": "Branch 135327887", "body": "", "comments": ["@yifeif, thanks for your PR! By analyzing the history of the files in this pull request, we identified @charlesnicholson, @dsmilkov and @nsthorat to be potential reviewers.\n", "Closing this and re-push after ndlstm test dependency issue is fixed.\n"]}, {"number": 4791, "title": "libtensorflow.so target not public", "body": "Is there a particular reason that the libtensorflow.so target isn't public? I working on a tensorflow application in C++ and it would be nice to not have to link against tensorflow statically since that's taking ~6min for me.\n", "comments": ["@asimshankar might have details here.\n", "I don't think there is a good reason for the target to be private, can be made public.\nIf you'd like to send in a pull request, we'd be happy to merge it.\n\n(Out of curiosity: From your notes above, I gather that your project is also using bazel and you're using tensorflow as an external dependency?)\n", "Yes, I've got my project building with bazel and tensorflow is set up as a local_repository. \n\nIt seems the linking was taking a long time due to something about using the clang from Xcode 7.3 (which I need to use because of CUDA), and seems to have been fixed by passing compiler flag -fvisibility-inlines-hidden.\n", "Good to know, thanks.\n\nI'm going to close this issue out. If you, or anyone else, needs the visibility change for the .so file in the future, we can add it then. Feel free to re-open if you disagree :)\n\nThanks!\n"]}, {"number": 4790, "title": "iOS cannot run the new trained Inception v1 model <no registered kernels>", "body": "### Environment info\n\niOS\n### steps:\n\n1, i train inception v1 (slim) on a subset of ImageNet dataset (269 of 1000)\n2, convert .ckpt into .pb by freeze_graph\n3, convert .pb file into 8bit precision\n4, load into iOS and run\n### Logs\n\nsimple/RunModelViewController.mm:222] Running model failed: Invalid argument: **No OpKernel was registered to support Op 'RandomUniform' with these attrs.  Registered kernels:**\n\n <**no registered kernels**>\n\n[[Node: InceptionV1/Logits/Dropout_0b/dropout/random_uniform/RandomUniform = RandomUniform[T=DT_INT32, _output_shapes=[[128,1,1,1024]], dtype=DT_FLOAT, seed=0, seed2=0](InceptionV1/Logits/Dropout_0b/dropout/Shape)]]\n\nI tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: \"ArgMin\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_INT32 } } } host_memory_arg: \"dimension\"')\n\nI tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: \"ArgMin\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: \"dimension\"')\n\nI tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: \"ArgMax\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_INT32 } } } host_memory_arg: \"dimension\"')\n\nI tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: \"ArgMax\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: \"dimension\"')\n\nI tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: \"AvgPoolGrad\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: \"orig_input_shape\"')\n\nI tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: \"BatchNormWithGlobalNormalizationGrad\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_FLOAT } } }')\n\nI tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: \"BroadcastGradientArgs\" device_type: \"GPU\" host_memory_arg: \"s0\" host_memory_arg: \"s1\" host_memory_arg: \"r0\" host_memory_arg: \"r1\"')\n\nI tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: \"BroadcastGradientArgs\" device_type: \"CPU\" host_memory_arg: \"s0\" host_memory_arg: \"s1\" host_memory_arg: \"r0\" host_memory_arg: \"r1\"')\n\nI tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: \"BiasAddGrad\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_INT32 } } }')\n\nI tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: \"BiasAddGrad\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_FLOAT } } }')\n\nI tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: \"BiasAddV1\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_INT32 } } }')\n\nI tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: \"BiasAddV1\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_FLOAT } } }')\n\nI tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: \"CheckNumerics\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_FLOAT } } }')\n\nI tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: \"ConcatOffset\" device_type: \"GPU\" host_memory_arg: \"concat_dim\" host_memory_arg: \"shape\" host_memory_arg: \"offset\"')\n\nI tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: \"ConcatOffset\" device_type: \"CPU\"')\n\nI tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: \"Concat\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_INT32 } } } host_memory_arg: \"concat_dim\"')\n\nI tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: \"Concat\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_FLOAT } } } host_memory_arg: \"concat_dim\"')\n\nI tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: \"Concat\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_QUINT8 } } } host_memory_arg: \"concat_dim\"')\n\nI tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: \"Concat\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_QINT8 } } } host_memory_arg: \"concat_dim\"')\n\nI tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: \"Concat\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_QUINT16 } } } host_memory_arg: \"concat_dim\"')\n\nI tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: \"Concat\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_QINT16 } } } host_memory_arg: \"concat_dim\"')\n\nI tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: \"Concat\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_QINT32 } } } host_memory_arg: \"concat_dim\"')\n\nI tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: \"Concat\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_BFLOAT16 } } } host_memory_arg: \"concat_dim\"')\n\nI tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: \"Placeholder\" device_type: \"GPU\"')\n\nI tensorflow/core/framework/op_kernel.cc:802] OpKernel ('op: \"Placeholder\" device_type: \"CPU\"')\n", "comments": ["i do not know why the .pb file, which i download from the link below, convert into 8bit only take 4M, but my trained inception v1 model .pb file convert to 8bit takes 6.5M. \n\nhttps://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip\n\nBTW, **freeze_graph** already move out unused nodes for prediction phase, is that right? \n\nThe .ckpt file size I get is 23.6M but .pb file size is 24M. it seems remove nothing.\n\ndropout should not be in the prediction phase, but i can see dropout in error log.\n", "freeze_graph will not remove any nodes. For that you need [optimize_for_inference.py](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/optimize_for_inference.py) (or strip_unused, but I believe that is deprecated now).\n", "@petewarden Is there any reason to keep strip_unused around now that you've added optimize_for_inference?\n", "@andrewharp No, I don't think it is useful, so it might make things less confusing to remove strip_unused.\n", "@andrewharp I try  optimize_for_inference.py, But it seems that the issue is still there.\n\n1, I freeze the .ckpt file into .pb file, which size is 24M\n2, run optimize_for_inference.py to ouput a new file. This new .pb file is 23.9M, which means very limited nodes are removed, as size drop 0.1M.\n3, convert this .pd file into 8bit file, which size is 6.5M as well.\n4, load into iOS and run. the error is the same:\n\nNo OpKernel was registered to support Op 'RandomUniform' with these attrs. Registered kernels\n\n<no registered kernels>\n\nThe current iOS example for inception v1 model should be different from what we trained from PC. I can judge this solely by the file size. Does google plan to provide the instruction about how the other developers to convert the models, which are trained on GPU or CPU into iOS? Now we can only use the inception v1 model from iOS example, which is for ImageNet 1000 classes.\n", "I'm surprised to see RandomUniform used in an inference graph. I believe you might need to set training=False when you create your model to get rid of ops like dropout that might use this, but I'm cc-ing @sguada since I'm hoping he might have some ideas on this?\n", "I just set --training=False for **optimize_for_inference.py** script, but the output file size is still 23.9M\n", "The output file size isn't significant. Most of the space is taken up by a few large weight parameter sets, so a lot of nodes can be removed without it changing the length significantly. Does the resulting model still fail with the same error?\n", "I just carefully review the script **optimize_for_inference.py**. It seems that there is no parameter for  --training=False/True. I cann't see this parameter. only 4 parameters below:\n\n--input=frozen_inception_graph.pb \\ \n--output=optimized_inception_graph.pb \\ \n--input_names=Mul \\ \n--output_names=softmax \n", "It's a parameter for the slim training library. I don't know the details, but I've seen it show up in similar issues, so I cc-ed @sguada for more info.\n", "Is there any update on this issue?\n", "No, I'm awaiting response from @sguada on the slim question.\n", "To get the version of the graph for inference, just built the network passing is_training=False.\n\nhttps://github.com/tensorflow/tensorflow/blob/754048a0453a04a761e112ae5d99c149eb9910dd/tensorflow/contrib/slim/python/slim/nets/inception_v1.py#L248\n", "The folder i use is from **Model** folder for inception v1.\n\nhttps://github.com/tensorflow/models/tree/master/slim \n\nbut not **contrib** folder below\n\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/slim/python/slim\n\nI think they should be the same, is that right?\n\nSo i should change **is_training=True** to **False** of the line below for training. correct me if wrong.\n\nhttps://github.com/tensorflow/models/blob/master/slim/train_image_classifier.py#L424\n", "I get new error on iOS: for **'FIFOQueue'** \n\nCould not create TensorFlow Graph: Invalid argument: No OpKernel was registered to support Op 'FIFOQueue' with these attrs.  Registered kernels:\n\n  <no registered kernels>\n\n[[Node: prefetch_queue/fifo_queue = FIFOQueue[_output_shapes=[[2]], capacity=2, component_types=[DT_FLOAT, DT_FLOAT], container=\"\", shapes=[[128,224,224,3], [128,269]], shared_name=\"\"]()]]\n\nF /Users/Bonan1/tensorflow/tensorflow/contrib/ios_examples/camera/CameraExampleViewController.mm:392] Couldn't load model: Invalid argument: **No OpKernel was registered to support Op 'FIFOQueue' with these attrs.**  Registered kernels:\n\n  <no registered kernels>\n", "If Google publish a tensorflow iOS version is only want to prove that tensorflow **could** run under iOS, but not want to support iOS strategically, since iOS is from Apple, then it should clearly point out on the website that Only the published iOS example works on iOS, but not any other new user defined model, even for inception v1.\n", "Pixel can beat iPhone? Maybe...\n", "There's a guide to preparing models for mobile devices here:\nhttps://petewarden.com/2016/09/27/tensorflow-for-mobile-poets/\nThe problem you're hitting (which is true across both Android and iOS versions) is that only certain ops are included in the library by default:\n\n> Mobile devices have limited amounts of memory, and apps need to be downloaded, so by default the iOS version of TensorFlow only includes support for operations that are common in inference and don\u2019t have large external dependencies. You can see the list of supported ops in the tensorflow/contrib/makefile/tf_op_files.txt file.\n\nIn this case, using a FifoQueue op for inference doesn't make much sense, so I believe you should be able to fix it by running the optimize_for_inference script as described in the tutorial. The tricky part will be figuring out the correct input and output node names for the model, but you'll need those when you run it, so hopefully you have them already.\n", "How do I know why there is a **FifoQueue** in inception v1 mode? \n\nWhat I use is exactly the guideline on the Tensorflow website and the info from @sguada above. I only train a subset (269 of 1000) of ImageNet dataset on inception v1 slim model and set **--is_training=False** as provided by @sguada. It is supposed to remove all training nodes from **graph.pbtxt**, which are not used for inference phase.\n\nHowever, after I get .ckpt files and freeze the graph to deploy to iOS device, it still does not work. I meet new error: **No OpKernel was registered to support Op 'FIFOQueue' with these attrs.**\n\nI can't see any **Official Guideline** on Tensorflow website about how to **REPRODUCE** that inception v1 model .pb file for iOS. It is all about **\"CAN DO\",** but not **\"HOW TO DO\".**  The key step is skipped. So how do you let other one to believe Tensorflow is a really **OPEN** framework? **\n\nWe can't develop an app that one feature only support Android, but not support iOS. If only one works, then we will drop all. A global view is critical. \n\nI do not believe any developer will drop iOS platform just become android support Deep Learning model. I really feel that some tensorflow strategy makers are very **\u5c0f\u5bb6\u8d25\u6c14**\n", "@sguada do you mean I run twice? Run once with **is_training=False** to get a graph def just for inference nodes purpose (stop the process once I get this file), because if I set **is_training=False**, the loss do not goes down, which means the network does not converge.\n\nafter I get the graph def file for inference nodes, I still need use the .ckpt file which is created under **is_training=True**, since this .ckpt file contains the correct values for weights.\n\nI use the graph def under **is_training=False** combine with .ckpt file under **is_training=True** to  get a freeze graph. Is that right?\n", "I already modify the code of **retrain.py** to support Inception V1 model. I will check in and share with community.\n", "I'm running into this issue on desktop - running optimize_for_inference drastically changes my model size, but it also appears to change the output tensors names, even if I specify the input and output tensors Im interested in the script.\r\n\r\nI understand that optimize_for_inference changes the graph, but should the i/o node names not stay the same since, well, you're asking the script to do so?\r\n\r\nApologies for poking at a closed issue, trying to wrap my head around this.\u00a0\r\n\r\nSpecifics are here: http://stackoverflow.com/questions/40747431/running-optimize-for-inference-on-inceptionv1-results-in-different-output-tensor", "I made a model, froze it, optimized for inference, yet I'm getting an error message about FIFOQueue on iOS\r\n\r\n\"Could not create TensorFlow Graph: Invalid argument: No OpKernel was registered to support Op 'FIFOQueue' with these attrs. Registered devices: [CPU], Registered kernels: <no registered kernels>\r\n[[Node: fifo_queue = FIFOQueue[capacity=30, component_types=[DT_FLOAT, DT_FLOAT, DT_FLOAT], container=\"\", shapes=[[640,480,3], [300,1,2], [300,1,4]], shared_name=\"\"]()]]\"\r\n\r\nI even tried setting is_training=False in tensorflow/contrib/slim/python/slim/nets/inception_v1.py before training and getting my input_graph.pb\r\n\r\nDid you ever find a solution @civilman628 ?   Or is FIFOQueue not supported in TensorFlow for iOS?    \r\n\r\n \r\n\r\n", "First, Google does not plan to support iOS well. Tensorflow is a very sham open source project. They let users to help them test and find bugs only, but not wish fully support if you meet problems.\r\n\r\nYou can see my code in #7172 about how to get .pbtxt file and freeze the models in .pb files like inception v1-v4 and inception_resnetv2...  The first node is \"Placeholder\", which accept a image, like [1,224,224,3] but not FIFOQueue anymore.\r\n\r\nI already load **inception v2** into iOS device. You may meet the issue like #5764. just update one line code can fix the issue.\r\n\r\n\r\n", "I added \"tensorflow/core/kernels/fifo_queue_op.cc\" to tensorflow/contrib/makefile/tf_op_files.txt then ran compile_ios_tensorflow.sh .  It seems to have done the trick.", "this way will retain many unnecessary nodes, which are not needed for inference phase. you can print out the nodes to see. ", "The bottom line is that android and ios have a subset of all ops. They need to be stripped down to have smaller binaries. Our engineers use TensorFlow for Android and IOS apps, but the process of stripping a model is currently not as easy as we would like. @civilman628, do you have any idea to contribute on how to make this process better? If not, you could certainly submit a pull request to improve the documentation. Adding all <op>.cc's to the Makefile in the limit would end up with all the ops in every ios binary.\r\n\r\n@petewarden, do you have anything to add?", "@aselle  There is no document about how you make this file: \r\nhttps://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip\r\n\r\nAs I said previously, we can't reproduce it. only a fixed model, which can predict 1000 classes is useless.", "If we can only use one demo on iOS, but can't create our own model, then it is meaningless. ", "see my solution on #4766 for retrain V1 model.", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activityand the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Hi,\r\nI am new to this issue. \r\nI want to serialize my Resnet101 based model.\r\nI am using the script optimize_for_inference.py, I don't know how to edit this script for Resnet101 model.\r\nWhen I run this script, I get the following errors: \r\n\r\n```\r\n/home/arun/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\r\n  from ._conv import register_converters as _register_converters\r\nTraceback (most recent call last):\r\n  File \"optimize_for_inference.py\", line 146, in <module>\r\n    app.run(main=main, argv=[sys.argv[0]] + unparsed)\r\n  File \"/home/arun/anaconda3/lib/python3.6/site-packages/tensorflow/python/platform/app.py\", line 124, in run\r\n    _sys.exit(main(argv))\r\n  File \"optimize_for_inference.py\", line 90, in main\r\n    FLAGS.output_names.split(\",\"), FLAGS.placeholder_type_enum)\r\n  File \"/home/arun/anaconda3/lib/python3.6/site-packages/tensorflow/python/tools/optimize_for_inference_lib.py\", line 109, in optimize_for_inference\r\n    placeholder_type_enum)\r\n  File \"/home/arun/anaconda3/lib/python3.6/site-packages/tensorflow/python/tools/strip_unused_lib.py\", line 83, in strip_unused\r\n    raise KeyError(\"The following input nodes were not found: %s\\n\" % not_found)\r\nKeyError: \"The following input nodes were not found: {'input'}\\n\"\r\n```\r\nI want to make this script work to serialize my Resnet model. I need help, if someone can help me.\r\n\r\nKind Regards\r\nArun", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging Awaiting TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Nagging TensorFlower: It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 4789, "title": "Overwrite the target file in HDFS Rename operation; it removes the ta\u2026", "body": "\u2026rget file first if it exists.\n\nChange: 134682344\n", "comments": ["@jhseu, thanks for your PR! By analyzing the history of the files in this pull request, we identified @keveman, @tensorflower-gardener and @vrv to be potential reviewers.\n"]}, {"number": 4788, "title": "Update link to doc for linux.", "body": "Update link to doc for linux.\n", "comments": ["@johmathe, thanks for your PR! By analyzing the history of the files in this pull request, we identified @vrv, @jendap and @victorhcm to be potential reviewers.\n", "Can one of the admins verify this patch?\n", "Thanks @johmathe for fixing the link!\n"]}, {"number": 4787, "title": "Typo in the README file", "body": "Typo in the README file.\n", "comments": ["@johmathe, thanks for your PR! By analyzing the history of the files in this pull request, we identified @vrv, @jendap and @victorhcm to be potential reviewers.\n", "Can one of the admins verify this patch?\n", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit https://cla.developers.google.com/ to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If you signed the CLA as a corporation, please let us know the company's name.\n\n<!-- need_sender_cla -->\n"]}, {"number": 4786, "title": "Branch 135176011", "body": "", "comments": []}, {"number": 4785, "title": "test", "body": "NOTE: Only file GitHub issues for bugs and feature requests.  All other topics will be closed.\n\nFor general support from the community, see [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\nTo make bugs and feature requests more easy to find and organize, we close issues that are deemed\nout of scope for GitHub Issues and point people to StackOverflow.\n\nFor bugs or installation issues, please provide the following information.\nThe more information you provide, the more easily we will be able to offer\nhelp and advice.\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\n### Environment info\n\nOperating System:\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\nIf installed from binary pip package, provide:\n1. A link to the pip package you installed:\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\nIf installed from source, provide \n1. The commit hash (`git rev-parse HEAD`)\n2. The output of `bazel version`\n### If possible, provide a minimal reproducible example (We usually don't have time to read hundreds of lines of your code)\n### What other attempted solutions have you tried?\n### Logs or other output that would be helpful\n\n(If logs are large, please upload as attachment or provide link).\n", "comments": []}, {"number": 4784, "title": "Cannot compile with \"-mavx\"", "body": "I tried to compile tensorflow 0.10 with avx support. The command I used is \n`bazel build -c opt --copt=-mavx //tensorflow/tools/pip_package:build_pip_package`. \nHowever bazel output errors\n\n```\n...\nERROR: /home/oci/yfu/tensorflow_xeonphi/tensorflow/core/kernels/BUILD:1210:1: C++ compilation of rule '//tensorflow/core/kernels:batch_matmul_op' failed: gcc failed: error executing command /opt/rh/devtoolset-4/\nroot/usr/bin/gcc -U_FORTIFY_SOURCE '-D_FORTIFY_SOURCE=1' -fstack-protector -Wall -Wl,-z,-relro,-z,now -B/opt/rh/devtoolset-4/root/usr/bin -B/usr/bin -Wunused-but-set-parameter ... (remaining 105 argument(s) skip\nped): com.google.devtools.build.lib.shell.BadExitStatusException: Process exited with status 1.\n...\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/GenericPacketMath.h:222:1: note:   template argument deduction/substitution failed:\nIn file included from external/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/Core:442:0,\n                 from external/eigen_archive/unsupported/Eigen/CXX11/Tensor:14,\n                 from ./third_party/eigen3/unsupported/Eigen/CXX11/Tensor:1,\n                 from ./tensorflow/core/kernels/batch_matmul_op_impl.h:21,\n                 from tensorflow/core/kernels/batch_matmul_op_real.cc:16:\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/ProductEvaluators.h:648:24: note:   cannot convert '0' (type 'int') to type 'const type& {aka const Eigen::half&}'\n     res = pset1<Packet>(0);\n                        ^\n```\n\nThe latest Eigen library seems to have explicit type conversion [here](https://github.com/RLovelett/eigen/blob/master/Eigen/src/Core/ProductEvaluators.h#L660)\nI compiled tensorflow with gcc 5.2.1 on CentOS 7.\nThere is a related Stackoverflow [question](http://stackoverflow.com/questions/38493835/tensorflow-avx-support) but no response on why the compilation is failed. \n", "comments": ["If this is related to #4775 please close it.\n", "@larry-fuy I think that your question isn's same with me.\n\nHave you ever built tensorflow r0.11rc0 version with avx support?\nWhen I built many tensorflow version(r0.9, r0.10rc0, r0.10, r0.11rc0), only tensorflow r0.10 had avx error. So, I suggest that you try to build other version.\n\nIn addition, If your machine is Intel Haswell, try to type '--copt=-mavx2' instead of '--copt=mavx' and before you build, please type 'bazel clean'.\n", "@sjlee7748 Thanks for suggestions. Actually I compiled the source code from master branch and assume it should be the latest version of 0.11. Sorry forget mention this in my post. I'll try other versions on your suggestions. \nCurrently I worked on a KNL machine and will try avx512 finally.\nI'll close this issue and switch to see #4775.\n"]}, {"number": 4783, "title": "Fix: Update nightly links in readme.md.", "body": "", "comments": ["@gunan, thanks for your PR! By analyzing the history of the files in this pull request, we identified @keveman, @vrv and @ebrevdo to be potential reviewers.\n"]}, {"number": 4782, "title": "tf.decode_raw should support tf.float16", "body": "Hi!\n\nIt should be trivial to add, I guess.\n", "comments": ["Test2\n", "Hi, @benoitsteiner it looks add `Eigen::half` in `decode_raw_op.cc` should be enough?\n\n```\ndiff --git a/tensorflow/core/kernels/decode_raw_op.cc b/tensorflow/core/kernels/decode_raw_op.cc\nindex d3bd991..280c2dc 100644\n--- a/tensorflow/core/kernels/decode_raw_op.cc\n+++ b/tensorflow/core/kernels/decode_raw_op.cc\n@@ -93,6 +93,7 @@ class DecodeRawOp : public OpKernel {\n       Name(\"DecodeRaw\").Device(DEVICE_CPU).TypeConstraint<type>(\"out_type\"), \\\n       DecodeRawOp<type>)\n\n+REGISTER(Eigen::half);\n REGISTER(float);\n REGISTER(double);\n REGISTER(int32);\n```\n", "You also need to update the op registration code in tensorflow/core/ops/parsing_ops.cc to declare that is now supports outputing half floats.\n", "Last but not least, I strongly encourage you to add a regression test to cover the float16 case in tensorflow/python/kernel_tests/decode_raw_op_test.py\n", "@benoitsteiner Many thanks! Let me try to fix it.\n"]}, {"number": 4781, "title": "`tf.scan` has Unexpected Behavior on Python CLI/Shell", "body": "### Version Info\n\n'0.10.0rc0'\nOS: Ubuntu\n### Issue\n\nWhile this doesn't affect runtime behavior, using the high level function `tf.scan` in the python shell results in unexpected behavior. Running the op whilst functional yields expected results. Running again with bad parameters (wrong dtype) raises exception, which is also expected. Running the original op again raises the same exception, which is not expected.\n### To Reproduce\n\nVia python CLI, run a working `tf.scan` function, run one that doesn't work, then run the original.\n\n```\n>>> import tensorflow as tf\n\n>>> tf.Session().run(tf.scan(lambda a, x: [a[0] + 1, tf.to_int64(0)], tf.constant([1,2,3,4,5],dtype=tf.int64), initializer=[tf.to_int64(-1), tf.to_int64(0)]))\n\n[array([0, 1, 2, 3, 4]), array([0, 0, 0, 0, 0])]\n\n>>> tf.Session().run(tf.scan(lambda a, x: [1, tf.to_int64(0)], tf.constant([1,2,3,4,5],dtype=tf.int64), initializer=[tf.to_int64(-1), tf.to_int64(0)]))\nE tensorflow/core/client/tensor_c_api.cc:485] Input 1 of node scan_1/while/Merge_1 was passed int32 from scan_1/while/NextIteration_1:0 incompatible with expected int64.\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 382, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 655, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 723, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 743, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.InvalidArgumentError: Input 1 of node scan_1/while/Merge_1 was passed int32 from scan_1/while/NextIteration_1:0 incompatible with expected int64.\n\n>>> tf.Session().run(tf.scan(lambda a, x: [a[0] + 1, tf.to_int64(0)], tf.constant([1,2,3,4,5],dtype=tf.int64), initializer=[tf.to_int64(-1), tf.to_int64(0)]))\nE tensorflow/core/client/tensor_c_api.cc:485] Input 1 of node scan_1/while/Merge_1 was passed int32 from scan_1/while/NextIteration_1:0 incompatible with expected int64.\nTraceback (most recent call last):\n  File \"<stdin>\", line 1, in <module>\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 382, in run\n    run_metadata_ptr)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 655, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 723, in _do_run\n    target_list, options, run_metadata)\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.py\", line 743, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.InvalidArgumentError: Input 1 of node scan_1/while/Merge_1 was passed int32 from scan_1/while/NextIteration_1:0 incompatible with expected int64.\n```\n", "comments": ["I can reproduce the behavior, and it seems like a bug to me.  @ebrevdo might have some thoughts.\n", "There are two problems:\n1. always create all your nodes before passing them to session.run.  even if it's a new local session.  strange things can happen if you don't.  this is because when you call session.run, it serializes your graph; and if you add new nodes after this, it'll serialize more of the graph and upload that.  but sometimes it'll still use some cached nodes.  @yuanbyu this may be a bug here.\n2. this code:\n\n```\ntf.Session().run(tf.scan(lambda a, x: [1, tf.to_int64(0)], tf.constant([1,2,3,4,5],dtype=tf.int64), initializer=[tf.to_int64(-1), tf.to_int64(0)]))\n```\n\nis incorrect: replace the body with `[tf.to_int64(1), tf.to_int64(0)]` and it'll work.\n\nto summarize:\n\n```\ntf.Session().run(tf.scan(lambda a, x: [1, tf.to_int64(0)], tf.constant([1,2,3,4,5],dtype=tf.int64), initializer=[tf.to_int64(-1), tf.to_int64(0)]))\n...\nInvalidArgumentError: Input 1 of node scan/while/Merge_1 was passed int32 from scan/while/NextIteration_1:0 incompatible with expected int64.\n\n\ntf.reset_default_graph()\n\ntf.Session().run(tf.scan(lambda a, x: [tf.to_int64(1), tf.to_int64(0)], tf.constant([1,2,3,4,5],dtype=tf.int64), initializer=[tf.to_int64(-1), tf.to_int64(0)]))\n\n[array([1, 1, 1, 1, 1]), array([0, 0, 0, 0, 0])]\n```\n\nbut really, it's not idiomatic to create new sessions and immediately add new nodes to them and execute at the same time.  create your nodes first, and when you're done execute all your session.run calls.\n", "Ah, thanks for the response! That's generally the way I go about my sessions with the exception of fooling around in the Python shell, but good to know the possible cause of this.\n"]}, {"number": 4780, "title": "contrib/quantization: Do not open dot file in binary mode", "body": "The Python 3 documentation states:\n\nSince printed arguments are converted to text strings,\nprint() cannot be used with binary mode file objects.\n", "comments": ["Can one of the admins verify this patch?\n", "@olesalscheider, thanks for your PR! By analyzing the history of the files in this pull request, we identified @petewarden to be a potential reviewer.\n", "@tensorflow-jenkins test this please.\n", "Thanks @olesalscheider !\n"]}, {"number": 4779, "title": "Accessing data for post-processing on the GPU without transfer to host", "body": "In TensorFlow's C++ API, after the session Run has been completed, is it possible to access the data while it's still on the GPU?\nI would like to do post-processing on the GPU with the output of TensorFlow. \n\nCurrently the output is sent back to the host and I will have to move it back to the GPU for post-processing. This data transfer is something that I am looking to avoid. \n", "comments": ["@zheng-xq probably has advice here (thanks XQ!)\n", "In general, all TensorFlow intermediate tensors disappear after a run, except: \n1. If you put it in a Variable, and mark it \"trainable=False\". I would recommend this for now. \n2. Push into a queue. However, the current queue implementation doesn't work with GPU yet. There are design discussion to change that. \n3. A semi-experimental feature called partial_run. Only touch this if you feel very brave. :) https://github.com/tensorflow/tensorflow/blob/2098b9abcf20d2c9694055bbfd6997bc00b73578/tensorflow/python/client/session_test.py#L1285\n", "Also\n4. Persistent Tensors. If you execute `GetSessionHandle` op on a tensor, this data will persist after the session run call has terminated, until session is reset, or someone calls `DeleteSessionTensor`\n", "Thank you @zheng-xq  and @yaroslavvb for your suggestions.\nI wanted to break it down a bit more to understand the steps better.\n1. Create new tensors input and output (on host)\n2. Load Graph \n3. Run session (on GPU)\n4. Output tensor with the output is now on the host. This is presumably after it was copied from the GPU and has now been deleted on the GPU\n\nIf I chose to do either a \"trainable=False\" approach or use GetSessionHandle, is there a way I can get a pointer to the tensor or data that's still on the GPU? \nMy objective is to pass the output tensor, which has a segmented image, to a CUDA kernel directly for post-processing. \n", "Was there any resolution on this issue?", "Every couple of months someone asks how to get a hold of GPU data (no copy) initialized by TensorFlow, or give TensorFlow GPU data initialized by someone else, and I haven't seen any solution (latest q was https://github.com/tensorflow/tensorflow/issues/6955#issuecomment-273828989)", "Latest official word is that it's not supported: https://github.com/tensorflow/tensorflow/issues/2210#event-706768999", "Assigning to @aselle for visibility. Feel free to close if indeed that's the official word.", "Not sure if it's related, but how does the Unified Memory Access feature of CUDA play a role in this? It would be nice if we just return a memory slice to user, with a tag specifying it on device or main memory.", "There's no UVM integration into TensorFlow, see https://github.com/tensorflow/tensorflow/issues/3678#issuecomment-238064949 for rationale", "Any update on this issue? I'm looking for a way to speed up inference moving pre and post processing of input and output of U-Net into GPU memory using OpenCV with CUDA build + Tensorflow C API. DtoH and HtoD memory operations eat all performance advantage of OpenCV CUDA image processing."]}, {"number": 4778, "title": "Initial support for building TensorFlow on Windows (#17).", "body": "This PR contains an initial version of support for building TensorFlow\n(CPU only) on Windows using CMake. It includes documentation for building\nwith CMake on Windows, platform-specific code for implementing core functions\non Windows, and CMake rules for building the C++ example trainer\nprogram and a PIP package (Python 3.5 only). The CMake rules support building\nTensorFlow with Visual Studio 2015.\n\nWindows support is a work in progress, and we feedback and contributions from\nthe community.\n\nFor full details of the features currently supported and instructions for\nhow to build TensorFlow on Windows, please see the file\n`tensorflow/contrib/cmake/README.md`.\n", "comments": ["@mrry, thanks for your PR! By analyzing the history of the files in this pull request, we identified @ebrevdo, @vrv and @aselle to be potential reviewers.\n", "Looks like our other platforms and build systems pull in more `core/platform` subdirectories than they should. I'll work on a fix.\n", "when can tf support windows with GPU ?\n"]}, {"number": 4777, "title": "bug fix when iterators stops at multiple of batch_size", "body": "In contrib.learn framwork,  `Estmator.fit()` supports `x`, `y` and `batch_size` arguments where `x` and `y` could be iterators/generators. However, when iterator finishes right at the edge, after exactly integer multiple of batch_size, a run is made anyway with batch_size = 0. This causes NaN errors with following code snippet. \n\n[Gist Link](https://www.google.com/url?q=https%3A%2F%2Fgist.github.com%2Fabhitopia%2Fb6b60cb8bf9bab58a78b221fb3c4473b&sa=D&sntz=1&usg=AFQjCNEgS-muOb4Z0UC3SDBQ-F5KcfBMbQ) - to reproduce error.\n\nFor more information on the issue see\n[Tensorflow google group discussion](https://groups.google.com/a/tensorflow.org/forum/#!topic/discuss/ZEzEa1TyYuE)\n\nSimply skipping session.run when feed_dict is empty solves the problem.\n", "comments": ["Can one of the admins verify this patch?\n", "@abhitopia, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener, @martinwicke and @ilblackdragon to be potential reviewers.\n", "Thanks for sending a PR!\n\nI think this is the wrong place to fix this. Instead, I think there is a bug in `StreamingDataFeeder`, `data_feeder.py` around line 510. \n", "@martinwicke  - Thanks for pointing out, please check new commits and let me know if that makes sense.\n", "This is the right change. Just a few small comments.\n", "Jenkins, test this please\n"]}, {"number": 4776, "title": "Fix python3 encoding issue with data format string", "body": "This fixes the python 3 issue found by @gunan in #4411.\n", "comments": ["Can one of the admins verify this patch?\n", "@admcrae, thanks for your PR! By analyzing the history of the files in this pull request, we identified @jhseu, @keveman and @tensorflower-gardener to be potential reviewers.\n", "Thanks @admcrae! @tensorflow-jenkins test this please.\n", "Thank you very much for the Fix @admcrae !\n"]}, {"number": 4775, "title": "Compile tensorflow with compile option \"-xMIC-AVX512\" does not work", "body": "Hi, All\n\nI want to use AVX512 with tensorflow because vectorization can increase performance.\nIn addition, building any program with icpc(Intel compiler) and compile option \"-xMIC-AVX512\" can vectorize automatically in state-of-art Intel machine.\nSo, I use the command as below:\n\n`CC=icpc bazel build -c opt --copt=-xMIC-AVX512 //tensorflow/tools/pip_package:build_pip_package`\n\nBut when I type the command, build does not work.\n### What related GitHub issues or StackOverflow threads have you found by searching the web for your problem?\n- Nothing exist related my issue in GitHub or StackOverflow\n### Environment info\n- Operating System: Centos 7.2.1511 \n- Tensorflow version: r0.10.0 source code version\n- Only use CPU\n### What other attempted solutions have you tried?\n\nAs far as I know, linear algebra library for Tensorflow is \"Eigen library\" and SIMD vectorizations(like SSE, AVX, etc.) are applied to the Eigen library.\nSo, I changed Eigen source code to apply the AVX512 and gcc compile option \"-mavx512f\" referring two links([eigen bug report](http://eigen.tuxfamily.org/bz/show_bug.cgi?id=1306), [Benoit Steiner's Bitbucket](https://bitbucket.org/benoitsteiner/eigen-avx512)), but I didn't apply AVX512 because there was little information about that.\n\nIf someone know the method about applying AVX512 or the date to release Eigen version with AVX512,  please tell me about that.\n\nThank you very much.\n", "comments": ["Few months ago I was able to compile tf for knl with gcc 6.1.0 and some gcc patches. But in the end I was unable to get good performance. I used good flags but seems like poor vectorization.\n\nSomebody can add more info on this?\n", "BTW, I ran all the tf tests under avx2 about 12 months ago, and there were several ops which gave incorrect answers or failed (alignment problems). At that point @benoitsteiner has fixed them in Eigen, but I'm not sure anyone tried testing advanced flags since then (it's not part of CI pipeline for sure), so there's a chance you get unexpected/incorrect results even if you make things compile\n", "Support for AVX512 in TensorFlow is still a work in progress. I'll link to the relevant code changes as we make them to keep everyone updated.\n", "@tripiana @yaroslavvb thank you for your interest in my question :) \n@benoitsteiner I'm really happy to hear that. If you don't mind, would you tell me  approximate date(e.g. about a month) to link the relevant code? Thank you so much!\n", "@benoitsteiner Is it still going on? I waited until a month but  I don't have any information about that. I am very appreciated if you tell me the progress, Thank you!\n", "The code that adds support for AVX512 to Eigen is pending a review before I can merge it (https://bitbucket.org/eigen/eigen/pull-requests/235). Once it's in I'll update TensorFlow to make use of the new capability.\n", " I think It's almost finished. Thank you for your support.\n", "Just to confirm, is it safe to compile with avx2 or not? @yaroslavvb was mentioning possible bugs / numerical errors.\n", "@benoitsteiner I'm keen to test this. Are you planning to update TensorFlow soon? Thanks.\n", "@alquraishi  - it should be safe to run with avx2, yes.  (Run the tests to be sure, of course, but it gets routinely used.)\r\n\r\nNote that in general, -mavx will probably get you a lot of the performance boosts, since what avx2 adds over avx is primarily integer support, and -mavx already has the wider vector float support.  I haven't surveyed it, but -mavx is used widely.  But you're safe using -mavx2 if you have it.", "Does Eigen support AVX512 in tf now ?", "@benoitsteiner  Hi, this command \"CC=icpc bazel build -c opt --copt=-xMIC-AVX512 //tensorflow/tools/pip_package:build_pip_package\" still can't be applied on KNL server. Is the new tensorflow merged?", "@yaroslavvb Hi,I can't even build with icpc as:\"CC=icpc bazel build -c opt  //tensorflow/tools/pip_package:build_pip_package\".  Can you give some help?", "@craftlk I overwrite the CROSSTOOL under subdir in `bazel-tensorflow` and that worked.\r\nBy the way  eigen said that they support AVX-512 now(Eigen3.3.0/Tensorflow0.11+/require `--copt='-DEIGEN_ENABLE_AVX512`)\r\nOn the other hand @benoitsteiner implemented the AVX-512 support for Fixedpoint last week. However, due to the use of AVX-512 DQ in that part, that implement cannot compiling on KNL.", "@c0710204 Hi, I want to know detailed information about how you compile tensorflow with AVX 512.\r\nWhen I used option '--copt=-DEIGEN_ENABLE_AVX512', compiling the source code is okay, but there was no speedup. (I think the option was not applied)\r\nSo, I want to know what is your version of tensorflow and compiling command.\r\nAdditionally, If you use further action, please tell me about that.\r\n\r\nThank you.", "@sjlee7748 Do you also add the  the avx512 compile flag like \u2018--copt=\u201c-mavx512f\u201d'?  You can add macro to Eigen code to check it worked or not. The version I used is before the avx-512 Fixedpoint function add into the tensorflow(because I used the Xeon-phi when i build) \r\nThe command I used is \r\n```bash\r\nbazel build --ignore_unsupported_sandboxing -c opt //tensorflow/tools/pip_package:build_pip_package  --copt \"-mavx512f\" --copt \"-mavx512cd\" --copt \"-mavx512er\" --copt \"-mavx512pf\" --copt \"-mavx2\" --copt \"-fopt-info-vec-all\" --copt \"-DEIGEN_ENABLE_AVX512\" --copt \"-DEIGEN_ENABLE_AVX2\"  --verbose_failures   -j 64\r\n```", "@c0710204 When I used your command, I had below errors.\r\n`gcc: error: unrecognized command line option '-mavx512f'`\r\n`gcc: error: unrecognized command line option '-mavx512cd'`\r\n`gcc: error: unrecognized command line option '-mavx512er'`\r\n`gcc: error: unrecognized command line option '-mavx512pf'`\r\n\r\nI think this error related with Tensorflow , OS and GCC version, but I don't know what is the best combination. Please tell me about that.\r\n( I have executed tensorflow 0.12.0 version with CentOS 7.2 and GCC 4.8.5)\r\n\r\nThank you.\r\n", "@sjlee7748 Oh ,sorry.I forgot the gcc version.To use avx-512, you must use gcc 4.9+ (I suggest use latest version like gcc 6.x)\r\nTo set the gcc you can change the bazel cache file (path looks like  `*****/external/local_config_cc/CROSSTOOL`). It will generated by bazel after 1 build (bazel clean will delete it)", "Hi @c0710204, I tried your command to build TF on Xeon Phi, but failded. Like describe in [https://github.com/tensorflow/tensorflow/issues/7116](url), Could you help to figure out what is wrong?", "Just to put the links in github form: #7116, #6349 ", "@benoitsteiner , it looks the eigen change was merged. Could you post an update and close this if relevant?", "@benoitsteiner ,  How to confirm that it's eigen that caused this problem?", "@drpngx @benoitsteiner \r\nHello, is there any update on this issue? I am waiting your comments. ", "Reading the thread, it looks like Eigen was updated. @DaejinJung , @craftlk did you try?\r\n\r\n(The eigen link was updated 6 days ago: https://github.com/tensorflow/tensorflow/commit/3fbcb798ada73d8cb0e5bf598f2f472741c4816c)", "Hi just pull the master branch. I use the command \"bazel build -c opt --copt \"-mavx512pf\" //tensorflow/tools/pip_package:build_pip_package\". The error is as fellows:\r\n\r\n ./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX512.h:84:11: error: 'Packet16q16i' does not name a type\r\n   typedef Packet16q16i half;\r\n           ^\r\n./third_party/eigen3/unsupported/Eigen/CXX11/src/FixedPoint/PacketMathAVX512.h:135:11: error: 'Packet16q16i' does not name a type\r\n   typedef Packet16q16i half;\r\nThe message is same as I got before.", "Did you run configure again? It needs to bazel fetch\n\nOn Feb 22, 2017 2:28 PM, \"jiazhentim\" <notifications@github.com> wrote:\n\n> Hi just pull the master branch. I use the command \"bazel build -c opt\n> --copt \"-mavx512pf\" //tensorflow/tools/pip_package:build_pip_package\".\n> The error is as fellows:\n>\n> ./third_party/eigen3/unsupported/Eigen/CXX11/src/\n> FixedPoint/PacketMathAVX512.h:84:11: error: 'Packet16q16i' does not name\n> a type\n> typedef Packet16q16i half;\n> ^\n> ./third_party/eigen3/unsupported/Eigen/CXX11/src/\n> FixedPoint/PacketMathAVX512.h:135:11: error: 'Packet16q16i' does not name\n> a type\n> typedef Packet16q16i half;\n> The message is same as I got before.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/4775#issuecomment-281825221>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AT_SbcjwO2AA-XvmsvIkaXIMlycremSTks5rfLZugaJpZM4KOtrM>\n> .\n>\n", "Yes, I run configure @drpngx ", "Looking at @benoitsteiner 's [link](https://bitbucket.org/eigen/eigen/pull-requests/235/added-support-for-avx512-to-eigen/diff), we merged Half support from `unsupported` to `Core`, in `arch/AVX512` and some in `arch/CUDA`. It looks like what needs to happen is that we update our internal code to include the right headers and use the right definition if necessary, away from `unsupported` and using the new `arch/` headers.", "What happens when you go to the `unsupported/FixedPoint` [header](https://github.com/tensorflow/tensorflow/blob/master/third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint#L35) and replace the includes with the new ones?\r\n\r\n```\r\n#include \"src/Core/arch/AVX512/PacketMath.h\"\r\n#include \"src/Core/arch/CUDA/TypeCasting.h\"\r\n```", "I've added the missing definition for Packet16q16i in https://github.com/tensorflow/tensorflow/pull/7820. That should solve the immediate compilation error. I think there are a few more primitives missing though.", "Hi @benoitsteiner , there is still an error:\r\ntensorflow/core/kernels/split_lib_cpu.cc:43:1:   required from here\r\nexternal/eigen_archive/unsupported/Eigen/CXX11/../../../Eigen/src/Core/GenericPacketMath.h:467:16: error: 'alignment' is not a member of 'Eigen::internal::unpacket_traits<Eigen::internal::Packet64q8u>'\r\n   if(Alignment >= unpacket_traits<Packet>::alignment)\r\n                ^\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\n", "Hi @drpngx, I tried and the came across a fatal error:\r\nIn file included from ./tensorflow/core/framework/numeric_types.h:25:0,\r\n                 from ./tensorflow/core/framework/allocator.h:23,\r\n                 from ./tensorflow/core/framework/op_kernel.h:22,\r\n                 from tensorflow/contrib/input_pipeline/kernels/input_pipeline_kernels.cc:16:\r\n./third_party/eigen3/unsupported/Eigen/CXX11/FixedPoint:36:45: fatal error: src/Core/arch/AVX512/PacketMath.h: No such file or directory\r\n", "@jiazhentim we have to wait for #7820 to be merged. If you want to check if that would solve your problem, you could try it locally:\r\n\r\n```\r\ngit fetch origin pull/7820/head:pr7820\r\ngit checkout pr7820\r\n```", "#7820 was merged, please try now.", "I've just checked that bazel build --copt=-march=skylake //tensorflow/tools/pip_package:build_pip_package now works with gcc 6.2 with the latest version of the codebase.", "Woohoo!", "Thanks, it works now.", "And is there a way to compile Tensorflow with ICC on KNL? I can compile it with gcc.", "@jiazhentim Try export CC=/yout/path/of/icpc, and then call bazel to build tensorflow.", "@drpngx @benoitsteiner Could you please let me know the exact command to build TensorFlow on Intel x86 platform (Ubuntu 16.04/18.04) with avx/avx2 and avx512 support?  And which gcc is required?"]}, {"number": 4774, "title": "weights_initializer in tf.contrib.layers.fully_connected", "body": "Hi, \n\nAt present contrib.layers.fully_connected is unable to accept a Tensor as an initializer for the weights.\n\nThis because when calling variable_scope.get_variable (which accepts a Tensor as an initializer) it specifies both the initializer and the shape. Is this expected behavior or a bug? \n\nI have put together a small [gist ](https://gist.github.com/marcoadurno/60faf136193d8eccc83d14932d188d25) that illustrates the issue.\n\nAt present what's the recommended way to pass a Tensor as an initializer? Would a [dummy init_fn](https://gist.github.com/marcoadurno/60faf136193d8eccc83d14932d188d25#file-layers_weights_test-py-L34) be acceptable?\n\nI'm currently running rev: 9c11fe2f1db1ccf5bcdb0724c18cc462ff5fbbd7.\n\nThanks,\n\nMarco\n", "comments": ["@marcoadurno Thanks for filling the issue and the gist!  FYI your `dummy init_fn` link is broken.\n\n@sguada probably has some advice here.\n", "@tatatodd link fixed, it was pointing to a copy of the gist in a private repo.\n", "You can use a function to initialize a variable with a constant, the problem is that those constants become part of the graph and adding many of them could make it very big.\n\nInstead the recommended way to initialize a variable with a value is using [assign_from_values_fn](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/framework/python/ops/variables.py#L447):\n\n```\ninit_assign_fn = assign_from_values_fn({'scope/weights': value})\nsess.run(init_assign_fn)\n```\n", "@marcoadurno, did you find a solution to this issue?", "Closing due to lack of response.  Please reopen if necessary."]}, {"number": 4773, "title": "ValueError: Shape (?, 4096) must have rank 1", "body": "Operating System: _CentOS 6 - box for vagrant_\n\nInstalled version of CUDA and cuDNN: \nls -l /path/to/cuda/lib/libcud*: \"No such file or directory\"\n_No CUDA installed._\n\nInstallation:\n1.  Installed with Anaconda 4.0.9;\n2. `python -c \"import tensorflow; print(tensorflow.__version__)\"`: _0.10.0rc0_;\n3. Python 3.5, numpy 1.11.2, scipy 0.18.1;\n### Reproduce\n\nIt is standard VGG model with 16 layers. I tried extract vgg.fc2 layer:\nhttp://pastebin.com/A1qd7g2e\n\nI also get this error after `session.run` was called.\n### What other attempted solutions have you tried?\n\nI'm a new user of tenserflow and don't know any attempted solutions. I found this issue - https://github.com/tensorflow/tensorflow/issues/3815, but it is closed.\n### Logs or other output that would be helpful\n\nStacktrace - http://pastebin.com/eaQi1T0R\n", "comments": ["@egorlitvinenko Please provide the full error log, including the stack trace.\n", "@tatatodd I provided all log with stacktrace, which I see in Jupyter notebook. Is there another place, from which I should take log?\n", "My apologies @egorlitvinenko I missed the stacktrace you provided.\n\nBut I'm still confused.  What implementation of vgg are you using?  Can you provide a link?\n\nI don't think it's implementation we've provided below, since there is no vgg16 (but there is vgg_16).\nhttps://github.com/tensorflow/models/blob/master/slim/nets/vgg.py\n", "@tatatodd Yes, it is another implementation - http://pastebin.com/tkmXvw4H\n", "@egorlitvinenko I recommend you first read about the basic concepts of TensorFlow, in particular the difference between \"Building the graph\" and \"Launching the graph in a session\":\nhttps://www.tensorflow.org/versions/r0.11/get_started/basic_usage.html#basic-usage\n\nHere are lines 7 and 8 of your example:\n\n```\nprint(vgg.fc2[:20]) # this is error line\nreturn vgg, sess.run(vgg.fc2, feed_dict={vgg.imgs: [img1]})\n```\n\nNote that the `sess.run` call in line 8 is where you actually run the graph.  The `vgg.fc2` in line 7 is referring to a graph node, _before_ you've run the graph.  If you want to inspect the output, you should inspect the result returned by `sess.run`.\n\nNote that we primarily use github issues to track bugs and feature requests.  This type of question is better suited for StackOverflow, which we also monitor.  In the future please ask these types of questions there and tag it with the `tensorflow` tag.  Thanks!\n"]}, {"number": 4772, "title": "tensorflow/models/compression does not work", "body": "To run the compression model:\n\n`python encoder.py --input_image=/your/image/here.png \\ --output_codes=output_codes.pkl --iteration=15 --model=residual_gru.pb`\n\nHowever, this error shows up:\n\n> [libprotobuf ERROR google/protobuf/src/google/protobuf/io/coded_stream.cc:207] A protocol message was rejected because it was too big (more than 67108864 bytes).  To increase the limit (or to disable these warnings), see CodedInputStream::SetTotalBytesLimit() in google/protobuf/io/coded_stream.h.\n\nI see from v0.8.0 RC0 that it has been fixed:\n\n> Added instructions and binaries for ProtoBuf library with fast serialization and without 64MB limit\n\nCould this error have been reintroduced? I'm using 0.10.0.\n", "comments": ["@jkschin Can you provide the full error log?  Also the following environment information:\n\n---\n\n### Environment info\n\nOperating System:\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\nIf installed from binary pip package, provide:\n1. A link to the pip package you installed:\n2. The output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.\n\nIf installed from source, provide \n1. The commit hash (`git rev-parse HEAD`)\n2. The output of `bazel version`\n", "-rw-r--r-- 1 root root   322936 Aug 16  2015 /usr/local/cuda/lib64/libcudadevrt.a\nlrwxrwxrwx 1 root root       16 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so -> libcudart.so.7.5\nlrwxrwxrwx 1 root root       19 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5 -> libcudart.so.7.5.18\n-rwxr-xr-x 1 root root   383336 Aug 15  2015 /usr/local/cuda/lib64/libcudart.so.7.5.18\n-rw-r--r-- 1 root root   720192 Aug 16  2015 /usr/local/cuda/lib64/libcudart_static.a\n-rwxr-xr-x 1 root root 59909104 Sep 20 20:51 /usr/local/cuda/lib64/libcudnn.so\n-rwxr-xr-x 1 root root 61453024 Jul  3 16:54 /usr/local/cuda/lib64/libcudnn.so.4\n-rwxr-xr-x 1 root root 61453024 Jul  3 16:54 /usr/local/cuda/lib64/libcudnn.so.4.0.7\n-rwxr-xr-x 1 root root 59909104 Sep 20 20:51 /usr/local/cuda/lib64/libcudnn.so.5\n-rwxr-xr-x 1 root root 59909104 Sep 20 20:51 /usr/local/cuda/lib64/libcudnn.so.5.0.5\n-rw-r--r-- 1 root root 58775484 Sep 20 20:51 /usr/local/cuda/lib64/libcudnn_static.a\n\nInstalled from source:\n51238b1b5219a37ba145915efa764cca870e0d9f\n0.3.0\n", "@jkschin The commit hash 51238b1b5219a37ba145915efa764cca870e0d9f corresponds to the `models` repository:\nhttps://github.com/tensorflow/models/commit/51238b1b5219a37ba145915efa764cca870e0d9f\n\nHow about your `tensorflow` repository?  If you installed from source, please provide the commit hash of that repo (i.e. run `git rev-parse HEAD` under the tensorflow repo directory).  Otherwise provide a link to the pip package you installed, and the output from `python -c \"import tensorflow; print(tensorflow.__version__)\"`.  Thanks!\n", "Please refer to: https://github.com/tensorflow/models/pull/510\nand https://github.com/tensorflow/models/pull/510/commits/608f46debea6b1e4ffb6c3ccea5771004693bd4c\n", "@tatatodd I recompiled and ran it already. I think I should just close this.\n"]}, {"number": 4771, "title": "Branch 135176011", "body": "", "comments": ["@yifeif, thanks for your PR! By analyzing the history of the files in this pull request, we identified @tensorflower-gardener, @dsmilkov and @charlesnicholson to be potential reviewers.\n"]}, {"number": 4770, "title": "bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu Failed With Error:could not insert 'nvidia_340_uvm': Invalid argument", "body": "I am installing tensorflow from source code since my GTX1080 need CUDA8.0. My installing steps are as following:\n1. pre-installing: Ubuntu14.04 os, Nvidia driver of version numbered 367.48, CUDA8.0 by cuda_8.0.44_linux.run, cuDNN5.1, bazel and jdk8.\n2. download tensorflow source from github, type yes for GPU support during running ./configure and these operations are successful .\n3. But errors stop me to continue tensorflow installing: \n\n```\nzyl@zyl-PC$ bazel build -c opt --config=cuda  //tensorflow/cc:tutorials_example_trainer\n\n- [ ] INFO: From Compiling tensorflow/core/kernels/tile_ops_gpu.cu.cc:\nnvcc warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.\nnvcc warning : option '--relaxed-constexpr' has been deprecated and replaced by option '--expt-relaxed-constexpr'.\nTarget //tensorflow/cc:tutorials_example_trainer up-to-date:bazel-bin/tensorflow/cc/tutorials_example_trainer\n\n- [ ] INFO: Elapsed time: 1233.946s, Critical Path: 1168.09s\nzyl@zyl-PC$ bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcublas.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcudnn.so.5 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcufft.so.8.0 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:111] successfully opened CUDA library libcurand.so.8.0 locally\n\n- [ ] modprobe: ERROR: could not insert 'nvidia_340_uvm': Invalid argument\nE tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed call to cuInit: CUDA_ERROR_UNKNOWN\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153] retrieving CUDA diagnostic information for host: zyl-PC\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160] hostname: zyl-PC\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] libcuda reported version is: 367.48.0\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:356] driver version \nfile contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  367.48  Sat Sep  3 18:21:08 PDT 2016 \nGCC version:  gcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04.3)\"\"\"    \nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] kernel reported version is: 367.48.0\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:293] kernel version seems to match DSO: 367.48.0\n\n- [ ] F tensorflow/cc/tutorials/example_trainer.cc:129] Check failed:\n::tensorflow::Status::OK() == (session->Run({{\"x\", x}}, \n{\"y:0\", \"y_normalized:0\"}, {}, &outputs)) \n(OK vs. Invalid argument: Cannot assign a device to node 'Cast': Could not satisfy explicit device specification '/gpu:0' \nbecause no devices matching that specification are registered in this process; \navailable devices: /job:localhost/replica:0/task:0/cpu:0 \n\n- [ ] [[Node:Cast = Cast[DstT=DT_FLOAT, SrcT=DT_INT32, _device=\"/gpu:0\"](Const)]])\nAborted (core dumped)\"\n```\n\n---\n\nthe tensorflow is failed to install from source code at the step of \"$ bazel-bin/tensorflow/cc/tutorials_example_trainer --use_gpu\" as discribed above. Obviously, both gpu and tensorflow would not be available.\nAnyone who sucessed in installing tensorflow and cuda8.0 can help me to fix it?\n", "comments": ["@Tcorpion Please provide the following information.  \n\n---\n\n### Environment info\n\nInstalled version of CUDA and cuDNN: \n(please attach the output of `ls -l /path/to/cuda/lib/libcud*`):\n\nIf installed from source, provide \n1. The commit hash (`git rev-parse HEAD`)\n2. The output of `bazel version`\n", "I have fixed it by \"sudo apt-get remove nvidia-340\"  referenceing \"https://github.com/fchollet/keras/issues/3043\"\n"]}, {"number": 4769, "title": "Tensorflow running problem with gpu_device.cc:170", "body": "I am having  a problem when running a tutorial example of tensorflow. It is an example for deep neural network with 2 hidden layers. Following is the output of my error file. \n\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcublas.so.7.5 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcudnn.so locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcufft.so.7.5 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcuda.so.1 locally\nI tensorflow/stream_executor/dso_loader.cc:108] successfully opened CUDA library libcurand.so.7.5 locally\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:102] Found device 0 with properties: \n\nname: Tesla K40t\nmajor: 3 minor: 5 \nmemoryClockRate (GHz) 0.8755\npciBusID 0000:82:00.0\nTotal memory: 11.25GiB\nFree memory: 11.09GiB\n\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:126] DMA: 0 \nI tensorflow/core/common_runtime/gpu/gpu_init.cc:136] 0:   Y \nI tensorflow/core/common_runtime/gpu/gpu_device.cc:839] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K40t, pci bus id: 0000:82:00.0)\nF tensorflow/core/common_runtime/gpu/gpu_device.cc:170] Check failed: err == cudaSuccess (71 vs. 0)\n/var/spool/PBS/mom_priv/jobs/2004520.wlm01.SC: line 10: 18679 Aborted\n\nI am using CentOS 6.6, python 2.7.11\n\nI can run the example smoothly when using the cpu version of tensorflow. Does anyone have idea and solution of it? Thanks.               \n", "comments": ["have you tried using cuda 8.0 and TF 0.11?\n", "Please can you supply the information requested in the tensorflow issues template.", "Closing due to lack of activity."]}, {"number": 4768, "title": "kernel version 352.63.0 does not match DSO version 361.93.2", "body": "Hi, \n\nI've installed TensorFlow with CUDA and CuDNN. \n\nWhy I run a session I've the following error:\n\n```\n>>> sess = tf.Session()\nE tensorflow/stream_executor/cuda/cuda_driver.cc:491] failed call to cuInit: CUDA_ERROR_INVALID_VALUE\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:153] retrieving CUDA diagnostic information for host: next-gpu1\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:160] hostname: next-gpu1\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:185] libcuda reported version is: 361.93.2\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:347] driver version file contents: \"\"\"NVRM version: NVIDIA UNIX x86_64 Kernel Module  352.63  Sat Nov  7 21:25:42 PST 2015\nGCC version:  gcc version 4.8.4 (Ubuntu 4.8.4-2ubuntu1~14.04.1)\n\"\"\"\nI tensorflow/stream_executor/cuda/cuda_diagnostics.cc:189] kernel reported version is: 352.63.0\nE tensorflow/stream_executor/cuda/cuda_diagnostics.cc:296] kernel version 352.63.0 does not match DSO version 361.93.2 -- cannot find working devices in this configuration\nI tensorflow/core/common_runtime/gpu/gpu_init.cc:81] No GPU devices available on machine.\n```\n", "comments": ["The following query shows some similar issues:\nhttps://github.com/issues?utf8=%E2%9C%93&q=is%3Aissue+repo%3Atensorflow%2Fmodels+repo%3Atensorflow%2Ftensorflow+%22kernel+version%22+%22does+not+match%22+%22DSO+version%22+\n\nSpecifically #4349 and #1158 are similar.  Basically you seem to have the wrong nvidia driver versions.\n", "Automatically closing due to lack of recent activity. Please reopen when additional information becomes available. Thanks!\n"]}, {"number": 4767, "title": "Problem initializing DT_DOUBLE variables in distributed TF", "body": "If you save code below as `init_bug.py` and run as `python init_bug.py`, it crashes with error below when running `init_op`. It works fine using local session or when changing `dtype` to `np.float32`. Also fails for `np.int32` type. Tried on 0.11rc0 on MacOS\n\n`tensorflow.python.framework.errors.InternalError: Output 0 of type float_ref does not match declared output type double_ref for node Variable = Variable[container=\"\", dtype=DT_DOUBLE, shape=[], shared_name=\"\", _device=\"/job:worker/replica:0/task:0/cpu:0\"]()\n`\n\n```\nimport subprocess, sys\nimport tensorflow as tf\nimport numpy as np\n\nworker_ip=\"127.0.0.1:12222\"\ncluster = {\"worker\": [worker_ip]}\nclusterspec = tf.train.ClusterSpec(cluster).as_cluster_def()\n\ndef launch_worker():\n  def runcmd(cmd): subprocess.Popen(cmd, shell=True, stderr=subprocess.STDOUT)\n  runcmd(\"python init_bug.py worker\")\n\nif __name__=='__main__':\n  if len(sys.argv)<2:\n    dtype=np.float64\n    global_param_var = tf.Variable(np.array(1).astype(dtype), dtype=dtype)\n    init_op = tf.initialize_all_variables()\n    launch_worker()\n    sess = tf.Session(\"grpc://\"+worker_ip)\n    sess.run(init_op)\n\n  else:\n    print(\"Launching worker\")\n    server = tf.train.Server(clusterspec, job_name=\"worker\")\n    server.join()\n```\n", "comments": ["same problem if I use `ones_initializer` or `zeros_initializer` with any `dtype` other than `float32` @mrry\n", "I ran your program (with an additional `print sess.run(global_param_var)` to confirm it was working)  using 0.11rc0 on Linux, and I couldn't reproduce your problem.\n\nI presume you're falling foul of implicit by-name variable sharing between sessions on the same server. If you create a `DT_FLOAT` variable called `\"Variable\"` on the server, then create a `DT_DOUBLE` variable called `\"Variable\"` in a different session on the same server, you'll get the error you described.\n\nTo avoid the problem, call `tf.Session.reset(\"grpc://\" + worker_ip)` before starting a subsequent session, or use a `with tf.container():` block to place the variables in different namespaces.\n", "Ah, indeed, it was remembering old state, tf.Session.reset fixes things, thanks!\n", "PS: it seems more robust to just kill processes, `tf.Session.reset` seems to occasionally hang if called at the same time as launching the server process\n"]}, {"number": 4766, "title": "freeze graph for inception v1 fine tuned .ckpt model file fail. Attempting to use uninitialized value", "body": "I try to fine tune inception v1 model on my own dataset, and i choose optimizer: rmsprop\n\nthe cmd is as below:\n\n---\n\npython train_image_classifier.py \\\n  --train_dir=/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/v1_finetune/ \\\n  --dataset_name=animals \\\n  --dataset_split_name=train \\\n  --dataset_dir=/home/scopeserver/RaidDisk/DeepLearning/mwang/data/datadic_train/ \\\n  --model_name=inception_v1 \\\n  **--checkpoint_path=/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/inceptionv1/inception_v1.ckpt \\**\n  --checkpoint_exclude_scopes=InceptionV1/Logits \\\n  --trainable_scopes=InceptionV1/Logits \\\n  --max_number_of_steps=60435 \\\n  --batch_size=128 \\\n  --learning_rate=0.001 \\\n  --save_interval_secs=3600 \\\n  --save_summaries_secs=3600 \\\n  --log_every_n_steps=200 \\\n  **--optimizer=rmsprop \\**\n  --weight_decay=0.00004\n\n---\n\nonce i get .ckpt file, i try to freeze the graph into a .pb file. \n\nbazel-bin/tensorflow/python/tools/freeze_graph \\\n --input_graph=/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/v1_finetune/graph.pbtxt \\\n **--input_checkpoint=/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/v1_findtune/model.ckpt-23293 \\**\n --output_graph=/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/v1_findtune/freeze.pb \n --output_node_names=InceptionV1/Logits/Predictions/Softmax\n\n---\n\nhowever, i get many issues, they are all: \n\n**Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1**\n\n---\n\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: **Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1**\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: **Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1**\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nW tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\nTraceback (most recent call last):\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 134, in <module>\n    tf.app.run()\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/platform/app.py\", line 30, in run\n    sys.exit(main(sys.argv[:1] + flags_passthrough))\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 131, in main\n    FLAGS.output_graph, FLAGS.clear_devices, FLAGS.initializer_nodes)\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 120, in freeze_graph\n    sess, input_graph_def, output_node_names.split(\",\"))\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/framework/graph_util.py\", line 226, in convert_variables_to_constants\n    returned_variables = sess.run(variable_names)\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 717, in run\n    run_metadata_ptr)\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 915, in _run\n    feed_dict_string, options, run_metadata)\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 965, in _do_run\n    target_list, options, run_metadata)\n  File \"/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 985, in _do_call\n    raise type(e)(node_def, op, message)\ntensorflow.python.framework.errors.FailedPreconditionError: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n     [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=2995273176636161830, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1)]]\n", "comments": ["i use **optimizer: sgd** to fine tune the inception v1 model on my dataset and then freeze .ckpt to .pb file has no issue.\n\nSo the problem is free graph does not support **optimizer: rmsprop**. \n\nIs there anymore can fix this?\n\nThanks.\n", "It does not support **optimizer: adagrad** as well.\n", "It does not support **optimizer: momentum**  ... ... \u6b64\u5904\u7701\u7565\u4e00\u4e07\u4e2a\u5b57\n", "@civilmanxx I think you need to specify the --saver flag to freeze_graph, with a SaverDef file:\n\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py#L50\nhttps://www.tensorflow.org/versions/r0.11/api_docs/python/state_ops.html#Saver\nSee `tf.train.Saver.as_saver_def()`\n", "Thanks for your info. but i do not know how to use this **--input_saver** parameter. There is no example usage for this one. and the default 4 parameters are only:\n\n--input_graph=some_graph_def.pb \n--input_checkpoint=model.ckpt-8361242 \n--output_graph=/tmp/frozen_graph.pb \n--output_node_names=softmax \n", "@civilmanxx The `--input_saver` parameter takes a `SaverDef` proto file, which you can retrieve via `tf.train.Saver.as_saver_def()`\n\nBut perhaps a better question: why are you trying to freeze the graph?\n", "I use freeze_graph to create a .pb file for iOS and Android, which need small files.\n\nSorry, i am not clear about  **tf.train.Saver.as_saver_def().**  When i train inception v1 (slim) model. \nThe only files output are: .**ckpt**, .**pbtxt**,  **checkpoint.txt**, .**meta** Nothing else.\n\nand .**pbtxt** file is for parameter **--input_graph**, but not for  **--input_saver** \nFor slim model, such as for inception v1, what change should I make to get this output file.\n\nThanks.\n", "@civilmanxx I see.  Ignore the `--input_saver` for now; I'm not sure whether that would help with your problem.\n\nOne thing to check is to see whether the checkpoint actually has a value for `InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1`.  You can use `inspect_checkpoint` to do this.\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/inspect_checkpoint.py\n\nYou'd do something like this:\n\n```\n$ bazel build tensorflow/python/tools:inspect_checkpoint\n$ bazel-bin/tensorflow/python/tools/inspect_checkpoint --file_name=/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/v1_findtune/model.ckpt-23293\n```\n\nThat will dump out the tensors that are saved in the checkpoint.  I'm suspecting your checkpoint will not contain `InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1`.\n\nBut that doesn't fix your problem.  One thing you might try is rather than picking the first checkpoint that becomes available, pick the last one after things have run for a while.  I don't actually expect this to help, but there's an off-chance that this might work.\n\nOtherwise it's possible that you simply can't change the optimizer when fine-tuning.\n\nLet me know how the above works out.\n", "I build and run the **inspect_checkpoint** tool. Yes, i am not using **model.ckpt-0**, which is the first model file, but using the intermediate file like **model.ckpt-354** below.\n\nbazel-bin/tensorflow/python/tools/inspect_checkpoint --file_name=/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/v1_finetune_test/**model.ckpt-354**\n\nIn the output tensors list from **inspect_checkpoint**, i can see the one in the error message, which mean the tenor is indeed in the .ckpt file:\n\nInceptionV1/Conv2d_2c_3x3/BatchNorm/moving_variance (DT_FLOAT) [192]\n**InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1** (DT_FLOAT) [269]\nInceptionV1/Mixed_5c/Branch_1/Conv2d_0a_1x1/BatchNorm/moving_mean (DT_FLOAT) [192]\n", "When I try to freeze the graph, i still get: \n**Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1**\n\nThat's to say, even if the .ckpt file contains this tensor, but freeze_graph still can't find its value.\n", "I print out the value of this tenor by running:\n\nbazel-bin/tensorflow/python/tools/inspect_checkpoint --file_name=/home/scopeserver/RaidDisk/DeepLearning/mwang/tensorflow/v1_finetune_test/model.ckpt-354 **--tensor_name=InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1**\n\nand i get: \n\ntensor_name:  InceptionV1/Logits/Conv2d_0c_1x1/biases/RMSProp_1\n[  9.86978375e-06   6.85426858e-06   1.77027832e-05   1.04204619e-05\n  -7.94137486e-06  -9.20329876e-06   2.95680911e-06   2.09460268e-05\n  -5.77514083e-06  -1.01968126e-05  -8.02813065e-06  -1.70251151e-05\n  -3.04158334e-06   2.19841127e-06  -2.55542436e-05  -1.87719270e-05\n  -8.19392062e-06   3.66311656e-06  -1.92649914e-05  -3.48176691e-05\n   6.33017817e-06   8.96366055e-06   2.15804866e-05  -9.80203549e-06\n  -9.40040172e-06  -2.70107030e-05   3.52742682e-05  -1.27857584e-05\n   1.15458715e-06  -8.41602559e-06  -1.81019448e-06  -1.99570350e-05\n   1.82883450e-05   1.69406612e-05  -1.27168605e-05   5.42765611e-06\n  -1.96899373e-06   7.29191515e-06  -2.48519846e-05   1.92835932e-06\n   1.76871454e-05  -1.50661640e-06  -7.86250166e-06  -3.23535346e-06\n   2.04215212e-06   1.63158147e-05  -1.69425930e-05  -2.68306958e-05\n  -7.31761611e-06   5.14951762e-06  -7.55638803e-06   2.02322772e-05\n   1.67525395e-05   4.68743565e-06   1.64220819e-05  -1.11979607e-05\n  -1.74423276e-05  -8.98806775e-06  -3.83554980e-05  -1.22094716e-05\n  -2.35030184e-05  -1.29438331e-05   5.34992614e-06  -3.60727995e-06\n  -2.71246008e-05   5.70658904e-06  -2.64325581e-06  -7.97819848e-06\n  -1.33307276e-05   2.16825920e-05   2.98314490e-06   1.05518566e-05\n   6.70201871e-06   4.20440801e-06  -7.08096150e-06  -1.80165316e-05\n   1.72656255e-05   2.83428253e-05   1.82465319e-05   1.23967075e-05\n   2.33141436e-05  -1.63435777e-06  -1.14988188e-06   1.61113312e-05\n   1.37271782e-05  -1.88547619e-05   7.98284816e-07   8.21670346e-06\n  -7.39948700e-06   8.04106458e-06   2.45966185e-05  -1.46105585e-05\n   5.56014083e-06  -1.79193321e-05   3.07190589e-06  -8.51533696e-06\n   2.19997964e-05  -7.68038899e-06  -1.71789070e-05   1.39526506e-07\n   6.30611748e-06   1.46591046e-05   3.25151541e-06  -1.13225215e-05\n   2.05118140e-05   4.65685525e-06  -1.44223113e-05  -1.28840911e-05\n  -1.97088298e-06   2.47331100e-05   2.40055924e-05   2.14417412e-07\n   2.33114297e-05   1.82627500e-05  -2.41962989e-05   8.27924760e-06\n  -1.21428036e-06  -8.21859430e-06  -2.46486661e-06  -2.20021235e-07\n   1.70503208e-05  -3.09693132e-05  -1.11911049e-05   2.44328999e-06\n   1.23004602e-05  -1.75034415e-06   1.76851918e-05   2.33764445e-06\n  -1.52175990e-05   1.08553759e-05   4.03943386e-06   8.38596225e-06\n   1.74842753e-05  -1.81624346e-05   4.53340999e-06  -1.92229868e-06\n   1.00148864e-05  -2.71023127e-05  -1.81133855e-05   4.28724888e-06\n   1.92390212e-06   1.37941170e-05   1.79978197e-05  -1.28009424e-06\n   4.44308125e-06   4.26719407e-06  -6.69852534e-06  -9.20531238e-06\n   8.26703763e-06   2.59753256e-06   9.29176167e-06  -2.32010316e-05\n  -5.92776814e-06  -1.21423118e-05  -1.42101646e-06  -1.23034388e-05\n  -2.68097119e-06   8.49927255e-06   3.27547023e-05   2.63869367e-07\n  -1.57098111e-05   1.06451871e-05  -3.19871688e-05   1.70684270e-05\n   2.85644364e-05   2.06342738e-05   1.11950585e-05   6.59950274e-06\n  -8.40794746e-06   1.61997814e-05   1.87620412e-06  -2.33516062e-06\n  -6.99355951e-07  -3.14291492e-06   7.36486800e-06   1.24595026e-05\n  -1.31625275e-05  -6.10871621e-06   8.97275822e-06   1.14148652e-05\n  -1.11353029e-05   1.74650613e-05  -2.01117291e-06  -2.66277470e-06\n  -8.68052211e-06   1.21099019e-05   1.57617851e-05  -2.73431997e-05\n   1.03377181e-06  -8.16130614e-06   1.46451766e-05  -6.66145797e-06\n   1.39290260e-05   1.38728010e-05  -9.32401144e-06   9.64610263e-06\n  -1.92830739e-05   6.85750592e-06   1.56476362e-05  -1.00207053e-05\n   7.60673856e-06   1.68155802e-05   4.31576382e-06   1.93709070e-06\n   6.80465473e-06  -6.80266885e-06   3.09764328e-05   8.38964479e-06\n   2.20953007e-05   8.35676815e-07   2.61040750e-05   2.08170622e-05\n   2.28708268e-05  -3.26187910e-05   4.37626159e-06  -6.92474578e-06\n   2.54311472e-05   1.40215589e-05  -1.15263119e-05  -9.43703526e-06\n   2.00015747e-05   7.14655641e-07  -4.79236814e-06   4.57760734e-06\n   1.16918418e-05   1.45129970e-05  -1.06864009e-05   4.67916243e-06\n  -9.73094666e-06   6.23696906e-06   7.30810643e-06  -4.06844592e-05\n   6.77832850e-06  -1.04136625e-05   1.29206921e-06  -1.40365119e-05\n  -9.67772939e-06  -7.36094648e-07   1.24232984e-05   1.10232659e-05\n   1.29062585e-06  -1.41258670e-05  -1.86327579e-05  -2.73564297e-06\n  -4.52741915e-05   7.24970550e-06  -1.89730181e-05  -6.96232109e-06\n  -2.37619884e-06  -6.00963813e-06   1.37013376e-05   4.31684703e-06\n   1.36891549e-05   1.73135504e-05   5.93294862e-06  -2.34130184e-05\n  -2.97952596e-07   1.17226900e-05   4.68787630e-06   3.51356834e-06\n  -2.66452334e-05  -2.45284918e-05  -2.92720833e-05   4.35316963e-07\n   2.62916342e-06  -2.14970769e-05   1.71843694e-05   4.73269353e-07\n  -1.06048610e-05]\n", "@civilmanxx Can you attach the graph.pbtxt and checkpoint file to this issue?  I'm now suspecting the errors are related to my previous \"saver\" suggestion.  There's another way to deal with this though, and I should be able to figure it out if I can easily reproduce it.  Thanks!\n", "[v1_finetune_test.zip](https://github.com/tensorflow/tensorflow/files/525121/v1_finetune_test.zip)\n\nThe zip file contains **.ckpt** and **.pbtxt** \n\nThe output node is **--output_node_names=InceptionV1/Logits/Predictions/Softmax**\n", "@civilmanxx Thank you for the files.  I can't figure out what's wrong.\n\nOne thing that might be suspicious in your graph.pbtxt is the existence of nodes prefixed with \"save_1\".  You can inspect the file itself (it's just text file) or use tensorboard to visualize it.  That's making me suspect that something about your finetuning is causing a mismatch somewhere.\n\nPerhaps one thing to try is to use the example of finetuning on inception v3.  You can try exactly the same thing: run the finetuning for a while and then try to freeze the graph.  The idea is to see whether the freezing works, and if so, to figure out what is different about your setup.\nhttps://github.com/tensorflow/models/tree/master/slim#fine-tuning-a-model-from-an-existing-checkpoint\nhttps://github.com/tensorflow/models/blob/master/slim/scripts/finetune_inception_v3_on_flowers.sh\n", "inception v3 model is too large for Android and iOS devices. It runs out of memory. In the example of iOS for tensorflow, it uses v1 as well.\n", "@civilmanxx I see, thanks for the info.\n\nMaybe @petewarden has some ideas about why freeze_graph is failing on a fine-tuned inception v1 graph.\n", "Have you managed to get past the issue? I tried to run the basic example from [slim_walkthrough notebook](https://github.com/tensorflow/models/blob/master/slim/slim_walkthough.ipynb) and then ran the following command:\n`bazel-bin/tensorflow/python/tools/freeze_graph --input_graph=/tmp/inception_finetuned/graph.pbtxt --input_checkpoint=/tmp/inception_finetuned/model.ckpt-2 --output_graph=/Users/nikogamulin/Desktop/freeze.pb --output_node_names=InceptionV1/Logits/Predictions/Softmax`\n\nwhich resulted the following error:\n\n> W tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/Adam_1\n>    [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/Adam_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=6007788667487390928, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/Adam_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/Adam_1)]]\n> ...\n> W tensorflow/core/framework/op_kernel.cc:968] Failed precondition: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/Adam_1\n>    [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/Adam_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=6007788667487390928, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/Adam_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/Adam_1)]]\n> Traceback (most recent call last):\n>   File \"/Users/nikogamulin/workspace/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 135, in <module>\n>     tf.app.run()\n>   File \"/Users/nikogamulin/workspace/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/platform/app.py\", line 32, in run\n>     sys.exit(main(sys.argv[:1] + flags_passthrough))\n>   File \"/Users/nikogamulin/workspace/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 132, in main\n>     FLAGS.output_graph, FLAGS.clear_devices, FLAGS.initializer_nodes)\n>   File \"/Users/nikogamulin/workspace/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/tools/freeze_graph.py\", line 121, in freeze_graph\n>     sess, input_graph_def, output_node_names.split(\",\"))\n>   File \"/Users/nikogamulin/workspace/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/framework/graph_util.py\", line 226, in convert_variables_to_constants\n>     returned_variables = sess.run(variable_names)\n>   File \"/Users/nikogamulin/workspace/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 717, in run\n>     run_metadata_ptr)\n>   File \"/Users/nikogamulin/workspace/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 915, in _run\n>     feed_dict_string, options, run_metadata)\n>   File \"/Users/nikogamulin/workspace/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 965, in _do_run\n>     target_list, options, run_metadata)\n>   File \"/Users/nikogamulin/workspace/tensorflow/bazel-bin/tensorflow/python/tools/freeze_graph.runfiles/org_tensorflow/tensorflow/python/client/session.py\", line 985, in _do_call\n>     raise type(e)(node_def, op, message)\n> tensorflow.python.framework.errors.FailedPreconditionError: Attempting to use uninitialized value InceptionV1/Logits/Conv2d_0c_1x1/biases/Adam_1\n>    [[Node: _send_InceptionV1/Logits/Conv2d_0c_1x1/biases/Adam_1_0 = _Send[T=DT_FLOAT, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=6007788667487390928, tensor_name=\"InceptionV1/Logits/Conv2d_0c_1x1/biases/Adam_1:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](InceptionV1/Logits/Conv2d_0c_1x1/biases/Adam_1)]]\n\nThen I tried to use SGD optimizer instead of Adam and got the following error:\n\n> ...\n> tensorflow.python.framework.errors.FailedPreconditionError: Attempting to use uninitialized value global_step\n>    [[Node: _send_global_step_0 = _Send[T=DT_INT64, client_terminated=true, recv_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device=\"/job:localhost/replica:0/task:0/cpu:0\", send_device_incarnation=8900174487477528080, tensor_name=\"global_step:0\", _device=\"/job:localhost/replica:0/task:0/cpu:0\"](global_step)]]\n\nAnyway, so far I haven't figured out how to get rid of these errors.\n", "I do not how to fix this as well. It seems that Google do not plan to support this, since v1 model is a small one, which fit for iOS device. If everyone could easily fine-tune a v1 model, freeze and convert it to 8bit file for iOS, then there will be no barrier for iOS. see my another post #4790\n", "@civilmanxx thanks for the link. Have you managed to get through first two points, described:\n1, i train inception v1 (slim) on a subset of ImageNet dataset (269 of 1000)\n2, convert .ckpt into .pb by freeze_graph\n\nI encounter the problem when trying to convert .ckpt (along with .pbtxt definition) to .pb. If you successfully converted to .pb, could you please describe how you ran finetuning (1) and conversion (2)?\nAs mentioned, I tried to run finetuning (1) as described in [slim walkthrough notebook](https://github.com/tensorflow/models/blob/master/slim/slim_walkthough.ipynb) and then for freezing (2) the following command:\n`bazel-bin/tensorflow/python/tools/freeze_graph --input_graph=/tmp/inception_finetuned/graph.pbtxt --input_checkpoint=/tmp/inception_finetuned/model.ckpt-2 --output_graph=/Users/nikogamulin/Desktop/freeze.pb --output_node_names=InceptionV1/Logits/Predictions/Softmax`\n\nBesides this, I have also tried to run finetuning with following command:\n\n```\npython train_image_classifier.py \\                 \n    --train_dir=${TRAIN_DIR} \\                                   \n    --dataset_dir=${DATASET_DIR} \\                 \n    --dataset_name=flowers \\                              \n    --dataset_split_name=train \\                          \n    --model_name=inception_v1 \\\n    --checkpoint_path=${CHECKPOINT_PATH} \\\n    --checkpoint_exclude_scopes=InceptionV1/Logits,InceptionV1/AuxLogits/Logits\n```\n\n and then freezing with same comand as in first case and also got an error.\n\nCould you please describe how you ran finetuning (1) - which .pbtxt (or .pb) and .ckpt files you used and after that (2) how you managed to convert the finetuned model into .pb file.\n", "I can't convert fine tuned .ckpt to .pb file, as the error I post above. The solver does not support.\n", "For \"**Attempting to use uninitialized value global_step**\" I met before as well. Is this because you kill the training too early?\n", "I was running finetuning for about 12 hours on flowers dataset. Have you got past uninitialized value global_step error if running for a certain amount of time?\n", "Are you using the latest code. Now I do not meet **Attempting to use uninitialized value global_step** anymore.\n", "There is another example for v3 fine tune and write .pb file directly. I think we can update code to fit v1, which mean we do not need freeze graph anymore.\n\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/image_retraining/retrain.py\n", "@nikogamulin I modify the code of retrain.py to support V1 model. It is done, do you need it?\n", "@civilman628 please share that modified retrain.py to support V1 model.", "just modify the https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/image_retraining/retrain.py\r\n\r\nthis retrain.py is for inception v3. pb.\r\n\r\nmodify the code as below for inception v1.pb.\r\n\r\nDATA_URL = 'https://storage.googleapis.com/download.tensorflow.org/models/inception5h.zip'\r\nBOTTLENECK_TENSOR_NAME = 'avgpool0/reshape:0'\r\nBOTTLENECK_TENSOR_SIZE = 1024\r\nMODEL_INPUT_WIDTH = 224\r\nMODEL_INPUT_HEIGHT = 224\r\nMODEL_INPUT_DEPTH = 3\r\nINPUT = 'input:0'\r\n\r\nlet me know if you have met other issue. you will get a new .pb file, which is fine tuned from inception v1. Just replace \"jpeg tensor\"  with shape 224*224*3*1 tenor for V1", "@civilman628 this dosen't solve the problem. Inception5h file is a .zip and the retrain.py wants a .tgz file. Can you also specify the line number to replace \" \"jpeg tensor\" with 2242243*1 tensor for V1\" and should I add INPUT='input:0'? I didn't get that.\r\n\r\nThe other way, I was able to retrain inceptionV1, generate checkpoints, make a .pb file using freeze tool, optimize it for inference and generate a APK. But the app crashed saying \"**_No Operation named [Mul] in the Graph_**\". Whats the input node name you gave in the **ClassifierActivity.java**?\r\n\r\nI tried giving input names Mul,input,Mul:0,input:0 but nothing worked.\r\nWhen i used optimize_for_inference on the .pb file, I gave **_--input_names=Mul_** and **_--output_names=InceptionV1/Logits/Predictions/Softmax_**\r\n\r\nPlease explain where did you get this information about    **_--output_names=InceptionV1/Logits/Predictions/Softmax_** , as you mentioned [here](https://github.com/tensorflow/tensorflow/issues/4808)", "One way to get the information on the input and output nodes is to run the summarize_graph tool on your frozen file:\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/tools/graph_transforms/summarize_graph_main.cc", "Hi @petewarden, thanks for the reply.\r\nI did that, following is the output\r\nNo inputs spotted.\r\nNo variables spotted.\r\nFound 1 possible outputs: (name=InceptionV1/Logits/Predictions/Softmax, op=Softmax) \r\nFound 5598451 (5.60M) const parameters, 0 (0) variable parameters, and 114 control_edges\r\nOp types used: 472 Const, 230 Mul, 173 Add, 172 Sub, 116 Identity, 114 Sum, 58 Reshape, 58 Conv2D, 57 Rsqrt, 57 Relu, 57 Reciprocal, 57 Square, 57 SquaredDifference, 57 Mean, 57 StopGradient, 13 MaxPool, 9 ConcatV2, 1 Squeeze, 1 RandomUniform, 1 Softmax, 1 RealDiv, 1 QueueDequeueV2, 1 Floor, 1 FIFOQueueV2, 1 BiasAdd, 1 AvgPool\r\n\r\nIf I am not wrong, **\"name=InceptionV1/Logits/Predictions/Softmax\"** is the name of the output node. But how do I know the **_input_node_name_** ?\r\n", "@SubhashKsr if you want to get the node names of graph file, which is .pb file (not ckpt, there are different), use the following code:\r\n\r\n```\r\nfor node in tf.get_default_graph().as_graph_def().node:\r\n       print (node.name)\r\n```\r\n\r\nas you see in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/image_retraining/retrain.py#L261\r\n\r\nclassify_image_graph_def.pb is the file for inception v3. you need to download inception5h.zip which contain inception v1 .pb file and replace v3 .pb file in the line 261. and can comment out the code for download section in .py file.\r\n\r\nfor inception v1, the node names are:\r\n\r\ninput\r\nconv2d0_w\r\nconv2d0_b\r\nconv2d1_w\r\nconv2d1_b\r\nconv2d2_w\r\nconv2d2_b\r\n...\r\n...\r\navgpool0/reshape/shape\r\navgpool0/reshape          (  _here is the bottle neck tensor_ )\r\nsoftmax2_pre_activation/matmul\r\nsoftmax2_pre_activation\r\nsoftmax2\r\noutput\r\noutput1\r\noutput2\r\n============\r\nThe first node in inception v1 is 'input', then you need to use 'input:0' in your code.  'avgpool0/reshape:0' is the bottle neck tensor of V1, which is a 1024 * 1 array. V3's bottle neck tensor is 2048 * 1 array. bottle neck tensor is just N-1 Layer of the CNN model. we call it feature vector.\r\n\r\nV1 does not have a jpeg decode node as V3. For V1's first node  'input', it uses 224 * 224 * 3 * 1 array as input tensor directly. if you print out V3's  node names as below, you will see V3's first node is DecodeJpeg/contents, which means V3 can accept jpg file in any size as the input, then the following nodes will expand dims and resize image as a 299 * 299 * 3 * 1 tensor. The 'Mul' in V3 is equivalent 'input' in V1.\r\nI hope my explanation can help you to find out how to change the retain.py for V1. It is not hard.\r\n\r\nDecodeJpeg/contents\r\nDecodeJpeg\r\nCast\r\nExpandDims/dim\r\nExpandDims\r\nResizeBilinear/size\r\nResizeBilinear\r\nSub/y\r\nSub\r\nMul/y\r\nMul\r\n\r\n\r\n\r\n", "@civilman628   \r\ni am confused regarding the freeze graph issue. I am using the inceptionv3 model , run the train_image_classifier.py for training, and eval_image_classifier for validation. Now i want to test the model on the new images. So can i use eval_image_classifier or do i need to freeze graph for the retrained model and use it for testing by writing another script like label_image.py ? freezing the graph has given me lot of errors. i got the same error as u posted. ", "**In iOS paltform,I meet a new error.but I can not fix it with previous method .Any reply will be appreciated!!**\r\n <tensorflow>Error adding graph to session: No OpKernel was registered to support Op 'AsString' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n  <no registered kernels>\r\n\r\n\t [[Node: O_str = AsString[T=DT_FLOAT, fill=\"\", precision=-1, scientific=false, shortest=false, width=-1](I)]]"]}, {"number": 4765, "title": "Added changes to scoping to the release notes", "body": "The changes to name scoping and variable scoping are important breaking changes and should be listed as major changes.\n", "comments": ["@jonasrauber, thanks for your PR! By analyzing the history of the files in this pull request, we identified @vrv, @gunan and @tensorflower-gardener to be potential reviewers.\n", "Can one of the admins verify this patch?\n", "@martinwicke per your request, the same pull request as #4745 to r0.11 as well\n"]}, {"number": 4764, "title": "Patch 3", "body": "", "comments": ["Can one of the admins verify this patch?\n", "@jonasrauber, thanks for your PR! By analyzing the history of the files in this pull request, we identified @Stibbons, @tensorflower-gardener and @danmane to be potential reviewers.\n", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\n\n<!-- need_author_cla -->\n"]}, {"number": 4763, "title": "Ability to Save Checkpoints Every N Steps using Estimator", "body": "TensorFlow Version: r0.10.0rc0\n\nFor TensorFlow/SKFlow/tf,learn Estimators, there is no option for specifying when an Estimator saves checkpoints other than `save_checkpoints_secs` in a `RunConfig`, which isn't usable for a monitor such as `ValidationMonitor`. For example, if I want to do early stopping and check every 10 steps, it is definitely not guaranteed that new checkpoints were saved for the model, even if I specify `save_checkpoints_secs` to be 1 second.\n### Tried:\n\nIt is currently not possible to use a `CheckpointMonitor` with an `Estimator` (e.g. `LinearClassifier`) as far as I can tell. There is no saver nor Scaffold I can specify that captures the same variables it does normally.\n\nWhen can we expect this capability, and are there workarounds currently?\n", "comments": ["@ispirmustafa might have some thoughts on this.\n", "Any thoughts on this? \n", "You can use `supervisor_save_model_steps` in a RunConfig.\n", "Ok I see that a RunConfig has the `save_checkpoints_steps` parameter in master but not 0.10 nor 0.11. I'll evaluate if it's worth cloning and building master. Thanks\n", "Thanks for the info @ispirmustafa!\n\n@craymichael I'm closing this out, but feel free to comment or open a new issue if you have further problems.\n", "Is save_checkpoints_steps now in version r1.0? I find it really useful. Thanks."]}]