[{"number": 55093, "title": "Create a generation_id for HLO modules that is unique across restarts of a process", "body": "Create a generation_id for HLO modules that is unique across restarts of a process\n", "comments": []}, {"number": 55092, "title": "wip: add stack trace to variable", "body": "wip: add stack trace to variable\n", "comments": []}, {"number": 55091, "title": "Add Gradient Op for Einsum", "body": "Add Gradient Op for Einsum\n", "comments": []}, {"number": 55090, "title": "lite: Use dynamic tensors for large tensors", "body": "lite: Use dynamic tensors for large tensors\n\nThis change introduces a way to use dynamic tensors for large tensors\nto optimize memory usage.\nThanks to new API `EnsureDynamicTensorsAreReleased`, now memory of dynamic\ntensors are deallocated when they are not needed and it helps to improve\nthe overall memory usage.\n", "comments": []}, {"number": 55089, "title": "[ST] Add a pattern to fold tensor.cast inside gml_st.loop.", "body": "[ST] Add a pattern to fold tensor.cast inside gml_st.loop.\n", "comments": []}, {"number": 55088, "title": "PSS Test: Handling more errors to avoid chief failures", "body": "PSS Test: Handling more errors to avoid chief failures\n", "comments": []}, {"number": 55087, "title": "Use most_specific_common_supertype in nest", "body": "Use most_specific_common_supertype in nest\n", "comments": []}, {"number": 55086, "title": "Allow the converter to optionally preserve `TF::AssertOp`.", "body": "Allow the converter to optionally preserve `TF::AssertOp`.\n\nAssert will be essential for training use case (Brella), e.g when validating the checksum. In the past, Assert is directly removed.\n", "comments": []}, {"number": 55085, "title": "[mlir][mhlo][sparse] account for sparse tensor outputs in mhlo to linalg lowering", "body": "[mlir][mhlo][sparse] account for sparse tensor outputs in mhlo to linalg lowering\n", "comments": []}, {"number": 55084, "title": "Use the new libstdcxx abi in devtoolset-9", "body": "Use the new libstdcxx abi in devtoolset-9\n", "comments": []}, {"number": 55083, "title": "Implement split3", "body": "Implement split3\n\nSome refactoring in xnn_define_split_even2 to extract all the checks for valid output dimensions so that we can reuse those checks. Also define a more generic xnn_define_split_even_n that is used by xnn_define_split_even2 and xnn_define_split_even3.\n", "comments": []}, {"number": 55082, "title": "Refactoring of ConvertUnary", "body": "ConvertUnary is rewritten using OpConverterBase", "comments": ["@bixia1 : This PR is a replacement for [PR#54230](https://github.com/tensorflow/tensorflow/pull/54230).\r\nI created it because there are a lot of merge conflicts with some current tensorflow files."]}, {"number": 55081, "title": "test visibility changes", "body": "test visibility changes\n\nFUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/54810 from Intel-tensorflow:gyshi/fiex_remapper_bug 42191f04e6b6880cd50f4f3f43be3c79e5d42dc7\n", "comments": []}, {"number": 55080, "title": "Introduce TensorArray most_specific_common_supertype", "body": "Introduce TensorArray most_specific_common_supertype\n", "comments": []}, {"number": 55079, "title": "Internal only changes", "body": "Internal only changes\n", "comments": []}, {"number": 55078, "title": "[KernelGen][JIT] Register malloc and free symbols to fix Windows", "body": "[KernelGen][JIT] Register malloc and free symbols to fix Windows\n\nRegister malloc/free to avoid using some unintended version from a shared\nlibrary. W/o this, the `ExecutionEngine` will try to resolve the missing symbol\nfrom shared libraries and from the current process. This can lead to using an\nincompatible pair of malloc and free, causing crashes on Windows.\n", "comments": []}, {"number": 55077, "title": "[mlir][mhlo] provide mechanism to register mhlo pass from python", "body": "[mlir][mhlo] provide mechanism to register mhlo pass from python\n", "comments": []}, {"number": 55076, "title": ". . . . . . . . . . . . . . .. . .", "body": ". . . . . . . . . . . . . . .. . .\n", "comments": []}, {"number": 55074, "title": "Add a few properties to ShardedVariable to support Keras saving and loading.", "body": "Add a few properties to ShardedVariable to support Keras saving and loading.\n", "comments": []}, {"number": 55073, "title": "TFHub Object Detection Models Cannot Quantize", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): v2.8.0-rc1-32-g3f878cff5b6 2.8.0\r\n- Python version: 3.8.2\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: Nvidia GeForce GTX 1050 8GB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nWhen taking the Object Detection Saved Models provided on [https://tfhub.dev/tensorflow/collections/object_detection/1](https://tfhub.dev/tensorflow/collections/object_detection/1) and converting them to TFLite with quantization enabled, the model outputted remains as a fully float model.\r\n\r\n**Describe the expected behavior**\r\nWhen converting these Saved Models using quantization enabled, one can produce a quantized TFLite.\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow_hub as hub\r\nimport numpy as np\r\n\r\ndef dataset_gen():\r\n    for _ in range(10):\r\n        yield [np.random.randint(0,256, [1,300,300,3]).astype(np.uint8)]\r\n\r\ninputs = tf.keras.Input(shape=(300,300,3), dtype=tf.uint8)\r\nlayers = hub.KerasLayer('https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2')(inputs)\r\nkeras_model = tf.keras.Model(inputs=inputs, outputs=layers)\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(keras_model)\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.representative_dataset = dataset_gen\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS] # [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\r\ntflite_model = converter.convert()\r\n\r\nwith open('ssd_mobilenet_v2_tfhub_quant.tflite', 'wb') as f:\r\n    f.write(tflite_model)\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n>>> tflite_model = converter.convert()\r\n2022-03-07 10:52:09.875517: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\r\nWARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 50). These functions will not be directly callable after loading.\r\nINFO:tensorflow:Assets written to: C:\\Users\\m\\AppData\\Local\\Temp\\tmpmpwp187_\\assets\r\nINFO:tensorflow:Assets written to: C:\\Users\\m\\AppData\\Local\\Temp\\tmpmpwp187_\\assets\r\nC:\\Users\\m\\venv\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:746: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\r\n  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\r\n2022-03-07 10:54:23.844584: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:357] Ignored output_format.\r\n2022-03-07 10:54:23.845355: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:360] Ignored drop_control_dependency.\r\n2022-03-07 10:54:23.864084: I tensorflow/cc/saved_model/reader.cc:43] Reading SavedModel from: C:\\Users\\m_qui\\AppData\\Local\\Temp\\tmpmpwp187_\r\n2022-03-07 10:54:24.146714: I tensorflow/cc/saved_model/reader.cc:78] Reading meta graph with tags { serve }\r\n2022-03-07 10:54:24.147497: I tensorflow/cc/saved_model/reader.cc:119] Reading SavedModel debug info (if present) from: C:\\Users\\m_qui\\AppData\\Local\\Temp\\tmpmpwp187_\r\n2022-03-07 10:54:27.534765: I tensorflow/cc/saved_model/loader.cc:228] Restoring SavedModel bundle.\r\n2022-03-07 10:54:32.634691: I tensorflow/cc/saved_model/loader.cc:212] Running initialization op on SavedModel bundle at path: C:\\Users\\m\\AppData\\Local\\Temp\\tmpmpwp187_\r\n2022-03-07 10:54:35.731075: I tensorflow/cc/saved_model/loader.cc:301] SavedModel load for tags { serve }; Status: success: OK. Took 11867479 microseconds.\r\n2022-03-07 10:54:40.800205: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:237] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\r\nfully_quantize: 0, inference_type: 6, input_inference_type: 0, output_inference_type: 0\r\n", "comments": ["@chunduriv Was able to replicate the issue on colab using TF v2.8.0 and tf-nightly(2.9.0.dev20220313) , please find the gist [here](https://colab.research.google.com/gist/sushreebarsa/3f71fef4636fee678c63a7201dde0575/55073.ipynb).Thanks!", "Hi @msquigle ! You can get an integer quantized model by adding the three lines after the representative dataset. Attaching [gist ](https://colab.sandbox.google.com/gist/mohantym/327abcfd4207f73611011758ce73fb82/github_55073.ipynb)for reference.\r\n```\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\r\n# Set the input and output tensors to uint8 (APIs added in r2.3)\r\nconverter.inference_input_type = tf.uint8\r\nconverter.inference_output_type = tf.uint8\r\n```", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55073\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55073\">No</a>\n"]}, {"number": 55071, "title": "Add flatbuffer conversions for while operator.", "body": "Add flatbuffer conversions for while operator.\n", "comments": []}, {"number": 55070, "title": "Fix fuchsia build errors.", "body": "Fix fuchsia build errors.\n\nThis command now succeeds: `blaze build //third_party/tensorflow/core/kernels/data/experimental:assert_prev_dataset_op --config=force_compact_protos --config=portable_proto_force_google3_compact --config=no_whole_archive --config=no_whole_archive --config=fuchsia --compilation_mode=opt --strip=never --copt=-fvisibility=hidden`.\n", "comments": []}, {"number": 55069, "title": "Refactor logic to create and setup split operators to allow them to be reused by split3/split4 in the future", "body": "Refactor logic to create and setup split operators to allow them to be reused by split3/split4 in the future\n", "comments": []}, {"number": 55068, "title": "Add flatbuffer conversions for while operator.", "body": "Add flatbuffer conversions for while operator.\n", "comments": []}, {"number": 55066, "title": "Transpose modified to support uint/int tensors.", "body": "Transpose modified to support uint/int tensors.\n", "comments": []}, {"number": 55064, "title": "MaxUnpooling kernel updated to support more input tensor types.", "body": "MaxUnpooling kernel updated to support more input tensor types.\n", "comments": []}, {"number": 55063, "title": "[tfrt:jit] Move signless conversion right after HLO->Linalg.", "body": "[tfrt:jit] Move signless conversion right after HLO->Linalg.\n", "comments": []}, {"number": 55062, "title": "More add tests for int/uint types.", "body": "More add tests for int/uint types.\n", "comments": []}, {"number": 55061, "title": "TensorDescriptor Read/Write improved to support all conversions.", "body": "TensorDescriptor Read/Write improved to support all conversions.\n", "comments": []}, {"number": 55060, "title": "`val_loss` is not available in training", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Window 10 - 21H2\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary): No\r\n- TensorFlow version (use command below): v2.8.0-rc1-32-g3f878cff5b6 2.8.0\r\n- Python version: 3.8.12 (default, Oct 12 2021, 03:01:40) [MSC v.1916 64 bit (AMD64)]\r\n- Bazel version (if compiling from source): No\r\n- GCC/Compiler version (if compiling from source): No\r\n- CUDA/cuDNN version:\r\n_Built on Fri_Dec_17_18:28:54_Pacific_Standard_Time_2021\r\nCuda compilation tools, release 11.6, V11.6.55\r\nBuild cuda_11.6.r11.6/compiler.30794723_0_\r\n- GPU model and memory: GTX 1080 - 8 GB\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nI train a multi-scale deep convolutional autoencoder. After some epochs `val_loss` cannot be identified by tensorflow callbacks any more:\r\n_WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr\r\nWARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,accuracy,lr_\r\n\r\nMy callbacks are:\r\n```python3\r\n    callbacks = [tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\r\n                                                      factor=0.5, patience=8, min_lr=0.00001),\r\n                 tf.keras.callbacks.ModelCheckpoint(\"models/ms-model1-1\", monitor=\"val_loss\"),\r\n                 tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=25),\r\n                 tf.keras.callbacks.TensorBoard(log_dir=\"train/ms-log1-1/\", histogram_freq=1),\r\n                 tf.keras.callbacks.ModelCheckpoint('models/ms-models-epochs/model{epoch:08d}', period=5)]\r\n```\r\nThe last `ModelCheckpoint` callback I added to work around this bug. This sadly means that I have to put more work into it, in order for it to work as I have to reduce the LR manually.\r\n\r\nIn tensorboard it looks like this:\r\n![grafik](https://user-images.githubusercontent.com/16071970/157038199-bf8110cb-57e6-46ae-8c86-8881afd66d5c.png)\r\n\r\nYou can see that the `val_loss` is not even calculated any more. This happens after epoch 4, so after the `ModelCheckpoint` was first reached.\r\n\r\n**Describe the expected behavior**\r\n\r\nThe expected behaviour would be that `val_loss` is further calculated and can therefore also be used in the `ModelCheckpoint`s, `EarlyStopping`s and other callbacks I use.\r\n\r\nI am not entirely sure if it is me using the library wrong or whether it really fails due to a bug (I am by no means an expert in TF). The code for the network generation is also included in the PR, the data sets are too big though and are not online available. The used data are Copernicus 4 channel 256x256 images. This is why I did not include the dataloading code as it seems irrelevant to me (I can include it though if you need it).\r\n\r\n**[Contributing](https://www.tensorflow.org/community/contribute)**\r\n\r\n- Do you want to contribute a PR? (yes/no): no (found a hacky workaround which is good enough for my problem)\r\n- Briefly describe your candidate solution(if contributing): N/A\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n``` python3\r\ndef create_normalized_convolution(filters: int,\r\n                                  activation=None,\r\n                                  strides=1,\r\n                                  kernel_size=3,\r\n                                  padding='SAME',\r\n                                  seq_name=None,\r\n                                  **kwargs) -> tf.keras.Sequential:\r\n    if activation is None:\r\n        activation = LeakyReLU()\r\n    return tf.keras.Sequential([\r\n        Conv2D(filters=filters, strides=strides, kernel_size=kernel_size, padding=padding, **kwargs),\r\n        BatchNormalization(),\r\n        activation\r\n    ], seq_name)\r\n\r\n\r\ndef create_normalized_convolution_transpose(filters: int,\r\n                                            activation=None,\r\n                                            strides=1,\r\n                                            kernel_size=3,\r\n                                            padding='SAME',\r\n                                            seq_name=None,\r\n                                            **kwargs) -> tf.keras.Sequential:\r\n    if activation is None:\r\n        activation = LeakyReLU()\r\n    return tf.keras.Sequential([\r\n        Conv2DTranspose(filters=filters, strides=strides, kernel_size=kernel_size, padding=padding, **kwargs),\r\n        BatchNormalization(),\r\n        activation\r\n    ], name=seq_name)\r\n\r\n\r\nclass BaseAutoencoder(tf.keras.Model):\r\n    \"\"\"\r\n    Base class for all used AEs.\r\n    The advantage of a base class is that it only requires you to specify the network structure in the constructor and\r\n    removes almost all boilerplate code.\r\n    \"\"\"\r\n\r\n    def __init__(self, latent_dim: int, image_size=256, channels=4):\r\n        super(BaseAutoencoder, self).__init__()\r\n\r\n        self._latent_dim = latent_dim\r\n        self._image_size = image_size\r\n        self._channels = channels\r\n        self._encoder: tf.keras.Sequential = None\r\n        self._decoder: tf.keras.Sequential = None\r\n\r\n    def get_latent_dim(self) -> int:\r\n        return self._latent_dim\r\n\r\n    def get_image_size(self) -> int:\r\n        return self._image_size\r\n\r\n    def get_channels(self) -> int:\r\n        return self._channels\r\n\r\n    def call(self, inputs):\r\n        bottleneck = self._encoder(inputs)\r\n        return self._decoder(bottleneck)\r\n\r\n    def encoder(self) -> tf.keras.Sequential:\r\n        return self._encoder\r\n\r\n    def decoder(self) -> tf.keras.Sequential:\r\n        return self._decoder\r\n\r\n\r\nclass MultiscaleAutoencoder(BaseAutoencoder):\r\n    \"\"\"\r\n    A custom multiscale implementation of an AutoEncoder.\r\n    \"\"\"\r\n\r\n    def __init__(self, latent_dim: int, image_size=256, channels=4, base_filter_count=32):\r\n        super(MultiscaleAutoencoder, self).__init__(latent_dim, image_size, channels)\r\n        self._base_filter_count = base_filter_count\r\n\r\n        raw_inp = Input(shape=(image_size, image_size, channels), dtype=tf.float32)\r\n        enc_inp = InputLayer(name='Input-ENCODER_0')(raw_inp)\r\n\r\n        high_res_enc = tf.keras.Sequential([\r\n            create_normalized_convolution(filters=base_filter_count,\r\n                                          strides=2,\r\n                                          seq_name=\"NormConv-LeakyReLU-HR_ENCODER_1\"),\r\n            create_normalized_convolution(filters=base_filter_count * 2,\r\n                                          strides=2,\r\n                                          seq_name=\"NormConv-LeakyReLU-HR_ENCODER_2\"),\r\n            create_normalized_convolution(filters=base_filter_count * 4,\r\n                                          strides=2,\r\n                                          seq_name=\"NormConv-LeakyReLU-HR_ENCODER_3\"),\r\n            create_normalized_convolution(filters=base_filter_count * 8,\r\n                                          strides=2,\r\n                                          seq_name=\"NormConv-LeakyReLU-HR_ENCODER_4\"),\r\n        ], name=\"HighResolution_ENCODER\")(enc_inp)\r\n\r\n        med_res = MaxPooling2D(padding='same', name=\"MaxPoolingMR_ENCODER\")(enc_inp),\r\n\r\n        medium_res_enc = tf.keras.Sequential([\r\n            create_normalized_convolution(filters=base_filter_count * 2,\r\n                                          strides=2,\r\n                                          seq_name=\"NormConv-LeakyReLU-MR_ENCODER_1\",\r\n                                          input_shape=(int(image_size / 2), int(image_size / 2), channels)),\r\n            create_normalized_convolution(filters=base_filter_count * 4,\r\n                                          strides=2,\r\n                                          seq_name=\"NormConv-LeakyReLU-MR_ENCODER_2\"),\r\n            create_normalized_convolution(filters=base_filter_count * 8,\r\n                                          strides=2,\r\n                                          seq_name=\"NormConv-LeakyReLU-MR_ENCODER_3\"),\r\n        ], name=\"MediumResolution_ENCODER\")(med_res)\r\n\r\n        low_res_enc = tf.keras.Sequential([\r\n            MaxPooling2D(padding='same', name=\"MaxPoolingLR_ENCODER\",\r\n                         input_shape=(int(image_size / 2), int(image_size / 2), channels)),\r\n            create_normalized_convolution(filters=base_filter_count * 4,\r\n                                          strides=2,\r\n                                          seq_name=\"NormConv-LeakyReLU-LR_ENCODER_1\"),\r\n            create_normalized_convolution(filters=base_filter_count * 8,\r\n                                          strides=2,\r\n                                          seq_name=\"NormConv-LeakyReLU-LR_ENCODER_2\"),\r\n        ], name=\"LowResolution_ENCODER\")(med_res)\r\n\r\n        lower_res_concat = concatenate([\r\n            medium_res_enc,\r\n            low_res_enc\r\n        ], name=\"LowerResolutionsMerger_ENCODER\")\r\n\r\n        res_concat = Concatenate(name=\"Multiscale-ENCODER_2\")([\r\n            high_res_enc,\r\n            lower_res_concat,\r\n        ])\r\n\r\n        conv_3_enc = create_normalized_convolution(filters=self._latent_dim ** 2 * 3,\r\n                                                   seq_name=\"NormConv-LeakyReLU_ENCODER_3\")(res_concat)\r\n        glob_max_pool_enc = GlobalMaxPool2D(name=\"GlobalMaxPooling_ENCODER_4\")(conv_3_enc)\r\n        out_enc = Dense(self._latent_dim ** 2 * 3, name=\"Dense-ENCODER_5\")(glob_max_pool_enc)\r\n\r\n        self._encoder = tf.keras.Model(inputs=raw_inp, outputs=out_enc, name=\"Encoder\")\r\n\r\n        raw_dec_inp = Input(shape=(self._latent_dim ** 2 * 3), dtype=tf.float32)\r\n        dec_inp = InputLayer(name='Input-DECODER_0')(raw_dec_inp)\r\n\r\n        reshape_dec = Reshape(target_shape=[self._latent_dim, self._latent_dim, 3], name='Reshape-DECODER_1')(dec_inp)\r\n        conv_1_dec = create_normalized_convolution_transpose(filters=self._latent_dim ** 2 * 3,\r\n                                                             seq_name=\"NormConv-LeakyReLU_ENCODER_2\")(reshape_dec)\r\n\r\n        hr_dec = tf.keras.Sequential([\r\n            create_normalized_convolution_transpose(filters=base_filter_count * 8,\r\n                                                    strides=2,\r\n                                                    seq_name=\"NormConv-LeakyReLU-HR_DECODER_1\"),\r\n            create_normalized_convolution_transpose(filters=base_filter_count * 4,\r\n                                                    strides=2,\r\n                                                    seq_name=\"NormConv-LeakyReLU-HR_DECODER_2\"),\r\n            create_normalized_convolution_transpose(filters=base_filter_count * 2,\r\n                                                    strides=2,\r\n                                                    seq_name=\"NormConv-LeakyReLU-HR_DECODER_3\"),\r\n            create_normalized_convolution_transpose(filters=base_filter_count,\r\n                                                    strides=2,\r\n                                                    seq_name=\"NormConv-LeakyReLU-HR_DECODER_4\")\r\n        ], name=\"HighResolution_DECODER\")(conv_1_dec)\r\n\r\n        mr_dec = tf.keras.Sequential([\r\n            create_normalized_convolution_transpose(filters=base_filter_count * 8,\r\n                                                    strides=2,\r\n                                                    seq_name=\"NormConv-LeakyReLU-MR_DECODER_1\"),\r\n            create_normalized_convolution_transpose(filters=base_filter_count * 4,\r\n                                                    strides=2,\r\n                                                    seq_name=\"NormConv-LeakyReLU-MR_DECODER_2\"),\r\n            create_normalized_convolution_transpose(filters=base_filter_count * 2,\r\n                                                    strides=2,\r\n                                                    seq_name=\"NormConv-LeakyReLU-MR_DECODER_3\")\r\n        ], name=\"MediumResolution_DECODER\")(conv_1_dec)\r\n\r\n        lr_dec = tf.keras.Sequential([\r\n            create_normalized_convolution_transpose(filters=base_filter_count * 8,\r\n                                                    strides=2,\r\n                                                    seq_name=\"NormConv-LeakyReLU-LR_DECODER_1\"),\r\n            create_normalized_convolution_transpose(filters=base_filter_count * 4,\r\n                                                    strides=2,\r\n                                                    seq_name=\"NormConv-LeakyReLU-LR_DECODER_2\"),\r\n            UpSampling2D(name=\"UpSampling2x-LR_DECODER\")\r\n        ], name=\"LowResolution_DECODER\")(conv_1_dec)\r\n\r\n        concat_lower_res = Concatenate(name=\"LowerResolutionsMerger_DECODER\")([\r\n            mr_dec,\r\n            lr_dec\r\n        ])\r\n\r\n        up_sample_mr = UpSampling2D(name=\"UpSampling2x-MR_DECODER\")(concat_lower_res)\r\n\r\n        concat_high_res = Concatenate(name=\"HighResolutionMerger_DECODER\")([\r\n            hr_dec,\r\n            up_sample_mr\r\n        ])\r\n\r\n        norm_conv_4_dec = create_normalized_convolution_transpose(\r\n            filters=4,\r\n            activation=Activation('sigmoid'),\r\n            seq_name='NormConv-Sigmoid-DECODER_4'\r\n        )(concat_high_res)\r\n\r\n        self._decoder = tf.keras.Model(inputs=raw_dec_inp, outputs=norm_conv_4_dec, name='Decoder')\r\n\r\n\r\nBATCH_SIZE = 24\r\nIMG_SIZE = 256\r\nmodel = autoencoder.MultiscaleAutoencoder(16)\r\ncallbacks = [tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\r\n                                                      factor=0.5, patience=8, min_lr=0.00001),\r\n                 tf.keras.callbacks.ModelCheckpoint(\"models/ms-model1-1\", monitor=\"val_loss\"),\r\n                 tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=25),\r\n                 tf.keras.callbacks.TensorBoard(log_dir=\"train/ms-log1-1/\", histogram_freq=1),\r\n                 tf.keras.callbacks.ModelCheckpoint('models/ms-models-epochs/model{epoch:08d}', period=5)]\r\nmodel.build(tf.TensorShape((None, IMG_SIZE, IMG_SIZE, 4)))\r\nloss = MeanAbsoluteError()\r\nmodel.compile(optimizer=tf.keras.optimizers.Adamax(learning_rate=0.032), loss=loss, metrics=['accuracy'])\r\nmodel.fit(train_ds_final,\r\n          validation_data=val_ds_final,\r\n          epochs=150,\r\n          callbacks=callbacks,\r\n          shuffle=True)\r\n```\r\n", "comments": ["@cb0s, Thanks for opening this issue. Development of keras moved to separate repository https://github.com/keras-team/keras/issues\r\n\r\nPlease post this issue on keras-team/keras repo.\r\nTo know more see;\r\nhttps://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999. Thanks!", "\"Transferred\" to [keras-repository](https://github.com/keras-team/keras/issues/16215). Do you want me to close the issue then?", "@cb0s, \r\n\r\nYes, can you please close this issue, since it is tracked https://github.com/keras-team/keras/issues/16215. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55060\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/55060\">No</a>\n"]}]