[{"number": 47731, "title": "micro: CUMSUM PR1", "body": "Extract the parsing out of a switch statement case to create a\r\nstandalone function which can be called by the micro op resolver.\r\n\r\nPR step 1 for issue #47290", "comments": []}, {"number": 47730, "title": "[ROCm] Fix for ROCm CSB breakage - 210311", "body": "The following commit breaks the ROCm CSB (errors while running GPU unit tests)\r\n\r\nhttps://github.com/tensorflow/tensorflow/pull/47398\r\n\r\n```\r\nERROR: /root/tensorflow/tensorflow/compiler/xla/service/gpu/tests/BUILD:573:13: undeclared inclusion(s) in rule '//tensorflow/compiler/xla/service/gpu/tests:hlo_to_llvm_ir':\r\nthis rule is missing dependency declarations for the following files included by 'tensorflow/compiler/xla/service/gpu/tests/hlo_to_llvm_ir.cc':\r\n  'tensorflow/compiler/xla/service/gpu/nvptx_compiler.h'\r\nTarget //tensorflow/compiler/xla/service/gpu/tests:constant.hlo.test failed to build\r\n```\r\n\r\nThis PR/commit fixes the ROCm build, by making the newly added functionality specific to the TF CUDA build.\r\n\r\nLong term, we need to add similar capability to the ROCM side, but for now this workaround is needed to get the ROCm CSB working again.\r\n\r\n----------------------------------\r\n\r\n/cc @cheshire @chsigg @penpornk ", "comments": ["It's up to you how to do this. I'll approve, but it's a bit annoying to lose this coverage for ROCm, and ideally the target should be separated into the common part and the NVIDIA-specific part.", "ah, actually you did this already. Great!", "@deven-amd Can you please resolve conflicts? Thanks!", "@gbaned The PR ( https://github.com/tensorflow/tensorflow/pull/47398) that broke ROCm build (and thus required this fix) seems to have been reverted ( https://github.com/tensorflow/tensorflow/commit/99b9d93780d68190ba0f7b8c3b97c665fc63077b) . \r\n\r\nSo it seems that this PR is no longer required. Do you want me to close this PR, or leave it around because we will need it once PR #47398  is admitted again?\r\n\r\n@mihaimaruseac @sanjoy @nouiz j just FYI. \r\nAny chance, we can make the commits in this PR, part of PR #47398 when it gets re-submitted? That way we can ensure it does not break the ROCm build to begin with.\r\n\r\nthanks", "Can we merge this with #47398 (cloned for resubmission)?", "I re-reverted my original MR, then applied your commits and then applied the missing commits from my original MR:\r\n\r\nhttps://github.com/tensorflow/tensorflow/pull/47707/\r\n\r\n@mihaimaruseac can you confirm that it works on your side, so then when they merge it, it hopefully won't break their internal tests? (Note, I'm not sure if their internal failure is your or something else, I didn't see the internal error).", "Closing out this PR as the commits in this PR were merged in as part of #47707 \r\n\r\nthank you @nouiz "]}, {"number": 47729, "title": "keras.io List of topics on the right cannot be navigated", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue: \r\nhttps://keras.io/guides/training_with_built_in_methods/\r\nIt is an example. \r\nThis issue applies to the whole site\r\n\r\n## Description of issue (what needs changing): \r\nList of topics on the right cannot be navigated at keras.io\r\n\r\n### Clear description\r\nWhen navigating docs at keras.io when the list of topics on the right (LOTOR) is longer than the browser height you cannot touch topics in the bottom. There is no scroll on the page, so the topics are un reachable.\r\n\r\n### Suggested solution\r\nLOTOR is fixed in position now \r\nLOTOR should have a scroll bar or move with all the page \r\n\r\nMany thanks", "comments": ["<img width=\"1348\" alt=\"Screen Shot 2021-03-22 at 3 03 50 PM\" src=\"https://user-images.githubusercontent.com/42785357/112064315-00965a80-8b20-11eb-8084-9d60247af9a7.png\">\r\n\r\nI see that the last topic on the right hand side index table fits exactly on the bottom of the screen and there is no more content to scroll down.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n"]}, {"number": 47727, "title": "Fix typo on post_training_float16_quant.ipynb", "body": "", "comments": ["Check out this pull request on&nbsp; <a href=\"https://app.reviewnb.com/tensorflow/tensorflow/pull/47727\"><img align=\"absmiddle\"  alt=\"ReviewNB\" height=\"28\" class=\"BotMessageButtonImage\" src=\"https://raw.githubusercontent.com/ReviewNB/support/master/images/button_reviewnb.png\"/></a> \n\n See visual diffs & provide feedback on Jupyter Notebooks. \n\n---\n\n <i>Powered by <a href='https://www.reviewnb.com/?utm_source=gh'>ReviewNB</a></i>", "\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F47727) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!"]}, {"number": 47726, "title": "updated convolutional_recurrent.py to include 1D, 2D, and 3D ConvLSTM instances.", "body": "Updating ConvLSTM to include 1D & 3D cases, as suggested by [this thread](https://github.com/tensorflow/tensorflow/issues/42399).\r\n\r\n- Implementation involves creating Base N-dimensional `ConvRNN`, `ConvLSTMCell`, and `ConvLSTM` classes which are inherited from by the concrete implementations in `ConvLSTM1D`, `ConvLSTM2D`, and `ConvLSTM3D`. Currently limited to 3D as maximum Convolution dimensionality as that is the highest rank implemented in `keras.backend`.\r\n\r\n- Rewrote tests to include 1D & 3D cases. The error message present in ConvLSTM2D as documented by [this thread](https://github.com/tensorflow/tensorflow/issues/36901) is still persistent. ", "comments": ["@mattlyon93  Can you please resolve conflicts? Thanks!", "@mattlyon93  Can you please check @fchollet's comments and keep us posted ? Thanks!", "This PR has been merged: https://github.com/keras-team/keras/commit/214d11055890d5f3dcc83d2af69ad17089b8177d"]}, {"number": 47725, "title": "Keras tuner - Incorrect parameters for model training", "body": "URL with the issue: \r\nhttps://www.tensorflow.org/tutorials/keras/keras_tuner#instantiate_the_tuner_and_perform_hypertuning\r\n\r\nDescription of issue (what needs changing):\r\n\r\nOn the second to last code cell where the hypermodel  is re-instantiated and trained with the optimal number of epochs, the test set is incorrectly used for the fit process. The train set should be used for this process, since we then proceed to evaluate the model on the test set in the final code block.\r\n\r\nIs the link to the source code correct?\r\n\r\nYes\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\nYes\r\n\r\nAre return values defined?\r\n\r\nYes\r\n\r\nAre you planning to also submit a pull request to fix the issue?\r\n\r\nYes, here: https://github.com/tensorflow/docs/pull/1844", "comments": ["@jvishnuvardhan Already made a PR for this(?)", "@yiannisEfth Sorry, I didn't notice that you have already raised a PR. \r\n\r\nI looked at the tutorial and noticed the typo you mentioned and updated the tutorial. My PR already merged and `master` version is already updated with the change. You can check the `master` version [here](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/keras_tuner.ipynb). Thanks! The updates will take some time to show up in the TF website.\r\n\r\nI am closing this issue as the related PR got updated. As you have more updates in your PR, Please raise another issue and update the PR accordingly. Sorry for missing your PR. Thanks! \r\n", "@jvishnuvardhan No probs! Raised a new issue and linked the PR here: https://github.com/tensorflow/tensorflow/issues/47848", "@yiannisEfth Thanks for your understanding and your contribution."]}, {"number": 47724, "title": "GPU and CPU gradients diverge in TF 2.4 for approximate gelu activation", "body": "Hi,\r\n\r\nUpon upgrading from TF 2.2 to TF 2.4, my team noticed a problem with an approximate version of `gelu` shown below as `gelu_approximate`, which exists also in TF v2.4 as `tf.nn.gelu(approximate=True)`. The gradients for `gelu_approximate` calculated on the GPU diverge from the gradients on the CPU as the input gets farther from 0. Since the implementation of `gelu_approximate` consists of primitives `tanh`, `pow`, etc, we should make sure something more fundamental isn't broken in TF. Please see the following reproduce code, which prints `\"GPU and CPU gradients are not close!\"` for v2.4 but not for v2.2.\r\n\r\n```python\r\n# gelu_problem.py\r\nimport numpy as np\r\nimport pandas as pd\r\nimport tensorflow as tf\r\nimport matplotlib.pyplot as plt\r\n \r\n\r\ndef gelu_approximate(x):\r\n    # Copied and inlined from tf.nn.gelu(approximate=True) which exists in TF v2.4 but not TF v2.2\r\n    return 0.5 * x * (1.0 + tf.tanh(0.7978845608028654 * (x + 0.044715 * tf.pow(x, 3))))\r\n\r\n\r\ndef gelu_gradient(x, device):\r\n    with tf.GradientTape() as tape:\r\n        tape.watch(x)\r\n        with tf.device(device):\r\n            y = gelu_approximate(x)\r\n    return tape.gradient(y, x)\r\n \r\n \r\ndef main():\r\n    print(f\"TF version is {tf.__version__}\")\r\n    x = tf.linspace(-500.0, 500.0, 500)\r\n    cpu = gelu_gradient(x, \"/CPU:0\")\r\n    gpu = gelu_gradient(x, \"/GPU:0\")\r\n    abs_error = np.abs(cpu - gpu)\r\n    df = pd.DataFrame(dict(cpu=cpu, gpu=gpu, abs_error=abs_error), index=x)\r\n    try:\r\n        np.testing.assert_allclose(cpu, gpu, atol=1e-3)\r\n    except (AssertionError,) as e:\r\n        print(\"GPU and CPU gradients are not close!\")\r\n        print(e)\r\n    df.plot(title=\"CPU vs. GPU gradients for tf.nn.gelu(approximate=True)\")\r\n    plt.show()\r\n \r\n \r\nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n\r\nOutput on our system:\r\n\r\n```\r\n$ nvidia-smi\r\nWed Mar 10 15:49:02 2021      \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|                               |                      |               MIG M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla V100-PCIE...  Off  | 00000000:04:00.0 Off |                    0 |\r\n| N/A   39C    P0    42W / 250W |  29877MiB / 32510MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n|   1  Tesla V100-PCIE...  Off  | 00000000:06:00.0 Off |                    0 |\r\n| N/A   40C    P0    38W / 250W |  31045MiB / 32510MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n|   2  Tesla V100-PCIE...  Off  | 00000000:07:00.0 Off |                    0 |\r\n| N/A   40C    P0    37W / 250W |  31045MiB / 32510MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n|   3  Tesla V100-PCIE...  Off  | 00000000:08:00.0 Off |                    0 |\r\n| N/A   41C    P0    38W / 250W |  31045MiB / 32510MiB |      0%      Default |\r\n|                               |                      |                  N/A |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                                \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                                  |\r\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n|        ID   ID                                                   Usage      |\r\n|=============================================================================|\r\n|    0   N/A  N/A   4126251      C   .../3/7/x/dist/bin/python3.7    29871MiB |\r\n|    1   N/A  N/A   4126251      C   .../3/7/x/dist/bin/python3.7    31039MiB |\r\n|    2   N/A  N/A   4126251      C   .../3/7/x/dist/bin/python3.7    31039MiB |\r\n|    3   N/A  N/A   4126251      C   .../3/7/x/dist/bin/python3.7    31039MiB |\r\n+-----------------------------------------------------------------------------+\r\n \r\n$ python -um gelu_problem\r\n2021-03-10 15:48:44.908579: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\r\nTF version is 2.4.0\r\n2021-03-10 15:48:50.149409: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-03-10 15:48:50.150776: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\r\n2021-03-10 15:48:50.220817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:\r\npciBusID: 0000:04:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\r\ncoreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\r\n2021-03-10 15:48:50.220842: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\r\n2021-03-10 15:48:50.224004: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\r\n2021-03-10 15:48:50.224038: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\r\n2021-03-10 15:48:50.226493: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\r\n2021-03-10 15:48:50.227454: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\r\n2021-03-10 15:48:50.229775: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\r\n2021-03-10 15:48:50.231379: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\r\n2021-03-10 15:48:50.235484: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\r\n2021-03-10 15:48:50.237107: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2021-03-10 15:48:50.237501: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-03-10 15:48:50.239017: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-03-10 15:48:50.239769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties:\r\npciBusID: 0000:04:00.0 name: Tesla V100-PCIE-32GB computeCapability: 7.0\r\ncoreClock: 1.38GHz coreCount: 80 deviceMemorySize: 31.75GiB deviceMemoryBandwidth: 836.37GiB/s\r\n2021-03-10 15:48:50.239789: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\r\n2021-03-10 15:48:50.239805: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\r\n2021-03-10 15:48:50.239819: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\r\n2021-03-10 15:48:50.239832: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\r\n2021-03-10 15:48:50.239845: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\r\n2021-03-10 15:48:50.239858: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\r\n2021-03-10 15:48:50.239872: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\r\n2021-03-10 15:48:50.239885: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\r\n2021-03-10 15:48:50.241280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\r\n2021-03-10 15:48:50.241307: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\r\n2021-03-10 15:48:51.004798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2021-03-10 15:48:51.004834: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0\r\n2021-03-10 15:48:51.004839: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N\r\n2021-03-10 15:48:51.010315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1908 MB memory) -> physical GPU (device: 0, name: Tesla V100-PCIE-32GB, pci bus id: 0000:04:00.0, compute capability: 7.0)\r\nGPU and CPU gradients are not close!\r\n \r\nNot equal to tolerance rtol=1e-07, atol=0.001\r\n \r\nMismatched elements: 466 / 500 (93.2%)\r\nMax absolute difference: 3.1899037\r\nMax relative difference: 1.\r\n x: array([ 0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\r\n        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,\r\n        0.      ,  0.      ,  0.      ,  0.      ,  0.      ,  0.      ,...\r\n y: array([-3.189903e+00, -3.151703e+00, -3.113807e+00, -3.076217e+00,\r\n       -3.038931e+00, -3.001947e+00, -2.965265e+00, -2.928882e+00,\r\n       -2.892799e+00, -2.857012e+00, -2.821522e+00, -2.786328e+00,...\r\n```\r\n\r\n![gelu_problem](https://user-images.githubusercontent.com/18267168/110800398-21220300-824a-11eb-85a9-4dfee7af8334.png)\r\n\r\nThis particular system is running Debian Linux, version 9.13. Python is version 3.7.9, TF is version 2.4.0. CUDNN is 7.6.5 and CUDA is 10.1.\r\n\r\nThank you,\r\n\r\nBen and team", "comments": ["`tf.nn.gelu` doesn't exist in TF 2.2, as it was introduced in TF 2.4. How were you able to run it in TF 2.2?", "> `tf.nn.gelu` doesn't exist in TF 2.2, as it was introduced in TF 2.4. How were you able to run it in TF 2.2?\r\n\r\n@reedwm our mistake when editing this example to make it shorter. (However, the original issue still applies). We had copied the function as it exists in TF 2.4 into our own function. I had edited it out just before this submission believing that `tf.nn.gelu` was in both versions, to make the submission shorter. Please just inline and copy the contents of `tf.nn.gelu` when the `approximate=True` branch is taken, instead of calling `tf.nn.gelu`, to get a bug-free repro in TF v2.2. This is what we had done initially. I can update the example above to reflect that change. Thanks.", "For more context, the approximation we used prior to TF 2.4 came from [this paper](https://arxiv.org/pdf/1606.08415.pdf). The `tf.nn.gelu(approximate=True)` happens to boil down to the same function we were using before the upgrade.", "Thank you for filing this issue. If tanh is run on the CPU, then your example passes, so the isuse is with tanh:\r\n\r\n```python\r\n# gelu_problem.py, but tanh is run on CPU which causes this to work correctly\r\nimport numpy as np\r\nimport pandas as pd\r\nimport tensorflow as tf\r\nimport matplotlib.pyplot as plt\r\n\r\n\r\ndef tanh_cpu(x):\r\n  with tf.device('/CPU:0'):\r\n    return tf.tanh(x)\r\n\r\n\r\ndef gelu_approximate(x, run_tanh_on_cpu):\r\n  tanh = tanh_cpu if run_tanh_on_cpu else tf.tanh\r\n  # Copied and inlined from tf.nn.gelu(approximate=True) which exists in TF v2.4 but not TF v2.2\r\n  return 0.5 * x * (1.0 + tanh(0.7978845608028654 * (x + 0.044715 * tf.pow(x, 3))))\r\n\r\n\r\ndef gelu_gradient(x, device, run_tanh_on_cpu):\r\n  with tf.GradientTape() as tape:\r\n    tape.watch(x)\r\n    with tf.device(device):\r\n      y = gelu_approximate(x, run_tanh_on_cpu)\r\n  return tape.gradient(y, x)\r\n\r\n\r\ndef main():\r\n  print(f\"TF version is {tf.__version__}\")\r\n  x = tf.linspace(-500.0, 500.0, 500)\r\n  cpu = gelu_gradient(x, \"/CPU:0\", run_tanh_on_cpu=True)\r\n  gpu = gelu_gradient(x, \"/GPU:0\", run_tanh_on_cpu=True)\r\n  abs_error = np.abs(cpu - gpu)\r\n  df = pd.DataFrame(dict(cpu=cpu, gpu=gpu, abs_error=abs_error), index=x)\r\n  try:\r\n    np.testing.assert_allclose(cpu, gpu, atol=1e-3)\r\n  except (AssertionError,) as e:\r\n    print(\"GPU and CPU gradients are not close!\")\r\n    print(e)\r\n  df.plot(title=\"CPU vs. GPU gradients for tf.nn.gelu(approximate=True)\")\r\n  plt.show()\r\n\r\n\r\nif __name__ == \"__main__\":\r\n  main()\r\n``` \r\n\r\nIn particular, running tanh on a very large float32 input incorrectly gives 0.99999976 instead of 1.0.\r\n\r\n```\r\nimport tensorflow as tf\r\nwith tf.device('/GPU:0'):\r\n  print(tf.tanh(tf.constant(1000., dtype=tf.float32)))  # 0.99999976, but should be 1.\r\n```\r\n\r\nWhen given very large inputs, tanh should round to 1 as the true result is much closer to 1 than 0.99999976. tanh gives the correct result on float16 or float64 values, just not float32 values. I do not understand gelu and tanh well enough to understand why the slightly incorrectly tanh output causes the gelu gradient to have such a large gradient, but fixing tanh should fix the issue.\r\n\r\nI bisected this and the issue first started occurring at c6023a81d4976f6ff79f957925364d21d7884004. @akuegel, can you fix the GPU tanh op when given large float32 inputs?", "I have verified that with a recent build (after the above commit)\r\n\r\n```\r\nimport tensorflow as tf\r\nwith tf.device('/GPU:0'):\r\n  print(tf.tanh(tf.constant(1000., dtype=tf.float32)))\r\n```\r\n\r\nproduces 1.0 as desired and your example also now works. Closing as fixed.\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47724\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47724\">No</a>\n", "Thank you, @sherhut."]}, {"number": 47723, "title": "Still unable to install in python 3.9(64 BIT) in windows 10 ", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version:\r\n- Python version:\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@ShyamSundhar1411 \r\nThere is a detailed thread about Tensorflow's support for Python 3.9 in #44485. Can you please confirm if we can close this issue as it is being already tracked? Thanks!", "This is marked as feature request. duplicate #44485\r\nWe will follow the progress of this feature in the above issue #44485\r\nThanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47723\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47723\">No</a>\n"]}, {"number": 47722, "title": "keras.MultiHeadAttention fails to save / load weights correctly", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n\r\nYes,\r\n```\r\nimport tensorflow.keras as tk\r\nimport numpy as np\r\n\r\ndef main(**kwargs):\r\n    inputs = tk.Input(shape=(1,2))\r\n    outputs = tk.layers.MultiHeadAttention(1, 2)(inputs, inputs)\r\n    model = tk.Model(inputs, outputs)\r\n    model.compile(tk.optimizers.Adam(),'MSE')\r\n\r\n    #Adding .fit call doesn't change the result\r\n    #data = np.ones((1,1,2))\r\n    #model.fit(x=data, y=data)\r\n\r\n    model.save(\"bug0\")\r\n    m0 = tk.models.load_model(\"bug0\")\r\n    m1 = tk.models.load_model(\"bug0\")\r\n\r\n    print()\r\n    print(m0.weights[0])\r\n    print(m1.weights[0])\r\n\r\n\r\nif __name__ == '__main__':\r\n    try:\r\n        main()\r\n    except Exception as e:\r\n        print(e)\r\n```\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n\r\n```\r\n$ lsb_release -a\r\nNo LSB modules are available.\r\nDistributor ID: Ubuntu\r\nDescription:    Ubuntu 20.04.2 LTS\r\nRelease:        20.04\r\nCodename:       focal\r\n\r\n```\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:n/a\r\n- TensorFlow installed from (source or binary):\r\n\r\n```\r\npip install tensorflow\r\n```\r\n\r\n- TensorFlow version (use command below):\r\n```\r\n$ python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"\r\nv2.4.0-49-g85c8b2a817f 2.4.1\r\n```\r\n- Python version:\r\n```\r\n$ python --version\r\nPython 3.8.5\r\n```\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\n\r\nWhen loading a saved model containing a MultiHeadAttention layer, the layer wights are different every time the model is loaded.\r\n\r\n**Describe the expected behavior**\r\n\r\nThe layer weights should be the same every time the model is loaded.\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\nimport tensorflow.keras as tk\r\nimport numpy as np\r\n\r\ndef main(**kwargs):\r\n    inputs = tk.Input(shape=(1,2))\r\n    outputs = tk.layers.MultiHeadAttention(1, 2)(inputs, inputs)\r\n    model = tk.Model(inputs, outputs)\r\n    model.compile(tk.optimizers.Adam(),'MSE')\r\n\r\n    #Adding .fit call doesn't change the result\r\n    #data = np.ones((1,1,2))\r\n    #model.fit(x=data, y=data)\r\n\r\n    model.save(\"bug0\")\r\n    m0 = tk.models.load_model(\"bug0\")\r\n    m1 = tk.models.load_model(\"bug0\")\r\n\r\n    print()\r\n    print(m0.weights[0])\r\n    print(m1.weights[0])\r\n\r\n\r\nif __name__ == '__main__':\r\n    try:\r\n        main()\r\n    except Exception as e:\r\n        print(e)\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n```\r\n2021-03-11 07:17:30.470279: W tensorflow/python/util/util.cc:348] Sets are not currently considered\\\r\n sequences, but this may change in the future, so consider avoiding using them.\r\nWARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_cond\\\r\nitional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_f\\\r\nn while saving (showing 5 of 30). These functions will not be directly callable after loading.\r\nWARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_cond\\\r\nitional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_f\\\r\nn while saving (showing 5 of 30). These functions will not be directly callable after loading.\r\n\r\n<tf.Variable 'multi_head_attention/query/kernel:0' shape=(2, 1, 2) dtype=float32, numpy=\r\narray([[[ 0.36944628, -0.00638223]],\r\n\r\n       [[-0.96410084, -0.4008801 ]]], dtype=float32)>\r\n<tf.Variable 'multi_head_attention/query/kernel:0' shape=(2, 1, 2) dtype=float32, numpy=\r\narray([[[ 0.94459724,  0.45157957]],\r\n\r\n       [[ 0.88224053, -0.97082996]]], dtype=float32)>\r\n```\r\n", "comments": ["Manually saving and loading the weights works as expected (still get a lot of warnings) when using a simple model. The `tf-nightly` version produces the same results except only one warning instead of two.\r\n\r\nHowever, embedded in a more complex model, the manual saving and loading does not work. I am still investigating this.\r\n\r\n```\r\nmodel.save(\"bug0\")\r\nmodel.save_weights(\"bug0-w\")\r\n\r\nm0 = tk.models.load_model(\"bug0\")\r\nm0.load_weights(\"bug0-w\")\r\n\r\nm1 = tk.models.load_model(\"bug0\")\r\nm1.load_weights(\"bug0-w\")\r\n```\r\n\r\n```\r\nWARNING:absl:Found untraced functions such as query_layer_call_and_return_conditional_losses, query\\\r\n_layer_call_fn, key_layer_call_and_return_conditional_losses, key_layer_call_fn, value_layer_call_a\\\r\nnd_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly c\\\r\nallable after loading.\r\nWARNING:absl:Found untraced functions such as query_layer_call_and_return_conditional_losses, query\\\r\n_layer_call_fn, key_layer_call_and_return_conditional_losses, key_layer_call_fn, value_layer_call_a\\\r\nnd_return_conditional_losses while saving (showing 5 of 30). These functions will not be directly c\\\r\nallable after loading.\r\n\r\n<tf.Variable 'multi_head_attention/query/kernel:0' shape=(2, 1, 2) dtype=float32, numpy=\r\narray([[[-0.37047267, -0.5616925 ]],\r\n\r\n       [[ 0.6572478 , -0.18718529]]], dtype=float32)>\r\n<tf.Variable 'multi_head_attention/query/kernel:0' shape=(2, 1, 2) dtype=float32, numpy=\r\narray([[[-0.37047267, -0.5616925 ]],\r\n\r\n       [[ 0.6572478 , -0.18718529]]], dtype=float32)>\r\n```", "@melton1968,\r\nI was able to save and load the weights without any issues by\r\n- saving the model as a `.h5` file or\r\n- using the `save_weights` and `load_weights` methods.\r\n\r\nPlease find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/9ecc22a8e58efff7e3e923351aa7a067/47722.ipynb#scrollTo=pWLoZ4L65xHR) and also take a look at similar issues [#47487](https://github.com/tensorflow/tensorflow/issues/47487) [#33424](https://github.com/tensorflow/tensorflow/issues/33424#issuecomment-544933871).\r\n\r\nRegarding the warnings logs, the issue is already being tracked in issue [#47479](https://github.com/tensorflow/tensorflow/issues/47479).\r\n\r\nThanks!", "@amahendrakar,\r\n\r\nMy actual use-case involves a subclassed Model which is not supported by the hd5 format:\r\n\r\n```\r\nSaving the model to HDF5 format requires the model to be a Functional model or a Sequential model.  It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`.\r\n```\r\n\r\nUsing `save_weights` and `load_weights` does seem to save and load the weights correctly. Unfortunate that the standard `save/load` methods are broken.", "This is due to random values for `kernel_initializer` in [MultiHeadAttentionLayer](https://www.tensorflow.org/api_docs/python/tf/keras/layers/MultiHeadAttention)\r\nSetting seed for `kernel_initializer= tk.initializers.glorot_uniform(seed=0)` can help to load same weights in your case.\r\nRefer [gist](https://colab.research.google.com/gist/ymodak/ed3d8d9e171a5fbf7a313d29cd20cdd7/47722.ipynb)", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47722\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47722\">No</a>\n"]}, {"number": 47720, "title": "mportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: No\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version: 2.4\r\n- Python version:3.8.5\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: no\r\n- GPU model and memory:no\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n---------------------------------------------------------------------------\r\nImportError                               Traceback (most recent call last)\r\nG:\\anaconda\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     63   try:\r\n---> 64     from tensorflow.python._pywrap_tensorflow_internal import *\r\n     65   # This try catch logic is because there is no bazel equivalent for py_extension.\r\n\r\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nImportError                               Traceback (most recent call last)\r\n<ipython-input-5-d6579f534729> in <module>\r\n----> 1 import tensorflow\r\n\r\nG:\\anaconda\\lib\\site-packages\\tensorflow\\__init__.py in <module>\r\n     39 import sys as _sys\r\n     40 \r\n---> 41 from tensorflow.python.tools import module_util as _module_util\r\n     42 from tensorflow.python.util.lazy_loader import LazyLoader as _LazyLoader\r\n     43 \r\n\r\nG:\\anaconda\\lib\\site-packages\\tensorflow\\python\\__init__.py in <module>\r\n     37 # go/tf-wildcard-import\r\n     38 # pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\r\n---> 39 from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n     40 \r\n     41 from tensorflow.python.eager import context\r\n\r\nG:\\anaconda\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py in <module>\r\n     81 for some common reasons and solutions.  Include the entire stack trace\r\n     82 above this error message when asking for help.\"\"\" % traceback.format_exc()\r\n---> 83   raise ImportError(msg)\r\n     84 \r\n     85 # pylint: enable=wildcard-import,g-import-not-at-top,unused-import,line-too-long\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"G:\\anaconda\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@TabshirBashar \r\nYou might be facing this issue because of the following reasons\r\n\r\nYou are running 32-bit Python or 32-bit OS\r\nYou have not installed the [Microsoft Visual C++ Redistributable](https://support.microsoft.com/en-us/topic/the-latest-supported-visual-c-downloads-2647da03-1eea-4433-9aff-95f26a218cc0) package\r\nYour CPU does not support AVX instructions.\r\nPlease take a look at the [system requirements](https://www.tensorflow.org/install/pip#system-requirements) and check if you have the correct dependencies installed.\r\n\r\nAlso, check this similar duplicate issue: #46124, #46738, #46788, #46490, #45398\r\n\r\nThanks!", "Thanx....I solved the issue by making a new environment for Tensorflow\n\nOn Fri, Mar 12, 2021 at 11:43 AM Saduf2019 ***@***.***> wrote:\n\n> @TabshirBashar <https://github.com/TabshirBashar>\n> You might be facing this issue because of the following reasons\n>\n> You are running 32-bit Python or 32-bit OS\n> You have not installed the Microsoft Visual C++ Redistributable\n> <https://support.microsoft.com/en-us/topic/the-latest-supported-visual-c-downloads-2647da03-1eea-4433-9aff-95f26a218cc0>\n> package\n> Your CPU does not support AVX instructions.\n> Please take a look at the system requirements\n> <https://www.tensorflow.org/install/pip#system-requirements> and check if\n> you have the correct dependencies installed.\n>\n> Also, check this similar duplicate issue: #46124\n> <https://github.com/tensorflow/tensorflow/issues/46124>, #46738\n> <https://github.com/tensorflow/tensorflow/issues/46738>, #46788\n> <https://github.com/tensorflow/tensorflow/issues/46788>, #46490\n> <https://github.com/tensorflow/tensorflow/issues/46490>, #45398\n> <https://github.com/tensorflow/tensorflow/issues/45398>\n>\n> Thanks!\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/47720#issuecomment-797249831>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/ALO5PETQZ3CGEQ4ZCYJTJXDTDGSXTANCNFSM4Y73UZ4A>\n> .\n>\n", "@TabshirBashar \r\nThank you for your update, glad the issue is resolved, please move this to closed sttaus.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47720\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47720\">No</a>\n"]}, {"number": 47719, "title": "ValueError: Input tensors to a Functional must come from `tf.keras.Input`. Received: 0 (missing previous layer metadata).", "body": "I use tensorflow 2.4 on google colab with a script like the following\r\n```\r\nn = 10\r\nplt.plot(y[:(n * 24)])\r\n#n = len(test_X)\r\nfor i in range(0, n):\r\n    avg_pred= predict_with_uncertainty(model, test_X[i].reshape(1, 24, test_X[i].shape[1]), 100)\r\n    \r\n    yHat = scaler.inverse_transform(avg_pred).reshape(avg_pred.shape[0] * avg_pred.shape[1])\r\n    YHat_SD = scaler.inverse_transform(ts_std).reshape(ts_std.shape[0] * ts_std.shape[1])\r\n    y = scaler.inverse_transform(test_y).reshape(prediction.shape[0] * prediction.shape[1])\r\n    plt.plot(range(i * 24, (i + 1) * 24), yHat, color='red')\r\n    # plots the uncertainty to the degree of half a standard deviation\r\n    plt.fill_between(range(i * 24, (i + 1) * 24),\r\n                     yHat + 1.96 * YHat_SD, \r\n                     yHat - 1.96 * YHat_SD, \r\n                     facecolor='red', alpha=0.25)\r\n\r\n    # plots the uncertainty to the degree of a full standard deviation\r\n    plt.fill_between(range(i * 24, (i + 1) * 24),\r\n                     yHat + 3 * YHat_SD, \r\n                     yHat - 3 * YHat_SD, \r\n                     facecolor='red', alpha=0.25)\r\n    plt.legend(['Truth', 'Prediction'], loc='upper right')\r\nplt.show()```\r\n\r\nerror:\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-20-74b3d2442e4c> in <module>()\r\n      3 #n = len(test_X)\r\n      4 for i in range(0, n):\r\n----> 5     avg_pred= predict_with_uncertainty(model, test_X[i].reshape(1, 24, test_X[i].shape[1]), 100)\r\n      6 \r\n      7     yHat = scaler.inverse_transform(avg_pred).reshape(avg_pred.shape[0] * avg_pred.shape[1])\r\n\r\n6 frames\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py in _validate_graph_inputs_and_outputs(self)\r\n    689                          'must come from `tf.keras.Input`. '\r\n    690                          'Received: ' + str(x) +\r\n--> 691                          ' (missing previous layer metadata).')\r\n    692       # Check that x is an input tensor.\r\n    693       # pylint: disable=protected-access\r\n\r\nValueError: Input tensors to a Functional must come from `tf.keras.Input`. Received: 0 (missing previous layer metadata).\r\n\r\nif using this script on tensorflow 1.15.0 it works\r\n\r\nthe solution that you give me means a lot to me\r\n", "comments": ["@sasmitohrr \r\nPlease share complete stand alone code such that we can replicate the issue or share the colab gist with the error.\r\nWe ran the code shared and face a different [error](https://colab.research.google.com/gist/Saduf2019/aa18ffd6e19f800f4e9c63a6d28d8ba6/untitled561.ipynb).", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 47718, "title": "Suppressed warnings in cortex_m_generic_makefile and cortex_m_corstone_300_makefile", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source or binary):\r\n- Tensorflow version (commit SHA if source): 8cb7f3a462db810d70521fab26eac8e2fed9e2b4\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):\r\n\r\n**Describe the problem**\r\nThe files cortex_m_generic_makefile.inc and cortex_m_corstone_300_makefile.inc both need to suppress additional warnings compared to default the Makefile.\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\nFor example remove OMIT_ERRORS from the mentioned files and try to build.\r\nmake -j -f tensorflow/lite/micro/tools/make/Makefile  TARGET=cortex_m_corstone_300 TARGET_ARCH=cortex-m55 test_kernel_conv_test \r\n\r\n\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47718\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47718\">No</a>\n"]}, {"number": 47717, "title": "Feeding a batch of different image shapes for a model with dynamic input shape", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution: Linux Ubuntu 18\r\n- TensorFlow installed from binary\r\n- TensorFlow version: 1.15\r\n- Python version: 3.7\r\n- Running on CPU.\r\n\r\n**Describe the current behavior**\r\nI am working on a model with a flexible input shape (None, None,3). That is, the images can be of any size but the number of channels should be 3. The model is compatible with handling dynamic shapes. As you can see in the following:\r\n```Python\r\n\r\narr1 = np.random.random((100, 100, 3))\r\narr2 = np.random.random((104, 100, 3))\r\narr3 = np.random.random((200, 240, 3))\r\n\r\nout = model.predict(np.expand_dims(arr1, 0))\r\nprint(out.shape)\r\n\r\nout = model.predict(np.expand_dims(arr2, 0))\r\nprint(out.shape)\r\n\r\nout = model.predict(np.expand_dims(arr3, 0))\r\nprint(out.shape)\r\n```\r\nAnd the output of this section is:\r\n```Python\r\n(1, 100, 100, 3)\r\n(1, 104, 100, 3)\r\n(1, 200, 240, 3)\r\n```\r\nHowever, this is a single image inference. When we have batches (e.g. when training with batch_size > 1), the batch will have a shape of (1, ) since NumPy cannot handle an array of arrays with different shapes. And as a result, I cannot feed the model batches of images. Shouldn't there be a way to feed a batch of images with different shapes to model?\r\n\r\nThis is my result on feeding a batch:\r\n```Python\r\n\r\nbatch = [arr1, arr1, arr1]\r\nout = model.predict(batch)\r\nprint(out.shape)\r\n\r\nbatch = [arr2, arr2, arr2]\r\nout = model.predict(batch)\r\nprint(out.shape)\r\n\r\n\r\nbatch = [arr1, arr2] #this one generates the error\r\nout = model.predict(batch)\r\nprint(out.shape)\r\n```\r\nAnd the result is:\r\n```Python\r\n(3, 100, 100, 3)\r\n(3, 104, 100, 3)\r\nTraceback (most recent call last):\r\n  File \"flexnet.py\", line 57, in <module>\r\n    out = model.predict(batch)\r\n  File \"/home/amin/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 908, in predict\r\n    use_multiprocessing=use_multiprocessing)\r\n  File \"/home/amin/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_arrays.py\", line 716, in predict\r\n    x, check_steps=True, steps_name='steps', steps=steps)\r\n  File \"/home/amin/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\", line 2471, in _standardize_user_data\r\n    exception_prefix='input')\r\n  File \"/home/amin/.local/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\", line 563, in standardize_input_data\r\n    'with shape ' + str(data_shape))\r\nValueError: Error when checking input: expected input_1 to have 4 dimensions, but got array with shape (2, 1)\r\n```\r\n\r\n", "comments": ["Every array (image) in a batch should be of the same size by definition. You can evaluate the arrays individually if you wish to. ", "You are absolutely right! But as I have shown in my issue, there can be a model which is flexible to dynamic shapes. Therefore, I wonder whether there is a way to feed a group of images of different width and height to these models as well.", "@m-parchami \r\nWe see that you are using tf version 1.15, there is no support for 1.x, please update to 2.x and let us know.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47717\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47717\">No</a>\n"]}, {"number": 47716, "title": "KeyError: 'custom_node:0' when loading saved model contains a custom node that already implement via register_ops.", "body": "HI tensorflower.\r\n\r\nI want to load a saved model with a custom op that's not support by tensorflow, so I write a dummy op register to tensorflow with the guide of https://www.tensorflow.org/guide/create_op, and the registration is succeed but I still get keyerror while parsing saved_model, here are some code snippets:\r\n```\r\nimport tensorflow as tf\r\nprint(tf.__version__)\r\n\r\nlsa_module = tf.load_op_library('./LinearSumAssignmentOp.so')\r\n\r\npath = \"/path/to/saved/model\"\r\nimported = tf.saved_model.load(path)\r\n```\r\nI get the following outputs\r\n```\r\n---------------------------------------------------------------------------\r\nKeyError                                  Traceback (most recent call last)\r\n<ipython-input-2-45f6f99eff8a> in <module>\r\n      2 \r\n      3 path = \"./to_nv_1/saved_models\"\r\n----> 4 imported = tf.saved_model.load(path)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py in load(export_dir, tags, options)\r\n    869     ValueError: If `tags` don't match a MetaGraph in the SavedModel.\r\n    870   \"\"\"\r\n--> 871   return load_internal(export_dir, tags, options)[\"root\"]\r\n    872 \r\n    873 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py in load_internal(export_dir, tags, options, loader_cls, filters)\r\n    900       try:\r\n    901         loader = loader_cls(object_graph_proto, saved_model_proto, export_dir,\r\n--> 902                             ckpt_options, filters)\r\n    903       except errors.NotFoundError as err:\r\n    904         raise FileNotFoundError(\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/load.py in __init__(self, object_graph_proto, saved_model_proto, export_dir, ckpt_options, filters)\r\n    130     self._concrete_functions = (\r\n    131         function_deserialization.load_function_def_library(\r\n--> 132             meta_graph.graph_def.library))\r\n    133     self._checkpoint_options = ckpt_options\r\n    134 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/function_deserialization.py in load_function_def_library(library, load_shared_name_suffix)\r\n    356     # import).\r\n    357     with graph.as_default():\r\n--> 358       func_graph = function_def_lib.function_def_to_graph(copy)\r\n    359     _restore_gradient_functions(func_graph, renamed_functions)\r\n    360 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/function_def_to_graph.py in function_def_to_graph(fdef, input_shapes)\r\n     62       input_shapes = input_shapes_attr.list.shape\r\n     63   graph_def, nested_to_flat_tensor_name = function_def_to_graph_def(\r\n---> 64       fdef, input_shapes)\r\n     65 \r\n     66   with func_graph.as_default():\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/function_def_to_graph.py in function_def_to_graph_def(fdef, input_shapes)\r\n    258   for node_def in graph_def.node:\r\n    259     for i in range(len(node_def.input)):\r\n--> 260       node_def.input[i] = nested_to_flat_tensor_name[node_def.input[i]]\r\n    261 \r\n    262   return graph_def, nested_to_flat_tensor_name\r\n\r\nKeyError: 'lane_local_mapper/lane_associator/cond/LinearSumAssignmentOp:matches:0'\r\n```\r\n\r\nAny idea about this error? I don't know the input and output shape of this node, so the REGISTER_OP .SetShapeFn likely deduce an error output shape, does it cause the error?\r\n\r\nThank && Best Regard.", "comments": ["@zerollzeng \r\nI ran the code shared and face a different error, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/7d68b6f4d0ecbe7808e65c0f6cc069ab/untitled561.ipynb) and share all dependencies to replicate the issue or share a colab gist with the reported error.", "@Saduf2019 Thanks for the quick reply!\r\n\r\nUnfortunately, I can't share my model with you due to privacy, do you have any suggestions or documentation about this error?\r\n\r\nThanks.", "@zerollzeng\r\nWithout a reproducible code snippet it would be difficult for us to debug the issue\r\n\r\nIn this case, could you please provide a dummy code to reproduce the issue reported here, or create a colab gist and share.\r\n\r\nYou may also refer to this link as per the error and let us know: [link](https://stackoverflow.com/questions/37654024/python-traceback-keyerror-using-beautifulsoup)", "ok @Saduf2019 \r\n\r\nI will close this issue for now, and when I have progress on this problem I will let you know. \r\n\r\nThanks"]}, {"number": 47714, "title": "I found maybe a bug about model.predict() and model.evaluate()", "body": "My machine is MacBook Pro 2020 13-inch, TensorFlow version is 2.4.\r\nWhen I use model.predict() and model.evaluate(), no matter which function is used first, the output result of the other function will be seriously different from expected. code show as below\r\n```\r\nimport tensorflow as tf\r\nimport matplotlib.pyplot as plt\r\nimport pylab\r\nimport numpy as np\r\n\r\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\r\nx_train = x_train.reshape((60000, 28, 28, 1))\r\nx_test = x_test.reshape((10000, 28, 28, 1))\r\nx_train = 2 * x_train / 255.0 - 1\r\nx_test = 2 * x_test / 255.0 - 1\r\n\r\nplt.imshow(x_train[0, :, :, ])\r\nprint()\r\npylab.show()\r\n\r\n\r\ndef build_model():\r\n    return tf.keras.Sequential([\r\n        tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation=tf.nn.relu,\r\n                               input_shape=(28, 28, 1)),\r\n        tf.keras.layers.Conv2D(64, (3, 3), activation=tf.nn.relu),\r\n        tf.keras.layers.MaxPooling2D((2, 2)),\r\n        tf.keras.layers.Conv2D(64, (3, 3), activation=tf.nn.relu),\r\n        tf.keras.layers.MaxPooling2D((2, 2)),\r\n        tf.keras.layers.Flatten(),\r\n        tf.keras.layers.Dense(49, activation=tf.nn.relu),\r\n        tf.keras.layers.Dense(10, activation=tf.nn.softmax)\r\n    ])\r\n\r\n\r\ndef train(x, y):\r\n    model = build_model()\r\n    model.summary()\r\n    model.compile(optimizer=tf.optimizers.Adam(), loss='sparse_categorical_crossentropy',\r\n                  metrics=['accuracy'])\r\n    model.fit(x, y, epochs=2)\r\n    # model.evaluate(x_test, y_test)\r\n\r\n    # predict\r\n    print(model.predict(x_test)[0])\r\n    print(y_test[0])\r\n    model.evaluate(x_test,y_test)\r\n    # print(model.predict(x_test)[0])\r\n\r\n    return model\r\n\r\n\r\nmodel = train(x_train, y_train)\r\n```\r\n", "comments": ["They are related but not the same.\r\nmodel.predict(x) give the prediction of with input data x.\r\nmodel.evaluate returns a tuple (loss, metric). In your definition which is (sparse_categorical_crossentropy, accuracy)\r\n\r\nYou could code yourself to compare the sparse_categorical_crossentropy loss of the test sets and the accuracy.", "I mean that if I use model.predict(test_x), and then I use model.evaluate(test_x,test_y), the result about accuracy is very lower than my expectation. If I don't use model.predict(test_x) before using model.evaluate(test_x,test_y), I will get a perfect accuarcy.", "@wangteng200000318 \r\nI ran the code shared and face a different error, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/2f174d54798b4368cc6ab4fb7c2c9b63/untitled561.ipynb), please share a colab gist with the issue reported.", "Maybe because my machine python version is 3.8.4, and the python's version in the collar is python 3.7??? Hence, I can run plt.imshow(x_train[0, :, :, ]) in my machine. \r\n`https://colab.research.google.com/drive/1Q_m8xDHWOUNoMT_mveZIbpZv83P7zSqO`\r\nI establish two demo. In demo1, Using model.predict(x_test) before using model.evaluate(x_test,y_test). In demo2, using model.evaluate() without model.predict(). I find the accuracy is close. But in  Apple releases the ARM64 TensorFlow2.4, the result about two demos is very different.\r\n<img width=\"1440\" alt=\"image\" src=\"https://user-images.githubusercontent.com/57594482/111020736-f62edf00-8402-11eb-8d7c-f358684f2d3b.png\">\r\n<img width=\"1440\" alt=\"image\" src=\"https://user-images.githubusercontent.com/57594482/111020774-37bf8a00-8403-11eb-8b4b-7c36bb70aa99.png\">\r\n\r\n", "@wangteng200000318 I tried on my Mac and colab with `tf-nightly` and `TF2.4`. Didn't see any issue with `Python3.7`. \r\n[Here](https://colab.research.google.com/gist/jvishnuvardhan/fddde74abb0af9a233e468f3dcad2253/untitled561.ipynb) is a gist for our reference. \r\n\r\nAs you mentioned that you had used `Python3.8`, Can you please try with `Python3.7` and let us know whether the issue persists there. Thanks!", "Because I use M1 chip Mac, my development environment may not allow me to use Python 3.7. If I use **Python3.7**, I will fail to configure the environment and there will be a number of errors indicating that the installation failed. My process of configuring the environment is looking at this [tutorial](https://towardsdatascience.com/tensorflow-2-4-on-apple-silicon-m1-installation-under-conda-environment-ba6de962b3b8)", "@wangteng200000318 Did you install [Mac-optimized TensorFlow and TensorFlow Addons](https://github.com/apple/tensorflow_macos)? If yes, please post them in their repo  [here](https://github.com/apple/tensorflow_macos/issues) so that some experts in that repo will resolve your issue.\r\n\r\nSupport for TF on M1-chip Mac is limited currently due to reasons mentioned [here](https://github.com/tensorflow/tensorflow/issues/44751#issuecomment-765604464). thanks!", "Ok, thank u!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47714\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47714\">No</a>\n"]}, {"number": 47713, "title": "tf.variable_scope with custom_getter in TF2", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.4.1\r\n- Are you willing to contribute it (Yes/No): Maybe\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nI need to achieve similar results in the code below in TF2. By going through enough SO questions and TF docs, It seems impossible, so this feature does not exist in TF2.\r\n\r\n    params = tf.trainable_variables(\"my_model\")\r\n    ema = tf.train.ExponentialMovingAverage(alpha)\r\n    ema_apply_op = ema.apply(params)\r\n\r\n\r\n    def custom_getter(getter, *args, **kwargs):\r\n        return ema.average(getter(*args, **kwargs))\r\n    \r\n    with tf.compat.v1.variable_scope(\r\n        \"my_model\", custom_getter=custom_getter, reuse=True\r\n    ):\r\n        avg_model = create_avg_model()\r\n\r\n**Will this change the current api? How?**\r\n\r\nI don't know.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nWhoever wants to create a keras model with a custom getter\r\n\r\n**Any Other info.**\r\n", "comments": ["I fixed the issue by converting to equivalent keras models. If there is a need to go further with providing some means to a custom getter in TF2, feel free to re-open the issue."]}, {"number": 47710, "title": "Unable to build tensorflow lite standalone pip package for raspberrypi zero", "body": "**System information**\r\n\r\nRaspbian buster lite\r\nLinux raspberrypi 5.4.83+ #1379 Mon Dec 14 13:06:05 GMT 2020 armv6l GNU/Linux\r\ngcc version 8.3.0 (Raspbian 8.3.0-6+rpi1)\r\npython 3.7.3\r\n\r\ntensorflow source @ commit a2a5b86c3bd90e03151a25c52c0f6cebbd573228\r\n\r\n**Describe the problem**\r\n\r\nUnable to build tensorflow lite standalone pip package for raspberrypi zero\r\n\r\nhttps://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/pip_package\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nI ran the commands in the aforementioned link on the raspberrypi zero. The only change is I used pip3\r\n\r\nsudo apt install swig libjpeg-dev zlib1g-dev python3-dev python3-numpy\r\npip3 install numpy pybind11\r\ntensorflow/lite/tools/make/download_dependencies.sh\r\ntensorflow/lite/tools/pip_package/build_pip_package.sh\r\n\r\nIt ran for maybe a day or so before giving up with the following:\r\n\r\ng++: fatal error: Killed signal terminated program cc1plus\r\ncompilation terminated.\r\nmake: *** [tensorflow/lite/tools/make/Makefile:335: /home/pi/tensorflow_src/tensorflow/lite/tools/make/gen/linux_armv6l/obj/tensorflow/lite/kernels/conv.o] Error 1\r\nmake: Leaving directory '/home/pi/tensorflow_src'\r\nTraceback (most recent call last):\r\n  File \"setup.py\", line 227, in <module>\r\n    'build_py': CustomBuildPy,\r\n  File \"/usr/lib/python3/dist-packages/setuptools/__init__.py\", line 145, in setup\r\n    return distutils.core.setup(**attrs)\r\n  File \"/usr/lib/python3.7/distutils/core.py\", line 148, in setup\r\n    dist.run_commands()\r\n  File \"/usr/lib/python3.7/distutils/dist.py\", line 966, in run_commands\r\n    self.run_command(cmd)\r\n  File \"/usr/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n    cmd_obj.run()\r\n  File \"/usr/lib/python3.7/distutils/command/bdist.py\", line 143, in run\r\n    self.run_command(cmd_name)\r\n  File \"/usr/lib/python3.7/distutils/cmd.py\", line 313, in run_command\r\n    self.distribution.run_command(command)\r\n  File \"/usr/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n    cmd_obj.run()\r\n  File \"/usr/lib/python3.7/distutils/command/bdist_dumb.py\", line 81, in run\r\n    self.run_command('build')\r\n  File \"/usr/lib/python3.7/distutils/cmd.py\", line 313, in run_command\r\n    self.distribution.run_command(command)\r\n  File \"/usr/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n    cmd_obj.run()\r\n  File \"/usr/lib/python3.7/distutils/command/build.py\", line 135, in run\r\n    self.run_command(cmd_name)\r\n  File \"/usr/lib/python3.7/distutils/cmd.py\", line 313, in run_command\r\n    self.distribution.run_command(command)\r\n  File \"/usr/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n    cmd_obj.run()\r\n  File \"setup.py\", line 133, in run\r\n    self.run_command('build_ext')\r\n  File \"/usr/lib/python3.7/distutils/cmd.py\", line 313, in run_command\r\n    self.distribution.run_command(command)\r\n  File \"/usr/lib/python3.7/distutils/dist.py\", line 985, in run_command\r\n    cmd_obj.run()\r\n  File \"setup.py\", line 125, in run\r\n    make()\r\n  File \"setup.py\", line 105, in make\r\n    subprocess.check_call(make_args(quiet=False))\r\n  File \"/usr/lib/python3.7/subprocess.py\", line 347, in check_call\r\n    raise CalledProcessError(retcode, cmd)\r\nsubprocess.CalledProcessError: Command '['make', 'SHELL=/bin/bash', 'BUILD_WITH_NNAPI=false', '-C', '/home/pi/tensorflow_src/tensorflow/lite/tools/pip_package/../../../..', '-f', 'tensorflow/lite/tools/make/Makefile', '-j', '1']' returned non-zero exit status 2.", "comments": ["@terryheo could you take at this issue?", "Could you try this?\r\n\r\nhttps://www.tensorflow.org/lite/guide/build_cmake_pip", "I ran docker pull tensorflow/tensorflow:devel and followed the instructions under Arm cross compilation\r\nI started the container and noticed python 3.6 was installed but only 3.5, 3.7 and 3.8 are supported. I updated python to use 3.7 but it could not find docker and `sudo apt-get install docker` did not help.\r\n\r\n```\r\nroot@0cff243a97ee:/tensorflow_src# tensorflow/tools/ci_build/ci_build.sh PI-PYTHON37 \\\r\n> tensorflow/lite/tools/pip_package/build_pip_package_with_cmake.sh rpi0\r\nWORKSPACE: /tensorflow_src\r\nCI_DOCKER_BUILD_EXTRA_PARAMS: \r\nCI_DOCKER_EXTRA_PARAMS: \r\nCOMMAND: tensorflow/lite/tools/pip_package/build_pip_package_with_cmake.sh rpi0\r\nCI_COMMAND_PREFIX: ./tensorflow/tools/ci_build/builds/with_the_same_user ./tensorflow/tools/ci_build/builds/configured pi-python37\r\nCONTAINER_TYPE: pi-python37\r\nBUILD_TAG: tf_ci\r\n  (docker container name will be tf_ci.pi-python37)\r\n\r\nBuilding container (tf_ci.pi-python37)...\r\ntensorflow/tools/ci_build/ci_build.sh: line 145: docker: command not found\r\nERROR: docker build failed. Dockerfile is at /tensorflow_src/tensorflow/tools/ci_build/Dockerfile.pi-python37\r\n\r\n```", "@terryheo any ideas on this? The script requires docker but it is not installed on the tensorflow/tensorflow:devel docker image that is recommended. I'm not sure it would make a different but I'm using docker on a mac. Docker does not want to install on this container; I get errors trying to install it from docker instructions", "Can you run docker from your command line?\r\nIt seems that you didn't update PATH variable.", "The guide (https://www.tensorflow.org/lite/guide/build_cmake_pip) says it was tested on \"Ubuntu 16.04.3 64-bit PC (AMD64) , TensorFlow devel Docker image tensorflow/tensorflow:devel\" \r\n\r\nThe docker devel image is now 18.04.5 LTS, so not sure if that is part of the problem.\r\n\r\nI'm running docker on my host system (macos). The tensorflow:devel container does not seem to have docker installed, so I'm unsure how I would be able to set my PATH variable\r\n\r\nThe guide says a prerequisite is to have cmake installed (https://www.tensorflow.org/lite/guide/build_cmake) This guide says to you install cmake with apt-get and then run 'cmake ../tensorflow_src/tensorflow/lite'. But this fails with\r\n\r\n```\r\nCMake Error at CMakeLists.txt:29 (cmake_minimum_required):\r\n  CMake 3.16 or higher is required.  You are running version 3.10.2\r\n```\r\n\r\nIt seems the apt-get version of cmake is no longer suitable. But the original command is failing on the docker command so I'm not sure if this is even an issue", "The script tensorflow/tools/ci_build/ci_build.sh invokes a Docker container so you should use it from your Docker host machine. (in your macOS)\r\nDepending on your target Python version, you'll use PY, PI-PYTHON37, PI-PYTHON38 container. And these container has a proper script to install CMake.\r\n\r\nPlease run [these commands](https://www.tensorflow.org/lite/guide/build_cmake_pip#build_examples) on your macOS.", "I ran `tensorflow/tools/ci_build/ci_build.sh PI-PYTHON37 tensorflow/lite/tools/pip_package/build_pip_package_with_cmake.sh rpi0` on my mac and It ran for a few minutes but then failed:\r\n\r\n`/workspace/tensorflow/lite/tools/cmake/toolchains/arm-rpi-linux-gnueabihf/x64-gcc-6.5.0/arm-rpi-linux-gnueabihf/arm-rpi-linux-gnueabihf/include/c++/6.5.0/bits/deque.tcc:741:7: note: parameter passing for argument of type '__gnu_cxx::__normal_iterator<const double*, std::vector<double> >' will change in GCC 7.1\r\n/workspace/tensorflow/lite/tools/cmake/toolchains/arm-rpi-linux-gnueabihf/x64-gcc-6.5.0/arm-rpi-linux-gnueabihf/arm-rpi-linux-gnueabihf/include/c++/6.5.0/bits/deque.tcc:741:7: note: parameter passing for argument of type '__gnu_cxx::__normal_iterator<const double*, std::vector<double> >' will change in GCC 7.1\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/floor.cc.o] Bus error\r\nmake[3]: *** Waiting for unfinished jobs....\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/c/c_api_experimental.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/c/c_api.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/delegates/interpreter_utils.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/activations.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/batch_matmul.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/batch_to_space_nd.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/concatenation.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/cpu_backend_gemm_eigen.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/densify.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/depth_to_space.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/gather.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/gather_nd.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/l2norm.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/logical.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/lstm.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/lstm_eval.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/matrix_diag.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/matrix_set_diag.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/maximum_minimum.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/pooling.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/register.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/register_ref.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/round.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/scatter_nd.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/segment_sum.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/select.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/space_to_depth.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/svdf.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/transpose_conv.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/unidirectional_sequence_lstm.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/unique.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/create_op_resolver_with_builtin_ops.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/tools/optimize/sparsity/format_converter.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:897: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/floor.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:143: recipe for target 'CMakeFiles/tensorflow-lite.dir/c/c_api_experimental.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:130: recipe for target 'CMakeFiles/tensorflow-lite.dir/c/c_api.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:182: recipe for target 'CMakeFiles/tensorflow-lite.dir/delegates/interpreter_utils.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:403: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/activations.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:494: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/batch_matmul.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:507: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/batch_to_space_nd.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:624: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/concatenation.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:676: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/cpu_backend_gemm_eigen.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:702: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/densify.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:728: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/depth_to_space.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:949: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/gather.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:962: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/gather_nd.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:1066: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/l2norm.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:1092: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/logical.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:1118: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/lstm.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:1131: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/lstm_eval.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:1144: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/matrix_diag.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:1157: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/matrix_set_diag.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:1170: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/maximum_minimum.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:1313: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/pooling.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:1430: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/register.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:1443: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/register_ref.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:1534: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/round.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:1547: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/scatter_nd.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:1560: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/segment_sum.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:1573: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/select.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:1638: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/space_to_depth.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:1742: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/svdf.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:1794: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/transpose_conv.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:1807: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/unidirectional_sequence_lstm.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:1833: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/unique.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:1937: recipe for target 'CMakeFiles/tensorflow-lite.dir/create_op_resolver_with_builtin_ops.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:2171: recipe for target 'CMakeFiles/tensorflow-lite.dir/tools/optimize/sparsity/format_converter.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:2067: recipe for target 'CMakeFiles/tensorflow-lite.dir/optional_debug_tools.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/optional_debug_tools.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:1196: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/mirror_pad.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/mirror_pad.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:1287: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/pack.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/pack.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/detection_postprocess.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:767: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/detection_postprocess.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:1690: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/squared_difference.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/squared_difference.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:468: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/audio_spectrogram.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/audio_spectrogram.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:871: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/fake_quant.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/fake_quant.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:429: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/add_n.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/add_n.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:754: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/dequantize.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/dequantize.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/floor_mod.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:923: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/floor_mod.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:1326: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/pow.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/pow.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:1378: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/range.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/range.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:1755: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/tile.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/tile.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:1716: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/strided_slice.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/strided_slice.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:1989: recipe for target 'CMakeFiles/tensorflow-lite.dir/interpreter_builder.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/interpreter_builder.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:1417: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/reduce.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/reduce.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:1612: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/slice.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/slice.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:1508: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/reverse_sequence.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/reverse_sequence.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/sub.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:1729: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/sub.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/comparisons.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:598: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/comparisons.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:663: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/cpu_backend_context.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/cpu_backend_context.cc.o] Bus error\r\nmake[3]: *** Deleting file 'CMakeFiles/tensorflow-lite.dir/kernels/cpu_backend_context.cc.o'\r\nmake[3]: unlink: CMakeFiles/tensorflow-lite.dir/kernels/cpu_backend_context.cc.o: Transport endpoint is not connected\r\nCMakeFiles/tensorflow-lite.dir/build.make:1469: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/resize_bilinear.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/resize_bilinear.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:2041: recipe for target 'CMakeFiles/tensorflow-lite.dir/model_builder.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/model_builder.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/reverse.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:1495: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/reverse.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/bidirectional_sequence_lstm.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:520: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/bidirectional_sequence_lstm.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:2132: recipe for target 'CMakeFiles/tensorflow-lite.dir/util.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/util.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:1053: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/kernel_util.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/kernel_util.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:1300: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/pad.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/pad.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:299: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/internal/kernel_utils.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:845: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/exp.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:585: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/ceil.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/internal/kernel_utils.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/exp.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/ceil.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:832: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/embedding_lookup_sparse.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/embedding_lookup_sparse.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:78: recipe for target 'CMakeFiles/tensorflow-lite.dir/core/api/flatbuffer_conversions.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:416: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/add.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:572: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/cast.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:637: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/conv.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:741: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/depthwise_conv.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:780: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/div.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:793: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/eigen_support.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:806: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/elementwise.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:858: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/expand_dims.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:884: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/fill.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:936: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/fully_connected.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:1079: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/local_response_norm.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/core/api/flatbuffer_conversions.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/add.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/cast.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/conv.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/depthwise_conv.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/div.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/eigen_support.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/elementwise.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/expand_dims.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/fill.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/fully_connected.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/local_response_norm.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/mfcc.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:1183: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/mfcc.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/arg_min_max.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/neg.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:442: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/arg_min_max.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:1235: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/neg.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/numeric_verify.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:1261: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/numeric_verify.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/quantize.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/resize_nearest_neighbor.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:1339: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/quantize.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:1482: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/resize_nearest_neighbor.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/space_to_batch_nd.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:1625: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/space_to_batch_nd.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:1651: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/sparse_to_dense.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/sparse_to_dense.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:117: recipe for target 'CMakeFiles/tensorflow-lite.dir/core/subgraph.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/core/subgraph.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:1664: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/split.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/split.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:910: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/floor_div.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/floor_div.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/split_v.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:1677: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/split_v.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/unpack.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:1846: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/unpack.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:1209: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/mul.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/mul.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/where.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:1859: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/where.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:1976: recipe for target 'CMakeFiles/tensorflow-lite.dir/interpreter.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/interpreter.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:2054: recipe for target 'CMakeFiles/tensorflow-lite.dir/mutable_op_resolver.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/mutable_op_resolver.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:2158: recipe for target 'CMakeFiles/tensorflow-lite.dir/schema/schema_utils.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/schema/schema_utils.cc.o] Bus error\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/cumsum.cc.o] Bus error\r\nCMakeFiles/tensorflow-lite.dir/build.make:689: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/cumsum.cc.o' failed\r\nCMakeFiles/tensorflow-lite.dir/build.make:1781: recipe for target 'CMakeFiles/tensorflow-lite.dir/kernels/transpose.cc.o' failed\r\nmake[3]: *** [CMakeFiles/tensorflow-lite.dir/kernels/transpose.cc.o] Bus error\r\nERRO[0453] error waiting for container: invalid character 'u' looking for beginning of `value``", "Looks like I didn't have enough memory allocated in docker. I increased from the default 2GB to 32GB and it succeeded!\r\n\r\ntensorflow/lite/tools/pip_package/gen//tflite_pip/python3.7/dist/tflite_runtime-2.5.0-cp37-cp37m-linux_armv6l.whl\r\n\r\nI do think the build guide could be a little more clear on the steps. For example,  install docker on host system, clone the tensorflow repo, start the daemon, maybe increase the memory, and then run the command.\r\n\r\nThanks for your help!", "@terryheo I ran into a few more snags. After installing the tflite wheel\r\n\r\n`pip3 install tflite_runtime-2.5.0-cp37-cp37m-linux_armv6l.whl`\r\n\r\nand trying to import \r\n\r\n`import tflite_runtime.interpreter as tflite`\r\n\r\nI first ran into a numpy issue `Original error was: libf77blas.so.3: cannot open shared object file: No such file or directory` which seemed to be resolved by running `sudo apt-get install libatlas-base-dev`\r\n\r\nThen I got `ModuleNotFoundError: No module named 'tensorflow'`\r\n\r\nI ran `pip3 install --user --upgrade tensorflow` but now I'm getting\r\n\r\n`ImportError: cannot import name 'metrics_interface' from 'tensorflow.lite.python' (/home/pi/.local/lib/python3.7/site-packages/tensorflow_core/lite/python/__init__.py)`\r\n\r\nI'm referencing this guide https://www.tensorflow.org/lite/guide/python and I'm confused why I need tensorflow installed as I had thought the tflite_runtime would be used instead\r\n", "The issue you saw was recent regression https://github.com/tensorflow/tensorflow/issues/47738.\r\nIt's fixed now. So please try it again with HEAD repository.", "@terryheo it works with the latest pull. thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47710\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47710\">No</a>\n", "> @terryheo it works with the latest pull. thanks!\r\n\r\nmind sharing the python wheel? i can't get the cross compilation to output a working whl for 2.5.0"]}, {"number": 47709, "title": "Pip install issue", "body": "**System information**\r\n- OS Platform and Distribution: Manjaro Linux\r\n- TensorFlow installed from: Pip\r\n- TensorFlow version: 2.4.1\r\n- Python version: 3.9.2\r\n- Installed using virtualenv? pip? conda?: pip 20.3.1\r\n- GPU model and memory: Asus GTX 1070 8GB OC Snow Edition\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nAn issue with Pip is preventing being able to install Tensorflow just by doing `pip install tensorflow` and can't search for it either with Pip because they've shut down the PyPI XMLRPC Search, which has remained shut down since Jan 12 2021 according to their site status page \u2192 https://status.python.org\r\n\r\nAttempting to install tensorflow produces the following error;\r\n\r\n```\r\n$ pip install tensorflow\r\n\r\nDefaulting to user installation because normal site-packages is not writeable\r\nERROR: Could not find a version that satisfies the requirement tensorflow\r\nERROR: No matching distribution found for tensorflow\r\n```\r\n\r\n\r\nand attempting to search for the package produces the following error as mentioned with the search being shut down;\r\n\r\n```\r\n$ pip search tensorflow\r\nERROR: Exception:\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.9/site-packages/pip/_internal/cli/base_command.py\", line 224, in _main\r\n    status = self.run(options, args)\r\n  File \"/usr/lib/python3.9/site-packages/pip/_internal/commands/search.py\", line 62, in run\r\n    pypi_hits = self.search(query, options)\r\n  File \"/usr/lib/python3.9/site-packages/pip/_internal/commands/search.py\", line 82, in search\r\n    hits = pypi.search({'name': query, 'summary': query}, 'or')\r\n  File \"/usr/lib/python3.9/xmlrpc/client.py\", line 1116, in __call__\r\n    return self.__send(self.__name, args)\r\n  File \"/usr/lib/python3.9/xmlrpc/client.py\", line 1456, in __request\r\n    response = self.__transport.request(\r\n  File \"/usr/lib/python3.9/site-packages/pip/_internal/network/xmlrpc.py\", line 46, in request\r\n    return self.parse_response(response.raw)\r\n  File \"/usr/lib/python3.9/xmlrpc/client.py\", line 1348, in parse_response\r\n    return u.close()\r\n  File \"/usr/lib/python3.9/xmlrpc/client.py\", line 662, in close\r\n    raise Fault(**self._stack[0])\r\nxmlrpc.client.Fault: <Fault -32500: \"RuntimeError: PyPI's XMLRPC API is currently disabled due to unmanageable load and will be deprecated in the near future. See https://status.python.org/ for more information.\">\r\n```\r\n\r\n**Any other info / logs**\r\n\r\n", "comments": ["Python 3.9 is currently not supported.\r\nSee https://www.tensorflow.org/install/pip#system-requirements", "This is marked as feature request. duplicate #44485\r\nThanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47709\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47709\">No</a>\n"]}, {"number": 47708, "title": "[TFLM] Added ceva.inc file in ext_libs so optimized kernels get pulled in", "body": "Added empty ceva.inc file to get optimized kernels pulled in - when OPTIMIZED_KERNEL_DIR is used, the Makefile checkes for an inc file and only then copies in the optimized kernels.\r\n", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 47707, "title": "[XLA:GPU]: Re-47398 + AMD fix + missing commits.", "body": "This re-enable my commits https://github.com/tensorflow/tensorflow/pull/47398 + apply AMD fixed from https://github.com/tensorflow/tensorflow/pull/47730 and add the commits not merged from https://github.com/tensorflow/tensorflow/pull/47398.\r\n\r\n@sanjoy ", "comments": ["@nouiz Can you please resolve conflicts? Thanks!", "I can't. My PR was reverted: 99b9d93780d68190ba0f7b8c3b97c665fc63077b\r\nThe only information I have is: `Breaks nigthly non pip tests`\r\nSo I can't try to fix it... Can someone fix it or help me get a error that tell me what is going on?", "All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F47707) for more info**.\n\n<!-- need_author_consent -->", "@googlebot I consent", "I reverted the revert, added the AMD fixes and added the missing commit. See the new description.\r\nI still do not know if this will fix the internal error as I do not have access to it. But it fixes tests on AMD GPUs.", "@gbaned do you know what's going on here (why this isn't auto-merging)?", "> @gbaned do you know what's going on here (why this isn't auto-merging)?\r\n\r\n@sanjoy  It is waiting for the reviewer approval, can you please take a look? Thank you!"]}, {"number": 47706, "title": "Training stalls after saving checkpoint 0", "body": "Hello,\r\n\r\nFirst of all, I have read and tried all solutions from #32017, unless it isn't the same error exactly.\r\n\r\n**System information**\r\n- OS Platform and Distribution: Windows 10\r\n- TensorFlow version: 2.4.1\r\n- Python version: 3.8.2\r\n- CUDA/cuDNN version: 11.2\r\n\r\nI have tried to train a model with this command:\r\nmelody_rnn_train --config=attention_rnn --run_dir=tmp\\\\run1 --sequence_example_file=tmp\\\\sequence_examples\\\\training_melodies.tfrecord --hparams=\"batch_size=64,rnn_layer_sizes=[64,64]\" --num_training_steps=1\r\n\r\nThe behaviour should be the same than in a normal t2t-trainer output.\r\n\r\nThere are a lot of warnings about deprecated stuff but, I am pretty sure they are not impoortant so the last output lines are:\r\n\r\n```\r\nINFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\r\nI0310 18:09:11.618963  5924 basic_session_run_hooks.py:613] Calling checkpoint listeners before saving checkpoint 0...\r\nINFO:tensorflow:Saving checkpoints for 0 into tmp\\\\run1\\train\\model.ckpt.\r\nI0310 18:09:11.622482  5924 basic_session_run_hooks.py:618] Saving checkpoints for 0 into tmp\\\\run1\\train\\model.ckpt.\r\nINFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\r\nI0310 18:09:16.462026  5924 basic_session_run_hooks.py:625] Calling checkpoint listeners after saving checkpoint 0...\r\n```\r\n\r\nAnd nothing more happens after that, it stalls and IDK why.\r\nThanks in advance.", "comments": ["@albertonavas99 \r\nPlease share simple stand alone code to reproduce the issue or a colab gist with the error.", "@Saduf2019 \r\nI have only executed the command below which belongs to a library called \"Magenta\" developed by Google. It has a repository: https://github.com/magenta/magenta/tree/master/magenta/models/melody_rnn. Also, it can be downloaded with:\r\n\r\n`pip install magenta`\r\n\r\nThe only file needed to execute this command  (--sequence_example_file) is compressed and attached here:\r\n[training_melodies.zip](https://github.com/tensorflow/tensorflow/files/6131575/training_melodies.zip)\r\n\r\nThanks.\r\n\r\n", "@albertonavas99 This issue is more related to `magenta` repo and I see you already opened an issue there. This `tensorflow` repo is more related to bugs and performance related issues in Tensorflow Core.   \r\n\r\nduplicate https://github.com/magenta/magenta/issues/1899\r\n\r\nI am closing this issue as it is more related to `magenta` repo. Please feel free to reopen If I am mistaken. thanks!"]}, {"number": 47705, "title": "Could not load libcusolver.so.10 with tf-nightly-gpu", "body": "**System information**\r\n- OS Platform and Distribution: Arch Linux\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 2.5.0 (tf-nightly-gpu)\r\n- Python version: 3.9\r\n- CUDA/cuDNN version: 11.2\r\n- GPU model and memory: 1070 TI 8GB\r\n\r\nProblem:\r\nCould not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.2/lib64:/usr/local/lib\r\n\r\nI have tried to edit the LD_LIBRARY_PATH like other issues have suggested but that does not work. I do not know which version of CUDA tf-nightly requires. \r\n\r\nCUDA Info:\r\n[taylor@taylor-desktop ~]$ pacman -Qi cuda\r\nName            : cuda\r\nVersion         : 11.2.1-4\r\nDescription     : NVIDIA's GPU programming toolkit\r\nArchitecture    : x86_64\r\nURL             : https://developer.nvidia.com/cuda-zone\r\nLicenses        : custom:NVIDIA\r\nGroups          : None\r\nProvides        : cuda-toolkit  cuda-sdk  libcudart.so=11.0-64  libcublas.so=11-64  libcublas.so=11-64\r\n                      libcusolver.so=11-64  libcusolver.so=11-64  libcusparse.so=11-64  libcusparse.so=11-64\r\nDepends On      : gcc  gcc-libs  opencl-nvidia  nvidia-utils  python\r\nOptional Deps   : gdb: for cuda-gdb [installed]\r\n                          glu: required for some profiling tools in CUPTI [installed]\r\nRequired By     : cudnn\r\nOptional For    : None\r\nConflicts With  : None\r\nReplaces        : cuda-toolkit  cuda-sdk  cuda-static\r\nInstalled Size  : 3.32 GiB\r\nPackager        : Konstantin Gizdov <arch@kge.pw>\r\nBuild Date      : Mon Mar 1 05:21:57 2021\r\nInstall Date    : Tue Mar 9 16:35:57 2021\r\nInstall Reason  : Explicitly installed\r\nInstall Script  : Yes\r\nValidated By    : Signature\r\n\r\nlibcusolver.so=11-64 is installed but tensorflow seems to be looking for libcusolver.so=10. Is that due to tf-nighlty requiring Cuda 11.0? Then it would be the same cuda version as required by tensorflow 2.4. Let me know if you need any more info or I need to format things differently. Thanks.", "comments": ["@TPrivat,\r\nEvery TensorFlow release is compatible with a certain CUDA and cuDNN version. For more information, please take a look at the [tested build configurations](https://www.tensorflow.org/install/source#gpu).\r\n\r\n\r\nVersion | Python version | Compiler | Build tools | cuDNN | CUDA\r\n-- | -- | -- | -- | -- | --\r\ntensorflow-2.4.0 | 3.6-3.8 | GCC 7.3.1 | Bazel 3.1.0 | 8.0 | 11.0\r\ntensorflow-2.3.0 | 3.5-3.8 | GCC 7.3.1 | Bazel 3.1.0 | 7.6 | 10.1\r\ntensorflow-2.2.0 | 3.5-3.8 | GCC 7.3.1 | Bazel 2.0.0 | 7.6 | 10.1\r\n\r\n\r\nIn this case, could you please try installing TensorFlow on **Python 3.8** with **CUDA 11.0** and **cuDNN 8** and check if you are facing the same issue. \r\n\r\nThanks!", "I can only use what is the arch repository. That is python 3.9, cuda 11.2 and cudnn 8.1 which is why I am using tf-nightly. What cuda cudnn version are compatible with tf-nightly/tf-nightly-gpu (2.5.0.dev20210309). \r\nThanks.", "@TPrivat,\r\nTF-nightly packages are compatible with **Python 3.9**, **CUDA 11.2** and **cuDNN 8.1**. I was able to install TensorFlow without any issues with the above configuration. Please check the attached screenshot for reference. \r\n\r\n![Screenshot 2021-03-18 7 59 49 PM](https://user-images.githubusercontent.com/57165142/111643330-e5c49d00-8824-11eb-8768-05c43f368f13.png)\r\n\r\nThanks!", "Yes it seems with the newer version of tf-nightly-gpu (2.5.0.dev20210318) the correct version of libcusolver is loaded. However I now have the errors \"failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\" and \"None of the MLIR Optimization Passes are enabled (registered 2)\". I do not get the line \"Adding visible gpu devices:\" and instead get \"CPU Frequency: 3600000000 Hz\", which I assume means it is still using my CPU rather than my GPU.\r\n\r\nBelow is the full read-out:\r\n`2021-03-18 17:55:57.237003: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\n2021-03-18 17:55:57.872950: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\r\n2021-03-18 17:55:57.907640: E tensorflow/stream_executor/cuda/cuda_driver.cc:328] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\r\n2021-03-18 17:55:57.907666: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: taylor-desktop\r\n2021-03-18 17:55:57.907673: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: taylor-desktop\r\n2021-03-18 17:55:57.907723: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 460.56.0\r\n2021-03-18 17:55:57.907744: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 460.56.0\r\n2021-03-18 17:55:57.907748: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 460.56.0\r\nDataset created, creating and adapting vector layer now...\r\n2021-03-18 17:55:57.948387: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:176] None of the MLIR Optimization Passes are enabled (registered 2)\r\n2021-03-18 17:55:57.948691: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 3600000000 Hz`\r\n\r\nI appreciate you taking time to help!", "![tensorflow_errors](https://user-images.githubusercontent.com/33856930/111708613-2bc53500-8814-11eb-9272-2a211d952ed4.png)\r\n\r\nThis may be an easier version to read of the errors/read-out\r\n\r\nAlso upon further testing it seems my GPU is in use for training. So it seems like everything is working. If the above errors do not indicate anything majorly wrong to you. I will say that this issue has been solved.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47705\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47705\">No</a>\n"]}, {"number": 47704, "title": "Numbers get printed out when model.fit() instead of verbosity associated with epochs/iterations -- tf.keras", "body": "This is my code so far, I am using ```tf.data.experimental.bucket_by_sequence_length``` because X_train is a list of 2D lists with differing number of rows -- so when training want to batch with similar sizes. \r\n\r\n\r\n```\r\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\r\n\r\ntrain_data = tf.data.Dataset.from_generator(lambda: (X_train, y_train),\u2028 output_types=(tf.float32, tf.float32),\u2028 output_shapes=(tf.TensorShape([None, len(X_train[0][0])]),tf.TensorShape([None, len(y_train[0][0])]))\u2028)\r\n\r\n\u2028val_data = tf.data.Dataset.from_generator(lambda: (X_test, y_test),\u2028 output_types=(tf.float32, tf.float32),\u2028 output_shapes=(tf.TensorShape([None, len(X_train[0][0])]),\u2028tf.TensorShape([None, len(y_train[0][0])]))\u2028)\u2028\r\n\r\ndef element_length_fn(x, y):\u2028    \r\n         return tf.shape(x)[0]\u2028\u2028\u2028\r\n\r\nmax_train = len(max(X_train, key=len))\u2028\r\nmin_train = len(min(X_train, key=len))\u2028\r\nmax_val = len(max(X_test, key=len))\u2028\r\nmin_val = len(min(X_test, key=len))\u2028\u2028\r\nbatch_size = 64\u2028\r\nbucket_boundaries_train = list(np.arange(min_train, max_train, 10)) \r\nbucket_batch_sizes_train = [batch_size] * (len(bucket_boundaries_train) + 1)\r\nbucket_boundaries_val = list(np.arange(min_val, max_val, 10)) \r\nbucket_batch_sizes_val = [batch_size] * (len(bucket_boundaries_val) + 1)\r\n\r\n\u2028\u2028train_data = train_data.apply(tf.data.experimental.bucket_by_sequence_length(\r\n              element_length_func=element_length_fn,\u2028\r\n              bucket_batch_sizes=bucket_batch_sizes_train,\r\n              bucket_boundaries=bucket_boundaries_train\u2028)\u2028)\u2028\u2028\r\n\r\nval_data = val_data.apply(\u2028tf.data.experimental.bucket_by_sequence_length(\r\n              element_length_func=element_length_fn,\u2028\r\n              bucket_batch_sizes=bucket_batch_sizes_val,\r\n              bucket_boundaries=bucket_boundaries_val,)\r\n\r\ndef create_model():\u2028    \r\n     i = Input(shape=(None, len(X_train[0][0])))\u2028\r\n     x = Bidirectional(LSTM(128, return_sequences=True))(i)\u2028    \r\n     x = TimeDistributed(Dense(2))(x)\u2028    \r\n     return tf.keras.Model(inputs=i, outputs=x)\r\n\r\nmodel = create_model()\u2028    \r\nmodel.compile(\u2028loss='mse',\u2028optimizer='adam',metrics=[metrics.RootMeanSquaredError()])\u2028\u2028\r\nmodel.fit(train_data,\r\n         epochs=5,\r\n         validation_data=val_data\u2028)\r\n\r\n```\r\n\r\n\r\n\r\nHowever, when I run this, no error apparently shows. The only bizarre thing is that what looks like lists keeps getting print out, as opposed to the verbosity you would expect when training (see below for a sample of what gets printed out). How can this be fixed?\r\n\r\n\r\n\r\n```\r\n -6.866918300812502, 8.563543404559187, 21.8377909841752, 6.40732927880351, -6.866918300812502, 8.563543404559187, 262.05, 115.33, -172.22000000000003, -25.5, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 1197.0, 0.009000000000000001, 2.3, 0.31, 2075.0, 3.5, 0.0, 0.0, 78516.0, 0.98, 0.0, 0.0, 275947.0, 70900.9, 0.0, 0.0, 5.0, 27149.0, 115.33, 0.0, 18.0, 6.40732927880351, 7.15266763866861, 6.40732927880351, 0.10420424903230041, 0.10420424903230041, 0.0, 0.0, 14.970872683362698, 13.4530996322305, -8.563543404559187, -7.045770353426991, 14.970872683362698, 13.4530996322305, -8.563543404559187, -7.045770353426991, 89.83, 403.59, 25.5, -288.26, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 1197.0, 0.009000000000000001, 2.3, 0.31, 2075.0, 3.5, 0.0, 0.0, 78516.0, 0.98, 0.0, 0.0, 275947.0, 70900.9, 0.0, 0.0, 6.0, 27167.0, 403.59, 0.0, 30.0, 13.4530996322305, 14.305335277337198, 13.4530996322305, 0.059574671168793, 0.059574671168793, 0.0, 0.0, 6.40732927880351, 24.934202366029503, 7.045770353426991, -11.481102733799002, 6.40732927880351, 24.934202366029503, 7.045770353426991, -11.481102733799002, 115.33, 1645.66, 288.26, -1242.0700000000002, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 1197.0, 0.009000000000000001, 2.3, 0.31, 2075.0, 3.5, 0.0, 0.0, 78516.0, 0.98, 0.0, 0.0, 275947.0, 70900.9, 0.0, 0.0, 7.0, 27197.0, 1645.66, 0.0, 66.0, 24.934202366029503, 26.911911990490605, 24.934202366029503, 0.07348826144942544, 0.07348826144942544, 0.0, 0.0, 13.4530996322305, 25.7129007505185, 11.481102733799002, -0.7786983844889974, 13.4530996322305, 25.7129007505185, 11.481102733799002, -0.7786983844889974, 403.59, 925.66, 1242.0700000000002, 720.0000000000001, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 1197.0, 0.009000000000000001, 2.3, 0.31, 2075.0, 3.5, 0.0, 0.0, 78516.0, 0.98, 0.0, 0.0, 275947.0, 70900.9, 0.0, 0.0, 8.0, 27263.0, 925.66, 0.0, 36.0, 25.7129007505185, 26.688391126782303, 25.7129007505185, 0.03655111211574236, 0.03655111211574236, 0.0, 0.0, 24.934202366029503, 26.095100358087002, 0.7786983844889974, -0.38219960756850213, 24.934202366029503, 26.095100358087002, 0.7786983844889974, -0.38219960756850213, 1645.66, 782.85, -720.0000000000001, 142.80999999999995, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 1197.0, 0.009000000000000001, 2.3, 0.31, 2075.0, 3.5, 0.0, 0.0, 78516.0, 0.98, 0.0, 0.0, 275947.0, 70900.9, 0.0, 0.0, 9.0, 27299.0, 782.85, 0.0, 30.0, 26.095100358087002, 26.643686954040604, 26.095100358087002, 0.020589740335108075, 0.020589740335108075, 0.0, 0.0, 25.7129007505185, 24.284601969264603, 0.38219960756850213, 1.810498388822399, 25.7129007505185, 24.284601969264603, 0.38219960756850213, 1.810498388822399, 925.66, 1019.95, -142.80999999999995, -237.10000000000002, 0.0, 0.0], [0.0, 0.0, 0.0, 1.0, 1197.0, 0.009000000000000001, 2.3, 0.31, 2075.0, 3.5, 0.0, 0.0, 78516.0, 0.98, \r\n```\r\n", "comments": ["Ok, I figured it out. Essentially it was a lack of introducing an actual callable object in the generator argument. I created a function called gen (generating my data) and passed it to the argument. "]}, {"number": 47703, "title": "TFLM: Exclude micro speech example", "body": "Excluding micro speech example in cortex_m_generic_makefile.inc to\r\nprevent warnings to be cleared.\r\n\r\nFix for: https://github.com/tensorflow/tensorflow/issues/47589\r\nIt also progress towards: https://github.com/tensorflow/tensorflow/issues/47070", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "@mansnils can you please resolve conflicts ", "@rthadur conflict is resolved"]}, {"number": 47701, "title": "\"Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED\" only when running old TF code", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): pip install tensorflow-gpu==2.1.0\r\n- TensorFlow version (use command below): v2.1.0-rc2-17-ge5bf8de 2.1.0\r\n- Python version: 3.5.2\r\n- CUDA/cuDNN version: Driver Version: 418.39       CUDA Version: 10.1\r\n- GPU model and memory: GeForce GTX 1080Ti (11GB)\r\n\r\nI've downloaded tensorflow-gpu 2.1.0 because it's compatible with the drivers currently installed. Indeed, TFv2 code works, but  I run into this problem when trying to run old TFv1 code. It seems that this error happens after the first convolution, so I guess there is a problem using convolutions, but it's funny that I have no such problem using TFv2 code. I've searched about it, and I've read that downgrading TF and even the drivers could solve it, but if TFv2 can use convolutions, why old TFv1 code could not? This might be a bug. Any workaround?\r\n\r\nTFv2 code that works: https://pastebin.com/D4YMMUPT\r\nOld TFv1 code that does not work: https://pastebin.com/AXAaYbKs\r\n\r\nError log:\r\n\r\n> 2021-03-10 17:45:34.210128: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\r\n> 2021-03-10 17:45:34.210184: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\r\n> 2021-03-10 17:45:34.210191: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\r\n> WARNING: Logging before flag parsing goes to stderr.\r\n> W0310 17:45:34.787791 139979412670208 deprecation.py:323] From /home/user/virtualenv1/lib/python3.5/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> non-resource variables are not supported in the long term\r\n> W0310 17:45:34.792874 139979412670208 deprecation.py:506] From /home/user/virtualenv1/lib/python3.5/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\r\n> Instructions for updating:\r\n> If using Keras pass *_constraint arguments to layers.\r\n> 2021-03-10 17:45:34.911558: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\r\n> 2021-03-10 17:45:34.930318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\n> pciBusID: 0000:17:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\r\n> coreClock: 1.62GHz coreCount: 28 deviceMemorySize: 10.90GiB deviceMemoryBandwidth: 451.17GiB/s\r\n> 2021-03-10 17:45:34.930522: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n> 2021-03-10 17:45:34.931581: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n> 2021-03-10 17:45:34.932423: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n> 2021-03-10 17:45:34.932628: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n> 2021-03-10 17:45:34.933731: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n> 2021-03-10 17:45:34.934569: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n> 2021-03-10 17:45:34.937042: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n> 2021-03-10 17:45:34.938760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n> 2021-03-10 17:45:34.939051: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA\r\n> 2021-03-10 17:45:34.961585: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3999980000 Hz\r\n> 2021-03-10 17:45:34.962354: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x59b5640 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n> 2021-03-10 17:45:34.962397: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n> 2021-03-10 17:45:35.060702: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5a3bb90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\r\n> 2021-03-10 17:45:35.060757: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1\r\n> 2021-03-10 17:45:35.062292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: \r\n> pciBusID: 0000:17:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\r\n> coreClock: 1.62GHz coreCount: 28 deviceMemorySize: 10.90GiB deviceMemoryBandwidth: 451.17GiB/s\r\n> 2021-03-10 17:45:35.062384: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n> 2021-03-10 17:45:35.062432: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n> 2021-03-10 17:45:35.062480: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\r\n> 2021-03-10 17:45:35.062526: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\r\n> 2021-03-10 17:45:35.062573: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\r\n> 2021-03-10 17:45:35.062617: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\r\n> 2021-03-10 17:45:35.062665: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n> 2021-03-10 17:45:35.065186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0\r\n> 2021-03-10 17:45:35.065292: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\r\n> 2021-03-10 17:45:35.067678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n> 2021-03-10 17:45:35.067707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 \r\n> 2021-03-10 17:45:35.067721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N \r\n> 2021-03-10 17:45:35.070991: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10308 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:17:00.0, compute capability: 6.1)\r\n> W0310 17:45:35.072554 139979412670208 deprecation.py:323] From /home/user/virtualenv1/lib/python3.5/site-packages/tensorflow_core/python/util/tf_should_use.py:235: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\r\n> Instructions for updating:\r\n> Use `tf.global_variables_initializer` instead.\r\n> 2021-03-10 17:45:35.750980: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\r\n> 2021-03-10 17:45:35.904388: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\r\n> 2021-03-10 17:45:35.905558: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED\r\n> 2021-03-10 17:45:35.905655: E tensorflow/stream_executor/cuda/cuda_dnn.cc:337] Possibly insufficient driver version: 418.39.0\r\n> 2021-03-10 17:45:35.905682: E tensorflow/stream_executor/cuda/cuda_dnn.cc:329] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED\r\n> 2021-03-10 17:45:35.905727: E tensorflow/stream_executor/cuda/cuda_dnn.cc:337] Possibly insufficient driver version: 418.39.0\r\n> Traceback (most recent call last):\r\n>   File \"/home/user/virtualenv1/lib/python3.5/site-packages/tensorflow_core/python/client/session.py\", line 1367, in _do_call\r\n>     return fn(*args)\r\n>   File \"/home/user/virtualenv1/lib/python3.5/site-packages/tensorflow_core/python/client/session.py\", line 1352, in _run_fn\r\n>     target_list, run_metadata)\r\n>   File \"/home/user/virtualenv1/lib/python3.5/site-packages/tensorflow_core/python/client/session.py\", line 1445, in _call_tf_sessionrun\r\n>     run_metadata)\r\n> tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.\r\n>   (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n> \t [[{{node Conv2D}}]]\r\n> \t [[Mean_1/_7]]\r\n>   (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n> \t [[{{node Conv2D}}]]\r\n> 0 successful operations.\r\n> 0 derived errors ignored.\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n>   File \"old_tf_script.py\", line 62, in <module>\r\n>     x:xx, y_: yy, keep_prob: 1.0})\r\n>   File \"/home/user/virtualenv1/lib/python3.5/site-packages/tensorflow_core/python/framework/ops.py\", line 790, in eval\r\n>     return _eval_using_default_session(self, feed_dict, self.graph, session)\r\n>   File \"/home/user/virtualenv1/lib/python3.5/site-packages/tensorflow_core/python/framework/ops.py\", line 5312, in _eval_using_default_session\r\n>     return session.run(tensors, feed_dict)\r\n>   File \"/home/user/virtualenv1/lib/python3.5/site-packages/tensorflow_core/python/client/session.py\", line 960, in run\r\n>     run_metadata_ptr)\r\n>   File \"/home/user/virtualenv1/lib/python3.5/site-packages/tensorflow_core/python/client/session.py\", line 1183, in _run\r\n>     feed_dict_tensor, options, run_metadata)\r\n>   File \"/home/user/virtualenv1/lib/python3.5/site-packages/tensorflow_core/python/client/session.py\", line 1361, in _do_run\r\n>     run_metadata)\r\n>   File \"/home/user/virtualenv1/lib/python3.5/site-packages/tensorflow_core/python/client/session.py\", line 1386, in _do_call\r\n>     raise type(e)(node_def, op, message)\r\n> tensorflow.python.framework.errors_impl.UnknownError: 2 root error(s) found.\r\n>   (0) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n> \t [[node Conv2D (defined at old_tf_script.py:18) ]]\r\n> \t [[Mean_1/_7]]\r\n>   (1) Unknown: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n> \t [[node Conv2D (defined at old_tf_script.py:18) ]]\r\n> 0 successful operations.\r\n> 0 derived errors ignored.\r\n> \r\n> Errors may have originated from an input operation.\r\n> Input Source operations connected to node Conv2D:\r\n>  Reshape (defined at old_tf_script.py:30)\r\n> \r\n> Input Source operations connected to node Conv2D:\r\n>  Reshape (defined at old_tf_script.py:30)\r\n> \r\n> Original stack trace for 'Conv2D':\r\n>   File \"old_tf_script.py\", line 31, in <module>\r\n>     h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\r\n>   File \"old_tf_script.py\", line 18, in conv2d\r\n>     return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\r\n>   File \"/home/user/virtualenv1/lib/python3.5/site-packages/tensorflow_core/python/ops/nn_ops.py\", line 1914, in conv2d_v2\r\n>     name=name)\r\n>   File \"/home/user/virtualenv1/lib/python3.5/site-packages/tensorflow_core/python/ops/nn_ops.py\", line 2011, in conv2d\r\n>     name=name)\r\n>   File \"/home/user/virtualenv1/lib/python3.5/site-packages/tensorflow_core/python/ops/gen_nn_ops.py\", line 969, in conv2d\r\n>     data_format=data_format, dilations=dilations, name=name)\r\n>   File \"/home/user/virtualenv1/lib/python3.5/site-packages/tensorflow_core/python/framework/op_def_library.py\", line 742, in _apply_op_helper\r\n>     attrs=attr_protos, op_def=op_def)\r\n>   File \"/home/user/virtualenv1/lib/python3.5/site-packages/tensorflow_core/python/framework/ops.py\", line 3322, in _create_op_internal\r\n>     op_def=op_def)\r\n>   File \"/home/user/virtualenv1/lib/python3.5/site-packages/tensorflow_core/python/framework/ops.py\", line 1756, in __init__\r\n>     self._traceback = tf_stack.extract_stack()\r\n> \r\n\r\n", "comments": ["@kuonb \r\nplease refer to these issues and let us know: [link](https://stackoverflow.com/questions/60368298/could-not-load-dynamic-library-libnvinfer-so-6), #36201, #35968, [link1](https://www.gitmemory.com/issue/tensorflow/tensorflow/36201/578413833)", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47701\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47701\">No</a>\n"]}, {"number": 47700, "title": "Unable to load tflite file in android, It provides =\" Internal error: Failed to run on the given Interpreter: tensorflow/lite/kernels/transpose.cc:55 op_context->perm->dims->data[0] != dims (3 != 2) 03-10 16:42:09.948  8010  8010 D check here: Node number 6 (TRANSPOSE) failed to prepare.\"", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Yes** \r\n colab link to tensorflow model = [https://colab.research.google.com/drive/1BI0661FaM6L4oqjNX1MYfHpJCKwKQhjt?usp=sharing](url)\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Windows 10**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: **Samsung Galaxy M30 s**\r\n- TensorFlow installed from (source or binary):  **pip3 install tensorflow**\r\n- TensorFlow version (use command below): **2.4.1**\r\n- Python version: **3.7**\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nUnable to load tflite model file , It provides Internal error. PLease find Log data that raised for this issue : \r\n**03-10 16:42:09.948  8010  8010 D check here: java.lang.IllegalArgumentException: Internal error: Failed to run on the given Interpreter: tensorflow/lite/kernels/transpose.cc:55 op_context->perm->dims->data[0] != dims (3 != 2)\r\n03-10 16:42:09.948  8010  8010 D check here: Node number 6 (TRANSPOSE) failed to prepare.\r\n03-10 16:42:09.948  8010  8010 D check here: \r\n03-10 16:42:09.948  8010  8010 D check here: \tat org.tensorflow.lite.NativeInterpreterWrapper.run(Native Method)\r\n03-10 16:42:09.948  8010  8010 D check here: \tat org.tensorflow.lite.NativeInterpreterWrapper.run(NativeInterpreterWrapper.java:163)\r\n03-10 16:42:09.948  8010  8010 D check here: \tat org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs(Interpreter.java:360)\r\n03-10 16:42:09.948  8010  8010 D check here: \tat org.tensorflow.lite.Interpreter.run(Interpreter.java:319)\r\n03-10 16:42:09.948  8010  8010 D check here: \tat com.example.testforlite.MainActivity$1.onClick(MainActivity.java:89)\r\n03-10 16:42:09.948  8010  8010 D check here: \tat android.view.View.performClick(View.java:5794)\r\n03-10 16:42:09.948  8010  8010 D check here: \tat com.google.android.material.button.MaterialButton.performClick(MaterialButton.java:1119)\r\n03-10 16:42:09.948  8010  8010 D check here: \tat android.view.View$PerformClick.run(View.java:22729)\r\n03-10 16:42:09.948  8010  8010 D check here: \tat android.os.Handler.handleCallback(Handler.java:751)\r\n03-10 16:42:09.948  8010  8010 D check here: \tat android.os.Handler.dispatchMessage(Handler.java:95)\r\n03-10 16:42:09.948  8010  8010 D check here: \tat android.os.Looper.loop(Looper.java:154)\r\n03-10 16:42:09.948  8010  8010 D check here: \tat android.app.ActivityThread.main(ActivityThread.java:6138)\r\n03-10 16:42:09.948  8010  8010 D check here: \tat java.lang.reflect.Method.invoke(Native Method)\r\n03-10 16:42:09.948  8010  8010 D check here: \tat com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:893)\r\n03-10 16:42:09.948  8010  8010 D check here: \tat com.android.internal.os.ZygoteInit.main(ZygoteInit.java:783)**\r\n\r\nI have passed input with correct dimension, still There is some error when I run tflite using Interpreter\r\n\r\n\r\n**Describe the expected behavior**\r\n\r\nExpected behaviour should load tflite model and provide output values for the provided input\r\n \r\n**Standalone code to reproduce the issue**\r\ncolab tensorflow model : [https://colab.research.google.com/drive/1BI0661FaM6L4oqjNX1MYfHpJCKwKQhjt?usp=sharing](url) \r\nandroid Code link : [https://github.com/Adeesh2411/TensorflowAndroidAPP](url)\r\ntflite file can be found in asset folder\r\n\r\n\r\n", "comments": ["@Adeesh2411 could you make sure that your android client has a TFLite dependency, which has the same or higher version of the TensorFlow used for TFLite model conversion?", "The old runtime may not be able to run the models generated with a newer version. My recommendation is upgrading TF version of your android client if the client has a lower version than 2.4.", "@abattery I converted my tensorflow vesion = 2.4.0 and tflite = 2.4.0. \r\nStill it provides same issue", "@Adeesh2411 could you confirm which TF version you are using for android?", "My dependency : \r\ndependencies {\r\n\r\n    implementation 'org.tensorflow:tensorflow-lite:2.4.0'\r\n    implementation 'androidx.appcompat:appcompat:1.2.0'\r\n    implementation 'com.google.android.material:material:1.3.0'\r\n    implementation 'androidx.constraintlayout:constraintlayout:2.0.4'\r\n    testImplementation 'junit:junit:4.+'\r\n    androidTestImplementation 'androidx.test.ext:junit:1.1.2'\r\n    androidTestImplementation 'androidx.test.espresso:espresso-core:3.3.0'\r\n}\r\n\r\nIn MainActivity file I'm importing : import org.tensorflow.lite.Interpreter;\r\nthen I initialize ` ByteBuffer My_byte = loadModelFile(MainActivity.this, Model);\r\n            tflite = new Interpreter(My_byte);` \r\n\r\nI didn't get what you meant by saying TF version in android . Is there anything I need to add in dependency?\r\n", "@abattery  Thank you for looking into my issue. \r\nI got working with model now. \r\nIsuue was with tflite dependency :\r\nI converted my tensorflow verion in python : \r\n```\r\ntensorboard==2.2.2\r\ntensorflow==2.2.0\r\ntensorflow-estimator==2.2.0\r\n```\r\nand in android my dependency version to :\r\n`implementation 'org.tensorflow:tensorflow-lite:2.2.0'`", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47700\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47700\">No</a>\n"]}, {"number": 47699, "title": "[ROCm] Re-enabling unit-tests that are now passing on the ROCm platform", "body": "/cc @cheshire @chsigg ", "comments": ["@cheshire @chsigg gentle ping", "@cheshire @chsigg gentle ping"]}, {"number": 47698, "title": "TF-TRT CombinedNMS: fix top_k parameter max value", "body": "Fixes #46453\r\n\r\nThe TRT plugin has a limitation on the max value of the top_k input parameter. This PR modifies the converter to refuse conversion if top_k > 4096. \r\n\r\nIn some cases it might be desirable to do the conversion, even if the top_k<=4096 restriction would lead to loss of accuracy. The user can set TF_TRT_ALLOW_NMS_TOPK_OVERRIDE=1 environment variable can be set to opt-in for conversion in this case.\r\n", "comments": ["Tagging @bixia1 for review and @DEKHTIARJonathan for visibility."]}, {"number": 47697, "title": "Improve notebooks for tflite-model-maker", "body": "", "comments": ["Check out this pull request on&nbsp; <a href=\"https://app.reviewnb.com/tensorflow/tensorflow/pull/47697\"><img align=\"absmiddle\"  alt=\"ReviewNB\" height=\"28\" class=\"BotMessageButtonImage\" src=\"https://raw.githubusercontent.com/ReviewNB/support/master/images/button_reviewnb.png\"/></a> \n\n See visual diffs & provide feedback on Jupyter Notebooks. \n\n---\n\n <i>Powered by <a href='https://www.reviewnb.com/?utm_source=gh'>ReviewNB</a></i>", "@ziyeqinghan @lintian06 could you review this PR?"]}, {"number": 47696, "title": "model.to_json() TypeError: Not JSON Serializable", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows, Linux\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): 1.14.0\r\n- Python version: 3.6.1\r\n\r\nCode to reproduce issue:\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\n\r\nprint(f'TensorFlow version={tf.__version__}')\r\nprint(f'Numpy version={np.__version__}')\r\n\r\nfrom tensorflow.keras.models import model_from_json\r\nfrom tensorflow.keras.layers import Layer\r\nfrom tensorflow.keras import Input, Model\r\n\r\ntf.compat.v1.disable_eager_execution()\r\n\r\ninputs = Input(shape=(3,))\r\noutput = inputs * 2\r\nloss = tf.keras.backend.mean(inputs)\r\noutputs = [output, loss]\r\nmodel = Model(inputs, outputs)\r\n\r\nloss = tf.reduce_mean(loss)\r\nloss = tf.keras.backend.mean(loss)\r\nmodel.add_loss(loss)\r\n\r\nmodel.compile(optimizer=\"adam\", loss=[None] * len(model.outputs))\r\nmodel.fit(np.random.random((2, 3)))\r\n\r\nmodel_json = model.to_json()  # TypeError: ('Not JSON Serializable:', b'\\n\\x03mul\\x12\\x03Mul\\x1a\\x07input_1\\x1a\\x05mul/y*\\x07\\n\\x01T\\x12\\x020\\x01')\r\nwith open(\"model.json\", \"w\") as json_file:\r\n    json_file.write(model_json)\r\nmodel.save_weights(\"model.h5\")\r\n\r\njson_file = open('model.json', 'r')\r\nloaded_model_json = json_file.read()\r\njson_file.close()\r\nloaded_model = model_from_json(loaded_model_json)\r\nprint(\"model_from_json ok\")\r\n```\r\n\r\nCauses:\r\n```batch\r\nTypeError                                 Traceback (most recent call last)\r\n\r\n<ipython-input-2-da2091051454> in <module>()\r\n     24 model.fit(np.random.random((2, 3)))\r\n     25 \r\n---> 26 model_json = model.to_json()  # TypeError: ('Not JSON Serializable:', b'\\n\\x03mul\\x12\\x03Mul\\x1a\\x07input_1\\x1a\\x05mul/y*\\x07\\n\\x01T\\x12\\x020\\x01')\r\n     27 with open(\"model.json\", \"w\") as json_file:\r\n     28     json_file.write(model_json)\r\n\r\n4 frames\r\n\r\n/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/serialization.py in get_json_type(obj)\r\n     67     return dict(obj)\r\n     68 \r\n---> 69   raise TypeError('Not JSON Serializable:', obj)\r\n\r\nTypeError: ('Not JSON Serializable:', b'\\n\\x03mul\\x12\\x03Mul\\x1a\\x07input_1\\x1a\\x05mul/y*\\x07\\n\\x01T\\x12\\x020\\x01')\r\n```\r\n\r\nVersions above 1.14.0 do not cause this in the function .to_json().\r\n\r\nGist: https://gist.github.com/kiflowb777/8fd25c7cde004b1e885d3c29970bb5c5", "comments": ["@kiflowb777 \r\nWe see that you are using tf 1.x which is not supported anymore, please upgrade to 2.x and let us know if you face any issues.", "With 2.x ```to_json()``` works but there is a problem with ```model_from_json()```. \r\nMore info: https://github.com/tensorflow/tensorflow/issues/47309", "@kiflowb777 \r\nAs it is tracked in #47309 can we move this to closed status.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47696\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47696\">No</a>\n"]}]