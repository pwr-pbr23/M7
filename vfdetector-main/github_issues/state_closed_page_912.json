[{"number": 26101, "title": "Bump TF version to 1.13.1", "body": "", "comments": ["~Sorry for disturbing you guys, but just out of curiosity, what happened to 1.13.0?~ I found it: #26046.", "Yes, I created the tag on the master branch by mistake.\r\nPreviously, when we overwrote tags, there were issues, so we decided to skip 1.13.0 and release 1.13.1\r\n", "will there be a  Tensorflow-1.13.1 on pypi ? it's still Tensorflow-1.13.0rc2 there"]}, {"number": 26100, "title": "Parallel quasi-newton optimizers for tensorflow-gpu", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 1.12.0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n**Describe the feature and the current behavior/state.**\r\nIs there any interest in implementing quasi-Newton methods for tensorflow-gpu? There has been some work on a parallel L-BFGS-B method (https://www.sciencedirect.com/science/article/pii/S0097849314000119) for GPus.\r\n\r\n**Will this change the current api? How?**\r\nNew implementation.\r\n\r\n**Who will benefit with this feature?**\r\nI have had some recent success with using the BFGS optimizer for feedforward neural network. This approach, however, is limited to small networks and to tensorflow-cpu.\r\n\r\n**Any Other info.**\r\n\r\n", "comments": ["Any updates?", "Found this from a [tweet](https://twitter.com/timudk/status/1118240779170803712). Second-order methods are very efficient for small & smooth problems. An example is [Picking an Optimizer for Style Transfer](https://blog.slavv.com/picking-an-optimizer-for-style-transfer-86e7b8cba84b) that shows BFGS performs better than SGD-like methods (related: tensorflow/tfjs#127). Currently this is done through a SciPy wrapper without GPU support (keras-team/keras#5085)\r\n\r\nUseful references: \r\n- PyTorch's L-BFGS implementation : [source code](https://pytorch.org/docs/stable/_modules/torch/optim/lbfgs.html) and [usage in style transfer](https://pytorch.org/tutorials/advanced/neural_style_tutorial.html#gradient-descent).\r\n- Prototyping L-BFGS with TF-eager: [TensorFlow meets PyTorch with Eager execution](https://medium.com/@yaroslavvb/tensorflow-meets-pytorch-with-eager-mode-714cce161e6c).", "You can have a look at the implementation of BFGS and LBFGS in Tensorflow_probability, which do not wrap Scipy: https://github.com/tensorflow/probability/tree/master/tensorflow_probability/python/optimizer", "It might be better to raise this feature request to Tensorflow_probability.", "I finally got TFP's BFGS optimizer working for a supervised problem. Would adding an example to https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples be desirable?", "> I finally got TFP's BFGS optimizer working for a supervised problem. Would adding an example to https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples be desirable?\r\n\r\n@jvdillon WDYT?", "> I finally got TFP's BFGS optimizer working for a supervised problem. Would adding an example to https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples be desirable?\r\n\r\nCan you share a code-snippet? ", "@timudk,\r\nAs per [this comment](https://github.com/tensorflow/tensorflow/issues/26100#issuecomment-505904074) this Feature seems to be implemented. Please find this [working example in the Tensorflow Documentation](https://www.tensorflow.org/probability/examples/Optimizers_in_TensorFlow_Probability#bfgs_and_l-bfgs_optimizers).Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 26099, "title": "tf.one_hot crashes when indices is tf.uint8", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes.\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04 / Windows 7\r\n- TensorFlow installed from (source or binary): Official pip source (tensorflow-gpu)\r\n- TensorFlow version (use command below): 1.12.0\r\n- Python version: 3.6\r\n- CUDA/cuDNN version: 9.0 / 7.5\r\n- GPU model and memory: 1080Ti / 12GB\r\n\r\n**Describe the current behavior**\r\ntf.one_hot crashes when the indices tensor has dtype=tf.uint8\r\nThe error message shows `Check failed: new_num_elements == NumElements()`\r\n\r\n**Code to reproduce the issue**\r\nhttps://gist.github.com/elmirador/4fc5148e5044478d668237209d265eac\r\n\r\n**Other info / logs**\r\nI've also tested under TF 1.4.1 and TF 1.10.0 (both on GPU) on different machines, both have the same problem.", "comments": ["Hello, I am new to the tensorflow community and which going thorugh the code I couldn't find gen_array_ops. If possible I would like to contribute to the issue.", "> Hello, I am new to the tensorflow community and which going thorugh the code I couldn't find gen_array_ops. If possible I would like to contribute to the issue.\r\n\r\n`gen_array_ops.py` is located under `tensorflow/python/ops/`.\r\nYou can't find it on github because `gen_array_ops` is generated during building.\r\nBasically it's a wrapper around the underlying C++ code of tensorflow. If you're interested, the C++ code of one_hot ops is located at `tensorflow/core/kernels/one_hot_op.cc`.", "@bono1567 Don't know if you had a chance to look into it and thank you for your interest!\r\nSince you haven't posted an update for a while and I just looked into it, I will submit a fix now.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=26099\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=26099\">No</a>\n"]}, {"number": 26098, "title": "[TF 2.0] optimizer_v2.get_updates() eager mode problem", "body": "**TF Version: 2.0.0-dev20190214\r\nWindows 10\r\nAnaconda Python 3.6.5\r\nGPU: GeForce GTX 1070 Max-Q Design\r\n[Tensorflow 2.0 (gpu) nightly](https://pypi.org/project/tf-nightly-gpu-2.0-preview/) installed via pip.**\r\n\r\n**Describe the current behavior**\r\nCalling [`<AnyOptimizerV2>.get_updates(params=my_model.trainable_weights, loss=my_loss)`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/optimizer_v2/optimizer_v2.py#L447) fails with any `my_loss` (due to eager mode being on):\r\n\r\n```\r\n    actor_updates = self.optimizer_actor.get_updates(params=self.actor.trainable_weights, loss=None)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 448, in get_updates\r\n    grads = self.get_gradients(loss, params)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 361, in get_gradients\r\n    grads = gradients.gradients(loss, params)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 158, in gradients\r\n    unconnected_gradients)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\", line 547, in _GradientsHelper\r\n    raise RuntimeError(\"tf.gradients is not supported when eager execution \"\r\nRuntimeError: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead.\r\n```\r\nGlobally disabling eager execution via `tf.compat.v1.disable_eager_execution()` fixes this particular issue but I don't want to globally disable eager mode! I'd like to know how the 2.0 API is intended to be used in this case.\r\n\r\n**Describe the expected behavior**\r\nSince the gradient computation is happening internally I expected behavior similar to TF1 i.e. computation of gradients in graph mode in this case. Also I don't want to use `tf.GradientTape` every time I want to compute the gradient instances - instead I want to obtain the update ops so they can be passed to a [`tf.keras.backend.function`](https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/keras/backend/function) which can then be executed on demand to compute and apply the gradients. For more context please see [here](https://stackoverflow.com/questions/54856829/tensorflow-2-0-tf-keras-api-eager-mode-vs-graph-mode).\r\n\r\n**Code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.optimizers import Adam\r\nfrom tensorflow.keras.layers import Dense\r\n\r\nmy_model = Sequential([Dense(1, activation='relu', input_shape=(5,))])\r\nmy_loss = -tf.reduce_mean(my_model.output)\r\nmy_optim = Adam()\r\nupdates = my_optim.get_updates(params=my_model.trainable_weights, loss=my_loss)\r\n```\r\nEdit: this has also been noticed here: https://github.com/tensorflow/tensorflow/issues/25472", "comments": ["@alextp I removed [the check for eager mode](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/gradients_util.py#L557-L559) as you suggested but then it fails shortly after:\r\n\r\n```\r\nFile \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\", line 600, in <listcomp>\r\n    from_ops = [t.op for t in xs]\r\nFile \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 934, in op\r\n    \"Tensor.op is meaningless when eager execution is enabled.\")\r\n```\r\nRelevant links to GitHub code:\r\n[`from_ops = [t.op for t in xs]`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/gradients_util.py#L614)\r\n[`\"Tensor.op is meaningless when eager execution is enabled.\"`](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/ops.py#L934)\r\n\r\nAny ideas?\r\n", "Ah, so it's a little more complex than that. I think a better fix is done inside keras proper by entering the keras graph before keras calls tf.gradients, in get_updates. @robieta do you know what the best place to do this is?", "I made [a pull request](https://github.com/tensorflow/tensorflow/pull/26142) that seems to fix this issue but then the next line in my code (which works with TF<2) fails - it attempts to use the computed updates inside a `tf.keras.backend.function`. Both lines are shown below (the first one now works with the PR).\r\n```\r\nactor_updates = self.optimizer_actor.get_updates(params=self.actor.trainable_weights, loss=-tf.keras.backend.mean(critic_output))\r\nself.actor_train_on_batch = tf.keras.backend.function(inputs=[state_input], outputs=[self.actor(state_input)], updates=actor_updates)\r\n```\r\nThe stack trace:\r\n```\r\n  self.actor_train_on_batch = tf.keras.backend.function(inputs=[state_input], outputs=[self.actor(state_input)], updates=actor_updates)\r\nFile \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 3235, in function\r\n  return EagerExecutionFunction(inputs, outputs, updates=updates, name=name)\r\nFile \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 3156, in __init__\r\n  add_sources=True, handle_captures=True, base_graph=source_graph)\r\nFile \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\lift_to_graph.py\", line 222, in lift_to_graph\r\n  add_sources=add_sources))\r\nFile \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\lift_to_graph.py\", line 87, in _map_subgraph\r\n  elif op.type == \"Placeholder\":\r\nAttributeError: 'NoneType' object has no attribute 'type'\r\n```\r\nI'm not yet sure if this happens because the output of `get_updates` is bad or because of some other reason.", "Can you post the full stack trace? Something fishy seems to be going on here.\r\n\r\n@robieta I think you wrote the exception-raising code, so reassigning this issue to you.", "Here's the full stack trace:\r\n```\r\nTraceback (most recent call last):\r\n  File \"C:/projects/huskarl/examples/ddpg-pendulum.py\", line 37, in <module>\r\n    agent = hk.agent.DDPG(actor=actor, critic=critic, nsteps=2)\r\n  File \"C:\\projects\\huskarl\\huskarl\\agent\\ddpg.py\", line 56, in __init__\r\n    self.actor_train_on_batch = tf.keras.backend.function(inputs=[state_input], outputs=[self.actor(state_input)], updates=actor_updates)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 3235, in function\r\n    return EagerExecutionFunction(inputs, outputs, updates=updates, name=name)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\", line 3156, in __init__\r\n    add_sources=True, handle_captures=True, base_graph=source_graph)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\lift_to_graph.py\", line 222, in lift_to_graph\r\n    add_sources=add_sources))\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\lift_to_graph.py\", line 87, in _map_subgraph\r\n    elif op.type == \"Placeholder\":\r\nAttributeError: 'NoneType' object has no attribute 'type'\r\n```\r\nIf I print `actor_updates` this is what I get:\r\n```\r\n[<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=1>]\r\n```\r\nApparently the `tf.Variable` inside `actor_updates` has `op = None`.", "In general I would say the code block at the top is something of an anti-pattern, because it's sort of splitting the difference between keras / non-keras and graph / non-graph. I would offer the following two approaches as alternatives. (Depending on your preference.)\r\n\r\nBoilerplate:\r\n```\r\nimport numpy as np\r\nimport tensorflow as tf\r\ntf.enable_v2_behavior()\r\n\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.optimizers import Adam\r\nfrom tensorflow.keras.layers import Dense\r\n\r\ndef pretty_print_weights(model):\r\n  \"\"\"Ugly comprehension to make pretty strings.\"\"\"\r\n  print(\", \".join([\" \".join([\"{:.3f}\" for _ in w]).format(\r\n        *w.flatten().tolist()) for w in model.get_weights()]))\r\n```\r\n\r\nThe \"I want Keras to handle it for me\" way:\r\n```\r\nmy_model = Sequential([Dense(1, activation='relu', input_shape=(5,))])\r\nclass ReduceMeanLoss(tf.keras.losses.Loss):\r\n  def call(self, y_true, y_pred):\r\n    return -tf.reduce_mean(y_pred)\r\nmy_model.compile(loss=ReduceMeanLoss(), optimizer=Adam())\r\n```\r\n\r\nAnd an example train loop:\r\n```\r\npretty_print_weights(my_model)\r\n\r\n# I've chosen `.train_on_batch` just because it's closer to manually applying\r\n# gradients, but `.fit` works too.\r\nfor _ in range(100):\r\n  my_model.train_on_batch(\r\n      tf.random.uniform((16, 5)),\r\n      tf.zeros((16,))  # unused since the loss ignored y_true\r\n  )\r\npretty_print_weights(my_model)\r\n```\r\n` `\r\n` `\r\n` `\r\nThe \"I want to handle my own updates\" way:\r\n```\r\nmy_model = Sequential([Dense(1, activation='relu', input_shape=(5,))])\r\nmy_optim = Adam()\r\n\r\n@tf.function  # Decorating with tf.function will kick the function body into a\r\n              # Graph context.\r\ndef my_train_fn(inputs):\r\n  outputs = my_model(inputs)\r\n  print(outputs, \"   <=== This is a symbolic Tensor, and this print only runs during tracing.\")\r\n  my_loss = -tf.reduce_mean(outputs)\r\n  updates = my_optim.get_updates(params=my_model.trainable_weights, loss=my_loss)\r\n\r\n  # We take advantage of the automatic control dependencies of tf.function here,\r\n  # so updates still gets executed when we run the function.\r\n```\r\n\r\nAnd an analogous training loop looks like:\r\n```\r\npretty_print_weights(my_model)\r\nfor _ in range(100):\r\n  my_train_fn(tf.random.uniform((16, 5)))\r\npretty_print_weights(my_model)\r\n```\r\n\r\nFinally, I haven't covered it but it's possible to call the entire thing under a `tf.Graph` scope of your own in which case Keras will treat that as the default graph. (This, for instance, is how Estimator works.) So if you really want to manage your own graph that is an option as well. But it can be rather irksome to get back to eager land because the function that we use in keras is a private symbol. (ConcreteFunction: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/eager/function.py#L463) If there wind up being lots of people who want to make eager compatible functions out of their graphs it might make sense to reassess whether there should be a public way to do that.\r\n\r\nI realize that was something of a brain dump; let me know if you have any questions!", "@robieta thanks for the brain dump \ud83d\ude04. I've used that first method many times. But in this particular case I don't think either method works without significant modifications, if at all. To provide more context - I'm working on [a reinforcement learning library](https://github.com/danaugrs/huskarl) and am implementing several algorithms - this latest one being [DDPG](https://arxiv.org/abs/1509.02971). The idea is fairly simple - there are two networks - the actor (which takes in a state and outputs an action) and the critic (which takes a state and an action and outputs the value of that action). Training the critic is straightforward and I do it using `model.train_on_batch`.\r\n\r\n<img align=\"right\" height=300 src=https://user-images.githubusercontent.com/5261448/53881965-c79bf380-3ff3-11e9-88db-3479fedeacc3.png>\r\n\r\nTraining the actor, however, is more complicated. I need to connect the actor's action output to the critic's action input, then given a state (which is fed to both critic and actor) backpropagate `-mean(critic_output)` through the critic and then through the actor, and then only apply the updates to the actor network. See diagram \u27a1\ufe0f.\r\n\r\nI was able to implement that quite concisely in TF 1.* - full snippet below:\r\n\r\n``` python\r\n# To train the actor we want to change its weights such that it picks the action that has the highest possible value\r\nstate_input = self.critic.input[1]\r\ncritic_output = self.critic([self.actor(state_input), state_input])\r\nactor_updates = self.optimizer_actor.get_updates(params=self.actor.trainable_weights, loss=-tf.keras.backend.mean(critic_output))\r\nself.actor_train_on_batch = tf.keras.backend.function(inputs=[state_input], outputs=[self.actor(state_input)], updates=actor_updates)\r\n```\r\n\r\nThen the training routine becomes beautifully simple:\r\n\r\n``` python\r\nself.critic.train_on_batch([np.array(action_batch), np.array(state_batch)], target_qvals)\r\nself.actor_train_on_batch([np.array(state_batch)])\r\n```\r\n\r\nI think this usage of the `tf.keras` API is extremely useful.\r\n\r\n**Why doesn't this work anymore in TF 2.0? Is that intended (@fchollet)?**", "Ahh. Thanks for the explanation. So it looks like what is happening is that with https://github.com/tensorflow/tensorflow/pull/26142 the gradients are now being computed symbolically, but somewhere in the apply process we're applying them to the variables in an eager fashion.\r\n\r\nThe issue that you're seeing is that when you call `keras.backend.function`, it tries to lift the relevant subgraph from the keras global graph into an execution graph, but fails because the update is eager rather than graph. So a temporary fix would be:\r\n```\r\nmy_model = Sequential([Dense(1, activation='relu', input_shape=(5,))])\r\nmy_loss = -tf.reduce_mean(my_model.output)\r\nmy_optim = Adam()\r\n\r\n# This is a hack to force the entire update calculation to be computed\r\n# with the keras global graph to unblock in the short term.\r\nwith my_loss.graph.as_default():\r\n  updates = my_optim.get_updates(params=my_model.trainable_weights, loss=my_loss)\r\n\r\nmy_fn = tf.keras.backend.function(inputs=my_model.inputs, outputs=my_model.outputs, updates=updates)\r\npretty_print_weights(my_model)\r\n\r\nfor _ in range(100):\r\n  my_fn(tf.random.uniform((16,5)))\r\npretty_print_weights(my_model)\r\n```\r\n\r\nMore broadly, two improvement to TensorFlow spring to mind:\r\n1) The variable updates on symbolic inputs should probably also be symbolic. @alextp @tanzhenyu Does this make more sense to do in the optimizer or variable class?\r\n\r\n2) The graph lifting code should check if there are invalid inputs and should provide an appropriate error message. (I can handle that.)\r\n\r\nThanks for pointing out this issue!", "https://github.com/tensorflow/tensorflow/commit/46924b2f7bc4262b2c4b36841d393741113594ca should resolve this issue. (The optimizer classes will now check if any updates are symbolic and return a symbolic apply op if so.) That change should already have been picked up in the latest `tf-nightly` build. Feel free to reopen this issue if you encounter any issues.\r\n\r\n(2) is going to be covered as part of a broader effort to improve error messaging.\r\n\r\nHappy RL-ing!", "I finally tried removing the workaround using version `2.0.0-alpha0` but the problem is still there!\r\n\r\nWith workaround (works):\r\n```python\r\nmy_loss = -tf.keras.backend.mean(critic_output)\r\nwith my_loss.graph.as_default():\r\n    actor_updates = self.optimizer_actor.get_updates(params=self.actor.trainable_weights, loss=my_loss)\r\nself.actor_train_on_batch = tf.keras.backend.function(inputs=[state_input], outputs=[self.actor(state_input)], updates=actor_updates)\r\n```\r\n\r\nWithout workaround (fails, but used to work in TF1):\r\n```python\r\nmy_loss = -tf.keras.backend.mean(critic_output)\r\nactor_updates = self.optimizer_actor.get_updates(params=self.actor.trainable_weights, loss=my_loss)\r\nself.actor_train_on_batch = tf.keras.backend.function(inputs=[state_input], outputs=[self.actor(state_input)], updates=actor_updates)\r\n```\r\n[Context](https://github.com/danaugrs/huskarl/blob/01a1ecc9a705f4c55dd4d0b136171b7dab21b63b/huskarl/agent/ddpg.py#L67-L70).\r\n\r\nFull stack trace:\r\n```\r\nC:\\projects\\huskarl\\examples>python ddpg-pendulum.py\r\n2019-05-03 14:16:18.351214: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2\r\nTraceback (most recent call last):\r\n  File \"ddpg-pendulum.py\", line 37, in <module>\r\n    agent = hk.agent.DDPG(actor=actor, critic=critic, nsteps=2)\r\n  File \"c:\\projects\\huskarl\\huskarl\\agent\\ddpg.py\", line 48, in __init__\r\n    actor_updates = self.optimizer_actor.get_updates(params=self.actor.trainable_weights, loss=-tf.keras.backend.mean(critic_output))\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 448, in get_updates\r\n    grads = self.get_gradients(loss, params)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py\", line 361, in get_gradients\r\n    grads = gradients.gradients(loss, params)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_impl.py\", line 158, in gradients\r\n    unconnected_gradients)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gradients_util.py\", line 558, in _GradientsHelper\r\n    raise RuntimeError(\"tf.gradients is not supported when eager execution \"\r\nRuntimeError: tf.gradients is not supported when eager execution is enabled. Use tf.GradientTape instead.\r\n```\r\n\r\nMinimal code to reproduce the issue:\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Dense\r\nfrom tensorflow.keras.optimizers import Adam\r\n\r\nmy_model = Sequential([Dense(1, activation='relu', input_shape=(5,))])\r\nmy_loss = -tf.reduce_mean(my_model.output)\r\nmy_optim = Adam()\r\n\r\n# with my_loss.graph.as_default(): # <-- THIS IS THE WORKAROUND\r\nupdates = my_optim.get_updates(params=my_model.trainable_weights, loss=my_loss)\r\n\r\nmy_fn = tf.keras.backend.function(inputs=my_model.inputs, outputs=my_model.outputs, updates=updates)\r\n\r\nfor _ in range(100):\r\n  my_fn(tf.random.uniform((16,5)))\r\n```\r\n\r\nIt's the same original problem - seems like it was never fixed. Can you guys reopen and take a look?", "I just upgraded to `2.0.0-beta0` and was able to remove the workaround! Thanks!"]}, {"number": 26097, "title": "sorry, unimplemented: non-trivial designated initializers not supported", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n-  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04.5 LTS - docker images tensorflow/tensorflow:latest and tensorflow/devel\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: -\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: commit a2bb5db1bf7931b0dc2cd08e53b8798489568198\r\n- Python version: Python 2.7.12\r\n- Installed using virtualenv? pip? conda?: sources\r\n- Bazel version (if compiling from source): 0.19.2\r\n- GCC/Compiler version (if compiling from source): gcc (Ubuntu 5.4.0-6ubuntu1~16.04.11) 5.4.0 20160609\r\n- CUDA/cuDNN version: -\r\n- GPU model and memory: -\r\n\r\n\r\n\r\n**Describe the problem**\r\nSome of the tests don't compile because of the incorrect order of parameters and cause the following error: \r\n`sorry, unimplemented: non-trivial designated initializers not supported`\r\n\r\nProblem is caused by the order in designated initializer which is different from the order in struct.\r\n\r\nHow should be tensorflow tested so that this test passes? It even doesn't pass on official Google tensorflow images.\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nbazel test --config=opt --test_size_filters=small,medium -- tensorflow/lite/toco/tflite:operator_test\r\n\r\n**Any other info / logs**\r\n", "comments": ["@jianlijianli you've recently worked on this code. Is it tested on some internal Google compiler which behaves differently form gcc on official TF docker image?", "@herbakamil I am closing this as this is a duplicate of #26093. We will resolve in the other issue. Thanks!"]}, {"number": 26095, "title": "Warnings raised for deprecated collections.abc usage.", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No.\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): b'v1.13.0-rc1-0-g63c13ff' 1.13.0-rc1\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory: irrelevant\r\n\r\n**Describe the current behavior**\r\nTensorFlows raises warnings like:\r\n```\r\njumping/simulation/test/test_simulation.py::test_gpu_inference[Device.tensorflow]\r\n  /home/neil/.pyenv/versions/3.7.0/lib/python3.7/site-packages/tensorflow/python/util/nest.py:823: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n    _pywrap_tensorflow.RegisterType(\"Mapping\", _collections.Mapping)\r\n\r\njumping/simulation/test/test_simulation.py::test_gpu_inference[Device.tensorflow]\r\n  /home/neil/.pyenv/versions/3.7.0/lib/python3.7/site-packages/tensorflow/python/util/nest.py:824: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n    _pywrap_tensorflow.RegisterType(\"Sequence\", _collections.Sequence)\r\n\r\njumping/simulation/test/test_simulation.py::test_gpu_inference[Device.tensorflow]\r\n  /home/neil/.pyenv/versions/3.7.0/lib/python3.7/site-packages/tensorflow/python/training/checkpointable/util.py:448: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\r\n\r\n```\r\n**Describe the expected behavior**\r\nThese warnings should not be raised.\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n```\r\nimport warnings\r\nwarnings.simplefilter(\"error\")\r\nimport tensorflow\r\n```\r\n\r\n**Other info / logs**\r\nI can do this if the patch will be accepted.", "comments": ["@NeilGirdhar Could you try the solution provided [here](https://stackoverflow.com/questions/35911252/disable-tensorflow-debugging-information) to disable warnings, errors etc. If that was not solving, please provide a code to reproduce the issue. Thanks!", "@jvishnuvardhan The tensorflow log level is not related to the warnings I'm talking about, which are raised by Python.  The problem is that tensorflow needs to fix its imports.\r\nRight now, these are just warnings, but Python 3.8 will be released in October. If we want tensorflow to keep working, we will need to fix this anyway.", "For 1.13, the branch is closed unless we have security issues. But I am happy to accept this patch for master.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/26095\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/26095\">No</a>\n"]}, {"number": 26094, "title": "Cross-compilation from Windows 10 to Ubuntu 16.04", "body": "**System information**\r\n- TensorFlow version: TF r1.12.0 if possible\r\n- Doc Link: N/A\r\n\r\n\r\n**Describe the documentation issue**\r\nI can't find any official tutorial on how to cross-compile Tensorflow on the main platforms other than the less-than-descriptive official tutorial to cross-compile for the Pi. I'm not sure if this is more of a Doc issue than a Feature request but I was looking for any help compiling for Ubuntu 16.04 from a Windows 10 machine. Since there are quite a bunch of error-prone steps to cross-compiling, as there are many options to configure and files to write in a specific way, I would really benefit from some guidance, even if minimal. There are a few tutorials on Medium, but those dont't target the same platforms and/or are old.\r\n\r\nIs this something that could be added to Tensorflow's website ?\r\n\r\n**We welcome contributions by users. Will you be able to update submit a PR (use the [doc style guide](https://www.tensorflow.org/community/documentation)) to fix the doc Issue?**\r\nNo, unless I manage to do it myself.", "comments": ["Any update on the question ? Not sure what that status means", "Hi @mat100payette!\r\nWe are checking to see whether you still need help in this issue . Have you checked this thread for installation in Ubuntu ? [link1](https://www.tensorflow.org/install/pip#ubuntu),[link2](https://www.tensorflow.org/install/source).Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 26093, "title": "sorry, unimplemented: non-trivial designated initializers not supported", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n-  OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.1 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: commit a2bb5db1bf7931b0dc2cd08e53b8798489568198\r\n- Python version: 2.7.15rc1\r\n- Installed using virtualenv? pip? conda?: sources\r\n- Bazel version (if compiling from source): 0.20.0\r\n- GCC/Compiler version (if compiling from source): gcc (Ubuntu 7.3.0-27ubuntu1~18.04) 7.3.0\r\n- CUDA/cuDNN version: -\r\n- GPU model and memory: -\r\n\r\n\r\n\r\n**Describe the problem**\r\nDuring compilation I get an error: sorry, unimplemented: non-trivial designated initializers not supported.\r\nIt can be solved by setting all function pointers to null and applying initialization in order as in the struct defintion.\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nbazel test --verbose_failures tensorflow/lite/delegates/nnapi:nnapi_delegate\r\n\r\n**Any other info / logs**\r\nI attach diff which fixes this error for me.\r\n[diff.txt](https://github.com/tensorflow/tensorflow/files/2901455/diff.txt)\r\n\r\n\r\n", "comments": ["@jdduke do you use at Google some internal compilers which behave differently from gcc on officially provided TF Docker images? That would explain why it passes within Google CI and it fails on TF docker image.\r\nI ask you because you've relatively recently worked on this code.", "Our internal compiler version is different than that used in our Docker builds, yes. Feel free to propose a PR and I'd be happy to approve. Could you confirm which NDK version is used in the Docker builds?", "I think there's no NDK in the Tensorflow docker image"]}, {"number": 26092, "title": "tensorflow lite tests on x86", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.1 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: commit a2bb5db1bf7931b0dc2cd08e53b8798489568198\r\n- Python version: 2.7.15rc1\r\n- Installed using virtualenv? pip? conda?: sources\r\n- Bazel version (if compiling from source): 0.20.0\r\n- GCC/Compiler version (if compiling from source): gcc (Ubuntu 7.3.0-27ubuntu1~18.04) 7.3.0\r\n- CUDA/cuDNN version: -\r\n- GPU model and memory: -\r\n\r\n\r\n\r\n**Describe the problem**\r\nTensorflow lite tests seem to require android sdk even though we wanted to test them on x86.\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nbazel test --local_resources 40000,23,2 -- //tensorflow/lite/...\r\n**Any other info / logs**\r\nERROR: /home/tclbot/.cache/bazel/_bazel_tclbot/eee9defa2fa4c4fc557baa005719ebd9/external/bazel_tools/tools/android/BUILD:391:1: Executing genrule @bazel_tools//tools/android:no_android_sdk_repository_error faile\r\nd (Exit 1)                                                                                      \r\nThis build requires an Android SDK. Please add the android_sdk_repository rule to your WORKSPACE.\r\n", "comments": ["We probably need to mark a few targets with the \"manual\" tag to allow this kind of glob-based testing for x86.", "@jdduke do you have some suggestions what quick fix I can do so that I have working CI which can run tf lite tests? I've came to the command below which disables tests in tflite which don't work on the standard non-google environment (so that all tests pass) but bazel still fails because of the error mentioned above\r\n\r\nbazel test --test_tag_filters=-no_oss,-gpu,-benchmark-test --test_lang_filters=cc,java -k \\\r\n    --jobs=${N_JOBS} --test_timeout 300,450,1200,3600 --config=opt \\\r\n    --test_output=errors --test_size_filters=small,medium -- \\\r\n    //tensorflow/lite/... \\\r\n    -//tensorflow/lite/kernels/internal/... \\\r\n    -//tensorflow/lite/kernels:resize_bilinear_test \\\r\n    -//tensorflow/lite/kernels:resize_nearest_neighbor_test \\\r\n    -//tensorflow/lite/testing/...", "Does excluding //tensorflow/lite/java/... work?", "@jdduke It works. Thank you very much for your help :)\r\n\r\nIt's good that [documentation](https://www.tensorflow.org/install/source) has been updated because even quite recently it was claiming that tests should work properly without any exclusions.\r\n\r\nAnyway it's a bit annoying that the big open-source project doesn't have all tests running in the official docker image and when somebody wants to develop something there and wants to have CI running he needs to figure out which tests don't work (because in some cases fixing them would be very time consuming).", "Yeah, apologies for the pain. Part of the problem is that internally we use another set of files to provide build hints for certain directories, but these hints are only used in our internal, automated builds.", "Closing this issue since it's resolved. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/26092\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/26092\">No</a>\n"]}, {"number": 26091, "title": "Tensorflow 2.0 Preview - tf.function error when wrapping a function that works ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.2 LTS\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (use command below): tf-nightly-2.0-preview==2.0.0.dev20190225\r\n- Python version: 3.6.4\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\nThere seems to be some issue with `tf.function`. The decorator transformation of the function for some reason leads to a wrong behaviour in one of the reshape operations, but it is unclear why that happens. \r\n[Here is a colab demonstrating the issue.](https://drive.google.com/open?id=1Iwrke8yainVV8NHPICOkZSzzAM7BTGCu)\r\n\r\n**Describe the expected behavior**\r\nThe function should work in the same way as without the decorator, but it doesn't.\r\n\r\n**Code to reproduce the issue**\r\nThe colab linked cotains the same code as below:\r\n```\r\ndef expand_bias_to(bias, shape):\r\n    return tf.reshape(bias, [1] * (len(shape) - len(bias.shape)) + bias.shape.as_list())\r\n\r\n\r\ndef initialize(x_shape):\r\n    w1 = tf.random_normal_initializer()([x_shape[1], 1000])\r\n    b1 = tf.zeros_initializer()([1000])\r\n    w2 = tf.random_normal_initializer()([1000, x_shape[1]])\r\n    b2 = tf.random_normal_initializer()([x_shape[1]])\r\n    return (w1, b1), (), (w2, b2)\r\n\r\n\r\ndef autoencoder(params, x):\r\n    (w1, b1), (), (w2, b2) = params\r\n    b1 = expand_bias_to(b1, x.shape)\r\n    h1 = tf.matmul(x, w1) + b1\r\n    h2 = tf.tanh(h1)\r\n    b2 = expand_bias_to(b2, h2.shape)\r\n    h3 = tf.matmul(h2, w2) + b2\r\n    return h3\r\n\r\n\r\ndef prepare_mnist_features_and_labels(x, y):\r\n    x = tf.cast(x, tf.float32) / 255.0\r\n    y = tf.cast(y, tf.int64)\r\n    return tf.reshape(x, [-1]), y\r\n\r\n\r\ndef mnist_dataset():\r\n    (x, y), _ = tf.keras.datasets.mnist.load_data()\r\n    ds = tf.data.Dataset.from_tensor_slices((x, y))\r\n    ds = ds.map(prepare_mnist_features_and_labels)\r\n    ds = ds.take(20000).shuffle(20000).batch(100)\r\n    return ds\r\n\r\n\r\ndef train_one_step(model, variables, batch, step_size):\r\n    with tf.GradientTape() as tape:\r\n        tape.watch(variables)\r\n        f_eval = model(variables, batch)\r\n        loss = tf.reduce_mean((f_eval - batch) ** 2)\r\n    grads = tape.gradient(loss, variables)\r\n    return tuple(\r\n        tuple(vi - step_size * gi for vi, gi in zip(ps, gs))\r\n        for ps, gs in zip(variables, grads)\r\n    )\r\n\r\n\r\ndef main(batch_size=100,\r\n         num_epochs=100000,\r\n         step_size=1e-4):\r\n    params = initialize([batch_size, 784])\r\n    train_dataset = mnist_dataset()\r\n    partial_func = partial(train_one_step, model=autoencoder)\r\n    train_step = tf.function(partial_func)\r\n#     train_step = partial_func\r\n    \r\n    epoch = 0\r\n    for images, _ in train_dataset:\r\n        start_time = time.time()\r\n        for _ in range(100):\r\n            train_step(variables=params, batch=images, step_size=step_size)\r\n        epoch_time = time.time() - start_time\r\n        epoch += 1\r\n\r\n        print(\"Epoch {} in {:0.2f} sec\".format(epoch, epoch_time))\r\n\r\nmain()\r\n```\r\nThe error is:\r\n```\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-3-533661780a33> in <module>()\r\n     66         print(\"Epoch {} in {:0.2f} sec\".format(epoch, epoch_time))\r\n     67 \r\n---> 68 main()\r\n\r\n<ipython-input-3-533661780a33> in main(batch_size, num_epochs, step_size)\r\n     60         start_time = time.time()\r\n     61         for _ in range(100):\r\n---> 62             train_step(variables=params, batch=images, step_size=step_size)\r\n     63         epoch_time = time.time() - start_time\r\n     64         epoch += 1\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    440       canon_args, canon_kwds = self._canonicalize_function_inputs(args, kwds)\r\n    441       # If we did not create any variables the trace we have is good enough.\r\n--> 442       return self._concrete_stateful_fn._filtered_call(canon_args, canon_kwds)  # pylint: disable=protected-access\r\n    443 \r\n    444     def fn_with_cond(*inner_args, **inner_kwds):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _filtered_call(self, args, kwargs)\r\n    537     \"\"\"\r\n    538     return self._call_flat(\r\n--> 539         (t for t in nest.flatten((args, kwargs))\r\n    540          if isinstance(t, (ops.Tensor,\r\n    541                            resource_variable_ops.ResourceVariable))))\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _call_flat(self, args)\r\n    590     # Only need to override the gradient in graph mode and when we have outputs.\r\n    591     if context.executing_eagerly() or not self.outputs:\r\n--> 592       outputs = self._inference_function.call(ctx, args)\r\n    593     else:\r\n    594       self._register_gradient()\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in call(self, ctx, args)\r\n    380             attrs=(\"executor_type\", executor_type,\r\n    381                    \"config_proto\", config),\r\n--> 382             ctx=ctx)\r\n    383       # Replace empty list with None\r\n    384       outputs = outputs or None\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     64     else:\r\n     65       message = e.message\r\n---> 66     six.raise_from(core._status_to_exception(e.code, message), None)\r\n     67   except TypeError as e:\r\n     68     if any(ops._is_keras_symbolic_tensor(x) for x in inputs):\r\n\r\n/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)\r\n\r\nInvalidArgumentError: Input to reshape is a tensor with 78400 values, but the requested shape has 784\r\n\t [[{{node Reshape_1}}]] [Op:__inference_function_19842]\r\n```\r\n\r\nNote that if we comment out the line with `train_step = partial_func` everything works correctly.\r\n", "comments": ["Very interesting. So if I @tf.function decorate train_one_step it works, but if I decorate the result of functools.partial it doesn't.\r\n\r\nI'll keep investigating.", "Yeah, there is something wrong going on when using functools.partial. For instance, if define the partial_func explicitly it works as well:\r\n```\r\ndef partial_func(*args, **kwargs):\r\n      return train_one_step(*args, **kwargs, model=autoencoder)\r\n```\r\n", "@allenlavoie I remember we had issues with functools.partial and tf.function before; does anything ring a bell?", "Partial objects are their own special thing, so I'm not at all surprised there's yet another bug related to them. But no more specific ideas at a glance.", "@vbardiovskyg I've root-caused this to code you wrote to handle partial and keywords in tf.function", "I've submitted a fix (66a39e5c20e4ca358d2a910e8d6f17c5de9e22f1) for this one particular issue with partial.\r\n\r\nWhen reproducing the original issue, I got another failure when trying \r\n`partial_func = partial(train_one_step, model=autoencoder)`. The `tf_inspect.getfullargspec` doesn't like keyword arguments if they are not the last arguments as even defined in the [contract](https://github.com/tensorflow/tensorflow/blob/c46d383150564c8b72b05acc65182c16f7221694/tensorflow/python/util/tf_inspect.py#L175).\r\n\r\nThis can be alleviated by just calling \r\n`partial_func = partial(train_one_step, autoencoder)`, although this is not ideal.\r\n", "Vojtech, can you file an issue with a minimal unit test for\ntf_inspect.getfullargspec?\n\nOn Fri, Mar 8, 2019 at 4:00 PM Vojtech Bardiovsky <notifications@github.com>\nwrote:\n\n> I've submitted a fix (66a39e5\n> <https://github.com/tensorflow/tensorflow/commit/66a39e5c20e4ca358d2a910e8d6f17c5de9e22f1>)\n> for this one particular issue with partial.\n>\n> When reproducing the original issue, I got another failure when trying\n> partial_func = partial(train_one_step, model=autoencoder). The\n> tf_inspect.getfullargspec doesn't like keyword arguments if they are not\n> the last arguments as even defined in the contract\n> <https://github.com/tensorflow/tensorflow/blob/c46d383150564c8b72b05acc65182c16f7221694/tensorflow/python/util/tf_inspect.py#L175>\n> .\n>\n> This can be alleviated by just calling\n> partial_func = partial(train_one_step, autoencoder), although this is not\n> ideal.\n>\n> \u2014\n> You are receiving this because you were assigned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/26091#issuecomment-471118565>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AAATxU0hCYPNxHKud0gN6DWH4GOyQI-Jks5vUvmogaJpZM4bP-Aw>\n> .\n>\n\n\n-- \n - Alex\n", "Filed: https://github.com/tensorflow/tensorflow/issues/26602", "This works in Python3.", "tensorflow.python.framework.errors_impl.InvalidArgumentError: Input to reshape is a tensor with 76800 values, but the requested shape has 768....\r\nI've had similar problems, but I don't know how to solve them....", "@alextp Do you have tested if using `@tf_function` for a function that has internally `partial` it will go to trace also the function inside `partial`? Cause seems that it is not working. See https://github.com/tensorflow/addons/pull/1830#issuecomment-628284713", "@mdanatg have you seen this before?", "@alextp We are investigating at https://github.com/tensorflow/tensorflow/pull/39541", "Looks like a bug in map_fn, which doesn't apply autograph to its function. The partial part was a bit of a red herring."]}, {"number": 26090, "title": "Remove useless temporary variable in prefetch dataset", "body": "Remove useless temporary variable in PrefetchThread function.", "comments": ["Any update?? @gunan @rthadur"]}, {"number": 26089, "title": "Updated lstm_eval.cc", "body": "", "comments": []}, {"number": 26088, "title": "Fix typo op_hint.py", "body": "", "comments": ["Nagging Reviewer @aselle: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 14 days with no activity and the `awaiting review` label has been applied."]}, {"number": 26087, "title": "Changes within the base SSD mobilenet v1 structure", "body": "I have to import the ssd_mobilenetv1_coco_2018 pretrained model inside PyTorch so I have to manage the specific chosen architecture in the code. I noticed that the first layers of the classification/box prediction have less output than the others (12 instead of 24). \r\nIsn't it a standard implementation?\r\nDoes this involve directly the number of anchors that will be built?\r\n\r\nThanks\r\n", "comments": ["This is not Build/Installation or Bug/Performance issue. Please post this kind of support questions at [Stackoverflow](https://stackoverflow.com/questions/tagged/tensorflow). There is a big community to support and learn from your questions. GitHub is mainly for addressing bugs in installation and performance. Thanks!\r\n"]}, {"number": 26086, "title": "Updated eigen_support.cc", "body": "", "comments": []}, {"number": 26085, "title": "Ambiguous behaviour of tf.train.global_step", "body": "**System information**\r\n- OS Platform and Distribution: *Darwin - Mac OS X 10.14*\r\n- TensorFlow installed from (source or binary): *Source*\r\n- TensorFlow version (use command below): *v1.12.0-rc2-3-ga6d8ffae09 1.12.0*\r\n- Python version: *3.6.5*\r\n\r\n**Describe the current behavior**\r\n\r\nLet me illustrate the ambiguous behaviour of global step when using iterators and custom gradient operations. For the example, I will consider a toy problem, Input is a list of 10 digits filled with 1. Output is a list of 10 digits filled with 1-10. A variable is added to the input, so during the course of training, Variable mimics the operation and finally predicts a list of 10 digits filled with 1-10.\r\n\r\n**Assumption: (Pls correct if wrong)**\r\n1. Global step is created using `tf.train.get_or_create_global_step()` and is fed to global_step variable in optimizer\r\n2. Global step increments for every run of optimizer.\r\n3. Global step is fetched using `tf.train.get_global_step()` for display purpose.\r\n\r\n#### 1. Basic Optimization using Initializable iterators as Data Feed. (Expected)\r\n```python\r\nimport tensorflow as tf\r\n\r\ndef gen():\r\n    for i in range(10):\r\n        yield [1,1,1,1,1,1,1,1,1,1]\r\n\r\nitr = tf.data.Dataset.from_generator(generator=gen, output_types=tf.float32)\r\nini = itr.make_initializable_iterator()\r\n\r\npred = ini.get_next() +  tf.Variable(initial_value=tf.random_normal(shape=(1,10)), dtype=tf.float32)\r\nlabel = tf.constant([1,2,3,4,5,6,7,8,9,10], shape=(1,10), dtype=tf.float32)\r\nloss = tf.reduce_mean(tf.square(pred - label))\r\ntraining_op = tf.train.AdamOptimizer(learning_rate=0.1).minimize(loss=loss, global_step=tf.train.get_or_create_global_step())\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(tf.group([tf.global_variables_initializer(), tf.local_variables_initializer(), tf.tables_initializer()]))\r\n    for i in range(10):\r\n        sess.run(ini.initializer)\r\n        print('Global Step: ', sess.run(tf.train.get_global_step()))\r\n        try:\r\n            while True:\r\n                _,l, g = sess.run([training_op, loss, tf.train.get_or_create_global_step()])\r\n        except tf.errors.OutOfRangeError:\r\n            pass\r\n\"\"\"\r\nOutput - Expected:\r\nGlobal Step:  0\r\nGlobal Step:  10\r\nGlobal Step:  20\r\nGlobal Step:  30\r\nGlobal Step:  40\r\nGlobal Step:  50\r\nGlobal Step:  60\r\nGlobal Step:  70\r\nGlobal Step:  80\r\nGlobal Step:  90\r\n\"\"\"\r\n``` \r\n\r\n\r\n#### 2. Replace `Optimizer.minimize` with `Optimizer.compute_gradients` and `Optimizer.apply_gradients` with basic gradient manipulation. (Expected)\r\n```python\r\nimport tensorflow as tf\r\n\r\ndef gen():\r\n    for i in range(10):\r\n        yield [1,1,1,1,1,1,1,1,1,1]\r\n\r\nitr = tf.data.Dataset.from_generator(generator=gen, output_types=tf.float32)\r\nini = itr.make_initializable_iterator()\r\n\r\npred = ini.get_next() +  tf.Variable(initial_value=tf.random_normal(shape=(1,10)), dtype=tf.float32)\r\nlabel = tf.constant([1,2,3,4,5,6,7,8,9,10], shape=(1,10), dtype=tf.float32)\r\nloss = tf.reduce_mean(tf.square(pred - label))\r\nopt = tf.train.AdamOptimizer(learning_rate=0.1)\r\ncompute_op = opt.compute_gradients(loss=loss)\r\n# Manipulate existing gradients\r\nxyz = [(tf.nn.sigmoid(i[0]), i[1]) for i in compute_op]\r\ntraining_op = opt.apply_gradients(grads_and_vars=xyz, global_step=tf.train.get_or_create_global_step())\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(tf.group([tf.global_variables_initializer(), tf.local_variables_initializer(), tf.tables_initializer()]))\r\n    for i in range(10):\r\n        sess.run(ini.initializer)\r\n        print('Global Step: ', sess.run(tf.train.get_global_step()))\r\n        try:\r\n            while True:\r\n                _,l, g = sess.run([training_op, loss, tf.train.get_or_create_global_step()])\r\n        except tf.errors.OutOfRangeError:\r\n            pass\r\n\"\"\"\r\nOutput - Expected:\r\nGlobal Step:  0\r\nGlobal Step:  10\r\nGlobal Step:  20\r\nGlobal Step:  30\r\nGlobal Step:  40\r\nGlobal Step:  50\r\nGlobal Step:  60\r\nGlobal Step:  70\r\nGlobal Step:  80\r\nGlobal Step:  90\r\n\"\"\"\r\n```\r\n\r\n#### 3. Similar to Step 2, but instead of operating on the gradient tensor, Gradients are replaced with `tf.zeros()` (Ambiguous)\r\n```python\r\nimport tensorflow as tf\r\n\r\ndef gen():\r\n    for i in range(10):\r\n        yield [1,1,1,1,1,1,1,1,1,1]\r\n\r\nitr = tf.data.Dataset.from_generator(generator=gen, output_types=tf.float32)\r\nini = itr.make_initializable_iterator()\r\n\r\npred = ini.get_next() +  tf.Variable(initial_value=tf.random_normal(shape=(1,10)), dtype=tf.float32)\r\nlabel = tf.constant([1,2,3,4,5,6,7,8,9,10], shape=(1,10), dtype=tf.float32)\r\nloss = tf.reduce_mean(tf.square(pred - label))\r\nopt = tf.train.AdamOptimizer(learning_rate=0.1)\r\ncompute_op = opt.compute_gradients(loss=loss)\r\n# Replace Gradients\r\nxyz = [(tf.zeros(shape=i[0].shape.as_list()), i[1]) for i in compute_op]\r\ntraining_op = opt.apply_gradients(grads_and_vars=xyz, global_step=tf.train.get_or_create_global_step())\r\n\r\nwith tf.Session() as sess:\r\n    sess.run(tf.group([tf.global_variables_initializer(), tf.local_variables_initializer(), tf.tables_initializer()]))\r\n    for i in range(10):\r\n        sess.run(ini.initializer)\r\n        print('Global Step: ', sess.run(tf.train.get_global_step()))\r\n        try:\r\n            while True:\r\n                _,l, g = sess.run([training_op, loss, tf.train.get_or_create_global_step()])\r\n        except tf.errors.OutOfRangeError:\r\n            pass\r\n\"\"\"\r\nOutput - Ambiguous:\r\nGlobal Step:  0\r\nGlobal Step:  11\r\nGlobal Step:  22\r\nGlobal Step:  33\r\nGlobal Step:  44\r\nGlobal Step:  55\r\nGlobal Step:  66\r\nGlobal Step:  77\r\nGlobal Step:  88\r\nGlobal Step:  99\r\n\"\"\"\r\n```\r\n\r\n**Describe the expected behavior**\r\n#### Expected behaviour for step 3\r\n```python\r\n\"\"\"\r\nOutput - Expected:\r\nGlobal Step:  0\r\nGlobal Step:  10\r\nGlobal Step:  20\r\nGlobal Step:  30\r\nGlobal Step:  40\r\nGlobal Step:  50\r\nGlobal Step:  60\r\nGlobal Step:  70\r\nGlobal Step:  80\r\nGlobal Step:  90\r\n\"\"\"\r\n```\r\n\r\n1. Why / How does global_step gets an extra increment in Step 3?\r\n2. Is it a bad idea to replace gradient tensors with custom tensors (Probably custom tensors do not obey tf.GraphKeys.UpdateOps)?\r\n3. What is the right method to replace gradients and proposed validation?", "comments": ["The reason why you see the global step numbers out of sync is that there is no control dependency between the read of the variable in get_or_create_global_step and the increment to it in session.run. Because they are unordered tensorflow can either give you the old value or the new value; the tf2 implementastion of variables prefers to give you the value before update while the tf1 prefers to give you the value after.\r\n\r\nIf you want to know which value you're getting you should add control dependencies to decide what happens. Note that this is only an issue for the global step because it's invisibly created and invisibly modified; this API endpoint (get_or_create_global_step) has been removed in tf2 because of this type of issue.\r\n\r\nSo, short answer is that this is WAI."]}, {"number": 26084, "title": "libtensorflow.dll leaks icu symbols on Windows", "body": "**System information**\r\n- OS Platform and Distribution: Windows 10\r\n- TensorFlow installed from (source or binary): Self-compiled with bazel & from https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-windows-x86_64-1.12.0.zip\r\n- TensorFlow version: 1.12.0 & 1.13.0-rc2\r\n\r\n**Describe the problem**\r\n`libtensorflow.dll` exports a ton of symbols from icu. They should be private to the dll.\r\n\r\n**Any other info / logs**\r\n```\r\nC:\\Users\\mfischer\\Desktop>dumpbin /exports tensorflow-1.12.0.dll\r\nMicrosoft (R) COFF/PE Dumper Version 14.16.27027.1\r\nCopyright (C) Microsoft Corporation.  All rights reserved.\r\n\r\n\r\nDump of file tensorflow-1.12.0.dll\r\n\r\nFile Type: DLL\r\n\r\n  Section contains the following exports for libtensorflow.so\r\n\r\n    00000000 characteristics\r\n    5BDBAEF0 time date stamp Fri Nov  2 02:57:04 2018\r\n        0.00 version\r\n           1 ordinal base\r\n        3078 number of functions\r\n        3078 number of names\r\n\r\n    ordinal hint RVA      name\r\n\r\n          1    0 01841AA0 ??0?$MaybeStackArray@D$0CI@@icu_62@@AEAA@AEBV01@@Z\r\n          2    1 023BC120 ??0?$MaybeStackArray@D$0CI@@icu_62@@QEAA@$$QEAV01@@Z\r\n          3    2 023BC180 ??0?$MaybeStackArray@D$0CI@@icu_62@@QEAA@H@Z\r\n          4    3 023BC200 ??0?$MaybeStackArray@D$0CI@@icu_62@@QEAA@XZ\r\n          5    4 023C5F90 ??0Appendable@icu_62@@QEAA@AEBV01@@Z\r\n          6    5 023C5F90 ??0Appendable@icu_62@@QEAA@XZ\r\n          7    6 0245DC70 ??0BreakIterator@icu_62@@IEAA@AEBV01@@Z\r\n          8    7 0245DCD0 ??0BreakIterator@icu_62@@IEAA@AEBVLocale@1@0@Z\r\n          9    8 0245DD20 ??0BreakIterator@icu_62@@IEAA@XZ\r\n         10    9 02399020 ??0ByteSink@icu_62@@QEAA@XZ\r\n         11    A 02454B40 ??0BytesDictionaryMatcher@icu_62@@QEAA@AEBV01@@Z\r\n         12    B 02454B70 ??0BytesDictionaryMatcher@icu_62@@QEAA@PEBDHPEAUUDataMemory@@@Z\r\n         13    C 023CC750 ??0BytesTrie@icu_62@@AEAA@PEAXPEBX@Z\r\n         14    D 023CC770 ??0BytesTrie@icu_62@@QEAA@AEBV01@@Z\r\n         15    E 023CC7A0 ??0BytesTrie@icu_62@@QEAA@PEBX@Z\r\n         16    F 0245BA10 ??0BytesTrieBuilder@icu_62@@QEAA@AEAW4UErrorCode@@@Z\r\n         17   10 02458DB0 ??0CStr@icu_62@@QEAA@AEBVUnicodeString@1@@Z\r\n         18   11 023D3F10 ??0CacheKeyBase@icu_62@@QEAA@AEBV01@@Z\r\n         19   12 023D3F30 ??0CacheKeyBase@icu_62@@QEAA@XZ\r\n         20   13 02459A80 ??0CanonicalIterator@icu_62@@QEAA@AEBVUnicodeString@1@AEAW4UErrorCode@@@Z\r\n         21   14 02399030 ??0Char16Ptr@icu_62@@QEAA@$$T@Z\r\n         22   15 02399030 ??0Char16Ptr@icu_62@@QEAA@PEAG@Z\r\n         23   16 02399030 ??0Char16Ptr@icu_62@@QEAA@PEA_S@Z\r\n         24   17 02399030 ??0Char16Ptr@icu_62@@QEAA@PEA_W@Z\r\n         25   18 02459090 ??0CharString@icu_62@@QEAA@$$QEAV01@@Z\r\n         26   19 023BC220 ??0CharString@icu_62@@QEAA@AEBV01@AEAW4UErrorCode@@@Z\r\n         27   1A 023BC270 ??0CharString@icu_62@@QEAA@PEBDHAEAW4UErrorCode@@@Z\r\n         28   1B 023BC2C0 ??0CharString@icu_62@@QEAA@VStringPiece@1@AEAW4UErrorCode@@@Z\r\n         29   1C 023BC320 ??0CharString@icu_62@@QEAA@XZ\r\n         30   1D 02459730 ??0CharacterIterator@icu_62@@IEAA@AEBV01@@Z\r\n         31   1E 02459760 ??0CharacterIterator@icu_62@@IEAA@H@Z\r\n         32   1F 02459790 ??0CharacterIterator@icu_62@@IEAA@HH@Z\r\n...\r\n```\r\n", "comments": ["@mika-fischer Could you explain more details on the problem and its context? Thanks! ", "I'm not sure what to say. `libtensorflow.dll` exports symbols for applications to use. It should only export the `TF...` symbols. Instead it also exports all of the symbols of its internal(!) dependency libicu. This is almost certainly a mistake.\r\n\r\nThe status quo creates problems when trying to link `libtensorflow.dll` into an application that already uses libicu because then the icu symbols would be present twice.\r\n\r\nThe build process needs to be fixed to not export those symbols. Looking at http://userguide.icu-project.org/packaging#TOC-Link-to-ICU-statically all you have to do is most probably define the C preprocessor symbol: `U_STATIC_IMPLEMENTATION`...", "I think @hamatake did something to address this in 7e090f6a5412fd5f22b5b75ca7ae7844c3d025e9, but perhaps the fix didn't completely solve the problem?", "Actually 7e090f6 should fix this issue. But it definitely is not fixed in https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-windows-x86_64-1.13.1.zip\r\n\r\nAre there nightly master libtensorflow zips that I could check to see if it's fixed in master?", "I'm not sure if we publish nightlies for that build.\r\n\r\n@av8ramit I noticed that you made a change internally (209826891) that caches artifacts for a libtensorflow CPU build on Windows, but do you know if these are published anywhere?", "Well, it's easy enough to check: `dumpbin /exports tensorflow.dll` will print all exported symbols.", "@mrry that was for the release packages unfortunately.", "Unfortunately that change was rolled back because it didn't actually fix\nthe build in question. This dropped off my radar for awhile but it's back\non. I've reproduced the link failure on a windows machine and am working on\na fix.\n\nOn Fri, Mar 1, 2019 at 3:35 PM Amit Patankar <notifications@github.com>\nwrote:\n\n> @mrry <https://github.com/mrry> that was for the release packages\n> unfortunately.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/26084#issuecomment-468847701>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AEnCCPY-80fZC5C1w7tZqQ9VGBOr6DApks5vSbkjgaJpZM4bPnbn>\n> .\n>\n", "This should be fixed by https://github.com/tensorflow/tensorflow/commit/025aa34d77b0ba1c9035cfa7b3c7f98bcccb1435", "Thanks @hamatake!"]}, {"number": 26083, "title": "tensorflow lite : Convertion from keras works fine but execution on device fails : ByteBuffer is not a valid flatbuffer model", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colaboratory / Android \r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Oneplus 6, Samsung Galaxy s8, ...\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): b'v1.13.0-rc1-2-gb6141b06f5' 1.13.0-rc1 (but also present in 1.12.0)\r\n- Firebase ML-Interpreter Version : 16.2.4\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: -\r\n- GPU model and memory: - \r\n\r\n**Describe the current behavior**\r\nWe want to convert a keras model to a tflite model. Some architectures won't convert (ex: Reshape Layer followed by a BatchNorm layer), but some seem to be able to be converted, but when used on device the error \"Caused by: java.lang.IllegalArgumentException: ByteBuffer is not a valid flatbuffer model\" happens. Here is a simple model description demonstrating this issue :\r\n\r\n**Describe the expected behavior**\r\nIf no errors are encountered when converting to tflite model, we should be able to run them with firebase model interpreter\r\n\r\n**Code to reproduce the issue**\r\n\r\nOn google Colaboratory create the model : \r\n\r\n```\r\n\r\nfrom tensorflow.keras import Model\r\nfrom tensorflow.keras.optimizers import Adam\r\nfrom tensorflow.keras.losses import mse, categorical_crossentropy\r\n\r\nstate = Input((884,))\r\nmask = Input((260,))\r\n\r\nbn = BatchNormalization()(state)\r\nrs1 = Reshape((52, 17))(bn)\r\nlstm1= LSTM((256, unroll=True))(rs1)\r\n\r\npolicy_raw = Dense(260, activation=sigmoid)(lstm1)\r\npolicy_masked = Multiply()([mask, policy_raw])\r\noutput_policy = Activation(activation=softmax)(policy_masked)\r\n\r\noutput_value = Dense(1)(state)\r\n\r\nmodel = Model([state, mask], [output_policy, output_value])\r\nmodel.compile(optimizer=Adam(), loss=[categorical_crossentropy, mse])\r\n\r\nmodel.save(\"keras_model.keras\")\r\n\r\n```\r\n\r\nConvert the model : \r\n\r\n\r\n```\r\nfrom tensorflow.lite.python.lite import TFLiteConverter\r\n\r\npath = \"keras_model.keras\"\r\n\r\nconverter = TFLiteConverter.from_keras_model_file(path)\r\n\r\ntflite_model = converter.convert()\r\n\r\nopen(path + \".tflite\", \"wb\").write(tflite_model)\r\n\r\n```\r\n\r\nThen download the tflite model : \r\n\r\n```\r\nfrom google.colab import files\r\n\r\nfiles.download(path +'.tflite')\r\n\r\n```\r\n\r\nThen try to use the model on Android with tflite through Firebase ML Interpreter : \r\n\r\n\r\n```\r\nFirebaseModelInputOutputOptions dataOptions = new FirebaseModelInputOutputOptions.Builder()\r\n                .setInputFormat(0, FLOAT32, new int[]{1, 884})\r\n                .setInputFormat(1, FLOAT32, new int[]{1, 260})\r\n                .setOutputFormat(0, FLOAT32, new int[]{1, 260})\r\n                .setOutputFormat(1, FLOAT32, new int[]{1, 1})\r\n                .build();\r\n\r\nfinal FirebaseLocalModelSource modelSource = new FirebaseLocalModelSource.Builder(\"asset\")\r\n                .setAssetFilePath(\"keras_model.tflite\").build();\r\n\r\nFirebaseModelManager.getInstance().registerLocalModelSource(modelSource);\r\n\r\n        final FirebaseModelOptions options = new FirebaseModelOptions.Builder()\r\n                .setLocalModelName(\"asset\")\r\n                .build();\r\n\r\nFirebaseModelInterpreter interpreter = FirebaseModelInterpreter.getInstance(options);\r\n\r\nfinal FirebaseModelInputs inputs = new FirebaseModelInputs.Builder()\r\n                .add(new float[][]{new float[884]})\r\n                .add(new float[][]{new float[260]})\r\n                .build();\r\n\r\ninterpreter.run(inputs, dataOptions)\r\n                .continueWith(new Continuation<FirebaseModelOutputs, Object>() {\r\n                    @Override\r\n                    public Object then(@NonNull final Task<FirebaseModelOutputs> task) {\r\n                        try {\r\n                            task.getResult();\r\n                        } catch (final Throwable e) {\r\n                            Log.e(\"TFLITE\", e.getMessage(), e);\r\n                        } finally {\r\n                        }\r\n\r\n                        return null;\r\n                    }\r\n                });\r\n```\r\n\r\nYou can find a converted model here : \r\n[keras_model.zip](https://github.com/tensorflow/tensorflow/files/2899987/keras_model.zip)\r\n\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nError log : \r\n\r\n```\r\ncom.google.firebase.ml.common.FirebaseMLException: The load task failed\r\n    com.google.android.gms.tasks.RuntimeExecutionException: com.google.firebase.ml.common.FirebaseMLException: The load task failed\r\n        at com.google.android.gms.tasks.zzu.getResult(Unknown Source:15)\r\n        at com.iscoolentertainment.unity.tflite.UnityTFLiteRunner$1.then(UnityTFLiteRunner.java:92)\r\n        at com.google.android.gms.tasks.zzd.run(Unknown Source:5)\r\n        at android.os.Handler.handleCallback(Handler.java:873)\r\n        at android.os.Handler.dispatchMessage(Handler.java:99)\r\n        at android.os.Looper.loop(Looper.java:193)\r\n        at android.app.ActivityThread.main(ActivityThread.java:6863)\r\n        at java.lang.reflect.Method.invoke(Native Method)\r\n        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:537)\r\n        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:858)\r\n     Caused by: com.google.firebase.ml.common.FirebaseMLException: The load task failed\r\n        at com.google.android.gms.internal.firebase_ml.zzio.zzf(Unknown Source:65)\r\n        at com.google.android.gms.internal.firebase_ml.zzij.call(Unknown Source:2)\r\n        at com.google.android.gms.internal.firebase_ml.zzie.zza(Unknown Source:29)\r\n        at com.google.android.gms.internal.firebase_ml.zzif.run(Unknown Source:2)\r\n        at android.os.Handler.handleCallback(Handler.java:873)\r\n        at android.os.Handler.dispatchMessage(Handler.java:99)\r\n        at com.google.android.gms.internal.firebase_ml.zze.dispatchMessage(Unknown Source:5)\r\n        at android.os.Looper.loop(Looper.java:193)\r\n        at android.os.HandlerThread.run(HandlerThread.java:65)\r\n     Caused by: com.google.firebase.ml.common.FirebaseMLException: Local model load failed: \r\n        at com.google.android.gms.internal.firebase_ml.zzje.zza(Unknown Source:127)\r\n        at com.google.android.gms.internal.firebase_ml.zzje.zzgd(Unknown Source:102)\r\n        at com.google.android.gms.internal.firebase_ml.zziq.zzgg(Unknown Source:7)\r\n        at com.google.android.gms.internal.firebase_ml.zziq.call(Unknown Source:23)\r\n        at com.google.android.gms.internal.firebase_ml.zzie.zza(Unknown Source:29)\u00a0\r\n        at com.google.android.gms.internal.firebase_ml.zzif.run(Unknown Source:2)\u00a0\r\n        at android.os.Handler.handleCallback(Handler.java:873)\u00a0\r\n        at android.os.Handler.dispatchMessage(Handler.java:99)\u00a0\r\n        at com.google.android.gms.internal.firebase_ml.zze.dispatchMessage(Unknown Source:5)\u00a0\r\n        at android.os.Looper.loop(Looper.java:193)\u00a0\r\n        at android.os.HandlerThread.run(HandlerThread.java:65)\u00a0\r\n     Caused by: java.lang.IllegalArgumentException: ByteBuffer is not a valid flatbuffer model\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.createModelWithBuffer(Native Method)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:74)\r\n        at org.tensorflow.lite.NativeInterpreterWrapper.<init>(NativeInterpreterWrapper.java:54)\r\n        at org.tensorflow.lite.Interpreter.<init>(Interpreter.java:114)\r\n        at com.google.android.gms.internal.firebase_ml.zzje.zzb(Unknown Source:222)\r\n        at com.google.android.gms.internal.firebase_ml.zzjf.zzc(Unknown Source:0)\r\n        at com.google.android.gms.internal.firebase_ml.zzje.zzb(Unknown Source:148)\r\n        at com.google.android.gms.internal.firebase_ml.zzje.zza(Unknown Source:116)\r\n        at com.google.android.gms.internal.firebase_ml.zzje.zzgd(Unknown Source:102)\u00a0\r\n        at com.google.android.gms.internal.firebase_ml.zziq.zzgg(Unknown Source:7)\u00a0\r\n        at com.google.android.gms.internal.firebase_ml.zziq.call(Unknown Source:23)\u00a0\r\n        at com.google.android.gms.internal.firebase_ml.zzie.zza(Unknown Source:29)\u00a0\r\n        at com.google.android.gms.internal.firebase_ml.zzif.run(Unknown Source:2)\u00a0\r\n        at android.os.Handler.handleCallback(Handler.java:873)\u00a0\r\n        at android.os.Handler.dispatchMessage(Handler.java:99)\u00a0\r\n        at com.google.android.gms.internal.firebase_ml.zze.dispatchMessage(Unknown Source:5)\u00a0\r\n        at android.os.Looper.loop(Looper.java:193)\u00a0\r\n        at android.os.HandlerThread.run(HandlerThread.java:65)\u00a0\r\n```\r\n\r\nFor information, if we use the model on Google collaboratory, it works fine : \r\n\r\n```\r\n\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n# Load TFLite model and allocate tensors.\r\ninterpreter = tf.lite.Interpreter(model_path=\"keras_model.tflite\")\r\ninterpreter.allocate_tensors()\r\n\r\n# Get input and output tensors.\r\ninput_details = interpreter.get_input_details()\r\noutput_details = interpreter.get_output_details()\r\n\r\n# Test model on random input data.\r\ninput_shape = input_details[0]['shape']\r\ninput_shape_2 = input_details[1]['shape']\r\ninput_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\r\ninterpreter.set_tensor(input_details[0]['index'], input_data)\r\ninput_data = np.array(np.random.random_sample(input_shape_2), dtype=np.float32)\r\ninterpreter.set_tensor(input_details[1]['index'], input_data)\r\n\r\ninterpreter.invoke()\r\noutput_data = interpreter.get_tensor(output_details[0]['index'])\r\nprint(output_data)\r\noutput_data = interpreter.get_tensor(output_details[1]['index'])\r\nprint(output_data)\r\n\r\n```\r\n\r\n", "comments": ["If we use Firebase ML Model Interpreter 17.0.3 instead of 16.2.4, the error message is gone and I can execute the model, but, the tflite output results are inconsistent to the keras or protobuf frozen graph ones.\r\n\r\nHere is (in attachment) a slightly different architecture, with the 3 versions (keras, frozen_graph and tflite), the keras and the frozen graph versions are consistent, but not the tflite one, no error messages or warnings are issued during conversion nor execution.\r\n\r\nThank you in advance for your insights.\r\n[conversion_issues.zip](https://github.com/tensorflow/tensorflow/files/2900907/conversion_issues.zip)\r\n\r\n", "> ByteBuffer is not a valid flatbuffer model\" happens\r\n\r\nThe first thing to check is to make sure the .tflite model in your APK is not being compressed.  In gradle, this would be specified as:\r\n```\r\naaptOptions {\r\n        noCompress \"tflite\"\r\n}\r\n```", "> > ByteBuffer is not a valid flatbuffer model\" happens\r\n> \r\n> The first thing to check is to make sure the .tflite model in your APK is not being compressed. In gradle, this would be specified as:\r\n> \r\n> ```\r\n> aaptOptions {\r\n>         noCompress \"tflite\"\r\n> }\r\n> ```\r\n\r\nI confirm this was correctly specified and the issue still happened.\r\nThe combination Batchnorm, Reshape, LSTM seems to be the culprit here as other model architectures work fine.\r\n\r\nThank you for your answer.", "Just curious, have you tried running this model directly against the Android TFLite SDK? Trying to rule out whether this is perhaps a versioning issues between MLKit and TFLite.", "It has been 44 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 26082, "title": "TensorForestEstimator throws ValueError due to bad feature column handling", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n\r\nBug was discovered when writing a custom script that used `TensorForestEstimator`.  Code is provided below.\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): \r\n```\r\nLinux sandbox 4.15.0-45-generic #48-Ubuntu SMP Tue Jan 29 16:28:13 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux\r\nVERSION=\"18.04.2 LTS (Bionic Beaver)\"\r\nVERSION_ID=\"18.04\"\r\nVERSION_CODENAME=bionic\r\n```\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n\r\nnot applicable\r\n\r\n- TensorFlow installed from (source or binary):\r\n\r\nTensorFlow binary installed from PyPi via `pip`.\r\n\r\n- TensorFlow version (use command below):\r\n\r\n```\r\ntf.VERSION = 1.12.0\r\ntf.GIT_VERSION = v1.12.0-0-ga6d8ffae09\r\ntf.COMPILER_VERSION = v1.12.0-0-ga6d8ffae09\r\nSanity check: array([1], dtype=int32)\r\n```\r\n\r\n- Python version:\r\n\r\nPython 3.6.8\r\n\r\n- Bazel version (if compiling from source):\r\n\r\nnot applicable\r\n\r\n- GCC/Compiler version (if compiling from source):\r\n\r\nSince Python was compiled from source via `pyenv install`, including compiler version:\r\n\r\n```\r\nc++ (Ubuntu 7.3.0-27ubuntu1~18.04) 7.3.0\r\n```\r\n\r\n- CUDA/cuDNN version:\r\n\r\nnot applicable\r\n\r\n- GPU model and memory:\r\n\r\nnot applicable\r\n\r\n- Other information\r\n\r\n```\r\n== are we in docker =============================================\r\nNo\r\n```\r\n\r\nPython environment is managed with `pyenv` version. 1.2.9, with the following packages installed:\r\n\r\n```\r\nabsl-py==0.7.0\r\nasn1crypto==0.24.0\r\nastor==0.7.1\r\nawscli==1.16.109\r\nazure-common==1.1.18\r\nazure-storage-blob==1.5.0\r\nazure-storage-common==1.4.0\r\nbackcall==0.1.0\r\nbleach==3.1.0\r\nboto3==1.9.99\r\nbotocore==1.12.99\r\ncertifi==2018.11.29\r\ncffi==1.12.1\r\nchardet==3.0.4\r\ncolorama==0.3.9\r\ncryptography==2.5\r\ncycler==0.10.0\r\ndecorator==4.3.2\r\ndefusedxml==0.5.0\r\ndocutils==0.14\r\nentrypoints==0.3\r\nfuture==0.17.1\r\ngast==0.2.2\r\ngrpcio==1.18.0\r\nh5py==2.9.0\r\nidna==2.8\r\nijson==2.3\r\nipykernel==5.1.0\r\nipython==7.3.0\r\nipython-genutils==0.2.0\r\njedi==0.13.2\r\nJinja2==2.10\r\njmespath==0.9.3\r\njsonschema==2.6.0\r\njupyter-client==5.2.4\r\njupyter-core==4.4.0\r\njupyterlab==0.35.4\r\njupyterlab-server==0.2.0\r\nKeras-Applications==1.0.7\r\nKeras-Preprocessing==1.0.9\r\nkiwisolver==1.0.1\r\nMarkdown==3.0.1\r\nMarkupSafe==1.1.0\r\nmatplotlib==3.0.2\r\nmistune==0.8.4\r\nmpmath==1.1.0\r\nnbconvert==5.4.1\r\nnbformat==4.4.0\r\nnotebook==5.7.4\r\nnumpy==1.16.1\r\npandas==0.24.1\r\npandocfilters==1.4.2\r\nparso==0.3.4\r\npexpect==4.6.0\r\npickleshare==0.7.5\r\nprometheus-client==0.6.0\r\nprompt-toolkit==2.0.9\r\nprotobuf==3.6.1\r\nptyprocess==0.6.0\r\npyasn1==0.4.5\r\npycparser==2.19\r\npycryptodomex==3.7.3\r\nPygments==2.3.1\r\nPyJWT==1.7.1\r\npyOpenSSL==19.0.0\r\npyparsing==2.3.1\r\npython-dateutil==2.8.0\r\npytz==2018.9\r\nPyYAML==3.13\r\npyzmq==18.0.0\r\nrequests==2.21.0\r\nrsa==3.4.2\r\ns3transfer==0.2.0\r\nscikit-learn==0.20.2\r\nscipy==1.2.1\r\nSend2Trash==1.5.0\r\nsix==1.12.0\r\nsnowflake-connector-python==1.7.6\r\nsympy==1.3\r\ntensorboard==1.12.2\r\ntensorflow==1.12.0\r\ntermcolor==1.1.0\r\nterminado==0.8.1\r\ntestpath==0.4.2\r\ntornado==5.1.1\r\ntraitlets==4.3.2\r\nurllib3==1.24.1\r\nwcwidth==0.1.7\r\nwebencodings==0.5.1\r\nWerkzeug==0.14.1\r\n```\r\n\r\n**Describe the current behavior**\r\n\r\nWhen `feature_columns` argument is specified, `TensorForestEstimator` will throw the following error during a `fit()`:\r\n\r\n```\r\nTypeError: '<' not supported between instances of '_RealValuedColumn' and 'str'\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nExpected behavior was that model would be built from training operation.\r\n\r\n\r\n**Code to reproduce the issue**\r\n\r\nNote that the CSV file 'Immunotherapy - ImmunoDataset.csv' can be obtained from the UC Irvine Machine Learning Repository at this URL:\r\n\r\nhttps://archive.ics.uci.edu/ml/datasets/Immunotherapy+Dataset\r\n# Sample Code for `TensorForestEstimator` with `pandas_input_fn`\r\n\r\n## Python Standard Library Imports\r\n\r\n\r\n```python\r\nimport csv\r\nimport random\r\n```\r\n\r\n## Non TensorFlow Imports\r\n\r\n\r\n```python\r\nimport numpy as np\r\nimport pandas as pd\r\n```\r\n\r\n## TensorFlow Library Imports\r\n\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.layers as layers\r\nimport tensorflow.contrib.tensor_forest as tforest\r\n```\r\n\r\n## Aliased TensorFlow Library Imports\r\n\r\n\r\n```python\r\nfrom tensorflow.estimator.inputs import pandas_input_fn\r\nfrom tensorflow.python.platform import tf_logging as logging\r\n```\r\n\r\n\r\n```python\r\ntf.logging.set_verbosity(tf.logging.DEBUG)\r\n```\r\n\r\n## Metadata for CSV Columns\r\n\r\n\r\n```python\r\nCOLUMN_PROPS = {\r\n    'sex' : {\r\n        'is_feature' : True,\r\n        'is_label' : False,\r\n        'dtype' : tf.int32,\r\n        'default' : -1,\r\n        'feature_column' : layers.real_valued_column(\r\n            'sex',\r\n            dtype=tf.int32\r\n        )\r\n    },\r\n    'age' : {\r\n        'is_feature' : True,\r\n        'is_label' : False,\r\n        'dtype' : tf.int32,\r\n        'default' : -1,\r\n        'feature_column' : layers.real_valued_column(\r\n            'age',\r\n            dtype=tf.int32\r\n        )  \r\n    },\r\n    'Time' : {\r\n        'is_feature' : True,\r\n        'is_label' : False,\r\n        'dtype' : tf.float32,\r\n        'default' : -1.0,\r\n        'feature_column' : layers.real_valued_column(\r\n            'Time',\r\n            dtype=tf.float32\r\n        )\r\n    },\r\n    'Number_of_Warts' : {\r\n        'is_feature' : True,\r\n        'is_label' : False,\r\n        'dtype' : tf.int32,\r\n        'default' : -1,\r\n        'feature_column' : layers.real_valued_column(\r\n            'Number_of_Warts',\r\n            dtype=tf.int32\r\n        ),\r\n    },\r\n    'Type' : {\r\n        'is_feature' : True,\r\n        'is_label' : False,\r\n        'dtype' : tf.int32,\r\n        'default' : -1,\r\n        'feature_column' : layers.real_valued_column(\r\n            'Type',\r\n            dtype=tf.int32\r\n        )\r\n    },\r\n    'Area' : {\r\n        'is_feature' : True,\r\n        'is_label' : False,\r\n        'dtype' : tf.int32,\r\n        'default' : -1,\r\n        'feature_column' : layers.real_valued_column(\r\n            'Area',\r\n            dtype=tf.int32\r\n        )\r\n    },\r\n    'induration_diameter' : {\r\n        'is_feature' : True,\r\n        'is_label' : False,\r\n        'dtype': tf.int32,\r\n        'default': -1,\r\n        'feature_column' : layers.real_valued_column(\r\n            'induration_diameter',\r\n            dtype=tf.int32\r\n        )\r\n    },\r\n    'Result_of_Treatment': {\r\n        'is_feature' : False,\r\n        'is_label' : True,\r\n        'dtype': tf.int32,\r\n        'default': -1,\r\n        'feature_column' : None\r\n    }\r\n}\r\n```\r\n\r\n## Ordering of CSV Columns\r\n\r\n\r\n```python\r\nCSV_COLUMNS = [\r\n    'sex',\r\n    'age',\r\n    'Time',\r\n    'Number_of_Warts',\r\n    'Type',\r\n    'Area',\r\n    'induration_diameter',\r\n    'Result_of_Treatment'\r\n]\r\n```\r\n\r\n## Generate Lists of Features and Labels from Metadata\r\n\r\n\r\n```python\r\nFEATURE_COLUMNS = []\r\nLABEL_COLUMN = None\r\n\r\nfor k in CSV_COLUMNS:\r\n    if COLUMN_PROPS[k]['is_feature']:\r\n        FEATURE_COLUMNS.append(k)\r\n    elif COLUMN_PROPS[k]['is_label']:\r\n        LABEL_COLUMN = k\r\n```\r\n\r\n## Helper Function for Shuffling and Exporting Subsets\r\n\r\nThis function is used to export training, evaluation, and test data sets as CSVs, shuffling the rows.\r\n\r\n\r\n```python\r\ndef generate_sets(datasets):\r\n    for k, v in datasets.items():\r\n        random.shuffle(v)\r\n        with open(k + '.csv', 'w') as fobj:\r\n            wrtr = csv.writer(fobj)\r\n            wrtr.writerow(header)\r\n            for rec in v:\r\n                wrtr.writerow(rec)\r\n```\r\n\r\n## Split Datasets for Traning, Evaluation, and Testing\r\n\r\n\r\n```python\r\ntrn = []\r\nevl = []\r\ntst = []\r\n\r\nwith open('Immunotherapy - ImmunoDataset.csv', 'r') as fobj:\r\n    rdr = csv.reader(fobj)\r\n    header = next(rdr)\r\n    label_key = header[-1]\r\n    feature_keys = header[:-1]\r\n\r\n    for rec in rdr:\r\n        # Output of random number generator determines\r\n        # which set the record will be placed.\r\n        rn =  random.random()\r\n        if rn < 0.6:\r\n            trn.append(rec)\r\n        elif rn < 0.8:\r\n            evl.append(rec)\r\n        else:\r\n            tst.append(rec)\r\n\r\ndatasets = {\r\n    'train' : trn,\r\n    'eval' : evl,\r\n    'test' : tst\r\n}\r\n\r\ngenerate_sets(datasets)\r\n```\r\n\r\n## Set up `TensorForest` Hyperparameters\r\n\r\n\r\n```python\r\nfhp = tforest.tensor_forest.ForestHParams(\r\n    num_classes=2,\r\n    num_features=7,\r\n    regression=False\r\n)\r\n```\r\n\r\n## Pluck Feature Columns from Metadata Dictionary\r\n\r\n\r\n```python\r\nfcs = [COLUMN_PROPS[k]['feature_column'] for k in FEATURE_COLUMNS]\r\n```\r\n\r\n## Instatntiate `TensorForestEstimator` Object\r\n\r\n\r\n```python\r\ntfe = tforest.random_forest.TensorForestEstimator(\r\n    fhp,\r\n    feature_columns=fcs,\r\n    report_feature_importances=True\r\n)\r\n```\r\n\r\n## Define a Wrapper for Training and Evaluation Using `pandas_input_fn`\r\n\r\n\r\n```python\r\ndef get_input_fn(csv_file, num_epochs=1):\r\n    \r\n    df = pd.read_csv(csv_file)\r\n\r\n    # Workaround for this issue:\r\n    #\r\n    # https://stackoverflow.com/questions/48577372/tensorflowusing-pandas-input-fn-with-tensorforestestimator\r\n    # https://github.com/tensorflow/tensorflow/issues/16692        \r\n\r\n    def internal_input_fn():\r\n\r\n        features = df.loc[:,'sex':'induration_diameter']\r\n        labels =  df.loc[:,'Result_of_Treatment']\r\n        \r\n        features, labels = pandas_input_fn(\r\n            x=features,\r\n            y=labels,\r\n            shuffle=True,\r\n            num_epochs=num_epochs\r\n        )()\r\n\r\n        features = {\r\n            k : tf.expand_dims(features[k], axis=1) \r\n            for k in features\r\n        }\r\n        \r\n        labels = tf.expand_dims(labels, axis=1)\r\n      \r\n        return features, labels\r\n    \r\n    return internal_input_fn\r\n```\r\n\r\n## Train on Data\r\n\r\n\r\n```python\r\ntfe.fit(\r\n    input_fn=get_input_fn('train.csv', num_epochs=None)\r\n)\r\n```\r\n\r\n## Evaluate the Model\r\n\r\n\r\n```python\r\ntfe.evaluate(input_fn=get_input_fn('eval.csv'))\r\n```\r\n\r\n## Define a Wrapper for Prediction\r\n\r\n\r\n```python\r\ndef get_predict_input_fn(csv_file):\r\n    \r\n    df = pd.read_csv(csv_file)\r\n    \r\n    print('actual values: {0}'.format(df.loc[:, 'Result_of_Treatment'].values))\r\n\r\n    # Workaround for this issue:\r\n    #\r\n    # https://stackoverflow.com/questions/48577372/tensorflowusing-pandas-input-fn-with-tensorforestestimator\r\n    # https://github.com/tensorflow/tensorflow/issues/16692        \r\n\r\n    def internal_input_fn():\r\n\r\n        features = df.loc[:,'sex':'induration_diameter']\r\n              \r\n        features = pandas_input_fn(\r\n            x=features,\r\n            shuffle=False\r\n        )()\r\n\r\n        features = {\r\n            k : tf.expand_dims(features[k], axis=1) \r\n            for k in features\r\n        }\r\n      \r\n        return features\r\n    \r\n    return internal_input_fn\r\n```\r\n\r\n## Make Predictions on Test Data\r\n\r\n\r\n```python\r\n# The documentation for tf.contrib.learn.Estimator.predict() lies.\r\n# \r\n# https://stackoverflow.com/questions/40705710/cannot-get-predictions-of-tensorflow-dnnclassifier\r\n\r\nnp.array(\r\n    [\r\n        res['classes']\r\n        for res in list(\r\n            tfe.predict(input_fn=get_predict_input_fn('test.csv'))\r\n        )\r\n    ],\r\n    dtype=np.int32\r\n)\r\n```\r\n\r\n**Other info / logs**\r\n\r\nSee my comment on the possible source of the problem.\r\n\r\nhttps://github.com/tensorflow/tensorflow/commit/0b182c3940a3d15d574da327ac705c2efa18a985#r32454203", "comments": ["thank you for reporting this ! can you try to do this instead? \r\n\r\n```\r\nimport pandas as pd\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\n\r\ndef main(file_name='/Users/pengyu/Downloads/Immunotherapy.xlsx'):\r\n    df = pd.read_excel(file_name)\r\n    fhp = tf.contrib.tensor_forest.python.tensor_forest.ForestHParams(\r\n        num_classes=2,\r\n        num_features=7,\r\n        regression=False\r\n    )\r\n\r\n    classifier = tf.contrib.tensor_forest.client.random_forest.TensorForestEstimator(\r\n        fhp)\r\n    x, y = df.drop('Result_of_Treatment', axis=1).values.astype(\r\n        np.float32), df['Result_of_Treatment'].values\r\n    classifier.fit(x, y)\r\n\r\n\r\nif __name__ == \"__main__\":\r\n    main()\r\n```\r\n\r\nsince `tf.contrib.tensor_forest` and `tf.contrib.layers` is going to be deprecated soon, i'm not sure whether we want to encourage people to use it.\r\n\r\n", "> thank you for reporting this ! can you try to do this instead?\r\n...\r\n\r\n> since `tf.contrib.tensor_forest` and `tf.contrib.layers` is going to be deprecated soon, i'm not sure whether we want to encourage people to use it.\r\n\r\nThanks for the follow-up on this.  I understand the reluctance to devote resources to deprecated code.  I did manage to find another way to address the problem.  The `TensorForestEstimator` constructor provides an argument for specifying a feature engineering function.  \r\n\r\n```\r\n    def make_feature_engineering_fn(self):\r\n\r\n        def _feature_engineering_fn(features, label):\r\n\r\n            # Encode features according to column definitions\r\n            # https://www.tensorflow.org/versions/r1.12/api_docs/python/tf/contrib/layers/transform_features\r\n            xformed_features = tflayers.transform_features(\r\n               features,\r\n               self.metadata.feature_columns\r\n            )\r\n\r\n            # Features that have been transformed will be keyed on the FeatureColumn object\r\n            # rather than the name associated with the feature.\r\n            # https://github.com/tensorflow/tensorflow/blob/v1.12.0/tensorflow/contrib/layers/python/layers/feature_column_ops.py#L822\r\n            features = {\r\n               k.name : xformed_features[k]\r\n               for k in xformed_features\r\n            }\r\n\r\n            if label is None:\r\n                return features, None\r\n            else:\r\n                return features, self._parse_label_column(label)\r\n\r\n        return _feature_engineering_fn\r\n\r\n    def _parse_label_column(self, label_string_tensor):\r\n        \"\"\"Parses a string tensor into the label tensor.\r\n\r\n        Args:\r\n          label_string_tensor: Tensor of dtype string. Result of parsing the CSV\r\n            column specified by LABEL_COLUMN.\r\n\r\n        Returns:\r\n          A Tensor of the same shape as label_string_tensor, should return\r\n          an int64 Tensor representing the label index for classification tasks,\r\n          and a float32 Tensor representing the value for a regression task.\r\n        \"\"\"\r\n\r\n        label_props = self.metadata.column_props[self.metadata.label_key]\r\n        if label_props['tf_dtype'] == tf.string:\r\n            # Build a Hash Table inside the graph\r\n            # https://www.tensorflow.org/versions/r1.12/api_docs/python/tf/contrib/lookup/index_table_from_tensor\r\n            table = tf.contrib.lookup.index_table_from_tensor(\r\n                # https://www.tensorflow.org/versions/r1.12/api_docs/python/tf/constant\r\n                tf.constant(label_props['unique_values'])\r\n            )\r\n\r\n            # Use the hash table to convert string labels to ints and one-hot encode\r\n            tf.logging.info('label_string_tensor: {0}'.format(label_string_tensor))\r\n            return table.lookup(label_string_tensor)\r\n        else:\r\n            return label_string_tensor\r\n```\r\n\r\nwhere `self.metadata.feature_columns` is a Python list with instances from `tf.contrib.layers.feature_column` module.", "@pjhinton,\r\n\r\n> Thanks for the follow-up on this. I understand the reluctance to devote resources to deprecated code. I did manage to find another way to address the problem. The TensorForestEstimator constructor provides an argument for specifying a feature engineering function.\r\n\r\nLooks like issue is resolved. Can we move this to closure!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 26081, "title": "Problem with keras implementation of Tensorflow", "body": "Hi,\r\nTF Version: b'v1.13.0-rc1-2-gb6141b06f5' 1.13.0-rc1\r\n\r\nI have switched a keras implementation to tensorflow.keras. My intention is to give the TPUs a try. The original model trains on GPU. The tensorfow version cancels and shows a different model output: \r\n\r\nOriginal output is:\r\n\r\nModel summary...\r\n__________________________________________________________________________________________________\r\nLayer (type)                    Output Shape         Param #     Connected to                    \r\n==================================================================================================\r\ninput_1 (InputLayer)            (None, 224, 224, 3)  0                                           \r\n__________________________________________________________________________________________________\r\nmobilenet_1.00_224 (Model)      (None, 7, 7, 1024)   3228864     input_1[0][0]                   \r\n__________________________________________________________________________________________________\r\nglobal_average_pooling2d_1 (Glo (None, 1024)         0           mobilenet_1.00_224[1][0]        \r\n__________________________________________________________________________________________________\r\ndropout_1 (Dropout)             (None, 1024)         0           global_average_pooling2d_1[0][0]\r\n__________________________________________________________________________________________________\r\ndense_1 (Dense)                 (None, 1024)         1049600     dropout_1[0][0]                 \r\n__________________________________________________________________________________________________\r\ngender (Dense)                  (None, 2)            2050        dense_1[0][0]                   \r\n__________________________________________________________________________________________________\r\nage (Dense)                     (None, 21)           21525       dense_1[0][0]                   \r\n==================================================================================================\r\nTotal params: 4,302,039\r\nTrainable params: 4,280,151\r\nNon-trainable params: 21,888\r\n\r\n\r\n**Tensorflow Keras Version is:**\r\n\r\nModel summary...\r\n__________________________________________________________________________________________________\r\nLayer (type)                    Output Shape         Param #     Connected to                    \r\n==================================================================================================\r\ninput_1 (InputLayer)            (None, 224, 224, 3)  0                                           \r\n__________________________________________________________________________________________________\r\nmobilenet_1.00_224 (Model)      (None, 7, 7, 1024)   3228864     input_1[0][0]                   \r\n__________________________________________________________________________________________________\r\nglobal_average_pooling2d (Globa (None, 1024)         0           mobilenet_1.00_224[1][0]        \r\n__________________________________________________________________________________________________\r\ndropout (Dropout)               (None, 1024)         0           global_average_pooling2d[0][0]  \r\n__________________________________________________________________________________________________\r\ndense (Dense)                   (None, 1024)         1049600     dropout[0][0]                   \r\n__________________________________________________________________________________________________\r\ngender (Dense)                  (None, 2)            2050        dense[0][0]                     \r\n__________________________________________________________________________________________________\r\nage (Dense)                     (None, 21)           21525       dense[0][0]                     \r\n==================================================================================================\r\nTotal params: 4,302,039\r\nTrainable params: 4,280,151\r\nNon-trainable params: 21,888\r\n_____________________________________________________________\r\n \r\n\r\nWhat I see is the missing _1 in dropout, dense and so on. \r\n\r\nThis results in the following error when trying to train:\r\nValueError: Output of generator should be a tuple `(x, y, sample_weight)` or `(x, y)`. Found: [{'input_1':...\r\n\r\nKind regards,\r\n\r\nDirk\r\n", "comments": ["You can execute your model correctly using GPU however it fails on TPU. Is my interpretation correct on this? Also in order to expedite the trouble-shooting process, can you please provide a code snippet to reproduce the issue reported here. Thanks!\r\n", "@ymodak Thanks. No the TPU is not the problem. The problem is the Keras implementation of tensor flow. I need to use tf.keras because of the TPU, but training also fails using tf.keras on a GPU. The only difference I see is the _1 and so on in the layers, so keras starts with _1, tf. keras starts without _x But i do not think that this is the problem, I have plotted both models for better understanding.\r\nThe code is derived from https://github.com/KinarR/age-gender-estimator-keras\r\nI wanted to give several implementations for a gender estimator a try (keras, tensor flow native) and so on, because I am evaluating this at the moment. My Changes are: Changing all Keras to tensorflow.keras. Assuming \"image_dim_ordering = 'tf'\" in MobileNetDeepEstimator because we are on tensorflow. And of course the tpu stuff. So the model is build in \r\n\r\n```\r\nclass MobileNetDeepEstimator:\r\n    def __init__(self, image_size, alpha, num_neu, weights=None):\r\n\r\n        \"\"\"if K.image_dim_ordering() == \"th\":\r\n            logging.debug(\"image_dim_ordering = 'th'\")\r\n            self._channel_axis = 1\r\n            self._input_shape = (3, image_size, image_size)\r\n        else:\"\"\"\r\n        if (1==1):\r\n            logging.debug(\"image_dim_ordering = 'tf'\")\r\n            self._channel_axis = -1\r\n            self._input_shape = (image_size, image_size, 3)\r\n            self.alpha = alpha\r\n            self.num_neu = num_neu\r\n            self.weights = weights\r\n            self.FC_LAYER_SIZE = 1024\r\n\r\n    def __call__(self):\r\n        logging.debug(\"Creating model...\")\r\n\r\n        inputs = Input(shape=self._input_shape)\r\n        model_mobilenet = MobileNet(input_shape=self._input_shape, alpha=self.alpha, depth_multiplier=1, dropout=1e-3,\r\n                                    include_top=False, weights=self.weights, input_tensor=None, pooling=None)\r\n\r\n        x = model_mobilenet(inputs)\r\n\r\n        feat_a = GlobalAveragePooling2D()(x)\r\n        feat_a = Dropout(0.5)(feat_a)\r\n        feat_a = Dense(self.FC_LAYER_SIZE, activation=\"relu\")(feat_a)\r\n\r\n        pred_g_softmax = Dense(2, activation='softmax', name='gender')(feat_a)\r\n        pred_a_softmax = Dense(self.num_neu, activation='softmax', name='age')(feat_a)\r\n\r\n        model = Model(inputs=inputs, outputs=[pred_g_softmax, pred_a_softmax])\r\n\r\n        return model\r\n```\r\n\r\nand compiled to\r\n\r\n```\r\ntpu_model = tf.contrib.tpu.keras_to_tpu_model(\r\n    model,\r\n    strategy=tf.contrib.tpu.TPUDistributionStrategy(\r\n        tf.contrib.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])        \r\n    )\r\n    )\r\n\r\n    tpu_model.compile(\r\n        optimizer=tf.keras.optimizers.SGD(lr=0.001,),\r\n        loss=tf.keras.losses.sparse_categorical_crossentropy,\r\n        metrics={'gender': 'accuracy',\r\n                 'age': 'accuracy'},\r\n    )\r\n\r\n\r\n```", "And these are the models Keras is the original one, tfkeras is the one, that won't work (tf.keras implementation)\r\n\r\nKeras:\r\n![kerasmodel_plot](https://user-images.githubusercontent.com/27775323/53403892-ce53b680-39b4-11e9-91d3-e7ac299e2511.png)\r\n\r\n", "**tf.keras:**\r\n\r\n![tfkerasmodel_plot](https://user-images.githubusercontent.com/27775323/53403907-d3b10100-39b4-11e9-81d3-a5a2388ad709.png)", "I've done some more investigation and tested tf.keras and keras in an virtualenv on my Mac. I can reproduce the behavior. The training works with keras while tf.keras throws the exception. It seems to be a problem with the generator. The generator is used like this:\r\n\r\n```\r\nhist = tpu_model.fit_generator(\r\n        image_generator.flow(mode='train'),\r\n        steps_per_epoch=int(len(train_keys) / batch_size),\r\n        epochs=nb_epochs,\r\n        callbacks=callbacks,\r\n        validation_data=image_generator.flow('val'),\r\n        validation_steps=int(len(val_keys) / batch_size)\r\n    )\r\n\r\n```\r\n\r\nand the image_generator:\r\n\r\n```\r\nimage_generator = ImageGenerator(ground_truth_data, batch_size,\r\n                                     input_shape[:2],\r\n                                     train_keys, val_keys,\r\n                                     path_prefix=images_path,\r\n                                     vertical_flip_probability=0\r\n                                     )\r\n class ImageGenerator(object):\r\n...\r\n\r\ndef flow(self, mode='train'):\r\n        while True:\r\n            if mode == 'train':\r\n                logging.debug('alive...')\r\n                shuffle(self.train_keys)\r\n                keys = self.train_keys\r\n            elif mode == 'val' or mode == 'demo':\r\n                shuffle(self.validation_keys)\r\n                keys = self.validation_keys\r\n            else:\r\n                raise Exception('invalid mode: %s' % mode)\r\n\r\n            inputs = []\r\n            targets = []\r\n            for key in keys:\r\n                image_path = self.path_prefix + key\r\n                image_array = imread(image_path)\r\n                image_array = imresize(image_array, self.image_size)\r\n\r\n                num_image_channels = len(image_array.shape)\r\n                if num_image_channels != 3:\r\n                    continue\r\n\r\n                ground_truth = self.ground_truth_data[key]\r\n\r\n                image_array = image_array.astype('float32')\r\n                if mode == 'train' or mode == 'demo':\r\n                    image_array = self.transform(image_array)[0]\r\n\r\n                if self.grayscale:\r\n                    image_array = cv2.cvtColor(image_array.astype('uint8'),\r\n                                               cv2.COLOR_RGB2GRAY).astype('float32')\r\n                    image_array = np.expand_dims(image_array, -1)\r\n\r\n                inputs.append(image_array)\r\n                targets.append(ground_truth)\r\n                if len(targets) == self.batch_size:\r\n                    inputs = np.asarray(inputs)\r\n                    targets = np.asarray(targets)\r\n\r\n                    gender = np_utils.to_categorical(targets[:, 0], 2)\r\n                    # Quantizing the age\r\n\r\n                    age_bins = np.linspace(0, 100, 21)\r\n                    age_step = np.digitize(targets[:, 1], age_bins)\r\n                    age_quantized = np_utils.to_categorical(age_step, 21)\r\n\r\n                    if mode == 'train' or mode == 'val':\r\n                        inputs = self.preprocess_images(inputs)\r\n                        yield self._wrap_in_dictionary(inputs, gender, age_quantized)\r\n                    if mode == 'demo':\r\n                        yield self._wrap_in_dictionary(inputs, gender, age_quantized)\r\n                    inputs = []\r\n                    targets = []\r\n```\r\n\r\nSo the exception as mentioned above is:\r\n\r\n> Output of generator should be a tuple `(x, y, sample_weight)` or `(x, y)`. Found: [{'input_1': array([[[[-0.79948485, -0.8227509 , -0.85790277],          [-0.79948485, -0.8227509 , -0.85790277],          [-0.79064566, -0.81391174, -0.84906363],          ...,          [-0.7384317 , -0.7693655 , -0.8045173 ],          [-0.7384317 , -0.7693655 , -0.8045173 ],          [-0.7384317 , -0.7693655 , -0.8045173 ]],          [[-0.79948485, -0.8227509 , -0.85790277],          [-0.79948485, -0.8227509 , -0.85790277],          [-0.79064566, -0.81391174, -0.84906363],          ...,          [-0.7384317 , -0.7693655 , -0.8045173 ],          [-0.7384317 , -0.7693655 , -0.8045173 ],          [-0.7384317 , -0.7693655 , -0.8045173 ]],          [[-0.79948485, -0.8227509 , -0.85790277],          [-0.79948485, -0.8227509 , -0.85790277],          [-0.79064566, -0.81391174, -0.84906363],          ...,          [-0.7384317 , -0.7693655 , -0.8045173 ],          [-0.7384317 , -0.7693655 , -0.8045173 ],          [-0.7384317 , -0.7693655 , -0.8045173 ]],          ...,          [[-0.32190108, -0.34516716, -0.3649835 ],          [-0.32190108, -0.34516716, -0.3649835 ],          [-0.3130619 , -0.33632797, -0.35614425],          ...,          [ 0.18057775,  0.14964402,  0.09915662],          [ 0.189417  ,  0.15848315,  0.10799599],          [ 0.189417  ,  0.15848315,  0.10799599]],          [[-0.32190108, -0.34516716, -0.3649835 ],          [-0.32190108, -0.34516716, -0.3649835 ],          [-0.3130619 , -0.33632797, -0.35614425],          ...,          [ 0.22477376,  0.19384003,  0.14335251],          [ 0.23361301,  0.20267916,  0.15219176],          [ 0.23361301,  0.20267916,  0.15219176]],          [[-0.32190108, -0.34516716, -0.3649835 ],          [-0.32190108, -0.34516716, -0.3649835 ],          [-0.3130619 , -0.33632797, -0.35614425],          ...,          [ 0.24245238,  0.2115184 ,  0.16103113],          [ 0.2512914 ,  0.22035766,  0.16987014],          [ 0.2512914 ,  0.22035766,  0.16987014]]],          [[[ 0.11772168,  0.13635767,  0.1170119 ],          [ 0.11052775,  0.12916386,  0.1098181 ],          [ 0.11052775,  0.12916386,  0.1098181 ],          ...,          [ 0.36219227,  0.38082862,  0.3481512 ],          [ 0.35499847,  0.3736347 ,  0.34095728],          [ 0.35499847,  0.3736347 ,  0.34095728]],          [[ 0.11772168,  0.13635767,  0.1170119 ],          [ 0.11052775,  0.12916386,  0.1098181 ],          [ 0.11052775,  0.12916386,  0.1098181 ],          ...,          [ 0.35499847,  0.3736347 ,  0.34095728],          [ 0.35499847,  0.3736347 ,  0.34095728],          [ 0.35499847,  0.3736347 ,  0.34095728]],          [[ 0.11052775,  0.12916386,  0.1098181 ],          [ 0.11052775,  0.12916386,  0.1098181 ],          [ 0.11052775,  0.12916386,  0.1098181 ],          ...,          [ 0.35499847,  0.3736347 ,  0.34095728],          [ 0.35499847,  0.3736347 ,  0.34095728],          [ 0.35499847,  0.3736347 ,  0.34095728]],          ...,          [[ 0.22574973,  0.24438608,  0.23837173],          [ 0.22574973,  0.24438608,  0.23837173],          [ 0.23294365,  0.25158   ,  0.24556577],          ...,          [-0.5251232 , -0.5531473 , -0.5724931 ],          [-0.5251232 , -0.5531473 , -0.5724931 ],          [-0.5179293 , -0.54595345, -0.5652993 ]],          [[ 0.23294365,  0.25158   ,  0.24556577],          [ 0.23294365,  0.25158   ,  0.24556577],          [ 0.23294365,  0.25158   ,  0.24556577],          ...,          [-0.5251232 , -0.5531473 , -0.5724931 ],          [-0.5251232 , -0.5531473 , -0.5724931 ],          [-0.5251232 , -0.5531473 , -0.5724931 ]],          [[ 0.23294365,  0.25158   ,  0.24556577],          [ 0.23294365,  0.25158   ,  0.24556577],          [ 0.23294365,  0.25158   ,  0.24556577],          ...,          [-0.5179293 , -0.54595345, -0.5652993 ],          [-0.5251232 , -0.5531473 , -0.5724931 ],          [-0.5251232 , -0.5531473 , -0.5724931 ]]],          [[[-1.        , -1.        , -1.        ],          [-1.        , -1.        , -1.        ],          [-1.        , -1.        , -1.        ],          ...,          [-1.        , -1.        , -1.        ],          [-1.        , -1.        , -1.        ],          [-1.        , -1.        , -1.        ]],          [[-1.        , -1.        , -1.        ],          [-1.        , -1.        , -1.        ],          [-1.        , -1.        , -1.        ],          ...,          [-1.        , -1.        , -1.        ],          [-1.        , -1.        , -1.        ],          [-1.        , -1.        , -1.        ]],          [[-1.        , -1.        , -1.        ],          [-1.        , -1.        , -1.        ],          [-1.        , -1.        , -1.        ],          ...,          [-1.        , -1.        , -1.        ],          [-1.        , -1.        , -1.        ],          [-1.        , -1.        , -1.        ]],          ...,          [[-1.        , -1.        , -1.        ],          [-1.        , -1.        , -1.        ],          [-1.        , -1.        , -1.        ],          ...,          [-0.87843734, -0.8746458 , -0.8314029 ],          [-0.9052509 , -0.90145934, -0.85821646],          [-0.9320644 , -0.9282729 , -0.88503003]],          [[-1.        , -1.        , -1.        ],          [-1.        , -1.        , -1.        ],          [-1.        , -1.        , -1.        ],          ...,          [-0.90702516, -0.8872958 , -0.84405285],          [-0.9338387 , -0.91410935, -0.8708664 ],          [-0.9454712 , -0.9416797 , -0.8984368 ]],          [[-1.        , -1.        , -1.        ],          [-1.        , -1.        , -1.        ],          [-1.        , -1.        , -1.        ],          ...,          [-0.920432  , -0.9007026 , -0.85745966],          [-0.94724554, -0.9275161 , -0.88427323],          [-0.9606523 , -0.9409229 , -0.89768   ]]],          ...,          [[[ 0.03327799,  0.30924726,  0.528203  ],          [ 0.03327799,  0.30924726,  0.528203  ],          [ 0.03327799,  0.30924726,  0.528203  ],          ...,          [ 0.0780406 ,  0.39597082,  0.528203  ],          [ 0.0780406 ,  0.39597082,  0.528203  ],          [ 0.0780406 ,  0.39597082,  0.528203  ]],          [[ 0.03327799,  0.30924726,  0.528203  ],          [ 0.03327799,  0.30924726,  0.528203  ],          [ 0.03327799,  0.30924726,  0.528203  ],          ...,          [ 0.08412147,  0.40205193,  0.528203  ],          [ 0.08412147,  0.40205193,  0.528203  ],          [ 0.08412147,  0.40205193,  0.528203  ]],          [[ 0.03327799,  0.30924726,  0.528203  ],          [ 0.03327799,  0.30924726,  0.528203  ],          [ 0.03327799,  0.30924726,  0.528203  ],          ...,          [ 0.12301791,  0.43255615,  0.528203  ],          [ 0.12301791,  0.43255615,  0.528203  ],          [ 0.12301791,  0.43255615,  0.528203  ]],          ...,          [[-0.53515565, -0.5277369 , -0.3423922 ],          [-0.50475085, -0.49733198, -0.31198746],          [-0.48042697, -0.47300816, -0.28766358],          ...,          [-0.9477527 , -0.83962744, -0.7214205 ],          [-0.9173479 , -0.8092226 , -0.6910157 ],          [-0.893024  , -0.78489876, -0.66669184]],          [[-0.5290747 , -0.5216558 , -0.33631128],          [-0.49258888, -0.48517007, -0.2998255 ],          [-0.5169128 , -0.50949395, -0.3241493 ],          ...,          [-0.94315565, -0.86020696, -0.7336079 ],          [-0.9188318 , -0.83588314, -0.709284  ],          [-0.88842696, -0.80547833, -0.67887914]],          [[-0.52299374, -0.51557493, -0.33023036],          [-0.468265  , -0.4608462 , -0.2755016 ],          [-0.53515565, -0.5277369 , -0.3423922 ],          ...,          [-0.9619255 , -0.8789769 , -0.7355933 ],          [-0.9370747 , -0.85412604, -0.7275269 ],          [-0.91275084, -0.82980216, -0.703203  ]]],          [[[ 0.7429316 ,  0.6751132 ,  0.5103228 ],          [ 0.7535478 ,  0.7189033 ,  0.55411303],          [ 0.7535478 ,  0.7516738 ,  0.62709653],          ...,          [ 0.25413465,  0.1983062 , -0.03242844],          [ 0.16746819,  0.11763465, -0.11310005],          [ 0.11637974,  0.06654608, -0.16418856]],          [[ 0.6699481 ,  0.6021297 ,  0.4373393 ],          [ 0.7137382 ,  0.6459197 ,  0.48112953],          [ 0.7535478 ,  0.72620165,  0.56141126],          ...,          [ 0.2542832 ,  0.19845474, -0.02628493],          [ 0.18859804,  0.13276958, -0.09197009],          [ 0.14557302,  0.09573948, -0.13499516]],          [[ 0.5458759 ,  0.47805762,  0.31326723],          [ 0.6042627 ,  0.5364444 ,  0.37165403],          [ 0.6991414 ,  0.6313231 ,  0.4665327 ],          ...,          [ 0.26081645,  0.19899309, -0.01975167],          [ 0.21779156,  0.16196299, -0.06277668],          [ 0.18936312,  0.13952959, -0.091205  ]],          ...,          [[-0.03483921, -0.22855121, -0.37535673],          [-0.04943597, -0.24314797, -0.3899535 ],          [-0.07133102, -0.26504302, -0.41184855],          ...,          [-0.0747655 , -0.08862936, -0.00762731],          [-0.0747655 , -0.08862936, -0.00762731],          [-0.0747655 , -0.08862936, -0.00762731]],          [[-0.03483921, -0.22855121, -0.37535673],          [-0.04943597, -0.24314797, -0.3899535 ],          [-0.07133102, -0.26504302, -0.41184855],          ...,          [-0.11125726, -0.12512118, -0.04411906],          [-0.11855567, -0.13241953, -0.05141747],          [-0.11855567, -0.13241953, -0.05141747]],          [[-0.03483921, -0.22855121, -0.37535673],          [-0.04943597, -0.24314797, -0.3899535 ],          [-0.07133102, -0.26504302, -0.41184855],          ...,          [-0.1331523 , -0.14701623, -0.06601417],          [-0.14045072, -0.15431458, -0.07331252],          [-0.147749  , -0.16161293, -0.08061087]]],          [[[-0.89266884, -0.9059861 , -0.91916364],          [-0.89266884, -0.9059861 , -0.91916364],          [-0.89266884, -0.9059861 , -0.91916364],          ...,          [-0.89266884, -0.9059861 , -0.91916364],          [-0.89266884, -0.9059861 , -0.91916364],          [-0.89266884, -0.9059861 , -0.91916364]],          [[-0.89266884, -0.9059861 , -0.91916364],          [-0.89266884, -0.9059861 , -0.91916364],          [-0.89266884, -0.9059861 , -0.91916364],          ...,          [-0.89266884, -0.9059861 , -0.91916364],          [-0.89266884, -0.9059861 , -0.91916364],          [-0.89266884, -0.9059861 , -0.91916364]],          [[-0.89266884, -0.9059861 , -0.91916364],          [-0.89266884, -0.9059861 , -0.91916364],          [-0.89266884, -0.9059861 , -0.91916364],          ...,          [-0.89266884, -0.9059861 , -0.91916364],          [-0.89266884, -0.9059861 , -0.91916364],          [-0.89266884, -0.9059861 , -0.91916364]],          ...,          [[-0.8745992 , -0.9059861 , -0.91916364],          [-0.8745992 , -0.9059861 , -0.91916364],          [-0.8745992 , -0.9059861 , -0.91916364],          ...,          [ 0.71699464,  0.45771182,  0.22694933],          [ 0.71699464,  0.45771182,  0.22694933],          [ 0.71699464,  0.45771182,  0.22694933]],          [[-0.79437065, -0.83606863, -0.91916364],          [-0.79462796, -0.8457861 , -0.91916364],          [-0.794566  , -0.8457241 , -0.91916364],          ...,          [ 0.7069906 ,  0.44770753,  0.21694505],          [ 0.7069906 ,  0.44770753,  0.21694505],          [ 0.7069906 ,  0.44770753,  0.21694505]],          [[-0.7443499 , -0.7860478 , -0.91916364],          [-0.7446072 , -0.79576534, -0.91916364],          [-0.74454516, -0.79570335, -0.91916364],          ...,          [ 0.74700713,  0.4877243 ,  0.2569617 ],          [ 0.74700713,  0.4877243 ,  0.2569617 ],          [ 0.74700713,  0.4877243 ,  0.2569617 ]]]], dtype=float32)}, {'gender': array([[1., 0.],        [0., 1.],        [0., 1.],        [1., 0.],        [1., 0.],        [1., 0.],        [0., 1.],        [1., 0.],        [0., 1.],        [1., 0.],        [0., 1.],        [1., 0.],        [1., 0.],        [1., 0.],        [1., 0.],        [1., 0.],        [1., 0.],        [1., 0.],        [0., 1.],        [1., 0.],        [0., 1.],        [1., 0.],        [1., 0.],        [0., 1.],        [1., 0.],        [0., 1.],        [0., 1.],        [1., 0.],        [0., 1.],        [0., 1.],        [0., 1.],        [1., 0.]], dtype=float32), 'age': array([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,         0., 0., 0., 0., 0.],        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,         0., 0., 0., 0., 0.],        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,         0., 0., 0., 0., 0.],        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,         0., 0., 0., 0., 0.],        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,         0., 0., 0., 0., 0.],        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,         0., 0., 0., 0., 0.],        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,         0., 0., 0., 0., 0.],        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,         0., 0., 0., 0., 0.],        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,         0., 0., 0., 0., 0.],        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,         0., 0., 0., 0., 0.],        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,         0., 0., 0., 0., 0.],        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,         0., 0., 0., 0., 0.],        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,         0., 0., 0., 0., 0.],        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,         0., 0., 0., 0., 0.],        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,         0., 0., 0., 0., 0.],        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,         0., 0., 0., 0., 0.],        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,         0., 0., 0., 0., 0.],        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,         0., 0., 0., 0., 0.],        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,         0., 0., 0., 0., 0.],        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,         0., 0., 0., 0., 0.],        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,         0., 0., 0., 0., 0.],        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,         0., 0., 0., 0., 0.],        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,         0., 0., 0., 0., 0.],        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,         0., 0., 0., 0., 0.],        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,         0., 0., 0., 0., 0.],        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,         0., 0., 0., 0., 0.],        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,         0., 1., 0., 0., 0.],        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,         0., 0., 0., 0., 0.],        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,         0., 0., 0., 0., 0.],        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,         0., 0., 0., 0., 0.],        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,         0., 0., 0., 0., 0.],        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,         0., 0., 0., 0., 0.]], dtype=float32)}]\r\n\r\nNow I tested both versions with:\r\n`next(image_generator.flow(mode='train'))`\r\n\r\nAnd both outputs look the same:\r\n\r\nKeras:\r\n[{'input_1': array([[[[-1.       ...e=float32)}, {'age': array([[0., 0., 0., ...e=float32), 'gender': array([[0., 1.],\r\n   ...e=float32)}]\r\n\r\nTfkeras\r\n[{'input_1': array([[[[-2.7333086...e=float32)}, {'age': array([[0., 0., 0., ...e=float32), 'gender': array([[1., 0.],\r\n   ...e=float32)}]\r\n\r\n", "so now I tested if the generator generates a tuple and voila it does not:\r\n\r\n```\r\nzzn = next(image_generator.flow(mode='train'))\r\n    if not isinstance(zzn, tuple):\r\n        logging.debug(\"error generator tuple\")\r\n\r\n```\r\n\r\nSo the exception seems to be correct. But Keras has no problem with this. The exception is thrown in tensorflow/python/keras/engine/training_generator.py\r\n\r\nIs there a different behavior between tf.keras and keras regarding the training generator?\r\n\r\nUpdate: Yes, tf.keras is more strict:\r\n\r\n```\r\ndef _get_next_batch(output_generator, mode):\r\n  \"\"\"Retrieves the next batch of input data.\"\"\"\r\n  try:\r\n    generator_output = next(output_generator)\r\n  except (errors.OutOfRangeError, StopIteration):\r\n    # Returning `None` will trigger looping to stop.\r\n    logging.warning('Your dataset iterator ran out of data.')\r\n    return None\r\n  if not isinstance(generator_output, tuple):\r\n    if mode == 'predict':\r\n      # Always wrap in a tuple.\r\n      return (generator_output,)\r\n    else:\r\n      raise ValueError('Output of generator should be '\r\n                       'a tuple `(x, y, sample_weight)` '\r\n                       'or `(x, y)`. Found: ' + str(generator_output))\r\n\r\n```\r\n\r\nwhile keras is less strict checking the type of a tuple:\r\n```\r\n\r\nif not hasattr(generator_output, '__len__'):\r\n                    raise ValueError('Output of generator should be '\r\n                                     'a tuple `(x, y, sample_weight)` '\r\n                                     'or `(x, y)`. Found: ' +\r\n                                     str(generator_output))\r\n```\r\n\r\nwhich in my case is true", "So changing the generator to generate tuples with\r\n`yield tuple(self._wrap_in_dictionary(inputs, gender, age_quantized))`\r\n\r\nsolves the problem, but I suggest that Keras implementation will find its way to tensorflow, so we get more flexibility(!)\r\n\r\nNow I get a new exception in this case its a TPU Problem (the code works without tpu now):\r\n\r\n> RuntimeError: Compilation failed: Compilation failure: Detected unsupported operations when trying \r\n\r\n> to compile graph cluster_15366487156777984482[] on XLA_TPU_JIT: Placeholder (No registered 'Placeholder' OpKernel for XLA_TPU_JIT devices compatible with node {{node tpu_139872799811176/input_2}}\r\n> \t.  Registered:  device='TPU'\r\n>   device='CPU'\r\n>   device='GPU'\r\n>   device='XLA_CPU'\r\n> ){{node tpu_139872799811176/input_2}}\r\n\r\nAny ideas? The only input_2 is in MobileNet", "@DHOFM Thanks for the thorough investigation. Now that you have filed a new issue explaining the newly discovered error, can we close this thread and track it there. ", "@ymodak Yes this thread can be closed. Should I open a feature requester my suggestion that Keras implementation will find its way to tensorflow, so we get more flexibility ??\r\n", "Yes, please post a feature request explaining the same. Thanks!"]}, {"number": 26080, "title": "Updated lite_test.py", "body": "", "comments": []}, {"number": 26079, "title": "add bazel rule swift", "body": "fix issue https://github.com/tensorflow/tensorflow/issues/25747", "comments": ["I applied this fix to my local branch and it passed successfully", "Which version of Bazel are you using?", "0.20.0", "0.22 (latest version) works for sure, and I believe 0.21 does as well. If you can, it's probably best to update to the latest version of Bazel.", "I will update to 0.22 to see if it works.\r\n\r\nIf that's the case I think documentations should be updated", "https://www.tensorflow.org/install/source\r\n\r\nThe offical documentation only require bazel 0.15,that maybe a source of problem", "I should mention that I don't experience this issue while using bazel 0.19.*", "That's a good point! Will discuss with the team to see if we want to update the documentation or explicitly pull in the Swift Bazel rules via the WORKSPACE file to support older versions of Bazel. \r\n\r\nIf we explicitly pull in the Swift Bazel rules, does that resolve the issue for 0.20 and older?", "Same issue occurs for both bazel 0.21 and 0.22. I think explicitly defining the Swift rules would be more compatible to most bazel versions", "actually it's not a problem with older versions, but with later versions starting from 0.20. The rules will have to be explicitly mentioned starting from versions 0.20", "@jackyko1991 and @preethivenkatesh, which platforms are you building on? When you upgraded to Bazel 0.22, did you run `bazel clean --expunge`? I don't see the issue on MacOS or Linux using Bazel 0.22.", "Actually, I was testing 0.20 on **Windows** and ran into issues. However, 0.20 seems to work fine on Linux without having to mention the rules explicitly on WORKSPACE. BTW, my comment on later versions(0.21 and .22) was based on @jackyko1991 comment", "Thank you for continuing to look into this. Do you mind providing the verbose logging for the error you are seeing on Windows (without explicitly loading the Swift rules in the WORKSPACE)?", "#25747 was closed as it appears to be a git-related issue.", "I used the latest git and tried bazel 0.21 and 0.22 on windows 10, same error occurs if swift rule is not explicitly defined", "@jackyko1991 can you please provide the detailed log with the error you are getting on Windows?\r\n\r\ncc @allevato", "``` bash\r\nWARNING: Option 'experimental_shortened_obj_file_path' is deprecated\r\nINFO: Invocation ID: 03a58090-2db6-4b61-85db-3cab65a42a6d\r\nERROR: error loading package '': Encountered error while reading extension file 'swift/repositories.bzl': no such package '@build_bazel_rules_swift//swift': Traceback (most recent call last):\r\n        File \"C:/users/jacky/_bazel_jacky/2exbtrly/external/bazel_tools/tools/build_defs/repo/git.bzl\", line 163\r\n                _clone_or_update(ctx)\r\n        File \"C:/users/jacky/_bazel_jacky/2exbtrly/external/bazel_tools/tools/build_defs/repo/git.bzl\", line 73, in _clone_or_update\r\n                fail((\"error cloning %s:\\n%s\" % (ctx....)))\r\nerror cloning build_bazel_rules_swift:\r\n+ cd C:/users/jacky/_bazel_jacky/2exbtrly/external\r\n+ rm -rf C:/users/jacky/_bazel_jacky/2exbtrly/external/build_bazel_rules_swift C:/users/jacky/_bazel_jacky/2exbtrly/external/build_bazel_rules_swift\r\nrm: cannot remove 'C:/users/jacky/_bazel_jacky/2exbtrly/external/build_bazel_rules_swift': Device or resource busy\r\nrm: cannot remove 'C:/users/jacky/_bazel_jacky/2exbtrly/external/build_bazel_rules_swift': Device or resource busy\r\nERROR: error loading package '': Encountered error while reading extension file 'swift/repositories.bzl': no such package '@build_bazel_rules_swift//swift': Traceback (most recent call last):\r\n        File \"C:/users/jacky/_bazel_jacky/2exbtrly/external/bazel_tools/tools/build_defs/repo/git.bzl\", line 163\r\n                _clone_or_update(ctx)\r\n        File \"C:/users/jacky/_bazel_jacky/2exbtrly/external/bazel_tools/tools/build_defs/repo/git.bzl\", line 73, in _clone_or_update\r\n                fail((\"error cloning %s:\\n%s\" % (ctx....)))\r\nerror cloning build_bazel_rules_swift:\r\n+ cd C:/users/jacky/_bazel_jacky/2exbtrly/external\r\n+ rm -rf C:/users/jacky/_bazel_jacky/2exbtrly/external/build_bazel_rules_swift C:/users/jacky/_bazel_jacky/2exbtrly/external/build_bazel_rules_swift\r\nrm: cannot remove 'C:/users/jacky/_bazel_jacky/2exbtrly/external/build_bazel_rules_swift': Device or resource busy\r\nrm: cannot remove 'C:/users/jacky/_bazel_jacky/2exbtrly/external/build_bazel_rules_swift': Device or resource busy\r\nINFO: Elapsed time: 0.826s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\n    Fetching @build_bazel_rules_swift; Cloning tags/0.6.0 of https://github.com/bazelbuild/rules_swift.git\r\n```\r\n\r\nversions:\r\nos: windows 10\r\n\r\ngit: 2.20.1.windows.1\r\n\r\nbazel: \r\nINFO: Invocation ID: e003576b-b676-44ea-87e2-754b784655d5\r\nBuild label: 0.22.0\r\nBuild target: bazel-out/x64_windows-opt/bin/src/main/java/com/google/devtools/build/lib/bazel/BazelServer_deploy.jar\r\nBuild time: Mon Jan 28 12:59:27 2019 (1548680367)\r\nBuild timestamp: 1548680367\r\nBuild timestamp as int: 1548680367", "These errors don't look specific to anything _inside_ rules_swift; they seem to indicate a problem cloning the repository because of existing file locks or something else:\r\n\r\n```\r\nerror cloning build_bazel_rules_swift:\r\n+ cd C:/users/jacky/_bazel_jacky/2exbtrly/external\r\n+ rm -rf C:/users/jacky/_bazel_jacky/2exbtrly/external/build_bazel_rules_swift C:/users/jacky/_bazel_jacky/2exbtrly/external/build_bazel_rules_swift\r\nrm: cannot remove 'C:/users/jacky/_bazel_jacky/2exbtrly/external/build_bazel_rules_swift': Device or resource busy\r\nrm: cannot remove 'C:/users/jacky/_bazel_jacky/2exbtrly/external/build_bazel_rules_swift': Device or resource busy\r\n```\r\n", "I have reboot the computer and run with admin right, same error occurs\n\n\u5728 2019\u5e742\u670828\u65e5\u9031\u56db 23:21\uff0cTony Allevato <notifications@github.com> \u5beb\u9053\uff1a\n\n> These errors don't look specific to anything *inside* rules_swift; they\n> seem to indicate a problem cloning the repository because of existing file\n> locks or something else:\n>\n> error cloning build_bazel_rules_swift:\n> + cd C:/users/jacky/_bazel_jacky/2exbtrly/external\n> + rm -rf C:/users/jacky/_bazel_jacky/2exbtrly/external/build_bazel_rules_swift C:/users/jacky/_bazel_jacky/2exbtrly/external/build_bazel_rules_swift\n> rm: cannot remove 'C:/users/jacky/_bazel_jacky/2exbtrly/external/build_bazel_rules_swift': Device or resource busy\n> rm: cannot remove 'C:/users/jacky/_bazel_jacky/2exbtrly/external/build_bazel_rules_swift': Device or resource busy\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/26079#issuecomment-468310986>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ALgaB0KRu5jtT6UXzluny_KZt_xRAXzlks5vR_QNgaJpZM4bPZE0>\n> .\n>\n", "My log is a little different. I can get around this by explicitly mentioning the swift rules\r\n\r\n `fatal: unable to access 'https://github.com/bazelbuild/rules_swift.git/': error setting certificate verify `\r\n\r\ngit 0.19.1 windows.1\r\nbazel 0.20.0\r\n\r\nDetailed log\r\n```\r\nWARNING: The following configs were expanded more than once: [monolithic]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.\r\nINFO: Invocation ID: 96e7d4c7-98e5-49ba-85b5-1a90bddb1848\r\nERROR: error loading package '': Encountered error while reading extension file 'swift/repositories.bzl': no such package '@build_bazel_rules_swift//swift': Traceback (most recent call last):\r\n        File \"C:/users/pvenkat2/desktop/path_to_output/external/bazel_tools/tools/build_defs/repo/git.bzl\", line 166\r\n                _clone_or_update(ctx)\r\n        File \"C:/users/pvenkat2/desktop/path_to_output/external/bazel_tools/tools/build_defs/repo/git.bzl\", line 72, in _clone_or_update\r\n                fail((\"error cloning %s:\\n%s\" % (ctx....)))\r\nerror cloning build_bazel_rules_swift:\r\n+ cd C:/users/pvenkat2/desktop/path_to_output/external\r\n+ rm -rf C:/users/pvenkat2/desktop/path_to_output/external/build_bazel_rules_swift C:/users/pvenkat2/desktop/path_to_output/external/build_bazel_rules_swift\r\n+ git clone --depth=1 https://github.com/bazelbuild/rules_swift.git C:/users/pvenkat2/desktop/path_to_output/external/build_bazel_rules_swift\r\nCloning into 'C:/users/pvenkat2/desktop/path_to_output/external/build_bazel_rules_swift'...\r\nfatal: unable to access 'https://github.com/bazelbuild/rules_swift.git/': error setting certificate verify locations:\r\n  CAfile: C:/Program Files/Git/mingw64/libexec/ssl/certs/ca-bundle.crt\r\n  CApath: none\r\n+ git clone https://github.com/bazelbuild/rules_swift.git C:/users/pvenkat2/desktop/path_to_output/external/build_bazel_rules_swift\r\nCloning into 'C:/users/pvenkat2/desktop/path_to_output/external/build_bazel_rules_swift'...\r\nfatal: unable to access 'https://github.com/bazelbuild/rules_swift.git/': error setting certificate verify locations:\r\n  CAfile: C:/Program Files/Git/mingw64/libexec/ssl/certs/ca-bundle.crt\r\n  CApath: none\r\nERROR: error loading package '': Encountered error while reading extension file 'swift/repositories.bzl': no such package '@build_bazel_rules_swift//swift': Traceback (most recent call last):\r\n        File \"C:/users/pvenkat2/desktop/path_to_output/external/bazel_tools/tools/build_defs/repo/git.bzl\", line 166\r\n                _clone_or_update(ctx)\r\n        File \"C:/users/pvenkat2/desktop/path_to_output/external/bazel_tools/tools/build_defs/repo/git.bzl\", line 72, in _clone_or_update\r\n                fail((\"error cloning %s:\\n%s\" % (ctx....)))\r\nerror cloning build_bazel_rules_swift:\r\n+ cd C:/users/pvenkat2/desktop/path_to_output/external\r\n+ rm -rf C:/users/pvenkat2/desktop/path_to_output/external/build_bazel_rules_swift C:/users/pvenkat2/desktop/path_to_output/external/build_bazel_rules_swift\r\n+ git clone --depth=1 https://github.com/bazelbuild/rules_swift.git C:/users/pvenkat2/desktop/path_to_output/external/build_bazel_rules_swift\r\nCloning into 'C:/users/pvenkat2/desktop/path_to_output/external/build_bazel_rules_swift'...\r\nfatal: unable to access 'https://github.com/bazelbuild/rules_swift.git/': error setting certificate verify locations:\r\n  CAfile: C:/Program Files/Git/mingw64/libexec/ssl/certs/ca-bundle.crt\r\n  CApath: none\r\n+ git clone https://github.com/bazelbuild/rules_swift.git C:/users/pvenkat2/desktop/path_to_output/external/build_bazel_rules_swift\r\nCloning into 'C:/users/pvenkat2/desktop/path_to_output/external/build_bazel_rules_swift'...\r\nfatal: unable to access 'https://github.com/bazelbuild/rules_swift.git/': error setting certificate verify locations:\r\n  CAfile: C:/Program Files/Git/mingw64/libexec/ssl/certs/ca-bundle.crt\r\n  CApath: none\r\nINFO: Elapsed time: 15.353s\r\nINFO: 0 processes.\r\n```` ", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!\r\n"]}, {"number": 26078, "title": "add clear user instructions for dataset.prefetch", "body": "The argument's name \"buffer_size\" and api_doc \"Creates a Dataset that prefetches elements from this dataset.\" mislead users, which could lead to huge memory usage. Several users made such misunderstanding which trigger huge memory usage, similar confuse in stack overflow: https://stackoverflow.com/questions/49707062/tensorflow-dataset-api-dataset-batchn-prefetchm-prefetches-m-batches-or-sam", "comments": ["@liutongxuan could you please check build errors", "> @liutongxuan could you please check build errors\r\n\r\nNot related, the PR only contains comments changes.", "The failures are related, in particular https://source.cloud.google.com/results/invocations/1a624d60-a977-4faa-b9b9-a7539aebfad4/log indicates that your comment changes violate the 80 character per line limit:\r\n\r\n```\r\nFAIL: Found 2 non-whitelited pylint errors:\r\ntensorflow/python/data/ops/dataset_ops.py:623: [C0301(line-too-long), ] Line too long (82/80)\r\ntensorflow/python/data/ops/dataset_ops.py:624: [C0301(line-too-long), ] Line too long (83/80)\r\n```\r\n\r\n", "@liutongxuan can you please resolve conflicts.", "@rthadur  fixed conflict, thx"]}, {"number": 26077, "title": "1.13.0-rc2 gpu doesnt work", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 1.13.0-rc2\r\n- Python version: 3.6.8\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10 / 7.3.1\r\n- GPU model and memory: NVIDIA GeForce GTX 1070 Ti\r\n[trainingres.txt](https://github.com/tensorflow/tensorflow/files/2899440/trainingres.txt)\r\n\r\nImage recognition error:\r\n\r\nWARNING:tensorflow:From C:\\Users\\navickg\\AppData\\Local\\Programs\\Python\\Python36\\Image_NEW_GPU\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nColocations handled automatically by placer.\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\navickg\\AppData\\Local\\Programs\\Python\\Python36\\itemtestprediction.py\", line 16, in <module>\r\n    predictions, probabilities = predictionPet.predictImage(\"C:\\\\Users\\\\navickg\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python36\\\\testimages\\\\lawnmower.jpg\", result_count=5)\r\n  File \"C:\\Users\\navickg\\AppData\\Local\\Programs\\Python\\Python36\\Image_NEW_GPU\\imageai\\Prediction\\Custom\\__init__.py\", line 588, in predictImage\r\n    prediction = model.predict(x=image_to_predict, steps=1)\r\n  File \"C:\\Users\\navickg\\AppData\\Local\\Programs\\Python\\Python36\\Image_NEW_GPU\\tensorflow\\python\\keras\\engine\\training.py\", line 1113, in predict\r\n    self, x, batch_size=batch_size, verbose=verbose, steps=steps)\r\n  File \"C:\\Users\\navickg\\AppData\\Local\\Programs\\Python\\Python36\\Image_NEW_GPU\\tensorflow\\python\\keras\\engine\\training_arrays.py\", line 266, in model_iteration\r\n    batch_outs = f(actual_inputs)\r\n  File \"C:\\Users\\navickg\\AppData\\Local\\Programs\\Python\\Python36\\Image_NEW_GPU\\tensorflow\\python\\keras\\backend.py\", line 3076, in __call__\r\n    run_metadata=self.run_metadata)\r\n  File \"C:\\Users\\navickg\\AppData\\Local\\Programs\\Python\\Python36\\Image_NEW_GPU\\tensorflow\\python\\client\\session.py\", line 1439, in __call__\r\n    run_metadata_ptr)\r\n  File \"C:\\Users\\navickg\\AppData\\Local\\Programs\\Python\\Python36\\Image_NEW_GPU\\tensorflow\\python\\framework\\errors_impl.py\", line 528, in __exit__\r\n    c_api.TF_GetCode(self.status.status))\r\ntensorflow.python.framework.errors_impl.UnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\r\n\t [[{{node conv2d/Conv2D}}]]\r\n\t [[{{node dense/Softmax}}]]\r\n\r\nWhile 1.12 built from source Tensorflow version works without any issues\r\n", "comments": ["I suspect its due to version mismatch of  cuDNN for CUDA and NVIDIA Hardware. Please take look at [cuDNN Support Matrix](https://docs.nvidia.com/deeplearning/sdk/cudnn-support-matrix/index.html) to know more.", "Thanks, I'll try to install newest cudnn version", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 26076, "title": "Why is op:BatchMatMul listed in file(.pbtxt), when there is no call to such op?", "body": "There is no usage of op named ***BatchMatMul*** in my code. If the op is not used then why is it listed in the file (.pbtxt)?\r\n\r\nCan anyone please help me with this...!\r\n\r\nThanks in advance.", "comments": ["It looks like you haven't used a template to create this issue. Please resubmit your issue using a template from [here](https://github.com/tensorflow/tensorflow/issues/new/choose). We ask users to use the template because it reduces overall time to resolve a new issue by avoiding extra communication to get to the root of the issue. We will close this issue in lieu of the new one you will create from the template. Thank you for your cooperation.\r\n", "Ok @ymodak.\r\nActually I was guessing it as a miscellaneous issue and used the related template.\r\nI have created a new issue using the Bug template.\r\nhttps://github.com/tensorflow/tensorflow/issues/26239"]}, {"number": 26075, "title": "TFLite model converted from pb file yields different output values", "body": "System information:\r\n\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): \r\n    `macOS Mojave version 10.14.3`\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: \r\n   `IPhone XS (iOS 12.1.4)`\r\nTensorFlow installed from (source or binary):\r\n    bazel tools: build from source\r\n    python imports: install with pip `tensorflow==1.12.0`\r\nTensorFlow version (use command below):\r\n   `bazel tools: github branch r1.13 commit bade323390591fff6fc82b7eeb4a6cc30f807389 Fri Feb 22 `11:00:40 2019 -0800\r\n    python imports: `('v1.12.0-rc2-3-ga6d8ffae09', '1.12.0')`\r\nPython version:\r\n    `Python 2.7.10`\r\nBazel version (if compiling from source):\r\n    `Build label: 0.22.0`\r\nGCC/Compiler version (if compiling from source):\r\n```\r\nConfigured with: --prefix=/Applications/Xcode.app/Contents/Developer/usr --with-gxx-include-dir=/usr/include/c++/4.2.1\r\nApple LLVM version 10.0.0 (clang-1000.11.45.5)\r\nTarget: x86_64-apple-darwin18.2.0\r\nThread model: posix\r\nInstalledDir: /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/usr/bin\r\n```    \r\nCUDA/cuDNN version:\r\n    N/A\r\nGPU model and memory:\r\n    N/A\r\nExact command to reproduce:\r\n\r\nI trained a custom model based on MobileNetV2 with a fews convolution layers and fully connected layer on top to output ranking score of input images. I tried to convert the model to tflite for running on iOS, but found that the output values of tflite model are different from origin model even with same inputs. Same behaviour is observed for tflite interpreter for iOS and python and also bazel-tools. Models trained with different input size of MobileNetV2 (224, 160, 96) also produce similar behaviour.\r\n\r\nI suppose the output values for tflite and original tensorflow model should output the same value?\r\n\r\nthe following link is a zip of the models files and output uploaded onto google drive\r\nhttps://drive.google.com/file/d/1tZVQk7kk5fCEnvnvOjZs1oF0y6YDLfOc/view?usp=sharing\r\n\r\n```\r\n# path variables\r\n\r\nCKPT_META_PATH=checkpoints/mvfn_096.ckpt-15000.meta\r\nCKPT_WEIGHT_PATH=checkpoints/mvfn_096.ckpt-15000\r\nFROZEN_PB_PATH=mvfn_096.pb\r\nTFLITE_PATH=mvfn_096.tflite\r\nTB_PATH=tb_log\r\nTFLITE_VIS_HTML_PATH=mvfn_096_tflite.html\r\nINPUT_IMAGE_SIZE=96\r\nTF_PATH=\"\" # path to tensorflow repo\r\n```\r\n```\r\n# freeze graph\r\n\r\npython ${TF_PATH}/tensorflow/python/tools/freeze_graph.py \\\r\n    --input_binary=true \\\r\n    --input_meta_graph=${CKPT_META_PATH} \\\r\n    --input_checkpoint=${CKPT_WEIGHT_PATH} \\\r\n    --output_graph=${FROZEN_PB_PATH} \\\r\n    --output_node_names=\"ranker/score_func\"\r\n```\r\n```\r\n# convert pb to tflite\r\n\r\nbazel run tensorflow/lite/toco:toco -- \\\r\n    --input_file=${FROZEN_PB_PATH} \\\r\n    --input_format=${TENSORFLOW_GRAPHDEF} \\\r\n    --output_file=TFLITE_PATH \\\r\n    --output_format=TFLITE \\\r\n    --inference_type=FLOAT \\\r\n    --inference_input_type=FLOAT \\\r\n    --input_arrays=input_image \\\r\n    --output_arrays=\"ranker/score_func\" \\\r\n    --input_shapes=1,${INPUT_IMAGE_SIZE},${INPUT_IMAGE_SIZE},3                # fix input batch size to 1\r\n```\r\n\r\n```\r\n# pb to tensorboard for visualization\r\n\r\npython ${TF_PATH}/tensorflow/python/tools/import_pb_to_tensorboard.py \\\r\n    --model_dir=${FROZEN_PB_PATH} \\\r\n    --log_dir=${TB_PATH}\r\n```\r\n```\r\n# visualize tflite\r\n\r\nbazel run tensorflow/lite/tools:visualize -- ${TFLITE_PATH} ${TFLITE_VIS_HTML_PATH}\r\n```\r\n\r\n```\r\n# diff tflite & pb\r\n\r\nbazel run tensorflow/lite/testing:tflite_diff_example_test -- \\\r\n    --tensorflow_model=${FROZEN_PB_PATH} \\\r\n    --tflite_model=${TFLITE_PATH} \\\r\n    --input_layer=\"input_image\" \\\r\n    --input_layer_type=float \\\r\n    --input_layer_shape=1,${INPUT_IMAGE_SIZE},${INPUT_IMAGE_SIZE},3 \\\r\n    --output_layer=\"ranker/score_func\"\r\n```\r\n```\r\n# output of tflite_diff_example_test\r\n# pb model and tflite model have different output values\r\n\r\n2019-02-25 05:34:28.723184: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.2 AVX AVX2 FMA\r\nThere were errors in invocation '', output tensor '170':\r\n  index 0: got 1.76843, but expected -4.20755\r\nThere were errors in invocation '', output tensor '170':\r\n  index 0: got 0.762267, but expected -3.9918\r\nThere were errors in invocation '', output tensor '170':\r\n  index 0: got 0.110205, but expected -4.65119\r\nThere were errors in invocation '', output tensor '170':\r\n  index 0: got 1.10238, but expected -4.45592\r\nThere were errors in invocation '', output tensor '170':\r\n  index 0: got 1.5811, but expected -4.54539\r\nThere were errors in invocation '', output tensor '170':\r\n  index 0: got 1.34377, but expected -4.36198\r\nThere were errors in invocation '', output tensor '170':\r\n  index 0: got 1.87406, but expected -4.3289\r\nThere were errors in invocation '', output tensor '170':\r\n  index 0: got 2.33834, but expected -4.49968\r\nThere were errors in invocation '', output tensor '170':\r\n  index 0: got 1.16959, but expected -4.78387\r\nThere were errors in invocation '', output tensor '170':\r\n  index 0: got 1.22668, but expected -4.53048\r\nThere were errors in invocation '', output tensor '170':\r\n  index 0: got 0.570301, but expected -4.27984\r\nThere were errors in invocation '', output tensor '170':\r\n  index 0: got -0.875985, but expected -4.32995\r\n```\r\n\r\n", "comments": ["I figured I made a mistake during step of freezing graph. My network is based on slim's mobilenet_v2 which contains batch_norm operations. My checkpoints' meta is saved with graph where `is_training=True`. The output `pb` file skipped all `moving_mean` and `moving_variance` in batch_norm operations. Somehow the `tflite` file generated from this pb file yields different values. \r\n\r\nMy solution was to reconstruct graph with `is_training=False`, then load my checkpoint weight, and convert to `pb` and `tflite` in python. Then inference by checkpoint, `pb`, and `tflite` return consistant values.\r\n```\r\n# snipplet of my model\r\n# when training set is_training=True\r\n# when infer or freeze graph set is_training=False\r\ndef build_model(is_training):\r\n    images = tf.PlaceHolder() # for input images\r\n    with tf.contrib.slim.arg_scope(mobilenet_v2.training_scope(is_training=is_training)):\r\n        _, endpoints = mobilenet_v2.mobilenet(images)\r\n    feature_map = endpoints['layer_19'] # select middle layer as feature map\r\n    score = some_other_layers(feature_map)\r\n    return score\r\n```\r\n```\r\n# ckpt to pb & tflite\r\nwith tf.Session() as sess:\r\n    build_model(is_training=False)\r\n    saver = tf.train.Saver(tf.global_variables())\r\n\r\n    # Load weights\r\n    saver.restore(sess, weight_path)\r\n\r\n    # Freeze the graph\r\n    frozen_graph_def = tf.graph_util.convert_variables_to_constants(\r\n        sess,\r\n        sess.graph_def,\r\n        output_node_names)\r\n\r\n    # Save the frozen graph\r\n    with open(pb_path, 'wb') as f:\r\n      f.write(frozen_graph_def.SerializeToString())\r\n\r\nif tf.__version__[:4] == \"1.13\":\r\n  converter = tf.lite.TFLiteConverter.from_frozen_graph(\r\n    pb_path, input_node_names, output_node_names, \r\n      input_shapes=input_shapes)\r\nelse:\r\n  converter = tf.contrib.lite.TFLiteConverter.from_frozen_graph(\r\n    pb_path, input_node_names, output_node_names, \r\n      input_shapes=input_shapes)\r\ntflite_model = converter.convert()\r\nopen(tflite_path, \"wb\").write(tflite_model)\r\n```\r\n\r\n\r\nHowever, I still don't understand why the `pb` and `tflite` yields different values given that the batch_norm should be (falsely) fixated by `freeze_graph.py`. Also would it be possible to add checking in `freeze_graph.py` to warn user about the `is_training` thing?", "Load balance to @karimnosseir -- could you take a look?", "Hi chrisfan918,\r\n\r\nCan you share the pb and tflite files after your freeze graph fix.\r\n\r\nThanks", "@karimnosseir here are the pb, tflite, ckpt files \r\nhttps://drive.google.com/file/d/1-sjLKab-RMlj5GRVmirvifltNPWtnqJy/view?usp=sharing\r\n\r\nNote that the ckpt is different from previous uploaded ckpt. As I have made some minor namespace changes in `some_other_layers` and retrained since the fix, and it is a bit complex to recover the exact model code of previous version. But the graph should be more or less the same.", "Hi chrisfan918,\r\n\r\nSorry for late reply as i was out of office. Trying on some random data. I can see the outputs are matching up to 1e-5. \r\nWhat is the difference that you see ? is it more/less than this\r\n\r\nThanks", "Issue is stale. Closing.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=26075\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=26075\">No</a>\n"]}, {"number": 26074, "title": "tf.spectral.dct length argument not implemented", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using):\r\n1.12.0\r\n- Are you willing to contribute it (Yes/No):\r\nYes\r\n\r\n**Describe the feature and the current behavior/state.**\r\ntf.spectral.dct has parameter \"n\" which is length of the transform. In https://github.com/tensorflow/tensorflow/blob/a68fec0c77a4c99d4306cd3e987b4f6f548a8112/tensorflow/python/ops/signal/dct_ops.py#L33~L34, It seems it is not implemented when it is not None. Is there any detailed plan to implement this?\r\n\r\n**Will this change the current api? How?**\r\nNo.\r\n\r\n**Who will benefit with this feature?**\r\n\r\n**Any Other info.**\r\n", "comments": ["I have no immediate plans to implement this (though it's been on my TODO list for a long time), and would welcome a community contribution to add it! The underlying RFFT op supports a length parameter so it should be fairly easy.", "@rryan I can have a look at this if its open. Would like to contribute and request if you can assign this to me! \r\n", "@rryan working on this issue and will raise a PR soon.", "@rryan this issue can be closed as the above PR is approved.", "Close the issue as the PR has been merged."]}, {"number": 26073, "title": " no such attribute 'downloaded_file_path' in 'http_file' rule", "body": "\r\n**System information**\r\n- OS Platform and Distribution :Linux Ubuntu 16.04\r\n- TensorFlow installed from :source code\r\n- TensorFlow version:https://github.com/tensorflow/tensorflow\r\n- Installed using bazel(bazel build tensorflow/cc:cc_ops):\r\n- Bazel version (0.15.0):\r\n- GCC/Compiler version (5.4.0):\r\n**Describe the problem**\r\nwhen i use bazel(bazel build tensorflow/cc:cc_ops) to buid the tensorflow source code from \"https://github.com/tensorflow/tensorflow\",there is some error as below:\r\nWARNING: while reading option defaults file '/home/luwei/ML/tensorflow/tensorflow-master/.bazelrc':\r\n  invalid command name 'try-import'.\r\nWARNING: while reading option defaults file '/home/luwei/ML/tensorflow/tensorflow-master/.bazelrc':\r\n  invalid command name 'try-import'.\r\nERROR: /home/luwei/.cache/bazel/_bazel_luwei/496db56b93dce7ae9ba21590959da509/external/bazel_toolchains/repositories/repositories.bzl:101:9: //external:bazel_gpg: no such attribute 'downloaded_file_path' in 'http_file' rule\r\nERROR: /home/luwei/.cache/bazel/_bazel_luwei/496db56b93dce7ae9ba21590959da509/external/bazel_toolchains/repositories/repositories.bzl:110:9: //external:docker_gpg: no such attribute 'downloaded_file_path' in 'http_file' rule\r\nERROR: /home/luwei/.cache/bazel/_bazel_luwei/496db56b93dce7ae9ba21590959da509/external/bazel_toolchains/repositories/repositories.bzl:119:9: //external:gcloud_gpg: no such attribute 'downloaded_file_path' in 'http_file' rule\r\nERROR: /home/luwei/.cache/bazel/_bazel_luwei/496db56b93dce7ae9ba21590959da509/external/bazel_toolchains/repositories/repositories.bzl:128:9: //external:launchpad_openjdk_gpg: no such attribute 'downloaded_file_path' in 'http_file' rule\r\nERROR: /home/luwei/.cache/bazel/_bazel_luwei/496db56b93dce7ae9ba21590959da509/external/bazel_toolchains/repositories/repositories.bzl:138:9: //external:golang_release: no such attribute 'downloaded_file_path' in 'http_file' rule\r\nERROR: /home/luwei/.cache/bazel/_bazel_luwei/496db56b93dce7ae9ba21590959da509/external/bazel_toolchains/repositories/repositories.bzl:147:9: //external:debian8_clang_release: no such attribute 'downloaded_file_path' in 'http_file' rule\r\nERROR: /home/luwei/.cache/bazel/_bazel_luwei/496db56b93dce7ae9ba21590959da509/external/bazel_toolchains/repositories/repositories.bzl:155:9: //external:ubuntu16_04_clang_release: no such attribute 'downloaded_file_path' in 'http_file' rule\r\nERROR: /home/luwei/.cache/bazel/_bazel_luwei/496db56b93dce7ae9ba21590959da509/external/bazel_toolchains/repositories/repositories.bzl:164:9: //external:debian8_libcxx_release: no such attribute 'downloaded_file_path' in 'http_file' rule\r\nERROR: /home/luwei/.cache/bazel/_bazel_luwei/496db56b93dce7ae9ba21590959da509/external/bazel_toolchains/repositories/repositories.bzl:172:9: //external:ubuntu16_04_libcxx_release: no such attribute 'downloaded_file_path' in 'http_file' rule\r\nERROR: /home/luwei/.cache/bazel/_bazel_luwei/496db56b93dce7ae9ba21590959da509/external/bazel_toolchains/repositories/repositories.bzl:184:13: //external:bazel_0141_installer: no such attribute 'downloaded_file_path' in 'http_file' rule\r\nERROR: /home/luwei/.cache/bazel/_bazel_luwei/496db56b93dce7ae9ba21590959da509/external/bazel_toolchains/repositories/repositories.bzl:184:13: //external:bazel_0150_installer: no such attribute 'downloaded_file_path' in 'http_file' rule\r\nERROR: /home/luwei/.cache/bazel/_bazel_luwei/496db56b93dce7ae9ba21590959da509/external/bazel_toolchains/repositories/repositories.bzl:184:13: //external:bazel_0152_installer: no such attribute 'downloaded_file_path' in 'http_file' rule\r\nERROR: /home/luwei/.cache/bazel/_bazel_luwei/496db56b93dce7ae9ba21590959da509/external/bazel_toolchains/repositories/repositories.bzl:184:13: //external:bazel_0161_installer: no such attribute 'downloaded_file_path' in 'http_file' rule\r\nERROR: /home/luwei/.cache/bazel/_bazel_luwei/496db56b93dce7ae9ba21590959da509/external/bazel_toolchains/repositories/repositories.bzl:184:13: //external:bazel_0171_installer: no such attribute 'downloaded_file_path' in 'http_file' rule\r\nERROR: /home/luwei/.cache/bazel/_bazel_luwei/496db56b93dce7ae9ba21590959da509/external/bazel_toolchains/repositories/repositories.bzl:184:13: //external:bazel_0172_installer: no such attribute 'downloaded_file_path' in 'http_file' rule\r\nERROR: /home/luwei/.cache/bazel/_bazel_luwei/496db56b93dce7ae9ba21590959da509/external/bazel_toolchains/repositories/repositories.bzl:184:13: //external:bazel_0180_installer: no such attribute 'downloaded_file_path' in 'http_file' rule\r\nERROR: /home/luwei/.cache/bazel/_bazel_luwei/496db56b93dce7ae9ba21590959da509/external/bazel_toolchains/repositories/repositories.bzl:184:13: //external:bazel_0181_installer: no such attribute 'downloaded_file_path' in 'http_file' rule\r\nERROR: /home/luwei/.cache/bazel/_bazel_luwei/496db56b93dce7ae9ba21590959da509/external/bazel_toolchains/repositories/repositories.bzl:184:13: //external:bazel_0190_installer: no such attribute 'downloaded_file_path' in 'http_file' rule\r\nERROR: /home/luwei/.cache/bazel/_bazel_luwei/496db56b93dce7ae9ba21590959da509/external/bazel_toolchains/repositories/repositories.bzl:184:13: //external:bazel_0192_installer: no such attribute 'downloaded_file_path' in 'http_file' rule\r\nERROR: /home/luwei/.cache/bazel/_bazel_luwei/496db56b93dce7ae9ba21590959da509/external/bazel_toolchains/repositories/repositories.bzl:184:13: //external:bazel_0200_installer: no such attribute 'downloaded_file_path' in 'http_file' rule\r\nERROR: /home/luwei/.cache/bazel/_bazel_luwei/496db56b93dce7ae9ba21590959da509/external/bazel_toolchains/repositories/repositories.bzl:184:13: //external:bazel_0210_installer: no such attribute 'downloaded_file_path' in 'http_file' rule\r\nERROR: /home/luwei/.cache/bazel/_bazel_luwei/496db56b93dce7ae9ba21590959da509/external/bazel_toolchains/repositories/repositories.bzl:196:9: //external:azul_open_jdk: no such attribute 'downloaded_file_path' in 'http_file' rule\r\nERROR: /home/luwei/.cache/bazel/_bazel_luwei/496db56b93dce7ae9ba21590959da509/external/bazel_toolchains/repositories/repositories.bzl:204:9: //external:azul_open_jdk_src: no such attribute 'downloaded_file_path' in 'http_file' rule\r\nERROR: error loading package '': Encountered error while reading extension file 'repositories/repositories.bzl': no such package '@io_bazel_rules_docker//repositories': error loading package 'external': Could not load //external package\r\nERROR: error loading package '': Encountered error while reading extension file 'repositories/repositories.bzl': no such package '@io_bazel_rules_docker//repositories': error loading package 'external': Could not load //external package\r\nINFO: Elapsed time: 0.051s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nbazel build tensorflow/cc:cc_ops\r\n\r\n**Any other info / logs**\r\n  no!", "comments": ["You need a newer version of Bazel to build TensorFlow. Please follow the instructions at https://www.tensorflow.org/install/source: when you run the `./configure` script, it will tell you if your version of Bazel can be used to build TF (right now, the minimum version is `0.19.0`)."]}, {"number": 26072, "title": "docker tensorflow-tensorflow/latest-gpu slow initialisation of GPU", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution: Ubuntu 16.04\r\nUsing Docker (latest-gpu image)\r\n- Mobile Device: No\r\n- TensorFlow installed from (source or binary): N/A\r\n- TensorFlow version: 1.13.0-rc1\r\n- Python version:  Python 3.5.2\r\n- Installed using virtualenv? pip? conda?: N/A\r\n- Bazel version (if compiling from source): N/A\r\n- GCC/Compiler version (if compiling from source): N/A\r\n- CUDA/cuDNN version:\r\nnvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2018 NVIDIA Corporation\r\nBuilt on Sat_Aug_25_21:08:01_CDT_2018\r\nCuda compilation tools, release 10.0, V10.0.130\r\n- GPU model and memory: Quadro M1200 \r\n\r\n```\r\n==============NVSMI LOG==============\r\n\r\nTimestamp                           : Mon Feb 25 00:50:20 2019\r\nDriver Version                      : 410.78\r\nCUDA Version                        : 10.0\r\n\r\nAttached GPUs                       : 1\r\nGPU 00000000:01:00.0\r\n    Product Name                    : Quadro M1200\r\n    Product Brand                   : Quadro\r\n    Display Mode                    : Disabled\r\n    Display Active                  : Disabled\r\n    Persistence Mode                : Enabled\r\n    Accounting Mode                 : Disabled\r\n    Accounting Mode Buffer Size     : 4000\r\n    Driver Model\r\n        Current                     : N/A\r\n        Pending                     : N/A\r\n    Serial Number                   : N/A\r\n    GPU UUID                        : GPU-d9093d17-7927-a053-9104-426e68b1d4ac\r\n    Minor Number                    : 0\r\n    VBIOS Version                   : 82.07.BB.00.13\r\n    MultiGPU Board                  : No\r\n    Board ID                        : 0x100\r\n    GPU Part Number                 : N/A\r\n    Inforom Version\r\n        Image Version               : N/A\r\n        OEM Object                  : N/A\r\n        ECC Object                  : N/A\r\n        Power Management Object     : N/A\r\n    GPU Operation Mode\r\n        Current                     : N/A\r\n        Pending                     : N/A\r\n    GPU Virtualization Mode\r\n        Virtualization mode         : None\r\n    IBMNPU\r\n        Relaxed Ordering Mode       : N/A\r\n    PCI\r\n        Bus                         : 0x01\r\n        Device                      : 0x00\r\n        Domain                      : 0x0000\r\n        Device Id                   : 0x13B610DE\r\n        Bus Id                      : 00000000:01:00.0\r\n        Sub System Id               : 0x224D17AA\r\n        GPU Link Info\r\n            PCIe Generation\r\n                Max                 : 3\r\n                Current             : 3\r\n            Link Width\r\n                Max                 : 16x\r\n                Current             : 16x\r\n        Bridge Chip\r\n            Type                    : N/A\r\n            Firmware                : N/A\r\n        Replays since reset         : 0\r\n        Tx Throughput               : 0 KB/s\r\n        Rx Throughput               : 0 KB/s\r\n    Fan Speed                       : N/A\r\n    Performance State               : P0\r\n    Clocks Throttle Reasons\r\n        Idle                        : Not Active\r\n        Applications Clocks Setting : Active\r\n        SW Power Cap                : Not Active\r\n        HW Slowdown                 : Not Active\r\n            HW Thermal Slowdown     : N/A\r\n            HW Power Brake Slowdown : N/A\r\n        Sync Boost                  : Not Active\r\n        SW Thermal Slowdown         : Not Active\r\n        Display Clock Setting       : Not Active\r\n    FB Memory Usage\r\n        Total                       : 4043 MiB\r\n        Used                        : 3813 MiB\r\n        Free                        : 230 MiB\r\n    BAR1 Memory Usage\r\n        Total                       : 256 MiB\r\n        Used                        : 3 MiB\r\n        Free                        : 253 MiB\r\n    Compute Mode                    : Default\r\n    Utilization\r\n        Gpu                         : 0 %\r\n        Memory                      : 0 %\r\n        Encoder                     : 0 %\r\n        Decoder                     : 0 %\r\n    Encoder Stats\r\n        Active Sessions             : 0\r\n        Average FPS                 : 0\r\n        Average Latency             : 0\r\n    FBC Stats\r\n        Active Sessions             : 0\r\n        Average FPS                 : 0\r\n        Average Latency             : 0\r\n    Ecc Mode\r\n        Current                     : N/A\r\n        Pending                     : N/A\r\n    ECC Errors\r\n        Volatile\r\n            Single Bit            \r\n                Device Memory       : N/A\r\n                Register File       : N/A\r\n                L1 Cache            : N/A\r\n                L2 Cache            : N/A\r\n                Texture Memory      : N/A\r\n                Texture Shared      : N/A\r\n                CBU                 : N/A\r\n                Total               : N/A\r\n            Double Bit            \r\n                Device Memory       : N/A\r\n                Register File       : N/A\r\n                L1 Cache            : N/A\r\n                L2 Cache            : N/A\r\n                Texture Memory      : N/A\r\n                Texture Shared      : N/A\r\n                CBU                 : N/A\r\n                Total               : N/A\r\n        Aggregate\r\n            Single Bit            \r\n                Device Memory       : N/A\r\n                Register File       : N/A\r\n                L1 Cache            : N/A\r\n                L2 Cache            : N/A\r\n                Texture Memory      : N/A\r\n                Texture Shared      : N/A\r\n                CBU                 : N/A\r\n                Total               : N/A\r\n            Double Bit            \r\n                Device Memory       : N/A\r\n                Register File       : N/A\r\n                L1 Cache            : N/A\r\n                L2 Cache            : N/A\r\n                Texture Memory      : N/A\r\n                Texture Shared      : N/A\r\n                CBU                 : N/A\r\n                Total               : N/A\r\n    Retired Pages\r\n        Single Bit ECC              : N/A\r\n        Double Bit ECC              : N/A\r\n        Pending                     : N/A\r\n    Temperature\r\n        GPU Current Temp            : 37 C\r\n        GPU Shutdown Temp           : N/A\r\n        GPU Slowdown Temp           : 96 C\r\n        GPU Max Operating Temp      : 92 C\r\n        Memory Current Temp         : N/A\r\n        Memory Max Operating Temp   : N/A\r\n    Power Readings\r\n        Power Management            : N/A\r\n        Power Draw                  : N/A\r\n        Power Limit                 : N/A\r\n        Default Power Limit         : N/A\r\n        Enforced Power Limit        : N/A\r\n        Min Power Limit             : N/A\r\n        Max Power Limit             : N/A\r\n    Clocks\r\n        Graphics                    : 993 MHz\r\n        SM                          : 993 MHz\r\n        Memory                      : 2505 MHz\r\n        Video                       : 893 MHz\r\n    Applications Clocks\r\n        Graphics                    : N/A\r\n        Memory                      : N/A\r\n    Default Applications Clocks\r\n        Graphics                    : N/A\r\n        Memory                      : N/A\r\n    Max Clocks\r\n        Graphics                    : 1150 MHz\r\n        SM                          : 1150 MHz\r\n        Memory                      : 2505 MHz\r\n        Video                       : 1035 MHz\r\n    Max Customer Boost Clocks\r\n        Graphics                    : N/A\r\n    Clock Policy\r\n        Auto Boost                  : N/A\r\n        Auto Boost Default          : N/A\r\n    Processes\r\n        Process ID                  : 1123\r\n            Type                    : G\r\n            Name                    : /usr/lib/xorg/Xorg\r\n            Used GPU Memory         : 8 MiB\r\n        Process ID                  : 31763\r\n            Type                    : C\r\n            Name                    : python\r\n            Used GPU Memory         : 3791 MiB\r\n```\r\n\r\n**Describe the problem**\r\n\r\nWhen using my GPU, it takes several minutes (just over 4 minutes) to initialise to do anything. Issue does not exist when using CPU\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n`docker run -it -u $(id -u):$(id -g) --runtime=nvidia -v $(realpath ~/tensorflow):/tf/tensorflow tensorflow/tensorflow:latest-gpu bash`\r\n\r\n`python test.py`\r\n\r\ncontents of test.py:\r\n\r\n```\r\nimport tensorflow as tf\r\nmnist = tf.keras.datasets.mnist\r\n\r\n(x_train, y_train),(x_test, y_test) = mnist.load_data()\r\nx_train, x_test = x_train / 255.0, x_test / 255.0\r\n\r\nmodel = tf.keras.models.Sequential([\r\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\r\n  tf.keras.layers.Dense(512, activation=tf.nn.relu),\r\n  tf.keras.layers.Dropout(0.2),\r\n  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\r\n])\r\nmodel.compile(optimizer='adam',\r\n              loss='sparse_categorical_crossentropy',\r\n              metrics=['accuracy'])\r\n\r\nmodel.fit(x_train, y_train, epochs=5)\r\nmodel.evaluate(x_test, y_test)\r\n```\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nlogs while running test script\r\n```\r\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\r\n11493376/11490434 [==============================] - 0s 0us/step\r\n11501568/11490434 [==============================] - 0s 0us/step\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nColocations handled automatically by placer.\r\nWARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\r\n2019-02-25 05:46:52.561440: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-02-25 05:46:52.628689: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-02-25 05:46:52.629997: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x50be7d0 executing computations on platform CUDA. Devices:\r\n2019-02-25 05:46:52.630035: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Quadro M1200, Compute Capability 5.0\r\n2019-02-25 05:46:52.664820: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2808000000 Hz\r\n2019-02-25 05:46:52.666234: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5128500 executing computations on platform Host. Devices:\r\n2019-02-25 05:46:52.666318: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\r\n2019-02-25 05:46:52.666979: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \r\nname: Quadro M1200 major: 5 minor: 0 memoryClockRate(GHz): 1.148\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 3.95GiB freeMemory: 3.90GiB\r\n2019-02-25 05:46:52.667052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\r\n2019-02-25 05:46:52.669065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-02-25 05:46:52.669122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \r\n2019-02-25 05:46:52.669152: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \r\n2019-02-25 05:46:52.669563: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3696 MB memory) -> physical GPU (device: 0, name: Quadro M1200, pci bus id: 0000:01:00.0, compute capability: 5.0)\r\nEpoch 1/5\r\n2019-02-25 05:51:01.254939: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\r\n60000/60000 [==============================] - 5s 84us/sample - loss: 0.2207 - acc: 0.9348\r\nEpoch 2/5\r\n60000/60000 [==============================] - 5s 79us/sample - loss: 0.0960 - acc: 0.9714\r\nEpoch 3/5\r\n60000/60000 [==============================] - 5s 78us/sample - loss: 0.0697 - acc: 0.9774\r\nEpoch 4/5\r\n60000/60000 [==============================] - 5s 79us/sample - loss: 0.0536 - acc: 0.9826\r\nEpoch 5/5\r\n60000/60000 [==============================] - 5s 76us/sample - loss: 0.0430 - acc: 0.9857\r\n10000/10000 [==============================] - 0s 29us/sample - loss: 0.0606 - acc: 0.9813\r\n```", "comments": ["@KaramAbuaisha \r\nThank you for your post. We noticed you have not filled out the fields in the issue [template](https://github.com/tensorflow/tensorflow/issues/new?template=10-build-installation-issue.md). Could you update them if they are relevant in your case, or leave them as N/A? Along with the template, please provide as many details as possible to find the root cause of the issue. Thanks!", "I updated the issue, please let me know if there's any important information missing ", "Is this the wrong place to ask about this problem?", "Thanks for the detailed instructions but I couldn't reproduce the issue on Volta GPUs.\r\n\r\nI suspect that this could be because we don't specify compute compatibility 5.0 required for Quadro M1200 GPU and this results in JIT compilation.\r\n\r\nCould you try building a custom docker after adding '5.0' in the list and see if that resolves the problem?\r\nhttps://github.com/tensorflow/tensorflow/blob/1c1c24c76b87fcaf3295f631a17124302dccdf95/tensorflow/tools/dockerfiles/dockerfiles/devel-gpu.Dockerfile#L78", "How do I build the custom docker exactly?\r\nI tried something that didn't work:\r\nI pulled this repo, edited the devel-gpu.Dockerfile as recommended and then built the image by executing `docker build -f ./dockerfiles/cpu.Dockerfile -t tf . ` from `tensorflow/tensorflow/tools/dockerfiles`\r\nThen I made a container like so: `sudo docker run --name test -it -u $(id -u):$(id -g) --runtime=nvidia -v $(realpath ~/tensorflow):/tf/tensorflow -p 8888:8888 tf:latest bash`\r\nBut when I tried running the script, I got the following error:\r\n```\r\nTraceback (most recent call last):\r\n  File \"test.py\", line 1, in <module>\r\n    import tensorflow as tf\r\nImportError: No module named tensorflow\r\n```\r\n", "I think I figured out how, I edited this file `/tensorflow/tools/dockerfiles/partials/ubuntu/devel-nvidia.partial.Dockerfile` to include 5.0 in `ENV TF_CUDA_COMPUTE_CAPABILITIES` and I then executed the following\r\n\r\n```\r\n# Build the tools-helper image so you can run the assembler\r\n$ docker build -t tf-tools -f tools.Dockerfile .\r\n\r\n# Set --user to set correct permissions on generated files\r\n$ docker run --user $(id -u):$(id -g) -it -v $(pwd):/tf tf-tools bash\r\n\r\n# Next you can make a handy alias depending on what you're doing. When building\r\n# Docker images, you need to run as root with docker.sock mounted so that the\r\n# container can run Docker commands. When assembling Dockerfiles, though, you'll\r\n# want to run as your user so that new files have the right permissions.\r\n\r\n# If you're BUILDING OR DEPLOYING DOCKER IMAGES, run as root with docker.sock:\r\n$ alias asm_images=\"docker run --rm -v $(pwd):/tf -v /var/run/docker.sock:/var/run/docker.sock tf-tools python3 assembler.py \"\r\n\r\n# If you're REBUILDING OR ADDING DOCKERFILES, remove docker.sock and add -u:\r\n$ alias asm_dockerfiles=\"docker run --rm -u $(id -u):$(id -g) -v $(pwd):/tf tf-tools python3 assembler.py \"\r\n\r\n# Check assembler flags\r\n$ asm_dockerfiles --help\r\n\r\n# Assemble all of the Dockerfiles\r\n$ asm_dockerfiles --release dockerfiles --construct_dockerfiles\r\n\r\n# Build devel-gpu-py3 image\r\n$ asm_images --release nightly --build_images  --only_tags_matching=\"^devel-gpu-py3$\"\r\n```\r\n\r\nI was able to observe that the temporary docker file generated had 5.0 in the list of compute capabilities and confirmed again by running the command `docker history --no-trunc tensorflow:devel-gpu-py3` to find that it was listed in there as well. I then ran the same test file mentioned above and found that the issue was not fixed. It still takes 4 minutes to initialize the gpu, here are the logs\r\n\r\n```\r\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\r\n11493376/11490434 [==============================] - 0s 0us/step\r\nWARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nColocations handled automatically by placer.\r\nWARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\r\n2019-03-19 00:07:13.715853: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-03-19 00:07:13.783574: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-03-19 00:07:13.784535: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x48e23f0 executing computations on platform CUDA. Devices:\r\n2019-03-19 00:07:13.784555: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Quadro M1200, Compute Capability 5.0\r\n2019-03-19 00:07:13.802868: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2808000000 Hz\r\n2019-03-19 00:07:13.804070: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x494c120 executing computations on platform Host. Devices:\r\n2019-03-19 00:07:13.804136: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\r\n2019-03-19 00:07:13.804578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \r\nname: Quadro M1200 major: 5 minor: 0 memoryClockRate(GHz): 1.148\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 3.95GiB freeMemory: 3.90GiB\r\n2019-03-19 00:07:13.804632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\r\n2019-03-19 00:07:13.806202: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-03-19 00:07:13.806249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \r\n2019-03-19 00:07:13.806278: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \r\n2019-03-19 00:07:13.806642: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3696 MB memory) -> physical GPU (device: 0, name: Quadro M1200, pci bus id: 0000:01:00.0, compute capability: 5.0)\r\nEpoch 1/5\r\n2019-03-19 00:11:15.093862: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\r\n60000/60000 [==============================] - 6s 105us/sample - loss: 0.2203 - acc: 0.9341\r\nEpoch 2/5\r\n60000/60000 [==============================] - 5s 82us/sample - loss: 0.0978 - acc: 0.9689\r\nEpoch 3/5\r\n60000/60000 [==============================] - 5s 79us/sample - loss: 0.0691 - acc: 0.9772\r\nEpoch 4/5\r\n60000/60000 [==============================] - 5s 78us/sample - loss: 0.0526 - acc: 0.9827\r\nEpoch 5/5\r\n60000/60000 [==============================] - 5s 78us/sample - loss: 0.0440 - acc: 0.9856\r\n10000/10000 [==============================] - 0s 30us/sample - loss: 0.0621 - acc: 0.9805\r\n```", "Could you set TF_CPP_MIN_VLOG_LEVEL environment variable to 10 using the following in python?\r\nos.environ['TF_CPP_MIN_VLOG_LEVEL'] = '10'\r\n\r\nThis might help us understand what it is doing between the timestamp '00:07:13.806642' and '00:11:15.093862'?\r\n\r\nAlso, It seems that some of the users are not having this issue with TensorFlow 2.0 nightly. See,\r\nhttps://github.com/tensorflow/tensorflow/issues/18652#issuecomment-474471312", "Sorry I actually made a mistake earlier, I still get the error `ImportError: No module named 'tensorflow'\r\n`", "I was actually in the wrong docker container when I tested it again and got the results above", "The commands to build dockerfiles seem correct to me but we need to use \"devel-gpu.Dockerfile\" Dockerfile while building the docker. ", "Even if I make no changes at all, I get the same import error as above so I must be doing something wrong", "Could you confirm that you are editing devel-gpu.Dockerfile file and then running the following command? \r\n`docker build -t tf-tools -f dockerfiles/devel-gpu.Dockerfile`\r\n\r\n(The script you posted has tools.Dockerfile and not devel-gpu.Dockerfile that we need to use.)\r\n\r\nIf this still does not work, could you run it after setting TF_CPP_MIN_VLOG_LEVEL environment variable?", "I was running this command `docker run --rm -u $(id -u):$(id -g) -v $(pwd):/tf tf-tools python3 assembler.py --release nightly --build_images --run_tests_path=$(realpath tests) --only_tags_matching=\"^devel-gpu-py3$\"`\r\n\r\nI just tried `docker build -f dockerfiles/devel-gpu.Dockerfile . ` and it had the same import error as above\r\n```\r\ntf-docker / > python\r\nPython 2.7.12 (default, Nov 12 2018, 14:36:49) \r\n[GCC 5.4.0 20160609] on linux2\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nImportError: No module named tensorflow\r\n```", "Adding @tfboyd to see if he knows any obvious issue with building the docker.\r\n`docker build -f dockerfiles/devel-gpu.Dockerfile .`\r\n\r\nCould you try setting TF_CPP_MIN_VLOG_LEVEL environment variable with the default TensorFlow docker to see if that helps investigate?\r\n\r\nThis issue might have the same underlying issue as #18652. So marking this as duplicate to that one.\r\n\r\nDuplicate of #18652.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=26072\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=26072\">No</a>\n", "I changed test.py to\r\n```\r\nimport tensorflow as tf\r\nimport os\r\nos.environ['TF_CPP_MIN_VLOG_LEVEL'] = '10'\r\nmnist = tf.keras.datasets.mnist\r\n\r\n(x_train, y_train),(x_test, y_test) = mnist.load_data()\r\nx_train, x_test = x_train / 255.0, x_test / 255.0\r\n\r\nmodel = tf.keras.models.Sequential([\r\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\r\n  tf.keras.layers.Dense(512, activation=tf.nn.relu),\r\n  tf.keras.layers.Dropout(0.2),\r\n  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\r\n])\r\nmodel.compile(optimizer='adam',\r\n              loss='sparse_categorical_crossentropy',\r\n              metrics=['accuracy'])\r\n\r\nmodel.fit(x_train, y_train, epochs=5)\r\nmodel.evaluate(x_test, y_test)\r\n```\r\nThis was the output\r\n```\r\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\r\n11493376/11490434 [==============================] - 0s 0us/step\r\nWARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nColocations handled automatically by placer.\r\nWARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\r\n2019-03-21 05:36:55.633860: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2019-03-21 05:36:55.699545: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2019-03-21 05:36:55.700506: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x5250560 executing computations on platform CUDA. Devices:\r\n2019-03-21 05:36:55.700548: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): Quadro M1200, Compute Capability 5.0\r\n2019-03-21 05:36:55.720246: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2808000000 Hz\r\n2019-03-21 05:36:55.721723: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x52ba280 executing computations on platform Host. Devices:\r\n2019-03-21 05:36:55.721812: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\r\n2019-03-21 05:36:55.722328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \r\nname: Quadro M1200 major: 5 minor: 0 memoryClockRate(GHz): 1.148\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 3.95GiB freeMemory: 3.90GiB\r\n2019-03-21 05:36:55.722388: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0\r\n2019-03-21 05:36:55.724256: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2019-03-21 05:36:55.724307: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 \r\n2019-03-21 05:36:55.724333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N \r\n2019-03-21 05:36:55.724694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3696 MB memory) -> physical GPU (device: 0, name: Quadro M1200, pci bus id: 0000:01:00.0, compute capability: 5.0)\r\nEpoch 1/5\r\n2019-03-21 05:41:16.531234: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally\r\n60000/60000 [==============================] - 6s 98us/sample - loss: 0.2175 - acc: 0.9356\r\nEpoch 2/5\r\n60000/60000 [==============================] - 6s 93us/sample - loss: 0.0968 - acc: 0.9707\r\nEpoch 3/5\r\n60000/60000 [==============================] - 6s 93us/sample - loss: 0.0703 - acc: 0.9783\r\nEpoch 4/5\r\n60000/60000 [==============================] - 6s 93us/sample - loss: 0.0528 - acc: 0.9837\r\nEpoch 5/5\r\n60000/60000 [==============================] - 6s 93us/sample - loss: 0.0445 - acc: 0.9854\r\n10000/10000 [==============================] - 0s 39us/sample - loss: 0.0622 - acc: 0.9811\r\n```\r\n\r\nIt looks like there is no difference", "I do not believe that this is a duplicate of #18652 because my delay happens after the tensor flow device is created \r\n`2019-03-21 05:14:11.545978: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 3696 MB memory) -> physical GPU (device: 0, name: Quadro M1200, pci bus id: 0000:01:00.0, compute capability: 5.0)`\r\n\r\nand the first log afterwards is about the cudas library \r\n`2019-03-21 05:18:22.893314: I tensorflow/stream_executor/dso_loader.cc:152] successfully opened CUDA library libcublas.so.10.0 locally`\r\n\r\nwhile in the issue referenced, the delay happens after \r\n`2019-03-21 05:14:11.544914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0`", "I will investigate building of custom docker for TensorFlow.", "Any updates?", "I do not have a compute compatible device 5.0, but my random guess is the jit compilation.  If you are using docker directly as I expect you are, it will not get cached.  You can test this theory by doing docker interactively (enter with bash) and running the test test twice.  I run nightly tests much bigger than this and the total run time is under 6 minutes and it seems you have a 5 minute gap if I am reading the log correctly.\r\n\r\nThe compute we include should be:\r\nexport TF_CUDA_COMPUTE_CAPABILITIES=3.5,3.7,5.2,6.0,6.1,7.0\r\n\r\nOne solution, I think, is to run the docker interactive and then commit it.  I think that would then end up working like a workstation without docker.  The reasons we cannot do all of the compatibility versions is it makes the binary too large.  pypi has a limit of 50MB and we already talked them into 350MB.  Each compute is I think 15MB maybe more off the top of my head.", "I have been using docker interactively and I can confirm that that isn't the case. The 4 minute delay occurs everytime I run the script within my container. On the other hand though (if I recall correctly), If I launch a jupyter notebook, the 4 minute delay only occurs the first time fitting a model unless I restart the kernel.\r\n\r\nI'd like to try to build a docker with the correct compute capabilities but whenever I do I get the error I mentioned above \r\n```\r\ntf-docker / > python\r\nPython 2.7.12 (default, Nov 12 2018, 14:36:49) \r\n[GCC 5.4.0 20160609] on linux2\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\nImportError: No module named tensorflow\r\n```", "do you run:\r\n\r\n```bash\r\nnvidia-docker run -it -v <your workspace of code>:/workspace  your/docker/image bash\r\n```\r\nand then run the script twice.  Just asking to be 100% sure, especially due to your memory of the notebook experience.\r\n\r\nJust asking to be sure as I dealt with the compile issue in the past (2 years ago maybe) related to kaggle and due to my work flow never realized it was a problem.  I have no other ideas at the moment.  My nightly tests do not have that gap so I am not sure how to repro.  \r\n\r\nInteresting your notebook does not have the same issue.  Is the notebook local or running inside the Docker image.      \r\n", "I run \r\n`sudo docker run --name tensorflowgpu -it -u $(id -u):$(id -g) --runtime=nvidia -v $(realpath ~/tensorflow):/tf/tensorflow -p 127.0.0.1:8888:8888 tensorflow/tensorflow:latest-gpu-py3-jupyter bash`\r\nI just confirmed that both times I run the script it takes 4 minutes before it starts training. \r\nThe notebook is running inside the docker container and I ran all the cells in `tensorflow-tutorials/basic_classification.ipynb` The first time it took 4 minues before starting training but the second time I ran through (without restarting kernel) it started training immediately. If i restart the kernel I must wait 4 minutes before it starts training again. ", "That result is a strike against my wild theory.  Thank you for trying.\n\nOn Fri, Mar 29, 2019, 4:50 PM Karam Abuaisha <notifications@github.com>\nwrote:\n\n> I run\n> sudo docker run --name tensorflowgpu -it -u $(id -u):$(id -g)\n> --runtime=nvidia -v $(realpath ~/tensorflow):/tf/tensorflow -p\n> 127.0.0.1:8888:8888 tensorflow/tensorflow:latest-gpu-py3-jupyter bash\n> I just confirmed that both times I run the script it takes 4 minutes\n> before it starts training.\n> The notebook is running inside the docker container and I ran all the\n> cells in tensorflow-tutorials/basic_classification.ipynb The first time\n> it took 4 minues before starting training but the second time I ran through\n> (without restarting kernel) it started training immediately. If i restart\n> the kernel I must wait 4 minutes before it starts training again.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/26072#issuecomment-478181799>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AWZestndP1siBSGpeZKHQD-ypqzyNdK9ks5vbqa_gaJpZM4bPJbW>\n> .\n>\n", "> I will investigate building of custom docker for TensorFlow.\r\n\r\n@smit-hinsu were you able to figure out the reason I was having issues with building a custom docker for tensorflow?", "I got the same problem. It seems that it will only occurs in the first time running tensorflow-gpu, hence it is not a serious problem, you can just regard it as a initialization. \r\nThe problem is actually about docker. When you using docker, every time you run the code it will build a new container, hence need a new initialization. To solve the problem, you need commit you container as a new image after you got that delay (initialized).", "To me it happens every time I run the python script. The only time the initialization doesn't have to be repeated is if I'm on a jupyter notebook (unless I reset then kernel, then I have to initialize again)", "It depends whether you using a new container to run the python script. If so, it will need a new initialization. To use the initialized docker container: 1. Commit it, it will save all the changes you did to the container to a new image; (or)2. Use \"docker exec\" to repeatedly use the same container.", "Sorry I'm not being clear, I am not starting a new container when I run the script again. I start my docker like so `sudo docker run --name tensorflowgpu -it -u $(id -u):$(id -g) --runtime=nvidia -v $(realpath ~/tensorflow):/tf/tensorflow -p 127.0.0.1:8888:8888 tensorflow/tensorflow:latest-gpu-py3-jupyter bash` So that I am able to run scripts and start a jupyter notebook server if i like. Within the same instance of a container, when I run the script multiple times, there is no difference between each execution; \\ I always have the same problem where I must wait 4 minutes. The only time it doesn't repeat is when I run the same block of code within an ipython notebook and the kernel is not reset, only in that one case will the initialisation only happen once (until I reset the kernel). I figure it's because the my gpu compute version is not supported by default in the docker. I can't verify this because in the past when I tried to create my own custom docker, I've had tensorflow import errors (completely unrelated to the original issue) and I'm not sure what the reason for that is. ", "If you can confirm that you are using the same container, then my solution maybe useless for you. But I still have to mention something which maybe helpful. \r\n`docker run` is a command to build a **new** container. (if you don't know this, please search the difference between docker container and docker image)\r\nCheck by this:\r\n1. Run `sudo docker run --name tensorflowgpu -it -u $(id -u):$(id -g) --runtime=nvidia -v $(realpath ~/tensorflow):/tf/tensorflow -p 127.0.0.1:8888:8888 tensorflow/tensorflow:latest-gpu-py3-jupyter bash` to build the container, run you script, you will suffer initialization. The use run `exit` in the container bash to exit the container. \r\n2. After that, run `docker exec -it tensorflowgpu bash`, run you script again. In my case, the initialization no longer appear.\r\nIf this is not helpful, I have to say sorry for wasting your time.", "Yeah I'm aware, I meant that I tried building a new docker image following the steps [here](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/dockerfiles)\r\nbut when I built a container based on that image I found that I couldn't import the tensorflow module in python and I'm not sure why that occurred. More detail is provided in the previous comments in this thread. \r\n\r\n\r\n\r\n> How do I build the custom docker exactly?\r\n> I tried something that didn't work:\r\n> I pulled this repo, edited the devel-gpu.Dockerfile as recommended and then built the image by executing `docker build -f ./dockerfiles/cpu.Dockerfile -t tf . ` from `tensorflow/tensorflow/tools/dockerfiles`\r\n> Then I made a container like so: `sudo docker run --name test -it -u $(id -u):$(id -g) --runtime=nvidia -v $(realpath ~/tensorflow):/tf/tensorflow -p 8888:8888 tf:latest bash`\r\n> But when I tried running the script, I got the following error:\r\n> \r\n> ```\r\n> Traceback (most recent call last):\r\n>   File \"test.py\", line 1, in <module>\r\n>     import tensorflow as tf\r\n> ImportError: No module named tensorflow\r\n> ```\r\n\r\n", "I forgot to mention, when I attempt to install tensorflow inside the container based on my locally built image, I get this error \r\n```\r\nERROR: Could not install packages due to an EnvironmentError: [Errno 13] Permission denied: '/.local'\r\nCheck the permissions.\r\n```", "I was able to build tensorflow from source with the correct compute capabilities and it has solved my problem. Thanks for the help! ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=26072\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=26072\">No</a>\n"]}, {"number": 26071, "title": "readme format typo update", "body": "fix readme formating issue", "comments": ["Nagging Reviewer @mrry: You have been added as a reviewer to this pull request. Please add your review or reassign. It has been 14 days with no activity and the `awaiting review` label has been applied."]}]