[{"number": 48833, "title": "Performance Bug When Using CMake to Build TFLite r2.4 for Android (2x slower inference times than Bazel)", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: MediaTek X20 Development Board\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): r2.4\r\n- Python version: 3.6.9 (also happens on 3.9.4)\r\n- Bazel version (if compiling from source): 3.1.0\r\n- GCC/Compiler version (if compiling from source): 7.5.0\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nAfter building benchmark_model for Android and running it on my development board, I get an inference time on MobilenetV2_Quantized of about 240ms when using Bazel built benchmark_model but over 550ms when using CMake built benchmark_model.\r\n\r\n*Building is done on Ubuntu 18.04\r\n*MobilenetV2_Quant is from tflite hosted models (.tflite) https://www.tensorflow.org/lite/guide/hosted_models\r\n*Performance is measured on MediaTek A53 dev board running Android 7\r\n\r\n**Describe the expected behavior**\r\nbenchmark_model binary should have the same performance regardless of build system\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n*Clone Repo and Mkdir*\r\ngit clone https://github.com/tensorflow/tensorflow.git tensorflow_src\r\nmkdir tflite_build\r\n\r\n*CMake Build*\r\ncd tflite_build\r\ncmake -DCMAKE_TOOLCHAIN_FILE=/home/ubuntu/android-ndk-r21e/build/cmake/android.toolchain.cmake \\\r\n-DANDROID_ABI=armeabi-v7a -DANDROID_NATIVE_API_LEVEL=28 -DANDROID_ARM_NEON=ON \\\r\n-DCMAKE_BUILD_TYPE=Release ../tensorflow_src/tensorflow/lite\r\ncmake --build . -j -t benchmark_model\r\n\r\n*Bazel Build (in tensorflow_src dir)*\r\nbazel build -c opt --config=android_arm tensorflow/lite/tools/benchmark:benchmark_model\r\n\r\n*Running on Mediatek dev board*\r\nI adb push both benchmark_model binaries to my dev board and run them, but get drastically different speeds. The board uses A53 cores, hence the android_arm argument in Bazel and armeabi-v7a argument in CMake.\r\n\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\n", "comments": ["@terryheo @multiverse-tf could you take a look at this report?", "Could you try to enable RUY with \"-DTFLITE_ENABLE_RUY=ON\" ?\r\nAlso you can add more C flags likes \"-DCMAKE_C_FLAGS=-march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations\" and \"-DCMAKE_CXX_FLAGS=-march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations\"", "Hi Terry,\r\n\r\nI just tried with -DTFLITE_ENABLE_RUY=ON, I'm now getting 271ms, a huge improvement over the previous 550ms! It's still slower than Bazel, which is at 240ms, and this difference is statistically significant given that the standard deviation is about 2ms (I'm using the default 50 runs in benchmark_model).\r\n\r\nTrying the additional C and C++ flags don't change the performance, it's still 271ms.\r\n-DCMAKE_C_FLAGS=\"-march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations\" -DCMAKE_CXX_FLAGS=\"-march=armv7-a -mfpu=neon-vfpv4 -funsafe-math-optimizations\"\r\n\r\nPerformance is the same for NDK releases r21e, r22b, and r23-beta3, just sharing additional info I forgot in the original post.\r\n\r\nIs Bazel taking ruy? Is this fix making CMake take a different codepath that covers up some underlying issue? I had built r2.4 in the past (using the args specified in OP) and inference performance was identical to Bazel. My hunch was that some of the 3p dependencies in the CMakeLists are not version controlled and thus changed something, since the r2.4 branch is in git and all the source code is version controlled.\r\n\r\nBtw, the master branch is currently broken for building benchmark_model using CMake for Android, I get:\r\n    /home/ubuntu/tensorflow_test_our_commit/tensorflow/lite/tools/benchmark/benchmark_tflite_model.cc:651: error: undefined reference to 'tflite::CpuBackendContext::CpuBackendContext()'\r\n\r\n-Zhaoxiong", "@jxnding \r\nCould you please confirm if the issue still persist.Thanks", "If it persists, could you share the benchmark result with  \"--enable_op_profiling=true\" flag?", "I think I've found the root cause. According to https://developer.android.com/ndk/guides/cmake\r\nNDK generates thumb instructions for armeabi-v7a by default.\r\nBy using arm mode improves the performance. You need to provide `-DANDROID_ARM_MODE=arm` to your cmake command.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48833\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48833\">No</a>\n"]}, {"number": 48832, "title": "fix xrt cuda memory allocator [reopen]", "body": "reopened for [pr](https://github.com/tensorflow/tensorflow/pull/44985)", "comments": ["@gbaned This pr changes some helpful function that is being used by some internal functions. More details in https://github.com/tensorflow/tensorflow/pull/44985#issuecomment-759709817. I will take this diff and try to land it internally.", "@JackCaoG Any update on the internal review ? ", "I am trying to see if I can implement it in a different way, internal code style check doesn't like current static map approach. I think all we need is a allocator with `allow_async_dealloc_==false`, maybe I can update the backend's default allocator upon initialization.", "Do you think you could give us an ETA that you have to land this ? I would very much appreciate it. ", "It is a bit hard to give a exact day, the process is\r\n1. Draft the cl, get it reviewed and merged (do some benchmark too)\r\n2. Update pytorch/xla's pinned tensorflow version and make sure all test passed\r\n\r\nI will update when we know better.", "> I am trying to see if I can implement it in a different way, internal code style check doesn't like current static map approach. I think all we need is a allocator with `allow_async_dealloc_==false`, maybe I can update the backend's default allocator upon initialization.\r\n\r\n1. The reason I need sync dealloc here is that xrt execute op is async, hence it is possible that there're multiple computing graph running at the same time. Sync dealloc could improve the cuda memory reuse.\r\n\r\n2. I have updated the class member as non-static.\r\n", "https://github.com/tensorflow/tensorflow/commit/03cb2b9d8393d2c841c7387ad279dfc3280e5fc1 is merged, we can close this one"]}, {"number": 48831, "title": "[tf.data] graduate RandomDataset from experimental to tf.data.Dataset.random", "body": "This PR graduates the `tf.data.experimental.RandomDataset` API into `tf.data.Dataset.random` by making the following changes:\r\n\r\n- [x] Adds the deprecation decorator for the experimental API.\r\n- [x] Add the `random()` method to `DatasetV2` class.\r\n- [x] Updates example in documentation with new API.\r\n- [x] Regenerate golden API's.\r\n- [x] Moved and updated the `random_dataset_test` target from experimental/kernel_tests to kernel_tests\r\n- [x] Updated the RELEASE.md file\r\n\r\nTEST LOG\r\n```\r\nINFO: Build completed successfully, 349 total actions\r\n//tensorflow/python/data/kernel_tests:random_dataset_test                PASSED in 2.4s\r\n```\r\n\r\ncc: @jsimsa ", "comments": []}, {"number": 48830, "title": "Error when loading TensorFlow SavedModel with tag set 'serve': FileFactory 'local_file' not found.", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Google Colab (Linux-4.19.112+-x86_64-with-Ubuntu-18.04-bionic)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Preinstalled\r\n- TensorFlow version: 2.4.1\r\n- Python version:  3.7.10\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): n/a\r\n- GCC/Compiler version (if compiling from source): n/a\r\n- CUDA/cuDNN version:  11.2  \r\n- GPU model and memory: Tesla P100 16G\r\n\r\n\r\n\r\n**Describe the problem**\r\nI have created a sequence classification model using tfhub `small_bert/bert_en_uncased_L-6_H-512_A-8` preprocessor and `bert_en_uncased_preprocess/2` encoder.  I have provided the main components of the code below.  After saving the saved_model and uploading to Google Cloud Storage, I am following the documentation for instantiating a BigQuery ML model from the saved model but receiving the following error:\r\n\r\n```\r\nExecuting query with job ID: d6223072-8b7c-4672-a450-5ec8a23e7351\r\nQuery executing: 8.99s\r\nERROR:\r\n 400 GET https://bigquery.googleapis.com/bigquery/v2/projects/adapt-ml/queries/d6223072-8b7c-4672-a450-5ec8a23e7351?maxResults=0&timeoutMs=400&location=US: Error when loading TensorFlow SavedModel with tag set 'serve': FileFactory 'local_file' not found. The application has not been linked against the '//file/localfile' library or InitGoogle() has not been called yet.\r\n\t [[{{node text_file_init/InitializeTableFromTextFileV2}}]]\r\n\r\n(job ID: d6223072-8b7c-4672-a450-5ec8a23e7351)\r\n\r\n                              -----Query Job SQL Follows-----                               \r\n\r\n    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |\r\n   1:CREATE OR REPLACE MODEL `adapt-ml.bigquery_ml.sentiment`\r\n   2:OPTIONS (MODEL_TYPE='TENSORFLOW',  MODEL_PATH='gs://adapt-ml-bucket/finetuned_model/*')\r\n    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |\r\n````\r\nI am not sure if this is a TensorFlow, TFHub, or BigQuery error as I was unable to locate any similar issue in web searches or Github searches.\r\n\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nCOmmand steps follow linearly below.\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\nModel Information:\r\n```\r\ndef build_classifier_model(train_dataset):\r\n  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\r\n  preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing', )\r\n  encoder_inputs = preprocessing_layer(text_input)\r\n  encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\r\n  outputs = encoder(encoder_inputs)\r\n  pooled = outputs['pooled_output']\r\n\r\n  net = tf.keras.layers.Dense(\r\n              HIDDEN_LAYER_DIMS,\r\n              kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.002),\r\n              activation=\"relu\",\r\n              name=\"pre_classifier\"\r\n          )(pooled)  \r\n  \r\n  net = tf.keras.layers.Dropout(DROPOUT, trainable=True)(net)\r\n  net = tf.keras.layers.Dense(2, activation=\"sigmoid\", name='classifier')(net)\r\n  model = tf.keras.Model(text_input, net)\r\n\r\n  loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\r\n\r\n  epochs = EPOCHS\r\n  steps_per_epoch = tf.data.experimental.cardinality(train_dataset).numpy()\r\n  num_train_steps = steps_per_epoch * epochs\r\n  num_warmup_steps = int(0.1*num_train_steps)\r\n\r\n  optimizer = optimization.create_optimizer(init_lr=LEARNING_RATE,\r\n                                            num_train_steps=num_train_steps,\r\n                                            num_warmup_steps=num_warmup_steps,\r\n                                            optimizer_type='adamw')\r\n\r\n  model.compile(optimizer=optimizer,\r\n                          loss=loss,\r\n                          metrics=['accuracy'])\r\n  \r\n  model.summary()\r\n  \r\n  return model\r\n```\r\n\r\nTrain Model:\r\n```\r\nmodel = build_classifier_model(train_dataset)\r\n\r\ncheckpoint = ModelCheckpoint(filepath=SAVE_MODEL_PATH, \r\n                             verbose=1,\r\n                             save_freq='epoch',\r\n                             monitor='val_accuracy',\r\n                             save_best_only=True, \r\n                             mode='max', \r\n                             save_weights_only=True)\r\n\r\n\r\n# Training model...\r\nhistory = model.fit(train_dataset, batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=checkpoint, validation_data=valid_dataset)\r\n```\r\n\r\nReload model and save as saved_model:\r\n```\r\nmodel = build_classifier_model(train_dataset)\r\nmodel.load_weights(SAVE_MODEL_PATH)\r\n#model.save('finetuned_model', include_optimizer=False, save_traces=False)\r\n#model = tf.keras.models.load_model('finetuned_model')\r\n\r\n!rm -r finetuned_model\r\n\r\ntf.saved_model.save(\r\n    model,\r\n    'finetuned_model',\r\n    signatures=None,\r\n    options=None, \r\n)\r\n```\r\n\r\nChecking correct signature:\r\n```\r\nloaded = tf.saved_model.load('finetuned_model')\r\nprint(list(loaded.signatures.keys()))  # [\"serving_default\"]\r\n\r\ninfer = loaded.signatures[\"serving_default\"]\r\nprint(infer.structured_input_signature)\r\nprint(infer.structured_outputs)\r\n-------------------------------------------------\r\n['serving_default']\r\n((), {'text': TensorSpec(shape=(None,), dtype=tf.string, name='text')})\r\n{'classifier': TensorSpec(shape=(None, 2), dtype=tf.float32, name='classifier')}\r\n```\r\n\r\nAfter copying to GS Bucket:\r\n```\r\n%%bigquery\r\n\r\nCREATE OR REPLACE MODEL `adapt-ml.bigquery_ml.sentiment`\r\nOPTIONS (MODEL_TYPE='TENSORFLOW',  MODEL_PATH='gs://adapt-ml-bucket/finetuned_model/*')\r\n```\r\n\r\n", "comments": ["@jroakes ,\r\n\r\nIn order to reproduce the issue reported here, could you please provide the complete code and the dataset you are using. Thanks!", "@tilakrayal sure.  Here is the cleaned-up Colab notebook with the full example. \r\nhttps://colab.research.google.com/drive/1w-E1gjRVV-Qpur9SHBWWFHJKIXhfM1JI?usp=sharing", "Hi @tilakrayal and @Saduf2019.  I was able to resolve the issue by using `https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3` instead of `https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2`. It appears there is an incorrect reference to `vocab.txt` in the prior versions of this Model.  It may be worth a more explicit notification on https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/2 alerting to this issue.\r\n\r\nhttps://github.com/tensorflow/hub/issues/719", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48830\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48830\">No</a>\n", "@jroakes \r\nI ran you code on tf 2.5 and the issue does not exist, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/7888e9968856a077d1057835157e07c1/untitled598.ipynb)", "@jroakes \r\nApologies for the delayed response, thank you for your update glad the issue is resolved."]}, {"number": 48829, "title": "Session takes a long time to initialize c++ api", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: no\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.2.0\r\n- Python version: \r\n- Bazel version (if compiling from source): 2.0.0\r\n- GCC/Compiler version (if compiling from source): 7.5.0\r\n- CUDA/cuDNN version: CUDA 10.1/ cuDNN 7.6.5 / computeCapability: 7.5\r\n- GPU model and memory: GeForce RTX 2080 SUPER, 7982MiB\r\n\r\n**Describe the current behavior**\r\nI compiled tensorflow from the source code and link it to my program, using CMake to build it. When I create a new session, it takes a long time, about 2-4 minutes. The Tensorflow logs below show that initialization took 3 minutes.\r\n\r\n**Standalone code to reproduce the issue**\r\n```cpp\r\n#include <memory>\r\n#include \"tensorflow/core/public/session.h\"\r\n\r\nnamespace tf = tensorflow;\r\n\r\nint main() {\r\n  std::unique_ptr <tf::Session>  session(tf::NewSession(tf::SessionOptions()));\r\n  return 0;\r\n}\r\n```\r\n\r\n```cmake\r\nCMAKE_MINIMUM_REQUIRED(VERSION 3.10 FATAL_ERROR)\r\nPROJECT(example LANGUAGES CXX)\r\n\r\nADD_EXECUTABLE(example main.cpp)\r\nTARGET_LINK_LIBRARIES(example\r\n  PRIVATE\r\n    /path/to/libtensorflow_cc.so\r\n)\r\nTARGET_INCLUDE_DIRECTORIES(example\r\n  PRIVATE\r\n    /path/to/tensorflow/include\r\n)\r\n\r\n```\r\n\r\n**Describe the expected behavior**\r\nOn my second computer with i7-5820K and 1080ti (11gb), the session initializes instantly. It seems to me that the problem is with the processor instructions, but I do not know which ones.\r\n\r\n**Other info / logs** \r\n\r\n**lscpu-log:**\r\n```\r\nArchitecture:        x86_64\r\nCPU op-mode(s):      32-bit, 64-bit\r\nByte Order:          Little Endian\r\nCPU(s):              8\r\nOn-line CPU(s) list: 0-7\r\nThread(s) per core:  1\r\nCore(s) per socket:  1\r\nSocket(s):           8\r\nNUMA node(s):        1\r\nVendor ID:           GenuineIntel\r\nCPU family:          6\r\nModel:               79\r\nModel name:          Intel(R) Xeon(R) CPU E5-2620 v4 @ 2.10GHz\r\nStepping:            1\r\nCPU MHz:             2099.998\r\nBogoMIPS:            4199.99\r\nL1d cache:           32K\r\nL1i cache:           32K\r\nL2 cache:            256K\r\nL3 cache:            20480K\r\nNUMA node0 CPU(s):   0-7\r\nFlags:               fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss syscall nx pdpe1gb rdtscp lm constant_tsc arch_perfmon nopl xtopology tsc_reliable nonstop_tsc cpuid pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand lahf_lm abm 3dnowprefetch cpuid_fault invpcid_single pti ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 invpcid rtm rdseed adx smap xsaveopt arat md_clear flush_l1d arch_capabilities\r\n```\r\n**tensorflow-log:**\r\n```\r\n2021-04-29 23:10:50.424958: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1                                                                \r\n2021-04-29 23:10:50.428763: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning\r\n NUMA node zero                                                                                                                                                                                             \r\n2021-04-29 23:10:50.429258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:                                                                                        \r\npciBusID: 0000:03:00.0 name: GeForce RTX 2080 SUPER computeCapability: 7.5                                                                                                                                  \r\ncoreClock: 1.86GHz coreCount: 48 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 462.00GiB/s                                                                                                               \r\n2021-04-29 23:10:50.429579: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1                                                           \r\n2021-04-29 23:10:50.431668: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10                                                             \r\n2021-04-29 23:10:50.433630: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10                                                              \r\n2021-04-29 23:10:50.433988: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10                                                             \r\n2021-04-29 23:10:50.436231: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10                                                           \r\n2021-04-29 23:10:50.437545: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10                                                           \r\n2021-04-29 23:10:50.443697: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7                                                               \r\n2021-04-29 23:10:50.443824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning\r\n NUMA node zero                                                                                                                                                                                             \r\n2021-04-29 23:10:50.444345: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning\r\n NUMA node zero                                                                                                                                                                                             \r\n2021-04-29 23:10:50.444774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0                                                                                          \r\n2021-04-29 23:13:59.144099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:                                                        \r\n2021-04-29 23:13:59.144129: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0                                                                                                                 \r\n2021-04-29 23:13:59.144197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N                                                                                                                 \r\n2021-04-29 23:13:59.144430: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning\r\n NUMA node zero                                                                                                                                                                                             \r\n2021-04-29 23:13:59.144994: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning\r\n NUMA node zero                                                                                                                                                                                             \r\n2021-04-29 23:13:59.145535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning\r\n NUMA node zero                                                                                                                                                                                             \r\n2021-04-29 23:13:59.146044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 2227 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 SUPER, pci bus id: 0000:03:00.0, compute capability: 7.5)\r\n```\r\n**thanks!**", "comments": ["@IldarKashaev, We are checking to see if you still need help on this issue. Can you try building the latest stable version of TF i.e 2.7.0 and let us know if the issue persists? You can use [this](https://www.tensorflow.org/install/source) guide for your reference and take a look at [this](https://www.tensorflow.org/install/source#linux) link for the tested build configs.Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48829\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48829\">No</a>\n"]}, {"number": 48828, "title": "make -f error", "body": "maos 11.3\r\nPython 3.9.4\r\nesp-idf4.2\r\n\r\n\r\nerror\uff1a\r\n\r\ncafe@CafedeiMac tensorflow % make -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_hello_world_esp_project\r\ntensorflow/lite/micro/tools/make/downloads/flatbuffers already exists, skipping the download.\r\ntensorflow/lite/micro/tools/make/downloads/pigweed already exists, skipping the download.\r\nmake: *** No rule to make target 'tensorflow/lite/micro/tools/make/gen/esp_xtensa-esp32_default/prj/hello_world/esp-idf/components/tfmicro/third_party/gemmlowp/fixedpoint/fixedpoint.h', needed by 'generate_hello_world_esp_project'.  Stop.\r\n\r\n", "comments": ["@coffice12 \r\n\r\nCould you please fill the template\r\n\r\nIn order to expedite the trouble-shooting process, please provide a code snippet/colab gist to reproduce the issue reported here. Thanks!\r\n\r\n\r\n\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48828\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48828\">No</a>\n"]}, {"number": 48827, "title": "[mlir-hlo] Added pass to transform view to alloc operations of the memref dialect.", "body": "We have added a new folder `Transform` to the mlir-hlo directory to add and compile new passes. This change also includes a number of new files, namely `passes.h`, `passed.td`, `register_passes.h` and `PassDetail.h`. These contain the information necessary to register new transformation-based passes in the MLIR namespace.\r\n\r\nWe have also added a new `memrefViewToAlloc` pass implemented in `memref_view_to_alloc.cc`. This pass intentionally converts `memref::View` ops to `memref::Alloc` ops. This is particularly useful for transforming the view-based intermediate output of the HLO backend into separate allocate operations.", "comments": ["I don't quite get why we have this new Transform directory? If these aren't MHLO passes, then why aren't they just implemented upstream?", "> What is the objective of this pass? This isn't generally correct, is it? Since you could have overlapping views that establish a reader/writer relationship?\r\n\r\nIf you're trying to get an LMHLO graph with trivial buffer assignment then I'd suggest putting this logic in `LhloDialectEmitter::GetOrCreateArrayView`, under a flag.  That way this does not look like a semantic preserving transformation.\r\n\r\nCC @jurahul @timshen91 ", "> I don't quite get why we have this new Transform directory? If these aren't MHLO passes, then why aren't they just implemented upstream?\r\n\r\nThis pass is only useful when playing around with LMHLO as produced by XLA. We could move it somewhere more downstream into an XLA subdirectory. Or do what @sanjoy suggested.\r\n\r\n", "> > What is the objective of this pass? This isn't generally correct, is it? Since you could have overlapping views that establish a reader/writer relationship?\r\n> \r\n> If you're trying to get an LMHLO graph with trivial buffer assignment then I'd suggest putting this logic in `LhloDialectEmitter::GetOrCreateArrayView`, under a flag. That way this does not look like a semantic preserving transformation.\r\n> \r\n> CC @jurahul @timshen91\r\n\r\nWe did not do this as it requires changes to XLA. This is a simple post-processing past to enable some experimentation. If you think adding support for this directly into XLA is better, can you help with adding that flag?", "Like @sherhut mentioned above, it was intended as an experimental pass. Our main use case is to transform Memref.views, which are outputs of JAX models, to simple allocation operations. This Transformation is necessary to use our new Buffer Reuse optimization feature (#48883). We transformed some examples to test the new feature and these issues have not been noticed. Therefore, for this purpose it was sufficient. \r\n\r\nWe agree that it cannot stay as it is. Either we implement a new analysis to fix this issue, or maybe @sanjoy can help us with the Xla flag. ", "> If you think adding support for this directly into XLA is better, can you help with adding that flag?\r\n\r\nNot at the moment, so I'm OK with this PR landing to unblock you.  But I'd suggest somehow making it obvious that this is an experimental transform, not intended to be semantics preserving.  Perhaps rename it to include \"Experimental\" somewhere in the name?  Doing that in a separate PR is fine as well.", "Thank you for your feedback.  \r\n\r\nAs @sanjoy suggested, we will mark it as experimental transform, so it is clear to be not semantic preserving.  As soon as we could fix the current problems, we will update the PR to have clean and semantic preserving transformation. \r\n\r\nBest Regards ", "@dfki-thsc  Any update on this PR? and please resolve conflicts Thanks!", "@dfki-thsc Any update on this PR? and please resolve conflicts Thanks!"]}, {"number": 48826, "title": "Cached augmentation and BATCH_SIZE not used in CycleGAN tutorial ", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/tutorials/generative/cyclegan\r\n\r\n## Description of issue (what needs changing):\r\n\r\nSeems like the data pipeline for the CycleGAN is using cache after augmenting the data.\r\nIs this intentional? Doesn't that make augmentation useless?\r\n\r\nAnother \"problem\" in the data pipeline: a batch size of 1 is used even if there is a 'BATCH_SIZE' variable at the start of the tutorial.", "comments": ["@nikitamaia @lamberta @MarkDaoust We have two Official CycleGAN tutorials for the community:\r\nhttps://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb\r\nhttps://github.com/keras-team/keras-io/blob/master/examples/generative/cyclegan.py", "The Web renderings are:\r\nhttps://keras.io/examples/generative/cyclegan/\r\nhttps://www.tensorflow.org/tutorials/generative/cyclegan", "The Keras project maintains a separate documentation site at https://keras.io/\r\n\r\nWe import some of their guide docs [here on tf.org](https://www.tensorflow.org/guide/keras/sequential_model) but not their community examples/tutorials.", "Yes I know but in cases like this one I think that it could be a little bit confusing for users when we have almost the same content (with the same potential question). Also, cause there is any specific claim that one documentation is community best effort maintained and the other one is  TensorFlow maintained.", "Happy to help merge changes to [tutorial](https://github.com/tensorflow/docs/blob/master/site/en/tutorials/generative/cyclegan.ipynb) in tensorflow/docs. For the Keras project, you'll have to work over there :)\r\n\r\nWe maintain the tensorflow/docs repo for official tensorflow.org tutorials. But we don't see an issue if the Keras project maintains Keras-specific docs.", "Ok I understand. Just to note that If there is something interesting in this ticket you will need two issues, two PRs, two reviews on both the repositories.", "@kaosdev \r\nCan you please confirm if the issue is resolved and  move this to closed status as the pr is merged.", "I can confirm the issue with the BATCH_SIZE is resolved.\n\nI can't see any change about the cached augmentation.\n\nI don't know if it's planned to fix also this issue or not.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n"]}, {"number": 48825, "title": "Warning message when using custom loss function", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): YES\r\n- OS Platform and Distribution: UBUNTU 18.04\r\n- TensorFlow installed from: CONDA\r\n- TensorFlow version: 2.4.1\r\n- Python version: 3.8\r\n- CUDA/cuDNN version: 11.2\r\n- GPU model and memory: 4 x TITAN Xp 12GB\r\n\r\n----------------------\r\n\r\nGreetings from Italy!\r\nI coded a simple autoencoder (I used one of the stock example script you can find on TF) just to see if I was able to implement a custom loss function. This is the code (jupyter notebook file): \r\n\r\nhttps://github.com/notprime/autoencoder/blob/main/autoencoder.ipynb\r\n\r\nBasically, that **`function`** in `[3]` is something I didn't code, and its vectorialization is pretty hard. Therefore, when I get the hidden output tensor, I convert it into a numpy array, compute the matrix I need, convert it back into a TF tensor, and I compute the custom loss function.\r\n\r\nWhen I train the model, I get the following error:\r\n```\r\nWARNING:tensorflow:AutoGraph could not transform <function compute_loss at 0x7f0e688fbe50> and will run it as-is.\r\nPlease report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\r\nCause: module 'gast' has no attribute 'Index'\r\n```\r\n\r\nIs this something I should worry about?\r\nMoreover, how does TF handle the automatic-differentiation of this `compute_loss` function (which calls in every for loop the other ** `function`**? This is something I'd really like to better understand.\r\nIf you also have some advices on how optimize the code let me know, this is really my first time using TF. Maybe I can convert those function into TF function using the methods `tf.autograph` or `tf.autograph.to_graph`?\r\n\r\nThanks in advance!\r\n", "comments": ["@notprime  Could you please confirm what version of gast are you using? Please try with gast 0.3.3 for TF version 2.4. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48825\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48825\">No</a>\n"]}, {"number": 48824, "title": "When pulling out layers from the model for extracting intermediate computation data, weights and activation output etc. the weights and biases are changing in different cases.", "body": "I realised is the weights and biases are getting modified in this procedure and graph structure is also changing when visualised through netron and the same changed structure is reflecting when checked via scripting to cross validate the netron output. Conv2_block1_2 for example had no BN layer before Relu. But If want to pull out the Relu output then it adds BN layers at every node which is being pulled out\r\n\r\n\r\n\r\noutputs= [my_model.get_layer(\"conv2_block1_1_relu\").output, my_model.get_layer(\"conv2_block1_2_conv\").output, my_model.get_layer(\"conv2_block1_2_relu\").output]\r\n\r\nmodel_debug = tensorflow.keras.Model(inputs=my_model.inputs, outputs=outputs)\r\n\r\n![orginal resnet tflite converted](https://user-images.githubusercontent.com/82860513/116591121-1deaef80-a93c-11eb-9473-e90b6a32abd4.png)\r\n![with few pulled to outputs weights changed ](https://user-images.githubusercontent.com/82860513/116590970-f7c54f80-a93b-11eb-9bf6-0c0b8b270e19.png)\r\n![with all initial layers pulled to outputs (2)](https://user-images.githubusercontent.com/82860513/116590996-feec5d80-a93b-11eb-81a3-71dec8623c28.png)\r\n\r\n\r\n\r\n", "comments": ["@manp-git\r\n\r\n Could you please fill the template\r\nIn order to expedite the trouble-shooting process, please provide a code snippet/colab gist to reproduce the issue reported here. Thanks!\r\n\r\n \r\n", "> @manp-git\r\n> \r\n> Could you please fill the template\r\n> In order to expedite the trouble-shooting process, please provide a code snippet/colab gist to reproduce the issue reported here. Thanks!\r\n\r\n\r\nHi @UsharaniPagadala , I have uploaded the snippets in the question. 1) The first one is default TF-Resnet-50 - quantisation to TFLite\r\n2) Change in weights and lower graph when I pulled out : outputs= [my_model.get_layer(\"conv2_block1_1_relu\").output, my_model.get_layer(\"conv2_block1_2_conv\").output, my_model.get_layer(\"conv2_block1_2_relu\").output]\r\n3) change in entire graph when I pulled out all inital layers to output\r\n", "Update:- Solution I have figured out to weight values getting changed is that - not to output the block but only the relu layer. Why is that so, I dont know.\r\nSecondly Why is the location of batch normalisation different in default resnet50 model as compared to tflite quantised resnet50 model, I am curious to know, as I want to change the weights to produce the relu output, which I am not able to do by set tensor, hence want to do using python convolution operations. What all keras functions would be required to reproduce the relu output from weights and output of previous layer is what i want to know.", "Sorry, it is little hard to understand your questions since there are more than one questions and they are little broad. What is the major goal here?", "Hi, I have created a new issue for one of the things here, in order to be specific, please have a look: https://github.com/tensorflow/tensorflow/issues/48879", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "@manp-git ,\r\nRelated issue #48879 has been closed.\r\nCould you please update TensorFlow to the latest stable version v.2.7 and let us know if you are facing the same error. Thanks!", "Thanks for acting on this issue. I don't have access to that project anymore so won't be able to cross check.\nWill work with the suggested version next time when required.\nYou may close the issue for now.", "@manp-git ,\r\nPlease feel free to move this issue to closed status.Thanks", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 48823, "title": "U2Net tf pb model works fine , but tflite model works wrong", "body": "The project is from [pytorch model](https://github.com/xuebinqin/U-2-Net)  \r\nI use [colab](https://colab.research.google.com/drive/10bPSzQL8-im6RdP8fXm2_VCcbETGvcNM?usp=sharing)\r\nI put two result pics together.    \r\n\r\nOnly need to update my_tf_model.pb-20210429T083200Z-001.zip in colab.  \r\n \r\n[my_tf_model.pb-20210429T083200Z-001.zip](https://github.com/tensorflow/tensorflow/files/6397925/my_tf_model.pb-20210429T083200Z-001.zip)  \r\n\r\n[my_tf_model.zip](https://github.com/tensorflow/tensorflow/files/6397926/my_tf_model.zip)  \r\n[my_model2.zip](https://github.com/tensorflow/tensorflow/files/6397932/my_model2.zip)  \r\n\r\n", "comments": ["Please elaborate more on the expected results.", "The expected result is like pb model's output.\r\n\r\nAnd there is some [expected result](https://github.com/xuebinqin/U-2-Net).  \r\n\r\nI have updated colab, thanks.", "Could you try conversion without the model optimization? I wonder whether this issue will be gone when the model optimization is off.", "When I comment this code:  \r\n    ```converter.optimizations = [tf.lite.Optimize.DEFAULT]```  \r\nIt works fine, thank you very much!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48823\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48823\">No</a>\n", "I have another questions, pls:   \r\n1.Don't use optimizations , time speed transforms from 800ms to 1700ms, is it normal? How to balance time and accuracy?   \r\n2.The tflite model's input is [1,3,224,224], should I do some special operation  to use it in android? Shoudl I change the shape to [1, 224,  224, 3]? Result is not good in my android app.  ", "@AR-fan ,\r\n\r\nCould you please confirm if the above mentioned issue is resolved. if yes, please feel free to move this issue to closed status and please submit a new issue from this [link](https://github.com/tensorflow/models/issues/new/choose) and fill in the template, so that we can track the issue there. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48823\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48823\">No</a>\n", "Let's use this for the remaining model optimization toolkit issue.", "Hello everyone , how is it going\uff1f", "Could you upload a new issue for the left-over issue for the model optimization toolkit? Looks like this issue already is closed and it is hard to get attentions due to the long history.", "OK, thank you!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48823\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48823\">No</a>\n", "\n--\n<string>1:947996152464:ios:458174e3f31524b50afe15</string> martes, 25 mayo 2021, 04:50a. m. -05:00 de tensorflow-butler[bot]  ***@***.*** :\n\n>Are you satisfied with the resolution of your issue?\n>Yes\n>No\n>\u2014\n>You are receiving this because you are subscribed to this thread.\n>Reply to this email directly,  view it on GitHub , or  unsubscribe ."]}, {"number": 48822, "title": "make xtensa folder generic for adding more product variants in future", "body": "@advaitjain please review, thanks.\r\nAfter this, I will start adding vision specific changes\r\nYou may merge 2 changelists to 1. 1st change was for review purpose, and compilation would fail unless 2nd changelist is added.", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "@kpraving  Can you please resolve conflicts? Thanks!", "will skip this approach and plan to merge code into single file. Closing this request."]}, {"number": 48821, "title": "C++ compilation of rule '@llvm-project//mlir:SPIRVDialect' failed (Exit 1): gcc failed: error executing command", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):Tensorflow-2.4.0\r\n- Python version:3.7.9\r\n- Bazel version (if compiling from source):3.1.0\r\n- GCC/Compiler version (if compiling from source):8.3.0\r\n- CUDA/cuDNN version: cpu mode\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nwhen I build tensorflow-2.4.0 on loongson platform, it build failed, log as below:\r\n\r\nroot@loongson:/home/loongson/codespace/tensorflow-2.4.0# bazel build --verbose_failures --config=noaws --config=opt --host_copt=-march=loongarch64 --copt=-O3 --copt=-Wformat --copt=-Wformat-security --copt=-fstack-protector --copt=-fPIC --copt=-fpic --linkopt=-znoexecstack --linkopt=-zrelro --linkopt=-znow --linkopt=-fstack-protector  //tensorflow/tools/pip_package:build_pip_package --disk_cache /mnt\r\nStarting local Bazel server and connecting to it...\r\nINFO: Invocation ID: a03d3db0-1b20-48fb-bef6-f73324e9b282\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=198\r\nINFO: Reading rc options for 'build' from /home/loongson/codespace/tensorflow-2.4.0/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /home/loongson/codespace/tensorflow-2.4.0/.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2\r\nINFO: Reading rc options for 'build' from /home/loongson/codespace/tensorflow-2.4.0/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/local/lib/python3.7/dist-packages --python_path=/usr/bin/python3 --config=xla --action_env TF_CONFIGURE_IOS=0\r\nINFO: Found applicable config definition build:short_logs in file /home/loongson/codespace/tensorflow-2.4.0/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /home/loongson/codespace/tensorflow-2.4.0/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:xla in file /home/loongson/codespace/tensorflow-2.4.0/.bazelrc: --define=with_xla_support=true\r\nINFO: Found applicable config definition build:noaws in file /home/loongson/codespace/tensorflow-2.4.0/.bazelrc: --define=no_aws_support=true\r\nINFO: Found applicable config definition build:opt in file /home/loongson/codespace/tensorflow-2.4.0/.tf_configure.bazelrc: --copt=-march=loongarch64 --host_copt=-march=loongarch64 --define with_default_optimizations=true\r\nINFO: Found applicable config definition build:linux in file /home/loongson/codespace/tensorflow-2.4.0/.bazelrc: --copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels\r\nINFO: Found applicable config definition build:dynamic_kernels in file /home/loongson/codespace/tensorflow-2.4.0/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS\r\nINFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (381 packages loaded, 29967 targets configured).\r\nINFO: Found 1 target...\r\nINFO: Deleting stale sandbox base /root/.cache/bazel/_bazel_root/ed10c4c178351d92634570f8a57528bc/sandbox\r\n**ERROR: /root/.cache/bazel/_bazel_root/ed10c4c178351d92634570f8a57528bc/external/llvm-project/mlir/BUILD:1931:1: C++ compilation of rule '@llvm-project//mlir:SPIRVDialect' failed (Exit 1): gcc failed: error executing command** \r\n  (cd /root/.cache/bazel/_bazel_root/ed10c4c178351d92634570f8a57528bc/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/usr/bin/python3 \\\r\n    PYTHON_LIB_PATH=/usr/local/lib/python3.7/dist-packages \\\r\n    TF2_BEHAVIOR=1 \\\r\n    TF_CONFIGURE_IOS=0 \\\r\n  /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections '-std=c++0x' -MD -MF bazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_objs/SPIRVDialect/SPIRVDialect.pic.d '-frandom-seed=bazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_objs/SPIRVDialect/SPIRVDialect.pic.o' -fPIC -DLLVM_ENABLE_STATS -D__STDC_LIMIT_MACROS -D__STDC_CONSTANT_MACROS -D__STDC_FORMAT_MACROS -DLLVM_BUILD_GLOBAL_ISEL -iquote external/llvm-project -iquote bazel-out/loongarch64-opt/bin/external/llvm-project -iquote external/zlib -iquote bazel-out/loongarch64-opt/bin/external/zlib -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/CallOpInterfacesIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/DialectSymbolRegistry -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/InferTypeOpInterfaceIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/OpAsmInterfaceIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/RegionKindInterfaceIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SideEffectInterfacesIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SymbolInterfacesIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/ControlFlowInterfacesIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/AffineMemoryOpInterfacesIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/AffineOpsIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/LoopLikeInterfaceIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/StandardOpsIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/VectorInterfacesIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/ViewLikeInterfaceIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SCFIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SCFPassIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/ParserTokenKinds -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SPIRVAvailabilityIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SPIRVCanonicalizationIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SPIRVOpUtilsIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SPIRVOpsIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SPIRVPassIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/SPIRVSerializationGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/CopyOpInterfaceIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/LinalgOpsIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/LinalgStructuredInterfacesIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/LinalgStructuredOpsIncGen -Ibazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_virtual_includes/TransformsPassIncGen -isystem external/llvm-project/mlir/include -isystem bazel-out/loongarch64-opt/bin/external/llvm-project/mlir/include -isystem external/llvm-project/llvm/include -isystem bazel-out/loongarch64-opt/bin/external/llvm-project/llvm/include -isystem external/zlib -isystem bazel-out/loongarch64-opt/bin/external/zlib -w -DAUTOLOAD_DYNAMIC_KERNELS '-march=loongarch64' -O3 -Wformat -Wformat-security -fstack-protector -fPIC -fpic '-std=c++14' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -c external/llvm-project/mlir/lib/Dialect/SPIRV/SPIRVDialect.cpp -o bazel-out/loongarch64-opt/bin/external/llvm-project/mlir/_objs/SPIRVDialect/SPIRVDialect.pic.o)\r\nExecution platform: @local_execution_config_platform//:platform\r\n/tmp/ccE09hqX.s: Assembler messages:\r\n/tmp/ccE09hqX.s:182293: Internal error (Bus error).\r\nPlease report this bug.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nINFO: Elapsed time: 338.589s, Critical Path: 58.18s\r\nINFO: 162 processes: 162 local.\r\nFAILED: Build did NOT complete successfully\r\n\r\n\r\n**Describe the expected behavior**\r\nIt is because llvm-project issue?  How can I set to use system llvm  when build Tensorflow, not use external/llvm-project which is download from the github.\r\n\r\n**Please help to resolve this issue!** \r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@zhangqiang-hf Could you please try with [tested_build_configurations](https://www.tensorflow.org/install/source#tested_build_configurations) using TF v2.6.0, please have a look at the similar [issue1](https://github.com/tensorflow/tensorflow/issues/40931), [issue2](https://stackoverflow.com/questions/68955826/using-bazel-to-build-tensorflow-gcc-internal-compiler-error-killed-program-c) and let us know if it helps?Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48821\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48821\">No</a>\n"]}, {"number": 48820, "title": "Convert Tensorflow trained model to older version compatible.", "body": "I want to make an object detection API. I decided to deploy it on AWS Lambda. For that purpose I used this git repository https://github.com/mikylucky/lambda-tensorflow-object-detection\r\n\r\nAs you can see it uses tensorflow 1.9 version. Unfortunately, I trained my model and exported inference graph with tensorflow 1.12 and when I try to run inference on AWS lambda with this script:\r\n\r\n```\r\nimport os\r\nimport glob\r\nimport boto3\r\nimport numpy as np\r\nimport tensorflow as tf\r\nimport PIL\r\nimport matplotlib\r\nimport sys\r\nfrom distutils.version import StrictVersion\r\nfrom PIL import Image\r\nfrom utils import ops as utils_ops\r\nfrom matplotlib import pyplot as plt\r\n\r\n# Object detection imports\r\nfrom utils import label_map_util\r\nfrom utils import visualization_utils as vis_util\r\nimport json\r\n\r\n# Download Model From S3.\r\nMODEL_GRAPH_DEF_PATH = '/tmp/model.pb'\r\nBUCKET_NAME = 'solver'\r\n\r\ndef lambda_handler(event, context):\r\n  s3 = boto3.resource('s3')\r\n  print(event['queryStringParameters'])\r\n  img_url = 'images/' + event['queryStringParameters']['image_name']\r\n  model_path = 'models/' + event['queryStringParameters']['model_name'] + '.pb'\r\n  print(\"DOWNLOADING MODEL \" + model_path)\r\n  s3.Bucket(BUCKET_NAME).download_file(model_path,MODEL_GRAPH_DEF_PATH)\r\n  print(\"DOWNLOADING IMAGE \" + img_url)\r\n  s3.Bucket(BUCKET_NAME).download_file(img_url,'/tmp/image.jpg')\r\n  label_path = 'models/' + event['queryStringParameters']['model_name'] + '.pbtxt'\r\n  print(\"DOWNLOADING LABEL MAP \" + label_path)\r\n  s3.Bucket(BUCKET_NAME).download_file(label_path,'/tmp/label_map.pbtxt')\r\n  print(glob.glob(\"/tmp/*\"))\r\n  detect()\r\n\r\ndef detect():\r\n  PATH_TO_CKPT = '/tmp/model.pb'\r\n  PATH_TO_IMAGE = '/tmp//image.jpg'\r\n  NUM_CLASSES = 1\r\n  label_map = label_map_util.load_labelmap('/tmp/label_map.pbtxt')\r\n  categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\r\n  category_index = label_map_util.create_category_index(categories)\r\n\r\n  detection_graph = tf.Graph()\r\n  with detection_graph.as_default():\r\n    od_graph_def = tf.GraphDef()\r\n    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\r\n        serialized_graph = fid.read()\r\n        od_graph_def.ParseFromString(serialized_graph)\r\n        tf.import_graph_def(od_graph_def, name='')\r\n\r\n    sess = tf.Session(graph=detection_graph)\r\n\r\n  # Define input and output tensors (i.e. data) for the object detection classifier\r\n\r\n  # Input tensor is the image\r\n  image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\r\n\r\n  # Output tensors are the detection boxes, scores, and classes\r\n  # Each box represents a part of the image where a particular object was detected\r\n  detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\r\n\r\n  # Each score represents level of confidence for each of the objects.\r\n  # The score is shown on the result image, together with the class label.\r\n  detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\r\n  detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\r\n\r\n  # Number of objects detected\r\n  num_detections = detection_graph.get_tensor_by_name('num_detections:0')\r\n \r\n  print(\"SOMETHING WAS LOADED\")\r\n  print(num_detections)\r\n```\r\n\r\nI get an error like this: \r\n\r\n> NodeDef mentions attr 'Truncate' not in Op<name=Cast; signature=x:SrcT -> y:DstT; attr=SrcT:type; attr=DstT:type>; NodeDef: ToFloat = Cast[DstT=DT_FLOAT, SrcT=DT_UINT8, Truncate=false](image_tensor). (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).: ValueError\r\n> Traceback (most recent call last):\r\n>   File \"/var/task/lambda_function.py\", line 36, in lambda_handler\r\n>     detect()\r\n>   File \"/var/task/lambda_function.py\", line 52, in detect\r\n>     tf.import_graph_def(od_graph_def, name='')\r\n>   File \"/var/task/tensorflow/python/util/deprecation.py\", line 432, in new_func\r\n>     return func(*args, **kwargs)\r\n>   File \"/var/task/tensorflow/python/framework/importer.py\", line 422, in import_graph_def\r\n>     raise ValueError(str(e))\r\n> ValueError: NodeDef mentions attr 'Truncate' not in Op<name=Cast; signature=x:SrcT -> y:DstT; attr=SrcT:type; attr=DstT:type>; NodeDef: ToFloat = Cast[DstT=DT_FLOAT, SrcT=DT_UINT8, Truncate=false](image_tensor). (Check whether your GraphDef-interpreting binary is up to date with your GraphDef-generating binary.).\r\n\r\nI read that it is because of tensorflow version difference between runtime environment and the one I trained model on. Sadly I cannot update tensorflow version on lambda to 1.12 to make it work, cause lambda has 200mb limit of function code, and this repository Im using is specially made to fit this requirement. Retraining models on 1.9 is not an option too, cause it would take a lot of time, and due to CUDA requirements I'm not even sure at the moment if my computer would be suitable for this.\r\n\r\nI wonder if there is a way to somehow convert .pb file to match 1.9 tensorflow version and to make it work?\r\n\r\n", "comments": ["@resera \r\nCould you please have a look on [this,](https://www.tensorflow.org/guide/versions#backward_and_partial_forward_compatibility) and let us know if it helps", "We don't support TF 1.x anymore. \r\nIf you want to use modern TF version with AWS lambda check https://aws.amazon.com/it/blogs/compute/building-deep-learning-inference-with-aws-lambda-and-amazon-efs/", "> @resera\r\n> Could you please have a look on [this,](https://www.tensorflow.org/guide/versions#backward_and_partial_forward_compatibility) and let us know if it helps\r\n\r\nHello, thanks for a suggestion. After saving a model with \r\n\r\n> strip_default_attrs=True\r\n\r\nIt now gives me a different error while running the object detection, it looks like this:\r\n\r\n`Error parsing message: DecodeError\r\nTraceback (most recent call last):\r\n  File \"/var/task/lambda_function.py\", line 36, in lambda_handler\r\n    detect()\r\n  File \"/var/task/lambda_function.py\", line 51, in detect\r\n    od_graph_def.ParseFromString(serialized_graph)\r\ngoogle.protobuf.message.DecodeError: Error parsing message`\r\n\r\nis something wrong with my exported graph? I used this code:\r\n\r\n> import time\r\nimport os\r\nimport tensorflow as tf\r\ntrained_checkpoint_prefix = './training/model.ckpt-13605'\r\nexport_dir = os.path.join('trained-inference-graphs', time.strftime(\"%Y%m%d-%H%M%S\"))\r\nloaded_graph = tf.Graph()\r\nwith tf.Session(graph=loaded_graph) as sess:\r\n    loader = tf.train.import_meta_graph(trained_checkpoint_prefix + '.meta')\r\n    loader.restore(sess, trained_checkpoint_prefix)\r\n    builder = tf.saved_model.builder.SavedModelBuilder(export_dir)\r\n    builder.add_meta_graph_and_variables(sess,\r\n                                         [tf.saved_model.tag_constants.TRAINING],\r\n                                         strip_default_attrs=True)\r\n    builder.add_meta_graph([tf.saved_model.tag_constants.SERVING], strip_default_attrs=True)\r\n    builder.save()", "@resera You can check [this](https://www.tensorflow.org/guide/versions#graph_and_checkpoint_compatibility_when_extending_tensorflow) document for Tensorflow version compatibility. ", "@resera, We no longer support TF 1.x issues, you can go ahead and close this issue. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48820\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48820\">No</a>\n"]}, {"number": 48819, "title": "Medical Visual Question Answering", "body": "", "comments": ["Check out this pull request on&nbsp; <a href=\"https://app.reviewnb.com/tensorflow/tensorflow/pull/48819\"><img align=\"absmiddle\"  alt=\"ReviewNB\" height=\"28\" class=\"BotMessageButtonImage\" src=\"https://raw.githubusercontent.com/ReviewNB/support/master/images/button_reviewnb.png\"/></a> \n\n See visual diffs & provide feedback on Jupyter Notebooks. \n\n---\n\n <i>Powered by <a href='https://www.reviewnb.com/?utm_source=gh'>ReviewNB</a></i>", "\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F48819) for more info**.\n\n<!-- need_sender_cla -->", "<p>@googlebot I signed it!</p>", "This repository is not a good place for this. You should open your own repository, write blog posts, promote it, etc. But this repository is only about the TF library, not examples built on top of TF."]}, {"number": 48818, "title": "TFDS link broken for Cars196", "body": "Trying to download Cars196 using tflite_model_maker\r\n\r\ntrain_data, validation_data, test_data = ImageClassifierDataLoader.from_tfds('cars196')\r\n\r\nDownloadError: Failed to get url https://imagenet.stanford.edu/internal/car196/cars_test.tgz. HTTP code: 404.\r\n\r\nIt was working previously, How to resolve?", "comments": ["@calvuser \r\nThis issue is better suited for [tensorflow/datasets](https://github.com/tensorflow/datasets). Thanks", "@calvuser \r\nCould you please check the [link1](https://www.tensorflow.org/datasets/catalog/cars196) [,link2](https://ai.stanford.edu/~jkrause/cars/car_dataset.html) , and let us know if it helps.Thanks\r\n", "@calvuser \r\nCould you please let us know if the above mentioned [comment](https://github.com/tensorflow/datasets) works for you as\r\nThe host website (stanford.edu) has ceased hosting the dataset which is parsed by tfds.load thus you see the error. Thanks\r\n\r\n", "Hi, I understand it has been fix on tfds.load.\r\n\r\nI am downloading it on TF model maker. train_data, validation_data, test_data = ImageClassifierDataLoader.from_tfds('cars196')\r\n\r\nseems like the link in TF model maker have to be fix as well", "@calvuser I noticed you have opened same issue in `datasets` repo https://github.com/tensorflow/datasets/issues/3195 and a PR also opened to update the link. In the meantime you can download manually from the website or using the following command. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/8f3a07b14ed7ec37869ed1796d7a4ec1/untitled.ipynb)\r\n\r\n`!wget http://ai.stanford.edu/~jkrause/car196/cars_test.tgz`\r\n\r\nI am closing this issue as this is a duplicate and the opened issue is in correct repository. Thanks!\r\n\r\n"]}, {"number": 48817, "title": "Distillation and multi-gpu training with tf.keras", "body": "I use https://github.com/keras-team/keras-io/blob/master/examples/vision/knowledge_distillation.py and single gpu everything is right.\r\n\r\nWhen I use https://keras.io/guides/distributed_training/#singlehost-multidevice-synchronous-training and knowledge_distillation, the val_loss will become very big and the acc is very low.\r\n\r\nIf I only use distributed_training to train, everything is right too.\r\n\r\nWhen I define test_step and train_step in class Distiller(keras.Model), should I use https://tensorflow.google.cn/guide/distributed_training#using_tfdistributestrategy_with_custom_training_loops?\r\n", "comments": ["As this is a specific  Keras.io guide I suggest you to open a ticket on https://github.com/keras-team/keras-io to check if they are interested to expand that example.", "@bhack Looks like `keras` was imported from `tensorflow` (in both the examples). I guess you can use https://tensorflow.google.cn/guide/distributed_training#using_tfdistributestrategy_with_custom_training_loops to define `train_step` and `test_step`.\r\n\r\n@nikitamaia Can you please take a loot at it. Thanks!", "> @bhack Looks like `keras` was imported from `tensorflow` (in both the examples). I guess you can use https://tensorflow.google.cn/guide/distributed_training#using_tfdistributestrategy_with_custom_training_loops to define `train_step` and `test_step`.\n> \n> @nikitamaia Can you please take a loot at it. Thanks!\n\nYes the new keras doc hosted there is always related to Keras in TF namespace but It Is a distinct repository", "@bhack @jvishnuvardhan Thanks! I will try it soon.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48817\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48817\">No</a>\n"]}, {"number": 48816, "title": "log_softmax potential issue in tflite int8 quantization (how can we skip it?)", "body": "Since tf.nn.log_softmax givens unexpected constant [-15.9375] for many dimensions. Can I ask how we can skip particular operations quantization? ", "comments": ["@gyin-ai Please share simple stand alone code such that we can replicate the issue faced or if possible share a colab gist.", "https://colab.research.google.com/drive/17-UsPhrBmGkJGk3b4fYH1-voCrkYw4Vz?usp=sharing. I can see a lot of -15.9375 value. When I tried some in-house smaller model, all dimensions are this value [-15.9375]. \r\n\r\nIt would be great if you can provide some suggestions to fix this issue without skipping this op's quantization.\r\n@abattery ", "@jianlijianli could you triage this issue?", "Hi gyin-ai,\r\n\r\nI noticed you are using random numbers as the \"representative_dataset\". This is reasonable for making sure the conversion works but accuracy might be impacted. representative_dataset is to run some \"representative\" data (usually a subset of actual data) through the system so the min/max information is captured for activations and quantization process uses the min/max information to quantize the state.\r\n\r\nCould you please use some real data for representative_dataset?\r\n\r\nFor skipping particular operations quantization, we are working on some prototype of API that allows selectively quantize (or skip quantize) certain ops/layers. @daverim, @liufengdb, could you please help with the API? Thanks.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48816\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48816\">No</a>\n"]}, {"number": 48815, "title": "Expose a few C API functions to allow custom gradients", "body": "**System information**\r\n- TensorFlow version: 2.4.1\r\n- Are you willing to contribute it: Yes\r\n\r\nI'm working on adding custom gradient support to TF-Java, using the legacy graph bindings until the new API is done (tensorflow/java#292).\r\n\r\nThis requires exposing a few internal functions of the C API:\r\n* `TF_Operation* ToOperation(Node* node) ` to work with the c++ API for gradient defs (necessary since the `Node` constructor isn't public, I can't just use the struct).\r\n* `TF_NewOperationLocked` and\r\n* `TF_FinishOperationLocked` because both the C API gradient definition function and the normal versions of those functions lock the graph's muxex, preventing you from using the C API op def functions in a gradient definition.\r\n\r\n**Describe the feature and the current behavior/state.**\r\nI would like to expose the above functions, presumably in `c_api_internal.h`.  These functions are not exposed currently.\r\n\r\nAnother option is to create and expose a `TF_AddGradientsWithPrefixLocked` that doesn't use the mutex instead of exposing `TF_NewOperationLocked` and `TF_FinishOperationLocked`.\r\n\r\n**Will this change the current api? How?**\r\nIt will expose the above functions.\r\n\r\n**Who will benefit with this feature?**\r\n\r\nAnyone who wants to add custom gradient support to an API using the C API.\r\n", "comments": []}, {"number": 48814, "title": "Build Failure fix on AVX2 machines replace si64 with epi64", "body": "**Problem**:\r\nCI has failed because of a recent commit from Public TF from Google for all AVX2 builds.\r\n**Observation:**\r\n*  Failure happens in AVX2 Haswell Machines\r\n\r\n**Analysis**\r\n*  Failure is because of this commit for AVX2 https://github.com/tensorflow/tensorflow/commit/878e2bb97bcef2881650a12c2187cd8a2249a6ad\r\n*  To Reproduce you need to build using the following command that will use AVX2.\r\n*  build command: build --cxxopt=-D_GLIBCXX_USE_CXX11_ABI=0 --copt=-O3 --copt=-march=haswell\r\n\r\n**Fix**\r\n*  \"replace _mm_loadu_si64 with _mm_loadl_epi64 that generates the same assembly and works for AVX2 (such as Haswell machines).\"\r\n*  For reference: Similar Fix from before: https://github.com/abseil/abseil-cpp/issues/394\r\n", "comments": ["@gbaned  @lu-wang-g  @talumbau Can this be reviewed and merged soon. All AVX2 are having build failures currently for stock TF", "LGTM. Thanks for linking the Abseil issue.", "Noting here that we are explicitly moving from an unaligned load intrinsic `_mm_loadu_si64` to an essentially ambiguous load intrinsic `_mm_loadl_si64` which is less than ideal. See this discussion from Rust community:\r\n\r\nhttps://github.com/rust-lang/stdarch/issues/582\r\n\r\nUltimately the behavior is compiler dependent. The immediate harm is likely to be contained by merging here, but the right answer might be to rollback this code or add additional code to ensure alignment guarantees, since we are treading on less sure ground with this `loadl` instruction."]}, {"number": 48813, "title": "undefined reference to `tensorflow::Status::Status", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): \r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.4.1\r\n- Python version: python3.6\r\n- Bazel version (if compiling from source): bazel 3.1.0\r\n- GCC/Compiler version (if compiling from source): GCC7.5.0\r\n- CUDA/cuDNN version: N\r\n- GPU model and memory: N\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nI have run the speech command example, and I already trained the model with python, and now I want to inference with C++ API, so I build libtensorflow.so successfully, and I compile **label_wav.cc** with CMakefile.txt , errors as bellow:\r\n\r\n/usr/bin/ld: CMakeFiles/main.dir/label_wav.cc.o: in function `tensorflow::Status::Status(tensorflow::error::Code, absl::string_view)':\r\n/home/yw.shi/env/tf241/tensorflow/core/platform/status.h:54: undefined reference to `tensorflow::Status::Status(tensorflow::error::Code, absl::string_view, std::vector<tensorflow::StackFrame, std::allocator<tensorflow::StackFrame> >&&)'\r\ncollect2: \u9519\u8bef\uff1ald \u8fd4\u56de 1\r\nmake[2]: *** [CMakeFiles/main.dir/build.make:84\uff1a../main] \u9519\u8bef 1\r\nmake[1]: *** [CMakeFiles/Makefile2:76\uff1aCMakeFiles/main.dir/all] \u9519\u8bef 2\r\nmake: *** [Makefile:84\uff1aall] \u9519\u8bef 2\r\n\r\n\r\n**Describe the expected behavior**\r\nWant to know how to build the label_wav.cc with cmake.\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\nCMakefile.txt\r\ncmake_minimum_required(VERSION 2.8)\r\nproject(assistant-service)\r\n\r\nmessage(${CMAKE_SOURCE_DIR})\r\n\r\nif (${CMAKE_BUILD_TYPE} STREQUAL \"DEBUG\")\r\n    add_definitions(-D_DEBUG)\r\nendif (${CMAKE_BUILD_TYPE} STREQUAL \"DEBUG\")\r\n\r\nset(CMAKE_CXX_FLAGS \"${CMAKE_CXX_FLAGS} -std=c++11 -fPIC -fpermissive\")\r\nset(CMAKE_CXX_FLAGS_DEBUG \"-O0 -g -ggdb -Wall\")\r\nset(CMAKE_CXX_FLAGS_RELEASE \"-O3 -Wall\")\r\n\r\nSET(CMAKE_THIRDPARTY_PATH \"/home/yw.shi/env/tf241\")\r\n\r\nSET(CMAKE_BUILD_WITH_INSTALL_RPATH TRUE) \r\nSET(CMAKE_INSTALL_RPATH\r\n    \"/root/anaconda3/lib\"\r\n    \"/usr/lib64\"\r\n    \"/home/yw.shi/env/tf241/lib/\"\r\n    \"/home/yw.shi/env/tf241/third_party/abseil-cpp/lib/\"\r\n   )\r\n\r\nset(Main  \"${CMAKE_SOURCE_DIR}/label_wav.cc\")\r\n\r\ninclude_directories(\"/home/yw.shi/framework/tensorflow-2.4.1/bazel-tensorflow-2.4.1/external/eigen_archive\")\r\ninclude_directories(\"/home/yw.shi/env/tf241\")\r\ninclude_directories(\"/home/yw.shi/env/tf241/compile\")\r\n\r\ninclude_directories(\"/home/yw.shi/env/tf241/third_party/abseil-cpp/include/\")\r\ninclude_directories(\"/home/yw.shi/env/tf241/protobuf/v3.9.2/include/\")\r\n\r\n\r\nlink_directories(\"/usr/lib64\")\r\nlink_directories(\"/home/yw.shi/env/tf241/lib\")\r\nlink_directories(\"/home/yw.shi/env/tf241/protobuf/v3.9.2/lib/\")\r\n\r\nlink_directories(\"/home/yw.shi/env/tf241/third_party/abseil-cpp/lib64\")\r\n\r\nset(EXECUTABLE_OUTPUT_PATH ${CMAKE_SOURCE_DIR})\r\nadd_executable(main ${Main})\r\ntarget_link_libraries(main tensorflow_cc tensorflow_framework)\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Bug fix ,this was caused by the abseil-cpp version was not the same as it in tensorflow/workspace.bzl, so when I change the right version the problems was gone", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48813\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48813\">No</a>\n"]}, {"number": 48812, "title": "Port micro op GATHER_ND and its test code from lite", "body": "Issue #46268. This PR aims to finish porting GATHER_ND from TFL to TFLM.\r\n(This PR combines the originally planned PRS 3, 4, and 5)\r\n\r\nNotes:\r\n1 For params/output tensors, only the float and int8_t data types are supported;\r\n2 For indices tensors, only the int32_t data type is supported;\r\n3 The reference implementation in lite/kernels/internal/reference/reference_ops.h was not used, due to the vector used in the reference (possible dynamic allocation);\r\n4 As with the TFL kernel Gather_ND, the TFLM kernel does not yet support batch_dims as of April 23, 2021.", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", ":frowning_face: Sorry, but only Googlers may change the label `cla: yes`."]}, {"number": 48811, "title": "Port micro op GATHER_ND and its test code from lite", "body": "Issue #46268. This PR aims to finish porting GATHER_ND from TFL to TFLM.\r\n(This PR combines the originally planned PRS 3, 4, and 5)\r\n\r\nNotes:\r\n1 For params/output tensors, only the float and int8_t data types are supported;\r\n2 For indices tensors, only the int32_t data type is supported;\r\n3 The reference implementation in lite/kernels/internal/reference/reference_ops.h was not used, due to the vector used in the reference (possible dynamic allocation);\r\n4 As with the TFL kernel Gather_ND, the TFLM kernel does not yet support batch_dims as of April 23, 2021.", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 48810, "title": "xla Compiling and Bug issues", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution : UBUNTU 18.04\r\n- TensorFlow installed from (source or binary): NVIDIA Container 21.03\r\n- TensorFlow version (use command below): 1.15.5\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:11.2/8.1.1\r\n- GPU model and memory: A100 40GB\r\n\r\nDear All-\r\n\r\nWe tried to run a tensorflow based program with xla option on and with Float64. It throws the following error\r\n\r\n2021-04-28 21:33:40.228029: W ./tensorflow/compiler/xla/service/hlo_pass_fix.h:50] Unexpectedly high number of iterations in HLO passes 'simplification' exiting fixed point loop.\r\n2021-04-28 21:34:18.432071: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:70] Can't find ptxas binary in ${CUDA_DIR}/bin.  Will back to the GPU driver for PTX -> sass compilation.  This is OK so long as you don't see a warning below about an out-of-date driver version. Custom ptxas location can be specified using $PATH.\r\n2021-04-28 21:34:18.432136: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:71] Searched for CUDA in the following directories:\r\n2021-04-28 21:34:18.432146: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   ./cuda_sdk_lib\r\n2021-04-28 21:34:18.432150: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   /usr/local/cuda\r\n2021-04-28 21:34:18.432153: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   .\r\n2021-04-28 21:34:18.432157: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:76] You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\r\n2021-04-28 21:34:18.489483: I tensorflow/compiler/jit/xla_compilation_cache.cc:241] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\r\n2021-04-28 21:34:21.374512: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:70] Can't find ptxas binary in ${CUDA_DIR}/bin.  Will back to the GPU driver for PTX -> sass compilation.  This is OK so long as you don't see a warning below about an out-of-date driver version. Custom ptxas location can be specified using $PATH.\r\n2021-04-28 21:34:21.374608: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:71] Searched for CUDA in the following directories:\r\n2021-04-28 21:34:21.374616: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   ./cuda_sdk_lib\r\n2021-04-28 21:34:21.374620: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   /usr/local/cuda\r\n2021-04-28 21:34:21.374624: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   .\r\n2021-04-28 21:34:21.374629: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:76] You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\r\n2021-04-28 21:34:21.432005: I tensorflow/compiler/jit/xla_compilation_cache.cc:241] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\r\n2021-04-28 21:34:22.707773: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:70] Can't find ptxas binary in ${CUDA_DIR}/bin.  Will back to the GPU driver for PTX -> sass compilation.  This is OK so long as you don't see a warning below about an out-of-date driver version. Custom ptxas location can be specified using $PATH.\r\n2021-04-28 21:34:22.707843: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:71] Searched for CUDA in the following directories:\r\n2021-04-28 21:34:22.707865: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   ./cuda_sdk_lib\r\n2021-04-28 21:34:22.707870: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   /usr/local/cuda\r\n2021-04-28 21:34:22.707875: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   .\r\n2021-04-28 21:34:22.707881: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:76] You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\r\n2021-04-28 21:34:22.770755: I tensorflow/compiler/jit/xla_compilation_cache.cc:241] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\r\n2021-04-28 21:34:23.269560: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:70] Can't find ptxas binary in ${CUDA_DIR}/bin.  Will back to the GPU driver for PTX -> sass compilation.  This is OK so long as you don't see a warning below about an out-of-date driver version. Custom ptxas location can be specified using $PATH.\r\n2021-04-28 21:34:23.269643: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:71] Searched for CUDA in the following directories:\r\n2021-04-28 21:34:23.269654: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   ./cuda_sdk_lib\r\n2021-04-28 21:34:23.269658: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   /usr/local/cuda\r\n2021-04-28 21:34:23.269664: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   .\r\n2021-04-28 21:34:23.269668: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:76] You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\r\n2021-04-28 21:34:23.335512: I tensorflow/compiler/jit/xla_compilation_cache.cc:241] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\r\n2021-04-28 21:34:25.538813: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:70] Can't find ptxas binary in ${CUDA_DIR}/bin.  Will back to the GPU driver for PTX -> sass compilation.  This is OK so long as you don't see a warning below about an out-of-date driver version. Custom ptxas location can be specified using $PATH.\r\n2021-04-28 21:34:25.538892: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:71] Searched for CUDA in the following directories:\r\n2021-04-28 21:34:25.538902: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   ./cuda_sdk_lib\r\n2021-04-28 21:34:25.538907: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   /usr/local/cuda\r\n2021-04-28 21:34:25.538910: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   .\r\n2021-04-28 21:34:25.538915: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:76] You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\r\n2021-04-28 21:34:25.597336: I tensorflow/compiler/jit/xla_compilation_cache.cc:241] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\r\n2021-04-28 21:34:26.675753: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:70] Can't find ptxas binary in ${CUDA_DIR}/bin.  Will back to the GPU driver for PTX -> sass compilation.  This is OK so long as you don't see a warning below about an out-of-date driver version. Custom ptxas location can be specified using $PATH.\r\n2021-04-28 21:34:26.675825: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:71] Searched for CUDA in the following directories:\r\n2021-04-28 21:34:26.675835: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   ./cuda_sdk_lib\r\n2021-04-28 21:34:26.675839: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   /usr/local/cuda\r\n2021-04-28 21:34:26.675844: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   .\r\n2021-04-28 21:34:26.675873: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:76] You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\r\n2021-04-28 21:34:26.738493: I tensorflow/compiler/jit/xla_compilation_cache.cc:241] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\r\n2021-04-28 21:34:28.676419: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:70] Can't find ptxas binary in ${CUDA_DIR}/bin.  Will back to the GPU driver for PTX -> sass compilation.  This is OK so long as you don't see a warning below about an out-of-date driver version. Custom ptxas location can be specified using $PATH.\r\n2021-04-28 21:34:28.676522: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:71] Searched for CUDA in the following directories:\r\n2021-04-28 21:34:28.676543: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   ./cuda_sdk_lib\r\n2021-04-28 21:34:28.676550: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   /usr/local/cuda\r\n2021-04-28 21:34:28.676554: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   .\r\n2021-04-28 21:34:28.676558: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:76] You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\r\n2021-04-28 21:34:28.692114: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:70] Can't find ptxas binary in ${CUDA_DIR}/bin.  Will back to the GPU driver for PTX -> sass compilation.  This is OK so long as you don't see a warning below about an out-of-date driver version. Custom ptxas location can be specified using $PATH.\r\n2021-04-28 21:34:28.692203: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:71] Searched for CUDA in the following directories:\r\n2021-04-28 21:34:28.692213: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   ./cuda_sdk_lib\r\n2021-04-28 21:34:28.692219: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   /usr/local/cuda\r\n2021-04-28 21:34:28.692223: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:74]   .\r\n2021-04-28 21:34:28.692226: W tensorflow/compiler/xla/service/gpu/nvptx_compiler.cc:76] You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\r\n2021-04-28 21:34:28.741081: I tensorflow/compiler/jit/xla_compilation_cache.cc:241] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\r\n2021-04-28 21:34:28.754700: I tensorflow/compiler/jit/xla_compilation_cache.cc:241] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\r\n2021-04-28 21:34:30.031037: E tensorflow/stream_executor/cuda/cuda_driver.cc:614] failed to load PTX text as a module: CUDA_ERROR_INVALID_PTX: a PTX JIT compilation failed\r\n2021-04-28 21:34:30.031132: E tensorflow/stream_executor/cuda/cuda_driver.cc:619] error log buffer (1024 bytes): ptxas error   : Entry function 'fusion_466' uses too much shared data (0xc600 bytes, 0xc000 max)\r\nptxas error   : Entry function 'fusion_462' uses too much shared data (0xc600 bytes, 0xc000 max)\r\nptxas error   : Entry function 'fusion_488' uses too much shared data (0xc600 bytes, 0xc000 max)\r\nptxas error   : Entry function 'fusion_498' uses too much shared data (0xc600 bytes, 0xc000 max)\r\nptxas error   : Entry function 'fusion_490' uses too much shared data (0xc600 bytes, 0xc000 max)\r\nptxas error   : Entry function 'fusion_500' uses too much shared data (0xc600 bytes, 0xc000 max)\r\nptxas error   : Entry function 'fusion_520' uses too much shared data (0xc600 bytes, 0xc000 max)\r\nptxas error   : Entry function 'fusion_524' uses too much shared data (0xc600 bytes, 0xc000 max)\r\nptxas error   : Entry function 'fusion_460' uses too much shared data (0xc600 bytes, 0xc000 max)\r\nptxas error   : Entry function 'fusion_534' uses too much shared data (0xc600 bytes, 0xc000 max)\r\nptxas error   : Entry function 'fusion_464' uses too \r\nTraceback (most recent call last):\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\r\n    return fn(*args)\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/client/session.py\", line 1349, in _run_fn\r\n    return self._call_tf_sessionrun(options, feed_dict, fetch_list,\r\n  File \"/usr/local/lib/python3.8/dist-packages/tensorflow_core/python/client/session.py\", line 1441, in _call_tf_sessionrun\r\n    return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\r\ntensorflow.python.framework.errors_impl.InternalError: Failed to load PTX text as a module: CUDA_ERROR_INVALID_PTX: a PTX JIT compilation failed\r\n\t [[{{node cluster_2_1/xla_run}}]]\r\nThe same code run with out the xla option on. The xla option work seamlessly for float32 and tf32.\r\n\r\nWe will appreciate your help.\r\n\r\nThanks!\r\nRaj\r\n", "comments": ["@raj-brown \r\n\r\nIn order to expedite the trouble-shooting process, please provide a code snippet/colab gist to reproduce the issue reported here. Thanks!\r\n\r\n\r\n\r\n", "@raj-brown \r\nCan you please confirm if you face this issue on stable version 2.4.1 along with cuda 11.0 [cuda version 11.2 is tested with tf 2.5, there is no update on 11.3].Thanks", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48810\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48810\">No</a>\n"]}, {"number": 48809, "title": "Exclude some Python targets from OSS presubmit checks.", "body": "While these targets work ok in the TF github repo, they need some additional setup for the tflite-micro repo which we are currently punting on.\r\n\r\nFixes http://b/186670822", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 48808, "title": "Tensorflow 2.3 or up Installation on Mac OS Big Sur 11.3", "body": "Hi,\r\n\r\nI am trying to install tensorflow 2.3 or up on Mac OS Big Sur 11.3.  I'm trying to do it in a conda environment with python 3.7.  This is a cpu install.  \r\n\r\nWhen I try pip install tensorflow, and go into a python terminal and import, it says that the module does not exist.  \r\nWhen I conda install tensorflow in the conda environment and go into a python terminal and import, I can only get tensorflow 2.0.0.  \r\nWhen I try conda install -c conda-forge tensorflow and go into a python terminal and import tensorflow, I get a slew of warnings of signed and unsigned types:\r\n/Users/blah/anaconda3/envs/funkmuffin2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: \r\nFutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\n/Users/blah/anaconda3/envs/funkmuffin2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: \r\nFutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\r\n.....\r\n/Users/blah/anaconda3/envs/funkmuffin2/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\r\n.... and when I conda update -f -c conda-forge tensorflow, I get the same warnings and I still only get tensorflow 1.14.\r\n\r\nWould you know why I cannot simply get tensorflow 2.3 or higher installed?  and/or would anybody know how to do so?  Thank you.   \r\n\r\n", "comments": ["Saw something similar. Are you on an M1 Mac?", "Thanks for the speedy reply.  No.  It's Intel Core i7.  \r\n\r\n\r\n> Saw something similar. Are you on an M1 Mac?\r\n\r\n", "@o0stsou0o \r\nWhat is the numpy version on your system, there seems to be compatibility issues with your tensorflow and numpy.\r\n\r\nCan you try: pip install   tensorflow 2.4.1 with numpy  1.19.x and let us know. [ypu may refer to [this comment](https://github.com/tensorflow/tensorflow/issues/47878#issuecomment-802602008), [link](https://stackoverflow.com/questions/57381430/synonym-of-type-is-deprecated-in-a-future-version-of-numpy-it-will-be-underst),#30427,#31249]", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48808\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/48808\">No</a>\n"]}, {"number": 48807, "title": "Do not check md files as part of check_contents.", "body": "Documentation should be exempt from these checks. For example the references to gmock in https://github.com/tensorflow/tensorflow/pull/48805 is intended and useful.\r\n", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 48806, "title": "[XLA/GPU] Add CustomCallSchedule to give schedule hints to custom-calls.", "body": "Add schedule hints EARLY_AS_POSSIBLE and LATE_AS_POSSIBLE to custom-calls.\r\nThis supports a custom-call case, where a logical operation can be lowered into\r\ntwo HLOs (e.g., PerformX and PerformXDone). We can utilize this mechanism to\r\neither hide host latencies between the pair of the custom-calls or the two calls\r\ncan more accurately identify the def-use relationship (typically PerformX is\r\nscheduled right after all of its producers have been scheduled and PerformXDone\r\nis scheduled right before its first consumer.)\r\n\r\nI need this change for implementing XLA Horovod ops. I have a working prototype internally within NVIDIA and it works well with this change for our tracked DL models, i.e., host overhead is well hidden and I do see some overlapping/parallelism between communication and computation.\r\n", "comments": ["@timshen91 could you help to review this PR? Thanks!\r\n\r\n@cheshire @sanjoy FYI.", "Please&nbsp;don't&nbsp;send&nbsp;me&nbsp;any&nbsp;more&nbsp;documents\r\n\r\n\r\n---Original---\r\nFrom: &quot;Marcello ***@***.***&gt;\r\nDate: Thu, Apr 29, 2021 23:32 PM\r\nTo: ***@***.***&gt;;\r\nCc: ***@***.***&gt;;\r\nSubject: Re: [tensorflow/tensorflow] [XLA/GPU] Add CustomCallSchedule to give schedule hints to custom-calls. (#48806)\r\n\r\n\r\n\r\n\r\n \r\n@Kariddi commented on this pull request.\r\n \r\n \r\nIn tensorflow/compiler/xla/service/gpu/gpu_hlo_schedule.cc:\r\n &gt; +    const std::vector<HloInstruction*&gt;&amp; instrs = input.instructions(); +    for (HloInstruction* instr : instrs) { +      if (scheduled.contains(instr)) { +        continue; +      } + +      early_as_possible_sched.push_back(instr); +      scheduled.insert(instr); + +      for (HloInstruction* user : instr-&gt;users()) { +        // Schedule any user who has the attribute `early_as_possible` and all +        // of its producers have been scheduled. +        if (CustomCallWithSchedule(user, +                                   CustomCallSchedule::EARLY_AS_POSSIBLE) &amp;&amp; +            absl::c_all_of(user-&gt;operands(), [&amp;](const HloInstruction* opnd) { +              return scheduled.contains(opnd);  \r\nShould control-dependencies also be checked?\r\n \r\n \r\nIn tensorflow/compiler/xla/service/gpu/gpu_hlo_schedule.cc:\r\n &gt; +    for (auto it = early_as_possible_sched.rbegin(); +         it != early_as_possible_sched.rend(); it++) { +      if (scheduled.contains(*it)) { +        continue; +      } + +      late_as_possible_sched.push_front(*it); +      scheduled.insert(*it); + +      for (HloInstruction* opnd : (*it)-&gt;unique_operands()) { +        // Schedule any opnd who has the attribute `late_as_possible` if all of +        // its users have been scheduled. +        if (CustomCallWithSchedule(opnd, +                                   CustomCallSchedule::LATE_AS_POSSIBLE) &amp;&amp; +            absl::c_all_of(opnd-&gt;users(), [&amp;](const HloInstruction* u) { +              return scheduled.contains(u);  \r\nSame about control-dependencies. I think you might need to check it.\r\n \r\n \r\nIn tensorflow/compiler/xla/service/hlo_parser_test.cc:\r\n &gt; @@ -1079,6 +1079,18 @@ ENTRY %CustomCallWithAliasing (p0: (f32[2,2], f32[42,2,3]), p1: f32[123,4]) -&gt; (    ROOT %custom-call = (f32[123,4]{0,1}, f32[2,2]{0,1}, f32[1,2,3]{0,1,2}) custom-call((f32[2,2]{0,1}, f32[42,2,3]{0,1,2}) %p0, f32[123,4]{0,1} %p1), custom_call_target=&quot;baz&quot;, output_to_operand_aliasing={{0}: (1, {}), {1}: (0, {0})}  }   +)&quot; +}, +// CustomCall with schedule. +{ +&quot;CustomCallWithSchedule&quot;, +R&quot;(HloModule custom_call + +ENTRY %CustomCall () -&gt; f32[1,2,3] { +  %constant = f32[1]{0} constant({12345}) +  ROOT %custom-call = f32[1,2,3]{0,2,1} custom-call(f32[1]{0} %constant), custom_call_target=&quot;foo\\&quot;bar&quot;, schedule=LATE_AS_POSSIBLE  \r\nCould you add the tests also for EARLY ?\r\n \r\n \r\nIn tensorflow/compiler/xla/service/hlo_memory_scheduler.h:\r\n &gt; @@ -32,6 +32,12 @@ limitations under the License.    namespace xla {   +// Postprocessor of the HloInstructionSequence. This is an opt-in postprocessing +// function to MemorySchedulerAlgorithm to enforce certain hlo schedule +// constraints desired for custom-calls. +typedef std::function<HloInstructionSequence(const HloInstructionSequence&amp;)&gt;  \r\n+1\r\n \r\n&mdash;\r\nYou are receiving this because you are subscribed to this thread.\r\nReply to this email directly, view it on GitHub, or unsubscribe.", "Codes updated. Please help to take another look. Thanks!", "@Kariddi A test failure is because I missed the initialization of custom_call_schedule_ in one of the `HloCustomCallInstruction` constructors. (EDIT: just checked. It was missing because that constructor is new and not in NV's forked branch.) I push [a commit](https://github.com/tensorflow/tensorflow/pull/48806/commits/ba453144301af295b09643ab3f3fde5d8055756d) to fix it. I don't think other test/build failures in the CI are related to this PR.\r\n\r\nCould you please approve the PR again? Thanks!", "> @Kariddi A test failure is because I missed the initialization of custom_call_schedule_ in one of the `HloCustomCallInstruction` constructors. (EDIT: just checked. It was missing because that constructor is new and not in NV's forked branch.) I push [a commit](https://github.com/tensorflow/tensorflow/pull/48806/commits/ba453144301af295b09643ab3f3fde5d8055756d) to fix it. I don't think other test/build failures in the CI are related to this PR.\r\n> \r\n> Could you please approve the PR again? Thanks!\r\n\r\nping~\r\n", "@sanjoy are you still on this?", "Warning: Unhelpful next ID: saw 76 but field \"custom_call_schedule\" already uses it. Use 77 instead? [misleading_next_id]\r\n", "Will do. I have some internet issue. Will do when my internet is up.\n\nOn Fri, May 14, 2021 at 3:59 PM George Karpenkov ***@***.***>\nwrote:\n\n> Warning: Unhelpful next ID: saw 76 but field \"custom_call_schedule\"\n> already uses it. Use 77 instead? [misleading_next_id]\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/48806#issuecomment-841541045>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AC3VUT5PTKKLR6B7O2KQGRLTNWTM7ANCNFSM43XR3SYA>\n> .\n>\n", "> Warning: Unhelpful next ID: saw 76 but field \"custom_call_schedule\" already uses it. Use 77 instead? [misleading_next_id]\r\n\r\nUpdated. Please help to take a look again."]}, {"number": 48805, "title": "micro: add documentation on porting ops from lite to micro", "body": "", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "@rkuester can you please check sanity build failures ?", "> @rkuester can you please check sanity build failures ?\r\n\r\nthe build failures are unrelated to the current PR and can be ignored."]}, {"number": 48804, "title": "Revert \"[Cherrypick:2.5]Switch absl to `lts_2021_03_24` LTS branch\"", "body": "Reverts tensorflow/tensorflow#48618\r\n\r\nBreaks TF Text on 2.5 release.", "comments": []}]