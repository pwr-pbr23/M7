[{"number": 47091, "title": "Calling tf.linalg.expm causes SIGSEGV. ", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Home (19041.789)\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.5.0-dev20201216\r\n- Python version: 3.7.7\r\n- CUDA/cuDNN version: 11.0.3/8.0.4.30\r\n- GPU model and memory: RTX 3070, 8GB\r\n\r\nCalling `tf.linalg.expm` causes the interpreter to exit. Attaching GDB reveals a SIGSEGV in thread 1. I have attached a demangled stack trace.\r\nCalling `tf.linalg.expm` should return a tensor with the result.\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\ntf.linalg.expm(tf.constant([[1.0]]))\r\n```\r\nPassing larger matrices or the result of `tf.random.normal` doesn't change the behavior. \r\n\r\n[tf_stacktrace.txt](https://github.com/tensorflow/tensorflow/files/5967082/tf_stacktrace.txt)\r\n", "comments": ["@relgukxilef,\r\nI was able to run the code without any issues on [TF v2.4](https://colab.research.google.com/gist/amahendrakar/59040e0ba2e0095d54ec56a923380bd9/47091.ipynb#scrollTo=eAcOTxDwx2UZ) and [TF-nightly](https://colab.research.google.com/gist/amahendrakar/05d9f648aff82758c4cebb382168d574/47091-tf-nightly.ipynb). Please check the linked gist for reference.\r\n\r\nCould you please try running the code in a new virtual environment and check if you are facing the same error. Thanks!", "The error occurs in both this environment and a second environment running Python 3.8.5 and TF 2.5.0-dev20210204 (the newest nightly at the time of installation). Both were created through Anaconda (which is not the recommended way of installing TF anymore)\r\nWhen creating a new environment with `virtualenv` and installing TF through pip (either `tensorflow` or `tf-nightly`) this problem does not occur. As far as I am concerned this is a solution for my case. Thanks for the suggestion. ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47091\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47091\">No</a>\n"]}, {"number": 47090, "title": "Loading of shuffle buffer occurs every epoch drastically increasing training time using tf.datasets", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 4.0.2\r\n- Python version: 3.6.9\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 8.0.2.39\r\n- GPU model and memory: 2x RTX 3090 w/24GB memory\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nHi all,\r\n\r\nFirstly, apologies if this is in the wrong place but I feel this is something that would be amazing to address if possible!\r\nI am training a model using images stored in a directory and creating datasets with the tf.keras.preprocessing.image_dataset_from_directory() method. Images are set as 50 x 50 pixels, greyscale.\r\nMy training routine is lightning fast thanks to the RTX 3090 graphics card. However, there is substantial I/O bottlenecking when filling the shuffle buffer up. Is there a way to address this and make it faster?\r\n\r\nI can see the shuffle buffer being reloaded every single Epoch which takes significant time.\r\n\r\nThanks!\r\n\r\n**Describe the expected behavior**\r\n\r\nLoading of the shuffle buffer only once to significantly decrease training time.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```\r\n\r\n## create data sets \r\n\r\n        train_ds = tf.keras.preprocessing.image_dataset_from_directory(\r\n          data_dir,\r\n          validation_split=validation_split,\r\n          subset=\"training\",\r\n          seed=seed,\r\n          image_size=(img_height, img_width),\r\n          batch_size=batch_size,\r\n          color_mode='grayscale'\r\n        )\r\n\r\n        val_ds = tf.keras.preprocessing.image_dataset_from_directory(\r\n          data_dir,\r\n          validation_split=validation_split,\r\n          subset=\"validation\",\r\n          seed=seed,\r\n          image_size=(img_height, img_width),\r\n          batch_size=batch_size,\r\n          color_mode='grayscale'\r\n        )\r\n\r\n## create and compile model \r\nmodel = get_compiled_model()\r\n\r\n## train network (call back simply saves epoch data if epoch result is better than previous)\r\n        history = model.fit(\r\n          train_ds,\r\n          validation_data=val_ds,\r\n          epochs=epochs,\r\n          initial_epoch=offset,\r\n          callbacks=callbacks,\r\n          steps_per_epoch=None,\r\n          validation_steps=None\r\n        )\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@LastHorizon \r\nI ran the code shared and face a different error, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/05edbb8ec298189d44c346d9568aaf1f/untitled529.ipynb).\r\nPlease share code that is indented and provide all dependencies, if possible share a colab gist as well with the data n error reported.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47090\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47090\">No</a>\n"]}, {"number": 47088, "title": "Switching to Cadence HiFi 4 NN Library v2.4.0", "body": "Using the latest version of HiFi 4 NN Library.\r\nThis version has optimized implementation of SVDF and Quantize for int8 datatype.\r\n\r\nTested the change using following commands:\r\n```\r\nmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=xtensa OPTIMIZED_KERNEL_DIR=xtensa TARGET_ARCH=hifi4 XTENSA_TOOLS_VERSION=RI-2020.5-linux XTENSA_CORE=AE_HiFi4_LE5_FP_XC clean_downloads\r\nmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=xtensa OPTIMIZED_KERNEL_DIR=xtensa TARGET_ARCH=hifi4 XTENSA_TOOLS_VERSION=RI-2020.5-linux XTENSA_CORE=AE_HiFi4_LE5_FP_XC test_kernel_fully_connected_test\r\n```", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "tagging @advaitjain @nyadla-sys @bhanuprakashbv "]}, {"number": 47087, "title": "NotImplementedError: Cannot convert a symbolic Tensor to a numpy array.", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary (pacman -S python-tensorflow)\r\n- TensorFlow version (use command below): 2.4.1\r\n- Python version: 3.9.1\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- GPU model and memory: Nvidia Geforce GTX 1060 6GB\r\n\r\n**Describe the current behavior**\r\n```\r\n\r\n2021-02-10 17:51:13.037468: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2021-02-10 17:51:13.037899: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2021-02-10 17:51:13.038418: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\r\nTraceback (most recent call last):\r\n  File \"/run/media/volker/DATA/configruns/load/./test.py\", line 13, in <module>\r\n    lstm = Bidirectional(lstm_nobi, name=\"layerC\")(embedding_layer)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/layers/wrappers.py\", line 539, in __call__\r\n    return super(Bidirectional, self).__call__(inputs, **kwargs)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 951, in __call__\r\n    return self._functional_construction_call(inputs, args, kwargs,\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1090, in _functional_construction_call\r\n    outputs = self._keras_tensor_symbolic_call(\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 822, in _keras_tensor_symbolic_call\r\n    return self._infer_output_signature(inputs, args, kwargs, input_masks)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 863, in _infer_output_signature\r\n    outputs = call_fn(inputs, *args, **kwargs)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/layers/wrappers.py\", line 652, in call\r\n    y = self.forward_layer(forward_inputs,\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py\", line 660, in __call__\r\n    return super(RNN, self).__call__(inputs, **kwargs)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 1012, in __call__\r\n    outputs = call_fn(inputs, *args, **kwargs)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/layers/recurrent_v2.py\", line 1157, in call\r\n    inputs, initial_state, _ = self._process_inputs(inputs, initial_state, None)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py\", line 859, in _process_inputs\r\n    initial_state = self.get_initial_state(inputs)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py\", line 642, in get_initial_state\r\n    init_state = get_initial_state_fn(\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py\", line 2506, in get_initial_state\r\n    return list(_generate_zero_filled_state_for_cell(\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py\", line 2987, in _generate_zero_filled_state_for_cell\r\n    return _generate_zero_filled_state(batch_size, cell.state_size, dtype)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py\", line 3003, in _generate_zero_filled_state\r\n    return nest.map_structure(create_zeros, state_size)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/util/nest.py\", line 659, in map_structure\r\n    structure[0], [func(*x) for x in entries],\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/util/nest.py\", line 659, in <listcomp>\r\n    structure[0], [func(*x) for x in entries],\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/keras/layers/recurrent.py\", line 3000, in create_zeros\r\n    return array_ops.zeros(init_state_size, dtype=dtype)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 201, in wrapper\r\n    return target(*args, **kwargs)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 2819, in wrapped\r\n    tensor = fun(*args, **kwargs)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 2868, in zeros\r\n    output = _constant_if_small(zero, shape, dtype, name)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 2804, in _constant_if_small\r\n    if np.prod(shape) < 1000:\r\n  File \"<__array_function__ internals>\", line 5, in prod\r\n  File \"/home/volker/.local/lib/python3.9/site-packages/numpy/core/fromnumeric.py\", line 3030, in prod\r\n    return _wrapreduction(a, np.multiply, 'prod', axis, dtype, out,\r\n  File \"/home/volker/.local/lib/python3.9/site-packages/numpy/core/fromnumeric.py\", line 87, in _wrapreduction\r\n    return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\r\n  File \"/usr/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 852, in __array__\r\n    raise NotImplementedError(\r\nNotImplementedError: Cannot convert a symbolic Tensor (layerC/forward_layerB/strided_slice:0) to a numpy array. This error may indicate that you're trying to pass a Tensor to a NumPy call, which is not supported\r\n```\r\n\r\n**Describe the expected behavior**\r\n\r\nNo NotImplementedError. [Here](https://stackoverflow.com/questions/66141547/notimplementederror-cannot-convert-a-symbolic-tensor-to-a-numpy-array?noredirect=1#comment116947834_66141547) someone claimed that with tf version 2.3.0, python 3.7.0, and numpy 1.19.2 it works. I also remember that code working about 10 months ago.\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```\r\nimport numpy as np\r\nfrom keras.layers import LSTM, Embedding, Input, Bidirectional\r\n\r\ndim = 30\r\nmax_seq_length = 40\r\nvecs = np.random.rand(45,dim)\r\n\r\ninput_layer = Input(shape=(max_seq_length,))\r\nembedding_layer = Embedding(len(vecs), dim, weights=[vecs], input_length=max_seq_length, trainable=False, name=\"layerA\")(input_layer)\r\nlstm_nobi = LSTM(max_seq_length, return_sequences=True, activation=\"linear\", name=\"layerB\")\r\nlstm = Bidirectional(lstm_nobi, name=\"layerC\")(embedding_layer)\r\n```\r\n\r\n", "comments": ["@Volker-Weissmann,\r\nI was able to run the code without any issues with TF v2.4.1. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/67488d44be04874d3b139ce03c0b9cf4/47087.ipynb).\r\n\r\nCould you please try running the code in a new virtual environment and let us know if you're facing the same error. Thanks!", "Turns out that tensorflow does not support Python 3.9.\r\nUsing python 3.8 solves this problem.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47087\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47087\">No</a>\n"]}, {"number": 47086, "title": " SavedModel restored in Graph mode under MirroredStrategy crashes global_variables_initializer", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux: colab.research.google.com and others\r\n- TensorFlow installed from (source or binary): pre-installed on colab\r\n- TensorFlow version (use command below): 2.4.1\r\n- Python version: 3.6.9\r\n\r\n**Describe the current behavior**\r\n\r\n1) `tf.compat.v1.global_variables_initializer()` crashes with `TypeError: Expected tf.group() expected Tensor arguments not 'None'` after restoring a SavedModel in Graph mode under MirroredStrategy as in the code below.\r\n\r\n2) Estimator does this kind of initialization automatically when used with `RunConfig(..., train_distribute=MirroredStrategy())`, so just fixing the example below won't help. See https://github.com/tensorflow/hub/issues/704 for user-level impact.\r\n\r\n**Describe the expected behavior**\r\n\r\n1) `tf.compat.v1.global_variables_initializer()` succeeds in this situation.\r\n\r\n2) An Estimator `model_fn` can use `tf.saved_model.load()` without this crash when used with `RunConfig(..., train_distribute=MirroredStrategy())`.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n[Also shared with Alphabet at https://colab.research.google.com/drive/1piVum7WJb_WlYhHbW6tYO7gWSzJeT7oO ]\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nclass Twice(tf.train.Checkpoint):\r\n  def __init__(self):\r\n    self._two = tf.Variable(2.0, name=\"two\")\r\n\r\n  @tf.function(input_signature=[tf.TensorSpec((None, None), tf.float32)])\r\n  def __call__(self, x):\r\n    return tf.multiply(x, self._two)\r\n\r\nexport_dir = \"/tmp/twice\"\r\ntf.saved_model.save(Twice(), export_dir)\r\n\r\nstrategy = tf.distribute.MirroredStrategy()\r\nwith tf.Graph().as_default() as g:\r\n  with strategy.scope():\r\n    obj = tf.saved_model.load(export_dir)\r\n\r\n  for v in tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.GLOBAL_VARIABLES):\r\n    prefix = \"NO INIT\" if v.initializer is None else \"ok init\"\r\n    print(prefix, v)\r\n\r\n  init_op = tf.compat.v1.global_variables_initializer()\r\n```\r\n\r\n```\r\nINFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\r\nNO INIT <tf.Variable 'two:0' shape=() dtype=float32>\r\nok init MirroredVariable:{\r\n  0: <tf.Variable 'two:0' shape=() dtype=float32>\r\n}\r\n---------------------------------------------------------------------------\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-4-7fd461f5dad0> in <module>()\r\n      8     print(prefix, v)\r\n      9 \r\n---> 10   init_op = tf.compat.v1.global_variables_initializer()\r\n\r\n2 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/control_flow_ops.py in group(*inputs, **kwargs)\r\n   2921       if not hasattr(inp, \"device\"):\r\n   2922         raise TypeError(\"Expected tf.group() expected Tensor arguments not \"\r\n-> 2923                         \"'%s' with type '%s'\" % (inp, type(inp)))\r\n   2924       dev = inp.device\r\n   2925       if dev in ops_on_device:\r\n\r\nTypeError: Expected tf.group() expected Tensor arguments not 'None' with type '<class 'NoneType'>'\r\n```\r\n", "comments": ["I am able to replicate the issue reported on tf 2.4 and nightly, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/94db1593f4993a582109e30cc5ad4b65/untitled532.ipynb)", "The issue is fixed in tf-nightly.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47086\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47086\">No</a>\n"]}, {"number": 47085, "title": "KerasClassifier, GridSearchCV ignore with tf.device('cpu:0')", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): pip install tensorflow\r\n- TensorFlow version (use command below): 2.4.1\r\n- Python version: 3.8.5\r\n- CUDA/cuDNN version: CUDA v11.0.2/cuDNN v8.0.4.30\r\n- GPU model and memory: Quadro M1200\r\n\r\n**Describe the current behavior**\r\nUsing KerasClassifier in combination with GridSearchCV ignores if I force to use CPU computing instead of GPU using `with tf.device('cpu:0')`\r\n\r\n**Describe the expected behavior**\r\nTF and Keras libraries should use specified hardware (CPU or GPU) if it is inside the `with tf.device(DEVICE_NAME)`.\r\n\r\n**Standalone code to reproduce the issue**\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Dense, Dropout\r\nfrom tensorflow.keras.wrappers.scikit_learn import KerasClassifier\r\nfrom sklearn.model_selection import GridSearchCV\r\n\r\ntf.debugging.set_log_device_placement(True)\r\nX_train = np.random.rand(1000,7)\r\ninput_dim = X_train.shape[1]\r\nepochs = [5, 10, 15]\r\nbatch_size = [10, 20, 30, 40]\r\nparam_grid = dict(epochs=epochs, batch_size=batch_size)\r\n\r\ndef create_sequential_model(activation='relu', dropout_rate=0.2, optimizer='SGD'):\r\n    model = Sequential()\r\n    model.add(Dense(4, input_dim=input_dim, activation=activation))\r\n    model.add(Dropout(dropout_rate))\r\n    model.add(Dense(2, activation=activation))\r\n    model.add(Dense(4, activation=activation))\r\n    model.add(Dense(7, activation='sigmoid'))\r\n    model.compile(loss='mse', optimizer=optimizer, metrics=['accuracy'])\r\n    return model\r\n\r\nwith tf.device('cpu:0'): # This works and runs on CPU\r\n    a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\r\n    b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\r\nc = tf.matmul(a, b) # This works and runs on GPU\r\nprint(c)\r\n\r\nwith tf.device('cpu:0'): # This doesn't work\r\n    model = KerasClassifier(build_fn=create_sequential_model, verbose=1) \r\n    grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=5)\r\n    grid_result = grid.fit(X_train, X_train) \r\n```\r\n\r\n**Other info / logs**\r\nProof it is using GPU instead of CPU\r\n![ErrorTFCPUGPU](https://user-images.githubusercontent.com/2531157/107632092-4da42880-6c66-11eb-91a0-d10e6bf514a6.png)\r\n\r\nPlease find the error displayed below (I know this error is because the parameter `n_jobs=-1` of GridSearchCV is not supported on tensorflow if using GPU)\r\n`TerminatedWorkerError: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.`\r\n", "comments": ["Also, I would like to add that I tried using the \"trick\" of setting `os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"` and it works. However, I intend to use GPU after I have obtained the best hyperparameters with the other created model and using the `fit` and `predict` function. So if I set CUDA_VISIBLE_DEVICES to -1 and then I try to set it back to '0' or '1', GPU won't work anymore and I would have to reinitize my whole program (or kernel if inside Jupyter Notebook) in order for GPU to work.", "@dvelaren \r\nI have tried in colab with TF-GPU version 2.4.1 . Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/0beae0906a79e8f19f9e01071d642e30/untitled671.ipynb).You are also seeing the same behavior?\r\nThanks!", "> @dvelaren\r\n> I have tried in colab with TF-GPU version 2.4.1 . Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/0beae0906a79e8f19f9e01071d642e30/untitled671.ipynb).You are also seeing the same behavior?\r\n> Thanks!\r\n\r\nHello @ravikyram your colab works even in the GridSearchCV. However error persist when trying outside of Colab.", "Hi @dvelaren ! Is this issue still valid in 2.8 version?", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47085\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47085\">No</a>\n"]}, {"number": 47084, "title": "Fix a bug where reordering tf.Transpose is not done correctly", "body": "When reordering tf.Transpose (downwards) and the original transpose must be preserved, the insertion point is off-by-one.\r\n\r\nAs demonstrated in attached test, this scenario is not handled properly:\r\n\r\n```\r\n%0 = transpose(%input, %axis_t)\r\n%1 = pad(%0, %axis_p)\r\nreturn %0, %1\r\n```\r\n\r\nWill get `operand #0 does not dominate this use` error from IR verifier, indicating a value is used before its def.\r\n\r\ncc: @huangkang-chn\r\n", "comments": []}, {"number": 47083, "title": "No gradients provided for any variable, check your graph for ops that do not support gradients, between variables. Problem with tf.cast op", "body": "I am creating a model using tf v1 and I got this problem and I dont know how to solve it, any ideas? I think is due to tf.cast op, but i need to use it so if a number is < 1, it turns into 0\r\n\r\nError: No gradients provided for any variable, check your graph for ops that do not support gradients, between variables\r\n\r\nMy code:\r\n\r\n#Ejemplo para 4 datos: Location, Email, IMEI y Device ID: \r\nfiltracion_location = tf.placeholder(tf.float32, name='location_input')\r\nfiltracion_email = tf.placeholder(tf.float32, name='email_input')\r\nfiltracion_imei = tf.placeholder(tf.float32, name='imei_input')\r\nfiltracion_device = tf.placeholder(tf.float32, name='device_input')\r\n\r\n#objetivo: answer: 1 \u00f2 0\r\ny_ = tf.placeholder(tf.float32, name='target')\r\n\r\n#distintos pesos para cada dato: nombre= Px\r\nPlocation = tf.Variable(9., name='Plocation')\r\nPemail = tf.Variable(8., name='Pemail')\r\nPimei = tf.Variable(3., name='Pimei')\r\nPdevice = tf.Variable(2., name='Pdevice')\r\n\r\n#umbral de decisi\u00f3n\r\numbral = tf.Variable(10., name='umbral')\r\n\r\n#variables auxiliares: \r\ny_aux1 = tf.Variable(0.)\r\ny_aux2 = tf.Variable(0.)\r\ny_aux3 = tf.Variable(0.)\r\ny_aux4 = tf.Variable(0.)\r\ny_aux5 = tf.Variable(0.)\r\ny_aux6 = tf.Variable(0.)\r\ny_aux7 = tf.Variable(0.)\r\n\r\n#salida del modelo\r\ny_aux1 = tf.add(tf.multiply(filtracion_location, Plocation), 0.0)\r\ny_aux2 = tf.add(tf.multiply(filtracion_email, Pemail), y_aux1)\r\ny_aux3 = tf.add(tf.multiply(filtracion_imei, Pimei), y_aux2)\r\ny_aux4 = tf.add(tf.multiply(filtracion_device, Pdevice), y_aux3)\r\n\r\n#conseguir que la salida sea 0 \u00f2 1\r\ny_aux5 = tf.divide(y_aux4, umbral)\r\ny_aux6 = tf.cast(y_aux5, tf.int16)\r\ny_aux7 = tf.cast(y_aux6, tf.float32)\r\n\r\n\r\ny = tf.div_no_nan(y_aux7, y_aux7)\r\ny = tf.identity(y, name='output')\r\n\r\nloss = tf.reduce_mean(tf.square(y - y_))\r\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\r\ntrain_op = optimizer.minimize(loss, name='train')  ---> here is the error\r\n\r\ninit = tf.global_variables_initializer()\r\n\r\n# Creating a tf.train.Saver adds operations to the graph to save and\r\n# restore variables from checkpoints.\r\n\r\nsaver_def = tf.train.Saver().as_saver_def()\r\n\r\nwith open('graph_Ant.pb', 'wb') as f:\r\n  f.write(tf.get_default_graph().as_graph_def().SerializeToString())\r\n", "comments": ["I also tried with tf.round operation instead of tf.cast and there was the same problem", "@alejandroaguileraalcalde-ing,\r\nTensorFlow 1.x is not actively supported. Could you please update TensorFlow to the latest stable version v2.4.1 and check if you are facing the same issue. Thanks!", "I am using TF 1.x becouse I am creating a app that works with \"training on device\" for a Federated Machine Learning project, so I need the checkpoints and graph file that TF v1 creates when using save method. \r\n\r\nCould you tell me the list of operations that support gradients? I have search for it and didnt get any result.", "Was able to reproduce the issue with TF v1.15.5. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/aeeba6d12f3bd6ed916574271790045a/47083.ipynb). Thanks!", "ok, but  could you show me or tell me where can I find the list of operations that suppport gradientes?", "I think the cast to `int16` is the problem here. That would cause `Cast` to [drop](https://github.com/tensorflow/tensorflow/blob/ab438b386b5b95ed310fd9c31a9c5570a9fc6db3/tensorflow/python/ops/math_grad.py#L1960) gradients."]}, {"number": 47082, "title": "Add GPU implementation for Unique[WithCounts] ops", "body": "Adds a GPU op kernel supporting the Unique and UniqueWithCounts ops (not the V2 versions).\r\n\r\ncc @nluehr ", "comments": ["Changed to WIP because I see from the test failures that I made an oversight in the contract of this op (I only ran the main tests myself and they didn't catch it). I will update again once I have a fix for it.", "I've changed the implementation to produce the output in the correct order now. (I also added an explicit test for that).\r\n\r\nRemoving \"WIP\", ready for review.", "I just noticed that existing uses of `ThenExecute` all seem to have `ScopedActivateExecutorContext` inside the lambda callback (e.g., [1]), but I didn't add that inside this PR (the same also applies to https://github.com/tensorflow/tensorflow/pull/46172). Is this important?\r\n\r\n[1] https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/segment_reduction_ops_impl.h#L277-L280", "Hi,\r\n\r\nI'm getting failures when I run `tensorflow/python/kernel_tests:unique_op_test_gpu` internally:\r\n\r\n```\r\nUniqueWithCountsTest.testInt32\r\nthird_party/tensorflow/python/kernel_tests/unique_op_test.py\", line 183, in testInt32\r\n    self.assertEqual(len(tf_y), len(np.unique(x)))\r\nAssertionError: 2 != 8\r\n```\r\n\r\n(I had to change the `tf_py_test` to a `cuda_py_test` to run the test internally.  I don't think that's necessary in OSS, but you might want to do the same to avoid any confounding issues.)", "Hm, what GPU is it running on when it fails? Also is it just that test or many?", "> I just noticed that existing uses of `ThenExecute` all seem to have `ScopedActivateExecutorContext` inside the lambda callback (e.g., [1]), but I didn't add that inside this PR (the same also applies to #46172). Is this important?\r\n\r\nYes, that's important, sorry for not catching that.  (The continuation could be run on another thread.)", "> > I just noticed that existing uses of `ThenExecute` all seem to have `ScopedActivateExecutorContext` inside the lambda callback (e.g., [1]), but I didn't add that inside this PR (the same also applies to #46172). Is this important?\r\n> \r\n> Yes, that's important, sorry for not catching that. (The continuation could be run on another thread.)\r\n\r\nCC @kaixih I believe your PR also needs this fix, can you please send a new PR addressing this?  Thanks!", "> Hm, what GPU is it running on when it fails? Also is it just that test or many?\r\n\r\nIt was running on P100, and TF was compiled with clang.\r\n\r\nAll of these tests fail:\r\n\r\n```\r\nUniqueTest.testInt32\r\nUniqueTest.testInt32OutIdxInt64\r\nUniqueTest.testOrderedByAppearance\r\nUniqueWithCountsTest.testInt32\r\nUniqueWithCountsTest.testInt32OutIdxInt64\r\nUniqueWithCountsTest.testOrderedByAppearance\r\n```\r\n\r\nAnd the failure mode is the same -- the output has only two elements.\r\n\r\nE.g.\r\n\r\n```\r\nthird_party/tensorflow/python/kernel_tests/unique_op_test.py\", line 49, in testInt32OutIdxInt64\r\n    self.assertEqual(len(tf_y), len(np.unique(x)))\r\nAssertionError: 2 != 8\r\n```", "I managed to build using clang-12, sm_60, and CUDA 11.0u1, but still haven't been able to repro the failure.\r\n\r\nI don't suppose changing the `bool` on this line to `TIndex` helps? https://github.com/tensorflow/tensorflow/pull/47082/files#diff-39b40cf87839d63bdeeffbef44effbbd5ff5f3549006091b32dbdfa27f8b8ca5R294", "> I managed to build using clang-12, sm_60, and CUDA 11.0u1, but still haven't been able to repro the failure.\r\n> \r\n> I don't suppose changing the `bool` on this line to `TIndex` helps? https://github.com/tensorflow/tensorflow/pull/47082/files#diff-39b40cf87839d63bdeeffbef44effbbd5ff5f3549006091b32dbdfa27f8b8ca5R294\r\n\r\nThis link does not point to a line.", "I think you need to expand the contracted diff of `unique_op_gpu.cu.cc` to see the line.\r\n\r\nIt's line 294 here:\r\n```\r\n    // Create a fancy input iterator to indicate segment boundaries.\r\n    gpuprim::TransformInputIterator<bool, SegmentIndicatorFunctor<T, TIndex>,\r\n                                    gpuprim::CountingInputIterator<TIndex>>\r\n        segment_indicator_iter(0, {sorted_input_ptr});\r\n```\r\nchanging to this:\r\n```\r\n    gpuprim::TransformInputIterator<TIndex, SegmentIndicatorFunctor<T, TIndex>,\r\n```", "> I think you need to expand the contracted diff of `unique_op_gpu.cu.cc` to see the line.\r\n> \r\n> It's line 294 here:\r\n> \r\n> ```\r\n>     // Create a fancy input iterator to indicate segment boundaries.\r\n>     gpuprim::TransformInputIterator<bool, SegmentIndicatorFunctor<T, TIndex>,\r\n>                                     gpuprim::CountingInputIterator<TIndex>>\r\n>         segment_indicator_iter(0, {sorted_input_ptr});\r\n> ```\r\n> \r\n> changing to this:\r\n> \r\n> ```\r\n>     gpuprim::TransformInputIterator<TIndex, SegmentIndicatorFunctor<T, TIndex>,\r\n> ```\r\n\r\nWow, that seems to work.  Trying to check in now.", "I see this was merged, but then reverted in [this nondescript commit](https://github.com/tensorflow/tensorflow/commit/b6a25c7641ac37426b1dadd21b74f814c36f1738)?\r\n\r\nI've pushed the `bool` fix to this branch so that it's complete; but now it says there is a merge conflict? I'm a bit confused.", "Ben, this was auto-reverted because `//tensorflow/python/debug:analyzer_cli_test_gpu` failed.  The failure seems trivial, I'll try to reland with a fix.", "Went in as https://github.com/tensorflow/tensorflow/commit/02585ace8ca787613637713aebfd581a6dc2a12a."]}, {"number": 47080, "title": "TF Lite Micro person detection example won't make?", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Python pip and git clone\r\n- TensorFlow version: 2.4.1\r\n- Python version: 3.8\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n\r\n\r\n**Describe the problem**\r\nI installed the whole Tensorflow package using both pip and git clone on Ubuntu 20.04. When I tried to make the person detection project as follows:\r\nmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_person_detection_esp_project\r\n\r\nIt errored out with no make rule. The whole log is:\r\n\r\n_terryl@DESKTOP-55BFST5:/mnt/c/Projects/tensorflow$ make -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_person_detection_esp_project\r\n--2021-02-10 22:34:31--  http://mirror.tensorflow.org/github.com/google/flatbuffers/archive/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip\r\nResolving mirror.tensorflow.org (mirror.tensorflow.org)... 216.58.195.80\r\nConnecting to mirror.tensorflow.org (mirror.tensorflow.org)|216.58.195.80|:80... connected.\r\nHTTP request sent, awaiting response... 200 OK\r\nLength: 1760478 (1.7M) [application/zip]\r\nSaving to: \u2018/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip\u2019\r\n\r\n/tmp/dca12522a9f9e37f126ab925 100%[=================================================>]   1.68M  8.23MB/s    in 0.2s\r\n\r\n2021-02-10 22:34:32 (8.23 MB/s) - \u2018/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip\u2019 saved [1760478/1760478]\r\n\r\nCloning into 'tensorflow/lite/micro/tools/make/downloads/pigweed'...\r\nremote: Sending approximately 12.05 MiB ...\r\nremote: Counting objects: 6, done\r\nremote: Finding sources: 100% (6/6)\r\nremote: Total 18665 (delta 8537), reused 18663 (delta 8537)\r\nReceiving objects: 100% (18665/18665), 11.99 MiB | 5.09 MiB/s, done.\r\nResolving deltas: 100% (8537/8537), done.\r\nUpdating files: 100% (1456/1456), done.\r\nUpdating files: 100% (647/647), done.\r\nNote: switching to '47268dff45019863e20438ca3746c6c62df6ef09'.\r\n\r\nYou are in 'detached HEAD' state. You can look around, make experimental\r\nchanges and commit them, and you can discard any commits you make in this\r\nstate without impacting any branches by switching back to a branch.\r\n\r\nIf you want to create a new branch to retain commits you create, you may\r\ndo so (now or later) by using -c with the switch command. Example:\r\n\r\n  git switch -c <new-branch-name>\r\n\r\nOr undo this operation with:\r\n\r\n  git switch -\r\n\r\nTurn off this advice by setting config variable advice.detachedHead to false\r\n\r\nHEAD is now at 47268dff pw_hdlc_lite: Client I/O improvements\r\nwarning: pw_presubmit/py/pw_presubmit/format_code.py has type 100644, expected 100755\r\nwarning: pw_presubmit/py/pw_presubmit/pigweed_presubmit.py has type 100644, expected 100755\r\nmake: *** No rule to make target 'generate_person_detection_esp_project'.  Stop._\r\n\r\nI tried multiple times clean installing tensorflow but always the same problem. Am I missing something or the example project got broken somehow? I tried making hello_world project for ESP32, it worked fine.\r\nPlease help, thanks!\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["Any advice or even a clue to look at would be highly appreciated! The project got stuck here! Thanks!", "duplicate #46277 \r\nAlso a [PR](https://github.com/tensorflow/tensorflow/pull/47063) is in progress to address this issue.\r\nThanks!\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47080\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47080\">No</a>\n"]}, {"number": 47079, "title": "model.predict infer batch size from x if x is an array/tensor", "body": "If you use a subclassed tf keras model, and write the call method, you may want to access the shape of the `inputs` argument. While training, this is possible. The shape would be [batch_size, width, height, channels] for a batch of images using a tf data dataset. However, when calling `model.predict(images)`, where images is an array [batch_size, width, height, channels], the shape would be [None, width, height, channels]. This is confusing, though can be fixed by setting the batch_size argument of predict.\r\n\r\nI propose that when calling model.predict on tensors/arrays (not datasets), batch_size is inferred from the shape of the inputted array. I have implemented the code myself by overriding the predict function in a class extending tf.keras.Model like shown:\r\n\r\n```\r\n...\r\ndef predict(self,\r\n                x,\r\n                batch_size=None,\r\n                verbose=0,\r\n                steps=None,\r\n                callbacks=None,\r\n                max_queue_size=10,\r\n                workers=1,\r\n                use_multiprocessing=False\r\n               ):\r\n         return super(Autoencoder, self).predict(x, (batch_size or x.shape[0]), verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\r\n...\r\n```\r\n\r\nI see no reason why the shape of `inputs` is not always known, so this seems like a reasonable request to me. I have not really checked, however, if `inputs.shape` is not set when not using a dataset to fit or evaluate, it would make sense that `inputs.shape` is populated there as well. It just doesn't make sense that the shape of `inputs` should ever have a None value in it when it is known.", "comments": ["Thanks for the issue! For backwards compatibility reasons, `batch_size` will default to `32` if not supplied. `tf.data.Dataset`s don't use this argument bc they are assumed to be batched already. What's happening here is prob that your data is not evenly divisible by `32` and so there is a last partial batch, and so the overall batch_size comes through as None", "Hi,\r\n\r\nThanks for the response. It looks like we're talking about two different things.\r\n\r\nWhen using datasets, the shape of `input` is [**batch_size**, width, height, channels], as it should be. My issue has to do with passing arrays, and not datasets.\r\n\r\nCurrently, passing a numpy array to `model.predict` will call `call`, and the `input` argument of `call` will have the shape [**None**, width, height, channels]. My issue is not in the batch size used by a dataset, but that I cannot determine the batch size of `input` when an array is passed to `model.predict`.", "Sure, what I meant was if your data is of shape `(48, 10)`, it will be split into batches of `32` and `16`, and so when the `tf.function` is traced, it will show a `None` `batch_size`. To confirm that this is the case, you can try passing a `batch_size` that evenly divides your data. Then the shape of `input` in `call` should be `[batch_size, ...]`", "I see. Thank you for the clarification! Could I ask why it shows a None batch_size when there is a remainder batch?"]}, {"number": 47078, "title": "micro: prepare to port operator ELU kernel from lite with test", "body": "Implement skeleton (non-working) code for operator and test.\r\nHeader files changed.\r\nNamespaces changed.\r\nSome original code deleted.\r\nSome original code modified.\r\n\r\nPR step 4 of the work to port operator ELU as tracked in Issue #46323", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 47077, "title": "Add an InitializeTarget function that can be specialized for a given target.", "body": "This will allow the unit tests to be run on additional targets that need some addiitonal initialization (for example corstone_300 from #46830).\r\n\r\nThis particular change is broken out from the Corstone PR #46830 to be able to have smaller more reviewable PRs.\r\n\r\nIn the past, we have added state to the DebugLog() and GetCurrentTimeTicks() functions as a way to avoid having an InitializeTarget function. With this change, we are deciding to go with an explicit intitialization step instead.\r\n\r\nThis change has added calls to tflite::InitializeTarget to the tests, benchmarks, and examples and converted the Arduino and SparkfunEdge to make use of this explicit initialization.\r\n\r\nThe changes for the Arduino and SparkfunEdge have not been tested on actual hardware.\r\n\r\nProgress towards #46829\r\nFixes http://b/150808076", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "@njeffrie: after our dicussion, I decided to go one step further and not add calls to InitializeTarget from DebugLog for the Arduino and SparkfunEdge.\r\n\r\nInstead, I added a call to InitializeTarget from all of our examples. I like this approach more because it gives full control of the initialization to the application rather than having some mysterious init calls hidden away in DebugLog.\r\n\r\nThe down-side is that I might have broken some examples on Arduino/SparkfunEdge because the change is not tested on actual hardware."]}, {"number": 47076, "title": "Fix and rename TRANSPOSE_CONV_2D, BATCH_TO_SPACE_ND and SPACE_TO_BATCH_ND", "body": "Rename TRANSPOSE_CONV_2D to TRANSPOSE_CONV. Fix invariant checks in space_to_batch_nd and batch_to_space_nd.\r\n\r\nFixes: http://b/179940765", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 47075, "title": "Implement support for RaggedTensors in binary_crossentropy loss.", "body": "Follow up to #46283.\r\n\r\nTagging @tomerk for review.", "comments": []}, {"number": 47074, "title": "re-open: Docker Image -e Password:password tensorflow/tensorflow:latest-gpu-jupyter", "body": "What is the password for jupyter in this docker image (tensorflow/tensorflow:latest-gpu-jupyter)?\r\n-e Password:password is not working, it's not allow resetting the password.\r\n\r\nI am reopening this issue since\r\nthe use of jupyter_notebook_config.py was removed in cae5763 and the PASSWORD env variable is now ignored.\r\nthank you.\r\n\r\n\r\n\r\n<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@Daphneitec \r\nThis has been reported already: #46502.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47074\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47074\">No</a>\n", "i had fix it with follow steps:\r\n#### step 1:go into the docker container ,and run the command ```# jupter notebook list```\r\nthen in the teminal, it will print some information as follow:\r\nCurrently running servers:\r\nhttp://0.0.0.0:8888/?token={\u201chere will show the service token\u201c} :: /tf\r\n#### step 2:open the url: http://localhost:8888 in browser, and setup new password with the token that get from the step 1 \r\n\r\n "]}, {"number": 47073, "title": "Reorder lite/micro/kernels/BUILD alphabetically", "body": "", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 47072, "title": "Tensorlist bug fixes", "body": "Hi\r\n\r\nThis set of patches fixes 2 bugs in current TF master which is also present in 2.4 and 2.3 versions, this pull request is against master branch, please tell me if you need 2.4 version.\r\n\r\nBug was reported in https://github.com/tensorflow/tensorflow/issues/44428 and https://github.com/tensorflow/tensorflow/issues/44526, in a nutshell TensorList can not be decoded from the proto data, there are two bugs (fixed in two commits): decoder for tensorlist got lost and rtti for tensorlist doesn't match.\r\n\r\nBoth bugs are related to the fact that for some reasons runtime reloads some TF libraries several times, either it is statically linked first time when model is being loaded and then the second time for the second model or maybe the reason for subsequent load is different, but nevertheless having multiple loads wreck things a lot. I observed this bug for the case when inference runtime loads multiple saved_model models, this never happened for single model runtimes.\r\n\r\nPlease check commit messages for details on how and when bugs appeared.", "comments": ["Given the long description in each commit, I would recommend opening a PR for each one. We are squashing on merge.\r\n\r\nPlus, it seems there are a few GPU build failures, so it would be nice to isolate and fix them", "Are you sure you want to split it into two pull requests? Because none of them will be able to fix the problem (although both of them will fix some bugs) and it will not be clear why did they occur in the first place.\r\nI will take a look why master changes started to produce internal compiler error during compilation", "Checked that master branch builds with my patches on top of commit b299b2600d2be042aa8604f83ef494cea91adb4d with gcc 8.3.1\r\n\r\nCould you please restart this test to check out whether it works with more master updates, and also what is the compiler version (and other related info) used in the test? Information is rather scarce via those 'Details' links or I maybe I just do not know where to look?", "Hi, any progress on merging this?", "Hey, any chance to get it merged into 2.5?", "@mihaimaruseac Can you please take a look on above comments from @bioothod. Thanks!", "Ping?", "@mihaimaruseac Any update on this PR? Please. Thanks!", "@bioothod Sorry for the delay! There was a problem pulling the PR in. Could you please help rebase? (In case it helps.)", "@penpornk I will rebase it", "Check out this pull request on&nbsp; <a href=\"https://app.reviewnb.com/tensorflow/tensorflow/pull/47072\"><img align=\"absmiddle\"  alt=\"ReviewNB\" height=\"28\" class=\"BotMessageButtonImage\" src=\"https://raw.githubusercontent.com/ReviewNB/support/master/images/button_reviewnb.png\"/></a> \n\n See visual diffs & provide feedback on Jupyter Notebooks. \n\n---\n\n <i>Powered by <a href='https://www.reviewnb.com/?utm_source=gh'>ReviewNB</a></i>", "Apparently rebase went weird", "All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F47072) for more info**.\n\n<!-- need_author_consent -->", "Force-pushing rebased branch has resolved everything. I can not test bugfix against current master, because it is unusable (model loading fails):\r\n```\r\n2021-05-25 21:15:45.377731: E tensorflow/core/lib/monitoring/collection_registry.cc:77] Cannot register 2 metrics with the same name: /tensorflow/core/saved_model/write/count\r\n2021-05-25 21:15:45.377906: E tensorflow/core/lib/monitoring/collection_registry.cc:77] Cannot register 2 metrics with the same name: /tensorflow/core/saved_model/read/count\r\n2021-05-25 21:15:45.377921: E tensorflow/core/lib/monitoring/collection_registry.cc:77] Cannot register 2 metrics with the same name: /tensorflow/core/saved_model/write/api\r\n2021-05-25 21:15:45.377931: E tensorflow/core/lib/monitoring/collection_registry.cc:77] Cannot register 2 metrics with the same name: /tensorflow/core/saved_model/read/api\r\n```\r\n\r\neven without my changes, but code around hasn't changed, so I still think it is relevant.", "I have manually verified that both commits in this PR are by the same github author who has CLA with us. Changing CLA label to yes."]}, {"number": 47071, "title": "Micro benchmarks is excluded for cortex_m_corstone_300_makefile.inc", "body": "@tensorflow/micro\r\n\r\n**System information**\r\n- Host OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- TensorFlow installed from (source or binary):\r\n- Tensorflow version (commit SHA if source):\r\n- Target platform (e.g. Arm Mbed OS, Arduino Nano 33 etc.):\r\n\r\n**Describe the problem**\r\nI hit this issue when working with: https://github.com/tensorflow/tensorflow/pull/46830\r\nMicro benchmarks had to be excluded.\r\n\r\n**Please provide the exact sequence of commands/steps when you ran into the problem**\r\nTry to run Micro benchmark for cortex_m_corstone_300_makefile.inc\r\n\r\n", "comments": ["As part of enabling benchmarks for the Ethos-U, we will want to support the Vela converted person detection model from the benchamark code. [Here](https://github.com/tensorflow/tensorflow/pull/48669#discussion_r622620181) an initial discussion on that topic.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47071\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47071\">No</a>\n"]}, {"number": 47069, "title": "Add support for masking to the Keras Functional API", "body": "**System information**\r\n- TensorFlow version (you are using): 2.3.0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\nIt appears that the function API does not support masking, meaning it cannot be used to make a *layer* that propagates mask from the input to to the output. Here is an example:\r\n\r\nSuppose that `layer` is some `tf.keras` layer that supports masking. Then we can make a model using the function API:\r\n\r\n    inputs = tf.keras.layers.Input(shape=(None,))\r\n    outputs = layer(inputs)\r\n    functional_layer = tf.keras.Model(inputs=inputs, outputs=outputs)\r\n\r\nBut it does not propogate the mask: If `x_emb` is a tensor with an attached mask (so it has an `x_emb._keras_mask` attribute) then consider the following\r\n\r\n    output = functional_layer(x_emb)\r\n    print(output._keras_layer)\r\n\r\n    ## AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute '_keras_layer'\r\n\r\nObviously subclassing `tf.keras.Model` supports masking, and so does the Sequential API:\r\n\r\n    sequential_layer = tf.keras.Sequential([\r\n        layer,\r\n        layer\r\n    ])\r\n    output2 = sequential_layer(x_emb)\r\n    print(output2._keras_mask)\r\n\r\n**Will this change the current api? How?**\r\n\r\nIt depends on how it is implemented. \r\n\r\n**Who will benefit with this feature?**\r\n\r\nModel developers. It will allow them to use the functional API to create layers which support masking.\r\n\r\n**Any Other info.**\r\n\r\nI posted a [question](https://stackoverflow.com/q/66092787/1349673) on SO about this.", "comments": ["Apologies this was a typo on my part, where I had accidentally written `_keras_layer` instead of `_keras_mask`."]}, {"number": 47067, "title": "TF 2.4 tf.data cached shuffle 35% slower compared to TF 2.3", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): 2.4, 2.5.0a20210210\r\n- Python version: 3.8.5\r\n\r\n**Describe the current behavior**\r\nWhen running the code example below, TF 2.4 is 35% slower in the first epoch compared to TF 2.3 when shuffling is enabled. The epoch times for the second epoch are only slightly slower, so this issue only seems to occur when the shuffle buffer is not fully filled yet.\r\n\r\nThis issue doesn't seem to happen without shuffling, so I don't think this issue is related to a problem in GCS read performance. TF nightly partially fixed this issue, but is still ~10% slower compared to TF 2.3. \r\n\r\nversion | 1st epoch | 1st epoch no shuffling\r\n---|---|---\r\n`v2.2.2` | 256.2 s |\r\n`v2.3.2` | **249.0 s** | 234.7 s\r\n`v2.4.1` | **334.7 s** | 230.6 s\r\n`v2.5.0a20210210` | 276.0 s | \r\n\r\n**Describe the expected behavior**\r\nThe time of the first epoch should not be slower compared to TF 2.3.\r\n\r\n**Standalone code to reproduce the issue**\r\n```python\r\nimport time\r\nimport tensorflow_datasets as tfds\r\n\r\ndataset = tfds.load(\r\n    \"imagenet2012\",\r\n    decoders={\"image\": tfds.decode.SkipDecoding()},\r\n    split=\"train\",\r\n    data_dir=\"gs://my_data_bucket\",\r\n)\r\n\r\nsamples = dataset.cardinality()  # 1281167\r\ndataset = dataset.cache().shuffle(samples).batch(256).prefetch(1)\r\n\r\nfor epoch in range(2):\r\n    start = time.time()\r\n    for data in dataset:\r\n        pass\r\n    end = time.time()\r\n    print(f\"Epoch {epoch + 1}: {(end - start):.1f} s\")\r\n```", "comments": ["@lgeiger,\r\nOn running the given code snippet, I am facing a `ValueError`, please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/aa1ff8e66576d954087402557b8ac382/47067.ipynb).\r\n\r\nIn order to expedite the trouble-shooting process, could you please provide a minimal reproducible code. \r\n\r\nAlso, check if you are facing the same issue with `tfds-nightly` version as well? Thanks!", "> On running the given code snippet, I am facing a ValueError, please find the gist of it here.\r\n\r\nI updated the code example above. Looks like Colab uses a different version TFDS.\r\n\r\nPlease note that since this is a performance issue it will be difficult to reproduce on Colab since a large dataset like ImageNet or similar is required to be able to see a difference.\r\n\r\n> Also, check if you are facing the same issue with tfds-nightly version as well?\r\n\r\nI did. Please see the table above.", "I did some tests on Google Colab but on the `imagenet_resized` dataset instead. The code is almost similar. I used `pip` to install required tensorflow version and restart the runtime. Below are my observations for 3 different versions of the Tensorflow.\r\n\r\n#### Code :\r\n\r\n```python\r\nimport time\r\nimport tensorflow_datasets as tfds \r\n\r\ndataset = tfds.load(\"imagenet_resized\",split=\"train\")\r\n\r\nsamples = dataset.cardinality()  # 1281167\r\ndataset = dataset.cache().shuffle(samples).batch(256).prefetch(1)\r\n\r\nfor epoch in range(2):\r\n    start = time.time()\r\n    for data in dataset:\r\n        pass\r\n    end = time.time()\r\n    print(f\"Epoch {epoch + 1}: {(end - start):.1f} s\")\r\n```\r\n| Version  | 1st epoch |\r\n| ------------- | ------------- |\r\n| TF 2.3.0  | 109.5 s  |\r\n| TF 2.3.2  | 110.8 s  |\r\n| TF 2.4.1  | 91.0 s  |\r\n\r\nfor me on CPU, TF 2.4.1 seems faster, don't know if it is only for this case.", "@ShubhamShaswat I can reproduce your results with the `imagenet_resized` dataset as well on my machine both when reading the dataset from the local disk as well as from GCS. So it looks like this issue only comes up with larger datasets.", "@lgeiger larger dataset could be the reason here, as per the samples size both have the same `cardinality` of `1281167` so this might not be the reason. If the datasize is the culprit I would like to test it with smaller samples size but with different datasizes just like `imagenet` and `imagenet_resized` and see if that's the real reason.", "On running the code with `imagenet2012`, facing an error stating `OSError: Not enough disk space. Needed: 155.84 GiB (download: Unknown size, generated: 155.84 GiB)`. \r\n\r\nWhereas with `imagenet_resized` dataset, the execution times are \r\n\r\nTF Version | 1st epoch | 2nd epoch\r\n---|---|---\r\n[2.3.2](https://colab.research.google.com/gist/amahendrakar/bd93339692ddb713b5b1e2ed43792384/47067-2-3-2.ipynb) | 118.3 s | 5.5 s\r\n[2.4.1](https://colab.research.google.com/gist/amahendrakar/0e007f9e2a136aad27a7998bc95e1db2/47067.ipynb) | 95.0 s | 3.7 s\r\n[2.5.0-dev20210223](https://colab.research.google.com/gist/amahendrakar/8319878707e674a103b85d82a4c219a2/47067-tf-nightly.ipynb) | 141.9 s | 4.1 s\r\n\r\nPlease check the linked gist for reference. Thanks!", "@amahendrakar great that you were able to reproduce the slowdown in `tf-nightly` with `imagenet_resized`.\r\n\r\n> On running the code with imagenet2012, facing an error stating OSError: Not enough disk space. Needed: 155.84 GiB (download: Unknown size, generated: 155.84 GiB).\r\n\r\nThis is expected as Colab doesn't have enough disk available to download ImageNet. You can reproduce it on colab by using a GCS bucket and streaming the data from there.", "Could you please try to download imagenet dataset manually here https://www.tensorflow.org/datasets/catalog/imagenet2012 and test it in the latest version again and let us know if you find satisfying results. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 47066, "title": " Request for better installation instructions for TF on Ampere GPUs!", "body": "After 6 weeks of trial and error, I gave up and replaced our brand new 3090 cards with the old 2080 Ti. **I just could not get tensorflow on the new GPUs to work.** \r\n\r\nMy colleagues and I have worked with TF from its early days. We have always been early adopters of the latest GPU generation. **There was never a mess like this.** In the worst case, the new TF system didn't utilize all the GPU's new resources, but we never had installation troubles like this.\r\n\r\nI tried all installation approaches mentioned in the TF home page (python packages, docker containers, compilation from source). Either it failed completely or - after hours/days on Stack Overflow - ended in disappointing results.\r\n\r\nThe closest I got to a success came with the upgrade to TF 2.4, but I was getting a million times the warning message \r\n**\"your cuda software stack is old. we fallback to the nvidia driver for some compilation. update your cuda version to get the best performance. the ptxas error was: ptxas fatal : value 'sm_86' is not defined for option 'gpu-name'\"**\r\nat each start of a TF script.\r\n\r\nThis is not inspiring confidence in the coupling of TF and CUDA. **This is plainly unusable.** \r\n\r\nAs I understand it, the CUDA toolkit is too old compared to the driver, so the driver is recompiled to match the CUDA version. **But why does this happen again and again?** Once should be enough. We have Ubuntu 20.04 with driver 460 installed. It should be possible to go back to version 450, but we could not achieve that. I don't know if this would help, anyway.\r\n\r\nWith Docker containers, there seem to be the same problems because they use the driver of the host system. \r\n\r\nAnother word about working with containers because they are recommended in the installation instructions: We work with an IDE which offers Docker support only for extra cost. No IDE, no debugger (and other important tools). And like this, Docker is not an option. \r\n\r\n \r\n\r\n\r\n\r\n", "comments": ["@wittmarf \r\nPlease refer to [this comment](https://github.com/tensorflow/tensorflow/issues/46933#issuecomment-773975025) and let us know.", "I was aware of this possibility, but I don't think hiding error or warning messages is a solution. \r\n\r\nWith \"not inspiring confidence in the coupling of TF and CUDA\", this is exactly what I meant. It would be a solution if the Nvidia PTX compiler was invoked just once and saved its result.", "OS Windows 10 Pro : 1909 18363.1379\r\nCUDA TOOLKIT : 11.1\r\nCUDNN: 8.1.0\r\n\r\nGPU : MSI RTX 3090 x trio\r\nCPU i7 3930k 32GB ram\r\nusing Anaconda\r\npython 3.7.9\r\ntf-nightly-gpu 2.5.0.dev20210114\r\ntf-nightly  2.5.0.dev20210114\r\n\r\n=> The above config allows me to run my code LSTM code in tensor flow (extract below):\r\nHowever clone the environment in Anaconda and upgrade the tf-nightly build to anything more recent, including todays build\r\nof 2.5.0.dev20210228 ... when the code reaches tf.model.fit .. it crashes out with no error reporting at all.\r\n\r\nThe reason why i tried upgrading the tf-nightly build : currently the model training time is about the same as on my RTX 2080ti and sometimes even slower which thought was down to issues with the tf-nightly builds and Ampere.\r\n\r\nWould very appreciate  any suggestions on why the newer tf-nightly builds are making my code crash \r\n\r\ncode block:\r\n\r\nmodel = tf.keras.models.Sequential([\r\n    #input shape equals term points in curve\r\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32,return_sequences=True),input_shape=(n_days,n_cols)),\r\n    tf.keras.layers.Dropout(0.2),\r\n    \r\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32)),\r\n    tf.keras.layers.Dropout(0.2),\r\n\r\n    tf.keras.layers.Dense(64, activation='relu',kernel_initializer=initializer),\r\n    tf.keras.layers.BatchNormalization(),\r\n    tf.keras.layers.Dropout(0.2),\r\n        \r\n    tf.keras.layers.Dense(64, activation='relu',kernel_initializer=initializer, bias_initializer=output_bias),\r\n    tf.keras.layers.BatchNormalization(),\r\n    tf.keras.layers.Dropout(0.2),\r\n\r\n    tf.keras.layers.Dense(t_cols, activation='sigmoid', bias_initializer=output_bias)])\r\n\r\n#list of keras metrics to compute in model\r\nMETRICS = [\r\n      keras.metrics.BinaryAccuracy(name='binary_accuracy'),\r\n      keras.metrics.Precision(name='precision'),\r\n      keras.metrics.Recall(name='recall'),\r\n      keras.metrics.AUC(name='auc'),\r\n]\r\n\r\nmodel.compile(optimizer=Adam(learning_rate=lng_rate),\r\n              loss='binary_crossentropy',\r\n              metrics=METRICS)\r\n\r\nhistory=model.fit(\r\n    X_train, \r\n    Y_train, \r\n    epochs=training_epochs, \r\n    batch_size=training_batch_size, \r\n    verbose=1,\r\n    class_weight=label_weights[0],\r\n    validation_data=(X_validation,Y_validation))", "@ALIANS-PRODUCTIONS Looks like you may have different issue when compared to the current issue. Can you please open a new issue with the standalone code. Creating new issue may help others who are facing similar issue like you. Thanks!", "Hi there, I created a separate ticket with sample code attached in the second comment and extensive detail:\nThank you very much for looking at my case!\n\ntf-nightly-gpu builds from February are crashing on 'tf.keras model.fit()' for Nvidia RTX 3090; January builds performance is slower than 2080ti on : 2Layer Bidirectional LSTM + 3 Dense Layers #47473\n\nFrom: Vishnuvardhan Janapati <notifications@github.com>\nSent: 01 March 2021 22:35\nTo: tensorflow/tensorflow <tensorflow@noreply.github.com>\nCc: ALIANS-PRODUCTIONS <ansar_ali_esq@hotmail.com>; Mention <mention@noreply.github.com>\nSubject: Re: [tensorflow/tensorflow] Request for better installation instructions for TF on Ampere GPUs! (#47066)\n\n\n@ALIANS-PRODUCTIONS<https://emea01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2FALIANS-PRODUCTIONS&data=04%7C01%7C%7Cae1b3260d0624a81b32008d8dd02500e%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637502349289372535%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=Fik26nHxqe210Q47sP0kYYlRHY6x2yXyB%2BvvUgm%2BnrE%3D&reserved=0> Looks like you may have different issue when compared to the current issue. Can you please open a new issue with the standalone code. Creating new issue may help others who are facing similar issue like you. Thanks!\n\n-\nYou are receiving this because you were mentioned.\nReply to this email directly, view it on GitHub<https://emea01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fissues%2F47066%23issuecomment-788353650&data=04%7C01%7C%7Cae1b3260d0624a81b32008d8dd02500e%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637502349289382526%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=TF25fPfivkpO5XilgpfF4QBWwoJQzizUK7nNFT5lBY4%3D&reserved=0>, or unsubscribe<https://emea01.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FAFCITOOMUBLWY6WV7QE2V63TBQJC7ANCNFSM4XM7QYCQ&data=04%7C01%7C%7Cae1b3260d0624a81b32008d8dd02500e%7C84df9e7fe9f640afb435aaaaaaaaaaaa%7C1%7C0%7C637502349289382526%7CUnknown%7CTWFpbGZsb3d8eyJWIjoiMC4wLjAwMDAiLCJQIjoiV2luMzIiLCJBTiI6Ik1haWwiLCJXVCI6Mn0%3D%7C1000&sdata=9E2xTH4OhZIshckoBM1sPFIdrSpJUKGjhU7g6TofhdA%3D&reserved=0>.\n", "@wittmarf,\r\n\r\nCan you take a look at this [blog](https://embea.de/blog/?p=114) and let us know if it helps in providing better instructions for installing TF on Ampere GPU?. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47066\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47066\">No</a>\n"]}, {"number": 47065, "title": "please update the release with lib file assets", "body": "according to the releases hitory, tf 1.15 has been updated to 1.15.5,  please upload the release lib and dll file the releases page, or www.tensorflow.com\r\n\r\nIt's so difficult to compile tensorflow correct. I flow the build introduction, try many times, use multi version of bazel, python, but always get error.\r\ni just want the new version lib files, with security bugs fixed.\r\nAnd i think i am not the only person, you can see a lot of devs submit compile error issue on this project.\r\n\r\nso please, update the latest jar and dll, any third part source is ok.", "comments": ["Can you please exactly to what page needs updating?\r\n\r\nThe pip package that is built and uploaded on PyPI should be enough.", "> Can you please exactly to what page needs updating?\r\n> \r\n> The pip package that is built and uploaded on PyPI should be enough.\r\n\r\nhttps://www.tensorflow.org/install/lang_java_legacy\r\nI find the 1.x version of java api has been deprecated.  could you please give me a link of the v1.15.5 libtensorflow_jni?", "Given deprecation, no new JNI has been built.", "@GerScau,\r\n\r\nCan you take a look at above comment and confirm if we can close the issue? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47065\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47065\">No</a>\n"]}, {"number": 47064, "title": "calling GradientTape.gradient inside its context warning even though tape recording is stopped", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): 2.3\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\n**Describe the current behavior**\r\nRunning a function with a gradient tape that has a stopped recording, updating gradients, inside its context causes an unnecessary/misleading warning about performance.\r\n\r\n**Describe the expected behavior**\r\nThere should be no warning about tons of extra memory & reduced performance.\r\n\r\n**Standalone code to reproduce the issue**\r\nhttps://colab.research.google.com/drive/1sasTq_SY7ylBETSQDmscIqYFkZpHDr9B?usp=sharing\r\n\r\n\r\nedit: Closing this. It's a context manager, and it wasn't used like one here.", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47064\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47064\">No</a>\n"]}, {"number": 47063, "title": "Fixed person_detection_example for esp32", "body": "1. Use int8 model\r\n2. Avoid build issues with target rule: Changed the rule from person_detection_int8 to person_detection for esp\r\n3. Treat uint8 camera buffer as int8\r\n", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "Closes https://github.com/tensorflow/tensorflow/issues/46083", "@advaitjain the build issue also reminds me to urge you to enable CI for ESP32", "> @advaitjain the build issue also reminds me to urge you to enable CI for ESP32\r\n\r\nOur recommendation for this is for you guys to add a continuous build (similar to the Xtensa continuous builds and publish the build badge to the TFLM Readme: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/micro#community-supported-builds", "Hello, I just sync'ed to the latest project files but still CANNOT build the person detection example with the same make no rule error.\r\n\r\nThe make cmd:\r\nmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_person_detection_esp_project\r\n\r\nHEAD is now at 47268dff pw_hdlc_lite: Client I/O improvements\r\nwarning: pw_presubmit/py/pw_presubmit/format_code.py has type 100644, expected 100755\r\nwarning: pw_presubmit/py/pw_presubmit/pigweed_presubmit.py has type 100644, expected 100755\r\nmake: *** No rule to make target 'generate_person_detection_esp_project'.  Stop.\r\n\r\nPlease fix, thanks!\r\n", "> Hello, I just sync'ed to the latest project files but still CANNOT build the person detection example with the same make no rule error.\r\n> \r\n> The make cmd:\r\n> make -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_person_detection_esp_project\r\n> \r\n> HEAD is now at 47268dff pw_hdlc_lite: Client I/O improvements\r\n> warning: pw_presubmit/py/pw_presubmit/format_code.py has type 100644, expected 100755\r\n> warning: pw_presubmit/py/pw_presubmit/pigweed_presubmit.py has type 100644, expected 100755\r\n> make: *** No rule to make target 'generate_person_detection_esp_project'. Stop.\r\n> \r\n> Please fix, thanks!\r\n\r\nHi @Hazeline2018 please cherry-pick changes from this PR and it should work.\r\n\r\nThe final fix will change the rule to `generate_person_detection_int8_esp_project` btw.\r\n", "I tried your changes on the latest tf branch, except for the changes in helper_functions since I couldn't build when I added it. However, I get a problem where all outputs from the network have the same values but with different signs. For example, person_score: 55, no_person_score: -55. I'm not sure if this is caused by your changes however.\r\n\r\nEDIT: A bit off topic, but I think it's weird how the outputs are fetched from data.uint8 into an int8 in main_functions.cc:\r\n`int8_t person_score = output->data.uint8[kPersonIndex];`\r\n`int8_t no_person_score = output->data.uint8[kNotAPersonIndex];`\r\n\r\nEDIT 2: I realized the output is fine if you have the scores as uint8 and add 128 to them. However(!), we need to subtract 128 from all input pixels for the model to give correct results. I added a PR in your bugfix branch:\r\n[https://github.com/vikramdattu/tensorflow/pull/1](https://github.com/vikramdattu/tensorflow/pull/1)", "Sorry guys, after weeks' struggling, still couldn't get any of the ESP projects generated. I even tried the \"hello world\" example, still the same error as following:\r\nPS C:\\Projects\\tensorflow> make -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_hello_world_esp_project\r\n\r\nFIND: Parameter format not correct\r\nFIND: Parameter format not correct\r\n--2021-03-29 17:48:46--  http://mirror.tensorflow.org/github.com/google/flatbuffers/archive/dca12522a9f9e37f126ab925fd38\r\n5c807ab4f84e.zip\r\nResolving mirror.tensorflow.org (mirror.tensorflow.org)... 172.217.9.48\r\nConnecting to mirror.tensorflow.org (mirror.tensorflow.org)|172.217.9.48|:80... connected.\r\nHTTP request sent, awaiting response... 200 OK\r\nLength: 1760478 (1.7M) [application/zip]\r\nSaving to: 'C:/Users/Tianhao/AppData/Local/Temp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip'\r\n\r\nC:/Users/Tianhao/AppData/Loca 100%[=================================================>]   1.68M  3.05MB/s    in 0.6s\r\n\r\n2021-03-29 17:48:47 (3.05 MB/s) - 'C:/Users/Tianhao/AppData/Local/Temp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip' sav\r\ned [1760478/1760478]\r\n\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: /tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: cannot execute bin\r\nary file\r\ntensorflow/lite/micro/tools/make/downloads/pigweed already exists, skipping the download.\r\nmake: *** No rule to make target 'generate_hello_world_esp_project'.  Stop.\r\n\r\nThe error log for \"person detection\" example as follows, I did use \"_int8\" target, still couldn't get it generated!\r\nPS C:\\Projects\\tensorflow> make -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_person_detection_int8_e\r\nsp_project\r\nFIND: Parameter format not correct\r\nFIND: Parameter format not correct\r\n--2021-03-29 17:50:08--  http://mirror.tensorflow.org/github.com/google/flatbuffers/archive/dca12522a9f9e37f126ab925fd38\r\n5c807ab4f84e.zip\r\nResolving mirror.tensorflow.org (mirror.tensorflow.org)... 172.217.9.48\r\nConnecting to mirror.tensorflow.org (mirror.tensorflow.org)|172.217.9.48|:80... connected.\r\nHTTP request sent, awaiting response... 200 OK\r\nLength: 1760478 (1.7M) [application/zip]\r\nSaving to: 'C:/Users/Tianhao/AppData/Local/Temp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip'\r\n\r\nC:/Users/Tianhao/AppData/Loca 100%[=================================================>]   1.68M  2.60MB/s    in 0.6s\r\n\r\n2021-03-29 17:50:09 (2.60 MB/s) - 'C:/Users/Tianhao/AppData/Local/Temp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip' sav\r\ned [1760478/1760478]\r\n\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: /tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: cannot execute bin\r\nary file\r\ntensorflow/lite/micro/tools/make/downloads/pigweed already exists, skipping the download.\r\nmake: *** No rule to make target 'generate_person_detection_int8_esp_project'.  Stop.\r\n\r\nAlways gives \"No rule to make target\" error. I'm stuck, please help! Thanks a lot!", "BTW, I was running on Windows 7 machine. I also tried running in Linux VM, but still the same problem. So it shouldn't be development IDE environment realted!", "> BTW, I was running on Windows 7 machine. I also tried running in Linux VM, but still the same problem. So it shouldn't be development IDE environment realted!\r\n\r\n@Hazeline2018\r\nPlease try following command for ESP:\r\n```\r\nmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_person_detection_esp_project\r\n```\r\ni.e., drop `int8` from it.\r\n", "> > BTW, I was running on Windows 7 machine. I also tried running in Linux VM, but still the same problem. So it shouldn't be development IDE environment realted!\r\n> \r\n> @Hazeline2018\r\n> Please try following command for ESP:\r\n> \r\n> ```\r\n> make -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_person_detection_esp_project\r\n> ```\r\n> \r\n> i.e., drop `int8` from it.\r\n\r\n@vikramdattu \r\nThanks for the reply. Yes, I tried the generate parameter w/o int8, same error:\r\n\r\nPS C:\\Projects\\tensorflow> make -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_person_detection_esp_pr\r\noject\r\nFIND: Parameter format not correct\r\nFIND: Parameter format not correct\r\n--2021-03-30 11:07:21--  http://mirror.tensorflow.org/github.com/google/flatbuffers/archive/dca12522a9f9e37f126ab925fd38\r\n5c807ab4f84e.zip\r\nResolving mirror.tensorflow.org (mirror.tensorflow.org)... 216.58.192.176\r\nConnecting to mirror.tensorflow.org (mirror.tensorflow.org)|216.58.192.176|:80... connected.\r\nHTTP request sent, awaiting response... 200 OK\r\nLength: 1760478 (1.7M) [application/zip]\r\nSaving to: 'C:/Users/Tianhao/AppData/Local/Temp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip'\r\n\r\nC:/Users/Tianhao/AppData/Loca 100%[=================================================>]   1.68M  3.56MB/s    in 0.5s\r\n\r\n2021-03-30 11:07:22 (3.56 MB/s) - 'C:/Users/Tianhao/AppData/Local/Temp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip' sav\r\ned [1760478/1760478]\r\n\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: /tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: cannot execute bin\r\nary file\r\ntensorflow/lite/micro/tools/make/downloads/pigweed already exists, skipping the download.\r\nmake: *** No rule to make target 'generate_person_detection_esp_project'.  Stop.", "I saw @adaitche 's mods for \"tensorflow/lite/micro/tools/make/helper_functions.inc\" file and I tried that too, NO luck. This gotta be a simple mismatch issue, but not sure why so hard to fix. Thanks!", "I think you missed picking few changes from this PR.\r\n\r\nPlease take changes from following files: `person_detection/Makefile.inc` and `person_detection/esp/Makefile.inc` as well.", "> I think you missed picking few changes from this PR.\r\n> \r\n> Please take changes from following files: `person_detection/Makefile.inc` and `person_detection/esp/Makefile.inc` as well.\r\n\r\nHave all the changes you mentioned been checked into the latest repository? Because I just freshly sync out the whole tensor flow project and rebuild it, but UNFORTUNATELY, still exactly same stubborn error! I tried both w/ and w/o int8 but same error.\r\n\r\nPlease help!", "No, the changes have not been accepted and the pull request is still pending.\r\nYou need to manually pick those changes in your checked out repo.", "> No, the changes have not been accepted and the pull request is still pending.\r\n> You need to manually pick those changes in your checked out repo.\r\n\r\n@vikramdattu \r\nI followed the exact changes for 4 files in this thread but still got the same error. I tried both w/ and w/o int8, same no make rule error. Am I still missing antying?", "Hello again,\r\nIt is strange... as below change adds this rule to compile esp project w/o int8\r\n\r\n\r\n```\r\nifneq ($(TARGET), esp)\r\n$(eval $(call microlite_test,person_detection_int8,\\\r\n$(person_detection_SRCS),$(person_detection_DRS)))\r\nelse\r\n$(eval $(call microlite_test,person_detection,\\\r\n$(person_detection_SRCS),$(person_detection_HDRS)))\r\nendif\r\n```", "yeah, I saw that code changes, but none worked. I ran this project a while back and everything was just working fine. When I decided to freshly sync the repository with all new updates, I encountered this no make rule error. Something must have changed that breaks the build. Would you or anyone be able to replicate this exact error?", "Yes, there are issues introduced on master, that's why the fix:\r\n\r\nThe make command works flawlessly when the patch is taken!\r\n\r\n```\r\nvikramdattu@Vikrams-MacBook-Pro tensorflow-lite-gitlab % gmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_person_detection_esp_project\r\ntensorflow/lite/micro/tools/make/downloads/flatbuffers already exists, skipping the download.\r\ntensorflow/lite/micro/tools/make/downloads/pigweed already exists, skipping the download.\r\ngmake: *** No rule to make target 'generate_person_detection_esp_project'.  Stop.\r\nvikramdattu@Vikrams-MacBook-Pro tensorflow-lite-gitlab % git cherry-pick 6d69beaf73fa2488f830a7fb7ed4ef931b44ce1d\r\n[tf_official_master 28d515f6246] Fixed person_detection_example for esp32\r\n Date: Wed Feb 10 15:03:04 2021 +0530\r\n 4 files changed, 17 insertions(+), 6 deletions(-)\r\nvikramdattu@Vikrams-MacBook-Pro tensorflow-lite-gitlab % gmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_person_detection_esp_project\r\ntensorflow/lite/micro/tools/make/downloads/flatbuffers already exists, skipping the download.\r\ntensorflow/lite/micro/tools/make/downloads/pigweed already exists, skipping the download.\r\nvikramdattu@Vikrams-MacBook-Pro tensorflow-lite-gitlab % \r\n\r\n```\r\n\r\nCan you please share `diff` on your branch and check again!\r\nBecause when the rule is added to Makefile, there is no way make will throw this error!\r\n\r\nTip: Make throws random errors when code is not formatted properly. (e.g., spaces in place of tab would also add these errors)\r\n\r\n", "@vikramdattu \r\n\r\nThanks for the experiment. I freshly git clone the whole tensorflow repo and did cherry-pick the commits as specified in your example, but failed updating. it seems not a valid SHA.\r\n\r\nPS C:\\Projects> git clone https://github.com/tensorflow/tensorflow.git --recursive\r\nCloning into 'tensorflow'...\r\nremote: Enumerating objects: 3182, done.\r\nremote: Counting objects: 100% (3182/3182), done.\r\nremote: Compressing objects: 100% (1592/1592), done.\r\nremote: Total 1122585 (delta 1820), reused 2670 (delta 1554), pack-reused 1119403\r\nReceiving objects: 100% (1122585/1122585), 663.56 MiB | 1.68 MiB/s, done.\r\nResolving deltas: 100% (914665/914665), done.\r\nChecking out files: 100% (24606/24606), done.\r\nPS C:\\Projects> git cherry-pick 6d69beaf73fa2488f830a7fb7ed4ef931b44ce1d\r\nfatal: not a git repository (or any of the parent directories): .git\r\nPS C:\\Projects> cd .\\tensorflow\r\n**_PS C:\\Projects\\tensorflow> git cherry-pick 6d69beaf73fa2488f830a7fb7ed4ef931b44ce1d\r\nfatal: bad object 6d69beaf73fa2488f830a7fb7ed4ef931b44ce1d_**\r\n\r\n", "I used the exact same cherry-pick cmd as in your example:\r\n\"git cherry-pick 6d69beaf73fa2488f830a7fb7ed4ef931b44ce1d\" but error out of bad object.", "BTW, since cherry-pick cmd doesn't work for me. So I just manually made the changes to those 4 files but still no luck, same no rule error. I'm running out of ideas ...", "You will need my forked tflite repo fetched for cherry-pick to work on that commit.\r\n\r\nHow about you download the patch instead:\r\nhttps://patch-diff.githubusercontent.com/raw/tensorflow/tensorflow/pull/47063.patch\r\n\r\nand apply it on your local checkout?", "> You will need my forked tflite repo fetched for cherry-pick to work on that commit.\r\n> \r\n> How about you download the patch instead:\r\n> https://patch-diff.githubusercontent.com/raw/tensorflow/tensorflow/pull/47063.patch\r\n> \r\n> and apply it on your local checkout?\r\n\r\n@vikramdattu \r\nThanks a lot for the help and effort. I was able to patch my local repo with your patch file successfully but still same error.\r\nI also manually examined the patch files and made sure they are correctly patched.\r\n\r\nPS C:\\Projects\\tensorflow> git apply .\\47063.patch\r\nPS C:\\Projects\\tensorflow> make -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_person_detection_esp_pr\r\noject\r\nFIND: Parameter format not correct\r\nFIND: Parameter format not correct\r\n--2021-04-02 10:36:18--  http://mirror.tensorflow.org/github.com/google/flatbuffers/archive/dca12522a9f9e37f126ab925fd38\r\n5c807ab4f84e.zip\r\nResolving mirror.tensorflow.org (mirror.tensorflow.org)... 172.217.10.112\r\nConnecting to mirror.tensorflow.org (mirror.tensorflow.org)|172.217.10.112|:80... connected.\r\nHTTP request sent, awaiting response... 200 OK\r\nLength: 1760478 (1.7M) [application/zip]\r\nSaving to: 'C:/Users/Tianhao/AppData/Local/Temp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip'\r\n\r\nC:/Users/Tianhao/AppData/Loca 100%[=================================================>]   1.68M  3.38MB/s    in 0.5s\r\n\r\n2021-04-02 10:36:19 (3.38 MB/s) - 'C:/Users/Tianhao/AppData/Local/Temp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip' sav\r\ned [1760478/1760478]\r\n\r\n/tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: /tmp/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip: cannot execute bin\r\nary file\r\ntensorflow/lite/micro/tools/make/downloads/pigweed already exists, skipping the download.\r\n**_make: *** No rule to make target 'generate_person_detection_esp_int8_project'.  Stop._**", "Again, I tried both w/ and w/o int8, same error.", "Hi, I'm struggling the same issues. \r\nIs there any update or changes? \r\n\r\nI am looking forward to solving this problem quickly.", "@SunBeenMoon, @Hazeline2018,  I had a similar issue in the beginning. I got it fixed with the following work around, though I am not sure how and why it was fixed.\r\n\r\nmy commands which make it working\r\n```\r\n$ git clone --depth 1 https://github.com/tensorflow/tensorflow.git\r\n$ cd tensorflow/\r\n$ make -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_person_detection_esp_project\r\n# error occurs, same as yours, I believe.\r\n# download 47063.patch according to vikramdattu\r\n$ ls 47063.patch                        # to make sure patch is downloaded\r\n$ git apply ./47063.patch\r\n$ make -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_person_detection_esp_project\r\n# it generate another error below and stop.\r\nmake: *** No rule to make target 'tensorflow/lite/micro/tools/make/gen/esp_xtensa-esp32_default/prj/person_detection/esp-idf/main/person_model_int8/person_detect_model_data.cc', needed by 'generate_person_detection_esp_project'.  Stop.\r\n$ make -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_person_detection_esp_int8_project\r\n# this command generate another error of below, but it seems fix the previous error.\r\nmake: *** No rule to make target 'generate_person_detection_esp_int8_project'.  Stop.\r\n$ make -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_person_detection_esp_project\r\n# so we re-do the generate_person_detection_esp_project again, it works and no error.\r\n```\r\ndetail log will be provided in next comment", "detail log from previous comment\r\n```\r\nubuntu@ubuntu:~$ git clone --depth 1 https://github.com/tensorflow/tensorflow.git\r\nCloning into 'tensorflow'...\r\nremote: Enumerating objects: 24117, done.\r\nremote: Counting objects: 100% (24117/24117), done.\r\nremote: Compressing objects: 100% (17754/17754), done.\r\nremote: Total 24117 (delta 9052), reused 10606 (delta 5794), pack-reused 0\r\nReceiving objects: 100% (24117/24117), 57.55 MiB | 3.95 MiB/s, done.\r\nResolving deltas: 100% (9052/9052), done.\r\nChecking out files: 100% (24617/24617), done.\r\nubuntu@ubuntu:~$ cd tensorflow/\r\nubuntu@ubuntu:~/tensorflow$ make -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_person_detection_esp_project\r\n--2021-04-06 07:01:44--  http://mirror.tensorflow.org/github.com/google/flatbuffers/archive/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip\r\nResolving mirror.tensorflow.org (mirror.tensorflow.org)... 172.217.160.112, 2404:6800:4012:1::2010\r\nConnecting to mirror.tensorflow.org (mirror.tensorflow.org)|172.217.160.112|:80... connected.\r\nHTTP request sent, awaiting response... 200 OK\r\nLength: 1760478 (1.7M) [application/zip]\r\nSaving to: \u2018/tmp/tmp.sFnwFGhM1G/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip\u2019\r\n\r\n/tmp/tmp.sFnwFGhM1G 100%[===================>]   1.68M  3.82MB/s    in 0.4s    \r\n\r\n2021-04-06 07:01:46 (3.82 MB/s) - \u2018/tmp/tmp.sFnwFGhM1G/dca12522a9f9e37f126ab925fd385c807ab4f84e.zip\u2019 saved [1760478/1760478]\r\n\r\nCloning into 'tensorflow/lite/micro/tools/make/downloads/pigweed'...\r\nremote: Sending approximately 13.29 MiB ...\r\nremote: Total 20574 (delta 9253), reused 20574 (delta 9253)\r\nReceiving objects: 100% (20574/20574), 13.27 MiB | 6.38 MiB/s, done.\r\nResolving deltas: 100% (9253/9253), done.\r\nNote: checking out '47268dff45019863e20438ca3746c6c62df6ef09'.\r\n\r\nYou are in 'detached HEAD' state. You can look around, make experimental\r\nchanges and commit them, and you can discard any commits you make in this\r\nstate without impacting any branches by performing another checkout.\r\n\r\nIf you want to create a new branch to retain commits you create, you may\r\ndo so (now or later) by using -b with the checkout command again. Example:\r\n\r\n  git checkout -b <new-branch-name>\r\n\r\nHEAD is now at 47268dff pw_hdlc_lite: Client I/O improvements\r\nmake: *** No rule to make target 'generate_person_detection_esp_project'.  Stop.\r\nubuntu@ubuntu:~/tensorflow$ ls 47063.patch\r\n47063.patch         \r\nubuntu@ubuntu:~/tensorflow$ git apply ./47063.patch\r\nubuntu@ubuntu:~/tensorflow$ make -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_person_detection_esp_project\r\ntensorflow/lite/micro/tools/make/downloads/flatbuffers already exists, skipping the download.\r\ntensorflow/lite/micro/tools/make/downloads/pigweed already exists, skipping the download.\r\ntensorflow/lite/micro/tools/make/download_and_extract.sh \"https://github.com/google/gemmlowp/archive/719139ce755a0f31cbf1c37f7f98adcc7fc9f425.zip\" \"7e8191b24853d75de2af87622ad293ba\" tensorflow/lite/micro/tools/make/downloads/gemmlowp  \r\ndownloading https://github.com/google/gemmlowp/archive/719139ce755a0f31cbf1c37f7f98adcc7fc9f425.zip\r\n\r\n.... skipped .....\r\n\r\nFinished patching kissfft\r\nmake: *** No rule to make target 'tensorflow/lite/micro/tools/make/gen/esp_xtensa-esp32_default/prj/person_detection/esp-idf/main/person_model_int8/person_detect_model_data.cc', needed by 'generate_person_detection_esp_project'.  Stop.\r\nubuntu@ubuntu:~/tensorflow$ make -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_person_detection_esp_int8_project\r\ntensorflow/lite/micro/tools/make/downloads/flatbuffers already exists, skipping the download.\r\ntensorflow/lite/micro/tools/make/downloads/pigweed already exists, skipping the download.\r\nmake: *** No rule to make target 'generate_person_detection_esp_int8_project'.  Stop.\r\nubuntu@ubuntu:~/tensorflow$ make -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_person_detection_esp_project\r\ntensorflow/lite/micro/tools/make/downloads/flatbuffers already exists, skipping the download.\r\ntensorflow/lite/micro/tools/make/downloads/pigweed already exists, skipping the download.\r\nubuntu@ubuntu:~/tensorflow$ \r\n```", "@marconi1964 \r\nIt seems that you were having different error with mine. Mine is stuck with no make rule error. \r\nI tried your sequence tho, but no luck, same error.\r\nI did the fresh git clone and patching then your sequence, still failed.\r\nIt looks like I'm not the only one who has the same no make rule issue. Hopefully, this can be solved since it's been dragging for almost a month. Thanks!", "With my patch applied, I reproduced an error mentioned by @marconi1964 by deleting the downloads and running command fresh.\r\n\r\n```\r\ngmake: *** No rule to make target 'tensorflow/lite/micro/tools/make/gen/esp_xtensa-esp32_default/prj/person_detection/esp-idf/main/person_model_int8/person_detect_model_data.cc', needed by 'generate_person_detection_esp_project'.  Stop.\r\n```\r\nInterestingly, running the command again fixes it.\r\n\r\nCommand used: `gmake -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_person_detection_esp_project`\r\n\r\nLooks like for first run, make is not able to find the file as it is now downloaded yet or something on the lines!\r\n", "Hi, @marconi1964 \r\nI'm still struggle in the same problem with @Hazeline2018.\r\n\r\nII'm curious about your settings.\r\nProbably there is a problem in the initial setting, so it seems that the build did not work.\r\n\r\n-------------------------------------------------- -------------------------------------------------- -\r\n\r\n> Install the ESP IDF\r\n> Follow the instructions of the ESP-IDF get started guide to setup the toolchain and the ESP-IDF itself.\r\n> \r\n> The next steps assume that the IDF environment variables are set :\r\n> \r\n> The IDF_PATH environment variable is set\r\n> idf.py and Xtensa-esp32 tools (e.g. xtensa-esp32-elf-gcc) are in $PATH\r\n> esp32-camera should be downloaded in components/ dir of example as explained in Building the example(below)\r\n\r\n-------------------------------------------------- -------------------------------------------------- -----\r\nHere, I am curious about how to set idf.py dhk Xtensa-esp32-elf-gcc.\r\n\r\nI am using virtualbox linux on window.\r\nHow can I check if idf.py is in the path?\r\nWhat I set is\r\n```\r\nexport IDF_PATH=/usr/my/esp/esp-idf\r\nexport PATH=$PATH:/usr/my/esp/esp-idf\r\n```\r\nto be.\r\n\r\nI wonder how you set it up.", "@SunBeenMoon for IDF installation,\r\n\r\nset IDF_PATH and then following commands:\r\n\r\n```\r\n./install.sh\r\n. ./export.sh\r\n```\r\n\r\nThe first command downloads/installs all the necessary tools, the second command sets the environment. You do not need set PATH var manually.\r\n\r\nRun `idf.py` to check if setup is proper.", "Thank you for your reply @vikramdattu \r\n\r\nI installed it correctly.\r\nBut I still get the same error. \r\n\r\nPlease let me know if you have any updates.", "@SunBeenMoon, \r\nI use Ubuntu 18.04 within VMware Workstation 15 player under Windows 10.\r\nThe error comes from TensorFlow Makefile, which is not related to idf.py and its set up. Nevertheless, I use the same idf.py set up as @vikramdattu.\r\n\r\n```\r\ncd ~/esp/esp-idf\r\n./install.sh\r\n. ./export.sh\r\n```", "Hey Guys,\r\n\r\nI just did a fresh git check out of the tensorflow in my Ubuntu-20.04 VM running on Windows10 and tried again, I'm getting exactly the same error as @marconi1964 mentioned earlier. Then reran the make cmd, and finally it generated the proj w/o error. For others to follow easily, I listed the whole cmds sequence as below. (just the cmds with some comments, omitting outputs to save space)\r\n\r\nterryl@DESKTOP-55BFST5:/mnt/c/Projects$ git clone --depth 1 https://github.com/tensorflow/tensorflow.git   (freshly check out)\r\nterryl@DESKTOP-55BFST5:/mnt/c/Projects$ cd tensorflow\r\nterryl@DESKTOP-55BFST5:/mnt/c/Projects/tensorflow$ make -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_person_detection_esp_project (first attempt, failed with no make rule error, as expected)\r\nmake: *** No rule to make target 'generate_person_detection_esp_project'.  Stop.\r\nterryl@DESKTOP-55BFST5:/mnt/c/Projects/tensorflow$ git apply ./47063.patch  (apply patch from @vikramdattu)\r\nterryl@DESKTOP-55BFST5:/mnt/c/Projects/tensorflow$ make -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_person_detection_esp_project    (2nd attempt after applying patch, failed, but with different error)\r\nmake: *** No rule to make target 'tensorflow/lite/micro/tools/make/gen/esp_xtensa-esp32_default/prj/person_detection/esp-idf/main/person_model_int8/person_detect_model_data.cc', needed by 'generate_person_detection_esp_project'.  Stop.\r\nterryl@DESKTOP-55BFST5:/mnt/c/Projects/tensorflow$ make -f tensorflow/lite/micro/tools/make/Makefile TARGET=esp generate_person_detection_esp_project    (3rd attempt, basically rerun the same make cmd again, and it works)\r\ntensorflow/lite/micro/tools/make/downloads/flatbuffers already exists, skipping the download.\r\ntensorflow/lite/micro/tools/make/downloads/pigweed already exists, skipping the download.\r\nterryl@DESKTOP-55BFST5:/mnt/c/Projects/tensorflow$\r\n\r\nnot sure exactly why rerunning the make cmd fixes the error, but I'm glad it's working on Ubuntu env. I'll try pure windows setup to see if the error still persists and update back.\r\nHope this helps!", "Thank you all of guys. \r\n\r\nI solve the problem.\r\nI fetched the file and then I can build the project.", "Hi @vikramdattu  @Hazeline2018 \r\n\r\nThanks to your kind help, I was able to build the project in tensorflow.\r\nHowever, the following problem occurred while executing idf.py build.\r\n```\r\nmsb@msb-VirtualBox:/usr/my/tensorflow/tensorflow/lite/micro/tools/make/gen/esp_xtensa-esp32_default/prj/person_detection/esp-idf$ idf.py build\r\nExecuting action: all (aliases: build)\r\nRunning ninja in directory /usr/my/tensorflow/tensorflow/lite/micro/tools/make/gen/esp_xtensa-esp32_default/prj/person_detection/esp-idf/build\r\nExecuting \"ninja all\"...\r\n[1/98] Building C object esp-idf/main/..._idf_main.dir/esp/app_camera_esp.c.obj\r\nFAILED: esp-idf/main/CMakeFiles/__idf_main.dir/esp/app_camera_esp.c.obj \r\n/home/msb/.espressif/tools/xtensa-esp32-elf/esp-2020r3-8.4.0/xtensa-esp32-elf/bin/xtensa-esp32-elf-gcc -DHAVE_CONFIG_H -DMBEDTLS_CONFIG_FILE=\\\"mbedtls/esp_config.h\\\" -DUNITY_INCLUDE_CONFIG_H -DWITH_POSIX -Iconfig -I/usr/my/esp/esp-idf/components/newlib/platform_include -I/usr/my/esp/esp-idf/components/freertos/include -I/usr/my/esp/esp-idf/components/freertos/port/xtensa/include -I/usr/my/esp/esp-idf/components/esp_hw_support/include -I/usr/my/esp/esp-idf/components/esp_hw_support/port/esp32/. -I/usr/my/esp/esp-idf/components/heap/include -I/usr/my/esp/esp-idf/components/log/include -I/usr/my/esp/esp-idf/components/lwip/include/apps -I/usr/my/esp/esp-idf/components/lwip/include/apps/sntp -I/usr/my/esp/esp-idf/components/lwip/lwip/src/include -I/usr/my/esp/esp-idf/components/lwip/port/esp32/include -I/usr/my/esp/esp-idf/components/lwip/port/esp32/include/arch -I/usr/my/esp/esp-idf/components/soc/include -I/usr/my/esp/esp-idf/components/soc/esp32/. -I/usr/my/esp/esp-idf/components/soc/esp32/include -I/usr/my/esp/esp-idf/components/hal/esp32/include -I/usr/my/esp/esp-idf/components/hal/include -I/usr/my/esp/esp-idf/components/esp_rom/include -I/usr/my/esp/esp-idf/components/esp_rom/esp32 -I/usr/my/esp/esp-idf/components/esp_common/include -I/usr/my/esp/esp-idf/components/esp_system/include -I/usr/my/esp/esp-idf/components/esp32/include -I/usr/my/esp/esp-idf/components/driver/include -I/usr/my/esp/esp-idf/components/driver/esp32/include -I/usr/my/esp/esp-idf/components/esp_pm/include -I/usr/my/esp/esp-idf/components/esp_ringbuf/include -I/usr/my/esp/esp-idf/components/efuse/include -I/usr/my/esp/esp-idf/components/efuse/esp32/include -I/usr/my/esp/esp-idf/components/xtensa/include -I/usr/my/esp/esp-idf/components/xtensa/esp32/include -I/usr/my/esp/esp-idf/components/vfs/include -I/usr/my/esp/esp-idf/components/esp_wifi/include -I/usr/my/esp/esp-idf/components/esp_wifi/esp32/include -I/usr/my/esp/esp-idf/components/esp_event/include -I/usr/my/esp/esp-idf/components/esp_netif/include -I/usr/my/esp/esp-idf/components/esp_eth/include -I/usr/my/esp/esp-idf/components/tcpip_adapter/include -I/usr/my/esp/esp-idf/components/app_trace/include -I/usr/my/esp/esp-idf/components/esp_timer/include -I/usr/my/esp/esp-idf/components/mbedtls/port/include -I/usr/my/esp/esp-idf/components/mbedtls/mbedtls/include -I/usr/my/esp/esp-idf/components/mbedtls/esp_crt_bundle/include -I/usr/my/esp/esp-idf/components/app_update/include -I/usr/my/esp/esp-idf/components/spi_flash/include -I/usr/my/esp/esp-idf/components/bootloader_support/include -I/usr/my/esp/esp-idf/components/esp_ipc/include -I/usr/my/esp/esp-idf/components/nvs_flash/include -I/usr/my/esp/esp-idf/components/pthread/include -I/usr/my/esp/esp-idf/components/esp_gdbstub/include -I/usr/my/esp/esp-idf/components/esp_gdbstub/xtensa -I/usr/my/esp/esp-idf/components/esp_gdbstub/esp32 -I/usr/my/esp/esp-idf/components/espcoredump/include -I/usr/my/esp/esp-idf/components/wpa_supplicant/include -I/usr/my/esp/esp-idf/components/wpa_supplicant/port/include -I/usr/my/esp/esp-idf/components/wpa_supplicant/include/esp_supplicant -I/usr/my/esp/esp-idf/components/perfmon/include -I/usr/my/esp/esp-idf/components/asio/asio/asio/include -I/usr/my/esp/esp-idf/components/asio/port/include -I/usr/my/esp/esp-idf/components/cbor/port/include -I/usr/my/esp/esp-idf/components/unity/include -I/usr/my/esp/esp-idf/components/unity/unity/src -I/usr/my/esp/esp-idf/components/cmock/CMock/src -I/usr/my/esp/esp-idf/components/coap/port/include -I/usr/my/esp/esp-idf/components/coap/port/include/coap -I/usr/my/esp/esp-idf/components/coap/libcoap/include -I/usr/my/esp/esp-idf/components/coap/libcoap/include/coap2 -I/usr/my/esp/esp-idf/components/console -I/usr/my/esp/esp-idf/components/nghttp/port/include -I/usr/my/esp/esp-idf/components/nghttp/nghttp2/lib/includes -I/usr/my/esp/esp-idf/components/esp-tls -I/usr/my/esp/esp-idf/components/esp-tls/esp-tls-crypto -I../components/esp32-camera/driver/include -I../components/esp32-camera/conversions/include -I/usr/my/esp/esp-idf/components/esp_adc_cal/include -I/usr/my/esp/esp-idf/components/esp_hid/include -I/usr/my/esp/esp-idf/components/tcp_transport/include -I/usr/my/esp/esp-idf/components/esp_http_client/include -I/usr/my/esp/esp-idf/components/esp_http_server/include -I/usr/my/esp/esp-idf/components/esp_https_ota/include -I/usr/my/esp/esp-idf/components/protobuf-c/protobuf-c -I/usr/my/esp/esp-idf/components/protocomm/include/common -I/usr/my/esp/esp-idf/components/protocomm/include/security -I/usr/my/esp/esp-idf/components/protocomm/include/transports -I/usr/my/esp/esp-idf/components/mdns/include -I/usr/my/esp/esp-idf/components/esp_local_ctrl/include -I/usr/my/esp/esp-idf/components/sdmmc/include -I/usr/my/esp/esp-idf/components/esp_serial_slave_link/include -I/usr/my/esp/esp-idf/components/esp_websocket_client/include -I/usr/my/esp/esp-idf/components/expat/expat/expat/lib -I/usr/my/esp/esp-idf/components/expat/port/include -I/usr/my/esp/esp-idf/components/wear_levelling/include -I/usr/my/esp/esp-idf/components/fatfs/diskio -I/usr/my/esp/esp-idf/components/fatfs/vfs -I/usr/my/esp/esp-idf/components/fatfs/src -I/usr/my/esp/esp-idf/components/freemodbus/common/include -I/usr/my/esp/esp-idf/components/idf_test/include -I/usr/my/esp/esp-idf/components/idf_test/include/esp32 -I/usr/my/esp/esp-idf/components/jsmn/include -I/usr/my/esp/esp-idf/components/json/cJSON -I/usr/my/esp/esp-idf/components/libsodium/libsodium/src/libsodium/include -I/usr/my/esp/esp-idf/components/libsodium/port_include -I/usr/my/esp/esp-idf/components/mqtt/esp-mqtt/include -I/usr/my/esp/esp-idf/components/openssl/include -I/usr/my/esp/esp-idf/components/spiffs/include -I/usr/my/esp/esp-idf/components/ulp/include -I/usr/my/esp/esp-idf/components/wifi_provisioning/include -I../components/tfmicro -I../components/tfmicro/third_party/gemmlowp -I../components/tfmicro/third_party/flatbuffers/include -I../components/tfmicro/third_party/ruy -I../components/tfmicro/third_party/kissfft -mlongcalls -Wno-frame-address -ffunction-sections -fdata-sections -Wall -Werror=all -Wno-error=unused-function -Wno-error=unused-variable -Wno-error=deprecated-declarations -Wextra -Wno-unused-parameter -Wno-sign-compare -ggdb -O2 -fmacro-prefix-map=/usr/my/tensorflow/tensorflow/lite/micro/tools/make/gen/esp_xtensa-esp32_default/prj/person_detection/esp-idf=. -fmacro-prefix-map=/usr/my/esp/esp-idf=IDF -fstrict-volatile-bitfields -Wno-error=unused-but-set-variable -std=gnu99 -Wno-old-style-declaration -D_GNU_SOURCE -DIDF_VER=\\\"v4.4-dev-744-g1cb31e509\\\" -DESP_PLATFORM -DTF_LITE_STATIC_MEMORY -MD -MT esp-idf/main/CMakeFiles/__idf_main.dir/esp/app_camera_esp.c.obj -MF esp-idf/main/CMakeFiles/__idf_main.dir/esp/app_camera_esp.c.obj.d -o esp-idf/main/CMakeFiles/__idf_main.dir/esp/app_camera_esp.c.obj -c ../main/esp/app_camera_esp.c\r\n../main/esp/app_camera_esp.c: In function 'app_camera_init':\r\n../main/esp/app_camera_esp.c:35:3: error: unknown type name 'camera_config_t'\r\n   camera_config_t config;\r\n   ^~~~~~~~~~~~~~~\r\n../main/esp/app_camera_esp.c:36:9: error: request for member 'ledc_channel' in something not a structure or union\r\n   config.ledc_channel = LEDC_CHANNEL_0;\r\n         ^\r\n../main/esp/app_camera_esp.c:36:25: error: 'LEDC_CHANNEL_0' undeclared (first use in this function)\r\n   config.ledc_channel = LEDC_CHANNEL_0;\r\n                         ^~~~~~~~~~~~~~\r\n../main/esp/app_camera_esp.c:36:25: note: each undeclared identifier is reported only once for each function it appears in\r\n../main/esp/app_camera_esp.c:37:9: error: request for member 'ledc_timer' in something not a structure or union\r\n   config.ledc_timer = LEDC_TIMER_0;\r\n         ^\r\n../main/esp/app_camera_esp.c:37:23: error: 'LEDC_TIMER_0' undeclared (first use in this function); did you mean '__TIME__'?\r\n   config.ledc_timer = LEDC_TIMER_0;\r\n                       ^~~~~~~~~~~~\r\n                       __TIME__\r\n../main/esp/app_camera_esp.c:38:9: error: request for member 'pin_d0' in something not a structure or union\r\n   config.pin_d0 = Y2_GPIO_NUM;\r\n         ^\r\n../main/esp/app_camera_esp.c:38:19: error: 'Y2_GPIO_NUM' undeclared (first use in this function)\r\n   config.pin_d0 = Y2_GPIO_NUM;\r\n                   ^~~~~~~~~~~\r\n../main/esp/app_camera_esp.c:39:9: error: request for member 'pin_d1' in something not a structure or union\r\n   config.pin_d1 = Y3_GPIO_NUM;\r\n         ^\r\n../main/esp/app_camera_esp.c:39:19: error: 'Y3_GPIO_NUM' undeclared (first use in this function)\r\n   config.pin_d1 = Y3_GPIO_NUM;\r\n                   ^~~~~~~~~~~\r\n../main/esp/app_camera_esp.c:40:9: error: request for member 'pin_d2' in something not a structure or union\r\n   config.pin_d2 = Y4_GPIO_NUM;\r\n         ^\r\n../main/esp/app_camera_esp.c:40:19: error: 'Y4_GPIO_NUM' undeclared (first use in this function)\r\n   config.pin_d2 = Y4_GPIO_NUM;\r\n                   ^~~~~~~~~~~\r\n../main/esp/app_camera_esp.c:41:9: error: request for member 'pin_d3' in something not a structure or union\r\n   config.pin_d3 = Y5_GPIO_NUM;\r\n         ^\r\n../main/esp/app_camera_esp.c:41:19: error: 'Y5_GPIO_NUM' undeclared (first use in this function)\r\n   config.pin_d3 = Y5_GPIO_NUM;\r\n                   ^~~~~~~~~~~\r\n../main/esp/app_camera_esp.c:42:9: error: request for member 'pin_d4' in something not a structure or union\r\n   config.pin_d4 = Y6_GPIO_NUM;\r\n         ^\r\n../main/esp/app_camera_esp.c:42:19: error: 'Y6_GPIO_NUM' undeclared (first use in this function)\r\n   config.pin_d4 = Y6_GPIO_NUM;\r\n                   ^~~~~~~~~~~\r\n../main/esp/app_camera_esp.c:43:9: error: request for member 'pin_d5' in something not a structure or union\r\n   config.pin_d5 = Y7_GPIO_NUM;\r\n         ^\r\n../main/esp/app_camera_esp.c:43:19: error: 'Y7_GPIO_NUM' undeclared (first use in this function)\r\n   config.pin_d5 = Y7_GPIO_NUM;\r\n                   ^~~~~~~~~~~\r\n../main/esp/app_camera_esp.c:44:9: error: request for member 'pin_d6' in something not a structure or union\r\n   config.pin_d6 = Y8_GPIO_NUM;\r\n         ^\r\n../main/esp/app_camera_esp.c:44:19: error: 'Y8_GPIO_NUM' undeclared (first use in this function)\r\n   config.pin_d6 = Y8_GPIO_NUM;\r\n                   ^~~~~~~~~~~\r\n../main/esp/app_camera_esp.c:45:9: error: request for member 'pin_d7' in something not a structure or union\r\n   config.pin_d7 = Y9_GPIO_NUM;\r\n         ^\r\n../main/esp/app_camera_esp.c:45:19: error: 'Y9_GPIO_NUM' undeclared (first use in this function)\r\n   config.pin_d7 = Y9_GPIO_NUM;\r\n                   ^~~~~~~~~~~\r\n../main/esp/app_camera_esp.c:46:9: error: request for member 'pin_xclk' in something not a structure or union\r\n   config.pin_xclk = XCLK_GPIO_NUM;\r\n         ^\r\n../main/esp/app_camera_esp.c:46:21: error: 'XCLK_GPIO_NUM' undeclared (first use in this function)\r\n   config.pin_xclk = XCLK_GPIO_NUM;\r\n                     ^~~~~~~~~~~~~\r\n../main/esp/app_camera_esp.c:47:9: error: request for member 'pin_pclk' in something not a structure or union\r\n   config.pin_pclk = PCLK_GPIO_NUM;\r\n         ^\r\n../main/esp/app_camera_esp.c:47:21: error: 'PCLK_GPIO_NUM' undeclared (first use in this function)\r\n   config.pin_pclk = PCLK_GPIO_NUM;\r\n                     ^~~~~~~~~~~~~\r\n../main/esp/app_camera_esp.c:48:9: error: request for member 'pin_vsync' in something not a structure or union\r\n   config.pin_vsync = VSYNC_GPIO_NUM;\r\n         ^\r\n../main/esp/app_camera_esp.c:48:22: error: 'VSYNC_GPIO_NUM' undeclared (first use in this function)\r\n   config.pin_vsync = VSYNC_GPIO_NUM;\r\n                      ^~~~~~~~~~~~~~\r\n../main/esp/app_camera_esp.c:49:9: error: request for member 'pin_href' in something not a structure or union\r\n   config.pin_href = HREF_GPIO_NUM;\r\n         ^\r\n../main/esp/app_camera_esp.c:49:21: error: 'HREF_GPIO_NUM' undeclared (first use in this function)\r\n   config.pin_href = HREF_GPIO_NUM;\r\n                     ^~~~~~~~~~~~~\r\n../main/esp/app_camera_esp.c:50:9: error: request for member 'pin_sscb_sda' in something not a structure or union\r\n   config.pin_sscb_sda = SIOD_GPIO_NUM;\r\n         ^\r\n../main/esp/app_camera_esp.c:50:25: error: 'SIOD_GPIO_NUM' undeclared (first use in this function)\r\n   config.pin_sscb_sda = SIOD_GPIO_NUM;\r\n                         ^~~~~~~~~~~~~\r\n../main/esp/app_camera_esp.c:51:9: error: request for member 'pin_sscb_scl' in something not a structure or union\r\n   config.pin_sscb_scl = SIOC_GPIO_NUM;\r\n         ^\r\n../main/esp/app_camera_esp.c:51:25: error: 'SIOC_GPIO_NUM' undeclared (first use in this function)\r\n   config.pin_sscb_scl = SIOC_GPIO_NUM;\r\n                         ^~~~~~~~~~~~~\r\n../main/esp/app_camera_esp.c:52:9: error: request for member 'pin_pwdn' in something not a structure or union\r\n   config.pin_pwdn = PWDN_GPIO_NUM;\r\n         ^\r\n../main/esp/app_camera_esp.c:52:21: error: 'PWDN_GPIO_NUM' undeclared (first use in this function)\r\n   config.pin_pwdn = PWDN_GPIO_NUM;\r\n                     ^~~~~~~~~~~~~\r\n../main/esp/app_camera_esp.c:53:9: error: request for member 'pin_reset' in something not a structure or union\r\n   config.pin_reset = -1;  // RESET_GPIO_NUM;\r\n         ^\r\n../main/esp/app_camera_esp.c:54:9: error: request for member 'xclk_freq_hz' in something not a structure or union\r\n   config.xclk_freq_hz = XCLK_FREQ;\r\n         ^\r\n../main/esp/app_camera_esp.c:54:25: error: 'XCLK_FREQ' undeclared (first use in this function)\r\n   config.xclk_freq_hz = XCLK_FREQ;\r\n                         ^~~~~~~~~\r\n../main/esp/app_camera_esp.c:55:9: error: request for member 'pixel_format' in something not a structure or union\r\n   config.pixel_format = CAMERA_PIXEL_FORMAT;\r\n         ^\r\n../main/esp/app_camera_esp.c:55:25: error: 'CAMERA_PIXEL_FORMAT' undeclared (first use in this function)\r\n   config.pixel_format = CAMERA_PIXEL_FORMAT;\r\n                         ^~~~~~~~~~~~~~~~~~~\r\n../main/esp/app_camera_esp.c:56:9: error: request for member 'frame_size' in something not a structure or union\r\n   config.frame_size = CAMERA_FRAME_SIZE;\r\n         ^\r\n../main/esp/app_camera_esp.c:56:23: error: 'CAMERA_FRAME_SIZE' undeclared (first use in this function)\r\n   config.frame_size = CAMERA_FRAME_SIZE;\r\n                       ^~~~~~~~~~~~~~~~~\r\n../main/esp/app_camera_esp.c:57:9: error: request for member 'jpeg_quality' in something not a structure or union\r\n   config.jpeg_quality = 10;\r\n         ^\r\n../main/esp/app_camera_esp.c:58:9: error: request for member 'fb_count' in something not a structure or union\r\n   config.fb_count = 1;\r\n         ^\r\n../main/esp/app_camera_esp.c:61:3: error: unknown type name 'esp_err_t'\r\n   esp_err_t err = esp_camera_init(&config);\r\n   ^~~~~~~~~\r\n../main/esp/app_camera_esp.c:61:19: error: implicit declaration of function 'esp_camera_init'; did you mean 'app_camera_init'? [-Werror=implicit-function-declaration]\r\n   esp_err_t err = esp_camera_init(&config);\r\n                   ^~~~~~~~~~~~~~~\r\n                   app_camera_init\r\n../main/esp/app_camera_esp.c:62:14: error: 'ESP_OK' undeclared (first use in this function)\r\n   if (err != ESP_OK) {\r\n              ^~~~~~\r\n../main/esp/app_camera_esp.c:63:5: error: implicit declaration of function 'ESP_LOGE'; did you mean 'ESP_PLATFORM'? [-Werror=implicit-function-declaration]\r\n     ESP_LOGE(TAG, \"Camera init failed with error 0x%x\", err);\r\n     ^~~~~~~~\r\n     ESP_PLATFORM\r\ncc1: some warnings being treated as errors\r\n[2/98] Performing build step for 'bootloader'\r\nninja: no work to do.\r\nninja: build stopped: subcommand failed.\r\n```\r\nI am curious if you know any solutions related to this.\r\n\r\nPlease share what happened when you tried to import it to the esp32 board.\r\nAlso I am using the latest version of esp-idf. What version do you use?", "Hi guys. I fix this problem!\r\n\r\nDownload the person detection example in espressif official git hub!\r\nhttps://github.com/espressif/tensorflow/tree/master/tensorflow/lite/micro/examples/person_detection#running-on-esp32", "With TFLM moving to its own GitHub repository, we are not going to be merging any TFLM specific pull requests in the TensorFlow repository starting today.\r\n\r\nI am closing the current PR but please feel free to open a new PR in https://github.com/tensorflow/tflite-micro/.\r\n\r\nhttps://groups.google.com/a/tensorflow.org/g/micro/c/W4DACgjPmOE\r\n"]}, {"number": 47062, "title": "tensorflow/cc/saved_model/README.md is broken", "body": "## URL(s) with the issue:\r\n\r\n- https://github.com/tensorflow/tensorflow/blob/master/tensorflow/cc/saved_model/README.md\r\n- https://raw.githubusercontent.com/tensorflow/tensorflow/master/tensorflow/cc/saved_model/README.md\r\n\r\n## Description of issue (what needs changing):\r\nI would expect to see some documentation regarding the package. Instead, it says `<!--#include file=\"../../python/saved_model/README.md\"-->`.\r\n", "comments": ["@atn832 Looks like there is no information in that `README.md` but general information about the package is given in the `README.md` in `python` folder [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/README.md). Thanks!\r\n\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 47061, "title": "tf.function Out of Memory on non first call", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 2.5.0\r\n- Python version: 3.8.5\r\n- Bazel version (if compiling from source): 4.0.0\r\n- GCC/Compiler version (if compiling from source): gcc 9.3.0\r\n- CUDA/cuDNN version: 11.1/8.0.5\r\n- GPU model and memory: Nvidia Quadro RTX 6000 ~ 23.8G\r\n\r\n\r\n**Describe the current behavior**\r\nIn a for loop of my python script, I call a @tf.function decorated function and the GPU allocator ran out of memory trying to allocate memory after hundreds of calls. The number of calls before the bug is variable.\r\n\r\n**Describe the expected behavior**\r\nI can't understand how the GPU can run hundreds times the function without memory issues and suddenly gets OOM. I would like to have better understanding, for example why GPU tries to allocate tensors on non-first call ? Have you any suggestions about how it can be solved ?\r\n\r\n**Standalone code to reproduce the issue**\r\nIt's impossible here to provide a simple reproducer.  The problem is I can't understand how this bug may happen.\r\n\r\n**Other info / logs**\r\nHere is the traceback on Jupyter. Note that the parameter N_CRITICS is a tensorflow constant, so it can't be the cause of the problem.\r\n```\r\n---------------------------------------------------------------------------\r\nResourceExhaustedError                    Traceback (most recent call last)\r\n<ipython-input-20-9b51c2da0088> in <module>\r\n      5     tmp_record = {}\r\n      6     for step in range(STEPS_PER_EPOCH):\r\n----> 7         res = train_step(N_CRITICS)\r\n      8 \r\n      9         # sauvegarde des r\u00e9sultats d'entrainement\r\n\r\n/NAS/deathrow/vincent/anaconda3/envs/env_vincent_2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    785     tracing_count = self.experimental_get_tracing_count()\r\n    786     with trace.Trace(self._name) as tm:\r\n--> 787       result = self._call(*args, **kwds)\r\n    788       compiler = \"xla\" if self._jit_compile else \"nonXla\"\r\n    789       new_tracing_count = self.experimental_get_tracing_count()\r\n\r\n/NAS/deathrow/vincent/anaconda3/envs/env_vincent_2/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    813       # In this case we have created variables on the first call, so we run the\r\n    814       # defunned version which is guaranteed to never create variables.\r\n--> 815       return self._stateless_fn(*args, **kwds)  # pylint: disable=not-callable\r\n    816     elif self._stateful_fn is not None:\r\n    817       # Release the lock early so that multiple threads can perform the call\r\n\r\n/NAS/deathrow/vincent/anaconda3/envs/env_vincent_2/lib/python3.8/site-packages/tensorflow/python/eager/function.py in __call__(self, *args, **kwargs)\r\n   2969       (graph_function,\r\n   2970        filtered_flat_args) = self._maybe_define_function(args, kwargs)\r\n-> 2971     return graph_function._call_flat(\r\n   2972         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\r\n   2973 \r\n\r\n/NAS/deathrow/vincent/anaconda3/envs/env_vincent_2/lib/python3.8/site-packages/tensorflow/python/eager/function.py in _call_flat(self, args, captured_inputs, cancellation_manager)\r\n   1945         and executing_eagerly):\r\n   1946       # No tape is watching; skip to running the function.\r\n-> 1947       return self._build_call_outputs(self._inference_function.call(\r\n   1948           ctx, args, cancellation_manager=cancellation_manager))\r\n   1949     forward_backward = self._select_forward_and_backward_functions(\r\n\r\n/NAS/deathrow/vincent/anaconda3/envs/env_vincent_2/lib/python3.8/site-packages/tensorflow/python/eager/function.py in call(self, ctx, args, cancellation_manager)\r\n    554       with _InterpolateFunctionError(self):\r\n    555         if cancellation_manager is None:\r\n--> 556           outputs = execute.execute(\r\n    557               str(self.signature.name),\r\n    558               num_outputs=self._num_outputs,\r\n\r\n/NAS/deathrow/vincent/anaconda3/envs/env_vincent_2/lib/python3.8/site-packages/tensorflow/python/eager/execute.py in quick_execute(op_name, num_outputs, inputs, attrs, ctx, name)\r\n     57   try:\r\n     58     ctx.ensure_initialized()\r\n---> 59     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\r\n     60                                         inputs, attrs, num_outputs)\r\n     61   except core._NotOkStatusException as e:\r\n\r\nResourceExhaustedError: 2 root error(s) found.\r\n  (0) Resource exhausted:  OOM when allocating tensor with shape[1,64,93,111,93] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n\t [[{{node while/body/_1/while/StatefulPartitionedCall/gradient_tape/sequential_33/sequential_31/conv3d_20/Conv3D_1/Conv3DBackpropInputV2}}]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n\t [[while/loop_body_control/_190/_23]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n  (1) Resource exhausted:  OOM when allocating tensor with shape[1,64,93,111,93] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\r\n\t [[{{node while/body/_1/while/StatefulPartitionedCall/gradient_tape/sequential_33/sequential_31/conv3d_20/Conv3D_1/Conv3DBackpropInputV2}}]]\r\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\r\n\r\n0 successful operations.\r\n0 derived errors ignored. [Op:__inference_train_step_49710]\r\n\r\nFunction call stack:\r\ntrain_step -> train_step\r\n```\r\n", "comments": ["@RocaVincent May it is building several graph models and once it runs out of memory with all those graph models, it is throwing the error. Please refer to this [tf.function](https://www.tensorflow.org/guide/function) guide to optimize the performance. Thanks!", "Thanks for the answer @jvishnuvardhan. But the guide says :\r\n\r\n> Note that if you repeatedly call a Function with the same argument type, TensorFlow will skip the tracing stage and reuse a previously traced graph, as the generated graph would be identical.\r\n\r\nHowever, my function takes only one argument which is a _tf.constant_ defined once. In addition, I've already tried to track retracing by putting a _print_ statement at the beginning of the function and there's been no printing... Therefore, there is apparently no retracing, so what can be the reasons that made the GPU keep trying to allocate tensors ?\r\n\r\nI will continue my technical investigations on Monday, but if you have any suggestions or explications it may be very usefull for me, and potentially for all users of _tf.function_. Thanks !", "I've got interesting results related to the issue. In my _tf.function_, I used [iterators](https://www.tensorflow.org/api_docs/python/tf/data/Iterator) and [get_next](https://www.tensorflow.org/api_docs/python/tf/data/Iterator#get_next) functions in order to read training samples. For now, it seems that putting these readings outside of _tf.function_ avoids OOM on non first call.\r\n\r\nHowever, it still surprises me because I don't understand why a call to the get_next function of a Tensorflow iterator may lead to an OOM on non first call. No documentation, at my knowledge, talks about this potential issue. Have you any explanation ?\r\n\r\nI give you in supplement the code I use to create my train [dataset](https://www.tensorflow.org/api_docs/python/tf/data/Dataset) :\r\n```\r\ndef prepare_train(record_fn):\r\n    keys_to_feature_train = {\"mri\": tf.io.FixedLenFeature(shape=IMAGE_SHAPE, dtype=tf.float32)}\r\n    return tf.data.TFRecordDataset(record_fn).map(lambda t: tf.io.parse_single_example(t, keys_to_feature_train)['mri'],\r\n                                          num_parallel_calls=AUTOTUNE, deterministic=False).cache().\\\r\n                                            shuffle(BUF_SIZE).repeat().batch(BATCH_SIZE).prefetch(AUTOTUNE)\r\n```", "I still encounter GPU Out-of-memery on non-first call, even when removing the *get_next* functions from the train *tf.function*. Therefore it's still an unexplainable issue for me.", "Hi @RocaVincent, can you provide any more code for us to look at (even if it's not a fully reproducible example)?", "Hi @nikitamaia, here is an example of `train_step` functions which caused me GPU OOM : \r\n\r\n```\r\n@tf_function(input_signature=(TensorSpec(shape=[BATCH_SIZE]+IMAGE_SHAPE, dtype=\"float32\"), TensorSpec(shape=[BATCH_SIZE]+IMAGE_SHAPE, dtype=\"float32\"),\r\n                             TensorSpec(shape=[BATCH_SIZE]+IMAGE_SHAPE, dtype=\"float32\"), TensorSpec(shape=[BATCH_SIZE]+IMAGE_SHAPE, dtype=\"float32\")))\r\ndef train_step(imagesA_d, imagesB_d, imagesA_g, imagesB_g):\r\n    # entrainement discriminateurs\r\n    fakesA = generator_BtoA(imagesB_d, training=False)\r\n    fakesB = generator_AtoB(imagesA_d, training=False)\r\n    with GradientTape(watch_accessed_variables=False) as tape:\r\n        tape.watch(discriminator_A.trainable_variables)\r\n        disc_realA = discriminator_A(imagesA_d, training=True)\r\n        disc_fakesA = discriminator_A(fakesA, training=True)\r\n        discA_loss = loss_adv(tf_ones(BATCH_SIZE), disc_realA) + loss_adv(tf_zeros(BATCH_SIZE), disc_fakesA)\r\n        discA_loss_scaled = discriminator_A_optimizer.get_scaled_loss(discA_loss)\r\n    gradients_discA = tape.gradient(discA_loss_scaled, discriminator_A.trainable_variables)\r\n    gradients_discA = discriminator_A_optimizer.get_unscaled_gradients(gradients_discA)\r\n    discriminator_A_optimizer.apply_gradients(zip(gradients_discA, discriminator_A.trainable_variables))\r\n    \r\n    with GradientTape(watch_accessed_variables=False) as tape:\r\n        tape.watch(discriminator_B.trainable_variables)\r\n        disc_realB = discriminator_B(imagesB_d, training=True)\r\n        disc_fakesB = discriminator_B(fakesB, training=True)\r\n        discB_loss = loss_adv(tf_ones(BATCH_SIZE), disc_realB) + loss_adv(tf_zeros(BATCH_SIZE), disc_fakesB)\r\n        discB_loss_scaled = discriminator_B_optimizer.get_scaled_loss(discB_loss)\r\n    gradients_discB = tape.gradient(discB_loss_scaled, discriminator_B.trainable_variables)\r\n    gradients_discB = discriminator_B_optimizer.get_unscaled_gradients(gradients_discB)\r\n    discriminator_B_optimizer.apply_gradients(zip(gradients_discB, discriminator_B.trainable_variables))\r\n    \r\n    \r\n    # entrainement generateurs\r\n    with GradientTape(persistent=True) as tape:\r\n        fakesA = generator_BtoA(imagesB_g, training=True)\r\n        fakesB = generator_AtoB(imagesA_g, training=True)\r\n        \r\n        # losses adversarielles\r\n        disc_fakesA = discriminator_A(fakesA, training=False)\r\n        disc_fakesB = discriminator_B(fakesB, training=False)\r\n        gen_AtoB_adv_loss = loss_adv(tf_ones(BATCH_SIZE), disc_fakesB)\r\n        gen_BtoA_adv_loss = loss_adv(tf_ones(BATCH_SIZE), disc_fakesA)\r\n                \r\n        # loss de reconstruction\r\n        cycledA = generator_BtoA(fakesB, training=True)\r\n        cycledB = generator_AtoB(fakesA, training=True)\r\n        cycle_loss_aba = cycle_loss(imagesA_g, cycledA)\r\n        cycle_loss_bab = cycle_loss(imagesB_g, cycledB)\r\n        sum_cycle_loss = cycle_loss_aba + cycle_loss_bab\r\n        \r\n        # losses finales\r\n        gen_AtoB_loss = gen_AtoB_adv_loss + LAMBDA_CYC*sum_cycle_loss\r\n        gen_AtoB_loss = generator_AtoB_optimizer.get_scaled_loss(gen_AtoB_loss)\r\n        gen_BtoA_loss = gen_BtoA_adv_loss + LAMBDA_CYC*sum_cycle_loss \r\n        gen_BtoA_loss = generator_BtoA_optimizer.get_scaled_loss(gen_BtoA_loss)\r\n        \r\n    gradients_gen_AtoB = tape.gradient(gen_AtoB_loss, generator_AtoB.trainable_variables)\r\n    gradients_gen_AtoB = generator_AtoB_optimizer.get_unscaled_gradients(gradients_gen_AtoB)\r\n    gradients_gen_BtoA = tape.gradient(gen_BtoA_loss, generator_BtoA.trainable_variables)\r\n    gradients_gen_BtoA = generator_BtoA_optimizer.get_unscaled_gradients(gradients_gen_BtoA)\r\n    generator_AtoB_optimizer.apply_gradients(zip(gradients_gen_AtoB, generator_AtoB.trainable_variables))\r\n    generator_BtoA_optimizer.apply_gradients(zip(gradients_gen_BtoA, generator_BtoA.trainable_variables))\r\n  \r\n    # Retourne les stats d'entrainement\r\n    return {\"discA_loss\": discA_loss, \"discB_loss\": discB_loss, \r\n            \"gen_AtoB_adv_loss\": gen_AtoB_adv_loss, \"gen_BtoA_adv_loss\": gen_BtoA_adv_loss,\r\n            \"cycle_loss_aba\": cycle_loss_aba, \"cycle_loss_bab\": cycle_loss_bab}\r\n```\r\n\r\nHere is the calling code for each step :\r\n```\r\nimagesA_d = iterA.get_next()\r\nimagesB_d = iterB.get_next()\r\nimagesA_g = iterA.get_next()\r\nimagesB_g = iterB.get_next()\r\nres = train_step(imagesA_d, imagesB_d, imagesA_g, imagesB_g)\r\n```\r\n\r\nAnd here is the function to create the training datasets :\r\n```\r\nkeys_to_feature_train = {\"mri\": FixedLenFeature(shape=IMAGE_SHAPE, dtype=\"float32\")}\r\n\r\ndef prepare_train(record_fn):\r\n    return TFRecordDataset(record_fn).map(lambda t: parse_single_example(t, keys_to_feature_train)['mri'],\r\n                                          num_parallel_calls=AUTOTUNE, deterministic=False).cache().\\\r\n                                            shuffle(BUF_SIZE).repeat().batch(BATCH_SIZE).prefetch(AUTOTUNE)\r\n\r\ndataset_trainA = prepare_train(DATA_DIR+\"/trainA.tfrecord\")\r\ndataset_trainB = prepare_train(DATA_DIR+\"/trainB.tfrecord\")\r\n\r\niterA = dataset_trainA.__iter__()\r\niterB = dataset_trainB.__iter__()\r\n```", "> I can't understand how the GPU can run hundreds times the function without memory issues and suddenly gets OOM.\r\n\r\nThis is not surprising by itself.  Since the graph executor is multi-threaded, the order in which the various operations try to allocate memory will vary from run to run, which can create different amounts of fragmentation.  And this can result in OOMs non-deterministically.\r\n\r\nYou can [set the number of inter op threads](https://www.tensorflow.org/api_docs/python/tf/config/threading/set_inter_op_parallelism_threads) to 1 to see if that helps.  It will reduce performance but increase determinism.\r\n\r\n> I would like to have better understanding, for example why GPU tries to allocate tensors on non-first call ? Have you any suggestions about how it can be solved ?\r\n\r\nGPU operations allocate memory as they execute (so a `tf.add(x, y)` will allocate memory for its output every time it executes, and that memory will be freed after the last use of the tensor it returned).", "@sanjoy Thank you for the explanations. I used to think the graph tracing step was aimed to allocate all the memory needed for computations. But apparently it's not the case.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47061\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47061\">No</a>\n"]}, {"number": 47060, "title": "Partially infer conv return types", "body": "Fixes #47057.\r\n\r\naf9ad9d introduces conv inferReturnTypes, but skips the inference when either input or filter does not have static shape (unranked or not all dimensions are static). However, it introduces the regression when it comes to partially dynamic input. This PR instead tries to infer as many dimensions as possible, which avoids shape information loss when there are only some dynamic dimensions (like batch dim).", "comments": ["@smit-hinsu Do you want to take a look since you approved #44022 ?"]}, {"number": 47059, "title": "Steps to build dynamic libraries of tflite for raspberry pi and aarch 64(armv8) boards", "body": "I have downloaded tensorflow source github and try to create tensorflow lite library from tools/ make makefiles.\r\nI have not found steps to build and generate dynamic tfLite library for these hardware devices. Could You provide me the steps to build dynamic .so for tfLite library\r\n", "comments": ["@pranathibl,\r\nPlease take a look at these links to build TensorFlow Lite for [Raspberry Pi](https://www.tensorflow.org/lite/guide/build_rpi) and [ARM64 boards](https://www.tensorflow.org/lite/guide/build_arm64) and let us know if it helps. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47059\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47059\">No</a>\n"]}, {"number": 47057, "title": "Conv2D output shape becomes fully dynamic when only input batch size is dynamic in tf-nightly", "body": "### 1. System information\r\n\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Colab\r\n- TensorFlow installation (pip package or built from source): pip\r\n- TensorFlow library (version, if pip package or github SHA, if built from source): 2.4.1 v.s. nightly\r\n\r\n### 2. Code\r\n\r\nnightly: https://colab.research.google.com/drive/1r-vzh6JCIc5A4K8aYEbMZANWVrtSkKrF?usp=sharing\r\n2.4.1: https://colab.research.google.com/drive/1ODMv9joqc2ybsSdNHhGq1RWKXYsnFjd-?usp=sharing\r\n\r\n### 3. Failure after conversion\r\n\r\nModels are correct, but nightly has fully dynamic output shape and 2.4.1 has dynamic batch dim only.\r\n\r\nNightly\r\n![image](https://user-images.githubusercontent.com/11615393/107465904-10ca1b80-6b18-11eb-9a96-9c7ba9254bcf.png)\r\n\r\n2.4.1\r\n![image](https://user-images.githubusercontent.com/11615393/107465944-1f183780-6b18-11eb-92ed-7befb0614e6b.png)\r\n\r\n1 here means dynamic dim (netron cannot show it precisely). It does not really matter in my use case though. Just a regression issue.", "comments": ["@smit-hinsu FYI this is related to 47060", "Hi @WindQAQ \r\n\r\nDid you experience any real issues? or did you just observed this change in the TFLite model?\r\n\r\nThe `shape` attributes in TFLite models are optional for most tensors, expect inputs & constants. \r\nThe TFLite runtime actually does shape propagation and recompute shape for the rest of the tensors. \r\nSo practically this shouldn't cause any problem. \r\n\r\nYour pull request still makes sense for improving the compiler/converter code quality. I'm just wondering if there's real issues triggerd by this behavior. ", "Thanks for the reply. There is actually no issue triggered by `shape`, just an observation.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47057\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/47057\">No</a>\n"]}]