[{"number": 44405, "title": "Fix typos in compiler directory", "body": "Splitting #43857 by top-level directories.", "comments": ["Nice, Thanks! \r\nLGTM, assuming it passes the tests.", "@Molkree can you please resolve conflicts", "@rthadur, resolved", "Can you please rebase your PR? It seems some files have changed by now. Also, possibly exclude the changes to tf2tensorrt directory, because those seem to trigger additional checks which our workflow to pull in PRs cannot handle (we would have to do it manually).", "@akuegel, rebase or merge? I don't see any conflicts in GitHub interface but sure, if you request it.\r\nAnd fine, I'll remove that directory now.", "@mihaimaruseac, I see that this was merged, should I close PR?", "@Molkree Thank you for the confirmation.\r\nSeems auto-merge is not happening but the changes are merged into master now, so we can close this PR."]}, {"number": 44404, "title": "Keras Sequential Model Not taking IN the data due to Matrix size-incompatible", "body": "I am using the beginner template code from TensorFlow. \r\n\r\nhttps://www.tensorflow.org/tutorials/quickstart/beginner\r\n\r\nThe code is \r\n\r\n```\r\n\r\n\r\n#x_train, y_train, x_test, y_test -- All defined before with images size 28 28 \r\nmodel = tf.keras.models.Sequential([\r\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\r\n  tf.keras.layers.Dense(128, activation='relu'),\r\n  tf.keras.layers.Dropout(0.2),\r\n  tf.keras.layers.Dense(10)\r\n])\r\npredictions = model(x_train[:1]).numpy()\r\npredictions\r\n```\r\n\r\nWhen I run the following code I expect this \r\narray([[-0.2858531 , -0.37892324,  0.25575462, -0.16782898,  0.17269424,\r\n        -0.4606699 , -0.15211505,  0.11725096,  0.58891714, -0.2277292 ]],\r\n      dtype=float32)\r\n\r\n\r\nThe error I get is\r\nInvalidArgumentError: Matrix size-incompatible: In[0]: [28,56], In[1]: [784,1] [Op:MatMul]\r\n\r\n\r\nThe partial code to create the images is --\r\n```\r\n\r\nx = img.crop([matrix[0][0]-2, matrix[0][1], matrix[2][0]+2, matrix[2][1]+2])\r\nimg = x.resize((28, 28))\r\ndisplay(img.convert('LA'))\r\nlstOfArrays.append(numpy.array(img.convert('LA')))                        \r\n\r\n```\r\n\r\n---------------------------------------------------------------------------\r\n\r\nWARNING:tensorflow:Model was constructed with shape Tensor(\"flatten_3_input:0\", shape=(None, 28, 28), dtype=float32) for input (None, 28, 28), but it was re-called on a Tensor with incompatible shape (28, 28, 2).\r\nWARNING:tensorflow:Layer flatten_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\r\n\r\nIf you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\r\n\r\nTo change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\r\n\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n<ipython-input-180-6c835adf6b59> in <module>\r\n----> 1 predictions = model(x_train[:1]).numpy()\r\n      2 predictions\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    820           with base_layer_utils.autocast_context_manager(\r\n    821               self._compute_dtype):\r\n--> 822             outputs = self.call(cast_inputs, *args, **kwargs)\r\n    823           self._handle_activity_regularization(inputs, outputs)\r\n    824           self._set_mask_metadata(inputs, outputs, input_masks)\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py in call(self, inputs, training, mask)\r\n    265       if not self.built:\r\n    266         self._init_graph_network(self.inputs, self.outputs, name=self.name)\r\n--> 267       return super(Sequential, self).call(inputs, training=training, mask=mask)\r\n    268 \r\n    269     outputs = inputs  # handle the corner case where self.layers is empty\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py in call(self, inputs, training, mask)\r\n    715     return self._run_internal_graph(\r\n    716         inputs, training=training, mask=mask,\r\n--> 717         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\r\n    718 \r\n    719   def compute_output_shape(self, input_shape):\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py in _run_internal_graph(self, inputs, training, mask, convert_kwargs_to_constants)\r\n    889 \r\n    890           # Compute outputs.\r\n--> 891           output_tensors = layer(computed_tensors, **kwargs)\r\n    892 \r\n    893           # Update tensor_dict.\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py in __call__(self, inputs, *args, **kwargs)\r\n    820           with base_layer_utils.autocast_context_manager(\r\n    821               self._compute_dtype):\r\n--> 822             outputs = self.call(cast_inputs, *args, **kwargs)\r\n    823           self._handle_activity_regularization(inputs, outputs)\r\n    824           self._set_mask_metadata(inputs, outputs, input_masks)\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\layers\\core.py in call(self, inputs)\r\n   1140         outputs = sparse_ops.sparse_tensor_dense_matmul(inputs, self.kernel)\r\n   1141       else:\r\n-> 1142         outputs = gen_math_ops.mat_mul(inputs, self.kernel)\r\n   1143     if self.use_bias:\r\n   1144       outputs = nn.bias_add(outputs, self.bias)\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py in mat_mul(a, b, transpose_a, transpose_b, name)\r\n   5614         pass  # Add nodes to the TensorFlow graph.\r\n   5615     except _core._NotOkStatusException as e:\r\n-> 5616       _ops.raise_from_not_ok_status(e, name)\r\n   5617   # Add nodes to the TensorFlow graph.\r\n   5618   if transpose_a is None:\r\n\r\n~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py in raise_from_not_ok_status(e, name)\r\n   6604   message = e.message + (\" name: \" + name if name is not None else \"\")\r\n   6605   # pylint: disable=protected-access\r\n-> 6606   six.raise_from(core._status_to_exception(e.code, message), None)\r\n   6607   # pylint: enable=protected-access\r\n   6608 \r\n\r\n~\\Anaconda3\\lib\\site-packages\\six.py in raise_from(value, from_value)\r\n\r\nInvalidArgumentError: Matrix size-incompatible: In[0]: [28,56], In[1]: [784,1] [Op:MatMul]", "comments": ["@Kunal2341,\r\nCould you please provide the TensorFlow version and the Python script or notebook you are running, so that we can reproduce the issue on our end.\r\n\r\nI was able to run the linked tutorial without any issues, please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/b85040476f1c7ce097d1d5f204d1fb10/44404.ipynb). Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 44403, "title": "tensorflow.python.framework.errors_impl.InvalidArgumentError: 'func' argument to TF_GraphCopyFunction cannot be null", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): macOS 10.14.6\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): v2.3.0-54-gfcc4b966f1 2.3.1 \r\n- Python version: 3.7.6\r\n\r\n**Describe the expected behavior**\r\nThis is probably a duplicate of https://github.com/tensorflow/tensorflow/issues/42239 (which I cannot reopen), but I was able to isolate it as standalone tf.test.TestCase.\r\n\r\nThe following test itself is successful, but after it completes, an error is logged. (If you run it in an IDE, the output is not attributes to the test case, but visible in the full log)\r\n\r\nWhile examining the original problem in our full model, I added some logging and I think a function named \"__inference__destroyer_15572\" was involved - I guess this is _destroyer() created in _list_functions_for_serialization() of CapturableResource which is a superclass of StaticHashTable.\r\n\r\nI couldn't catch it with a python breakpoint, probably because it happens when objects are released. Given that memory management is probably involved, I suspect the python version is important (which would explain why the example in the other issue was not reproducible)\r\n\r\nIt also still happens with tf-nightly v1.12.1-44401-g11bbaed857 2.4.0-dev20201023.\r\n\r\nIt doesn't appear with v2.1.0-rc2-17-ge5bf8de410 2.1.0\r\n\r\n**Standalone code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\nimport os\r\nimport shutil\r\n\r\n\r\nclass MyLookup(tf.keras.layers.Layer):\r\n    def __init__(self, **kwargs):\r\n        super().__init__(**kwargs)\r\n        self.table_init = tf.lookup.KeyValueTensorInitializer(\r\n            key_dtype=tf.int64,\r\n            keys=[0, 1, 2],\r\n            value_dtype=tf.string,\r\n            values=[\"A\", \"B\", \"C\"],\r\n            name=\"table_init\")\r\n        self.index_to_kw = tf.lookup.StaticHashTable(self.table_init, \"?\")\r\n\r\n    def call(self, inputs, **kwargs):\r\n        return self.index_to_kw.lookup(inputs)\r\n\r\n\r\nclass TestSaveProblem(tf.test.TestCase):\r\n\r\n    def determine_and_clear_test_workdir(self):\r\n        testname = self.id()\r\n        result = os.path.abspath(os.path.join(\r\n            os.path.dirname(__file__), \"tmp_test_workdir\", testname))\r\n        shutil.rmtree(result, ignore_errors=True)\r\n        return result\r\n\r\n    def testSaveProblem(self):\r\n        export_dir = self.determine_and_clear_test_workdir() + \"/saved_model\"\r\n\r\n        exampledata = [1, 2]\r\n\r\n        input = tf.keras.layers.Input(shape=1, dtype=tf.int64)\r\n        output = MyLookup(name='result')(input)\r\n        model = tf.keras.Model(inputs=[input], outputs=[output])\r\n\r\n        # save and load\r\n        model.save(export_dir, save_format='tf', include_optimizer=False)\r\n        loaded_model = tf.saved_model.load(export_dir, [tf.saved_model.SERVING]).signatures[\r\n            'serving_default']\r\n\r\n        # test after saving and loading (works!)\r\n        loaded_result = loaded_model(tf.constant(exampledata, dtype=tf.int64))['result']\r\n        self.assertAllEqual([b\"B\", b\"C\"], loaded_result)\r\n\r\nif __name__ == '__main__':\r\n    tf.test.main()\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n```\r\n(tf2.3.1) till@mac-brychcyt [/Users/till/test] 21:08% python test_saveproblem.py \r\nRunning tests under Python 3.7.6: /Users/till/tf2.3.1/bin/python\r\n[ RUN      ] TestSaveProblem.testSaveProblem\r\n2020-10-28 21:08:59.759328: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-10-28 21:08:59.770427: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fe5afe7a390 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-10-28 21:08:59.770444: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n2020-10-28 21:08:59.868931: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\r\nINFO:tensorflow:Assets written to: /Users/till/test/tmp_test_workdir/__main__.TestSaveProblem.testSaveProblem/saved_model/assets\r\nI1028 21:09:00.045232 4522530240 builder_impl.py:775] Assets written to: /Users/till/test/tmp_test_workdir/__main__.TestSaveProblem.testSaveProblem/saved_model/assets\r\nINFO:tensorflow:time(__main__.TestSaveProblem.testSaveProblem): 0.37s\r\nI1028 21:09:00.122746 4522530240 test_util.py:1973] time(__main__.TestSaveProblem.testSaveProblem): 0.37s\r\n[       OK ] TestSaveProblem.testSaveProblem\r\n[ RUN      ] TestSaveProblem.test_session\r\n[  SKIPPED ] TestSaveProblem.test_session\r\n----------------------------------------------------------------------\r\nRan 2 tests in 0.371s\r\n\r\nOK (skipped=1)\r\nException ignored in: <function CapturableResourceDeleter.__del__ at 0x12f193170>\r\nTraceback (most recent call last):\r\n  File \"/Users/till/tf2.3.1/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py\", line 202, in __del__\r\n    self._destroy_resource()\r\n  File \"/Users/till/tf2.3.1/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 780, in __call__\r\n    result = self._call(*args, **kwds)\r\n  File \"/Users/till/tf2.3.1/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 823, in _call\r\n    self._initialize(args, kwds, add_initializers_to=initializers)\r\n  File \"/Users/till/tf2.3.1/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 697, in _initialize\r\n    *args, **kwds))\r\n  File \"/Users/till/tf2.3.1/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 2855, in _get_concrete_function_internal_garbage_collected\r\n    graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n  File \"/Users/till/tf2.3.1/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 3213, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n  File \"/Users/till/tf2.3.1/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 3075, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n  File \"/Users/till/tf2.3.1/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\", line 986, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n  File \"/Users/till/tf2.3.1/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\", line 600, in wrapped_fn\r\n    return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n  File \"/Users/till/tf2.3.1/lib/python3.7/site-packages/tensorflow/python/saved_model/function_deserialization.py\", line 237, in restored_function_body\r\n    return _call_concrete_function(function, inputs)\r\n  File \"/Users/till/tf2.3.1/lib/python3.7/site-packages/tensorflow/python/saved_model/function_deserialization.py\", line 74, in _call_concrete_function\r\n    result = function._call_flat(tensor_inputs, function._captured_inputs)  # pylint: disable=protected-access\r\n  File \"/Users/till/tf2.3.1/lib/python3.7/site-packages/tensorflow/python/saved_model/load.py\", line 106, in _call_flat\r\n    cancellation_manager)\r\n  File \"/Users/till/tf2.3.1/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 1938, in _call_flat\r\n    flat_outputs = forward_function.call(ctx, args_with_tangents)\r\n  File \"/Users/till/tf2.3.1/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 579, in call\r\n    executor_type=executor_type)\r\n  File \"/Users/till/tf2.3.1/lib/python3.7/site-packages/tensorflow/python/ops/functional_ops.py\", line 1192, in partitioned_call\r\n    f.add_to_graph(graph)\r\n  File \"/Users/till/tf2.3.1/lib/python3.7/site-packages/tensorflow/python/eager/function.py\", line 495, in add_to_graph\r\n    g._add_function(self)\r\n  File \"/Users/till/tf2.3.1/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\", line 3345, in _add_function\r\n    gradient)\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: 'func' argument to TF_GraphCopyFunction cannot be null\r\n```\r\n", "comments": ["@brychcy \r\nI ran the code shared and face different error, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/45c4805dae0c9d43164758039eae5e1c/untitled455.ipynb).", "Your error is because colab passes some options to python that confuse the test runner.\r\nIn following notebook the example is written to a file and executed in a nested python:\r\nhttps://colab.research.google.com/drive/1xGMVF8T4BerrJIbmfy5KFE8c4H0Qszuy?usp=sharing", "I've made another version where you can see the problem in the colab without nested python (I've removed the test infrastructure, so it doesn't show anymore that the loadel model works).\r\n\r\nhttps://colab.research.google.com/drive/118FCkHW82jSUgre-V1ulbJQEXIs64qLG?usp=sharing\r\n\r\nSimply repeatedly loading the model causes old instances to be released and the error appears:\r\n\r\n```\r\nimport tensorflow as tf\r\nimport os\r\n\r\nclass MyLookup(tf.keras.layers.Layer):\r\n    def __init__(self, **kwargs):\r\n        super().__init__(dtype=tf.int64, input_shape=(1,), **kwargs)\r\n        self.table_init = tf.lookup.KeyValueTensorInitializer(\r\n            key_dtype=tf.int64,\r\n            keys=[0, 1, 2],\r\n            value_dtype=tf.string,\r\n            values=[\"A\", \"B\", \"C\"],\r\n            name=\"table_init\")\r\n        self.index_to_kw = tf.lookup.StaticHashTable(self.table_init, \"?\")\r\n\r\n    def call(self, inputs, **kwargs):\r\n        return self.index_to_kw.lookup(inputs)\r\n\r\n\r\nexport_dir = \"tmp_test_workdir/saved_model\"\r\n\r\nexampledata = [1, 2]\r\n\r\nmodel = tf.keras.Sequential()\r\nmodel.add(MyLookup(name='result'))\r\n\r\n# save and load\r\nmodel.save(export_dir, save_format='tf', include_optimizer=False)\r\n\r\nfor i in range(1,5):\r\n    tf.saved_model.load(export_dir, [tf.saved_model.SERVING])\r\n\r\npass\r\n```\r\n\r\n\r\nIf you run this in a debugger, you can set a breakpoint at \"pass\" and the message is already in the log.\r\n\r\n", "I am able to replicate the issue please find the [gist here](https://colab.research.google.com/gist/Saduf2019/94f06e74c429ac8b4117b5ef76239e34/untitled477.ipynb).", "I am getting the same bug, is there any known workarounds to this issue?", "> I am getting the same bug, is there any known workarounds to this issue?\r\n\r\nAt least in the case described in the bug report, the error message is annoying, but harmless,\r\nbecause mentioned function _destroyer() is a No-Op as destroy_resource_fn of CapturableResourceDeleter is None for  StaticHashTable - actually almost always: looking through the tensorflow non-test sources, destroy_resource_fn seems to be always None except in code related to TensorRT.\r\n\r\nSo if you don't use that, you can simply ignore the error.", "I am also getting the same bug, with save/load keras model during test. Hope there can be workaround to silence the warning. ", "I'm having a similar issue. [This code](https://github.com/tensorflow/tensorflow/issues/44403#issuecomment-718570017) indeed produces the error message. \r\n\r\nPython 3.8.5; tensorflow-cpu==2.4.1\r\n\r\n==\r\n\r\nTo silence the message, you can use something like this:\r\n\r\n```\r\nimport sys\r\n\r\ndef unraisablehook(unraisable):\r\n    # https://docs.python.org/3/library/sys.html#sys.unraisablehook\r\n    from tensorflow.python.framework.errors_impl import InvalidArgumentError\r\n    if unraisable.exc_type is not InvalidArgumentError:\r\n        urh(unraisable)\r\n\r\n# https://stackoverflow.com/questions/38036540/what-type-of-message-exception-ignored-in-is\r\nurh = sys.unraisablehook\r\nsys.unraisablehook = unraisablehook\r\n```", "Thanks for posting the workaround.\r\nIt should just be noted that sys.unraisablehook is only available since python 3.8, but the tensorflow docker images still use python 3.6.9.\r\n", "I am seeing this error in a TFX Evaluator component (version 0.27.0). It seems harmless, but it feels a bit iffy.", "Thanks for reporting.  I believe we fixed this a few weeks ago.  I tested [this](https://colab.research.google.com/gist/Saduf2019/94f06e74c429ac8b4117b5ef76239e34/untitled477.ipynb) repro again and cannot reproduce on the latest nightly.  I believe the fixes should have made it into 2.5 too.  Please let me know if you're still experiencing it with the latest nightly.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44403\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44403\">No</a>\n", "Yes, seems to be fixed in 2.5.0. Thanks!\r\n"]}, {"number": 44402, "title": "[Cherrypick r2.4] Fixed the markdown formatting of client.monitor and client.trace API documentation", "body": null, "comments": []}, {"number": 44401, "title": "[CherryPick r2.4] [tf.data] Preserving accurate cardinality information for `group_by_window` transformation.", "body": "PiperOrigin-RevId: 338679574\nChange-Id: Ibba771ef1050f5fbf08daf6dee251e4463f03e09", "comments": []}, {"number": 44400, "title": "Pycharm 3.9 not supporting Tensorflow", "body": "ERROR: Could not find a version that satisfies the requirement tensorflow (from versions: none)\r\nHi!, i'm someone thats completley new to coding, now i was instructed to download tensorflow thru pycharm (i prefer to have things stored physically on my device rather than online) as i tried all of the guides i realized that for most platforms i was getting the exact same answer, i was searching breifly and saw that there wasnt another thread about this topic, so thank you to anyone that interacts with this!\r\n![image](https://user-images.githubusercontent.com/73615107/97494015-c7bcd580-1933-11eb-86b9-6fd88744b189.png)\r\n", "comments": ["@sbarbosa0714 \r\n\r\nTensorFlow pip packages are compatible with Python 3.5\u20133.8.\r\n\r\nFrom the below link we can see that the whl files are available upto Python v3.8.\r\nhttps://pypi.org/project/tf-nightly/2.4.0.dev20201023/#files\r\n\r\nPython3.9 is not yet supported. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Duplicate of #44485 (assuming you meant/use Python 3.9)\r\n\r\nNote that pycharm still downloads stuff locally."]}, {"number": 44399, "title": "Cherrypicks tmznn - profiler markdown documentation", "body": "", "comments": []}, {"number": 44398, "title": "[CherryPick r2.4]Disable test for macos.", "body": "PiperOrigin-RevId: 339518747\nChange-Id: Icc30e85709c361c27e650f1fefef640f4a81fae9", "comments": []}, {"number": 44397, "title": "Fix typos in cc directory", "body": "Splitting #43857 by top-level directories.", "comments": []}, {"number": 44396, "title": "DLL Error", "body": "Traceback (most recent call last):\r\n  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"train_audio.py\", line 4, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\n\r\nPlease can someone help me with this!", "comments": ["From the template it looks like you are installing **TensorFlow** (TF) prebuilt binaries:\n   * For TF-GPU - See point 1\n   * For TF-CPU - See point 2\n-----------------------------------------------------------------------------------------------\n**1. Installing **TensorFlow-GPU** (TF) prebuilt binaries**\n\nMake sure you are using compatible TF and CUDA versions. Please refer following TF version and CUDA version compatibility table.\n| TF  | CUDA |\n| :-------------: | :-------------: |\n| 2.1.0 - 2.2.0  | 10.1 |\n| 1.13.1 - 2.0  | 10.0  |\n| 1.5.0 - 1.12.0 | 9.0 |\n\n  * If you have above configuration and using _**Windows**_ platform -\n    * Try adding the CUDA, CUPTI, and cuDNN installation directories to the %PATH% environment variable.\n    * Refer [windows setup guide](https://www.tensorflow.org/install/gpu#windows_setup).\n  * If you have above configuration and using _**Ubuntu/Linux**_ platform -\n    * Try adding the CUDA, CUPTI, and cuDNN installation directories to the $LD_LIBRARY_PATH environment variable.\n    * Refer [linux setup guide](https://www.tensorflow.org/install/gpu#linux_setup).\n  * If error still persists then, apparently your CPU model does not support AVX instruction sets.\n    * Refer [hardware requirements](https://www.tensorflow.org/install/pip#hardware-requirements).\n\n-----------------------------------------------------------------------------------------------\n**2. Installing **TensorFlow** (TF) CPU prebuilt binaries**\n\n*TensorFlow release binaries version 1.6 and higher are prebuilt with AVX instruction sets.*\n\nTherefore on any CPU that does not have these instruction sets, either CPU or GPU version of TF will fail to load.\nApparently, your CPU model does not support AVX instruction sets. You can still use TensorFlow with the alternatives given below:\n\n   * Try Google Colab to use TensorFlow.\n      * The easiest way to use TF will be to switch to [google colab](https://colab.sandbox.google.com/notebooks/welcome.ipynb#recent=true). You get pre-installed latest stable TF version. Also you can use ```pip install```  to install any other preferred TF version.\n      * It has an added advantage since you can you easily switch to different hardware accelerators (cpu, gpu, tpu) as per the task.\n      * All you need is a good internet connection and you are all set.\n   * Try to build TF from sources by changing CPU optimization flags.\n\n*Please let us know if this helps.*\n", "@jayhar2043,\r\nYou might be facing this issue because of the following reasons\r\n\r\n- You are running 32-bit Python or 32-bit OS\r\n- You have not installed the [Microsoft Visual C++ Redistributable](https://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads) package\r\n- Your CPU does not support AVX instructions. \r\n\r\nPlease take a look at the [system requirements](https://www.tensorflow.org/install/pip#system-requirements) and check if you have the correct dependencies installed.\r\n\r\nAlso, check similar issue #36167 for more information. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44396\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44396\">No</a>\n"]}, {"number": 44395, "title": "Fix typos in c directory", "body": "Splitting #43857 by top-level directories per @mihaimaruseac comments.", "comments": ["As far as I can tell, failing macOS check has nothing to do with changes here as it was failing for the last few days on other PRs as well."]}, {"number": 44393, "title": "tflite_convert produce 1kb tensorflow lite file", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- TensorFlow installed from (source or binary): source if i remember correctly\r\n- TensorFlow version (or github SHA if from source): 2.3.1\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nSo, i'm trying to use [SSD ResNet101 V1 FPN 640x640 (RetinaNet101) found here][1] model for my android application. \r\nI download the model on desktop and then i use this command\r\n\r\n`    python object_detection/export_tflite_graph_tf2.py --pipeline_config_path C:\\Users\\Davide\\Desktop\\ssd_resnet101_v1_fpn_640x640_coco17_tpu-8\\pipeline.config --trained_checkpoint_dir C:\\Users\\Davide\\Desktop\\ssd_resnet101_v1_fpn_640x640_coco17_tpu-8\\checkpoint --output_directory C:\\Users\\Davide\\Desktop\\fine_tuned`\r\n\r\nAfter a bit on desktop a new folder \"fine_tuned\" appear, after that i use the second command:\r\n\r\n    `tflite_convert --saved_model_dir=C:\\Users\\Davide\\Desktop\\fine_tuned\\saved_model --output_file=C:\\Users\\Davide\\Desktop\\mobilenet.tflite`\r\n\r\nAnd the file appear on the desktop, the problem is that it's 1kb. When i try to use it inside my application i get this error:\r\n\r\n        `java.lang.RuntimeException: Unable to start activity ComponentInfo{com.example.sd_detect/com.example.sd_detect.MainActivity}: java.lang.IllegalStateException: This model does not contain associated files, and is not a Zip file.`\r\n\r\n  [1]: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\r\n\r\noutput from tflite_convert\r\n\r\n   ```\r\n 2020-10-26 15:11:42.511698: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cudart64_101.dll'; dlerror: cudart64_101.dll not found\r\n    2020-10-26 15:11:42.511837: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n    2020-10-26 15:12:01.023376: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'nvcuda.dll'; dlerror: nvcuda.dll not found\r\n    2020-10-26 15:12:01.023482: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\r\n    2020-10-26 15:12:01.030610: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: DESKTOP-II0SFO3\r\n    2020-10-26 15:12:01.030829: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: DESKTOP-II0SFO3\r\n    2020-10-26 15:12:01.042164: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x17c13580870 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n    2020-10-26 15:12:01.042253: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\n    I1026 15:14:04.769973  1808 lite.py:624] Using experimental converter: If you encountered a problem please file a bug. You can opt-out by setting experimental_new_converter=False\r\n    2020-10-26 15:14:13.437234: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:313] Ignored output_format.\r\n    2020-10-26 15:14:13.437349: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:316] Ignored drop_control_dependency.\r\n    2020-10-26 15:14:13.439460: I tensorflow/cc/saved_model/reader.cc:31] Reading SavedModel from: C:\\Users\\Davide\\Desktop\\fine_tuned\\saved_model\r\n    2020-10-26 15:14:13.642525: I tensorflow/cc/saved_model/reader.cc:54] Reading meta graph with tags { serve }\r\n    2020-10-26 15:14:13.642639: I tensorflow/cc/saved_model/loader.cc:250] Reading SavedModel debug info (if present) from: C:\\Users\\Davide\\Desktop\\fine_tuned\\saved_model\r\n    2020-10-26 15:14:14.428409: I tensorflow/cc/saved_model/loader.cc:215] Restoring SavedModel bundle.\r\n    2020-10-26 15:14:16.534036: I tensorflow/cc/saved_model/loader.cc:199] Running initialization op on SavedModel bundle at path: C:\\Users\\Davide\\Desktop\\fine_tuned\\saved_model\r\n    2020-10-26 15:14:17.186241: I tensorflow/cc/saved_model/loader.cc:319] SavedModel load for tags { serve }; Status: success: OK. Took 3746762 microseconds.\r\n```\r\n\r\n", "comments": ["@fanto88 \r\n\r\nI have tried in TF nightly version and i am not seeing any issue. Please, find the gist here.Please, verify once and close the [issue](https://colab.research.google.com/gist/ravikyram/6a82614b71b7fe759099d3daee477d78/untitled94.ipynb?authuser=1).Thanks!", "Thanks for the comment. Now the model converted is 71mb, so it should be fine. But when i try to use it instead of the model used in the Android Example for object detection an exception occurs:\r\n\r\n```\r\nE/AndroidRuntime: FATAL EXCEPTION: main\r\n    Process: com.example.sd_detect, PID: 23556\r\n    java.lang.RuntimeException: Unable to start activity ComponentInfo{com.example.sd_detect/com.example.sd_detect.MainActivity}: java.lang.IllegalStateException: This model does not contain associated files, and is not a Zip file.\r\n        at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:3374)\r\n        at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:3513)\r\n        at android.app.servertransaction.LaunchActivityItem.execute(LaunchActivityItem.java:83)\r\n        at android.app.servertransaction.TransactionExecutor.executeCallbacks(TransactionExecutor.java:135)\r\n        at android.app.servertransaction.TransactionExecutor.execute(TransactionExecutor.java:95)\r\n        at android.app.ActivityThread$H.handleMessage(ActivityThread.java:2109)\r\n        at android.os.Handler.dispatchMessage(Handler.java:107)\r\n        at android.os.Looper.loop(Looper.java:214)\r\n        at android.app.ActivityThread.main(ActivityThread.java:7682)\r\n        at java.lang.reflect.Method.invoke(Native Method)\r\n        at com.android.internal.os.RuntimeInit$MethodAndArgsCaller.run(RuntimeInit.java:516)\r\n        at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:950)\r\n```", "@fanto88 \r\n\r\nSince the original issue was resolved. Can you please close this issue and create a new one by filling issue template.Thanks!", "Yeah, i will do it for sure. Thanks!", "@fanto88 could you please share your solution? i am having same issue using tflite_convert, i have tensorflow 2.3.0, object detection ssd_mobilenet_v1", "and it produces only 1kb file of tflite", "Like @ravikyram suggested, using the nighly version of TF fixed the problem automatically."]}, {"number": 44392, "title": "One more attempt to fix wheel rename issues", "body": "", "comments": []}, {"number": 44391, "title": "TensorFlow 2.2 and 2.3 not detecting the Titan XP GPU", "body": "\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04 LTS\r\n- TensorFlow installed from (source or binary): Binary in Virtual environment as per https://www.tensorflow.org/install/pip and https://www.tensorflow.org/install/gpu\r\n- TensorFlow version: 2.2 and 2.3 in two virtual environments\r\n- Python version:  Tried both 3.6 and 3.8 in virtual environments\r\n- Installed using virtualenv? pip? conda?: PIP\r\n\r\n- CUDA: \r\n`nvcc: NVIDIA (R) Cuda compiler driver\r\nCopyright (c) 2005-2019 NVIDIA Corporation\r\nBuilt on Sun_Jul_28_19:07:16_PDT_2019\r\nCuda compilation tools, release 10.1, V10.1.243 `\r\n\r\n-cuDNN version: \r\n`#define CUDNN_MAJOR 7\r\n#define CUDNN_MINOR 6\r\n#define CUDNN_PATCHLEVEL 5\r\n--\r\n#define CUDNN_VERSION (CUDNN_MAJOR * 1000 + CUDNN_MINOR * 100 + CUDNN_PATCHLEVEL)\r\n`\r\n- GPU model and memory: Titan XP (Details from nvidia-smi, shared below)\r\n`Wed Oct 28 13:05:46 2020       \r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|                               |                      |               MIG M. |\r\n|===============================+======================+======================|\r\n|   0  TITAN Xp            Off  | 00000000:01:00.0  On |                  N/A |\r\n| 23%   31C    P5    17W / 250W |    371MiB / 12192MiB |      0%      Default |\r\n|                               |                      |                  N/A `\r\n\r\n\r\n**Describe the problem**\r\n**TensorFlow 2.2 and 2.3 not detecting the Titan XP GPU**\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\nCreated virtual environments using : `python3.8 -m venv --system-site-packages ./TF_2` (same step for python 3.6)\r\nSourced: source TF_2/bin/activate\r\nCode and outputs from terminal with python: \r\n`>>> **import tensorflow as tf**\r\n2020-10-28 12:56:39.039879: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n>>> **tf.config.list_physical_devices('GPU')**\r\n2020-10-28 12:56:45.248971: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\r\n2020-10-28 12:56:45.282612: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-10-28 12:56:45.283010: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: TITAN Xp computeCapability: 6.1\r\ncoreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\r\n2020-10-28 12:56:45.283029: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-10-28 12:56:45.283144: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.1/lib64\r\n2020-10-28 12:56:45.284267: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-10-28 12:56:45.284454: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-10-28 12:56:45.285753: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-10-28 12:56:45.286488: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-10-28 12:56:45.289239: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-10-28 12:56:45.289253: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\n**Skipping registering GPU devices...\r\n[]**\r\n`\r\n\r\n\r\n**Any other info / logs**\r\nNote the path was set in the ~/.bashrc \r\n`export PATH=/usr/local/cuda-10.1/bin${PATH:+:${PATH}}\r\nexport LD_LIBRARY_PATH=/usr/local/cuda-10.1/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\r\nexport PATH=~/Downloads/protobuf${PATH:+:${PATH}}`\r\n", "comments": ["@RRK13,\r\nPlease make sure you have executed all the commands as per the [installation guide](https://www.tensorflow.org/install/gpu#ubuntu_1804_cuda_101). \r\n\r\nAlso, please take a look at this [StackOverflow comment](https://stackoverflow.com/a/64174245) from a similar issue and let us know if it helps. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 44390, "title": "Tensorflow release files missing from PyPi, fallback to local hashing ", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution: Linux Ubuntu 16.04\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: 2.2\r\n- Python version: 3.7\r\n- Installed using virtualenv? pip? conda?: pip 20.2.4\r\n\r\n\r\n**Describe the problem**\r\nWhen using pip-compile to get recreate a requirements file with a hash pointer to tensorflow, the hash must be generated each time. It would be create it the required files/settings were included \r\n\r\n\r\n```md\r\ntensorflow-gpu\r\n  Missing release files on PyPI\r\n  Couldn't get hashes from PyPI, fallback to hashing files\r\n  Hashing tensorflow_gpu-2.2.0-cp38-win_amd64.whl\r\ntensorflow-gpu\r\n    Missing release files on PyPI\r\n    Couldn't get hashes from PyPI, fallback to hashing files\r\n    Hashing tensorflow_gpu-2.2.0-cp38-cp38-win_amd64.whl\r\n    Hashing tensorflow_gpu-2.2.0-cp37-cp37m-win_amd64.whl\r\n    Hashing tensorflow_gpu-2.2.0-cp38-cp38-manylinux2010_x86_64.whl\r\n    Hashing tensorflow_gpu-2.2.0-cp35-cp35m-manylinux2010_x86_64.whl\r\n    Hashing tensorflow_gpu-2.2.0-cp36-cp36m-manylinux2010_x86_64.whl\r\n    Hashing tensorflow_gpu-2.2.0-cp35-cp35m-win_amd64.whl\r\n    Hashing tensorflow_gpu-2.2.0-cp36-cp36m-win_amd64.whl\r\n    Hashing tensorflow_gpu-2.2.0-cp37-cp37m-manylinux2010_x86_64.whl\r\n```\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n```shell-script\r\necho \"tensorflow==2.2\" > tensorflow.in\r\npip install pip-tools\r\npip-compile -v --allow-unsafe --generate-hashes tensorflow.in\r\n```\r\n\r\n**Any other info / logs**\r\nNice to have... not sure how simple it is? But every other package I am working with has this setup properly, so i only notice Tensorflow taking its time.", "comments": ["@dciborow \r\n\r\nPlease paste the error message (using makrdown formatting around it) instead of screenshotting. Screenshots are not searchable so they don't help in looking for the issue and also don't help other people having the same error from finding about the issue.", "@saberkun , done!\r\n", "This is likely related to how we're doing the combined pip package. Can you try with 2.3, nightly and (soon) 2.4rc0?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44390\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44390\">No</a>\n"]}, {"number": 44389, "title": "fatal error: fatbinary_section.h: No such file or directory", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.3\r\n- Python version: 3.6, 3.7\r\n- Installed using virtualenv? pip? conda?:\r\n- Bazel version (if compiling from source): 3.1.0\r\n- GCC/Compiler version (if compiling from source): 7.5\r\n- CUDA/cuDNN version: 11.1 , 8\r\n- GPU model and memory: RTX 2080 Ti\r\n\r\n**Describe the problem**\r\n\r\nI am installing TF from the source following steps https://www.tensorflow.org/install/source.\r\nand\r\nhttps://towardsdatascience.com/how-to-compile-tensorflow-2-3-with-cuda-11-1-8cbecffcb8d3\r\nThe build ended up with the error in the following.\r\n\r\nINFO: Analyzed target //tensorflow/tools/pip_package:build_pip_package (0 packages loaded, 0 targets configured).\r\nINFO: Found 1 target...\r\nERROR: /root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/external/nccl_archive/BUILD.bazel:53:1: C++ compilation of rule '@nccl_archive//:device_dlink' failed (Exit 1)\r\nbazel-out/k8-opt/bin/external/nccl_archive/device_dlink.cc:69:10: fatal error: fatbinary_section.h: No such file or directory\r\n #include <fatbinary_section.h>\r\n          ^~~~~~~~~~~~~~~~~~~~~\r\ncompilation terminated.\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nERROR: /root/tensorflow/tensorflow/lite/toco/python/BUILD:84:1 C++ compilation of rule '@nccl_archive//:device_dlink' failed (Exit 1)\r\nINFO: Elapsed time: 120.484s, Critical Path: 45.36s\r\nINFO: 989 processes: 989 local.\r\n\r\nPlease let me know how to fix it as google returns zero search results for it.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\n bazel build --config=cuda //tensorflow/tools/pip_package:build_pip_package\r\n\r\nbefore this I had the following error and fixed it as shown:\r\nError:\r\nERROR: /root/tensorflow/tensorflow/stream_executor/cuda/BUILD:144:1: C++ compilation of rule '//tensorflow/stream_executor/cuda:cudart_stub' failed (Exit 1)\r\ntensorflow/stream_executor/cuda/cudart_stub.cc:19:10: fatal error: third_party/gpus/cuda/include/cuda_runtime_api.h: No such file or directory\r\n #include \"third_party/gpus/cuda/include/cuda_runtime_api.h\"\r\n \r\ncompilation terminated.\r\n \r\nSolution:\r\nsudo apt-get install nvidia-cuda-toolkit\r\n \r\nexport CPATH=/usr/local/cuda-11.1/targets/x86_64-linux/include:$CPATH\r\nexport LD_LIBRARY_PATH=/usr/local/cuda-11.1/targets/x86_64-linux/lib:$LD_LIBRARY_PATH\r\nexport PATH=/usr/local/cuda-11.1/bin:$PATH\r\n\r\n\r\nI also fixed other errors: \r\nEdit\r\nthird_party/gpus/cuda_configure.bzl\r\n \r\n \"cudart\": _check_cuda_lib_params(\r\n            \"cudart\",\r\n            cpu_value,\r\n            cuda_config.config[\"cuda_library_dir\"],\r\n            # Comment this out since cudart is still on 11.0 instead of\r\n            # the same as cuda 11.1\r\n            # cuda_config.cuda_version,\r\n            \"11.0\",\r\n            static = False,\r\n        ),\r\n        \"cudart_static\": _check_cuda_lib_params(\r\n            \"cudart_static\",\r\n            cpu_value,\r\n            cuda_config.config[\"cuda_library_dir\"],\r\n            # Comment this out since cudart is still on 11.0 instead of\r\n            # the same as cuda 11.1\r\n            # cuda_config.cuda_version,\r\n            \"11.0\",\r\n            static = True,\r\n        ),\r\n        \"cublas\": _check_cuda_lib_params(\r\n            \"cublas\",\r\n            cpu_value,\r\n            cuda_config.config[\"cublas_library_dir\"],\r\n            # Comment this out since cudart is still on 11.0 instead of\r\n            # the same as cuda 11.1\r\n            # cuda_config.cuda_version,\r\n            \"11\",\r\n            static = False,\r\n        ),\r\n\r\n", "comments": ["@ElhamSol \r\n\r\nPlease, see tested build configurations from [here](https://www.tensorflow.org/install/source#gpu).please check if you are facing the same issue with CUDA 10.1 and cuDNN 7.4.\r\n\r\nAlso, please take a look at #42047 for more information regarding TensorFlow support for CUDA 11. Thanks!", "@ravikyram Thanks for reply. But, I wasn't able to install tensorflow 2.0.0+ with Cuda 10.1 and that's why I switched to 11.1.\r\n(I'd like to use 2.3.0, so please don't ask me to go back to 2.0.0 as a solution)\r\nI even tried going back to Cuda 10.1, but nvidia doesn't allow it anymore. \r\n`sudo apt-get -y install cuda-10.1` doesn't work anymore and it forces me to install 11.1.\r\n\r\n#42047 doesn't help the issue I posted.\r\nI've been reading on github and stackoverflow for the past week and I was able to solve other errors with them. \r\nFor this one I found zero results in github and google search.\r\n\r\nI appreciate it if you could spend some time going through the issue and let me know the solution.\r\nThis is for my work and I've been stuck with it for a week.\r\n\r\n\r\n\r\n", "TF 2.4.0-rc0  pre built pip package released today and it supports cuda 11.0.\r\nhttps://github.com/tensorflow/tensorflow/releases/tag/v2.4.0-rc0\r\nYou may have to fall back on cuda 11.0 to use the pre built pip package.\r\nAlso do you still prefer to build TF from source for cuda 11.1?", "> @ravikyram Thanks for reply. But, I wasn't able to install tensorflow 2.0.0+ with Cuda 10.1 and that's why I switched to 11.1.\r\n> (I'd like to use 2.3.0, so please don't ask me to go back to 2.0.0 as a solution)\r\n> I even tried going back to Cuda 10.1, but nvidia doesn't allow it anymore.\r\n> `sudo apt-get -y install cuda-10.1` doesn't work anymore and it forces me to install 11.1.\r\n> \r\n> #42047 doesn't help the issue I posted.\r\n> I've been reading on github and stackoverflow for the past week and I was able to solve other errors with them.\r\n> For this one I found zero results in github and google search.\r\n> \r\n> I appreciate it if you could spend some time going through the issue and let me know the solution.\r\n> This is for my work and I've been stuck with it for a week.\r\n\r\nI managed to install CUDA 10.1, but now get the following error building TF 2.3.1\r\nERROR: /root/tensorflow/tensorflow/python/tools/BUILD:314:1 C++ compilation of rule '//tensorflow/core/profiler/internal/gpu:cupti_wrapper' failed (Exit 1)\r\n\r\n", "> TF 2.4.0-rc0 pre built pip package released today and it supports cuda 11.0.\r\n> https://github.com/tensorflow/tensorflow/releases/tag/v2.4.0-rc0\r\n> You may have to fall back on cuda 11.0 to use the pre built pip package.\r\n> Also do you still prefer to build TF from source for cuda 11.1?\r\n\r\nI tried to use the pre built pip package version 2.3.1 and it ends up being CPU only.\r\nI am not switching back to 11.0.", "> I managed to install CUDA 10.1, but now get the following error building TF 2.3.1\r\n> ERROR: /root/tensorflow/tensorflow/python/tools/BUILD:314:1 C++ compilation of rule '//tensorflow/core/profiler/internal/gpu:cupti_wrapper' failed (Exit 1)\r\n\r\nDid you add CUPTI to the `$LD_LIBRARY_PATH` environmental variable?\r\nSee [linux gpu setup](https://www.tensorflow.org/install/gpu#linux_setup).\r\n", "I did but for some reason it wasn't finding it anyway.\r\n\r\nI reinstalled ubuntu, cuda 10.1 and everything and this time pip install tensorflow =2.3.0 worked.\r\nI might have missed a step last time.\r\n\r\n", "@ElhamSol \r\n\r\nPlease, close this thread if your issue was resolved. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44389\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44389\">No</a>\n"]}, {"number": 44388, "title": "targets: Rename litex_vexriscv_makefile", "body": "With a93e36e78ea82af7a770c082a9ad4f93fc0dd7e8 merged\r\nto master, target-specific makefiles must have strict\r\nnames that match TARGET.\r\n\r\nSigned-off-by: Mateusz Holenko <mholenko@antmicro.com>", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n"]}, {"number": 44387, "title": "Tensorflow keras `save_weights` and `load_weights` produce random evaluation result on some dataset", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Window 10 and Mac OS 10.15.7\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): `pip install tensorflow`\r\n- TensorFlow version (use command below): 2.3.1\r\n- Python version: Window 10 (3.7.4), Mac OS (3.8.5)\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: Has CUDA only on Window 10 (CUDA 10.1, cuDNN 7.6.5) \r\n- GPU model and memory: MSI GeForce GTX1080 8GB\r\n\r\n\r\n**Describe the current behavior**\r\nWhen `save_weights` and `load_weights` on keras model, seem to work fine in the same python session with training.\r\nBut after stop that python session and try calling `load_weights` on a new python session, some dataset produce a random evaluation result.\r\n\r\n**Describe the expected behavior**\r\nEvaluation result after `load_weights` should be the same across python session\r\n\r\n**Standalone code to reproduce the issue**\r\n[This ](https://github.com/sainttail/tensorflow-load-weights-problem)is the full standalone reproducible problem when `load_weights` each time get you a random evaluation loss and accuracy\r\n\r\n", "comments": ["Was able to reproduce the issue with TF v2.3 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/e6a008f2b0bb5ae45560a89a3f840802/44387.ipynb). Thanks!", "@sainttail This is duplicate of https://github.com/tensorflow/tensorflow/issues/43954\r\n\r\nThis is not an issue with `load_weights` but the user code. I checked weights, labels, and features. There is no change in weight and labels after loading the model but there is a change in features. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/36fbef60353b521b76b01afdf242a199/44387.ipynb). Thanks!\r\n\r\nI am showing the difference in features before saving and after loading the weights. Please note that I restarted runtime as you mentioned.\r\n\r\n```\r\nAfter training model, loss: 0.9711138010025024, accuracy: 0.5186440944671631\r\ntest_features\r\n[[-0.49808972  0.41190585 -0.27875089 ... -0.9401052   0.57645319\r\n  -1.15568602]\r\n [-0.49808972  0.41190585 -0.27875089 ...  0.04428938  0.57645319\r\n  -0.1313082 ]\r\n [ 0.70921448 -2.42566817 -0.27875089 ...  0.04428938  0.57645319\r\n  -0.1313082 ]\r\n ...\r\n [ 0.70921448  0.41190585 -0.27875089 ...  0.04428938  0.57645319\r\n  -0.1313082 ]\r\n [ 0.70921448  0.41190585  3.58440841 ...  0.04428938  0.57645319\r\n  -2.18006385]\r\n [-1.70539393  0.41190585  3.58440841 ... -1.92449978  0.57645319\r\n  -2.18006385]]\r\n\r\n\r\nRestored model, loss: 1.0805716514587402, accuracy: 0.4203389883041382\r\ntest features\r\n[[ 0.41190585  0.57645319 -0.49808972 ... -1.15568602 -0.27875089\r\n  -0.9401052 ]\r\n [ 0.41190585  0.57645319 -0.49808972 ... -0.1313082  -0.27875089\r\n   0.04428938]\r\n [-2.42566817  0.57645319  0.70921448 ... -0.1313082  -0.27875089\r\n   0.04428938]\r\n ...\r\n [ 0.41190585  0.57645319  0.70921448 ... -0.1313082  -0.27875089\r\n   0.04428938]\r\n [ 0.41190585  0.57645319  0.70921448 ... -2.18006385  3.58440841\r\n   0.04428938]\r\n [ 0.41190585  0.57645319 -1.70539393 ... -2.18006385  3.58440841\r\n  -1.92449978]]\r\n```\r\n\r\nAs there is a change in features that were input to the model, evaluation metrics are changed.\r\n\r\nI am closing this issue as this is not a bug or performance related to TensorFlow. Please feel free to reopen if I am mistaken. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44387\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44387\">No</a>\n", "@jvishnuvardhan Thanks, for helping me. I've never once thought that the same code produce different feature values. ", "@jvishnuvardhan Hello, I've some trouble with LSTM layer model saving and loading. After loading the whole model from other python file weights of the LSTM layer is being different from the saving session. \r\n\r\nI've asked for it in one of the **keras-team/keras** issue topics. But could not find any workaround yet. I've just seen the https://github.com/keras-team/keras/issues/14240#issue-718065369 topic then decide to ask under this topic as well.\r\n\r\nHere is my issue which I described: https://github.com/keras-team/keras/issues/4875#issuecomment-719030257\r\nYou can see the weight differences between different python files right after training and after loading: https://github.com/keras-team/keras/issues/4875#issuecomment-719905493\r\n\r\nJust for a recap, my setup is:\r\n> Python 3.8.6\r\n> Keras 2.4.3\r\n> TensorFlow 2.3.1\r\n> Windows10 and using PowerShell\r\n\r\n\r\n### UPDATE: \r\nInformation for upcoming newbies like me\r\nI should have applied normalization to my test-set in my second python file that's why I was getting wrong results.\r\n", "@namcho Can you please create a new issue with a simple standalone code to reproduce the issue? It will help the community and helps us to track the issue better. Thanks!"]}, {"number": 44386, "title": "tf.where raises TypeError for a RaggedTensor argument 'condition'", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): `pip install tensorflow`\r\n- TensorFlow version (use command below): v2.3.0-54-gfcc4b966f1 2.3.1\r\n- Python version: 3.8.2 64-bit ('venv')\r\n\r\n**Describe the current behavior**\r\nCalling tf.where raises TypeError for a RaggedTensor argument 'condition' `TypeError: Expected bool passed to parameter 'condition' of op 'SelectV2', got tf.RaggedTensor`.\r\n\r\n**Describe the expected behavior**\r\ntf.where should support RaggedTensor\r\n\r\n**Other info / logs** \r\nSource code snippet:\r\n\r\n`input_action_mask = tf.where(tf.math.equal(action_mask, 0), NO_ZERO_INPUT_VALUE, action_mask, name=\"input_action_mask\")`\r\n\r\n`action_mask` is a RaggedTensor, `NO_ZERO_INPUT_VALUE` is a float (I think broadcasting should not be a problem here)\r\n\r\n```\r\n2020-10-28 15:26:31,076 ERROR worker.py:1018 -- Possible unhandled error from worker: ray::RolloutWorker.__init__() (pid=3809, ip=172.28.211.149)\r\n  File \"/home/user/venv/lib/python3.8/site-packages/tensorflow/python/framework/tensor_util.py\", line 268, in inner\r\n    _check_failed(v)\r\n  File \"/home/user/venv/lib/python3.8/site-packages/tensorflow/python/framework/tensor_util.py\", line 249, in _check_failed\r\n    raise ValueError(v)\r\nValueError: tf.RaggedTensor(values=Tensor(\"tu_policy/Equal_1:0\", shape=(?, 1, 133), dtype=bool), row_splits=Tensor(\"tu_policy/Placeholder_12:0\", shape=(?,), dtype=int64))\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nray::RolloutWorker.__init__() (pid=3809, ip=172.28.211.149)\r\n  File \"/home/user/venv/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\", line 465, in _apply_op_helper\r\n    values = ops.convert_to_tensor(\r\n  File \"/home/user/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 1499, in convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/home/user/venv/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\", line 338, in _constant_tensor_conversion_function\r\n    return constant(v, dtype=dtype, name=name)\r\n  File \"/home/user/venv/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\", line 263, in constant\r\n    return _constant_impl(value, dtype, shape, name, verify_shape=False,\r\n  File \"/home/user/venv/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\", line 280, in _constant_impl\r\n    tensor_util.make_tensor_proto(\r\n  File \"/home/user/venv/lib/python3.8/site-packages/tensorflow/python/framework/tensor_util.py\", line 456, in make_tensor_proto\r\n    _AssertCompatible(values, dtype)\r\n  File \"/home/user/venv/lib/python3.8/site-packages/tensorflow/python/framework/tensor_util.py\", line 335, in _AssertCompatible\r\n    raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\r\nTypeError: Expected bool, got tf.RaggedTensor(values=Tensor(\"tu_policy/Equal_1:0\", shape=(?, 1, 133), dtype=bool), row_splits=Tensor(\"tu_policy/Placeholder_12:0\", shape=(?,), dtype=int64)) of type 'RaggedTensor' instead.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nray::RolloutWorker.__init__() (pid=3809, ip=172.28.211.149)\r\n  File \"python/ray/_raylet.pyx\", line 479, in ray._raylet.execute_task\r\n  File \"python/ray/_raylet.pyx\", line 483, in ray._raylet.execute_task\r\n  File \"python/ray/_raylet.pyx\", line 484, in ray._raylet.execute_task\r\n  File \"python/ray/_raylet.pyx\", line 438, in ray._raylet.execute_task.function_executor\r\n  File \"/home/user/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 416, in __init__\r\n    self._build_policy_map(policy_dict, policy_config)\r\n  File \"/home/user/venv/lib/python3.8/site-packages/ray/rllib/evaluation/rollout_worker.py\", line 1008, in _build_policy_map\r\n    policy_map[name] = cls(obs_space, act_space, merged_conf)\r\n  File \"/home/user/venv/lib/python3.8/site-packages/ray/rllib/policy/tf_policy_template.py\", line 206, in __init__\r\n    DynamicTFPolicy.__init__(\r\n  File \"/home/user/venv/lib/python3.8/site-packages/ray/rllib/policy/dynamic_tf_policy.py\", line 198, in __init__\r\n    self.model = ModelCatalog.get_model_v2(\r\n  File \"/home/user/venv/lib/python3.8/site-packages/ray/rllib/models/catalog.py\", line 339, in get_model_v2\r\n    raise e\r\n  File \"/home/user/venv/lib/python3.8/site-packages/ray/rllib/models/catalog.py\", line 324, in get_model_v2\r\n    instance = model_cls(obs_space, action_space,\r\n  File \"/mnt/c/Users/user/Desktop/KI_Galvanik/MARL_for_Galvanic_per_second_2_TUs/articleSchedulingModel.py\", line 41, in __init__\r\n    input_action_mask = tf.where(tf.math.equal(action_mask, 0), NO_ZERO_INPUT_VALUE, action_mask, name=\"input_action_mask\")\r\n  File \"/home/user/venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\", line 201, in wrapper\r\n    return target(*args, **kwargs)\r\n  File \"/home/user/venv/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\", line 4461, in where_v2\r\n    return gen_math_ops.select_v2(condition=condition, t=x, e=y, name=name)\r\n  File \"/home/user/venv/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 8874, in select_v2\r\n    _, _, _op, _outputs = _op_def_library._apply_op_helper(\r\n  File \"/home/user/venv/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\", line 475, in _apply_op_helper\r\n    raise TypeError(\r\nTypeError: Expected bool passed to parameter 'condition' of op 'SelectV2', got tf.RaggedTensor(values=Tensor(\"tu_policy/Equal_1:0\", shape=(?, 1, 133), dtype=bool), row_splits=Tensor(\"tu_policy/Placeholder_12:0\", shape=(?,), dtype=int64)) of type 'RaggedTensor' instead. Error: Expected bool, got tf.RaggedTensor(values=Tensor(\"tu_policy/Equal_1:0\", shape=(?, 1, 133), dtype=bool), row_splits=Tensor(\"tu_policy/Placeholder_12:0\", shape=(?,), dtype=int64)) of type 'RaggedTensor' instead.\r\n```", "comments": ["@klausk55 \r\nPlease share simple stand alone code to replicate the issue or if possible share a colab gist with the error reported.", "In the following stand alone code I get a different error.\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\nprint(tf.version.VERSION, tf.version.GIT_VERSION)\r\n\r\nNO_ZERO_INPUT_VALUE = 1e-6\r\n\r\naction_mask = tf.keras.layers.Input(shape=(None, 1, 133), name=\"action_mask\", ragged=True)\r\n\r\ninput_action_mask = tf.where(tf.math.equal(action_mask, 0), NO_ZERO_INPUT_VALUE, action_mask, name=\"input_action_mask\")\r\n```\r\n\r\n```\r\n2020-10-28 16:41:33.727533: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\r\n2020-10-28 16:41:33.727579: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\r\n2.3.1 v2.3.0-54-gfcc4b966f1\r\n2020-10-28 16:46:39.442645: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\r\n2020-10-28 16:46:39.442705: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\r\n2020-10-28 16:46:39.442727: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ODU-GALV1): /proc/driver/nvidia/version does not exist\r\n2020-10-28 16:46:39.443208: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-10-28 16:46:39.450030: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2207995000 Hz\r\n2020-10-28 16:46:39.450744: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4abb7f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-10-28 16:46:39.450822: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\nTraceback (most recent call last):\r\n  File \"/usr/lib/python3.8/runpy.py\", line 193, in _run_module_as_main\r\n    return _run_code(code, main_globals, None,\r\n  File \"/usr/lib/python3.8/runpy.py\", line 86, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/home/user/.vscode-server/extensions/ms-python.python-2020.9.114305/pythonFiles/lib/python/debugpy/__main__.py\", line 45, in <module>\r\n    cli.main()\r\n  File \"/home/user/.vscode-server/extensions/ms-python.python-2020.9.114305/pythonFiles/lib/python/debugpy/../debugpy/server/cli.py\", line 430, in main\r\n    run()\r\n  File \"/home/user/.vscode-server/extensions/ms-python.python-2020.9.114305/pythonFiles/lib/python/debugpy/../debugpy/server/cli.py\", line 267, in run_file\r\n    runpy.run_path(options.target, run_name=compat.force_str(\"__main__\"))\r\n  File \"/usr/lib/python3.8/runpy.py\", line 263, in run_path\r\n    return _run_module_code(code, init_globals, run_name,\r\n  File \"/usr/lib/python3.8/runpy.py\", line 96, in _run_module_code\r\n    _run_code(code, mod_globals, init_globals,\r\n  File \"/usr/lib/python3.8/runpy.py\", line 86, in _run_code\r\n    exec(code, run_globals)\r\n  File \"/mnt/c/Users/user/Desktop/KI_Galvanik/MARL_for_Galvanic_per_second_2_TUs/test.py\", line 10, in <module>\r\n    input_action_mask = tf.where(tf.math.equal(action_mask, 0), NO_ZERO_INPUT_VALUE, action_mask, name=\"input_action_mask\")\r\n  File \"/home/user/venv/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\", line 201, in wrapper\r\n    return target(*args, **kwargs)\r\n  File \"/home/user/venv/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\", line 4461, in where_v2\r\n    return gen_math_ops.select_v2(condition=condition, t=x, e=y, name=name)\r\n  File \"/home/user/venv/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 8869, in select_v2\r\n    return select_v2_eager_fallback(\r\n  File \"/home/user/venv/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 8889, in select_v2_eager_fallback\r\n    _attr_T, _inputs_T = _execute.args_to_matching_eager([t, e], ctx)\r\n  File \"/home/user/venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\", line 262, in args_to_matching_eager\r\n    ops.convert_to_tensor(\r\n  File \"/home/user/venv/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 1499, in convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n  File \"/home/user/venv/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\", line 338, in _constant_tensor_conversion_function\r\n    return constant(v, dtype=dtype, name=name)\r\n  File \"/home/user/venv/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\", line 263, in constant\r\n    return _constant_impl(value, dtype, shape, name, verify_shape=False,\r\n  File \"/home/user/venv/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\", line 275, in _constant_impl\r\n    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n  File \"/home/user/venv/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\", line 300, in _constant_eager_impl\r\n    t = convert_to_eager_tensor(value, ctx, dtype)\r\n  File \"/home/user/venv/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\", line 98, in convert_to_eager_tensor\r\n    return ops.EagerTensor(value, ctx.device_name, dtype)\r\nValueError: TypeError: object of type 'RaggedTensor' has no len()\r\n```\r\n\r\nOh my goodness what a fucking day! Sorry.", "@klausk55\r\nI ran the code shared and it has been fixed in tf-nightly, do not face any error, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/d709353d6640ca2a25fa9f946e00d266/untitled455.ipynb). Thanks!", "Any ideas regarding the first reported error?\r\n\r\n`TypeError: Expected bool passed to parameter 'condition' of op 'SelectV2', got tf.RaggedTensor(values=Tensor(\"tu_policy/Equal_1:0\", shape=(?, 1, 133), dtype=bool), row_splits=Tensor(\"tu_policy/Placeholder_12:0\", shape=(?,), dtype=int64)) of type 'RaggedTensor' instead. Error: Expected bool, got tf.RaggedTensor(values=Tensor(\"tu_policy/Equal_1:0\", shape=(?, 1, 133), dtype=bool), row_splits=Tensor(\"tu_policy/Placeholder_12:0\", shape=(?,), dtype=int64)) of type 'RaggedTensor' instead.`\r\n\r\n\r\nBy the way, are currently RaggedTensors supported by any further `tf.keras.layers` types or yet only by `tf.keras.layers.Input`?", "@klausk55 \r\nCan you please try on nightly and see if you are facing the error.", "No longer facing the error on nightly!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44386\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44386\">No</a>\n"]}, {"number": 44385, "title": "InvalidArgumentError on List of Dicts inside TensorFlow Dataset", "body": "# Problem Statement\r\n\r\nI have to read from Google Cloud Storage, several JSON Lines files `.jsonl`. In order to do this, I have created a dataset from the records I want to read, which is a `numpy array` containing `[[<gs:// url>, id], ...]` where `id` is row number to check which line is train/test/validation.\r\n\r\n# Code\r\n\r\nThe main function, which creates the `TF Dataset` from a `generator` which yields the previously described `np.ndarray` and then runs a map function to download and parse the file is:\r\n\r\n```python\r\ndef load_dataset(records: np.ndarray) -> tf.data.Dataset:\r\n    \"\"\"Create Tensorflow Dataset MapDataset (generator) from a list of gs:// data URL.\r\n\r\n    Args:\r\n        records (np.ndarray): List of strings, which are gs://<foo>/foo<N>/*.jsonl.gz files\r\n\r\n    Returns:\r\n        tf.data.Dataset: MapDataset generator which can be used for training Keras models.\r\n    \"\"\"\r\n    dataset = tf.data.Dataset.from_generator(lambda: _generator(records), (tf.string, tf.int8))\r\n    return dataset\r\n\r\n\r\ndef _generator(records):\r\n    for r in records:\r\n        yield r[0], r[1]\r\n```\r\n\r\nAs you can see, the `generator` is simply iterating through the `np.ndarray` to get `url` and a `'line index'`\r\n\r\nThen I have to `load and preprocess` the file from the URL to get a list of the `json -> Dict` objects.\r\n\r\n```python\r\ndef _load_and_preprocess(filepath, selected_sample):\r\n    \"\"\"Read a file GCS or local path and process it into a tensor\r\n\r\n    Args:\r\n        path (tensor): path string, pointer to GCS or local path\r\n\r\n    Returns:\r\n        tensor: processed input\r\n    \"\"\"\r\n    sample_raw_input = tf.io.read_file(filepath)\r\n    uncompressed_inputs = tf.py_function(_get_uncompressed_inputs, [sample_raw_input], tf.string)\r\n    sample = tf.py_function(_load_sampled_sample, [uncompressed_inputs, selected_sample], tf.float32) #This `tf.float32` is definitely wrong\r\n    return sample #This is not a tensor, but a List of Dictionaries which I will process later\r\n\r\n\r\ndef _get_uncompressed_inputs(record):\r\n    return zlib.decompress(record.numpy(), 16 + zlib.MAX_WBITS)\r\n\r\n\r\ndef _load_sampled_sample(inputs: Iterable, selected_sample: List[int]) -> List[Dict[str, str]]:\r\n    if not tf.executing_eagerly():\r\n        raise RuntimeError(\"TensorFlow must be executing eagerly.\")\r\n    inputs = inputs.numpy()\r\n    selected_sample = selected_sample.numpy()\r\n    sample = _load__sampled_sample_from_jsonl(inputs, selected_sample)\r\n    return sample\r\n\r\n\r\ndef _load__sampled_sample_from_jsonl(jsonl: bytes, selected_sample: List[int]) -> List[Dict[str, str]]:\r\n    json_lines = _read_jsonl(jsonl).split(\"\\n\")\r\n    sample = list()\r\n    for n, sample_json in enumerate(json_lines):\r\n        sample_obj = _read_json(sample_json) if n in selected_sample else None\r\n        if sample_obj:\r\n            sample.append(sample_obj)\r\n    return sample\r\n\r\n\r\ndef _read_jsonl(jsonl: bytes) -> str:\r\n    return jsonl.decode()\r\n\r\n```\r\n\r\n# Executing\r\n\r\nI then create the dataset with the above code, and try to retrieve a single sample from it to test.\r\n\r\n```python\r\nval_ds = load_dataset(validation_records)\r\nsamples = tf.data.experimental.get_single_element(\r\n    val_ds\r\n) # This should be a list of Dicts\r\n```\r\n\r\nWhich `raises`:\r\n\r\n```\r\nInvalidArgumentError: ValueError: Attempt to convert a value ({...}) with an unsupported type (<class 'dict'>) to a Tensor.\r\n# ... are the dict values, which is really big so I've shortened it to `...`\r\nTraceback (most recent call last):\r\n\r\n  File \"/home/victor/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 242, in __call__\r\n    return func(device, token, args)\r\n\r\n  File \"/home/victor/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 140, in __call__\r\n    outputs = [\r\n\r\n  File \"/home/victor/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 141, in <listcomp>\r\n    _maybe_copy_to_context_device(self._convert(x, dtype=dtype),\r\n\r\n  File \"/home/victor/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/script_ops.py\", line 120, in _convert\r\n    return ops.convert_to_tensor(value, dtype=dtype)\r\n\r\n  File \"/home/victor/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\", line 1499, in convert_to_tensor\r\n    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n\r\n  File \"/home/victor/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\", line 338, in _constant_tensor_conversion_function\r\n    return constant(v, dtype=dtype, name=name)\r\n\r\n  File \"/home/victor/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\", line 263, in constant\r\n    return _constant_impl(value, dtype, shape, name, verify_shape=False,\r\n\r\n  File \"/home/victor/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\", line 275, in _constant_impl\r\n    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\r\n\r\n  File \"/home/victor/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\", line 300, in _constant_eager_impl\r\n    t = convert_to_eager_tensor(value, ctx, dtype)\r\n\r\n  File \"/home/victor/anaconda3/lib/python3.8/site-packages/tensorflow/python/framework/constant_op.py\", line 98, in convert_to_eager_tensor\r\n    return ops.EagerTensor(value, ctx.device_name, dtype)\r\n\r\nValueError: Attempt to convert a value ({...}) with an unsupported type (<class 'dict'>) to a Tensor.\r\n# ... are the dict values, which is really big so I've shortened it to `...`\r\n\r\n\r\n\t [[{{node EagerPyFunc_1}}]] [Op:DatasetToSingleElement]\r\n```\r\n\r\n# Conclusion\r\n\r\nIs there any way I can work with List of Dicts without Eager execution (which is not allowed from TF Dataset)?\r\n\r\nThis list of dicts is not the input for my model, however, I simply cannot work with it in the `preprocessing` function because this error is raised before passing the values to any other function.\r\n\r\n\r\n# Additional Informations:\r\n\r\n* Python Version: `3.8`\r\n* Tensorflow Version: `2.3.1`", "comments": ["Ok, I think I have fixed it with running eagerly a `dataset.map` function:\r\n\r\n`dataset.map(lambda file, samples: tf.py_function(_load_and_preprocess, [file, samples], tf.variant))`\r\n\r\nWhich is described here: https://stackoverflow.com/questions/51659374/how-can-you-map-values-in-a-tf-data-dataset-using-a-dictionary"]}, {"number": 44384, "title": "[TF-numpy] More efficient if condition", "body": "If `axis` is None, We don't need assign `axisa`, `axisb`, `axisc`.", "comments": []}, {"number": 44383, "title": "[TF-numpy] `np.size` always returns `int`", "body": "`np.size` of original numpy always returns `int`. But, Sometimes `np.size` of tensorflow returns 'float'\r\n\r\n**before**\r\n```python\r\nnp.size(np.array(5))\r\n# output -> 1.0\r\n```\r\n\r\n**after**\r\n```python\r\nnp.size(np.array(5))\r\n# output -> 1\r\n```", "comments": []}, {"number": 44382, "title": "[TF-numpy] `imag` and `real` returns scalar when `val` is a scalar.", "body": "`np.imag` and `np.real` returns scalar when `val` is a scalar.\r\n\r\n```python\r\n# Example\r\nimport tensorflow as tf\r\nnp = tf.experimental.numpy\r\n\r\nnp.real(5)\r\n# output -> 5\r\n```", "comments": ["@marload can you please check ubuntu sanity build failures ?", "@marload  Any update on this PR? Please. Thanks!", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "The failures seem unrelated. A rebase to HEAD should solve the problems. @marload ", "@marload  Can you please check @wangpengmit's comments and keep us posted ? Thanks!", "@marload Any update on this PR? Please. Thanks!", "I'm going to go ahead and close this PR, because it seems to have stalled. If you're still interested in pursing this (and responding to my comments), please feel free to reopen!"]}, {"number": 44381, "title": "TF Nightly fails to find most recent cusolver64", "body": "**System information**\r\n- Windows 10\r\n- TF-Nightly 2.5.0.dev20201027\r\n- Python version: 3.8\r\n- Pip install\r\n- CUDA/cuDNN version: 11\r\n- GPU model and memory: Quadro M2000M\r\n\r\n**Describe the problem**\r\n\r\nTF-Nightly still fails to import all required libraries.  All dll's other than cusolver appear to link to version 11, while cusolver tries to find a version 10 and ignores 11.\r\n\r\n\r\n2020-10-28 12:07:52.945021: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2020-10-28 12:08:06.077965: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-10-28 12:08:06.080459: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library nvcuda.dll\r\n2020-10-28 12:08:06.596743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1724] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: Quadro M2000M computeCapability: 5.0\r\ncoreClock: 1.137GHz coreCount: 5 deviceMemorySize: 4.00GiB deviceMemoryBandwidth: 74.65GiB/s\r\n2020-10-28 12:08:06.600978: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudart64_110.dll\r\n2020-10-28 12:08:06.612213: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublas64_11.dll\r\n2020-10-28 12:08:06.612951: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cublasLt64_11.dll\r\n2020-10-28 12:08:06.620033: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cufft64_10.dll\r\n2020-10-28 12:08:06.623163: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library curand64_10.dll\r\n2020-10-28 12:08:06.625507: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cusolver64_10.dll'; dlerror: cusolver64_10.dll not found\r\n2020-10-28 12:08:06.632009: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cusparse64_11.dll\r\n2020-10-28 12:08:06.634138: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library cudnn64_8.dll\r\n2020-10-28 12:08:06.634754: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1761] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\nSkipping registering GPU devices...\r\n2020-10-28 12:08:24.017842: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-10-28 12:08:24.143577: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1265] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-10-28 12:08:24.144363: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1271]      \r\n2020-10-28 12:08:24.144755: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-10-28 12:08:24.303626: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2", "comments": ["2020-10-28 12:08:06.625507: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'cusolver64_10.dll'; dlerror: cusolver64_10.dll not found.\r\n\r\nI think you need to downgrade your CUDA toolkit version. I faced the same issue, I found a temporary workaround by renaming the \r\n\r\n> cusolver64_11.dll      \r\n\r\nfile to \r\n\r\n> cusolver64_10.dll     \r\n\r\n in C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.1\\bin which seemed to resolve the issue but I think would cause some repercussions later. So the best bet would be to downgrade CUDA version.\r\n", "This quick fix (symlink) works on Linux:\r\n\r\nhttps://github.com/tensorflow/tensorflow/issues/43947#issuecomment-715295153\r\n\r\nPerhaps you could try something similar on Windows", "Well I had thought this at first but it slipped my mind later on. Will give this a try surely. Thanks for pointing out.", "also happens in tf@2.4-rc0", "> This quick fix (symlink) works on Linux:\r\n> \r\n> [#43947 (comment)](https://github.com/tensorflow/tensorflow/issues/43947#issuecomment-715295153)\r\n> \r\n> Perhaps you could try something similar on Windows\r\n\r\nif that still doesn't help, make sure `LD_LIBRARY_PATH` points to CUDA 11.1 installation\r\n```bash\r\nLD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda-11.1/lib64:/usr/local/cuda/extras/CUPTI/lib64\r\nexport LD_LIBRARY_PATH\r\n```\r\nI spent an hour trying to figure out what's happening only to discover later that I don't have `LD_LIBRARY_PATH` set :man_facepalming: ", "I had the same problem. I Found a link to Download The DLL file here\r\n https://transfert.mffp.gouv.qc.ca/?ShareToken=790B76CF0EBA6B094F39CF985247901B63D4AD19. It is valid till 11/12/2020 10:30:00 AM. Make sure to place the file in the Bin folder of the CUDA install ", "On both WIndows and Ubuntu18.04 with CUDA 11.0 or 11.1 and cuDNN 8.0.2 or 8.0.5, this is happening with 2.4.0-rc1, but reverting back to 2.4.0-rc0 fixes it for me.", "On Windows 10, with CUDA 11.2 and TF 2.4.0 creating a symlink works. Open the Command Prompt as Administrator and execute the following commands:\r\n\r\n```batch\r\ncd \"C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v11.2\\bin\"\r\nmklink cusolver64_10.dll cusolver64_11.dll\r\n```", "Copy cusolver64_100.dll to cuda 11.1 and rename it to cusolver64_10.dll.  \r\n![image](https://user-images.githubusercontent.com/41668023/105572797-58b91680-5d94-11eb-9a22-54042cc1cd66.png)\r\n", "@jmfreeland,\r\n\r\nCan you try building the recent nightly version i.e `2.7.0.dev20210912` using this [guide](https://www.tensorflow.org/install/source_windows) and let us know if the issue persists. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44381\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44381\">No</a>\n"]}, {"number": 44380, "title": "GPU kernel for SparseSegmentReduction ops.", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): r.1.5.2\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nHi, I have noticed that the SparseSegmentReduction ops do not have GPU implementation. I was wondering is there any consideration for not implementing GPU version SparseSegmentReduction ops? And will the feature be supported in future version?\r\n\r\n\r\n**Will this change the current api? How?**\r\nIt will not change the current API.\r\n\r\n**Who will benefit with this feature?**\r\nPeople who use GPU to train the sparse networks.\r\n\r\n**Any Other info.**\r\n", "comments": ["@Lifann,\r\nSorry for the delayed response. Can you please share the reproducible code which demonstrates these Ops doesn't work in GPU? Thanks! "]}, {"number": 44379, "title": "tf.data.Dataset.from_tensor_slices requests same shape tensors", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.3.0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\nAs of now, tf.data.Dataset.from_tensor_slices requests the input tensors to be of the same shape, which is not working very well with the new text preprocessing function tf.keras.preprocessing.text.Tokenizer\r\n\r\n**Will this change the current api? How?**\r\nNo\r\n\r\n**Who will benefit with this feature?**\r\nNLP practionners will benefit from this feature.\r\n\r\n**Any Other info.**\r\nCurrently it is not possible to create a tensorflow dataset immidiately after using tf.keras.preprocessing.text.Tokenizer because the sequences of idexes generated are'nt all of the same length. This can be solved by using tf.keras.preprocessing.sequence.pad_sequences but it is not very memory friendly as many sequences will be padded with a great deal of unnecessary zeros.\r\nAdding this feature will make it possible to preprocess text data, encode it, put it in a tensor dataset, split between train and test and then pad using .padded_batch method, which way more memory friendly and will make training the model faster as well.\r\n", "comments": ["To achieve this today, you need to use `Dataset.from_generator`.\r\n\r\n```\r\nlist_of_uneven_length_tensors = [[1], [2, 3, 4], [5, 6]]\r\n\r\ndef gen():\r\n  for tensor in list_of_uneven_length_tensors:\r\n    yield tensor\r\n\r\nds = tf.data.Dataset.from_generator(gen, output_types=tf.int64)\r\nfor elem in ds:\r\n  print(elem)\r\n```\r\n\r\n`from_tensor_slices` is named the way it is because it takes a single (rectangular) `Tensor` and iterates through the slices of the tensor. What we could potentially do is add a new `Dataset.from_tensor_list` method which takes a list of tensors and iterates over them. Would that work for your use case here?", "@Charlestng,\r\n\r\nCan you take a look on the above comment by @aaudiber to use `Dataset.from_generator`, and confirm if that helps? Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 44378, "title": "Tflite ops: TensorListReserve, TensorListSetItem, TensorListStack", "body": "**System information**\r\nLinux Ubuntu 18.04\r\nTensorFlow installed from source\r\nTensorFlow version 2.1.0\r\n\r\n\r\n**Provide the text output from tflite_convert**\r\n\r\n```\r\nSome of the operators in the model are not supported by the standard TensorFlow Lite runtime and are not recognized by TensorFlow. If you have a custom implementation for them you can disable this error with --allow_custom_ops, or by setting allow_custom_ops=True when calling tf.lite.TFLiteConverter(). Here is a list of builtin operators you are using: ADD, CONCATENATION, FULLY_CONNECTED. Here is a list of operators for which you will need custom implementations: TensorListReserve, TensorListSetItem, TensorListStack.\r\n```\r\n\r\n**Standalone code to reproduce the issue** \r\nhttps://colab.research.google.com/drive/1jEUZxqM4Olr3Hbiu9WoCpYiVyGGx1ko8?usp=sharing\r\n\r\n", "comments": ["@Movisoto,\r\nI was able to reproduce the issue with [TF v2.1](https://colab.research.google.com/gist/amahendrakar/7fcc19838f87fbaa9f24c701299e50de/44378-2-1.ipynb). However, with [TF v2.3](https://colab.research.google.com/gist/amahendrakar/55e1c38fb617128131ed380ab052bfa9/44378.ipynb#scrollTo=g32rWA9zCLbp) I am facing a different error stating `requires element_shape to be 1D tensor during TF Lite transformation pass`. Please find the attached gist. \r\n\r\nCould you please update TensorFlow to v2.3 and check if you are facing the same issue? Thanks!", "@amahendrakar,\r\nthanks a lot for your response! \r\nYes, I got a different error stating `requires element_shape to be 1D tensor during TF Lite transformation pass` while I was using tf v2.3, as I understood the reason is that tf lite converter works only with fixed batch size, nevertheless as I understand I have already set all input shapes and batch size. Could you please help?\r\n\r\nThanks a lot in advance!", "@amahendrakar looking forward to hearing from you! As I researched it should be connected with an unfixed batch size of the model, but I have set all the input shapes", "@Movisoto Can you please share a standalone code? When I ran your gist, it is throwing an error as shown below. Thanks!\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nNameError                                 Traceback (most recent call last)\r\n<ipython-input-15-fee02e8da1f7> in <module>()\r\n      1 config = Config()\r\n----> 2 generator = model.generator\r\n      3 discriminator = model.discriminator\r\n      4 regressor = generator.regressor\r\n      5 smpl = generator.smpl\r\n\r\nNameError: name 'model' is not defined\r\n```", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 44377, "title": "Error during extract ", "body": "I installed using Nvidia CPU, my Nvidia is (GeForce GTX 1070) after finish installation no issue, continue to open the file and able to use the software.\r\n\r\nAfter selecting the video and clicking extract i got an error below, and the same as well with S3fd\r\n\r\nSetting Faceswap backend to NVIDIA\r\n10/28/2020 18:35:58 INFO     Log level set to: INFO\r\n10/28/2020 18:36:00 INFO     Output Directory: C:\\Users\\Daniel-PC\\Videos\\Model B\r\n\r\n10/28/2020 18:36:00 INFO     Loading Detect from Mtcnn plugin...\r\n10/28/2020 18:36:00 INFO     Loading Align from Fan plugin...\r\n10/28/2020 18:36:00 INFO     Loading Mask from Components plugin...\r\n10/28/2020 18:36:00 INFO     Loading Mask from Extended plugin...\r\n10/28/2020 18:36:00 INFO     Starting, this may take a while...\r\n10/28/2020 18:36:00 INFO     Initializing MTCNN (Detect)...\r\n10/28/2020 18:36:02 INFO     Initialized MTCNN (Detect) with batchsize of 8\r\n10/28/2020 18:36:02 INFO     Initializing FAN (Align)...\r\n\r\n2020-10-28 18:36:04.204035: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:725] failed to record completion event; therefore, failed to create inter-stream dependency\r\n2020-10-28 18:36:04.204401: E tensorflow/stream_executor/stream.cc:334] Error recording event in stream: Error recording CUDA event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered; not marking stream as bad, as the Event object may be at fault. Monitor for further errors.\r\n2020-10-28 18:36:04.204967: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered\r\n2020-10-28 18:36:04.205426: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:273] Unexpected Event status: 1\r\nProcess exited.\r\n\r\n10/28/2020 18:43:50 INFO     Loading Detect from S3Fd plugin...\r\n10/28/2020 18:43:50 INFO     Loading Align from Fan plugin...\r\n10/28/2020 18:43:50 INFO     Loading Mask from Components plugin...\r\n10/28/2020 18:43:50 INFO     Loading Mask from Extended plugin...\r\n10/28/2020 18:43:50 INFO     Starting, this may take a while...\r\n10/28/2020 18:43:50 INFO     Initializing S3FD (Detect)...\r\n10/28/2020 18:43:51 INFO     Initialized S3FD (Detect) with batchsize of 4\r\n10/28/2020 18:43:51 INFO     Initializing FAN (Align)...\r\n\r\n2020-10-28 18:43:54.494508: E tensorflow/stream_executor/cuda/cuda_driver.cc:910] failed to synchronize the stop event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered\r\n2020-10-28 18:43:54.494821: E tensorflow/stream_executor/gpu/gpu_timer.cc:55] Internal: Error destroying CUDA event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered\r\n2020-10-28 18:43:54.495199: E tensorflow/stream_executor/gpu/gpu_timer.cc:60] Internal: Error destroying CUDA event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered\r\n2020-10-28 18:43:54.495492: E tensorflow/stream_executor/stream.cc:5485] Internal: Failed to enqueue async memset operation: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered\r\n2020-10-28 18:43:54.495879: E tensorflow/stream_executor/cuda/cuda_driver.cc:575] failed to load PTX text as a module: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered\r\n2020-10-28 18:43:54.496149: E tensorflow/stream_executor/cuda/cuda_driver.cc:580] error log buffer (1024 bytes):\r\n2020-10-28 18:43:54.496344: E tensorflow/stream_executor/cuda/cuda_driver.cc:575] failed to load PTX text as a module: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered\r\n2020-10-28 18:43:54.496580: E tensorflow/stream_executor/cuda/cuda_driver.cc:580] error log buffer (1024 bytes):\r\n2020-10-28 18:43:54.521217: F .\\tensorflow/core/kernels/random_op_gpu.h:232] Non-OK-status: GpuLaunchKernel(FillPhiloxRandomKernelLaunch<Distribution>, num_blocks, block_size, 0, d.stream(), gen, data, size, dist) status: Internal: an illegal memory access was encountered\r\n\r\n\r\nI am still new to this and please help, i tried uninstalling and reinstall but still the same issue.", "comments": []}, {"number": 44376, "title": "Error during extract (Help)", "body": "After clicking extract i got an error below, and the same as well with S3fd\r\n\r\nSetting Faceswap backend to NVIDIA\r\n10/28/2020 18:35:58 INFO     Log level set to: INFO\r\n10/28/2020 18:36:00 INFO     Output Directory: C:\\Users\\Daniel-PC\\Videos\\Model B\r\n\r\n10/28/2020 18:36:00 INFO     Loading Detect from Mtcnn plugin...\r\n10/28/2020 18:36:00 INFO     Loading Align from Fan plugin...\r\n10/28/2020 18:36:00 INFO     Loading Mask from Components plugin...\r\n10/28/2020 18:36:00 INFO     Loading Mask from Extended plugin...\r\n10/28/2020 18:36:00 INFO     Starting, this may take a while...\r\n10/28/2020 18:36:00 INFO     Initializing MTCNN (Detect)...\r\n10/28/2020 18:36:02 INFO     Initialized MTCNN (Detect) with batchsize of 8\r\n10/28/2020 18:36:02 INFO     Initializing FAN (Align)...\r\n\r\n2020-10-28 18:36:04.204035: E tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:725] failed to record completion event; therefore, failed to create inter-stream dependency\r\n2020-10-28 18:36:04.204401: E tensorflow/stream_executor/stream.cc:334] Error recording event in stream: Error recording CUDA event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered; not marking stream as bad, as the Event object may be at fault. Monitor for further errors.\r\n2020-10-28 18:36:04.204967: E tensorflow/stream_executor/cuda/cuda_event.cc:29] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered\r\n2020-10-28 18:36:04.205426: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:273] Unexpected Event status: 1\r\nProcess exited.\r\n\r\n10/28/2020 18:43:50 INFO     Loading Detect from S3Fd plugin...\r\n10/28/2020 18:43:50 INFO     Loading Align from Fan plugin...\r\n10/28/2020 18:43:50 INFO     Loading Mask from Components plugin...\r\n10/28/2020 18:43:50 INFO     Loading Mask from Extended plugin...\r\n10/28/2020 18:43:50 INFO     Starting, this may take a while...\r\n10/28/2020 18:43:50 INFO     Initializing S3FD (Detect)...\r\n10/28/2020 18:43:51 INFO     Initialized S3FD (Detect) with batchsize of 4\r\n10/28/2020 18:43:51 INFO     Initializing FAN (Align)...\r\n\r\n2020-10-28 18:43:54.494508: E tensorflow/stream_executor/cuda/cuda_driver.cc:910] failed to synchronize the stop event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered\r\n2020-10-28 18:43:54.494821: E tensorflow/stream_executor/gpu/gpu_timer.cc:55] Internal: Error destroying CUDA event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered\r\n2020-10-28 18:43:54.495199: E tensorflow/stream_executor/gpu/gpu_timer.cc:60] Internal: Error destroying CUDA event: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered\r\n2020-10-28 18:43:54.495492: E tensorflow/stream_executor/stream.cc:5485] Internal: Failed to enqueue async memset operation: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered\r\n2020-10-28 18:43:54.495879: E tensorflow/stream_executor/cuda/cuda_driver.cc:575] failed to load PTX text as a module: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered\r\n2020-10-28 18:43:54.496149: E tensorflow/stream_executor/cuda/cuda_driver.cc:580] error log buffer (1024 bytes):\r\n2020-10-28 18:43:54.496344: E tensorflow/stream_executor/cuda/cuda_driver.cc:575] failed to load PTX text as a module: CUDA_ERROR_ILLEGAL_ADDRESS: an illegal memory access was encountered\r\n2020-10-28 18:43:54.496580: E tensorflow/stream_executor/cuda/cuda_driver.cc:580] error log buffer (1024 bytes):\r\n2020-10-28 18:43:54.521217: F .\\tensorflow/core/kernels/random_op_gpu.h:232] Non-OK-status: GpuLaunchKernel(FillPhiloxRandomKernelLaunch<Distribution>, num_blocks, block_size, 0, d.stream(), gen, data, size, dist) status: Internal: an illegal memory access was encountered\r\n\r\n\r\nI am still new to this and please help, i tried uninstalling and reinstall but still the same issue.\r\n\r\n", "comments": ["@dancloud123 \r\n\r\nPlease, fill i[ssue template](https://github.com/tensorflow/tensorflow/issues/new/choose). please, let us know which TF version you are using?\r\n\r\nProvide the exact sequence of commands / steps that you executed before running into the problem.Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 44375, "title": "DeepLabV3+ Xception SemanticPredictions output layer corrupt", "body": "I can not do inference on a frozen custom trained Xception model. Resnet/Mobilenet is working ok. What might be the difference then? Is there anything special to know about the Xception model output?\r\nDuring training loss and images look very good. However when using the frozen model the output is always empty.\r\n\r\n**System information**\r\nPlatform: Linux Ubuntu 20.04 / Nvidia GPU 8 GB\r\nPython: 3.7\r\nTensorflow: v1.15.2-30-g4386a66\r\nModel: xception_41\r\n\r\n**Describe the current behavior**\r\nOutput tensor for SemanticPredictions is always the same value.\r\n\r\n**Describe the expected behavior**\r\nOutput tensor for SemanticPredictions should contain the classes prediction value.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\n\r\nThe model was trained:\r\n```\r\npython deeplab/train.py --logtostderr --training_number_of_steps=96400 \\\r\n  --train_split=\"trainval\"  \\\r\n  --train_crop_size=\"384,384\" --train_batch_size=4 --dataset=\"vehicle\" --save_interval_secs=300 \\\r\n  --save_summaries_secs=300 --save_summaries_images=True --log_steps=100 --train_logdir=training_xception_41 \\\r\n  --dataset_dir=${PATH_TO_DATASET} \\\r\n  --scale_factor_step_size=0.05 \\\r\n  --min_scale_factor=0.60 \\\r\n  --max_scale_factor=0.75 \\\r\n  --scale_factor_step_size=0.05 \\\r\n  --output_stride=8 --base_learning_rate=0.125 \\\r\n  --weight_decay=0.00125 \\\r\n  --model_variant=\"xception_41\"\r\n```\r\n\r\nThe model was frozen:\r\n```\r\npython deeplab/export_model.py \\\r\n--model_variant=\"xception_41\" \\\r\n--num_classes=${CLASSES} \\\r\n--dataset=\"vehicle\" \\\r\n--checkpoint_path=${toFreeze} \\\r\n--crop_size=384 \\\r\n--crop_size=384 \\\r\n--export_path=graph_xception_41.pb \\\r\n--output_stride=8\r\n```\r\n\r\nI can see a difference in output graphs (left Resnet / right Xception):\r\n[![https://imgur.com/pPswXVo.png](https://imgur.com/pPswXVo.png)](https://imgur.com/pPswXVo.png)", "comments": ["@thhart,\r\nIssues related to tensorflow/models are tracked in the models repo. Could you please submit a new issue from [this link](https://github.com/tensorflow/models/issues/new/choose), so that the issue can be tracked there. Thanks!", "The same problem applies to nas_pnasnet by the way.\r\nHowever I can see a difference SemanticProbabilities layer here also empty.\r\nFor Xception the SemanticProbabilities layer was not empty.", "Moved to: https://github.com/tensorflow/models/issues/9426"]}]