[{"number": 29359, "title": "TF (v1.9+) unable to call subprocess when making a tf.data.dataset during training in an estimator", "body": "What I am trying to do:\r\n\r\nI have a TSV file consisting of string and integer values.\r\n\r\nEach line in the file corresponds to a record e.g. \r\n\r\n```tsv\r\na  1  2    # record 1\r\nb  3  4    # record 2\r\n```\r\n\r\nThe values of these records are a condensed way of storing part of the input data. \r\n\r\nI have a bash function that can take the stringified tsv file, e.g.\r\n\r\n```bash\r\nmy-bash-func \"a\\t\\1\\t2\\nb\\t3\\t4\\n\"\r\n```\r\n\r\nwhich will return the input for my model.\r\n\r\nI have a python wrapper function which uses `subprocess` to pipe the file to this bash command and return the output to python:\r\n\r\n```python\r\nprocess(['my-bash-func'], stdin=\"a\\t\\1\\t2\\nb\\t3\\t4\\n\")\r\n```\r\n\r\nwhere process might be defined as:\r\n\r\n```python\r\ndef process(command:list, stdin:str, popen_options={}):\r\n    '''\r\n    Arguments:\r\n        command (list): a list of strings indicating the command and its\r\n            arguments to spawn as a subprocess.\r\n\r\n        stdin (str): passed as stdin to the subprocess. Assumed to be utf-8\r\n            encoded.\r\n\r\n        popen_options (dict): used to configure the subprocess.Popen command\r\n\r\n    Returns:\r\n        stdout, stderr\r\n    '''\r\n    command = clean_command(command)\r\n    popen_config = POPEN_DEFAULTS.copy()\r\n    popen_config.update(popen_options)\r\n    try:\r\n        pid = subprocess.Popen(args = command, **popen_config)\r\n        stdout_data, stderr_data = pid.communicate(stdin)\r\n    except OSError as err:\r\n        error_message(command, err)\r\n        sys.exit(1)\r\n    if pid.returncode != 0:\r\n        error_message(command, 'pid code {}'.format(pid.returncode), stdout_data, stderr_data)\r\n    return stdout_data, stderr_data\r\n```\r\n\r\nan example output might be:\r\n\r\n```python\r\n\"x\\t\\y\\t3\\nw\\tv\\t8\\n\"\r\n```\r\n\r\nafter parsing, splitting lines and tabs, the constructed input is now:\r\n\r\n```python\r\na  1  2  x  y  3  # record 1\r\nb  3  4  w  v  8 # record 2\r\n```\r\n\r\nwith this information both the input to the model and the label for the input can be constructed, via a python function:\r\n\r\n```\r\nrecord = [\"a\", 1, 2, \"x\", \"y\", 3]\r\n(features, label) = restored_record_to_feature_label_tuple(record)\r\n```\r\nfor _each_ epoch during training some randomness needs to be injected. This is done via altering the values in the TSV e.g. record 1 (from the TSV) might have the following values over three epochs:\r\n\r\n```python\r\na   1  2    # record 1 from TSV on epoch 1\r\na  -1  3    # record 1 from TSV on epoch 2\r\na   2  1    # record 1 from TSV on epoch 3\r\n```\r\n\r\neven with `tf.py_func` I have been unable to find a way to string together this input pipeline:\r\n\r\n```python\r\n# pseudo-code\r\n\r\n# only needs to be done once. This TSV can also be encoded as tf Records.\r\ntsv_data = parse_tsv(read_tsv(filename))\r\n\r\n# done once per epoch\r\ntsv_data_plus_randomness = randomify(tsv_data)\r\n\r\n# reconstruct input (calls subprocess)\r\nreconstructed_input = parse_tsv(\r\n    process(\r\n        [\"my-bash-func\"], \r\n        stringify(tsv_data_plus_randomness)\r\n    )\r\n)\r\n\r\n\r\nfeatures, labels = restored_record_to_feature_label_tuple(reconstructed_input)\r\n```\r\n\r\nIdeally the above code can become a function compatible with tf.Estimator api\r\n\r\n```python\r\ntrain_fn = # everything after reading in the tsv the first time\r\n\r\ntrain_spec = tf.estimator.TrainSpec(input_fn=train_fn)\r\n```\r\n\r\n\r\nI _understand_ that this amount of processing is a bottleneck for the model. Ideally, if there were 100 epochs, the data for the 100 epochs of randomness would be pre-calculated and stored. Due to the nature of the model and the usefulness going forward, being able to work with the TSV (at the cost of training time) is worth the trade off. I state this after having done this approach already.\r\n\r\nI have a reusable custom estimator [template][reusable estimator] which might be of use for trying to figure out why this is not possible. \r\n\r\nIt seems that once the data is a tf.data.Dataset (be if from `tf.data.experimental.CsvDataset` or `tf.data.TFRecordDataset`), this amount of pythonic interface is not possible. \r\n\r\n\r\n\r\n\r\n-------------------------------\r\n\r\nAddendum: \r\nI have been very open about what I know and do not know regarding Tensorflow. I have read extensively the documentation and even produced a concept to reduced the redundancy of the tf record interface via [FIO][https://pypi.org/project/fio/].\r\n\r\nWhat I propose above is not an outrageous input pipeline and shouldn't be so obscure in regards to figuring out how to implement it. \r\n\r\nI went on quite an adventure trying to achieve a [reusable estimator]. While tf.estimator is \"supported\" (not actively developed but pre-made estimators may be added) in tf 2.0, it is likely to be removed or completely deprcyated by tf 3.0. Below includes a sampling of the adventure, and it is important to note, that even with some questions having >1k views, many are unanswered. Further, several issues (e.g. the issue regarding exporting device placement https://github.com/tensorflow/tensorflow/issues/23834) took so long to get any attention by developers that now that TF 2.0 is just about here, no one really cares to invest too much time into actually making user estimators functional as they will be replaced with keras models. \r\n\r\nDespite the colabs linked in these SO questions have been quite useful and individuals besides myself have used them (even apparently a company in china), sparing themselves the misery of figuring out how to get a basic custom model going (with some quality of life bells and whistles). \r\n\r\nI state all this to emphasize that I would not be asking this if I could figure out how to do it from the existing TF documentation / source code.\r\n\r\nsome of the relevant S.O.  questions:\r\n\r\n- https://stackoverflow.com/questions/53634736/tensorflow-estimator-api-use-numpy-functions\r\n- https://stackoverflow.com/questions/53414168/tensorflow-exportoutputs-predictouput-and-specifying-signature-constants-defau\r\n- https://stackoverflow.com/questions/53410469/tensorflow-estimator-servinginputreceiver-features-vs-receiver-tensors-when-and\r\n- https://stackoverflow.com/questions/53409652/tensorflow-estimator-clear-deivces-in-exporters\r\n- https://stackoverflow.com/questions/53409547/tensorflow-estimator-bestexporter-event-file-pattern-doesnt-do-anything\r\n- https://stackoverflow.com/questions/53356558/tensorflow-v1-10-load-savedmodel-with-different-device-placement-or-manually-se\r\n- https://stackoverflow.com/questions/53356029/tensorflow-v1-10-serving-custom-estimator\r\n- https://stackoverflow.com/questions/53355055/tensorflow-estimator-to-tensorflow-js\r\n- https://stackoverflow.com/questions/53317235/tensorflow-custom-estimators-defining-estimator-spec-triggers-error\r\n- https://stackoverflow.com/questions/53307954/tensorflow-custom-estimator-predict-throwing-value-error\r\n- https://stackoverflow.com/questions/53226898/tensorflow-custom-estimator-stuck-when-calling-evaluate-after-training\r\n- https://stackoverflow.com/questions/52874647/tensorflow-v1-10-why-is-an-input-serving-receiver-function-needed-when-checkpoi\r\n- https://stackoverflow.com/questions/52641737/tensorflow-1-10-custom-estimator-early-stopping-with-train-and-evaluate\r\n- https://stackoverflow.com/questions/52064866/tensorflow-1-10-tfrecorddataset-recovering-tfrecords\r\n- https://stackoverflow.com/questions/52035692/tensorflow-v1-10-store-images-as-byte-strings-or-per-channel\r\n\r\n\r\n[reusable estimator]: https://colab.research.google.com/drive/1GKAqEo7qSr6kMAgxPrOrudA5eLndQ6Ub#scrollTo=L8V8lpVFdyWL", "comments": ["@gadagashwini any ideas?", "@ymodak I'd be curious to know your thoughts", "@tanzhenyu  thoughts?", "You seem to be using older version(1.x) of Tensorflow which is not supported anymore. Please try the latest [Tensorflow version](https://www.tensorflow.org/install/pip) and let us know if the problem still persists. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/29359\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/29359\">No</a>\n"]}, {"number": 29358, "title": "[Doc] Broken reference link in basic text classification tutorial", "body": "# DOC Issue\r\n\r\n## URL(s) with the issue:\r\nhttps://www.tensorflow.org/tutorials/keras/basic_text_classification\r\n\r\n## Description of issue (what needs changing):\r\nBroken(Wrong) Link in basic text classification tutorial. Needs to be updated/removed/changed.\r\n\r\n### Clear description\r\nIn the basic text classification tutorial (imdb reviews) the reference link for pad_sequences points to https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/sequence/pad_sequences but you get redirected to \r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/preprocessing\r\nwhich is pretty unhelpful. \r\n+\r\non \r\nhttps://www.tensorflow.org/api_docs/python/tf/keras/preprocessing\r\nthe reference link to the keras documentation returns a 404.\r\nSo there is not much information to be gained from following that link. \r\n\r\n", "comments": ["@ivenk Thanks for finding this broken link. I am closing the issue as it was resolved by the PR https://github.com/tensorflow/docs/pull/629. Thanks!"]}, {"number": 29356, "title": "Copy tensorflow.lib from the correct directory", "body": "PiperOrigin-RevId: 251205189", "comments": []}, {"number": 29355, "title": "[XLA] Make HasSideEffectNoRecurse virtual", "body": "This allows for instructions which inherit from HloInstruction to be marked as having side effects and not be removed from the graph by DCE - for example we can create a class/HLO Instruction which inherits from HloCustomCallInstruction and has side effects, such as print.", "comments": ["Hi, thanks for the patch.\r\n\r\nI don't think this is an approach we want to take in XLA.  In part, we want to guard the performance of these functions.  But also we cannot support extension points like this in our compiler.  Because they're unused in the main codebase, they will inevitably break, etc.\r\n\r\nBeing able to make custom-call conditionally side-effecting sounds fine, but that can be a property of the kCustomCall instruction; it does not require a subclass.  Do you have other use-cases in mind other than this?", "Thanks for the feedback. I'll make a PR for the alternative suggested"]}, {"number": 29354, "title": "Suggested KMP_AFFINITY settings harm performance", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes (actually keras, using tensorflow backend)\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): RHEL 7.6\r\n- TensorFlow installed from (source or binary): binary (via anaconda)\r\n- TensorFlow version (use command below): 1.13.1 (mkl_py37h54b294f_0)\r\n- Python version: 3.7.3\r\n- CUDA/cuDNN version: N/A\r\n\r\n**Describe the current behavior**\r\nSet `KMP_AFFINITY=\"granularity=fine,verbose,compact,1,0\"` as per the performance guidelines.\r\nhttps://www.tensorflow.org/guide/performance/overview\r\n\r\nWith `OMP_NUM_THREADS=4`, I train a model and see the following output on a 44 core (88 hyperthreads) system:\r\n```\r\nOMP: Info #250: KMP_AFFINITY: pid 372422 tid 372422 thread 0 bound to OS proc set 0\r\nOMP: Info #250: KMP_AFFINITY: pid 372420 tid 372420 thread 0 bound to OS proc set 0\r\nOMP: Info #250: KMP_AFFINITY: pid 372423 tid 372423 thread 0 bound to OS proc set 0\r\nOMP: Info #250: KMP_AFFINITY: pid 372424 tid 372424 thread 0 bound to OS proc set 0\r\nOMP: Info #250: KMP_AFFINITY: pid 372425 tid 372425 thread 0 bound to OS proc set 0\r\nOMP: Info #250: KMP_AFFINITY: pid 372426 tid 372426 thread 0 bound to OS proc set 0\r\nOMP: Info #250: KMP_AFFINITY: pid 372427 tid 372427 thread 0 bound to OS proc set 0\r\nOMP: Info #250: KMP_AFFINITY: pid 372421 tid 372421 thread 0 bound to OS proc set 0\r\nOMP: Info #250: KMP_AFFINITY: pid 372414 tid 372414 thread 0 bound to OS proc set 0\r\nOMP: Info #250: KMP_AFFINITY: pid 372415 tid 372415 thread 0 bound to OS proc set 0\r\nOMP: Info #250: KMP_AFFINITY: pid 372416 tid 372416 thread 0 bound to OS proc set 0\r\nOMP: Info #250: KMP_AFFINITY: pid 372417 tid 372417 thread 0 bound to OS proc set 0\r\nOMP: Info #250: KMP_AFFINITY: pid 372418 tid 372418 thread 0 bound to OS proc set 0\r\nOMP: Info #250: KMP_AFFINITY: pid 372419 tid 372419 thread 0 bound to OS proc set 0\r\nOMP: Info #250: KMP_AFFINITY: pid 372429 tid 372429 thread 0 bound to OS proc set 0\r\nOMP: Info #250: KMP_AFFINITY: pid 372413 tid 372413 thread 0 bound to OS proc set 0\r\nOMP: Info #250: KMP_AFFINITY: pid 372378 tid 372396 thread 1 bound to OS proc set 4\r\nOMP: Info #250: KMP_AFFINITY: pid 372378 tid 372460 thread 2 bound to OS proc set 8\r\nOMP: Info #250: KMP_AFFINITY: pid 372378 tid 372461 thread 3 bound to OS proc set 10\r\nOMP: Info #250: KMP_AFFINITY: pid 372378 tid 372462 thread 4 bound to OS proc set 6\r\n```\r\nThere are a bunch of processes and threads here. Some are worker processes for feeding in data. Only the final 4 are \"training\" threads, which are pinned appropriately. The other procs/threads are erroneously pinned to a single hardware thread context.\r\n\r\nUsing `KMP_AFFINITY=\"verbose\"`, I get the following output (and substantially greater performance):\r\n```\r\nOMP: Info #250: KMP_AFFINITY: pid 373414 tid 373414 thread 0 bound to OS proc set 0-87\r\nOMP: Info #250: KMP_AFFINITY: pid 373416 tid 373416 thread 0 bound to OS proc set 0-87\r\nOMP: Info #250: KMP_AFFINITY: pid 373420 tid 373420 thread 0 bound to OS proc set 0-87\r\nOMP: Info #250: KMP_AFFINITY: pid 373425 tid 373425 thread 0 bound to OS proc set 0-87\r\nOMP: Info #250: KMP_AFFINITY: pid 373424 tid 373424 thread 0 bound to OS proc set 0-87\r\nOMP: Info #250: KMP_AFFINITY: pid 373418 tid 373418 thread 0 bound to OS proc set 0-87\r\nOMP: Info #250: KMP_AFFINITY: pid 373422 tid 373422 thread 0 bound to OS proc set 0-87\r\nOMP: Info #250: KMP_AFFINITY: pid 373427 tid 373427 thread 0 bound to OS proc set 0-87\r\nOMP: Info #250: KMP_AFFINITY: pid 373415 tid 373415 thread 0 bound to OS proc set 0-87\r\nOMP: Info #250: KMP_AFFINITY: pid 373432 tid 373432 thread 0 bound to OS proc set 0-87\r\nOMP: Info #250: KMP_AFFINITY: pid 373426 tid 373426 thread 0 bound to OS proc set 0-87\r\nOMP: Info #250: KMP_AFFINITY: pid 373421 tid 373421 thread 0 bound to OS proc set 0-87\r\nOMP: Info #250: KMP_AFFINITY: pid 373423 tid 373423 thread 0 bound to OS proc set 0-87\r\nOMP: Info #250: KMP_AFFINITY: pid 373419 tid 373419 thread 0 bound to OS proc set 0-87\r\nOMP: Info #250: KMP_AFFINITY: pid 373429 tid 373429 thread 0 bound to OS proc set 0-87\r\nOMP: Info #250: KMP_AFFINITY: pid 373417 tid 373417 thread 0 bound to OS proc set 0-87\r\nOMP: Info #250: KMP_AFFINITY: pid 373298 tid 373399 thread 1 bound to OS proc set 0-87\r\nOMP: Info #250: KMP_AFFINITY: pid 373298 tid 373441 thread 2 bound to OS proc set 0-87\r\nOMP: Info #250: KMP_AFFINITY: pid 373298 tid 373442 thread 3 bound to OS proc set 0-87\r\nOMP: Info #250: KMP_AFFINITY: pid 373298 tid 373443 thread 4 bound to OS proc set 0-87\r\n```\r\n**Describe the expected behavior**\r\nDon't pin non-OMP worker processes to a single hardware thread context. Perhaps the documentation could suggest starting with `KMP_AFFINITY=\"disabled\"`, as a baseline?\r\n\r\n**Other info / logs**\r\nOther performance related issues in the tracker are likely to have been raised because of this problem. E.g. #29008 and #23238 are currently open. There are closed issues that are likely caused by this, but have been closed without proper resolution (#15320 and #22212, but probably many others). At least suggesting `KMP_AFFINITY=\"disabled\"` in such issues might be warranted in the future.", "comments": ["Hi @ @grahamgower \r\nCould you paste all the KMP information?\r\nwhen you set\r\n```\r\nKMP_AFFINITY=\"granularity=fine,verbose,compact,1,0\"\r\nOMP_NUM_THREADS=4\r\n```\r\nsuch as \r\n```\r\nOMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.\r\nOMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info\r\nOMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-25,52-77\r\nOMP: Info #156: KMP_AFFINITY: 52 available OS procs\r\nOMP: Info #157: KMP_AFFINITY: Uniform topology\r\nOMP: Info #179: KMP_AFFINITY: 1 packages x 26 cores/pkg x 2 threads/core (26 total cores)\r\nOMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:\r\nOMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0\r\nOMP: Info #171: KMP_AFFINITY: OS proc 52 maps to package 0 core 0 thread 1\r\nOMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 0 core 1 thread 0\r\nOMP: Info #171: KMP_AFFINITY: OS proc 53 maps to package 0 core 1 thread 1\r\nOMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 2 thread 0\r\nOMP: Info #171: KMP_AFFINITY: OS proc 54 maps to package 0 core 2 thread 1\r\nOMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 0 core 3 thread 0\r\nOMP: Info #171: KMP_AFFINITY: OS proc 55 maps to package 0 core 3 thread 1\r\nOMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 4 thread 0\r\nOMP: Info #171: KMP_AFFINITY: OS proc 56 maps to package 0 core 4 thread 1\r\nOMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 0 core 5 thread 0\r\nOMP: Info #171: KMP_AFFINITY: OS proc 57 maps to package 0 core 5 thread 1\r\nOMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 6 thread 0\r\nOMP: Info #171: KMP_AFFINITY: OS proc 58 maps to package 0 core 6 thread 1\r\nOMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 0 core 8 thread 0\r\nOMP: Info #171: KMP_AFFINITY: OS proc 59 maps to package 0 core 8 thread 1\r\nOMP: Info #171: KMP_AFFINITY: OS proc 8 maps to package 0 core 9 thread 0\r\nOMP: Info #171: KMP_AFFINITY: OS proc 60 maps to package 0 core 9 thread 1\r\nOMP: Info #171: KMP_AFFINITY: OS proc 9 maps to package 0 core 10 thread 0\r\nOMP: Info #171: KMP_AFFINITY: OS proc 61 maps to package 0 core 10 thread 1\r\nOMP: Info #171: KMP_AFFINITY: OS proc 10 maps to package 0 core 11 thread 0\r\nOMP: Info #171: KMP_AFFINITY: OS proc 62 maps to package 0 core 11 thread 1\r\nOMP: Info #171: KMP_AFFINITY: OS proc 11 maps to package 0 core 12 thread 0\r\nOMP: Info #171: KMP_AFFINITY: OS proc 63 maps to package 0 core 12 thread 1\r\nOMP: Info #171: KMP_AFFINITY: OS proc 12 maps to package 0 core 13 thread 0\r\nOMP: Info #171: KMP_AFFINITY: OS proc 64 maps to package 0 core 13 thread 1\r\nOMP: Info #171: KMP_AFFINITY: OS proc 13 maps to package 0 core 16 thread 0\r\nOMP: Info #171: KMP_AFFINITY: OS proc 65 maps to package 0 core 16 thread 1\r\nOMP: Info #171: KMP_AFFINITY: OS proc 14 maps to package 0 core 17 thread 0\r\nOMP: Info #171: KMP_AFFINITY: OS proc 66 maps to package 0 core 17 thread 1\r\nOMP: Info #171: KMP_AFFINITY: OS proc 15 maps to package 0 core 18 thread 0\r\nOMP: Info #171: KMP_AFFINITY: OS proc 67 maps to package 0 core 18 thread 1\r\nOMP: Info #171: KMP_AFFINITY: OS proc 16 maps to package 0 core 19 thread 0\r\nOMP: Info #171: KMP_AFFINITY: OS proc 68 maps to package 0 core 19 thread 1\r\nOMP: Info #171: KMP_AFFINITY: OS proc 17 maps to package 0 core 20 thread 0\r\nOMP: Info #171: KMP_AFFINITY: OS proc 69 maps to package 0 core 20 thread 1\r\nOMP: Info #171: KMP_AFFINITY: OS proc 18 maps to package 0 core 21 thread 0\r\nOMP: Info #171: KMP_AFFINITY: OS proc 70 maps to package 0 core 21 thread 1\r\nOMP: Info #171: KMP_AFFINITY: OS proc 19 maps to package 0 core 22 thread 0\r\nOMP: Info #171: KMP_AFFINITY: OS proc 71 maps to package 0 core 22 thread 1\r\nOMP: Info #171: KMP_AFFINITY: OS proc 20 maps to package 0 core 24 thread 0\r\nOMP: Info #171: KMP_AFFINITY: OS proc 72 maps to package 0 core 24 thread 1\r\nOMP: Info #171: KMP_AFFINITY: OS proc 21 maps to package 0 core 25 thread 0\r\nOMP: Info #171: KMP_AFFINITY: OS proc 73 maps to package 0 core 25 thread 1\r\nOMP: Info #171: KMP_AFFINITY: OS proc 22 maps to package 0 core 26 thread 0\r\nOMP: Info #171: KMP_AFFINITY: OS proc 74 maps to package 0 core 26 thread 1\r\nOMP: Info #171: KMP_AFFINITY: OS proc 23 maps to package 0 core 27 thread 0\r\nOMP: Info #171: KMP_AFFINITY: OS proc 75 maps to package 0 core 27 thread 1\r\nOMP: Info #171: KMP_AFFINITY: OS proc 24 maps to package 0 core 28 thread 0\r\nOMP: Info #171: KMP_AFFINITY: OS proc 76 maps to package 0 core 28 thread 1\r\nOMP: Info #171: KMP_AFFINITY: OS proc 25 maps to package 0 core 29 thread 0\r\nOMP: Info #171: KMP_AFFINITY: OS proc 77 maps to package 0 core 29 thread 1\r\nOMP: Info #250: KMP_AFFINITY: pid 64740 tid 64869 thread 0 bound to OS proc set 0\r\nOMP: Info #250: KMP_AFFINITY: pid 64740 tid 64869 thread 1 bound to OS proc set 1\r\nOMP: Info #250: KMP_AFFINITY: pid 64740 tid 64869 thread 2 bound to OS proc set 2\r\nOMP: Info #250: KMP_AFFINITY: pid 64740 tid 66062 thread 3 bound to OS proc set 3\r\nOMP: Info #250: KMP_AFFINITY: pid 64740 tid 66063 thread 4 bound to OS proc set 4\r\nOMP: Info #250: KMP_AFFINITY: pid 64740 tid 66065 thread 6 bound to OS proc set 6\r\nOMP: Info #250: KMP_AFFINITY: pid 64740 tid 66064 thread 5 bound to OS proc set 5\r\nOMP: Info #250: KMP_AFFINITY: pid 64740 tid 66066 thread 7 bound to OS proc set 7\r\nOMP: Info #250: KMP_AFFINITY: pid 64740 tid 66067 thread 8 bound to OS proc set 8\r\nOMP: Info #250: KMP_AFFINITY: pid 64740 tid 66068 thread 9 bound to OS proc set 9\r\nOMP: Info #250: KMP_AFFINITY: pid 64740 tid 66069 thread 10 bound to OS proc set 10\r\nOMP: Info #250: KMP_AFFINITY: pid 64740 tid 66070 thread 11 bound to OS proc set 11\r\nOMP: Info #250: KMP_AFFINITY: pid 64740 tid 66071 thread 12 bound to OS proc set 12\r\nOMP: Info #250: KMP_AFFINITY: pid 64740 tid 66072 thread 13 bound to OS proc set 13\r\nOMP: Info #250: KMP_AFFINITY: pid 64740 tid 66074 thread 15 bound to OS proc set 15\r\nOMP: Info #250: KMP_AFFINITY: pid 64740 tid 66073 thread 14 bound to OS proc set 14\r\nOMP: Info #250: KMP_AFFINITY: pid 64740 tid 66075 thread 16 bound to OS proc set 16\r\nOMP: Info #250: KMP_AFFINITY: pid 64740 tid 66076 thread 17 bound to OS proc set 17\r\nOMP: Info #250: KMP_AFFINITY: pid 64740 tid 66077 thread 18 bound to OS proc set 18\r\nOMP: Info #250: KMP_AFFINITY: pid 64740 tid 66078 thread 19 bound to OS proc set 19\r\nOMP: Info #250: KMP_AFFINITY: pid 64740 tid 66080 thread 21 bound to OS proc set 21\r\nOMP: Info #250: KMP_AFFINITY: pid 64740 tid 66079 thread 20 bound to OS proc set 20\r\nOMP: Info #250: KMP_AFFINITY: pid 64740 tid 66082 thread 23 bound to OS proc set 23\r\nOMP: Info #250: KMP_AFFINITY: pid 64740 tid 66081 thread 22 bound to OS proc set 22\r\nOMP: Info #250: KMP_AFFINITY: pid 64740 tid 66084 thread 25 bound to OS proc set 25\r\nOMP: Info #250: KMP_AFFINITY: pid 64740 tid 66083 thread 24 bound to OS proc set 24\r\nOMP: Info #250: KMP_AFFINITY: pid 64740 tid 66085 thread 26 bound to OS proc set 52\r\nOMP: Info #250: KMP_AFFINITY: pid 64740 tid 66086 thread 27 bound to OS proc set 53\r\n```", "This is what I see with \r\n```\r\nNUM_PARALLEL_EXEC_UNITS=4\r\nos.environ['OMP_NUM_THREADS'] = str(NUM_PARALLEL_EXEC_UNITS)\r\nos.environ[\"KMP_AFFINITY\"]= \"granularity=fine,verbose,compact,1,0\"\r\n\r\n...\r\n\r\nconfig = tf.ConfigProto(intra_op_parallelism_threads=NUM_PARALLEL_EXEC_UNITS,\r\n                        inter_op_parallelism_threads=1,\r\n                        allow_soft_placement=True,\r\n                        device_count={'CPU': NUM_PARALLEL_EXEC_UNITS })\r\n```\r\n\r\n```\r\nOMP: Info #212: KMP_AFFINITY: decoding x2APIC ids.\r\nOMP: Info #210: KMP_AFFINITY: Affinity capable, using global cpuid leaf 11 info\r\nOMP: Info #154: KMP_AFFINITY: Initial OS proc set respected: 0-87\r\nOMP: Info #156: KMP_AFFINITY: 88 available OS procs\r\nOMP: Info #157: KMP_AFFINITY: Uniform topology\r\nOMP: Info #179: KMP_AFFINITY: 2 packages x 22 cores/pkg x 2 threads/core (44 total cores)\r\nOMP: Info #214: KMP_AFFINITY: OS proc to physical thread map:\r\nOMP: Info #171: KMP_AFFINITY: OS proc 0 maps to package 0 core 0 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 44 maps to package 0 core 0 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 4 maps to package 0 core 1 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 48 maps to package 0 core 1 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 8 maps to package 0 core 2 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 52 maps to package 0 core 2 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 10 maps to package 0 core 3 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 54 maps to package 0 core 3 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 6 maps to package 0 core 4 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 50 maps to package 0 core 4 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 2 maps to package 0 core 5 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 46 maps to package 0 core 5 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 12 maps to package 0 core 8 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 56 maps to package 0 core 8 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 16 maps to package 0 core 9 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 60 maps to package 0 core 9 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 20 maps to package 0 core 10 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 64 maps to package 0 core 10 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 18 maps to package 0 core 11 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 62 maps to package 0 core 11 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 14 maps to package 0 core 12 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 58 maps to package 0 core 12 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 24 maps to package 0 core 16 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 68 maps to package 0 core 16 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 28 maps to package 0 core 17 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 72 maps to package 0 core 17 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 32 maps to package 0 core 18 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 76 maps to package 0 core 18 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 30 maps to package 0 core 19 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 74 maps to package 0 core 19 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 26 maps to package 0 core 20 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 70 maps to package 0 core 20 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 22 maps to package 0 core 21 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 66 maps to package 0 core 21 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 36 maps to package 0 core 24 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 80 maps to package 0 core 24 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 40 maps to package 0 core 25 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 84 maps to package 0 core 25 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 42 maps to package 0 core 26 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 86 maps to package 0 core 26 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 38 maps to package 0 core 27 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 82 maps to package 0 core 27 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 34 maps to package 0 core 28 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 78 maps to package 0 core 28 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 1 maps to package 1 core 0 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 45 maps to package 1 core 0 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 5 maps to package 1 core 1 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 49 maps to package 1 core 1 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 9 maps to package 1 core 2 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 53 maps to package 1 core 2 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 11 maps to package 1 core 3 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 55 maps to package 1 core 3 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 7 maps to package 1 core 4 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 51 maps to package 1 core 4 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 3 maps to package 1 core 5 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 47 maps to package 1 core 5 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 13 maps to package 1 core 8 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 57 maps to package 1 core 8 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 17 maps to package 1 core 9 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 61 maps to package 1 core 9 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 21 maps to package 1 core 10 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 65 maps to package 1 core 10 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 19 maps to package 1 core 11 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 63 maps to package 1 core 11 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 15 maps to package 1 core 12 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 59 maps to package 1 core 12 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 25 maps to package 1 core 16 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 69 maps to package 1 core 16 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 29 maps to package 1 core 17 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 73 maps to package 1 core 17 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 33 maps to package 1 core 18 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 77 maps to package 1 core 18 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 31 maps to package 1 core 19 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 75 maps to package 1 core 19 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 27 maps to package 1 core 20 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 71 maps to package 1 core 20 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 23 maps to package 1 core 21 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 67 maps to package 1 core 21 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 37 maps to package 1 core 24 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 81 maps to package 1 core 24 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 41 maps to package 1 core 25 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 85 maps to package 1 core 25 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 43 maps to package 1 core 26 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 87 maps to package 1 core 26 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 39 maps to package 1 core 27 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 83 maps to package 1 core 27 thread 1 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 35 maps to package 1 core 28 thread 0 \r\nOMP: Info #171: KMP_AFFINITY: OS proc 79 maps to package 1 core 28 thread 1 \r\nOMP: Info #250: KMP_AFFINITY: pid 208694 tid 208694 thread 0 bound to OS proc set 0\r\nOMP: Info #250: KMP_AFFINITY: pid 210004 tid 210004 thread 0 bound to OS proc set 0\r\nOMP: Info #250: KMP_AFFINITY: pid 210005 tid 210005 thread 0 bound to OS proc set 0\r\nOMP: Info #250: KMP_AFFINITY: pid 210002 tid 210002 thread 0 bound to OS proc set 0\r\nOMP: Info #250: KMP_AFFINITY: pid 210003 tid 210003 thread 0 bound to OS proc set 0\r\nOMP: Info #250: KMP_AFFINITY: pid 209998 tid 209998 thread 0 bound to OS proc set 0\r\nOMP: Info #250: KMP_AFFINITY: pid 210001 tid 210001 thread 0 bound to OS proc set 0\r\nOMP: Info #250: KMP_AFFINITY: pid 209999 tid 209999 thread 0 bound to OS proc set 0\r\nOMP: Info #250: KMP_AFFINITY: pid 210000 tid 210000 thread 0 bound to OS proc set 0\r\nOMP: Info #250: KMP_AFFINITY: pid 208694 tid 209280 thread 1 bound to OS proc set 4\r\nOMP: Info #250: KMP_AFFINITY: pid 208694 tid 220311 thread 2 bound to OS proc set 8\r\nOMP: Info #250: KMP_AFFINITY: pid 208694 tid 220312 thread 3 bound to OS proc set 10\r\nOMP: Info #250: KMP_AFFINITY: pid 208694 tid 220313 thread 4 bound to OS proc set 6\r\n```", "Hi @grahamgower \r\nFrom your logs, I see lots of different process(different pid numbers).\r\nSuch as 208694, 209998-21005.\r\nHowever, in the major process 208694, different threads are binding to different procs and the binding id means KMP setting works.\r\n\r\nI am curious why would you have different pids? \r\n\r\n", "After some more investigation, I have a minimal working example (see below). Additional processes are created by keras because I'm asking for them via fit_generator(). In my case, there appears to be a bad interaction with skimage.transform.resize(). I didn't check the details of what this function does that causes the problem, but I guess it also uses a pool of threads which respects KMP_AFFINITY.\r\n\r\nThis behaviour can be worked around by setting KMP_AFFINITY to \"noverbose\" or \"none\" in each worker process. In my initial report, I suggested KMP_AFFINITY=\"disabled\" - but that is wrong, as that disables multithreading completely. \"none\" appears to be the default behaviour: to retain multithreading, without any cpu affinity. I humbly suggest that the tensorflow documentation should recommend \"none\" as the default.\r\n\r\n```\r\n#!/usr/bin/env python3\r\n\r\nimport os\r\n\r\nNUM_PARALLEL_EXEC_UNITS = 4\r\nos.environ['OMP_NUM_THREADS'] = str(NUM_PARALLEL_EXEC_UNITS)\r\nos.environ[\"KMP_AFFINITY\"] = \"granularity=fine,verbose,compact,1,0\"\r\n#os.environ[\"KMP_AFFINITY\"] = \"verbose\" # no affinity\r\n#os.environ[\"KMP_AFFINITY\"] = \"none\" # no affinity\r\n#os.environ[\"KMP_AFFINITY\"] = \"disabled\" # completely disable thread pools\r\n\r\nimport numpy as np\r\nimport keras\r\nimport tensorflow as tf\r\nfrom keras import backend as K\r\nfrom keras import models, layers\r\nimport skimage\r\n\r\nconfig = tf.ConfigProto(intra_op_parallelism_threads=NUM_PARALLEL_EXEC_UNITS,\r\n                        inter_op_parallelism_threads=1,\r\n                        allow_soft_placement=True,\r\n                        device_count={'CPU': NUM_PARALLEL_EXEC_UNITS })\r\nsession = tf.Session(config=config)\r\n\r\nK.set_session(session)\r\n\r\nclass MySeq(keras.utils.Sequence):\r\n    def __init__(self, files, dim, batch_size=32):\r\n        self.batch_size = batch_size\r\n        self.files = files\r\n        self.dim = dim\r\n\r\n        # Workaround to avoid pinning all worker processes to one cpu.\r\n        #os.environ[\"KMP_AFFINITY\"]= \"none\"\r\n\r\n    def __len__(self):\r\n        return len(self.files) // self.batch_size\r\n\r\n    def __getitem__(self, idx):\r\n        files = self.files[idx*self.batch_size:(idx+1)*self.batch_size]\r\n\r\n        x = np.empty((self.batch_size, *self.dim), dtype=np.float16)\r\n        y = np.empty(self.batch_size, dtype=np.uint8)\r\n\r\n        for i, fn in enumerate(files):\r\n            # load files ... (just make dummy data here)\r\n            y[i] = np.random.randint(2)\r\n            img = (10+100*y[i]) * np.random.rand(128,128)\r\n\r\n            # reduce image size\r\n            if True:\r\n                # This uses a thread pool, which is affected by KMP_AFFINITY.\r\n                x[i] = skimage.transform.resize(img, self.dim, preserve_range=True)\r\n            else:\r\n                # This is unaffected by KMP_AFFINITY.\r\n                x[i,:,:,0] = img[:self.dim[0], :self.dim[1]]\r\n\r\n        return x, y\r\n\r\n\r\ndim = (32,32,1)\r\nfilelist = [str(x) for x in range(10000)] # placeholder, not real files\r\nitrain = int(0.9 * len(filelist))\r\n\r\ntrain_seq = MySeq(filelist[:itrain], dim)\r\ntest_seq = MySeq(filelist[itrain:], dim)\r\n\r\nmodel = models.Sequential([\r\n                layers.Flatten(input_shape=dim),\r\n                layers.Dense(1, activation='softmax'),\r\n                ])\r\n\r\nmodel.summary()\r\n\r\nmodel.compile(optimizer='adam',\r\n              loss='binary_crossentropy',\r\n              metrics=['accuracy'])\r\n\r\nmodel.fit_generator(generator=train_seq,\r\n                        validation_data=test_seq,\r\n                        epochs=1,\r\n                        use_multiprocessing=True,\r\n                        workers=4)\r\n```", "@grahamgower  Thanks for your suggestions and reporting your findings. \r\nOne of the crucial BKMs that allows us to maximize CPU usage is the KMP_AFFINITY params, typically around training and inference compute operations. Setting KMP_AFFINITY to CPU affinity has displayed major benefits on critical workloads in Xeon architecture. Each param that goes in the KMP_AFFINITY has its own significance. Please do take a read at the draft [here](https://software.intel.com/en-us/articles/maximize-tensorflow-performance-on-cpu-considerations-and-recommendations-for-inference) that illustrates the benefits of these params . With that said, I'll try to have a section added about your custom use case as part of the document. We appreciate trying TF w/ MKL build", "@grahamgower Please close this issue and reopen if you have similar findings in future and have additional suggesion that needs to be addressed", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/29354\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/29354\">No</a>\n"]}, {"number": 29353, "title": "Error in Building of TFF on virtualenv Windows", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: tensorflow-1.13.1\r\n- Python version :3.7\r\n- Installed using virtualenv (16.6.0) and pip (19.1.1)\r\n- Bazel version (if compiling from source):  bazel v0.26.0 already installed.\r\n\r\n\r\n\r\n\r\nI want some new functions in TFF, that are not added to the compiled version, so I want to build the newest code. I cloned it with git, then I followed the steps in [https://github.com/tensorflow/federated/blob/master/docs/install.md](url) \r\nBut stuck in step 7 when building with Bazel. The following is the error:\r\n\r\nError Track:\r\n```\r\n(venv) C:\\Users\\ezalaab\\Documents\\eclipse-workspace\\MANA-FederatedLearning\\location-based-federated-learning\\Test\\federated>bazel build //tensorflow_federated/tools:build_pip_package\r\nStarting local Bazel server and connecting to it...\r\nINFO: Call stack for the definition of repository 'local_config_cc' which is a cc_autoconf (rule definition at C:/users/ezalaab/_bazel_ezalaab/cixvmrpx/external/bazel_tools/tools/cpp/cc_configure.bzl:53:15):\r\n - C:/users/ezalaab/_bazel_ezalaab/cixvmrpx/external/bazel_tools/tools/cpp/cc_configure.bzl:91:5\r\n - /DEFAULT.WORKSPACE.SUFFIX:286:1\r\nERROR: An error occurred during the fetch of repository 'local_config_cc':\r\n   Traceback (most recent call last):\r\n        File \"C:/users/ezalaab/_bazel_ezalaab/cixvmrpx/external/bazel_tools/tools/cpp/cc_configure.bzl\", line 46\r\n                configure_windows_toolchain(repository_ctx)\r\n        File \"C:/users/ezalaab/_bazel_ezalaab/cixvmrpx/external/bazel_tools/tools/cpp/windows_cc_configure.bzl\", line 349, in configure_windows_toolchain\r\n                _find_missing_vc_tools(repository_ctx, vc_path)\r\n        File \"C:/users/ezalaab/_bazel_ezalaab/cixvmrpx/external/bazel_tools/tools/cpp/windows_cc_configure.bzl\", line 252, in _find_missing_vc_tools\r\n                find_msvc_tool(repository_ctx, vc_path, tool)\r\n        File \"C:/users/ezalaab/_bazel_ezalaab/cixvmrpx/external/bazel_tools/tools/cpp/windows_cc_configure.bzl\", line 225, in find_msvc_tool\r\n                repository_ctx.path((vc_path + \"\\\\Tools\\\\MSVC\")).readdir()\r\nC:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC (No such file or directory)\r\nINFO: Call stack for the definition of repository 'benjaminp_six' which is a new_git_repository (rule definition at C:/users/ezalaab/_bazel_ezalaab/cixvmrpx/external/bazel_tools/tools/build_defs/repo/git.bzl:239:22):\r\n - C:/users/ezalaab/documents/eclipse-workspace/mana-federatedlearning/location-based-federated-learning/test/federated/WORKSPACE:20:1\r\nERROR: no such package '@local_config_cc//': Traceback (most recent call last):\r\n        File \"C:/users/ezalaab/_bazel_ezalaab/cixvmrpx/external/bazel_tools/tools/cpp/cc_configure.bzl\", line 46\r\n                configure_windows_toolchain(repository_ctx)\r\n        File \"C:/users/ezalaab/_bazel_ezalaab/cixvmrpx/external/bazel_tools/tools/cpp/windows_cc_configure.bzl\", line 349, in configure_windows_toolchain\r\n                _find_missing_vc_tools(repository_ctx, vc_path)\r\n        File \"C:/users/ezalaab/_bazel_ezalaab/cixvmrpx/external/bazel_tools/tools/cpp/windows_cc_configure.bzl\", line 252, in _find_missing_vc_tools\r\n                find_msvc_tool(repository_ctx, vc_path, tool)\r\n        File \"C:/users/ezalaab/_bazel_ezalaab/cixvmrpx/external/bazel_tools/tools/cpp/windows_cc_configure.bzl\", line 225, in find_msvc_tool\r\n                repository_ctx.path((vc_path + \"\\\\Tools\\\\MSVC\")).readdir()\r\nC:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC (No such file or directory)\r\nERROR: Analysis of target '//tensorflow_federated/tools:build_pip_package' failed; build aborted: no such package '@local_config_cc//': Traceback (most recent call last):\r\n        File \"C:/users/ezalaab/_bazel_ezalaab/cixvmrpx/external/bazel_tools/tools/cpp/cc_configure.bzl\", line 46\r\n                configure_windows_toolchain(repository_ctx)\r\n        File \"C:/users/ezalaab/_bazel_ezalaab/cixvmrpx/external/bazel_tools/tools/cpp/windows_cc_configure.bzl\", line 349, in configure_windows_toolchain\r\n                _find_missing_vc_tools(repository_ctx, vc_path)\r\n        File \"C:/users/ezalaab/_bazel_ezalaab/cixvmrpx/external/bazel_tools/tools/cpp/windows_cc_configure.bzl\", line 252, in _find_missing_vc_tools\r\n                find_msvc_tool(repository_ctx, vc_path, tool)\r\n        File \"C:/users/ezalaab/_bazel_ezalaab/cixvmrpx/external/bazel_tools/tools/cpp/windows_cc_configure.bzl\", line 225, in find_msvc_tool\r\n                repository_ctx.path((vc_path + \"\\\\Tools\\\\MSVC\")).readdir()\r\nC:/Program Files (x86)/Microsoft Visual Studio/2017/Community/VC/Tools/MSVC (No such file or directory)\r\nINFO: Elapsed time: 4.112s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (27 packages loaded, 226 targets conf\\\r\nigured)\r\n```\r\n", "comments": ["@AbbasiAYE Please have a look on this [link](https://www.tensorflow.org/install/source_windows) to install Tensorflow from source using bazel. Please let us know how it progresses. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 29352, "title": "Markdown format issue in tutorials/load_data/tf_records", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/tutorials/load_data/tf_records\r\n\r\n## Description of issue (what needs changing):\r\nin the context\r\n\r\n> The tf.train.Feature message type can accept one of the following three types (See the [.proto file](https://www.tensorflow.org/tutorials/load_data/(https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/feature.proto)%20for%20reference). Most other generic types can be coerced into one of these.\r\n\r\nNote: the link of `.proto file` is incorrect. \r\n\r\nIt should be \r\n\r\n> The tf.train.Feature message type can accept one of the following three types (See the [.proto file](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/example/feature.proto) for reference). Most other generic types can be coerced into one of these.\r\n", "comments": ["Closing this issue since the associated PR has been merged. Feel free to reopen if the problem still persists. Thanks!"]}, {"number": 29351, "title": "Tensor traversing", "body": "How to traverse a Tensor? Let's say a tensor is of dims (3, Q, R, S). I want to traverse all three 3D tensor one by one \r\n0th 3D tensor    (Q,R,S)\r\n1th 3D tensor    (Q,R,S)\r\n2nd 3D tensor   (Q,R,S)\r\n3rd 3D tensor    (Q,R,S)\r\nAny leads will be appreciated.\r\n", "comments": ["This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged//tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there and provide better and faster help for such type of issues. Thanks!\r\n"]}, {"number": 29350, "title": "Check failed: host_index <= host_buffer->size() (20138 vs. 10069) in cudnn_conv_algorithm_picker.cc:284", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): no\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Debian 9.8\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version (use command below): 9628bc838b9f8f4a5abc2f9f76808f2c212c3182\r\n- Python version: 3.5\r\n- Bazel version (if compiling from source): 0.25.2\r\n- GCC/Compiler version (if compiling from source): 6.3\r\n- CUDA/cuDNN version: 10.0/7.4.1\r\n- GPU model and memory: V100-SXM2-16GB\r\n\r\n**Describe the expected behavior**\r\n\r\nThe benchmark script finishes normally and prints performance numbers, as only a single-day of commits before on 2019-05-31 with 2d47a0ebca181a9476cbd6d971c819d05fd6f7e1 (we run into this with our in-house untested nightly build at 2019-06-01).\r\n\r\n**Describe the current behavior**\r\n\r\n```\r\nI0603 16:27:54.804590 140049462265600 session_manager.py:500] Running local_init_op.\r\nI0603 16:28:02.836288 140049462265600 session_manager.py:502] Done running local_init_op.\r\n2019-06-03 16:28:11.377907: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\r\n2019-06-03 16:28:14.911938: F tensorflow/compiler/xla/service/gpu/cudnn_conv_algorithm_picker.cc:284] Check failed: host_index <= host_buffer->size() (20138 vs. 10069)\r\nFatal Python error: Aborted\r\n\r\nThread 0x00007f5fce730700 (most recent call first):\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1429 in _call_tf_sessionrun\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1341 in _run_fn\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1356 in _do_call\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1350 in _do_run\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1173 in _run\r\n  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 950 in run\r\n  File \"/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py\", line 868 in benchmark_one_step\r\n  File \"/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py\", line 2429 in benchmark_with_session\r\n  File \"/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py\", line 2293 in _benchmark_graph\r\n  File \"/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py\", line 2084 in _benchmark_train\r\n  File \"/benchmarks/scripts/tf_cnn_benchmarks/benchmark_cnn.py\", line 1879 in run\r\n  File \"benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py\", line 68 in main\r\n  File \"/usr/local/lib/python3.5/dist-packages/absl/app.py\", line 251 in _run_main\r\n  File \"/usr/local/lib/python3.5/dist-packages/absl/app.py\", line 300 in run\r\n  File \"benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py\", line 72 in <module>\r\n```\r\n\r\n**Code to reproduce the issue**\r\n\r\nRunning https://github.com/tensorflow/benchmarks with the following options:\r\n\r\n```\r\npython3 benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py \\\r\n    --num_gpus=8 \\\r\n    --model=resnet50 \\\r\n    --batch_size=256 \\\r\n    --use_fp16 \\\r\n    --variable_update=replicated \\\r\n    --all_reduce_spec=nccl \\\r\n    --xla\r\n```\r\n\r\nor (the error message is all the same)\r\n\r\n```\r\npython3 benchmarks/scripts/tf_cnn_benchmarks/tf_cnn_benchmarks.py \\\r\n    --num_gpus=8 \\\r\n    --model=resnet50 \\\r\n    --batch_size=256 \\\r\n    --use_fp16 \\\r\n    --variable_update=parameter_server \\\r\n    --local_parameter_device=cpu \\\r\n    --xla\r\n```\r\n\r\n**Other info / logs**\r\n\r\nOur Bazel build command is attached below:\r\n\r\n```\r\nbazel build \\\r\n    -c opt \\\r\n    --action_env CUDA_TOOLKIT_PATH=\"/usr/local/cuda\" \\\r\n    --action_env GCC_HOST_COMPILER_PATH=\"/usr/bin/gcc\" \\\r\n    --action_env=PYTHON_BIN_PATH=\"/usr/bin/python3\" \\\r\n    --action_env=PYTHON_LIB_PATH=\"/usr/local/lib/python3.5/dist-packages\" \\\r\n    --action_env=TF_CONFIGURE_IOS=\"0\" \\\r\n    --action_env=TF_CUDA_COMPUTE_CAPABILITIES=\"6.1,7.0,7.5\" \\\r\n    --config=cuda \\\r\n    --config=gdr \\\r\n    --config=tensorrt \\\r\n    --config=verbs \\\r\n    --copt=-Wno-sign-compare \\\r\n    --copt=-march=ivybridge \\\r\n    --define=with_default_optimizations=true \\\r\n    --define=with_xla_support=true \\\r\n    --host_copt=-march=ivybridge \\\r\n    --python_path=\"/usr/bin/python3\" \\\r\n    //tensorflow/tools/pip_package:build_pip_package\r\n```", "comments": ["Friendly ping @tfboyd ", "Ping @timshen91 for this suspicious CL: e734bb03dd8a188b040c527f3fcfce9f6ec85631", "Using a single GPU does not reveal this error.", "Removing the `static` specifier in https://github.com/tensorflow/tensorflow/commit/e734bb03dd8a188b040c527f3fcfce9f6ec85631#diff-a471413a17d71b1d18f51d6cf23e0029R278 resolves the issue.\r\n\r\nI need to sign another corporate CLA though, and I don't mind anyone else open a PR with this fix while I am waiting for the process to be done.", "I just opened an internal bug. I will link this to it and hopefully get it merged today.  I saw it Friday night in our nightly end to end tests.  I saw the same pattern and interesting Transformer works just fine; but running a trivial benchmark and not using XLA also triggers the issue.  Than you for narrowing down the root cause.", "Internal bug that is also linked to this one:  https://b.corp.google.com/issues/134386554", "Should be obsoleted by 3679396fb5676fed06d84a35c63fe29bd257a829.", "@tfboyd Reopen as this issue still affects r2.0. Ping @bananabowl @martinwicke for cherry-picking 3679396, and ping @timshen91 to double check.", "+ Goldie for r2.0\n\nOn Thu, Jun 6, 2019 at 12:54 AM Bairen Yi <notifications@github.com> wrote:\n\n> @tfboyd <https://github.com/tfboyd> Reopen as this issue still affects\n> r2.0. Ping @bananabowl <https://github.com/bananabowl> @martinwicke\n> <https://github.com/martinwicke> for cherry-picking 3679396\n> <https://github.com/tensorflow/tensorflow/commit/3679396fb5676fed06d84a35c63fe29bd257a829>,\n> and ping @timshen91 <https://github.com/timshen91> to double check.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/29350?email_source=notifications&email_token=AKEVL2E4NNOIREGY36T77ODPZC7FBA5CNFSM4HSF5N6KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODXCAKVA#issuecomment-499385684>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AKEVL2G46E56AKNUUGKQYRLPZC7FBANCNFSM4HSF5N6A>\n> .\n>\n", "Should be fixed by 93eee337a1932744df77515dc855dc478b4609a4. Thanks @goldiegadde!"]}, {"number": 29349, "title": "The error occurs during the training", "body": "Hi, The following error occurs during the training, and I don't know what is wrong and why ? Can you give me some guides?\r\n\r\n\r\n\r\n\r\n> Epoch 14/500\r\n> \r\n>   1/379 [..............................] - ETA: 2:47 - loss: 0.3781 - acc: 0.0589 - dice_coefficient: 0.6219\r\n>   2/379 [..............................] - ETA: 2:42 - loss: 0.4649 - acc: 0.1007 - dice_coefficient: 0.5351\r\n>   3/379 [..............................] - ETA: 2:41 - loss: 0.4255 - acc: 0.1039 - dice_coefficient: 0.5745\r\n>   4/379 [..............................] - ETA: 2:40 - loss: 0.5212 - acc: 0.1125 - dice_coefficient: 0.4788\r\n>   5/379 [..............................] - ETA: 2:40 - loss: 0.4794 - acc: 0.0989 - dice_coefficient: 0.5206\r\n>   6/379 [..............................] - ETA: 2:39 - loss: 0.4852 - acc: 0.0932 - dice_coefficient: 0.5148\r\n>   7/379 [..............................] - ETA: 2:42 - loss: 0.4820 - acc: 0.0836 - dice_coefficient: 0.5180\r\n>   8/379 [..............................] - ETA: 2:42 - loss: 0.5002 - acc: 0.0879 - dice_coefficient: 0.4998\r\n>   9/379 [..............................] - ETA: 2:41 - loss: 0.4970 - acc: 0.0849 - dice_coefficient: 0.5030\r\n>  10/379 [..............................] - ETA: 2:41 - loss: 0.4749 - acc: 0.0865 - dice_coefficient: 0.5251\r\n>  11/379 [..............................] - ETA: 2:40 - loss: 0.4679 - acc: 0.0840 - dice_coefficient: 0.5321\r\n>  12/379 [..............................] - ETA: 2:39 - loss: 0.4617 - acc: 0.0879 - dice_coefficient: 0.5383\r\n>  13/379 [>.............................] - ETA: 3:42 - loss: 0.4474 - acc: 0.0889 - dice_coefficient: 0.5526\r\n>  14/379 [>.............................] - ETA: 4:58 - loss: 0.4365 - acc: 0.0878 - dice_coefficient: 0.5635\r\n>  15/379 [>.............................] - ETA: 5:51 - loss: 0.4238 - acc: 0.0836 - dice_coefficient: 0.5762\r\n>  16/379 [>.............................] - ETA: 6:52 - loss: 0.4224 - acc: 0.0866 - dice_coefficient: 0.5776\r\n>  17/379 [>.............................] - ETA: 7:45 - loss: 0.4172 - acc: 0.0905 - dice_coefficient: 0.58282019-06-03 16:02:15.556534: F tensorflow/stream_executor/cuda/cuda_dnn.cc:521] Check failed: cudnnSetTensorNdDescriptor(handle_.get(), elem_type, nd, dims.data(), strides.data()) == CUDNN_STATUS_SUCCESS (3 vs. 0)batch_descriptor: {count: 0 feature_map_count: 3 spatial: 64 64 64  value_min: 0.000000 value_max: 0.000000 layout: BatchDepthYX}\r\n\r\n", "comments": ["Please provide details about what platform you are using (operating system, architecture). Also include your TensorFlow version. Also, did you compile from source or install a binary?\r\n\r\nMake sure you also include the exact minimal code snippet to reproduce the issue included in your test case. If you are unclear what to include see the issue template displayed in [the Github new issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).\r\n\r\nWe ask for this in the issue submission template, because it is really difficult to help without that information. Thanks!", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 29348, "title": "In eager mode, the name of variables always has a suffix of value index", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.0.0alpla0\r\n- Are you willing to contribute it (Yes/No):\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n<pre>\r\nIn [32]: type(x)\r\nOut[32]: tensorflow.python.ops.resource_variable_ops.ResourceVariable\r\n\r\nIn [33]: x.name\r\nOut[33]: 'my_model/context_predictor/kernel:0'\r\n\r\nIn [34]: x.name.split(\":\")[0]\r\nOut[34]: 'my_model/context_predictor/kernel'\r\n</pre>\r\n\r\n**Will this change the current api? How?**\r\nWe can add a property to `tf.Tensor` like:\r\n<pre>\r\n@property\r\ndef unique_name(self):      # or other simpler names\r\n  return self.name.split(\":\")[0]\r\n</pre>\r\n**Who will benefit with this feature?**\r\nWho wants to get variable names", "comments": ["Running the small snippet you provided, I get this error `AttributeError: Tensor.name is meaningless when eager execution is enabled.`\r\nCould you please provide a working demo?", "@lufol My mistake. We should only consider to get variable names in tf2.\r\n<pre>\r\nIn [8]: w = tf.Variable(tf.random.normal((3, 4)), name=\"test\")\r\n\r\nIn [9]: w.name\r\nOut[9]: 'test:0'\r\n\r\nIn [10]: w.name.split(\":\")[0]\r\nOut[10]: 'test'\r\n</pre>", "Thanks for the correction, now I can reproduce your problem.\r\nA possible solution, without adding new code to tf, would be to use `w._shared_name`.\r\nBut keep in mind that this is a protected member of class `Variable`.\r\n\r\nIf this solves your problem, please close sthis issue.\r\nBest regards\r\nLukas", "@lufol BTW, do you know why this property is defined to be protected. You know, in tf 1.x, we often use `w.op.name` to get the shared name here.", "@llan-ml Sorry, I have no clue. I just thought, maybe the index after `name` is counted up if the same name is used again, but this is not the case as\r\n`w = tf.Variable(tf.random.normal((3, 4)), name=\"test\")`\r\n`v = tf.Variable(tf.random.normal((3, 4)), name=\"test\")`\r\n`print(w.name)`\r\n`print(v.name)`\r\nOutputs is both cases\r\n`test:0`"]}, {"number": 29347, "title": "feedable iterator deal sparse feature error", "body": "<em>Please make sure that this is a bug. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):centos\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:no\r\n- TensorFlow installed from (source or binary): conda\r\n- TensorFlow version (use command below): 1.13\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: no cuda\r\n- GPU model and memory: no gpu\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with: 1. TF 1.0: `python -c \"import\r\ntensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` 2. TF 2.0: `python -c\r\n\"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n**Describe the current behavior**\r\nexcept error when run tf.data.Iterator.from_string_handle(handle, training_dataset.output_types, training_dataset.output_shapes)\r\n\r\ntensorflow.python.framework.errors_impl.InvalidArgumentError: Data type mismatch at component 0: expected int32 but got variant.\r\n\t [[Node: IteratorFromStringHandle = IteratorFromStringHandle[output_shapes=[[?,?]], output_types=[DT_INT32], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_Placeholder_0_0)]]\r\n\r\nprint(training_dataset.output_types)\r\n<dtype: 'int32'>\r\n\r\n**Describe the expected behavior**\r\n\r\n**Code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate the problem.\r\n\r\n**Other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["def parser(record):\r\n    keys_to_features = {\r\n    \"feature_ids\": tf.VarLenFeature(tf.int64)\r\n    } \r\n    parsed = tf.parse_single_example(record, keys_to_features)\r\n    feature_ids = tf.cast(parsed[\"feature_ids\"], tf.int32)\r\n    return feature_ids", "when i just feed fixedlen 'label', it works, but when i feed varlen 'feature_ids' or 'feature_vals', it except above error, so seems it does not support sparse feature", "@guangyuyan In order to expedite the trouble-shooting process, please provide a code snippet to reproduce the issue reported here. Thanks!\r\n", "Closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 29346, "title": "Pass the Android aar build with android-ndk-r19c clang 3.8", "body": "Add user-provided default constructor and remove \"const\" statement\r\nfor \"reducer\".\r\n\r\nBuild cmds:\r\n$bazel build --cxxopt='--std=c++11' -c opt --config=android_arm64 \\\r\n   --config=monolithic //tensorflow/lite/java:tensorflow-lite-with-select-tf-ops\r\n\r\nBuild error:\r\ntensorflow/core/kernels/bias_op.cc:278:13: error: default initialization of an object\r\nof const type 'const functor::ReduceMiddleDimensions<float, AccumT,\r\nEigen::internal::scalar_sum_op<AccumT>, Eigen::internal::SumReducer<float> >'\r\n(aka 'const ReduceMiddleDimensions<float, float, scalar_sum_op<float>,\r\n SumReducer<float> >') without a user-provided default constructor\r\n            redux;\r\n                        ^\r\ntensorflow/core/kernels/quantized_resize_bilinear_op.cc:52:16: error: default\r\ninitialization of an object of const type 'const tensorflow::LegacyScaler'\r\nwithout a user-provided default constructor\r\n  const Scaler scaler;\r\n                 ^\r\n\r\nSigned-off-by: Chen Guoyin <guoyin.chen@gmail.com>", "comments": ["FYR, with android ndk r19c, I can run bazel build --cxxopt='--std=c++11' -c opt --config=android_arm64 --config=monolithic //tensorflow/lite/java:tensorflow-lite-with-select-tf-ops without problem. BTW, the clang in ndk-r19 should be clang 8.0.2.", "> FYR, with android ndk r19c, I can run bazel build --cxxopt='--std=c++11' -c opt --config=android_arm64 --config=monolithic //tensorflow/lite/java:tensorflow-lite-with-select-tf-ops without problem. BTW, the clang in ndk-r19 should be clang 8.0.2.\r\n\r\nI thought i was using r19 ndk. But it actually use the r12 ndk which has the clang 3.8.\r\nandroid-ndk-r12-beta2/toolchains/llvm/prebuilt/linux-x86_64/bin$ ./clang --version\r\nAndroid clang version 3.8.256229  (based on LLVM 3.8.256229)\r\nTarget: x86_64-unknown-linux\r\nThread model: posix\r\nInstalledDir: /home/myname/android-studio/android-ndk-r12-beta2/toolchains/llvm/prebuilt/linux-x86_64/bin/."]}, {"number": 29345, "title": "Pass the Android aar build with android-ndk-r19c clang 3.8", "body": "Add user-provided default constructor and remove \"const\" statement\r\nfor \"reducer\".\r\n\r\nBuild cmds:\r\n$bazel build --cxxopt='--std=c++11' -c opt --config=android_arm64 \\\r\n   --config=monolithic //tensorflow/lite/java:tensorflow-lite-with-select-tf-ops\r\n\r\nBuild error:\r\ntensorflow/core/kernels/bias_op.cc:278:13: error: default initialization of an object\r\nof const type 'const functor::ReduceMiddleDimensions<float, AccumT,\r\nEigen::internal::scalar_sum_op<AccumT>, Eigen::internal::SumReducer<float> >'\r\n(aka 'const ReduceMiddleDimensions<float, float, scalar_sum_op<float>,\r\n SumReducer<float> >') without a user-provided default constructor\r\n            redux;\r\n                        ^\r\ntensorflow/core/kernels/quantized_resize_bilinear_op.cc:52:16: error: default\r\ninitialization of an object of const type 'const tensorflow::LegacyScaler'\r\nwithout a user-provided default constructor\r\n  const Scaler scaler;\r\n                 ^\r\n\r\nSigned-off-by: guoyin.chen <guoyin.chen@nxp.com>", "comments": ["So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored or co-authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this state. It's up to you to confirm consent of all the commit author(s), set the `cla` label to `yes` (if enabled on your project), and then merge this pull request when appropriate.*\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F29345) for more info**.\n\n<!-- need_author_consent -->", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F29345) for more info**.\n\n<!-- ok -->"]}, {"number": 29344, "title": "Android inference AAR build failure from source code", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04 LTS\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: master branch with commit e1c98eeb\r\n- Python version: 2.7\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source): 0.24.1\r\n- GCC/Compiler version (if compiling from source): clang 3.8 from android-ndk-r19c\r\n- CUDA/cuDNN version: n/a\r\n- GPU model and memory: n/a\r\n\r\n**Describe the problem**\r\nAndroid aar build with android-ndk-r19c clang 3.8 will have below build error:\r\n    tensorflow/core/kernels/bias_op.cc:278:13: error: default initialization of an object of const type 'const functor::ReduceMiddleDimensions<float, AccumT,  Eigen::internal::scalar_sum_op<AccumT>, Eigen::internal::SumReducer<float> >'   (aka 'const ReduceMiddleDimensions<float, float, scalar_sum_op<float>,  SumReducer<float> >') without a user-provided default constructor\r\n                redux;\r\n                            ^\r\n    tensorflow/core/kernels/quantized_resize_bilinear_op.cc:52:16: error: default initialization of an object of const type 'const tensorflow::LegacyScaler' without a user-provided default constructor\r\n      const Scaler scaler;\r\n                     ^\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n    Build cmds:\r\n    $bazel build --cxxopt='--std=c++11' -c opt --config=android_arm64 \\\r\n       --config=monolithic //tensorflow/lite/java:tensorflow-lite-with-select-tf-ops\r\n\r\n", "comments": ["Please review below patch to fix this build issue.\r\nhttps://github.com/tensorflow/tensorflow/pull/29346", "FYR, with android ndk r19c, I can run `bazel build --cxxopt='--std=c++11' -c opt --config=android_arm64 \r\n--config=monolithic //tensorflow/lite/java:tensorflow-lite-with-select-tf-ops` without problem. BTW, the clang in ndk-r19 should be clang 8.0.2.", "@guoyinchen Can we close this, since the associated PR has been merged. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=29344\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=29344\">No</a>\n"]}, {"number": 29343, "title": "ImportError: DLL load failed: The specified module could not be found.", "body": "\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Pro\r\n- TensorFlow installed from (source or binary): build from source\r\n- TensorFlow version: 1.13.1\r\n- Python version: 3.6.3\r\n- Bazel version (if compiling from source): 0.19.2\r\n- CUDA/cuDNN version: (v10.0), (cudnn-10.0-windows10-x64-v7.5.0.56)\r\n\r\n**Any other info / logs**\r\n....\r\n....\r\nApplication\\vs\\tensorflow;C:\\msys64\\usr\\bin;F:\\Work\\VS\\DNN\\cuda\\bin\r\n    SET PYTHON_BIN_PATH=E:/Application/python/Miniconda3/python.exe\r\n    SET PYTHON_LIB_PATH=E:/Application/python/Miniconda3/lib/site-packages\r\n    SET TF_CUDA_CLANG=0\r\n    SET TF_CUDA_COMPUTE_CAPABILITIES=5.0\r\n    SET TF_CUDA_VERSION=10.0\r\n    SET TF_CUDNN_VERSION=7\r\n    SET TF_NEED_CUDA=1\r\n    SET TF_NEED_OPENCL_SYCL=0\r\n    SET TF_NEED_ROCM=0\r\n  C:/msys64/usr/bin/bash.exe bazel-out/x64_windows-opt/genfiles/tensorflow/tf_python_api_gen_v1.genrule_script.sh\r\nTraceback (most recent call last):\r\n  File \"\\\\?\\C:\\Users\\Dev\\AppData\\Local\\Temp\\Bazel.runfiles_aeo0bwxr\\runfiles\\org_tensorflow\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"\\\\?\\C:\\Users\\Dev\\AppData\\Local\\Temp\\Bazel.runfiles_aeo0bwxr\\runfiles\\org_tensorflow\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"\\\\?\\C:\\Users\\Dev\\AppData\\Local\\Temp\\Bazel.runfiles_aeo0bwxr\\runfiles\\org_tensorflow\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"E:\\Application\\python\\Miniconda3\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"E:\\Application\\python\\Miniconda3\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"\\\\?\\C:\\Users\\Dev\\AppData\\Local\\Temp\\Bazel.runfiles_aeo0bwxr\\runfiles\\org_tensorflow\\tensorflow\\python\\tools\\api\\generator\\create_python_api.py\", line 27, in <module>\r\n    from tensorflow.python.tools.api.generator import doc_srcs\r\n  File \"\\\\?\\C:\\Users\\Dev\\AppData\\Local\\Temp\\Bazel.runfiles_aeo0bwxr\\runfiles\\org_tensorflow\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"\\\\?\\C:\\Users\\Dev\\AppData\\Local\\Temp\\Bazel.runfiles_aeo0bwxr\\runfiles\\org_tensorflow\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"\\\\?\\C:\\Users\\Dev\\AppData\\Local\\Temp\\Bazel.runfiles_aeo0bwxr\\runfiles\\org_tensorflow\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"\\\\?\\C:\\Users\\Dev\\AppData\\Local\\Temp\\Bazel.runfiles_aeo0bwxr\\runfiles\\org_tensorflow\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"\\\\?\\C:\\Users\\Dev\\AppData\\Local\\Temp\\Bazel.runfiles_aeo0bwxr\\runfiles\\org_tensorflow\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"E:\\Application\\python\\Miniconda3\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"E:\\Application\\python\\Miniconda3\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n", "comments": ["It works on https://github.com/tensorflow/tensorflow/issues/28848#issuecomment-498554319", "Good to know the issue is resolved."]}, {"number": 29342, "title": "tf.config.set_soft_device_placement() seems to have no effect", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nMacOSX 10.13.6\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nN/A\r\n- TensorFlow installed from (source or binary):\r\nbinary\r\n- TensorFlow version (use command below):\r\nVERSION='2.0.0-dev20190527'\r\nGIT_VERSION='v1.12.1-2821-gc5b8e15064'\r\n- Python version:\r\n3.5\r\n- Bazel version (if compiling from source):\r\nN/A\r\n- GCC/Compiler version (if compiling from source):\r\nN/A\r\n- CUDA/cuDNN version:\r\nCUDA 10.0 (it's just a Colab GPU instance)\r\n- GPU model and memory:\r\nTesla P4 15079MiB\r\n\r\n**Describe the current behavior**\r\nThe `tf.config.set_soft_device_placement()` function seems to have no effect when I create an integer variable and try to place it on a GPU, I still get an exception.\r\n\r\n**Describe the expected behavior**\r\nI expect soft placement to fallback to using the CPU. No error.\r\n\r\n**Code to reproduce the issue**\r\n```python\r\nimport tensorflow as tf\r\ntf.config.set_soft_device_placement(True)\r\nwith tf.device(\"/gpu:0\"):\r\n    f = tf.Variable(42)\r\n```\r\n\r\n**Other info / logs**\r\nThe code above causes the following exception:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nNotFoundError                             Traceback (most recent call last)\r\n<ipython-input-3-1babaf613bc3> in <module>()\r\n      2 tf.config.set_soft_device_placement(True)\r\n      3 with tf.device(\"/gpu:0\"):\r\n----> 4     f = tf.Variable(42)\r\n\r\n10 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py in __call__(cls, *args, **kwargs)\r\n    260       return cls._variable_v1_call(*args, **kwargs)\r\n    261     elif cls is Variable:\r\n--> 262       return cls._variable_v2_call(*args, **kwargs)\r\n    263     else:\r\n    264       return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py in _variable_v2_call(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation, shape)\r\n    254         synchronization=synchronization,\r\n    255         aggregation=aggregation,\r\n--> 256         shape=shape)\r\n    257 \r\n    258   def __call__(cls, *args, **kwargs):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py in <lambda>(**kws)\r\n    235                         shape=None):\r\n    236     \"\"\"Call on Variable class. Useful to force the signature.\"\"\"\r\n--> 237     previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)\r\n    238     for _, getter in ops.get_default_graph()._variable_creator_stack:  # pylint: disable=protected-access\r\n    239       previous_getter = _make_getter(getter, previous_getter)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variable_scope.py in default_variable_creator_v2(next_creator, **kwargs)\r\n   2549       synchronization=synchronization,\r\n   2550       aggregation=aggregation,\r\n-> 2551       shape=shape)\r\n   2552 \r\n   2553 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/variables.py in __call__(cls, *args, **kwargs)\r\n    262       return cls._variable_v2_call(*args, **kwargs)\r\n    263     else:\r\n--> 264       return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n    265 \r\n    266 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py in __init__(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\r\n    462           synchronization=synchronization,\r\n    463           aggregation=aggregation,\r\n--> 464           shape=shape)\r\n    465 \r\n    466   def __repr__(self):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py in _init_from_args(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, shape)\r\n    616               shared_name=shared_name,\r\n    617               name=name,\r\n--> 618               graph_mode=self._in_graph_mode)\r\n    619         # pylint: disable=protected-access\r\n    620         if (self._in_graph_mode and initial_value is not None and\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py in eager_safe_variable_handle(initial_value, shape, shared_name, name, graph_mode)\r\n    223   dtype = initial_value.dtype.base_dtype\r\n    224   return variable_handle_from_shape_and_dtype(\r\n--> 225       shape, dtype, shared_name, name, graph_mode, initial_value)\r\n    226 \r\n    227 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py in variable_handle_from_shape_and_dtype(shape, dtype, shared_name, name, graph_mode, extra_handle_data)\r\n    139                                                    shared_name=shared_name,\r\n    140                                                    name=name,\r\n--> 141                                                    container=container)\r\n    142   if extra_handle_data is None:\r\n    143     extra_handle_data = handle\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/gen_resource_variable_ops.py in var_handle_op(dtype, shape, container, shared_name, name)\r\n   1416       else:\r\n   1417         message = e.message\r\n-> 1418       _six.raise_from(_core._status_to_exception(e.code, message), None)\r\n   1419   # Add nodes to the TensorFlow graph.\r\n   1420   dtype = _execute.make_type(dtype, \"dtype\")\r\n\r\n/usr/local/lib/python3.6/dist-packages/six.py in raise_from(value, from_value)\r\n\r\nNotFoundError: No registered 'VarHandleOp' OpKernel for GPU devices compatible with node {{node VarHandleOp}}\r\n\t (OpKernel was found, but attributes didn't match) Requested Attributes: container=\"\", dtype=DT_INT32, shape=[], shared_name=\"cd2c89b7-88b7-44c8-ad83-06c2a9158347\"\r\n\t.  Registered:  device='GPU'; dtype in [DT_VARIANT]\r\n  device='GPU'; dtype in [DT_INT64]\r\n  device='GPU'; dtype in [DT_COMPLEX128]\r\n  device='GPU'; dtype in [DT_COMPLEX64]\r\n  device='GPU'; dtype in [DT_BOOL]\r\n  device='GPU'; dtype in [DT_DOUBLE]\r\n  device='GPU'; dtype in [DT_FLOAT]\r\n  device='GPU'; dtype in [DT_HALF]\r\n  device='CPU'\r\n  device='XLA_CPU'\r\n  device='XLA_GPU'\r\n [Op:VarHandleOp] name: Variable/\r\n```", "comments": ["Also, if I activate soft placement and I try to place an operation on a GPU device that does not exist, I still get an exception. I expected TF to fallback to using the CPU:\r\n\r\n```python\r\nimport tensorflow as tf\r\ntf.config.set_soft_device_placement(True)\r\nwith tf.device(\"/gpu:1\"):\r\n    f = tf.Variable(42.0)\r\n```\r\n\r\nRaises this exception:\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nRuntimeError                              Traceback (most recent call last)\r\n<ipython-input-1-3a03536f5e27> in <module>\r\n      2 tf.config.set_soft_device_placement(True)\r\n      3 with tf.device(\"/gpu:1\"):\r\n----> 4         f = tf.Variable(42.5)\r\n      5\r\n\r\n~/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/ops/variables.py in __call__(cls, *args, **kwargs)\r\n    259       return cls._variable_v1_call(*args, **kwargs)\r\n    260     elif cls is Variable:\r\n--> 261       return cls._variable_v2_call(*args, **kwargs)\r\n    262     else:\r\n    263       return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n\r\n~/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/ops/variables.py in _variable_v2_call(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation, shape)\r\n    253         synchronization=synchronization,\r\n    254         aggregation=aggregation,\r\n--> 255         shape=shape)\r\n    256\r\n    257   def __call__(cls, *args, **kwargs):\r\n\r\n~/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/ops/variables.py in <lambda>(**kws)\r\n    234                         shape=None):\r\n    235     \"\"\"Call on Variable class. Useful to force the signature.\"\"\"\r\n--> 236     previous_getter = lambda **kws: default_variable_creator_v2(None, **kws)\r\n    237     for _, getter in ops.get_default_graph()._variable_creator_stack:  # pylint: disable=protected-access\r\n    238       previous_getter = _make_getter(getter, previous_getter)\r\n\r\n~/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py in default_variable_creator_v2(next_creator, **kwargs)\r\n   2542       synchronization=synchronization,\r\n   2543       aggregation=aggregation,\r\n-> 2544       shape=shape)\r\n   2545\r\n   2546\r\n\r\n~/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/ops/variables.py in __call__(cls, *args, **kwargs)\r\n    261       return cls._variable_v2_call(*args, **kwargs)\r\n    262     else:\r\n--> 263       return super(VariableMetaclass, cls).__call__(*args, **kwargs)\r\n    264\r\n    265\r\n\r\n~/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py in __init__(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\r\n    462           synchronization=synchronization,\r\n    463           aggregation=aggregation,\r\n--> 464           shape=shape)\r\n    465\r\n    466   def __repr__(self):\r\n\r\n~/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py in _init_from_args(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, shape)\r\n    607             initial_value = ops.convert_to_tensor(\r\n    608                 initial_value() if init_from_fn else initial_value,\r\n--> 609                 name=\"initial_value\", dtype=dtype)\r\n    610           # Don't use `shape or initial_value.shape` since TensorShape has\r\n    611           # overridden `__bool__`.\r\n\r\n~/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor(value, dtype, name, preferred_dtype, dtype_hint)\r\n   1095   preferred_dtype = deprecation.deprecated_argument_lookup(\r\n   1096       \"dtype_hint\", dtype_hint, \"preferred_dtype\", preferred_dtype)\r\n-> 1097   return convert_to_tensor_v2(value, dtype, preferred_dtype, name)\r\n   1098\r\n   1099\r\n\r\n~/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in convert_to_tensor_v2(value, dtype, dtype_hint, name)\r\n   1153       name=name,\r\n   1154       preferred_dtype=dtype_hint,\r\n-> 1155       as_ref=False)\r\n   1156\r\n   1157\r\n\r\n~/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/ops.py in internal_convert_to_tensor(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors, accept_composite_tensors)\r\n   1232\r\n   1233     if ret is None:\r\n-> 1234       ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\r\n   1235\r\n   1236     if ret is NotImplemented:\r\n\r\n~/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py in _constant_tensor_conversion_function(v, dtype, name, as_ref)\r\n    303                                          as_ref=False):\r\n    304   _ = as_ref\r\n--> 305   return constant(v, dtype=dtype, name=name)\r\n    306\r\n    307\r\n\r\n~/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py in constant(value, dtype, shape, name)\r\n    244   \"\"\"\r\n    245   return _constant_impl(value, dtype, shape, name, verify_shape=False,\r\n--> 246                         allow_broadcast=True)\r\n    247\r\n    248\r\n\r\n~/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py in _constant_impl(value, dtype, shape, name, verify_shape, allow_broadcast)\r\n    252   ctx = context.context()\r\n    253   if ctx.executing_eagerly():\r\n--> 254     t = convert_to_eager_tensor(value, ctx, dtype)\r\n    255     if shape is None:\r\n    256       return t\r\n\r\n~/miniconda3/envs/tf2/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py in convert_to_eager_tensor(value, ctx, dtype)\r\n    109       return ops.EagerTensor(\r\n    110           value, handle, device, dtype, tensor)\r\n--> 111     t = ops.EagerTensor(value, handle, device, dtype)\r\n    112     scalar_cache[cache_key] = t\r\n    113     return t\r\n\r\nRuntimeError: Error copying tensor to device: /job:localhost/replica:0/task:0/device:GPU:1. /job:localhost/replica:0/task:0/device:GPU:1 unknown device.\r\n```", "Hey, have you had a look at this example from the GPU guide at tensorflow.org\r\n\r\n`tf.debugging.set_log_device_placement(True)`\r\n`# Create some tensors`\r\n`a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])`\r\n`b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])`\r\n`c = tf.matmul(a, b)`\r\n`print(c)`\r\n\r\nTo me it looks like TF is choosing which device is then suitable to execute this op:\r\n\r\n> If enabled, an op will be placed on CPU if any of the following are true\r\n>     1. there's no GPU implementation for the OP\r\n>     2. no GPU devices are known or registered\r\n>     3. need to co-locate with reftype input(s) which are from CPU\r\n\r\nfrom [TF config](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/framework/config.py)", "Hi @lufol,\r\n\r\nThanks for your answer. Yes I saw this doc, that's actually why I filed this bug. I don't see what soft placement would change in this example.\r\n\r\nI expect soft placement to change something when the user requests a specific device but there is no op for that device, or the device does not exist. This would be useful if you want to write a program and deploy it on machines that may or may not have GPUs, for example. So on a machine without any GPU, I expect the following code to work without any error, and just fallback to placing the variable on the CPU:\r\n\r\n```python\r\ntf.config.set_soft_device_placement(True)\r\nwith tf.device(\"/gpu:0\"):\r\n    x = tf.Variable(1.0)\r\n```\r\n\r\nPerhaps I'm misunderstanding what `set_soft_device_placement()` is designed for?", "Okay, I got it: the semantics of soft placement have changed since TF 1.\r\n\r\nIn TF 1, the following code works fine on a machine without any GPU (I just tried it):\r\n\r\n```python\r\nimport tensorflow as tf\r\n\r\nwith tf.device(\"/gpu:42\"): # there is no such device\r\n    i = tf.Variable(123) # plus integers are not allowed on GPUs\r\n\r\n# but let's make TF super soft and tolerant:\r\nconfig = tf.ConfigProto()\r\nconfig.allow_soft_placement = True\r\nwith tf.Session(config=config) as sess:\r\n    sess.run(i.initializer)\r\n    print(sess.run(i))\r\n```\r\n\r\nPrints 123, no problem. :)\r\n\r\nThat's why I was surprised that it didn't work in TF 2.0. I'm actually not sure when you would ever need to call `set_soft_device_placement(False)` in TF 2.0, what's the use case?", "From what I understand, you either use \r\n\r\n- `tf.config.set_soft_device_placement(True)` to let tf automatically decide, which device to use. \r\n\r\n- or you use `tf.config.set_soft_device_placement(False)` and decide for each tensor where to place it like this `with tf.device('/CPU:0'): ...`\r\n\r\nSo I guess in your case the first option would be best.", "Hi @lufol,\r\n\r\nI just ran some tests, and it really seems like `tf.config.set_soft_device_placement(False)` makes no difference at all. Whether it's `True` or `False`, the default behavior is applied.\r\n\r\nI'm quite puzzled.", "Have tried to reproduce on Colab with TF 2.0.0-dev20190527  with set_soft_device_placement as True as well as False and was able to get same result in both the scenarios as mentioned in the issue.", "Yes @ageron , you are right. \r\nBut I guess at least the doc does not explicitly says to execute the tensors on CPU if `tf.config.set_soft_device_placement(False)` according to the doc:\r\n\r\n> If enabled, an op will be placed on CPU if any of the following are true\r\n    1. there's no GPU implementation for the OP\r\n    2. no GPU devices are known or registered\r\n    3. need to co-locate with reftype input(s) which are from CPU\r\n\r\nMaybe one could add something to the doc explaining the behaviour if `tf.config.set_soft_device_placement()` is set to `False`?\r\n\r\nBehaviour is reproducable [here](https://colab.research.google.com/drive/1rtGjX9O_3rEI7yarMHMHBvu0l222dFXd).", "@jaingaurav any comments?", "Sorry for the delay. There have been multiple discussions about this internally. It seems that soft placement is respected by `tf.function` but not by the `tf.device` placement. We'd like to resolve this, however given it is a behavior change we're unlikely to be able to change the default in 1.0.", "Thanks @jaingaurav. I'm just thinking about TF 2.x, I understand that it must keep the same behavior in TF 1.x.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=29342\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=29342\">No</a>\n"]}, {"number": 29341, "title": "Build Issues with bazel 0.15.0, branch r1.12,no GPU", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Linux ubuntu 4.4.0-21-generic\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:N/A\r\n- TensorFlow installed from (source or binary):source\r\n- TensorFlow version: r1.12\r\n- Python version:3.6.6\r\n- Installed using virtualenv? pip? conda?:conda\r\n- Bazel version (if compiling from source):N/A\r\n- GCC/Compiler version (if compiling from source):gcc version 5.4.0 20160609\r\n- CUDA/cuDNN version:N/A\r\n- GPU model and memory:N/A\r\n\r\n\r\n\r\n**Describe the problem**\r\nCompilation fails for tensorflow branch r1.12 with the following stacktrace.\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n1) Bazel installed version - 0.15.0\r\n2)./configure \r\n    Compilation flags  \"-march=native -mssse3 -mcx16 -msse4.1 -msse4.2 -mpopcnt\"\r\n\r\n3)bazel build --config=opt --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\" //tensorflow/tools/pip_package:build_pip_package\r\n\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n\r\n**ERROR: /root/tensorflow/tensorflow/BUILD:533:1: Executing genrule //tensorflow:tf_python_api_gen_v1 failed (Exit 1)\r\nTraceback (most recent call last):\r\n  File \"/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py\", line 27, in <module>\r\n    from tensorflow.python.tools.api.generator import doc_srcs\r\n  File \"/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/__init__.py\", line 55, in <module>\r\n    'tensorflow_estimator.python.estimator'))\r\n  File \"/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/tools/component_api_helper.py\", line 85, in package_hook\r\n    set_child_as_subpackage()\r\n  File \"/root/.cache/bazel/_bazel_root/efb88f6336d9c4a18216fb94287b8d97/execroot/org_tensorflow/bazel-out/host/bin/tensorflow/create_tensorflow.python_api_1.runfiles/org_tensorflow/tensorflow/python/tools/component_api_helper.py\", line 69, in set_child_as_subpackage\r\n    os.path.join(os.path.dirname(child_pkg.__file__), \"..\"))]\r\nAttributeError: module **'tensorflow_estimator.python.estimator'** has no attribute '__file__'\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nINFO: Elapsed time: 1.055s, Critical Path: 0.55s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully**\r\n", "comments": ["@viX-shaw Can you please let us know if you followed the steps mentioned in the tensorflow website [link](https://www.tensorflow.org/install/source#tested_build_configurations). Thanks!", "@gadagashwini Yes , I followed all the steps in that tutorial. After failing to build r1.12 with bazel 0.15 may times , I tried building r1.13 with 0.19 and it worked without any additional pip or lib dependencies.\r\n", "@viX-shaw  As it is working now, are you happy for this issue to be closed?", "Sure\r\n"]}, {"number": 29340, "title": "Tensorflow 2.0 doesn't start new compute cycle with tensor.numpy()", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 18.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: n/a\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 2.0 alpha\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: n/a\r\n- **GCC/Compiler version (if compiling from source)**: n/a\r\n- **CUDA/cuDNN version**: n/a\r\n- **GPU model and memory**: n/a\r\n- **Exact command to reproduce**:\r\n\r\nif __name__ == \"__main__\":\r\n    rand: tf.Tensor = tf.random.uniform([], minval=1, maxval=10, dtype=tf.int32)\r\n    print([rand.numpy() for i in range(20)])\r\n\r\n### Describe the problem\r\nWhen you run the following (equivalent code from tensorflow 1):\r\ntf.compat.v1.disable_eager_execution()\r\nif __name__ == \"__main__\":\r\n    rand: tf.Tensor = tf.random.uniform([], minval=1, maxval=10, dtype=tf.int32)\r\n    with tf.compat.v1.Session() as sess:\r\n        print([rand.eval() for i in range(20)])\r\n\r\nYou get different output for every eval() call. This make sense since every eval() call executes the subgraph to evaluate rand node. When you execute the same code in Tensorflow 2.0, the result seems to be cached for some reason.\r\n", "comments": ["I will gladly work on this. Any tips? @jackshi0912 ", "@jackshi0912 : Please help us to know the definition of \"name\" in the code. It will surely help us to proceed further. Thanks!", "@achandraa I think it should be `if __name__ == \"__main__\"`.\r\n\r\nYou can reproduce this with `tf2` by:\r\n<pre>\r\nrand = tf.random.uniform([], minval=1, maxval=10, dtype=tf.int32)\r\nprint([rand.numpy() for i in range(20)])\r\n</pre>\r\nand\r\n<pre>\r\nrand = tf.random.uniform([], minval=1, maxval=10, dtype=tf.int32)\r\nwith tf.compat.v1.Session() as sess:\r\n    print([rand.eval() for i in range(20)])\r\n</pre>", "A broader problem that is related to the design of Eager Execution:\r\n\r\nIn tf1, you could do something like sess.run([all the nodes you want to compute]). This way you can run a single compute cycle with all the nodes evaluated.\r\nIs there a similar function in tf2? Say I have some RNG as part of my graph, I would like to grab all their values along with some results based on them all in one compute cycle. For example:\r\n\r\nrand1 = tf.random.uniform([], minval=1, maxval=10, dtype=tf.int32)\r\nrand2 = tf.random.uniform([], minval=1, maxval=10, dtype=tf.int32)\r\noutput = some_very_complicated_stack(rand1, rand2)\r\nwith tf.compat.v1.Session() as sess:\r\n    rand1_val, rand2_val, output_val = sess.run([rand1, rand2, output])\r\n\r\nThis way I know what the output value is of my system as well as the random input that went into it in the same compute cycle. I don't see a way to accomplish this in tf2 yet.", "> I will gladly work on this. Any tips? @jackshi0912\r\n\r\nIn tf1, eval() or sess.run() resets the \"readyness\" of the nodes because each call is a separate compute cycle. \r\nMy guess is that in tf2, numpy() does not reset the \"readyness\" of the nodes. It sees that the node is already evaluated with a cached value and just grabbed it.", "@jackshi0912 You should write them in a function:\r\n<pre>\r\nIn [5]: def foo():\r\n   ...:     rand1 = tf.random.uniform([], minval=1, maxval=10, dtype=tf.int32)\r\n   ...:     rand2 = tf.random.uniform([], minval=1, maxval=10, dtype=tf.int32)\r\n   ...:     output = rand1 + rand2\r\n   ...:     return rand1, rand2, output\r\n   ...:\r\n   ...:\r\n\r\nIn [6]: foo()\r\nOut[6]:\r\n(&lttf.Tensor: id=425, shape=(), dtype=int32, numpy=3>,\r\n &lttf.Tensor: id=429, shape=(), dtype=int32, numpy=7>,\r\n &lttf.Tensor: id=430, shape=(), dtype=int32, numpy=10>)\r\n\r\nIn [7]: foo()\r\nOut[7]:\r\n(&lttf.Tensor: id=437, shape=(), dtype=int32, numpy=7>,\r\n &lttf.Tensor: id=441, shape=(), dtype=int32, numpy=4>,\r\n &lttf.Tensor: id=442, shape=(), dtype=int32, numpy=11>)\r\n</pre>\r\n\r\nJust think tf2 as numpy. You cannot do what you want in numpy without repeatedly calling a function.", "Just to verify whether I am on track or not, I have tried reproducing the below code snippet on Colab with TF2.0-alpha/2.0.0-dev20190605/1.13.1 and was able to get different output each time I am executing the snippet. \r\n\r\n**On TF1.13.1 :**\r\nimport tensorflow as tf \r\ntf.compat.v1.disable_eager_execution()\r\nif ____name____ == \"____main____\":\r\n  rand: tf.Tensor = tf.random.uniform([], minval=1, maxval=10, dtype=tf.int32)\r\n  with tf.compat.v1.Session() as sess:\r\n    print([rand.eval() for i in range(20)])\r\n\r\n**On TF2.0 :**\r\nimport tensorflow as tf \r\nif ____name____ == \"____main____\":\r\n  rand: tf.Tensor = tf.random.uniform([], minval=1, maxval=10, dtype=tf.int32)\r\n  with tf.compat.v1.Session() as sess:\r\n    print([rand.eval() for i in range(20)])\r\n\r\nLet me know if I am missing out anything. Thanks!\r\n", "Thank you for this info!\r\n\r\nI'm old school graph sessions user. I still think of \"Tensors\" as a compute graph node that can be evaluated rather than actual values. It will take some time to get used to tensorflow 2.0.\r\n\r\nThanks you!", "Sure @jackshi0912 . Please feel free to connect with us with the separate issue if you are stuck anywhere.", "Are you satisfied with the resolution of your issue?<br> [Yes](https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=29340)<br> [No](https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=29340)\r\n"]}, {"number": 29339, "title": "[TF 2.0 API Docs] tf.data.Dataset.map() example has web render issues.", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/data\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/data/Dataset\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/data/TextLineDataset\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/ops/dataset_ops.py\r\n\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### The map() method call for each of these classes has an example which is not being rendered properly.\r\n\r\nThis is what is intended by the docstring\r\n\r\n```\r\n   # NOTE: The following examples use `{ ... }` to represent the\r\n    # contents of a dataset.\r\n    # Each element is a `tf.Tensor` object.\r\n    a = { 1, 2, 3, 4, 5 }\r\n    # `map_func` takes a single argument of type `tf.Tensor` with the same\r\n    # shape and dtype.\r\n    result = a.map(lambda x: ...)\r\n```\r\n\r\nThis is what gets rendered to the web.  It looks like the back tick references have an issue.\r\n\r\n```\r\n# NOTE: The following examples use `{ ... }` to represent the\r\n# contents of a dataset.\r\n# Each element is a <a href=\"../../tf/Tensor\"><code>tf.Tensor</code></a> object.\r\na = { 1, 2, 3, 4, 5 }\r\n# `map_func` takes a single argument of type <a href=\"../../tf/Tensor\"><code>tf.Tensor</code></a> with the same\r\n# shape and dtype.\r\nresult = a.map(lambda x: ...)\r\n```\r\n\r\n\r\n### Submit a pull request?\r\n\r\nNo, the docstring looks correct.  I don't know how to fix the error.", "comments": ["Why are there reference links inside the code after all? I'm confused. \r\nYou can't click them anyway, right?", "The code creates documentation via doc strings.", "I don\u2019t know if the code links work or not.  That is a good point.", "The issue also exists in r2.0 https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset#for_example_5", "Regarding the links in the code block, we auto-link backticked TF symbols, so it's probably written as \\`tf.Tensor\\`. We probably shouldn't expand links in code blocks, if we can detect that.", "> Regarding the links in the code block, we auto-link backticked TF symbols, so it's probably written as `tf.Tensor`. We probably shouldn't expand links in code blocks, if we can detect that.\r\n\r\nCould we check for \"#\" in the same line? In that way we could know that it is a code comment and thus, not link it.", "Yes, that would work.", "I would like to work on it if that is okay with you and if you could point me in the right direction as I don't know where this is done.", "Hey, you can definitely work on it. Thanks.\r\n\r\nTo start, changing the regular expression here (https://github.com/tensorflow/docs/blob/master/tools/tensorflow_docs/api_generator/parser.py#L118) to not consider lines that start with '#' should solve it.\r\n\r\nGood luck and let me know if you have any questions :)", "I have opened a PR. I believe that should do the work.\r\n\r\nThanks!", "I think this issue could be closed now as it is solved!", "Thank you, Anestis!"]}, {"number": 29338, "title": "[TF 2.0 API Docs] tf.data.Dataset and tf.data.experimental.CsvDataset list_files", "body": "\r\n## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/data/Dataset#list_files\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/data/experimental/CsvDataset#list_files\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/\r\n\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### list_files() routine for both classes use the same bit of code to describe how to use the method.  The descriptive text is written in docstring and it looks like this\r\nExample:\r\n      If we had the following files on our filesystem:\r\n        - /path/to/dir/a.txt\r\n        - /path/to/dir/b.py\r\n        - /path/to/dir/c.py\r\n      If we pass \"/path/to/dir/*.py\" as the directory, the dataset\r\n      would produce:\r\n        - /path/to/dir/b.py\r\n        - /path/to/dir/c.py\r\n\r\nHowever, when rendered it is all one line without the indentation or bullet points.  So it looks like this:\r\n\r\nIf we had the following files on our filesystem: - /path/to/dir/a.txt - /path/to/dir/b.py - /path/to/dir/c.py If we pass \"/path/to/dir/*.py\" as the directory, the dataset would produce: - /path/to/dir/b.py - /path/to/dir/c.py\r\n\r\n\r\n\r\n\r\nThis should be corrected.\r\n\r\n", "comments": ["Ahh, this also causes problems with TextLineDataset.list_files() routine.  Its probably in every subclass method as well. ie. TFRecordDataset", "@netskink,\r\nI see that in the latest version of the documentation the pages are rendered as expected i.e. with bullet points and indentation. \r\n\r\n- https://www.tensorflow.org/api_docs/python/tf/data/Dataset#list_files\r\n- https://www.tensorflow.org/api_docs/python/tf/data/experimental/CsvDataset#list_files\r\n\r\nClosing this issue as it is resolved. Please feel free to re-open if mistaken. Thanks!"]}, {"number": 29337, "title": "[TF 2.0 API Docs] tf.data.Dataset", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/data/Dataset\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/data/ops/dataset_ops.py\r\n\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Need an overall example of how to use tf.data.Dataset\r\n\r\nIt is a struggle to relate the dataset with the keras model code.  The model.fit() doc describes how to use a tf.dataset as input but without experimentation its hard to discern the correct format of the dataset.\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?  Yes.\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly? Yes\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? Yes.\r\n\r\n### Usage example\r\n\r\nIs there a usage example?  No.  I added an example for the common use case of most users to use the dataset with a simple model.fit call for keras.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? No. yes, it would be helpful.\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue?  Yes.\r\n\r\n[[TF 2.0 API Docs] tf.data Add pointer to tutorials which work with r2.0 #29323](https://github.com/tensorflow/tensorflow/pull/29323)", "comments": ["Referencing the corresponding PR request : #29323 ", "Is this issue still valid? The attached pull requests looks like it's a bit out of sync.\r\n\r\nFor the TF2 ref docs, we now automatically include links to usage in our guide and tutorials. See here: https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset\r\n\r\nThese examples are easier for us to test and maintain then any snippets included in the doc strings.", "I thought it was closed already\n\nOn Fri, Jul 12, 2019 at 13:16 Billy Lamberta <notifications@github.com>\nwrote:\n\n> Is this issue still valid? The attached pull requests looks like it's a\n> bit out of sync.\n>\n> For the TF2 ref docs, we now automatically include links to usage in our\n> guide and tutorials. See here:\n> https://www.tensorflow.org/versions/r2.0/api_docs/python/tf/data/Dataset\n>\n> These examples are easier for us to test and maintain then any snippets\n> included in the doc strings.\n>\n> \u2014\n> You are receiving this because you authored the thread.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/29337?email_source=notifications&email_token=ABBXUHCXVIIIHIFTRGZKKJTP7C377A5CNFSM4HSDPWY2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODZ2KVGI#issuecomment-510962329>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABBXUHHBHYMGTNAV3DWOSBTP7C377ANCNFSM4HSDPWYQ>\n> .\n>\n-- \nRocking the roll like a natural man!\n", "Thanks for confirming"]}, {"number": 29336, "title": "Tensorflow won't import in python", "body": "All I have done is try to import tensorflow\r\nI am using windows 8.1\r\n\r\nWhenever I try to import Tensorflow i get the same error.\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Program Files\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\r\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])\r\n  File \"C:\\Program Files\\Python37\\lib\\imp.py\", line 296, in find_module\r\n    raise ImportError(_ERR_MSG.format(name), name=name)\r\nImportError: No module named '_pywrap_tensorflow'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Program Files\\Python37\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 66, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Program Files\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 28, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"C:\\Program Files\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\r\n    import _pywrap_tensorflow\r\nModuleNotFoundError: No module named '_pywrap_tensorflow'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Keegan\\AppData\\Local\\atom\\app-1.37.0\\PriceAdderUpper.py\", line 1, in <module>\r\n    import tensorflow\r\n  File \"C:\\Program Files\\Python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Program Files\\Python37\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 72, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Program Files\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\r\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])\r\n  File \"C:\\Program Files\\Python37\\lib\\imp.py\", line 296, in find_module\r\n    raise ImportError(_ERR_MSG.format(name), name=name)\r\nImportError: No module named '_pywrap_tensorflow'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Program Files\\Python37\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 66, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Program Files\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 28, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"C:\\Program Files\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\r\n    import _pywrap_tensorflow\r\nModuleNotFoundError: No module named '_pywrap_tensorflow'\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nI did the pip3 install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.0.0-py3-none-any.whl install method and I am using python 3.7.3", "comments": ["@TiredPast Did you follow these [steps](https://www.tensorflow.org/install/pip) to install tensorflow? Thanks! ", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n"]}, {"number": 29335, "title": "[TF 2.0 API Docs] tf.image.central_crop", "body": "Added a usage example image.central_crop under image_ops_impl.py. The issue has been raised and is under this link https://github.com/tensorflow/tensorflow/issues/29334", "comments": []}, {"number": 29334, "title": "[TF 2.0 API Docs] tf.image.central_crop", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/image/central_crop\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/image_ops_impl.py\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Usage example\r\n\r\nNo usage example provided\r\n\r\n### Submit a pull request?\r\n\r\nYes", "comments": ["Closing the issue since PR is merged to master. Thanks!"]}, {"number": 29333, "title": "[TF 2.0 API Docs] tf.image.adjust_saturation", "body": "Updated adjust_saturation by adding a usage example in the docstring in image_ops_impl.py. Also added a raise InvalidArgumentError for incorrect shape in the docstring. The issue has been raised and is provided in this link https://github.com/tensorflow/tensorflow/issues/29332", "comments": []}, {"number": 29332, "title": "[TF 2.0 API Docs] tf.image.adjust_saturation", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/image/adjust_saturation\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/image_ops_impl.py\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Raises listed and defined\r\n\r\nRaises are not listed\r\n\r\n### Usage example\r\n\r\nNo usage example has been provided\r\n\r\n### Submit a pull request?\r\n\r\nYes\r\nhttps://github.com/tensorflow/tensorflow/pull/29333", "comments": ["Closing this issue since the associated PR has been merged. Feel free to reopen if the problem still persists. Thanks!"]}, {"number": 29331, "title": "[TF 2.0 API Docs] tf.image.adjust_jpeg_quality", "body": "Updated adjust_jpeg_quality by adding a usage example in the docstring in image_ops_impl.py. Added raises that were happening but not occurring in the docstring. The issue has been raised and is provided in this link https://github.com/tensorflow/tensorflow/issues/29330", "comments": []}, {"number": 29330, "title": "[TF 2.0 API Docs] tf.image.adjust_jpeg_quality", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/versions/master/api_docs/python/tf/image/adjust_jpeg_quality\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/ops/image_ops_impl.py\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Raises listed and defined\r\n\r\nRaises are not listed and defined.\r\n\r\n### Usage example\r\n\r\nNo usage example has been provided\r\n\r\n### Submit a pull request?\r\n\r\nYes\r\nhttps://github.com/tensorflow/tensorflow/pull/29331", "comments": ["Closing this issue since the associated PR has been merged. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=29330\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=29330\">No</a>\n"]}, {"number": 29329, "title": "tf.Module doesn't recognise non trainable variables from keras layers [TF 2.0]", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 16.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): tf-nightly-2.0-preview==2.0.0.dev20190602\r\n- Python version: 3.6\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: CPU\r\n- GPU model and memory: \r\n\r\nWhen using Keras layers inside `tf.Module` module and setting `trainable=False` in the keras layer doesn't results in non-trainable variables in the `tf.Module` scope. \r\nThe below example code module `M`'s `trainable_variables` should return 6, But it returns 8. \r\n\r\n**Code to reproduce the issue**\r\n```import tensorflow as tf\r\n\r\n\r\nclass M(tf.Module):\r\n\r\n    def __init__(self):\r\n        super(M, self).__init__()\r\n        self.list = []\r\n        self.list.append([tf.keras.layers.Dense(5, trainable=False), tf.keras.layers.Dense(5)])\r\n        self.list.append([tf.keras.layers.Dense(5), tf.keras.layers.Dense(5)])\r\n\r\n    def __call__(self, inputs):\r\n        output = inputs\r\n        for l_list in self.list:\r\n            for l in l_list:\r\n                output = l(output)\r\n        return output\r\n\r\nm = M()\r\nm(tf.ones((10, 10)))\r\nGot: print(len(m.trainable_variables))  = 8\r\n\r\nExpected: print(len(m.trainable_variables)) = 6\r\n```", "comments": ["I could reproduce the reported issue here on tf-nightly-2.0-preview version. Thanks! ", "Thanks for reporting the issue. Here is some context about the root cause. \r\n\r\nThere are two \"trainable\" concept here, one is that whether the variable itself is trainable, the second is that whether the layer contains the variable is trainable. The first one is immutable, while the second is mutable. The layer/container's trainable state will affect the return value for trainable/non_trainable_variable.\r\n\r\nWhen creating a variable, user could do layer.add_variable(trainable=False), that will force the variable to be non-trainable, regardless whether the layer itself is trainable or not. \r\n\r\nIn the case that the layer is not trainable, we will create the variable as trainable variable. We check layer.trainable state in the layer.trainable_weights/non_trainable_weights to return the correct value.\r\n\r\nIn your specific case, tf.module just recursively visit all its attribute, and find all the variable like object. It discards the container/layer trainable state, and relying on only the variable trainable information, which is why it returns 8 here.\r\n\r\nA simple workaround is to change the base class for M to be layer, which will correctly check the sub layer trainable state, while we are fixing the issue on the tf.module side.", "Also adding @tomhennigan who is the owner of tf.Module", "Unfortunately, the trainable_variable definition for keras.layer is different from tf.module. keras.layer will respect both \"trainable\" concept, while tf.module only respect the variable level \"trainable\" state.", "+1 to what @qlzh727 said. One option if you want to have the trainable behavior from Keras is to swap from `tf.Module` to `tf.keras.layers.Layer` as your base class. Keras layers support being deeply nested so the rest of your code works unchanged:\r\n\r\n```python\r\nclass M(tf.keras.layers.Layer):\r\n  # .. same as your example ..\r\n\r\nprint(len(m.trainable_variables))  # 6\r\n```\r\n\r\nI think in general it's worth pointing out that there are a few places where Keras and TF don't agree on the definition of trainable, `tf.Module` is consistent with these other parts of TF. A few examples (ignoring TF1 and global collections etc):\r\n\r\n```python\r\nprint(sum(1 for v in m.variables if v.trainable))  # 8\r\n\r\nwith tf.GradientTape() as tape:\r\n  m(tf.ones((10, 10)))\r\n  print(len(tape.watched_variables()))  # 8\r\n```", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=29329\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=29329\">No</a>\n", "I think this issue should not be closed, until it fixed in `tf.Module`. If `tf.Module` can't work properly with `tf.keras.layers`; what's the purpose of it?", "Not all TensorFlow users use Keras. `tf.Module` is a simple, framework independent base class for stateful objects in TensorFlow. It enables checkpointing, and variable/module tracking. For more motivation please see the RFC tensorflow/community#56.\r\n\r\nKeras has it's own definition of trainable/non-trainable variables (defined in terms of trainable/non-trainable `Layer`s), if you want to use the Keras definition then please use Keras directly. The good news is that since 23c8fd4ca Keras `Layer` extends `tf.Module` so if subclassing `Layer` is a more appropriate choice you don't lose the benefits enabled by `tf.Module`."]}]