[{"number": 44339, "title": "Tensorflow auto killed my training processing.", "body": "\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 18.04):\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version (use command below): tf-nightly-2.4.0\r\n- Python version:\r\n- Bazel version (if compiling from source): 3.7.4\r\n- GCC/Compiler version (if compiling from source): 7.3.0\r\n- CUDA/cuDNN version: CUDA 11.0 / cuDNN 8.0.4\r\n- GPU model and memory: RTX3090 24GB\r\n- RAM: 32GB\r\n\r\n\r\nI'm training my Faster RCNN model.And I train it in my old GPU(1080 8GB).It didn't occur any error.Last week, I changed to RTX3090 and environment. When I run my code, I can run normal in first one hour. After that keras show the code runtime getting longer. I don't get any information, just get 'killed'.Someone saies  maybe high RAM usage, and I watch my memory, it auto increasing indeed. But I can't find code bug.\r\nSo I want to know if tf-nightly-gpu version bug?Or GPU environment setting?\r\n\r\nThanks~\r\n", "comments": ["@Runist,\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the output log. Thanks!", "> @Runist,\r\n> In order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the output log. Thanks!\r\n\r\nYeah, this is my [code](https://github.com/Runist/Faster_RCNN).I am not sure this format is your want.", "> @Runist,\r\n> In order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the output log. Thanks!\r\n\r\nBy the way, I didn't get any output log or information about my error.The only thing that happened was that the program was running slower and slower, each training step took longer and longer, the available memory was getting smaller and smaller until it was used up, and then \"killed\" was printed on the screen.", "I tried to reduce GPU memory, but this error still exists.However I also test it in my DenseNet demo.It works normal.", "@Runist,\r\nWhile trying to download the `faster_rcnn.h5` weights file I am facing a 404 error, please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/58ab1c9e00ca68a24845e93524531661/44339.ipynb). \r\n\r\nAlso, try setting a hard limit on the total GPU memory as mentioned in [this guide](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth) and let us know if it helps. Thanks! ", "> @Runist,\r\n> While trying to download the `faster_rcnn.h5` weights file I am facing a 404 error, please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/58ab1c9e00ca68a24845e93524531661/44339.ipynb).\r\n> \r\n> Also, try setting a hard limit on the total GPU memory as mentioned in [this guide](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth) and let us know if it helps. Thanks!\r\n\r\nBecause the code could not work normal, I didn't get right model, I just reserved a spot.And I have try to set GPU memory to 7GB, it is same as RTX 1080, it also lead to RAM usage growth.\r\nSo I also change RTX 1080 to test, I want to know it is GPU problem or my code problem.Even RTX 1080 it also will lead to RAM usage growth.But RTX 1080 doesn't fill up memory quickly because of its small memory and slow computation.\r\nLast week, I find the problem is \"train_on_batch\", I commented out all the code except for the TF.data input section.Just for loop this, it doesn't lead RAM usage growth.When I add \"train_on_batch\" and test.The RAM usage growth.\r\nSo maybe will help you.I updated my code once with using python generator input data.If you want to use tf.data  version, you should download the previous version.", "Apologies for the delay in response. Is this still an issue? Can you try with latest tf-nightly (2.5 version) or with recently released TF 2.4-rc2 version for cuda 11.0 support?", "> Apologies for the delay in response. Is this still an issue? Can you try with latest tf-nightly (2.5 version) or with recently released TF 2.4-rc2 version for cuda 11.0 support?\r\n\r\nI use rtx3090 by tf-nightly-2.5 and cuda 11.1. Cuda 11.0 can't work. I can avoid memory leaky via **tf.Gradient**.So I guarantee it was **train_on_batch**.And I test it in tf-1.13, it work normally.I also goole my problem, I find same [issue#33030](https://github.com/tensorflow/tensorflow/issues/33030#issuecomment-589533406).", "Thanks for sharing your investigation. Should we close this issue since you have found a workaround?\r\n", "Casually, if you have more important to do you can close it, but I still think you should open it. BecauseI found that TF =2.0.0 train_on_batch existed memory leak, but now it is TF-nightly =2.5.0. There is still a problem.I just found a solution, but that doesn't mean the train_on_batch memory leak problem is solved.", "Could you please test it in Tensorflow 2.7 and let us know if the problem still exists. Thanks!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44339\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44339\">No</a>\n"]}, {"number": 44338, "title": "remove large loop warning", "body": "The sentence throws a large unrolled loop warning which is produced by autograph when there are 3000+ ```self._created_variables```, disable autograph to fix it.\r\n```\r\nWARNING: Large unrolled loop detected. Did you mean to use a TF loop? The following ops were created after iteration 3002: (<tf.Operation 'VarIsInitializedOp_3000/resource' type=Placeholder>, <tf.Operation 'VarIsInitializedOp_3000' type=VarIsInitializedOp>, <tf.Operation 'LogicalAnd_3000' type=LogicalAnd>)\r\nSee https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/autograph/g3doc/reference/common_errors.md#warning-large-unrolled-loop-detected\r\nLocation:\r\n  File \"keras/train.py\", line 215, in <module>\r\n    app.run(main)\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 299, in run\r\n    _run_main(main, args)\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/absl/app.py\", line 250, in _run_main\r\n    sys.exit(main(argv))\r\n\r\n  File \"keras/train.py\", line 209, in main\r\n    validation_steps=(FLAGS.eval_samples // FLAGS.batch_size))\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 108, in _method_wrapper\r\n    return method(self, *args, **kwargs)\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\", line 1098, in fit\r\n    tmp_logs = train_function(iterator)\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 780, in __call__\r\n    result = self._call(*args, **kwds)\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\", line 904, in _call\r\n    return function_lib.defun(fn_with_cond)(*canon_args, **canon_kwds)\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 2828, in __call__\r\n    graph_function, args, kwargs = self._maybe_define_function(args, kwargs)\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 3213, in _maybe_define_function\r\n    graph_function = self._create_graph_function(args, kwargs)\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\", line 3075, in _create_graph_function\r\n    capture_by_value=self._capture_by_value),\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\", line 986, in func_graph_from_py_func\r\n    func_outputs = python_func(*func_args, **func_kwargs)\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\", line 969, in wrapper\r\n    user_requested=True,\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py\", line 596, in converted_call\r\n    result = converted_f(*effective_args, **kwargs)\r\n\r\n  File \"/tmp/tmpyw1arwrw.py\", line 42, in tf__fn_with_cond\r\n    ag__.for_stmt(ag__.ld(self)._created_variables, None, loop_body, get_state_1, set_state_1, ('condition',), {'iterate_names': 'wr'})\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/operators/control_flow.py\", line 368, in for_stmt\r\n    _py_for_stmt(iter_, extra_test, body, None, None)\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/operators/control_flow.py\", line 397, in _py_for_stmt\r\n    body(target)\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/operators/control_flow.py\", line 384, in protected_body\r\n    after_iteration()\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/operators/control_flow.py\", line 834, in after_iteration\r\n    did_warn = self._verify_inefficient_unroll()\r\n\r\n  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/operators/control_flow.py\", line 817, in _verify_inefficient_unroll\r\n    '', self.iterations, new_ops, '\\n'.join(traceback.format_stack()))\r\n```", "comments": ["@mdanatg `fn_with_cond` doesn't seem like it needs Autograph so lgtm.  What do you think?", "> I prefer to fix the limit in autograph (or remove the check altogether, since it's rarely useful), as other users will encounter it as well. I'll send a separate change so this PR will not be required.\r\n> \r\n> @fsx950223 how many iterations did you have in this particular case?\r\n\r\n3800", "Thanks! I'll raise it to 10000 for now, and we can further bump it in the future.", "> Thanks! I'll raise it to 10000 for now, and we can further bump it in the future.\r\n\r\nI got the warning when I train the efficientdet-d0.\r\nAnd efficientdet-d7 has many more variables than efficientdet-d0(Maybe several times).\r\nIn fact, I have avoided it by building the model manually(Decrease uninitialized variables).", "That's good to know. So perhaps 50000 is a better value. The limit is controlled by [this constant](https://github.com/tensorflow/tensorflow/blob/30994be76cfc11bbb91bce5819dac1fbc38a212a/tensorflow/python/autograph/operators/control_flow.py#L93). There is no upper limit for it; the only reason it's small is to trigger quickly in the event of an infinite loop. Should you encounter it again, feel free to send a PR with an increase."]}, {"number": 44335, "title": "[CherryPick 2.4] Add -no_cuda11 tag to the ubuntu pip build scripts.", "body": "PiperOrigin-RevId: 339067352\nChange-Id: I935694b8ad0a1f6c788f55db5370513446251bc9", "comments": []}, {"number": 44334, "title": "Fix CI on Windows", "body": "py3.7 passed previous tests so we're picking the py37 changes from #44271 and then trying to fix forward from where py37 failed", "comments": []}, {"number": 44333, "title": "why gradient of clip_by_value(x) is zero, when x is outside of range?", "body": "I agree with derivative of mathematical notation,\r\nbecause output value is not changing when x is outside of range\r\n\r\n![xnviewmp_2020-10-26_22-02-22](https://user-images.githubusercontent.com/8076202/97212824-54538080-17da-11eb-9d23-d76828e3cbd5.jpg)\r\n\r\nBut let look at it from the ML perspective.\r\n\r\nLet `x = -2`\r\nwe can just simply decide `x = x+1` \r\n\r\nthus `Clip(x, -1, 1) = x + 1 = -1`\r\n\r\ngradient for `x+y` is `1` for both\r\n\r\nTherefore gradient of clip(x) should be 1 for any value and range ?\r\n", "comments": ["If you want to preserve the gradient you could take a look at https://www.tensorflow.org/probability/api_docs/python/tfp/math/clip_by_value_preserve_gradient", "thanks"]}, {"number": 44331, "title": "Non-deterministic results if using Functional model creation style on GPU", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Arch Linux, kernel 5.8.14-arch1-1\r\n- TensorFlow installed from (source or binary): python-tensorflow-opt-cuda package\r\n- TensorFlow version (use command below): unknown 2.3.1\r\n- Python version: Python 3.8.6\r\n- CUDA/cuDNN version: CUDA 11.1.0, cuDNN 8.0.4\r\n- GPU model and memory: Nvidia GeForce RTX 2070 8gb\r\n\r\n**Describe the current behavior**\r\n\r\nWhen using Functional interface to compose the Model results are slightly non-deterministic after several rounds of training. I've included a script that highlights the differences. If we use the Functional model creation method, results are sometimes different between runs - but if we use Sequential model, the results are always the same.\r\n\r\nNon-determinism seems to be related to GPU - running with `CUDA_VISIBLE_DEVICES=-1` makes output deterministic.\r\n\r\n**Describe the expected behavior**\r\n\r\nExpected results to be deterministic for both Functional and Sequential models (or non-deterministic for both, if there are some fundamental issues with GPU optimizations). [TensoFlow Determinism](https://github.com/NVIDIA/framework-determinism) page suggests that TensorFlow 2.3 should be deterministic by default.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\n```python\r\nimport hashlib\r\n\r\n# generate some training data\r\nimport numpy\r\nnumpy.random.seed(542326146)\r\nD = numpy.random.uniform(size=(64, 8)).astype(\"float32\")\r\nL = numpy.random.binomial(n=1, p=0.5, size=64).astype(\"float32\")\r\n\r\n# ensure that data is always the same\r\nm = hashlib.sha256()\r\nm.update(D.tobytes())\r\nassert(m.hexdigest() == \"96291d29976308b4f9b4a9514466a44f4d45b2944bd149951e017688d56aa380\")\r\nm = hashlib.sha256()\r\nm.update(L.tobytes())\r\nassert(m.hexdigest() == \"f51400856346bd43b2f04d81f7177fab8844f572ea6a281d1a429e26713fb4f4\")\r\n\r\nimport tensorflow as tf\r\ntf.random.set_seed(542326146)\r\nimport tensorflow.keras.layers as layers\r\n\r\nuse_functional = True # change to False to switch to Sequential model and get deterministic results\r\nif use_functional:\r\n    # Functional\r\n    input_layer = layers.Input(shape=(8))\r\n    dense1_layer = layers.Dense(8, activation=tf.nn.relu, kernel_initializer=tf.keras.initializers.he_normal())(input_layer)\r\n    output_layer = layers.Dense(2, activation=tf.nn.softmax, kernel_initializer=tf.keras.initializers.he_normal())(dense1_layer)\r\n    model = tf.keras.models.Model(inputs=[input_layer], outputs=[output_layer])\r\nelse:\r\n    # Sequential\r\n    model = tf.keras.Sequential([\r\n        layers.Input(shape=(8)),\r\n        layers.Dense(8, activation=tf.nn.relu, kernel_initializer=tf.keras.initializers.he_normal()),\r\n        layers.Dense(2, activation=tf.nn.softmax, kernel_initializer=tf.keras.initializers.he_normal()),\r\n    ])\r\n\r\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\r\nmodel.fit(x=D, y=L, epochs=4, verbose=0)\r\n\r\n# get a hash of model weights\r\nm = hashlib.sha256()\r\nfor w in model.get_weights():\r\n    m.update(w.tobytes())\r\nprint(m.hexdigest())\r\n\r\n```\r\n\r\nRun with:\r\n```bash\r\nfor i in $(seq 16); do python train.py; done\r\n```\r\n\r\nExample of output on my machine:\r\n```\r\nc61bf7b08f9ecaa84afa9be3f9910f4e7533faa393ec2138c1d47d62913b3c19\r\n097afc63c6796b52dbcf4d9216fcaf56122fe6a77ffc997c35d538f644061f3e\r\n097afc63c6796b52dbcf4d9216fcaf56122fe6a77ffc997c35d538f644061f3e\r\n17f78cb99882f3b9d33fd90cb714e43800a1547d878f801e85044d8ba41650a0\r\nc61bf7b08f9ecaa84afa9be3f9910f4e7533faa393ec2138c1d47d62913b3c19\r\nc61bf7b08f9ecaa84afa9be3f9910f4e7533faa393ec2138c1d47d62913b3c19\r\nc61bf7b08f9ecaa84afa9be3f9910f4e7533faa393ec2138c1d47d62913b3c19\r\nc61bf7b08f9ecaa84afa9be3f9910f4e7533faa393ec2138c1d47d62913b3c19\r\n1e3d2b84fc8de77db548a805a78e4206b30f3e4726c49ec4f16bcc681ddb27f9\r\n097afc63c6796b52dbcf4d9216fcaf56122fe6a77ffc997c35d538f644061f3e\r\nc61bf7b08f9ecaa84afa9be3f9910f4e7533faa393ec2138c1d47d62913b3c19\r\n097afc63c6796b52dbcf4d9216fcaf56122fe6a77ffc997c35d538f644061f3e\r\n097afc63c6796b52dbcf4d9216fcaf56122fe6a77ffc997c35d538f644061f3e\r\nc61bf7b08f9ecaa84afa9be3f9910f4e7533faa393ec2138c1d47d62913b3c19\r\nc61bf7b08f9ecaa84afa9be3f9910f4e7533faa393ec2138c1d47d62913b3c19\r\n08d1b83a3548d180d2940e380a276ff3861604514bf9a857632a3770fc460dd7\r\n```", "comments": ["I tracked the issue to StatelessTruncatedNormal call (it is called by HeUniform initializer when layers.Dense sets itself up). \r\n\r\nHere's the updated reproducer:\r\n\r\n```python\r\nimport hashlib\r\n\r\nSEED = 542326146\r\n\r\n# generate some training data\r\nimport numpy\r\nnumpy.random.seed(SEED)\r\nD = numpy.random.uniform(size=(64, 8)).astype(\"float32\")\r\nL = numpy.random.binomial(n=1, p=0.5, size=64).astype(\"float32\")\r\n\r\n\r\nimport tensorflow as tf\r\ntf.random.set_seed(SEED)\r\n\r\n\r\nfrom tensorflow.python.keras import backend\r\nfrom tensorflow.python.ops import stateless_random_ops\r\n# commenting this out makes results deterministic\r\nstateless_random_ops.stateless_truncated_normal(shape=(32,32), mean=0.0, stddev=0.2, dtype=backend.floatx(), seed=[SEED, 0])\r\n\r\n\r\nimport tensorflow.keras.layers as layers\r\nmodel = tf.keras.Sequential([\r\n    layers.Input(shape=(8)),\r\n    layers.Dense(8, activation=tf.nn.relu, kernel_initializer=tf.keras.initializers.he_normal()),\r\n    layers.Dense(2, activation=tf.nn.softmax, kernel_initializer=tf.keras.initializers.he_normal()),\r\n])\r\n\r\nmodel.compile(optimizer='adam', loss='sparse_categorical_crossentropy')\r\nmodel.fit(x=D, y=L, epochs=4, verbose=0)\r\n\r\n# get a hash of model weights\r\nm = hashlib.sha256()\r\nfor w in model.get_weights():\r\n    m.update(w.tobytes())\r\nprint(m.hexdigest())\r\n```", "I have tried in colab with TF version 2.3 and was able to reproduce the issue. Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/6ede8802aa538ea0a2deb128f761f62f/untitled88.ipynb?authuser=1). Thanks!", "Was able to reproduce your issue in Tensorflow GPU 2.5, please find the gist [here](https://colab.research.google.com/gist/sachinprasadhs/64703145bc240238f02a47c252a987ab/44331.ipynb). Thanks!", "@sachinprasadhs Actually it looks that the issue wasn't reproduced this time - the printed hex is the same each time (I copied the output and filtered out the garbage):\r\n```\r\n$ xclip -sel c -o | grep -v '^2021' | grep -v WARNING | grep -v coreClock | grep -v pciBusID\r\nc61bf7b08f9ecaa84afa9be3f9910f4e7533faa393ec2138c1d47d62913b3c19\r\nc61bf7b08f9ecaa84afa9be3f9910f4e7533faa393ec2138c1d47d62913b3c19\r\nc61bf7b08f9ecaa84afa9be3f9910f4e7533faa393ec2138c1d47d62913b3c19\r\nc61bf7b08f9ecaa84afa9be3f9910f4e7533faa393ec2138c1d47d62913b3c19\r\nc61bf7b08f9ecaa84afa9be3f9910f4e7533faa393ec2138c1d47d62913b3c19\r\nc61bf7b08f9ecaa84afa9be3f9910f4e7533faa393ec2138c1d47d62913b3c19\r\nc61bf7b08f9ecaa84afa9be3f9910f4e7533faa393ec2138c1d47d62913b3c19\r\nc61bf7b08f9ecaa84afa9be3f9910f4e7533faa393ec2138c1d47d62913b3c19\r\nc61bf7b08f9ecaa84afa9be3f9910f4e7533faa393ec2138c1d47d62913b3c19\r\nc61bf7b08f9ecaa84afa9be3f9910f4e7533faa393ec2138c1d47d62913b3c19\r\nc61bf7b08f9ecaa84afa9be3f9910f4e7533faa393ec2138c1d47d62913b3c19\r\nc61bf7b08f9ecaa84afa9be3f9910f4e7533faa393ec2138c1d47d62913b3c19\r\nc61bf7b08f9ecaa84afa9be3f9910f4e7533faa393ec2138c1d47d62913b3c19\r\nc61bf7b08f9ecaa84afa9be3f9910f4e7533faa393ec2138c1d47d62913b3c19\r\nc61bf7b08f9ecaa84afa9be3f9910f4e7533faa393ec2138c1d47d62913b3c19\r\nc61bf7b08f9ecaa84afa9be3f9910f4e7533faa393ec2138c1d47d62913b3c19\r\n```", "Could you please try this to get the deterministic result, https://www.tensorflow.org/api_docs/python/tf/config/experimental/enable_op_determinism.\r\nNote: This API is new and is available in `tf-nightly`", "Thank you, enable_op_determinism ensures stable results for this reproducer! Closing the issue.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44331\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44331\">No</a>\n"]}, {"number": 44330, "title": "TensorFlow 1.14 or 1.15 not detecting the Titan XP GPU. TensorFlow 2.x detectes the same Titan XP GPU !", "body": "**System information**\r\n- Have a simple code : to check the GPU and tested with the TensorFlow 1.14, 1.15 and TensorFlow 2.2 and 2.3. Code is shared below.\r\n\r\n```\r\nimport tensorflow as tf\r\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\r\ntf.config.list_physical_devices('GPU')\r\n```\r\n\r\n### **_Output for TensorFlow 1.14 and TensorFlow 1.15_**\r\n\r\n` python\r\nPython 3.6.9 (default, Oct  8 2020, 12:12:24) \r\n[GCC 8.4.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n/home/rr/TF_1_14/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\n/home/rr/TF_1_14/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\r\n/home/rr/TF_1_14/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\r\n/home/rr/TF_1_14/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\r\n/home/rr/TF_1_14/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\r\n/home/rr/TF_1_14/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\r\n/home/rr/TF_1_14/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\n/home/rr/TF_1_14/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\r\n/home/rr/TF_1_14/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\r\n/home/rr/TF_1_14/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\r\n/home/rr/TF_1_14/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\r\n/home/rr/TF_1_14/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\r\n>>> print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\r\n2020-10-26 11:56:38.543745: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcuda.so.1\r\n2020-10-26 11:56:38.570403: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:1005] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-10-26 11:56:38.570983: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1640] Found device 0 with properties: \r\nname: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582\r\npciBusID: 0000:01:00.0\r\n2020-10-26 11:56:38.571042: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcudart.so.10.0'; dlerror: libcudart.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64\r\n2020-10-26 11:56:38.571087: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcublas.so.10.0'; dlerror: libcublas.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64\r\n2020-10-26 11:56:38.571131: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcufft.so.10.0'; dlerror: libcufft.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64\r\n2020-10-26 11:56:38.571170: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcurand.so.10.0'; dlerror: libcurand.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64\r\n2020-10-26 11:56:38.571212: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcusolver.so.10.0'; dlerror: libcusolver.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64\r\n2020-10-26 11:56:38.571256: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Could not dlopen library 'libcusparse.so.10.0'; dlerror: libcusparse.so.10.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64\r\n2020-10-26 11:56:38.573773: I tensorflow/stream_executor/platform/default/dso_loader.cc:42] Successfully opened dynamic library libcudnn.so.7\r\n2020-10-26 11:56:38.573792: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1663] Cannot dlopen some GPU libraries. Skipping registering GPU devices...\r\n**_Num GPUs Available:  0_**\r\n`\r\n\r\n### **_Output for TensorFlow 2.x**\r\n` python\r\nPython 3.6.9 (default, Oct  8 2020, 12:12:24) \r\n[GCC 8.4.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n2020-10-26 11:46:11.025219: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n>>> print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\r\n2020-10-26 11:46:21.325573: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\r\n2020-10-26 11:46:21.349766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-10-26 11:46:21.350134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:01:00.0 name: TITAN Xp computeCapability: 6.1\r\ncoreClock: 1.582GHz coreCount: 30 deviceMemorySize: 11.91GiB deviceMemoryBandwidth: 510.07GiB/s\r\n2020-10-26 11:46:21.350166: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-10-26 11:46:21.351260: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-10-26 11:46:21.352291: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-10-26 11:46:21.352479: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-10-26 11:46:21.353628: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-10-26 11:46:21.354306: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-10-26 11:46:21.356778: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-10-26 11:46:21.356860: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-10-26 11:46:21.357494: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-10-26 11:46:21.357935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1858] Adding visible gpu devices: 0\r\n**_Num GPUs Available:  1_**\r\n`\r\n\r\n\r\n\r\n- OS Platform and Distribution: **Ubuntu 18.04**\r\n- TensorFlow installed from binary via pip \r\n- TensorFlow version (use command below):1.14, 1.15, 2.2 and 2.3\r\n- Python version: 3.6\r\n- CUDA/cuDNN version: 10.1\r\n- GPU model and memory: Titan XP\r\n\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"` : `v1.14.0-rc1-22-gaf24dc91b5 1.14.0`\r\n\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`:` v2.3.0-54-gfcc4b966f1 2.3.1`\r\n\r\n**Describe the current behavior**\r\nThe TensorFlow 1.14 and TensorFlow 1.15 not able to detect the GPU or not able use the GPU. In the same system in different virtual environment, TensorFlow 2.2 or TensorFlow 2.3 is able to detect GPU and able to use it as shown above. \r\n\r\n**Describe the expected behavior**\r\nAll TensorFlow should be able to detect Titan XP and use the GPU. \r\n\r\n", "comments": ["Please switch to TF 2.x. We no longer release code on the 1.x branches.", "> Please switch to TF 2.x. We no longer release code on the 1.x branches.\r\n\r\nmy code is based on TF 1.14 running with TitanXP. I had to format the system and tried to reinstall all SW's. Hence requesting for support to run TF 1.14 or TF 1.15 to run with GPU Titan XP. ", "We can no longer support TF 1.x code. It's a matter of headcount and tech evolution.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Has there been any progress on this front? I am experiencing the same issue.\r\n1.15 on Titan XP. Migrating to 2.x is not an option at this point", "TF 1.x is no longer supported. We cannot do any change to code on 1.x."]}, {"number": 44329, "title": "RAM exhaustion while CPU taining doesn't throw exception", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (use command below): 2.3.0\r\n- Python version: 3.8.2\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: N/A\r\n- GPU model and memory: N/A\r\n\r\n**Describe the current behavior**\r\nWhile training on CPU, memory exhaustion doesn't throw any exceptions, just warnings.\r\n\r\n**Describe the expected behavior**\r\nRAM memory exhaustion will throw exception.\r\n\r\n**Standalone code to reproduce the issue**\r\n\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\nimport tensorflow as tf \r\nimport numpy as np\r\n\r\nfashion_mnist = tf.keras.datasets.fashion_mnist\r\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\r\n\r\nmodel = tf.keras.Sequential([\r\n    tf.keras.layers.Flatten(input_shape=(28, 28)),\r\n    tf.keras.layers.Dense(2048 * 2048, activation='relu'),\r\n    tf.keras.layers.Dense(10)\r\n])\r\n\r\nmodel.compile(optimizer='adam',\r\n        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n        metrics=['accuracy'])\r\n\r\nmodel.fit(train_images, train_labels, epochs=1, batch_size=100)\r\n```\r\n\r\n**Other info / logs**\r\n```\r\n2020-10-24 18:31:34.045523: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1757] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\nSkipping registering GPU devices...\r\n2020-10-24 18:31:34.058101: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-10-24 18:31:34.070957: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-10-24 18:31:34.075908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]\r\n2020-10-24 18:31:34.078952: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\r\n2020-10-24 18:31:43.412026: I tensorflow/core/profiler/lib/profiler_session.cc:133] Profiler session started.\r\n2020-10-24 18:31:43.420340: I tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1391] Profiler found 1 GPUs\r\n2020-10-24 18:31:43.429960: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cupti64_110.dll'; dlerror: cupti64_110.dll not found\r\n2020-10-24 18:31:43.444796: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'cupti.dll'; dlerror: cupti.dll not found\r\n2020-10-24 18:31:43.452632: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1441] function cupti_interface_->Subscribe( &subscriber_, (CUpti_CallbackFunc)ApiCallback, this)failed with error CUPTI could not be loaded or symbol could not be found.\r\n2020-10-24 18:31:43.467569: E tensorflow/core/profiler/internal/gpu/cupti_tracer.cc:1522] function cupti_interface_->Finalize()failed with error CUPTI could not be loaded or symbol could not be found.\r\n2020-10-24 18:31:44.057786: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 1)\r\nEpoch 1/4\r\nWARNING:tensorflow:From D:\\yolov3-to-tf\\python_server\\server\\venv_server\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:574: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse fn_output_signature instead\r\n2020-10-24 18:32:20.966123: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 2215116800 exceeds 10% of free system memory.\r\n2020-10-24 18:32:22.455623: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 2215116800 exceeds 10% of free system memory.\r\n2020-10-24 18:32:36.990875: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 2215116800 exceeds 10% of free system memory.\r\n2020-10-24 18:32:37.683320: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 2225779200 exceeds 10% of free system memory.\r\n```\r\n\r\n", "comments": ["@jvishnuvardhan \r\nI ran the code shared and colab crashes,please find the [gist here](https://colab.research.google.com/gist/Saduf2019/66c5fc071b37a028017538ba39bbb626/untitled450.ipynb).", "Colab crashes because tensorflow will not throw any exception and will not release allocated RAM, that's the problem.", "@KacperPaszkowski I agree with you that colab is crashing. But, it is crashing due to too many trainable parameters.\r\n\r\nI changed your model to have only 2048 units for Dense layer (instead of 2048*2048).\r\n`tf.keras.layers.Dense(2048 * 2048, activation='relu')`\r\nChanged the above line to\r\n`tf.keras.layers.Dense(2048, activation='relu')`\r\n\r\nWith the above change everything works as expected. \r\n\r\nYour original model has ~3.3 billion trainable parameters. Please check the shared gist. When I reduced dense units to 2048, then we have ~1.6 million. I am not sure whether this was  a typo or your use-case requires so many dense units. If you need so many dense units then use gpu.\r\n\r\n Please take a look at the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/bc68cbf4108c13f98ed2e7feac2ecb52/untitled450.ipynb).  Thanks!\r\n\r\nPlease verify once and close the issue if this was resolved for you. Thanks!", "I dig a little bit deeper into this and I think I know what is going on. Problem is that when you try to train model with too big batch size on CPU, tensorflow tries to allocate whole RAM which leads to freezing of PC and doesn't allow tensorflow to throw any error or clean RAM. I found solution by limiting python RAM usage, so tensorflow will not use whole RAM and will raise exception as excepted.", "I am closing this issue as this was resolved. Please feel free to reopen if I am mistaken. Thanks!"]}, {"number": 44328, "title": "Tensorflow DLL leaks references to itself, preventing the DLL from unloading", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes (see below).\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10 Pro 64bit (version 2004)\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: N/A.\r\n- TensorFlow installed from (source or binary): Binary.\r\n- TensorFlow version (use command below): 2.3.1 (CPU only).\r\n- Python version: N/A.\r\n- Bazel version (if compiling from source): N/A.\r\n- GCC/Compiler version (if compiling from source): N/A.\r\n- CUDA/cuDNN version: N/A.\r\n- GPU model and memory: N/A.\r\n\r\n**Describe the current behavior**\r\n\r\nWe link to the Tensorflow DLL dynamically (i.e., using ``LoadLibrary()`` directly on ``tensorflow.dll``, or on another DLL that itself links to Tensorflow). We use the Tensorflow C API to run some data through a model. Eventually, when processing is complete, the DLL is unlinked (i.e., using ``FreeLibrary()`` directly on ``tensorflow.dll``, or the other DLL that itself links to Tensorflow). For some reason unknown to us, at this stage the operating system (Windows) still believes the DLL is in use (the reference count is non-zero), thus any static resource allocated internally by Tensorflow is (probably?) not freed.\r\n\r\nThe code example below illustrates this problem.\r\n\r\nIf, within the same process, and under certain conditions, the procedure above is repeated a second time (link again to TF, run a model, etc.), we experience an access violation error in ``TF_SessionRun()``. We are not able to produce a sample code that reproduces this last error, as it only occurs when our software is used by a third party application (the source code of which we do not have access to). However, we noticed that the error would no longer happen if we forcefully unlink the Tensorflow DLL by repeatedly calling ``FreeLibrary(\"tensorflow.dll\")`` until the OS holds no reference to it (this requires some 30-40 calls to ``FreeLibrary()``!). This implies that some internal state of Tensorflow from the first \"link/process/unlink\" run is still in use, but is somehow invalid.\r\n\r\n**Describe the expected behavior**\r\n\r\nA cycle of  ``LoadLibrary()`` / run TF / ``FreeLibrary()`` should leave the Tensorflow DLL reference count unchanged (i.e., equal to zero if TF is not used anywhere else in the program). On ``FreeLibrary()``, any internal resource held by TF should be freed (provided TF is not in use by other parts of the program). Loading the DLL again should result in a blank new internal state of TF.\r\n\r\n**Standalone code to reproduce the issue**\r\n```c++\r\n#include <iostream>\r\n#include <exception>\r\n#include <string>\r\n#include <windows.h>\r\n#include <tlhelp32.h>\r\n\r\n// Helper function to count the number of references to tensorflow.dll\r\nstd::size_t GetTensorflowRefCount() {\r\n    auto handle = GetCurrentProcessId();\r\n    auto s = CreateToolhelp32Snapshot(TH32CS_SNAPMODULE, handle);\r\n\r\n    std::size_t value = 0;\r\n    MODULEENTRY32 me32;\r\n    me32.dwSize = sizeof(MODULEENTRY32);\r\n    Module32First(s, &me32);\r\n    do {\r\n        if (std::strcmp(me32.szModule, \"tensorflow.dll\") == 0) {\r\n            value = me32.GlblcntUsage;\r\n            break;\r\n        }\r\n    } while(Module32Next(s, &me32));\r\n\r\n    CloseHandle(s);\r\n    return value;\r\n}\r\n\r\n// Manually import Tensorflow some types and functions\r\ntypedef enum TF_Code {\r\n  TF_OK = 0,\r\n  TF_CANCELLED = 1,\r\n  TF_UNKNOWN = 2,\r\n  TF_INVALID_ARGUMENT = 3,\r\n  TF_DEADLINE_EXCEEDED = 4,\r\n  TF_NOT_FOUND = 5,\r\n  TF_ALREADY_EXISTS = 6,\r\n  TF_PERMISSION_DENIED = 7,\r\n  TF_UNAUTHENTICATED = 16,\r\n  TF_RESOURCE_EXHAUSTED = 8,\r\n  TF_FAILED_PRECONDITION = 9,\r\n  TF_ABORTED = 10,\r\n  TF_OUT_OF_RANGE = 11,\r\n  TF_UNIMPLEMENTED = 12,\r\n  TF_INTERNAL = 13,\r\n  TF_UNAVAILABLE = 14,\r\n  TF_DATA_LOSS = 15,\r\n} TF_Code;\r\n\r\nusing TF_Status = void;\r\nusing TF_Graph = void;\r\nusing TF_SessionOptions = void;\r\nusing TF_Session = void;\r\n\r\nTF_Code            (*TF_GetCode)(TF_Status*);\r\nTF_Status*         (*TF_NewStatus)();\r\nTF_Graph*          (*TF_NewGraph)();\r\nTF_SessionOptions* (*TF_NewSessionOptions)();\r\nTF_Session*        (*TF_NewSession)(TF_Graph*, TF_SessionOptions*, TF_Status*);\r\nvoid               (*TF_DeleteSession)(TF_Session*, TF_Status*);\r\nvoid               (*TF_DeleteSessionOptions)(TF_SessionOptions*);\r\nvoid               (*TF_DeleteGraph)(TF_Graph*);\r\nvoid               (*TF_DeleteStatus)(TF_Status*);\r\n\r\nvoid ImportTensorflow(HINSTANCE handle) {\r\n#define LOAD_FUNCTION(Function) Function = reinterpret_cast<decltype(Function)>(GetProcAddress(handle, #Function))\r\n    LOAD_FUNCTION(TF_GetCode);\r\n    LOAD_FUNCTION(TF_NewStatus);\r\n    LOAD_FUNCTION(TF_NewGraph);\r\n    LOAD_FUNCTION(TF_NewSessionOptions);\r\n    LOAD_FUNCTION(TF_NewSession);\r\n    LOAD_FUNCTION(TF_DeleteSession);\r\n    LOAD_FUNCTION(TF_DeleteSessionOptions);\r\n    LOAD_FUNCTION(TF_DeleteGraph);\r\n    LOAD_FUNCTION(TF_DeleteStatus);\r\n#undef LOAD_FUNCTION\r\n}\r\n\r\n// Helper function to throw on error\r\nvoid TFStatusCheck(TF_Status* status) {\r\n    if (TF_GetCode(status) != TF_OK) {\r\n        throw std::runtime_error(\"Error in tensorflow\");\r\n    }\r\n}\r\n\r\nint main() {\r\n    // Load Tensorflow DLL and import functions\r\n    std::cout << \"initial: \" << GetTensorflowRefCount() << std::endl;\r\n    auto handle = LoadLibrary(\"tensorflow.dll\");\r\n    std::cout << \"DLL loaded: \" << GetTensorflowRefCount() << std::endl;\r\n    ImportTensorflow(handle);\r\n    std::cout << \"functions imported: \" << GetTensorflowRefCount() << std::endl;\r\n\r\n    // Create a dummy session\r\n    TF_Status* status = nullptr;\r\n    TF_Graph* graph = nullptr;\r\n    TF_SessionOptions* options = nullptr;\r\n    TF_Session* session = nullptr;\r\n\r\n    try\r\n    {\r\n        status = TF_NewStatus();\r\n        std::cout << \"TF_NewStatus: \" << GetTensorflowRefCount() << std::endl;\r\n        graph = TF_NewGraph();\r\n        std::cout << \"TF_NewGraph: \" << GetTensorflowRefCount() << std::endl;\r\n        options = TF_NewSessionOptions();\r\n        std::cout << \"TF_NewSessionOptions: \" << GetTensorflowRefCount() << std::endl;\r\n        session = TF_NewSession(graph, options, status);\r\n        TFStatusCheck(status);\r\n        std::cout << \"TF_NewSession: \" << GetTensorflowRefCount() << std::endl;\r\n    }\r\n    catch (const std::exception& e)\r\n    {\r\n        std::cout << e.what() << std::endl;\r\n    }\r\n\r\n    // Free allocated resources\r\n    if (session) TF_DeleteSession(session, status);\r\n    std::cout << \"TF_DeleteSession: \" << GetTensorflowRefCount() << std::endl;\r\n    if (options) TF_DeleteSessionOptions(options);\r\n    std::cout << \"TF_DeleteSessionOptions: \" << GetTensorflowRefCount() << std::endl;\r\n    if (graph)   TF_DeleteGraph(graph);\r\n    std::cout << \"TF_DeleteGraph: \" << GetTensorflowRefCount() << std::endl;\r\n    if (status)  TF_DeleteStatus(status);\r\n    std::cout << \"TF_DeleteStatus: \" << GetTensorflowRefCount() << std::endl;\r\n\r\n    // Free DLL\r\n    FreeLibrary(handle);\r\n    std::cout << \"DLL unloaded: \" << GetTensorflowRefCount() << std::endl;\r\n\r\n    return 0;\r\n}\r\n```\r\n\r\n**Other info / logs**\r\nSimply compile the above on Windows with ``clang++ test.cpp -o test``.\r\nOutput on my computer:\r\n```\r\ninitial: 0\r\nDLL loaded: 1\r\nfunctions imported: 1\r\nTF_NewStatus: 1\r\nTF_NewGraph: 2\r\nTF_NewSessionOptions: 2\r\n2020-10-26 13:38:48.388408: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2\r\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\r\n2020-10-26 13:38:48.398942: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x1ffcd6eeec0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\r\n2020-10-26 13:38:48.399288: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\r\nTF_NewSession: 41\r\nTF_DeleteSession: 40\r\nTF_DeleteSessionOptions: 40\r\nTF_DeleteGraph: 40\r\nTF_DeleteStatus: 40\r\nDLL unloaded: 39\r\n```\r\nNotice the following:\r\n - ``TF_NewGraph`` generates a new reference to the DLL\r\n - ``TF_NewSession`` generates 39(!) new references to the DLL\r\n - ``TF_DeleteSession`` removes one reference\r\n - We are left with 39 leaked references, which we did not create explicitly in our program.\r\n - We were able to reproduce this with a number of TF versions (1.15, 2.1.1, 2.3.1), with or without GPU support.", "comments": ["This is intended behavior. Several internal shared objects in TF provide functionality while they are being loaded. This is achieved by static initializers and global data.\r\n\r\nWe do not support unloading TF shared libraries. Doing so would lead to a lot of bugs and sudden behavior changes.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44328\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44328\">No</a>\n", "I am not sure I understand this reasoning. Static initializers and global data are destroyed when a process is terminated, and this does not lead to bugs and sudden behavior changes, because this data cannot be used afterwards anyway. The same holds for DLL unloading. From the point of view of Tensorflow, unloading the DLL should have the same effect as terminating the process, static data should be deleted automatically on unload without you having to do anything. Loading the DLL back again should have the same effect as starting a new process.\r\n\r\nSee this simple DLL example (compile with ``clang++ -shared dll.cpp -o dll.dll``):\r\n```c++\r\n#include <iostream>\r\n#include <windows.h>\r\n\r\nstruct foo {\r\n    foo() { std::cout << \"construct \" << this << std::endl; }\r\n    ~foo() { std::cout << \"destruct \" << this << std::endl; }\r\n    void baz() { std::cout << \"use \" << this << std::endl; }\r\n};\r\n\r\nextern \"C\" {\r\n__declspec(dllexport) void bar() {\r\n    static foo tmp;\r\n    tmp.baz();\r\n}\r\n}\r\n\r\nBOOL APIENTRY DllMain(HMODULE hModule, DWORD dwReasonForCall, LPVOID lpReserved)\r\n{\r\n    return TRUE;\r\n}\r\n```\r\n\r\n... and a program that uses it (compile with ``clang++ test_dll.cpp -o test_dll.exe``):\r\n```c++\r\n#include <iostream>\r\n#include <string>\r\n#include <windows.h>\r\n#include <tlhelp32.h>\r\n\r\n// Helper function to count the number of references to dll.dll\r\nstd::size_t GetDLLRefCount() {\r\n    auto handle = GetCurrentProcessId();\r\n    auto s = CreateToolhelp32Snapshot(TH32CS_SNAPMODULE, handle);\r\n\r\n    std::size_t value = 0;\r\n    MODULEENTRY32 me32;\r\n    me32.dwSize = sizeof(MODULEENTRY32);\r\n    Module32First(s, &me32);\r\n    do {\r\n        if (std::strcmp(me32.szModule, \"dll.dll\") == 0) {\r\n            value = me32.GlblcntUsage;\r\n            break;\r\n        }\r\n    } while(Module32Next(s, &me32));\r\n\r\n    CloseHandle(s);\r\n    return value;\r\n}\r\n\r\nvoid (*bar)();\r\n\r\nvoid ImportDLL(HINSTANCE handle) {\r\n#define LOAD_FUNCTION(Function) Function = reinterpret_cast<decltype(Function)>(GetProcAddress(handle, #Function))\r\n    LOAD_FUNCTION(bar);\r\n#undef LOAD_FUNCTION\r\n}\r\n\r\nint main() {\r\n    // Load dll DLL and import funcitons\r\n    std::cout << \"initial: \" << GetDLLRefCount() << std::endl;\r\n    auto handle = LoadLibrary(\"dll.dll\");\r\n    std::cout << \"DLL loaded: \" << GetDLLRefCount() << std::endl;\r\n    ImportDLL(handle);\r\n    std::cout << \"functions imported: \" << GetDLLRefCount() << std::endl;\r\n\r\n    // Use DLL\r\n    bar();\r\n    std::cout << \"DLL used: \" << GetDLLRefCount() << std::endl;\r\n\r\n    // Free DLL\r\n    FreeLibrary(handle);\r\n    std::cout << \"DLL unloaded: \" << GetDLLRefCount() << std::endl;\r\n\r\n    return 0;\r\n}\r\n```\r\n\r\nThis prints, on my machine:\r\n```\r\ninitial: 0\r\nDLL loaded: 1\r\nfunctions imported: 1\r\nconstruct 00007FFF3BBC41D0\r\nuse 00007FFF3BBC41D0\r\nDLL used: 1\r\ndestruct 00007FFF3BBC41D0\r\nDLL unloaded: 0\r\n```\r\n\r\nSee how the destructor of the static variable ``bar::tmp`` is automatically called when the DLL is unloaded. This is the expected behavior, and allows me to re-load the DLL afterwards if I need to, with a brand new static state as if I just started the process.", "FYI, I just got around to test an alternative library to Tensorflow, PyTorch, and it does not suffer from this problem. I can load/unload their DLL as in the simple example above. This suggests to me that Tensorflow is doing something unconventional, and possibly incorrect.", "TensorFlow also takes into account the security aspect of the framework. Hence, it has a much safer design, that prevents scenarios which seem to work but later would be exploitable/cause hard to debug bugs.\r\n\r\nIf you don't care about these aspects and other frameworks allow you to use an unsafe design, by all means.", "Thank you for your reply. Could you elaborate (or point me to a link/code) on that additional safety, and how this relates to not being able to unload the DLL? It might help us solve the problem on our end.\r\n\r\nIronically, it was precisely Tensorflow's inability to unload that has caused us a hard-to-debug bug. To this date we also have no correct solution for it either, because our own design relies on that ability for all our dependencies.", "Imagine code taking a pointer to objects from the DLL and what happens when the DLL gets unloaded", "That would be a programming error, or a breach of contract. Much like using a ``TF_Session*`` after it has been deleted by ``TF_DeleteSession()``. In both cases the user is in control of when these pointers are used, and when they are no longer valid (when deleted explicitly, or when unloading the DLL), so any misuse is solely the user's fault.\r\n\r\nThis safety risk didn't prevent you from exposing the ``TF_DeleteSession()`` function (and other functions to delete resources), because resources should be freed when no longer used. The same goes with DLLs.", "We no longer use Tensorflow, so this is no longer relevant to us. However, if anyone else stumbles upon this problem and is willing to do something about it, here is a pointer to a possible solution inspired by [this blog article](https://www.forrestthewoods.com/blog/debugging-a-dynamic-library-that-wouldnt-unload/).\r\n\r\nI just learned today that, on Windows, `std::thread` increases the refcount of the DLL it is created in, until the thread terminates (see [here](https://devblogs.microsoft.com/oldnewthing/20131105-00/?p=2733) for the rationale; I guess that's a common thing people do in the Windows world, and is not limited to just `std::thread`?). I assume Tensorflow has some sort of global thread pool, but a) it does not handle `DllMain` events or any other resource management mechanism to automatically close the thread pool when no external reference to Tensorflow exists, and b) it offers no way to manually close the thread pool from the public C API either. Therefore, it is not possible to delete these thread objects, hence the DLL refcount can never go down to zero. "]}, {"number": 44327, "title": "cannot see keras properly in tf-nightly-gpu install", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 10\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): binary\r\n- TensorFlow version: tf-nightly-gpu\r\n- Python version: 3.7\r\n- Installed using virtualenv? pip? conda?: pip\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 11.1\r\n- GPU model and memory: nVidia MX250, 4GB\r\n\r\n\r\n\r\n**Describe the problem**\r\nI installed tf-nightly-gpu in my environment and first ran into a missing dll issue (#44291) which was resolved. Now I can import keras but do not seem to see it or use anything inside it. See commands below\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\n\r\nfrom tensorflow import keras\r\nfrom keras import regularizers\r\nTraceback (most recent call last):\r\nFile \"\", line 1, in\r\nModuleNotFoundError: No module named 'keras'\r\ndir()\r\n['annotations', 'builtins', 'doc', 'loader', 'name', 'package', 'spec', 'keras', 'tensorflow']\r\n\r\nAs you can see, keras is visible as a package after importing it, but does not seem to work properly.\r\n\r\n**Any other info / logs**\r\nInclude any logs or source code that would be helpful to diagnose the problem. If including tracebacks, please include the full traceback. Large logs and files should be attached.\r\n", "comments": ["@apurvakalia,\r\nI was able to import the modules without any issues, please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/88250876a6c9d55b367affcac8afb26b/44327.ipynb). Could you please check if you are facing the same issue in a virtual environment?\r\n\r\nAlso, try importing `tensorflow.keras` instead of `keras` and check if it works. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44327\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44327\">No</a>\n"]}, {"number": 44326, "title": "Error while converting to tflite model", "body": "I am trying to convert a trained keras model to tflite. However, I am facing the error shown below. Is this likely because of the Albert layer in the model?\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04\r\n- TensorFlow installed from (source or binary): pip\r\n- TensorFlow version (or github SHA if from source): 2.3.0\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(text_classifier_model)\r\ntflite_model = converter.convert()\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nException                                 Traceback (most recent call last)\r\n~/anaconda3/lib/python3.8/site-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n    195     try:\r\n--> 196       model_str = wrap_toco.wrapped_toco_convert(model_flags_str,\r\n    197                                                  toco_flags_str, input_data_str,\r\n\r\n~/anaconda3/lib/python3.8/site-packages/tensorflow/lite/python/wrap_toco.py in wrapped_toco_convert(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n     31   \"\"\"Wraps TocoConvert with lazy loader.\"\"\"\r\n---> 32   return _pywrap_toco_api.TocoConvert(\r\n     33       model_flags_str,\r\n\r\nException: fail to open input file\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nConverterError                            Traceback (most recent call last)\r\n<ipython-input-5-c548bab089a8> in <module>\r\n----> 1 tflite_model = converter.convert()\r\n\r\n~/anaconda3/lib/python3.8/site-packages/tensorflow/lite/python/lite.py in convert(self)\r\n    785         Invalid quantization parameters.\r\n    786     \"\"\"\r\n--> 787     saved_model_convert_result = self._convert_as_saved_model()\r\n    788     if saved_model_convert_result:\r\n    789       return saved_model_convert_result\r\n\r\n~/anaconda3/lib/python3.8/site-packages/tensorflow/lite/python/lite.py in _convert_as_saved_model(self)\r\n    767         self._trackable_obj = _load(self.saved_model_dir,\r\n    768                                     self._saved_model_tags)\r\n--> 769         return super(TFLiteKerasModelConverterV2,\r\n    770                      self).convert(meta_graph.graph_def, input_tensors,\r\n    771                                    output_tensors)\r\n\r\n~/anaconda3/lib/python3.8/site-packages/tensorflow/lite/python/lite.py in convert(self, graph_def, input_tensors, output_tensors)\r\n    627 \r\n    628     # Converts model.\r\n--> 629     result = _toco_convert_impl(\r\n    630         input_data=graph_def,\r\n    631         input_tensors=input_tensors,\r\n\r\n~/anaconda3/lib/python3.8/site-packages/tensorflow/lite/python/convert.py in toco_convert_impl(input_data, input_tensors, output_tensors, enable_mlir_converter, *args, **kwargs)\r\n    567       input_tensors, output_tensors, *args, **kwargs)\r\n    568   debug_info_str = debug_info.SerializeToString() if debug_info else None\r\n--> 569   data = toco_convert_protos(\r\n    570       model_flags.SerializeToString(),\r\n    571       toco_flags.SerializeToString(),\r\n\r\n~/anaconda3/lib/python3.8/site-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n    200       return model_str\r\n    201     except Exception as e:\r\n--> 202       raise ConverterError(str(e))\r\n    203 \r\n    204   if distutils.spawn.find_executable(_toco_from_proto_bin) is None:\r\n\r\nConverterError: fail to open input file```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n\r\n```\r\n# Architecture of text_classifier_model\r\n```\r\n__________________________________________________________________________________________________\r\nLayer (type)                    Output Shape         Param #     Connected to                     \r\n==================================================================================================\r\ninput_title_word_ids (InputLaye [(None, 35)]         0                                            \r\n__________________________________________________________________________________________________\r\ninput_title_mask (InputLayer)   [(None, 35)]         0                                            \r\n__________________________________________________________________________________________________\r\nsegment_title_ids (InputLayer)  [(None, 35)]         0                                            \r\n__________________________________________________________________________________________________\r\ninput_text_word_ids (InputLayer [(None, 250)]        0                                            \r\n__________________________________________________________________________________________________\r\ninput_text_mask (InputLayer)    [(None, 250)]        0                                            \r\n__________________________________________________________________________________________________\r\nsegment_text_ids (InputLayer)   [(None, 250)]        0                                            \r\n__________________________________________________________________________________________________\r\nalbert_layer (KerasLayer)       [(None, 768), (None, 11683584    input_title_word_ids[0][0]       \r\n                                                                 input_title_mask[0][0]           \r\n                                                                 segment_title_ids[0][0]          \r\n                                                                 input_text_word_ids[0][0]        \r\n                                                                 input_text_mask[0][0]            \r\n                                                                 segment_text_ids[0][0]           \r\n__________________________________________________________________________________________________\r\ntitle_repeat_vector (RepeatVect (None, 1, 768)       0           albert_layer[0][0]               \r\n__________________________________________________________________________________________________\r\ntext_repeat_vector (RepeatVecto (None, 1, 768)       0           albert_layer[1][0]               \r\n__________________________________________________________________________________________________\r\nglobal_average_pooling1d (Globa (None, 768)          0           title_repeat_vector[0][0]        \r\n__________________________________________________________________________________________________\r\nglobal_average_pooling1d_1 (Glo (None, 768)          0           text_repeat_vector[0][0]         \r\n__________________________________________________________________________________________________\r\nconcatenate (Concatenate)       (None, 1536)         0           global_average_pooling1d[0][0]   \r\n                                                                 global_average_pooling1d_1[0][0] \r\n__________________________________________________________________________________________________\r\nrepeat_vector (RepeatVector)    (None, 1, 1536)      0           concatenate[0][0]                \r\n__________________________________________________________________________________________________\r\nbidirectional (Bidirectional)   (None, 150)          725850      repeat_vector[0][0]              \r\n__________________________________________________________________________________________________\r\ndense (Dense)                   (None, 64)           9664        bidirectional[0][0]              \r\n__________________________________________________________________________________________________\r\ndropout (Dropout)               (None, 64)           0           dense[0][0]                      \r\n__________________________________________________________________________________________________\r\ndense_1 (Dense)                 (None, 1)            65          dropout[0][0]     \r\n\r\n```\r\n# Standalone code to reproduce issues\r\n\r\n[Colab Notebook](https://colab.research.google.com/drive/11Jwz2YV1h1EniI4vVwaxyf3jXRNUSNys?usp=sharing)", "comments": ["@AdirthaBorgohain Can you please share a standalone code to reproduce the issue? Thanks!", "> @AdirthaBorgohain Can you please share a standalone code to reproduce the issue? Thanks!\r\n\r\nI have added in a colab noteboook to my initial post.  Please let me know if you need anything else. Thanks.", "Any update?\r\n", "@AdirthaBorgohain Could you try conversion with tf-nightly version? ", "@abattery I ran the code in recent `tf-nightly`. [Here](https://colab.research.google.com/gist/jvishnuvardhan/4e14888100e5e35ede1a1b5bc37f98b0/tflite.ipynb) is the gist for your reference.\r\nOne of the main error looks like `tf.Einsum`. Please check part of the error trace below.\r\n\r\n> 'tf.Einsum' op is neither a custom op nor a flex op\r\n\r\n\r\n```\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:2342: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\r\n  warnings.warn('`Model.state_updates` will be removed in a future version. '\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:1395: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\r\n  warnings.warn('`layer.updates` will be removed in a future version. '\r\nWARNING:absl:Found untraced functions such as forward_gru_layer_call_fn, forward_gru_layer_call_and_return_conditional_losses, backward_gru_layer_call_fn, backward_gru_layer_call_and_return_conditional_losses, gru_cell_1_layer_call_fn while saving (showing 5 of 145). These functions will not be directly callable after loading.\r\nINFO:tensorflow:Assets written to: /tmp/tmp9n8xjicj/assets\r\nINFO:tensorflow:Assets written to: /tmp/tmp9n8xjicj/assets\r\n---------------------------------------------------------------------------\r\nException                                 Traceback (most recent call last)\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n    212                                                  debug_info_str,\r\n--> 213                                                  enable_mlir_converter)\r\n    214       return model_str\r\n\r\n6 frames\r\nException: <unknown>:0: error: loc(callsite(callsite(callsite(callsite(callsite(callsite(\"embedding_projection/einsum/Einsum@__inference_albert_transformer_encoder_layer_call_and_return_conditional_losses_11038\" at \"albert_transformer_encoder/StatefulPartitionedCall@__inference_model_layer_call_and_return_conditional_losses_11140\") at \"StatefulPartitionedCall@__inference_model_layer_call_fn_11174\") at \"StatefulPartitionedCall@__inference_restored_function_body_13318\") at \"model/albert_layer/StatefulPartitionedCall@__inference__wrapped_model_14265\") at \"StatefulPartitionedCall@__inference_signature_wrapper_17324\") at \"StatefulPartitionedCall\")): 'tf.Einsum' op is neither a custom op nor a flex op\r\n<unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from\r\n```", "@jvishnuvardhan this error can be resolved via enabling SELECT TF op option.", "Thanks @abattery. Forgot to enable it.\r\n\r\nWhen I enable `tf.lite.OpsSet.SELECT_TF_OPS`, there is no error. Please check the [gist here](https://colab.research.google.com/gist/jvishnuvardhan/674a74838edfd8dfb292e30a02684803/tflite.ipynb).\r\n\r\nI am closing this issue as this was resolved. Please feel free to reopen if I am mistaken. Thanks!"]}, {"number": 44325, "title": "Add gpu implementation of ResourceSparseApplyAdadelta Op for issue #2\u2026", "body": "# This commit is related to issue #2314 and #30537.\r\n## When I want to use Adadelta Optimizer in GPU, I encounted the following error\uff1a\r\nError environment info:\r\n- Ubuntu 16\r\n- Python 3.6\r\n- Tensorflow 2.3\r\n- CUDA 10.1\r\n- GPU Tesla V100\r\n- GPU Driver 396.37\r\n\r\n```\r\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute  \r\ninputs, attrs, num_outputs)  \r\ntensorflow.python.framework.errors\\_impl.InvalidArgumentError: Cannot assign a device for operation Adadelta/Adadelta/update/Unique: Could not satisfy explicit device specification '' because the node {{colocation\\_node Adadelta/Adadelta/update/Unique}} was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/device:GPU:0'. All available devices \\[/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA\\_CPU:0, /job:localhost/replica:0/task:0/device:XLA\\_GPU:0, /job:localhost/replica:0/task:0/device:GPU:0\\].  \r\nColocation Debug Info:  \r\nColocation group had the following types and supported devices:  \r\nRoot Member(assigned\\_device\\_name\\_index\\_=2 requested\\_device\\_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned\\_device\\_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource\\_device\\_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported\\_device\\_types_=\\[CPU\\] possible\\_devices\\_=\\[\\]  \r\nIdentity: GPU CPU XLA\\_CPU XLA\\_GPU  \r\nReadVariableOp: GPU CPU XLA\\_CPU XLA\\_GPU  \r\nResourceSparseApplyAdadelta: CPU  \r\nUnique: GPU CPU  \r\nShape: GPU CPU XLA\\_CPU XLA\\_GPU  \r\n\\_Arg: GPU CPU XLA\\_CPU XLA_GPU  \r\nConst: GPU CPU XLA\\_CPU XLA\\_GPU  \r\nStridedSlice: GPU CPU XLA\\_CPU XLA\\_GPU  \r\nUnsortedSegmentSum: GPU CPU XLA\\_CPU XLA\\_GPU\r\n\r\nColocation members, user-requested devices, and framework assigned devices, if any:  \r\nwide\\_deep\\_8564 (_Arg) framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0  \r\nadadelta\\_adadelta\\_update\\_resourcesparseapplyadadelta\\_accum (_Arg) framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0  \r\nadadelta\\_adadelta\\_update\\_resourcesparseapplyadadelta\\_accum\\_update (\\_Arg) framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0  \r\nAdadelta/Adadelta/update/Unique (Unique)  \r\nAdadelta/Adadelta/update/Shape (Shape)  \r\nAdadelta/Adadelta/update/strided_slice/stack (Const)  \r\nAdadelta/Adadelta/update/strided\\_slice/stack\\_1 (Const)  \r\nAdadelta/Adadelta/update/strided\\_slice/stack\\_2 (Const)  \r\nAdadelta/Adadelta/update/strided_slice (StridedSlice)  \r\nAdadelta/Adadelta/update/UnsortedSegmentSum (UnsortedSegmentSum)  \r\nAdadelta/Adadelta/update/ResourceSparseApplyAdadelta (ResourceSparseApplyAdadelta)  \r\nwide\\_deep/StatefulPartitionedCall/embedding\\_lookup\\_sparse\\_30/embedding\\_lookup\\_sparse/embedding_lookup/ReadVariableOp (ReadVariableOp)  \r\nFunc/wide\\_deep/StatefulPartitionedCall/input/\\_148 (Identity) /job:localhost/replica:0/task:0/device:GPU:0\r\n\r\n     [[{{node Adadelta/Adadelta/update/Unique}}]] [Op:__inference_train_step_9850]\r\n```\r\n\r\nTo fix this, I wrote the GPU implementation for ResourceSparseApplyAdadelta Op and tested in r2.3 branch.\r\nTest Environment info:\r\n- Docker Image: tensorflow/tensorflow:nightly-custom-op-gpu-ubuntu16\r\n- Ubuntu 16\r\n- Python 3.6\r\n- Tensorflow r2.3\r\n- CUDA 10.1\r\n- cuDNN 7\r\n- Cuda Compute Capabilities 7.0 (Tesla V100 Driver 396.37)\r\n- GCC 7\r\n- bazel 3.1.0\r\n", "comments": []}, {"number": 44324, "title": "Updated README.md", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F44324) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot  I signed it!", "We will not be encouraging one liner grammatical changes as this is expensive process, thank you for your interest.\r\nCC @mihaimarusea", "@gbaned  help me to contribute to tensorflow"]}, {"number": 44323, "title": "add gpu implementation for ResourceSparseApplyAdadelta for issue #231\u2026", "body": "When I want to use Adadelta Optimizer in GPU, I encounted the following error\uff1a\r\nError Env info:\r\n- Ubuntu 16\r\n- Python 3.6\r\n- Tensorflow 2.3\r\n- CUDA 10.1\r\n- GPU Tesla V100 \r\n- GPU Driver 396.37\r\n```\r\nFile \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\", line 60, in quick_execute  \r\ninputs, attrs, num_outputs)  \r\ntensorflow.python.framework.errors\\_impl.InvalidArgumentError: Cannot assign a device for operation Adadelta/Adadelta/update/Unique: Could not satisfy explicit device specification '' because the node {{colocation\\_node Adadelta/Adadelta/update/Unique}} was colocated with a group of nodes that required incompatible device '/job:localhost/replica:0/task:0/device:GPU:0'. All available devices \\[/job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:XLA\\_CPU:0, /job:localhost/replica:0/task:0/device:XLA\\_GPU:0, /job:localhost/replica:0/task:0/device:GPU:0\\].  \r\nColocation Debug Info:  \r\nColocation group had the following types and supported devices:  \r\nRoot Member(assigned\\_device\\_name\\_index\\_=2 requested\\_device\\_name_='/job:localhost/replica:0/task:0/device:GPU:0' assigned\\_device\\_name_='/job:localhost/replica:0/task:0/device:GPU:0' resource\\_device\\_name_='/job:localhost/replica:0/task:0/device:GPU:0' supported\\_device\\_types_=\\[CPU\\] possible\\_devices\\_=\\[\\]  \r\nIdentity: GPU CPU XLA\\_CPU XLA\\_GPU  \r\nReadVariableOp: GPU CPU XLA\\_CPU XLA\\_GPU  \r\nResourceSparseApplyAdadelta: CPU  \r\nUnique: GPU CPU  \r\nShape: GPU CPU XLA\\_CPU XLA\\_GPU  \r\n\\_Arg: GPU CPU XLA\\_CPU XLA_GPU  \r\nConst: GPU CPU XLA\\_CPU XLA\\_GPU  \r\nStridedSlice: GPU CPU XLA\\_CPU XLA\\_GPU  \r\nUnsortedSegmentSum: GPU CPU XLA\\_CPU XLA\\_GPU\r\n\r\nColocation members, user-requested devices, and framework assigned devices, if any:  \r\nwide\\_deep\\_8564 (_Arg) framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0  \r\nadadelta\\_adadelta\\_update\\_resourcesparseapplyadadelta\\_accum (_Arg) framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0  \r\nadadelta\\_adadelta\\_update\\_resourcesparseapplyadadelta\\_accum\\_update (\\_Arg) framework assigned device=/job:localhost/replica:0/task:0/device:GPU:0  \r\nAdadelta/Adadelta/update/Unique (Unique)  \r\nAdadelta/Adadelta/update/Shape (Shape)  \r\nAdadelta/Adadelta/update/strided_slice/stack (Const)  \r\nAdadelta/Adadelta/update/strided\\_slice/stack\\_1 (Const)  \r\nAdadelta/Adadelta/update/strided\\_slice/stack\\_2 (Const)  \r\nAdadelta/Adadelta/update/strided_slice (StridedSlice)  \r\nAdadelta/Adadelta/update/UnsortedSegmentSum (UnsortedSegmentSum)  \r\nAdadelta/Adadelta/update/ResourceSparseApplyAdadelta (ResourceSparseApplyAdadelta)  \r\nwide\\_deep/StatefulPartitionedCall/embedding\\_lookup\\_sparse\\_30/embedding\\_lookup\\_sparse/embedding_lookup/ReadVariableOp (ReadVariableOp)  \r\nFunc/wide\\_deep/StatefulPartitionedCall/input/\\_148 (Identity) /job:localhost/replica:0/task:0/device:GPU:0\r\n\r\n     [[{{node Adadelta/Adadelta/update/Unique}}]] [Op:__inference_train_step_9850]\r\n\r\n```\r\nThis problem is related to issues #2314 and #30537.\r\nTo fix this, I wrote the GPU implementation for ResourceSparseApplyAdadelta Op and tested in r2.3 branch.\r\nTest Env info:\r\n- Docker Image: tensorflow/tensorflow:nightly-custom-op-gpu-ubuntu16\r\n- Ubuntu 16\r\n- Python 3.6\r\n- Tensorflow r2.3.1\r\n- CUDA 10.1\r\n- cuDNN 7\r\n- Cuda Compute Capabilities 7.0 (Tesla V100 Driver 396.37)\r\n- GCC 7\r\n- bazel 3.1.0", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F44323) for more info**.\n\n<!-- need_sender_cla -->", "@googlebot I signed it!", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F44323) for more info**.\n\n<!-- need_author_cla -->", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F44323) for more info**.\n\n<!-- need_author_cla -->", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F44323) for more info**.\n\n<!-- need_author_cla -->", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F44323) for more info**.\n\n<!-- need_author_cla -->", "@googlebot I fixed it.", "\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F44323) for more info**.\n\n<!-- need_sender_cla -->", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and then comment `@googlebot I fixed it.`. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F44323) for more info**.\n\n<!-- need_author_cla -->"]}, {"number": 44322, "title": "Models for person_detect used in micro vision demo of Tensorflow Lite", "body": "Hello,\r\n\r\ndid you upload the source models?\r\nIt would be very nice for me to get the Tensorflow Lite model and the original unquantized model file.\r\n\r\nThank you in advance,\r\nIlkay\r\n\r\n---\r\n\r\nThey are currently only available as c++ source files.  I will have a look at adding the source model to the download.  In the meantime, a simple c++ method which dumps the array to file would re-create the tflite model.  You can find the grayscale c++ file [here](https://storage.googleapis.com/download.tensorflow.org/data/tf_lite_micro_person_data_grayscale.zip):  and the RGB model c++ file [here](https://storage.googleapis.com/download.tensorflow.org/data/tf_lite_micro_person_data.tgz).\r\n\r\n_Originally posted by @njeffrie in https://github.com/tensorflow/tensorflow/issues/29792#issuecomment-529726207_", "comments": ["Hello @IlkayW \r\nAre you able to get TFLite model?\r\n\r\nThanks,\r\nBhavika", "@bhavikapanara not yet unfortunately.", "Here's are tflite versions for the quantized int8 and uint8 models we use in the test. In order to get a floating point model, you can try this experimental [tf2 keras training pipeline](https://github.com/mlperf/tiny/tree/master/v0.1/reference_submissions/person_detection) (accuracy is lower than the slim based [tf1 pipeline](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/examples/person_detection/training_a_model.md), but it is easier to understand and modify).\r\n\r\n[vww_models.zip](https://github.com/tensorflow/tensorflow/files/5484143/vww_models.zip)\r\n\r\n", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@njeffrie Why doesn't the uint8 model have any activation functions?\r\nI am using netron to inspect the model and there are no ReLU-6 activations.", "In TFLite flatbuffer models, we fuse activation functions to the previous operator, so that the activation is applied directly after the bias is added in the previous layer. This is an optimization to reduce overhead by reducing the number of operators in a network. With quantized models we go one step further and implement relu variants using quantized ranges. i.e. for an operator with a relu activation after it, we set the output range to be [0, observed_max] where observed_max is set during quantized calibration. This way, the operator itself will clip the output values to the specified range without the need for any additional logic.", "I have changed how we package tflite models in our examples. Now we include the quantized person detection model under `tensorflow/lite/micro/models`. I've been meaning to update the example to include full training which would help if you wanted the float model, but for now you can find the training and various models (float, quantized) [here](https://github.com/mlcommons/tiny/tree/master/v0.5/training/visual_wake_words)."]}, {"number": 44321, "title": "Tensorflow import error", "body": "Below is the error I see.. any suggestions will be greatful\r\n\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\212474419\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 64, in <module>\r\n    from tensorflow.python._pywrap_tensorflow_internal import *\r\nImportError: DLL load failed while importing _pywrap_tensorflow_internal: \uc9c0\uc815\ub41c \ubaa8\ub4c8\uc744 \ucc3e\uc744 \uc218 \uc5c6\uc2b5\ub2c8\ub2e4.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "comments": ["@minchotomy,\r\nInstallation issues within the Anaconda environment are tracked in the Anaconda repo.\r\n\r\nCould you please submit a new issue using [this link](https://github.com/ContinuumIO/anaconda-issues/issues) and fill in the template, so that the issue can be tracked there. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44321\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44321\">No</a>\n"]}, {"number": 44320, "title": "Request for person_detect.tflite file used in micro vision demo of Tensorflow Lite", "body": "Hello,\r\n\r\nis it possible to get the Tensorflow Lite file for the person detection of the micro vision demo?\r\nThe original or unquantized model file would be helpful for my research as well.\r\nIs there a way to get the person_detect.h5 file, if it exists?\r\n\r\n\r\nThank you in advance,\r\n\r\nIlkay\r\n", "comments": ["Hi @petewarden and Tensorflow people , I need the person_detect.tflite for my research too! I have ESP32-CAM and ESP-EYE.\r\n// don't have a file system. It was created using the command:\r\n// xxd -i person_detect.tflite > person_detect_model_data.cc\r\n\r\nWhere can we find the person_detect.tflite?\r\nThank You!"]}, {"number": 44319, "title": "Build up new Optimizer", "body": "<em>Please make sure that this is a feature request. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:feature_template</em>\r\n\r\n\r\n**System information**\r\n- TensorFlow version (you are using): 2.3.0\r\n- Are you willing to contribute it (Yes/No): Yes\r\n\r\nwill TensorFlow add AdaBelief ?\r\nhttps://arxiv.org/abs/2010.07468\r\n\r\n\r\n**Describe the feature and the current behavior/state.**\r\n\r\n**Will this change the current api? How?**\r\n\r\n**Who will benefit with this feature?**\r\n\r\n**Any Other info.**\r\n", "comments": ["I would love to contribute to this.\r\n\r\nCould anyone else be willing to guide me through \r\nas I have only recently started contributing to open source.", "@IchiruTake i think https://github.com/tensorflow/addons is more suitable for this feature. ", "Will try to work on an implementation.", "Thanks for opening this issue. Development of keras moved to separate repository https://github.com/keras-team/keras/issues\r\n\r\nPlease post this issue on keras-team/keras repo.\r\nTo know more see;\r\nhttps://discuss.tensorflow.org/t/keras-project-moved-to-new-repository-in-https-github-com-keras-team-keras/1999\r\nThank you!"]}, {"number": 44318, "title": "Illegal memory access when running large models on GPU", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): **Yes**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Linux RedHat 7.6**\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): **Docker container**\r\n- TensorFlow version (use command below): **I used the one from the tag 2.3.0-gpu**\r\n- Python version: **3.6.8**\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: **10.1.243**\r\n- GPU model and memory: **Tesla V100-SXM2-32GB**\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\nWhen I run a large model, it I get an illegal memory access was encountered. This occurs even when I use managed memory.\r\n\r\n**Describe the expected behavior**\r\nI expect to see either an OOM error or no error when I used managed memory to emulate a larger memory size.\r\n**Standalone code to reproduce the issue**\r\n\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n     import tensorflow as tf \r\n     import numpy as np\r\n     # Uncomment this to use CUDA Managed Memory (This issue still happens regardless if this is uncommented or not).\r\n     #config = tf.compat.v1.ConfigProto()\r\n     #config.gpu_options.per_process_gpu_memory_fraction = 5 \r\n     #session = tf.compat.v1.InteractiveSession(config=config)\r\n \r\n     # Grab some random dataset\r\n     fashion_mnist = tf.keras.datasets.fashion_mnist\r\n     (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\r\n \r\n     # Standard MNIST Example, except with a large model\r\n     model = tf.keras.Sequential([\r\n         tf.keras.layers.Flatten(input_shape=(28, 28)),\r\n         tf.keras.layers.Dense(2048 * 2048, activation='relu'),\r\n         tf.keras.layers.Dense(10)\r\n      ])\r\n \r\n     model.compile(optimizer='adam',\r\n             loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n             metrics=['accuracy'])\r\n \r\n     model.fit(train_images, train_labels, epochs=1)\r\n\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\nHere is full log\r\n[tf.log](https://github.com/tensorflow/tensorflow/files/5436897/tf.log)\r\nThis part seems relevant.\r\n     Non-OK-status: GpuLaunchKernel(FillPhiloxRandomKernelLaunch<Distribution>, num_blocks, block_size, 0, d.stream(), gen, data, size, dist) status: Internal: an illegal memory access was encountered\r\n    \r\n", "comments": ["@PershingSquare,\r\nI was able to reproduce the issue using the given code snippet. \r\n\r\nHowever, setting a hard limit on the total GPU memory as shown in the guide [here](https://www.tensorflow.org/guide/gpu#limiting_gpu_memory_growth), I ran into an OOM error as expected. Please check [this gist](https://colab.research.google.com/gist/amahendrakar/b9425771f853d3ac74cf60de8efcaeb9/44318.ipynb) for reference. Thanks!", "What causes the GpuLaunchKernel(FillPhiloxRandomKernelLaunch, num_blocks, block_size, 0, d.stream(), gen, data, size, dist) status: Internal: an illegal memory access was encountered\r\nportion and how I do avoid it?", "@PershingSquare,\r\n>`tf.keras.layers.Dense(2048 * 2048, activation='relu')`\r\n\r\nLooks like the error was caused due to the size of the Dense layer. You can avoid this by limiting the GPU memory as mentioned in [this guide](per_process_gpu_memory_fraction). Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 44317, "title": "TensorFlow 1.14 bug", "body": "```\r\nimport tensorflow as tf\r\n\r\nsess = tf.Session()\r\n\r\nlogits = tf.constant([[0.1,0.2,0.3,0.4],[0.5,0.6,0.7,0.8]],dtype=tf.float32)\r\ntopk_logits_value,topk_logits_index = tf.math.top_k(logits,k=3)\r\nprint(sess.run(topk_logits_index))\r\n\r\nsample_index = tf.multinomial(topk_logits_value,num_samples=1)\r\n\r\nrange = tf.range(0,sample_index.get_shape()[0])\r\nsample_index = tf.cast(sample_index,tf.int32)\r\n\r\nsample_index = range * sample_index.get_shape()[0] + tf.reshape(sample_index,[-1])\r\nprint(sess.run(sample_index))\r\n\r\nprint(sess.run(tf.reshape(topk_logits_index,[-1])))\r\nsample_global_index = tf.gather(tf.reshape(topk_logits_index,[-1]),indices=sample_index)\r\nprint(sess.run(sample_global_index))\r\n\r\nsample_global_index = tf.gather(tf.reshape(topk_logits_index,[-1]),indices=tf.constant([2,4]))\r\nprint(sess.run(sample_global_index))\r\n\r\n```\r\n\r\nprint results:\r\n\r\n```\r\n[[3 2 1]\r\n [3 2 1]]\r\n[2 4]\r\n[3 2 1 3 2 1]\r\n\r\n[3 1] # should be [1,2]\r\n\r\n[1 2]\r\n\r\n```", "comments": ["@guotong1988, isn't th `tf.multinomial` *deprecated* ?? It might be an old error.\r\n\r\nif I am not wrong, we have to use `tf.random.categorical` now . Please let me know if this issues is to further looked into.\r\n", "OK, I try it now.", "Still wrong with `tf.random.categorical`", "You should switch to TF 2.x. We no longer fix code on TF 1.x.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44317\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44317\">No</a>\n"]}, {"number": 44316, "title": "Fix ESP32 build", "body": "1. Fixed ESP32 build.\r\nBuild was broken after a commit which makes makefile inc file to be named as `makefile_$(TARGET).inc` (see https://github.com/tensorflow/tensorflow/issues/43898 for more details)\r\n\r\n2. Modified README files for ESP32 to make those consistent across other examples.\r\n", "comments": ["Thanks for contributing to TensorFlow Lite Micro.\n\nTo keep this process moving along, we'd like to make sure that you have completed the items on this list:\n   * Read the [contributing guidelines for TensorFlow Lite Micro](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/micro/CONTRIBUTING.md)\n   * Created a [TF Lite Micro Github issue](https://github.com/tensorflow/tensorflow/issues/new?labels=comp%3Amicro&template=70-tflite-micro-issue.md)\n   * Linked to the issue from the PR description\n   \n\nWe would like to have a discussion on the Github issue first to determine the best path forward, and then proceed to the PR review.\n", "@petewarden PTAL.\r\n\r\ncc: @AdityaHPatwardhan @kedars ", "@vikramdattu  Can you please resolve conflicts? Thanks!", "> @vikramdattu Can you please resolve conflicts? Thanks!\r\n\r\nDone! \ud83d\udc4d\ud83c\udffb"]}, {"number": 44315, "title": "Failed to build due to keras import error (Executing genrule //tensorflow/python/keras/api:keras_python_api_gen failed)", "body": "I am trying to build tensorflow by pulling recent code changes. Keras is not built as part of tensorflow.\r\n\r\n**System information**\r\n- OS Platform and Distribution: Linux Ubuntu 20.04\r\n- TensorFlow installed from: source\r\n- TensorFlow version: 2.1\r\n- Python version: 3.8.4\r\n- Installed using virtualenv? pip? conda?: virtualenv\r\n- Bazel version (if compiling from source): 3.1.0\r\n- GCC/Compiler version (if compiling from source): 9.3.0\r\n- CUDA/cuDNN version: 11\r\n- GPU model and memory: Nvidia RTX 2070\r\n\r\n\r\n```\r\nfrom tensorflow.python.keras.preprocessing import image\r\n  File \"/home/zero/.cache/bazel/_bazel_zero/6a745063bb93c191166f02cd77ede64a/execroot/org_tensorflow/bazel-out/k8-opt-exec-50AE0418/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v1.runfiles/org_tensorflow/tensorflow/python/keras/preprocessing/image.py\", line 24, in <module>\r\n    from keras_preprocessing import image\r\n  File \"/home/zero/env/lib/python3.8/site-packages/keras_preprocessing/image.py\", line 18, in <module>\r\n    backend = get_keras_submodule('backend')\r\n  File \"/home/zero/env/lib/python3.8/site-packages/keras_preprocessing/__init__.py\", line 24, in get_keras_submodule\r\n    raise ImportError('You need to first `import keras` '\r\nImportError: You need to first `import keras` in order to use `keras_preprocessing`. For instance, you can do:\r\n\r\nimport keras\r\nfrom keras_preprocessing import image\r\n\r\nOr, preferably, this equivalent formulation:\r\n\r\nfrom keras import preprocessing\r\n\r\n\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nERROR: /home/zero/tensorflow/tensorflow/python/tools/BUILD:226:1 Executing genrule //tensorflow/python/keras/api:keras_python_api_gen_compat_v1 failed (Exit 1)\r\n```\r\n\r\n", "comments": ["I saw this warning somewhere in between the logs. I am building on Ubuntu (not windows).\r\n\r\n```\r\nAuto-Configuration Warning: 'TMP' environment variable is not set, using 'C:\\Windows\\Temp' as default\r\n```\r\n\r\n", "use \r\nModule: tf.keras.preprocessing.image ", "> I am trying to build tensorflow by pulling recent code changes. Keras is not built as part of tensorflow.\r\n> \r\n> **System information**\r\n> \r\n> * OS Platform and Distribution: Linux Ubuntu 20.04\r\n> * TensorFlow installed from: source\r\n> * TensorFlow version: 2.1\r\n> * Python version: 3.8.4\r\n> * Installed using virtualenv? pip? conda?: virtualenv\r\n> * Bazel version (if compiling from source): 3.1.0\r\n> * GCC/Compiler version (if compiling from source): 9.3.0\r\n> * CUDA/cuDNN version: 11\r\n> * GPU model and memory: Nvidia RTX 2070\r\n> \r\n> ```\r\n> from tensorflow.python.keras.preprocessing import image\r\n>   File \"/home/zero/.cache/bazel/_bazel_zero/6a745063bb93c191166f02cd77ede64a/execroot/org_tensorflow/bazel-out/k8-opt-exec-50AE0418/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v1.runfiles/org_tensorflow/tensorflow/python/keras/preprocessing/image.py\", line 24, in <module>\r\n>     from keras_preprocessing import image\r\n>   File \"/home/zero/env/lib/python3.8/site-packages/keras_preprocessing/image.py\", line 18, in <module>\r\n>     backend = get_keras_submodule('backend')\r\n>   File \"/home/zero/env/lib/python3.8/site-packages/keras_preprocessing/__init__.py\", line 24, in get_keras_submodule\r\n>     raise ImportError('You need to first `import keras` '\r\n> ImportError: You need to first `import keras` in order to use `keras_preprocessing`. For instance, you can do:\r\n> \r\n> import keras\r\n> from keras_preprocessing import image\r\n> \r\n> Or, preferably, this equivalent formulation:\r\n> \r\n> from keras import preprocessing\r\n> \r\n> \r\n> Target //tensorflow/tools/pip_package:build_pip_package failed to build\r\n> Use --verbose_failures to see the command lines of failed build steps.\r\n> ERROR: /home/zero/tensorflow/tensorflow/python/tools/BUILD:226:1 Executing genrule //tensorflow/python/keras/api:keras_python_api_gen_compat_v1 failed (Exit 1)\r\n> ```\r\n\r\n\r\nUse \r\nModule: tf.keras.preprocessing.image\r\n ", "Thanks @vaibhavthapli \r\nI tried changing `from tensorflow.python.keras.preprocessing import image` to `from tensorflow.keras.preprocessing import image` as you suggested in `/tensorflow/tensorflow/python/keras/preprocessing/__init__.py`. Got this error.\r\n```\r\n  from tensorflow.python.keras.preprocessing.sequence import _remove_long_seq\r\n  File \"/home/zero/.cache/bazel/_bazel_zero/6a745063bb93c191166f02cd77ede64a/execroot/org_tensorflow/bazel-out/k8-opt-exec-50AE0418/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen.runfiles/org_tensorflow/tensorflow/python/keras/preprocessing/__init__.py\", line 26, in <module>\r\n    from tensorflow.keras.preprocessing import image\r\nModuleNotFoundError: No module named 'tensorflow.keras'\r\n```", "You have to write \r\nImport tensorflow as tf\r\nThen\r\ntf.keras.preprocessing import  image", "Don't use \r\ntensorflow.keras.prerocessing \r\nBcz u give tensorflow name as tf.\r\n", "I am not getting this error while importing tensorflow in my code. I am seeing these errors while building tensorflow from source code.\r\n\r\nFull trace of logs\r\n\r\n```\r\nERROR: /home/zero/tensorflow/tensorflow/python/keras/api/BUILD:124:1: Executing genrule //tensorflow/python/keras/api:keras_python_api_gen_compat_v1 failed (Exit 1)\r\n2020-10-26 09:45:38.438376: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\r\nTraceback (most recent call last):\r\n  File \"/home/zero/.cache/bazel/_bazel_zero/6a745063bb93c191166f02cd77ede64a/execroot/org_tensorflow/bazel-out/k8-opt-exec-50AE0418/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v1.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py\", line 807, in <module>\r\n    main()\r\n  File \"/home/zero/.cache/bazel/_bazel_zero/6a745063bb93c191166f02cd77ede64a/execroot/org_tensorflow/bazel-out/k8-opt-exec-50AE0418/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v1.runfiles/org_tensorflow/tensorflow/python/tools/api/generator/create_python_api.py\", line 786, in main\r\n    importlib.import_module(package)\r\n  File \"/home/zero/.pyenv/versions/3.8.4/lib/python3.8/importlib/__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1014, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 991, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 975, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 671, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 783, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"/home/zero/.cache/bazel/_bazel_zero/6a745063bb93c191166f02cd77ede64a/execroot/org_tensorflow/bazel-out/k8-opt-exec-50AE0418/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v1.runfiles/org_tensorflow/tensorflow/python/keras/datasets/imdb.py\", line 25, in <module>\r\n    from tensorflow.python.keras.preprocessing.sequence import _remove_long_seq\r\n  File \"/home/zero/.cache/bazel/_bazel_zero/6a745063bb93c191166f02cd77ede64a/execroot/org_tensorflow/bazel-out/k8-opt-exec-50AE0418/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v1.runfiles/org_tensorflow/tensorflow/python/keras/preprocessing/__init__.py\", line 26, in <module>\r\n    from tensorflow.python.keras.preprocessing import image\r\n  File \"/home/zero/.cache/bazel/_bazel_zero/6a745063bb93c191166f02cd77ede64a/execroot/org_tensorflow/bazel-out/k8-opt-exec-50AE0418/bin/tensorflow/python/keras/api/create_tensorflow.python_api_keras_python_api_gen_compat_v1.runfiles/org_tensorflow/tensorflow/python/keras/preprocessing/image.py\", line 24, in <module>\r\n    from keras_preprocessing import image\r\n  File \"/home/zero/env/lib/python3.8/site-packages/keras_preprocessing/image.py\", line 18, in <module>\r\n    backend = get_keras_submodule('backend')\r\n  File \"/home/zero/env/lib/python3.8/site-packages/keras_preprocessing/__init__.py\", line 24, in get_keras_submodule\r\n    raise ImportError('You need to first `import keras` '\r\nImportError: You need to first `import keras` in order to use `keras_preprocessing`. For instance, you can do:\r\n\r\n```\r\nimport keras\r\nfrom keras_preprocessing import image\r\n```\r\n\r\nOr, preferably, this equivalent formulation:\r\n\r\n```\r\nfrom keras import preprocessing\r\n```\r\n\r\nTarget //tensorflow/tools/pip_package:build_pip_package failed to build\r\nUse --verbose_failures to see the command lines of failed build steps.\r\nERROR: /home/zero/tensorflow/tensorflow/python/tools/BUILD:82:1 Executing genrule //tensorflow/python/keras/api:keras_python_api_gen_compat_v1 failed (Exit 1)\r\nINFO: Elapsed time: 2.019s, Critical Path: 1.57s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully\r\n```", "@suhasshastry \r\n\r\nI have tried in colab with TF version 2.1, 2.3 and i am not seeing any issue. Please, find the gist [here](https://colab.research.google.com/gist/ravikyram/a7306c1c6ad2cd08fbaa6925c7b1b793/untitled86.ipynb?authuser=1). Please, verify once and close  the issue. Thanks!", "@suhasshastry \r\n\r\nPlease, try with tested build configurations from [here](https://www.tensorflow.org/install/source#gpu).Thanks!", "Re-cloned and built from scratch. Issue is resolved.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44315\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44315\">No</a>\n"]}, {"number": 44314, "title": "TensorFlow 1.14 bug", "body": "```\r\nimport tensorflow as tf\r\n\r\nsess = tf.Session()\r\n\r\nlogits = tf.constant([[0.1,0.2,0.3,0.4],[0.5,0.6,0.7,0.8]],dtype=tf.float32)\r\ntopk_logits_value,topk_logits_index = tf.math.top_k(logits,k=3)\r\nprint(sess.run(topk_logits_index))\r\n# print(sess.run(topk_logits_value))\r\nsample_index = tf.multinomial(topk_logits_value,num_samples=1)\r\n\r\nrange = tf.range(0,sample_index.get_shape()[0])\r\nsample_index = tf.cast(sample_index,tf.int32)\r\nrange = tf.expand_dims(range,-1)\r\n# print(sess.run(range))\r\nsample_index = tf.concat([range,sample_index],-1)\r\nprint(sess.run(sample_index))\r\n\r\nsample_global_index = tf.gather_nd(topk_logits_index,indices=sample_index)\r\nprint(sess.run(sample_global_index))\r\n\r\nsample_global_index = tf.gather_nd(topk_logits_index,indices=tf.constant([[0,0],[1,2]]))\r\nprint(sess.run(sample_global_index))\r\n```\r\n\r\nprint result:\r\n\r\n```\r\n[[3 2 1]\r\n [3 2 1]]\r\n[[0 0]\r\n [1 2]]\r\n\r\n[2 1] # should be [3,1]\r\n\r\n[3 1]\r\n```", "comments": ["I think this issue can be closed as the similar issue #44317 is open.", "The difference is `tf.gather` and `tf.gather_nd`.", "You should switch to TF 2.x. We no longer fix code on TF 1.x.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44314\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44314\">No</a>\n"]}, {"number": 44313, "title": "OperatorNotAllowedInGraphError in tf.debugging.Assert and tf.keras.Input", "body": "### System information\r\n\r\n-   **Have I written custom code (as opposed to using a stock example script\r\n    provided in TensorFlow)**:\r\n    - Yes\r\n-   **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\n    - Linux Ubuntu 18.04.4 LTS\r\n-   **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue\r\n    happens on a mobile device**:\r\n-   **TensorFlow installed from (source or binary)**:\r\n    - `pip install tensorflow`\r\n-   **TensorFlow version (use command below)**:\r\n    - v2.3.0-54-gfcc4b966f1 2.3.1\r\n-   **Python version**:\r\n    - 3.6.9\r\n-   **Bazel version (if compiling from source)**:\r\n-   **GCC/Compiler version (if compiling from source)**:\r\n-   **CUDA/cuDNN version**:\r\n    - 10.1/7.6.5\r\n-   **GPU model and memory**:\r\n    - Geforce RTX 2080 SUPER (8GB)\r\n-   **Exact command to reproduce**:\r\n    - The minimal python script which can reproduce the issue is in the Source code / logs section below.\r\n\r\n**Describe the current behavior**\r\nI would like to check if inputs to a `Model` is valid or not by using the `tf.debugging.Assert()` function.\r\nBut the straightforward implementation results in an OperatorNotAllowedInGraphError:\r\n```\r\nTraceback (most recent call last):\r\n  File \"reproduce_tfbug.py\", line 9, in <module>\r\n    [inputs]\r\n  File \"/home/shimaya/venv/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\", line 201, in wrapper\r\n    return target(*args, **kwargs)\r\n  File \"/home/shimaya/venv/lib/python3.6/site-packages/tensorflow/python/util/tf_should_use.py\", line 247, in wrapped\r\n    return _add_should_use_warning(fn(*args, **kwargs),\r\n  File \"/home/shimaya/venv/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py\", line 151, in Assert\r\n    if not condition:\r\n  File \"/home/shimaya/venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 877, in __bool__\r\n    self._disallow_bool_casting()\r\n  File \"/home/shimaya/venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 490, in _disallow_bool_casting\r\n    self._disallow_in_graph_mode(\"using a `tf.Tensor` as a Python `bool`\")\r\n  File \"/home/shimaya/venv/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 479, in _disallow_in_graph_mode\r\n    \" this function with @tf.function.\".format(task))\r\ntensorflow.python.framework.errors_impl.OperatorNotAllowedInGraphError: using a `tf.Tensor` as a Python `bool` is not allowed in Graph execution. Use Eager execution or decorate this function with @tf.function.\r\n```\r\nThis seems to occur only when the argument of the `Assert()` is a `tf.keras.Input` tensor.\r\n\r\n**Describe the expected behavior**\r\nI expect this simple assertion works. I believe such simple syntax will be helpful to many TensorFlow users.\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow.keras as K\r\n\r\nif __name__ == \"__main__\":\r\n    inputs = K.Input(shape=(10, 10))\r\n\r\n    tf.debugging.Assert(\r\n        tf.reduce_all(inputs >= 0.), \r\n        [inputs]\r\n    )\r\n\r\n    # any operations or model definitions follow\r\n    # ...\r\n```", "comments": ["@w-shimaya \r\nPlease provide complete stand alone indented code such that we can replicate or if possible share a colab gist with the error reported.", "@Saduf2019 \r\nThank you for your response. \r\nI'd be glad if you could refer to this [gist](https://gist.github.com/w-shimaya/46c35998d8ed53a6cd03ca48d3ad1ad6) to reproduce the issue. \r\nAlso, at least in my environment, the standalone code I attached can reproduce the issue.\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow.keras as K\r\n\r\nif __name__ == \"__main__\":\r\n    inputs = K.Input(shape=(10, 10))\r\n\r\n    tf.debugging.Assert(\r\n        tf.reduce_all(inputs >= 0.), \r\n        [inputs]\r\n    )\r\n\r\n    # any operations or model definitions follow\r\n    # ...\r\n```\r\nThanks!", "i ran the code shared and am able to replicate the issue reported, please find the [gist here](https://colab.research.google.com/gist/Saduf2019/b920f5b78c9a4d9a9f9024adabb1c3ec/untitled456.ipynb). Thanks!", "`tf.debugging` API does not support Keras symbolic tensors.\r\nMost of the `tf.debugging` ops expects a  numeric tensor for assertion which does not fall in line with keras inputs.\r\nSee https://github.com/tensorflow/tensorflow/issues/41627 to know more.", "@ymodak \r\nThank you for your information!\r\nI will put tf.debugging operations in a custom layer for now and there seems to be no problem.\r\nI'd be happy if you are planning to add features such as assertion of Keras symbolic tensors officially.\r\n", "Thanks for confirming. I will close this issue now and update this thread when have more information.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44313\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44313\">No</a>\n"]}, {"number": 44312, "title": "docs: Could not load dynamic library 'libcublas.so.10'", "body": "## URL(s) with the issue:\r\n\r\nhttps://www.tensorflow.org/install/gpu#install_cuda_with_apt\r\n\r\n## Description of issue (what needs changing):\r\n\r\nI followed the Ubuntu 18.04 (CUDA 10.1) instructions and have installed cuda-10-1, libcudnn7=7.6.5.32-1+cuda10.1, libcudnn7-dev=7.6.5.32-1+cuda10.1 as per the instructions.\r\n\r\nWhen I train I'm seeing\r\n```\r\nCould not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory\r\n```\r\n\r\nIn context:\r\n\r\n```\r\n2020-10-26 01:41:57.018284: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-10-26 01:41:57.018526: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory\r\n2020-10-26 01:41:57.119177: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-10-26 01:41:57.144040: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-10-26 01:41:57.274656: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-10-26 01:41:57.292466: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-10-26 01:41:57.619082: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudnn.so.7\r\n2020-10-26 01:41:57.619159: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\nSkipping registering GPU devices...\r\n```\r\n\r\nI'm running Ubuntu 18.04.5 LTS (Bionic Beaver)", "comments": ["@tekumara \r\n\r\nPlease, fill [issue template](https://github.com/tensorflow/tensorflow/issues/new/choose).Please, let us know which tensorflow version you are using?\r\n\r\nPlease, see tested build configurations from [here](https://www.tensorflow.org/install/source#gpu).\r\nPlease, see [link1](https://stackoverflow.com/questions/55224016/importerror-libcublas-so-10-0-cannot-open-shared-object-file-no-such-file-or), #26182 an see if it helps you. Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Thanks @ravikyram I used the docs template rather than the issue template.\r\nI'm using tensorflow 2.3.1 - I'm presume it's compatible with the [install docs](https://www.tensorflow.org/install/gpu#install_cuda_with_apt).", "@tekumara \r\n\r\nCan you install in a fresh environment and see if you are facing issue?\r\nYou can try below commands and see if you are still getting the issue.\r\n```\r\n1. sudo apt install --reinstall libcublas10\r\n2. add this to ~/.bashrc:\r\n3. export LD_LIBRARY_PATH=/usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH\r\n4. Reboot once and check\r\n```\r\n\r\nThanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "`apt-get install libcublas10` installed cuda 10.2 versions:\r\n```\r\n$ dpkg -L libcublas10\r\n/.\r\n/usr\r\n/usr/local\r\n/usr/local/cuda-10.2\r\n/usr/local/cuda-10.2/targets\r\n/usr/local/cuda-10.2/targets/x86_64-linux\r\n/usr/local/cuda-10.2/targets/x86_64-linux/lib\r\n/usr/local/cuda-10.2/targets/x86_64-linux/lib/libcublas.so.10.2.2.214\r\n/usr/local/cuda-10.2/targets/x86_64-linux/lib/libcublasLt.so.10.2.2.214\r\n/usr/local/cuda-10.2/targets/x86_64-linux/lib/libnvblas.so.10.2.2.214\r\n/usr/share\r\n/usr/share/doc\r\n/usr/share/doc/libcublas10\r\n/usr/share/doc/libcublas10/changelog.Debian.gz\r\n/usr/share/doc/libcublas10/copyright\r\n/usr/local/cuda-10.2/lib64\r\n/usr/local/cuda-10.2/targets/x86_64-linux/lib/libcublas.so.10\r\n/usr/local/cuda-10.2/targets/x86_64-linux/lib/libcublasLt.so.10\r\n/usr/local/cuda-10.2/targets/x86_64-linux/lib/libnvblas.so.10\r\n```\r\n\r\nI can add _/usr/local/cuda-10.2/targets/x86_64-linux/lib/_ to `LD_LIBRARY_PATH` and it works. But if feels like I am mixing and matching cuda 10.1 and cuda 10.2 file versions, and there might be a better way.", "@tekumara \r\n\r\nPlease, see this [SO link](https://stackoverflow.com/a/64472380) and see if it helps you. Thanks!", "Yes that's what I did (see above). Perhaps the docs should be updated to reflect this?", "Ok. I also had this problem and here was my solution, since nothing in this thread did.\r\nInfo: Of Remote\r\nUbuntu 18.04 LTS\r\nCuda 10.1\r\nTensorflow 2.3.1\r\nAccessed with Pycharm Professional 2020.2 (remote interpreter)\r\n\r\nThe problem was the environment variables were not correctly set due to PyCharm. If you are using **PyCharm and using a remote host**, you should add the LD_LIBRARY_PATH variable to your environment variables in PyCharm, [editing .bashrc will not solve the problem, nor will editing the .profile](https://intellij-support.jetbrains.com/hc/en-us/community/posts/360006460899-Remote-development-does-not-run-bashrc-on-the-remote-host-while-compiling):\r\n\r\nIn PyCharm\r\n1. Run > Edit Configurations....\r\n2. Click on the list icon for Environment Variables\r\n3. Add the LD_LIBRARY_PATH variable with the value /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH (as given previously in this thread).\r\n\r\nI'm sorry if this is the wrong place for this, but this may help others. I was not aware of this issue with PyCharm.", "> Ok. I also had this problem and here was my solution, since nothing in this thread did.\r\n> Info: Of Remote\r\n> Ubuntu 18.04 LTS\r\n> Cuda 10.1\r\n> Tensorflow 2.3.1\r\n> Accessed with Pycharm Professional 2020.2 (remote interpreter)\r\n> \r\n> The problem was the environment variables were not correctly set due to PyCharm. If you are using **PyCharm and using a remote host**, you should add the LD_LIBRARY_PATH variable to your environment variables in PyCharm, [editing .bashrc will not solve the problem, nor will editing the .profile](https://intellij-support.jetbrains.com/hc/en-us/community/posts/360006460899-Remote-development-does-not-run-bashrc-on-the-remote-host-while-compiling):\r\n> \r\n> In PyCharm\r\n> \r\n> 1. Run > Edit Configurations....\r\n> 2. Click on the list icon for Environment Variables\r\n> 3. Add the LD_LIBRARY_PATH variable with the value /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH (as given previously in this thread).\r\n> \r\n> I'm sorry if this is the wrong place for this, but this may help others. I was not aware of this issue with PyCharm.\r\n\r\neven though I'm in the exact same situation this didn't help  , I still got:\r\n\r\nW tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10:cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH\r\n\r\nwhat do you think I should do ?", "\r\n> even though I'm in the exact same situation this didn't help , I still got:\r\n> \r\n> W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10:cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda-10.1/lib64:/usr/local/cuda/extras/CUPTI/lib64:$LD_LIBRARY_PATH\r\n> \r\n> what do you think I should do ?\r\n\r\nAre you pointing to the correct folder on your system? E.g. did you check that `libcublas.so.10` is in the above path. Some people have complained that CUDA 10.1 also installed files from 10.2 and that their libcublas.so.10 was in the CUDA 10.2 folder. Maybe check this.\r\n\r\nAlso maybe double check how you've added the variables. `LD_LIBRARY_PATH` is the name of the variable and the path is the value. They are two different columns, which is somewhat difficult to see.", "@hdubbs the problem was that the file was in the 10.2 version ,\r\nand eventually I followed this https://stackoverflow.com/a/64472380/10255757\r\nand added the export LD_LIBRARY_PATH=/usr/local/cuda-10.2/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\r\nin the .bashrc file and the problem was solved .\r\nthanks \ud83d\udc4d ", "Closing as [requested](https://github.com/tensorflow/tensorflow/issues/45263#issuecomment-751933452) Please reopen if it's a mistake", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44312\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44312\">No</a>\n", "I would like to provide how I solved this issue after a long term.\r\nJust I saw that  this file was not inside of my directory libcublas.so.10. I do not know why.\r\nI had installed CUDA-10.0, CUDA-10.1 and CUDA-10.2 but I called for CUDA-10.1. My solution was to pass the libcublas.so.10.0 and rename it to libcublas.so.10 from CUDA-10.0 to CUDA-10.1 and it worked! I verified that my GPU is running! I am so happy!"]}, {"number": 44311, "title": "Mysterious exception when using tf.data.Dataset.from_tensor_slices", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nGoogle Colab\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nN/A\r\n- TensorFlow installed from (source or binary):\r\n?\r\n- TensorFlow version (use command below):\r\n2.3.0\r\n- Python version:\r\n3.6.9\r\n- Bazel version (if compiling from source):\r\nN/A\r\n- GCC/Compiler version (if compiling from source):\r\nN/A\r\n- CUDA/cuDNN version:\r\n?\r\n- GPU model and memory:\r\n?\r\n\r\n**Describe the current behavior**\r\nWhen I run `tf.data.Dataset.from_tensor_slices(data)`, it takes a very long time, but at the end, I get:\r\nan `InvalidArgumentError` with `OpKernel 'Pack' has constraint on attr 'T' not in NodeDef '[N=0, axis=0]', KernelDef: 'op: \"Pack\" device_type: \"CPU\" constraint { name: \"T\" allowed_values { list { type: DT_QINT32 } } }`\r\n*`data` is a `list` containing my data*\r\n**Describe the expected behavior**\r\nIt should run without any exceptions. The docs don't mention that this function will raise an `InvalidArgumentError`. I have tried searching the internet for a solution, but the only thing I could find is a Chinese site with no useful information.\r\n**Standalone code to reproduce the issue**\r\n*This is my exact code*\r\nhttps://gist.github.com/firebird52/a87558e9d6a675e3d68d22ccc48f447b\r\n**Other info / logs** \r\nI think it has to do with my data. It seems to be saying that my data has to be of type `DT_QINT32`. All of my data is in the form of strings.", "comments": ["Do you need to use `tf.data.Dataset.from_tensor_slices(data[1][0])`?", "I don't know. I'm fairly new to Tensorflow, but I'll try that out, @bhack .", "@bhack It does prevent the error, but I wanted to merge the rows of the dataset. How would I do that?", "If you want to use `from_tensor_slices` you need to prepare something compatible", "Ok. I want to merge the rows of the dataset in a way so that they are compatible with `from_tensor` or `from_tensor_slices`. Is there a way to do that, @bhack ?", "For this as It Is not a bug or feature request you need to close the ticket and open a support question at https://stackoverflow.com/questions/tagged/tensorflow", "Okay, @bhack. I'll put this on Stack Overflow."]}, {"number": 44310, "title": "Parallelize each level of BFS in `GetMatchingPaths`", "body": "This is a PR from JIZHI Team & TaiJi AI platform in Tencent.\r\n\r\nI have tried to submit a PR #44269 which parallelize the `tf.gfile.Glob` in Python, by multi-threaeds against multiple path patterns. This PR is going to optimize the `GetMatchingPaths` in C++, which brings PBFS into the progress, parallelizes every level of tree by a additional queue. The optimizion can bring considerable performance improvement when the number of files to match reaches a certain level.\r\n\r\nSince the content of the change is different, I put this in another PR.  @mihaimaruseac  Could you please task a look at this? Thanks for your review!", "comments": [" @mihaimaruseac  Sorry for some careless compiling problems in the previous commit.. I have fixed them already. Could you please take a look and give any suggestions?", "First thing, the CI could crash because the Pr was approved by @SuperSaiyan-God who has no approval rights. @SuperSaiyan-God , please don't spam approve PRs, it goes against the code of conduct.\r\n\r\nSecond, I see you are using `<mutex>`, but TF has its own mutex wrapper. Can you use TF's synchronization primitives instead of those from the C++ lib?\r\n\r\nFinally, this will also need to be replicated on the filesystem plugins side.", "@mihaimaruseac Thanks for your advising! As you mentioned, I have turned `mutex` lib from C++ lib to TF's mutex wrapper in [299062c](https://github.com/tensorflow/tensorflow/pull/44310/commits/299062c88a69a9bfb90d578648314f6780d5d402).\r\n\r\nBut I\u2019m sorry I didn\u2019t figure out the specific meaning of your last point... What do you mean that needs to be replicated, could you please explain it in more detail?  Thanks!", "> Finally, this will also need to be replicated on the filesystem plugins side.\r\n\r\n@mihaimaruseac \r\nI think this is not the case. Because all 3 cloud filesystems and `posix`, we have `ops_->get_matching_paths == nullptr` and it will fall back on this function `internal::GetMatchingPaths`\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/79cdd9533a3566b4b84c374645bf9ccf752cb9f4/tensorflow/c/experimental/filesystem/modular_filesystem.cc#L191-L195\r\n\r\nBeside, if there is a filesystem that has its own `get_matching_paths`, I think it will be quite different from `internal::GetMatchingPaths` so it is not the case either.", "@mihaimaruseac Could you please check this again?", "Do you have some benchmarks for the implementation?", "> Do you have some benchmarks for the implementation?\r\n\r\n@mihaimaruseac  Thanks for leading the progress of this pr. \r\n\r\nI haved made benchmarks against two file systems separately, those are local posix file system and remote hdfs file system. For each file system, I used 4 different directories for benchmarking, the first of which is an empty directory to measure the fixed overhead of the operation itself.\r\n\r\nEach test is repeated 10 times and the average is taken as the result. The all benchmark results are as follows:\r\n\r\n***System environment: Intel(R) Xeon(R) CPU E5-2699 v4 @ 2.20GHz 80 threads***\r\n\r\n**Local POSIX file system**:\r\n\r\n- d1: an empty directory\r\n- d2: 7601 directories, 76354 files\r\n- d3: 64520 directories, 905496 files\r\n- d4: 113322 directories, 1317540 files\r\n\r\n| version  | patterns | Duration (ms) |\r\n| -------- | -------- | ------------- |\r\n| baseline | d1       | 448           |\r\n| baseline | d2       | 4,257          |\r\n| baseline | d3       | 27,527         |\r\n| baseline | d4       | 133,951        |\r\n| opt      | d1       | 475           |\r\n| opt      | d2       | 3,258          |\r\n| opt      | d3       | 14,128         |\r\n| opt      | d4       | 74,653         |\r\n\r\n**Remote HDFS file system**:\r\n\r\n- d1: an empty directory\r\n- d2: 3 directories, 6000 files\r\n- d3: 10 directories, 35896 files\r\n- d4: 10 directories, 63212 files\r\n\r\n| version  | patterns | Duration (ms) |\r\n| -------- | -------- | ------------- |\r\n| baseline | d1       | 2,166         |\r\n| baseline | d2       | 955,592       |\r\n| baseline | d3       | 5,236,644     |\r\n| baseline | d4       | 8,102,354     |\r\n| opt      | d1       | 2,234         |\r\n| opt      | d2       | 104,478       |\r\n| opt      | d3       | 648,057       |\r\n| opt      | d4       | 1,002,565     |\r\n\r\nP.S. The `baseline` is the implement of current tensorflow master and the `opt` is the implement of my parallelized version.\r\n\r\nAccording to the results of the benchmarks, the effect of parallel optimization is quite obvious which approximately \r\n **speeded up 8 times** in the current machine environment.\r\n", "Hi, @mihaimaruseac  @gbaned \r\n\r\nThere seems to be some compilation errors that have nothing to do with the code I modified, and I would like to ask for advice how I should solve them to make the ci process run through?", "> There seems to be some compilation errors \r\n\r\nThe errors are not your fault ( They are caused by the some other parts of the `baseline` ) so I think you do not need to do anything.", "> The errors are not your fault ( They are caused by the some other parts of the `baseline` ) so I think you do not need to do anything.\r\n\r\n@vnvo2409 Okay, Thanks for your reply!  : )", "This is awesome. Thank you"]}, {"number": 44309, "title": "Model.predict() subsequent predictions returning nan (tf-nightly TF 2.4.0-dev20201023, NVIDIA-SMI 456.71, CUDA 11.1, cuDNN 8.0.4, RTX 3090)", "body": "This seems to be an interesting issue with serial predictions using RTX 3090 with updated version of tf-nightly and CUDA 11.1 (Windows 10, cuDNN 8.0.4). I tried submitting the issue on stackoverflow without any resolution. \r\n\r\nI'm passing a single image_array: (IMAGE_DATA TYPE <class 'numpy.ndarray'> IMAGE_DATA.SHAPE (1, 640, 640, 3)) to MODEL.predict(IMAGE_DATA). The first time the model is compiled, the predictions make sense (accurate bounding boxes, class type). However, the second time a new image or a copy of the first image is passed to MODEL.predict() it returns predictions that don't make any sense (see below). This is a YOLOv3 model.\r\n\r\nPREDICTED_BOXES = model.predict(IMAGE_DATA)\r\nLEN(PREDICTED_BOXES) = 25200\r\n[[ nan nan nan nan nan nan]\r\n[ nan nan nan nan nan nan]\r\n[ nan nan nan nan nan nan]\r\n...\r\n[640. 640. inf inf 1. 1.]\r\n[640. 640. inf inf 1. 1.]\r\n[640. 640. inf inf 1. 1.]]\r\n\r\n--> postprocessing of boxes returns [x1, y1, x2, y2, class_prob, class_num]:\r\n[0.000e+00 0.000e+00 1.919e+03 1.079e+03 1.000e+00 0.000e+00]\r\n\r\nIf I run the same code/images using only my CPU on the same computer as the RTX 3090 it correctly predicts on all images. If I run the same code/images on a different computer with a GTX 1060 and TF 2.3.0, CUDA 10.1 NVIDIA-SMI 441.87 it correctly predicts on all images.\r\n\r\nHas anyone else had a similar issue and are there any thoughts on what the problem might be or fixes/workarounds?\r\n\r\nThanks\r\n", "comments": ["@fussners \r\nPlease share simple stand alone code for us to replicate the issue faced or if possible share a colab gist with error reported. ", "I have the same configuration as you, But I am stuck in the epoch and there is no error. Have you ever encountered this problem?", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44309\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44309\">No</a>\n", "Did you get resolution on this? I am facing the same issue, unfortunately!", "@ajaymaity I had the same error. Did you fix it?", "@rafikg @ajaymaity @fussners \r\nYo guys, anyone got the issue solved? lol\r\nI'm facing this exact same problem, tested on RTX3060, RTX3070 laptop, RTX2080\r\nRTX3000 series can't run with CUDNN 7\r\nOn RTX2080 I tried tensorflow 2.3 or below, it is working perfectly. Tensorflow 2.4 & 2.5 is return all NAN except the first prediction"]}, {"number": 44307, "title": "Could not load dynamic library 'libcudnn.so.7'", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Linux Ubuntu 20.04**\r\n- TensorFlow installed from (source or binary): \r\n- TensorFlow version: **2.3.1**\r\n- Python version: **Python 3.8.5**\r\n- Installed using virtualenv? pip? conda?: **pip**\r\n- CUDA/cuDNN version: **CUDA 11.1/cuDNN v8**\r\n- GPU model and memory: **RTX 3080**\r\n\r\nISSUE similar to #20271 and #36426\r\n\r\n\r\n**Describe the problem**\r\nSo I was setting up CUDA and cuDNN for my RTX 3080 on ubuntu 20.04. I followed the TF guide and installed CUDA 10.1 and cuDNN v7. But then I was running into several issues. From a similar issue #43718, I was [suggested](https://github.com/tensorflow/tensorflow/issues/43718#issuecomment-714649169) to use CUDA 11.1 and cuDNN v8.\r\n\r\nBut whenever I run `tf.config.list_physical_devices('GPU')` I get the following error:\r\n```\r\n2020-10-25 17:36:10.844295: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\r\n2020-10-25 17:36:10.879258: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:982] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-10-25 17:36:10.879821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1716] Found device 0 with properties: \r\npciBusID: 0000:2b:00.0 name: GeForce RTX 3080 computeCapability: 8.6\r\ncoreClock: 1.71GHz coreCount: 68 deviceMemorySize: 9.76GiB deviceMemoryBandwidth: 707.88GiB/s\r\n2020-10-25 17:36:10.879836: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-10-25 17:36:10.881041: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n2020-10-25 17:36:10.881627: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcufft.so.10\r\n2020-10-25 17:36:10.881750: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcurand.so.10\r\n2020-10-25 17:36:10.882821: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusolver.so.10\r\n2020-10-25 17:36:10.883332: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcusparse.so.10\r\n2020-10-25 17:36:10.883401: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudnn.so.7'; dlerror: libcudnn.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11.1/lib64:/usr/local/cuda-11.1/lib64:/opt/ros/noetic/lib\r\n2020-10-25 17:36:10.883408: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1753] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\r\nSkipping registering GPU devices...\r\n[]\r\n```\r\nHere is my ~/.zshrc:\r\n```\r\n# ROS\r\nsource /opt/ros/noetic/setup.zsh\r\n\r\n# CUDA\r\nexport PATH=/usr/local/cuda-11.1/bin${PATH:+:${PATH}}\r\nexport LD_LIBRARY_PATH=/usr/local/cuda-11.1/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\r\n# export LD_LIBRARY_PATH=/usr/lib/cuda/lib64:$LD_LIBRARY_PATH\r\n# export LD_LIBRARY_PATH=/usr/lib/cuda/include:$LD_LIBRARY_PATH\r\n```\r\n", "comments": ["I'm pretty certain that your Tensorflow is built against CUDA 10.1. \r\n\r\n> 2020-10-25 17:36:10.879836: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\r\n2020-10-25 17:36:10.881041: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcublas.so.10\r\n\r\nIf it was built against CUDA 11.1 you'd be seeing 11/11.1 libs. I would suggest purging CUDA and CUDNN and starting with a clean environment. \r\n \r\nWhat is weird is that it successfully loaded CUDA 10.1 libs, did you source your .zhrc after making those changes or restarted/ opened a new session? ", "@BorhenJlidi I tried following the official documentation to purge CUDA 10.1. I'm not sure anymore I'm new to ubuntu. Should I just reinstall ubuntu and start over again?", "@Harsh188 reinstalling Ubuntu won't do you any good in this case, nothing is wrong with your OS.\r\nFor me to be able to help you, please write down a precise list of what packages you installed in order and what commands you executed. If you don't remember , salvage what you can from .bash_history . I've got to know the order of installation, package format, build args...\r\n\r\nPS: if you prefer a prebuilt TF binary, go for tf nightly 2.4. Some users reported it to work with RTX30 series.", "```\r\n**powerlevel**\r\n    1  subl\r\n    2  ^[[200~yay -S --noconfirm zsh-theme-powerlevel10k-git~\r\n    3  yay -S --noconfirm zsh-theme-powerlevel10k-git\r\n    4  git clone --depth=1 https://github.com/romkatv/powerlevel10k.git ~/powerlevel10k\r\n    5  echo 'source ~/powerlevel10k/powerlevel10k.zsh-theme' >>! ~/.zshrc\r\n    6  p10k configure\r\n    7  sudo reboot\r\n    8  python\r\n    9  python3\r\n   10  subl ~/zshrc\r\n   11  subl ~/.zshrc\r\n   12  python\r\n\r\n**Nvidia-Driver**\r\n   20  git clone https://github.com/zsh-users/zsh-syntax-highlighting.git \"$HOME/.zsh-syntax-highlighting\" --depth 1\r\n   21  echo \"source $HOME/.zsh-syntax-highlighting/zsh-syntax-highlighting.zsh\" >> \"$HOME/.zshrc\"\r\n   22  ubuntu-drivers devices\r\n   23  cd \r\n   24  ubuntu-drivers devices\r\n   25  ubuntu-drivers\r\n   26  ubuntu-drivers devices\r\n   27  sudo apt update \r\n   28  git status\r\n   29  ubuntu-drivers devices\r\n   30  sudo add-apt-repository ppa:oem-solutions-group/nvidia-driver-staging\r\n   31  sudo apt update\r\n   32  sudo nano /etc/apt/sources.list.d/graphics-drivers*.list\r\n   33  apt search nvidia-driver*\r\n   34  apt search nvidia-driver\r\n   35  sudo nano /etc/apt/sources.list.d/graphics-drivers.list\r\n   36  sudo apt install nvidia-driver-455 nvidia-settings\r\n   37  apt search nvidia-driver\r\n   38  ubuntu-drivers devices\r\n   39  sudo reboot\r\n\r\n**Docker**\r\n   52  sudo apt-get update\r\n   53  sudo apt-get install \\\\n    apt-transport-https \\\\n    ca-certificates \\\\n    curl \\\\n    gnupg-agent \\\\n    software-properties-common\r\n   54  curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -\r\n   55  sudo apt-key fingerprint 0EBFCD88\r\n   56  sudo add-apt-repository \\\\n   \"deb [arch=amd64] https://download.docker.com/linux/ubuntu \\\\n   $(lsb_release -cs) \\\\n   stable\"\r\n   57  sudo apt-get update\r\n   58  sudo apt-get install docker-ce docker-ce-cli containerd.io\r\n   59  apt-cache madison docker-ce\r\n   60  sudo apt-get install docker-ce=<5:19.03.13~3-0~ubuntu-focal> docker-ce-cli=<5:19.03.13~3-0~ubuntu-focal> containerd.io\\n\r\n   61  sudo apt-get install docker-ce=<VERSION_STRING> docker-ce-cli=<VERSION_STRING> containerd.io\r\n   62  sudo docker run hello-world\r\n   63  clear\r\n\r\n**cuDNN v8**\r\n   77  cd \r\n   78  tar -xvzf cudnn-10.1-linux-x64-v8.0.4.30.tgz\r\n   80  cd Downloads\r\n   81  tar -xvzf cudnn-10.1-linux-x64-v8.0.4.30.tgz\r\n   82  sudo cp cuda/include/cudnn.h /usr/lib/cuda/include/\r\n   83  sudo cp cuda/lib64/libcudnn* /usr/lib/cuda/lib64/\r\n   84  ^[[200~sudo chmod a+r /usr/lib/cuda/include/cudnn.h /usr/lib/cuda/lib64/libcudnn*\r\n   85  sudo chmod a+r /usr/lib/cuda/include/cudnn.h /usr/lib/cuda/lib64/libcudnn*\\n\r\n   86  echo 'export LD_LIBRARY_PATH=/usr/lib/cuda/lib64:$LD_LIBRARY_PATH' >> ~/.zshrc\r\n   87  echo 'export LD_LIBRARY_PATH=/usr/lib/cuda/include:$LD_LIBRARY_PATH' >> ~/.zshrc\r\n   88  source ~/.zshrc\r\n\r\n**Checking things?**\r\n   94  lspci -v\r\n   96  nvidia-smi -a\r\n   97  nvcc --version\r\n   98  sudo apt update\r\n   99  sudo apt install nvidia-cuda-toolkit\r\n  100  nvcc --version\r\n  101  whereis cuda\r\n  102  tar -xvzf cudnn-10.1-linux-x64-v8.0.4.30.tgz\\n\r\n  103  source env/bin/activate\r\n  104  python\r\n  105  pip list\r\n  106  sudo docker run hello-world\r\n  107  clear\r\n  108  curl -sS https://download.spotify.com/debian/pubkey_0D811D58.gpg | sudo apt-key add - \\necho \"deb http://repository.spotify.com stable non-free\" | sudo tee /etc/apt/sources.list.d/spotify.list\r\n  109  sudo apt-get update && sudo apt-get install spotify-client\r\n  110  cd \r\n  111  export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/extras/CUPTI/lib64\r\n  112  subl ~/.zshrc\r\n\r\n**cuDNN v7**\r\n  116  cd \r\n  117  cd Downloads\r\n  118  tar -xvzf cudnn-10.1-linux-x64-v7.6.5.32.tgz\r\n  120  sudo cp cuda/include/cudnn.h /usr/lib/cuda/include/\r\n  122  sudo cp cuda/lib64/libcudnn* /usr/lib/cuda/lib64/\r\n  123  sudo chmod a+r /usr/lib/cuda/include/cudnn.h /usr/lib/cuda/lib64/libcudnn*\r\n  124  git status\r\n  125  nvcc -V\r\n  126  nvidia-smi\r\n  141  subl ~/.zshrc\r\n\r\n**Installing ROS/Removing CUDA**\r\n  147  cd \r\n  148  sudo sh -c 'echo \"deb http://packages.ros.org/ros/ubuntu $(lsb_release -sc) main\" > /etc/apt/sources.list.d/ros-latest.list'\r\n  149  sudo apt-key adv --keyserver 'hkp://keyserver.ubuntu.com:80' --recv-key C1CF6E31E6BADE8868B172B4F42ED6FBAB17C654\r\n  150  sudo apt update\r\n  151  sudo apt install ros-noetic-desktop-full\r\n  152  source /opt/ros/noetic/setup.bash\\n\r\n  153  echo \"source /opt/ros/noetic/setup.zsh\" >> ~/.zshrc\\nsource ~/.zshrc\r\n  154  nvcc --version\r\n  155  lspci | grep -i nvidia\r\n  156  uname -m && cat /etc/*release\r\n  157  gcc --version\r\n  158  uname -r\r\n  159  sudo apt-get install linux-headers-$(uname -r)\r\n  160  sudo /usr/local/cuda-X.Y/bin/uninstall_cuda_X.Y.pl\r\n  161  whereis cuda\r\n  162  whereis cuda-X.Y\r\n  163  dpkg -l | grep -i nvidia\r\n  164  sudo /usr/local/cuda-X.Y/bin/uninstall_cuda_X.Y.pl\r\n  165  sudo /usr/lib/cuda-X.Y/bin/uninstall_cuda_X.Y.pl\r\n  166  sudo apt-get remove --auto-remove nvidia-cuda-toolkit\r\n  167  sudo apt-get purge --auto-remove nvidia-cuda-toolkit\r\n  168  sudo /usr/bin/nvidia-uninstall\\n\r\n  169  whereis cuda\r\n  171  nvcc -V\r\n  172  nvidia-smi\r\n  173  sudo dpkg -i cuda-repo-<distro>_<version>_<architecture>.deb\r\n  174  wget https://developer.download.nvidia.com/compute/cuda/11.1.0/local_installers/cuda_11.1.0_455.23.05_linux.run\r\n  175  sudo sh cuda_11.1.0_455.23.05_linux.run\r\n  176  which cuda\r\n  177  whereis cuda\r\n  178  sudo sh cuda_11.1.0_455.23.05_linux.run\r\n  203  rl\r\n  204  roscore\r\n  205  cd \r\n  206  sudo apt-get install ros-$(rosversion -d)-turtlesim\r\n  207  rosrun turtlesim turtlesim_node\r\n\r\n**Testing ROS**\r\n  216  cd\r\n  217  printevn | grep ROS\r\n  218  rosversion -d\r\n  219  printenv | grep ROS\r\n  220  rosversion -h\r\n  221  source /opt/ros/noetic/setup.bash\r\n  222  mkdir -p ~/catkin_ws/src\r\n  223  cd ~/catkin_ws\r\n  224  catkin_make\r\n  225  source devel/setup.bash\r\n  226  source /devel/setup.bash\r\n  227  source devel/setup.bash\r\n  228  echo $ROS_PACKAGE_PATH /home/harsh/catkin_ws/src:/opt/ros/noetic/share\r\n  229  cd\r\n  230  sudo apt-get install ros-neotic-ros-tutorials\r\n  231  sudo apt-get install ros-noetic-ros-tutorials\r\n  232  rospack find roscpp\r\n  233  roscd roscpp\r\n  234  pwd\r\n  235  echo $ROS_PACKAGE_PATH\r\n  236  roscd roscpp/cmake/\r\n  237  roscd log\r\n  238  rosls roscpp_tutorials/\r\n  239  roscd roscpp_tutorials/\r\n  240  roscd turtle\r\n  241  rosls\r\n  242  roscd turtlesim/\r\n  243  rosls\r\n\r\n**Downloading CUDA 11**\r\n  244  cd\r\n  246  which CUDA\r\n  247  whereis cuda\r\n  249  lspci | grep -i nvidia~\r\n  250  nvcc -V\r\n  251  sudo apt-get install linux-headers-$(uname -r)\r\n  252  gcc --version\r\n  253  uname -r\r\n  254  sudo apt-get remove --auto-remove nvidia-cuda-toolkit~\r\n  255  sudo apt-get purge nvidia*\\nsudo apt-get autoremove\\nsudo apt-get autoclean\\nsudo rm -rf /usr/local/cuda*\r\n  256  get https://developer.download.nvidia.com/compute/cuda/11.1.0/local_installers/cuda_11.1.0_455.23.05_linux.run\r\n  257  wget https://developer.download.nvidia.com/compute/cuda/11.1.0/local_installers/cuda_11.1.0_455.23.05_linux.run\r\n  258  sudo sh cuda_11.1.0_455.23.05_linux.run\r\n  259  cat /usr/local/cuda/version.txt\r\n  260  sudo lshw -numeric -C display\r\n  261  lspci | grep -i nvidia\r\n  262  md5sum\r\n  263  wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin\r\n  264  sudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600\r\n  265  wget https://developer.download.nvidia.com/compute/cuda/11.1.0/local_installers/cuda-repo-ubuntu2004-11-1-local_11.1.0-455.23.05-1_amd64.deb\r\n  266  sudo dpkg -i cuda-repo-ubuntu2004-11-1-local_11.1.0-455.23.05-1_amd64.deb\r\n  267  sudo apt-key add /var/cuda-repo-ubuntu2004-11-1-local/7fa2af80.pub\r\n  268  sudo apt-get update\r\n  269  sudo apt-get -y install cuda\r\n  270  cat /usr/local/cuda/version.txt\r\n  271  nvcc --version\r\n  272  /usr/local/cuda/bin/nvcc --version\r\n  273  dpkg -l | grep cuda-toolkit\r\n  274  whereis cuda\r\n  275  nvcc -V\r\n  276  sudo apt install nvidia-cuda-toolkit\r\n  277  nvcc -V\r\n  278  nvcc --version\r\n  279  nvidia-smi\r\n  280  dpkg -l | grep cuda-toolkit\r\n  281  whereis cuda\r\n  282  /usr/local/cuda/bin/nvcc --version\r\n  283  subl ~/.zshrc\r\n  284  export PATH=/usr/local/cuda-11.1/bin${PATH:+:${PATH}}\r\n  285  export LD_LIBRARY_PATH=/usr/local/cuda-11.1/lib64\\\\n                         ${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\r\n  286  export LD_LIBRARY_PATH=/usr/local/cuda-11.1/lib64:${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\r\n  287  export LD_LIBRARY_PATH=/usr/local/cuda-11.1/lib64\\${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\r\n  288  systemctl status nvidia-persistenced\r\n  289  source ~/.zshrc\r\n  290  /usr/bin/nvidia-persistenced --verbose\r\n  291  sudo -i\r\n  293  cd Downloads\r\n  294  ls\r\n  297  tar -xzvf cudnn-11.1-linux-x64-v8.0.4.30.tgz\r\n  298  sudo cp cuda/include/cudnn*.h /usr/local/cuda/include\r\n  299  sudo cp cuda/lib64/libcudnn* /usr/local/cuda/lib64\\n\r\n  300  sudo chmod a+r /usr/local/cuda/include/cudnn*.h /usr/local/cuda/lib64/libcudnn*\r\n  301  cp -r /usr/src/cudnn_samples_v8/ $HOME\r\n  302  sudo update-alternatives --config libcudnn\r\n  303  sudo dpkg -i libcudnn*.deb\r\n  304  ldconfig -p | grep cuda\r\n  305  nvidia-smi\r\n  306  cat /usr/local/cuda/include/cudnn.h | grep CUDNN_MAJOR -A 2\r\n  307  cd\r\n  308  python\r\n  309  pip list\r\n  310  pip install tensorflow\r\n  311  python\r\n  312  source ~/.zshrc\r\n  313  export LD_LIBRARY_PATH=/usr/local/cuda-11.1/lib64\\\\n                         ${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\r\n  314  export PATH=/usr/local/cuda-11.1/bin${PATH:+:${PATH}}\r\n  315  export LD_LIBRARY_PATH=/usr/local/cuda-11.1/lib64\\\\n                         ${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\r\n  316  export LD_LIBRARY_PATH=/usr/local/cuda-11.1/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\r\n  317  source ~/.zshrc\r\n  318  python\r\n  319  source ~/.zshrc\r\n  321  export PATH=/usr/local/cuda-11.1/bin${PATH:+:${PATH}}\r\n  322  export LD_LIBRARY_PATH=/usr/local/cuda-11.1/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\r\n  323  python\r\n```\r\n\r\nThe packages I've installed:\r\n- `Powerlevel`\r\n- `Docker`\r\n- `Spotify`\r\n- `Nvidia-driver`\r\n- `cuDNN v8` for `CUDA 10.1`\r\n- `cuDNN v7` for `CUDA 10.1`\r\n- `ROS Noetic`\r\n- Purge `CUDA 10.1` [not sure if this was done correctly]\r\n- `CUDA 11.1`\r\n- `cuDNN v8` for `CUDA 11.1`", "Thanks for providing the log. I must point out that every CUDA runfile installation will overwrite the installed Nvidia driver.\r\nI noticed that you used runfiles for both CUDA installations, from my experience local deb repos are more reliable.\r\nI don't see anything wrong with installation of each individual package, but I must ask `  310  pip install tensorflow` is this the one and only tensorflow installation that you've done? If so, it will require preinstalled CUDA 10.1 and CUDNN 7. Installing CUDA 11.1 for a prebuilt binary against CUDA 10.1 does not have any effect. If we assume that you installed tensorflow after installing CUDA 11.1, the error messages indicate that CUDA 10.1 libs are still visible but not CUDNN 7.\r\n\r\n>   312  source ~/.zshrc\r\n  313  export LD_LIBRARY_PATH=/usr/local/cuda-11.1/lib64\\\\n                         ${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\r\n  314  export PATH=/usr/local/cuda-11.1/bin${PATH:+:${PATH}}\r\n  315  export LD_LIBRARY_PATH=/usr/local/cuda-11.1/lib64\\\\n                         ${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\r\n  316  export LD_LIBRARY_PATH=/usr/local/cuda-11.1/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\r\n  317  source ~/.zshrc\r\n\r\nAnother question, are you sourcing .zhrc without modifying it? are you running those exports in other terminals other the ones in which you are runing python tensorflow scripts?\r\n\r\nTo be precise, these are the packages that enabled me to use tensorflow 2.3.1 with RTX 3080 on Ubuntu 20.04 :\r\ncuda-repo-ubuntu2004-11-1-local_11.1.0-455.23.05-1_amd64.deb\r\ncudnn-11.1-linux-x64-v8.0.4.30.tgz\r\nTensorRT-7.2.1.6.Ubuntu-18.04.x86_64-gnu.cuda-11.1.cudnn8.0.tar.gz", "I see. I wasn't sure what exactly the differences were between run file and deb so I just randomly chose run file. But then I realized something wasn't working so I used deb to install CUDA 11.1 again.  I installed tensorflow in with virtualenv but I didn't have it on my global pip so that's why I ran `310 pip install tensorflow` to test if TensorFlow was detecting my gpu.\r\n\r\n> Another question, are you sourcing .zhrc without modifying it?\r\n\r\nI actually had sublime open with .zshrc so I was changing it and then sourcing it. Heres what my .zshrc file looks like: \r\n```\r\nif [[ -r \"${XDG_CACHE_HOME:-$HOME/.cache}/p10k-instant-prompt-${(%):-%n}.zsh\" ]]; then\r\n  source \"${XDG_CACHE_HOME:-$HOME/.cache}/p10k-instant-prompt-${(%):-%n}.zsh\"\r\nfi\r\n\r\nexport ZSH=$HOME/.oh-my-zsh\r\n\r\nZSH_THEME=\"robbyrussell\"\r\n\r\nplugins=(git)\r\n\r\nsource $ZSH/oh-my-zsh.sh\r\n\r\nalias python=python3\r\nalias pip=pip3\r\n\r\nsource ~/powerlevel10k/powerlevel10k.zsh-theme\r\n\r\n[[ ! -f ~/.p10k.zsh ]] || source ~/.p10k.zsh\r\nsource /home/harsh/.zsh-syntax-highlighting/zsh-syntax-highlighting.zsh\r\n\r\n# ROS\r\nsource /opt/ros/noetic/setup.zsh\r\n\r\n# CUDA\r\nexport PATH=/usr/local/cuda-11.1/bin${PATH:+:${PATH}}\r\nexport LD_LIBRARY_PATH=/usr/local/cuda-11.1/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}\r\n# export LD_LIBRARY_PATH=/usr/lib/cuda/lib64:$LD_LIBRARY_PATH\r\n# export LD_LIBRARY_PATH=/usr/lib/cuda/include:$LD_LIBRARY_PATH\r\n```\r\n\r\nI'm not sure how to make TensorFlow use CUDA 11.1 instead of CUDA 10.1. It's very confusing. I think if there is no direct solution to this, I might just reinstall Ubuntu. That way I can make sure that I only install CUDA 11.1. I don't know if this is an effective solution.", "> # export LD_LIBRARY_PATH=/usr/lib/cuda/include:$LD_LIBRARY_PATH\r\nuncomment this line or add cuda include to LD_LIBRARY_PATH especially if you want to build something against CUDA.\r\n\r\n> I'm not sure how to make TensorFlow use CUDA 11.1 instead of CUDA 10.1. It's very confusing. I think if there is no direct solution to this, I might just reinstall Ubuntu. That way I can make sure that I only install CUDA 11.1. I don't know if this is an effective solution.\r\n\r\nThere are two solutions :\r\n1. Install dependencies and pre-built tensorflow binaries (tf-nightly as I mentioned was reported to work out of the box with CUDA 11.1 https://pypi.org/project/tf-nightly/)\r\n2. Install dependencies and build tensorflow from source.\r\n", "Thanks a lot for your help @BorhenJlidi!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44307\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/44307\">No</a>\n"]}, {"number": 44305, "title": "Optimize all reduce v2", "body": "the original dense all reduce is not efficient, update to a more efficient one.", "comments": ["All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F44305) for more info**.\n\n<!-- need_author_consent -->", "@googlebot I consent.", "All (the pull request submitter and all commit authors) CLAs are signed, **but** one or more commits were authored or co-authored by someone other than the pull request submitter.\n\nWe need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that by leaving a comment that contains only `@googlebot I consent.` in this pull request.\n\n*Note to project maintainer:* There may be cases where the author cannot leave a comment, or the comment is not properly detected as consent.  In those cases, you can manually confirm consent of the commit author(s), and set the `cla` label to `yes` (if enabled on your project).\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F44305) for more info**.\n\n<!-- need_author_consent -->", "We never patch the nightly branch. Please open/rebase against `master`", "@chengmengli06  Can you please check @mihaimaruseac's comments and keep us posted ? Thanks!", "Closing since this is against nightly branch which we don't update"]}]