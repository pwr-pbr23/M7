[{"number": 43663, "title": "TFLite android image classification demo failed on samsung note10 whose soc is snapdragon 855", "body": "- system platform: macos 10.15\r\n\r\n- example: [tflite image classification official demo](https://github.com/tensorflow/examples/tree/master/lite/examples/image_classification/android)\r\n\r\n- IDE: android studio 4.0.1\r\n\r\n- hardware: samsung note10 equiped with snapdragon 855\r\n\r\nerrors: when I tried to use the dsp delegate on the phone, I modified the code like this:\r\n```\r\ncase DSP:\r\n                dspDelegate = new HexagonDelegate(activity);\r\n                tfliteOptions.addDelegate(dspDelegate);\r\n                break;\r\n```\r\nin the [classifier.java](https://github.com/tensorflow/examples/blob/master/lite/examples/image_classification/android/lib_support/src/main/java/org/tensorflow/lite/examples/classification/tflite/Classifier.java#L201)\r\n\r\nso I built and run the demo and selected quantized_efficientnet & dsp to run the DNN on the hexagon and it was ok.\r\n\r\nHowever, when I download the android NDK 21.3.6528147, android studio tell me that I need to install NDK 21.0.6113669, I followed the instruction and re-built and re-run the app. When I selected quantized_efficientnet & dsp again, I got the following error:\r\n\r\n```\r\nE/AndroidRuntime: FATAL EXCEPTION: inference\r\nE/org.tensorflow.lite.examples.classification: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/apps_std_imp.c:729:Error 45: fopen failed for testsig-0xfe534ed3.so. (No such file or directory)\r\nE/org.tensorflow.lite.examples.classification: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/apps_std_imp.c:729:Error 45: fopen failed for testsig.so. (No such file or directory)\r\nD/org.tensorflow.lite.examples.classification: vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:989: Error 0x80000406: remote_handle_open_domain: dynamic loading failed for file:///libhexagon_nn_skel_v66.so?hexagon_nn_domains_skel_handle_invoke&_modver=1.0&_dom=cdsp on domain 3 (dlerror segment 0 failed signature verification (0xF4 B) for libhexagon_nn_s\r\n    vendor/qcom/proprietary/commonsys-intf/adsprpc/src/fastrpc_apps_user.c:1027: Error 0x80000406: remote_handle64_open failed for file:///libhexagon_nn_skel_v66.so?hexagon_nn_domains_skel_handle_invoke&_modver=1.0&_dom=cdsp\r\nW/tflite: Failed to fetch Hexagon NN version. This might be because you're using incompatible versions of libhexagon_interface and libhexagon_nn_skel. You must use compatible versions. Refer to Tensorflow Lite Hexagon Delegate Guide.\r\nI/tflite: Hexagon Delegate is not supported.\r\nE/AndroidRuntime: FATAL EXCEPTION: inference\r\n    Process: org.tensorflow.lite.examples.classification, PID: 9186\r\n    java.lang.UnsupportedOperationException: This Device doesn't support Hexagon DSP execution.\r\n        at org.tensorflow.lite.HexagonDelegate.<init>(HexagonDelegate.java:39)\r\n        at org.tensorflow.lite.examples.classification.tflite.Classifier.<init>(Classifier.java:257)\r\n        at org.tensorflow.lite.examples.classification.tflite.ClassifierQuantizedEfficientNet.<init>(ClassifierQuantizedEfficientNet.java:46)\r\n        at org.tensorflow.lite.examples.classification.tflite.Classifier.create(Classifier.java:159)\r\n        at org.tensorflow.lite.examples.classification.ClassifierActivity.recreateClassifier(ClassifierActivity.java:162)\r\n        at org.tensorflow.lite.examples.classification.ClassifierActivity.lambda$onInferenceConfigurationChanged$0$ClassifierActivity(ClassifierActivity.java:132)\r\n        at org.tensorflow.lite.examples.classification.-$$Lambda$ClassifierActivity$83lGy2TUjuj0M5n4BhMB9qlLgSY.run(Unknown Source:8)\r\n        at android.os.Handler.handleCallback(Handler.java:873)\r\n        at android.os.Handler.dispatchMessage(Handler.java:99)\r\n        at android.os.Looper.loop(Looper.java:216)\r\n        at android.os.HandlerThread.run(HandlerThread.java:65)\r\n```\r\n\r\nwhere Classifier.java:257 is \r\ndspDelegate = new HexagonDelegate(activity); // (definition is: private HexagonDelegate dspDelegate = null;)\r\n\r\n\r\nso I uninstalled the NDK and it was ok again.\r\n", "comments": ["1)\r\nIn the initialize line for the delegate\r\n(e.g.) hexagonDelegate = new HexagonDelegate(activity);\r\nCan you print\r\nactivity.getApplicationInfo().nativeLibraryDir\r\nand check that the shared lib files are on the device under the same path.\r\nadb shell ls -al <PATH_PRINTED_FROM_ABOVE>\r\n\r\nIf you can paste the results in the reply will be good.\r\n\r\n2) Are you using app bundle ?", "I added \r\n`System.out.println(\"activity.getApplicationInfo().nativeLibraryDir: \" + activity.getApplicationInfo().nativeLibraryDir);`\r\nbefore initialize line (because the code will fail at the initialize line) for the dsp delegate like this:\r\n```\r\ncase DSP:\r\n                System.out.println(\"activity.getApplicationInfo().nativeLibraryDir: \" + activity.getApplicationInfo().nativeLibraryDir);\r\n                dspDelegate = new HexagonDelegate(activity);\r\n                tfliteOptions.addDelegate(dspDelegate);\r\n```\r\n\r\nwhen I build an run it without NDK, \r\nthe output is\r\n`I/System.out: activity.getApplicationInfo().nativeLibraryDir: /data/app/org.tensorflow.lite.examples.classification-7iQPWk8WX-zeI0qENU6CHw==/lib/arm64`\r\n\r\nand I check the path on the device and the output is\r\n```\r\ntotal 8526\r\ndrwxr-xr-x 2 system system    3488 2020-10-07 10:28 .\r\ndrwxr-xr-x 3 system system    3488 2020-10-07 10:28 ..\r\n-rwxr-xr-x 1 system system   88096 1981-01-01 01:01 libhexagon_interface.so\r\n-rwxr-xr-x 1 system system 1148720 1981-01-01 01:01 libhexagon_nn_skel.so\r\n-rwxr-xr-x 1 system system 1165168 1981-01-01 01:01 libhexagon_nn_skel_v65.so\r\n-rwxr-xr-x 1 system system 1161072 1981-01-01 01:01 libhexagon_nn_skel_v66.so\r\n-rwxr-xr-x 1 system system 2178720 1981-01-01 01:01 libtensorflowlite_gpu_jni.so\r\n-rwxr-xr-x 1 system system  531432 1981-01-01 01:01 libtensorflowlite_hexagon_jni.so\r\n-rwxr-xr-x 1 system system 2440400 1981-01-01 01:01 libtensorflowlite_jni.so\r\n```\r\n\r\nso I download the NDK and re-do the same steps above\r\nand I get the output like this:\r\n\r\n`I/System.out: activity.getApplicationInfo().nativeLibraryDir: /data/app/org.tensorflow.lite.examples.classification-lFI9puZibQIiXlcPlB0lxw==/lib/arm64`\r\n\r\nwhich is different from the above one. So I also check the dir and the output is like this:\r\n\r\n```\r\ntotal 8526\r\ndrwxr-xr-x 2 system system    3488 2020-10-07 10:38 .\r\ndrwxr-xr-x 3 system system    3488 2020-10-07 10:38 ..\r\n-rwxr-xr-x 1 system system   88088 1981-01-01 01:01 libhexagon_interface.so\r\n-rwxr-xr-x 1 system system 1148720 1981-01-01 01:01 libhexagon_nn_skel.so\r\n-rwxr-xr-x 1 system system 1165168 1981-01-01 01:01 libhexagon_nn_skel_v65.so\r\n-rwxr-xr-x 1 system system 1161072 1981-01-01 01:01 libhexagon_nn_skel_v66.so\r\n-rwxr-xr-x 1 system system 2178720 1981-01-01 01:01 libtensorflowlite_gpu_jni.so\r\n-rwxr-xr-x 1 system system  531432 1981-01-01 01:01 libtensorflowlite_hexagon_jni.so\r\n-rwxr-xr-x 1 system system 2440400 1981-01-01 01:01 libtensorflowlite_jni.so\r\n```\r\n\r\nand I find both the output of the adb shell are same, including 7 files with the same filename \r\n\r\nwhile the build ouput with NDK is like this:\r\n```\r\nExecuting tasks: [:app:assembleDebug] in project /Users/wangqipeng/Project/tflite_image_classification\r\n\r\nWARNING: The specified Android SDK Build Tools version (28.0.0) is ignored, as it is below the minimum supported version (29.0.2) for Android Gradle Plugin 4.0.0.\r\nAndroid SDK Build Tools 29.0.2 will be used.\r\nTo suppress this warning, remove \"buildToolsVersion '28.0.0'\" from your build.gradle file, as each version of the Android Gradle Plugin now has a default version of the build tools.\r\nWARNING: The specified Android SDK Build Tools version (28.0.0) is ignored, as it is below the minimum supported version (29.0.2) for Android Gradle Plugin 4.0.0.\r\nAndroid SDK Build Tools 29.0.2 will be used.\r\nTo suppress this warning, remove \"buildToolsVersion '28.0.0'\" from your build.gradle file, as each version of the Android Gradle Plugin now has a default version of the build tools.\r\n> Task :app:preBuild UP-TO-DATE\r\n> Task :app:preDebugBuild UP-TO-DATE\r\n> Task :lib_support:preBuild UP-TO-DATE\r\n> Task :lib_support:preDebugBuild UP-TO-DATE\r\n> Task :models:downloadEfficientNetFloat UP-TO-DATE\r\n> Task :models:unzipModelEfficientNetFloat UP-TO-DATE\r\n> Task :models:downloadEfficientNetQuant UP-TO-DATE\r\n> Task :models:unzipModelEfficientNetQuant UP-TO-DATE\r\n> Task :models:downloadModelFloat UP-TO-DATE\r\n\r\n> Task :models:unzipModelFloat\r\nUnzipping build/intermediates/mobilenet_v1_1.0_224.tgz\r\n\r\n> Task :models:downloadModelQuant UP-TO-DATE\r\n\r\n> Task :models:unzipModelQuant\r\nUnzipping build/intermediates/mobilenet_v1_1.0_224_quant.tgz\r\n\r\n> Task :models:cleanUnusedFiles\r\n> Task :models:preBuild\r\n> Task :models:preDebugBuild\r\n> Task :models:compileDebugAidl NO-SOURCE\r\n> Task :lib_support:compileDebugAidl NO-SOURCE\r\n> Task :app:compileDebugAidl NO-SOURCE\r\n> Task :lib_support:packageDebugRenderscript NO-SOURCE\r\n> Task :app:generateDebugBuildConfig UP-TO-DATE\r\n> Task :app:compileDebugRenderscript NO-SOURCE\r\n> Task :app:javaPreCompileDebug UP-TO-DATE\r\n> Task :app:generateDebugResValues UP-TO-DATE\r\n> Task :app:generateDebugResources UP-TO-DATE\r\n> Task :models:packageDebugRenderscript NO-SOURCE\r\n> Task :lib_support:generateDebugResValues UP-TO-DATE\r\n> Task :models:compileDebugRenderscript NO-SOURCE\r\n> Task :models:generateDebugResValues UP-TO-DATE\r\n> Task :lib_support:compileDebugRenderscript NO-SOURCE\r\n> Task :lib_support:generateDebugResources UP-TO-DATE\r\n> Task :lib_support:packageDebugResources UP-TO-DATE\r\n> Task :models:generateDebugResources UP-TO-DATE\r\n> Task :models:packageDebugResources UP-TO-DATE\r\n> Task :app:mergeDebugResources UP-TO-DATE\r\n> Task :app:createDebugCompatibleScreenManifests UP-TO-DATE\r\n> Task :app:extractDeepLinksDebug UP-TO-DATE\r\n> Task :lib_support:extractDeepLinksDebug UP-TO-DATE\r\n> Task :lib_support:processDebugManifest UP-TO-DATE\r\n> Task :models:extractDeepLinksDebug UP-TO-DATE\r\n> Task :models:processDebugManifest UP-TO-DATE\r\n> Task :app:processDebugManifest UP-TO-DATE\r\n> Task :lib_support:compileDebugLibraryResources UP-TO-DATE\r\n> Task :lib_support:parseDebugLocalResources UP-TO-DATE\r\n> Task :models:parseDebugLocalResources UP-TO-DATE\r\n> Task :models:generateDebugRFile UP-TO-DATE\r\n> Task :lib_support:generateDebugRFile UP-TO-DATE\r\n> Task :models:compileDebugLibraryResources UP-TO-DATE\r\n> Task :app:processDebugResources UP-TO-DATE\r\n> Task :lib_support:generateDebugBuildConfig UP-TO-DATE\r\n> Task :lib_support:javaPreCompileDebug UP-TO-DATE\r\n> Task :models:generateDebugBuildConfig UP-TO-DATE\r\n> Task :models:javaPreCompileDebug UP-TO-DATE\r\n> Task :models:compileDebugJavaWithJavac UP-TO-DATE\r\n> Task :models:bundleLibCompileToJarDebug UP-TO-DATE\r\n> Task :lib_support:compileDebugJavaWithJavac UP-TO-DATE\r\n> Task :lib_support:bundleLibCompileToJarDebug UP-TO-DATE\r\n> Task :app:compileDebugJavaWithJavac UP-TO-DATE\r\n> Task :app:compileDebugSources UP-TO-DATE\r\n> Task :app:mergeDebugShaders UP-TO-DATE\r\n> Task :app:compileDebugShaders NO-SOURCE\r\n> Task :app:generateDebugAssets UP-TO-DATE\r\n> Task :lib_support:mergeDebugShaders UP-TO-DATE\r\n> Task :lib_support:compileDebugShaders NO-SOURCE\r\n> Task :lib_support:generateDebugAssets UP-TO-DATE\r\n> Task :lib_support:packageDebugAssets UP-TO-DATE\r\n> Task :models:mergeDebugShaders UP-TO-DATE\r\n> Task :models:compileDebugShaders NO-SOURCE\r\n> Task :models:generateDebugAssets UP-TO-DATE\r\n> Task :models:packageDebugAssets UP-TO-DATE\r\n> Task :app:mergeDebugAssets UP-TO-DATE\r\n> Task :app:processDebugJavaRes NO-SOURCE\r\n> Task :lib_support:processDebugJavaRes NO-SOURCE\r\n> Task :lib_support:bundleLibResDebug NO-SOURCE\r\n> Task :models:processDebugJavaRes NO-SOURCE\r\n> Task :models:bundleLibResDebug NO-SOURCE\r\n> Task :app:mergeDebugJavaResource UP-TO-DATE\r\n> Task :app:desugarDebugFileDependencies UP-TO-DATE\r\n> Task :app:checkDebugDuplicateClasses UP-TO-DATE\r\n> Task :app:mergeExtDexDebug UP-TO-DATE\r\n> Task :lib_support:bundleLibRuntimeToJarDebug UP-TO-DATE\r\n> Task :models:bundleLibRuntimeToJarDebug UP-TO-DATE\r\n> Task :app:dexBuilderDebug UP-TO-DATE\r\n> Task :app:mergeLibDexDebug UP-TO-DATE\r\n> Task :app:mergeProjectDexDebug UP-TO-DATE\r\n> Task :app:mergeDebugJniLibFolders UP-TO-DATE\r\n> Task :lib_support:mergeDebugJniLibFolders UP-TO-DATE\r\n> Task :lib_support:mergeDebugNativeLibs UP-TO-DATE\r\n> Task :lib_support:stripDebugDebugSymbols\r\n> Task :lib_support:copyDebugJniLibsProjectOnly\r\n> Task :models:mergeDebugJniLibFolders UP-TO-DATE\r\n> Task :models:mergeDebugNativeLibs UP-TO-DATE\r\n> Task :models:stripDebugDebugSymbols NO-SOURCE\r\n> Task :models:copyDebugJniLibsProjectOnly UP-TO-DATE\r\n> Task :app:validateSigningDebug UP-TO-DATE\r\n> Task :app:mergeDebugNativeLibs\r\n> Task :app:stripDebugDebugSymbols\r\n> Task :app:packageDebug\r\n> Task :app:assembleDebug\r\n\r\nBUILD SUCCESSFUL in 4s\r\n67 actionable tasks: 8 executed, 59 up-to-date\r\n\r\nBuild Analyzer results available\r\n```\r\n\r\n", "Are there any updates on this issue?\r\nI have a similar issue with my Sony Xperia XZ2 phone.\r\nThe error (`fopen failed for testsig-0xxxxxxxxx.so. (No such file or directory)`) only appears when the DSP library is launched from an Android app (apk).\r\nI can execute the CLI benchmark binary via adb.", "Wondering if it might be related to app bundle\r\nsee https://www.tensorflow.org/lite/performance/hexagon_delegate#add_the_shared_library_to_your_app\r\n\r\n@emakryo what other log you get beside the testsig one ?", "Hi @qipengwang ! Android image classification example  is running fine in Android studio latest version . Can you let us know from your side with Target SDK version 28 and NDK version 23b  ?", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43663\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43663\">No</a>\n"]}, {"number": 43662, "title": "Create build.yml", "body": "", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F43662) for more info**.\n\n<!-- need_sender_cla -->"]}, {"number": 43661, "title": "Core dumped when invoking TFLite model converted using latest nightly TFLite converter (2.4.0dev2020929)", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Linux Ubuntu 20.04**\r\n- TensorFlow installed from (source or binary): **binary**\r\n- TensorFlow version (or github SHA if from source): **2.4.0.dev20200929**\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\n```\r\nimport tensorflow as tf\r\n\r\nimport numpy as np\r\n\r\n\r\ndef wrap_frozen_graph(graph_def, inputs, outputs):\r\n    def _imports_graph_def():\r\n        tf.compat.v1.import_graph_def(graph_def, name=\"\")\r\n    wrapped_import = tf.compat.v1.wrap_function(_imports_graph_def, [])\r\n    import_graph = wrapped_import.graph\r\n    return wrapped_import.prune(\r\n        tf.nest.map_structure(import_graph.as_graph_element, inputs),\r\n        tf.nest.map_structure(import_graph.as_graph_element, outputs))\r\n\r\n\r\ngraph_def = tf.compat.v1.GraphDef()\r\n_ = graph_def.ParseFromString(open('minimal_093011.pb', 'rb').read())\r\ndnn_function = wrap_frozen_graph(graph_def, inputs='import/first_graph_input:0', outputs='import_1/second_graph_output/Mean:0')\r\nconverter = tf.lite.TFLiteConverter.from_concrete_functions([dnn_function])\r\n\r\nconverter.experimental_enable_mlir_converter = True\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\nconverter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\r\n\r\n\r\ndef representative_dataset_gen():\r\n    image = np.random.randint(low=0, high=255, size=(1, 480, 640, 3), dtype='uint8')\r\n    yield [image]\r\n\r\n\r\nconverter.representative_dataset = representative_dataset_gen\r\nconverter.inference_input_type = tf.uint8\r\nconverter.inference_output_type = tf.uint8\r\n\r\nmodel = converter.convert()\r\n```\r\n\r\n**Link to Google Colab Notebook**\r\n\r\n```\r\nhttps://colab.research.google.com/drive/1U8UVDl6lIs1zKjfpFc7hrr3jAo-0eh_i?usp=sharing\r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n\r\n```\r\nhttps://drive.google.com/file/d/1Hvr9hfvaxj3sBi0D0U0iAAe1kEaiJJWB/view?usp=sharing\r\n```\r\n\r\n**Failure details**\r\nThe conversion is successful in that it generates a tflite graph. However, when I invoke the graph, I get a core dump error:\r\n[1]    511859 abort (core dumped)  python src/reproduce_minimal_tflite_test.py\r\n\r\n**Code used to invoke the graph. Also included in Colab notebook linked above.**\r\n```\r\nimage = np.random.randint(low=0, high=255, size=(1, 480, 640, 3), dtype='uint8')\r\n\r\ntflite_model = tf.lite.Interpreter('models/minimal_093011.tflite')\r\ntflite_model.allocate_tensors()\r\n\r\ninput_details = tflite_model.get_input_details()\r\ntflite_model.set_tensor(input_details[0]['index'], image)\r\ntflite_model.invoke()\r\n```\r\n\r\n**Traceback**\r\n\r\n```\r\n#0  __GI_raise (sig=sig@entry=6) at ../sysdeps/unix/sysv/linux/raise.c:50                                                                                                                                                                     \r\n#1  0x00007ffff7dc0859 in __GI_abort () at abort.c:79                                                                                                                                                                                         \r\n#2  0x00007fffb9386e42 in tflite::QuantizeMultiplierSmallerThanOneExp(double, int*, int*) ()                                                                                                                                                  \r\n   from /home/yousef/miniconda3/envs/tf2.3/lib/python3.7/site-packages/tensorflow/lite/python/interpreter_wrapper/_pywrap_tensorflow_interpreter_wrapper.so                                                                                   \r\n#3  0x00007fffb9158090 in void tflite::ops::builtin::comparisons::(anonymous namespace)::ComparisonQuantized<signed char, &(bool tflite::reference_ops::GreaterFn<int>(int, int))>(TfLiteTensor const*, TfLiteTensor const*, TfLiteTensor*, bo\r\nol) () from /home/yousef/miniconda3/envs/tf2.3/lib/python3.7/site-packages/tensorflow/lite/python/interpreter_wrapper/_pywrap_tensorflow_interpreter_wrapper.so                                                                               \r\n#4  0x00007fffb9158b7e in tflite::ops::builtin::comparisons::(anonymous namespace)::GreaterEval(TfLiteContext*, TfLiteNode*) ()                                                                                                               \r\n   from /home/yousef/miniconda3/envs/tf2.3/lib/python3.7/site-packages/tensorflow/lite/python/interpreter_wrapper/_pywrap_tensorflow_interpreter_wrapper.so                                                                                   \r\n#5  0x00007fffb9369713 in tflite::Subgraph::Invoke() () from /home/yousef/miniconda3/envs/tf2.3/lib/python3.7/site-packages/tensorflow/lite/python/interpreter_wrapper/_pywrap_tensorflow_interpreter_wrapper.so                              \r\n#6  0x00007fffb936c1f0 in tflite::Interpreter::Invoke() () from /home/yousef/miniconda3/envs/tf2.3/lib/python3.7/site-packages/tensorflow/lite/python/interpreter_wrapper/_pywrap_tensorflow_interpreter_wrapper.so                           \r\n#7  0x00007fffb90f7548 in tflite::interpreter_wrapper::InterpreterWrapper::Invoke() ()                                                                                                                                                        \r\n   from /home/yousef/miniconda3/envs/tf2.3/lib/python3.7/site-packages/tensorflow/lite/python/interpreter_wrapper/_pywrap_tensorflow_interpreter_wrapper.so                                                                                   \r\n#8  0x00007fffb90eb6ee in pybind11::cpp_function::initialize<pybind11_init__pywrap_tensorflow_interpreter_wrapper(pybind11::module&)::{lambda(tflite::interpreter_wrapper::InterpreterWrapper&)#6}, pybind11::object, tflite::interpreter_wrap\r\nper::InterpreterWrapper&, pybind11::name, pybind11::is_method, pybind11::sibling>(pybind11_init__pywrap_tensorflow_interpreter_wrapper(pybind11::module&)::{lambda(tflite::interpreter_wrapper::InterpreterWrapper&)#6}&&, pybind11::object (*\r\n)(tflite::interpreter_wrapper::InterpreterWrapper&), pybind11::name const&, pybind11::is_method const&, pybind11::sibling const&)::{lambda(pybind11::detail::function_call&)#3}::_FUN(pybind11::detail::function_call) ()                     \r\n   from /home/yousef/miniconda3/envs/tf2.3/lib/python3.7/site-packages/tensorflow/lite/python/interpreter_wrapper/_pywrap_tensorflow_interpreter_wrapper.so                                                                                   \r\n#9  0x00007fffb90ecb39 in pybind11::cpp_function::dispatcher(_object*, _object*, _object*) ()                                                                                                                                                 \r\n   from /home/yousef/miniconda3/envs/tf2.3/lib/python3.7/site-packages/tensorflow/lite/python/interpreter_wrapper/_pywrap_tensorflow_interpreter_wrapper.so                                                                                   \r\n#10 0x00005555556b9914 in _PyMethodDef_RawFastCallKeywords (method=0x55555694b100, self=0x7fffbb8c9270, args=0x7fffaf04dd98, nargs=<optimised out>, kwnames=<optimised out>)                                                                  \r\n    at /tmp/build/80754af9/python_1598874792229/work/Objects/call.c:693                                                                                                                                                                       \r\n#11 0x00005555556b9a31 in _PyCFunction_FastCallKeywords (func=0x7fffc08de460, args=<optimised out>, nargs=<optimised out>, kwnames=<optimised out>) at /tmp/build/80754af9/python_1598874792229/work/Objects/call.c:732                       \r\n#12 0x000055555572639e in call_function (kwnames=0x0, oparg=<optimised out>, pp_stack=<synthetic pointer>) at /tmp/build/80754af9/python_1598874792229/work/Python/ceval.c:4619                                                               \r\n#13 _PyEval_EvalFrameDefault (f=<optimised out>, throwflag=<optimised out>) at /tmp/build/80754af9/python_1598874792229/work/Python/ceval.c:3093                                                                                              \r\n#14 0x00005555556b8e7b in function_code_fastcall (globals=<optimised out>, nargs=1, args=<optimised out>, co=<optimised out>) at /tmp/build/80754af9/python_1598874792229/work/Objects/call.c:283                                             \r\n#15 _PyFunction_FastCallKeywords (func=<optimised out>, stack=0x7ffff6d615c0, nargs=1, kwnames=<optimised out>) at /tmp/build/80754af9/python_1598874792229/work/Objects/call.c:408                                                           \r\n#16 0x0000555555721740 in call_function (kwnames=0x0, oparg=<optimised out>, pp_stack=<synthetic pointer>) at /tmp/build/80754af9/python_1598874792229/work/Python/ceval.c:4616                                                               \r\n#17 _PyEval_EvalFrameDefault (f=<optimised out>, throwflag=<optimised out>) at /tmp/build/80754af9/python_1598874792229/work/Python/ceval.c:3110                                                                                              \r\n#18 0x0000555555668829 in _PyEval_EvalCodeWithName (_co=0x7ffff6cfa1e0, globals=<optimised out>, locals=<optimised out>, args=<optimised out>, argcount=<optimised out>, kwnames=0x0, kwargs=0x0, kwcount=0, kwstep=2, defs=0x0, defcount=0,  \r\n    kwdefs=0x0, closure=0x0, name=0x0, qualname=0x0) at /tmp/build/80754af9/python_1598874792229/work/Python/ceval.c:3930                                                                                                                     \r\n#19 0x0000555555669714 in PyEval_EvalCodeEx (_co=<optimised out>, globals=<optimised out>, locals=<optimised out>, args=<optimised out>, argcount=<optimised out>, kws=<optimised out>, kwcount=0, defs=0x0, defcount=0, kwdefs=0x0,          \r\n    closure=0x0) at /tmp/build/80754af9/python_1598874792229/work/Python/ceval.c:3959                                                                                                                                                         \r\n#20 0x000055555566973c in PyEval_EvalCode (co=<optimised out>, globals=<optimised out>, locals=<optimised out>) at /tmp/build/80754af9/python_1598874792229/work/Python/ceval.c:524                                                           \r\n#21 0x0000555555780f14 in run_mod (mod=<optimised out>, filename=<optimised out>, globals=0x7ffff6dcac30, locals=0x7ffff6dcac30, flags=<optimised out>, arena=<optimised out>)                                                                \r\n    at /tmp/build/80754af9/python_1598874792229/work/Python/pythonrun.c:1035                                                                                                                                                                  \r\n#22 0x000055555578b331 in PyRun_FileExFlags (fp=0x5555558c3100, filename_str=<optimised out>, start=<optimised out>, globals=0x7ffff6dcac30, locals=0x7ffff6dcac30, closeit=1, flags=0x7fffffffdd80)                                          \r\n    at /tmp/build/80754af9/python_1598874792229/work/Python/pythonrun.c:988                                                                                                                                                                   \r\n#23 0x000055555578b523 in PyRun_SimpleFileExFlags (fp=0x5555558c3100, filename=<optimised out>, closeit=1, flags=0x7fffffffdd80) at /tmp/build/80754af9/python_1598874792229/work/Python/pythonrun.c:429                                      \r\n#24 0x000055555578c655 in pymain_run_file (p_cf=0x7fffffffdd80, filename=0x5555558c2870 L\"src/reproduce_minimal_tflite_test.py\", fp=0x5555558c3100) at /tmp/build/80754af9/python_1598874792229/work/Modules/main.c:462                       \r\n#25 pymain_run_filename (cf=0x7fffffffdd80, pymain=0x7fffffffde90) at /tmp/build/80754af9/python_1598874792229/work/Modules/main.c:1652                                                                                                       \r\n#26 pymain_run_python (pymain=0x7fffffffde90) at /tmp/build/80754af9/python_1598874792229/work/Modules/main.c:2913     \r\n#27 pymain_main (pymain=0x7fffffffde90) at /tmp/build/80754af9/python_1598874792229/work/Modules/main.c:3460           \r\n#28 0x000055555578c77c in _Py_UnixMain (argc=<optimised out>, argv=<optimised out>) at /tmp/build/80754af9/python_1598874792229/work/Modules/main.c:3495                                                                                      \r\n#29 0x00007ffff7dc20b3 in __libc_start_main (main=0x555555649c90 <main>, argc=2, argv=0x7fffffffdff8, init=<optimised out>, fini=<optimised out>, rtld_fini=<optimised out>, stack_end=0x7fffffffdfe8) at ../csu/libc-start.c:308             \r\n#30 0x0000555555730ff0 in _start () at ../sysdeps/x86_64/elf/start.S:103\r\n```\r\n", "comments": ["@yousef-xailient,\r\nI do not have access to the Colab notebook and the saved model file. Could you please grant the required permissions to view the files. Thanks!", "@amahendrakar \r\n\r\nMy bad. You can try now.", "Was able to reproduce the issue. Session crashes on running the code with TF v2.3 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/9253e439795b5ccf487ada3ab385bb90/43661-tf-nightly.ipynb). Thanks!", "Hi @jvishnuvardhan,\r\n\r\nI noticed that you were assigned to this. Let me know if you have all you need or need any help with this.", "@yousef-xailient Looks like there is an `dtype` incompatibility. Please check `input_details` where dtype is mentioned as `int32` but the provided input is `uint8`.\r\n\r\n`print(input_details)`\r\n`[{'name': 'import/first_graph_input', 'index': 0, 'shape': array([  1, 480, 640,   3], dtype=int32), 'shape_signature': array([ -1, 480, 640,   3], dtype=int32), 'dtype': <class 'numpy.uint8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}]`\r\n\r\nNeed to check more to find the root-cause. Thanks!\r\n ", "@jvishnuvardhan the 'dtype' key is uint8, the other dtypes are shapes and other information about the graph, not involved in the graph itself, I think. I've had quantized models with shape_signature array([], dtype=int32) work fine before.", "Hi, @karimnosseir, I see that you have been assigned to this issue. Please let me know if I can be of any help.", "Hi, is this still on going issue ?\r\n\r\nThanks", "Hi,\r\n\r\nI have the exact same problem and coredump.\r\nI have searched everywhere and I did not found any solution to this issue.\r\nThe problem is still reproducible on latest version (2.7.0-dev20210729) through the Collab link : https://colab.research.google.com/gist/amahendrakar/9253e439795b5ccf487ada3ab385bb90/43661-tf-nightly.ipynb\r\n\r\nI would be nice to have some feedback/investigation why the crash occurs...\r\n\r\nThanks for your support ", "I was able to replicate in [2.8 version](https://colab.research.google.com/gist/mohantym/57fdccfc4b03c75f73ccf436d5ff4776/untitled13.ipynb?authuser=1#scrollTo=7uOzGdYOID7I) too.", "That looks invalid values from quantization params.\r\nJaesung can you please have a look\r\n\r\n\r\nThanks", "Thanks. @sngyhan fyi", "Can you please tag me too in the fix?", "This should be fixed by a989426ee1346693cc015792f11d715f6944f2b8", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43661\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43661\">No</a>\n"]}, {"number": 43660, "title": "Error converting from TensorFlow frozen graph to TFLite using TF1.15", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): **Linux Ubuntu 20.04**\r\n- TensorFlow installed from (source or binary): **binary**\r\n- TensorFlow version (or github SHA if from source): **1.15.0**\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nIf possible, please share a link to Colab/Jupyter/any notebook.\r\n```\r\ninput_name = 'import/first_graph_input'\r\noutput_name = 'import_1/second_graph_output/Mean'\r\nconverter = tf.lite.TFLiteConverter.from_frozen_graph('minimal_093010.pb', input_arrays=[input_name], output_arrays=[output_name])\r\n\r\nconverter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n\r\ndef representative_dataset_gen():\r\n  image = np.random.randint(low=0, high=255, size=(480, 640, 3))\r\n  image = image.astype(np.float32)\r\n  yield [image]\r\n\r\nconverter.representative_dataset = representative_dataset_gen\r\nconverter.inference_input_type = tf.uint8\r\nconverter.inference_output_type = tf.uint8\r\n\r\nmodel = converter.convert()\r\n```\r\n\r\n**Link to Colab Notebook**\r\n\r\n```\r\nhttps://colab.research.google.com/drive/1CN8iIlznqCMK7hRBwHw8kP2RLamwGZeQ?usp=sharing\r\n```\r\n\r\n**The output from the converter invocation**\r\n\r\n```\r\nRuntimeError: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors.Failed to create calibrator, context already registered.\r\n```\r\n\r\n**Also, please include a link to the saved model or GraphDef**\r\n\r\n```\r\nhttps://drive.google.com/file/d/1dkc3-tYwviEyFJg2Y0IZEyRdTbKj5piF/view?usp=sharing\r\n```\r\n\r\n**Failure details**\r\n```\r\nConversion fails. It is successful for non-quantized tflite graphs, but fails when doing full-integer quantization.\r\n```\r\n\r\n**Traceback**\r\n```\r\nTraceback (most recent call last):\r\n  File \"src/convert_pb_to_tflite.py\", line 60, in <module>\r\n    main()\r\n  File \"src/convert_pb_to_tflite.py\", line 48, in main\r\n    convert_pb_to_tflite_with_quantization(args.pb_graph_path, args.tflite_graph_path)\r\n  File \"src/convert_pb_to_tflite.py\", line 41, in convert_pb_to_tflite_with_quantization\r\n    model = converter.convert()\r\n  File \"/home/yousef/miniconda3/envs/tf15/lib/python3.7/site-packages/tensorflow_core/lite/python/lite.py\", line 993, in convert\r\n    inference_output_type)\r\n  File \"/home/yousef/miniconda3/envs/tf15/lib/python3.7/site-packages/tensorflow_core/lite/python/lite.py\", line 239, in _calibrate_quantize_model\r\n    inference_output_type, allow_float)\r\n  File \"/home/yousef/miniconda3/envs/tf15/lib/python3.7/site-packages/tensorflow_core/lite/python/optimize/calibrator.py\", line 75, in calibrate_and_quantize\r\n    self._calibrator.FeedTensor(calibration_sample)\r\n  File \"/home/yousef/miniconda3/envs/tf15/lib/python3.7/site-packages/tensorflow_core/lite/python/optimize/tensorflow_lite_wrap_calibration_wrapper.py\", line 112, in FeedTensor\r\n    return _tensorflow_lite_wrap_calibration_wrapper.CalibrationWrapper_FeedTensor(self, input_value)\r\nRuntimeError: Attempting to use a delegate that only supports static-sized tensors with a graph that has dynamic-sized tensors.No calibrator found for context.Node number 0 (CONV_2D) failed to invoke.\r\n```", "comments": ["@yousef-xailient \r\nI ran the code shared but got a different error as \"minimal_093010.pb\" is missing, you can share a colab gist with the error reported, please note we would be supporting 2.x issues only, there is no support for 1.x\r\nWith respect to the error shared it shows that the model you are trying to convert does not implicitly support dynamic shaped inputs, you could fix the input tensor size, and refer to [this link](https://medium.com/google-developer-experts/selfie2anime-with-tflite-part-2-tflite-model-84002cf521dc).\r\nPlease upgrade to 2.x and let us know if you face any issues.", "@Saduf2019 \r\n\r\nI've included the link to the pb graph here https://drive.google.com/file/d/1dkc3-tYwviEyFJg2Y0IZEyRdTbKj5piF/view?usp=sharing\r\n\r\nI tried with the latest version of TF (tf-nightly 2.4.0) and the issues I faced are here https://github.com/tensorflow/tensorflow/issues/43661\r\n\r\n", "@yousef-xailient \r\nAs we have the issue tracked at #43661, please move this to closed status, please refer to the points and link shared and update.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43660\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43660\">No</a>\n", "@Saduf2019 could you run the Colab shared in that issue and report back? The points above do not apply to the other issue as the graph converted successfully.", "@yousef-xailient \r\nPlease share the colab with access to view it."]}, {"number": 43659, "title": "[INTEL MKL] Adding CentOS 8 oneDNN partials and dockerfiles", "body": "This PR introduces [oneDNN](https://github.com/oneapi-src/oneDNN) Partials and Dockerfiles for TensorFlow.\r\n\r\nIn order to regenerate the files simply run:\r\n\r\n```\r\n$ cd tensorflow/tools/dockerfiles\r\n$ alias asm_dockerfiles=\"docker run --rm -u $(id -u):$(id -g) -v $(pwd):/tf tf-tools python3 assembler.py \"\r\n$ alias asm_images=\"docker run --rm -v $(pwd):/tf -v /var/run/docker.sock:/var/run/docker.sock tf-tools python3 assembler.py \"\r\n\r\n$ asm_dockerfiles --release dockerfiles --construct_dockerfiles\r\n$ sed -i '' -e 's/Copyright 2019 The TensorFlow Authors/Copyright 2020 The TensorFlow Authors/g' dockerfiles/onednn/*\r\n$ TF_VERSION=2.2.0 && asm_images --release centos-onednn --repository intel/intel-optimized-tensorflow --arg BAZEL_VERSION=2.0.0 --arg TF_BRANCH=v${TF_VERSION} --arg TF_PACKAGE_VERSION=${TF_VERSION} --arg _TAG_PREFIX=${TF_VERSION}-centos --build_images --only_tags_matching '.*centos-.*'\r\n ```\r\nOnce the images are built you should have the following:\r\n```\r\nintel/intel-optimized-tensorflow:2.2.0-centos-8\r\nintel/intel-optimized-tensorflow:2.2.0-centos-8-devel\r\nintel/intel-optimized-tensorflow:2.2.0-centos-8-jupyter\r\nintel/intel-optimized-tensorflow:2.2.0-centos-8-devel-jupyter\r\nintel/intel-optimized-tensorflow:2.2.0-centos-8-mpi-horovod\r\nintel/intel-optimized-tensorflow:2.2.0-centos-8-devel-mpi-horovod\r\nintel/intel-optimized-tensorflow:2.2.0-centos-8-mpi-horovod-jupyter\r\nintel/intel-optimized-tensorflow:2.2.0-centos-8-devel-mpi-horovod-jupyter\r\nintel/intel-optimized-tensorflow:2.2.0-centos-8-mpich-horovod\r\nintel/intel-optimized-tensorflow:2.2.0-centos-8-devel-mpich-horovod\r\nintel/intel-optimized-tensorflow:2.2.0-centos-8-mpich-horovod-jupyter\r\nintel/intel-optimized-tensorflow:2.2.0-centos-8-devel-mpich-horovod-jupyter\r\n```\r\n", "comments": ["Hi @angerson \r\nPlease feel free to review and let me know if you have any questions.\r\n\r\nThanks.", "Hi @angerson \r\nAny feedback on this?", "Thanks for the ping. Sorry I'm late on this.\r\n\r\nI may be missing something, but is there something in the way of combining the many new sections? They look repetitive, so it seems like they could get expanded.", "You mean for `spec.yaml` file? I can look into that.", "Yeah, in spec.yaml. Thanks!\n\nOn Wed, Oct 7, 2020 at 4:12 PM Abolfazl Shahbazi <notifications@github.com>\nwrote:\n\n> You mean for spec.yaml file? I can look into that.\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/pull/43659#issuecomment-705240721>,\n> or unsubscribe\n> <https://github.com/notifications/unsubscribe-auth/AHXWEQCWO25GWZRBJYSRQC3SJTYXDANCNFSM4R6ON4QA>\n> .\n>\n", "Cool. I'll take a stab at simplifying it.", "@ashahba Any update on this PR? Please. Thanks!", "@gbaned I got it bit busy last week, I'll make sure to get this updated again in the next few days.", "Sorry @angerson I've been a bit busy to update this PR. But I'll get to it soon.", "Hi @angerson \r\nThe file a bit more organized now and some duplicates have been removed. Users should be able to generate images this way now:\r\n\r\n```bash\r\nTF_VERSION=2.3.0 && \\\r\nasm_images \\\r\n    --release onednn \\\r\n    --repository intel/intel-optimized-tensorflow \\\r\n    --arg BAZEL_VERSION=3.1.0 \\\r\n    --arg TF_BRANCH=v${TF_VERSION} \\\r\n    --arg TF_PACKAGE_VERSION=${TF_VERSION} \\\r\n    --arg _TAG_PREFIX=${TF_VERSION}-centos \\\r\n    --build_images \\\r\n    --only_tags_matching '.*centos-8-.*$'\r\n```\r\n\r\nand that'll generate the following images:\r\n```\r\nintel/intel-optimized-tensorflow:2.3.0-centos-8\r\nintel/intel-optimized-tensorflow:2.3.0-centos-8-devel\r\nintel/intel-optimized-tensorflow:2.3.0-centos-8-devel-jupyter\r\nintel/intel-optimized-tensorflow:2.3.0-centos-8-devel-mpich-horovod\r\nintel/intel-optimized-tensorflow:2.3.0-centos-8-devel-mpich-horovod-jupyter\r\nintel/intel-optimized-tensorflow:2.3.0-centos-8-devel-mpi-horovod\r\nintel/intel-optimized-tensorflow:2.3.0-centos-8-devel-mpi-horovod-jupyter\r\nintel/intel-optimized-tensorflow:2.3.0-centos-8-jupyter\r\nintel/intel-optimized-tensorflow:2.3.0-centos-8-mpich-horovod\r\nintel/intel-optimized-tensorflow:2.3.0-centos-8-mpich-horovod-jupyter\r\nintel/intel-optimized-tensorflow:2.3.0-centos-8-mpi-horovod\r\nintel/intel-optimized-tensorflow:2.3.0-centos-8-mpi-horovod-jupyter\r\n```\r\n\r\n", "@angerson  Can you please take a look on above comments from @ashahba. Thanks!", "Hi @angerson would you please review?\r\n\r\nThanks.", "Thanks for the ping. I just got back from a long vacation.", "Sounds great @angerson \r\nIf there is any area that I can contribute to, or a design document that you like to review please feel free to tag me.\r\n\r\nThanks."]}, {"number": 43658, "title": "[Intel MKL] Enabling FusedMatMul op with native format", "body": "", "comments": []}, {"number": 43657, "title": "null pointer dereference Error in TF2.3.0 with runforMultipleInputOutput", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Android\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: Samsung A51\r\nTensorFlow installed from (source or binary): Maven\r\nTensorFlow version (use command below): implementation('org.tensorflow:tensorflow-lite:2.3.0'){changing=true}\r\nPython version: n/a\r\nBazel version (if compiling from source): n/a\r\nGCC/Compiler version (if compiling from source): n/a\r\nCUDA/cuDNN version: n/a\r\nGPU model and memory: n/a\r\n\r\n\r\n**Describe the current behavior**\r\n\r\n.tflite generated using tf.lite.TFLiteConverter.from_saved_model\r\ntf_version = 2.3.0\r\nPython Implementation for Inference works without errors.\r\n\r\nusing the same model on Android for inference gives the error-\r\n2020-09-24 07:31:59.732 17121-17121/? A/DEBUG: Cause: null pointer dereference\r\n\r\nDebugging Log - \r\n\r\n\r\n**Model Input Tensor Details**\r\n2020-09-24 07:31:59.284 16761-16761/Processor: hws2:0 2 Input SHAPE- 0\r\n2020-09-24 07:31:59.285 16761-16761/Processor: mask:0 1 1 1 1 Input SHAPE- 1\r\n2020-09-24 07:31:59.285 16761-16761/Processor: image:0 1 1 1 3 Input SHAPE- 2\r\n2020-09-24 07:31:59.285 16761-16761/Processor: hws:0 2 Input SHAPE- 3\r\n\r\n2020-09-24 07:31:59.285 16761-16761/Processor: strided_slice_1:0 1 1 3 Output SHAPE- 0\r\n\r\n**Model Reallocating the Input Tensor**\r\nafter :\r\ntflite.resizeInput(1,dim);\r\ntflite.resizeInput(2,dim);\r\ntflite.allocateTensors();\r\n\r\n**Model Input Tensor Details After Reallocation**\r\n2020-09-24 07:31:59.286 16761-16761/Processor: hws2:0 2 Input SHAPE- 0\r\n2020-09-24 07:31:59.286 16761-16761/Processor: mask:0 1 256 256 1 Input SHAPE- 1\r\n2020-09-24 07:31:59.286 16761-16761/Processor: image:0 1 256 256 3 Input SHAPE- 2\r\n2020-09-24 07:31:59.286 16761-16761/Processor: hws:0 2 Input SHAPE- 3\r\n\r\n2020-09-24 07:31:59.286 16761-16761/Processor: strided_slice_1:0 1 1 3 Output SHAPE- 0\r\n\r\nNotice : Output Shape doesnt changes, which I _assume_ is the correct behavior\r\n\r\nOn Running :\r\ntflite.runForMultipleInputsOutputs(inputs, outputs);\r\n\r\ninputs and outputs are properly initialized and non-null\r\nThis error comes -\r\n\r\n2020-09-24 07:31:59.442 16761-16761/com.package.deepak A/libc: Fatal signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0x0 in tid 16761 (service.deepak), pid 16761 (service.deepak)\r\n\r\n2020-09-24 07:31:59.731 17121-17121/? A/DEBUG: *** *** *** *** *** *** *** *** *** *** *** *** *** *** *** ***\r\n2020-09-24 07:31:59.732 17121-17121/? A/DEBUG: Build fingerprint: Samsung-A50\r\n2020-09-24 07:31:59.732 17121-17121/? A/DEBUG: Revision: '2'\r\n2020-09-24 07:31:59.732 17121-17121/? A/DEBUG: ABI: 'arm64'\r\n2020-09-24 07:31:59.732 17121-17121/? A/DEBUG: pid: 16761, tid: 16761, name: service.deepak >>> com.package.deepak <<<\r\n2020-09-24 07:31:59.732 17121-17121/? A/DEBUG: signal 11 (SIGSEGV), code 1 (SEGV_MAPERR), fault addr 0x0\r\n2020-09-24 07:31:59.732 17121-17121/? A/DEBUG: Cause: null pointer dereference\r\n\r\n2020-09-24 07:41:50.415 18015-18015/? A/DEBUG: backtrace:\r\n2020-09-24 07:41:50.415 18015-18015/? A/DEBUG: #00 pc 000000000001dd6c /system/lib64/libc.so (memcpy+124)\r\n2020-09-24 07:41:50.415 18015-18015/? A/DEBUG: #1 pc 0000000000133560 /data/app/com.package.deepak-fuEaz_w7MUZ9fy7vI4iAfA==/lib/arm64/libtensorflowlite_jni.so\r\n2020-09-24 07:41:50.415 18015-18015/? A/DEBUG: #2 pc 00000000001331e8 /data/app/com.package.deepak-fuEaz_w7MUZ9fy7vI4iAfA==/lib/arm64/libtensorflowlite_jni.so\r\n2020-09-24 07:41:50.415 18015-18015/? A/DEBUG: #3 pc 00000000001b269c /data/app/com.package.deepak-fuEaz_w7MUZ9fy7vI4iAfA==/lib/arm64/libtensorflowlite_jni.so\r\n2020-09-24 07:41:50.415 18015-18015/? A/DEBUG: #4 pc 00000000001b546c /data/app/com.package.deepak-fuEaz_w7MUZ9fy7vI4iAfA==/lib/arm64/libtensorflowlite_jni.so\r\n2020-09-24 07:41:50.415 18015-18015/? A/DEBUG: #5 pc 0000000000046738 /data/app/com.package.deepak-fuEaz_w7MUZ9fy7vI4iAfA==/lib/arm64/libtensorflowlite_jni.so (Java_org_tensorflow_lite_NativeInterpreterWrapper_run+32)\r\n2020-09-24 07:41:50.415 18015-18015/? A/DEBUG: #6 pc 0000000000563be0 /system/lib64/libart.so (art_quick_generic_jni_trampoline+144)\r\n2020-09-24 07:41:50.416 18015-18015/? A/DEBUG: #7 pc 000000000055ae4c /system/lib64/libart.so (art_quick_invoke_static_stub+604)\r\n2020-09-24 07:41:50.416 18015-18015/? A/DEBUG: #8 pc 00000000000d04e8 /system/lib64/libart.so (art::ArtMethod::Invoke(art::Thread*, unsigned int*, unsigned int, art::JValue*, char const*)+232)\r\n2020-09-24 07:41:50.416 18015-18015/? A/DEBUG: #9 pc 00000000002838ac /system/lib64/libart.so (art::interpreter::ArtInterpreterToCompiledCodeBridge(art::Thread*, art::ArtMethod*, art::ShadowFrame*, unsigned short, art::JValue*)+344)\r\n2020-09-24 07:41:50.416 18015-18015/? A/DEBUG: #10 pc 000000000027d8b4 /system/lib64/libart.so (bool art::interpreter::DoCall<false, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+968)\r\n2020-09-24 07:41:50.416 18015-18015/? A/DEBUG: #11 pc 000000000052b750 /system/lib64/libart.so (MterpInvokeStatic+204)\r\n2020-09-24 07:41:50.416 18015-18015/? A/DEBUG: #12 pc 000000000054d394 /system/lib64/libart.so (ExecuteMterpImpl+14612)\r\n2020-09-24 07:41:50.416 18015-18015/? A/DEBUG: #13 pc 000000000021fcf4 /dev/ashmem/dalvik-classes.dex extracted in memory from /data/app/com.package.deepak-fuEaz_w7MUZ9fy7vI4iAfA==/base.apk_17926_17926 (deleted) (org.tensorflow.lite.NativeInterpreterWrapper.run+156)\r\n2020-09-24 07:41:50.416 18015-18015/? A/DEBUG: #14 pc 00000000002575b8 /system/lib64/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEb.llvm.1037722801+488)\r\n2020-09-24 07:41:50.416 18015-18015/? A/DEBUG: #15 pc 000000000025d0ac /system/lib64/libart.so (art::interpreter::ArtInterpreterToInterpreterBridge(art::Thread*, art::CodeItemDataAccessor const&, art::ShadowFrame*, art::JValue*)+216)\r\n2020-09-24 07:41:50.416 18015-18015/? A/DEBUG: #16 pc 000000000027d898 /system/lib64/libart.so (bool art::interpreter::DoCall<false, false>(art::ArtMethod*, art::Thread*, art::ShadowFrame&, art::Instruction const*, unsigned short, art::JValue*)+940)\r\n2020-09-24 07:41:50.416 18015-18015/? A/DEBUG: #17 pc 000000000052a24c /system/lib64/libart.so (MterpInvokeVirtual+588)\r\n2020-09-24 07:41:50.416 18015-18015/? A/DEBUG: #18 pc 000000000054d214 /system/lib64/libart.so (ExecuteMterpImpl+14228)\r\n2020-09-24 07:41:50.417 18015-18015/? A/DEBUG: #19 pc 000000000021f2fe /dev/ashmem/dalvik-classes.dex extracted in memory from /data/app/com.package.deepak-fuEaz_w7MUZ9fy7vI4iAfA==/base.apk_17926_17926 (deleted) (org.tensorflow.lite.Interpreter.runForMultipleInputsOutputs+10)\r\n2020-09-24 07:41:50.417 18015-18015/? A/DEBUG: #20 pc 00000000002575b8 /system/lib64/libart.so (_ZN3art11interpreterL7ExecuteEPNS_6ThreadERKNS_20CodeItemDataAccessorERNS_11ShadowFrameENS_6JValueEb.llvm.1037722801+488)\r\n2020-09-24 07:41:50.417 18015-18015/? A/DEBUG: #21 pc 000000000051aae0 /system/lib64/libart.so (artQuickToInterpreterBridge+1020)\r\n2020-09-24 07:41:50.417 18015-18015/? A/DEBUG: #22 pc 0000000000563cfc /system/lib64/libart.so (art_quick_to_interpreter_bridge+92)\r\n2020-09-24 07:41:50.417 18015-18015/? A/DEBUG: #23 pc 0000000000019ba4 /dev/ashmem/dalvik-jit-code-cache_17926_17926 (deleted) (com.package.deepak.Processor.process+12052)\r\n2020-09-24 07:41:50.417 18015-18015/? A/DEBUG: #24 pc 000000000055aedc /system/lib64/libart.so (art_quick_osr_stub+44)\r\n\r\nDescribe the expected behavior\r\nthe Android code should run.\r\n\r\nPs - Reproducible Code/Model is not available due to confidentiality reasons.", "comments": ["Can you provide a link to the model? It's possible this model has dynamically shaped outputs, which means the output shape depends on *input values*. In which case, the output tensor's shape can't be known until you run evaluation. We're working on making this easier to support with Java, where you can do something like:\r\n\r\n```\r\nFeed Input tensor\r\nRun inference\r\nFetch output tensor\r\n```\r\n\r\nRather than providing input/output buffers in a single invocation.", "> Can you provide a link to the model? It's possible this model has dynamically shaped outputs, which means the output shape depends on _input values_. In which case, the output tensor's shape can't be known until you run evaluation. We're working on making this easier to support with Java, where you can do something like:\r\n> \r\n> ```\r\n> Feed Input tensor\r\n> Run inference\r\n> Fetch output tensor\r\n> ```\r\n> \r\n> Rather than providing input/output buffers in a single invocation.\r\n\r\nThe model is custom made and might not be possible to share.\r\nFurther, as I know how the network will modify the output shape (equal to input image), i am allocating a buffer of that size before inference call.\r\nShape of output = Shape of input with name='image'\r\nNow the input can have varied dimensions. MODEL is converted using (None,None) parameter.\r\n\r\nPS - the same model works fine in Python.", "Can you attach the code you're using to allocate your inputs/outputs, and their respective (Java) buffers?", "> Can you attach the code you're using to allocate your inputs/outputs, and their respective (Java) buffers?\r\n\r\n`\r\nfloat[] image_ = getPixelData(image);\r\nLog.d(TAG, \"Image Float Array \"+image_.length+\" : \"+image_[0]);\r\nByteBuffer imageBuffer = ByteBuffer.allocateDirect(4 * modelH * modelW * 3);\r\nimageBuffer.rewind();\r\nimageBuffer.order(ByteOrder.nativeOrder());\r\nfor (int i = 0; i < image_.length; i++) {\r\n    imageBuffer.putFloat((float) image_[i]);\r\n}\r\nLog.d(TAG, \"Image Buffer Array \"+imageBuffer.getFloat(0)+\" : \"+imageBuffer.capacity());\r\n`\r\n\r\n\r\n`\r\nprivate static float[] getPixelData(Bitmap imageBitmap) {\r\n    if (imageBitmap == null) {\r\n        return null;\r\n    }\r\n    int width = imageBitmap.getWidth();\r\n    int height = imageBitmap.getHeight();\r\n    int inputSize = 256;\r\n    int[] pixels = new int[width * height];\r\n    float[] floatValues = new float[width * height * 3];\r\n    imageBitmap.getPixels(pixels, 0, imageBitmap.getWidth(), 0, 0, imageBitmap.getWidth(), imageBitmap.getHeight());\r\n    int pixel = 0, k = 0;\r\n    for (int i = 0; i < height; ++i) {\r\n        for (int j = 0; j < width; ++j) {\r\n            final int val = pixels[pixel++];\r\n            floatValues[k++] = (float) ((val >> 16) & 0xFF);// - (float) 123.68;            floatValues[k++] = (float) ((val >> 8) & 0xFF);// - (float) 116.779;            floatValues[k++] = (float) (val & 0xFF);// - (float) 103.939;        }\r\n    }\r\n    return floatValues;\r\n}\r\n`\r\n\r\nPS - I dont know why is it showing in single line in preview, while formatting seems fine in EDIT window", "@jdduke any update", "@DeepakG19 \r\nCould you please try on the latest version of tf and let us know if this is still an issue.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43657\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43657\">No</a>\n"]}, {"number": 43656, "title": "TF hangs on HTC Cluster", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow): Yes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): CentOS, Linux 7\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary): Pip, under Anaconda\r\n- TensorFlow version (use command below): 2.2.0, 2.3.0\r\n- Python version: 3.7\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: 10.1.243 / 7.6.5__cuda-10.1\r\n- GPU model and memory: Various - K40, K80, P100, V100 (12-64GB)\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\nI am currently experimenting with running my training jobs on an HTC cluster running the [Slurm](https://slurm.schedmd.com/quickstart.html) job queue manager, however my code just hangs, with no error messages printed. The same code works without issue on my own Ubuntu Deep Learning system, equipped with 2 Titan RTX cards, and also on Google Colab.\r\n\r\nI have a suspicion that this is related to my dataset code, which involves two `from_generator` transforms. This is shown in the code supplied below, in the `get_dataset` function. The first `from_generator` runs a function `load_audio`, which yields batches of audio files from disk. The second, running `get_subseqs`, slices subsequences from the loaded batches, following the [cross-batch statefulness pattern](https://www.tensorflow.org/guide/keras/rnn#cross-batch_statefulness), described in the TensorFlow RNN documentation. So I am feeding subsequences to my RNNs, since there are too many samples to be fed in one go (note that the subsequences retain the batch size).\r\n\r\nIf I remove the first `from_generator` the training _does not_ hang, however. The function `get_dataset_NO_HANG` shows this - it builds a dataset using a _single_ `from_generator`, which runs the `get_rand_seqs` function, which simply yields randomly generated subsequences.\r\n\r\n**Describe the expected behavior**\r\n\r\nIt shouldn't just hang forever, with no info...\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n```\r\nimport os\r\nimport fnmatch\r\nimport random\r\nimport time\r\nimport tensorflow as tf\r\nimport numpy as np\r\n#import librosa\r\n\r\nNUM_EPOCHS = 2\r\nBATCH_SIZE = 16\r\nFRAME_SIZE = 64\r\nNUM_BATCHES = 4\r\nSEQ_LEN = 1024\r\nOVERLAP = FRAME_SIZE\r\nNUM_SAMPS = 128000 + OVERLAP\r\n\r\n##################### DATASET #####################\r\n\r\ndef find_files(directory, pattern='*.wav'):\r\n    '''Recursively finds all files matching the pattern.'''\r\n    files = []\r\n    for root, dirnames, filenames in os.walk(directory):\r\n        for filename in fnmatch.filter(filenames, pattern):\r\n            files.append(os.path.join(root, filename))\r\n    random.shuffle(files)\r\n    return files\r\n\r\n# This can load audio files (preferably of only a few seconds long!), but I have commented out that code\r\n# and replaced with a line that simply generates some arrays of random 'samples'...\r\ndef load_audio(files, batch_size):\r\n    #for filename in files:\r\n    for filename in range(0, 350):\r\n        #(audio, _) = librosa.load(filename, sr=None, mono=True)\r\n        audio = np.random.randint(0, 256, size=(batch_size * NUM_SAMPS))\r\n        audio = audio.reshape(-1, 1)\r\n        print(\"Loading corpus entry {}\".format(filename))\r\n        yield audio\r\n\r\ndef pad_batch(batch, batch_size, seq_len, overlap):\r\n    num_samps = ( int(np.floor(len(batch[0]) / float(seq_len))) * seq_len )\r\n    zeros = np.zeros([batch_size, overlap, 1], dtype='float32')\r\n    return tf.concat([zeros, batch[:, :num_samps, :]], axis=1)\r\n\r\ndef get_subseqs(dataset, batch_size, seq_len, overlap):\r\n    for batch in dataset:\r\n        num_samps = len(batch[0])\r\n        for i in range(overlap, num_samps, seq_len):\r\n            x = batch[:, i-overlap : i+seq_len]\r\n            y = x[:, overlap : overlap+seq_len]\r\n            yield (x, y)\r\n\r\ndef get_dataset(files=None, num_epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, overlap=OVERLAP,\r\n                seq_len=SEQ_LEN, drop_remainder=False):\r\n    dataset = tf.data.Dataset.from_generator(\r\n        lambda: load_audio(files, batch_size),\r\n        output_types=tf.float32,\r\n        output_shapes=((None, 1))\r\n    )\r\n    dataset = dataset.repeat(num_epochs).batch(batch_size, drop_remainder)\r\n    dataset = dataset.map(lambda batch: tf.py_function(\r\n        func=pad_batch, inp=[batch, batch_size, seq_len, overlap], Tout=tf.float32\r\n    ))\r\n    return tf.data.Dataset.from_generator(\r\n        lambda: get_subseqs(dataset, batch_size, seq_len, overlap),\r\n        output_types=(tf.int32, tf.int32),\r\n        output_shapes=(\r\n            (batch_size, seq_len + overlap, 1),\r\n            (batch_size, seq_len, 1)))\r\n\r\n# If we use the following there is NO hang...\r\n\r\ndef get_rand_seqs(num_samps, num_batches=NUM_BATCHES, batch_size=BATCH_SIZE, overlap=OVERLAP, seq_len=SEQ_LEN):\r\n    time.sleep(0.03)\r\n    for _ in range(0, num_batches):\r\n        batch = np.random.randint(0, 256, size=(batch_size * num_samps))\r\n        batch = batch.reshape((batch_size, num_samps, 1))\r\n        for i in range(overlap, num_samps, seq_len):\r\n            x = batch[:, i-overlap : i+seq_len]\r\n            y = x[:, overlap : overlap+seq_len]\r\n            yield (x, y)\r\n\r\ndef get_dataset_NO_HANG(num_epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, overlap=OVERLAP, seq_len=SEQ_LEN):\r\n    dataset = tf.data.Dataset.from_generator(\r\n        lambda: get_subseqs(NUM_SAMPS),\r\n        output_types=(tf.int32, tf.int32),\r\n        output_shapes=(\r\n            (batch_size, seq_len + overlap, 1),\r\n            (batch_size, seq_len, 1)))\r\n    dataset = dataset.repeat(num_epochs)\r\n    return dataset\r\n\r\n##################### MODEL #####################\r\n\r\n# This is just a dummy model, not my real one, although I do make extensive use of RNNs...\r\nclass TestModel(tf.keras.Model):\r\n\r\n    def __init__(self, frame_size=FRAME_SIZE, dim=1024):\r\n        super(TestModel, self).__init__()\r\n        self.frame_size = frame_size\r\n        self.q_levels = 256\r\n        self.dim = dim\r\n        self.num_lower_tier_frames = 4\r\n        self.input_expand = tf.keras.layers.Dense(self.dim)\r\n        self.rnn = tf.keras.layers.GRU(self.dim, return_sequences=True, stateful=True)\r\n        self.upsample = tf.Variable(\r\n            tf.initializers.GlorotNormal()(\r\n                shape=[self.num_lower_tier_frames, self.dim, self.dim]),\r\n            name=\"upsample\",\r\n        )\r\n        self.out = tf.keras.layers.Dense(self.q_levels, activation='relu')\r\n\r\n    def train_step(self, data):\r\n        (x, y) = data\r\n        with tf.GradientTape() as tape:\r\n            raw_output = self(x, training=True)\r\n            prediction = tf.reshape(raw_output, [-1, self.q_levels])\r\n            target = tf.reshape(y, [-1])\r\n            loss = self.compiled_loss(\r\n                target,\r\n                prediction,\r\n                regularization_losses=self.losses)\r\n        grads = tape.gradient(loss, self.trainable_variables)\r\n        grads, _ = tf.clip_by_global_norm(grads, 5.0)\r\n        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\r\n        self.compiled_metrics.update_state(target, prediction)\r\n        return {metric.name: metric.result() for metric in self.metrics}\r\n\r\n    def call(self, input):\r\n        batch_size = tf.shape(input)[0]\r\n        input = tf.cast(input[:, : -self.frame_size, :], tf.float32)\r\n        frames = tf.reshape(input, [\r\n            batch_size,\r\n            tf.shape(input)[1] // self.frame_size,\r\n            self.frame_size\r\n        ])\r\n        num_steps = tf.shape(frames)[1]\r\n        frames = self.input_expand(frames)\r\n        hidden = self.rnn(frames)\r\n        output_shape = [\r\n            batch_size,\r\n            num_steps * self.num_lower_tier_frames,\r\n            self.dim\r\n        ]\r\n        outputs = tf.nn.conv1d_transpose(\r\n            hidden,\r\n            self.upsample,\r\n            strides=self.num_lower_tier_frames,\r\n            output_shape=output_shape,\r\n        )\r\n        return self.out(tf.transpose(outputs, perm=(0,2,1)))\r\n\r\n##################### TRAINING #####################\r\n\r\n#files = find_files('path/to/wavs') # Leave this as is, no audio needs to be loaded\r\ntrain_dataset = get_dataset() # This hangs on the HTC, but get_dataset_NO_HANG does not...\r\n\r\nmodel = TestModel()\r\n\r\nopt = tf.optimizers.Adam(learning_rate=0.001, epsilon=1e-4)\r\ncompute_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\r\ntrain_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\r\nmodel.compile(optimizer=opt, loss=compute_loss, metrics=[train_accuracy])\r\n\r\nmodel.fit(\r\n    train_dataset,\r\n    epochs=NUM_EPOCHS,\r\n    steps_per_epoch=500,\r\n    shuffle=False\r\n)\r\n```\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n\r\nNo error messages are produced.\r\n\r\nI submit a job using `sbatch <my_run_script.sh>` on the login node, and the system then runs the code on a GPU node. I don't have enough access to the Slurm cluster where I am running my code to investigate what be going on behind the scenes, and I don't have enough knowledge/experience of such systems to be able to hazard a guess (I know that the login node in the cluster runs CentOS... I run my code under Anaconda, with TF 2.2.0, also tried TF 2.3.0 but same issues). So I have no idea what's going on, it's quite baffling. It does seem to be related to the above code, however.\r\n", "comments": ["I have fixed some typo errors in the posted code.", "Update: Even enumerating the dataset on the HTC hangs:\r\n\r\n```\r\nfor (i, (x, y)) in enumerate(train_dataset):\r\n    print(i)\r\n    time.sleep(0.2)\r\n    print(tf.shape(x))\r\n    print(tf.shape(y))\r\n```\r\n\r\nthe above produces nothing on that system, but works everywhere else.", "As mentioned in the template by @relativeflux, I was able to run the code without any issues on Google Colab. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/df99e89a30ecd5a769d467761f3b82fb/43656.ipynb). Thanks!", "**UPDATE**: Removing the second `from_generator` and just returning from the `map` transform works in the HTC environment. So, if I define `get_dataset` thus:\r\n\r\n```\r\ndef get_dataset(files=None, num_epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, overlap=OVERLAP,\r\n                seq_len=SEQ_LEN, drop_remainder=False):\r\n    dataset = tf.data.Dataset.from_generator(\r\n        lambda: load_audio(files, batch_size),\r\n        output_types=tf.float32,\r\n        output_shapes=((None, 1))\r\n    )\r\n    dataset = dataset.repeat(num_epochs).batch(batch_size, drop_remainder)\r\n    return dataset.map(lambda batch: tf.py_function(\r\n        func=pad_batch, inp=[batch, batch_size, seq_len, overlap], Tout=tf.float32\r\n    ))\r\n```\r\n\r\nand then just\r\n\r\n```\r\nfor (i, x) in enumerate(train_dataset):\r\n    print(i)\r\n    time.sleep(0.2)\r\n    print(tf.shape(x))\r\n```\r\n\r\n..._that_ works... Evidently _something_ within the context of the HTC environment is interfering with the execution of the second `from_generator`.\r\n", "Using a dataset iterator instead of a second `from_generator` works on the HTC:\r\n\r\n```\r\ndef get_dataset(files=None, num_epochs=NUM_EPOCHS, batch_size=BATCH_SIZE, overlap=OVERLAP,\r\n                  seq_len=SEQ_LEN, drop_remainder=False):\r\n    dataset = tf.data.Dataset.from_generator(\r\n        lambda: load_audio(files, batch_size),\r\n        output_types=tf.float32,\r\n        output_shapes=((None, 1))\r\n    )\r\n    dataset = dataset.repeat(num_epochs).batch(batch_size, drop_remainder)\r\n    return dataset.map(lambda batch: tf.py_function(\r\n        func=pad_batch, inp=[batch, batch_size, seq_len, overlap], Tout=tf.float32\r\n    ))\r\n\r\ndef ds_iter(dataset, seq_len=SEQ_LEN, overlap=OVERLAP):\r\n    for batch in dataset:\r\n        print('ds_iter')\r\n        num_samps = len(batch[0])\r\n        for i in range(overlap, num_samps, seq_len):\r\n            x = batch[:, i-overlap : i+seq_len]\r\n            y = x[:, overlap : overlap+seq_len]\r\n            yield (x, y)\r\n\r\ndataset = get_dataset(drop_remainder=True)\r\ngen = ds_iter(dataset)\r\nfor (i, (x, y)) in enumerate(gen):\r\n    print(i)\r\n    time.sleep(0.2)\r\n    print(tf.shape(x))\r\n    print(tf.shape(y))\r\n```\r\n\r\nIn fact the above is what I was originally doing, passing the generator to `fit` (as `x`). I consolidated everything into a dataset because I also use `validation_data` arg to `fit`, and [the docs say](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit) that 'validation_data does not support all the data types that are supported in x, eg, dict, generator or keras.utils.Sequence'... But is this the case? Because if not I can just revert back to the above pattern. [This](https://stackoverflow.com/a/60003165/795131) StackOverflow answer indicates that a generator _can_ in fact be passed to `validation_data`.", "This is now resolved. I have been in touch with the administrators of the cluster, and with their help was able to establish that it was caused by the Slurm `--ntasks-per-node` setting being too low (it was set to 1). That param just manages the number of CPUs available for a given task on a cluster node, and increasing it to 5 resolved the issue.\r\n\r\nI don't have any info as to whether this might be something arising from the interaction between the Slurm system and TensorFlow, however.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43656\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43656\">No</a>\n"]}, {"number": 43654, "title": "can't compile tensorflow from source", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Linux Ubuntu 20.04\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 2.3.0\r\n- Python version:3.8.2\r\n- Installed using virtualenv? pip? conda?: pip \r\n- Bazel version (if compiling from source): 3.1.0\r\n- GCC/Compiler version (if compiling from source):9.3.0\r\n- CUDA/cuDNN version: 10.1/7\r\n- GPU model and memory: 1070 ti\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\n**Provide the exact sequence of commands / steps that you executed before running into the problem**\r\ni can't compile tensorflow from source, i tried to use different versions of cuda and cudn, i tried to compile without using cuda libraries, but nothing works. I do not know what I am doing wrong, I follow the instructions https://www.tensorflow.org/install/source, but I keep getting the error\r\n\r\n**how i write the config file**\r\ndmitry@future:~/tensorflow$ ./configure\r\nYou have bazel 3.1.0 installed.\r\nPlease specify the location of python. [Default is /usr/bin/python3]: \r\n\r\n\r\nFound possible Python library paths:\r\n  /usr/lib/python3/dist-packages\r\n  /usr/local/lib/python3.8/dist-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/lib/python3/dist-packages]\r\n\r\nDo you wish to build TensorFlow with ROCm support? [y/N]: n\r\nNo ROCm support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with CUDA support? [y/N]: y\r\nCUDA support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with TensorRT support? [y/N]: n\r\nNo TensorRT support will be enabled for TensorFlow.\r\n\r\nFound CUDA 10.1 in:\r\n    /usr/local/cuda-10.1/targets/x86_64-linux/lib\r\n    /usr/local/cuda-10.1/targets/x86_64-linux/include\r\nFound cuDNN 7 in:\r\n    /usr/lib/x86_64-linux-gnu\r\n    /usr/include\r\n\r\n\r\nPlease specify a list of comma-separated CUDA compute capabilities you want to build with.\r\nYou can find the compute capability of your device at: https://developer.nvidia.com/cuda-gpus. Each capability can be specified as \"x.y\" or \"compute_xy\" to include both virtual and binary GPU code, or as \"sm_xy\" to only include the binary code.\r\nPlease note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only supports compute capabilities >= 3.5 [Default is: 6.1]: \r\n\r\n\r\nDo you want to use clang as CUDA compiler? [y/N]: y\r\nClang will be used as CUDA compiler.\r\n\r\nDo you wish to download a fresh release of clang? (Experimental) [y/N]: n\r\nClang will not be downloaded.\r\n\r\nPlease specify which clang should be used as device and host compiler. [Default is /usr/bin/clang]: \r\n\r\n\r\nPlease specify optimization flags to use during compilation when bazel option \"--config=opt\" is specified [Default is -march=native -Wno-sign-compare]: -march=native -mno-avx\r\n\r\n\r\nWould you like to interactively configure ./WORKSPACE for Android builds? [y/N]: n\r\nNot configuring the WORKSPACE for Android builds.\r\n\r\nPreconfigured Bazel build configs. You can use any of the below by adding \"--config=<>\" to your build command. See .bazelrc for more details.\r\n        --config=mkl            # Build with MKL support.\r\n        --config=monolithic     # Config for mostly static monolithic build.\r\n        --config=ngraph         # Build with Intel nGraph support.\r\n        --config=numa           # Build with NUMA support.\r\n        --config=dynamic_kernels        # (Experimental) Build kernels into separate shared objects.\r\n        --config=v2             # Build TensorFlow 2.x instead of 1.x.\r\nPreconfigured Bazel build configs to DISABLE default on features:\r\n        --config=noaws          # Disable AWS S3 filesystem support.\r\n        --config=nogcp          # Disable GCP support.\r\n        --config=nohdfs         # Disable HDFS support.\r\n        --config=nonccl         # Disable NVIDIA NCCL support.\r\nConfiguration finished\r\n\r\n\r\n**here is the output of the compilation process**\r\ndmitry@future:~/tensorflow$ bazel build --config=cuda [--config=option] //tensorflow/tools/pip_package:build_pip_package\r\nWARNING: The following configs were expanded more than once: [cuda_clang, using_cuda]. For repeatable flags, repeats are counted twice and may lead to unexpected behavior.\r\nINFO: Options provided by the client:\r\n  Inherited 'common' options: --isatty=1 --terminal_columns=236\r\nINFO: Reading rc options for 'build' from /home/dmitry/tensorflow/.bazelrc:\r\n  Inherited 'common' options: --experimental_repo_remote_exec\r\nINFO: Reading rc options for 'build' from /home/dmitry/tensorflow/.bazelrc:\r\n  'build' options: --apple_platform_type=macos --define framework_shared_object=true --define open_source_build=true --java_toolchain=//third_party/toolchains/java:tf_java_toolchain --host_java_toolchain=//third_party/toolchains/java:tf_java_toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=0 --define=use_fast_cpp_protos=true --define=allow_oversize_protos=true --spawn_strategy=standalone -c opt --announce_rc --define=grpc_no_ares=true --noincompatible_remove_legacy_whole_archive --noincompatible_prohibit_aapt1 --enable_platform_specific_config --config=short_logs --config=v2\r\nINFO: Reading rc options for 'build' from /home/dmitry/tensorflow/.tf_configure.bazelrc:\r\n  'build' options: --action_env PYTHON_BIN_PATH=/usr/bin/python3 --action_env PYTHON_LIB_PATH=/usr/lib/python3/dist-packages --python_path=/usr/bin/python3 --config=xla --action_env CUDA_TOOLKIT_PATH=/usr/local/cuda-10.1 --action_env TF_CUDA_COMPUTE_CAPABILITIES=6.1 --config=cuda_clang --action_env CLANG_CUDA_COMPILER_PATH=/usr/bin/clang --config=cuda_clang --action_env TF_CONFIGURE_IOS=0\r\nINFO: Found applicable config definition build:short_logs in file /home/dmitry/tensorflow/.bazelrc: --output_filter=DONT_MATCH_ANYTHING\r\nINFO: Found applicable config definition build:v2 in file /home/dmitry/tensorflow/.bazelrc: --define=tf_api_version=2 --action_env=TF2_BEHAVIOR=1\r\nINFO: Found applicable config definition build:xla in file /home/dmitry/tensorflow/.bazelrc: --define=with_xla_support=true\r\nINFO: Found applicable config definition build:cuda_clang in file /home/dmitry/tensorflow/.bazelrc: --config=using_cuda --define=using_cuda_clang=true --define=using_clang=true --action_env TF_CUDA_CLANG=1\r\nINFO: Found applicable config definition build:using_cuda in file /home/dmitry/tensorflow/.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=1\r\nINFO: Found applicable config definition build:cuda_clang in file /home/dmitry/tensorflow/.bazelrc: --config=using_cuda --define=using_cuda_clang=true --define=using_clang=true --action_env TF_CUDA_CLANG=1\r\nINFO: Found applicable config definition build:using_cuda in file /home/dmitry/tensorflow/.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=1\r\nINFO: Found applicable config definition build:cuda in file /home/dmitry/tensorflow/.bazelrc: --config=using_cuda --define=using_cuda_nvcc=true\r\nINFO: Found applicable config definition build:using_cuda in file /home/dmitry/tensorflow/.bazelrc: --define=using_cuda=true --action_env TF_NEED_CUDA=1 --crosstool_top=@local_config_cuda//crosstool:toolchain --define=tensorflow_enable_mlir_generated_gpu_kernels=1\r\nINFO: Found applicable config definition build:linux in file /home/dmitry/tensorflow/.bazelrc: --copt=-w --host_copt=-w --define=PREFIX=/usr --define=LIBDIR=$(PREFIX)/lib --define=INCLUDEDIR=$(PREFIX)/include --cxxopt=-std=c++14 --host_cxxopt=-std=c++14 --config=dynamic_kernels\r\nINFO: Found applicable config definition build:dynamic_kernels in file /home/dmitry/tensorflow/.bazelrc: --define=dynamic_loaded_kernels=true --copt=-DAUTOLOAD_DYNAMIC_KERNELS\r\nERROR: Skipping '[--config=option]': no such target '//:[--config=option]': target '[--config=option]' not declared in package '' defined by /home/dmitry/tensorflow/BUILD\r\nERROR: no such target '//:[--config=option]': target '[--config=option]' not declared in package '' defined by /home/dmitry/tensorflow/BUILD\r\nINFO: Elapsed time: 0.267s\r\nINFO: 0 processes.\r\nFAILED: Build did NOT complete successfully (0 packages loaded)\r\n    currently loading: tensorflow/tools/pip_package\r\n\r\nI really don't understand what the problem is, because I tried to do everything according to the instructions. I would be very grateful if you could help me. My thanks\r\n", "comments": ["`bazel build --config=cuda //tensorflow/tools/pip_package:build_pip_package`\r\n\r\n` [--config=option]` it is just a placeholder/template. It means: add  manually other config options if you need.\r\n", "Yes indeed. I thought that the [--config = option] parameter was needed to explicitly tell bazel that options should be read from the config file, I was wrong. Silly mistake. I am very grateful to you,my thanks", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43654\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43654\">No</a>\n"]}, {"number": 43653, "title": "tensorflow.keras.backend.dot does not work as expected when second argument is 3-dimensional or higher", "body": "# System information\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n    - Yes (but reproducing this bug requires very minimal code)\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n    - Manjaro Linux (rolling release)\r\n- TensorFlow installed from (source or binary):\r\n    - binary\r\n- TensorFlow version (use command below):\r\n    - git version: v2.3.0-rc2-23-gb36436b087 (2.3.0)\r\n- Python version:\r\n    - python 3.8\r\n\r\n# Describe the current behavior\r\n\r\ntensorflow.keras.backend.dot does not compute dot product along expected axes. It computes dot product along the last axis of the first argument and along the next-to-last axis of the second argument.\r\n\r\n# Describe the expected behavior\r\n\r\nI expect dot product to be computed along the last axis of the first argument and the first axes of the second argument. (Note that this only differs from the current behavior if the second argument is 3-dimensional or higher.)\r\n\r\n# Note\r\n\r\nThis behavior is not incorrect *per se*, rather it is unconventional and unexpected and therefore it can cause extremely mysterious errors. At the very least, this behavior should be included in the documentation (it is not currently documented) with a few more examples to illustrate. Perhaps this is the best solution to avoid breaking the code of people who have figured out this subtlety and used it extensively.\r\n\r\n# Standalone code to reproduce the issue\r\n\r\n### Example 1:\r\n```\r\nimport tensorflow.keras.backend as K\r\n\r\nx = K.placeholder(shape=(1, 2))\r\ny = K.placeholder(shape=(2, 3, 4))\r\n\r\nprint(K.dot(x, y))\r\n```\r\nI expect this to print a placeholder tensor of shape `(1, 3, 4)`, but instead, I get a long traceback, the last line of which is:\r\n```\r\nValueError: Dimensions must be equal, but are 2 and 3 for '{{node MatMul_3}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Reshape_7, Reshape_8)' with input shapes: [1,2], [3,8].\r\n```\r\n(see below for full traceback)\r\n\r\n### Example 2:\r\n```\r\nx = K.placeholder(shape=(1, 2))\r\ny = K.placeholder(shape=(3, 2, 4))\r\n\r\nprint(K.dot(x, y))\r\n```\r\nI would expect this to raise an error because the last dimension of `x` does not match the first dimension of `y`. Instead, this prints a placeholder tensor of shape `(1,3,4)` indicating that the dot product was computed along the last axis of `x` and the next-to-last axis of `y`.\r\n\r\n### Example 3:\r\n```\r\nx = K.placeholder(shape=(1, 2))\r\ny = K.placeholder(shape=(3, 4, 5, 6, 7, 2, 8))\r\n\r\nprint(K.dot(x, y))\r\n```\r\nAgain, I expect this to raise an error, but the dot product is computed without complaint.\r\n\r\n# Other info / logs\r\n\r\nTraceback from Example 1 above:\r\n```\r\n---------------------------------------------------------------------------\r\nInvalidArgumentError                      Traceback (most recent call last)\r\n~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py in _create_c_op(graph, node_def, inputs, control_inputs, op_def)\r\n   1811   try:\r\n-> 1812     c_op = pywrap_tf_session.TF_FinishOperation(op_desc)\r\n   1813   except errors.InvalidArgumentError as e:\r\n\r\nInvalidArgumentError: Dimensions must be equal, but are 2 and 3 for '{{node MatMul_5}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Reshape_12, Reshape_13)' with input shapes: [1,2], [3,8].\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-34-711261b03ba4> in <module>\r\n----> 1 K.dot(x, y)\r\n\r\n~/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)\r\n    199     \"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\r\n    200     try:\r\n--> 201       return target(*args, **kwargs)\r\n    202     except (TypeError, ValueError):\r\n    203       # Note: convert_to_eager_tensor currently raises a ValueError, not a\r\n\r\n~/.local/lib/python3.8/site-packages/tensorflow/python/keras/backend.py in dot(x, y)\r\n   1825         array_ops.transpose(y, perm=y_permute_dim), [y_shape[-2], -1])\r\n   1826     return array_ops.reshape(\r\n-> 1827         math_ops.matmul(xt, yt), x_shape[:-1] + y_shape[:-2] + y_shape[-1:])\r\n   1828   if is_sparse(x):\r\n   1829     out = sparse_ops.sparse_tensor_dense_matmul(x, y)\r\n\r\n~/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py in wrapper(*args, **kwargs)\r\n    199     \"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\r\n    200     try:\r\n--> 201       return target(*args, **kwargs)\r\n    202     except (TypeError, ValueError):\r\n    203       # Note: convert_to_eager_tensor currently raises a ValueError, not a\r\n\r\n~/.local/lib/python3.8/site-packages/tensorflow/python/ops/math_ops.py in matmul(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\r\n   3252       return ret\r\n   3253     else:\r\n-> 3254       return gen_math_ops.mat_mul(\r\n   3255           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\r\n   3256 \r\n\r\n~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_math_ops.py in mat_mul(a, b, transpose_a, transpose_b, name)\r\n   5638     transpose_b = False\r\n   5639   transpose_b = _execute.make_bool(transpose_b, \"transpose_b\")\r\n-> 5640   _, _, _op, _outputs = _op_def_library._apply_op_helper(\r\n   5641         \"MatMul\", a=a, b=b, transpose_a=transpose_a, transpose_b=transpose_b,\r\n   5642                   name=name)\r\n\r\n~/.local/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py in _apply_op_helper(op_type_name, name, **keywords)\r\n    740       # Add Op to graph\r\n    741       # pylint: disable=protected-access\r\n--> 742       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\r\n    743                                  name=scope, input_types=input_types,\r\n    744                                  attrs=attr_protos, op_def=op_def)\r\n\r\n~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py in _create_op_internal(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\r\n    589       inp = self.capture(inp)\r\n    590       inputs[i] = inp\r\n--> 591     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\r\n    592         op_type, inputs, dtypes, input_types, name, attrs, op_def,\r\n    593         compute_device)\r\n\r\n~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py in _create_op_internal(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\r\n   3475     # Session.run call cannot occur between creating and mutating the op.\r\n   3476     with self._mutation_lock():\r\n-> 3477       ret = Operation(\r\n   3478           node_def,\r\n   3479           self,\r\n\r\n~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py in __init__(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\r\n   1972       if op_def is None:\r\n   1973         op_def = self._graph._get_op_def(node_def.op)\r\n-> 1974       self._c_op = _create_c_op(self._graph, node_def, inputs,\r\n   1975                                 control_input_ops, op_def)\r\n   1976       name = compat.as_str(node_def.name)\r\n\r\n~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py in _create_c_op(graph, node_def, inputs, control_inputs, op_def)\r\n   1813   except errors.InvalidArgumentError as e:\r\n   1814     # Convert to ValueError for backwards compatibility.\r\n-> 1815     raise ValueError(str(e))\r\n   1816 \r\n   1817   return c_op\r\n\r\nValueError: Dimensions must be equal, but are 2 and 3 for '{{node MatMul_5}} = MatMul[T=DT_FLOAT, transpose_a=false, transpose_b=false](Reshape_12, Reshape_13)' with input shapes: [1,2], [3,8].\r\n```", "comments": ["There are of course plenty of workarounds: You can simply reshape your data, or you can use `tensorflow.tensordot(x, y, axes=(-1, 0))`.", "Was able to reproduce the issue with TF v2.3 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/81fe29b0ab56a1678f0dff40f2c6b61c/43653-tf-nightly.ipynb). Thanks!", "@Doekeb Looks like this is intended. I checked `numpy` as follows and numpy also throws similar error.\r\n\r\n```\r\nimport numpy as np\r\nnp.dot(np.ones((1,2),dtype=np.int32),np.ones((2,3,4),dtype=np.int32))\r\n\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-14-589d6aaa8220> in <module>()\r\n----> 1 np.dot(np.ones((1,2),dtype=np.int32),np.ones((2,3,4),dtype=np.int32))\r\n\r\n<__array_function__ internals> in dot(*args, **kwargs)\r\n\r\nValueError: shapes (1,2) and (2,3,4) not aligned: 2 (dim 1) != 3 (dim 1)\r\n```\r\n", "@jvishnuvardhan Thanks for checking it out so quickly and for the numpy reference! I am willing to accept that this is intended behavior, however I do insist that it should be explained in tensorflow documentation (see my note in the original report).\r\n\r\nIndeed, the numpy docstring includes the following:\r\n```\r\n- If `a` is an N-D array and `b` is an M-D array (where ``M>=2``), it is a\r\n  sum product over the last axis of `a` and the second-to-last axis of `b`::\r\n\r\n    dot(a, b)[i,j,k,m] = sum(a[i,j,:] * b[k,:,m])\r\n```\r\nBut no such explanation (nor illustrative example) is found in the current tensorflow documentation which reads in its entirety as follows:\r\n```\r\nSignature: tf.keras.backend.dot(x, y)\r\nDocstring:\r\nMultiplies 2 tensors (and/or variables) and returns a tensor.\r\n\r\nArguments:\r\n    x: Tensor or variable.\r\n    y: Tensor or variable.\r\n\r\nReturns:\r\n    A tensor, dot product of `x` and `y`.\r\n\r\nExamples:\r\n\r\n>>> x = tf.keras.backend.placeholder(shape=(2, 3))\r\n>>> y = tf.keras.backend.placeholder(shape=(3, 4))\r\n>>> xy = tf.keras.backend.dot(x, y)\r\n>>> xy\r\n<tf.Tensor ... shape=(2, 4) dtype=float32>\r\n\r\n>>> x = tf.keras.backend.placeholder(shape=(32, 28, 3))\r\n>>> y = tf.keras.backend.placeholder(shape=(3, 4))\r\n>>> xy = tf.keras.backend.dot(x, y)\r\n>>> xy\r\n<tf.Tensor ... shape=(32, 28, 4) dtype=float32>\r\n\r\n>>> x = tf.keras.backend.random_uniform_variable(shape=(2, 3), low=0, high=1)\r\n>>> y = tf.keras.backend.ones((4, 3, 5))\r\n>>> xy = tf.keras.backend.dot(x, y)\r\n>>> tf.keras.backend.int_shape(xy)\r\n(2, 4, 5)\r\nFile:      ~/.local/lib/python3.8/site-packages/tensorflow/python/keras/backend.py\r\nType:      function\r\n```", "@Doekeb Thanks for the detailed information. Sure. we will update it soon. Thanks!", "@Doekeb we have updated it and it will take some time to reflect on TF website. Thanks for raising this issue.\r\n\r\nI am closing this issue as this was resolved. Thanks!", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43653\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43653\">No</a>\n"]}, {"number": 43652, "title": "Support 5D tensors in the binary ops of Grappler Layout Optimizer (part 2)", "body": "This is to fix some issue found in https://github.com/tensorflow/tensorflow/pull/43166.\r\n\r\n@andyly @nluehr ", "comments": ["As https://github.com/tensorflow/tensorflow/pull/43166 was rolled back, can you rebase that PR into this one also?", "> As #43166 was rolled back, can you rebase that PR into this one also?\r\n\r\nSure. Rebased all the changes on top of master."]}, {"number": 43651, "title": "Error \"Cannot iterate over a tensor with unknown first dimension\" when using TF Keras Attention Layer.", "body": "Hello,\r\nI'm trying to implement a Text Summarizing model Seq2Seq model with Attention layer, while building the layer, I'm getting the above error exactly at Attention Layer which is imported from TF Keras Layer.\r\n\r\nCode Section:\r\n`# Decoder\r\ndecoder_input = Input(shape=(None,))\r\ndecoder_embed = Embedding(y_vocab_size, embedding_dim, trainable=True)(decoder_input)\r\n\r\ndecoder_lstm1 = LSTM(300, return_state=True, return_sequences=True, dropout=0.4)\r\ndecoder_lstm_output, decoder_h, decoder_c = decoder_lstm1(decoder_embed, initial_state=[encoder_h, encoder_c])\r\n\r\natt_output, att_state = Attention()([encoder_output, decoder_lstm_output])\r\ndecoder_concat_output = Concatenate(axis=-1)([decoder_lstm_output, attn_out])\r\n\r\nError:\r\nTypeError                                 Traceback (most recent call last)\r\n<ipython-input-13-a3d0f9f7e616> in <module>()\r\n     25 decoder_lstm_output, decoder_h, decoder_c = decoder_lstm1(decoder_embed, initial_state=[encoder_h, encoder_c])\r\n     26 \r\n---> 27 att_output, att_state = Attention()([encoder_output, decoder_lstm_output])\r\n     28 decoder_concat_output = Concatenate(axis=-1)([decoder_lstm_output, attn_out])\r\n     29 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/ops.py in __iter__(self)\r\n    510     if shape[0] is None:\r\n    511       raise TypeError(\r\n--> 512           \"Cannot iterate over a tensor with unknown first dimension.\")\r\n    513     return _TensorIterator(self, shape[0])\r\n    514 \r\n\r\nTypeError: Cannot iterate over a tensor with unknown first dimension.`\r\n\r\nCan anyone please help me on this? I'm sharing the link to Colab notebook as well. Thanks!\r\n\r\nGoogle Colab Notebook Link:\r\nhttps://colab.research.google.com/drive/1EvxOwIH8yeqS7pRJh9aNF-XXoj0N0uQw?usp=sharing", "comments": ["@BlueLobster413 \r\nplease refer to [this link](https://stackoverflow.com/questions/56351377/tensorflow-2-0-input-being-creating-with-first-shape-element-as-none) and let us know if it helps. [also [link](https://www.xspdf.com/resolution/50082506.html) ]", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "> @BlueLobster413\r\n> please refer to [this link](https://stackoverflow.com/questions/56351377/tensorflow-2-0-input-being-creating-with-first-shape-element-as-none) and let us know if it helps. [also [link](https://www.xspdf.com/resolution/50082506.html) ]\r\n\r\nI tried above solutions but didn't worked for me, Did you find any other alternate solutions", "@dineshy98 \r\nCould you please open a new issue with all the required information for us to analyse.", "@dineshy98 did you manage to solve this issue?"]}, {"number": 43649, "title": "Unable to convert simple LSTM keras model to tflite ", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): 16.04\r\n- TensorFlow installed from (source or binary): Binary\r\n- TensorFlow version (or github SHA if from source):\r\n\r\n\r\n**Command used to run the converter or code if you\u2019re using the Python API**\r\nColab link: https://colab.research.google.com/drive/14HxDxImtW769ldxblyowXulKc7_Poi1G?usp=sharing\r\n\r\n# Copy and paste here the exact command\r\n```python\r\nimport numpy as np\r\nimport tensorflow as tf\r\nfrom tensorflow import keras\r\nfrom tensorflow.keras import layers\r\n\r\ndef build_model(input_shape):\r\n    X_input = layers.Input(shape = input_shape)\r\n\r\n    X = layers.Conv1D(128, 7, strides=4)(X_input)                           \r\n    X = layers.BatchNormalization()(X)                                 \r\n    X = layers.Activation('relu')(X)                                 \r\n    X = layers.Dropout(0.5)(X)                                 \r\n\r\n    X = layers.LSTM(64, return_sequences=True)(X)                                \r\n    X = layers.Dropout(0.5)(X)                           \r\n    X = layers.BatchNormalization()(X)                                \r\n    \r\n    X = layers.LSTM(64, return_sequences=True)(X)                              \r\n    X = layers.Dropout(0.5)(X)                                \r\n    X = layers.BatchNormalization()(X)                                \r\n    X = layers.Dropout(0.5)(X)\r\n\r\n    X = layers.TimeDistributed(layers.Dense(1, activation = \"sigmoid\"))(X) \r\n\r\n    model = keras.models.Model(inputs = X_input, outputs = X)\r\n    return model\r\n\r\nmodel = build_model((1000, 100))\r\nmodel.summary()\r\n\r\nx = np.random.rand(10, 1000, 100).astype(np.float32)\r\ny = np.random.randint(2, size=(10, 249)).astype(np.float32)\r\n\r\nmodel.compile('adam', 'binary_crossentropy')\r\nmodel.fit(x, y, epochs=1)\r\n\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(model)\r\ntflite_model = converter.convert()\r\n```\r\n\r\n**The output from the converter invocation**\r\n```\r\nINFO:tensorflow:Assets written to: /tmp/tmpkt6586gh/assets\r\n\r\nINFO:tensorflow:Assets written to: /tmp/tmpkt6586gh/assets\r\n\r\n---------------------------------------------------------------------------\r\n\r\nException                                 Traceback (most recent call last)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n    198                                                  debug_info_str,\r\n--> 199                                                  enable_mlir_converter)\r\n    200       return model_str\r\n\r\n6 frames\r\n\r\nException: <unknown>:0: error: loc(callsite(callsite(callsite(unknown at \"functional_7/lstm_13/PartitionedCall@__inference__wrapped_model_240475\") at \"StatefulPartitionedCall@__inference_signature_wrapper_247244\") at \"StatefulPartitionedCall\")): We cannot duplicate the value since it's not constant.\r\n\r\n<unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from\r\n<unknown>:0: note: loc(callsite(callsite(callsite(unknown at \"functional_7/lstm_13/PartitionedCall@__inference__wrapped_model_240475\") at \"StatefulPartitionedCall@__inference_signature_wrapper_247244\") at \"StatefulPartitionedCall\")): see current operation: %10 = \"tfl.unidirectional_sequence_lstm\"(%5, %cst_19, %cst_20, %cst_21, %cst_22, %cst_11, %cst_12, %cst_13, %cst_14, %cst_6, %cst_6, %cst_6, %cst_15, %cst_16, %cst_17, %cst_18, %cst_6, %cst_6, %9, %9, %cst_6, %cst_6, %cst_6, %cst_6) {cell_clip = 1.000000e+01 : f32, fused_activation_function = \"TANH\", proj_clip = 0.000000e+00 : f32, time_major = false} : (tensor<?x249x128xf32>, tensor<64x128xf32>, tensor<64x128xf32>, tensor<64x128xf32>, tensor<64x128xf32>, tensor<64x64xf32>, tensor<64x64xf32>, tensor<64x64xf32>, tensor<64x64xf32>, none, none, none, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, none, none, tensor<?x64xf32>, tensor<?x64xf32>, none, none, none, none) -> tensor<?x249x64xf32>\r\n<unknown>:0: error: Failed to duplicate values for the stateful op\r\n\r\n<unknown>:0: note: see current operation: \"func\"() ( {\r\n^bb0(%arg0: tensor<?x1000x100xf32>):  // no predecessors\r\n  %cst = \"std.constant\"() {value = dense<9.9943357E-4> : tensor<1xf32>} : () -> tensor<1xf32>\r\n  %cst_0 = \"std.constant\"() {value = dense<\"0xE30BE3B458690BB4A3B6ACB5D7BB263456F1E83527D417B745E0B1319E918E35717B2034BADFF2B5BC71DA36C9BEA6357FEAB834E78A50363F337B34D9EF64B4243D06B6D7ED4D362185EBB5851C1EB2DF5C6235448401B64B6CBF351CE0B435577819B5A3C8B9B5BAE50FB6EAAE85B4296D0D37742E8636472DA93410A839B6B0F3AA3545ED9DB55EABA73528FE6935C57C20B521FCCAB6146D6F35B1C9E3358C367935A6835C362040E9B5305A5A3675D79B36CCD3E8B5F7D83134F3FCC73558A42E367F36F335F08B0FB62B3B19B74367E4B5A1900EB72DF76FB5304B5C3496D04A357B7F97B6FBEA86348AC3333573A2B9B5B92C32363C003D36A47F273632596D34966B3DB57958B3B70D0C39B6C66FA9363016AB35DAD79835A23DA6B6F3E29E3664AC87B5A2592BB68AC90834D6331835B9B600B54DCBDE341AD586B6189BD2B413F0A6B5B607D3B47F7BACB5ED4D0A361A575436845BD6B6B54B1CB77C09C8B40B3FFAB59DDAEC32E65F85B4081C2DB75E45B836379ED23527C9BF36C94CA336A5C433B614DAC036A6E308B51BD9CE363BA05B3513036035681B1EB3D27FE3B5C7E7A3B5FC8B99B60D8705364DFF6A36E1A98DB5BCA14736CA373AB645C5F3B5F9ED09B6B64C03B7B5838A35DC3846B437DD33B6ECDE2F36C14FBEB50FB1B3B566EE05360741D83504D09E353793CA35265F0A365235DBB59A810935\"> : tensor<128xf32>} : () -> tensor<128xf32>\r\n  %cst_1 = \"std.constant\"() {value = dense<-3> : tensor<i32>} : () -> tensor<i32>\r\n  %cst_2 = \"std.constant\"() {value = dense<0.000000e+00> : tensor<f32>} : () -> tensor<f32>\r\n  %cst_3 = \"std.constant\"() {value = dense<64> : tensor<i32>} : () -> tensor<i32>\r\n  %cst_4 = \"std.constant\"() {value = dense<[-1, 64]> : tensor<2xi32>} : () -> tensor<2xi32>\r\n  %cst_5 = \"std.constant\"() {value = dense<[-1, 249, 1]> : tensor<3xi32>} : () -> tensor<3xi32>\r\n  %cst_6 = \"std.constant\"() {value} : () -> none\r\n  %cst_7 = \"std.constant\"() {value = dense<\"0x4868803FB466803F4AA9803F79A8803F6BA8803F6FA9803FB8A9803FEF67803F40A6803FB567803F0F68803FD0A8803FBB67803F14A8803FD067803F28AA803F87A8803F96A8803F9F67803F40A9803FCFA8803F4A67803F3266803F71A9803F03A9803F8567803FF967803FDFA9803F49A8803FA2A8803F2868803FF0A9803FBF67803F0DA9803FFB67803FE867803FD3A8803F6EA9803F5DA9803FBD67803F4967803F1BA9803FD067803F1E67803FBA67803FE266803FCF66803FDE67803FBFA8803F9467803F1969803F7767803F2068803FEAA8803FF7A7803FA1A9803F13A8803F7B68803FECA1803FA0A8803F40A9803FE267803F2768803FD5A9803F3467803FC6A8803FA8A8803F3D67803FADA8803F1D67803F2E67803FC468803F32A8803F6168803FDBA8803F8967803FFB67803F1AAA803F9F66803FEE66803FBFA1803FA2A8803F6FA9803FF767803FE6A7803F5E67803FBF66803FEEA8803FEB67803FC8A7803F05A9803F6067803F47A9803FF267803FE366803F1368803F9C67803F9DA8803F7F68803F1568803F15A9803F3C67803FE1A8803FA367803F3568803FA6A9803F5768803F4767803FD5A8803FF466803FB867803F7667803F3667803F4466803FD767803F99A8803F53A8803F5967803F1BA9803F1BA9803FC367803FC0A9803F00A8803FADA8803F71AA803FB96D803FDC66803F6167803F\"> : tensor<128xf32>} : () -> tensor<128xf32>\r\n  %cst_8 = \"std.constant\"() {value = dense<\"0x160683BB18CC3ABCF0152FBBF47A0BBCCBE290BA473EB03B98DEB43B6E7DE8B9E0962BBB34720DBB8CA08A3B947205BB88E016394D3C5D3A369976BB0448A43A4068CDB9E0EE09BA7EBE473BD78709BC4126053C2EB5053A50CE7D3B4CC968BA2AD9B13A79CB9EBA586D723AAC9489BAC4398CBB14ABD5BAB6B728BB9C6525BB9161F7BA8983CD3BC35ECFBB2D9F9CBBF17F413AC03E83B9E90A02BB5DEC68BB034E65BBA1F7863BFA1E953AB95826BBA83343BB949F05BCC33118BC85B9C43A808605BA0088DDB67116D03B38E3B63B093E0CBBBC50E7BBC46B5C3A4C76DC3A7EE0F0BB66A0243A3E91483A6302453A0496793BBEF99A3A8D1BC4BB945DD739D443583944B28BBBBAF4E53BE6BCC2BB9875453BD01E8D39C44A8ABA5AA8C3B9549853BB217EDA3A346F8AB9A23B1CBB45BF413C62A405BA4C8D97395AEEAA3BFB4FE3BBF6160ABB8568B73AF16F10BB44E2823BDE8B12BB5B0602BC4BACBDBBD95B0D3CE2C34B3A952B8B3AD8C7A6BAE4C12B3B0AB69E3B9853533BB3BD063C623A11BBAD8DF33A4889993BC668D6BA8E00A53B4CDCB0BB89AE693BC4A2B2B90BFDDCBAA60B0CBCE3CA52BAA7CD98BBBAE736BB6E005E3B9E3B4DBC80ABE93BAA4E8C3B6BA7D33AE01EFEBBC409ED391A19A93A2C052FBAA54B14BC8C2D70BC58F684BABC128B39AE80803CEC36D2B97C6839BADB88663B08E706391CC5ABBB\"> : tensor<128xf32>} : () -> tensor<128xf32>\r\n  %cst_9 = \"std.constant\"() {value = dense<[1.00473976, 1.00521708, 1.00263178, 1.00512218, 1.00516057, 1.00505733, 1.00508463, 1.00512767, 1.00468206, 1.00509381, 1.00515211, 1.00500977, 1.00460923, 1.00526345, 1.00518048, 1.00323498, 1.00313473, 1.00481927, 1.00307453, 1.00518346, 1.00318122, 1.00508034, 1.00511396, 1.00325751, 1.00530183, 1.00303495, 1.00524509, 1.00510859, 1.00507498, 1.00289106, 1.00500321, 1.00317168, 1.00510597, 1.00283813, 1.00500691, 1.00319803, 1.00302553, 1.00532532, 1.00289774, 1.00283813, 1.0031631, 1.00312734, 1.00510907, 1.00331628, 1.00476944, 1.0048629, 1.00319898, 1.00497484, 1.00326228, 1.00507808, 1.005170e+00, 1.00541019, 1.00510037, 1.00526011, 1.002900e+00, 1.00523686, 1.00262475, 1.00306499, 1.00506783, 1.00488198, 1.00327921, 1.00528109, 1.00526297, 1.00270772]> : tensor<64xf32>} : () -> tensor<64xf32>\r\n  %cst_10 = \"std.constant\"() {value = dense<[0.00212347507, 0.00114128285, 0.00424089422, 1.03820697E-4, 0.0025341576, 0.00241684401, -9.20396414E-4, 0.00274362462, -6.54401258E-4, -5.62307425E-4, 1.24871498E-4, -0.00112991163, 0.00194295647, -7.7732536E-4, 0.00172411324, 0.00204211427, -6.12335338E-4, 3.90041969E-4, -5.3005293E-5, 0.00170475454, 4.90864331E-4, 0.00253311382, -3.48295085E-4, 0.00198506215, 9.72406648E-4, 2.20654067E-4, -7.47772981E-4, -8.11745994E-4, 0.00160141359, -0.00112064206, 9.69715358E-4, 0.00184346607, 0.00207264954, 0.00188718142, 0.00195737928, 0.00224771816, 0.00170390774, 5.08747587E-4, -0.00367517141, 0.00248319749, -0.00254705641, 0.00120391347, -2.9670808E-4, 3.36897792E-5, -8.59148916E-4, 0.00119491515, -1.53806293E-4, -1.64092053E-4, -9.07708308E-4, 0.00232663471, -0.00211252738, -0.00117885927, 0.00240447256, 9.73630347E-4, -0.00122551713, -0.00213340251, -2.57467618E-5, 2.70258111E-4, -0.002932237, -0.00138859439, -0.00181194942, -3.7918007E-4, 1.09911198E-4, 0.00112971466]> : tensor<64xf32>} : () -> tensor<64xf32>\r\n  %cst_11 = \"std.constant\"() {value = dense<\"0xA182193D6852173C04EF7BBDE9BE8A3D7CEA35BDCFE4B43D92E47D3D203D4CBDF34D47BEF58101BD743B16BD4DC6B0BCEB285FBDDA1B953DBD410BBE8276743DE01D883CA2DD9ABA644B8CBC566B79BCEC738DBD6DFBB23D88AF1E3D16DDF0BCF265EB3D9D6F423D33D63BBDB9250FBDDF2AA33A84F3A13AFABE08BEE40BD73DA8CECEBDCFDAE23C880CE13D2C98B83D1C7C1CBD205A33BDB1CC8F3D5302CABDDF2D263D0FC7F73C924A213B38AEC5BD83D60B3DDC5A903D8C1406BD96AFAC3DAC2C3FBDCAAADD3CBCAD7D3DF47FF0BD3BA8063D3C38D1BC5DD0283D50752E3DC32A87BD19ABBD3CD6CA69BCDC160DBD3CB404BDE0952ABCBD5BD5BC52ECA23DD24424BE36F8E13DDFD9353DCBAC7EBD952CAE3D72B62A3DFAE18EBC64C742BD09C7A6BD782D893DA82564BD76DB853D6F4C3D3D017768BC1F998A3C3D29253DA49FBFBBEACA8EBD78CB4EBDB967943D431578BD7BECF73D87C2083C3DF3CCBD331D8BBC45E580BD6536C03D4252713D076A5ABD1F541B3D6AA0BEBD3E48533D542121BCEFC6A9BC66504E3D31ED84BC06C0823DDFFA8B3BA4E8843DA9B56F3DF12592BD4A8FC83C41E5A33CE4AF413C26658CBDCC65D33C98A9A63D61A3A7BDB0DBA4BDCB8A1DBC5808323DC65F08BD3C8B993D766D323DA37EEF3D067076BC0E4C6CBC1051923DD8E361BC626F77BB0B762A3CE106D3BD39A465BC4A82B23DCBEE70BDCEAC883D097C8A3D6F62DF3C74B00E3D725B843D6EF454BDFCFE3B3C8A2AB63DD790053D75ECF13D21F274BD39D99ABBC924F9BCE27D19BD2BCEC63DF30222BE2107173D3D0BBEBC974E08BEBE8D2E3B393C5CBD896FA1BD45DA24BCE6AB33BBD54CA4BCF304853DEFE0973DE595643D593CA73CAA2DEFBDEF3AA13CF18759BD45EE3E3B107800BC9F800B3E4051833C39EFA23C0904D6BB154CA83D9DA2ACBC847EF93C71CC1ABD31BAB5BD9E910EBEC9966E3C48AC03BC521E3B3C721A4C3D455AE13C1CCDB2BCEABBA4BC6EE801BDDB...\r\n  %cst_12 = \"std.constant\"() {value = dense<\"0x66A9D5BC396F00BED31B653CBEB2253EB266683DAA630A3DF348CEBCF921B7BD509439BD439542BAD13474BD50CF123EB550903DCC7231BD983BA93CF6F072BB6E887C3D1C737B3D5C8CB9BDEA58B7BCF5C9983D97F4A7BD0192D9BD4E499EBBE0C9653D1DD8D6BBC63A713C85216E3D0030273D52F0853DFC9D473CD1F2993D7BEF073D09E1EABC11318D3DBAEFD3BAF6F5003C8430E53D9FB23CBE15C8913DE8D51D3E97891EBD6F89113D38A9613DA190463CFC4416BDF6021DBD59C065BDFF96FA3C0708A43DEFFD0C3E4C58553D4A549F3BC421A13D5C81D43D121F8F3D6301DDBD5C3DAFBD68E7FBBC8FF3173D860B82BD5CA4813D2459C4BD27B28ABD2360FC3D99B2D93DEB55CF3DF8BD293D7379A63D1CF2803C04D155BDBB080BBDD78D923CDBCA91BC523C43BD2EA68CBCFAB694BD1DBD203E6412133D2CED05BEA8DB97BD997E86BDBC0975BDCCC16BBD4B03E2BD251DCFBC15767DBD60F5A03D3BA1513C4D6232BC4867D9BDBABA2F3D19B2BEBDB4954BBD04CA29BD5D0B78BCD756ABBC32D2C93C1FF7C53D200A42BD560120BBA03F1B3D8117733DFB1C733D33226DBD34D8DA3CD8BE07BE9B29D63B826181BD78DFB8BDAD7EE9BB5423ADBD9CB8C83C081CA23DBE7A573D307787BD8140D93DD924DFBCF5550CBE1D03513DACFEABBB88CFE2BCE2211C3D349F8FBC54DE90BDC9B06D3DCE33ADBD243C023D9738ACBABB02663C5C5EC5BAD8BC023CB6FFB23D5A9C43BCC95EDFBCA81ABC39B596AB3D7E972EBC836699BB42FBF7BC0EE007BCABA3443C2A66A23D3206B83D39AF383DC412C3BC690B83BCD4F0E63D4806D53C734E343C26C90CBD524036BD7EFE7EBDCAB4693C742EEB3DDC93E9BD299513BE850DC23C3EB5A0BD89AD64BEADBA753C9FC18EBDA89B80BCE4728BBDC3E4133DEAC54BBA7C4E47BD22C6C0BAE80E623CF8D8473D16C9B3BDA2950F3D9612A0BB3268D53D28B28FBD3B3BBFBD2A76723DE100AB3C47387E3CBF6718BE722E3E3BB0...\r\n  %cst_13 = \"std.constant\"() {value = dense<\"0x89C41CBCAF8AC2BD457EC23CD0CC16BCDD6A2E3E4B478DBC4A2143BDE0E4163DC250BE3D7AD2E63C0B11D0BCD79A753D854C7EBD3B4937BD391179BD91CD3ABCA9A6CE3C81A82DBD882EB5BD84F241BD6FE39C3B3454B3BCFC44D63B201256BBCFBA66BC47A1433CBDA498BD270A4DBCC07E54BD9E16AABDBE61383D0DE75A3DEDE8183CAB07A33CCF79503C688DFC3DC0CED7BC1849B13D867A0C3D8D5ACF3B5D2397BCDC9714BDB08E7E3C010337BD73C62A3DAEB2B33DD24E80BA17078FBC6D4424BC209F7E3CC06D473D2241CDBCC26B54BDC6A5A83D9C7856BDE09ABD3C85FDEFBDA4D7833C6915F23D001EEDBDA773F13CDB9F9DBD7380B1BDCFEB073D93BF32BD5F6775BD76C3AA3CA6E285BD7FC16B3C72BCDBBB19CB11BE82DBA73D4B2E753D8FB6413D5B9105BDDA452C3D15C974BDA361F83DB88388BD1448BBBD13E0863D9FA8093E9FFE50BD041B82BD121C153EE47D033CAEBC623D206BCDBCE86DBB3DEC3C0F3DC3B0EBBABB11F8BCDF9FF53DABC904BDB8FCBDBCBEC815BD9C355DBDEE006B3D1F62B9BC2C97CF3BEEEC20BDF51B943B98698E3D29FDD03DB7095B3D004BFDBC496E013E0AB17BBB7DF4DC3C0D276D3D541044BB9E114D3DB58D703B0BC2A03B298C37BDC529E13CF947C03D842C943D51F332BDFFE530BCC7E1FABC9FB590BDF217F5BD5529DB3C3CED813D353E043D6CE673BDD2552DBDD2AD353C518714BCF721C3BCE40CEDBD31E215BDFD2EA33CB41004BD53159BBC96A9E2BD6222D3BDD0096CBD1CF7A93C2D2D30BC1E152BBD6DBE24BD4CE7B1BDE1CFA1BDE07E053EBA5A2F3D6603EBBC1C6BD03B3597A9BD3208B8BD86C3193DBFF3933D0739263D661E893DE212173EAE038CBD400913BD8B40353DAACA84BD0532403E6E5636BCC8ECF6BCB1B4E53D0BB02FBDA03DAB3D36EB00BDFC06E5BDFF78A73CF7FC72BD351988BDEB09BF3C1C5F47BD7861893C3273A6BC8D118ABAC607C63DF3B7FBBDAB3D0A3D2BFCE8BD9E04AEBD0F...\r\n  %cst_14 = \"std.constant\"() {value = dense<\"0x6D7FE53B90D80ABB900637BD90E9CABC41E959BBC4683A3EF659273CDAB79B3B7277E6BD9680A3BC06664CBD4495EF3C78CB36BCCBEE783DE7233CBDE6E06C3DC4E310BC40B12F3DEEED48BDEF40503D9182B5BCCCE6443CC09188BD2A2999BDCD20EFBCDAFE4EBCA274FC3B446CC03B85408ABDB62E763DB49CE1BCCFCC7A3D2D801E3D624E3D3C00EC92BD55E9B2BC7D302ABD8F380DBD9CD3813D47EBCB3D977EF0BD3ED69D3DA41AA13CC517C63CD524CCBCA81C313D21F81F3DB2BD113D837E02BCDADD843D932C763D4FEF5D3DDEAB18BE12D212BC3B738EBD7B78C4BC6F65353EAD2506BE0FAA3BBCC8604B3DF5740A3D0D51C23D0084E1BD0A42DB3C9FEE8C3B93908BBD930453BDAFD70A3EB82CAC3C2D97083E656B03BD2E28033C25B813BDE6E4DE3D129D213D32C1A2BCD7B222BD972851BD34FD8B3DDA896BBC1EA2803C456AC73C9E63763DCD31DBBC3DFAC4BDB4A13E3DAFB8033D64513A3D8F72343E05EC913D109BA2BCA691A8BD0A49143B3513213DEE201CBC7A9B993B7745F23C686CC4BD9270853C8613F4BDAAA698BC8C5B2DBE3FC999BD8AFA8CBC99B65ABDBA5AAABCA0028A3D9635423D2656C03C37AC0B3D3992013EB451B8BCE33ED03D25F2B0BDE2D507BD65A05F3DD0EDA53D5D1B333BC79CC3BDB4DD04BD7D3116BBE4606D3DD404203DF22C133DB880BCBCDBF5D4BD7D9E8ABC2CEB9E3D04D5CABC95F8343DA6DAC73D7725F1BDB6ADA93B57E9BB3C9F0D9CBC409ACBB7E5088DBB42502EBC4EEAA3BC6EE8283C188C683C916A223DA2FF0ABDC0FD8F3CE56611BCBD8D97BD4628443D928C95BDEA581ABC0D16D63D2E85843C05A28BBC40538437626B323C9A7127BEAE940F3D8556A53C14C3533B1F17993DD2B3E5BD851BC3BD980643BD8980603CD9625A3D0072C1BC279913BD045D55BDE0D406BD55C56BBDA6EBF13C748ECDBC907E77BD0490C23D3C8B923C148F323DEC107A3A1CF4C43D9B2FBE3D556331BD0E6CEA3B5A54833D8B...\r\n  %cst_15 = \"std.constant\"() {value = dense<[-9.8901696E-4, 8.5479155E-4, 9.79730626E-4, -9.92890913E-4, -9.96473943E-4, 9.94842383E-4, -9.81436577E-4, -9.86810191E-4, 9.76143696E-4, -9.95050533E-4, 9.96386515E-4, 9.97202587E-4, 9.95036563E-4, 9.89387161E-4, 9.55004477E-4, -9.91261797E-4, -9.74753813E-4, -9.9344307E-4, -9.93789755E-4, -9.86392376E-4, 9.69534274E-4, -9.80411772E-4, 9.94408153E-4, 9.93013498E-4, 9.97127848E-4, -9.42781102E-4, -9.70873865E-4, 9.89013817E-4, 9.76190961E-4, 9.85609483E-4, -9.92171582E-4, -9.76951909E-4, 9.94690228E-4, -9.26485285E-4, -9.87045699E-4, -9.95974405E-4, 9.95763926E-4, -9.95861366E-4, -9.9247531E-4, 9.89652355E-4, -9.91960754E-4, -9.92493587E-4, 9.88994841E-4, -9.96514922E-4, 9.97994909E-4, 7.89895537E-4, -9.94454952E-4, 9.82676516E-4, -9.95628302E-4, -9.84977814E-4, 9.91726177E-4, 9.94249363E-4, -9.90893808E-4, -9.91686829E-4, -9.92248067E-4, 9.85561753E-4, 8.73027078E-4, 9.94159607E-4, 9.96555201E-4, -9.95308626E-4, -9.89207183E-4, 9.23537358E-4, -9.56159958E-4, 9.97224473E-4]> : tensor<64xf32>} : () -> tensor<64xf32>\r\n  %cst_16 = \"std.constant\"() {value = dense<[1.00099027, 1.00098932, 1.00099516, 0.999001443, 0.999003052, 1.00099671, 0.999013066, 0.999002039, 0.999003827, 0.999007761, 0.999003648, 1.00099814, 1.00098109, 1.0009973, 0.999003589, 0.999007225, 1.00099742, 1.00099838, 1.00099516, 1.00099599, 0.999002635, 1.00093877, 1.00099826, 0.999011039, 1.00098026, 0.999085307, 0.999004065, 0.999006569, 1.00098586, 9.990090e-01, 0.999005258, 0.9990049, 1.00098383, 0.999015271, 0.999016046, 9.990040e-01, 1.00099528, 1.00099838, 0.999001204, 1.00099707, 1.00098884, 0.999010801, 1.00098121, 0.999003827, 1.00099885, 0.999003291, 0.9990139, 0.999089419, 0.999002397, 0.999002635, 1.00099599, 1.00099051, 1.00099814, 0.999006092, 1.00099432, 0.999023616, 1.00092232, 1.0009979, 1.00094688, 0.999000966, 0.999003708, 1.0009973, 0.999011337, 1.00099313]> : tensor<64xf32>} : () -> tensor<64xf32>\r\n  %cst_17 = \"std.constant\"() {value = dense<[-9.96331218E-4, 9.9947548E-4, -9.99390729E-4, -9.99690964E-4, 9.99050796E-4, 9.99103183E-4, 9.98863601E-4, 9.99490497E-4, 9.99209471E-4, -9.99391428E-4, 9.99218085E-4, 9.99209703E-4, 9.80420154E-4, -9.99758602E-4, 9.98847535E-4, -9.99662093E-4, -9.99377341E-4, -9.989780e-04, 9.99162555E-4, 9.99477691E-4, -9.99286537E-4, -9.98504692E-4, 9.99714247E-4, 9.97304683E-4, 9.9933322E-4, -9.93805122E-4, -9.5772784E-4, 9.99755342E-4, -9.997870e-04, 9.98014817E-4, -8.64997389E-4, 9.97377792E-4, -9.99638345E-4, 9.9680887E-4, -9.98852308E-4, -9.99114126E-4, -9.99839277E-4, 9.98401781E-4, -9.99705167E-4, -9.99090261E-4, 9.95945185E-4, -9.99628449E-4, -9.98933333E-4, 9.98956267E-4, 9.99524607E-4, 9.99682699E-4, -9.98335075E-4, 9.99589916E-4, 9.97847644E-4, 9.99562675E-4, 9.99166746E-4, 9.97601891E-4, -9.99633572E-4, 9.98750911E-4, 9.99411451E-4, 9.98528324E-4, 9.96360555E-4, 9.99749638E-4, -9.9872041E-4, -9.99665353E-4, -9.9975022E-4, -9.98956849E-4, 9.98632749E-4, 9.98964183E-4]> : tensor<64xf32>} : () -> tensor<64xf32>\r\n  %cst_18 = \"std.constant\"() {value = dense<[-9.969270e-04, -9.82557306E-4, -9.93291963E-4, -9.90343512E-4, -9.97934374E-4, 9.90803935E-4, -9.84228565E-4, -9.96587565E-4, -9.97572089E-4, 9.795690e-04, 9.94196743E-4, 9.95259266E-4, 9.97718772E-4, 9.96876275E-4, 9.75065515E-4, -9.9695567E-4, -9.92954708E-4, 9.90913482E-4, -9.94683359E-4, 9.95306298E-4, 9.89426276E-4, 9.78857278E-4, 9.94338188E-4, 9.96380113E-4, 9.88848274E-4, -9.76715586E-4, -9.89963999E-4, 9.82530764E-4, -9.80048673E-4, -9.93657624E-4, -9.90298925E-4, 9.94730857E-4, -8.47386254E-4, -9.94144822E-4, -9.24524327E-4, -9.96671849E-4, -9.95290349E-4, 9.90399857E-4, 9.92561923E-4, 9.9778769E-4, -9.91268665E-4, 9.9106389E-4, 9.91855398E-4, -9.95182781E-4, 9.90162254E-4, -9.9000032E-4, -9.91538865E-4, 9.92999994E-4, -9.93227935E-4, 9.92302317E-4, 9.95503971E-4, 9.89457941E-4, -9.93986148E-4, -6.98388088E-4, -9.90565284E-4, 9.86032304E-4, 9.90497064E-4, 9.35149088E-4, -9.74465802E-4, 9.96848801E-4, 9.82844852E-4, -9.86666884E-4, -8.83933331E-4, 9.90752945E-4]> : tensor<64xf32>} : () -> tensor<64xf32>\r\n  %cst_19 = \"std.constant\"() {value = dense<\"0x5344EF3D6F3B673DAA17D2BCFC80D8BB3A659CBD8BDFABBC20C0E43DC24936BCDCA37A3B048FED3CDC876ABDA432D13DDCA59E3DB15ADABCDD4EA03DD654DC3DC02DC43C2E2A8ABDB2939E3D157A04BD361F1F3CFA9E25BDF88F99BDE1A8D8BD795D84BDC0E7FF3CD640793D7D12E1BD4FADA1BC89F9AABC7645ABBD9E28CDBC7DD1F23CD3C3A5BD0FABD1BD0D9B10BC264CBBBDCDE8EA3C0B15CBBD4A7AF63CAA93AF3D986C5B3D808A6FBD9118FDBDBE8AB0BC2DC1393D1CF2EA3D28A8813B1464803D54D8B7BC1BDEF8BDECAEB13D6D3700BE0ADBDCBD43E14F3D21DBE0BD3F86E9BD0914A73D0E649ABDABE0CF3D915CB03DD4CD003E73D400BC34DFF4BDDDA5A03D5521DC3D21B2D83D7FA049BB99CA493C272F263C87B59B3D5F36D63DD436B43CCF74FE3C937FFC3D8504933D532B813DFF09CDBDE626283B4403893D5F3E71BD3B68CABC8913A53D60C6B1BC7953A5BB25F7FEBC1F508E3DF1B7D43D09231DBD7148EFBDDE25E5BDB49F323CE29DE63D939BB73C853EC4BD37AEAC3C1E5A9F3C38094D3B00D0F83DD5798EBD6D06193D194BEC3CD435E73DEE0315BC622BF53B9A9DDDBD6213CD3D41A660BD7B0BA4BDD4CBC8BD02643E3CC2A0143CD760DABDF6DFC23C9D6D2CBD8FB1B0BD9C19C33D08A4BA3D9350F03D0DFADEBDED66BEBD326683BCF92B8C3DBE63A13D97324DBD36B7CBBDE8340CBD7E6B9D3DD693B1BD7D1EAA3D2CCC7F3C5D209ABDC6B0613DF9EBE9BDD293023B9938A53DC8901EBD766BDA3D8AD7C53D0748EBBD1DDEA03D4011083B17847BBD2D5DBABD0266AF3CA5EA42BD3EB48B3CAE1193BCEDE8333DF9F55CBD9F432BBD85C7573D37DAB3BDC4A1953DD9384ABDB035D0BCAF5A7B3D1CEDFDBD8C4BABBDF96740BCF393D93DA8EBBABC70E1233CC840A33DBEE46DBD312427BD2D9E0ABCBA08C33D7C4C19BD66C8193D742CF0BC0F4459BD1BC9B8BD7920CFBD483BBB3D3FB86CBD7DC88CBB62F5CC3DD8D3BEBDE230003EB4F3263D4C...\r\n  %cst_20 = \"std.constant\"() {value = dense<\"0xAD2AB8BDDE00973DAD58C4BCAAAA8ABD75A3EEBDAA08B0BD2D53A93D8504B23DDE2FB33BB3BE9FBD989925BC0180AB3DFAD7873C54A8E53C03E8A33D09130CBD58F704399614103D97E8D33DEFB35D3D758777BC79D024BD6DFE94BD24C8F93D476802BDD1F54F3C10553F3D81D7153CF91AC83D9EA319BDAC8620BDB427AABD9A4974BD1D738D3D025E99BC2F7E73BCDE4A403CDBC7BABDE06C773C89D2863DB5C5AA3D583BA8BBEB8C0FBD823FA1BDB832E83D32FCB23DA16C273D96B7B63DF29EF53C0889C73DED0C94BD6E02923D5A82663DE94CB23D2EF47FBD00AC25BD1AF43A3DEA7770BCF737F9BDFBF3373DE486933D909AC7BC5D79FBBB67AF9C3DBD84E7BD233CF23DA612F1BD8D3F1DBD92C2543CD17DA33DD4AF93BDE9BD973C8A8CCDBDE528353D0C4898BD07FCE8BD8D29BCBD5D1F85BDA61EBF3DE184433D9DD575BB95EDB5BD6E2A07BD5EBAFDBD48BDED3D72CF12BCD0A3D13CFCE0DBBD2229363C6CEFEFBDAC20813DBDAA803D3182AFBD7C68D83DFF424DBDD227C4BDFE7BE5BD4FCA4D3DADD4CF3DC6B5B63D3A019FBDC6BC983D3BAAB23D5777833D57B5FA3D37D6E23C3592783B9C3BB5BD6664CA3B78CF8A3D5FDED8BD6B1DCD3C19FA5E3D6A26D93DB1FC913DF855433B59E44F3DDF7182BD8BA8A93C0C70F7BD8C801A3D5206C53D2C47873DB2E6953C11F0AA3DAB8BFCBDBAA3CA3D78D9703DB89D6D3D19439DBD3AEDA23DF0168F3DC76907BD9F8898BDEF5EF6BD9114C53DD43CF23DF13FF23D0893DABCF51D41BD786C123D0B26A5BB19B2263D82838BBDA85EE5BD2690B63DBED5C5BA7C7564BD6E56A6BD19FCC03CF05475BD78E06A3D0C62BC3D4FE8B2BDD99C49BCD47A2E3C688BD53D489791BCF7B716BDA65771BD5EC69EBB2E4B56BCAC51E73D780214BCA4B4343D4C23B1BD05F8A23D4E41B53D1A62FB3C23DFA23D3A5BC0BD63B3DA3C1F69D3BD36DDA03DF7DDEFBC874AE1BDE2A3A33C4DFD1B3D6483773DF80AD43D3106B9BD5D...\r\n  %cst_21 = \"std.constant\"() {value = dense<\"0x049BE93D7A68483DF5E4723D2580483D76C58E3DA721C63DB6EECABDA84A2BBCF3CA943D1D4856BD4EAB20BD0E74FD3C39EFCFBD859A1F3D8EFF293B871BE43DCC4AB0BDD950D1BD2424A2BCDA6E763DA485C63DAA94F6BD6FFF21BDC5581C3DEA3C0D3D12F634BD665424BC304417BD493C8B3D6746FD3DDBCAA5BDF32FF7BD041A3DBC652130BD3390CCBD082A4FBDC4B9333D68D6A0BD1347783DEB589C3C0E4B87BD3A9EBE3D740E363D79114C3D5C08AE3D4A43B03D6910A5BB2522F8BD2CD2423D79659F3D0008DBBCE94957BDB476DABD66AF84BD0A822DBD5C6C22BDCC74D1BD7CDDC3BD5D3379BD61FCD6BDF149C6BD6CF3C33BD54295BDFC3BE43A68EE5F3CE8EB1BBD0C06A6BDF506E03D95FBE1BD84B8BB3DFA45223DBAE941BDC375333DAA694CBD61B3B2BCDD252BBD665B703DDB02EFBDA3CEA0BDA04E74BD7247763D54AB52BC804867BDCA3EA53D10419DBDEA13593D1EEADA3DDA3D373CB72900BEC178A73C04140CBD56A1B5BCA10AD53D145FB3BD6CE6EE3C2FCD803DE885113DFFD7A4BC0D0229BD65DCDBBD2B7E32BDFADB68BDDBA3C8BD8BFB973DADF3A9BD6BA79CBDDE5289BD691E8BBD3CF32BBD94268E3DE057B8BD34A97BBDD728DBBDDD87CCBC3EC91D3DA4186E3C94F2E0BDD8C727BDE067E63DD96AD4BD02F7AEBD71CDA23B593330BD675072BDC80E00BD7280983D30DFDD3BEE3A873D5D1A6ABDEC6617BDAA5AD5BDFDD60B3DDFA5AA3D14E05FBD2DD79C3D3833BEBCCACCF8BC1701D7BD135BE23B047CD63D5275AB3D904B473BCD9EAB3DF5A0983CF2509C3D473985BB494FE23DB29A9F3DDCA8A0BC8FF44C3DF76AC9BDAD84F3BDCFF94B3DAC8EB23DB00033BD8D7314BD1E60DDBDC38BA4BC3CEB98BDFFBCAA3DD626C9BDF906153CBD87473D76B2CF3C5DE8003EE5CD2C3D9EF7F93CEE2DAC3D109A9DB98D1CB4BDE875F7BD4065D7BD1BF4973DD281083DEDB1D3BDCCECBCBB1A55D5BDDDFB39BD950AC33C31A1853C8628EEBB53...\r\n  %cst_22 = \"std.constant\"() {value = dense<\"0x5D62F63D997CCD3D4BA877BC4A6FB63DC912423D2C82183D2FA383BDA72B963D6EFED3BD4D49B2BD771090BD3654F3BD4D75333DE2D6C7BBF5B6AABD53769F3C79F556BD9F1BEF3DC5ADD23D4C76EB3D5153AE3D7EBAD03D5BA1D6BC9D1D9FBDFE8C93BA4816E2BDC8DD823D6FCD063C1DBE0D3DE13DEBBD537A9B3DAD92E73DD896F6BDDDDA953D6BFF94BD0360E73DC79267BDEAC94E3D875070BD198A27BDE113E33DFBBD2F3D440148BC47577E3DD1FEA2BD59BA083D3163F03D8E7013BDF103B83DF1901FBD113002BC6713B5BD29AA893DA79F57BC415AEBBDB6D20F3A8472A43D4A5C6ABDF9EEBC3D9A28513D662064BD4A66983AA1D7DEBCB1F2713DD81F89BC22DEFDBC06E136BD32DD2D3D5F5C633D52CB75BD30F0D63D88682ABB6602B0BD018489BD4206E1BD0998A8BD65EFD1BD4D52FCBD471C953D15D42E3DBF46923DED88E53D3BA8C6BC9CA3DEBDD7A1E3BD967CAC3DF35E36BC13528CBDDC24EFBD2599EF3D42D14CBD50D1B0BD01C3D73DA0AEA4BD9517ED3C2ABD0E3D73E5F3BD5B13C8BDDC26ECBCABB5C73D9C64FF3D65C4203DA898E3BB3E24953D9C31B0BDABC9F4BD78ECC43DFCEDBEBD5B1DA4BD8DBE64BD22FFF4BBDBC6F93DB20AB03D3676A0BD6541E33D6D59BB3D43F4AEBDEFDB2CBD0FCC863D4BB24DBC6C4204BC418F6C3DB2F8F5BDD467E4BD581304BDE2BE863D3262053B88C2F9BDF115A0BD06ACB23D3664BD3D223975BBB4F3EABC375DCEBD1FA79DBB83CBF0BDF9D5D6BD4E315ABDB799A9BD46D955BD3144CD3D9BBA753C3B5FA1BD3E158EBDE4E3D9BDC771D3BBFA7AAABD7A36A7BD0AEC6C3C93158CBDABCFC2BD1EEEAD3D643FA73C9DBFDBBD2829D8BCEB47133C22B665BD01F2B4BDF9495FBD1044813C03C9B73CAFE6B8BD32C7CE3DD6C81DBA59A8A13DFA6BC13D5DA5D03C541B69BDF2C0F6BD7F0C6CBD1D150BBD1A04833CAB3B583D57C8F33D6022C53C1411993DE33D67BDD79517BC60ACF73DBE3194BD02C5F13C39...\r\n  %cst_23 = \"std.constant\"() {value = dense<[1.00309217, 1.00306129, 1.00305521, 1.00297964, 1.00312328, 1.0031054, 1.00307453, 1.00310564, 1.00313675, 1.00305128, 1.00307429, 1.00305736, 1.003070e+00, 1.0029887, 1.00302231, 1.00311744, 1.00306451, 1.00375688, 1.00299633, 1.0030781, 1.00298929, 1.00297678, 1.00304294, 1.003090e+00, 1.00315344, 1.0030973, 1.00511754, 1.00309551, 1.00313067, 1.00304472, 1.00306332, 1.00306582, 1.00493622, 1.00297606, 1.00302935, 1.00298393, 1.0030632, 1.00310445, 1.00310719, 1.00504351, 1.0031389, 1.00311208, 1.00314331, 1.00296211, 1.00310755, 1.00303924, 1.00302505, 1.00302935, 1.00308597, 1.00316334, 1.00303519, 1.00307107, 1.00308514, 1.00304747, 1.00304878, 1.00306785, 1.0030061, 1.00506783, 1.00308836, 1.00306702, 1.00507414, 1.00302899, 1.0030452, 1.00310063]> : tensor<64xf32>} : () -> tensor<64xf32>\r\n  %cst_24 = \"std.constant\"() {value = dense<[0.00105503935, 9.57053503E-4, 9.19337617E-4, -0.00135998649, 9.4322121E-4, 0.00111438113, -8.29911325E-4, -9.97727853E-4, -8.51589313E-4, 0.00107562402, -8.04005772E-4, -0.00109937368, 0.00111207424, -8.78392602E-4, -9.8252925E-4, -0.00109786494, -9.11238894E-4, 8.16963788E-4, -9.54134739E-4, -0.00101923943, -0.001126813, 0.00118361623, 8.54798709E-4, 9.88998217E-4, 9.06906615E-4, -9.89600433E-4, -0.00116529281, 0.00105114921, 8.55009945E-4, 8.50873534E-4, 9.1296091E-4, -8.51154094E-4, 1.086330e-03, -9.83795617E-4, 8.56689236E-4, -0.00103523524, -9.80255194E-4, -0.00102012744, -0.00115606235, 8.70998425E-4, 9.38069541E-4, 9.53909824E-4, -0.0011939907, 0.00102742529, -8.92813433E-4, -7.36643909E-4, -8.27286276E-4, 8.32178513E-4, -8.53449397E-4, -0.00132732699, -8.82953347E-4, 6.98925112E-4, 0.00104335765, -8.36898805E-4, -9.04436689E-4, 8.80992854E-4, -0.00101167895, 8.2154182E-4, 6.41766353E-4, -8.16440617E-4, -9.5120765E-4, -9.956470e-04, 0.00102537207, -9.21818893E-4]> : tensor<64xf32>} : () -> tensor<64xf32>\r\n  %cst_25 = \"std.constant\"() {value = dense<\"0x57DB0CBD98589CBCF5952EBD0F15A3BDF67FB8BDCE40E2BDEF01AEBDE96A9A3BCCA6FA3D00BD52B7717D39BD7535073CA1190EBD86AFFB3C909A783D69947DBCE275DCBC741E1D3C7655B33B0FB10EBE24EC883D7EE41ABD3C77DABADFA302BD45EA86BC642234BCB7F5CB3D1BCBE13C40D2C7BC1404D23B18616BBC207E8FBADCDB2B3D319844BD13F903BE7F4B0A3EC031543D97FA703DD35ABC3CEA50A1BDFD1D9E3CC128573C33151ABD431AB1BDA7544BBC5E766D3D3913F0BD33A8613D0386053DAD2B93BCE34D3BBDDD0DB03C24A202BD1A7DD83D4D7429BD34C57ABDA91C8ABCAB0A9BBC692EF4BD51C18A3D3D669B3C58387C3CC4EB9DBD696F5C3D169C05BD4B6314BD342F143DF44D34BDAEC08B3D99EC033C8C0D0ABAB2E5EABD46A7CF3D36A99BBDCD3003BD0CE8643C6A7FD6BDCD81463CF1BDC43C996EB9BC51C262BB5D381A3DC11208BE4901533DB260B7BD7C11483DCB68BCBB5E504FBD1EEF8EBD2444953D4A354ABD754971BCDF1381BDEB8DAEBBB777513D9B84A8BCF75E80BD44854FBD6441D73C9E98923B9E6730BBF02B3EBD0B7E89BDD8A0C13C3E17A5BDB803A73D72259EBD8FF9C33D0EC2C5BD75751E3DC8CC28BDDE59B23D0A571DBB1729483DFCA694BCB318BFBD71E4ED3DEF78233CB63E7BBD8E5748BDBD76493CA9A88CBDBC63283DD12F7C3D47CF4BBD0DDFBE3DC5AA05BB1484A93D772E123E2D8BA0BD915DA4BD2F18943D316FDEBD4DAA35BD1B72033D4894193C52AB18BE504801BD9C6E133D8E2E0E3DF92B583D7D60E33D05D30C3DDA25A6BCCFDBF9BCFDBD66BC3C8CA73C5EC90FBD38E7243EE6995E3CE04A7E3D0FCAB6BDC18515BD130BC43CA1C52FBD23F1623D9880DEBAA5AF8F3CFAF62CBD61E162BC70BCE7BD05F25A3DEC0BC5BDA1A3E0BBA6DA98BD0AD3BDBB668398BD57A79A3C0F28523D2EDE593DDFA711BD610EAC3D507FF8BBC63F96BDCA47B33DDE4C103DEBE4D7BD2E3A85BDFFE20D3DE346C1BD2AD7BDBC16...\r\n  %cst_26 = \"std.constant\"() {value = dense<\"0x243AB1BDCD79CEBD1CED5C3D886FB73DEFED813BECC66B3D0B1C16BD2794AD3D33965D3C6882053DF2AFD2BDED128E3AA4A181BD60E8C33D5AF85F3D9E10A23B1471F33C9AF99E3CFDF8B53D614642BCB90694BDD88B5DBDBA7DFD3DBD0BA13CB63220BDEDBB203D26BCF73CFC6CFDBC4264B9BDFD5B95BCE28F65BDC8C2F5BC9A49183EBA09133D9B0C77BBB24684BCAA8C35BCEAA130BD5AD285BD7EC060BDAD7FF93BB0FE163D2C4D20BD58C2F0BC087FFCBD683A603DC8B88CBD6CD782BDEE772BBD9462323DF1B340BC12E8433DDBDD63BD3477AEBD860FA83BFAC9B6BD7FD7753C73C5FD3CC6C709BE60C60E3DB51D013DAC0F2C3D17B884BC5887EEBCEF237DBD9B09E4BC733B2C3D1C80CEBCDEE455BD4F04FDBCAD1E49BC43871E3C1A8ECA3DD20E94BD3B710E3EE2C2FD3BBEC82DBDCAC50DBDFB34C7BC93F06EBC69CA8B3DC6C58F3C7C0BCFBD76B20DBC08282E3D3A339DBD1B8B82BC244C81BD9312BB3DED724EBD0821613D92F4703DF433EDBD68C207BA0A90F1BCE8950B3CC97FD13DCE253CBC6454BFBCE9EA0CBD6AE87ABC031D203DBCCC063DC7F4663DC837163C1902D93C2A18DBBBBE25AB3DF6A756BD34B55DBAC2BC1D3C3C5542BD5EAE673D9CFA2A3C3BECFC3D7E4D54BDD3A00BBD88B5B7BD2FADBE3CD4EF3FBD0A6B7B3DBF47533D3E78133D802185BD03D3B33DA96BAE3DCF705C3DD6D238BD72C20B3D664893BB63218DBB7DC039BCFEF558BB22AAFE3DF312C8BC013DAABC3F77383E099EF13CD4096F3C82F286BDED74873D9E9DFFBB9FCC9ABB697E723D156042BDF276DCBC13F5F03C64E581BD957C0F3DF01A12BB913E85BDEEE2A0BDD01E28BDF00A063D168982BDBAA9F13B0F2FAD3C65E7DABD67D2B3BD8AA73A3B0BF7DCBCB63A843D0F782B3EF9B1EBBCA744093DB28B73BD9A7BDE3D12D26CBD0AF738BC02665F3D664B3BBD7BC5F13DDFC2DFBA33FC24BC57261A3DDFE25D3D14BAEDBCC1F281BD93D46B3DC8CEC5BBEE0DE43C55...\r\n  %cst_27 = \"std.constant\"() {value = dense<\"0xB7BA29BECA620D3D20AEDBBDCCBDDEBAD30E06BE26719EBC3934383CC1D7C9BD64AB3A3DBF6F17BDEBBEBBBD64B084BDDEE5BE3D1326AA3C0F96943DBA169C3DAE31EC3CAE130B3D6793F3BD3CA1CB3C70FC43BA30AB123C08815E3D23BE82BD79AE013D89C0B83C329594BD3ED8903DD68541BD99E611BD57A6013E71C7283E05E89B3D58F7D9BCF7721CBD4E9D6B3CA373573D1D43CFBD3E417A3DD0FA85BBEC654B3D5E0350BD17BC993C9587B0BDE8E21FBED7152EBDDD2BDDBA0CBA633DC50E0D3E006C96B899F709BE170D8F3D453EFABCDDBF513CDEA0CA3C50C5A43D0D7776BC92EC04BDC0FEE33D901673BCE986D1BD297B223C5F35103CE28748BB8F6AE33D669F8E3DDAC5EB3DB23702BD5EBFEC3BD2D5C5BD75A218BD86DC9B3DCCC3F2BD2C90A23C1685C13C7EFCA0BD3494AE3DF8FACF3D90D6D03C8A2B97BCF78D783A7DC8863A4F5BCFBD2C9A6DBD7D168DBA90CA853C0020C7BC93526F3C14AC773D4F593B3DEA5D733DDBF0093DEDAE0C3D0C9115BC73D80EBC63BE82BA682CD0BDCAC09F3C8276E8BDE8B1B1BD80B19CBCF54CDE3B8FA52C3DE46312BD448A0DBC7220EABD56B6273DDBDECE3DA50DA33C3719843CFF151DBD9E500F3B0713E13B8070E5BBE8CDC5BDD83B4C3D6A906A3D86CAF73C80482CBBD7F815BDDA30893DF15EC93CB056AEBD74EE08BE0B05A73DCC6162BC146C8DBC3FA3C83C6C700B3E407C9BBD6F2593BD56356E3CC687063B0EDC46BDB0BB9B3CA8E916BD5A97EB3CE4DFB93D0E23F53C35078CBD8A2206BDEB0F013CC85FA13CD8D2F43D49FCF23C9E582D3DC3D171BB87D40ABDA395813B36D0173CB93B153D5C1662BBE4383E3DCC5013BD4798D63D0E5CC2BA1F7804BEB417543D20C1803CED3CB8BDC4B407BD6536FF3D0FF19B3DF50E313C5EB773BB498EDEBA77BB9EBDEEC5813B50EE3FBD591A093D5F4AF5BDB198C43A117BB73C23B7903DF63F16BDC373F73C2AF111BD1AAD08BC9A695EBC994078BC5F9770BD82...\r\n  %cst_28 = \"std.constant\"() {value = dense<\"0x3B2952BD677CF73C5B0D57BD9D4EE8BD51532C3E5255FB3A9457EA3D6E4389BD01FB85BDD2F7753D09B23A3C74B8E4BCEE0DECBDA09AA1BDD545D83C116A7B3D66DBC2BD3318D73BA2EAFA3C3A5CF6BC249C0DBDBC33B4BD4834233ECA2B4DBD99490D3DE709743D006A68BC70A7CCBC2AEA47BCD4C3383E1893433BC7B6E23DE79A90BD211FF5BDF370ACBDE1BE9FBA9B5594BD1E0E0FBE4DC4DFBDBB4364BD0E780ABBA0D5F33B51969D3DA31D0BBCF6BB9A3DF0FD183CC10C1ABD300144BDDA9665BB256B033DADEB813D3818A0BD0EE55A3DFC4FC1BC49130EBEB4FD8E3D65D696BCB4A37EBA6AE42CBDBD6551BD0E80DA3D072448BDAFF731BDE94905BD91F1C4BBF82A943D88BA963DCF358C3A9426A2BC18D114BBAC5A44BC60A2913D6C65C33D1FB8553BA2643A3D386C493BB014373DD428763D34A6B4BB888E773D4FE68FBDE8E8B3BC43CBA2BD9A57C3BC66EB5B3C8A9FD13C7143493D9EA0A63C970CB53B738686BDDEF6353DBE80583BEC4EBC3B70BFBDBD2C25B83DF3A90ABD49B9E93BEAA4663C55915CBDFBD81BBD46E069BD91B5A9BD18DBD9BC0C676CBDC7473CBD8AEF893DBF83213C278C453C8064A839C4CD393E0705933DB8A772BD4B9E8B3DFA9D863D64F30E3D63EF31BD4D00313D1F2B273DC1C1A63D45AF453C776B5F3CE801CBBD114E1C3DE601B4BD27E70BBCED12123DF031C6BCD132943D5793513D0A6FC23CA03545BD23BE083E36C7853D2B270D3BBC43BBBDFE94953DEF66C73D9486073D27149E3D8194AE3CCFF1D6BD648A7C3DFB6D153E29F854BDFEFE66BD1D47693DE950B83D8F62F63C239EAEBC481D4EBDD95AA5BD9AD4783D07FC703D7B8229BD873E47BDE099943D63D4373D8037B93C730D113E60DA0C3D4B121EBDDE0E5B3DE5649EBD29400B3D795B4B3D161FB93C8FF2513DB3CBA63C267D283D746AE03D57555FBD56BAF23C6AC7023D0ACB1CBEC92324BE53B2B5BDDADD4D3DB995DCBC9BDC053D61881BBEB67A02BDCE...\r\n  %cst_29 = \"std.constant\"() {value = dense<[9.67585132E-4, -9.76218085E-4, 8.44327267E-4, -9.95431095E-4, 9.78885102E-4, -9.89362248E-4, -9.97170456E-4, 9.94593254E-4, -9.74801718E-4, -9.967850e-04, -9.7882736E-4, -9.50525922E-4, 9.79408272E-4, -9.92655172E-4, 9.97303985E-4, 9.82631579E-4, 9.90360276E-4, -9.92504647E-4, -9.657435E-4, 4.47311701E-4, -9.95136913E-4, 9.76480427E-4, -9.81111777E-4, 9.97065915E-4, -9.86331375E-4, 9.94870206E-4, -9.89393214E-4, 9.676800e-04, -9.70026711E-4, -9.91622568E-4, 9.94842383E-4, -9.94916772E-4, 9.85594349E-4, 9.97806666E-4, -8.78486142E-4, -9.95528069E-4, 9.8985678E-4, -9.93425492E-4, 9.95124923E-4, 9.83530771E-4, 9.93813737E-4, 9.74371622E-4, 9.73470451E-4, -9.74504452E-4, -9.87119157E-4, -9.95987677E-4, -9.89082618E-4, 9.94357862E-4, -9.81126562E-4, -9.95713984E-4, 9.92701738E-4, -9.9737267E-4, -9.672870e-04, -7.41955242E-4, 9.90436179E-4, -8.20829126E-4, -9.95927955E-4, -9.940910e-04, 9.85695864E-4, 9.85741498E-4, 9.95741924E-4, -9.95478476E-4, 9.654010e-04, -9.80447861E-4]> : tensor<64xf32>} : () -> tensor<64xf32>\r\n  %cst_30 = \"std.constant\"() {value = dense<[0.999001801, 0.999005556, 9.990270e-01, 1.00099504, 0.999001979, 0.999002933, 0.999001145, 1.00095022, 0.999001979, 9.990040e-01, 0.999001502, 0.999003231, 1.00099468, 1.00091136, 1.00086093, 1.00098407, 0.999001622, 0.999009847, 0.999010264, 0.999002337, 1.00099421, 1.00099874, 1.00095701, 0.999001383, 0.999006628, 1.00099599, 0.999303638, 1.00099146, 0.999027907, 0.99900186, 1.00099814, 0.99900937, 1.0009948, 1.0009985, 0.999017238, 1.00099349, 1.00099826, 1.00098813, 1.000934, 1.00099516, 1.00097382, 1.00099266, 1.00099349, 1.00099623, 0.999081313, 0.999002218, 0.99900335, 0.999011158, 1.00099492, 1.00099647, 1.00099587, 0.999002039, 1.00099766, 1.00099695, 0.999008536, 0.999002814, 9.990050e-01, 0.99900335, 1.00099838, 1.00099766, 1.00099349, 1.00099289, 1.00097156, 1.00099587]> : tensor<64xf32>} : () -> tensor<64xf32>\r\n  %cst_31 = \"std.constant\"() {value = dense<[9.99597366E-4, -9.9919259E-4, 9.99345094E-4, -9.99698997E-4, 9.98205738E-4, -9.99698182E-4, -9.997270e-04, -9.99498763E-4, -9.98643808E-4, -9.96864866E-4, 9.99229145E-4, -9.99716343E-4, -9.98876639E-4, -9.98718547E-4, 9.98445553E-4, -9.99442767E-4, 9.99625306E-4, -9.8527607E-4, -9.95822483E-4, 9.97575931E-4, 9.998920e-04, 9.99492942E-4, 9.98938339E-4, 9.99762909E-4, 9.9961739E-4, -9.97697352E-4, -9.98864998E-4, -9.97156603E-4, 9.99353942E-4, 9.98489558E-4, 9.99433104E-4, 9.99394804E-4, -9.98000847E-4, -9.99715761E-4, -9.94169735E-4, -9.9937967E-4, -9.99294221E-4, 9.98356263E-4, 9.9906174E-4, -9.97644616E-4, 9.99090727E-4, 9.94966947E-4, 9.99400159E-4, 9.963630e-04, 9.97329829E-4, 9.99510521E-4, 9.99477691E-4, 9.99089912E-4, 9.99575247E-4, 9.99586307E-4, -9.99113777E-4, 9.99390496E-4, -9.97681403E-4, -9.83843114E-4, -9.97356371E-4, -9.98840085E-4, -9.99069889E-4, -9.98023431E-4, -9.98752773E-4, 9.9920528E-4, 9.99455805E-4, -9.99182928E-4, -9.99532174E-4, -9.97857307E-4]> : tensor<64xf32>} : () -> tensor<64xf32>\r\n  %cst_32 = \"std.constant\"() {value = dense<[9.81708988E-4, 9.63601749E-4, 9.90674947E-4, -5.41209592E-4, -9.96806542E-4, -9.83843347E-4, -9.94779984E-4, 9.9403772E-4, 9.31107497E-4, -9.93747846E-4, 9.95395239E-4, -9.97131573E-4, 9.82350902E-4, -9.86792613E-4, 9.92027809E-4, 9.9402538E-4, -9.92390792E-4, -9.95012698E-4, 9.74349154E-4, -9.90020693E-4, -9.8652183E-4, 9.94545291E-4, -9.17962461E-4, 9.61345387E-4, -9.95251466E-4, 9.94973583E-4, -9.72526962E-4, -8.81796877E-4, -9.74486291E-4, -9.71922826E-4, 9.95795126E-4, -9.96316666E-4, 9.90363652E-4, 9.97908413E-4, -9.92957735E-4, 9.958980e-04, -9.9491293E-4, -9.92778339E-4, 9.9361909E-4, 9.95804904E-4, -9.4126031E-4, 9.86351747E-4, -9.81890945E-4, -9.85238584E-4, -9.91161214E-4, 9.91085078E-4, 9.90797532E-4, 9.80959506E-4, -9.92152839E-4, -9.79809905E-4, -9.88770509E-4, -9.91929322E-4, 9.80777665E-4, 9.96440299E-4, 9.86681901E-4, -9.95011068E-4, -9.93575318E-4, -9.95142967E-4, -9.86838829E-4, 9.61801095E-4, 9.941320e-04, -9.97495604E-4, 9.76995914E-4, -9.35959106E-4]> : tensor<64xf32>} : () -> tensor<64xf32>\r\n  %cst_33 = \"std.constant\"() {value = dense<\"0x3CBBEA3B451EFC3C60A407BED262B2BD7C0C7A3CFF35FCBD7183ABBC10F0DEBD85B86F3BF859E8BD1E64D33D55CE933DDEAA983D9FEADB3CDA31EC3D3C21CABDCD54ACBDB8C4A53D1C5EE43D1F7C923C3235963B7944063DAB03AD3DEB26ADBD296D1FBD1F3076BD45E99E3CA6A8813D07F06FBD219E023ECF15E3BD65EF063EC05155BDCE53BE3D2376CEBD4699F9BD562A7DBD1212AD3D42EDC0BD5B01773C7A7302BE3B3154BCE519743DDAB986BDCE14F8BDAB8836BD28DB81BD3A817F3DE73DC73D70DBB6BDB0834C3D1304043EADAB303D7655613D43489B3D9D721B3CA09A64BDE792CEBD6595DABD8433703D64C8963D54EE823CA734DC3C2ABD923DFE0A9EBC5A62A33CA5A88C3DA94A37BD71A7D4BD6FDD993BDAB6B1BD0C41A0BD1AD223BD0896563D5B6883BDE674E7BD5F2828BD592626BDB648683D3EFB8D3DC9D5923C7A5A253D020280BD7AD50A3EA061933DEEE6EA3DA68980BDC1E8D73DED3E073DA01DD4BDD8A40EBCC040093DA770DBBD9FDFC6BD82B5B1BDB2CC863C1324FBBC1608A0BC5C5D623DEE427F3D76A0E1BC28ACC1BDEA90FB3C56958A3CCF4B9DBD9C0E75BDCEC400BE4A27B9BCD59D9ABDE0DE8D3DA88210BD4630073E8E5EE53DBA0D78BD9EDC6DBDEEF5393DB1E0013E2978033DAEDF66BDB14407BE71B99A3C54988A3BB329A2BD14870DBD3961FDBCF374FABD966B05BEF002BC3D12D97B3D10827FBCA725B8BD31450F3DF0AA3CBDE61ADE3B88D2083E1DF108BEA99499BDE546FA3D38DD04BE59D6CFBD38D4543D15C7E93B9679813D34A20C3ED939D5BD2CA7E23DF4F10BBE60166EBDDD6CDBBB6A0C33BDBC04F03D9EB6AE3D8B38CBBD8B162B3D45AC2D3DB9151B3DCBF58D3CD2030A3DCACEBE3D041E39BCD2ADD3BC429D92BD5957413DE843D23DF490C4BDB5507D3DCA2E3F3D2B4533BD60AEF03D983C61BD1A148BBDBBF7913D22773EBC47ADD7BCCE0D25BD1BC232BDEB76D2BCA2E7803C6D1319BD5C34B0BDEBDC88BDD3...\r\n  %cst_34 = \"std.constant\"() {value = dense<\"0x014B1ABDB51FB4BD77A132BD54BFD0BD4F596A3D1439DBBD4B39EB3C3275BB3D4E52EA3B0C8E09BE29C90A3EEE3700BD61CF76BD068808BEA24409BE589A66BD592285BB270BDFBA970207BE86B801BD95EEEBBDA06603BE7BC2BC3D6FE8373C88BF633DD3B03C3DCBECDBBC90F75FBD7C7E1FBD6475ED3D99DD51BD16F0DE3D8BA496BC0371E23D2845C8BD240BDDBD06C70ABECBAE9FBDC59E7EBC127B74BC6C35E2BD0E0204BE62115DBD8162903DFABBC5BDA22CD63C20D287BC54E58E3D915B523D34A8A83D10299DBD4D61D0BD87EAA53D446D613D4CBF5D3D494C573DB2AC4CBCE665B3BDC4D505BD3948DC3CB294F73C1FAF88BD7E9C193DFF06A23D0164063D49C43A3D8A2BF1BD0F5EC53B666907BEDF79373D55F1D3BD551C3A3D9D624CBD78BB9B3D5BEF8A3DCC4AEB3D37CEE73DA0F3D23D5AE4333D398D333C0306E5BD1FD7FD3DFFA9C7BD7039563DFD73EA3D71A1033E011503BEF3378C3DCD73AABDFF37833D52D096BD3D34BB3C54DEDE3D37F3AB3D70D93B3D8A3EFF3DF7C0C23D33575BBD7DEA00BEF8A9933CFE7813BD42A5E23D330B0EBD91A6A7BD3FCD3B3C2336323DCA5FE03D9F115CBB8C62D9BDCD34D73D86A4E1BD4678E03C053EBD3D567A7D3D19B108BDDBF6043E64208E3D4BA3C7BCC430D13D8135DFBDDD03D93B5F07EA3DB103853D8910963CA87AAEBDD58C9BBDF4FC123D6BEFB5BDC1039DBD8BF9EA3D9217E63DD208E7BDB178BB3D150883BBE2B1B2BD231692BD66571FBD09410BBD0CEAA33CA5D80F3CA0EB393CECF9713D7945B9BD2F86E1BDFED7D03DFB04FEBC0A5E623D19BE9C3D3691C8BCA05488BD0BF2003E26D94C3DA780E43D15E7BC3B012DD93D4E7904BE9B62C2BD3F70C5BD5D0883BB1125E63DA76D5F3D1357A13D7CA6DD3C5FA5043DE6124FBD253E18BD96AA56BD2862433D7415093E81CB583C25F1D03DE67913BDA296BCBDD8BDBB3DBCB286BD45C0873CD374D9BD1559DF3DADDD363DC94E09BD045B313D43...\r\n  %cst_35 = \"std.constant\"() {value = dense<\"0x5D257E3DBA77A83D1581D63D2E973EBDA2A94DBD964DF53DFAD025BC0FF4C2BDF04190BDEE3EF63DCDE432BD168D683D0505E33C1F296EBD1F04DA3D367BF53D7BEE3F3DF8E0BF3BFB4BB6BDE1A901BD3FCDA63DF6C21BBD835D033E90BFE6BC6636C1BDF1DCBD3DBEC6D2BDFDC6D7BD6505F63DC242293DCF3833BD3756FE3C1102E9BD9A23A73CBAFE8B3DAAC1343DE017543CFCE2F53DAB0EB5BC55BE903DCC7B2FBD4047863DF7851ABDD6108DBDD0583C3DE83617BC68409B3DC56C913DCE77F33D119805BE7DB4FDBDD7211D3C14E68ABD8DF580BB31F189BD20D4033D05A4613DEFD400BD18BA263D79EEE13D338CC6BD99A5A13DB00219BC5A25813DDDBA92BDCBC1BE3D163D5D3D9F0E063E21DF79BC2BBCBF3D41A565BD820EC5BC547700BE6C6605BED73D93BD37E4FB3D05D896BD950D6DBD41B33F3D27A1D0BD1EF30F3DD5E09C3D0616D2BB350F903D0362B03D79E6C8BD248981BD707E653DA0AB09BD46F375BDEE20AE3C68F05BBCD2BBA93D9667C9BD79C4C53DC05B043E54A6F1BABACF26BDEDB7773DC6F69EBD472836BC20C101BEFC594B3C4FE1AC3DBDC1833DE29B563D1AA472BDF7CEAEBDB245F63CBC9BF53D74252C3DDFB7CA3D386E97BD3149C43D4481193D520EF93D6017E4BD20CAE3BC8CCD6DBDB81BA43D50C8343C4685BABDDC66003DC0FB15BCF78402BEC98EFEBDA818EB3D3AF8C8BDE9182DBD94E9F63DE5FAC63B4B81B9BD5CA7063E3A8F44BC174B1CBD1438033D2E0D873DED16B6BD637A403DB264DE3D271984BD35E2C63CB16FB53D8CDD2B3D8266E3BDFAAA373C8026B8BD6F229DBDD2C31ABC72CA5E3DEA95363DAB6EDBBC6B5B2F3DCB6F95BDDDD8EA3C8901B73D28680A3E9759F13D3B6FEDBD1908573DCA1696BCA5391CBCD6D098BCB976ADBDB54E06BE8371E23D5151EBBD6732A8BDAE23A83DB32EB8BDAE81083E6E7050BCB540B3BC309A82BC6E119DBCC77870BC10F2E23D1B6E943D5AE878BD8AA005BE709BB7BD22...\r\n  %cst_36 = \"std.constant\"() {value = dense<\"0x995CD03CBBE0F2BC23A0B83D48070DBDF106813DE32A793D0519BEBDB63500BE784AF03D7D1305BEA39E16BD33ED57BDCA32003E1E046A3DED87D53DCB0B973C34B9E93DD9DEFCBCD0BE98BDC43B023E21A9913C4627BBBD7968C5BC1B3BFE3D0F0D8E3D9634BABD105803BE6B94E63D9E21053EBA02443DF1C36F3CFB839B3DF33E093E6068933C7EDFB0BD083287BDB414D1BD03AA97BDB145483DB00B033DE32F993B77EA6DBD1E9EA03D9C9203BE6C34C53DF5F68C3D322ECEBD15D28E3DB4F9ECBCD16A2A3D4E5010BD9ECD1CBDA52C87BCEDD8F83C012CD8BC0282903D597C61BD031D093E29D503BE3EDC463CC16181BC0DE1C93D945909BE259AA6BDE1E3093D17954C3D88372E3BDE8DD0BDDEE0993DDA9D11BDDB4B153D925C763D4EF890BDB87F5C3D949394BD9CB4C4BD423FACBD59E4C43D0794163C29518BBBAC9DF13D5B3A90BD03E6D9BA55EDCCBD505E51BD39AC9CBCC8FBF43DBD6F043E587DCEBC68F6D33C2F98E33DA63BEB3D5745273DD450AA3D27C306BEDCB2283B2AFDF2BCEDC7E23DC93CD13DC4366FBCC26EE3BBDCEEAA3D5C1BF63DCEA0083E90D650BD5DF6903DA98E813DDA45D7BD905F00BDE0FC01BD8CBCA5BD189D89BD4D14393DF7AE0DBC40F34DBC44231A3D3CE5BEBD251A8ABD842DB5BDB6417DBDB4CE51BC313E08BECE2BE9BCD31644BCC43D6D3DCACACF3D64C1B0BD88C0203D2413C3BD6F8C2F3CC92935BDBB6A89BC233F52BD143A79BCCA0B9A3D9A346DBC1D79AF3D7EB2053E89CD053E23EE00BEA38193BB9BF92D3C994AF4BC5AB848BD95C6E9BD29354DBD664080BD22B2863DE8B2F63D2A9D043EFADDF83DDCB348BD8C43073EF1A77F3D8F37743D7A43813D7D3294BD01EFDC3D66C6973D7DB3F7BD5F09A6BB1960183DE14360BD3C9DDB3CD948DE3B570B79BCC223E83DAE53643CDF1A883DE6B9D9BD7E3C2BBD90DF603DE8BEE6BA3C009C3D3EEC2FBD62B506BE8A230ABEFABE71BB7AC709BE312AE2BBD811A1BC24...\r\n  %cst_37 = \"std.constant\"() {value = dense<[[0.141972259, -0.140112832, -6.299400e-02, -0.188756421, -0.296468705, -0.193415761, -0.257958204, 0.138051048, -0.116950154, -0.166800201, 0.279425412, 0.252810538, 0.0246988367, 0.0818047821, 0.16655989, -0.172646925, -0.231393486, -6.86961692E-4, -0.0970985144, 0.223860174, -0.260656685, 0.19828698, -0.0498352349, 0.245914236, 0.0637414455, -0.111480176, -0.0401437283, 0.0500495099, -0.125676543, 0.205395907, 0.16058588, -0.00452343794, 0.0116028748, -0.248046264, 0.07183934, -0.224206865, -2.637570e-01, 0.066637516, -0.215825126, -0.0450223759, 0.197781667, 0.0415594503, 0.103903204, -0.0888473243, -0.0138380127, -0.186089963, 0.185404703, -0.167652592, 0.23974292, -0.218838304, 0.213134632, -0.162772402, 0.181808576, -0.103578761, -0.0596696399, 0.105313681, -0.101291053, 0.0236400794, -0.167137861, -0.129845485, 0.107204571, 0.193863332, 0.0873046442, -0.0449375287]]> : tensor<1x64xf32>} : () -> tensor<1x64xf32>\r\n  %cst_38 = \"std.constant\"() {value = dense<0.000000e+00> : tensor<128xf32>} : () -> tensor<128xf32>\r\n  %cst_39 = \"std.constant\"() {value = dense<\"0x11D42CBD71902DBBAF29743C2A2046BD3D29603DA16E253C59952F3D6711333DE78F003D62E7983C43FC32BD7CEF39BD549D323DAC6DD8BB8D966C3DA49C59BD4A37633DF48E6EBD97D7303DC92BF2BC4B556C3D1D015F3DE9623FBDBB26BE3CEB0D373BBE8CB0BCAF44B7BB10770DBC078021BD6DC820BC7EBF1B3DDAB0003DE611E83CB0176B3A1CF9793D5EFA2DBCDC6C83BC36485EBCA0DC6D3DC12CC53BB0F4203C50F4F8BCC6AA5C3D37C1D0BCFC9D80BB9184B5BC1907B23C816A64BD9C592B3D3F9597BCC49A1EBDC77677BDFDD033BDFEBD78BD1EB8563D10AB72BDC65A883C6F32B93C1FF4483D0B81D3BC21BE743D26379BBBF426C9BCD079413D963334BCC8A072BDB28DA0BC5C6E763C1411B83C646B203DCF8F0ABD8F68EABCE98177BDC03B13BDDED4433DE78B42BD693F3BBC4BB11EBDC14911BDFF5E623D1FA1E83C56BC34BC950A21BDECAD4E3C4B8D423D038441BD2536E0BCC4F1483D1123A03CD98765BD39D2BFBCDB07BA3C77554ABD922F8FBC175AEBBBBE6F613D8BB24A3D3B9B8D3CEC540DBD8A5519BD2A4AA1BCD0835ABDBA1A8D3CE5A677BD5AD34BBA6D350E3D45A85F3D9C85373D70C191BB7AF56E3DD60993BCF984E0BC0D0C96BCB27C2EBD5300A9BBD805433D63F0403D53013E3DC01A133C7FDC733DC71D283C8B9E7BBC9568753D2FA60C3D485BBC3C921A353DD35C0A3BD3C69C3C3857133D52ACCC3CDEEF3DBDB8D1A0BC0A854ABD7967ADBCEBA4303DA95E33BD8F4B853C1EDF0ABD697C3ABD24378A3CF3E05E3D139DA63CBD0B373D48F1E43C5CF140BCEF6804BD147B263D2E1BCFBB35A9023DA01444BDD5E0093D05B8713C58BA5D3D5A41BBBAF4B5E4BCB8ECEB3CBE0B61BDF3AC28BD863C813B958456BDD0ED2ABD6492113DA355663C8322F23CDB5079BD1D40953C210C483DB1B0BFBB3A137FBD3DBB6EBD7D2B8A3CFB42CFBB44F64DBDA1BC473D7099A1B932482BBD08A304BCC7C14D3DD09DD23CF9FC4CBD6440683DF9...\r\n  %cst_40 = \"std.constant\"() {value = dense<0> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %cst_41 = \"std.constant\"() {value = dense<1> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %0 = \"tfl.expand_dims\"(%arg0, %cst_1) : (tensor<?x1000x100xf32>, tensor<i32>) -> tensor<?x1x1000x100xf32>\r\n  %1 = \"tfl.conv_2d\"(%0, %cst_39, %cst_38) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"VALID\", stride_h = 1 : i32, stride_w = 4 : i32} : (tensor<?x1x1000x100xf32>, tensor<128x1x7x100xf32>, tensor<128xf32>) -> tensor<?x1x249x128xf32>\r\n  %2 = \"tfl.squeeze\"(%1) {squeeze_dims = [-3]} : (tensor<?x1x249x128xf32>) -> tensor<?x249x128xf32>\r\n  %3 = \"tfl.add\"(%2, %cst_0) {fused_activation_function = \"NONE\"} : (tensor<?x249x128xf32>, tensor<128xf32>) -> tensor<?x249x128xf32>\r\n  %4 = \"tfl.mul\"(%3, %cst_7) {fused_activation_function = \"NONE\"} : (tensor<?x249x128xf32>, tensor<128xf32>) -> tensor<?x249x128xf32>\r\n  %5 = \"tfl.add\"(%4, %cst_8) {fused_activation_function = \"RELU\"} : (tensor<?x249x128xf32>, tensor<128xf32>) -> tensor<?x249x128xf32>\r\n  %6 = \"tfl.shape\"(%5) : (tensor<?x249x128xf32>) -> tensor<3xi32>\r\n  %7 = \"tfl.strided_slice\"(%6, %cst_40, %cst_41, %cst_41) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<3xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %8 = \"tfl.pack\"(%7, %cst_3) {axis = 0 : i32, values_count = 2 : i32} : (tensor<i32>, tensor<i32>) -> tensor<2xi32>\r\n  %9 = \"tfl.fill\"(%8, %cst_2) : (tensor<2xi32>, tensor<f32>) -> tensor<?x64xf32>\r\n  %10 = \"tfl.unidirectional_sequence_lstm\"(%5, %cst_19, %cst_20, %cst_21, %cst_22, %cst_11, %cst_12, %cst_13, %cst_14, %cst_6, %cst_6, %cst_6, %cst_15, %cst_16, %cst_17, %cst_18, %cst_6, %cst_6, %9, %9, %cst_6, %cst_6, %cst_6, %cst_6) {cell_clip = 1.000000e+01 : f32, fused_activation_function = \"TANH\", proj_clip = 0.000000e+00 : f32, time_major = false} : (tensor<?x249x128xf32>, tensor<64x128xf32>, tensor<64x128xf32>, tensor<64x128xf32>, tensor<64x128xf32>, tensor<64x64xf32>, tensor<64x64xf32>, tensor<64x64xf32>, tensor<64x64xf32>, none, none, none, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, none, none, tensor<?x64xf32>, tensor<?x64xf32>, none, none, none, none) -> tensor<?x249x64xf32>\r\n  %11 = \"tfl.mul\"(%10, %cst_9) {fused_activation_function = \"NONE\"} : (tensor<?x249x64xf32>, tensor<64xf32>) -> tensor<?x249x64xf32>\r\n  %12 = \"tfl.add\"(%11, %cst_10) {fused_activation_function = \"NONE\"} : (tensor<?x249x64xf32>, tensor<64xf32>) -> tensor<?x249x64xf32>\r\n  %13 = \"tfl.cast\"(%12) : (tensor<?x249x64xf32>) -> tensor<?x?x64xf32>\r\n  %14 = \"tfl.shape\"(%12) : (tensor<?x249x64xf32>) -> tensor<3xi32>\r\n  %15 = \"tfl.strided_slice\"(%14, %cst_40, %cst_41, %cst_41) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<3xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %16 = \"tfl.pack\"(%15, %cst_3) {axis = 0 : i32, values_count = 2 : i32} : (tensor<i32>, tensor<i32>) -> tensor<2xi32>\r\n  %17 = \"tfl.fill\"(%16, %cst_2) : (tensor<2xi32>, tensor<f32>) -> tensor<?x64xf32>\r\n  %18 = \"tfl.unidirectional_sequence_lstm\"(%13, %cst_33, %cst_34, %cst_35, %cst_36, %cst_25, %cst_26, %cst_27, %cst_28, %cst_6, %cst_6, %cst_6, %cst_29, %cst_30, %cst_31, %cst_32, %cst_6, %cst_6, %17, %17, %cst_6, %cst_6, %cst_6, %cst_6) {cell_clip = 1.000000e+01 : f32, fused_activation_function = \"TANH\", proj_clip = 0.000000e+00 : f32, time_major = false} : (tensor<?x?x64xf32>, tensor<64x64xf32>, tensor<64x64xf32>, tensor<64x64xf32>, tensor<64x64xf32>, tensor<64x64xf32>, tensor<64x64xf32>, tensor<64x64xf32>, tensor<64x64xf32>, none, none, none, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, none, none, tensor<?x64xf32>, tensor<?x64xf32>, none, none, none, none) -> tensor<?x?x64xf32>\r\n  %19 = \"tfl.mul\"(%18, %cst_23) {fused_activation_function = \"NONE\"} : (tensor<?x?x64xf32>, tensor<64xf32>) -> tensor<?x?x64xf32>\r\n  %20 = \"tfl.add\"(%19, %cst_24) {fused_activation_function = \"NONE\"} : (tensor<?x?x64xf32>, tensor<64xf32>) -> tensor<?x?x64xf32>\r\n  %21 = \"tfl.reshape\"(%20, %cst_4) : (tensor<?x?x64xf32>, tensor<2xi32>) -> tensor<?x64xf32>\r\n  %22 = \"tfl.fully_connected\"(%21, %cst_37, %cst) {fused_activation_function = \"NONE\", keep_num_dims = false, weights_format = \"DEFAULT\"} : (tensor<?x64xf32>, tensor<1x64xf32>, tensor<1xf32>) -> tensor<?x1xf32>\r\n  %23 = \"tfl.logistic\"(%22) : (tensor<?x1xf32>) -> tensor<?x1xf32>\r\n  %24 = \"tfl.reshape\"(%23, %cst_5) : (tensor<?x1xf32>, tensor<3xi32>) -> tensor<?x249x1xf32>\r\n  \"std.return\"(%24) : (tensor<?x249x1xf32>) -> ()\r\n}) {arg0 = {tf_saved_model.index_path = [\"input_8\"]}, result0 = {tf_saved_model.index_path = [\"time_distributed_4\"]}, sym_name = \"serving_default\", tf.entry_function = {control_outputs = \"\", inputs = \"serving_default_input_8:0\", outputs = \"StatefulPartitionedCall:0\"}, tf_saved_model.exported_names = [\"serving_default\"], type = (tensor<?x1000x100xf32>) -> tensor<?x249x1xf32>} : () -> ()\r\n\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nConverterError                            Traceback (most recent call last)\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/convert.py in toco_convert_protos(model_flags_str, toco_flags_str, input_data_str, debug_info_str, enable_mlir_converter)\r\n    200       return model_str\r\n    201     except Exception as e:\r\n--> 202       raise ConverterError(str(e))\r\n    203 \r\n    204   if distutils.spawn.find_executable(_toco_from_proto_bin) is None:\r\n\r\nConverterError: <unknown>:0: error: loc(callsite(callsite(callsite(unknown at \"functional_7/lstm_13/PartitionedCall@__inference__wrapped_model_240475\") at \"StatefulPartitionedCall@__inference_signature_wrapper_247244\") at \"StatefulPartitionedCall\")): We cannot duplicate the value since it's not constant.\r\n\r\n<unknown>:0: note: loc(\"StatefulPartitionedCall\"): called from\r\n<unknown>:0: note: loc(callsite(callsite(callsite(unknown at \"functional_7/lstm_13/PartitionedCall@__inference__wrapped_model_240475\") at \"StatefulPartitionedCall@__inference_signature_wrapper_247244\") at \"StatefulPartitionedCall\")): see current operation: %10 = \"tfl.unidirectional_sequence_lstm\"(%5, %cst_19, %cst_20, %cst_21, %cst_22, %cst_11, %cst_12, %cst_13, %cst_14, %cst_6, %cst_6, %cst_6, %cst_15, %cst_16, %cst_17, %cst_18, %cst_6, %cst_6, %9, %9, %cst_6, %cst_6, %cst_6, %cst_6) {cell_clip = 1.000000e+01 : f32, fused_activation_function = \"TANH\", proj_clip = 0.000000e+00 : f32, time_major = false} : (tensor<?x249x128xf32>, tensor<64x128xf32>, tensor<64x128xf32>, tensor<64x128xf32>, tensor<64x128xf32>, tensor<64x64xf32>, tensor<64x64xf32>, tensor<64x64xf32>, tensor<64x64xf32>, none, none, none, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, none, none, tensor<?x64xf32>, tensor<?x64xf32>, none, none, none, none) -> tensor<?x249x64xf32>\r\n<unknown>:0: error: Failed to duplicate values for the stateful op\r\n\r\n<unknown>:0: note: see current operation: \"func\"() ( {\r\n^bb0(%arg0: tensor<?x1000x100xf32>):  // no predecessors\r\n  %cst = \"std.constant\"() {value = dense<9.9943357E-4> : tensor<1xf32>} : () -> tensor<1xf32>\r\n  %cst_0 = \"std.constant\"() {value = dense<\"0xE30BE3B458690BB4A3B6ACB5D7BB263456F1E83527D417B745E0B1319E918E35717B2034BADFF2B5BC71DA36C9BEA6357FEAB834E78A50363F337B34D9EF64B4243D06B6D7ED4D362185EBB5851C1EB2DF5C6235448401B64B6CBF351CE0B435577819B5A3C8B9B5BAE50FB6EAAE85B4296D0D37742E8636472DA93410A839B6B0F3AA3545ED9DB55EABA73528FE6935C57C20B521FCCAB6146D6F35B1C9E3358C367935A6835C362040E9B5305A5A3675D79B36CCD3E8B5F7D83134F3FCC73558A42E367F36F335F08B0FB62B3B19B74367E4B5A1900EB72DF76FB5304B5C3496D04A357B7F97B6FBEA86348AC3333573A2B9B5B92C32363C003D36A47F273632596D34966B3DB57958B3B70D0C39B6C66FA9363016AB35DAD79835A23DA6B6F3E29E3664AC87B5A2592BB68AC90834D6331835B9B600B54DCBDE341AD586B6189BD2B413F0A6B5B607D3B47F7BACB5ED4D0A361A575436845BD6B6B54B1CB77C09C8B40B3FFAB59DDAEC32E65F85B4081C2DB75E45B836379ED23527C9BF36C94CA336A5C433B614DAC036A6E308B51BD9CE363BA05B3513036035681B1EB3D27FE3B5C7E7A3B5FC8B99B60D8705364DFF6A36E1A98DB5BCA14736CA373AB645C5F3B5F9ED09B6B64C03B7B5838A35DC3846B437DD33B6ECDE2F36C14FBEB50FB1B3B566EE05360741D83504D09E353793CA35265F0A365235DBB59A810935\"> : tensor<128xf32>} : () -> tensor<128xf32>\r\n  %cst_1 = \"std.constant\"() {value = dense<-3> : tensor<i32>} : () -> tensor<i32>\r\n  %cst_2 = \"std.constant\"() {value = dense<0.000000e+00> : tensor<f32>} : () -> tensor<f32>\r\n  %cst_3 = \"std.constant\"() {value = dense<64> : tensor<i32>} : () -> tensor<i32>\r\n  %cst_4 = \"std.constant\"() {value = dense<[-1, 64]> : tensor<2xi32>} : () -> tensor<2xi32>\r\n  %cst_5 = \"std.constant\"() {value = dense<[-1, 249, 1]> : tensor<3xi32>} : () -> tensor<3xi32>\r\n  %cst_6 = \"std.constant\"() {value} : () -> none\r\n  %cst_7 = \"std.constant\"() {value = dense<\"0x4868803FB466803F4AA9803F79A8803F6BA8803F6FA9803FB8A9803FEF67803F40A6803FB567803F0F68803FD0A8803FBB67803F14A8803FD067803F28AA803F87A8803F96A8803F9F67803F40A9803FCFA8803F4A67803F3266803F71A9803F03A9803F8567803FF967803FDFA9803F49A8803FA2A8803F2868803FF0A9803FBF67803F0DA9803FFB67803FE867803FD3A8803F6EA9803F5DA9803FBD67803F4967803F1BA9803FD067803F1E67803FBA67803FE266803FCF66803FDE67803FBFA8803F9467803F1969803F7767803F2068803FEAA8803FF7A7803FA1A9803F13A8803F7B68803FECA1803FA0A8803F40A9803FE267803F2768803FD5A9803F3467803FC6A8803FA8A8803F3D67803FADA8803F1D67803F2E67803FC468803F32A8803F6168803FDBA8803F8967803FFB67803F1AAA803F9F66803FEE66803FBFA1803FA2A8803F6FA9803FF767803FE6A7803F5E67803FBF66803FEEA8803FEB67803FC8A7803F05A9803F6067803F47A9803FF267803FE366803F1368803F9C67803F9DA8803F7F68803F1568803F15A9803F3C67803FE1A8803FA367803F3568803FA6A9803F5768803F4767803FD5A8803FF466803FB867803F7667803F3667803F4466803FD767803F99A8803F53A8803F5967803F1BA9803F1BA9803FC367803FC0A9803F00A8803FADA8803F71AA803FB96D803FDC66803F6167803F\"> : tensor<128xf32>} : () -> tensor<128xf32>\r\n  %cst_8 = \"std.constant\"() {value = dense<\"0x160683BB18CC3ABCF0152FBBF47A0BBCCBE290BA473EB03B98DEB43B6E7DE8B9E0962BBB34720DBB8CA08A3B947205BB88E016394D3C5D3A369976BB0448A43A4068CDB9E0EE09BA7EBE473BD78709BC4126053C2EB5053A50CE7D3B4CC968BA2AD9B13A79CB9EBA586D723AAC9489BAC4398CBB14ABD5BAB6B728BB9C6525BB9161F7BA8983CD3BC35ECFBB2D9F9CBBF17F413AC03E83B9E90A02BB5DEC68BB034E65BBA1F7863BFA1E953AB95826BBA83343BB949F05BCC33118BC85B9C43A808605BA0088DDB67116D03B38E3B63B093E0CBBBC50E7BBC46B5C3A4C76DC3A7EE0F0BB66A0243A3E91483A6302453A0496793BBEF99A3A8D1BC4BB945DD739D443583944B28BBBBAF4E53BE6BCC2BB9875453BD01E8D39C44A8ABA5AA8C3B9549853BB217EDA3A346F8AB9A23B1CBB45BF413C62A405BA4C8D97395AEEAA3BFB4FE3BBF6160ABB8568B73AF16F10BB44E2823BDE8B12BB5B0602BC4BACBDBBD95B0D3CE2C34B3A952B8B3AD8C7A6BAE4C12B3B0AB69E3B9853533BB3BD063C623A11BBAD8DF33A4889993BC668D6BA8E00A53B4CDCB0BB89AE693BC4A2B2B90BFDDCBAA60B0CBCE3CA52BAA7CD98BBBAE736BB6E005E3B9E3B4DBC80ABE93BAA4E8C3B6BA7D33AE01EFEBBC409ED391A19A93A2C052FBAA54B14BC8C2D70BC58F684BABC128B39AE80803CEC36D2B97C6839BADB88663B08E706391CC5ABBB\"> : tensor<128xf32>} : () -> tensor<128xf32>\r\n  %cst_9 = \"std.constant\"() {value = dense<[1.00473976, 1.00521708, 1.00263178, 1.00512218, 1.00516057, 1.00505733, 1.00508463, 1.00512767, 1.00468206, 1.00509381, 1.00515211, 1.00500977, 1.00460923, 1.00526345, 1.00518048, 1.00323498, 1.00313473, 1.00481927, 1.00307453, 1.00518346, 1.00318122, 1.00508034, 1.00511396, 1.00325751, 1.00530183, 1.00303495, 1.00524509, 1.00510859, 1.00507498, 1.00289106, 1.00500321, 1.00317168, 1.00510597, 1.00283813, 1.00500691, 1.00319803, 1.00302553, 1.00532532, 1.00289774, 1.00283813, 1.0031631, 1.00312734, 1.00510907, 1.00331628, 1.00476944, 1.0048629, 1.00319898, 1.00497484, 1.00326228, 1.00507808, 1.005170e+00, 1.00541019, 1.00510037, 1.00526011, 1.002900e+00, 1.00523686, 1.00262475, 1.00306499, 1.00506783, 1.00488198, 1.00327921, 1.00528109, 1.00526297, 1.00270772]> : tensor<64xf32>} : () -> tensor<64xf32>\r\n  %cst_10 = \"std.constant\"() {value = dense<[0.00212347507, 0.00114128285, 0.00424089422, 1.03820697E-4, 0.0025341576, 0.00241684401, -9.20396414E-4, 0.00274362462, -6.54401258E-4, -5.62307425E-4, 1.24871498E-4, -0.00112991163, 0.00194295647, -7.7732536E-4, 0.00172411324, 0.00204211427, -6.12335338E-4, 3.90041969E-4, -5.3005293E-5, 0.00170475454, 4.90864331E-4, 0.00253311382, -3.48295085E-4, 0.00198506215, 9.72406648E-4, 2.20654067E-4, -7.47772981E-4, -8.11745994E-4, 0.00160141359, -0.00112064206, 9.69715358E-4, 0.00184346607, 0.00207264954, 0.00188718142, 0.00195737928, 0.00224771816, 0.00170390774, 5.08747587E-4, -0.00367517141, 0.00248319749, -0.00254705641, 0.00120391347, -2.9670808E-4, 3.36897792E-5, -8.59148916E-4, 0.00119491515, -1.53806293E-4, -1.64092053E-4, -9.07708308E-4, 0.00232663471, -0.00211252738, -0.00117885927, 0.00240447256, 9.73630347E-4, -0.00122551713, -0.00213340251, -2.57467618E-5, 2.70258111E-4, -0.002932237, -0.00138859439, -0.00181194942, -3.7918007E-4, 1.09911198E-4, 0.00112971466]> : tensor<64xf32>} : () -> tensor<64xf32>\r\n  %cst_11 = \"std.constant\"() {value = dense<\"0xA182193D6852173C04EF7BBDE9BE8A3D7CEA35BDCFE4B43D92E47D3D203D4CBDF34D47BEF58101BD743B16BD4DC6B0BCEB285FBDDA1B953DBD410BBE8276743DE01D883CA2DD9ABA644B8CBC566B79BCEC738DBD6DFBB23D88AF1E3D16DDF0BCF265EB3D9D6F423D33D63BBDB9250FBDDF2AA33A84F3A13AFABE08BEE40BD73DA8CECEBDCFDAE23C880CE13D2C98B83D1C7C1CBD205A33BDB1CC8F3D5302CABDDF2D263D0FC7F73C924A213B38AEC5BD83D60B3DDC5A903D8C1406BD96AFAC3DAC2C3FBDCAAADD3CBCAD7D3DF47FF0BD3BA8063D3C38D1BC5DD0283D50752E3DC32A87BD19ABBD3CD6CA69BCDC160DBD3CB404BDE0952ABCBD5BD5BC52ECA23DD24424BE36F8E13DDFD9353DCBAC7EBD952CAE3D72B62A3DFAE18EBC64C742BD09C7A6BD782D893DA82564BD76DB853D6F4C3D3D017768BC1F998A3C3D29253DA49FBFBBEACA8EBD78CB4EBDB967943D431578BD7BECF73D87C2083C3DF3CCBD331D8BBC45E580BD6536C03D4252713D076A5ABD1F541B3D6AA0BEBD3E48533D542121BCEFC6A9BC66504E3D31ED84BC06C0823DDFFA8B3BA4E8843DA9B56F3DF12592BD4A8FC83C41E5A33CE4AF413C26658CBDCC65D33C98A9A63D61A3A7BDB0DBA4BDCB8A1DBC5808323DC65F08BD3C8B993D766D323DA37EEF3D067076BC0E4C6CBC1051923DD8E361BC626F77BB0B762A3CE106D3BD39A465BC4A82B23DCBEE70BDCEAC883D097C8A3D6F62DF3C74B00E3D725B843D6EF454BDFCFE3B3C8A2AB63DD790053D75ECF13D21F274BD39D99ABBC924F9BCE27D19BD2BCEC63DF30222BE2107173D3D0BBEBC974E08BEBE8D2E3B393C5CBD896FA1BD45DA24BCE6AB33BBD54CA4BCF304853DEFE0973DE595643D593CA73CAA2DEFBDEF3AA13CF18759BD45EE3E3B107800BC9F800B3E4051833C39EFA23C0904D6BB154CA83D9DA2ACBC847EF93C71CC1ABD31BAB5BD9E910EBEC9966E3C48AC03BC521E3B3C721A4C3D455AE13C1CCDB2BCEABBA4BC6EE801BDDB...\r\n  %cst_12 = \"std.constant\"() {value = dense<\"0x66A9D5BC396F00BED31B653CBEB2253EB266683DAA630A3DF348CEBCF921B7BD509439BD439542BAD13474BD50CF123EB550903DCC7231BD983BA93CF6F072BB6E887C3D1C737B3D5C8CB9BDEA58B7BCF5C9983D97F4A7BD0192D9BD4E499EBBE0C9653D1DD8D6BBC63A713C85216E3D0030273D52F0853DFC9D473CD1F2993D7BEF073D09E1EABC11318D3DBAEFD3BAF6F5003C8430E53D9FB23CBE15C8913DE8D51D3E97891EBD6F89113D38A9613DA190463CFC4416BDF6021DBD59C065BDFF96FA3C0708A43DEFFD0C3E4C58553D4A549F3BC421A13D5C81D43D121F8F3D6301DDBD5C3DAFBD68E7FBBC8FF3173D860B82BD5CA4813D2459C4BD27B28ABD2360FC3D99B2D93DEB55CF3DF8BD293D7379A63D1CF2803C04D155BDBB080BBDD78D923CDBCA91BC523C43BD2EA68CBCFAB694BD1DBD203E6412133D2CED05BEA8DB97BD997E86BDBC0975BDCCC16BBD4B03E2BD251DCFBC15767DBD60F5A03D3BA1513C4D6232BC4867D9BDBABA2F3D19B2BEBDB4954BBD04CA29BD5D0B78BCD756ABBC32D2C93C1FF7C53D200A42BD560120BBA03F1B3D8117733DFB1C733D33226DBD34D8DA3CD8BE07BE9B29D63B826181BD78DFB8BDAD7EE9BB5423ADBD9CB8C83C081CA23DBE7A573D307787BD8140D93DD924DFBCF5550CBE1D03513DACFEABBB88CFE2BCE2211C3D349F8FBC54DE90BDC9B06D3DCE33ADBD243C023D9738ACBABB02663C5C5EC5BAD8BC023CB6FFB23D5A9C43BCC95EDFBCA81ABC39B596AB3D7E972EBC836699BB42FBF7BC0EE007BCABA3443C2A66A23D3206B83D39AF383DC412C3BC690B83BCD4F0E63D4806D53C734E343C26C90CBD524036BD7EFE7EBDCAB4693C742EEB3DDC93E9BD299513BE850DC23C3EB5A0BD89AD64BEADBA753C9FC18EBDA89B80BCE4728BBDC3E4133DEAC54BBA7C4E47BD22C6C0BAE80E623CF8D8473D16C9B3BDA2950F3D9612A0BB3268D53D28B28FBD3B3BBFBD2A76723DE100AB3C47387E3CBF6718BE722E3E3BB0...\r\n  %cst_13 = \"std.constant\"() {value = dense<\"0x89C41CBCAF8AC2BD457EC23CD0CC16BCDD6A2E3E4B478DBC4A2143BDE0E4163DC250BE3D7AD2E63C0B11D0BCD79A753D854C7EBD3B4937BD391179BD91CD3ABCA9A6CE3C81A82DBD882EB5BD84F241BD6FE39C3B3454B3BCFC44D63B201256BBCFBA66BC47A1433CBDA498BD270A4DBCC07E54BD9E16AABDBE61383D0DE75A3DEDE8183CAB07A33CCF79503C688DFC3DC0CED7BC1849B13D867A0C3D8D5ACF3B5D2397BCDC9714BDB08E7E3C010337BD73C62A3DAEB2B33DD24E80BA17078FBC6D4424BC209F7E3CC06D473D2241CDBCC26B54BDC6A5A83D9C7856BDE09ABD3C85FDEFBDA4D7833C6915F23D001EEDBDA773F13CDB9F9DBD7380B1BDCFEB073D93BF32BD5F6775BD76C3AA3CA6E285BD7FC16B3C72BCDBBB19CB11BE82DBA73D4B2E753D8FB6413D5B9105BDDA452C3D15C974BDA361F83DB88388BD1448BBBD13E0863D9FA8093E9FFE50BD041B82BD121C153EE47D033CAEBC623D206BCDBCE86DBB3DEC3C0F3DC3B0EBBABB11F8BCDF9FF53DABC904BDB8FCBDBCBEC815BD9C355DBDEE006B3D1F62B9BC2C97CF3BEEEC20BDF51B943B98698E3D29FDD03DB7095B3D004BFDBC496E013E0AB17BBB7DF4DC3C0D276D3D541044BB9E114D3DB58D703B0BC2A03B298C37BDC529E13CF947C03D842C943D51F332BDFFE530BCC7E1FABC9FB590BDF217F5BD5529DB3C3CED813D353E043D6CE673BDD2552DBDD2AD353C518714BCF721C3BCE40CEDBD31E215BDFD2EA33CB41004BD53159BBC96A9E2BD6222D3BDD0096CBD1CF7A93C2D2D30BC1E152BBD6DBE24BD4CE7B1BDE1CFA1BDE07E053EBA5A2F3D6603EBBC1C6BD03B3597A9BD3208B8BD86C3193DBFF3933D0739263D661E893DE212173EAE038CBD400913BD8B40353DAACA84BD0532403E6E5636BCC8ECF6BCB1B4E53D0BB02FBDA03DAB3D36EB00BDFC06E5BDFF78A73CF7FC72BD351988BDEB09BF3C1C5F47BD7861893C3273A6BC8D118ABAC607C63DF3B7FBBDAB3D0A3D2BFCE8BD9E04AEBD0F...\r\n  %cst_14 = \"std.constant\"() {value = dense<\"0x6D7FE53B90D80ABB900637BD90E9CABC41E959BBC4683A3EF659273CDAB79B3B7277E6BD9680A3BC06664CBD4495EF3C78CB36BCCBEE783DE7233CBDE6E06C3DC4E310BC40B12F3DEEED48BDEF40503D9182B5BCCCE6443CC09188BD2A2999BDCD20EFBCDAFE4EBCA274FC3B446CC03B85408ABDB62E763DB49CE1BCCFCC7A3D2D801E3D624E3D3C00EC92BD55E9B2BC7D302ABD8F380DBD9CD3813D47EBCB3D977EF0BD3ED69D3DA41AA13CC517C63CD524CCBCA81C313D21F81F3DB2BD113D837E02BCDADD843D932C763D4FEF5D3DDEAB18BE12D212BC3B738EBD7B78C4BC6F65353EAD2506BE0FAA3BBCC8604B3DF5740A3D0D51C23D0084E1BD0A42DB3C9FEE8C3B93908BBD930453BDAFD70A3EB82CAC3C2D97083E656B03BD2E28033C25B813BDE6E4DE3D129D213D32C1A2BCD7B222BD972851BD34FD8B3DDA896BBC1EA2803C456AC73C9E63763DCD31DBBC3DFAC4BDB4A13E3DAFB8033D64513A3D8F72343E05EC913D109BA2BCA691A8BD0A49143B3513213DEE201CBC7A9B993B7745F23C686CC4BD9270853C8613F4BDAAA698BC8C5B2DBE3FC999BD8AFA8CBC99B65ABDBA5AAABCA0028A3D9635423D2656C03C37AC0B3D3992013EB451B8BCE33ED03D25F2B0BDE2D507BD65A05F3DD0EDA53D5D1B333BC79CC3BDB4DD04BD7D3116BBE4606D3DD404203DF22C133DB880BCBCDBF5D4BD7D9E8ABC2CEB9E3D04D5CABC95F8343DA6DAC73D7725F1BDB6ADA93B57E9BB3C9F0D9CBC409ACBB7E5088DBB42502EBC4EEAA3BC6EE8283C188C683C916A223DA2FF0ABDC0FD8F3CE56611BCBD8D97BD4628443D928C95BDEA581ABC0D16D63D2E85843C05A28BBC40538437626B323C9A7127BEAE940F3D8556A53C14C3533B1F17993DD2B3E5BD851BC3BD980643BD8980603CD9625A3D0072C1BC279913BD045D55BDE0D406BD55C56BBDA6EBF13C748ECDBC907E77BD0490C23D3C8B923C148F323DEC107A3A1CF4C43D9B2FBE3D556331BD0E6CEA3B5A54833D8B...\r\n  %cst_15 = \"std.constant\"() {value = dense<[-9.8901696E-4, 8.5479155E-4, 9.79730626E-4, -9.92890913E-4, -9.96473943E-4, 9.94842383E-4, -9.81436577E-4, -9.86810191E-4, 9.76143696E-4, -9.95050533E-4, 9.96386515E-4, 9.97202587E-4, 9.95036563E-4, 9.89387161E-4, 9.55004477E-4, -9.91261797E-4, -9.74753813E-4, -9.9344307E-4, -9.93789755E-4, -9.86392376E-4, 9.69534274E-4, -9.80411772E-4, 9.94408153E-4, 9.93013498E-4, 9.97127848E-4, -9.42781102E-4, -9.70873865E-4, 9.89013817E-4, 9.76190961E-4, 9.85609483E-4, -9.92171582E-4, -9.76951909E-4, 9.94690228E-4, -9.26485285E-4, -9.87045699E-4, -9.95974405E-4, 9.95763926E-4, -9.95861366E-4, -9.9247531E-4, 9.89652355E-4, -9.91960754E-4, -9.92493587E-4, 9.88994841E-4, -9.96514922E-4, 9.97994909E-4, 7.89895537E-4, -9.94454952E-4, 9.82676516E-4, -9.95628302E-4, -9.84977814E-4, 9.91726177E-4, 9.94249363E-4, -9.90893808E-4, -9.91686829E-4, -9.92248067E-4, 9.85561753E-4, 8.73027078E-4, 9.94159607E-4, 9.96555201E-4, -9.95308626E-4, -9.89207183E-4, 9.23537358E-4, -9.56159958E-4, 9.97224473E-4]> : tensor<64xf32>} : () -> tensor<64xf32>\r\n  %cst_16 = \"std.constant\"() {value = dense<[1.00099027, 1.00098932, 1.00099516, 0.999001443, 0.999003052, 1.00099671, 0.999013066, 0.999002039, 0.999003827, 0.999007761, 0.999003648, 1.00099814, 1.00098109, 1.0009973, 0.999003589, 0.999007225, 1.00099742, 1.00099838, 1.00099516, 1.00099599, 0.999002635, 1.00093877, 1.00099826, 0.999011039, 1.00098026, 0.999085307, 0.999004065, 0.999006569, 1.00098586, 9.990090e-01, 0.999005258, 0.9990049, 1.00098383, 0.999015271, 0.999016046, 9.990040e-01, 1.00099528, 1.00099838, 0.999001204, 1.00099707, 1.00098884, 0.999010801, 1.00098121, 0.999003827, 1.00099885, 0.999003291, 0.9990139, 0.999089419, 0.999002397, 0.999002635, 1.00099599, 1.00099051, 1.00099814, 0.999006092, 1.00099432, 0.999023616, 1.00092232, 1.0009979, 1.00094688, 0.999000966, 0.999003708, 1.0009973, 0.999011337, 1.00099313]> : tensor<64xf32>} : () -> tensor<64xf32>\r\n  %cst_17 = \"std.constant\"() {value = dense<[-9.96331218E-4, 9.9947548E-4, -9.99390729E-4, -9.99690964E-4, 9.99050796E-4, 9.99103183E-4, 9.98863601E-4, 9.99490497E-4, 9.99209471E-4, -9.99391428E-4, 9.99218085E-4, 9.99209703E-4, 9.80420154E-4, -9.99758602E-4, 9.98847535E-4, -9.99662093E-4, -9.99377341E-4, -9.989780e-04, 9.99162555E-4, 9.99477691E-4, -9.99286537E-4, -9.98504692E-4, 9.99714247E-4, 9.97304683E-4, 9.9933322E-4, -9.93805122E-4, -9.5772784E-4, 9.99755342E-4, -9.997870e-04, 9.98014817E-4, -8.64997389E-4, 9.97377792E-4, -9.99638345E-4, 9.9680887E-4, -9.98852308E-4, -9.99114126E-4, -9.99839277E-4, 9.98401781E-4, -9.99705167E-4, -9.99090261E-4, 9.95945185E-4, -9.99628449E-4, -9.98933333E-4, 9.98956267E-4, 9.99524607E-4, 9.99682699E-4, -9.98335075E-4, 9.99589916E-4, 9.97847644E-4, 9.99562675E-4, 9.99166746E-4, 9.97601891E-4, -9.99633572E-4, 9.98750911E-4, 9.99411451E-4, 9.98528324E-4, 9.96360555E-4, 9.99749638E-4, -9.9872041E-4, -9.99665353E-4, -9.9975022E-4, -9.98956849E-4, 9.98632749E-4, 9.98964183E-4]> : tensor<64xf32>} : () -> tensor<64xf32>\r\n  %cst_18 = \"std.constant\"() {value = dense<[-9.969270e-04, -9.82557306E-4, -9.93291963E-4, -9.90343512E-4, -9.97934374E-4, 9.90803935E-4, -9.84228565E-4, -9.96587565E-4, -9.97572089E-4, 9.795690e-04, 9.94196743E-4, 9.95259266E-4, 9.97718772E-4, 9.96876275E-4, 9.75065515E-4, -9.9695567E-4, -9.92954708E-4, 9.90913482E-4, -9.94683359E-4, 9.95306298E-4, 9.89426276E-4, 9.78857278E-4, 9.94338188E-4, 9.96380113E-4, 9.88848274E-4, -9.76715586E-4, -9.89963999E-4, 9.82530764E-4, -9.80048673E-4, -9.93657624E-4, -9.90298925E-4, 9.94730857E-4, -8.47386254E-4, -9.94144822E-4, -9.24524327E-4, -9.96671849E-4, -9.95290349E-4, 9.90399857E-4, 9.92561923E-4, 9.9778769E-4, -9.91268665E-4, 9.9106389E-4, 9.91855398E-4, -9.95182781E-4, 9.90162254E-4, -9.9000032E-4, -9.91538865E-4, 9.92999994E-4, -9.93227935E-4, 9.92302317E-4, 9.95503971E-4, 9.89457941E-4, -9.93986148E-4, -6.98388088E-4, -9.90565284E-4, 9.86032304E-4, 9.90497064E-4, 9.35149088E-4, -9.74465802E-4, 9.96848801E-4, 9.82844852E-4, -9.86666884E-4, -8.83933331E-4, 9.90752945E-4]> : tensor<64xf32>} : () -> tensor<64xf32>\r\n  %cst_19 = \"std.constant\"() {value = dense<\"0x5344EF3D6F3B673DAA17D2BCFC80D8BB3A659CBD8BDFABBC20C0E43DC24936BCDCA37A3B048FED3CDC876ABDA432D13DDCA59E3DB15ADABCDD4EA03DD654DC3DC02DC43C2E2A8ABDB2939E3D157A04BD361F1F3CFA9E25BDF88F99BDE1A8D8BD795D84BDC0E7FF3CD640793D7D12E1BD4FADA1BC89F9AABC7645ABBD9E28CDBC7DD1F23CD3C3A5BD0FABD1BD0D9B10BC264CBBBDCDE8EA3C0B15CBBD4A7AF63CAA93AF3D986C5B3D808A6FBD9118FDBDBE8AB0BC2DC1393D1CF2EA3D28A8813B1464803D54D8B7BC1BDEF8BDECAEB13D6D3700BE0ADBDCBD43E14F3D21DBE0BD3F86E9BD0914A73D0E649ABDABE0CF3D915CB03DD4CD003E73D400BC34DFF4BDDDA5A03D5521DC3D21B2D83D7FA049BB99CA493C272F263C87B59B3D5F36D63DD436B43CCF74FE3C937FFC3D8504933D532B813DFF09CDBDE626283B4403893D5F3E71BD3B68CABC8913A53D60C6B1BC7953A5BB25F7FEBC1F508E3DF1B7D43D09231DBD7148EFBDDE25E5BDB49F323CE29DE63D939BB73C853EC4BD37AEAC3C1E5A9F3C38094D3B00D0F83DD5798EBD6D06193D194BEC3CD435E73DEE0315BC622BF53B9A9DDDBD6213CD3D41A660BD7B0BA4BDD4CBC8BD02643E3CC2A0143CD760DABDF6DFC23C9D6D2CBD8FB1B0BD9C19C33D08A4BA3D9350F03D0DFADEBDED66BEBD326683BCF92B8C3DBE63A13D97324DBD36B7CBBDE8340CBD7E6B9D3DD693B1BD7D1EAA3D2CCC7F3C5D209ABDC6B0613DF9EBE9BDD293023B9938A53DC8901EBD766BDA3D8AD7C53D0748EBBD1DDEA03D4011083B17847BBD2D5DBABD0266AF3CA5EA42BD3EB48B3CAE1193BCEDE8333DF9F55CBD9F432BBD85C7573D37DAB3BDC4A1953DD9384ABDB035D0BCAF5A7B3D1CEDFDBD8C4BABBDF96740BCF393D93DA8EBBABC70E1233CC840A33DBEE46DBD312427BD2D9E0ABCBA08C33D7C4C19BD66C8193D742CF0BC0F4459BD1BC9B8BD7920CFBD483BBB3D3FB86CBD7DC88CBB62F5CC3DD8D3BEBDE230003EB4F3263D4C...\r\n  %cst_20 = \"std.constant\"() {value = dense<\"0xAD2AB8BDDE00973DAD58C4BCAAAA8ABD75A3EEBDAA08B0BD2D53A93D8504B23DDE2FB33BB3BE9FBD989925BC0180AB3DFAD7873C54A8E53C03E8A33D09130CBD58F704399614103D97E8D33DEFB35D3D758777BC79D024BD6DFE94BD24C8F93D476802BDD1F54F3C10553F3D81D7153CF91AC83D9EA319BDAC8620BDB427AABD9A4974BD1D738D3D025E99BC2F7E73BCDE4A403CDBC7BABDE06C773C89D2863DB5C5AA3D583BA8BBEB8C0FBD823FA1BDB832E83D32FCB23DA16C273D96B7B63DF29EF53C0889C73DED0C94BD6E02923D5A82663DE94CB23D2EF47FBD00AC25BD1AF43A3DEA7770BCF737F9BDFBF3373DE486933D909AC7BC5D79FBBB67AF9C3DBD84E7BD233CF23DA612F1BD8D3F1DBD92C2543CD17DA33DD4AF93BDE9BD973C8A8CCDBDE528353D0C4898BD07FCE8BD8D29BCBD5D1F85BDA61EBF3DE184433D9DD575BB95EDB5BD6E2A07BD5EBAFDBD48BDED3D72CF12BCD0A3D13CFCE0DBBD2229363C6CEFEFBDAC20813DBDAA803D3182AFBD7C68D83DFF424DBDD227C4BDFE7BE5BD4FCA4D3DADD4CF3DC6B5B63D3A019FBDC6BC983D3BAAB23D5777833D57B5FA3D37D6E23C3592783B9C3BB5BD6664CA3B78CF8A3D5FDED8BD6B1DCD3C19FA5E3D6A26D93DB1FC913DF855433B59E44F3DDF7182BD8BA8A93C0C70F7BD8C801A3D5206C53D2C47873DB2E6953C11F0AA3DAB8BFCBDBAA3CA3D78D9703DB89D6D3D19439DBD3AEDA23DF0168F3DC76907BD9F8898BDEF5EF6BD9114C53DD43CF23DF13FF23D0893DABCF51D41BD786C123D0B26A5BB19B2263D82838BBDA85EE5BD2690B63DBED5C5BA7C7564BD6E56A6BD19FCC03CF05475BD78E06A3D0C62BC3D4FE8B2BDD99C49BCD47A2E3C688BD53D489791BCF7B716BDA65771BD5EC69EBB2E4B56BCAC51E73D780214BCA4B4343D4C23B1BD05F8A23D4E41B53D1A62FB3C23DFA23D3A5BC0BD63B3DA3C1F69D3BD36DDA03DF7DDEFBC874AE1BDE2A3A33C4DFD1B3D6483773DF80AD43D3106B9BD5D...\r\n  %cst_21 = \"std.constant\"() {value = dense<\"0x049BE93D7A68483DF5E4723D2580483D76C58E3DA721C63DB6EECABDA84A2BBCF3CA943D1D4856BD4EAB20BD0E74FD3C39EFCFBD859A1F3D8EFF293B871BE43DCC4AB0BDD950D1BD2424A2BCDA6E763DA485C63DAA94F6BD6FFF21BDC5581C3DEA3C0D3D12F634BD665424BC304417BD493C8B3D6746FD3DDBCAA5BDF32FF7BD041A3DBC652130BD3390CCBD082A4FBDC4B9333D68D6A0BD1347783DEB589C3C0E4B87BD3A9EBE3D740E363D79114C3D5C08AE3D4A43B03D6910A5BB2522F8BD2CD2423D79659F3D0008DBBCE94957BDB476DABD66AF84BD0A822DBD5C6C22BDCC74D1BD7CDDC3BD5D3379BD61FCD6BDF149C6BD6CF3C33BD54295BDFC3BE43A68EE5F3CE8EB1BBD0C06A6BDF506E03D95FBE1BD84B8BB3DFA45223DBAE941BDC375333DAA694CBD61B3B2BCDD252BBD665B703DDB02EFBDA3CEA0BDA04E74BD7247763D54AB52BC804867BDCA3EA53D10419DBDEA13593D1EEADA3DDA3D373CB72900BEC178A73C04140CBD56A1B5BCA10AD53D145FB3BD6CE6EE3C2FCD803DE885113DFFD7A4BC0D0229BD65DCDBBD2B7E32BDFADB68BDDBA3C8BD8BFB973DADF3A9BD6BA79CBDDE5289BD691E8BBD3CF32BBD94268E3DE057B8BD34A97BBDD728DBBDDD87CCBC3EC91D3DA4186E3C94F2E0BDD8C727BDE067E63DD96AD4BD02F7AEBD71CDA23B593330BD675072BDC80E00BD7280983D30DFDD3BEE3A873D5D1A6ABDEC6617BDAA5AD5BDFDD60B3DDFA5AA3D14E05FBD2DD79C3D3833BEBCCACCF8BC1701D7BD135BE23B047CD63D5275AB3D904B473BCD9EAB3DF5A0983CF2509C3D473985BB494FE23DB29A9F3DDCA8A0BC8FF44C3DF76AC9BDAD84F3BDCFF94B3DAC8EB23DB00033BD8D7314BD1E60DDBDC38BA4BC3CEB98BDFFBCAA3DD626C9BDF906153CBD87473D76B2CF3C5DE8003EE5CD2C3D9EF7F93CEE2DAC3D109A9DB98D1CB4BDE875F7BD4065D7BD1BF4973DD281083DEDB1D3BDCCECBCBB1A55D5BDDDFB39BD950AC33C31A1853C8628EEBB53...\r\n  %cst_22 = \"std.constant\"() {value = dense<\"0x5D62F63D997CCD3D4BA877BC4A6FB63DC912423D2C82183D2FA383BDA72B963D6EFED3BD4D49B2BD771090BD3654F3BD4D75333DE2D6C7BBF5B6AABD53769F3C79F556BD9F1BEF3DC5ADD23D4C76EB3D5153AE3D7EBAD03D5BA1D6BC9D1D9FBDFE8C93BA4816E2BDC8DD823D6FCD063C1DBE0D3DE13DEBBD537A9B3DAD92E73DD896F6BDDDDA953D6BFF94BD0360E73DC79267BDEAC94E3D875070BD198A27BDE113E33DFBBD2F3D440148BC47577E3DD1FEA2BD59BA083D3163F03D8E7013BDF103B83DF1901FBD113002BC6713B5BD29AA893DA79F57BC415AEBBDB6D20F3A8472A43D4A5C6ABDF9EEBC3D9A28513D662064BD4A66983AA1D7DEBCB1F2713DD81F89BC22DEFDBC06E136BD32DD2D3D5F5C633D52CB75BD30F0D63D88682ABB6602B0BD018489BD4206E1BD0998A8BD65EFD1BD4D52FCBD471C953D15D42E3DBF46923DED88E53D3BA8C6BC9CA3DEBDD7A1E3BD967CAC3DF35E36BC13528CBDDC24EFBD2599EF3D42D14CBD50D1B0BD01C3D73DA0AEA4BD9517ED3C2ABD0E3D73E5F3BD5B13C8BDDC26ECBCABB5C73D9C64FF3D65C4203DA898E3BB3E24953D9C31B0BDABC9F4BD78ECC43DFCEDBEBD5B1DA4BD8DBE64BD22FFF4BBDBC6F93DB20AB03D3676A0BD6541E33D6D59BB3D43F4AEBDEFDB2CBD0FCC863D4BB24DBC6C4204BC418F6C3DB2F8F5BDD467E4BD581304BDE2BE863D3262053B88C2F9BDF115A0BD06ACB23D3664BD3D223975BBB4F3EABC375DCEBD1FA79DBB83CBF0BDF9D5D6BD4E315ABDB799A9BD46D955BD3144CD3D9BBA753C3B5FA1BD3E158EBDE4E3D9BDC771D3BBFA7AAABD7A36A7BD0AEC6C3C93158CBDABCFC2BD1EEEAD3D643FA73C9DBFDBBD2829D8BCEB47133C22B665BD01F2B4BDF9495FBD1044813C03C9B73CAFE6B8BD32C7CE3DD6C81DBA59A8A13DFA6BC13D5DA5D03C541B69BDF2C0F6BD7F0C6CBD1D150BBD1A04833CAB3B583D57C8F33D6022C53C1411993DE33D67BDD79517BC60ACF73DBE3194BD02C5F13C39...\r\n  %cst_23 = \"std.constant\"() {value = dense<[1.00309217, 1.00306129, 1.00305521, 1.00297964, 1.00312328, 1.0031054, 1.00307453, 1.00310564, 1.00313675, 1.00305128, 1.00307429, 1.00305736, 1.003070e+00, 1.0029887, 1.00302231, 1.00311744, 1.00306451, 1.00375688, 1.00299633, 1.0030781, 1.00298929, 1.00297678, 1.00304294, 1.003090e+00, 1.00315344, 1.0030973, 1.00511754, 1.00309551, 1.00313067, 1.00304472, 1.00306332, 1.00306582, 1.00493622, 1.00297606, 1.00302935, 1.00298393, 1.0030632, 1.00310445, 1.00310719, 1.00504351, 1.0031389, 1.00311208, 1.00314331, 1.00296211, 1.00310755, 1.00303924, 1.00302505, 1.00302935, 1.00308597, 1.00316334, 1.00303519, 1.00307107, 1.00308514, 1.00304747, 1.00304878, 1.00306785, 1.0030061, 1.00506783, 1.00308836, 1.00306702, 1.00507414, 1.00302899, 1.0030452, 1.00310063]> : tensor<64xf32>} : () -> tensor<64xf32>\r\n  %cst_24 = \"std.constant\"() {value = dense<[0.00105503935, 9.57053503E-4, 9.19337617E-4, -0.00135998649, 9.4322121E-4, 0.00111438113, -8.29911325E-4, -9.97727853E-4, -8.51589313E-4, 0.00107562402, -8.04005772E-4, -0.00109937368, 0.00111207424, -8.78392602E-4, -9.8252925E-4, -0.00109786494, -9.11238894E-4, 8.16963788E-4, -9.54134739E-4, -0.00101923943, -0.001126813, 0.00118361623, 8.54798709E-4, 9.88998217E-4, 9.06906615E-4, -9.89600433E-4, -0.00116529281, 0.00105114921, 8.55009945E-4, 8.50873534E-4, 9.1296091E-4, -8.51154094E-4, 1.086330e-03, -9.83795617E-4, 8.56689236E-4, -0.00103523524, -9.80255194E-4, -0.00102012744, -0.00115606235, 8.70998425E-4, 9.38069541E-4, 9.53909824E-4, -0.0011939907, 0.00102742529, -8.92813433E-4, -7.36643909E-4, -8.27286276E-4, 8.32178513E-4, -8.53449397E-4, -0.00132732699, -8.82953347E-4, 6.98925112E-4, 0.00104335765, -8.36898805E-4, -9.04436689E-4, 8.80992854E-4, -0.00101167895, 8.2154182E-4, 6.41766353E-4, -8.16440617E-4, -9.5120765E-4, -9.956470e-04, 0.00102537207, -9.21818893E-4]> : tensor<64xf32>} : () -> tensor<64xf32>\r\n  %cst_25 = \"std.constant\"() {value = dense<\"0x57DB0CBD98589CBCF5952EBD0F15A3BDF67FB8BDCE40E2BDEF01AEBDE96A9A3BCCA6FA3D00BD52B7717D39BD7535073CA1190EBD86AFFB3C909A783D69947DBCE275DCBC741E1D3C7655B33B0FB10EBE24EC883D7EE41ABD3C77DABADFA302BD45EA86BC642234BCB7F5CB3D1BCBE13C40D2C7BC1404D23B18616BBC207E8FBADCDB2B3D319844BD13F903BE7F4B0A3EC031543D97FA703DD35ABC3CEA50A1BDFD1D9E3CC128573C33151ABD431AB1BDA7544BBC5E766D3D3913F0BD33A8613D0386053DAD2B93BCE34D3BBDDD0DB03C24A202BD1A7DD83D4D7429BD34C57ABDA91C8ABCAB0A9BBC692EF4BD51C18A3D3D669B3C58387C3CC4EB9DBD696F5C3D169C05BD4B6314BD342F143DF44D34BDAEC08B3D99EC033C8C0D0ABAB2E5EABD46A7CF3D36A99BBDCD3003BD0CE8643C6A7FD6BDCD81463CF1BDC43C996EB9BC51C262BB5D381A3DC11208BE4901533DB260B7BD7C11483DCB68BCBB5E504FBD1EEF8EBD2444953D4A354ABD754971BCDF1381BDEB8DAEBBB777513D9B84A8BCF75E80BD44854FBD6441D73C9E98923B9E6730BBF02B3EBD0B7E89BDD8A0C13C3E17A5BDB803A73D72259EBD8FF9C33D0EC2C5BD75751E3DC8CC28BDDE59B23D0A571DBB1729483DFCA694BCB318BFBD71E4ED3DEF78233CB63E7BBD8E5748BDBD76493CA9A88CBDBC63283DD12F7C3D47CF4BBD0DDFBE3DC5AA05BB1484A93D772E123E2D8BA0BD915DA4BD2F18943D316FDEBD4DAA35BD1B72033D4894193C52AB18BE504801BD9C6E133D8E2E0E3DF92B583D7D60E33D05D30C3DDA25A6BCCFDBF9BCFDBD66BC3C8CA73C5EC90FBD38E7243EE6995E3CE04A7E3D0FCAB6BDC18515BD130BC43CA1C52FBD23F1623D9880DEBAA5AF8F3CFAF62CBD61E162BC70BCE7BD05F25A3DEC0BC5BDA1A3E0BBA6DA98BD0AD3BDBB668398BD57A79A3C0F28523D2EDE593DDFA711BD610EAC3D507FF8BBC63F96BDCA47B33DDE4C103DEBE4D7BD2E3A85BDFFE20D3DE346C1BD2AD7BDBC16...\r\n  %cst_26 = \"std.constant\"() {value = dense<\"0x243AB1BDCD79CEBD1CED5C3D886FB73DEFED813BECC66B3D0B1C16BD2794AD3D33965D3C6882053DF2AFD2BDED128E3AA4A181BD60E8C33D5AF85F3D9E10A23B1471F33C9AF99E3CFDF8B53D614642BCB90694BDD88B5DBDBA7DFD3DBD0BA13CB63220BDEDBB203D26BCF73CFC6CFDBC4264B9BDFD5B95BCE28F65BDC8C2F5BC9A49183EBA09133D9B0C77BBB24684BCAA8C35BCEAA130BD5AD285BD7EC060BDAD7FF93BB0FE163D2C4D20BD58C2F0BC087FFCBD683A603DC8B88CBD6CD782BDEE772BBD9462323DF1B340BC12E8433DDBDD63BD3477AEBD860FA83BFAC9B6BD7FD7753C73C5FD3CC6C709BE60C60E3DB51D013DAC0F2C3D17B884BC5887EEBCEF237DBD9B09E4BC733B2C3D1C80CEBCDEE455BD4F04FDBCAD1E49BC43871E3C1A8ECA3DD20E94BD3B710E3EE2C2FD3BBEC82DBDCAC50DBDFB34C7BC93F06EBC69CA8B3DC6C58F3C7C0BCFBD76B20DBC08282E3D3A339DBD1B8B82BC244C81BD9312BB3DED724EBD0821613D92F4703DF433EDBD68C207BA0A90F1BCE8950B3CC97FD13DCE253CBC6454BFBCE9EA0CBD6AE87ABC031D203DBCCC063DC7F4663DC837163C1902D93C2A18DBBBBE25AB3DF6A756BD34B55DBAC2BC1D3C3C5542BD5EAE673D9CFA2A3C3BECFC3D7E4D54BDD3A00BBD88B5B7BD2FADBE3CD4EF3FBD0A6B7B3DBF47533D3E78133D802185BD03D3B33DA96BAE3DCF705C3DD6D238BD72C20B3D664893BB63218DBB7DC039BCFEF558BB22AAFE3DF312C8BC013DAABC3F77383E099EF13CD4096F3C82F286BDED74873D9E9DFFBB9FCC9ABB697E723D156042BDF276DCBC13F5F03C64E581BD957C0F3DF01A12BB913E85BDEEE2A0BDD01E28BDF00A063D168982BDBAA9F13B0F2FAD3C65E7DABD67D2B3BD8AA73A3B0BF7DCBCB63A843D0F782B3EF9B1EBBCA744093DB28B73BD9A7BDE3D12D26CBD0AF738BC02665F3D664B3BBD7BC5F13DDFC2DFBA33FC24BC57261A3DDFE25D3D14BAEDBCC1F281BD93D46B3DC8CEC5BBEE0DE43C55...\r\n  %cst_27 = \"std.constant\"() {value = dense<\"0xB7BA29BECA620D3D20AEDBBDCCBDDEBAD30E06BE26719EBC3934383CC1D7C9BD64AB3A3DBF6F17BDEBBEBBBD64B084BDDEE5BE3D1326AA3C0F96943DBA169C3DAE31EC3CAE130B3D6793F3BD3CA1CB3C70FC43BA30AB123C08815E3D23BE82BD79AE013D89C0B83C329594BD3ED8903DD68541BD99E611BD57A6013E71C7283E05E89B3D58F7D9BCF7721CBD4E9D6B3CA373573D1D43CFBD3E417A3DD0FA85BBEC654B3D5E0350BD17BC993C9587B0BDE8E21FBED7152EBDDD2BDDBA0CBA633DC50E0D3E006C96B899F709BE170D8F3D453EFABCDDBF513CDEA0CA3C50C5A43D0D7776BC92EC04BDC0FEE33D901673BCE986D1BD297B223C5F35103CE28748BB8F6AE33D669F8E3DDAC5EB3DB23702BD5EBFEC3BD2D5C5BD75A218BD86DC9B3DCCC3F2BD2C90A23C1685C13C7EFCA0BD3494AE3DF8FACF3D90D6D03C8A2B97BCF78D783A7DC8863A4F5BCFBD2C9A6DBD7D168DBA90CA853C0020C7BC93526F3C14AC773D4F593B3DEA5D733DDBF0093DEDAE0C3D0C9115BC73D80EBC63BE82BA682CD0BDCAC09F3C8276E8BDE8B1B1BD80B19CBCF54CDE3B8FA52C3DE46312BD448A0DBC7220EABD56B6273DDBDECE3DA50DA33C3719843CFF151DBD9E500F3B0713E13B8070E5BBE8CDC5BDD83B4C3D6A906A3D86CAF73C80482CBBD7F815BDDA30893DF15EC93CB056AEBD74EE08BE0B05A73DCC6162BC146C8DBC3FA3C83C6C700B3E407C9BBD6F2593BD56356E3CC687063B0EDC46BDB0BB9B3CA8E916BD5A97EB3CE4DFB93D0E23F53C35078CBD8A2206BDEB0F013CC85FA13CD8D2F43D49FCF23C9E582D3DC3D171BB87D40ABDA395813B36D0173CB93B153D5C1662BBE4383E3DCC5013BD4798D63D0E5CC2BA1F7804BEB417543D20C1803CED3CB8BDC4B407BD6536FF3D0FF19B3DF50E313C5EB773BB498EDEBA77BB9EBDEEC5813B50EE3FBD591A093D5F4AF5BDB198C43A117BB73C23B7903DF63F16BDC373F73C2AF111BD1AAD08BC9A695EBC994078BC5F9770BD82...\r\n  %cst_28 = \"std.constant\"() {value = dense<\"0x3B2952BD677CF73C5B0D57BD9D4EE8BD51532C3E5255FB3A9457EA3D6E4389BD01FB85BDD2F7753D09B23A3C74B8E4BCEE0DECBDA09AA1BDD545D83C116A7B3D66DBC2BD3318D73BA2EAFA3C3A5CF6BC249C0DBDBC33B4BD4834233ECA2B4DBD99490D3DE709743D006A68BC70A7CCBC2AEA47BCD4C3383E1893433BC7B6E23DE79A90BD211FF5BDF370ACBDE1BE9FBA9B5594BD1E0E0FBE4DC4DFBDBB4364BD0E780ABBA0D5F33B51969D3DA31D0BBCF6BB9A3DF0FD183CC10C1ABD300144BDDA9665BB256B033DADEB813D3818A0BD0EE55A3DFC4FC1BC49130EBEB4FD8E3D65D696BCB4A37EBA6AE42CBDBD6551BD0E80DA3D072448BDAFF731BDE94905BD91F1C4BBF82A943D88BA963DCF358C3A9426A2BC18D114BBAC5A44BC60A2913D6C65C33D1FB8553BA2643A3D386C493BB014373DD428763D34A6B4BB888E773D4FE68FBDE8E8B3BC43CBA2BD9A57C3BC66EB5B3C8A9FD13C7143493D9EA0A63C970CB53B738686BDDEF6353DBE80583BEC4EBC3B70BFBDBD2C25B83DF3A90ABD49B9E93BEAA4663C55915CBDFBD81BBD46E069BD91B5A9BD18DBD9BC0C676CBDC7473CBD8AEF893DBF83213C278C453C8064A839C4CD393E0705933DB8A772BD4B9E8B3DFA9D863D64F30E3D63EF31BD4D00313D1F2B273DC1C1A63D45AF453C776B5F3CE801CBBD114E1C3DE601B4BD27E70BBCED12123DF031C6BCD132943D5793513D0A6FC23CA03545BD23BE083E36C7853D2B270D3BBC43BBBDFE94953DEF66C73D9486073D27149E3D8194AE3CCFF1D6BD648A7C3DFB6D153E29F854BDFEFE66BD1D47693DE950B83D8F62F63C239EAEBC481D4EBDD95AA5BD9AD4783D07FC703D7B8229BD873E47BDE099943D63D4373D8037B93C730D113E60DA0C3D4B121EBDDE0E5B3DE5649EBD29400B3D795B4B3D161FB93C8FF2513DB3CBA63C267D283D746AE03D57555FBD56BAF23C6AC7023D0ACB1CBEC92324BE53B2B5BDDADD4D3DB995DCBC9BDC053D61881BBEB67A02BDCE...\r\n  %cst_29 = \"std.constant\"() {value = dense<[9.67585132E-4, -9.76218085E-4, 8.44327267E-4, -9.95431095E-4, 9.78885102E-4, -9.89362248E-4, -9.97170456E-4, 9.94593254E-4, -9.74801718E-4, -9.967850e-04, -9.7882736E-4, -9.50525922E-4, 9.79408272E-4, -9.92655172E-4, 9.97303985E-4, 9.82631579E-4, 9.90360276E-4, -9.92504647E-4, -9.657435E-4, 4.47311701E-4, -9.95136913E-4, 9.76480427E-4, -9.81111777E-4, 9.97065915E-4, -9.86331375E-4, 9.94870206E-4, -9.89393214E-4, 9.676800e-04, -9.70026711E-4, -9.91622568E-4, 9.94842383E-4, -9.94916772E-4, 9.85594349E-4, 9.97806666E-4, -8.78486142E-4, -9.95528069E-4, 9.8985678E-4, -9.93425492E-4, 9.95124923E-4, 9.83530771E-4, 9.93813737E-4, 9.74371622E-4, 9.73470451E-4, -9.74504452E-4, -9.87119157E-4, -9.95987677E-4, -9.89082618E-4, 9.94357862E-4, -9.81126562E-4, -9.95713984E-4, 9.92701738E-4, -9.9737267E-4, -9.672870e-04, -7.41955242E-4, 9.90436179E-4, -8.20829126E-4, -9.95927955E-4, -9.940910e-04, 9.85695864E-4, 9.85741498E-4, 9.95741924E-4, -9.95478476E-4, 9.654010e-04, -9.80447861E-4]> : tensor<64xf32>} : () -> tensor<64xf32>\r\n  %cst_30 = \"std.constant\"() {value = dense<[0.999001801, 0.999005556, 9.990270e-01, 1.00099504, 0.999001979, 0.999002933, 0.999001145, 1.00095022, 0.999001979, 9.990040e-01, 0.999001502, 0.999003231, 1.00099468, 1.00091136, 1.00086093, 1.00098407, 0.999001622, 0.999009847, 0.999010264, 0.999002337, 1.00099421, 1.00099874, 1.00095701, 0.999001383, 0.999006628, 1.00099599, 0.999303638, 1.00099146, 0.999027907, 0.99900186, 1.00099814, 0.99900937, 1.0009948, 1.0009985, 0.999017238, 1.00099349, 1.00099826, 1.00098813, 1.000934, 1.00099516, 1.00097382, 1.00099266, 1.00099349, 1.00099623, 0.999081313, 0.999002218, 0.99900335, 0.999011158, 1.00099492, 1.00099647, 1.00099587, 0.999002039, 1.00099766, 1.00099695, 0.999008536, 0.999002814, 9.990050e-01, 0.99900335, 1.00099838, 1.00099766, 1.00099349, 1.00099289, 1.00097156, 1.00099587]> : tensor<64xf32>} : () -> tensor<64xf32>\r\n  %cst_31 = \"std.constant\"() {value = dense<[9.99597366E-4, -9.9919259E-4, 9.99345094E-4, -9.99698997E-4, 9.98205738E-4, -9.99698182E-4, -9.997270e-04, -9.99498763E-4, -9.98643808E-4, -9.96864866E-4, 9.99229145E-4, -9.99716343E-4, -9.98876639E-4, -9.98718547E-4, 9.98445553E-4, -9.99442767E-4, 9.99625306E-4, -9.8527607E-4, -9.95822483E-4, 9.97575931E-4, 9.998920e-04, 9.99492942E-4, 9.98938339E-4, 9.99762909E-4, 9.9961739E-4, -9.97697352E-4, -9.98864998E-4, -9.97156603E-4, 9.99353942E-4, 9.98489558E-4, 9.99433104E-4, 9.99394804E-4, -9.98000847E-4, -9.99715761E-4, -9.94169735E-4, -9.9937967E-4, -9.99294221E-4, 9.98356263E-4, 9.9906174E-4, -9.97644616E-4, 9.99090727E-4, 9.94966947E-4, 9.99400159E-4, 9.963630e-04, 9.97329829E-4, 9.99510521E-4, 9.99477691E-4, 9.99089912E-4, 9.99575247E-4, 9.99586307E-4, -9.99113777E-4, 9.99390496E-4, -9.97681403E-4, -9.83843114E-4, -9.97356371E-4, -9.98840085E-4, -9.99069889E-4, -9.98023431E-4, -9.98752773E-4, 9.9920528E-4, 9.99455805E-4, -9.99182928E-4, -9.99532174E-4, -9.97857307E-4]> : tensor<64xf32>} : () -> tensor<64xf32>\r\n  %cst_32 = \"std.constant\"() {value = dense<[9.81708988E-4, 9.63601749E-4, 9.90674947E-4, -5.41209592E-4, -9.96806542E-4, -9.83843347E-4, -9.94779984E-4, 9.9403772E-4, 9.31107497E-4, -9.93747846E-4, 9.95395239E-4, -9.97131573E-4, 9.82350902E-4, -9.86792613E-4, 9.92027809E-4, 9.9402538E-4, -9.92390792E-4, -9.95012698E-4, 9.74349154E-4, -9.90020693E-4, -9.8652183E-4, 9.94545291E-4, -9.17962461E-4, 9.61345387E-4, -9.95251466E-4, 9.94973583E-4, -9.72526962E-4, -8.81796877E-4, -9.74486291E-4, -9.71922826E-4, 9.95795126E-4, -9.96316666E-4, 9.90363652E-4, 9.97908413E-4, -9.92957735E-4, 9.958980e-04, -9.9491293E-4, -9.92778339E-4, 9.9361909E-4, 9.95804904E-4, -9.4126031E-4, 9.86351747E-4, -9.81890945E-4, -9.85238584E-4, -9.91161214E-4, 9.91085078E-4, 9.90797532E-4, 9.80959506E-4, -9.92152839E-4, -9.79809905E-4, -9.88770509E-4, -9.91929322E-4, 9.80777665E-4, 9.96440299E-4, 9.86681901E-4, -9.95011068E-4, -9.93575318E-4, -9.95142967E-4, -9.86838829E-4, 9.61801095E-4, 9.941320e-04, -9.97495604E-4, 9.76995914E-4, -9.35959106E-4]> : tensor<64xf32>} : () -> tensor<64xf32>\r\n  %cst_33 = \"std.constant\"() {value = dense<\"0x3CBBEA3B451EFC3C60A407BED262B2BD7C0C7A3CFF35FCBD7183ABBC10F0DEBD85B86F3BF859E8BD1E64D33D55CE933DDEAA983D9FEADB3CDA31EC3D3C21CABDCD54ACBDB8C4A53D1C5EE43D1F7C923C3235963B7944063DAB03AD3DEB26ADBD296D1FBD1F3076BD45E99E3CA6A8813D07F06FBD219E023ECF15E3BD65EF063EC05155BDCE53BE3D2376CEBD4699F9BD562A7DBD1212AD3D42EDC0BD5B01773C7A7302BE3B3154BCE519743DDAB986BDCE14F8BDAB8836BD28DB81BD3A817F3DE73DC73D70DBB6BDB0834C3D1304043EADAB303D7655613D43489B3D9D721B3CA09A64BDE792CEBD6595DABD8433703D64C8963D54EE823CA734DC3C2ABD923DFE0A9EBC5A62A33CA5A88C3DA94A37BD71A7D4BD6FDD993BDAB6B1BD0C41A0BD1AD223BD0896563D5B6883BDE674E7BD5F2828BD592626BDB648683D3EFB8D3DC9D5923C7A5A253D020280BD7AD50A3EA061933DEEE6EA3DA68980BDC1E8D73DED3E073DA01DD4BDD8A40EBCC040093DA770DBBD9FDFC6BD82B5B1BDB2CC863C1324FBBC1608A0BC5C5D623DEE427F3D76A0E1BC28ACC1BDEA90FB3C56958A3CCF4B9DBD9C0E75BDCEC400BE4A27B9BCD59D9ABDE0DE8D3DA88210BD4630073E8E5EE53DBA0D78BD9EDC6DBDEEF5393DB1E0013E2978033DAEDF66BDB14407BE71B99A3C54988A3BB329A2BD14870DBD3961FDBCF374FABD966B05BEF002BC3D12D97B3D10827FBCA725B8BD31450F3DF0AA3CBDE61ADE3B88D2083E1DF108BEA99499BDE546FA3D38DD04BE59D6CFBD38D4543D15C7E93B9679813D34A20C3ED939D5BD2CA7E23DF4F10BBE60166EBDDD6CDBBB6A0C33BDBC04F03D9EB6AE3D8B38CBBD8B162B3D45AC2D3DB9151B3DCBF58D3CD2030A3DCACEBE3D041E39BCD2ADD3BC429D92BD5957413DE843D23DF490C4BDB5507D3DCA2E3F3D2B4533BD60AEF03D983C61BD1A148BBDBBF7913D22773EBC47ADD7BCCE0D25BD1BC232BDEB76D2BCA2E7803C6D1319BD5C34B0BDEBDC88BDD3...\r\n  %cst_34 = \"std.constant\"() {value = dense<\"0x014B1ABDB51FB4BD77A132BD54BFD0BD4F596A3D1439DBBD4B39EB3C3275BB3D4E52EA3B0C8E09BE29C90A3EEE3700BD61CF76BD068808BEA24409BE589A66BD592285BB270BDFBA970207BE86B801BD95EEEBBDA06603BE7BC2BC3D6FE8373C88BF633DD3B03C3DCBECDBBC90F75FBD7C7E1FBD6475ED3D99DD51BD16F0DE3D8BA496BC0371E23D2845C8BD240BDDBD06C70ABECBAE9FBDC59E7EBC127B74BC6C35E2BD0E0204BE62115DBD8162903DFABBC5BDA22CD63C20D287BC54E58E3D915B523D34A8A83D10299DBD4D61D0BD87EAA53D446D613D4CBF5D3D494C573DB2AC4CBCE665B3BDC4D505BD3948DC3CB294F73C1FAF88BD7E9C193DFF06A23D0164063D49C43A3D8A2BF1BD0F5EC53B666907BEDF79373D55F1D3BD551C3A3D9D624CBD78BB9B3D5BEF8A3DCC4AEB3D37CEE73DA0F3D23D5AE4333D398D333C0306E5BD1FD7FD3DFFA9C7BD7039563DFD73EA3D71A1033E011503BEF3378C3DCD73AABDFF37833D52D096BD3D34BB3C54DEDE3D37F3AB3D70D93B3D8A3EFF3DF7C0C23D33575BBD7DEA00BEF8A9933CFE7813BD42A5E23D330B0EBD91A6A7BD3FCD3B3C2336323DCA5FE03D9F115CBB8C62D9BDCD34D73D86A4E1BD4678E03C053EBD3D567A7D3D19B108BDDBF6043E64208E3D4BA3C7BCC430D13D8135DFBDDD03D93B5F07EA3DB103853D8910963CA87AAEBDD58C9BBDF4FC123D6BEFB5BDC1039DBD8BF9EA3D9217E63DD208E7BDB178BB3D150883BBE2B1B2BD231692BD66571FBD09410BBD0CEAA33CA5D80F3CA0EB393CECF9713D7945B9BD2F86E1BDFED7D03DFB04FEBC0A5E623D19BE9C3D3691C8BCA05488BD0BF2003E26D94C3DA780E43D15E7BC3B012DD93D4E7904BE9B62C2BD3F70C5BD5D0883BB1125E63DA76D5F3D1357A13D7CA6DD3C5FA5043DE6124FBD253E18BD96AA56BD2862433D7415093E81CB583C25F1D03DE67913BDA296BCBDD8BDBB3DBCB286BD45C0873CD374D9BD1559DF3DADDD363DC94E09BD045B313D43...\r\n  %cst_35 = \"std.constant\"() {value = dense<\"0x5D257E3DBA77A83D1581D63D2E973EBDA2A94DBD964DF53DFAD025BC0FF4C2BDF04190BDEE3EF63DCDE432BD168D683D0505E33C1F296EBD1F04DA3D367BF53D7BEE3F3DF8E0BF3BFB4BB6BDE1A901BD3FCDA63DF6C21BBD835D033E90BFE6BC6636C1BDF1DCBD3DBEC6D2BDFDC6D7BD6505F63DC242293DCF3833BD3756FE3C1102E9BD9A23A73CBAFE8B3DAAC1343DE017543CFCE2F53DAB0EB5BC55BE903DCC7B2FBD4047863DF7851ABDD6108DBDD0583C3DE83617BC68409B3DC56C913DCE77F33D119805BE7DB4FDBDD7211D3C14E68ABD8DF580BB31F189BD20D4033D05A4613DEFD400BD18BA263D79EEE13D338CC6BD99A5A13DB00219BC5A25813DDDBA92BDCBC1BE3D163D5D3D9F0E063E21DF79BC2BBCBF3D41A565BD820EC5BC547700BE6C6605BED73D93BD37E4FB3D05D896BD950D6DBD41B33F3D27A1D0BD1EF30F3DD5E09C3D0616D2BB350F903D0362B03D79E6C8BD248981BD707E653DA0AB09BD46F375BDEE20AE3C68F05BBCD2BBA93D9667C9BD79C4C53DC05B043E54A6F1BABACF26BDEDB7773DC6F69EBD472836BC20C101BEFC594B3C4FE1AC3DBDC1833DE29B563D1AA472BDF7CEAEBDB245F63CBC9BF53D74252C3DDFB7CA3D386E97BD3149C43D4481193D520EF93D6017E4BD20CAE3BC8CCD6DBDB81BA43D50C8343C4685BABDDC66003DC0FB15BCF78402BEC98EFEBDA818EB3D3AF8C8BDE9182DBD94E9F63DE5FAC63B4B81B9BD5CA7063E3A8F44BC174B1CBD1438033D2E0D873DED16B6BD637A403DB264DE3D271984BD35E2C63CB16FB53D8CDD2B3D8266E3BDFAAA373C8026B8BD6F229DBDD2C31ABC72CA5E3DEA95363DAB6EDBBC6B5B2F3DCB6F95BDDDD8EA3C8901B73D28680A3E9759F13D3B6FEDBD1908573DCA1696BCA5391CBCD6D098BCB976ADBDB54E06BE8371E23D5151EBBD6732A8BDAE23A83DB32EB8BDAE81083E6E7050BCB540B3BC309A82BC6E119DBCC77870BC10F2E23D1B6E943D5AE878BD8AA005BE709BB7BD22...\r\n  %cst_36 = \"std.constant\"() {value = dense<\"0x995CD03CBBE0F2BC23A0B83D48070DBDF106813DE32A793D0519BEBDB63500BE784AF03D7D1305BEA39E16BD33ED57BDCA32003E1E046A3DED87D53DCB0B973C34B9E93DD9DEFCBCD0BE98BDC43B023E21A9913C4627BBBD7968C5BC1B3BFE3D0F0D8E3D9634BABD105803BE6B94E63D9E21053EBA02443DF1C36F3CFB839B3DF33E093E6068933C7EDFB0BD083287BDB414D1BD03AA97BDB145483DB00B033DE32F993B77EA6DBD1E9EA03D9C9203BE6C34C53DF5F68C3D322ECEBD15D28E3DB4F9ECBCD16A2A3D4E5010BD9ECD1CBDA52C87BCEDD8F83C012CD8BC0282903D597C61BD031D093E29D503BE3EDC463CC16181BC0DE1C93D945909BE259AA6BDE1E3093D17954C3D88372E3BDE8DD0BDDEE0993DDA9D11BDDB4B153D925C763D4EF890BDB87F5C3D949394BD9CB4C4BD423FACBD59E4C43D0794163C29518BBBAC9DF13D5B3A90BD03E6D9BA55EDCCBD505E51BD39AC9CBCC8FBF43DBD6F043E587DCEBC68F6D33C2F98E33DA63BEB3D5745273DD450AA3D27C306BEDCB2283B2AFDF2BCEDC7E23DC93CD13DC4366FBCC26EE3BBDCEEAA3D5C1BF63DCEA0083E90D650BD5DF6903DA98E813DDA45D7BD905F00BDE0FC01BD8CBCA5BD189D89BD4D14393DF7AE0DBC40F34DBC44231A3D3CE5BEBD251A8ABD842DB5BDB6417DBDB4CE51BC313E08BECE2BE9BCD31644BCC43D6D3DCACACF3D64C1B0BD88C0203D2413C3BD6F8C2F3CC92935BDBB6A89BC233F52BD143A79BCCA0B9A3D9A346DBC1D79AF3D7EB2053E89CD053E23EE00BEA38193BB9BF92D3C994AF4BC5AB848BD95C6E9BD29354DBD664080BD22B2863DE8B2F63D2A9D043EFADDF83DDCB348BD8C43073EF1A77F3D8F37743D7A43813D7D3294BD01EFDC3D66C6973D7DB3F7BD5F09A6BB1960183DE14360BD3C9DDB3CD948DE3B570B79BCC223E83DAE53643CDF1A883DE6B9D9BD7E3C2BBD90DF603DE8BEE6BA3C009C3D3EEC2FBD62B506BE8A230ABEFABE71BB7AC709BE312AE2BBD811A1BC24...\r\n  %cst_37 = \"std.constant\"() {value = dense<[[0.141972259, -0.140112832, -6.299400e-02, -0.188756421, -0.296468705, -0.193415761, -0.257958204, 0.138051048, -0.116950154, -0.166800201, 0.279425412, 0.252810538, 0.0246988367, 0.0818047821, 0.16655989, -0.172646925, -0.231393486, -6.86961692E-4, -0.0970985144, 0.223860174, -0.260656685, 0.19828698, -0.0498352349, 0.245914236, 0.0637414455, -0.111480176, -0.0401437283, 0.0500495099, -0.125676543, 0.205395907, 0.16058588, -0.00452343794, 0.0116028748, -0.248046264, 0.07183934, -0.224206865, -2.637570e-01, 0.066637516, -0.215825126, -0.0450223759, 0.197781667, 0.0415594503, 0.103903204, -0.0888473243, -0.0138380127, -0.186089963, 0.185404703, -0.167652592, 0.23974292, -0.218838304, 0.213134632, -0.162772402, 0.181808576, -0.103578761, -0.0596696399, 0.105313681, -0.101291053, 0.0236400794, -0.167137861, -0.129845485, 0.107204571, 0.193863332, 0.0873046442, -0.0449375287]]> : tensor<1x64xf32>} : () -> tensor<1x64xf32>\r\n  %cst_38 = \"std.constant\"() {value = dense<0.000000e+00> : tensor<128xf32>} : () -> tensor<128xf32>\r\n  %cst_39 = \"std.constant\"() {value = dense<\"0x11D42CBD71902DBBAF29743C2A2046BD3D29603DA16E253C59952F3D6711333DE78F003D62E7983C43FC32BD7CEF39BD549D323DAC6DD8BB8D966C3DA49C59BD4A37633DF48E6EBD97D7303DC92BF2BC4B556C3D1D015F3DE9623FBDBB26BE3CEB0D373BBE8CB0BCAF44B7BB10770DBC078021BD6DC820BC7EBF1B3DDAB0003DE611E83CB0176B3A1CF9793D5EFA2DBCDC6C83BC36485EBCA0DC6D3DC12CC53BB0F4203C50F4F8BCC6AA5C3D37C1D0BCFC9D80BB9184B5BC1907B23C816A64BD9C592B3D3F9597BCC49A1EBDC77677BDFDD033BDFEBD78BD1EB8563D10AB72BDC65A883C6F32B93C1FF4483D0B81D3BC21BE743D26379BBBF426C9BCD079413D963334BCC8A072BDB28DA0BC5C6E763C1411B83C646B203DCF8F0ABD8F68EABCE98177BDC03B13BDDED4433DE78B42BD693F3BBC4BB11EBDC14911BDFF5E623D1FA1E83C56BC34BC950A21BDECAD4E3C4B8D423D038441BD2536E0BCC4F1483D1123A03CD98765BD39D2BFBCDB07BA3C77554ABD922F8FBC175AEBBBBE6F613D8BB24A3D3B9B8D3CEC540DBD8A5519BD2A4AA1BCD0835ABDBA1A8D3CE5A677BD5AD34BBA6D350E3D45A85F3D9C85373D70C191BB7AF56E3DD60993BCF984E0BC0D0C96BCB27C2EBD5300A9BBD805433D63F0403D53013E3DC01A133C7FDC733DC71D283C8B9E7BBC9568753D2FA60C3D485BBC3C921A353DD35C0A3BD3C69C3C3857133D52ACCC3CDEEF3DBDB8D1A0BC0A854ABD7967ADBCEBA4303DA95E33BD8F4B853C1EDF0ABD697C3ABD24378A3CF3E05E3D139DA63CBD0B373D48F1E43C5CF140BCEF6804BD147B263D2E1BCFBB35A9023DA01444BDD5E0093D05B8713C58BA5D3D5A41BBBAF4B5E4BCB8ECEB3CBE0B61BDF3AC28BD863C813B958456BDD0ED2ABD6492113DA355663C8322F23CDB5079BD1D40953C210C483DB1B0BFBB3A137FBD3DBB6EBD7D2B8A3CFB42CFBB44F64DBDA1BC473D7099A1B932482BBD08A304BCC7C14D3DD09DD23CF9FC4CBD6440683DF9...\r\n  %cst_40 = \"std.constant\"() {value = dense<0> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %cst_41 = \"std.constant\"() {value = dense<1> : tensor<1xi32>} : () -> tensor<1xi32>\r\n  %0 = \"tfl.expand_dims\"(%arg0, %cst_1) : (tensor<?x1000x100xf32>, tensor<i32>) -> tensor<?x1x1000x100xf32>\r\n  %1 = \"tfl.conv_2d\"(%0, %cst_39, %cst_38) {dilation_h_factor = 1 : i32, dilation_w_factor = 1 : i32, fused_activation_function = \"NONE\", padding = \"VALID\", stride_h = 1 : i32, stride_w = 4 : i32} : (tensor<?x1x1000x100xf32>, tensor<128x1x7x100xf32>, tensor<128xf32>) -> tensor<?x1x249x128xf32>\r\n  %2 = \"tfl.squeeze\"(%1) {squeeze_dims = [-3]} : (tensor<?x1x249x128xf32>) -> tensor<?x249x128xf32>\r\n  %3 = \"tfl.add\"(%2, %cst_0) {fused_activation_function = \"NONE\"} : (tensor<?x249x128xf32>, tensor<128xf32>) -> tensor<?x249x128xf32>\r\n  %4 = \"tfl.mul\"(%3, %cst_7) {fused_activation_function = \"NONE\"} : (tensor<?x249x128xf32>, tensor<128xf32>) -> tensor<?x249x128xf32>\r\n  %5 = \"tfl.add\"(%4, %cst_8) {fused_activation_function = \"RELU\"} : (tensor<?x249x128xf32>, tensor<128xf32>) -> tensor<?x249x128xf32>\r\n  %6 = \"tfl.shape\"(%5) : (tensor<?x249x128xf32>) -> tensor<3xi32>\r\n  %7 = \"tfl.strided_slice\"(%6, %cst_40, %cst_41, %cst_41) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<3xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %8 = \"tfl.pack\"(%7, %cst_3) {axis = 0 : i32, values_count = 2 : i32} : (tensor<i32>, tensor<i32>) -> tensor<2xi32>\r\n  %9 = \"tfl.fill\"(%8, %cst_2) : (tensor<2xi32>, tensor<f32>) -> tensor<?x64xf32>\r\n  %10 = \"tfl.unidirectional_sequence_lstm\"(%5, %cst_19, %cst_20, %cst_21, %cst_22, %cst_11, %cst_12, %cst_13, %cst_14, %cst_6, %cst_6, %cst_6, %cst_15, %cst_16, %cst_17, %cst_18, %cst_6, %cst_6, %9, %9, %cst_6, %cst_6, %cst_6, %cst_6) {cell_clip = 1.000000e+01 : f32, fused_activation_function = \"TANH\", proj_clip = 0.000000e+00 : f32, time_major = false} : (tensor<?x249x128xf32>, tensor<64x128xf32>, tensor<64x128xf32>, tensor<64x128xf32>, tensor<64x128xf32>, tensor<64x64xf32>, tensor<64x64xf32>, tensor<64x64xf32>, tensor<64x64xf32>, none, none, none, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, none, none, tensor<?x64xf32>, tensor<?x64xf32>, none, none, none, none) -> tensor<?x249x64xf32>\r\n  %11 = \"tfl.mul\"(%10, %cst_9) {fused_activation_function = \"NONE\"} : (tensor<?x249x64xf32>, tensor<64xf32>) -> tensor<?x249x64xf32>\r\n  %12 = \"tfl.add\"(%11, %cst_10) {fused_activation_function = \"NONE\"} : (tensor<?x249x64xf32>, tensor<64xf32>) -> tensor<?x249x64xf32>\r\n  %13 = \"tfl.cast\"(%12) : (tensor<?x249x64xf32>) -> tensor<?x?x64xf32>\r\n  %14 = \"tfl.shape\"(%12) : (tensor<?x249x64xf32>) -> tensor<3xi32>\r\n  %15 = \"tfl.strided_slice\"(%14, %cst_40, %cst_41, %cst_41) {begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, shrink_axis_mask = 1 : i32} : (tensor<3xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\r\n  %16 = \"tfl.pack\"(%15, %cst_3) {axis = 0 : i32, values_count = 2 : i32} : (tensor<i32>, tensor<i32>) -> tensor<2xi32>\r\n  %17 = \"tfl.fill\"(%16, %cst_2) : (tensor<2xi32>, tensor<f32>) -> tensor<?x64xf32>\r\n  %18 = \"tfl.unidirectional_sequence_lstm\"(%13, %cst_33, %cst_34, %cst_35, %cst_36, %cst_25, %cst_26, %cst_27, %cst_28, %cst_6, %cst_6, %cst_6, %cst_29, %cst_30, %cst_31, %cst_32, %cst_6, %cst_6, %17, %17, %cst_6, %cst_6, %cst_6, %cst_6) {cell_clip = 1.000000e+01 : f32, fused_activation_function = \"TANH\", proj_clip = 0.000000e+00 : f32, time_major = false} : (tensor<?x?x64xf32>, tensor<64x64xf32>, tensor<64x64xf32>, tensor<64x64xf32>, tensor<64x64xf32>, tensor<64x64xf32>, tensor<64x64xf32>, tensor<64x64xf32>, tensor<64x64xf32>, none, none, none, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, tensor<64xf32>, none, none, tensor<?x64xf32>, tensor<?x64xf32>, none, none, none, none) -> tensor<?x?x64xf32>\r\n  %19 = \"tfl.mul\"(%18, %cst_23) {fused_activation_function = \"NONE\"} : (tensor<?x?x64xf32>, tensor<64xf32>) -> tensor<?x?x64xf32>\r\n  %20 = \"tfl.add\"(%19, %cst_24) {fused_activation_function = \"NONE\"} : (tensor<?x?x64xf32>, tensor<64xf32>) -> tensor<?x?x64xf32>\r\n  %21 = \"tfl.reshape\"(%20, %cst_4) : (tensor<?x?x64xf32>, tensor<2xi32>) -> tensor<?x64xf32>\r\n  %22 = \"tfl.fully_connected\"(%21, %cst_37, %cst) {fused_activation_function = \"NONE\", keep_num_dims = false, weights_format = \"DEFAULT\"} : (tensor<?x64xf32>, tensor<1x64xf32>, tensor<1xf32>) -> tensor<?x1xf32>\r\n  %23 = \"tfl.logistic\"(%22) : (tensor<?x1xf32>) -> tensor<?x1xf32>\r\n  %24 = \"tfl.reshape\"(%23, %cst_5) : (tensor<?x1xf32>, tensor<3xi32>) -> tensor<?x249x1xf32>\r\n  \"std.return\"(%24) : (tensor<?x249x1xf32>) -> ()\r\n}) {arg0 = {tf_saved_model.index_path = [\"input_8\"]}, result0 = {tf_saved_model.index_path = [\"time_distributed_4\"]}, sym_name = \"serving_default\", tf.entry_function = {control_outputs = \"\", inputs = \"serving_default_input_8:0\", outputs = \"StatefulPartitionedCall:0\"}, tf_saved_model.exported_names = [\"serving_default\"], type = (tensor<?x1000x100xf32>) -> tensor<?x249x1xf32>} : () -> ()\r\n\r\n\r\n\r\n```\r\n\r\n", "comments": ["@AakashKumarNain,\r\nI was able to reproduce the issue with [TF v2.3](https://colab.research.google.com/gist/amahendrakar/ad349af3e5bf8ce6034a6f72b05bb20a/43649.ipynb). However, the issue seems to be fixed with the latest [TF-nightly](https://colab.research.google.com/gist/amahendrakar/a65cbd9a4e81d06dc0189540d510a6d6/43649-tf-nightly.ipynb). I was able to run the code without any errors. Please find the attached gist. Thanks!", "Thanks @amahendrakar . Is it possible to convert a model trained in `2.3` with `nightly` version?", "@AakashKumarNain Yes, you can bring old TF models to the recent TF version for TFLite conversion. However, for inference, you need to match your TF version with the same TF version, which is used for conversion.", "Thanks @abattery for the info.", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43649\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43649\">No</a>\n"]}, {"number": 43647, "title": "In case hdfsBuilderConnect returns nullptr", "body": "In case [hdfsBuilderConnect returns nullptr](https://github.com/apache/hadoop/blob/release-3.3.0-RC0/hadoop-hdfs-project/hadoop-hdfs-native-client/src/main/native/libhdfs/include/hdfs/hdfs.h#L261)\r\n\r\n```c\r\n    /** \r\n     * Connect to HDFS using the parameters defined by the builder.\r\n     *\r\n     * The HDFS builder will be freed, whether or not the connection was\r\n     * successful.\r\n     *\r\n     * Every successful call to hdfsBuilderConnect should be matched with a call\r\n     * to hdfsDisconnect, when the hdfsFS is no longer needed.\r\n     *\r\n     * @param bld    The HDFS builder\r\n     * @return       Returns a handle to the filesystem, or NULL on error.\r\n     */\r\n     LIBHDFS_EXTERNAL\r\n     hdfsFS hdfsBuilderConnect(struct hdfsBuilder *bld);\r\n```", "comments": ["cc @jhseu @mihaimaruseac @vnvo2409", "> https://github.com/tensorflow/tensorflow/pull/43188#issuecomment-701466229\r\n\r\n@byronyi \r\nCan you help me review the PR, Thanks!"]}, {"number": 43646, "title": "CMake issues when building TFLite", "body": "**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Ubuntu 18.04.5 LTS\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: 8a643858ce174b8b (master)\r\n- Bazel version (if compiling from source): CMake 3.18.2\r\n- GCC/Compiler version (if compiling from source): GCC 7.5.0 / LLVM 6.0\r\n\r\n\r\n\r\n\r\n**Describe the problem**\r\n\r\nI'm seeing various issues whilst trying to build `libtensorflow-lite.a`. I have a fix for the first but not sure what the remedy is for the others.\r\n\r\n1] Missing dependency on `sparsity` required by `lite/kernels/density.cc` and `lite/kernels/fully_connected.cc`\r\n\r\nThis fixes\r\n\r\n```\r\ndiff --git a/tensorflow/lite/CMakeLists.txt b/tensorflow/lite/CMakeLists.txt\r\nindex ac7e373f18..b731401fc1 100644\r\n--- a/tensorflow/lite/CMakeLists.txt\r\n+++ b/tensorflow/lite/CMakeLists.txt\r\n@@ -264,6 +264,10 @@ populate_tflite_source_vars(\"kernels/internal/reference/integer_ops\"\r\n populate_tflite_source_vars(\"kernels/internal/reference/sparse_ops\"\r\n   TFLITE_KERNEL_INTERNAL_REF_SPARSE_OPS_SRCS\r\n )\r\n+populate_tflite_source_vars(\"tools/optimize/sparsity\"\r\n+  TFLITE_TOOLS_OPTIMIZE_SPARSITY_SRCS\r\n+)\r\n+\r\n \r\n # Common include directories\r\n include_directories(\r\n@@ -294,6 +298,7 @@ add_library(tensorflow-lite\r\n   ${TFLITE_KERNEL_SRCS}\r\n   ${TFLITE_NNAPI_SRCS}\r\n   ${TFLITE_SRCS}\r\n+  ${TFLITE_TOOLS_OPTIMIZE_SPARSITY_SRCS}\r\n )\r\n target_link_libraries(tensorflow-lite\r\n   PUBLIC\r\n\r\n```\r\n\r\n2] The built library `libtensorflow-lite.a` doesn't itself include all the dependencies it needs as build in `[build dir]/_deps`\r\n\r\n\r\n3] Enabling `TFLITE_ENABLE_XNNPACK` gives the following error when built with GCC (build's OK with LLVM)\r\n\r\n```\r\n/home/gavin/CK-TOOLS/lib-tflite-src-static-gcc-7.5.0-v2.3.91-with.xnnpack-linux-64/build/xnnpack/src/f16-clamp/gen/neonfp16arith-x16.c: In function \u2018xnn_f16_clamp_ukernel__neonfp16arith_x16\u2019:\r\n/home/gavin/CK-TOOLS/lib-tflite-src-static-gcc-7.5.0-v2.3.91-with.xnnpack-linux-64/build/xnnpack/src/f16-clamp/gen/neonfp16arith-x16.c:32:44: warning: passing argument 1 of \u2018vld1q_dup_f16\u2019 from incompatible pointer type [-Wincompatible-pointer-types]\r\n   const float16x8_t vy_min = vld1q_dup_f16(&params->min);\r\n                                            ^\r\nIn file included from /home/gavin/CK-TOOLS/lib-tflite-src-static-gcc-7.5.0-v2.3.91-with.xnnpack-linux-64/build/xnnpack/src/f16-clamp/gen/neonfp16arith-x16.c:12:0:\r\n/usr/lib/gcc/aarch64-linux-gnu/7/include/arm_neon.h:17359:1: note: expected \u2018const float16_t * {aka const __fp16 *}\u2019 but argument is of type \u2018const uint16_t * {aka const short unsigned int *}\u2019\r\n vld1q_dup_f16 (const float16_t* __a)\r\n ^~~~~~~~~~~~~\r\n```\r\n\r\n\r\n4] Building `TFLITE_ENABLE_XNNPACK` with LLVM looks like it builds all the right things but doesn't affect performance.\r\n\r\n", "comments": ["Did you get a chance to refer [Build TensorFlow Lite with CMake](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/tools/cmake#build-tensorflow-lite-with-cmake) guide?", "Hi @ymodak, yes as per the instructions. Bit tricky to read, but it's wrapped up in this script -\r\n\r\nhttps://github.com/ctuning/ck-tensorflow/blob/master/package/lib-tflite-cmake/scripts.linux/install.sh\r\n\r\n", "Could you make a PR on 1 & 2?\r\nRegarding 4, you need to enable xxnpack delegate to get the performance improvement.\r\nhttps://blog.tensorflow.org/2020/07/accelerating-tensorflow-lite-xnnpack-integration.html", "CMake build should be fine now.\r\n\r\nhttps://www.tensorflow.org/lite/guide/build_cmake\r\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43646\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43646\">No</a>\n"]}, {"number": 43645, "title": "Keras EarlyStopping callback on val_auc running mysteriously", "body": "**System information**\r\n- OS : Windows 10\r\n- Python version : 3.6.5\r\n- Tensorflow : 2.3.0\r\n### Simple DL GridsearchCV modelling using Keras\r\n\r\n```\r\nepochs = [1, 6, 11, 16, 21, 26, 31, 36, 41, 46]\r\nbatch_size = [2,4]\r\n\r\n stopper = EarlyStopping(monitor='val_auc', patience= 10, mode = 'max', min_delta = 1, restore_best_weights=True)\r\n save_mod = ModelCheckpoint(r'C:\\......................\\best_model.h5', monitor='val_acc', mode='max', save_best_only=True, save_freq \r\n = 'epoch')\r\n\r\n param_grid = dict(epochs = epochs, batch_size = batch_size)\r\n\r\n def create_classify_model(learn_rate = 0.01, momentum = 0):\r\n            # create model\r\n            network = Sequential()\r\n            #input layer and 1st hidden layer\r\n            network.add(Dense(units = data_seg.x_tr.shape[1], activation=\"relu\", input_shape = \r\n            (data_seg.x_tr.shape[1],)))\r\n\r\n            #dropout layer for input layer\r\n            network.add(Dropout(0.2, input_shape = (data_seg.x_tr.shape[1],)))\r\n\r\n            #second hidden layer\r\n            network.add(Dense(units = math.trunc(data_seg.x_tr.shape[1]*0.8), activation = \"relu\"))\r\n\r\n            #dropout layer for hidden layer\r\n            network.add(Dropout(0.5))\r\n\r\n            #output layer\r\n            network.add(Dense(units = len(np.unique(data_seg.y_tr)), activation = \"softmax\"))\r\n\r\n            optimizer = SGD(lr=learn_rate, momentum=momentum)\r\n\r\n            #compiling neural network\r\n            network.compile(loss = \"categorical_crossentropy\", optimizer = optimizer, metrics = \r\n['acc',auc_metric()])\r\n\r\n            return network\r\n\r\nneural_network = KerasClassifier(build_fn=create_classify_model, workers = -1, use_multiprocessing = \r\nTrue, verbose=2)\r\ngrid = GridSearchCV(estimator=neural_network, param_grid=param_grid)\r\n\r\nfit_params = dict(callbacks=[stopper, save_mod], validation_split = 0.05)\r\n\r\ngrid_model = grid.fit(data_seg.x_tr, data_seg.y_tr, **fit_params)\r\n```\r\n\r\n### Output\r\n`471/471 - 1s - loss: 0.7568 - acc: 0.6019 - auc: 0.6357 - val_loss: 0.4909 - val_acc: 0.7600 - \r\nval_auc: 0.8676\r\n125/125 - 0s - loss: 0.5264 - acc: 0.7751 - auc: 0.8459\r\nWARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available \r\nmetrics are: loss,acc,auc_1,val_loss,val_acc,val_auc_1\r\n472/472 - 1s - loss: 0.7242 - acc: 0.6288 - auc_1: 0.6494 - val_loss: 0.5680 - val_acc: 0.7000 - \r\nval_auc_1: 0.7896\r\n124/124 - 0s - loss: 0.6316 - acc: 0.6250 - auc_1: 0.6942\r\nWARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available \r\nmetrics are: loss,acc,auc_2,val_loss,val_acc,val_auc_2\r\n472/472 - 1s - loss: 0.7193 - acc: 0.6182 - auc_2: 0.6563 - val_loss: 0.5279 - val_acc: 0.7400 - \r\nval_auc_2: 0.8544\r\n124/124 - 0s - loss: 0.5929 - acc: 0.7863 - auc_2: 0.7995\r\nWARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available \r\nmetrics are: loss,acc,auc_3,val_loss,val_acc,val_auc_3\r\n472/472 - 1s - loss: 0.7060 - acc: 0.6299 - auc_3: 0.6649 - val_loss: 0.5369 - val_acc: 0.8000 - \r\nval_auc_3: 0.8400\r\n124/124 - 0s - loss: 0.5564 - acc: 0.7661 - auc_3: 0.8305\r\nWARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available \r\nmetrics are: loss,acc,auc_4,val_loss,val_acc,val_auc_4\r\n472/472 - 1s - loss: 0.7258 - acc: 0.6161 - auc_4: 0.6398 - val_loss: 0.5676 - val_acc: 0.7400 - \r\nval_auc_4: 0.7936`\r\n\r\nThe ouput here, showcases that the val_auc metric which has been used to monitor EarlyStopping has been given an integer value, which increases with every epoch end I suppose. Hence, can someone help me understand about how can I monitor the val_auc in this case ?\r\n", "comments": ["@innovativeC,\r\nOn running the given code, I am facing an error stating `NameError: name 'data_seg' is not defined`. \r\n\r\nIn order to expedite the trouble-shooting process, could you please provide the complete code to reproduce the issue reported here and also the dataset you are using. Thanks!", "@amahendrakar , data_seg.x_tr and data_seg.y_tr are actually the X and Y_true datasets used here. You can insert any classification dataset here, the result I am getting is constant across any classifcation dataset I have used whenever I've utilized auc as stopping metric.\r\n\r\nPS - Can't share the complete code, since its proprietary. That being said, only preprocessing of the dataset was done prior to the code shared above..", "@innovativeC,\r\nIn this case, could you please share a dummy dataset with similar shape and size, so that we can reproduce the issue on our end. Thanks!", "@amahendrakar, Sure I am sharing the URL of the dataset I used, [https://www.kaggle.com/vetrirah/av-healthcare2?select=train.csv](url). The data_seg.x_tr and data_seg.y_tr here would be the X and Y sets.", "@innovativeC,\r\nI am still facing the same error. The dataset you have provided does not seem to have X and Y sets. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/ab52c7d029f2d9531faad4a96a90b557/43645.ipynb#scrollTo=IIaoaolomr55). \r\n\r\nCould you please provide a minimal working code sample, which we can use to reproduce the issue on our end? Thanks!", "@amahendrakar  This is the link to the dataset [https://drive.google.com/file/d/18ZOZ_tiRAXZGCdqaFzHyHYA0J44qytx-/view?usp=sharing](url). Also I have made some changes to the collab notebook which you had shared. You can find it here - [https://colab.research.google.com/gist/innovativeC/7f9df6ab55653628074a3d898cf044c6/43645.ipynb](url)", "Was able to reproduce the issue with TF v2.3 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/835ee579feee64a865689e2764960d07/43645.ipynb). Thanks!", "@amahendrakar @ymodak Any insights on why this is happening ? Thanks!", "Hi guys, any update on this bug ?", "Just encountered the same problem when tuning keras model with nni. I observed that the `val_auc[_number]` comes from creating the same model multiple times in one script. The first time we create the model, `val_auc` has no suffix. And each time after the first creation, `val_auc` becomes `val_auc_1`, `val_auc_2`, and so on.\r\n", "Same issue.  Here is a MWE\r\n\r\n```\r\nimport numpy as np\r\nfrom tensorflow.keras.layers import Input, Dense\r\nfrom tensorflow.keras.models import Model\r\nimport tensorflow as tf\r\n\r\ndef make_and_fit():\r\n    inp = Input(shape=(1,))\r\n    out = Dense(1, activation='sigmoid')(inp)\r\n    model = Model(inputs=inp, outputs=out)\r\n    auc = tf.keras.metrics.AUC()\r\n    model.compile(loss='binary_crossentropy',\r\n                  metrics=[auc])\r\n    x = np.random.normal(size=10)\r\n    y = np.random.normal(size=10) > 0\r\n    xv = np.random.normal(size=10)\r\n    yv = np.random.normal(size=10) > 0\r\n    earlystopping = tf.keras.callbacks.EarlyStopping(monitor='val_auc',\r\n                                                     patience=2)\r\n    model.fit(x=x,\r\n              y=y,\r\n              validation_data=(xv, yv),\r\n              epochs=2,\r\n              verbose=1,\r\n              callbacks=earlystopping)\r\n\r\nfor i in range(2):\r\n    make_and_fit()\r\n```\r\n\r\nwhich yields\r\n```\r\nEpoch 1/2\r\n1/1 [==============================] - 1s 641ms/step - loss: 0.8790 - auc: 0.3750 - val_loss: 0.8296 - val_auc: 0.3600\r\nEpoch 2/2\r\n1/1 [==============================] - 0s 14ms/step - loss: 0.8779 - auc: 0.3750 - val_loss: 0.8291 - val_auc: 0.3600\r\nEpoch 1/2\r\n1/1 [==============================] - 1s 519ms/step - loss: 0.9755 - auc_1: 0.3810 - val_loss: 0.6031 - val_auc_1: 0.7600\r\nWARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,auc_1,val_loss,val_auc_1\r\nEpoch 2/2\r\n1/1 [==============================] - 0s 14ms/step - loss: 0.9736 - auc_1: 0.3810 - val_loss: 0.6030 - val_auc_1: 0.7600\r\nWARNING:tensorflow:Early stopping conditioned on metric `val_auc` which is not available. Available metrics are: loss,auc_1,val_loss,val_auc_1\r\n```", "@innovativeC Is this still an issue for you? Can you please test with recent `TF2.7` and `tf-nightly`?\r\n\r\n@cranedroesch i tested your code by adding [`clear_session`](https://www.tensorflow.org/api_docs/python/tf/keras/backend/clear_session)  as shown below. As Keras tracks its inputs/outputs, i think we cannot use same metric name if they are in memory. Clearing them from memory, results in better memory management also as listed [here](https://www.tensorflow.org/api_docs/python/tf/keras/backend/clear_session). [Here](https://colab.research.google.com/gist/jvishnuvardhan/a5872527ecd168a65bd47c33fa9f5713/untitled1115.ipynb) is gist for reference. Thanks!\r\n\r\n\r\n```\r\nfor i in range(2):\r\n  tf.keras.backend.clear_session()\r\n  make_and_fit()\r\n```", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43645\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43645\">No</a>\n"]}, {"number": 43644, "title": "TRTEngineOp is not used", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):No\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):Ubuntu18.04\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):pip3 install tensorflow-gpu =1.13.1\r\n- TensorFlow version (use command below):b'v1.13.1-0-g6612da8951' 1.13.1\r\n- Python version:Python 3.6.9\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version: Cuda10.0.130-1 cudnn:7.6.0.64-1+cuda10.0\r\n- GPU model and memory: GeForce GTX 1080 Ti 11G\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**  \r\n[This is the place to do it.](https://github.com/tensorflow/models/tree/master/research/object_detection)\r\n\r\nTRTEngineOp is not used.\r\nI performed the TF-TRT conversion of [ssd_inception_v2_coco](http://download.tensorflow.org/models/object_detection/ssd_inception_v2_coco_2018_01_28.tar.gz) with the following code.(convert_trt_minimum.py)\r\n```\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\r\n  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\r\n/usr/lib/python3/dist-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.25.9) or chardet (3.0.4) doesn't match a supported version!\r\n  RequestsDependencyWarning)\r\nWARNING:tensorflow:From convert_trt_minimum.py:7: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nUse tf.gfile.GFile.\r\nWARNING:tensorflow:TensorRT mismatch. Compiled against version 5.0.2, but loaded 5.1.5. Things may not work\r\n2020-09-29 17:19:48.474780: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-09-29 17:19:48.525360: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2020-09-29 17:19:48.525702: I tensorflow/core/grappler/devices.cc:51] Number of eligible GPUs (core count >= 8): 2\r\n2020-09-29 17:19:48.525790: I tensorflow/core/grappler/clusters/single_machine.cc:359] Starting new session\r\n2020-09-29 17:19:48.526009: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\r\n2020-09-29 17:19:48.530274: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x1fdeb10 executing computations on platform CUDA. Devices:\r\n2020-09-29 17:19:48.530286: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1\r\n2020-09-29 17:19:48.530290: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (1): GeForce GTX 1080 Ti, Compute Capability 6.1\r\n2020-09-29 17:19:48.550032: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3696000000 Hz\r\n2020-09-29 17:19:48.551389: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x1fddee0 executing computations on platform Host. Devices:\r\n2020-09-29 17:19:48.551438: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>\r\n2020-09-29 17:19:48.551788: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 0 with properties: \r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 10.91GiB freeMemory: 9.67GiB\r\n2020-09-29 17:19:48.551877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1433] Found device 1 with properties: \r\nname: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582\r\npciBusID: 0000:02:00.0\r\ntotalMemory: 10.92GiB freeMemory: 10.77GiB\r\n2020-09-29 17:19:48.554355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1512] Adding visible gpu devices: 0, 1\r\n2020-09-29 17:19:49.861234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] Device interconnect StreamExecutor with strength 1 edge matrix:\r\n2020-09-29 17:19:49.861263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:990]      0 1 \r\n2020-09-29 17:19:49.861268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 0:   N Y \r\n2020-09-29 17:19:49.861271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1003] 1:   Y N \r\n2020-09-29 17:19:49.861383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 9370 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)\r\n2020-09-29 17:19:49.861825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 10441 MB memory) -> physical GPU (device: 1, name: GeForce GTX 1080 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1)\r\n2020-09-29 17:19:51.064635: I tensorflow/contrib/tensorrt/segment/segment.cc:443] There are 3957 ops of 51 different types in the graph that are not converted to TensorRT: TopKV2, NonMaxSuppressionV2, TensorArrayWriteV3, Const, Squeeze, ResizeBilinear, Maximum, Where, Switch, TensorArrayGatherV3, TensorArrayV3, LoopCond, NoOp, TensorArrayScatterV3, Placeholder, Add, ExpandDims, Exit, Cast, Identity, Shape, StridedSlice, Less, TensorArraySizeV3, RealDiv, TensorArrayReadV3, Reshape, Merge, Enter, Range, Conv2D, NextIteration, Greater, Split, ZerosLike, Pack, Mul, Equal, Sub, Minimum, Tile, ConcatV2, Size, Unpack, Assert, DataFormatVecPermute, Transpose, Gather, Exp, Slice, Fill, (For more information see https://docs.nvidia.com/deeplearning/dgx/integrate-tf-trt/index.html#support-ops).\r\n2020-09-29 17:19:51.088668: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:913] Number of TensorRT candidate segments: 4\r\n2020-09-29 17:19:51.117406: W tensorflow/contrib/tensorrt/convert/convert_nodes.cc:3710] Validation failed for TensorRTInputPH_0 and input slot 0: Input tensor with shape [?,?,?,3] has an unknown non-batch dimension at dim 1\r\n2020-09-29 17:19:51.117436: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:1021] TensorRT node TRTEngineOp_0 added for segment 0 consisting of 476 nodes failed: Invalid argument: Validation failed for TensorRTInputPH_0 and input slot 0: Input tensor with shape [?,?,?,3] has an unknown non-batch dimension at dim 1. Fallback to TF...\r\n2020-09-29 17:19:51.117587: W tensorflow/contrib/tensorrt/convert/convert_nodes.cc:3710] Validation failed for TensorRTInputPH_0 and input slot 0: Input tensor with shape [?,546,?,?] has an unknown non-batch dimension at dim 2\r\n2020-09-29 17:19:51.117598: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:1021] TensorRT node TRTEngineOp_1 added for segment 1 consisting of 3 nodes failed: Invalid argument: Validation failed for TensorRTInputPH_0 and input slot 0: Input tensor with shape [?,546,?,?] has an unknown non-batch dimension at dim 2. Fallback to TF...\r\n2020-09-29 17:19:51.135200: W tensorflow/contrib/tensorrt/log/trt_logger.cc:34] DefaultLogger Half2 support requested on hardware without native FP16 support, performance will be negatively affected.\r\n2020-09-29 17:19:52.748882: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:1015] TensorRT node TRTEngineOp_2 added for segment 2 consisting of 3 nodes succeeded.\r\n2020-09-29 17:19:52.749750: W tensorflow/contrib/tensorrt/log/trt_logger.cc:34] DefaultLogger Half2 support requested on hardware without native FP16 support, performance will be negatively affected.\r\n2020-09-29 17:19:52.864456: I tensorflow/contrib/tensorrt/convert/convert_graph.cc:1015] TensorRT node TRTEngineOp_3 added for segment 3 consisting of 4 nodes succeeded.\r\n2020-09-29 17:19:52.940261: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:581] Optimization results for grappler item: tf_graph\r\n2020-09-29 17:19:52.940287: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   constant folding: Graph size after: 6180 nodes (1), 10272 edges (2), time = 392.139ms.\r\n2020-09-29 17:19:52.940292: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   layout: Graph size after: 6211 nodes (31), 10304 edges (32), time = 116.429ms.\r\n2020-09-29 17:19:52.940295: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   constant folding: Graph size after: 6201 nodes (-10), 10304 edges (0), time = 302.23ms.\r\n2020-09-29 17:19:52.940298: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:583]   TensorRTOptimizer: Graph size after: 6196 nodes (-5), 10299 edges (-5), time = 2023.22498ms.\r\n\r\n```\r\nI then ran the inference through sample_detection.py.\r\n![trtbug](https://user-images.githubusercontent.com/19382501/94534788-c7211880-027b-11eb-8d9c-5001e9f70a20.png)\r\nTRTEngineOp is there, but it is not used for inference.\r\nThe defined TRTEngineOp should be used for inference.\r\n\r\n\r\n**Standalone code to reproduce the issue**\r\n[codes.zip](https://github.com/tensorflow/tensorflow/files/5297462/codes.zip)\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["@ikyasam18 \r\nAs you have mentioned you are using tf version 1.13 which is very old version and there is no support for tf 1.x versions can you please upgrade to 2.x versions and let us know if this is still an issue.Thanks!", "Perhaps you should try to fix warning logs `WARNING:tensorflow:TensorRT mismatch. Compiled against version 5.0.2, but loaded 5.1.5. Things may not work`\r\nSee https://github.com/tensorflow/models/issues/7025#issuecomment-507056242", "@ikyasam18 \r\nPlease refer to [this comment](https://github.com/tensorflow/tensorflow/issues/31039#issuecomment-555755934) of similar issue and let us know if it helps.\r\nSimilar error issues:\r\n[link](https://github.com/tensorflow/models/issues/5061), [link1](https://github.com/tensorflow/models/issues/7025#issuecomment-509295178),[link1](https://forums.developer.nvidia.com/t/warningtensorrt-mismatch/76487/4)", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43644\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43644\">No</a>\n"]}, {"number": 43643, "title": "how to save a model with weights and paramters ", "body": "when i create a model and compiled it and call the model.fit() and then i saved the model called model.save(path)\r\nthen i tried to load my saved module and i get the model correctly but  it cannot load the ckpt files so the evaluate result showed accuracy is around 10%,  i mean, how can i load module without training it again?", "comments": ["@aLLLiyyy \r\n\r\nPlease, go through this [tutorial ](https://www.tensorflow.org/tutorials/keras/save_and_load?hl=en)and see if it helps you.Thanks!", "You need to load the weights from the checkpoint and re-evaluate.\r\nHow are you saving the checkpoints?\r\nIf using [`tf.keras.callbacks.ModelCheckpoint`](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/ModelCheckpoint) api you can use `model.load_weights` method\r\n\r\n```python\r\n# Loads the weights\r\nmodel.load_weights(checkpoint_path)\r\n\r\n# Re-evaluate the model\r\nloss,acc = model.evaluate(test_images,  test_labels, verbose=2)\r\nprint(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))\r\n```", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@ymodak thanks for your reply,but i think you missread what i mean\uff0ci already saved the checkpoint as you said using the ModelCheckpoint api ,but i still need to create that model explicitly,do you know a method that i can save the full model and weights directly as a frozen pb file, the i can load that model without load_weight and can predict normally as i just trained before. then what should i do?thank you!", "This [article](https://leimao.github.io/blog/Save-Load-Inference-From-TF2-Frozen-Graph/) can be a good starting point to convert your model into `.pb` format.", "i d like to read it soon, ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 43642, "title": "doc issue", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/MyMethod\r\n\r\n## Description of issue (what needs changing):\r\n\r\n### Clear description\r\n\r\nFor example, why should someone use this method? How is it useful?\r\n\r\n### Correct links\r\n\r\nIs the link to the source code correct?\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? For example,\r\nhttps://www.tensorflow.org/versions/r2.0/api_docs/python/tf/feature_column/categorical_column_with_vocabulary_file#raises\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? See the docs\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs,\r\ndocs API guide: https://www.tensorflow.org/community/contribute/docs_ref and the\r\ndocs style guide: https://www.tensorflow.org/community/contribute/docs_style\r\n", "comments": []}, {"number": 43641, "title": "scatter_nd documentation is wrong", "body": "Thank you for submitting a TensorFlow documentation issue. Per our GitHub\r\npolicy, we only address code/doc bugs, performance issues, feature requests, and\r\nbuild/installation issues on GitHub.\r\n\r\nThe TensorFlow docs are open source! To get involved, read the documentation\r\ncontributor guide: https://www.tensorflow.org/community/contribute/docs\r\n\r\n## URL(s) with the issue:\r\n\r\nPlease provide a link to the documentation entry, for example:\r\nhttps://www.tensorflow.org/api_docs/python/tf/scatter_nd\r\n\r\n## Description of issue (what needs changing):\r\nThe output for the second example is wrong. The documentation has this:\r\n[[[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],\r\n\r\n [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]],\r\n\r\n [[5, 5, 5, 5], [6, 6, 6, 6], [7, 7, 7, 7], [8, 8, 8, 8]],\r\n\r\n [[0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0], [0, 0, 0, 0]]]\r\n\r\nWhen I ran this test code in Colab, I get this output:\r\n[[[5 5 5 5]\r\n  [6 6 6 6]\r\n  [7 7 7 7]\r\n  [8 8 8 8]]\r\n\r\n [[0 0 0 0]\r\n  [0 0 0 0]\r\n  [0 0 0 0]\r\n  [0 0 0 0]]\r\n\r\n [[5 5 5 5]\r\n  [6 6 6 6]\r\n  [7 7 7 7]\r\n  [8 8 8 8]]\r\n\r\n [[0 0 0 0]\r\n  [0 0 0 0]\r\n  [0 0 0 0]\r\n  [0 0 0 0]]]\r\n\r\n### Clear description\r\n\r\nThe documentation has the wrong output. \r\n\r\n### Correct links\r\n\r\nHere is a Colab notebook that demonstrates the problem:\r\n\r\nhttps://colab.research.google.com/drive/1XYjNsbz1Atfa5bbD7W4FxvIr0zap-HOJ?usp=sharing\r\n\r\n### Parameters defined\r\n\r\nAre all parameters defined and formatted correctly?\r\n\r\nExactly as in the documentation page.\r\n\r\n### Returns defined\r\n\r\nAre return values defined?\r\n\r\nThey are not what are in the documentation page :)\r\n\r\n### Raises listed and defined\r\n\r\nAre the errors defined? \r\n\r\nYes, error returns are defined. I have not tested them.\r\n\r\n### Usage example\r\n\r\nIs there a usage example?\r\n\r\nSee the API guide: https://www.tensorflow.org/community/contribute/docs_ref\r\non how to write testable usage examples.\r\n\r\n### Request visuals, if applicable\r\n\r\nAre there currently visuals? If not, will it clarify the content?\r\n\r\nNo.\r\n\r\n### Submit a pull request?\r\n\r\nAre you planning to also submit a pull request to fix the issue? \r\n\r\nNo. Frankly, I have trouble understanding what the correct output should be.\r\n", "comments": ["Oh hell, I misread the doc. Never mind."]}, {"number": 43640, "title": "bug in tf", "body": "<em>Please make sure that this is a bug. As per our\r\n[GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md),\r\nwe only address code/doc bugs, performance issues, feature requests and\r\nbuild/installation issues on GitHub. tag:bug_template</em>\r\n\r\n**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\n- TensorFlow installed from (source or binary):\r\n- TensorFlow version (use command below):\r\n- Python version:\r\n- Bazel version (if compiling from source):\r\n- GCC/Compiler version (if compiling from source):\r\n- CUDA/cuDNN version:\r\n- GPU model and memory:\r\n\r\nYou can collect some of this information using our environment capture\r\n[script](https://github.com/tensorflow/tensorflow/tree/master/tools/tf_env_collect.sh)\r\nYou can also obtain the TensorFlow version with:\r\n1. TF 1.0: `python -c \"import tensorflow as tf; print(tf.GIT_VERSION, tf.VERSION)\"`\r\n2. TF 2.0: `python -c \"import tensorflow as tf; print(tf.version.GIT_VERSION, tf.version.VERSION)\"`\r\n\r\n\r\n**Describe the current behavior**\r\n\r\n**Describe the expected behavior**\r\n\r\n**Standalone code to reproduce the issue**\r\nProvide a reproducible test case that is the bare minimum necessary to generate\r\nthe problem. If possible, please share a link to Colab/Jupyter/any notebook.\r\n\r\n**Other info / logs** Include any logs or source code that would be helpful to\r\ndiagnose the problem. If including tracebacks, please include the full\r\ntraceback. Large logs and files should be attached.\r\n", "comments": ["Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43640\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43640\">No</a>\n"]}, {"number": 43639, "title": "this is a test issue", "body": "This template is for miscellaneous issues not covered by the other issue categories.\r\n\r\nFor questions on how to work with TensorFlow, or support for problems that are not verified bugs in TensorFlow, please go to [StackOverflow](https://stackoverflow.com/questions/tagged/tensorflow).\r\n\r\nIf you are reporting a vulnerability, please use the [dedicated reporting process](https://github.com/tensorflow/tensorflow/blob/master/SECURITY.md).\r\n\r\nFor high-level discussions about TensorFlow, please post to discuss@tensorflow.org, for questions about the development or internal workings of TensorFlow, or if you would like to know how to contribute to TensorFlow, please post to developers@tensorflow.org.\r\n", "comments": []}, {"number": 43638, "title": "Keras batch norm performance issue with parameter server strategy", "body": "**System information**\r\n\r\nHave I written custom code (as opposed to using a stock\r\nexample script provided in TensorFlow): Yes\r\nOS Platform and Distribution (e.g.,\r\nLinux Ubuntu 16.04): Ubuntu 16.04\r\nMobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if\r\nthe issue happens on mobile device:\r\nTensorFlow installed from (source or\r\nbinary): source\r\nTensorFlow version (use command below): 1.14\r\nPython version: - Bazel\r\nversion (if compiling from source):\r\nGCC/Compiler version (if compiling from\r\nsource):\r\nCUDA/cuDNN version: Cuda 10.1 cuDNN 7.6.5\r\nGPU model and memory: V100\r\n\r\n**Describe the current behavior**\r\n\r\nCurrently I'm observing a performance issue regarding Keras batch norm layer on tensorflow 1.14 with the following setup: Parameter server for multi-workers, mirrored strategy within each individual worker (8 GPUs per worker). All variables are cached on the worker cpus via `caching_device` to reduce parameter server <-> gpu communication.\r\n\r\nSpecifically, I'm wondering why https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/layers/normalization.py#L492 exists (first added in https://github.com/tensorflow/tensorflow/commit/88ad9949ef4ea6e07105a326a1d21c108cb2883a). This places all moving mean / variance update tensors, for each GPU, on the parameter server, causing communication between worker GPUs and the parameter server that does not scale (passing the tensor 64 times in my setup rather than 8 times in a 1 GPU per worker, 8 workers setup). Upon removing the colocation, the update tensors are placed on individual GPUs, and the communication disappears and distributed training with the parameter server scales properly. Does the colocation exist to properly synchronize the moving mean / variance updates?\r\n\r\n**Describe the expected behavior**\r\n\r\nI'd expect there to be no communication between individual GPUs and the parameter server, and the moving mean and variance update tensors placed on devices in a way that is efficient.", "comments": ["@bilisun,\r\nTensorFlow 1.x is not actively supported. Could you please update TensorFlow to v2.3 and check if you are facing the same issue. \r\n\r\nAlso, in order to expedite the trouble-shooting process, could you please provide a minimal working example to reproduce the issue reported here. Thanks!\r\n", "Trying v2.3 might take some time, will check back in with you.\r\n\r\nIn the meantime, where can I find the rationale for https://github.com/tensorflow/tensorflow/commit/88ad9949ef4ea6e07105a326a1d21c108cb2883a#diff-c2a77473d7da4416da00fd1c7050f26dR367? Thank you!", "> In the meantime, where can I find the rationale for [88ad994#diff-c2a77473d7da4416da00fd1c7050f26dR367](https://github.com/tensorflow/tensorflow/commit/88ad9949ef4ea6e07105a326a1d21c108cb2883a#diff-c2a77473d7da4416da00fd1c7050f26dR367)?\r\n\r\n@bilisun,\r\nCould you please check the associated PR for this.\r\n\r\n> Trying v2.3 might take some time, will check back in with you.\r\n\r\nAlso, any updates regarding this? Is this still an issue? Thanks!", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "@amahendrakar There isn't really an associated PR, the PR adding that change seems like a generic cherry-pick of many, many commits (https://github.com/tensorflow/tensorflow/pull/20064). Trying v2.3 won't be feasible for a long time for me.", "Hi @bilisun, the script you're pointing to is in contrib, which is no longer supported so I think it is going to be difficult to track down the rationale for this one. Note that `tf.keras` does not work with PSS in TF 2.3. However, there have been a lot of recent changes to PSS and you should be able to use it with `tf.keras` in nightly. My recommendation is to check the PSS implementation in 2.x and if you still have performance concerns we can certainly help address those.", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 43637, "title": "libhexagon_interface.so for non Android - eLinux platform", "body": "<em>Please make sure that this is a build/installation issue. As per our [GitHub Policy](https://github.com/tensorflow/tensorflow/blob/master/ISSUES.md), we only address code/doc bugs, performance issues, feature requests and build/installation issues on GitHub. tag:build_template</em>\r\n\r\n**System information**\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04): Automotive Grade Linux\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device: SA8195P\r\n- TensorFlow installed from (source or binary): source\r\n- TensorFlow version: r2.3\r\n- Bazel version (if compiling from source): 3.1.0\r\n- GCC/Compiler version (if compiling from source): aarch64-linux-gnu 8.3.0\r\n\r\n\r\n\r\n**Describe the problem**\r\nHello.\r\nI'm trying to get hexagon delgate to work on Qualcomm's SA8195P platform. This platform is based on Snapdragon 8xx series. But the problem is that this platform works on Automotive Grade Linux. The currently available libhexagon_interface.so doesn't work as it has Android dependencies. I cannot find the source code of libhexagon_interface.so in tensorflow git. Is it possible to get source code of libhexagon_interface.so or a complied binary of libhexagon_interface.so for aarch64 Linux without Android dependencies?\r\n\r\nI noticed that the binary of libhexagon_interface.so for openwrt is provided to hardiksd.\r\nhttps://github.com/tensorflow/tensorflow/issues/39736\r\n\r\nThank you.\r\n\r\n\r\n\r\n", "comments": ["@Hozzu \r\nPlease refer to these issues and let us know if it helps: #35506 #39736 #38302 ", "> @Hozzu\r\n> Please refer to these issues and let us know if it helps: #35506 #39736 #38302\r\n\r\nI understand that the source code cannot be shared because of license.\r\nThen, I want to get the binary of libhexagon_interface.so for aarch64 Linux without Android dependencies.\r\nIt seems that karimnosseir sent this binary to some people.\r\nHow can I get it?", "@karimnosseir  could you please share the requested binary.\r\n\r\n@Hozzu please share your email id as done in the above issues.", "> @karimnosseir could you please share the requested binary.\r\n> \r\n> @Hozzu please share your email id as done in the above issues.\r\n\r\npkshin@redwood.snu.ac.kr\r\n\r\nThank you!", "@Hozzu Thanks, i will reach out directly shortly\r\n\r\nThanks", "@karimnosseir \r\nThank you for your update.\r\n@Hozzu \r\nPlease move this issue to closed status once resolved.", "Thank you @karimnosseir @Saduf2019 ", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43637\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43637\">No</a>\n", "@karimnosseir I have the same request, Could you please share? ", "@r-wheeler Can you please reach out directly to me ? email same as my name here.\r\n\r\nThanks"]}, {"number": 43636, "title": "[ROCm] Adding #defines for ROCm / MIOpen / HIP Runtime version numbers ", "body": "This PR/commit introduces the following #defines in the `rocm/rocm_config.h` file\r\n\r\n```\r\n#define TF_ROCM_VERSION <Version Number of ROCm install>\r\n#define TF_MIOPEN_VERSION <Verion Number of MIOpen in ROCm install>\r\n#define TF_HIPRUNTIME_VERSION <Version Number of HIP Runtinme in ROCm install>\r\n```\r\n\r\nThese #defines should be used within TF code to add ROCm/MIOpen/HIp Runtime version specific code.\r\n\r\nA new script `find_rocm_config.py` is being added by this commit. This script does all the work of determining the version number information and it is pretty easy to extend it to query more information about the ROCM install.\r\n\r\nThe information collected by the script is available to `rocm_configure.bzl` and hence can be used to add version specific code in `rocm_configure.bzl` as well.\r\n\r\n----------------------------------------------------------\r\n\r\n/cc @cheshire @chsigg @nvining-work ", "comments": ["@cheshire @chsigg gentle ping", "@gbaned let me know if there is anything that needs to be done on my end to get this PR merged", "@deven-amd  It is processing internally, we will let you know if anything required from you.  Thank you!", "@gbaned any update on this one? \r\ngetting this PR merged is a pre-req to enable me to file the next PR (which will update TF builds to use ROCm 3.9). \r\nthanks.", "It seems this runs again into the error that you cannot execute a python script checked into the repository in the configure step during a remote build execution. You can take a look at the workaround used in cuda_configure.bzl (function _check_cuda_libs) for a workaround how to do this.\r\n\r\nHere is the error btw:\r\nERROR: An error occurred during the fetch of repository 'ubuntu18.04-gcc7_manylinux2010-rocm_config_rocm':\r\n   Traceback (most recent call last):\r\n\tFile \"/tmpfs/tensor_flow/third_party/gpus/rocm_configure.bzl\", line 558\r\n\t\t_get_rocm_config(repository_ctx, <2 more arguments>)\r\n\tFile \"/tmpfs/tensor_flow/third_party/gpus/rocm_configure.bzl\", line 412, in _get_rocm_config\r\n\t\tfind_rocm_config(repository_ctx, <1 more arguments>)\r\n\tFile \"/tmpfs/tensor_flow/third_party/gpus/rocm_configure.bzl\", line 390, in find_rocm_config\r\n\t\t_exec_find_rocm_config(<2 more arguments>)\r\n\tFile \"/tmpfs/tensor_flow/third_party/gpus/rocm_configure.bzl\", line 386, in _exec_find_rocm_config\r\n\t\texecute(repository_ctx, <1 more arguments>)\r\n\tFile \"/tmpfs/tensor_flow/third_party/remote_config/common.bzl\", line 215, in execute\r\n\t\traw_exec(repository_ctx, <1 more arguments>)\r\n\tFile \"/tmpfs/tensor_flow/third_party/remote_config/common.bzl\", line 239, in raw_exec\r\n\t\trepository_ctx.execute(cmdline)\r\nArgument 1 of execute is neither a label nor a string.\r\n\r\nEssentially it is the same kind of error that you got in https://github.com/tensorflow/tensorflow/pull/41515\r\nIn that PR I could replace the python script by a command line tool. This kind of fix doesn't seem to be possible here.", "@deven-amd  Can you please check @akuegel's comments and keep us posted ? Thanks!", "@akuegel @gbaned \r\n\r\nI have updated the manner in which `find_rocm_config.py` is invoked, to mimic the manner in which `find_cuda_config.py` is invoked. I am hoping that this is enough to make the script execute properly in rbe, but I have no way to check/confirm it. Please trigger the RBE on your end, and let me know if the changes are good. \r\n\r\nthanks\r\n\r\ndeven", "> @akuegel @gbaned\r\n> \r\n> I have updated the manner in which `find_rocm_config.py` is invoked, to mimic the manner in which `find_cuda_config.py` is invoked. I am hoping that this is enough to make the script execute properly in rbe, but I have no way to check/confirm it. Please trigger the RBE on your end, and let me know if the changes are good.\r\n> \r\n> thanks\r\n> \r\n> deven\r\n\r\nThanks for fixing it, it looks like it now runs successfully with RBE. It might still take until tomorrow until we merge this PR, because we still need an internal approval by an OWNER of this code area.", "I ran into some additional issues, it seems the find_rocm_config.py script didn't find some configs. So in the end I just commented out all _find_*_config lines which are currently unused (and regenerated the compressed file), and then it worked."]}, {"number": 43635, "title": "update graph.h", "body": "update comment for Graph:: FindEdgeId method", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here with `@googlebot I signed it!` and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F43635) for more info**.\n\n<!-- need_sender_cla -->", "> @googlebot I signed it!\r\n\r\n", "CLAs look good, thanks!\n\n\u2139\ufe0f **Googlers: [Go here](https://goto.google.com/prinfo/https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fpull%2F43635) for more info**.\n\n<!-- ok -->"]}, {"number": 43633, "title": "[ROCm] Porting changes to support newer ROCm versions to r2.1", "body": "This PR contains updates required to make TF r2.1 work with newer ROCm versions (r2.1 branch currently supports ROCm 3.7) \r\n\r\nThis PR has two commits right now, but that is expected to grow by the time we get around to merging this PR.  Please see individual commit messages for details on the changes being made\r\n\r\n----------------------------\r\n\r\n @mihaimaruseac \r\nAs with the prior PRs, it is understood that this PR will be merged along with the next patch to r2.1, whenever that happens to be.\r\n\r\n/cc @cheshire @chsigg @nvining-work ", "comments": []}, {"number": 43632, "title": "[ROCm] Adding bsdmainutils to the install list for ROCm docker containers.", "body": "For the ROCm TensorFlow build, the \"hexdump\" utility is required for the tool flow used by MLIR generated GPU kernels. \r\n\r\nThe \"hexdump\" utility is part of the \"bsdmainutils\" package and that package is currently not installed in the ROCm docker container. This change simply adds the \"bsdmainutils\" package to the install list\r\n\r\n------------------------------------------\r\n\r\n/cc @cheshire @chsigg @nvining-work ", "comments": ["@akuegel this might help with re-enabling the unit tests for rocm  ( https://github.com/tensorflow/tensorflow/commit/712fd5cfe4a5de420a4226c874664423eba4cb1a )\r\n ", "I have already re-enabled the tests, after the new docker image was deployed that included 1b98b8676b2a246380d600e3e2fa1724db7f3f53\r\nI don't know whether this change is needed as well, but probably doesn't hurt."]}, {"number": 43631, "title": "tf.cond throws AssertionError when computing its gradient twice", "body": "**System information**\r\n- Have I written custom code (as opposed to using a stock example script provided in TensorFlow):\r\nYes\r\n- OS Platform and Distribution (e.g., Linux Ubuntu 16.04):\r\nTested on Arch Linux and the default Google Colab env\r\n- Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device:\r\nN/A\r\n- TensorFlow installed from (source or binary):\r\nBinary\r\n- TensorFlow version (use command below):\r\nv2.3.0-0-gb36436b087 2.3.0 (and I've also tried 2.4.0, same problem)\r\n- Python version:\r\n3.6.9\r\n- Bazel version (if compiling from source):\r\nN/A\r\n- GCC/Compiler version (if compiling from source):\r\nN/A\r\n- CUDA/cuDNN version:\r\nN/A\r\n- GPU model and memory:\r\nN/A\r\n\r\n**Describe the current behavior**\r\nCalling `g.gradient` twice on a tensor obtained from `tf.cond` call in `@tf.function` causes AssertionError:\r\n`assert len(func_graph.outputs) == len(grads)`. The problem appears only if variable in the `true_fn` or `false_fn` was transformed (multiplied, exponentiated, etc.)\r\n\r\n**Describe the expected behavior**\r\nTF should either:\r\n* Successfully calculate the gradient, or \r\n* Consistently fail after the first time and even if the `true_fn` doesn't contain any transformation of the variable.\r\n\r\n**Standalone code to reproduce the issue**\r\n```\r\nimport tensorflow as tf\r\n\r\na = tf.Variable(tf.ones(10))\r\n\r\n@tf.function\r\ndef test_cond(cond_var):\r\n    with tf.GradientTape(persistent=True) as g:\r\n         loss = tf.cond(\r\n             cond_var > 0,\r\n             lambda: tf.reduce_sum(1 * a),\r\n             lambda: tf.reduce_sum(1 * a))\r\n\r\n    gradient1 = g.gradient(loss, [a])\r\n    gradient2 = g.gradient(loss, [a])\r\n    return gradient1, gradient2\r\n\r\ng1, g2 = test_cond(tf.convert_to_tensor(1))\r\n```\r\n\r\n<details>\r\n<summary>This throws the following AssertionError:</summary>\r\n\r\n\r\n```\r\n---------------------------------------------------------------------------\r\nAssertionError                            Traceback (most recent call last)\r\n<ipython-input-27-7a87d1b88655> in <module>()\r\n     15     return gradient1, gradient2\r\n     16 \r\n---> 17 g1, g2 = test_cond(tf.convert_to_tensor(1))\r\n\r\n8 frames\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in __call__(self, *args, **kwds)\r\n    778       else:\r\n    779         compiler = \"nonXla\"\r\n--> 780         result = self._call(*args, **kwds)\r\n    781 \r\n    782       new_tracing_count = self._get_tracing_count()\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _call(self, *args, **kwds)\r\n    821       # This is the first call of __call__, so we have to initialize.\r\n    822       initializers = []\r\n--> 823       self._initialize(args, kwds, add_initializers_to=initializers)\r\n    824     finally:\r\n    825       # At this point we know that the initialization is complete (or less\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in _initialize(self, args, kwds, add_initializers_to)\r\n    695     self._concrete_stateful_fn = (\r\n    696         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\r\n--> 697             *args, **kwds))\r\n    698 \r\n    699     def invalid_creator_scope(*unused_args, **unused_kwds):\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _get_concrete_function_internal_garbage_collected(self, *args, **kwargs)\r\n   2853       args, kwargs = None, None\r\n   2854     with self._lock:\r\n-> 2855       graph_function, _, _ = self._maybe_define_function(args, kwargs)\r\n   2856     return graph_function\r\n   2857 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _maybe_define_function(self, args, kwargs)\r\n   3211 \r\n   3212       self._function_cache.missed.add(call_context_key)\r\n-> 3213       graph_function = self._create_graph_function(args, kwargs)\r\n   3214       self._function_cache.primary[cache_key] = graph_function\r\n   3215       return graph_function, args, kwargs\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py in _create_graph_function(self, args, kwargs, override_flat_arg_shapes)\r\n   3073             arg_names=arg_names,\r\n   3074             override_flat_arg_shapes=override_flat_arg_shapes,\r\n-> 3075             capture_by_value=self._capture_by_value),\r\n   3076         self._function_attributes,\r\n   3077         function_spec=self.function_spec,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in func_graph_from_py_func(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\r\n    984         _, original_func = tf_decorator.unwrap(python_func)\r\n    985 \r\n--> 986       func_outputs = python_func(*func_args, **func_kwargs)\r\n    987 \r\n    988       # invariant: `func_outputs` contains only Tensors, CompositeTensors,\r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py in wrapped_fn(*args, **kwds)\r\n    598         # __wrapped__ allows AutoGraph to swap in a converted function. We give\r\n    599         # the function a weak reference to itself to avoid a reference cycle.\r\n--> 600         return weak_wrapped_fn().__wrapped__(*args, **kwds)\r\n    601     weak_wrapped_fn = weakref.ref(wrapped_fn)\r\n    602 \r\n\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py in wrapper(*args, **kwargs)\r\n    971           except Exception as e:  # pylint:disable=broad-except\r\n    972             if hasattr(e, \"ag_error_metadata\"):\r\n--> 973               raise e.ag_error_metadata.to_exception(e)\r\n    974             else:\r\n    975               raise\r\n\r\nAssertionError: in user code:\r\n\r\n    <ipython-input-27-7a87d1b88655>:14 test_cond  *\r\n        gradient2 = g.gradient(loss, [a])\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py:1073 gradient  **\r\n        unconnected_gradients=unconnected_gradients)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/imperative_grad.py:77 imperative_grad\r\n        compat.as_str(unconnected_gradients.value))\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/backprop.py:162 _gradient_function\r\n        return grad_fn(mock_op, *out_grads)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/cond_v2.py:121 _IfGrad\r\n        true_graph, grads, util.unique_grad_fn_name(true_graph.name))\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/cond_v2.py:384 _create_grad_func\r\n        func_graph=_CondGradFuncGraph(name, func_graph))\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py:986 func_graph_from_py_func\r\n        func_outputs = python_func(*func_args, **func_kwargs)\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/cond_v2.py:383 <lambda>\r\n        lambda: _grad_fn(func_graph, grads), [], {},\r\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/cond_v2.py:359 _grad_fn\r\n        assert len(func_graph.outputs) == len(grads)\r\n\r\n    AssertionError: \r\n\r\n```\r\n</details>\r\n\r\nWhat's interesting, if you replace `1 * a` with `a` inside the `tf.cond` call, then everything works fine. If you remove one of the `g.gradient` calls, it also works fine.\r\n\r\nI've uploaded the code [to colab](https://colab.research.google.com/drive/1XximLOFyx828syl5QteZ8oOvXE7CqUGT?usp=sharing) as well.", "comments": ["Can you try with:\r\n```\r\nimport tensorflow as tf\r\nprint(tf.version.GIT_VERSION, tf.version.VERSION)\r\n\r\na = tf.Variable(tf.ones(10), dtype=tf.float32)\r\n\r\n@tf.function\r\ndef test_cond(cond_var):\r\n    with tf.GradientTape(persistent=True) as g:\r\n        # This doesn't work...\r\n        if cond_var>0:\r\n            loss = tf.reduce_sum(1. * a)\r\n        else:\r\n            loss = tf.reduce_sum(1. * a)\r\n\r\n        # ...but this does\r\n        #  loss = tf.cond(\r\n        #      cond_var > 0,\r\n        #      lambda: tf.reduce_sum(a),\r\n        #      lambda: tf.reduce_sum(a))\r\n\r\n    gradient1 = g.gradient(loss, [a])\r\n    gradient2 = g.gradient(loss, [a])\r\n    return gradient1, gradient2\r\n\r\ng1,g2 = test_cond(1)\r\nprint(g1,g2)\r\n```", "Sure, I've changed the [colab example](https://colab.research.google.com/drive/1XximLOFyx828syl5QteZ8oOvXE7CqUGT?usp=sharing). If you pass a Python boolean then it works well, but if you pass TensorFlow boolean it fails with the same message.", "@maciejwolczyk Yes I think that your problem is related to autograph with identity function. If you transform `a` e.g. `(1. + a)` and \r\nif you insert a debugging print like:\r\n```python\r\nprint(\"Num of grads %d - Func_graph outputs %d  - Name: %s \" % (len(grads),len(func_graph.outputs),name))\r\nfor output in func_graph.outputs:\r\n  print(\"Output: \",output)\r\n```\r\nbefore the return on the  `_create_grad_func`:\r\nhttps://github.com/tensorflow/tensorflow/blob/55956aced7956ef25876096ffdf6434aab5e05e5/tensorflow/python/ops/cond_v2.py#L380-L382\r\n\r\nYou will see:\r\n```\r\nNum of grads 1 - Func_graph outputs 1  - Name: cond_true_19_grad_44 \r\nOutput:  Tensor(\"cond/Identity:0\", shape=(), dtype=float32)\r\n[<tf.Tensor 'gradient_tape/cond/gradients/cond/Sum_grad/Tile:0' shape=(10,) dtype=float32>, None]\r\nNum of grads 1 - Func_graph outputs 1  - Name: cond_false_20_grad_61 \r\nOutput:  Tensor(\"cond/Identity:0\", shape=(), dtype=float32)\r\n[None, <tf.Tensor 'gradient_tape/cond/gradients/cond/Sum_grad/Tile:0' shape=(10,) dtype=float32>]\r\nNum of grads 1 - Func_graph outputs 1  - Name: cond_true_19_grad_85 \r\nOutput:  Tensor(\"cond/Identity:0\", shape=(), dtype=float32)\r\n[<tf.Tensor 'gradient_tape/cond/gradients/cond/Sum_grad/Tile:0' shape=(10,) dtype=float32>, None]\r\nNum of grads 1 - Func_graph outputs 1  - Name: cond_false_20_grad_102 \r\nOutput:  Tensor(\"cond/Identity:0\", shape=(), dtype=float32)\r\n[None, <tf.Tensor 'gradient_tape/cond/gradients/cond/Sum_grad/Tile:0' shape=(10,) dtype=float32>]\r\n```\r\nSo you have 1 grad and 1 func_graph output (for cond_true and cond_false) that is ok cause  `_grad_fn`:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/55956aced7956ef25876096ffdf6434aab5e05e5/tensorflow/python/ops/cond_v2.py#L360\r\n\r\nWhen you use a single identity e.g. (1.*a)  it will add an additional `OptionalFromValue` output but gradients are still 1 and so the assert will mismatch:\r\n`\r\nNum of grads 1 - Func_graph outputs 1  - Name: cond_true_19_grad_44 \r\nOutput:  Tensor(\"cond/Identity:0\", shape=(), dtype=float32)\r\n[<tf.Tensor 'gradient_tape/cond/gradients/cond/mul_grad/Mul_1:0' shape=(10,) dtype=float32>, None]\r\nNum of grads 1 - Func_graph outputs 1  - Name: cond_false_20_grad_67 \r\nOutput:  Tensor(\"cond/Identity:0\", shape=(), dtype=float32)\r\n[None, <tf.Tensor 'gradient_tape/cond/gradients/cond/Sum_grad/Tile:0' shape=(10,) dtype=float32>]\r\nNum of grads 1 - Func_graph outputs 2  - Name: cond_true_19_rewritten_grad_94 \r\nOutput:  Tensor(\"cond/Identity:0\", shape=(), dtype=float32)\r\nOutput:  Tensor(\"cond/OptionalFromValue:0\", shape=(), dtype=variant)\r\n`\r\n\r\n", "That seems correct, thanks! Still, it is a rather unexpected behaviour. Is there a possible fix? If not, then I think an error message explaining what happened would be nice. ", "/cc @saxenasaurabh ", "/cc @sun51 ", "Was able to reproduce the issue with TF v2.3 and TF-nightly. Please find the gist of it [here](https://colab.research.google.com/gist/amahendrakar/39a267c0a2ce7a7285228b3e431f1302/43631-tf-nightly.ipynb). Thanks!", "Control flow does not support persistent tape yet. When taking gradient of a control flow op, we update the forward op with extra outputs which the tape is unaware of and hence there is a mismatch between the number of incoming grads and the number of outputs of the forward op. One workaround for now is to wrap the `tf.cond` inside a tf.function:\r\n\r\n```\r\nimport tensorflow as tf\r\nprint(tf.version.GIT_VERSION, tf.version.VERSION)\r\n\r\na = tf.Variable(tf.ones(10), dtype=tf.float32)\r\n\r\n@tf.function\r\ndef test_cond(cond_var):\r\n    with tf.GradientTape(persistent=True) as g:\r\n        @tf.function\r\n        def f():\r\n            if cond_var:\r\n                loss = tf.reduce_sum(1 * a)\r\n            else:\r\n                loss = tf.reduce_sum(1 * a)\r\n            return loss\r\n\r\n        loss = f()\r\n    gradient1 = g.gradient(loss, [a])\r\n    gradient2 = g.gradient(loss, [a])\r\n    return gradient1, gradient2\r\n\r\ng1,g2 = test_cond(tf.convert_to_tensor(True))\r\nprint(g1,g2)\r\n```", "@saxenasaurabh Thanks.. Do you think that  we can improve the error message?\nCause without internals debugging It Is hard to understand what's happen.", "We should throw a better error message for sure. I will also try to think of a fix.", "> One workaround for now is to wrap the `tf.cond` inside a tf.function:\r\n\r\nGreat, thanks, I will use it for now!\r\n\r\nI agree that a better error message would be very useful.", "@maciejwolczyk \r\nI ran the code shared on tf 2.4 and do not see nay error, please refer to the [gist here](https://colab.research.google.com/gist/Saduf2019/92061a2bdbd30749974b6c202f8d5737/untitled589.ipynb). ", "This issue has been automatically marked as stale because it has not had recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n", "Are you satisfied with the resolution of your issue?\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=Yes&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43631\">Yes</a>\n<a href=\"https://docs.google.com/forms/d/e/1FAIpQLSfaP12TRhd9xSxjXZjcZFNXPGk4kc1-qMdv3gc6bEP90vY1ew/viewform?entry.85265664=No&entry.2137816233=https://github.com/tensorflow/tensorflow/issues/43631\">No</a>\n"]}, {"number": 43630, "title": "Improve documentation for tf.linalg.qr", "body": "Currently, there is no user documentation for the backward method in tf.linalg.qr.\r\n\r\nThe user can backpropagate through the qr factorization and they should know what assumptions (limitations) are being made by the autodiff methodology, as detailed in the reference document:\r\n\r\n[QR and LQ Decomposition Matrix Backpropagation Algorithms for Square, Wide, and Deep Matrices and Their Software Implementation](https://arxiv.org/abs/2009.10071)", "comments": []}]