[{"number": 22803, "title": "Model converted to TFLite always returns NaN as output.", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS 10.13.6\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: --\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**:  v1.10.0-12-g4dcfddc5d1 1.10.1\r\n- **Python version**: 3.6.5\r\n- **Bazel version (if compiling from source)**: --\r\n- **GCC/Compiler version (if compiling from source)**: --\r\n- **CUDA/cuDNN version**: --\r\n- **GPU model and memory**: Intel Iris Plus Graphics 650 1536 MB\r\n- **Exact command to reproduce**: `python3 test.py`\r\n\r\n### Describe the problem\r\nI have been trying to convert a frozen graph trained using [this repo](https://github.com/GeorgeSeif/Semantic-Segmentation-Suite) for using on android with TFLite. Trained model uses MobileNetV2 as frontend and [Mobile UNet for Semantic Segmentation](https://arxiv.org/abs/1704.04861) as the model. The problem I am facing is: the frozen pb graph segments the image correctly but TFLite converted model returns all `nan` for the output. To try the problem I wrote the following script. The model is converted without any errors or warnings, but the output is not correct. Do you have any idea what might be causing this?\r\n\r\nNote: converted model is also returning NaNs on android device.\r\n\r\n**Frozen graph**: [output_graph.pb](https://drive.google.com/file/d/1qGwD8h5ub0HjtO-Cc8Zd-HU6Uv-t9apF/view?usp=sharing)\r\n\r\n### Source code / logs\r\n\r\n**test.py**\r\n```python\r\nimport tensorflow as tf\r\nimport numpy as np\r\nimport cv2\r\nfrom tensorflow.python.platform import gfile\r\nfrom tensorflow.contrib.lite.python.convert_saved_model import set_tensor_shapes\r\n\r\nsess = tf.Session()\r\n\r\n# load graph\r\nwith gfile.FastGFile('output_graph.pb', 'rb') as f:\r\n    graph_def = tf.GraphDef()\r\ngraph_def.ParseFromString(f.read())\r\nsess.graph.as_default()\r\ntf.import_graph_def(graph_def, name='')\r\n\r\n# get tensors\r\ninput_tensor = sess.graph.get_tensor_by_name('Placeholder:0')\r\noutput_tensor = sess.graph.get_tensor_by_name('logits/Conv2D:0')\r\n\r\n# generate random image\r\ninput_image = np.array(np.random.random_sample(\r\n    [1, 128, 128, 3]), dtype=np.float32)\r\n\r\n# run the model with tf\r\noutput_image = sess.run(output_tensor, feed_dict={input_tensor: input_image})\r\n\r\n# print tf output\r\nprint('--- Tensorflow output ---')\r\nprint(output_image)\r\nprint('-------------------------')\r\n\r\n# set shapes\r\ninput_tensor.set_shape([1, 128, 128, 3])\r\noutput_tensor.set_shape([1, 128, 128, 32])\r\n\r\n# convert model\r\nconverter = tf.contrib.lite.TocoConverter.from_session(\r\n    sess, [input_tensor], [output_tensor])\r\ntflite_model = converter.convert()\r\n\r\n# Prepare interpreter\r\ninterpreter = tf.contrib.lite.Interpreter(model_content=tflite_model)\r\ninterpreter.allocate_tensors()\r\n\r\ninput_details = interpreter.get_input_details()\r\noutput_details = interpreter.get_output_details()\r\n\r\n# set input data\r\ninterpreter.set_tensor(input_details[0]['index'], input_image)\r\n\r\n# run model on interpreter\r\ninterpreter.invoke()\r\n\r\n# retrive output\r\noutput_data = interpreter.get_tensor(output_details[0]['index'])\r\n\r\n# print tflite output\r\nprint('--- TFLite output ---')\r\nprint(output_data)\r\nprint('---------------------')\r\n```\r\n\r\n**output**\r\n```shell\r\n--- Tensorflow output ---\r\n[[[[-14.484754   -14.454916    -3.9344878  ... -10.294399\r\n     -2.837898    -8.190185  ]\r\n   [-14.120294   -10.590508    -4.032942   ...  -6.7745924\r\n     -0.4497184   -9.78646   ]\r\n   [-14.561665   -10.49988     -8.065053   ...  -7.422716\r\n     -0.7991432  -10.160792  ]\r\n   ...\r\n   [-13.12197     -7.3976164   -7.1669674  ...  -9.533363\r\n     -2.0361094  -10.951963  ]\r\n   [-15.041047    -7.3879066   -6.724542   ... -11.897878\r\n     -2.1202648  -13.670592  ]\r\n   [-14.483544   -10.037312    -6.356632   ... -12.075281\r\n     -2.2860763  -10.284541  ]]\r\n\r\n  [[-10.372202   -13.09114     -3.6517806  ...  -7.623592\r\n     -1.8009435   -6.817739  ]\r\n   [-10.72727    -10.886565    -5.621975   ...  -7.8185344\r\n     -1.4768337  -10.389865  ]\r\n   [-11.611484   -10.158413    -7.931344   ...  -4.938987\r\n     -0.23626254  -8.830031  ]\r\n   ...\r\n   [-12.590868    -6.102834   -10.619679   ...  -9.990441\r\n     -1.0927511  -10.764243  ]\r\n   [-12.30341     -4.7649236   -6.600345   ...  -9.458132\r\n     -0.8608778  -12.198781  ]\r\n   [-11.649162    -6.2056537   -5.922945   ... -10.207803\r\n     -1.5887291   -9.819743  ]]\r\n\r\n  [[-11.40545    -13.755798    -6.9160714  ... -11.7735195\r\n     -3.3357754  -11.139454  ]\r\n   [-11.398698   -11.785369    -6.5561953  ...  -9.794318\r\n     -2.8272014  -11.654141  ]\r\n   [ -9.548821    -7.3276024   -8.640192   ...  -4.349879\r\n      0.14261375  -7.0007625 ]\r\n   ...\r\n   [-12.497658    -5.8748426   -9.083981   ...  -9.841493\r\n     -1.4732579  -11.357761  ]\r\n   [-14.517144    -5.2391934   -8.496638   ... -10.834668\r\n     -2.6033173  -13.944796  ]\r\n   [-14.292226    -7.0837607   -6.3621516  ... -10.551426\r\n     -3.6190045  -12.224428  ]]\r\n\r\n  ...\r\n\r\n  [[ -6.1242228  -14.730902    -6.034355   ...  -5.2220926\r\n     -1.1160429   -2.2097938 ]\r\n   [ -5.003286   -16.216772    -5.28262    ...  -5.2270694\r\n     -1.7447093   -4.245701  ]\r\n   [ -5.595118   -15.978978    -4.214302   ...  -5.4203877\r\n     -1.8398296   -4.396698  ]\r\n   ...\r\n   [-13.178917   -13.012176   -10.450902   ... -15.064126\r\n     -1.9914117   -9.5184765 ]\r\n   [-10.992667    -8.671063    -6.456934   ... -14.054223\r\n     -1.4051182   -9.887496  ]\r\n   [ -9.728466   -10.335494    -7.3331285  ... -10.754501\r\n     -1.7173084   -4.671226  ]]\r\n\r\n  [[ -5.4983754  -15.449182    -5.7204423  ...  -4.4113154\r\n     -1.0589103   -2.6990566 ]\r\n   [ -5.384841   -16.741693    -5.5674496  ...  -5.684756\r\n     -1.8891927   -4.65452   ]\r\n   [ -5.7909193  -16.244637    -4.5293765  ...  -6.4048567\r\n     -2.3706574   -4.982708  ]\r\n   ...\r\n   [-10.004818   -11.296059    -7.158481   ... -10.9329\r\n     -2.0753372   -8.129092  ]\r\n   [ -7.942011    -8.787835    -2.8869028  ... -10.7461605\r\n     -1.7351687   -7.8243003 ]\r\n   [ -9.368582   -11.195904    -5.3443894  ...  -8.967132\r\n     -1.5083878   -5.205722  ]]\r\n\r\n  [[ -7.6940765  -15.492795    -4.6488175  ...  -5.7006836\r\n     -1.3711176   -3.7699785 ]\r\n   [ -5.243174   -15.9268875   -5.07713    ...  -3.642994\r\n     -1.4748344   -4.1258245 ]\r\n   [ -4.8627806  -13.911514    -4.372596   ...  -2.4015875\r\n     -1.4164882   -3.6560988 ]\r\n   ...\r\n   [ -9.049875   -12.410313    -5.53057    ...  -8.292001\r\n     -2.442209    -4.6609883 ]\r\n   [ -7.18582    -11.061987    -3.3339026  ...  -7.413499\r\n     -2.0413182   -5.4470387 ]\r\n   [ -9.58725    -13.576278    -5.9882216  ...  -8.204617\r\n     -2.0788593   -5.216848  ]]]]\r\n-------------------------\r\n--- TFLite output ---\r\n[[[[nan nan nan ... nan nan nan]\r\n   [nan nan nan ... nan nan nan]\r\n   [nan nan nan ... nan nan nan]\r\n   ...\r\n   [nan nan nan ... nan nan nan]\r\n   [nan nan nan ... nan nan nan]\r\n   [nan nan nan ... nan nan nan]]\r\n\r\n  [[nan nan nan ... nan nan nan]\r\n   [nan nan nan ... nan nan nan]\r\n   [nan nan nan ... nan nan nan]\r\n   ...\r\n   [nan nan nan ... nan nan nan]\r\n   [nan nan nan ... nan nan nan]\r\n   [nan nan nan ... nan nan nan]]\r\n\r\n  [[nan nan nan ... nan nan nan]\r\n   [nan nan nan ... nan nan nan]\r\n   [nan nan nan ... nan nan nan]\r\n   ...\r\n   [nan nan nan ... nan nan nan]\r\n   [nan nan nan ... nan nan nan]\r\n   [nan nan nan ... nan nan nan]]\r\n\r\n  ...\r\n\r\n  [[nan nan nan ... nan nan nan]\r\n   [nan nan nan ... nan nan nan]\r\n   [nan nan nan ... nan nan nan]\r\n   ...\r\n   [nan nan nan ... nan nan nan]\r\n   [nan nan nan ... nan nan nan]\r\n   [nan nan nan ... nan nan nan]]\r\n\r\n  [[nan nan nan ... nan nan nan]\r\n   [nan nan nan ... nan nan nan]\r\n   [nan nan nan ... nan nan nan]\r\n   ...\r\n   [nan nan nan ... nan nan nan]\r\n   [nan nan nan ... nan nan nan]\r\n   [nan nan nan ... nan nan nan]]\r\n\r\n  [[nan nan nan ... nan nan nan]\r\n   [nan nan nan ... nan nan nan]\r\n   [nan nan nan ... nan nan nan]\r\n   ...\r\n   [nan nan nan ... nan nan nan]\r\n   [nan nan nan ... nan nan nan]\r\n   [nan nan nan ... nan nan nan]]]]\r\n---------------------\r\n```\r\n", "comments": ["I faced the same problem too!\r\n\r\nAfter days of investigation, I found the problem is caused by batch norm.\r\nThe values of feature maps significantly increases (around x100, and sometimes x1e+35) each time passing through the batch norm layer (either slim.batch_norm or tf.nn.fused_batch_norm). Eventually causes the values to become inf or nan (and only nan shown in final output).\r\n\r\nI'm not sure if this is a problem for specific tensorflow version?\r\nThis problem happens to me for both TF 1.11.0 and TF-nightly.", "Hi @hubert0527  and @sercant,\r\nDid you guys find any solution to this problem so far?  ", "Hi @hazirbas,\r\nNot on my end, unfortunately.", "@hubert0527 Thank you for pointing at batch normalization: when I had removed it from network my outputs became normal (not nan). But of course the quality of my network fell drammatically without batch normalization. I tried to replace tf.layer.batch_normalization with tf.keras.layers.BatchNormalization and tf.contrib.layers.batch_norm, but no effect. Finally I solved the problem by implementing my own batch normalization like this:\r\n\r\n```\r\n    def my_moments(input_tensor):\r\n        mean = tf.reduce_mean(input_tensor, axis=[0, 1, 2])\r\n        dev = input_tensor - mean\r\n        dev = dev * dev\r\n        dev = tf.reduce_mean(dev, axis=[0, 1, 2])\r\n        return mean, dev\r\n```\r\n\r\n```\r\n    def my_bn(input_tensor):\r\n        mu = tf.Variable(tf.ones(input_tensor.shape[3]))\r\n        beta = tf.Variable(tf.zeros(input_tensor.shape[3]))\r\n        mean, dev = my_moments(input_tensor)\r\n        return beta + mu * (input_tensor - mean) / (tf.sqrt(dev) + 0.001)\r\n```\r\n\r\nNote that this is not literal implementation of batch norm (here moving average is not used), because only train mode was required for my project. Also note that we cannot use tf.nn.moments to calc mean and dev because it is not supported by tflite (so we need to implement own function for moments). After replacing batch normalization with provided functions I was able to train my network, export it to tflite and use it during inference in tflite correctly.\r\n", "> @hubert0527 Thank you for pointing at batch normalization: when I had removed it from network my outputs became normal (not nan). But of course the quality of my network fell drammatically without batch normalization. I tried to replace tf.layer.batch_normalization with tf.keras.layers.BatchNormalization and tf.contrib.layers.batch_norm, but no effect. Finally I solved the problem by implementing my own batch normalization like this:\r\n> \r\n> ```\r\n>     def my_moments(input_tensor):\r\n>         mean = tf.reduce_mean(input_tensor, axis=[0, 1, 2])\r\n>         dev = input_tensor - mean\r\n>         dev = dev * dev\r\n>         dev = tf.reduce_mean(dev, axis=[0, 1, 2])\r\n>         return mean, dev\r\n> ```\r\n> ```\r\n>     def my_bn(input_tensor):\r\n>         mu = tf.Variable(tf.ones(input_tensor.shape[3]))\r\n>         beta = tf.Variable(tf.zeros(input_tensor.shape[3]))\r\n>         mean, dev = my_moments(input_tensor)\r\n>         return beta + mu * (input_tensor - mean) / (tf.sqrt(dev) + 0.001)\r\n> ```\r\n> Note that this is not literal implementation of batch norm (here moving average is not used), because only train mode was required for my project. Also note that we cannot use tf.nn.moments to calc mean and dev because it is not supported by tflite (so we need to implement own function for moments). After replacing batch normalization with provided functions I was able to train my network, export it to tflite and use it during inference in tflite correctly.\r\n\r\nHave you tried using `tf.layers.batch_normalization`? I have another network and it seems to be working on `tensorflow v1.12.0`.", "> > @hubert0527 Thank you for pointing at batch normalization: when I had removed it from network my outputs became normal (not nan). But of course the quality of my network fell drammatically without batch normalization. I tried to replace tf.layer.batch_normalization with tf.keras.layers.BatchNormalization and tf.contrib.layers.batch_norm, but no effect. Finally I solved the problem by implementing my own batch normalization like this:\r\n> > ```\r\n> >     def my_moments(input_tensor):\r\n> >         mean = tf.reduce_mean(input_tensor, axis=[0, 1, 2])\r\n> >         dev = input_tensor - mean\r\n> >         dev = dev * dev\r\n> >         dev = tf.reduce_mean(dev, axis=[0, 1, 2])\r\n> >         return mean, dev\r\n> > ```\r\n> > ```\r\n> >     def my_bn(input_tensor):\r\n> >         mu = tf.Variable(tf.ones(input_tensor.shape[3]))\r\n> >         beta = tf.Variable(tf.zeros(input_tensor.shape[3]))\r\n> >         mean, dev = my_moments(input_tensor)\r\n> >         return beta + mu * (input_tensor - mean) / (tf.sqrt(dev) + 0.001)\r\n> > ```\r\n> > Note that this is not literal implementation of batch norm (here moving average is not used), because only train mode was required for my project. Also note that we cannot use tf.nn.moments to calc mean and dev because it is not supported by tflite (so we need to implement own function for moments). After replacing batch normalization with provided functions I was able to train my network, export it to tflite and use it during inference in tflite correctly.\r\n> \r\n> Have you tried using `tf.layers.batch_normalization`? I have another network and it seems to be working on `tensorflow v1.12.0`.\r\n\r\nYes, I tried tf.layers.batch_normalization. It was my original normalization function which I started my investigation from. And I also was using tensorflow v1.12 when the problem was faced.", "Load balancing... @karimnosseir could you take a look?", "@sercant When freezing a model for inference, the attribute \"is_training\" of the BN layers should be set as false. In your frozen model, \"is_training\" is true. That makes the means/variances of BN layers to be all 0s. \r\nMaybe you should regenerate a frozen model with \"is_training=false\" and then convert it to a tflite model.\r\n\r\n\r\n", "Hi Sercant,\r\n\r\nAs IrvingMeng mentioned, you need to make sure is_training is false. Can you please confirm and share tflite &pb files for the model\r\n\r\nThanks", "@IrvingMeng Thank you, that really fixes the problem. \r\n\r\nIn my case I was using training=True during export intentionally because that gives better performance on my task. It worked fine during pb inference, so I was surprised that tflite was not working. But now I see that batch normalization in tflite works correct when using as intended. And for my task I should use custom normalization, for example suggested above.", "@sercant Have you found some solution for this problem? I have the same problem :(", "Thank you @IrvingMeng for pointing out the issue with the batch normalization parameter.\r\n\r\n> @sercant Have you found some solution for this problem? I have the same problem :(\r\n\r\n@ricardobnjunior Have you tried the solution suggested by @IrvingMeng ? I, unfortunately, don't work on this issue anymore since I initially opened it in October and got the answer in March. If you can confirm that the suggested solution works, the issue can be closed.", "Hello,\r\n\r\nI have been playing around with the pix2pix example:\r\nhttps://colab.research.google.com/drive/1Uv5QwTcygHgrD0e3AO1L_uwyuYqICrVJ\r\n\r\nIf you check out the link you can see setting trainable=False for BatchNormalization does not help.\r\nBut I can confirm that the issue is with BatchNormalization since when those layers are removed the conversion runs as expected.", "@ablenesi I tested my solution with the tf.layers.batch_normalization from tensorflow v1 (following the steps in this page https://www.tensorflow.org/lite/guide/get_started ). However, it won't work with the model built with keras layers.  \r\nI encountered issue #24591 when freezing a tf model built with keras layers.  \r\nPlease let me know if you find a solution for the keras modesl. :)\r\n\r\n", "@ablenesi Hi, did you find any workaround?", "I find a solution about this question. Just change the attribute fused of tf.keras.layers.bn to false. The output is correct.", "Marking issue as resolved due to inactivity. Feel free to re-open this if it's unresolved or file a [new issue](https://github.com/tensorflow/tensorflow/issues/new/choose)", "Hi, I'm not sure if I should be filing a different issue or it's ok to re-open this one. I am facing the same issue with nan values after converting pix2pix' generator to tflite. As @wangrui261 said, I replaced all `tf.keras.layers.BatchNormalization()` to `tf.keras.layers.BatchNormalization(fused=False, trainable=False)`, but the output is still nan. I tried removing all batch normalization layers and, even though the output is wrong, it has values.\r\n\r\nI am using tensorflow version 2.3.0 and Python 3.7.7\r\n\r\nHas anyone been able to solve this or has found a workaround?", "Re-opening unresolved issue.", "I discovered this generator also returns NaN values when running on CPU. As @hubert0527 said, this is due to big values of feature maps after Batch Normalization layers. I found somewhere in stack overflow that GPU zeroes these NaN values, while CPU keeps them, so I added a Lambda layer with a `tf.where` to solve this in CPU: `tf.keras.layers.Lambda(lambda x: tf.where(tf.math.is_nan(x), tf.zeros_like(x), x))` and CPU and GPU executions return almost the same values (1e-6 maximum error in my case).\r\n\r\nI have the feeling that this would fix the TFLite conversion, but when calling `allocate_tensors` on the new TFLite model I get the following error: ` Encountered unresolved custom op: IsNan.Node number 3 (IsNan) failed to prepare.`.\r\nI have never added a new operation to TFLite and thus I don't know how to proceed (the official documentation assumes too much previous knowledge for me). Is there any \"novice\" documentation that I can look in order to add IsNan custom operation to TFLite ?", "@javirk: I have the same issue as you do. Do you find any solution for transferring pix2pix GAN to tf lite model? Thank you so much!", "@javirk One way is to use TF SELECT which will fallback to TF kernel for the missing TF ops \r\nhttps://www.tensorflow.org/lite/guide/ops_select\r\nAnother way is to write a TFLite custom op\r\nhttps://www.tensorflow.org/lite/guide/ops_custom\r\n\r\n", "I still have this problem.\r\nafter removing all bn layers output is still Nan!\r\nwhether on Cpu or Gpu! ", "Finally I solve the problem by quantizing deep model...\r\nprobably this problem appears on devices with low processing power\r\n(my dev is samsung A50)\r\nthis is the code:\r\nconverter = tf.lite.TFLiteConverter.from_keras_model(self.deep_model)\r\n            converter.optimizations = [tf.lite.Optimize.DEFAULT]\r\n            converter.target_spec.supported_ops = [\r\n                tf.lite.OpsSet.TFLITE_BUILTINS  # enable TensorFlow Lite ops.\r\n            ]\r\n            tflite_model = converter.convert()\r\n            open(\"converted_model.tflite\", \"wb\").write(tflite_model)"]}, {"number": 22802, "title": "Unable to download Android prebuilt binaries", "body": "Hi all!\r\n\r\nOn the README.md file at https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/android#android-tensorflow-support it is said that we can download prebuilt binaries for Android via https://ci.tensorflow.org/view/Nightly/job/nightly-android, but unfortunately this link is broken. \r\n\r\nIs there another way to get prebuilt binaries for Android?\r\n\r\nKindest regards.", "comments": ["@marcominerva This link is deprecated. There is an ongoing effort to get the Android builds back. You can refer to [20771](https://github.com/tensorflow/tensorflow/issues/20771). In the meantime, you can build your own Android project following this [tutorial](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/android/README.md). \r\n\r\nWill close this soon since it is a duplicate.", "you could use the aar package from here:\r\nhttps://bintray.com/google/tensorflow/tensorflow/1.13.0-rc0"]}, {"number": 22801, "title": "fix non_max_suppression_with_overlaps() function call", "body": "- add a simple unit test case", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_author_cla -->", "CLAs look good, thanks!\n\n<!-- ok -->", "seems like there is a lint error on my change.\r\nI'll update this PR tonight.", "Thanks for your review @rmlarsen \r\nI've updated this PR to fix lint errors and rebased against the latest master.", "@pclove1 Thanks!", "rebased to resolve a merge conflict"]}, {"number": 22800, "title": "Variance Inflation Factor estimate for each layer as guidance for dropout", "body": "Dear All,\r\n\r\nThe [arXiv paper](https://arxiv.org/pdf/1806.06850.pdf) makes the following useful suggestion:\r\n\r\n\"We thus believe it would be helpful for NN software to include layer-by-layer checks for multicollinearity. If a layer is found to output a higher degree of multicollinearity, one might consider reducing the number of units in it, or even eliminating it entirely. Applying dropout to such layers is another possible action. One related implication is that later NN layers possibly should have fewer units than the earlier ones\"\r\n\r\n(Please see Table 2 of the paper.)\r\n\r\nConcrete guidance on how to implement dropout remains a bit of a dark art. I don't think it needs to be. If we can produce VIF estimates for each layer, we can very possibly implement dropout with greater confidence. \r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Sure thing. \r\n\r\nHave I written custom code -- N/A\r\nOS Platform and Distribution -- N/A\r\nTensorFlow installed from -- N/A\r\nTensorFlow version-- N/A\r\nBazel version-- N/A\r\nCUDA/cuDNN version-- N/A\r\nGPU model and memory-- N/A\r\nExact command to reproduce-- N/A\r\nMobile device-- N/A\r\n", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n", "I see it as a feature request: provide VIF for each layer so that people can decide on the optimal number of hidden units in the previous layer or the dropout. But ok."]}, {"number": 22799, "title": "1.12-rc0 cherry-pick request: Mark tensorflow/contrib/tpu:datasets_test flaky", "body": "It fails 1/1000 runs in OSS builds.\r\n\r\nPiperOrigin-RevId: 216050192", "comments": []}, {"number": 22798, "title": "Could TensorFlow read data from MySQL? If not, what's the right way to add the feature?", "body": "I wanted to write a training program that read data from MySQL.\r\n\r\nI found [tf.contrib.data.SqlDataset](https://www.tensorflow.org/api_docs/python/tf/contrib/data/SqlDataset), which seems reads from SQLite, but not other SQL DBMSes.\r\n\r\nI tried to see how if I can extend it to support MySQL. It seems that (please correct me if I am wrong): [`tf.contrib.data.SqlDataset`](https://github.com/tensorflow/tensorflow/blob/b72265dc002e712fc3d0f33434f13c7a36a484b2/tensorflow/contrib/data/python/ops/readers.py#L363) uses `class SqlDatasetOp`, which uses [SQL drivers in the directory](https://github.com/tensorflow/tensorflow/tree/ad5c0c4d091c93ef65e91c55cb4df065d0c7a989/tensorflow/core/kernels/data/sql), and it seems that I can extend `SqlDatasetOp` by adding the MySQL connection driver as `mysql_query_connection.{h,cc}` in the directory.  However, this would require me to add MySQL libraries as TensorFlow dependencies in [`tensorflow/core/lib/db/BUILD`](https://github.com/tensorflow/tensorflow/blob/ad5c0c4d091c93ef65e91c55cb4df065d0c7a989/tensorflow/core/lib/db/BUILD); thus makes the TensorFlow binary depends on too many external staff. Is such kind of contributions welcome by the community?\r\n\r\nI also noticed that the [Hadoop sequence file dataset](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/hadoop) is in the `contrib` directory. Is this the recommended way to adding datasets?\r\n\r\nThanks!\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "This question is better asked on [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a bug or feature request. There is also a larger community that reads questions there.\r\n\r\nIf you think we've misinterpreted a bug, please comment again with a clear explanation, as well as all of the information requested in the [issue template](https://github.com/tensorflow/tensorflow/issues/new). Thanks!\r\n"]}, {"number": 22797, "title": "Add soversion to libraries", "body": "Add version to library sonames\r\n\r\nPreviously the libs were just \"libtensorflow.so\" without any version.\r\nThis adds the version to the library (eg libtensorflow.so.1.13.0) and\r\nadds the appropriate symlinks to the full name from the base and\r\nsoversion.\r\n\r\nThe soname is used by compilers to fill in the DT_NEEDED section in the\r\nheader of binaries that link to the library. Having the version means\r\nthat different versions of the library are able to co-exist and if the\r\nABI changes, programs linking to the lib do not break.\r\n\r\nFor more info see:\r\nhttps://www.debian.org/doc/debian-policy/ch-sharedlibs.html\r\nhttps://autotools.io/libtool/version.html\r\n\r\nSigned-off-by: Jason Zaman <jason@perfinion.com>\r\n", "comments": ["@perfinion : Thanks for the PR, but could you elaborate a bit on this? When building from source we'll always only have a single shared library, not a versioned one. So perhaps what you want is for this versioning to be done in the binary distributions rather than by changes to the BUILD rules?\r\n\r\nOr am I missing something?", "@asimshankar Sorry, the background is at https://groups.google.com/a/tensorflow.org/forum/#!topic/build/0FjOGrinf5k I should have linked that in the beginning.\r\nbasically the version needs to be put in the .so file when building. right now the soname is just \"libtensorflow.so\" so it cant be versioned later. the soname needs to be set and also requires the symlinks so the other bits of the build work.", "@asimshankar, @perfinion mentioned the other day that this naming setup was working for everything but Java. Could you take another look at it? (@perfinion, can you describe what you're doing again, like you did in the SIG Build meeting?)", "A summary of the reasons for this change:\r\n\r\nDistros are quite strict about versioning the libraries properly so that binary compatibility is easy. Whenever a library makes a breaking change the verison in the library is supposed to change accordingly, then other binaries will link to those specific versions. Lets take nsync as a specific example.\r\n\r\n```\r\n$ ls -al /usr/lib64/libnsync*\r\nlrwxrwxrwx. 1 root root    13 Sep 21 01:58 /usr/lib64/libnsync.so -> libnsync.so.1*\r\nlrwxrwxrwx. 1 root root    18 Sep 21 01:58 /usr/lib64/libnsync.so.1 -> libnsync.so.1.20.1*\r\n-rwxr-xr-x. 1 root root 42856 Sep 21 01:58 /usr/lib64/libnsync.so.1.20.1*\r\nlrwxrwxrwx. 1 root root    17 Sep 21 01:58 /usr/lib64/libnsync_cpp.so -> libnsync_cpp.so.1*\r\nlrwxrwxrwx. 1 root root    22 Sep 21 01:58 /usr/lib64/libnsync_cpp.so.1 -> libnsync_cpp.so.1.20.1*\r\n-rwxr-xr-x. 1 root root 51144 Sep 21 01:58 /usr/lib64/libnsync_cpp.so.1.20.1*\r\n$ scanelf -ByF '%S %p' /usr/lib64/libnsync*1.20.1\r\nlibnsync.so.1 /usr/lib64/libnsync.so.1.20.1\r\nlibnsync_cpp.so.1 /usr/lib64/libnsync_cpp.so.1.20.1\r\n```\r\n\r\nwhen building a program that uses nsync, you'd build with `gcc foo.c -lnsync` then the compiler would look for libnsync.so, follow the symlink and link with that, then it will take the soname that is embedded in the library and put that in the NEEDED. So now when nsync releases a 2.0.0 version the lib will update the version and libnsync.so.2.0.0 will exist and the symlinks will point to that instead. libnsync.so.1 will still link to libnsync.so.1.20.1. This means both libnsync.so.1 and libnsync.so.2 can be installed at the same time and any existing binaries that link with the old one will keep working just fine and new compiled binaries will use the new one. More info from debian is here: https://www.debian.org/doc/debian-policy/ch-sharedlibs.html but the idea is exactly the same on all distros.\r\n\r\nThe linking is like this, notice the .1 that its using.\r\n```\r\n$ ldd /usr/lib64/libtensorflow_framework.so \r\n[ ... snip ... ]\r\n\tlibnsync_cpp.so.1 => /usr/lib64/libnsync_cpp.so.1 (0x00007f7e751e2000)\r\n```\r\n\r\nBazel does not really understand these versioning things so I've used a bunch of genrules to make the symlinks and they work well for all the C++ and go stuff. java is the bit that isn't linking quite right to them. or rather, it is linking to them properly, but later fails because it needs the lib itself and the symlink but only has one.\r\n\r\n", "Asim has left the company, and @sjamesr is the new owner for the Java releases -- maybe he can help with the breakages.", "Hi there, I looked at this a couple of days ago and couldn't reproduce the failures. I'll take another shot at it again today.", "@sjamesr hey, thanks for looking into this! yeah, I rebased and tried recently too and the java tests pass on my machine. I'm not sure what changed to make it work now tho. The tests still appear to be failing on some of the builders (but not all, so it clearly sometimes works?). I've been playing around with building with the remote execution in a container to see if that'll help find the error but not gotten that going yet. Do let me know if you find how to repro the issues :)", "I managed to get the java tests to fail using RBE. The targets all build properly, just the tests fail at runtime. Hopefully i'll figure out how to make them run now.", "@angersson @sjamesr It should pass java and go tests now. RBE is a lot stricter so I could track things down. Basically added tf_binary_additional_srcs() to data= and a few places like that so It was properly in the deps. The symlink is not a proper library according to bazel so it can't be put in srcs= or deps= like normal but data= followed the same pattern as several other libs.\r\n\r\nI'm seeing a failure of the tests in `//tensorflow/lite/testing/...` but those appear turned off in at least some of the CI bots so not sure if they are known bad?", "The mac builds fail weirdly, I'm not sure why. The linker commandline contains `-l:libtensorflow_framework.so` but it should be `-ltensorflow_framework`. It's probably looking for a file named `lib:libtensorflow_framework.so.1`? I'm not sure what rule is adding that tho. I tried a few updates \r\n\r\nI tried adding `tf_binary_additional_srcs()` in a few more places but its not making a difference?\r\nOnce this is figured out, I'll re-test and remove the random hacks before its merged.\r\n\r\nThe error is for mac is:\r\n```clang: warning: argument unused during compilation: '-pthread' [-Wunused-command-line-argument]\r\nld: library not found for -l:libtensorflow_framework.so.1\r\nclang: error: linker command failed with exit code 1 (use -v to see invocation)```\r\n", "@klimek Can you take a look at this when you have a chance? Linux builds pass on my machine and remotely. one of the windows builders passes too but MacOS is failing hard. I tried on a mac locally and changing `tf_binary_additional_srcs()` to `[\"//tensorflow:libtensorflow_framework.so\"]` (ie without the .1 suffix) made it build but it still fails on the CI. (look at the previous force-pushed change for the diff)\r\n\r\nWe really have to fix the library versioning, lots of distros dont like un-versioned libs and I definitely want this in soon because TF2.0 is starting to take shape.\r\n\r\n@meteorcloudy you made some changes to `tf_cc_shared_object` recently, can you take a look too?", "@r4nt ", "@meteorcloudy \r\nI skip the versioning for .dlls now. lets see if the builders pass on windows. Also do you have any insight for the OSX build?", "@perfinion Looks good, but I'm not quite sure how versioned dynamic library work on macOS.\r\n\r\nA quick search: https://docstore.mik.ua/orelly/unix3/mac/ch05_04.htm", "@meteorcloudy yeah, I'd found that page, OSX works basically the same way as linux just with different filename order, the version before the .dylib. It would be possible to disable the versioning on OSX but I dont like that idea unless we really really have to.\r\n\r\nI could repro the `-l:libtensorflow_framework.so.1` breakage on my mac. It probably has something to do with libtensorflow.so.1 being a symlink? if i change things to just .so without the .1 then I can get it to build on my mac but the CI bots go crazy.", "Tests finally all pass. Looks like some of the GPU builders are failing but I cant see the details.\r\nTo fix the macos builds I had to turn on the per_os libs for libtensorflow_framework too. `-l:libtensorflow_framework.so.1` is not allowed on mac, it only allows `-l:libtensorflow_framework.1.dylib`.\r\n\r\n@r4nt @meteorcloudy @gunan @angersson Can you review it again and see if its ready to merge?", "I made a tf_shared_library_deps() to make the go change cleaner. It returns the os-specific name for libtensorflow.so and all the version symlinks. looks like the tests are okay so should be all good to go."]}, {"number": 22796, "title": "systemlibs: unbundle icu", "body": "This uses the same TF_SYSTEM_LIBS method as all the other libs", "comments": ["icu now is the source of conflicts in tensorflow c++ bazel builds (Windows) like tf_tutorials_example_trainer. Errors like \"unresolved icu_62::ErrorCodes\" and etc."]}, {"number": 22795, "title": "System freezes after decreasing batch size when using CuDNNLSTM", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 18.04\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: No\r\n- **TensorFlow installed from (source or binary)**: Yes (conda)\r\n- **TensorFlow version (use command below)**: 1.10.0\r\n- **Python version**: 3.6.6\r\n- **Bazel version (if compiling from source)**: \r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**: 10.0, V10.0.130\r\n- **GPU model and memory**: GeForce GTX 1070 \r\n- **Exact command to reproduce**:\r\n\r\n### Describe the problem\r\nWhile executing rather simple model in Keras/TensorFlow with three `keras.layers.CuDNNLSTM` layers, some skip connections, `Embedding` and `Dense` layers with <10 GB data read from numpy arrays, my system has frozen after using smaller batch size. When using batches of size 512 or larger everything was fine, when decreasing it to 256 system freezes (still screen, mouse and keyboard non responsive) after just a few dozen of iterations (not epochs). This happened several times in a row, with no single success, so I stopped experimenting further. Once I waited for 10 minutes to see if anything changes, but with no success. Everything went fine when using smaller batches and regular `keras.layers.LSTM` layers. Additionally, I used `nvidia-smi` and `top` monitoring tools and didn't notice anything strange before the crashes, but I might have missed something because of screen freezes. RAM and GPU usage in seconds before crushes was fine, far from limits.", "comments": ["@twolodzko This is likely triggered by the memory limitation since your data size is significant (<10 GB) and you are reading from numpy arrays. Try to stay with batch size of 512 or increase RAM, also optimize how you feed the data.", "@wt-huang thanks, but how using smaller batches needs more RAM?", "@twolodzko When the batch size is smaller, dataset becomes bigger causing GPU resource hungry hence more RAM is needed.", "@wt-huang thanks, nice to learn something new. Nevertheless, the fact that system freezes (rather then app dies) seems to be a kind of bug, isn't it?", "@twolodzko gladly. System freeze or lockup doesn't necessarily contitute a bug as there may be other cofounding factors in the mix. However, if a problem is observed consistently in systems across the board then it is a bug. We could potentially add warnings and messages after conducting some pre-checks.\r\n\r\n\r\n", "Closing this, feel free to reopen if problem persists."]}, {"number": 22794, "title": "Win10: ImportError: DLL load failed: The specified module could not be found", "body": "### System information:\r\nHave I written custom code: No\r\nOS Platform and Distribution: Windows 10 Pro updated\r\nMobile device: None\r\nTensorFlow installed from: pip install\r\nTensorFlow version:  1.11.0\r\nPython Version: 3.6.6\r\nBazel version: not installed\r\nCUDA/cuDNN version: CUDA 9.0, cuDNN 8.0\r\nGPU model and memory: GF-GTX970 STRIX\r\nExact command to reproduce:\r\npip install tensorflow\r\npip install tensorflow-gpu\r\npython\r\nimport tensorflow as tf\r\n\r\n### Problem\r\nI have had this error consistently even after trying to downgrade to older versions of CUDA tool, cuDNN, python, tensorflow and tensorflow-gpu. I have updated my enviornment variables. I have installed Visual C++ Redistributable Update.\r\nI have read and tried to follow the solutions from other similar issues (such as #10033 and #17101), but have not succeeded in fixing the problem. \r\n\r\n### Log\r\nC:\\Users\\user>python\r\nPython 3.6.6 (v3.6.6:4cf1f54eb7, Jun 27 2018, 03:37:03) [MSC v.1900 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n <> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 22, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nMobile device", "> Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\r\n> Mobile device\r\n\r\nOk done.", "I had the same issue while trying to use tensorflow-gpu on windows 10.\r\nSince i couldn't get it to work on cuDNN10..i opted for 9 instead using...\r\n\r\n>conda create --name tf-gpu\r\n>conda install -c aaronzs tensorflow-gpu\r\n>conda install -c anaconda cudatoolkit\r\n>conda install -c anaconda cudnn\r\n>conda install keras-gpu\r\n\r\nyou can also check the fullpost on https://www.pugetsystems.com/labs/hpc/The-Best-Way-to-Install-TensorFlow-with-GPU-Support-on-Windows-10-Without-Installing-CUDA-1187/\r\n\r\nCredit to Dr Donald Kinghorn", "I have same problem with you @damcclane . How did you solve ?\r\n\r\nWin10 x64, python 3.6, cuda9 with cudnn 7.0.5 and also Win10 x64, python 3.7, cuda10 with cudnn 7.3.1\r\n\r\nBoth has the same problem. My graphic card is Nvidia GeForce 1050 Ti", "Same issue. Win10 x64, python 3.5, tensorflow-gpu 1.11.0, CUDA 8 with CUDNN 6 installed.", "Same problem,Win10 x64,python 3.6 ,cuda 9 with cudnn 7.0", "Same problem, anyone knows how to solve this?", "Same problem here\u2026 :(", "I've had this issue in the past and it was because I had the wrong version of CUDNN. You could try downloading a few of them and see if any of those work.", "I would like to encourage all who are facing this issue to create a new issue on [TensorFlow repo](https://github.com/tensorflow/tensorflow/issues/new) so that we can focus on solving your problem on individual basis since the system config can vary from person to person. Thanks!", "Fixed, Thenks!\n\nOn Wed, Oct 17, 2018 at 10:39 AM Corentin Jemine <notifications@github.com>\nwrote:\n\n> I've had this issue in the past and it was because I had the wrong version\n> of CUDNN. You could try downloading a few of them and see if any of those\n> work.\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/22794#issuecomment-430676267>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AYfA4TRxTaZ7pKfyszlWqPGknt_ohvlaks5ul082gaJpZM4XLOd->\n> .\n>\n", "I installed CUDA9 and cuDNN 7.0.5 again and restarted the computer. The related problem has just gone.", "I am using Cuda10 and cudaNN 7.3.1.20 and i got the following error can someone tell the solution @tensorflowbutler \r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Darshan\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Darshan\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Darshan\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Darshan\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Darshan\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\Darshan\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 22, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\Darshan\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Darshan\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Darshan\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Darshan\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Darshan\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Darshan\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Darshan\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.", "Same issue, Windows 10 x64, python3.5, tensorflow-gpu 1.11.0, CUDA 10.0, cudnn 7.3.1, my graphics card is  GTX 1070Ti", "@iteratorlee \r\n> I would like to encourage all who are facing this issue to create a new issue on [TensorFlow repo](https://github.com/tensorflow/tensorflow/issues/new/choose) so that we can focus on solving your problem on individual basis since the system config can vary from person to person. Thanks!\r\n\r\n", "Same problem, on cuda 10, when I install anaconda I have missed the PyHamcrest, after I install \"pip install PyHamcrest\" all worked fine until today. I get the same error.  ", "I am facing the same issues. The problem appears also in importing another package named PyQSTEM for electron microscopy simulation. If someone can find a way to fix the problem, could please share here the solution? Thanks\r\n", "> Same issue, Windows 10 x64, python3.5, tensorflow-gpu 1.11.0, CUDA 10.0, cudnn 7.3.1, my graphics card is GTX 1070Ti\r\n\r\nSame issue, and I tried to install CUDA 9.0, but NVIDIA inform me the driver is not compatible graphic hardware, but with CUDA 10.0, there is no such warning.", "Lucky, Issue solved when getting visual studio 2017 with C++ package installed, Windows 10 x64, python3.6.7, tensorflow-gpu 1.11.0, cudnn 7.3.1, both cuda 9.0 & cuda 10.0  installed(not checking which is the right one), my graphics card is GTX 1070Ti.", "I finally solve the problem by installing cuda 9.0 instead of 9.2 or 10.0 with tensorflow 1.12.0 and cudnn 7.4.1.5", "I can confirm, that the following assembly does not work on Windows 10:\r\n\r\n* tensorflow 1.12.0\r\n* cuda toolkit 10.0.130\r\n* cudnn 7.4.1.5\r\n\r\nAdditional infos:\r\n\r\n* NVIDIA Quadro P1000 with NVIDIA driver 411.81\r\n* Microsoft Visual C++ 2015 Redistributable 14.0.24215 (``C:\\Windows\\system32\\msvcp140.dll`` exists)\r\n* Python 3.6.7\r\n\r\nI also get the message\r\n\r\n> ImportError: DLL load failed: The specified module could not be found.\r\n\r\nUnfortunately, it does not say which module is missed.\r\n\r\n[EDIT]\r\n\r\nJust realized, that you write:\r\n\r\n> TensorFlow supports CUDA 9.0. \r\n\r\nI'll reinstall now.\r\n", "Traceback (most recent call last):\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: %1 is not a valid Win32 application.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\ABC\\Desktop\\pyprograms\\tensorflowbasic\\1.py\", line 1, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Program Files\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Program Files\\Python36\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: %1 is not a valid Win32 application.", "My install:\r\n\r\nWindows 10.0.17763.134 x64\r\nNVIDIA Driver 416.92\r\nCUDA 10.0.130\r\nCUDNN 7.4.1.5 for CUDA 10.0\r\nPython 3.6.7\r\nGeForce GTX 1080 Ti\r\n\r\nThe cause of this error seems to be people installing Python without Tcl/Tk support not realizing that Tcl is necessary for SWIG and module imports. I just tested this and in my case it was not enough to modify the Python installation to add Tcl/Tk -- I had to delete everything and install from scratch and now I am not getting the error anymore.\r\n\r\nTL;DR -- just fully remove and reinstall Python with Tcl/Tk option selected.", "After spending almost two days, I finally solved the problem by installing:\r\n\r\n- cuda 9.0 instead of 9.2 or 10.0 \r\n- tensorflow1.12.0 \r\n- cudnn 7.4.1.5\r\n\r\nThanks to @WuYunfan \ud83d\udcaf ", "First I install \r\n- CUDA 10.0\r\n- cudnn 7.3\r\n- tensorflow 1.12.0\r\n\r\nand I got this error.\r\nThen I uninstall tf 1.12 and install tf 1.10 . It ask me for cudart64.dll. I add it into path and tf works.\r\nThen I reinstall tf 1.12 and all works well.", "TensorFlow supports CUDA 9.0", "@ljzsky While it is true that TensorFlow will officially support CUDA 10.0 from version 1.13, TensorFlow 1.12 can be (and has been) built against CUDA 10.0 and it works with it just fine.", "@linsui What you say makes absolutely no sense. TensorFlow is a library which has no means to ask you for cudart64.dll.", "@levicki I don't know why but tf1.10 shows different message from tf1.11 and tf1.12.", "l got this problem\r\nTraceback (most recent call last):\r\n  File \"C:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\anaconda\\envs\\tensorflow\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\anaconda\\envs\\tensorflow\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\anaconda\\envs\\tensorflow\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\anaconda\\envs\\tensorflow\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\nFailed to load the native TensorFlow runtime.\r\n\r\nplease can someone tell me how to solve this problem? \r\n\r\n", "@thischeng \r\nThis is not a support forum, this is a place where issues are reported along with enough information for developers to reproduce them, and if they turn out to be an actual issue in the tensorflow code they will be fixed in one of the future releases.\r\n\r\nIt seems that you have not even bothered to read this thread, because there are several workarounds posted above including mine.\r\n\r\nFinally, asking for help without specifying full hardware and software configuration and without listing what steps you have taken so far to try to solve the issue on your own is rude to say the least.", "@levicki \r\nthank you for you criticism , i did' t see it clearly, next time i will pay attention to my way of asking questions.", "I encountered the same issue. My configuration is:\r\n\r\n- CUDA Toolkit v9.0 (installed without Visual Studio support)\r\n- Tensorflow-gpu v 1.12.0 (installed with pip)\r\n- cudnn v7.4.1.5 CUDA v9.0 compatible.\r\n- nVidia GeForce 1070\r\n- Windows 10 Home\r\n\r\nAfter spending almost a day figuring out why tensorflow did not find the correct dll file, I found a guide on how to install cudnn that, by the way, is not as simple as it seems. The guide is written by nVidia and here you are the actions I follow. \r\n\r\n1. Download from nVidia official site, the correct cudnn version for your configuration.\r\n2. Then extract cuda folder, it does not matter where you extract it.\r\n3. Open File Explorer and go to the directory where you installed CUDA, in my case that was C:/Program Files/NVIDIA GPU Computing Toolkit.\r\n4. Go to CUDA/v9.0/lib/x64. Here you have to put the file named \"cudnn.lib\" that you can find inside CUDA/lib/x64 (cudnn package, downloaded from nVidia)\r\n5. Repeat the process for (left cudnn package, right CUDA installation path): \r\n- CUDA/bin/cudnn64_7.dll -> CUDA/v9.0/bin\r\n- CUDA/include/cudnn.h    -> CUDA/v9.0/include\r\n6. Now you have to check if the environment variable is set correctly. Be sure CUDA_PATH variable, with C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0 value is present, if not add it.\r\n7. Enjoy tensorflow-gpu working on your system", "> I encountered the same issue. My configuration is:\r\n> \r\n> * CUDA Toolkit v9.0 (installed without Visual Studio support)\r\n> * Tensorflow-gpu v 1.12.0 (installed with pip)\r\n> * cudnn v7.4.1.5 CUDA v9.0 compatible.\r\n> * nVidia GeForce 1070\r\n> * Windows 10 Home\r\n> \r\n> After spending almost a day figuring out why tensorflow did not find the correct dll file, I found a guide on how to install cudnn that, by the way, is not as simple as it seems. The guide is written by nVidia and here you are the actions I follow.\r\n> \r\n> 1. Download from nVidia official site, the correct cudnn version for your configuration.\r\n> 2. Then extract cuda folder, it does not matter where you extract it.\r\n> 3. Open File Explorer and go to the directory where you installed CUDA, in my case that was C:/Program Files/NVIDIA GPU Computing Toolkit.\r\n> 4. Go to CUDA/v9.0/lib/x64. Here you have to put the file named \"cudnn.lib\" that you can find inside CUDA/lib/x64 (cudnn package, downloaded from nVidia)\r\n> 5. Repeat the process for (left cudnn package, right CUDA installation path):\r\n> \r\n> * CUDA/bin/cudnn64_7.dll -> CUDA/v9.0/bin\r\n> * CUDA/include/cudnn.h    -> CUDA/v9.0/include\r\n> \r\n> 1. Now you have to check if the environment variable is set correctly. Be sure CUDA_PATH variable, with C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0 value is present, if not add it.\r\n> 2. Enjoy tensorflow-gpu working on your system\r\n\r\nThank you! that solved my problem! \r\nMy system:\r\nwindows 10\r\npython 3.6\r\nCuda Toolkit v9.0\r\ncudnn 7.4.2\r\nGraphics card: Nvidia p4000\r\n\r\nAfter uninstalling v10 and its associated cudnn and then installing the above mentioned and then following the tutorial from (andpi314)\r\nTensor Flow GPU up and running.\r\n", "This is my situation, check the cudnn's copy &paste\uff0c make sure bin,include,lib, the file of the three folders are copying and pasting to the same path of the cuda, i just copy to the wrong path ,after checking the system path of cuda ,do the copy &paste again,then it runs correctly.", "Traceback (most recent call last):\r\n  File \"C:\\Users\\SPECTRE\\Anaconda3\\envs\\tfpose\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\SPECTRE\\Anaconda3\\envs\\tfpose\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\SPECTRE\\Anaconda3\\envs\\tfpose\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\SPECTRE\\Anaconda3\\envs\\tfpose\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\SPECTRE\\Anaconda3\\envs\\tfpose\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\SPECTRE\\Anaconda3\\envs\\tfpose\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\SPECTRE\\Anaconda3\\envs\\tfpose\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\SPECTRE\\Anaconda3\\envs\\tfpose\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\SPECTRE\\Anaconda3\\envs\\tfpose\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\SPECTRE\\Anaconda3\\envs\\tfpose\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\SPECTRE\\Anaconda3\\envs\\tfpose\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\SPECTRE\\Anaconda3\\envs\\tfpose\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\SPECTRE\\Anaconda3\\envs\\tfpose\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.", "I met the same situation and my config is: \r\nCUDA10\r\ncudnn v7.4 for CUDA10\r\nTensorflow-gpu v1.12.0\r\n\r\nI see the solutions above that suggest the CUDA9, but the information in my GeForce Controler shows my GPU GTX1050Ti only supports CUDA10(it writes \"NVIDIA CUDA 10.0.132 driver\", actually I don't know what it means), how can I resolve this?", "> I installed CUDA9 and cuDNN 7.0.5 again and restarted the computer. The related problem has just gone.\r\n\r\n@Asichurter I have the same graphic card and have no problem with above combination.", "**SOLUTION**! If you're trying to run TF with CUDA 10\r\n\r\nTensorflow 1.12 DOES NOT support CUDA 10 but nightly build DOES\r\n\r\nThere are 2 solutions\r\n1. Remove TF 1.12 and install nightly build 1.13\r\npip uninstall tensorflow-gpu\r\npip install tf-nightly-gpu\r\n\r\nAlternative solution: Downgrade CUDA to 9.0\r\n\r\nRemember about copying CUDNN files to right location in CUDA installation folder every time when reinstalling", "I had the same problems, and tried most of the proposed fixes for about 3 hours with no luck.  However I found the post by kennedyCzar at the top - and this fixed my issue (\"ImportError: DLL load failed: The specified module could not be found.\")  I highly encourage readers to try this approach as it is fast and easy.  I specifically went to the referenced blog post by Dr. Donald Kinghorn and followed the instructions.\r\n\r\nSee below for copy of kennedyCzar's post from Oct 16, 2018:\r\n\r\n> \r\n> \r\n> I had the same issue while trying to use tensorflow-gpu on windows 10.\r\n> Since i couldn't get it to work on cuDNN10..i opted for 9 instead using...\r\n> \r\n> > conda create --name tf-gpu\r\n> > conda install -c aaronzs tensorflow-gpu\r\n> > conda install -c anaconda cudatoolkit\r\n> > conda install -c anaconda cudnn\r\n> > conda install keras-gpu\r\n> \r\n> you can also check the fullpost on https://www.pugetsystems.com/labs/hpc/The-Best-Way-to-Install-TensorFlow-with-GPU-Support-on-Windows-10-Without-Installing-CUDA-1187/\r\n> \r\n> Credit to Dr Donald Kinghorn\r\n\r\n", "I had CUDA 10 running with tensorflow-gpu v1.12. I didn't read the small prints and thus missed that this version didnt work with CUDA 10. Downgraded to CUDA 9 and it works now.", "I had the same issue with TensorFlow 1.12.0 and none of the solutions worked for me. Then I downgraded to TensorFlow 1.10.0 and this time the error message was much more informative. It told me that cudart64_90.dll could not be found which is located in `C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\bin`. After adding this specific path to the PATH variable, it run smoothly without errors.\r\n\r\nThis makes me wonder if there is a bug in TensorFlow so that it fails to navigate to the \"bin\" subfolder itself given that `C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0` is already present in numerous environment variables like CUDA and CUDA_HOME, so it should be able to find it.\r\n\r\nSecondly, it makes me wonder why TensorFlow 1.12.0 has so much less informative error messages. In 1.12.0 it just says that some DLL could not be imported. In 1.10.0 it showed me exactly which DLL is missing and even proposed the working solution to add it to PATH. This is a way better error handling and I suggest that you revisit the commit from the person who thought obscuring error messages was a good idea.", "> **SOLUTION**! If you're trying to run TF with CUDA 10\r\n> \r\n> Tensorflow 1.12 DOES NOT support CUDA 10 but nightly build DOES\r\n> \r\n> There are 2 solutions\r\n> \r\n> 1. Remove TF 1.12 and install nightly build 1.13\r\n>    pip uninstall tensorflow-gpu\r\n>    pip install tf-nightly-gpu\r\n> \r\n> Alternative solution: Downgrade CUDA to 9.0\r\n> \r\n> Remember about copying CUDNN files to right location in CUDA installation folder every time when reinstalling\r\n\r\n**confirm this solution**\r\n\r\nuse tf-nightly-gpu\r\nwin10\r\ncuda 10.0\r\npython 3.6.4\r\ngeforce 960M\r\ncudnn64_7", "> I finally solve the problem by installing cuda 9.0 instead of 9.2 or 10.0 with tensorflow 1.12.0 and cudnn 7.4.1.5\r\n\r\nbut i download the cudnn7.4.1.5 instead of cudnn7.0.5 still encounter this error.\r\nmy configuration following:\r\ncuda 9.0\r\ncudnn7.4.1\r\npip install tensorflow-gpu==1.12.0\r\npython 3.6.4\r\nnvidia geforce 1080TI\r\n", "> > I finally solve the problem by installing cuda 9.0 instead of 9.2 or 10.0 with tensorflow 1.12.0 and cudnn 7.4.1.5\r\n> \r\n> but i download the cudnn7.4.1.5 instead of cudnn7.0.5 still encounter this error.\r\n> my configuration following:\r\n> cuda 9.0\r\n> cudnn7.4.1\r\n> pip install tensorflow-gpu==1.12.0\r\n> python 3.6.4\r\n> nvidia geforce 1080TI\r\n\r\nFinal i downgrade the bazel version to 0.20.0 (from 0.21.0) solve this issue. but i don't know why can't compatible for lastst bazel version.", "cuda 10.0\r\ncudnn7.4.2\r\npip install tf-nightly-gpu\r\npython 3.6.4\r\nnvidia geforce 1070\r\n\r\nit works.", ">cuda 10.0\r\ncudnn7.4.2\r\npip install tf-nightly-gpu\r\npython 3.6.4\r\nnvidia geforce 1070\r\n\r\n>it works.\r\n\r\nIt is working for me now as well. Thanks for it.\r\nJust a note: I was unable to properly uninstall TF and had a lower Python version. I uninstalled Python completely and installed version 3.6.8 instead of 3.6.4.\r\nThen used `pip install tf-nightly-gpu` to install TF and is working now", "Installation of Microsoft Build Tools 2015 helps me with this issue. It works now.", "> I have same problem with you @damcclane . How did you solve ?\r\n> \r\n> Win10 x64, python 3.6, cuda9 with cudnn 7.0.5 and also Win10 x64, python 3.7, cuda10 with cudnn 7.3.1\r\n> \r\n> Both has the same problem. My graphic card is Nvidia GeForce 1050 Ti\r\n\r\ntensorflow doesn't support python 3.7 you can create a different environment with lower python through anaconda", "I had the exact same issue. According to the [GPU Support Guide](https://www.tensorflow.org/install/gpu), I have all the correct versions of CUDA and cuDNN installed - CUDA 9.0 and cuDNN 7.4.2.24.\r\n\r\nWhat ended up working for me was entering the following commands after installing all the dependencies:\r\n\r\n```\r\nSET PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\bin;%PATH%\r\nSET PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\extras\\CUPTI\\libx64;%PATH%\r\nSET PATH=C:\\tools\\cuda\\bin;%PATH%\r\n```\r\nThe `cuda` folder from your cuDNN zip must be copied to `C:\\tools\\`.\r\n\r\nHope this was helpful.", "i am also see the same issue\r\n", "Hi guys, I've seen this problem a few times now and can comment on a few things.\r\nFirst of which seems to be that Jupyter notebooks can sort of \"hold on\" to a bad tensorflow configuration (even after resetting the kernel) a full stop and start of the Jupyter solved this for me at least once.\r\n\r\nThe other things are all related to CUDA. I HIGHLY recommend that you just uninstall all version of CUDA, then install V10, and make sure to get the correct cudnn too.\r\n\r\nTo install Cudnn, just copy and paste everything in the cuda folder, over into your cuda install.\r\n\r\nThese are basically all the issues with this error. Remember you can test cuda by typing `nvcc --version` and making sure it returns v10. If this command doesn't work, then it means your setup cannot see cuda properly.\r\n\r\n", "if you see the issue , you cloud try install tf-nightly.this way can solve you issue", "### **### The SOLUTION for \"ImportError: DLL load failed: The specified procedure could not be found.\"**\r\n\r\nWhen you import numpy you get this error, right? \r\n`python -c \"import numpy\"`\r\n\r\nSo go to the Anaconda folder and go to site-packages folder according to the environment of anaconda.  Then go to numpy\\.libs folder. There are *.dll file, right?\r\n\r\nNow copy the link to the .libs folder and enter the path with \"PATH\" in anaconda prompt. \r\n`PATH=path\\to\\site-packages\\numpy\\.libs;%PATH%`\r\n\r\nNow check again to import numpy.\r\n`python -c \"import numpy\"`\r\n\r\nNow it is working right? ", "Installation:\r\n\r\n```\r\n(base) C:\\Users\\omarc>pip install tensorflow-gpu\r\nCollecting tensorflow-gpu\r\n  Downloading https://files.pythonhosted.org/packages/1f/31/62178ec117dc0318bde6e3b4f2a066a2ea637cc806ff53cb26e36974280a/tensorflow_gpu-1.13.0rc2-cp37-cp37m-win_amd64.whl (259.8MB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 259.8MB 17kB/s\r\nCollecting keras-applications>=1.0.6 (from tensorflow-gpu)\r\n  Downloading https://files.pythonhosted.org/packages/90/85/64c82949765cfb246bbdaf5aca2d55f400f792655927a017710a78445def/Keras_Applications-1.0.7-py2.py3-none-any.whl (51kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 61kB 3.6MB/s\r\nRequirement already satisfied: six>=1.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.12.0)\r\nCollecting absl-py>=0.1.6 (from tensorflow-gpu)\r\n  Downloading https://files.pythonhosted.org/packages/31/bc/ab68120d1d89ae23b694a55fe2aece2f91194313b71f9b05a80b32d3c24b/absl-py-0.7.0.tar.gz (96kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 102kB 9.3MB/s\r\nCollecting termcolor>=1.1.0 (from tensorflow-gpu)\r\n  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\r\nRequirement already satisfied: wheel>=0.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (0.32.3)\r\nCollecting astor>=0.6.0 (from tensorflow-gpu)\r\n  Downloading https://files.pythonhosted.org/packages/35/6b/11530768cac581a12952a2aad00e1526b89d242d0b9f59534ef6e6a1752f/astor-0.7.1-py2.py3-none-any.whl\r\nCollecting keras-preprocessing>=1.0.5 (from tensorflow-gpu)\r\n  Downloading https://files.pythonhosted.org/packages/c0/bf/0315ef6a9fd3fc2346e85b0ff1f5f83ca17073f2c31ac719ab2e4da0d4a3/Keras_Preprocessing-1.0.9-py2.py3-none-any.whl (59kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 61kB 7.7MB/s\r\nCollecting gast>=0.2.0 (from tensorflow-gpu)\r\n  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\r\nRequirement already satisfied: numpy>=1.13.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow-gpu) (1.15.4)\r\nCollecting tensorboard<1.13.0,>=1.12.0 (from tensorflow-gpu)\r\n  Downloading https://files.pythonhosted.org/packages/07/53/8d32ce9471c18f8d99028b7cef2e5b39ea8765bd7ef250ca05b490880971/tensorboard-1.12.2-py3-none-any.whl (3.0MB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3.1MB 3.9MB/s\r\nCollecting protobuf>=3.6.1 (from tensorflow-gpu)\r\n  Downloading https://files.pythonhosted.org/packages/77/78/a7f1ce761e2c738e209857175cd4f90a8562d1bde32868a8cd5290d58926/protobuf-3.6.1-py2.py3-none-any.whl (390kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 399kB 251kB/s\r\nCollecting tensorflow-estimator<1.14.0rc0,>=1.13.0rc0 (from tensorflow-gpu)\r\n  Downloading https://files.pythonhosted.org/packages/67/c1/3e8f58945f55769274e490d85df3bc4639ac258c60c6e3c6c7973d2a9e81/tensorflow_estimator-1.13.0rc0-py2.py3-none-any.whl (367kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 368kB 350kB/s\r\nCollecting grpcio>=1.8.6 (from tensorflow-gpu)\r\n  Downloading https://files.pythonhosted.org/packages/17/80/b135a60dfb12e9e0d691e4e66020b6f90fd8864e17ed5c719881bdea7d41/grpcio-1.18.0-cp37-cp37m-win_amd64.whl (1.5MB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1.5MB 2.3MB/s\r\nRequirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (from keras-applications>=1.0.6->tensorflow-gpu) (2.8.0)\r\nRequirement already satisfied: werkzeug>=0.11.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow-gpu) (0.14.1)\r\nCollecting markdown>=2.6.8 (from tensorboard<1.13.0,>=1.12.0->tensorflow-gpu)\r\n  Downloading https://files.pythonhosted.org/packages/7a/6b/5600647404ba15545ec37d2f7f58844d690baf2f81f3a60b862e48f29287/Markdown-3.0.1-py2.py3-none-any.whl (89kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 92kB 8.4MB/s\r\nRequirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from protobuf>=3.6.1->tensorflow-gpu) (40.6.3)\r\nCollecting mock>=2.0.0 (from tensorflow-estimator<1.14.0rc0,>=1.13.0rc0->tensorflow-gpu)\r\n  Downloading https://files.pythonhosted.org/packages/e6/35/f187bdf23be87092bd0f1200d43d23076cee4d0dec109f195173fd3ebc79/mock-2.0.0-py2.py3-none-any.whl (56kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 61kB 6.2MB/s\r\nCollecting pbr>=0.11 (from mock>=2.0.0->tensorflow-estimator<1.14.0rc0,>=1.13.0rc0->tensorflow-gpu)\r\n  Downloading https://files.pythonhosted.org/packages/8c/7f/fed53b379500fd889707d1f6e61c2a35e12f2de87396894aff89b017d1d6/pbr-5.1.2-py2.py3-none-any.whl (107kB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 112kB 10.5MB/s\r\nBuilding wheels for collected packages: absl-py, termcolor, gast\r\n  Running setup.py bdist_wheel for absl-py ... done\r\n  Stored in directory: C:\\Users\\omarc\\AppData\\Local\\pip\\Cache\\wheels\\90\\db\\f8\\2c3101f72ef1ad434e4662853174126ce30201a3e163dcbeca\r\n  Running setup.py bdist_wheel for termcolor ... done\r\n  Stored in directory: C:\\Users\\omarc\\AppData\\Local\\pip\\Cache\\wheels\\7c\\06\\54\\bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\r\n  Running setup.py bdist_wheel for gast ... done\r\n  Stored in directory: C:\\Users\\omarc\\AppData\\Local\\pip\\Cache\\wheels\\5c\\2e\\7e\\a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\r\nSuccessfully built absl-py termcolor gast\r\nInstalling collected packages: keras-applications, absl-py, termcolor, astor, keras-preprocessing, gast, grpcio, markdown, protobuf, tensorboard, pbr, mock, tensorflow-estimator, tensorflow-gpu\r\nSuccessfully installed absl-py-0.7.0 astor-0.7.1 gast-0.2.2 grpcio-1.18.0 keras-applications-1.0.7 keras-preprocessing-1.0.9 markdown-3.0.1 mock-2.0.0 pbr-5.1.2 protobuf-3.6.1 tensorboard-1.12.2 tensorflow-estimator-1.13.0rc0 tensorflow-gpu-1.13.0rc2 termcolor-1.1.0\r\n\r\n```\r\n\r\nOutput of some sample code:\r\n\r\n```\r\n\r\nC:\\ProgramData\\Anaconda3\\python.exe \"C:/Users/omarc/OneDrive - Massachusetts Institute of Technology/test_tensorflow/keras-master/examples/mnist_cnn.py\"\r\nUsing TensorFlow backend.\r\nTraceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:/Users/omarc/OneDrive - Massachusetts Institute of Technology/test_tensorflow/keras-master/examples/mnist_cnn.py\", line 9, in <module>\r\n    import keras\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\__init__.py\", line 3, in <module>\r\n    from . import utils\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\__init__.py\", line 6, in <module>\r\n    from . import conv_utils\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\conv_utils.py\", line 9, in <module>\r\n    from .. import backend as K\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\__init__.py\", line 89, in <module>\r\n    from .tensorflow_backend import *\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 5, in <module>\r\n    import tensorflow as tf\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\ProgramData\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n\r\nProcess finished with exit code 1\r\n```\r\n", "> pip install tensorflow-gpu==1.10.0\r\n\r\n Could not find a version that satisfies the requirement tensorflow-gpu==1.10.0 (from versions: 1.13.0rc1, 1.13.0rc2)\r\nNo matching distribution found for tensorflow-gpu==1.10.0", "> > pip install tensorflow-gpu==1.10.0\r\n> \r\n> Could not find a version that satisfies the requirement tensorflow-gpu==1.10.0 (from versions: 1.13.0rc1, 1.13.0rc2)\r\n> No matching distribution found for tensorflow-gpu==1.10.0\r\n\r\nIf you can't get an older version of tensorflow-gpu, I had the same dll issue while using CUDA 9.0 and tensorflow-gpu 1.13.0. Installed 10.0 and it seems to have solved the problem so far. Based on that, pretty sure 1.13.0 requires 10 instead of 9.", "> cuda 10.0\r\n> cudnn7.4.2\r\n> pip install tf-nightly-gpu\r\n> python 3.6.4\r\n> nvidia geforce 1070\r\n> \r\n> it works.\r\n\r\nSame here\r\npython 3.6.7\r\ngeforce 1060\r\n\r\nI had problems with numpy, so make sure to use numpy 1.16. I had to reinstall it from pip because Anaconda's version is outdated.", "have the same problem. I use non-gpu version TF, so I guess it is not a cuda or cudnn prblem?\r\npython 3.6.0\r\nTF 1.12.0\r\nnumpy 1.16.1\r\nprotobuf 3.6.1\r\n", "Don\u2019t use protobuf 3.6 that\u2019s probably the problem. I believe the latest you can use is 3.3 go to there github and find earlier versions.", "I am running something that uses TF 1.12, that requires protobuf 3.6.1. oh well....\r\n", "The problem is about **_version compatibility_**. It's about compatibility of **_tensorflow_**, **_python_**, **_cudnn_** and **_cuda_**. Version compatibility can be found on [this page](https://tensorflow.google.cn/install/source_windows). Take my computer for example. \r\n\r\n### System information:\r\nOS Platform and Distribution: Windows 10 (I don't think it matters.)\r\nMobile device: None\r\nTensorFlow installed from: pip install\r\n**TensorFlow version: 1.4.0** (**important**)\r\n**Python Version: 3.6**  (**important**)\r\nBazel version: not installed (I'm not compiling from source code, so I don't need it.)\r\n**CUDA/cuDNN version: cuda_8.0.61_win10.exe,  cudnn-8.0-windows10-x64-v6.0.zip** (**important**)\r\nGPU model : Geforce GTX Series  (I don't think it matters.)\r\n\r\n### Solution:\r\nBased on the version compatibility table in the above [page](https://tensorflow.google.cn/install/source_windows). This line \r\n\r\ntensorflow_gpu-1.4.0 | 3.5-3.6 | MSVC 2015 update 3 | Cmake v3.6.3 | 6 | 8\r\n-- | -- | -- | -- | -- | --\r\n\r\n\r\n\r\nI use **_python3.6_**.7 (Actually your version belongs to python3.6 Series is ok, because I tried python3.6.3 on the wrong version of other software .It has same error called \"ImportError: DLL load failed blablablabalbla...\". According the form in the Hyperlink, if you use python3.5 ,it should be ok.) \r\nI has installed **_cuda8.0_** and **_cudnnv6_**(When you unzip this zip, it contains the **_cudnn64_6.dll_** file. And you need put the cudnn64_6.dll in the right path ) (The number **8** in the last column is the number of CUDA versions. The number **6** in the fifth column is the number of cudnn versions)\r\nSO ,I **_pip install tensorflow-gpu==1.4.0_** and then **import tensorflow as tf** , it works.\r\n\r\nI found this problem because when I fixed the Python and CUDA and cudnn versions, installing the lower version of tensorflow prompted another error: the cudnn64_*. DLL file was not found.", "The following steps describe how to build a cuDNN dependent program. In the following sections:\r\nyour CUDA directory path is referred to as C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\r\nyour cuDNN directory path is referred to as <installpath>\r\nNavigate to your <installpath> directory containing cuDNN.\r\nUnzip the cuDNN package.\r\ncudnn-9.0-windows7-x64-v7.zip\r\nor\r\ncudnn-9.0-windows10-x64-v7.zip\r\nCopy the following files into the CUDA Toolkit directory.\r\nCopy <installpath>\\cuda\\bin\\cudnn64_7.dll to C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\bin.\r\nCopy <installpath>\\cuda\\ include\\cudnn.h to C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\include.\r\nCopy <installpath>\\cuda\\lib\\x64\\cudnn.lib to C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v9.0\\lib\\x64.\r\n\r\nThe document of cudnn give the right cudnn setup way, when I put this file into the specify location, it works\r\nThe full document can be found in [https://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html](url)", "This worked for me \r\nWindows 10 \r\npython 3.6.X  (downgraded from 3.7) \r\nTensorflow 1.12  (not working with 1.13.1 for sure, downgraded)\r\nCUDA/cudnn 9.0 (make sure follow @mxl1990 's step to copy those files) \r\n", "Thanks all the above. I am gonna try again soon", "I have the same question with the author,and i solve it now.\r\nwindow 10\r\npython 3.6.2\r\ngpu rtx2080\r\nmy problem is the version of CUDA and the cudnn does not fit each other.\r\n2019/3/3 today the newest version of CUDA is 10.1 but there isn't a corresponding version of cudnn.\r\nso i changed the CUDA 10.0 and reinstall the tensorflow,it works now!\r\n", "Ran into the same problem.\r\n\r\nIf you are using Anaconda (Python 3.6), highly suggest to use `conda` instead of `pip`. It usually takes care of EVERYTHING: `conda install tensorflow-gpu`\r\n\r\n```\r\n(base) C:\\Users>conda install tensorflow-gpu\r\nSolving environment: done\r\n\r\n## Package Plan ##\r\n\r\n  environment location: D:\\Software\\Anaconda3\r\n\r\n  added / updated specs:\r\n    - tensorflow-gpu\r\n\r\n\r\nThe following packages will be downloaded:\r\n\r\n    package                    |            build\r\n    ---------------------------|-----------------\r\n    cudnn-7.3.1                |        cuda9.0_0       170.9 MB\r\n    grpcio-1.12.1              |   py36h1a1b453_0         1.4 MB\r\n    tensorflow-base-1.12.0     |gpu_py36h6e53903_0       180.8 MB\r\n    conda-4.6.7                |           py36_0         1.7 MB\r\n    tensorflow-1.12.0          |gpu_py36ha5f9131_0           4 KB\r\n    keras-preprocessing-1.0.5  |           py36_0          52 KB\r\n    gast-0.2.2                 |           py36_0         138 KB\r\n    keras-applications-1.0.6   |           py36_0          49 KB\r\n    tensorboard-1.12.0         |   py36he025d50_0         3.1 MB\r\n    termcolor-1.1.0            |           py36_1           8 KB\r\n    absl-py-0.7.0              |           py36_0         157 KB\r\n    protobuf-3.6.0             |   py36he025d50_0         517 KB\r\n    cudatoolkit-9.0            |                1       339.8 MB\r\n    tensorflow-gpu-1.12.0      |       h0d30ee6_0           3 KB\r\n    markdown-3.0.1             |           py36_0         125 KB\r\n    _tflow_select-2.1.0        |              gpu           3 KB\r\n    libprotobuf-3.6.0          |       h1a1b453_0         2.0 MB\r\n    astor-0.7.1                |           py36_0          44 KB\r\n    ------------------------------------------------------------\r\n                                           Total:       700.7 MB\r\n```\r\n\r\nIf you already messed up the versions, try to use `conda remove` or `pip uninstall` to delete packages, including `tensorflow-gpu` and `tensorflow`. Or remove Anaconda and reinstall it.\r\n\r\n", "> I have the same question with the author,and i solve it now.\r\n> window 10\r\n> python 3.6.2\r\n> gpu rtx2080\r\n> my problem is the version of CUDA and the cudnn does not fit each other.\r\n> 2019/3/3 today the newest version of CUDA is 10.1 but there isn't a corresponding version of cudnn.\r\n> so i changed the CUDA 10.0 and reinstall the tensorflow,it works now!\r\n\r\n@parkerdu Savior! My system is running Python 3.7.1 on Windows 10 and my GPU is RTX 2080 Ti. All I did was downgrading CUDA from 10.1 to 10.0 and it now works. But I'm a little confused with what you mean by \r\n\r\n> the newest version of CUDA is 10.1 but there isn't a corresponding version of cudnn.\r\n\r\nsince there is a version of cuDNN released on Feb 25, 2019 according to [https://developer.nvidia.com/rdp/cudnn-download](url) . It doesn't work with the latest version of TensorFlow installed through \"pip install tensorflow-gpu\" in my case but it's there. I'm wondering why it's not the \r\n\r\n> corresponding version of cudnn. \r\n\r\nAgain, thanks for your solution.   ", "> > I have the same question with the author,and i solve it now.\r\n> > window 10\r\n> > python 3.6.2\r\n> > gpu rtx2080\r\n> > my problem is the version of CUDA and the cudnn does not fit each other.\r\n> > 2019/3/3 today the newest version of CUDA is 10.1 but there isn't a corresponding version of cudnn.\r\n> > so i changed the CUDA 10.0 and reinstall the tensorflow,it works now!\r\n> \r\n> @parkerdu Savior! My system is running Python 3.7.1 on Windows 10 and my GPU is RTX 2080 Ti. All I did was downgrading CUDA from 10.1 to 10.0 and it now works. But I'm a little confused with what you mean by\r\n> \r\n> > the newest version of CUDA is 10.1 but there isn't a corresponding version of cudnn.\r\n> \r\n> since there is a version of cuDNN released on Feb 25, 2019 according to [https://developer.nvidia.com/rdp/cudnn-download](url) . It doesn't work with the latest version of TensorFlow installed through \"pip install tensorflow-gpu\" in my case but it's there. I'm wondering why it's not the\r\n> \r\n> > corresponding version of cudnn.\r\n> \r\n> Again, thanks for your solution.\r\n\r\nyou are right! I haven't see the latest version of cudnn. Thanks for your point.", "After hours of installing different versions I finally managed to make it work, this is my final setup:\r\n\r\n* Python 3.6.8\r\n* Tensorflow 1.13\r\n* CUDA 10\r\n* cuDNN v7.5.0 (Feb 21, 2019), for CUDA 10.0\r\n\r\nI tried with CUDA 10.1 but didn't work, switched to 10.0 and it finally worked.", "python 3.7.2\r\nTensorflow-gpu 2.0.0a0\r\ntensorboard          1.13.0\r\ntensorflow-estimator 1.13.0\r\nCUDA 10.1\r\ncuDNN v7.5.0 for CUDA10.0\r\nwin10 x64\r\nPlease help", "@steven12138 You can follow the previous post that worked. \r\nAFAIK, the python 3.7.X python is not supported. ", "This is what worked for me on Window 10 and for GPU NVIDIA GeForce RTX 2080 Ti:\r\nPython 3.5 (3.6 did not work)\r\nTensorflow-gpu 1.13 (or tf-nightly-gpu)\r\nCUDA 10\r\ncuDNN for CUDA 10.0\r\nThe problem was because of using python 3.6. Using Python 3.5 solved it.", "CUDA 9.0\r\ncudnn 7.0.5\r\nWindows 10\r\ntf 1.12.0\r\nfailed...no idea\r\n\r\n----\r\nsolved, \r\none problem is the PATH is incorrect, I corrected it but the problem still exists.\r\nThen I downgrade the tf to 1.10.0, and it works.", "> Ran into the same problem.\r\n> \r\n> If you are using Anaconda (Python 3.6), highly suggest to use `conda` instead of `pip`. It usually takes care of EVERYTHING: `conda install tensorflow-gpu`\r\n> \r\n> ```\r\n> (base) C:\\Users>conda install tensorflow-gpu\r\n> Solving environment: done\r\n> \r\n> ## Package Plan ##\r\n> \r\n>   environment location: D:\\Software\\Anaconda3\r\n> \r\n>   added / updated specs:\r\n>     - tensorflow-gpu\r\n> \r\n> \r\n> The following packages will be downloaded:\r\n> \r\n>     package                    |            build\r\n>     ---------------------------|-----------------\r\n>     cudnn-7.3.1                |        cuda9.0_0       170.9 MB\r\n>     grpcio-1.12.1              |   py36h1a1b453_0         1.4 MB\r\n>     tensorflow-base-1.12.0     |gpu_py36h6e53903_0       180.8 MB\r\n>     conda-4.6.7                |           py36_0         1.7 MB\r\n>     tensorflow-1.12.0          |gpu_py36ha5f9131_0           4 KB\r\n>     keras-preprocessing-1.0.5  |           py36_0          52 KB\r\n>     gast-0.2.2                 |           py36_0         138 KB\r\n>     keras-applications-1.0.6   |           py36_0          49 KB\r\n>     tensorboard-1.12.0         |   py36he025d50_0         3.1 MB\r\n>     termcolor-1.1.0            |           py36_1           8 KB\r\n>     absl-py-0.7.0              |           py36_0         157 KB\r\n>     protobuf-3.6.0             |   py36he025d50_0         517 KB\r\n>     cudatoolkit-9.0            |                1       339.8 MB\r\n>     tensorflow-gpu-1.12.0      |       h0d30ee6_0           3 KB\r\n>     markdown-3.0.1             |           py36_0         125 KB\r\n>     _tflow_select-2.1.0        |              gpu           3 KB\r\n>     libprotobuf-3.6.0          |       h1a1b453_0         2.0 MB\r\n>     astor-0.7.1                |           py36_0          44 KB\r\n>     ------------------------------------------------------------\r\n>                                            Total:       700.7 MB\r\n> ```\r\n> If you already messed up the versions, try to use `conda remove` or `pip uninstall` to delete packages, including `tensorflow-gpu` and `tensorflow`. Or remove Anaconda and reinstall it.\r\n\r\nthis guy saved a day, thank you", "I use virtualenv with python 3.6.8, and just run \r\n`pip install tensorflow-gpu`\r\n\r\ncuda 9.0\r\ncudnn 7.4.1 for cuda 9.0\r\npython 3.6.8\r\ntensorflow 1.12.0 \r\nvisual C ++ 2015 redistribution\r\n\r\nThis Configuration works. \r\nAttention, tensorflow 1.13 not works for me with this configuration.\r\n\r\n=========================Edit================\r\nAs I've tried again.\r\nIf you want use tensorflow 1.13.1, you can refer to the configuration below:\r\ncuda 10.0\r\ncudnn 7.5.0 for cuda 10.0\r\npython 3.6.8\r\ntensorflow 1.13.1\r\nvisual C++ redistribution 2015 or 2017\r\n\r\nAnd i find , the official site said that tensorflow only support cuda 9 now, but actually it is already update to CUDA 10 , you can find on the release note at github.\r\n\r\nso simplicity,  CUDA 9.0 ( cudnn 7.4.1)  == > tensorflow 1.12.0\r\n                      CUDA 10.0 (cidnn 7.5.0)== > tensorflow 1.13.1", "python 3.7.2\r\nTensorflow-gpu 2.0.0a0\r\ntensorboard 1.13.0\r\ntensorflow-estimator 1.13.0\r\nCUDA 10.1\r\ncuDNN v7.5.0 for CUDA10.0\r\nwin10 x64\r\nDidn't work", "I have no problem at the terminal, but I have this problem on pycharm, I hope I can give you a reference.\r\n\r\nWin10+python 3.6+cuda 10.0+cudnn 7.5+tensorflow 1.13.1", "I had same issue. I resolved it by uninstalling tensorflow-gpu and reinstalling through conda.\r\n\r\n`conda install tensorflow-gpu`", "I had a problem \r\n\r\nTypeError: Couldn't build proto file into descriptor pool!\r\nInvalid proto descriptor for file \"object_detection/protos/post_processing.proto\":\r\n  object_detection/protos/post_processing.proto: Import \"object_detection/protos/calibration.proto\" has not been loaded.\r\n  object_detection.protos.PostProcessing.calibration_config: \"object_detection.protos.CalibrationConfig\" seems to be defined in \"protos/calibration.proto\", which is not imported by \"object_detection/protos/post_processing.proto\".  To use it here, please add the necessary import.", "> I just downgraded TensorFlow to 1.10.0 and it worked\r\n> \r\n> `pip install tensorflow-gpu==1.10.0`\r\n\r\nWhen I ran the ```pip install tensorflow-gpu``` command, 1.13.0 got installed and I got the error ```Win10: ImportError: DLL load failed: The specified module could not be found```. So I tried downgrading to ```1.10.0``` as @57ar7up suggested. This did not work as pip could not find the required ```.whl``` file and the connection kept timing out. \r\n\r\nSo I followed @WuYunfan 's approach and ```1.12.0``` worked.\r\n> I finally solve the problem by installing cuda 9.0 instead of 9.2 or 10.0 with tensorflow 1.12.0 and cudnn 7.4.1.5\r\n\r\n\r\nFinally my setup is:\r\n* Nvidia GTX 1070\r\n* CUDA 9.0 with the 4 patches (This installed GeForce drivers 385.54)\r\n* CuDNN v7.5.0.56 (for CUDA 9.0)\r\n* TF GPU 1.12.0\r\n\r\nI guess ```1.13.0``` is to be used for CUDA 10.0", "Python 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow\r\nTraceback (most recent call last):\r\n  File \"D:\\MLandBigData\\Anaconda3.5\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"D:\\MLandBigData\\Anaconda3.5\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"D:\\MLandBigData\\Anaconda3.5\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"D:\\MLandBigData\\Anaconda3.5\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"D:\\MLandBigData\\Anaconda3.5\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: \u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6a21\u5757\u3002\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"D:\\MLandBigData\\Anaconda3.5\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"D:\\MLandBigData\\Anaconda3.5\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"D:\\MLandBigData\\Anaconda3.5\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"D:\\MLandBigData\\Anaconda3.5\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"D:\\MLandBigData\\Anaconda3.5\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"D:\\MLandBigData\\Anaconda3.5\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"D:\\MLandBigData\\Anaconda3.5\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"D:\\MLandBigData\\Anaconda3.5\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: \u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6a21\u5757\u3002\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "python 3.7.1\r\nTensorflow-gpu 1.13.1\r\n\r\nCUDA 8.0\r\ncuDNN v7.1.4 for CUDA 8.0\r\nwin10 x64\r\nPlease help\r\n===========================\r\nI built the tensorflow from source with environments following and worked:\r\npython 3.7.1\r\nTensorflow-gpu 1.13.1\r\n\r\nCUDA 9.1\r\ncuDNN v7.0.5 for CUDA 9.1\r\nwin10 x64", "My error message is copied a few lines down. I have tried some of the solutions that seemed to work for other people, but did not have them work for me.  Specifically: \r\nAlways python 3.6.8 & Windows 10 & Visual Studios 2017 & Quadro M1000M GPU\r\nUsed pip to install tensorflow-gpu 1.13.1\r\nAfter reading I found out that CUDA 10.1 (which I tried originally) doesn't work with anything, so I switched to CUDA 10.0. With CUDA 10.0 I tried cudNN 7.4.2 & 7.5.0. Neither works, I still have CUDA 10.1 installed (does tensorflow automatically try both, or do I need to set it to use 10.0 somehow?). \r\n\r\nI have previously uninstalled & reinstalled tensorflow-gpu a few times (also plain tensorflow - which does not detect my GPU), though tensorflow-gpu was always installed for my tests. This is also my first time working with either CUDA or cudNN, so I'm not 100% sure I \"installed\" cudNN correctly (from extracted cudNN folders bin, lib & include copy the relevant file over to the Cuda bin, lib & inc folders). I also installed tf-nightly-gpu, as that worked with one solution.\r\n\r\nError message: \r\n\r\nPython 3.6.8rc1 (v3.6.8rc1:cc3e73212a, Dec 12 2018, 00:15:46) [MSC v.1900 64 bit (AMD64)] on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\601969\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\601969\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\601969\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\601969\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\601969\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\601969\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\__init__.py\", line 28, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Users\\601969\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\601969\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\601969\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\601969\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\601969\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\601969\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\601969\\AppData\\Local\\Programs\\Python\\Python36\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.", "Same issue. Win10 x64, python 3.6, tensorflow-gpu 1.12.0, CUDA 10.1 with CUDNN 10.1 installed.", "> I use virtualenv with python 3.6.8, and just run\r\n> `pip install tensorflow-gpu`\r\n> \r\n> cuda 9.0\r\n> cudnn 7.4.1 for cuda 9.0\r\n> python 3.6.8\r\n> tensorflow 1.12.0\r\n> visual C ++ 2015 redistribution\r\n> \r\n> This Configuration works.\r\n> Attention, tensorflow 1.13 not works for me with this configuration.\r\n> \r\n> =========================Edit================\r\n> As I've tried again.\r\n> If you want use tensorflow 1.13.1, you can refer to the configuration below:\r\n> cuda 10.0\r\n> cudnn 7.5.0 for cuda 10.0\r\n> python 3.6.8\r\n> tensorflow 1.13.1\r\n> visual C++ redistribution 2015 or 2017\r\n> \r\n> And i find , the official site said that tensorflow only support cuda 9 now, but actually it is already update to CUDA 10 , you can find on the release note at github.\r\n> \r\n> so simplicity, CUDA 9.0 ( cudnn 7.4.1) == > tensorflow 1.12.0\r\n> CUDA 10.0 (cidnn 7.5.0)== > tensorflow 1.13.1\r\n\r\nThank you. solved my issue\r\nmy setting\r\nWin10 + python 3.6.6 + GeForce GTX 1050 Ti (Legion Notebook)\r\nVisual Studio Community 2017 + CUDA 10.0 (cudnn 7.5.0)  + tensorflow 1.13.1 \r\n\r\n", "Overall, getting the basic validation test to work for tensorflow-gpu (1.13.1) is a big ordeal -- don't know where exactly the utterly useless DLL load error message comes from...\r\n\r\nNoting down my parameters (as of 03/18/2019) in case it helps any brave soul !\r\nBase framework: Windows 10 Pro/64,    Anaconda 3-5.1.0 (python 3.6.4),  \r\n                          Visual Studio 2017       [GPU=RTX2060]\r\nUnsuccessful target setup that throws the DLL error: \r\n       CUDA 10.1 + corresponding cuDNN (7.5.0.56)\r\nWhat seems to work (after resolving minor glitch with numpy version in anaconda)\r\n       CUDA 10.0 + cuDNN 7.4.1.5", "I tried with CUDA 10.1 but all version combinations didn't work, then I switched to CUDA 10.0 as someone suggested and it finally worked. So I guess the problem lies at the CUDA 10.1.\r\n\r\nMy successful version combinations are:\r\n\r\nCUDA 10.0  (NOT CUDA 10.1)\r\ncuDNN v7.5.0 (Feb 21, 2019), for CUDA 10.0 (NOT the one for CUDA 10.1)\r\nAnnaconda Anaconda 2018.12 (with Python 3.7 version, 64-Bit Graphical Installer)\r\n\r\nThen I tested 2 combinations: Python 3.7.1 + Tensorflow 1.13.1 and Python 3.68 + Tensorflow 2.0.0-alpha0. They both work.\r\n\r\nBTW, I used \r\n     conda install tensorflow-gpu\r\ninstead of \r\n      pip install tensorflow-gpu\r\nto install tensorflow as someone suggested.\r\n\r\nGood luck.", "i had the same issue using (conda install tensorflow-gpu) solve the problem.\r\ncuda 10.0\r\ncudnn 7.41.5 for cuda 10.0\r\npython 7.1", "> I just downgraded TensorFlow to 1.10.0 and it worked\r\n> \r\n> `pip install tensorflow-gpu==1.10.0`\r\n\r\nyes, it works. mark!", "> I have the same question with the author,and i solve it now.\r\n> window 10\r\n> python 3.6.2\r\n> gpu rtx2080\r\n> my problem is the version of CUDA and the cudnn does not fit each other.\r\n> 2019/3/3 today the newest version of CUDA is 10.1 but there isn't a corresponding version of cudnn.\r\n> so i changed the CUDA 10.0 and reinstall the tensorflow,it works now!\r\n\r\nHi, I have the same setup with python 3.7.\r\nNow there is a cudnn version of CUDA 10.1, however tensorflow-gpu still doesn't work if I install it from pip.\r\nDid you rebuild it yourself?\r\n\r\nEdit.: Found the issue. Even tho there is a  cudNN version from nvidia to support CUDA 10.1, there is no python library to support CUDA 10.1. This library is installed as a dependency with tensorflow-gpu, but only supports CUDA 10.0.", "I just installed latest conda 3.7 \r\nrun \"conda install tensorflow-gpu\" in anaconda promt\r\nno need to install cuda, cudann and mess with PATH variables\r\neverything works", "I can confirm that CUDA 10.1 does not work. But then, tensorflow never claimed it did and its guide asks to [download CUDA 10.0](https://www.tensorflow.org/install/gpu).\r\n\r\nFor those who can't find this version, it's available in the NVIDIA archives and here is a direct link: https://developer.nvidia.com/cuda-10.0-download-archive", "My settings:\r\n\r\nPython 3.6.5\r\nCUDA 9.0\r\ncuDNN 7.41.5\r\ntensorflow 1.12.0\r\ntensorflow-gpu 1.12.0\r\n\r\ngreat work", "Hi All,\r\n\r\nFacing the same issue!\r\n\r\nCan anyone provide a 'working' env info for _AMD Radeon HD7500M_ Graphic Accelerator with the following:\r\n\r\n- Win10 Pro, FU 1803\r\n- I3 3rd Gen, 4GB\r\n- CUDA ver.10.0.130\r\n- CUDNN ver 7.3.1 for 10.0_0\r\n- Anaconda3 (2018.12)\r\n- Py 3.7.1\r\n- Tensorflow-gpu 1.13.1 - 'Conda' install using 'Anaconda prompt'\r\n\r\nThanks!\r\n\r\n\r\n", "I got the same DLL load failed error when running trying to run tensorboard, no problems running the others:\r\n\r\nWin10\r\ntensorflow-gpu 1.11.0\r\ntensorboard 1.11.0\r\ncudnn 7.1.4\r\ncuda9.0_0\r\npython 3.6.3", "My settings:\r\n\r\nWin10x64\r\ntensorflow-gpu 1.13.1\r\nCUDA 10.1\r\nCUDNN 7.5 for cuda10.1\r\npython 3.7.1\r\n\r\nAnd I got the same error! \r\n\r\n\r\n", "> I got the same DLL load failed error when running trying to run tensorboard, no problems running the others:\r\n> \r\n> Win10\r\n> tensorflow-gpu 1.11.0\r\n> tensorboard 1.11.0\r\n> cudnn 7.1.4\r\n> cuda9.0_0\r\n> python 3.6.3\r\n\r\nI fixed the error by upgrading cygrpc in pip since the DLL load import error comes up when importing cygrpc", "> My settings:\r\n> \r\n> Win10x64\r\n> tensorflow-gpu 1.13.1\r\n> CUDA 10.1\r\n> CUDNN 7.5 for cuda10.1\r\n> python 3.7.1\r\n> \r\n> And I got the same error!\r\n\r\nI've changed the env :\r\n\u00b7tensorflow-gpu 1.12.0\r\n\u00b7CUDA 9.0\r\n\u00b7Cudnn 7.5 for CUDA9.0\r\n\u00b7python3.6.8\r\n\r\nFinally, it works!\r\n", "Is it that tf-gpu works with 'NVIDIA' accelerators ONLY!\r\n\r\n'RADEON' ones - need to use a different lib/ build!", "https://github.com/fo40225/tensorflow-windows-wheel\r\n\r\nTook me ages but finally sorted this issue on my PC. Was a mixture of not having the correct cuDNN installed and VS redist. Find the correct versions for your Python version, CPU and Graphics card in the link above.", "Thank you DTopping256!!!  ", "> I had same issue. I resolved it by uninstalling tensorflow-gpu and reinstalling through conda.\r\n> \r\n> `conda install tensorflow-gpu`\r\n\r\nI was creating a new venv and downloaded tensorflow-gpu again following the directions here (https://www.tensorflow.org/install/pip). However, it installed the latest stable version (1.13) which caused a problem. I installed tf-gpu using conda and they installed the packages together with tf-gpu version 1.12.0-h0d30ee6_0. I guess the 1.12v doesn't cause any issues at least on my laptop.\r\n\r\nFYI:\r\nWin10x64\r\nCUDA V10.1.105\r\npython 3.6.5\r\nnvidia gpu 1070 max-q", "The same problem.\r\nwin10 x64\r\ncuda 9.0.176\r\ncudnn 7.0\r\npython 3.6.0\r\ntensorflow-gpu 1.13.0\r\n\r\n------------------------------------------------\r\n@2019/04/16\r\nI have soved the problem by setup tensorflow-gpu-1.12\uff0cmaybe the latest version tensorflow-gpu-1.13 need cuda-10.0.\r\n\r\nTehre is [my summary](https://blog.csdn.net/pkxpp/article/details/88925868), but the language is chinese.^_^\r\n", "> I had same issue. I resolved it by uninstalling tensorflow-gpu and reinstalling through conda.\r\n> \r\n> `conda install tensorflow-gpu`\r\n\r\nThis worked with me too, I have installed tensorflow with **pip** and then I uninstalled it using `pip uninstall tensorflow-gpu` and then again installed using `conda install tensorflow-gpu`", "Microsoft Windows [Version 6.3.9600]\r\n(c) 2013 Microsoft Corporation. All rights reserved.\r\n\r\nC:\\Users\\Dell>python\r\nPython 3.7.1 (default, Dec 10 2018, 22:54:23) [MSC v.1915 64 bit (AMD64)] :: Ana\r\nconda, Inc. on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> iimprt tensorflow\r\n  File \"<stdin>\", line 1\r\n    iimprt tensorflow\r\n                    ^\r\nSyntaxError: invalid syntax\r\n>>> import tensorflow\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tenso\r\nrflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tenso\r\nrflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tenso\r\nrflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, descript\r\nion)\r\n  File \"C:\\Users\\Dell\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Dell\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line\r\n24, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-im\r\nport\r\n  File \"C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\"\r\n, line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tenso\r\nrflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tenso\r\nrflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tenso\r\nrflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Dell\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tenso\r\nrflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, descript\r\nion)\r\n  File \"C:\\Users\\Dell\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Dell\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.\r\n>>>", "What a sorry mess of an install process this currently is! \r\n\r\nWith thanks to the contributors here I have finally got it working (I think!) \r\n\r\nI had followed all the regular PIP install processes from the tensorflow page and had ended up with this combination on my new Windows 10 desktop (Nvid GTX 1660) & Ananconda with a new Python 3.6 environment. \r\n\r\nTens: 1.13.1 \r\nCuda: 10.1 \r\ncuDNN: 7.5 \r\n\r\nand also updated my system PATH to add those libraries as needed (although some CUDA paths had appeared already there,  presumably as part the its install now, but more paths were added as needed as described [here](https://www.tensorflow.org/install/gpu#windows_setup)). \r\n\r\nin jupyter tried to: \r\nimport tensorflow as tf \r\n\r\nand got the error everyone sees: \r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nMy first attempt at a solution worked! \r\n\r\nfollowing the advice from @oshadaamila [above](https://github.com/tensorflow/tensorflow/issues/22794#issuecomment-478855387) I uninstalled the PiP tensorflow and reinstall using Conda . \r\n\r\nConda brought in the following versions: \r\nTens: 1.13.1 \r\nCuda: 10.0.130\r\ncuDNN: 7.3 \r\n\r\nThe import now works and a small code test ran fine: \r\n\r\na= tf.constant(4)\r\nb=tf.constant(5)\r\nsess=tf.Session()\r\nc= a+b\r\nprint('Sum= ', sess.run(c))\r\n\r\ngives the answer of 9. \r\n\r\nI did not change anything in the system PATH environment - all the new CUDA and cuDNN are now installed in the Anaconda3/pkgs folders so they seem to be preferentially referenced when in a python environment. \r\n\r\nIts possible I will have errors if trying to work something outside the Ananconda environment but for now Im even trying to do that. \r\n ", "### For TensorFlow 1.31.1\r\n\r\ntensorflow/configure.py \r\n```\r\n_DEFAULT_CUDA_VERSION = '10.0'   // see here\r\n\r\n_DEFAULT_CUDA_PATH_WIN = ('C:/Program Files/NVIDIA GPU Computing '\r\n                          'Toolkit/CUDA/v%s' % _DEFAULT_CUDA_VERSION)\r\n\r\n# ...\r\n\r\ndef set_tf_cuda_version(environ_cp):\r\n  \"\"\"Set CUDA_TOOLKIT_PATH and TF_CUDA_VERSION.\"\"\"\r\n  ask_cuda_version = (\r\n      'Please specify the CUDA SDK version you want to use. '\r\n      '[Leave empty to default to CUDA %s]: ') % _DEFAULT_CUDA_VERSION\r\n\r\n  # ...\r\n\r\n  for _ in range(_DEFAULT_PROMPT_ASK_ATTEMPTS):\r\n    # Configure the Cuda SDK version to use.\r\n    tf_cuda_version = get_from_env_or_user_or_default(\r\n        environ_cp, 'TF_CUDA_VERSION', ask_cuda_version, _DEFAULT_CUDA_VERSION)\r\n\r\n  # ...\r\n\r\n  environ_cp['TF_CUDA_VERSION'] = tf_cuda_version\r\n```\r\n\r\n**so the curren CUDA version is 10.0\uff0cbut the NVIDIA give 10.1**\uff0cinstall  CUDA10.0 and cudnn10.0 then restart cmd\uff0cis will work\r\n\r\nfor older version https://developer.nvidia.com/cuda-toolkit-archive\r\n\r\ndetail: https://blog.kenorizon.cn/note/tensorflow-installation.html\r\n", "Try pip install tensorflow-gpu==1.13.1-rc2 if you have to use CUDA 10.0 for RTX. I have CUDA 10.0, cuDNN 7.5.0, python 3.6 and it works!", "i fixed this by installing cuda 10.1 (i have tensorflow 2.0alpha btw) and cudnn 7.5.0.56\r\nrestart your computer or else import tensorflow-gpu will not work", "Observed the similar issue with TF 1.13.1 and CUDA 10.1 - fixed by removing CUDA 10.1 and installing CUDA 10.0.", "I had the same issue and downgrading to CUDA 10.0 solved it (tensorflow 1.13.1, GTX 1080ti)", "Solved via downgrade to CUDA 10.0 and cuDNN 7.5 for CUDA 10.0 ", "Solved by downgrading to CUDA 10.0, cuDNN v7.5.0.56, Python 3.6.7 and tensorflow 1.13.1. \r\n\r\nDon't forget to clean or uninstall any previous version of tensorflow and CUDA if you attempt to go for this combination. If you have Python 3.7, and trying to install tensorflow 1.13.1 or any lower version, then it won't work because as of now no version of tensorflow is supporting Python 3.7. Remove Python 3.7, and start afresh.", "Hi, @utkalsinha    Did you install tensorflow from source code? I compile tensorflow source code under CUDA 10.0, cuDNN v7.5.0.56, Python 3.6.6 and tensorflow 1.13.1, but also failed. The only difference between us is I use Python3.6.6 while your is Python3.6.7", "Do not forget to add the environment variables for CUDA and cuDNN\r\nSET PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\bin;%PATH%\r\nSET PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\extras\\CUPTI\\libx64;%PATH%\r\nSET PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\include;%PATH%\r\nSET PATH=C:\\tools\\cuda\\bin;%PATH%", "Got same problem.. after after one week applying all hook and crook... Just deactivated the Windows defender and it worked", "> Hi, @utkalsinha Did you install tensorflow from source code? I compile tensorflow source code under CUDA 10.0, cuDNN v7.5.0.56, Python 3.6.6 and tensorflow 1.13.1, but also failed. The only difference between us is I use Python3.6.6 while your is Python3.6.7\r\n\r\n@asa008: Nope. I have directly installed tensorflow-gpu via pip as `pip install tensorflow-gpu==1.13.1`", "After spending some time on it, for `tensorflow==2.0.0-alpha0` , on Windows 10 try to install:\r\n\r\n1. python 3.6\r\n2. CUDA v10.0\r\n3. cudnn 7.4.1.5", "> After spending some time on it, for `tensorflow==2.0.0-alpha0` , on Windows 10 try to install:\r\n> \r\n> 1. python 3.6\r\n> 2. CUDA v10.0\r\n> 3. cudnn 7.4.1.5\r\n\r\nUsed Python 3.7.3 with same CUDA and cuDNN but got same DLL error.", "In my experience (after lots of trial and error), it is best to set the CUDA paths using the GUI based editor on Windows. \r\n\r\nMy setup is as follows:\r\n1. CUDA 10.0\r\n2. latest cudnn available (follow the instructions on Nvidia site)\r\n3. Setting the paths using the Environment Variables editor in Windows. \r\n--> In my experience, using \"SET PATH...\" on the Command Line still forgets the new paths. \r\n--> I also restarted the PC prior to installing Tensorflow.\r\n4. Tensorflow v1.13\r\n5. conda environment with Python 3.6\r\n\r\nI haven't tried this on tensorflow alpha, hopefully it works the same.", "I tested several combinations on my Windows 10 machine, and these are the results:\r\nFAIL\r\ntensorflow-gpu==r1.13\r\npython 3.7.3\r\nCUDA v10.1\r\ncudnn 7.5.0.56\r\n\r\nFAIL\r\ntensorflow-gpu==2.0.0-alpha0 \r\npython 3.7.3\r\nCUDA v10.1\r\ncudnn 7.5.0.56\r\n\r\nFAIL\r\ntensorflow-gpu==2.0.0-alpha0 \r\npython 3.6.8\r\nCUDA v10.1\r\ncudnn 7.5.0.56\r\n\r\nSUCCESS\r\ntensorflow-gpu==2.0.0-alpha0 \r\npython 3.6.8\r\nCUDA v10.0\r\ncudnn 7.4.1.5", "If you have this issue you can downgrade the lib to tensorflow-gpu==1.10.0, at today the superior versions have problems, this issue is common in windows.\r\nPD. after that you need CUDA to use this lib correctly.", "What about in Linux, are tensorflow higher versions are much more stable?", "plz help\r\n\r\nWARNING:tensorflow:From C:\\Users\\HP\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.", "Open ...\\Python37\\Lib\\site-packages\\tensorflow\\python\\\\_pywrap_tensorflow_internal.pyd use [Dependency Walker](http://www.dependencywalker.com/), it will show you the DLL dependency tree, you will find which DLL cause the problem. TensorFlow always linked to the specific CUDA version.", "Same here, Win10 Pro x64, Python 3.6.8, Tensorflow-gpu 1.13.1, cuDNN 7.5.1.10, CUDA 10.1, Driver 430.64\r\n![image](https://user-images.githubusercontent.com/40433852/58214432-e8c6d300-7d0a-11e9-9d49-809e154d094d.png)\r\n", "> My install:\r\n> \r\n> Windows 10.0.17763.134 x64\r\n> NVIDIA Driver 416.92\r\n> CUDA 10.0.130\r\n> CUDNN 7.4.1.5 for CUDA 10.0\r\n> Python 3.6.7\r\n> GeForce GTX 1080 Ti\r\n> \r\n> The cause of this error seems to be people installing Python without Tcl/Tk support not realizing that Tcl is necessary for SWIG and module imports. I just tested this and in my case it was not enough to modify the Python installation to add Tcl/Tk -- I had to delete everything and install from scratch and now I am not getting the error anymore.\r\n> \r\n> TL;DR -- just fully remove and reinstall Python with Tcl/Tk option selected.\r\n\r\nbase on @levicki cuda and cudnn version,   i also set the path according tf offical websit,\r\nSET PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\bin;%PATH% SET PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\extras\\CUPTI\\libx64;%PATH% SET PATH=C:\\Program Files\\NVIDIA GPU Computing Toolkit\\CUDA\\v10.0\\include;%PATH% SET PATH=C:\\tools\\cuda\\bin;%PATH%   (can't find tools in C, just ignore this one)\r\nI installed tensorflow2 alpha  successfully,  by the way my configuration is :\r\n> Windows 10.0.17763.134 x64\r\n> NVIDIA Driver 416.92\r\n> CUDA 10.0.130\r\n> CUDNN 7.4.1.5 for CUDA 10.0\r\n> Python 3.5.2\r\n> GeForce Titan xp x4\r\n\r\nif still not work, i also reinstalled pillow and then reinstall tf2, hopes it would helpful.", "> Same here, Win10 Pro x64, Python 3.6.8, Tensorflow-gpu 1.13.1, cuDNN 7.5.1.10, CUDA 10.1, Driver 430.64\r\n> ![image](https://user-images.githubusercontent.com/40433852/58214432-e8c6d300-7d0a-11e9-9d49-809e154d094d.png)\r\n\r\nMaybe you should use CUDA 10.0, not 10.1\u3002I just solved this problem on my PC, you can verify it use [Dependency Walker](http://www.dependencywalker.com/), like this:\r\n![image](https://user-images.githubusercontent.com/10413780/58223301-ae315a80-7d4b-11e9-9bee-cd82fa1eef96.png)", "originally` CUDA 9` working, I updated to `tensorflow-gpu 1.13.1` and it reported DLL not found.\r\nThen tried downgrading `tensorflow-gpu` to several versions, but still reported DLL not found.\r\nThen I updated  `CUDA10.1 update1` and `cudnn 7.5.1.10`  (both latest version) it reported DLL not found.\r\nThen tried downgrading `tensorflow-gpu` still reported DLL not found.\r\nThen use `dependency Walker`, but this app stuck upon opening (I am using win10)\r\nThen I copied `dependency Walker` and `_pywrap_tensorflow_internal.pyd` to a win7 device, confirmed it needs a dependency on `CUBLAXX_100.DLL`.\r\nThen I installed CUDA10.0 and it works.\r\n\r\nI shall say it is NOT a good experience everytime I install tensorflow-gpu.\r\nClear message and suggestion is needed rather than a simple `DLL missing`", "+1. Same problem as qinst64.", "can anyone give me a copy of cuda 10.0? cuda 10.0 has been wiped out ,only a version of 10.1 is available in the official site.Thanks!", "forget  that my system is windows10.Thank you!", "oh,I find it,hopeful anyone can get help!\r\nhttps://developer.nvidia.com/cuda-toolkit-archive", "I faced the same issue, turned out it I simply did not install cudnn (as I thought it would be included by installing CUDA, turned out it isnt)\r\nInstallationguide can be found [here](https://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html#install-windows)", "@ymodak Since it seems impossible to provide tensorflow builds for all possible Python+CUDA+cuDNN versions, would you guys at least consider improving the error message to include:\r\n\r\n1. The name of the DLL which can't be found if you are loading it dynamically\r\n\r\nOr:\r\n\r\n2. The name of the statically loaded DLL which failed to load because of unsatisfied dependency chain?\r\n", "SUCCESS\r\ntensorflow-gpu==1.10.0\r\npython 3.6.8\r\nCUDA v9.0\r\ncudnn 7.6.0\r\nThis finally solved my autokeras installation problem", "## SUCCESS\r\n\r\n - Windows 10 Home 64bit\r\n - [CUDA Toolkit 10.0](https://developer.nvidia.com/cuda-10.0-download-archive) (Sept 2018)\r\n - [Download cuDNN v7.6.0 (May 20, 2019), for CUDA 10.0](https://developer.nvidia.com/rdp/cudnn-download#a-collapse760-10)\r\n - Python 3.7.3 Windows AMD64\r\n - Tensorflow-gpu 1.13.1", "Can we install cuda and cudnn in Radeon graphic card\n\nOn Sat, 6 Apr 2019, 10:22 p.m. Jed Baxter, <notifications@github.com> wrote:\n\n> What a sorry mess of an install process this currently is!\n>\n> With thanks to the contributors here I have finally got it working (I\n> think!)\n>\n> I had followed all the regular PIP install processes from the tensorflow\n> page and had ended up with this combination on my new Windows 10 desktop\n> (Nvid GTX 1660):\n>\n> Tens: 1.13.1\n> Cuda: 10.1\n> cuDNN: 7.5\n>\n> and also updated my system PATH to add those libraries as needed (although\n> some CUDA paths had appeared already there, presumably as part the its\n> install now, but more paths were added as needed as described here\n> <https://www.tensorflow.org/install/gpu#windows_setup>).\n>\n> in jupyter tried to:\n> import tensorflow as tf\n>\n> and got the error everyone sees:\n> ImportError: DLL load failed: The specified module could not be found.\n>\n> My first attempt at a solution worked!\n>\n> following the advice from @oshadaamila <https://github.com/oshadaamila>\n> above\n> <https://github.com/tensorflow/tensorflow/issues/22794#issuecomment-478855387>\n> I uninstalled the PiP tensorflow and reinstall using Conda .\n>\n> Conda brought in the following versions:\n> Tens: 1.13.1\n> Cuda: 10.0.130\n> cuDNN: 7.3\n>\n> The import now works and a small code test ran fine:\n>\n> a= tf.constant(4)\n> b=tf.constant(5)\n> sess=tf.Session()\n> c= a+b\n> print('Sum= ', sess.run(c))\n>\n> gives the answer of 9.\n>\n> I did not change anything in the system PATH environment - all the new\n> CUDA and cuDNN are now installed in the Anaconda3/pkgs folders so they seem\n> to be preferentially referenced when in a python environment.\n>\n> Its possible I will have errors if trying to work something outside the\n> Ananconda environment but for now Im even trying to do that.\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/22794#issuecomment-480519001>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/Auda9lPIPF0BJa_NUNfnkhqoHPcvmTwCks5veNC2gaJpZM4XLOd->\n> .\n>\n", "Can we install cuda in radeon graphic card\n\nOn Sun, 14 Apr 2019, 8:38 a.m. Utkal Sinha, <notifications@github.com>\nwrote:\n\n> Solved by downgrading to CUDA 10.0, cuDNN v7.5.0.56, Python 3.6.7 and\n> tensorflow 1.13.1.\n>\n> Don't forget to clean or uninstall any previous version of tensorflow and\n> CUDA if you attempt to go for this combination. If you have Python 3.7, and\n> trying to install tensorflow 1.13.1 or any lower version, then it won't\n> work because as of now no version of tensorflow is supporting Python 3.7.\n> Remove Python 3.7, and start afresh.\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/22794#issuecomment-482915167>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/Auda9j9qH1-Z_UgS8jT6-hZZD4xwlzISks5vgpuugaJpZM4XLOd->\n> .\n>\n", "@roopahtshree  [GPU](https://www.tensorflow.org/install/gpu#hardware_requirements)\r\n\r\nCheck below link. NVIDIA\u00ae GPU card with CUDA\u00ae Compute Capability 3.5 or higher\r\nhttps://developer.nvidia.com/cuda-gpus\r\n\r\n", "Had the same issue, but using CUDA 10.0, CUDNN 7, Python 3.6.8, and TensorFlow 1.13 works now.\r\n", "https://docs.nvidia.com/deeplearning/sdk/cudnn-support-matrix/index.html\r\n\r\nWindows 10\r\n[cuDNN 7.5.0](https://developer.nvidia.com/compute/machine-learning/cudnn/secure/v7.5.0.56/prod/9.0_20190219/cudnn-9.0-windows10-x64-v7.5.0.56.zip)\r\n[CUDA 9.0.176](https://developer.nvidia.com/cuda-90-download-archive?target_os=Windows&target_arch=x86_64&target_version=10&target_type=exelocal)\r\n[tensorflow-gpu 1.10.0](https://files.pythonhosted.org/packages/ae/d9/60e1e73abffaeb0aaca7cc2bcfeb973ec3b314a3e46e26270966829b5207/tensorflow_gpu-1.10.0-cp36-cp36m-win_amd64.whl)\r\nAnaconda Python 3.6.2\r\n\r\nok!!!\r\n\r\nWindows 8.1\r\ncuDNN 7.6.0 for CUDA 10.0\r\nCUDA 10.0 for Windows 7\r\ntensorflow-gpu 1.13.1\r\nAnaconda Python 3.7+\r\n\r\nok!!!!\r\n\r\n", "@pishangujeniya \r\n> * Windows 10 Home 64bit\r\n> * [CUDA Toolkit 10.0](https://developer.nvidia.com/cuda-10.0-download-archive) (Sept 2018)\r\n> * [Download cuDNN v7.6.0 (May 20, 2019), for CUDA 10.0](https://developer.nvidia.com/rdp/cudnn-download#a-collapse760-10)\r\n> * Python 3.7.3 Windows AMD64\r\n> * Tensorflow-gpu 1.13.1\r\n\r\nI've been trying to install tensorflow for the past couple days, and I've tried almost all of these configurations. This one worked for me. Thank you so much.", "Here I post my solution:\r\nI also encounter the prolem\uff08**ImportError: DLL load failed: \u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6a21\u5757\u3002Failed to load the native TensorFlow runtime**.\uff09 while directly using pip isntall(tensorflow1.13.1). I turned to **lfd.uci** and downloaded another  compiled **older version tensorflow1.9** , and then installed it locally. It works .\r\n- win10 x64\r\n- cuda10.1 cudnn 7.5\r\n- anaconda3 2019.3 with python3.7\r\n", "It seems like with TensorFlow 1.13.1, only CUDA 10 will work (and not CUDA 10.1). Configuration shared by @pishangujeniya worked.\r\n\r\nCUDA Toolkit 10.0 (Sept 2018)\r\nDownload cuDNN v7.6.0 (May 20, 2019), for CUDA 10.0", "My configuration works with the following:\r\n\r\ntensorflow-gpu==1.14.0\r\npython 3.6.8\r\nCUDA v10.0\r\ncudnn 7.4.1.5", "I am running TensorFlow in Anaconda and also ran in to this issue. It's related to compatibility issues between versions of TensorFlow, CUDA, and cuDNN. Anaconda's latest cudatoolkit automatically downloads and installs the correct versions of CUDA and cuDNN for TF v1.13. You can use cudatoolkit rather than manually installing CUDA and cuDNN.\r\n\r\nI was able to resolve this issue by:\r\n1) Uninstalling Anaconda, then downloading and installing latest version of Anaconda\r\n2) Creating new virtual environment and use \"conda install tensorflow-gpu\" (automatically installs CUDA and cuDNN as well)\r\n3) Working within this environment for the project", "Thanks everyone. 10.1 toolkit kept failing with the same error, but 10.0 worked like a charm.  ", "I fixed it by uninstall cuda10.1 and install cuda 10.0", "> I am running TensorFlow in Anaconda and also ran in to this issue. It's related to compatibility issues between versions of TensorFlow, CUDA, and cuDNN. Anaconda's latest cudatoolkit automatically downloads and installs the correct versions of CUDA and cuDNN for TF v1.13. You can use cudatoolkit rather than manually installing CUDA and cuDNN.\r\n> \r\n> I was able to resolve this issue by:\r\n> \r\n> 1. Uninstalling Anaconda, then downloading and installing latest version of Anaconda\r\n> 2. Creating new virtual environment and use \"conda install tensorflow-gpu\" (automatically installs CUDA and cuDNN as well)\r\n> 3. Working within this environment for the project\r\n\r\nAfter all the trials this answer made my day. 'conda install tensorflow-gpu' lock the tensorflow at 1.12 and solved all the dependency issues. \r\n", "I have faced the same issue.....\r\n\r\nC:\\Anaconda3>python\r\nPython 3.7.1 (default, Oct 28 2018, 08:39:03) [MSC v.1912 64 bit (AMD64)] :: Anaconda, Inc. on win32\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 28, in <module>\r\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: A dynamic link library (DLL) initialization routine failed.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "Found out something interesting which should help some of you who are using anaconda.\r\n\r\nSystem Spec:\r\nWidows 10\r\nPython 3.7.3\r\nCuda 10.0\r\ncudnn and cupti installed with conda\r\n\r\nBy adding anaconda to system path during the installation (the none recommended/default setting) I was unable to tf running. Reinstalling it without selecting the option solved this issue.", "I think this might be related to pointing out to cudnn64_7.dll file, after installation on windows it's needed to point out to cuDNN64_7.dll. Instruction to add it below:\r\n- Type path in windows 10 search box\r\n- Open settings: Edit the System environment variables from control panel\r\n- In the Advanced tab, click Environment Variables\u2026\r\n- Select Path under User variables for your-user-name and click Edit...\r\n- In the new window Edit environment variable , click New and paste following path into the text box\r\n- (Your CUDNN64_7.dll location) (eg. mine - C:\\cudnn-10.0-windows10-x64-v7.6.0.64\\cuda\\bin)\r\n- Click OK to close the window, and OK again to close the Environment Variables window and System - Properties window\r\n-Open a Anaconda Prompt and type echo %PATH% , you should be able to see the newly added path in the output.", "I doubt so. Or at least that's not the cause for me. I did add the path manually but the system hasn't been able to detect it", "I also get the same error.\r\nSomehow upgrading TensorFlow to version1.14.0 solves the problem :)", "installed in conda environment and works well on win10 + gtx1060 (nb version)\r\ntensorflow 1.13.1\r\ntensorflow-gpu 1.13.1\r\ntensorflow-datasets 1.0.1\r\nkeras 2.2.3\r\ncudatoolkit 9.0\r\ncudnn 7.6.4\r\npython 3.6.7\r\n", "I am stuck on this issue all day today\r\nIn the virtual environment I am able to successfully import Tensorflow 2 but within Visual Studio Jupyter notebook I am getting the below error\r\n\r\n`_mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)`\r\n`  File \"C:\\Users\\IT\\envs\\tf1env\\lib\\imp.py\", line 242, in load_module`\r\n `   return load_dynamic(name, filename, file)`\r\n`  File \"C:\\Users\\IT\\envs\\tf1env\\lib\\imp.py\", line 342, in load_dynamic`\r\n`    return _load(spec)`\r\n`ImportError: DLL load failed: The specified module could not be found.`\r\n\r\nI am using Tensorflow 2, CUDA 10.1 and cuDNN 7.6.5", "This is not an easy issue to figure out or resolve on your own.\r\n\r\nThe easy button is to follow the instructions in this  post:  \r\nhttps://www.pugetsystems.com/labs/hpc/How-to-Install-TensorFlow-with-GPU-Support-on-Windows-10-Without-Installing-CUDA-UPDATED-1419\r\n\r\nor just use Google Colab - they take care of all of this for you.\r\n", "\"ImportError: DLL load failed:\" doesn't think to mention which DLL is missing? this will be fun", "Same problem\r\nIn the conda lsit, it said I already installed the package.\r\nBut when I tried to run it, there are a lot of errors.\r\n\r\nI do't know what's wrong", "Had this issue with Tensorflow 2.1.0 (CPU version). Managed to fix it by downgrading to Tensorflow 2.0.0:\r\n```\r\npip install tensorflow==2.0.0\r\n```", "If you are having this after 2.1.0, it is probably because it comes with GPU support by default. And it requires _Microsoft Visual C++ Redistributable for Visual Studio 2015_ as shown in the installation step #1 on the website.\r\n\r\n![image](https://user-images.githubusercontent.com/7988466/72201765-a39d1000-3457-11ea-897a-5694c742a4c8.png)\r\n---\r\n### From the release notes:\r\n![image](https://user-images.githubusercontent.com/7988466/72201808-08586a80-3458-11ea-8f51-0fa04d270bee.png)\r\n\r\n", "I found the release notes that @abdulrahman-khankan screenshot'd above: https://github.com/tensorflow/tensorflow/releases/tag/v2.1.0\r\n\r\nHere is the [Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017 and 2019](https://support.microsoft.com/help/2977003/the-latest-supported-visual-c-downloads) link from that document. Remember, text in screenshots can't be clicked, copied, translated, read by screen readers, etc.!", "I assumed everyone knows how to go to the releases page or just google the MS installers. Thanks for sharing the links!", "Because of further issues with PyInstaller I ended up downgrading to `tensorflow == 1.14.0`.", "@ERDataDoc using your link \r\n\r\n> The easy button is to follow the instructions in this post:\r\n> https://www.pugetsystems.com/labs/hpc/How-to-Install-TensorFlow-with-GPU-Support-on-Windows-10-Without-Installing-CUDA-UPDATED-1419\r\n \r\nis helpful but sometimes it can upgrade the driver to CUDA 10.2 which is not supported yet\r\n(that happened in my case)", "Sorry I realize this isn't helpful but I've now given up trying to do anything serious with Python under Windows.  3 Weeks in and I'm still trying to install all the shit I need for the first tutorial (Maybe I set my sights too high but then I do remember punch cards and paper tape)", "https://github.com/tensorflow/tensorflow/issues/22512#issuecomment-572603142\r\nThis solved it for me.\r\n(Downgrading to tensorflow 2.0.0)\r\n`pip install tensorflow==2.0.0`", "https://github.com/tensorflow/tensorflow/issues/22794#issuecomment-580329356\r\n\r\nI installed the redistributable and msvcp140.dll is available on my file system.\r\n\r\nHowever, I still get the error. Downgrading helps, but I need to upgrade my version, since there is an unfixed bug on 2.0.0 I can't get around.\r\n\r\nIs there any notice from the developers, that they are working on this?", "I fixed it.\r\nSpend days searching to fix them.\r\n\r\nInstalled tensorflow with pip install tensorflow-cpu\r\nUpdated visual c++ 2015-2019\r\n\r\nissue was because i didn't had nvidia graphics so that i should install with cpu version because i am using Raedon vega 8 graphics\r\n\r\nHope it helps.", "In my case, I was using Python 3.6 and it was erroring. So I upgraded to 3.6.8 and it then worked with tensorflow 2.0.0", "It's work for me python: 3.7.6\r\npip install tensorflow==2.0\r\nif you are using tensoflow-gpu\r\npip install --upgrade tensorflow-gpu==2.0", "I installed\r\n- python 3.6.2 (<-- had to change my python version, and change to 64bit)\r\n- I already had the msvcp140.dll and msvcp140_1.dll in my System32/\r\n- Cuda 10.0 (not sure if that was necessary).\r\n- pip install tensorflow==2.0 (<-- 2.1.0 did not work!)\r\nand then it worked :)", "This is the final answer on this thread: https://github.com/tensorflow/tensorflow/issues/22794#issuecomment-573297027\r\n\r\nPlease don't spam with \"I solved it!\" and custom solutions.", "Hi, @mihaimaruseac \r\n1. Can you add new item with a description of the problems that may be cause by the lack of support for AVX command to the [instruction](https://www.tensorflow.org/install) on the site? \r\n2. \u0421an you add this [link](https://github.com/tensorflow/tensorflow/issues/19584) to the [problem list](https://www.tensorflow.org/install/errors) where __Error message__ is equal _\"ImportError: DLL load failed: The specified module could not be found.\"_\r\n3. Do you know how to create own binaries that will be without AVX support? \r\n\r\nIf some one need tensorflow whl without AVX support you can find it in this [repository](https://github.com/fo40225/tensorflow-windows-wheel), many thanks to the author. Or you can use [Intel Software Development Emulator](https://software.intel.com/en-us/articles/intel-software-development-emulator) to run original tensorflow with AVX support.\r\n\r\nTo test AVX support use [Coreinfo](https://docs.microsoft.com/en-us/sysinternals/downloads/coreinfo). \r\n", "ERROR:root:Internal Python error in the inspect module.\r\nBelow is the traceback from this internal error.\r\n\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Pankaj\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-28-ac88d38a0633>\", line 1, in <module>\r\n    flair_data, ot_data =load_dataset(PATH)\r\n  File \"<ipython-input-23-dc2f310765f5>\", line 64, in load_dataset\r\n    train_ot = np.vstack(train_ot)\r\n  File \"<__array_function__ internals>\", line 6, in vstack\r\n  File \"C:\\Users\\Pankaj\\Anaconda3\\lib\\site-packages\\numpy\\core\\shape_base.py\", line 283, in vstack\r\n    return _nx.concatenate(arrs, 0)\r\n  File \"<__array_function__ internals>\", line 6, in concatenate\r\nValueError: need at least one array to concatenate\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Pankaj\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ValueError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Pankaj\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Pankaj\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Pankaj\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Pankaj\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Pankaj\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Pankaj\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1151, in get_records\r\n    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\r\n  File \"C:\\Users\\Pankaj\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 319, in wrapped\r\n    return f(*args, **kwargs)\r\n  File \"C:\\Users\\Pankaj\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 353, in _fixed_getinnerframes\r\n    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\r\n  File \"C:\\Users\\Pankaj\\Anaconda3\\lib\\inspect.py\", line 1502, in getinnerframes\r\n    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\r\n  File \"C:\\Users\\Pankaj\\Anaconda3\\lib\\inspect.py\", line 1460, in getframeinfo\r\n    filename = getsourcefile(frame) or getfile(frame)\r\n  File \"C:\\Users\\Pankaj\\Anaconda3\\lib\\inspect.py\", line 696, in getsourcefile\r\n    if getattr(getmodule(object, filename), '__loader__', None) is not None:\r\n  File \"C:\\Users\\Pankaj\\Anaconda3\\lib\\inspect.py\", line 733, in getmodule\r\n    if ismodule(module) and hasattr(module, '__file__'):\r\n  File \"C:\\Users\\Pankaj\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Pankaj\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Pankaj\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 953, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\r\n  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\r\n  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\r\n  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\r\n  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\r\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\r\n  File \"C:\\Users\\Pankaj\\Anaconda3\\lib\\site-packages\\tensorflow_core\\__init__.py\", line 42, in <module>\r\n    from . _api.v2 import audio\r\n  File \"C:\\Users\\Pankaj\\Anaconda3\\lib\\site-packages\\tensorflow_core\\_api\\v2\\audio\\__init__.py\", line 10, in <module>\r\n    from tensorflow.python.ops.gen_audio_ops import decode_wav\r\n  File \"C:\\Users\\Pankaj\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_audio_ops.py\", line 9, in <module>\r\n    from tensorflow.python import pywrap_tensorflow as _pywrap_tensorflow\r\n  File \"C:\\Users\\Pankaj\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 50, in __getattr__\r\n    module = self._load()\r\n  File \"C:\\Users\\Pankaj\\Anaconda3\\lib\\site-packages\\tensorflow\\__init__.py\", line 44, in _load\r\n    module = _importlib.import_module(self.__name__)\r\n  File \"C:\\Users\\Pankaj\\Anaconda3\\lib\\importlib\\__init__.py\", line 127, in import_module\r\n    return _bootstrap._gcd_import(name[level:], package, level)\r\n  File \"C:\\Users\\Pankaj\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\__init__.py\", line 49, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\Pankaj\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 74, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\Pankaj\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\r\n    exec(code_obj, self.user_global_ns, self.user_ns)\r\n  File \"<ipython-input-28-ac88d38a0633>\", line 1, in <module>\r\n    flair_data, ot_data =load_dataset(PATH)\r\n  File \"<ipython-input-23-dc2f310765f5>\", line 64, in load_dataset\r\n    train_ot = np.vstack(train_ot)\r\n  File \"<__array_function__ internals>\", line 6, in vstack\r\n  File \"C:\\Users\\Pankaj\\Anaconda3\\lib\\site-packages\\numpy\\core\\shape_base.py\", line 283, in vstack\r\n    return _nx.concatenate(arrs, 0)\r\n  File \"<__array_function__ internals>\", line 6, in concatenate\r\nValueError: need at least one array to concatenate\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Pankaj\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\r\n    stb = value._render_traceback_()\r\nAttributeError: 'ValueError' object has no attribute '_render_traceback_'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\Pankaj\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\Pankaj\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\Pankaj\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\Pankaj\\Anaconda3\\lib\\imp.py\", line 242, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\Pankaj\\Anaconda3\\lib\\imp.py\", line 342, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\n\r\nFailed to load the native TensorFlow runtime.\r\n\r\nSee https://www.tensorflow.org/install/errors\r\n\r\nfor some common reasons and solutions.  Include the entire stack trace\r\nabove this error message when asking for help.", "please uninstall the latest Microsoft Visual C++ Redistributable for Visual Studio version if you install 2019 and before that\r\n\r\ndownload  Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017 and 2019 depending on your system either x64 or x86 on this website\r\n\r\nhttps://support.microsoft.com/en-my/help/2977003/the-latest-supported-visual-c-downloads", "> please uninstall the latest Microsoft Visual C++ Redistributable for Visual Studio version if you install 2019 and before that\r\n> \r\n> download Microsoft Visual C++ Redistributable for Visual Studio 2015, 2017 and 2019 depending on your system either x64 or x86 on this website\r\n> \r\n> https://support.microsoft.com/en-my/help/2977003/the-latest-supported-visual-c-downloads\r\n\r\nHi fitrialif,\r\nI did install that Micrsoft Visual C++. But the same error persists. After installing that, is there anything else I should do (moving files around,etc?)", "Seems to be a problem with TF2.1.\r\n\r\nDowngrading to TF2.0 worked for me: pip install tensorflow==2.0", "@pallyndr this is because you need to download the newest MSVC redistributable for 2.1 as mentioned in https://github.com/tensorflow/tensorflow/issues/22794#issuecomment-573297027\r\n\r\nUnfortunately as people keep piling on the thread with \"it works for me\"/\"I'm having the same issue\"/\"solved it by doing this other thing\", the actual solution in the above comment got burried.", "after I download MSVC and CUDA (I am with NVIDIA card) and cuDNN it worked. ", "Locking conversation to not get more comments that mute the solution"]}, {"number": 22793, "title": "tf.nn.softmax can give a result, when input shape is [2,3] and axis=2, Is it a bug?", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nwindows 10\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**:\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary\r\n- **TensorFlow version (use command below)**:\r\n1.10.0\r\n- **Python version**:\r\n3.5.2\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**:\r\n- **CUDA/cuDNN version**:\r\nno CUDA\r\n- **GPU model and memory**:\r\nno GPU\r\n- **Exact command to reproduce**:\r\n\r\n\r\n### Describe the problem\r\n\r\nfor  `tf.nn.softmax` , the `axis=2` but the input tensor shape is `[2,3]`.\r\nAnd the result is \r\n\r\n```\r\ntf.Tensor(\r\n[[0.5 0.5 0.5]\r\n [0.5 0.5 0.5]], shape=(2, 3), dtype=float32)\r\n```\r\n\r\nI think the axis should `>=0` and `<=1`\r\n\r\nif the `axis>=2`, it should be error.\r\n\r\n### Source code / logs\r\n\r\n```\r\nimport tensorflow as tf\r\ntf.enable_eager_execution()\r\nones = tf.ones(shape=[2,3])\r\ntemp = tf.nn.softmax(ones,axis=2)\r\nprint(temp)\r\n```\r\n", "comments": ["Added a PR #22849 for the fix.", "Nagging Assignees @drpngx, @harshini-gadige: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly."]}, {"number": 22792, "title": "Add (init) symbol names prefixed with an underscore", "body": "The command: `python -c 'from tensorflow.contrib import tensorrt as trt'` fails\r\nwith:\r\n```\r\nFile \"/xxx/lib/python2.7/site-packages/tensorflow/contrib/tensorrt/wrap_conversion.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_wrap_conversion', fp, pathname, description)\r\nImportError: dynamic module does not define init function (init_wrap_conversion)\r\n\r\n\u279c  1534993632 nm /xxx/lib/python2.7/site-packages/tensorflow/contrib/tensorrt/_wrap_conversion.so  | grep wrap_conversion\r\n0000000000003670 t _init_wrap_conversion <---------- symbol defined, but local, not exposed\r\n                 U init_wrap_conversion\r\n                 I init_wrap_conversion (indirect for init_wrap_conversion)\r\n```\r\nHappens because the linker version script has: `init_wrap_conversion` instead of `_init_wrap_conversion`\r\n\r\nxref: https://github.com/tensorflow/tensorflow/issues/21818\r\nxref: https://stackoverflow.com/a/37534357", "comments": ["Gunan are you able to take a look or reassign as necessary? Thanks!"]}, {"number": 22791, "title": "Add alternate clock_gettime() implementation for macOS < 10.12", "body": "clock_gettime is not available in macOS SDK < 10.12\r\n\r\nxref: https://github.com/tensorflow/tensorflow/issues/22636#issuecomment-426488627", "comments": []}, {"number": 22788, "title": "TFTRT User provided INT8 quantization scales", "body": "TF-TRT now supports the following quantization nodes:\r\n- QuantizeAndDequantizeV2\r\n- QuantizeAndDequantizeV3\r\n- FakeQuantWithMinMaxVars\r\n- FakeQuantWithMinMaxArgs\r\n\r\nWhen these nodes are converted:\r\n1. Their quantization ranges are extracted and stored\r\n2. The nodes are removed\r\n3. The ranges are applied to the relevant tensors\r\n\r\nThis enables a path for TF-TRT to deploy models trained with quantization in the loop, for example those trained with tf.contrib.quantize.\r\n\r\ntrt.create_inference_graph() has a new boolean argument, `use_calibration`.\r\nIf we are in INT8 mode and use_calibration=True, create_inference_graph will return a calibration graph just like it did previously.\r\nThe calibrator will not override ranges provided via quantization nodes.\r\nIf we are in INT8 mode and use_calibration=False, a warning will be issued for every tensor which does not have a calibration range. Since TRT may fuse some operations, users may not always need to provide a value for these tensors. If a tensor that TRT needs is missing, the conversion will fail.\r\n\r\nThis PR also adds support for Relu6 nodes, and fixes a bug with not renaming tensors.\r\n\r\nCurrent Issues/Considerations:\r\n- If a model was trained with quantization nodes in places where TRT will not quantize (i.e. due to op fusion), then accuracy may drop dramatically. The solution is to figure out which ops will be fused by TRT and avoid placing quantization nodes between those ops. Another option is to place clip ops with each quantization node, so that if the tensor is not quantized it will still be clipped to be in the expected range - this will impact performace negatively.\r\n- TRT does not have documentation for op fusion yet.\r\n- TRT only supports symmetric quantization. Ranges are converted to symmetric ranges using `max(abs(min_range), abs(max_range))`.\r\n- Since the tensors which are inputs and outputs to the TRTEngine are renamed to \"TensorRTInputPH_{X}\", \"TensorRTOutputPH_{X}\", if these tensors are missing ranges the warnings will not make sense to users.\r\n- MatMul and BiasAdd are not fused, requiring users to provide a range between these ops.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "> I signed it!\r\n\r\n", "CLAs look good, thanks!\n\n<!-- ok -->", "Hi @aaroey, thanks for merging in the transpose ops. I'm going to start rebasing this PR. Afterwards I will work on improving the tests and adding some C++ unit tests as well.", "Hi @aaroey, the PR is ready to go now after you review the latest changes.\r\n\r\nI have a test script to train or evaluate a simple model on MNIST using this feature. Would it make sense to include it in the test suite here? How do you handle tests which use external data (the model checkpoint in this case).", "@trevor-m thanks for making the changes, I'll take a look soon. Please add the mnist test case, it's fine to include test data as long as it's not too big. ", "Thanks for reviewing! Perhaps we should then remove Dequantize as well - it won't do much by itself and it requires inputs of qint8.", "> @trevor-m thanks for making the changes, I'll take a look soon. Please add the mnist test case, it's fine to include test data as long as it's not too big.\r\n\r\n@aaroey \r\nI have implemented all of your requested changes and I am just finishing up the tests. However I am getting this error with the MNIST test. Have you encountered this before? I suspect it has to do with how bazel is executing the test...\r\n```\r\n2018-11-09 00:41:44.473973: E tensorflow/contrib/tensorrt/convert/convert_graph.cc:660] Node construction failed withInvalid argument: Op type not registered 'TRTEngineOp' in binary running on 8eb481f0e4e9. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed. while building NodeDef 'my_trt_op_0'\r\n2018-11-09 00:41:44.474018: W tensorflow/contrib/tensorrt/convert/convert_graph.cc:1017] Engine my_trt_op_0 creation for segment 0, composed of 29 nodes failed: Invalid argument: Op type not registered 'TRTEngineOp' in binary running on 8eb481f0e4e9. Make sure the Op and Kernel are registered in the binary running in this process. Note that if you are loading a saved graph which used ops from tf.contrib, accessing (e.g.) `tf.contrib.resampler` should be done before importing the graph, as contrib ops are lazily registered when the module is first accessed. while building NodeDef 'my_trt_op_0'. Skipping...\r\n```", "Thanks @trevor-m for the changes! If the test failure is the only problem left, please upload the commits, I can help to take a look.", "Cool, thanks for all of the helpful feedback!", "Sorry it looks like it somehow automatically requested a lot of people to review - please ignore.", "Hi @trevor-m, thanks for the fix. At this point, since the PR is already in the merging state internally, it's a bit hard to merge your new changes. I can try to merge them, just FYI. If you have new changes, would you please issue a separate PR after this one is merged? Thanks.", "> Hi @trevor-m, thanks for the fix. At this point, since the PR is already in the merging state internally, it's a bit hard to merge your new changes. I can try to merge them, just FYI. If you have new changes, would you please issue a separate PR after this one is merged? Thanks.\r\n\r\nOh I see, sorry about that. If you are unable to merge any of the changes let me know which ones and I can issue a separate PR later. There won't be any other changes from now on.", "@trevor-m not a problem at all. It's my fault didn't mention that. I'll let you know how it goes later. :)", "This PR is actually merged. Not sure why it's still open like this.", "> This PR is actually merged. Not sure why it's still open like this.\r\n\r\nThanks Lambda! I probably messed it up when I pushed those commits after you had started merging.", "@trevor-m no worries I'll try again."]}, {"number": 22787, "title": "Bug fix: tf.assert_* prints the entire input by default in eager mode", "body": "With the exception of `assert_equal`, all the ops that invoke `tf.Assert` will print out their input tensors in their entirety by default when running in eager mode. This behavior is different from the behavior when running in graph mode, and it's also somewhat dangerous. For example,\r\n```\r\ntf.assert_greater(np.zeros([1000,1000], dtype=np.float32), 0.)\r\n```\r\nwill generate a five megabyte error message when running in eager mode.\r\n\r\nThis pull request changes the behavior of the `summarize` argument of `tf.Assert` (and by extension all the other ops that call `tf.Assert) to be the same in eager mode as in graph mode. Specifically, after the changes in this PR, the default number of elements to print will be 3, and values of `summarize` less than zero will cause all elements to be printed. I also added a test case.", "comments": ["@alextp can you take another look, please?"]}, {"number": 22786, "title": "1.12-rc1 cherry-pick request: Support Keras TPU model to load saved weights and predict.", "body": "PiperOrigin-RevId: 215920993", "comments": ["Can you file a bug in buganizer, assign to me, and describe the urgency of this PR?", "Thank you, Todd! Do I need to do anything about the Internal CI build failure?", "The failures are due to internal issues.  I'm going to merge now.", "Great. Thanks a lot, Todd."]}, {"number": 22785, "title": "[Intel MKL] Adding support for Depthwise 2D Convolution (fwd)", "body": "", "comments": ["@LakshayT For your review.", "It's still being worked on.", "@penpornk We've addressed all these issues internally, but we're waiting for https://github.com/tensorflow/tensorflow/pull/21483 to merge first.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this PR still valid? Assigning the `stalled` label. Please comment to reassure me that this is still being worked on.", "@penpornk We're ready to merge this. Can you review/approve?", "@claynerobison I apologize for the long delay. Could I ask you to please rebase to resolve the conflict?", "@rmlarsen We're preparing to submit a few more PRs for 1.13 that are going to cause more conflicts, so let's wait on this one. ", "@claynerobison sounds good. Thanks.", "@rmlarsen  the conflicts have been resolved. Thanks", "Hi @penpornk , It looks like the testing is stuck waiting for internal safe approval. Is there anything we need to change to pass the review?", "@agramesh1 Rasmus is on vacation starting from today. @harshini-gadige is helping me pulling the PR in right now. Hopefully it can be merged soon.", "@penpornk thanks for taking care of it. It looks like there are some failures in the internal safe checks, let us know what changes are needed. ", "@agramesh1 Unfortunately, copybara was acting strange today and this PR wasn't imported correctly. I had to apply manual fix internally and so it needed one more reviewer (since I can't review my own changes). Waiting for review right now. I'll keep you updated."]}, {"number": 22784, "title": "1.12-rc0 cherry-pick request: Fix bug in nonpip builds in ci_parameterized_build.sh", "body": "The extra spaces were confusing bash's string-line-continuation from\r\nthe backslash `\\` on the previous line.\r\n\r\nPiperOrigin-RevId: 215964853", "comments": []}, {"number": 22783, "title": "Clean up the code under INTEL_MKL_ML_ONLY", "body": "The code under INTEL_MKL_ML_ONLY is deprecated. This PR is to remove it.", "comments": []}, {"number": 22782, "title": "Rel notes 1 12", "body": "", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_author_cla -->", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n<!-- cla_yes -->", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_author_cla -->", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n<!-- cla_yes -->", "@av8ramit could you please assign to branch owner?", "We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for all the commit author(s) or Co-authors.  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_author_cla -->", "A Googler has manually verified that the CLAs look good.\n\n(Googler, please make sure the reason for overriding the CLA status is clearly documented in these comments.)\n\n<!-- cla_yes -->"]}, {"number": 22781, "title": "Update state_ops.py", "body": "fix a typo in the documentation of function batch_scatter_update.", "comments": ["\nThanks for your pull request. It looks like this may be your first contribution to a Google open source project (if not, look below for help). Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed (or fixed any issues), please reply here (e.g. `I signed it!`) and we'll verify it.\n\n----\n\n#### What to do if you already signed the CLA\n\n##### Individual signers\n\n*   It's possible we don't have your GitHub username or you're using a different email address on your commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n\n##### Corporate signers\n\n*   Your company has a Point of Contact who decides which employees are authorized to participate. Ask your POC to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the Google project maintainer to [go/cla#troubleshoot](http://go/cla#troubleshoot) ([Public version](https://opensource.google.com/docs/cla/#troubleshoot)).\n*   The email used to register you as an authorized contributor must be the email used for the Git commit. Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n*   The email used to register you as an authorized contributor must also be [attached to your GitHub account](https://github.com/settings/emails).\n\t\t\n\n<!-- need_sender_cla -->", "I signed it", "CLAs look good, thanks!\n\n<!-- ok -->", "Oops, looks like you are mistakenly trying to merge this commit into the `r1.12` release branch.  Instead, you should be merging this change into the `master` branch."]}, {"number": 22780, "title": "tf.keras doesn't work with tensorflow optimizer when using TFOptimizer", "body": "I'm trying to use tf.keras with the new AdamW optimizer in tensorflow and am running into issues. A toy version of the code is as follows:\r\n\r\n```python\r\nfrom tensorflow.contrib.opt import AdamWOptimizer\r\nfrom tensorflow.python.keras.optimizers import TFOptimizer\r\nfrom tensorflow.python.keras.layers import Dense\r\nfrom tensorflow.python.keras.models import Sequential\r\n\r\nmodel = Sequential()\r\nmodel.add(Dense(2, activation=\"tanh\", input_shape=(3,)))\r\n\r\ntfopt = AdamWOptimizer(weight_decay=0.1, learning_rate=.004)\r\noptimizer = TFOptimizer(tfopt)\r\n\r\nmodel.compile(optimizer=optimizer, loss='mean_squared_error')\r\nmodel.fit(np.random.random((5, 3)),\r\n          np.random.random((5, 2)),\r\n          epochs=5, batch_size=5)\r\n```\r\n\r\nError is as follows:\r\n\r\n```python\r\n../python3.6/site-packages/tensorflow/python/keras/engine/training.py:1605: in fit\r\n    validation_steps=validation_steps)\r\n../python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py:153: in fit_loop\r\n    outs = f(ins)\r\n../python3.6/site-packages/tensorflow/python/keras/backend.py:2978: in __call__\r\n    run_metadata=self.run_metadata)\r\n../python3.6/site-packages/tensorflow/python/client/session.py:1399: in __call__\r\n    run_metadata_ptr)\r\n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \r\n\r\nself = <tensorflow.python.framework.errors_impl.raise_exception_on_not_ok_status object at 0x11ecde550>\r\ntype_arg = None, value_arg = None, traceback_arg = None\r\n\r\n    def __exit__(self, type_arg, value_arg, traceback_arg):\r\n      try:\r\n        if c_api.TF_GetCode(self.status.status) != 0:\r\n          raise _make_specific_exception(\r\n              None, None,\r\n              compat.as_text(c_api.TF_Message(self.status.status)),\r\n>             c_api.TF_GetCode(self.status.status))\r\nE             tensorflow.python.framework.errors_impl.FailedPreconditionError: Attempting to use uninitialized value training/TFOptimizer/beta2_power\r\nE                [[{{node training/TFOptimizer/beta2_power/read}} = Identity[T=DT_FLOAT, _class=[\"loc:@training/TFOptimizer/AdamW/Assign\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](training/TFOptimizer/beta2_power)]]\r\n\r\n../python3.6/site-packages/tensorflow/python/framework/errors_impl.py:526: FailedPre\r\n```\r\n\r\n### System information\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: MacOS Mojave\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.10.0\r\n- **Python version**: 3.6\r\n- **Exact command to reproduce**: See above\r\n- **Have I written custom code**: N/A\r\n- **Bazel version**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Mobile device**: N/A\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nMobile device", "Which modules are you using to import Sequential() and Dense() functions?\r\nCan you please post all the modules you used to execute the above code snippet?", "@ymodak Just updated the code. I'm importing from `tensorflow.python.keras.layers` and `tensorflow.python.keras.models`", "Thanks for the update.  I was able to execute your script successfully in TF version 1.10 and Python 2.7.\r\nCan you test it against python 2.7 if possible?\r\nI will try to build against Python 3.6 and check if I run into the error you are observing.", "Works fine it python 2.7. Looks like it is a python 3.6 problem.", "@lminer Hi, can you use native optimizer (not TFOptimizer) directly? I think keras will take care of itself.\r\n\r\n```python\r\nfrom tensorflow.contrib.opt import AdamWOptimizer\r\nfrom tensorflow.python.keras.optimizers import TFOptimizer\r\nfrom tensorflow.python.keras.layers import Dense\r\nfrom tensorflow.python.keras.models import Sequential\r\n\r\nmodel = Sequential()\r\nmodel.add(Dense(2, activation=\"tanh\", input_shape=(3,)))\r\n\r\ntfopt = AdamWOptimizer(weight_decay=0.1, learning_rate=.004)\r\n\r\nmodel.compile(optimizer=tfopt, loss='mean_squared_error')\r\nmodel.fit(np.random.random((5, 3)),\r\n          np.random.random((5, 2)),\r\n          epochs=5, batch_size=5)\r\n```", "@facaiy it works! So is there any reason to ever use `TFOptimizer`?", "It's a private wrapper class for native tf optimizer, and I think user should not use it directly. Please check https://www.tensorflow.org/api_docs/python/tf/keras/optimizers to find all public optimizers.", "@fchollet How about renaming `TFOptimizer` to `_TFOptimizer`? Or update document for model.compile?", "Closing this issue since work around provided by @facaiy solves the problem."]}, {"number": 22779, "title": "1.12-rc0 cherry-pick request: Workaround build errors in Android NDK r14b.", "body": "PiperOrigin-RevId: 215950376", "comments": []}, {"number": 22778, "title": "1.12-rc0 cherry-pick request: [tf.data] Fix noisy warning.", "body": "PiperOrigin-RevId: 215607171", "comments": []}, {"number": 22777, "title": "1.12-rc0 cherry-pick request: [tf.data] Fix bug in `tf.data.experimental.unbatch()`.", "body": "Previously, if the rank of the input to this transformation was\r\nstatically unknown, we would erroneously report that the output is a\r\nscalar, and violate downstream shape integrity checks. Instead, in\r\nthat case the output shape should be unknown.\r\n\r\nPiperOrigin-RevId: 215683027", "comments": []}, {"number": 22776, "title": "1.12-rc0 cherry-pick request: Do 2 warmup runs in assert_no_new_pyobjects_executing_eagerly.", "body": "PiperOrigin-RevId: 215944829", "comments": []}, {"number": 22775, "title": "Keras cannot get gradient for using only one output from multi-outputs in another model", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Y\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: N/A\r\n- **TensorFlow installed from (source or binary)**:  binary\r\n- **TensorFlow version (use command below)**: 1.11.0-dev20180823\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: 9.0 / 7\r\n- **GPU model and memory**: Quadro M4000\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\nI build one keras model with two outputs. I want to build another model that is exactly just a part of the existing model by using only one output. However, it shows the error message as\r\n\r\n    ValueError: An operation has `None` for gradient. Please make sure that all of your ops have a gradient defined (i.e. are differentiable). Common ops without gradient: K.argmax, K.round, K.eval.\r\n\r\n### Source code / logs\r\nExample codes are shown below\r\n\r\n\tdef get_test0_net():\r\n\t  data_input = keras.Input(shape=(4, 4, 3))\r\n\t  x0 = Conv2D(3, 3, padding='same')(data_input)\r\n\t  x1 = Conv2D(3, 3, padding='same')(data_input)\r\n\t  return keras.Model(inputs=data_input, outputs=[x0, x1])\r\n\t  \r\n\tdef test0():\r\n\t  model = get_test0_net()\r\n\r\n\t  batch_in = np.ones((1,4,4,3))\r\n\t  batch_out = [np.zeros((1,4,4,3)), np.zeros((1,4,4,3))]\r\n\r\n        # the original model can train without problem\r\n\t#  model.compile(loss='mse', optimizer='adam')\r\n\t#  model.train_on_batch(batch_in, batch_out)\r\n\t  \r\n\t  data_input = keras.Input(shape=(4, 4, 3))\r\n\t  out = model(data_input)[0]\r\n\t  new_model = keras.Model(data_input, out)\r\n\t  new_model.compile(loss='mse', optimizer='adam')\r\n\t  new_model.train_on_batch(batch_in, batch_out[0])", "comments": ["You are asking `new_model` to compute the gradients of some weights (specifically the weights of the second `Conv2D` layer) that are not involved in the forward pass of the model. Naturally, these weights have None gradients, which is an error.\r\n\r\nMake sure that all layers you are including in your model are used."]}, {"number": 22774, "title": "Eager Execution basics lacks definition of eager execution ", "body": "Does the page [Eager Execution basics](https://www.tensorflow.org/tutorials/eager/eager_basics) have the right title? It hardly touches on eager execution, might be better named Tensor Basics.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "This is is a docs issue. But here are my details.\r\n\r\n**Have I written custom code**\r\nno\r\n\r\n**OS Platform and Distribution**\r\nMacOS High Sierra 10.13.6\r\n\r\n**TensorFlow installed from**\r\n Pip\r\n\r\n**TensorFlow version**\r\n1.10\r\n\r\n**Bazel version**\r\nn/a\r\n\r\n**CUDA/cuDNN version**\r\nn/a\r\n\r\n**GPU model and memory**\r\nn/a\r\n\r\n**Exact command to reproduce**\r\nhttps://www.tensorflow.org/tutorials/eager/eager_basics\r\n\r\n**Mobile device**n/a", "@satsumas Here is a better source for [eager execution](https://www.tensorflow.org/guide/eager). This page does touch upon how to enable eager execution and some tensors basics, but some of the materials are not very relevant. We will note this down. "]}, {"number": 22773, "title": "Tensorboard slow with S3", "body": "TensorBoard version - 1.5.1\r\nTensorFlow version if different from TensorBoard - No\r\nOS Platform and version (e.g., Linux Ubuntu 16.04) - Tensorflow installed on EC2 instance of AWS\r\n\r\nDescription of issue:\r\nI have placed all event files in S3 bucket of AWS cloud. And its content size will be around 6 GB. The problem which I am facing is that the tensorboard is very slow in scanning all the event files. It is taking more than an hour. Is there a way to reduce the processing time.", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "I am closing this issue since it is Tensorboard related query. I would encourage you to post it on [Tensorboard repository](https://github.com/tensorflow/tensorboard/issues) if you haven't already. Thanks!"]}, {"number": 22772, "title": "tf.keras.layers.SeparableConv2D fails on Cloud TPU", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes: Convnet for MNIST, hand-written\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Google Colaboratory, default versions of Python & all libraries\r\n- **Mobile device (e.g. iPhone 8, Pixel 2, Samsung Galaxy) if the issue happens on mobile device**: n/a\r\n- **TensorFlow installed from (source or binary)**: n/a\r\n- **TensorFlow version (use command below)**: n/a\r\n- **Python version**: n/a\r\n- **Bazel version (if compiling from source)**: n/a \r\n- **GCC/Compiler version (if compiling from source)**: n/a\r\n- **CUDA/cuDNN version**: n/a\r\n- **GPU model and memory**: TPU\r\n- **Exact command to reproduce**: n/a, see below\r\n\r\n### Description\r\ntf.keras.layers.SeparableConv2D fails on Cloud TPU. Colaboratory notebook with small example linked, works with GPU runtime but not TPU runtime.\r\n\r\nhttps://colab.research.google.com/drive/1TyYSeA6bq2YBT7Ngo7thHfrcrAR30aXa\r\n\r\nExpected result is successful training to >99% accuracy, this works on GPU but on TPU model.fit throws (full stack trace in notebook):\r\n\r\n```\r\n/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py in __init__(self, fetches, contraction_fn)\r\n    289       except ValueError as e:\r\n    290         raise ValueError('Fetch argument %r cannot be interpreted as a '\r\n--> 291                          'Tensor. (%s)' % (fetch, str(e)))\r\n    292       except KeyError as e:\r\n    293         raise ValueError('Fetch argument %r cannot be interpreted as a '\r\n\r\nValueError: Fetch argument <tf.Variable 'separable_conv2d_6/depthwise_kernel:0' shape=(5, 5, 1, 1) dtype=float32> cannot be interpreted as a Tensor. (Tensor Tensor(\"separable_conv2d_6/depthwise_kernel/Read/ReadVariableOp:0\", shape=(5, 5, 1, 1), dtype=float32) is not an element of this graph.)\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce\nMobile device", "Updated.", "@choongng I ran the above code snippet on TPU without running into any errors. You should see output like this:\r\n```\r\nINFO:tensorflow:Connecting to: grpc://10.10.45.90:7980\r\nTrain on 60000 samples, validate on 10000 samples\r\nEpoch 1/12\r\nINFO:tensorflow:New input shapes; (re-)compiling: mode=train, [TensorSpec(shape=(32, 28, 28, 1), dtype=tf.float32, name=u'separable_conv2d_input0'), TensorSpec(shape=(32, 10), dtype=tf.float32, name=u'dense_1_target_10')]\r\nINFO:tensorflow:Overriding default placeholder.\r\nINFO:tensorflow:Remapping placeholder for separable_conv2d_input\r\nINFO:tensorflow:Cloning Nadam {'beta_1': 0.8999999761581421, 'epsilon': 1e-07, 'schedule_decay': 0.004, 'beta_2': 0.9990000128746033, 'lr': 0.0020000000949949026}\r\nINFO:tensorflow:Get updates: Tensor(\"loss/mul:0\", shape=(), dtype=float32)\r\nINFO:tensorflow:Started compiling\r\nINFO:tensorflow:Finished compiling. Time elapsed: 2.77214789391 secs\r\nINFO:tensorflow:Setting weights on TPU model.\r\n59392/60000 [============================>.] - ETA: 0s - loss: 0.8010 - acc: 0.7334INFO:tensorflow:New input shapes; (re-)compiling: mode=train, [TensorSpec(shape=(12, 28, 28, 1), dtype=tf.float32, name=u'separable_conv2d_input0'), TensorSpec(shape=(12, 10), dtype=tf.float32, name=u'dense_1_target_10')]\r\nINFO:tensorflow:Overriding default placeholder.\r\nINFO:tensorflow:Remapping placeholder for separable_conv2d_input\r\nINFO:tensorflow:Cloning Nadam {'beta_1': 0.8999999761581421, 'epsilon': 1e-07, 'schedule_decay': 0.004, 'beta_2': 0.9990000128746033, 'lr': 0.0020000000949949026}\r\nINFO:tensorflow:Get updates: Tensor(\"loss_1/mul:0\", shape=(), dtype=float32)\r\nINFO:tensorflow:Started compiling\r\nINFO:tensorflow:Finished compiling. Time elapsed: 2.15880703926 secs\r\n59904/60000 [============================>.] - ETA: 0s - loss: 0.7972 - acc: 0.7345INFO:tensorflow:New input shapes; (re-)compiling: mode=eval, [TensorSpec(shape=(32, 28, 28, 1), dtype=tf.float32, name=u'separable_conv2d_input0'), TensorSpec(shape=(32, 10), dtype=tf.float32, name=u'dense_1_target_10')]\r\nINFO:tensorflow:Overriding default placeholder.\r\nINFO:tensorflow:Remapping placeholder for separable_conv2d_input\r\nINFO:tensorflow:Cloning Nadam {'beta_1': 0.8999999761581421, 'epsilon': 1e-07, 'schedule_decay': 0.004, 'beta_2': 0.9990000128746033, 'lr': 0.0020000000949949026}\r\nINFO:tensorflow:Started compiling\r\nINFO:tensorflow:Finished compiling. Time elapsed: 1.6451818943 secs\r\nINFO:tensorflow:New input shapes; (re-)compiling: mode=eval, [TensorSpec(shape=(2, 28, 28, 1), dtype=tf.float32, name=u'separable_conv2d_input0'), TensorSpec(shape=(2, 10), dtype=tf.float32, name=u'dense_1_target_10')]\r\nINFO:tensorflow:Overriding default placeholder.\r\nINFO:tensorflow:Remapping placeholder for separable_conv2d_input\r\nINFO:tensorflow:Cloning Nadam {'beta_1': 0.8999999761581421, 'epsilon': 1e-07, 'schedule_decay': 0.004, 'beta_2': 0.9990000128746033, 'lr': 0.0020000000949949026}\r\nINFO:tensorflow:Started compiling\r\nINFO:tensorflow:Finished compiling. Time elapsed: 1.2268679142 secs\r\n60000/60000 [==============================] - 20s 340us/step - loss: 0.7966 - acc: 0.7347 - val_loss: 0.1647 - val_acc: 0.9464\r\nEpoch 2/12\r\n60000/60000 [==============================] - 6s 96us/step - loss: 0.2937 - acc: 0.9121 - val_loss: 0.1101 - val_acc: 0.9664\r\nEpoch 3/12\r\n60000/60000 [==============================] - 6s 96us/step - loss: 0.2161 - acc: 0.9341 - val_loss: 0.1041 - val_acc: 0.9696\r\nEpoch 4/12\r\n60000/60000 [==============================] - 6s 97us/step - loss: 0.1777 - acc: 0.9449 - val_loss: 0.0703 - val_acc: 0.9792\r\nEpoch 5/12\r\n60000/60000 [==============================] - 6s 96us/step - loss: 0.1513 - acc: 0.9539 - val_loss: 0.0622 - val_acc: 0.9800\r\nEpoch 6/12\r\n60000/60000 [==============================] - 6s 95us/step - loss: 0.1393 - acc: 0.9527 - val_loss: 0.0584 - val_acc: 0.9800\r\nEpoch 7/12\r\n60000/60000 [==============================] - 6s 100us/step - loss: 0.1339 - acc: 0.9568 - val_loss: 0.0562 - val_acc: 0.9816\r\nEpoch 8/12\r\n60000/60000 [==============================] - 6s 99us/step - loss: 0.1219 - acc: 0.9605 - val_loss: 0.0785 - val_acc: 0.9776\r\nEpoch 9/12\r\n60000/60000 [==============================] - 6s 97us/step - loss: 0.1211 - acc: 0.9592 - val_loss: 0.0456 - val_acc: 0.9880\r\nEpoch 10/12\r\n60000/60000 [==============================] - 6s 96us/step - loss: 0.1093 - acc: 0.9655 - val_loss: 0.0637 - val_acc: 0.9832\r\nEpoch 11/12\r\n60000/60000 [==============================] - 6s 97us/step - loss: 0.1063 - acc: 0.9663 - val_loss: 0.0459 - val_acc: 0.9880\r\nEpoch 12/12\r\n60000/60000 [==============================] - 6s 96us/step - loss: 0.0985 - acc: 0.9696 - val_loss: 0.0491 - val_acc: 0.9880\r\n```", "Verified it's working, thanks! (cc @fchollet)", "Are all your questions answered?\r\n[Yes](https://goo.gl/forms/Oe0tEvODFRoI2gJF3)\r\n[No](https://goo.gl/forms/fUjzOfrtkFbrOT8d2)"]}]