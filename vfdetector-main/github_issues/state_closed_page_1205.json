[{"number": 17025, "title": "Adds a check for shuffle=None in numpy_input_fn", "body": "`numpy_input_fn`'s shuffle argument is set to `None` by default. If the argument is not provided, the function raises a `TypeError` since shuffle is of type `NoneType` and not `bool`.\r\n\r\nThis is fixed by adding a simple check to see if shuffle is `None`, and setting it to `False` if so.\r\n\r\nFrom my understanding, this should be the desired behavior. Do let me know if this is not the case! It doesn't seem like additional test code is needed, or any existing test code needs to be changed.\r\n\r\nThanks!", "comments": ["closed this accidentally- reopened now", "I see [here](https://github.com/tensorflow/tensorflow/commit/bcdc5c3a00a60ed0a287beb9b6decc8f99ac40f4#diff-df648dee1064f39733864796977e7326) that the default value actually used to be `True`, and that the default value was removed. @xiejw why was the default value removed? In https://github.com/tensorflow/tensorflow/blob/a3aa84f28c09b86e4961632d0e2581d06bb4a47e/tensorflow/python/data/ops/dataset_ops.py#L603-L604 for example, the dataset value is set to True by default.\r\n\r\nThanks!", "We made the default as None for purpose, as there was a debate what's the default value it should be. For training, True is the best option, but for non-training, False is more appropriate. So, the decision at that time was to ask user explicitly set rather than guess for user.\r\n\r\n@martinwicke Do we change the mind now? ", "No, if we set it to either False or True, people will ignore the argument, and do the wrong thing either in training or in eval/inference.\r\n\r\nI think None is still the right thing. However, we should either not have a default (may not be possible), or change the error to be a ValueError, and add an appropriate error message (\"You must set the shuffle argument for numpy_input_fn to either True (in training) or False (otherwise)\" or something like that).", "According to the check \r\n\r\n    raise TypeError('shuffle must be explicitly set as boolean; '\r\n                     'got {}'.format(shuffle))\t                     'got {}'.format(shuffle))\r\n\r\nThe message is ok, but can be improved. ", "How about something like:\r\n\r\n```\r\nraise ValueError('shuffle must be provided and explicitly set as boolean; '\r\n                 'got {}'.format(shuffle))\r\n```\r\n\r\nor \r\n\r\n```\r\nraise ValueError('shuffle must be provided and explicitly set as True (for training) or False (otherwise); '\r\n                 'got {}'.format(shuffle))\r\n```\r\n\r\nI like the first option since it concisely covers both the case of users not providing a value for `shuffle` and for users providing a non boolean value, but also doesn't assume the use case (users might want to shuffle in cases other than just training?)", "I think your comment is reasonable. Or a little improving like\r\n\r\n    shuffle must be provided and explicitly set as boolean (It is recommended to set as True for training). \r\n\r\n\r\n", "Nagging Reviewer : It has been 14 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "sorry for the delay. I missed the email notification. Thanks for contribution.", "just updated to fix the docstrings and test functions- the tests now run correctly on my machine"]}, {"number": 17024, "title": "Script train_image_classifier.py has no option use_nesterov in the MomentumOptimizer", "body": "**Have I written custom code:** No\r\n**OS Platform and Distribution:** Ubuntu 17.04\r\n**TensorFlow installed from:** Pip\r\n**TensorFlow version:** 1.4.0\r\n**Bazel version:** N/A\r\n**CUDA/cuDNN version:** CUDA 8.0.61, CUDNN v6\r\n**GPU model and memory:** Tesla K80\r\n**Exact command to reproduce:** N/A\r\n\r\nIn Tensorflow, the `MomentumOptimizer` has `use_nesterov` disabled by default. In the generic classifier training script - `train_image_classifier.py` - the flags do not have `use_nesterov` option (see [here](https://github.com/tensorflow/models/blob/4c05414826e87f3b8ef0534862748e4b7fcd1ec7/research/slim/train_image_classifier.py#L297) and [here](https://github.com/tensorflow/models/blob/4c05414826e87f3b8ef0534862748e4b7fcd1ec7/research/slim/train_image_classifier.py#L116)), which makes it real easy to miss the fact that it is not being used. I think an additional flag should be introduced in the optimizer section of `train_image_classifier.py`.\r\n\r\nP.S. Why was the decision taken to disable `use_nesterov`? I tried searching online if there were any disadvantages associated with Nesterov momentum but did not come up with much. [The paper referenced in Tensorflow documentation](http://proceedings.mlr.press/v28/sutskever13.pdf) only encourages the use of Nesterov momentum versus classical momentum. Am I missing something?", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 91 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 17023, "title": "Adds a check for shuffle=None in numpy_input_fn", "body": "`numpy_input_fn`'s shuffle argument is set to `None` by default. If the argument is not provided, the function raises a `TypeError` since shuffle is of type `NoneType` and not `bool`.\r\n\r\nThis is fixed by adding a simple check to see if `shuffle` is `None`, and setting it to `False` if so.\r\n\r\nFrom my understanding, this should be the desired behavior. Do let me know if this is not the case! It doesn't seem like additional test code is needed, or any existing test code needs to be changed.\r\n\r\nThanks!", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_author_cla -->"]}, {"number": 17022, "title": "Is python 3.7.x supported with Tensorflow", "body": "Ive been trying to install Tensorflow on my computer which currently runs python 3.7, however I keep running into some common issues... And each time i try to use the solutions provided, nothing works. \n\nIm not sure, but Im guessing python 3.7 might not be supported considering the official Tensorflow page has no link to python 3.7, that maybe this is the reason I havent been able to correctly install Tensorflow.", "comments": ["Python 3.7 isn't eventually officially supported by Python. It's still in beta testing, and very much under active development.\r\n\r\nFor now, stick with Python 3.6.", "now\uff0cit's ok.", "Python 3.7 appears to be official now, (\"final release\" on June 27th).", "I don't think Python 3.7 support is ready yet. For homebrew users landing on this page, simply point to an older Formula file for Python.\r\n\r\n```\r\nbrew install https://raw.githubusercontent.com/Homebrew/homebrew-core/f2a764ef944b1080be64bd88dca9a1d80130c558/Formula/python.rb\r\n```\r\n\r\nI found this from https://github.com/Homebrew/homebrew-core/commits/master/Formula/python.rb.", "I sill get\r\n```shell\r\n> pip3 install -U  tensorflow\r\nCollecting tensorflow\r\n  Could not find a version that satisfies the requirement tensorflow (from versions: )\r\nNo matching distribution found for tensorflow\r\n```", "I am getting the same ^", "I am trying to  use tensorflow to differentiate cats and dogs images (following this [tutorial:](https://www.youtube.com/watch?v=Ge65ukmJTzQ&index=2&list=PLQVvvaa0QuDf5h6si5lUbTh4ejzTQVJCW) )on python 3.7 .but i get the following  error ..\r\n```\r\n`Traceback (most recent call last):\r\n  File \"C:\\Users\\donka\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\r\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])\r\n  File \"C:\\Users\\donka\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 297, in find_module\r\n    raise ImportError(_ERR_MSG.format(name), name=name)\r\nImportError: No module named '_pywrap_tensorflow'\r\n```\r\n\r\n`During handling of the above exception, another exception occurred`:\r\n\r\n```\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\donka\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 54, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\donka\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 28, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"C:\\Users\\donka\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-\r\n```packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\r\n    import _pywrap_tensorflow\r\nModuleNotFoundError: No module named '_pywrap_tensorflow'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\donka\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Users\\donka\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 60, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\donka\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\r\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])\r\n  File \"C:\\Users\\donka\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 297, in find_module\r\n    raise ImportError(_ERR_MSG.format(name), name=name)\r\nImportError: No module named '_pywrap_tensorflow'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\donka\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 54, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\donka\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 28, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"C:\\Users\\donka\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\r\n    import _pywrap_tensorflow\r\nModuleNotFoundError: No module named '_pywrap_tensorflow'\r\n\r\n\r\nError importing tensorflow.  Unless you are using bazel,\r\nyou should not try to import tensorflow from its source directory;\r\nplease exit the tensorflow source tree, and relaunch your python interpreter\r\nfrom there.`\r\n\r\nIs this regard to the compatibility of 3.7python version with tensorflow ...plz help", "I changed my python interpreter to Python 3.6 64 bit rather than 3.7 and it now works, no longer getting import errors or:\r\n\r\n```\r\nCollecting tensorflow\r\n  Could not find a version that satisfies the requirement tensorflow (from versions: )\r\nNo matching distribution found for tensorflow\r\n```", "You can install tensorflow on mac with pre-built wheel, https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.9.0-py3-none-any.whl . However, it gives syntax error when you import. ", "guys need help , i am unable to install tensorflow on python 3.7 .\r\n\r\nshould be re consider to downgrade it ?  ", "@ramaakkantvdas try downgrading to python 3.6 as suggested by @jaiken06. This worked for me as well.", "@toby-w , thanks , but it worked using this line : python -m pip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-0.12.0-py3-none-any.whl\r\n\r\n\r\nTensorFlow works on Python 3.7", "what version of tensorflow is this link? 0.12? \r\nseems to not work with Keras, am I alone?", "Trying to install the Tensorflow API through pip in a virtual environment results in this:\r\n\r\n`Collecting tensorflow\r\n  Could not find a version that satisfies the requirement tensorflow (from versions: )\r\nNo matching distribution found for tensorflow`\r\n\r\nHas tensorflow not officially been released yet?", "Thanks ramaakkantvdas , I successfully installed the Tensorflow on my python 3.7 using the line you recommended  but when I tried to import it, I got the following error, anyone know how to solve it, please?\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\r\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])\r\n  File \"C:\\Python37\\lib\\imp.py\", line 297, in find_module\r\n    raise ImportError(_ERR_MSG.format(name), name=name)\r\nImportError: No module named '_pywrap_tensorflow'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Python37\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 54, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 28, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"C:\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\r\n    import _pywrap_tensorflow\r\nModuleNotFoundError: No module named '_pywrap_tensorflow'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<pyshell#0>\", line 1, in <module>\r\n    import tensorflow\r\n  File \"C:\\Python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Python37\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 60, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\r\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])\r\n  File \"C:\\Python37\\lib\\imp.py\", line 297, in find_module\r\n    raise ImportError(_ERR_MSG.format(name), name=name)\r\nImportError: No module named '_pywrap_tensorflow'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Python37\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 54, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 28, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"C:\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\r\n    import _pywrap_tensorflow\r\nModuleNotFoundError: No module named '_pywrap_tensorflow'\r\n\r\n\r\nError importing tensorflow.  Unless you are using bazel,\r\nyou should not try to import tensorflow from its source directory;\r\nplease exit the tensorflow source tree, and relaunch your python interpreter\r\nfrom there.\r\n\r\n", "hey guys i managed to install , \r\n\r\nbut when i import tensorflow i got the following error .\r\n\r\nimport tensorflow as tf\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\ramaa\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\r\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])\r\n  File \"C:\\Users\\ramaa\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\imp.py\", line 297, in find_module\r\n    raise ImportError(_ERR_MSG.format(name), name=name)\r\nImportError: No module named '_pywrap_tensorflow'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\ramaa\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 54, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\ramaa\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 28, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"C:\\Users\\ramaa\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\r\n    import _pywrap_tensorflow\r\nModuleNotFoundError: No module named '_pywrap_tensorflow'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"<stdin>\", line 1, in <module>\r\n  File \"C:\\Users\\ramaa\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n    from tensorflow.python import *\r\n  File \"C:\\Users\\ramaa\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 60, in <module>\r\n    raise ImportError(msg)\r\nImportError: Traceback (most recent call last):\r\n  File \"C:\\Users\\ramaa\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\r\n    fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])\r\n  File \"C:\\Users\\ramaa\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\imp.py\", line 297, in find_module\r\n    raise ImportError(_ERR_MSG.format(name), name=name)\r\nImportError: No module named '_pywrap_tensorflow'\r\n\r\nDuring handling of the above exception, another exception occurred:\r\n\r\nTraceback (most recent call last):\r\n  File \"C:\\Users\\ramaa\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 54, in <module>\r\n    from tensorflow.python import pywrap_tensorflow\r\n  File \"C:\\Users\\ramaa\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 28, in <module>\r\n    _pywrap_tensorflow = swig_import_helper()\r\n  File \"C:\\Users\\ramaa\\AppData\\Local\\Programs\\Python\\Python37-32\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\r\n    import _pywrap_tensorflow\r\nModuleNotFoundError: No module named '_pywrap_tensorflow'\r\n\r\n\r\nError importing tensorflow.  Unless you are using bazel,\r\nyou should not try to import tensorflow from its source directory;\r\nplease exit the tensorflow source tree, and relaunch your python interpreter\r\nfrom there.", "i am not sure how to go about from here ,.. can someone throw some light here ,.\r\n\r\nError is : No module named '_pywrap_tensorflow'\r\n\r\n", "I think I solve my problem...I deleted the tensorflow folder in (Lib>site-packages)path and downloaded new tensor Zip file from this link https://github.com/tensorflow/tensorflow, then extracted it and put it instead of the older tensorflow\r\n", "great Fatima ,i need to check and try  i will get back and let you all know ", "yeah, i am facing the same issues with python 3.7", "I am also facing same issues. I need a whl file of tensorflow-gpu. If anyone built it please mmail me to sukeshpabolu@gmail.com", "Is there an ETA for Python 3.7 support?", "Hello FatimaShahad, witch file did you get on the github? I found this list, but I don\u00b4t know witch file I have to download to follow your instruction... Can you help me?\r\nBy the way, I alread download the TensorFlow 0.12, that ramaakkantvdas recomended...\r\n\r\nThanks\r\n\r\nc\tfix C++ header guards.\t5 days ago\r\ncc\tReplaced calls to tensorflow::StringPiece::ToString with string conve\u2026\t4 days ago\r\ncompiler\tRun AddSpecialCaseCopies in HloRematerialization.\t2 days ago\r\ncontrib\tExpose the RegAdagradOptimizer (which allows the user to specify whet\u2026\t14 hours ago\r\ncore\tMake registration macro namespace-agnostic\t2 days ago\r\ndocs_src\tUpdate TensorFlow.js roadmap\t2 days ago\r\nexamples\tReplaced calls to tensorflow::StringPiece::ToString with string conve\u2026\t4 days ago\r\ng3doc\tRemove usage of magic-api-link syntax from source files.\t17 days ago\r\ngo\tGo: Update generated wrapper functions for TensorFlow ops.\t2 days ago\r\njava\tMerge pull request #21770 from skavulya:rename-ecosystem-jars\t4 days ago\r\njs\tGenerate TypeScript Op attribute values for \"type\" and \"int\" OpDef at\u2026\t2 days ago\r\npython\tcompat: Update forward compatibility horizon to 2018-08-26\t8 hours ago\r\nsecurity\tMerge pull request #20725 from yongtang:20722-TFSA-2018-001\ta month ago\r\nstream_executor\tRemoved redundant std::string -> string conversions.\t2 days ago\r\ntools\tUpgrade Keras applications and Keras preprocessing.\t2 days ago\r\n.clang-format\tAdd a .clang-format file for automatically formatting .cc/.h files.\t2 years ago\r\nBUILD\tMerge pull request #21122 from NervanaSystems:master\t5 days ago\r\n__init__.py\tfix cmake python 2.7 test import fail\t2 months ago\r\napi_template.__init__.py\tInternal Change.\t2 months ago\r\ntensorflow.bzl\tMerge pull request #21122 from NervanaSystems:master\t5 days ago\r\ntf_exported_symbols.lds\tPython library and C++ bindings for creating and compiling local XLA \u2026\t8 months ago\r\ntf_framework_version_script.lds\tMerge changes from github.\t2 months ago\r\ntf_version_script.lds\tPython library and C++ bindings for creating and compiling local XLA \u2026\t8 months ago\r\nversion_check.bzl\tRolling back tensorflow .bzl file changes\t2 months ago\r\nworkspace.bzl\t[TF:XLA] Bump open source llvm revision to r340606\t2 days ago", "sorry: \r\nI meant \"which\" and not \"witch\"\r\n\r\n", "Now i\u00b4m with this problem:\r\nError importing tensorflow.  Unless you are using bazel,\r\nyou should not try to import tensorflow from its source directory;\r\nplease exit the tensorflow source tree, and relaunch your python interpreter\r\nfrom there.", "Hello ciribellialvaro, I couldn't import tensorflow too so I download python 3.6 and everything is fine now", "@jaiken06 or anyone, how did you downgrade to python 3.6? I installed python with yum on an ec2 instance and couldn't figure out how to downgrade correctly ", "please try using this link https://www.python.org/downloads/\r\n\r\nor you might have to search it via google . i already had the installer file so hence i was saved of some worries . \r\n\r\nTensorflow works fine in python 3.6 . i had issues in 3.7 hence downgraded . ", "@ramaakkantvdas I'm running on an EC2 instance, so I can't use a download link :/ ", "@AlexFine : i have no idea about AWS instances , please check with the support . i am working on windows .so i have installed on it . so yours must be Linux instances . you might have to check with python community forums as there you might be getting some answers . ", "Hello Alex,\n\nYou can try unistall the python 3.7 on the control panel, then, download\nthe python 3.6 and install.\n\nBut, the lesson 234 of the course Machine Learng, I only did on the Visual\nStudio Code...\n\nTks\n\n*\u00c1lvaro Ciribelli Borges*\n\n\n\nEm ter, 11 de set de 2018 \u00e0s 01:58, Ramakanth Das <notifications@github.com>\nescreveu:\n\n> please try using this link https://www.python.org/downloads/\n>\n> or you might have to search it via google . i already had the installer\n> file so hence i was saved of some worries .\n>\n> Tensorflow works fine in python 3.6 . i had issues in 3.7 hence downgraded\n> .\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/17022#issuecomment-420146308>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AnUwOW_Hd4h_9yR4oUeAMwZIfMZqQeb1ks5uZ0LqgaJpZM4SGKVk>\n> .\n>\n", "I found this to work after searching for a while. I will leave this here as it might be useful for someone and save some time.\r\n\r\nTensorflow only supports Python 3.6 as of today. You can install a different version of python alongside your standard one. You need to:\r\n- Download the Python3.6 tgz file from the official website (eg. Python-3.6.6.tgz)\r\n- Unpack it with `tar -xvzf Python-3.6.6.tgz`\r\n- `cd Python-3.6.6`\r\n- run `./configure`\r\n- run `make altinstall` to install it (`install` vs `altinstall` explanation here https://stackoverflow.com/questions/16018463/difference-in-details-between-make-install-and-make-altinstall)\r\n\r\nYou'll normally find your new python install under `/usr/local/bin`. Now you can create a new virtualenv specifying the python version with:\r\n- `virtualenv --python=python3.6 env3.6`\r\n- Get into the virtualenv running the command `source env3.6/source/bin/activate`.\r\n- Install tensorflow with the classic `pip install tensorflow`\r\n- Profit", "Is there a timeline yet for when TensorFlow will support 3.7 or if they are working towards it, or are we still in the dark?", "> Is there a timeline yet for when TensorFlow will support 3.7 or if they are working towards it, or are we still in the dark?\r\n\r\nSean , we found an work around for time being , Dont know when it would be supported or start working . ", "For installation part this works: `python3 -m pip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.9.0-py3-none-any.whl`\r\n\r\nBut on 3.7, post installaion you will face other issues, \r\nsolved this one https://github.com/tensorflow/tensorflow/issues/20690\r\nbut still stuck on this https://github.com/tensorflow/tensorflow/issues/21472\r\n", "Will wait till tensorflow is installed via pip install tensorflow. Someone have to build it for linux as a wheel and udpate to pypi.org.", "For me worked to install Python3.6.4 and no later ... even 3.6.5 fails (and later of course).\r\nInstall Python3.6 from here:\r\nhttps://www.python.org/downloads/mac-osx/ \r\nWorks ", "I have tried several ways finally downgraded to Python 3.6.6. Thank God, finally, tensorflow and keras installed successfully without any issues just by pip itself.\r\n\r\nC:\\Python36\\Scripts>pip install keras\r\nC:\\Python36\\Scripts>pip install tensorflow\r\n\r\nThanks for your info and comments regarding this issue guys. They were really helpful. Keep posting, Thanks once again.", "Perfect! \r\nI was frustrated as well till I found the solution.\r\n\r\nplease upvote.\r\nAnd [here](https://stackoverflow.com/questions/51235428/does-tensorflow-1-9-support-python-3-7/52783694#52783694) as well (just look for **Finally Worked for me!**)\r\nThanks!", "@nathaniel-lemonade The link you provided shows 3.6*. \r\nI can't downgrade cos I'm already using some features of 3.7 on my project. \r\n\r\nAny solution yet on this?", "I got the same issue with Python 3.7, I just use conda to reinstall tensorflow and keras dependencies. \r\n[https://docs.continuum.io/anaconda/install/](url)\r\n\r\nAnd it fix the problem : \r\n\r\n`conda install tensorflow keras`", "#Its python and tensorflow version compatibily issue on Windows 10\r\n\r\ni have Uninstall existing tensorflow \r\n\r\nUse commnad:\r\nconda install tensorflow keras\r\n\r\nThis itself degrade installed python version from 3.7 to 3.6.6 and tensorflow version 1.11.0\r\n\r\nNow tensorflow works perfectly!! :)\r\n\r\n\r\n>python\r\nPython 3.6.6...\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> print(tf.__version__)\r\n1.11.0\r\n", "> \r\n> \r\n> I got the same issue with Python 3.7, I just use conda to reinstall tensorflow and keras dependencies.\r\n> [https://docs.continuum.io/anaconda/install/](url)\r\n> \r\n> And it fix the problem :\r\n> \r\n> `conda install tensorflow keras`\r\n\r\nIt seems that this works on my system:\r\n- Windows 10\r\n- Python 3.7\r\n\r\nLaunching conda install tensorflow keras downgrade from python 3.7 to 3.6 and then install tensorflow.\r\n\r\nThanks!!!", "Hi everyone,\n\nI solve the problem unistalling everything: Anaconda, Ptyhon, Spyder...\nRestarted the laptop, installed the anaconda again, opened it, and then I\nclicked on \"environments\" to install Theano, tensorflow, and Keras, in this\norder.\nAfter that, I restarted the lap top again, and everything worked.\nbut unfortunately, I recently changed my normal HD for an SSD, and my\nwindows is not accepting to install Anaconda!\n\n*\u00c1lvaro Ciribelli Borges*\n*+55 (31) 98822-9972*\n\n\nEm qua, 24 de out de 2018 \u00e0s 11:33, nidhibansal1902 <\nnotifications@github.com> escreveu:\n\n> #Its python and tensorflow version compatibily issue on Windows 10\n>\n> i have Uninstall existing tensorflow\n>\n> Use commnad:\n> conda install tensorflow keras\n>\n> This itself degrade installed python version from 3.7 to 3.6.6 and\n> tensorflow version 1.11.0\n>\n> Now tensorflow works perfectly!! :)\n>\n> python\n> Python 3.6.6...\n> Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>\n> import tensorflow as tf\n> print(tf.*version*)\n> 1.11.0\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/17022#issuecomment-432680401>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AnUwOUuL4dTOmn6f8BCyC1dHYEzCZkUoks5uoHpDgaJpZM4SGKVk>\n> .\n>\n", "```\r\nMac OS 10.13.6\r\n\r\npython --version\r\nPython 3.7.0\r\n\r\npip3 install -U  tensorflow\r\nCollecting tensorflow\r\n  Could not find a version that satisfies the requirement tensorflow (from versions: )\r\nNo matching distribution found for tensorflow\r\n```", "I had same problems as you guys, trying to install tensorflow with the pip install command and I had the same error (\"could not find....\"). Now, reading the comments, I'm understanding that there are two solutions to the problem. 1) downgrade python 3.7 to 3.6.6 and repeat the pip install command. 2) download anaconda package and do everything through anaconda, that' right? no other solutions?", "> \r\n> \r\n> I had same problems as you guys, trying to install tensorflow with the pip install command and I had the same error (\"could not find....\"). Now, reading the comments, I'm understanding that there are two solutions to the problem. 1) downgrade python 3.7 to 3.6.6 and repeat the pip install command. 2) download anaconda package and do everything through anaconda, that' right? no other solutions?\r\n\r\nIn my case I created a new environment and then launch  \"conda install tensorflow keras\". Then everything worked fine.", "@lemillos thank you for answering me. Please, could you be more precise ? What I have to do step by step ? Install Conda package and then simply type on my cmd conda install tensorflow keras? What are you meaning for \"create a new environment\"? Do you mean a virtual environment? You would help me a lot, thank you anyway", "Im using Anaconda 5.3.1(released on 19th Nov, 2018) which by default installs python 3.7.0. \r\nBut when i try to install keras , using **conda install -c conda-forge keras** ,\r\n it  is taking eternity to respond.\r\nAlso pip install keras aslo not working with python 3.7.0\r\nconda install tensorflow  - not working\r\npip install tensorflow - not working !\r\n\r\n\r\nDowngrading to py3.6\r\n\r\n", "Im using Anaconda 5.3.1(released on 19th Nov, 2018) which by default installs python 3.7.0. \r\nBut when i try to install keras , using **conda install -c conda-forge keras** ,\r\n it  is taking eternity to respond.\r\nAlso pip install keras aslo not working with python 3.7.0\r\nconda install tensorflow  - not working\r\npip install tensorflow - not working !\r\n\r\n\r\nDowngrading to py3.6\r\n\r\n", "on win 10 python 3.7 I ran\r\n\r\nconda install tensorflow-gpu  --dry-run \r\n\r\n\r\nafter about 5minutes it provided a remedy which included downgrading to py 3.6.7\r\n\r\n\r\nThis suggest to me you can create an enviorment within or in addition to your base install loading it with python 36 .. Check the docs its not that complicated .  I did this with pyhon 2.7 a long time ago.\r\n\r\nAfter re-vist ", "If you have a mac system, the following command will help you install tensorflow on your machine.\r\nP.S. It does work with Python 3.7\r\n\r\npython3 -m pip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.3.0-py3-none-any.whl\r\nThanks!", "> @lemillos thank you for answering me. Please, could you be more precise ? What I have to do step by step ? Install Conda package and then simply type on my cmd conda install tensorflow keras? What are you meaning for \"create a new environment\"? Do you mean a virtual environment? You would help me a lot, thank you anyway\r\n\r\nSure, but i am assuming that:\r\n1. You've installed Anaconda and conda command on cmd works fine.\r\n2. Your system is a Windows one\r\n\r\nSo: \r\n- Create a new environment:  _conda create -n tensorflow_ or _conda create --name tensorflow_\r\n- Go into your new environment: _source activate tensorflow_ or _conda activate tensorflow_\r\n- Install tensorflow keras: _conda install tensorflow keras_\r\n\r\nRegards. ", "> Python 3.7 appears to be official now, (\"final release\" on June 27th).\r\n\r\nNo, It may be official, but it still isn't \"installable\", unless of course, the name has changed. the error I got was  -  \r\n\r\nCollecting Tensorflow (from -r pythonEnv.txt (line 26))\r\n  Could not find a version that satisfies the requirement Tensorflow (from -r pythonEnv.txt (line 26)) (from versions: )\r\nNo matching distribution found for Tensorflow (from -r pythonEnv.txt (line 26))\r\n\r\n**on Python 3.7**\r\n", "@MaximusIndus That was about Python 3.7, not Tensorflow.  https://www.python.org/dev/peps/pep-0537/#release-schedule", "True, \r\nI think Python is expendable none use whatsoever as it just survives on Open source - Undependable Open Source at that. ", "Better to move to motivated, money driven Sucker.", "> I got the same issue with Python 3.7, I just use conda to reinstall tensorflow and keras dependencies.\r\n> [https://docs.continuum.io/anaconda/install/](url)\r\n> \r\n> And it fix the problem :\r\n> \r\n> `conda install tensorflow keras`\r\n\r\nGreat it works on centos", "Python 3.7 didn't support TensoFlow.\r\nI can use TensorFlow by using Python 3.6.\r\nIf you want to use TensorFlow, install python3.6 and use it.", "diagressing a bit from OP...\r\nBERT (NLP) needs Tensorflow 1.10.0 or higher and the same is available only if I have Python 3.6.5 on Windows PC (x64)", " I got the same issue with Python 3.7, I tried running  reinstall tensorflow and keras dependencies. this didnt work , error log below  ,need help to resolve this please \r\n\r\n(base) C:\\Users\\sumanth>conda install tensorflow keras\r\nSolving environment: failed\r\n\r\nUnsatisfiableError: The following specifications were found to be in conflict:\r\n  - anaconda==2018.12=py37_0 -> bleach==3.0.2=py37_0\r\n  - anaconda==2018.12=py37_0 -> mkl-service==1.1.2=py37hb782905_5\r\n  - anaconda==2018.12=py37_0 -> numexpr==2.6.8=py37hdce8814_0\r\n  - anaconda==2018.12=py37_0 -> scikit-learn==0.20.1=py37h343c172_0\r\n  - tensorflow\r\nUse \"conda info <package>\" to see the dependencies for each package.\r\n", "create an environment and use python 36. install spyder and pandas with conda. Install tensorflow-gpu with pip.  I suggested this before on an earlier post. Tensorflow recommends pip not conda.  \r\n", "> If you have a mac system, the following command will help you install tensorflow on your machine.\r\n> P.S. It does work with Python 3.7\r\n> \r\n> python3 -m pip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.3.0-py3-none-any.whl\r\n> Thanks!\r\n\r\nthats tf-1.3 while tf-1.12 is out", "It's stupid to me that python 3.7 is still not support yet..", "Why is this issue closed? Tensorflow doesn't support Python 3.7 yet.. Or is there a different issue that tracks Python 3.7 support?  \r\n", "May I humbly suggest that someone with permissions lock this issue, to limit comments to collaborators? That'd prevent spam for those of us watching this issue to get notified about when 3.7 support lands. Thanks.", "below works for Windows 8.1, python 3.7.1 (installed via Miniconda)\r\nthen install the below wheel files:\r\nnumpy\u20111.16.0+mkl\u2011cp37\u2011cp37m\u2011win_amd64.whl\r\nprotobuf\u20113.6.1\u2011cp37\u2011cp37m\u2011win_amd64.whl\r\ntensorflow\u20111.9.0\u2011cp37\u2011cp37m\u2011win_amd64.whl\r\nfrom Christoph Gohlke's \"Unofficial Windows Binaries for Python Extension Packages\" site.", "> I am trying to use tensorflow to differentiate cats and dogs images (following this [tutorial:](https://www.youtube.com/watch?v=Ge65ukmJTzQ&index=2&list=PLQVvvaa0QuDf5h6si5lUbTh4ejzTQVJCW) )on python 3.7 .but i get the following error ..\r\n> \r\n> ```\r\n> `Traceback (most recent call last):\r\n>   File \"C:\\Users\\donka\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\r\n>     fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])\r\n>   File \"C:\\Users\\donka\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 297, in find_module\r\n>     raise ImportError(_ERR_MSG.format(name), name=name)\r\n> ImportError: No module named '_pywrap_tensorflow'\r\n> ```\r\n> `During handling of the above exception, another exception occurred`:\r\n> \r\n> ```\r\n> Traceback (most recent call last):\r\n>   File \"C:\\Users\\donka\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 54, in <module>\r\n>     from tensorflow.python import pywrap_tensorflow\r\n>   File \"C:\\Users\\donka\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 28, in <module>\r\n>     _pywrap_tensorflow = swig_import_helper()\r\n>   File \"C:\\Users\\donka\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-\r\n> ```packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\r\n>     import _pywrap_tensorflow\r\n> ModuleNotFoundError: No module named '_pywrap_tensorflow'\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n>   File \"<stdin>\", line 1, in <module>\r\n>   File \"C:\\Users\\donka\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\__init__.py\", line 24, in <module>\r\n>     from tensorflow.python import *\r\n>   File \"C:\\Users\\donka\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 60, in <module>\r\n>     raise ImportError(msg)\r\n> ImportError: Traceback (most recent call last):\r\n>   File \"C:\\Users\\donka\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 18, in swig_import_helper\r\n>     fp, pathname, description = imp.find_module('_pywrap_tensorflow', [dirname(__file__)])\r\n>   File \"C:\\Users\\donka\\AppData\\Local\\Programs\\Python\\Python37\\lib\\imp.py\", line 297, in find_module\r\n>     raise ImportError(_ERR_MSG.format(name), name=name)\r\n> ImportError: No module named '_pywrap_tensorflow'\r\n> \r\n> During handling of the above exception, another exception occurred:\r\n> \r\n> Traceback (most recent call last):\r\n>   File \"C:\\Users\\donka\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\__init__.py\", line 54, in <module>\r\n>     from tensorflow.python import pywrap_tensorflow\r\n>   File \"C:\\Users\\donka\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 28, in <module>\r\n>     _pywrap_tensorflow = swig_import_helper()\r\n>   File \"C:\\Users\\donka\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 20, in swig_import_helper\r\n>     import _pywrap_tensorflow\r\n> ModuleNotFoundError: No module named '_pywrap_tensorflow'\r\n> \r\n> \r\n> Error importing tensorflow.  Unless you are using bazel,\r\n> you should not try to import tensorflow from its source directory;\r\n> please exit the tensorflow source tree, and relaunch your python interpreter\r\n> from there.`\r\n> \r\n> Is this regard to the compatibility of 3.7python version with tensorflow ...plz help\r\n> ```\r\n\r\nnow is support python3.7.x+win10+tensorflow?", "From https://pypi.org/project/tensorflow/#files or https://pypi.tuna.tsinghua.edu.cn/simple/tensorflow/ , I see no python3.7 support now.", "I have built the .whl for tensorflow 1.12.0 with python 3.7.2\r\npip3 install tensorflow-1.12.0-cp37-cp37m-linux_x86_64.whl\r\nensure pip3 is pointing to 3.7.2\r\nfile is here https://bit.ly/2FBoFs2\r\nright now only cpu build is available", "So Python 3.7 is still not supported even if it is 2019 now.", "quite amazing that Google didnt make any move for this long time... ", "I was stuck on installing.\r\n\r\nAll websites for tensorflow don't work with regular tensorflow install instructions.\r\nUsing tf-nightly does let me install without a problem on Python 3.7.2 (x64).", "> I was stuck on installing.\r\n> \r\n> All websites for tensorflow don't work with regular tensorflow install instructions.\r\n> Using tf-nightly does let me install without a problem on Python 3.7.2 (x64).\r\n\r\nI switched back to Python 3.6. Do not use the latest Anaconda since it comes with Python 3.7.", "After everything I tried, I finally decided to switch back on Python 3.6.8  : : Anaconda.\r\nAnd now tensorflow is working for me!\r\nHere is the command for it!\r\n\r\n**conda install tensorflow keras**", "As of now, tensorflow does not work with Python 3.7. \r\n\r\nIf you are using Anaconda, do the following: \r\n`conda install python=3.6`\r\nThen\r\n`conda install tensorflow keras`\r\n\r\nDone and save yourself the headaches. ", "#25429 ", "On Windows, this distribution works for me:\r\nhttps://github.com/fo40225/tensorflow-windows-wheel", "`!pip install tf-nightly`\r\n\r\nThis works for me :D", "> As of now, tensorflow does not work with Python 3.7.\r\n> \r\n> If you are using Anaconda, do the following:\r\n> `conda install python=3.6`\r\n> Then\r\n> `conda install tensorflow keras`\r\n> \r\n> Done and save yourself the headaches.\r\n\r\n", "the ONLY perfect option..Thanks", "I was just able to successfully install tensorflow on default python 3.7.2\nbuilt from scratch (under Fedora 29).\n\n~>pip3 install tensorflow\nCollecting tensorflow\n  Downloading\nhttps://files.pythonhosted.org/packages/be/80/18adfb46ba0a4044e9feaa0897ceae4673ac07d34deeb74490bc0d4e4987/tensorflow-1.13.0rc1-cp37-cp37m-manylinux1_x86_64.whl\n(92.7MB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 92.7MB 697kB/s\n\nInstalling collected packages: ... , tensorflow\nSuccessfully installed ... tensorflow-1.13.0rc1\ntensorflow-estimator-1.13.0rc0\n\n\nOn Mon, 11 Feb 2019 at 07:48, shalin4788 <notifications@github.com> wrote:\n\n> the ONLY perfect option..Thanks\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/17022#issuecomment-462170530>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABNtFjD9Z7kZQHOoYwmnnXhGXG9e7i9Xks5vMIWRgaJpZM4SGKVk>\n> .\n>\n\n\n-- \nHope dies last, the saying goes; expectations, though, may outlive hope.\n", "Also can confirm Python 3.7.2 on macOS Mojave is able to install tensorflow.\r\n```\r\nLast login: Thu Feb  7 13:56:17 on ttys002\r\nIvande-MacBook-Pro:~ lifehome$ python3 --version\r\nPython 3.7.2\r\nIvande-MacBook-Pro:~ lifehome$ pip3 install tensorflow\r\nCollecting tensorflow\r\n  Downloading https://files.pythonhosted.org/packages/8a/71/0d71554808f4ccb837a95a23c353f5feea705be6c5ef1967bd03a79f146b/tensorflow-1.13.0rc1-cp37-cp37m-macosx_10_11_x86_64.whl (73.6MB)\r\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 73.6MB 402kB/s\r\n\r\n\r\n...\r\n\r\nSuccessfully built termcolor absl-py gast\r\nInstalling collected packages: six, numpy, keras-preprocessing, protobuf, markdown, werkzeug, grpcio, tensorboard, astor, pbr, mock, absl-py, tensorflow-estimator, termcolor, gast, h5py, keras-applications, tensorflow\r\nSuccessfully installed absl-py-0.7.0 astor-0.7.1 gast-0.2.2 grpcio-1.18.0 h5py-2.9.0 keras-applications-1.0.7 keras-preprocessing-1.0.9 markdown-3.0.1 mock-2.0.0 numpy-1.16.1 pbr-5.1.2 protobuf-3.6.1 six-1.12.0 tensorboard-1.12.2 tensorflow-1.13.0rc1 tensorflow-estimator-1.13.0rc0 termcolor-1.1.0 werkzeug-0.14.1\r\n```", "Hello,\r\nAnyone was able to compile tensorflow-gpu for Python 3.7.x ? Thanks", "works fire for me as well.  (latest nvidia driver on Fedora 29)\n\nOn Mon, 11 Feb 2019 at 23:11, Waleed El-Badry <notifications@github.com>\nwrote:\n\n> Hello,\n> Anyone was able to compile tensorflow-gpu for Python 3.7.x ? Thanks\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/17022#issuecomment-462305483>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/ABNtFoeVnoeSicATUYod4J-TaSb7wb7bks5vMV3cgaJpZM4SGKVk>\n> .\n>\n", "TF v1.13.0-rc1 cpu version now works for me on python 3.7.2 (high sierra). Installs and imports just fine.\r\n\r\nedit: According to https://github.com/tensorflow/tensorflow/issues/20517#issuecomment-461910761, both cpu and gpu versions should be available on all OSes.", "TensorFlow v1.13.0rc1 is now working for me on python 3.7.0 on windows 10. i had to upgrade my numpy package to v1.16.1 to overcome some few errors.", "Yes, to reiterate: The 1.13.0rc1 release includes Python3.7 binaries for all OS-es for [cpu](https://pypi.org/project/tensorflow/1.13.0rc1/#files) and [gpu](https://pypi.org/project/tensorflow-gpu/1.13.0rc1/#files). ", "> \r\n> \r\n> Yes, to reiterate: The 1.13.0rc1 release includes Python3.7 binaries for all OS-es for [cpu](https://pypi.org/project/tensorflow/1.13.0rc1/#files) and [gpu](https://pypi.org/project/tensorflow-gpu/1.13.0rc1/#files).\r\n\r\nMay I get the CUDA/CUDNN versions that was tested with Windows 10 x64 and Python 3.7.x?\r\n", "> May I get the CUDA/CUDNN versions that was tested with Windows 10 x64 and Python 3.7.x?\r\n\r\nYou may check the release notes for at least some info:\r\n\r\n> TensorFlow GPU binaries are now built against CUDA 10 and TensorRT 5.0.\r\nhttps://github.com/tensorflow/tensorflow/releases\r\n\r\nAnd for CUDA 10, there is only CuDNN 7 (namely, 7.3.0, 7.3.1, 7.4.1, 7.4.2) as far as I can see.", "Hello,\r\nI can confirm now TensorFlow Nightly Build GPU works with \r\n\r\n- Windows 10 x64\r\n- NVIDIA CUDA 10.0.130_411.31\r\n- CuDNN 7.4.2.24\r\n- Python 3.7.2\r\n- tf-nightly-gpu 1.13.0.dev20190211\r\n\r\n![Testing TensorFlow](https://serving.photos.photobox.com/28518925056f65b4fcac54d46779a679943ad4a159c27b47b4496749186386ed66418b66.jpg)\r\n", "Tensorflow works with python 3.7 , \r\n\r\npip install tensorflow==1.13.1", "![image](https://user-images.githubusercontent.com/18187666/55610455-85fa9600-57b5-11e9-8f56-58078ae7d6d8.png)\r\n![image](https://user-images.githubusercontent.com/18187666/55610491-9f034700-57b5-11e9-9a7b-a1185bbf90f3.png)\r\nI installded the tensorflow, but can't import it.\r\nAnyone know how to fix it?", "I would recommend using nightly build and check if it is solved.", "Thanks, it worked.", "> I changed my python interpreter to Python 3.6 64 bit rather than 3.7 and it now works, no longer getting import errors or:\r\n> \r\n> ```\r\n> Collecting tensorflow\r\n>   Could not find a version that satisfies the requirement tensorflow (from versions: )\r\n> No matching distribution found for tensorflow\r\n> ```\r\n\r\nHi please can you let me know how I can change interpreter and install with 3.6 pls?", "[Tensorflow 1.13.1](https://github.com/tensorflow/tensorflow/releases/tag/v1.13.1) now supports Python 3.7.", "> pip install tensorflow==1.13.1\r\n> \r\n> pip install tensorflow\r\n> \r\n> tried all above but still no support with current python version (3.7.2)\r\n\r\nYou should try the nigthly build.\r\n", "Great that TensorFlow 1 finally supports Python 3.7! This page should probably be updated to reflect that: https://www.tensorflow.org/install/pip (currently, it says that for Python 3, only 3.4, 3.5 and 3.6 are suported)\r\n\r\nDoes this mean that Python 3.7 is also supported by the preview release of [TensorFlow 2.0 Alpha](https://www.tensorflow.org/alpha)?", "@lamberta who can update that in the appropriate places.\r\n\r\n[Yes](https://pypi.org/manage/project/tensorflow/release/2.0.0a0/) it is.", "Currently Python 3.7 \"pip install tensorflow\" still doesn't work\r\nhttps://pypi.org/project/tensorflow/ <- shows\r\n![https://i.imgur.com/RNP653z.png](https://i.imgur.com/RNP653z.png)\r\n![https://i.imgur.com/GhdykYT.png](https://i.imgur.com/GhdykYT.png)", "<img width=\"1313\" alt=\"Screen Shot 2019-04-25 at 8 37 04 AM\" src=\"https://user-images.githubusercontent.com/16280574/56739911-7081e780-6735-11e9-85e7-fd4aa2809932.png\">\r\nWorks for me, both tensorflow 2.0 and 1.13 could be found", "@PathToLife this seems like a configuration issue. Can you please open a new GitHub issue with additional information. I can confirm the binaries for all three OS's for Python3.7 are there.", "Can confirm the URLs here for the 3.7 package: \r\nhttps://www.tensorflow.org/install/pip#package-location", "There still seems to be no [complete URL](https://www.tensorflow.org/install/pip#package-location) for Python 3.7 and Windows, which is what the installation instructions tells you to use when using Conda. I.e. accordingly, Python 3.7 is still off limits for Conda on Windows.", "Actually, I don't know whether this intuition is correct or not. I was using pip install keras in a virtual environment of Python 2.7 but it was of no use and when I did import keras, it didn't work. Later I did pip install Keras. A capital 'K' and then it worked. Maybe, try it.", "**tensorflow-gpu** works well on **Python 3.7.2**\r\n**OS :** Windows 10 x64\r\n**Python** : 3.7.2\r\n**CUDA** : 10\r\n**CUDNN** : 7.5\r\n\r\n\r\n![2019-06-26_11-00-44](https://user-images.githubusercontent.com/5664750/60166651-d9eba880-9801-11e9-82b4-d67e92416209.png)\r\n", "Seems like 3.7 been added to the package index now.\r\nhttps://pypi.org/project/tensorflow/\r\n\r\n> Currently Python 3.7 \"pip install tensorflow\" still doesn't work\r\n> https://pypi.org/project/tensorflow/ <- shows\r\n> ![https://i.imgur.com/RNP653z.png](https://camo.githubusercontent.com/a1253d8f71c8acaa686fa33b27410bc548d1f756/68747470733a2f2f692e696d6775722e636f6d2f524e503635337a2e706e67)\r\n> ![https://i.imgur.com/GhdykYT.png](https://camo.githubusercontent.com/f920f85fe15098b4bbba08b626064ba6c9009d16/68747470733a2f2f692e696d6775722e636f6d2f476864796b59542e706e67)\r\n\r\n", "tensorflow-gpu works well on Python 3.7.3\r\nOS : Windows 10 x64\r\nPython : 3.7.3\r\nCUDA : 10.0\r\nCUDNN : 7.6.1.34", "It has been a year. Is TensorFlow ever going to update to the supported version of Python or are we forever stuck in 2018?", "Hey @StevenGann can you please clarify? Which version would you like supported on which OS? I believe TF supports Python3.7 on both CPU and GPU on all our supported OS-es which is why this issue was opened.", "pip install tensorflow==1.13.1\r\nit works for me on Python 3.7\r\nGood Luck.", "> \r\n> \r\n> pip install tensorflow==1.13.1\r\n> it works for me on Python 3.7\r\n> Good Luck.\r\n\r\nfor me still not i think google team fix this patch otherwise you guys told me ", "hi\r\nconda install -c hesi_m tensorflow\r\nok :-)", "@ali289 now problem is solved for tensorflow and python 3.7 you can access that thank you team ", "Yes, python 3.7.3 with tensorflow 1.14.0 and keras 2.2.5, keras sequential model working perfect in Tornado API", "Hi, I am still facing the problem of installing tensorflow in python 3.7. Can anyone help me to solve or any clarification?", "this may help you\n\nhttps://docs.anaconda.com/anaconda/user-guide/tasks/tensorflow/\n\nOn Thu, Sep 12, 2019 at 12:10 PM Sahan Ruwanga <notifications@github.com>\nwrote:\n\n> Hi, I am still facing the problem of installing tensorflow in python 3.7.\n> Can anyone help me to solve or any clarification?\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/17022?email_source=notifications&email_token=AEIS7RMZLO7YULYO4H7FA6LQJHP67A5CNFSM4EQYUVSKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD6Q2E5I#issuecomment-530686581>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AEIS7ROX7TXR355ZQJYMCA3QJHP67ANCNFSM4EQYUVSA>\n> .\n>\n", "this may help you\nhttps://docs.anaconda.com/anaconda/user-guide/tasks/tensorflow/\n\nOn Thu, Sep 12, 2019 at 12:10 PM Sahan Ruwanga <notifications@github.com>\nwrote:\n\n> Hi, I am still facing the problem of installing tensorflow in python 3.7.\n> Can anyone help me to solve or any clarification?\n>\n> \u2014\n> You are receiving this because you commented.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/17022?email_source=notifications&email_token=AEIS7RMZLO7YULYO4H7FA6LQJHP67A5CNFSM4EQYUVSKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD6Q2E5I#issuecomment-530686581>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AEIS7ROX7TXR355ZQJYMCA3QJHP67ANCNFSM4EQYUVSA>\n> .\n>\n", "@kalanka29 thanks for your information. is there a way to install tensorflow without anaconda? It works fine on anaconda and I need it without anaconda.\r\n", "![image](https://user-images.githubusercontent.com/9469239/68040694-97edda00-fcad-11e9-8982-0da96632e39a.png)\r\nStill having issues here, I believe we should be able to install tf on python 3.7 without anaconda.", "> \r\n> \r\n> ![image](https://user-images.githubusercontent.com/9469239/68040694-97edda00-fcad-11e9-8982-0da96632e39a.png)\r\n> Still having issues here, I believe we should be able to install tf on python 3.7 without anaconda.\r\n\r\nYeah! try python 64-bit version. tensorflow 2.0 is working fine for me in there!", "> > ![image](https://user-images.githubusercontent.com/9469239/68040694-97edda00-fcad-11e9-8982-0da96632e39a.png)\r\n> > Still having issues here, I believe we should be able to install tf on python 3.7 without anaconda.\r\n> \r\n> Yeah! try python 64-bit version. tensorflow 2.0 is working fine for me in there!\r\n\r\nThanks that worked! I wonder why I didn't have installed the x64 version", "OS : Windows 10 Pro\r\nPython 3.7.6\r\nStill not able to install Tensorflow in 2020.\r\n\r\n![image](https://user-images.githubusercontent.com/10788426/73738438-78fa5a80-476a-11ea-8e04-9c272707163c.png)\r\n\r\n", "Your log says `No matching distribution found for tensroflow`\r\n\r\n`tensroflow`", "Ahh got it..stupid typo !", "For those still experiencing issues with installing Tensorflow with Python 3.7, here is a proposed solution, especially if you are using Intel CPUs to run your workloads. In an activated conda environment with Python 3.7.x:\r\n\r\n```\r\npython -v\r\nPython 3.7.6 (default, Jan  8 2020, 19:59:22)\r\n[GCC 7.3.0] :: Anaconda, Inc. on linux\r\n```\r\n\r\nExecute: \r\n`conda install tensorflow=1.15 `\r\n\r\nIn the list of packages to be installed, you should see:\r\n`tensorflow         pkgs/main/linux-64::tensorflow-1.15.0-mkl_py37h28c19af_0`\r\n\r\n\r\nThis should install Tensorflow version 1.15 with the latest Intel MKL-DNN optimizations for best performance on Intel CPUs. \r\n\r\n", "As mentioned in the [pip install guide](https://www.tensorflow.org/install/pip#2.-create-a-virtual-environment-recommended), Conda is *not* officially supported and is provided by the Conda community. And the [last update](https://anaconda.org/conda-forge/tensorflow) looks like it was 4 months ago", "> As mentioned in the [pip install guide](https://www.tensorflow.org/install/pip#2.-create-a-virtual-environment-recommended), Conda is _not_ officially supported and is provided by the Conda community. And the [last update](https://anaconda.org/conda-forge/tensorflow) looks like it was 4 months ago\r\n\r\nGood point and good catch. Then, let's rephrase it differently: If the official pip method does not work for you, the community-supported method could help. ", "Traceback (most recent call last):\r\n  File \"C:\\Users\\taye\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow.py\", line 58, in <module>\r\n    from tensorflow.python.pywrap_tensorflow_internal import *\r\n  File \"C:\\Users\\taye\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 28, in <module>\r\n    _pywrap_tensorflow_internal = swig_import_helper()\r\n  File \"C:\\Users\\taye\\Anaconda3\\envs\\tensor\\lib\\site-packages\\tensorflow_core\\python\\pywrap_tensorflow_internal.py\", line 24, in swig_import_helper\r\n    _mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)\r\n  File \"C:\\Users\\taye\\Anaconda3\\envs\\tensor\\lib\\imp.py\", line 243, in load_module\r\n    return load_dynamic(name, filename, file)\r\n  File \"C:\\Users\\taye\\Anaconda3\\envs\\tensor\\lib\\imp.py\", line 343, in load_dynamic\r\n    return _load(spec)\r\nImportError: DLL load failed: The specified module could not be found.\r\n\r\nDuring handling of the above exception, another exception occurred:", "Hi all,\r\npip install tensorflow==1.13.1\r\nIts work for me, but when i create new project then there is tensorflow 2.1 avaliable, that doesnot work. How can i make tensorflow == 1.13.1 for every project same. \r\nPlease need help", "@taye1 \r\n\r\nPlease see: https://github.com/tensorflow/tensorflow/issues/36167#issuecomment-577886156", "**Hello guys!! I have a problem with installing _Tensorflow_!**\r\n**Python 3.7.3 (v3.7.3:ef4ec6ed12, Mar 25 2019, 21:26:53) [MSC v.1916 32 bit (Intel)] on win32**\r\n\r\n**How to install it ???**", "TF does not work on 32 bits.", "Is there an alternative to Tensorflow for 32-bit users?", "You can use Google Colab notebooks, just like other Google Drive files and have your code run in the cloud.\r\n\r\nGCP also offers VMs suited for deep learning that could be used in the cloud", "> Trying to install the Tensorflow API through pip in a virtual environment results in this:\r\n> \r\n> `Collecting tensorflow Could not find a version that satisfies the requirement tensorflow (from versions: ) No matching distribution found for tensorflow`\r\n> \r\n> Has tensorflow not officially been released yet?\r\n\r\nit's released but,not supported yet,.... Downgrade it\r\n"]}, {"number": 17021, "title": "sigmoid_cross_entropy Docstring bug", "body": "### Describe the problem\r\nTf.losses.sigmoid_cross_entory parameter description of label indicates it has to be \"integer\" and in range (0,1). There are no integers between (0,1) so that seems really difficult to abide by. \r\nIt seems that in the code it does not need to be integer and the range should be [0, 1]. \r\nhttps://www.tensorflow.org/api_docs/python/tf/losses/sigmoid_cross_entropy\r\n\r\nP.S. Why does softmax_cross_entropy assume one-hot encoding? For instance in distillation your labels are softmax outputs (floats in [0, 1]). ", "comments": ["+1 This parameter description was hilariously confusing.", "+1. The line \r\n\r\n`multi_class_labels = math_ops.cast(multi_class_labels, logits.dtype)\r\n`\r\nCasts multi_class_labels to the logits.dtype anyways, so there shouldn't be the integer requirement.", "@drpngx  can you please take a look?\r\n", "From the code, it looks like it just wants binary labels. I read the doc to mean either `0` or `1`. Feel free to send a PR to clarify the doc."]}, {"number": 17020, "title": "\"DeprecationWarning: The binary mode of fromstring is deprecated\" warning appears in some cases", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: Binary, tf-nightly\r\n- **TensorFlow version (use command below)**: 1.7.0.dev20180214, git version b2a0f1c\r\n- **Python version**: 2.7.12\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**:\r\n\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.contrib.image.ops import gen_distort_image_ops\r\nfrom tensorflow.python.framework import tensor_util\r\ntensor_util.constant_value(tf.convert_to_tensor([1., 1.]))\r\n```\r\n\r\n### Describe the problem\r\nWhen I run the program above, I get the warning\r\n```\r\n/home/reedwm/venvs/tfnightlycpu/local/lib/python2.7/site-packages/tensorflow/python/framework/tensor_util.py:560: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\r\n  return np.fromstring(tensor.tensor_content, dtype=dtype).reshape(shape)\r\n```\r\n\r\nThis may not seem so bad, but when running [`tf_cnn_benchmarks`](https://github.com/tensorflow/benchmarks/tree/master/scripts/tf_cnn_benchmarks), I get hundreds of such warnings.\r\n\r\nWhat's very strange is that if I comment the line `from tensorflow.contrib.image.ops import gen_distort_image_ops`, I don't get the warning.\r\n\r\nThis is the same issue as ppwwyyxx/tensorpack#641. @yaroslavvb, did you file a TensorFlow bug for this? If so, this can be marked as a duplicate.\r\n\r\nNot really sure who to triage this to. /CC @mrry, can you address this or retriage?\r\n", "comments": ["@reedwm Have you tried switching `np.fromstring()` to `np.frombuffer()` on that line?", "Yeah that works. I'll submit a CL.\r\n\r\nI am curious why the issue goes away if I comment `from tensorflow.contrib.image.ops import gen_distort_image_ops` though."]}, {"number": 17019, "title": "Branch 185747281", "body": "", "comments": []}, {"number": 17017, "title": "Integration of \"Tensor Comprehensions\"?", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Not relevant\r\n- **TensorFlow installed from (source or binary)**: Not relevant\r\n- **TensorFlow version (use command below)**: Not relevant\r\n- **Python version**: Not relevant\r\n- **Bazel version (if compiling from source)**: Not relevant\r\n- **GCC/Compiler version (if compiling from source)**: Not relevant\r\n- **CUDA/cuDNN version**: Not relevant\r\n- **GPU model and memory**: Not relevant\r\n- **Exact command to reproduce**: Not relevant\r\n\r\n### Describe the problem\r\nFAIR just released an initial version of their [Tensor Comprehension Framework](https://research.fb.com/announcing-tensor-comprehensions/) which I think is a really clever concept. The Tensor comprehension library allows to define functions with a syntax similar to einstein-notation and then compiles these functions into fast GPU code via evolutionary search. Is this something you would consider including into the core or would you rather favor an integration as a separate framework?\r\n\r\nCheers,\r\nPhil\r\n", "comments": ["Thanks for your suggestion. Please check out XLA.", "@bignamehyp how is XLA a replacement of Tensor Comprehension?", "@neocxi it's not indeed. If we omit the user-facing and language-level aspects of TC, our positioning is strictly below the graph-level abstraction. TC gives a first reasonable answer to: \"I have a subgraph, what is a good implementation of that subgraph on target hardware X\". \r\nOur hope is that your favorite graph-level compiler/engine (XLA, NNVM, nGraph, TensorRT, Caffe2, ONNX, ...) starts providing HPC kernel synthesis. \r\nBut I'm sure all these aforementioned solutions have something that fits the bill in the works.", "I alt for the auto-tuner and the polyhedral solution to maximize the NN implementation since it's already kind of canonicalized.\r\n ", "Why is this issue closed?"]}, {"number": 17016, "title": "Error in `tfe.implicit_gradients(loss)` in eager mode", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: \r\n- **TensorFlow version (use command below)**: 1.5.0\r\n- **Python version**: 3.6\r\n- **Bazel version (if compiling from source)**:\r\n- **GCC/Compiler version (if compiling from source)**: 7.2.0\r\n- **CUDA/cuDNN version**: -\r\n- **GPU model and memory**: -\r\n- **Exact command to reproduce**:\r\n---\r\n\r\nI was trying to run MNIST model in `Eager` mode on Kaggle Kernels but as I am passing data to my model, the optimizer is throwing this particular error :\r\n`ValueError: No trainable variables were accessed while the function was being computed.` I can confirm that the data being passed to the model are non-zero and are in the correct shape. I don't understand why is the model is throwing the error then. Here is my code:\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.eager as tfe\r\n\r\ntfe.enable_eager_execution()\r\n\r\nclass MNIST(object):\r\n    def __init__(self, data_format):\r\n        # Set the input shape according to the availability of GPU \r\n        if data_format == 'channels_first':\r\n            self._input_shape = [-1, 1, 28, 28]\r\n        else:\r\n            self._input_shape = [-1, 28, 28, 1]\r\n        \r\n        self.conv1 = tf.layers.Conv2D(32, 3, \r\n                                      activation=tf.nn.relu, \r\n                                      padding='same', \r\n                                      data_format=data_format)\r\n        \r\n        self.maxpool = tf.layers.MaxPooling2D((2,2), (2,2), \r\n                                            padding='same', \r\n                                            data_format=data_format)\r\n        \r\n        self.conv2 = tf.layers.Conv2D(64, 3, \r\n                                      activation=tf.nn.relu, \r\n                                      padding='same', \r\n                                      data_format=data_format)\r\n        \r\n        self.dense1 = tf.layers.Dense(1024, activation=tf.nn.relu)\r\n        self.dropout = tf.layers.Dropout(0.5)\r\n        self.dense2 = tf.layers.Dense(10)\r\n        \r\n        \r\n \r\n    def predict(self, inputs):\r\n        x = tf.reshape(inputs, self._input_shape)\r\n        x = self.conv1(x)\r\n        x = self.maxpool(x)\r\n        x = self.conv2(x)\r\n        x = self.maxpool(x)\r\n        x = tf.layers.flatten(x)\r\n        x = self.dense1(x)\r\n        x = self.dropout(x) #enable at training and disable at testing\r\n        x = self.dense2(x)\r\n        return x\r\n\r\n# Define loss functions\r\ndef loss(model, inputs, targets):\r\n    return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\r\n                          logits=model.predict(inputs), labels=targets))\r\n\r\n# Calculate accuracy\r\ndef compute_accuracy(predictions, labels):\r\n    model_pred = tf.argmax(predictions, axis=1,output_type=tf.int64)\r\n    actual_labels = tf.argmax(labels, axis=1, output_type=tf.int64)\r\n    return tf.reduce_sum(tf.cast(tf.equal(model_pred, actual_labels)),dtype=tf.float32) / float(predictions.shape[0].value)\r\n\r\ndevice = \"gpu:0\" if tfe.num_gpus() else \"cpu:0\"\r\nmodel = MNIST('channels_first' if tfe.num_gpus() else 'channels_last')\r\noptimizer = tf.train.AdamOptimizer(learning_rate=1e-4)\r\ngrad = tfe.implicit_gradients(loss)\r\n\r\nbatch_size = 8\r\ntrain_batches = len(X_train) // batch_size\r\nvalid_batches = len(X_valid) // batch_size\r\nnb_epochs = 5\r\n\r\nfor i in range(nb_epochs):\r\n    with tf.device(device):\r\n        for j in range(train_batches):\r\n            inputs, targets = next(train_data_gen)\r\n            optimizer.apply_gradients(grad(model, inputs, targets))\r\n            if j % 10 == 0:\r\n                print(\"Step %d: Loss on training set : %f\" %(i, loss(model, inputs, targets).numpy()))\r\n        \r\n", "comments": ["@AakashKumarNain does #15682 help shed any light on your problem? \r\nhttps://github.com/tensorflow/tensorflow/issues/15682", "@cy89 I already looked into it and that's very different case from mine. That's why I opened up a new issue", "@AakashKumarNain I'm sorry, I should have asked before: do you have a backtrace or other debug information you can also post?", "@cy89 I don't know if this helps much but this is all I got. As soon as the first batch of data comes from the generator, I think forward pass works fine but during backprop, something is wrong. Please see the full error log below:\r\n\r\n```\r\nIncoming data shape: (8, 28, 28, 1) (8, 10)\r\nWARNING:tensorflow:From <ipython-input-14-22dc84f65208>:4: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\n\r\nFuture major versions of TensorFlow will allow gradients to flow\r\ninto the labels input on backprop by default.\r\n\r\nSee tf.nn.softmax_cross_entropy_with_logits_v2.\r\n\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-16-7bd0e7654c19> in <module>()\r\n      9             inputs, targets = next(train_data_gen)\r\n     10             print(\"Incoming data shape:\", inputs.shape, targets.shape)\r\n---> 11             optimizer.apply_gradients(grad(model, inputs, targets))\r\n     12             if j % 10 == 0:\r\n     13                 print(\"Step %d: Loss on training set : %f\" %(i, loss(model, inputs, targets).numpy()))\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py in grad_fn(*args, **kwds)\r\n    416   def grad_fn(*args, **kwds):\r\n    417     \"\"\"Computes the gradient of the wrapped function.\"\"\"\r\n--> 418     return implicit_val_and_grad(f)(*args, **kwds)[1]\r\n    419 \r\n    420   return grad_fn\r\n\r\n/opt/conda/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py in grad_fn(*args)\r\n    361 \r\n    362     if not sources:\r\n--> 363       raise ValueError(\"No trainable variables were accessed while the \"\r\n    364                        \"function was being computed.\")\r\n    365     grad = imperative_grad.imperative_grad(_default_vspace,\r\n\r\nValueError: No trainable variables were accessed while the function was being computed.\r\n\r\n\r\n\r\n```", "@cy89 Any updates on this?", "@AakashKumarNain : Is it possible that there is some issue with your input generation? I'm unable to reproduce the problem after following the very similar example in the [eager user guide](https://github.com/tensorflow/tensorflow/blob/eb38b9c/tensorflow/contrib/eager/python/g3doc/guide.md#using-keras-and-the-layers-api) or even after modifying the portion of your snippet that feeds the data (since the snippet didn't include the definitions of `X_train` and `train_data_gen` etc. I could not repeat your setup). Specifically, I used your snippet all up to the line `batch_size = 8` and then replaced the remainder with:\r\n\r\n```python\r\nfrom tensorflow.examples.tutorials.mnist import input_data\r\ndata = input_data.read_data_sets(\"./mnist_data\", one_hot=True)\r\nnb_epochs = 5\r\nbatch_size = 8\r\nfor i in range(nb_epochs):\r\n    with tf.device(device):\r\n        for j in range(20):\r\n            (inputs, targets) = data.train.next_batch(batch_size)\r\n            optimizer.apply_gradients(grad(model, inputs, targets))\r\n            if j % 10 == 0:\r\n                print(\"Step %d: Loss on training set : %f\" %(i, loss(model, inputs, targets).numpy()))\r\n```\r\n\r\nI suspect there is something weird about how you're creating `inputs` and `targets`.", "@asimshankar I don't think there is any problem with my generator code. Anyways, I am putting up my generator code also, so that you can take another look:\r\n\r\n```python\r\n# Reshape the data\r\nX_train = np.array(X_train.iloc[:, :]).reshape(len(X_train),28,28,1)\r\nX_valid = np.array(X_valid.iloc[:, :]).reshape(len(X_valid), 28, 28,1)\r\nX_test = np.array(test.iloc[:,1:]).reshape(len(test), 28, 28,1)\r\n\r\nprint(\"X_train shape: \", X_train.shape)\r\nprint(\"X_valid.shape: \", X_valid.shape)\r\nprint(\"X_test.shape: \", X_test.shape)\r\n\r\nX_train = X_train.astype(np.float32)\r\nX_valid = X_valid.astype(np.float32)\r\nX_test = X_test.astype(np.float32)\r\n\r\ntrain_mean = X_train.mean()\r\n\r\n# Mean subtraction from pixels\r\nX_train -= train_mean\r\nX_valid -= train_mean\r\nX_test -= train_mean\r\n\r\n# Normalization\r\nX_train /=255.\r\nX_valid /=255.\r\nX_test /=255.\r\n\r\n# One Hot Encoding(OHE)\r\ny_train = to_categorical(y_train, num_classes=10).astype(np.int8)\r\ny_valid = to_categorical(y_valid, num_classes=10).astype(np.int8)\r\n\r\n#A simple generator\r\ndef data_gen(data, labels, batch_size=8):\r\n    n = len(data)\r\n    batch_data = np.zeros((batch_size, 28, 28, 1), dtype=np.float32)\r\n    batch_labels = np.zeros((batch_size,10), dtype=np.int8)\r\n    indices = np.arange(n)\r\n    i =0\r\n    while True:\r\n        np.random.shuffle(indices)\r\n        #print(indices,\"\\n\")\r\n        next_batch = indices[(i*batch_size):(i+1)*batch_size]\r\n        for j, idx in enumerate(next_batch):\r\n            batch_data[j] = data[idx]\r\n            batch_labels[j] = labels[idx]\r\n        \r\n        yield batch_data, batch_labels\r\n        i +=1  \r\n\r\n# create generator instance for training and validation \r\ntrain_data_gen = data_gen(X_train, y_train)\r\nvalid_data_gen = data_gen(X_valid, y_valid)\r\n```", "Can you provide a minimal self contained example that reproduces the problem? The code snippets provided so far seem to refer to code not already included (eg `to_categorical`). \r\n\r\nSince I am unable to reproduce the problem (see my previous comment, where is very used your model definition and was able to create a working training loop), it's hard to provide advice. Thanks. ", "@asimshankar Here is the completer code. For downloading the data, visit [this](https://www.kaggle.com/zalando-research/fashionmnist) page.\r\n\r\n```python\r\nimport os\r\nimport glob\r\nfrom pathlib import Path\r\nimport numpy as np # linear algebra\r\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\r\nimport matplotlib.pyplot as plt\r\nimport seaborn as sns\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.eager as tfe\r\nfrom keras.preprocessing import image\r\nfrom skimage.io import imread, imsave, imshow\r\nfrom keras.utils import to_categorical\r\nfrom sklearn.model_selection import train_test_split\r\n\r\nnp.random.seed(111)\r\n\r\n#Read the train and test csv first\r\ntrain = pd.read_csv('../input/fashion-mnist_train.csv')\r\ntest = pd.read_csv('../input/fashion-mnist_test.csv')\r\nprint(\"Number of training samples: \", len(train))\r\nprint(\"Number of test samples: \", len(test))\r\n\r\n\r\nlabels = train[\"label\"]\r\ntrain = train.drop([\"label\"], axis =1)\r\n\r\n# Split the training dataset into training and validation sets\r\nX_train, X_valid, y_train, y_valid = train_test_split(train, labels, test_size=0.2, random_state=111)\r\nprint(\"Number of samples in the train set: \", len(X_train))\r\nprint(\"Number of samples in the validation set: \", len(X_valid))\r\n\r\n\r\n\r\n# Reshape the data\r\nX_train = np.array(X_train.iloc[:, :]).reshape(len(X_train),28,28,1)\r\nX_valid = np.array(X_valid.iloc[:, :]).reshape(len(X_valid), 28, 28,1)\r\nX_test = np.array(test.iloc[:,1:]).reshape(len(test), 28, 28,1)\r\nprint(\"X_train shape: \", X_train.shape)\r\nprint(\"X_valid.shape: \", X_valid.shape)\r\nprint(\"X_test.shape: \", X_test.shape)\r\n\r\n\r\nX_train = X_train.astype(np.float32)\r\nX_valid = X_valid.astype(np.float32)\r\nX_test = X_test.astype(np.float32)\r\n\r\ntrain_mean = X_train.mean()\r\n\r\n# Mean subtraction from pixels\r\nX_train -= train_mean\r\nX_valid -= train_mean\r\nX_test -= train_mean\r\n\r\n# Normalization\r\nX_train /=255.\r\nX_valid /=255.\r\nX_test /=255.\r\n\r\n# One Hot Encoding(OHE)\r\ny_train = to_categorical(y_train, num_classes=10).astype(np.int8)\r\ny_valid = to_categorical(y_valid, num_classes=10).astype(np.int8)\r\n\r\n\r\n\r\n# We will define our model now.\r\nclass MNIST(object):\r\n    def __init__(self, data_format):\r\n        # Set the input shape according to the availability of GPU \r\n        if data_format == 'channels_first':\r\n            self._input_shape = [-1, 1, 28, 28]\r\n        else:\r\n            self._input_shape = [-1, 28, 28, 1]\r\n        \r\n        # Start defining the type of layers that you want in your network\r\n        self.conv1 = tf.layers.Conv2D(32, 3, activation=tf.nn.relu, padding='same', data_format=data_format)\r\n        self.maxpool = tf.layers.MaxPooling2D((2,2), (2,2), padding='same', data_format=data_format)\r\n        self.conv2 = tf.layers.Conv2D(64, 3, activation=tf.nn.relu, padding='same', data_format=data_format)\r\n        self.dense1 = tf.layers.Dense(1024, activation=tf.nn.relu)\r\n        self.dropout = tf.layers.Dropout(0.5)\r\n        self.dense2 = tf.layers.Dense(10)\r\n        \r\n        \r\n    #Combine the layers to form the architecture\r\n    def predict(self, inputs, drop=False):\r\n        x = tf.reshape(inputs, self._input_shape)\r\n        x = self.conv1(x)\r\n        x = self.maxpool(x)\r\n        x = self.conv2(x)\r\n        x = self.maxpool(x)\r\n        x = tf.layers.flatten(x)\r\n        x = self.dense1(x)\r\n        x = self.dropout(x, training=drop) #enable at training and disable at testing\r\n        x = self.dense2(x)\r\n        return x\r\n\r\n# Define loss functions\r\ndef loss(model, inputs, targets, drop=False):\r\n    return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model.predict(inputs, drop=drop), labels=targets))\r\n\r\n# Calculate accuracy\r\ndef compute_accuracy(predictions, labels):\r\n    model_pred = tf.argmax(predictions, axis=1,output_type=tf.int64)\r\n    actual_labels = tf.argmax(labels, axis=1, output_type=tf.int64)\r\n    return tf.reduce_sum(tf.cast(tf.equal(model_pred, actual_labels)),dtype=tf.float32) / float(predictions.shape[0].value)        \r\n\r\n\r\n\r\n#A simple generator\r\ndef data_gen(data, labels, batch_size=8):\r\n    n = len(data)\r\n    batch_data = np.zeros((batch_size, 28, 28, 1), dtype=np.float32)\r\n    batch_labels = np.zeros((batch_size,10), dtype=np.int8)\r\n    indices = np.arange(n)\r\n    i =0\r\n    while True:\r\n        np.random.shuffle(indices)\r\n        #print(indices,\"\\n\")\r\n        next_batch = indices[(i*batch_size):(i+1)*batch_size]\r\n        for j, idx in enumerate(next_batch):\r\n            batch_data[j] = data[idx]\r\n            batch_labels[j] = labels[idx]\r\n        \r\n        yield batch_data, batch_labels\r\n        i +=1  \r\n\r\n# create generator instance for training and validation \r\ntrain_data_gen = data_gen(X_train, y_train)\r\nvalid_data_gen = data_gen(X_valid, y_valid)\r\n\r\ndevice = \"gpu:0\" if tfe.num_gpus() else \"cpu:0\"\r\nmodel = MNIST('channels_first' if tfe.num_gpus() else 'channels_last')\r\noptimizer = tf.train.AdamOptimizer(learning_rate=1e-4)\r\ngrad = tfe.implicit_gradients(loss)\r\n\r\nbatch_size = 8\r\ntrain_batches = len(X_train) // batch_size\r\nvalid_batches = len(X_valid) // batch_size\r\nnb_epochs = 5\r\n\r\nfor i in range(nb_epochs):\r\n    with tf.device(device):\r\n        for j in range(train_batches):\r\n            inputs, targets = next(train_data_gen)\r\n            optimizer.apply_gradients(grad(model, inputs, targets))\r\n            if j % 10 == 0:\r\n                print(\"Step %d: Loss on training set : %f\" %(i, loss(model, inputs, targets, drop=True).numpy()))\r\n```", "I notice that you aren't calling `tfe.enable_eager_execution()`, which means eager execution isn't enabled. Is that intentional?", "Ahh...I must have deleted that by mistake while deleting the comments. Though I one thing that I found weird was earlier I was importing `eager` and enabled it too but that didn't work. I restarted the notebook and it worked fine. "]}, {"number": 17015, "title": "tfcompile tf.cond not dominated by switch nodes", "body": "Using the following example:\r\n\r\n```\r\ngraph = tf.Graph()\r\nwith graph.as_default():\r\n  x = tf.placeholder(name='x', shape=(2,), dtype=tf.float64)\r\n  y = tf.cond(x[0] > x[1], partial(lambda x: x[0], x), partial(lambda x: x[1], x))\r\n```\r\n\r\nCompiling with:\r\n`\r\ntfcompile --graph=test_graph.pb --config=test_config.pb --entry_point=test_func --cpp_class=test --out_object=test.o --out_header=test.hpp --gen_program_shape=true --target_cpu=haswell\r\n`\r\n\r\nGives the following error:\r\n`\r\n2018-02-13 16:32:27.484808: F tensorflow/compiler/aot/tfcompile_main.cc:140] Non-OK-status: status status: Failed precondition: Value {name:'cond/strided_slice_1' id:20 op device:{/device:XLA_CPU_JIT} def:{cond/strided_slice_1 = StridedSlice[Index=DT_INT32, T=DT_DOUBLE, begin_mask=0, ellipsis_mask=0, end_mask=0, new_axis_mask=0, shrink_axis_mask=1](cond/strided_slice_1/Switch, cond/strided_slice_1/stack, cond/strided_slice_1/stack_1, cond/strided_slice_1/stack_2)}} not dominated by switch nodes.\r\n`\r\n\r\nWould expect code to be generated similar to:\r\n```\r\ndouble test_func( double* x )\r\n{\r\n  if (x[0] > x[1] )\r\n    return x[0];\r\n  else\r\n    return x[1];\r\n}\r\n```\r\n\r\ntensorflow version 1.5.0\r\nRHEL 7.3 64bit\r\ntensorflow built from source \r\npython 2.7\r\nbazel 0.7\r\ngcc 4.8.5\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: yes, provided above\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: RHEL 7.3 64bit\r\n- **TensorFlow installed from (source or binary)**: source\r\n- **TensorFlow version (use command below)**: 1.5.0\r\n- **Python version**: 2.7\r\n- **Bazel version (if compiling from source)**: 0.7\r\n- **GCC/Compiler version (if compiling from source)**: gcc 4.8.5\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: provided above", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!", "@jhunsaker did you ever ask about this on SO? I'm hitting the same problem."]}, {"number": 17014, "title": "Importing graph with tf.contrib.resampler.resampler fails", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nOSx High Sierra\r\n- **TensorFlow installed from (source or binary)**:\r\npip install\r\n- **TensorFlow version (use command below)**:\r\n1.5.0\r\n- **Python version**: \r\n3.5.4\r\n- **CUDA/cuDNN version**:\r\nCPU\r\n- **Bazel version (if compiling from source)**:\r\nN/A\r\n- **GPU model and memory**:\r\nN/A\r\n- **Exact command to reproduce**:\r\nSee below\r\n\r\n\r\n### Describe the problem\r\nImporting a graph def with a  `tf.contrib.resampler.resampler` op fails iff `tf.contrib` is not imported first.\r\n\r\nExecute:\r\n```\r\nimport tensorflow as tf\r\n\r\ndef export_model(filename, sess, output_node_names):\r\n    from tensorflow.python.framework import graph_util\r\n    output_graph_def = graph_util.convert_variables_to_constants(sess,\r\n                                                                 sess.graph.as_graph_def(add_shapes=True),\r\n                                                                 output_node_names)\r\n    with tf.gfile.GFile(filename, \"wb\") as f:\r\n        f.write(output_graph_def.SerializeToString())\r\n        \r\ndef read_frozen_protobuf(path):\r\n    with tf.gfile.FastGFile(str(path), 'rb') as f:\r\n        graph_def = tf.GraphDef()\r\n        graph_def.ParseFromString(f.read())\r\n        return graph_def\r\n\r\n    \r\ndef export(filename):\r\n    tf.reset_default_graph()\r\n    g = tf.Graph()\r\n    with tf.Session(graph=g, config=tf.ConfigProto(allow_soft_placement=True)) as sess:\r\n        images = tf.placeholder(dtype=tf.float64, shape=[32, 32], name='images')\r\n        points = tf.placeholder(dtype=tf.float64, shape=[32, 2], name='points')\r\n        resampled = tf.contrib.resampler.resampler(images, points, name='resampled')\r\n        output_node_names = ['resampled/Resampler']\r\n        export_model(filename, sess, output_node_names)\r\n        \r\ndef load(filename):\r\n    import numpy as np\r\n    tf.reset_default_graph()\r\n    g = tf.Graph()\r\n    with tf.Session(graph=g, config=tf.ConfigProto(allow_soft_placement=True)) as sess:\r\n        images = np.zeros((32, 32), dtype=np.float64)\r\n        points = np.zeros((32, 2), dtype=np.float64)\r\n        graph_def = read_frozen_protobuf(filename)\r\n        tf.import_graph_def(graph_def, \r\n                            input_map={'images': images,\r\n                                       'points': points},\r\n                            return_elements=['resampled/Resampler:0'])\r\n        \r\n######################################################\r\nfrozen_graph_def = '/tmp/test.frozen'\r\nexport(frozen_graph_def)\r\nload(frozen_graph_def)\r\n```\r\n\r\nThen, in a new interpreter (where the load(..) function is defined), execute:\r\n```\r\nfrozen_graph_def = '/tmp/test.frozen'\r\nload(frozen_graph_def)\r\n```\r\n\r\nThis give the error message:\r\n```\r\n---------------------------------------------------------------------------\r\nValueError                                Traceback (most recent call last)\r\n<ipython-input-1-64251e160f7d> in <module>()\r\n     42 frozen_graph_def = '/tmp/test.frozen'\r\n     43 # export(frozen_graph_def)\r\n---> 44 load(frozen_graph_def)\r\n\r\n<ipython-input-1-64251e160f7d> in load(filename)\r\n     37                             input_map={'images': images,\r\n     38                                        'points': points},\r\n---> 39                             return_elements=['resampled/Resampler:0'])\r\n     40 \r\n     41 ######################################################################\r\n\r\n/lib/python3.5/site-packages/tensorflow/python/util/deprecation.py in new_func(*args, **kwargs)\r\n    314                 'in a future version' if date is None else ('after %s' % date),\r\n    315                 instructions)\r\n--> 316       return func(*args, **kwargs)\r\n    317     return tf_decorator.make_decorator(func, new_func, 'deprecated',\r\n    318                                        _add_deprecated_arg_notice_to_docstring(\r\n\r\n/lib/python3.5/site-packages/tensorflow/python/framework/importer.py in import_graph_def(graph_def, input_map, return_elements, name, op_dict, producer_op_list)\r\n    539         # Set any default attr values that aren't present.\r\n    540         if node.op not in op_dict:\r\n--> 541           raise ValueError('No op named %s in defined operations.' % node.op)\r\n    542         op_def = op_dict[node.op]\r\n    543         for attr_def in op_def.attr:\r\n\r\nValueError: No op named Resampler in defined operations.\r\n```", "comments": ["@kosklain and @fabioviola, PTAL when you have a moment. ", "Hi, @stefanbrugger \r\n\r\nThis is unfortunately an issue with any part of the contrib library which defines custom C++ ops - you can easily modify your example to call tf.contrib.rnn.LSTMBlockFusedCell and trigger exactly the same kind of error. After you do `import tensorflow as tf`, tf skips loading all of contrib into memory until it is necessary. When you access `tf.contrib.resampler` inside `export()`, under the hood some extra ops get loaded and are available for the immediately following code. It might help to think of lines that access tf.contrib.* as having an implict `import` statement right above them, as that is effectively what is happening.\r\n\r\nIn the short term a workaround is to always access the specific subpart of contrib you might want to use ops from at the top of your program - if you just do the follwing at the top of the file:\r\n\r\n```python\r\nimport tensorflow as tf\r\ntf.contrib.resampler  # This is effectively importing some more ops\r\n\r\n# ... rest of code\r\n```\r\n\r\nThe above change means when you come to import the saved graph def, all the ops are available and load_model completes successfully.\r\n\r\nThis is currently not documented too well, we will add some extra information to the relevant docstrings.\r\n\r\nIn the long term there are plans to make dealing with ops that aren't in the core more seamless, which should mean this workaround isn't necessary.\r\n\r\nPlease let me know if any of the above doesn't make sense.\r\n\r\n", "Informally assigning to @malcolmreynolds for now (I think we might need to add him to the TF group to be able to assign him ownership of the bug), for the docs-related updates.\r\n\r\nMalcolm, thanks for jumping in. When you're happy with the docs, please ping the bug.", "@malcolmreynolds Thanks for the response. We probably should have noted that we knew of the workaround - but it still feels like bad behaviour because it's not at all obvious in a large network where the offending op comes from. This is exacerbated by networks that already contain custom ops which also need to be imported previously (obviously).\r\n\r\nSounds good that there are plans to make this happen more seamlessly and I agree that improved documentation would go a long way to helping with this.", "Nagging Assignee @malcolmreynolds: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @malcolmreynolds: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @malcolmreynolds: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @malcolmreynolds: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Hello, has this issue been solved yet? Is there anyway to use this or substitute the resampler function for any other function?", "@danperazzo: making the error message more explicit (as mentioned above) has been done, see https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/op.cc#L76 - as far as I'm aware, the approach above of making sure these custom ops are loaded before you try and load a graphdef using them should still work. So if you're hitting this exact issue it should be possible to work around it without needing a substitution.\r\n\r\ntf.contrib is (as far as I'm aware) now removed, so resampler not being available at all might be a problem, but it would be separate from this issue specifically - assuming you have a way to get a custom op to be available to build the graph, doing the same procedure before reloading a graphdef should work. I will have to defer to someone on the TF team to give more details though.", "> @danperazzo: making the error message more explicit (as mentioned above) has been done, see https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/op.cc#L76 - as far as I'm aware, the approach above of making sure these custom ops are loaded before you try and load a graphdef using them should still work. So if you're hitting this exact issue it should be possible to work around it without needing a substitution.\r\n> \r\n> tf.contrib is (as far as I'm aware) now removed, so resampler not being available at all might be a problem, but it would be separate from this issue specifically - assuming you have a way to get a custom op to be available to build the graph, doing the same procedure before reloading a graphdef should work. I will have to defer to someone on the TF team to give more details though.\r\n\r\nhi\uff0cavoid this error by including tf.contrib.resampler in the begining works fine for me(python3.7 and tensorflow 1.14). \r\n\r\nHowever, when I want to convert the py file to exe file at the platform of  Windows by using pyinstaller. This error occurs again.\r\n\r\nIs there anything I could do to solve this problem?", "@mwsunshine sorry, I have no experience with pyinstaller. If it's an officially supported configuration maybe someone on the TF team can help.", "Thanks @malcolmreynolds ! "]}, {"number": 17013, "title": "[Android Studio + TensorFlow] Error with some Kernel's Operations", "body": "### System information\r\n- **Have I written custom code**: Yes\r\n- **OS Platform and Distribution**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from**: Source\r\n- **TensorFlow version (use command below)**: 1.5.0\r\n- **Python version**: 2.7.12\r\n- **Bazel version**: 0.10.0\r\n- **GCC/Compiler version (if compiling from source)**: 5.4.0\r\n- **GPU model and memory**: GTX 1050 TI 256MB\r\n- **Exact command to reproduce**: Build on Android Studio\r\n\r\n## Describe the problem\r\nHello guys,\r\n\r\nMy team and I are attempting to import and use a specific model on Android Studio. This functionality is pretty easy, we feed this model with an image in bitmap format and we receive a matrix points with results.\r\nBut on **Run** step this model shows different errors according to **libtensorflow_inference.so**.\r\n\r\nI create an image to better explain my problem to you. See below:\r\n![issue](https://user-images.githubusercontent.com/29979626/36210004-7405189e-1184-11e8-80b4-1f77044c100a.png)\r\n\r\n\r\n## Source code / logs\r\n### Initially, I want to load my model:\r\n```\r\npublic static Detector testCreate(AssetManager assetManager, String modelFileName, String labelFileName, int inputWidth, int inputHeight, int inputDepth, String inputName, String outputName) throws IOException {\r\n\r\n\tTensorFlowImageDetector d = new TensorFlowImageDetector();\r\n        d.inputName = inputName;\r\n        d.outputName = outputName;\r\n        d.inferenceInterface = new TensorFlowInferenceInterface(assetManager, modelFileName);\r\n\r\n        d.inputWidth = inputWidth;\r\n        d.inputHeight = inputHeight;\r\n        d.inputDepth = inputDepth;\r\n\r\n        d.outputNames = new String[]{outputName};\r\n        // start outputs\r\n        // fix labelfilename != null\r\n\r\n        return d;\r\n}\r\n```\r\n\r\n### Before I need to detect element on image (feed, run and fetch):\r\n```\r\npublic Detection testDetectImage(final float[] pixels) {\r\n\r\n        // Log this method so that it can be analyzed with systrace.\r\n        TraceCompat.beginSection(\"detectImage\");\r\n\r\n        // Copy the input data into TensorFlow.\r\n        TraceCompat.beginSection(\"feed\");\r\n        inferenceInterface.feed(inputName, pixels, 1, inputWidth, inputHeight, inputDepth);\r\n        TraceCompat.endSection();\r\n\r\n        // Run the inference call.\r\n        TraceCompat.beginSection(\"run\");\r\n        inferenceInterface.run(outputNames, Boolean.parseBoolean(null));\r\n        TraceCompat.endSection();\r\n\r\n        // Copy the output Tensor back into the output array.\r\n        TraceCompat.beginSection(\"fetch\");\r\n        //inferenceInterface.fetch(outputName, outputs);\r\n        TraceCompat.endSection();\r\n\r\n        return null;\r\n}\r\n```\r\n### Comments\r\n1. Errors occurring on **Run** function\r\n2. We already tried to solve the problem with 3 different ways mentioned in the image\r\n3. My model has an input size of 1x256x256x3 and for test, I'm using a matrix of zeros\r\n4. To generate a custom library we used this tutorial: https://medium.com/@daj/how-to-shrink-the-tensorflow-android-inference-library-cb698facf758\r\n5. To generate a full library of Android, on Bazel, we used `--copt=-D__ANDROID_TYPES_FULL__` flag\r\n6. We used JAR created by Bazel when generated custom libraries\r\n\r\n### Logs for errors\r\n>**Op Sin**\r\n```\r\n02-14 13:23:08.584 8090-8090/? E/art: No implementation found for long org.tensorflow.contrib.android.RunStats.allocate() (tried Java_org_tensorflow_contrib_android_RunStats_allocate and Java_org_tensorflow_contrib_android_RunStats_allocate__)\r\n02-14 13:23:08.584 8090-8090/? I/TensorFlowInferenceInterface: TensorFlow native methods not found, attempting to load via tensorflow_inference\r\n02-14 13:23:08.685 8090-8090/? I/TensorFlowInferenceInterface: Successfully loaded TensorFlow native methods (RunStats error may be ignored)\r\n02-14 13:23:11.083 8090-8090/com.example.lis.zitronenkuchen I/TensorFlowInferenceInterface: Model load took 518ms, TensorFlow version: 1.6.0-rc0\r\n02-14 13:23:11.092 8090-8090/com.example.lis.zitronenkuchen I/TensorFlowInferenceInterface: Successfully loaded model from 'file:///android_asset/frozen_pose3d.pb'\r\n02-14 13:23:11.092 8090-8090/com.example.lis.zitronenkuchen D/MainActivity: Load Success!\r\n02-14 13:23:11.215 8090-8090/com.example.lis.zitronenkuchen E/TensorFlowInferenceInterface: Failed to run TensorFlow inference with inputs:[input_image], outputs:[MatMul]\r\n02-14 13:23:11.216 8090-8090/com.example.lis.zitronenkuchen D/AndroidRuntime: Shutting down VM\r\n02-14 13:23:11.217 8090-8090/com.example.lis.zitronenkuchen E/AndroidRuntime: FATAL EXCEPTION: main\r\n                                                                              Process: com.example.lis.zitronenkuchen, PID: 8090\r\n                                                                              java.lang.RuntimeException: Unable to start activity ComponentInfo{com.example.lis.zitronenkuchen/com.example.lis.zitronenkuchen.MainActivity}: java.lang.RuntimeException: Error initializing TensorFlow!\r\n                                                                                  at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2659)\r\n                                                                                  at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2724)\r\n                                                                                  at android.app.ActivityThread.-wrap12(ActivityThread.java)\r\n                                                                                  at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1473)\r\n                                                                                  at android.os.Handler.dispatchMessage(Handler.java:102)\r\n                                                                                  at android.os.Looper.loop(Looper.java:154)\r\n                                                                                  at android.app.ActivityThread.main(ActivityThread.java:6123)\r\n                                                                                  at java.lang.reflect.Method.invoke(Native Method)\r\n                                                                                  at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:867)\r\n                                                                                  at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:757)\r\n                                                                               Caused by: java.lang.RuntimeException: Error initializing TensorFlow!\r\n                                                                                  at com.example.lis.zitronenkuchen.MainActivity.onCreate(MainActivity.java:44)\r\n                                                                                  at android.app.Activity.performCreate(Activity.java:6672)\r\n                                                                                  at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1140)\r\n                                                                                  at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2612)\r\n                                                                                  at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2724)\u00a0\r\n                                                                                  at android.app.ActivityThread.-wrap12(ActivityThread.java)\u00a0\r\n                                                                                  at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1473)\u00a0\r\n                                                                                  at android.os.Handler.dispatchMessage(Handler.java:102)\u00a0\r\n                                                                                  at android.os.Looper.loop(Looper.java:154)\u00a0\r\n                                                                                  at android.app.ActivityThread.main(ActivityThread.java:6123)\u00a0\r\n                                                                                  at java.lang.reflect.Method.invoke(Native Method)\u00a0\r\n                                                                                  at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:867)\u00a0\r\n                                                                                  at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:757)\u00a0\r\n                                                                               Caused by: java.lang.IllegalArgumentException: No OpKernel was registered to support Op 'Sin' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n                                                                                <no registered kernels>\r\n                                                                              \r\n                                                                              \t [[Node: ViewpointNet/get_rot_mat/Sin = Sin[T=DT_FLOAT](ViewpointNet/get_rot_mat/Sqrt)]]\r\n                                                                                  at org.tensorflow.Session.run(Native Method)\r\n                                                                                  at org.tensorflow.Session.access$100(Session.java:48)\r\n                                                                                  at org.tensorflow.Session$Runner.runHelper(Session.java:298)\r\n                                                                                  at org.tensorflow.Session$Runner.run(Session.java:248)\r\n                                                                                  at org.tensorflow.contrib.android.TensorFlowInferenceInterface.run(TensorFlowInferenceInterface.java:230)\r\n                                                                                  at org.tensorflow.contrib.android.TensorFlowInferenceInterface.run(TensorFlowInferenceInterface.java:197)\r\n                                                                                  at org.tensorflow.contrib.android.TensorFlowInferenceInterface.run(TensorFlowInferenceInterface.java:187)\r\n                                                                                  at com.example.lis.zitronenkuchen.TensorFlowImageDetector.detectImage(TensorFlowImageDetector.java:73)\r\n                                                                                  at com.example.lis.zitronenkuchen.MainActivity.onCreate(MainActivity.java:41)\r\n                                                                                  \t... 12 more\r\n```\r\n\r\n>**Op Identity**\r\n```\r\nE/art: No implementation found for long org.tensorflow.contrib.android.RunStats.allocate() (tried Java_org_tensorflow_contrib_android_RunStats_allocate and Java_org_tensorflow_contrib_android_RunStats_allocate__)\r\nI/TensorFlowInferenceInterface: TensorFlow native methods not found, attempting to load via tensorflow_inference\r\nI/TensorFlowInferenceInterface: Successfully loaded TensorFlow native methods (RunStats error may be ignored)\r\nD/AndroidRuntime: Shutting down VM\r\n\r\n\r\n                  --------- beginning of crash\r\nE/AndroidRuntime: FATAL EXCEPTION: main\r\n                  Process: com.example.lis.zitronenkuchen, PID: 6521\r\n                  java.lang.RuntimeException: Unable to start activity ComponentInfo{com.example.lis.zitronenkuchen/com.example.lis.zitronenkuchen.MainActivity}: java.lang.RuntimeException: Error initializing TensorFlow!\r\n                      at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2659)\r\n                      at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2724)\r\n                      at android.app.ActivityThread.-wrap12(ActivityThread.java)\r\n                      at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1473)\r\n                      at android.os.Handler.dispatchMessage(Handler.java:102)\r\n                      at android.os.Looper.loop(Looper.java:154)\r\n                      at android.app.ActivityThread.main(ActivityThread.java:6123)\r\n                      at java.lang.reflect.Method.invoke(Native Method)\r\n                      at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:867)\r\n                      at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:757)\r\n                   Caused by: java.lang.RuntimeException: Error initializing TensorFlow!\r\n                      at com.example.lis.zitronenkuchen.MainActivity.onCreate(MainActivity.java:44)\r\n                      at android.app.Activity.performCreate(Activity.java:6672)\r\n                      at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1140)\r\n                      at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2612)\r\n                      at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2724)\u00a0\r\n                      at android.app.ActivityThread.-wrap12(ActivityThread.java)\u00a0\r\n                      at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1473)\u00a0\r\n                      at android.os.Handler.dispatchMessage(Handler.java:102)\u00a0\r\n                      at android.os.Looper.loop(Looper.java:154)\u00a0\r\n                      at android.app.ActivityThread.main(ActivityThread.java:6123)\u00a0\r\n                      at java.lang.reflect.Method.invoke(Native Method)\u00a0\r\n                      at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:867)\u00a0\r\n                      at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:757)\u00a0\r\n                   Caused by: org.tensorflow.TensorFlowException: Op type not registered 'Identity' in binary running on localhost. Make sure the Op and Kernel are registered in the binary running in this process.\r\n                      at org.tensorflow.Graph.importGraphDef(Native Method)\r\n                      at org.tensorflow.Graph.importGraphDef(Graph.java:130)\r\n                      at org.tensorflow.Graph.importGraphDef(Graph.java:114)\r\n                      at org.tensorflow.contrib.android.TensorFlowInferenceInterface.loadGraph(TensorFlowInferenceInterface.java:561)\r\n                      at org.tensorflow.contrib.android.TensorFlowInferenceInterface.<init>(TensorFlowInferenceInterface.java:105)\r\n                      at com.example.lis.zitronenkuchen.TensorFlowImageDetector.create(TensorFlowImageDetector.java:47)\r\n                      at com.example.lis.zitronenkuchen.MainActivity.onCreate(MainActivity.java:29)\r\n                      at android.app.Activity.performCreate(Activity.java:6672)\u00a0\r\n                      at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1140)\u00a0\r\n                      at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2612)\u00a0\r\n                      at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2724)\u00a0\r\n                      at android.app.ActivityThread.-wrap12(ActivityThread.java)\u00a0\r\n                      at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1473)\u00a0\r\n                      at android.os.Handler.dispatchMessage(Handler.java:102)\u00a0\r\n                      at android.os.Looper.loop(Looper.java:154)\u00a0\r\n                      at android.app.ActivityThread.main(ActivityThread.java:6123)\u00a0\r\n                      at java.lang.reflect.Method.invoke(Native Method)\u00a0\r\n                      at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:867)\u00a0\r\n                      at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:757)\u00a0\r\n```\r\n\r\n>**Op Switch**\r\n```\r\n02-14 13:09:36.334 26040-26040/com.example.lis.zitronenkuchen E/art: No implementation found for long org.tensorflow.contrib.android.RunStats.allocate() (tried Java_org_tensorflow_contrib_android_RunStats_allocate and Java_org_tensorflow_contrib_android_RunStats_allocate__)\r\n02-14 13:09:36.334 26040-26040/com.example.lis.zitronenkuchen I/TensorFlowInferenceInterface: TensorFlow native methods not found, attempting to load via tensorflow_inference\r\n02-14 13:09:36.406 26040-26040/com.example.lis.zitronenkuchen I/TensorFlowInferenceInterface: Successfully loaded TensorFlow native methods (RunStats error may be ignored)\r\n02-14 13:09:37.835 26040-26040/com.example.lis.zitronenkuchen I/TensorFlowInferenceInterface: Model load took 1382ms, TensorFlow version: 1.3.1\r\n02-14 13:09:37.843 26040-26040/com.example.lis.zitronenkuchen I/TensorFlowInferenceInterface: Successfully loaded model from 'file:///android_asset/frozen_pose3d.pb'\r\n02-14 13:09:37.843 26040-26040/com.example.lis.zitronenkuchen D/MainActivity: Load Success!\r\n02-14 13:09:37.892 26040-26040/com.example.lis.zitronenkuchen E/TensorFlowInferenceInterface: Failed to run TensorFlow inference with inputs:[input_image], outputs:[MatMul]\r\n02-14 13:09:37.892 26040-26040/com.example.lis.zitronenkuchen D/AndroidRuntime: Shutting down VM\r\n02-14 13:09:37.893 26040-26040/com.example.lis.zitronenkuchen E/AndroidRuntime: FATAL EXCEPTION: main\r\n                                                                                Process: com.example.lis.zitronenkuchen, PID: 26040\r\n                                                                                java.lang.RuntimeException: Unable to start activity ComponentInfo{com.example.lis.zitronenkuchen/com.example.lis.zitronenkuchen.MainActivity}: java.lang.RuntimeException: Error initializing TensorFlow!\r\n                                                                                    at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2426)\r\n                                                                                    at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2490)\r\n                                                                                    at android.app.ActivityThread.-wrap11(ActivityThread.java)\r\n                                                                                    at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1354)\r\n                                                                                    at android.os.Handler.dispatchMessage(Handler.java:102)\r\n                                                                                    at android.os.Looper.loop(Looper.java:148)\r\n                                                                                    at android.app.ActivityThread.main(ActivityThread.java:5443)\r\n                                                                                    at java.lang.reflect.Method.invoke(Native Method)\r\n                                                                                    at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:728)\r\n                                                                                    at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:618)\r\n                                                                                 Caused by: java.lang.RuntimeException: Error initializing TensorFlow!\r\n                                                                                    at com.example.lis.zitronenkuchen.MainActivity.onCreate(MainActivity.java:44)\r\n                                                                                    at android.app.Activity.performCreate(Activity.java:6245)\r\n                                                                                    at android.app.Instrumentation.callActivityOnCreate(Instrumentation.java:1130)\r\n                                                                                    at android.app.ActivityThread.performLaunchActivity(ActivityThread.java:2379)\r\n                                                                                    at android.app.ActivityThread.handleLaunchActivity(ActivityThread.java:2490)\u00a0\r\n                                                                                    at android.app.ActivityThread.-wrap11(ActivityThread.java)\u00a0\r\n                                                                                    at android.app.ActivityThread$H.handleMessage(ActivityThread.java:1354)\u00a0\r\n                                                                                    at android.os.Handler.dispatchMessage(Handler.java:102)\u00a0\r\n                                                                                    at android.os.Looper.loop(Looper.java:148)\u00a0\r\n                                                                                    at android.app.ActivityThread.main(ActivityThread.java:5443)\u00a0\r\n                                                                                    at java.lang.reflect.Method.invoke(Native Method)\u00a0\r\n                                                                                    at com.android.internal.os.ZygoteInit$MethodAndArgsCaller.run(ZygoteInit.java:728)\u00a0\r\n                                                                                    at com.android.internal.os.ZygoteInit.main(ZygoteInit.java:618)\u00a0\r\n                                                                                 Caused by: java.lang.IllegalArgumentException: No OpKernel was registered to support Op 'Switch' with these attrs.  Registered devices: [CPU], Registered kernels:\r\n                                                                                  device='GPU'; T in [DT_STRING]\r\n                                                                                  device='GPU'; T in [DT_BOOL]\r\n                                                                                  device='GPU'; T in [DT_INT32]\r\n                                                                                  device='GPU'; T in [DT_INT64]\r\n                                                                                  device='GPU'; T in [DT_FLOAT]\r\n                                                                                  device='GPU'; T in [DT_HALF]\r\n                                                                                  device='CPU'; T in [DT_QINT32]\r\n                                                                                  device='CPU'; T in [DT_QUINT8]\r\n                                                                                  device='CPU'; T in [DT_QINT8]\r\n                                                                                  device='CPU'; T in [DT_FLOAT]\r\n                                                                                  device='CPU'; T in [DT_HALF]\r\n                                                                                  device='CPU'; T in [DT_INT32]\r\n                                                                                  device='CPU'; T in [DT_INT64]\r\n                                                                                \r\n                                                                                \t [[Node: PosePrior/dropout/cond/Switch = Switch[T=DT_BOOL](PlaceholderWithDefault, PlaceholderWithDefault)]]\r\n                                                                                    at org.tensorflow.Session.run(Native Method)\r\n                                                                                    at org.tensorflow.Session.access$100(Session.java:48)\r\n                                                                                    at org.tensorflow.Session$Runner.runHelper(Session.java:295)\r\n                                                                                    at org.tensorflow.Session$Runner.run(Session.java:245)\r\n                                                                                    at org.tensorflow.contrib.android.TensorFlowInferenceInterface.run(TensorFlowInferenceInterface.java:143)\r\n                                                                                    at com.example.lis.zitronenkuchen.TensorFlowImageDetector.detectImage(TensorFlowImageDetector.java:73)\r\n                                                                                    at com.example.lis.zitronenkuchen.MainActivity.onCreate(MainActivity.java:41)\r\n                                                                                    \t... 12 more\r\n```\r\n\r\nThank you! :grin:", "comments": ["@daj can you help me?", "+1", "I'm having a similar problem, I was getting the \" No OpKernel was registered to support Op 'ArgMax' with these attrs.\" error when i tried to run after generating my custom .so ", "> Op type not registered 'Identity' in binary running on localhost. Make sure the Op and Kernel are registered in the binary running in this process.\r\n\r\nThese error messages appear to be showing that the ops you need (`Sin`, `Identity` etc) are not being included in your optimized libtensorflow_inference.so.  I'm not sure why this would happen for your \"Attempt 3\" if it really is using the full TensorFlow library, but it certainly explains the failures for \"Attempt 1\" and \"Attempt 2\".\r\n\r\nIn [my blog post](https://medium.com/@daj/how-to-shrink-the-tensorflow-android-inference-library-cb698facf758), see the `Checking the list of operations in ops_to_register.h` section.  You will need to add the missing ops to the `ops_to_register.h` file, and rebuild libtensorflow_inference.so.  This reduced list of ops is the reason that we're able to create smaller versions of the TensorFlow library (i.e. we're trying to discard all the unneeded ops).\r\n\r\nYou might find Pete Warden's free eBook [Building Mobile Applications with TensorFlow](http://www.oreilly.com/data/free/building-mobile-applications-with-tensorflow.csp) useful on this topic.  Good luck!", "@daj Thanks for answer,\r\n\r\nHowever I did it. I has check `ops_to_register.h` file and it contained `Identity` function. \r\n\r\nSo after I rebuilt it and load on Android Studio that error happened: \r\n`org.tensorflow.TensorFlowException: Op type not registered 'Identity' in binary running on localhost. Make sure the Op and Kernel are registered in the binary running in this process.`\r\n\r\nIs there any other error that I could have made or probably the error is in the `libtensorflow_inference.so` build?", "What I mean is that it looks like my code in Android Studio is not loading my library. Because I believe I have done everything the right way. I use the library that I created but it does not recognize the function inside it.", "What kind of device/emulator are you using?  Did you build the correct architecture for your device using the `--cpu` option?  Most real devices will need to use an `armeabi-v7a`, whereas most emulators will need `x86`.  \r\n\r\nSince you are getting different error messages each time, that suggests that you are succeeding in replacing the default library with your own one.  You could try using the Android Studio `Profile or Debug APK` option to check the correct versions of the libraries are inside the APK in the correct folders.\r\n\r\nWere you able to get the example from my blog to work?  I suggest starting from a working project and making minor changes until you get close enough to your final destination.", "I am using `armeabi-v7a` for real device and `x86_64` for emulated device. But I created the library for both of them. Yes, I repeated every step for each one with the correct flag `--cpu=armeabi-v7a` and `--cpu=x86_64`.\r\n\r\n[On your blog](https://medium.com/@daj/how-to-shrink-the-tensorflow-android-inference-library-cb698facf758),\r\n\r\n> Copy your new `libtensorflow_inference.so` file into your project, putting it in the correct folder for the architecture that you built, e.g. `app/src/main/jniLibs/armeabi-v7a/`.\r\n\r\nIn my case: `jniLibs/armeabi-v7a` and `jniLibs/x86_64`\r\n\r\nYeah, We have already use a lot of debug :smile:\r\n\r\nI think the only thing I did not try was to download your project and test it.", "I believe I need to mention that the only part that I was in doubt was in this part\r\n\r\n> Extract the Java classes.jar from the `org.tensorflow:tensorflow-android` dependency. Copy them into your `app/libs` folder, and update your `build.gradle` file.\r\n\r\nI don't understood how to _extract the Java classes.jar from the org.tensorflow:tensorflow-android dependency_.\r\n\r\nBut after searching I found that it was possible to generate a JAR file based on my project, using the Bazel. ", "> I don't understood how to extract the Java classes.jar from the org.tensorflow:tensorflow-android dependency.\r\n\r\nYou can probably just take my `app/libs/tensorflow-android.jar` from this commit:\r\nhttps://github.com/daj/AndroidTensorFlowMNISTExample/commit/6e1b15ff6d3182be0e665c0456f356ffc2f62514", "I am suffering from the same problem. I want to replace the model in the tensorflow for android demo app (https://github.com/tensorflow/tensorflow) with my custom model but I never succeeded. Below are what I have tried so far:\r\n\r\n1. I replaced the `.pb` file and its corresponding labels. But it showed runtime error something like\r\n`No OpKernel was registered to support Op 'ListDiff'`\r\nThis is because my model requires some additional tensorflow operations like `ListDiff` which are not included in `org.tensorflow:tensorflow-android`.\r\n\r\n2. I followed the instructions that I found by googling most of which mention rebuilding `libtensorflow_inference.so` with this command:\r\n`bazel build -c opt --copt=\"-DSELECTIVE_REGISTRATION\" --copt=\"-DSUPPORT_SELECTIVE_REGISTRATION\" //tensorflow/contrib/android:libtensorflow_inference.so     --host_crosstool_top=@bazel_tools//tools/cpp:toolchain --crosstool_top=//external:android/crosstool --cpu=armeabi-v7a --verbose_failures`\r\nAfter that I copied `libtensorflow_inference.so` to the `libs/armeabi-v7a` folder under my android example folder. \r\nBut it also failed.\r\n\r\n3. I tried a number of options when building the `libtensorflow_inference.so` (like removing selective registration) and it failed. Supporting selective registration affected the file size of `libtensorflow_inference.so` from 13.7MB to 3.4MB but it seems that the operations used in my `.pb` file like `ListDiff` are excluded in the both cases.\r\n\r\n4. What is more interesting is that `ops_to_register.h` was properly generated. The `ListDiff` operation was included in the `ops_to_register.h`. Besides, when I tried to build the `libtensorflow_inference.so` without `ops_to_register.h` it gave an error as\r\n`./tensorflow/core/framework/selective_registration.h:46:10: fatal error: 'ops_to_register.h' file not found`\r\nBut when I examined the `libtensorflow_inference.so` file with `nm -D libtensorflow_inference.so` command, I could not find the `ListDiff` operation in it.\r\n\r\n5. To avoid collisions of any kind, I commented out\r\n`compile 'org.tensorflow:tensorflow-android:+'`\r\nand inserted\r\n`compile fileTree(dir: 'libs', include: ['*.jar', '**/*.so'])`\r\nbut it did not solve the problem.\r\n\r\n6. I compressed the `.so` file after I put it into `lib` folder and changed the file extension from `zip` to `.jar`, but it did not help.\r\nI guess this is because the operations are already missing in the `.so` file.\r\n\r\n7. As my phone uses 64-bit CPU, I changed `armeabi-v7a` to `arm64-v8a` when building the native library. However, it did notwork.\r\n(This failure was expected in advance actually because `arm64-v8a` systems are compatible with `armeabi-v7a` libraries.)\r\n\r\n8. I do not remember the exact code but I have added scripts that import the native library to the `.java` file but it did not work.\r\n\r\n\r\nI am using android ndk r14b  and sdk 26.0.1 (and 27.0.3) in Mac OS X and ubuntu 16.04.\r\nDoes anyone have a solution?\r\n", "@jspark-cochlearai We tried everything you said. Unsuccessfully.", "@gabrielrlp maybe you can check /tensorflow/contrib/makefile/tf_op_files.txt ", "Nagging Assignee @bignamehyp: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 30 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!", "You can add listdiff_op.cc to android_extended_ops_group1 in \"tensorflow/core/kernels/BUILD\" or update tensorflow to latest version (over 1.8).  Compiling your own library, and  then you can use \"nm -D XX.so|grep listdiff\" to check validation."]}, {"number": 17011, "title": "[Feature Request] Specify output size for tf.contrib.image.transform", "body": "## Status Quo\r\nRight now the output size of [tf.contrib.image.transform](https://www.tensorflow.org/api_docs/python/tf/contrib/image/transform) is equal to the input size.\r\n\r\n## Request\r\nSpecify output size for [tf.contrib.image.transform](https://www.tensorflow.org/api_docs/python/tf/contrib/image/transform) by argument.\r\n\r\n## Usage example:\r\nThis would be very useful for custom augmentations where the input images do not have a fixed size, but the output images shall have a constant size. This operation can be simulated by padding the input images (such that no information is lost when e.g. rotation the image), then transforming them and finally cropping/padding them to the desired size, but it'd be much more efficient and a lot easier if the op could support setting the desired output size.\r\n\r\nThanks!", "comments": ["Would ` tf.image.resize_image_with_crop_or_pad` help you?", "Unfortunately it doesn't. That only replaces the \"finally cropping/padding\" part, but still there are three memory costly operations needed to perform the desired operation (namely `tf.pad` such that the rotation does not crop parts of the input, then `tf.contrib.image.transform`, and finally `tf.image.resize_image_with_crop_or_pad`). Also it is limited, such that you cannot specify the offset but it always uses central cropping/padding. Unfortunately this is a bottleneck for our training, because the padding and cropping seems to take quite long for large inputs (I guess due to memory allocations?).\r\n\r\nBy my guess it should not be too complicated to implement parametrizable output size. As far as I checked the source code, the output is generated in [tensorflow/contrib/image/kernels/image_ops.h:164](https://github.com/tensorflow/tensorflow/blob/1b6453bec58e3c0c020fe654d04ba4fb8dbb20a3/tensorflow/contrib/image/kernels/image_ops.h#L164). The problem I see is that it is generated by \"images.generate\", which should be something like \"output->generate\" (unfortunately I do not know further details on these interfaces). Finally adding allocation by argument to [tensorflow/contrib/image/kernels/image_ops.cc:86](https://github.com/tensorflow/tensorflow/blob/f1f2fff2c149ea3a848ec61b7d3fcd39a6dc3f06/tensorflow/contrib/image/kernels/image_ops.cc#L86) should solve the issue? Maybe someone with more insight than me can comment on this.", "Thank you for your suggestion. We will consider it if we heard more demands for this feature.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "@tensorflowbutler: Yes, still an issue. The feature is still required.", "Maybe @ringw is interested in this request, as there seems to be a bug with gpu computation (see #17485) and work needs to be done anyway?", "@bignamehyp: There is definitely great demand for this feature in our institution!", "Nagging Assignee @ringw: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ringw: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@voegtlel, btw: I think you could use tf.image.pad_to_bounding_box. But it is not very efficient anyway. Just submit a fix to this. ", "@quydev I do not see how `tf.image.pad_to_bounding_box` helps here. I did not specify how to do the final padding/cropping, and anyway `pad_to_bounding_box` does that by using `tf.pad` (see [image_ops_impl.py\r\n:646](https://github.com/tensorflow/tensorflow/blob/eafd4671772b111b3ed12c4c0b4f355248ecee30/tensorflow/python/ops/image_ops_impl.py#L646).\r\nBut the commit looks really promising! Would be nice to see this in the next release :)", "Nagging Assignee @ringw: It has been 18 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ringw: It has been 33 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ringw: It has been 48 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ringw: It has been 63 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ringw: It has been 78 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee @ringw: It has been 93 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Fixed."]}, {"number": 17010, "title": "Fixes #16976", "body": "", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_author_cla -->", "Mind to check CLA again? @googlebot ", "CLAs look good, thanks!\n\n<!-- ok -->", "@byronyi I'm adding a more general fix, will let you know once it's pushed.", "@aaroey good to know, I\u2019ll close this once it\u2019s pushed :)", "@byronyi I tested that febed14f36eef0d3800d891b18717df36f786852 fixed the issue, would you help to double check? Thanks.", "Thanks!"]}, {"number": 17009, "title": "Failed to call cudnnRNNBackwardData: CUDNN_STATUS_INTERNAL_ERROR", "body": "### System information\r\n- **Have I written custom code**: Yes\r\n- **OS Platform and Distribution**: Ubuntu 16.04\r\n- **TensorFlow installed from**: binary\r\n- **TensorFlow version**: 1.4.1\r\n- **Python version**: 3.5.2\r\n- **Bazel version:** Not compiled from source\r\n- **GCC/Compiler version**: Not compiled from source\r\n- **CUDA/cuDNN version**: 8.0/v6\r\n- **GPU model and memory**: GeForce GTX 1080 (8GB x 4)\r\n- **Exact command to reproduce**: Code as per below\r\n\r\nThe code starts training and after an arbitrary number of iterations on batches, it gives the following error:\r\n\r\n```\r\n2018-02-14 23:51:31.591963: E tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS\r\n2018-02-14 23:51:31.592000: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:203] Unexpected Event status: 1\r\n2018-02-14 23:51:31.592023: E tensorflow/stream_executor/cuda/cuda_dnn.cc:1679] Failed to call cudnnRNNBackwardData: CUDNN_STATUS_INTERNAL_ERROR\r\nAborted (core dumped)\r\n```\r\n\r\nI'm using `cudnn_gru` in a `tf.while_loop` control flow operation and using initializers from outside the `tf.while` scope since variables aren't allowed to be instantiated within the `tf.while` scope:\r\n\r\n```\r\nimport tensorflow as tf\r\n\r\ngru_fw = tf.contrib.cudnn_rnn.CudnnGRU(num_layers=1, num_units=150, input_size=500)\r\ngru_fw_1 = tf.contrib.cudnn_rnn.CudnnGRU(num_layers=1, num_units=150, input_size=1800)\r\ne = tf.random_uniform([gru_fw.params_size()], -0.1, 0.1)\r\nf = tf.random_uniform([gru_fw.params_size()], -0.1, 0.1)\r\ng = tf.zeros([1, 4, 150])\r\nh = tf.zeros([1, 4, 150])\r\nzeros_i = tf.zeros([4, 150])\r\n\r\nclass cudnn_gru:\r\n\tdef __init__(self, num_layers, num_units, batch_size, input_size, keep_prob=1.0, is_train=None, scope=None):\r\n\t\tself.num_layers = num_layers\r\n\t\tself.grus = []\r\n\t\tself.params = []\r\n\t\tself.inits = []\r\n\t\tself.dropout_mask = []\r\n\t\tfor layer in range(num_layers):\r\n\t\t\tinput_size_ = input_size if layer == 0 else 2 * num_units\r\n\t\t\tgru_fw = tf.contrib.cudnn_rnn.CudnnGRU(\r\n\t\t\t\tnum_layers=1, num_units=num_units, input_size=input_size_)\r\n\t\t\tgru_bw = tf.contrib.cudnn_rnn.CudnnGRU(\r\n\t\t\t\tnum_layers=1, num_units=num_units, input_size=input_size_)\r\n\t\t\twith tf.variable_scope('CUDNN_GRU', reuse=tf.AUTO_REUSE):\r\n\t\t\t\tparam_fw = tf.get_variable(\"param_fw\",initializer=e,validate_shape=False)\r\n\t\t\t\tparam_bw = tf.get_variable(\"param_bw\",initializer=f,validate_shape=False)\r\n\t\t\t\tinit_fw = tf.get_variable(\"init_fw\", initializer=g)\r\n\t\t\t\tinit_bw = tf.get_variable(\"init_bw\", initializer=h)\r\n\tdef __call__(self, inputs, seq_len, keep_prob=1.0, is_train=None, concat_layers=True):\r\n\t\toutputs = [tf.transpose(inputs, [1, 0, 2])]\r\n\t\tfor layer in range(self.num_layers):\r\n\t\t\tgru_fw, gru_bw = self.grus[layer]\r\n\t\t\tparam_fw, param_bw = self.params[layer]\r\n\t\t\tinit_fw, init_bw = self.inits[layer]\r\n\t\t\tmask_fw, mask_bw = self.dropout_mask[layer]\r\n\t\t\twith tf.variable_scope(\"fw\"):\r\n\t\t\t\tout_fw, _ = gru_fw(outputs[-1] * mask_fw, init_fw, param_fw)\r\n\t\t\twith tf.variable_scope(\"bw\"):\r\n\t\t\t\tinputs_bw = tf.reverse_sequence(\r\n\t\t\t\t\toutputs[-1] * mask_bw, seq_lengths=seq_len, seq_dim=0, batch_dim=1)\r\n\t\t\t\tout_bw, _ = gru_bw(inputs_bw, init_bw, param_bw)\r\n\t\t\t\tout_bw = tf.reverse_sequence(\r\n\t\t\t\t\tout_bw, seq_lengths=seq_len, seq_dim=0, batch_dim=1)\r\n\t\t\toutputs.append(tf.concat([out_fw, out_bw], axis=2))\r\n\t\tif concat_layers:\r\n\t\t\tres = tf.concat(outputs[1:], axis=2)\r\n\t\telse:\r\n\t\t\tres = outputs[-1]\r\n\t\tres = tf.transpose(res, [1, 0, 2])\r\n\t\treturn res\r\n\r\nclass native_gru:\r\n\tdef __init__(self, num_layers, num_units, batch_size, input_size, keep_prob=1.0, is_train=None, scope=\"native_gru\"):\r\n\t\tself.num_layers = num_layers\r\n\t\tself.grus = []\r\n\t\tself.inits = []\r\n\t\tself.dropout_mask = []\r\n\t\tself.scope = scope\r\n\t\tfor layer in range(num_layers):\r\n\t\t\tinput_size_ = input_size if layer == 0 else 2 * num_units\r\n\t\t\tgru_fw = tf.contrib.rnn.GRUCell(num_units)\r\n\t\t\tgru_bw = tf.contrib.rnn.GRUCell(num_units)\r\n\t\t\twith tf.variable_scope('native_GRU', reuse=tf.AUTO_REUSE):\r\n\r\n\t\t\t\tinit_fw = tf.get_variable(\"init_fw\", initializer=zeros_i)\r\n\t\t\t\tinit_bw = tf.get_variable(\"init_bw\", initializer=zeros_i)\r\n\t\t\t\t\r\n\t\t\t#init_fw = tf.Variable(tf.zeros([batch_size, num_units]))\r\n\t\t\t#init_bw = tf.Variable(tf.zeros([batch_size, num_units]))\r\n\t\t\tmask_fw = dropout(tf.ones([batch_size, 1, input_size_], dtype=tf.float32),\r\n\t\t\t\t\t\t\t  keep_prob=keep_prob, is_train=is_train, mode=None)\r\n\t\t\tmask_bw = dropout(tf.ones([batch_size, 1, input_size_], dtype=tf.float32),\r\n\t\t\t\t\t\t\t  keep_prob=keep_prob, is_train=is_train, mode=None)\r\n\t\t\tself.grus.append((gru_fw, gru_bw, ))\r\n\t\t\tself.inits.append((init_fw, init_bw, ))\r\n\t\t\tself.dropout_mask.append((mask_fw, mask_bw, ))\r\n\r\n\tdef __call__(self, inputs, seq_len, keep_prob=1.0, is_train=None, concat_layers=True):\r\n\t\toutputs = [inputs]\r\n\t\twith tf.variable_scope(self.scope):\r\n\t\t\tfor layer in range(self.num_layers):\r\n\t\t\t\tgru_fw, gru_bw = self.grus[layer]\r\n\t\t\t\tinit_fw, init_bw = self.inits[layer]\r\n\t\t\t\tmask_fw, mask_bw = self.dropout_mask[layer]\r\n\t\t\t\twith tf.variable_scope(\"fw_{}\".format(layer)):\r\n\t\t\t\t\tout_fw, _ = tf.nn.dynamic_rnn(\r\n\t\t\t\t\t\tgru_fw, outputs[-1] * mask_fw, seq_len, initial_state=init_fw, dtype=tf.float32)\r\n\t\t\t\twith tf.variable_scope(\"bw_{}\".format(layer)):\r\n\t\t\t\t\tinputs_bw = tf.reverse_sequence(\r\n\t\t\t\t\t\toutputs[-1] * mask_bw, seq_lengths=seq_len, seq_dim=1, batch_dim=0)\r\n\t\t\t\t\tout_bw, _ = tf.nn.dynamic_rnn(\r\n\t\t\t\t\t\tgru_fw, inputs_bw, seq_len, initial_state=init_bw, dtype=tf.float32)\r\n\t\t\t\t\tout_bw = tf.reverse_sequence(\r\n\t\t\t\t\t\tout_bw, seq_lengths=seq_len, seq_dim=1, batch_dim=0)\r\n\t\t\t\toutputs.append(tf.concat([out_fw, out_bw], axis=2))\r\n\t\tif concat_layers:\r\n\t\t\tres = tf.concat(outputs[1:], axis=2)\r\n\t\telse:\r\n\t\t\tres = outputs[-1]\r\n\t\treturn res\r\n```\r\nThis has not happened before, when the project structure was sequential and not within a control flow mechanism. Also, if I change the implementation to use native GRU instead of cudnn_gru, it works perfectly fine.", "comments": ["Hey, I had a crash, maybe related? Also on Ubuntu 16.04 \r\nIn my case the crash happens running a tutorial, `not` custom code.\r\n\r\n```\r\nFrom models/tutorials/rnn/ptb:\r\npython ptb_word_lm.py --data_path=simple-examples/data/ --model=small --save_path=build\r\n```\r\nCrashing [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc#L203) while polling [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/stream_executor/cuda/cuda_event.cc#L49)\r\n\r\nNote in the output below it runs through a few iterations in the first epoch before crashing. Also of note, this is a really low mem GPU machine, before I found this issue, I assumed memory limits had been reached.\r\n\r\n```\r\n2018-02-15 13:42:07.302928: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX FMA\r\n2018-02-15 13:42:07.435901: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:895] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2018-02-15 13:42:07.436403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1105] Found device 0 with properties: \r\nname: GeForce GT 730 major: 3 minor: 5 memoryClockRate(GHz): 1.006\r\npciBusID: 0000:01:00.0\r\ntotalMemory: 1.95GiB freeMemory: 1.82GiB\r\n2018-02-15 13:42:07.436453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GT 730, pci bus id: 0000:01:00.0, compute capability: 3.5)\r\nWARNING:tensorflow:From ptb_word_lm.py:504: Supervisor.__init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.\r\nInstructions for updating:\r\nPlease switch to tf.train.MonitoredTrainingSession\r\n2018-02-15 13:42:17.089765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1195] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GT 730, pci bus id: 0000:01:00.0, compute capability: 3.5)\r\nEpoch: 1 Learning rate: 1.000\r\n0.004 perplexity: 5095.013 speed: 3685 wps\r\n0.104 perplexity: 846.368 speed: 5772 wps\r\n0.204 perplexity: 627.641 speed: 5847 wps\r\n0.304 perplexity: 505.304 speed: 5854 wps\r\n0.404 perplexity: 435.348 speed: 5852 wps\r\n0.504 perplexity: 389.893 speed: 5815 wps\r\n2018-02-15 13:43:50.493081: E tensorflow/stream_executor/cuda/cuda_event.cc:49] Error polling for event status: failed to query event: CUDA_ERROR_ILLEGAL_ADDRESS\r\n2018-02-15 13:43:50.493151: F tensorflow/core/common_runtime/gpu/gpu_event_mgr.cc:203] Unexpected Event status: 1\r\n```\r\n\r\nSystem information\r\n - **Have I written custom code:** No\r\n - **OS Platform and Distribution:** Ubuntu 16.04\r\n - **TensorFlow installed from:** binary\r\n - **TensorFlow version:** tensorflow-gpu (1.5.0)\r\n - **Python version:** 3.5.2\r\n - **Bazel version:** Not compiled from source\r\n - **GCC/Compiler version:** Not compiled from source\r\n - **CUDA/cuDNN version:** 9.1/v7\r\n - **GPU model and memory:** GeForce GT 730 (2GB x 1)\r\n", "Have you tried reducing (to half) the batch size? The cause of your error seems to be a different than mine.", "@burglarhobbit yeah even at batch_size=1, but as you said, might be a different cause.", "@ebrevdo can you please take a look? ", "I get the same error with Keras on Ubuntu 16.04\r\n\r\nMy model is\r\n\r\n  ```\r\n inp1 = Input(shape=(maxlen, ), name='w_inp')\r\n    x = Embedding(embedding_matrix.shape[0],\r\n                  embedding_matrix.shape[1],\r\n                  weights=[embedding_matrix],\r\n                  trainable=trainable, name='w_emb')(inp1)\r\n    x = SpatialDropout1D(dropout, name='w_drop')(x)\r\n\r\n    for i in range(rnn_layers):\r\n        x = Bidirectional(CuDNNGRU(n_hidden, return_sequences=True), name='w_bidi%d' % i)(x)\r\n    avg_pool = GlobalAveragePooling1D(name='w_ave')(x)\r\n    max_pool = GlobalMaxPooling1D(name='w_max')(x)\r\n    conc1 = concatenate([avg_pool, max_pool], name='w_conc')\r\n \r\n    inp2 = Input(shape=(char_maxlen, ), name='c_inp')\r\n    x = Embedding(char_embedding_matrix.shape[0],\r\n                  char_embedding_matrix.shape[1],\r\n                  weights=[char_embedding_matrix], name='c_emb')(inp2)\r\n    x = SpatialDropout1D(dropout, name='c_drop')(x)\r\n\r\n    for i in range(rnn_layers - 1):\r\n        x = Bidirectional(CuDNNGRU(n_hidden, return_sequences=True), name='c_bidi%d' % i)(x)\r\n    conc2 = Bidirectional(Rec(n_hidden, return_sequences=False), name='c_bidi%d' % rnn_layers)(x)\r\n\r\n    conc = concatenate([conc1, conc2], name='w_c_conc')\r\n\r\n    outp = Dense(6, activation=\"sigmoid\", name='output')(conc)\r\n\r\n    model = Model(inputs=[inp1, inp2], outputs=outp)\r\n    model.compile(loss='binary_crossentropy',\r\n                  optimizer='adam',\r\n                  metrics=['accuracy'])\r\n```", "@peterwilliams97 It would mean that the graph gets disconnected somewhere in between which is why it is not able to perform backprop.", "@burglarhobbit Thanks\r\nWhat can I do to prevent this? It happens over a day into my modelling in a late epoch of a late CV round of the fourth or fifth model in the test run. It is caused by some sort of resource leak somewhere?", "I saw this again today under similar circumstances to my last comment\r\n```\r\n File \"/home/pcadmin/code/Butt-Head-Astronomer/toxic/mod_rec_word_char.py\", line 89, in get_model2\r\n    x = Bidirectional(Rec(n_hidden, return_sequences=True), name='c_bidi')(x)\r\n  File \"/home/pcadmin/anaconda3/lib/python3.6/site-packages/keras/layers/wrappers.py\", line 324, in __call__\r\n    return super(Bidirectional, self).__call__(inputs, **kwargs)\r\n  File \"/home/pcadmin/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 617, in __call__\r\n    output = self.call(inputs, **kwargs)\r\n  File \"/home/pcadmin/anaconda3/lib/python3.6/site-packages/keras/layers/wrappers.py\", line 385, in call\r\n    y_rev = self.backward_layer.call(inputs, **kwargs)\r\n  File \"/home/pcadmin/anaconda3/lib/python3.6/site-packages/keras/layers/cudnn_recurrent.py\", line 90, in call\r\n    output, states = self._process_batch(inputs, initial_state)\r\n  File \"/home/pcadmin/anaconda3/lib/python3.6/site-packages/keras/layers/cudnn_recurrent.py\", line 297, in _process_batch\r\n    is_training=True)\r\n  File \"/home/pcadmin/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 1555, in __call__\r\n    seed=self._seed)\r\n  File \"/home/pcadmin/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 944, in _cudnn_rnn_no_input_c\r\n    direction, dropout, seed, name)\r\n  File \"/home/pcadmin/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/python/ops/cudnn_rnn_ops.py\", line 858, in _cudnn_rnn\r\n    name=name)\r\n  File \"/home/pcadmin/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/cudnn_rnn/ops/gen_cudnn_rnn_ops.py\", line 107, in cudnn_rnn\r\n    is_training=is_training, name=name)\r\n  File \"/home/pcadmin/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\r\n    op_def=op_def)\r\n  File \"/home/pcadmin/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3160, in create_op\r\n    op_def=op_def)\r\n  File \"/home/pcadmin/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1625, in __init__\r\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\r\n\r\nInternalError (see above for traceback): Failed to call ThenRnnForward\r\n         [[Node: c_bidi_24/CudnnRNN_1 = CudnnRNN[T=DT_FLOAT, direction=\"unidirectional\", dropout=0, input_mode=\"linear_input\", is_training=true, rnn_mode=\"gru\", seed=234, seed2=0, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](c_bidi_24/transpose_2, c_bidi_24/ExpandDims_1, w_bidi_24/Const, c_bidi_24/concat_1)]]\r\n         [[Node: output_24/Sigmoid/_5943 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_571_output_24/Sigmoid\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\r\n```\r\n\r\nThe Keras description of the model is\r\n```\r\n__________________________________________________________________________________________________\r\nLayer (type)                    Output Shape         Param #     Connected to                     \r\n==================================================================================================\r\nw_inp (InputLayer)              (None, 150)          0                                            \r\n__________________________________________________________________________________________________\r\nc_inp (InputLayer)              (None, 600)          0                                            \r\n__________________________________________________________________________________________________\r\nw_emb (Embedding)               (None, 150, 300)     45000000    w_inp[0][0]                      \r\n__________________________________________________________________________________________________\r\nc_emb (Embedding)               (None, 600, 25)      25000       c_inp[0][0]                      \r\n__________________________________________________________________________________________________\r\nw_drop (SpatialDropout1D)       (None, 150, 300)     0           w_emb[0][0]                      \r\n__________________________________________________________________________________________________\r\nc_drop (SpatialDropout1D)       (None, 600, 25)      0           c_emb[0][0]                      \r\n__________________________________________________________________________________________________\r\nw_bidi (Bidirectional)          (None, 150, 256)     330240      w_drop[0][0]                     \r\n__________________________________________________________________________________________________\r\nc_bidi (Bidirectional)          (None, 600, 256)     119040      c_drop[0][0]                     \r\n__________________________________________________________________________________________________\r\nw_ave (GlobalAveragePooling1D)  (None, 256)          0           w_bidi[0][0]                     \r\n__________________________________________________________________________________________________\r\nw_max (GlobalMaxPooling1D)      (None, 256)          0           w_bidi[0][0]                     \r\n__________________________________________________________________________________________________\r\nc_ave (GlobalAveragePooling1D)  (None, 256)          0           c_bidi[0][0]                     \r\n__________________________________________________________________________________________________\r\nc_max (GlobalMaxPooling1D)      (None, 256)          0           c_bidi[0][0]                     \r\n__________________________________________________________________________________________________\r\nw_conc (Concatenate)            (None, 512)          0           w_ave[0][0]                      \r\n                                                                 w_max[0][0]                      \r\n__________________________________________________________________________________________________\r\nc_conc (Concatenate)            (None, 512)          0           c_ave[0][0]                      \r\n                                                                 c_max[0][0]                      \r\n__________________________________________________________________________________________________\r\nw_c_conc (Concatenate)          (None, 1024)         0           w_conc[0][0]                     \r\n                                                                 c_conc[0][0]                     \r\n__________________________________________________________________________________________________\r\noutput (Dense)                  (None, 6)            6150        w_c_conc[0][0]                   \r\n==================================================================================================\r\nTotal params: 45,480,430\r\nTrainable params: 480,430\r\nNon-trainable params: 45,000,000\r\n__________________________________________________________________________________________________\r\n```\r\n`nvidia-smi` output after the crash is \r\n```\r\n+-----------------------------------------------------------------------------+\r\n| NVIDIA-SMI 390.30                 Driver Version: 390.30                    |\r\n|-------------------------------+----------------------+----------------------+\r\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n|===============================+======================+======================|\r\n|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\r\n| N/A   29C    P8    30W / 149W |     15MiB / 11441MiB |      0%      Default |\r\n+-------------------------------+----------------------+----------------------+\r\n                                                                               \r\n+-----------------------------------------------------------------------------+\r\n| Processes:                                                       GPU Memory |\r\n|  GPU       PID   Type   Process name                             Usage      |\r\n|=============================================================================|\r\n|    0      1511      G   /usr/lib/xorg/Xorg                            15MiB |\r\n+-----------------------------------------------------------------------------+\r\n```", "@peterwilliams97 Did you try asking in the keras github repo? I do not have much experience in keras to comment on it but have you tried running it on a cpu? Sometimes CUDA acts weird which has caused me to choose native GRU rather than cudnn_gru when using while loops in tensorflow", "Could you provide a minimum reproducible example? Also, why not using the CudnnGRU comes with TF?", "My minimal reproducible example is doing parameter search on the above Keras model on my full dataset for a day or so. This search has been running on a number of VMs and it has crashed on all of them with different parameters each time. I can't see a common pattern to use for a simpler example. Restarting a VM with the same initial parameters in the parameter search leads to a crash a different point in the search.\r\n\r\nI thought I was using TF CudnnGRU  indirectly. Keras `CuDNNGRU` calls TF `CudnnGRU` according to the Keras source code.\r\n```\r\nfrom tensorflow.contrib.cudnn_rnn.python.ops import cudnn_rnn_ops\r\nself._cudnn_gru = cudnn_rnn_ops.CudnnGRU(...\r\n```", "The errors logged showed certain GPU kernel had problem, but didn't pinpoint which one.\r\n\r\n@burglarhobbit, @peterwilliams97  the models above are too complicated for quick trouble shooting. Could you make them **minimum** examples which only has one input, output and calls the suspicious layer function (tf.layer or tf.keras)? \r\n\r\n", "@protoget Here it is:\r\n\r\n```\r\nimport tensorflow as tf\r\nmax_para = tf.placeholder(tf.int32)\r\nnum_units = 150\r\ninputs = tf.placeholder(tf.float32,shape=[15,8,num_units])\r\nclass cudnn_gru:\r\n    def __init__(self):\r\n        self.gru_fw = tf.contrib.cudnn_rnn.CudnnGRU(1, num_units, \r\n            kernel_initializer=tf.random_normal_initializer(stddev=0.1))\r\n        with tf.variable_scope('CUDNN_GRU', reuse=tf.AUTO_REUSE):\r\n            self.init_fw = tf.get_variable(\"init_fw\",shape=[1, 8, num_units],initializer=\r\n                tf.zeros_initializer())\r\n            self.init_bw = tf.get_variable(\"init_bw\",shape=[1, 8, num_units],initializer=\r\n                tf.zeros_initializer())\r\n    def __call__(self,inputs):\r\n        out_fw, _ = self.gru_fw(inputs, initial_state=(self.init_fw,))\r\n\r\nclass cudnn_gru2:\r\n    def __init__(self):\r\n        self.gru_fw = tf.contrib.cudnn_rnn.CudnnGRU(1, num_units-1, \r\n            kernel_initializer=tf.random_normal_initializer(stddev=0.1))\r\n        with tf.variable_scope('CUDNN_GRU', reuse=tf.AUTO_REUSE):\r\n            self.init_fw = tf.get_variable(\"init_fw\",shape=[1, 8, num_units],initializer=\r\n                tf.zeros_initializer())\r\n            self.init_bw = tf.get_variable(\"init_bw\",shape=[1, 8, num_units],initializer=\r\n                tf.zeros_initializer())\r\n    def __call__(self,inputs):\r\n        out_fw, _ = self.gru_fw(inputs, initial_state=(self.init_fw,))\r\n\r\ndef get_output():\r\n    gru = cudnn_gru()\r\n    out = gru(inputs)\r\n    return tf.constant(1)\r\n\r\ndef get_output2():\r\n    gru = cudnn_gru2()\r\n    out = gru(inputs)\r\n    return tf.constant(2)\r\n\r\nfor i in range(3):\r\n    i_ = tf.constant(i)\r\n    out = tf.cond(i_<max_para,get_output,get_output2)\r\n```", "I had the same problem. I had both cuda 10.0 and 10.1 installed. I removed the 10.1 and then downgraded the graphic card's driver and the problem was gone. ", "@burglarhobbit Is this still an issue ?\r\nWe see that you are using old version of tensorflow 1.x which is not actively supported, We recommend that you upgrade to 2.4 or later version.Please have a look at the [migration](https://www.tensorflow.org/guide/migrate) guide for reference to migrate from TensorFlow 1.x to TensorFlow 2.Thank you!", "This issue has been automatically marked as stale because it has no recent activity. It will be closed if no further activity occurs. Thank you.\n", "Closing as stale. Please reopen if you'd like to work on this further.\n"]}, {"number": 17008, "title": "Fix typo", "body": "", "comments": []}, {"number": 17007, "title": "Installation Tensorflow from source stuck at Downloading grpc ", "body": "Installation Tensorflow 1.4.0-rc0 from source on RHEL 7.4 \r\n\r\nInstallation went fine with Python3.6, CUDA 9.1,  CUDNN 7.0.5\r\n\r\ncd tensorflow-1.4.0-rc0\r\n./configure\r\nbazel build --config=opt //tensorflow/tools/pip_package:build_pip_package\r\n\r\nHowever, it is not moving from \r\nINFO: Downloading https://mirror.bazel.build/github.com/grpc/grpc/archive/781fd/6f6ea03645a520cd5c675da67ab61f87e4b.tar.gz\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Kindly find the details below\r\n\r\nHave I written custom code - No/NA\r\nOS Platform and Distribution - RHEL 7.4 Codename: Maipo \r\nTensorFlow installed from : https://github.com/tensorflow/tensorflow/archive/v1.4.0-rc0.zip\r\nTensorFlow version - 1.4.0\r\nBazel version - https://github.com/bazelbuild/bazel/releases/download/0.5.4/bazel-0.5.4-installer-linux-x86_64.sh\r\nCUDA/cuDNN version - cudnn-9.1-linux-x64-v7.tgz \r\nGPU model and memory - eForce GTX 1080 Ti, 11 GB\r\nExact command to reproduce  - cd tensorflow-1.4.0-rc0\r\n./configure\r\nbazel build --config=opt //tensorflow/tools/pip_package:build_pip_package", "This question is better asked on  [StackOverflow](http://stackoverflow.com/questions/tagged/tensorflow) since it is not a  bug or feature request. There is also a larger community that reads questions there. Thanks!"]}, {"number": 17006, "title": "Batch normalization acting weird?!", "body": "### System Information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No custom code\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 7.1\r\n- **TensorFlow version (use command below)**: 1.3.0\r\n- **Python version**: 3.6\r\n- **Exact command to reproduce**: See code below\r\n- **Bazel version**: Not building from source\r\n- **CUDA/cuDNN version**: Version 6\r\n- **GPU model and memory**: Nvidia Quadro k2200 with 4GB\r\n\r\n\r\n### Describe the problem\r\nHello everyone,\r\n\r\nso theres the method tf.layers.batch_normalization and i am trying to understand what is Happening behind the curtains and in how far it is manually reproducible and in conformance of the paper by Ioffe&Szegedy. After running a small script which can only Train the two Parameters Gamma and beta to minimize the loss it appears that there is not normalization taking place(activation reduces by the mean over all activations of one Batch divided by the square-root of the variance of all activations of one batch). It is more or less always considering the Initial activation and simply multiplies this with Gamma plus beta. And that is especially interesting if the Batch size is reduced to one(not even remotely sure what is Happening then; yet it seems like this does not affect the computation at all)...\r\n\r\nThank you for your time and consideration!\r\n\r\n### Source code / logs\r\n```Python\r\nimport numpy as np\r\nimport tensorflow as tf\r\n\r\ntest_img = np.array([[[[50],[100]],\r\n                   [[150],[2000]]],\r\n                   [[[0],[300]],\r\n                   [[140],[5000]]],\r\n                   [[[0],[300]],\r\n                   [[140],[5500]]],\r\n                   [[[0],[200]],\r\n                   [[1400],[5000]]],\r\n                   [[[0],[300]],\r\n                   [[140],[5000]]]], np.float32)\r\ngt_img = np.array([[[[60],[130]],\r\n                [[180],[225]]],\r\n                [[[60],[130]],\r\n                [[180],[225]]],\r\n                [[[600],[130]],\r\n                [[1800],[225]]],\r\n                [[[60],[100]],\r\n                [[180],[205]]],\r\n                [[[60],[100]],\r\n                [[180],[205]]]], np.float32)\r\ntest_img_op = tf.convert_to_tensor(test_img, tf.float32)\r\nnorm_op = tf.layers.batch_normalization(test_img_op, momentum=0)\r\n\r\nloss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = gt_img,\r\n                                                             logits = norm_op))\r\ncount = 0\r\nupdate_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\r\nwith tf.control_dependencies(update_ops):\r\n    optimizer_obj = tf.train.AdamOptimizer(0.01).minimize(loss_op)\r\nwith tf.Session() as sess:\r\n    sess.run(tf.group(tf.global_variables_initializer(), \r\n                      tf.local_variables_initializer()))\r\n    print(test_img)\r\n    while True:\r\n        count += 1\r\n        if count < 100:\r\n            new_img, op, lossy, trainable = sess.run([norm_op, \r\n                                                      optimizer_obj, \r\n                                                      loss_op, \r\n                                                      tf.trainable_variables()])\r\n            print(trainable)\r\n            print(new_img)\r\n        else:\r\n            break\r\n```", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nTensorFlow installed from\nBazel version\nCUDA/cuDNN version\nGPU model and memory", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 15 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 17005, "title": "Fix cmake for MacOS", "body": "This change address cmake build issues for MacOS.\r\n", "comments": ["Built on:\r\nmacOS v10.13.2\r\ngcc version\r\n  Configured with: --prefix=/Library/Developer/CommandLineTools/usr --with-gxx-include-dir=/usr/include/c++/4.2.1\r\n  Apple LLVM version 9.0.0 (clang-900.0.39.2)\r\n  Target: x86_64-apple-darwin17.3.0\r\nPython 2.7.10\r\nCommand:\r\n```bash\r\nmkdir ~/tensorflow/tensorflow/contrib/cmake/build\r\ncd ~/tensorflow/tensorflow/contrib/cmake/build\r\ncmake -DCMAKE_BUILD_TYPE=Release ..\r\nmake -j8 tf_python_build_pip_package\r\npip install tf_python/dist/tensorflow-1.6.0rc0-cp27-cp27m-macosx_10_13_intel.whl\r\nPython\r\nPython 2.7.10 (default, Jul 15 2017, 17:16:57)\r\n[GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.31)] on darwin\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> import tensorflow as tf\r\n>>> hello = tf.constant('Hello, TensorFlow!')\r\n>>> sess = tf.Session()\r\n>>> print(sess.run(hello))\r\nHello, TensorFlow!\r\n```\r\n", "@yifeif I added detailed explanation for each change and also updated the gemmlowp_URL.", "Nagging Assignee @yifeif: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Sorry for the delay and thanks for adding the comments @tedhtchang.", "Mind looking at the conflicts?", "@jhseu Sure I will resolve the conflict.", "Nagging Assignee @yifeif: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Windows doesn't build with newer version of gemmlowp library. I will take a look this failure.\r\nIf anyone wants see the error,  here are the messages:\r\nINFO: Build completed, 1 test FAILED, 6 total actions\r\n1564\r\n         t:\\src\\github\\tensorflow\\cmake_build\\gemmlowp\\src\\gemmlowp\\internal\\../internal/platform.h(57): error C3861: '_aligned_malloc': identifier not found (compiling source file T:\\src\\github\\tensorflow\\tensorflow\\core\\kernels\\quantized_matmul_op.cc) [T:\\src\\github\\tensorflow\\cmake_build\\tf_core_kernels.vcxproj]\r\n1565\r\n         t:\\src\\github\\tensorflow\\cmake_build\\gemmlowp\\src\\gemmlowp\\internal\\../internal/platform.h(60): error C3861: '_aligned_free': identifier not found (compiling source file T:\\src\\github\\tensorflow\\tensorflow\\core\\kernels\\quantized_matmul_op.cc) [T:\\src\\github\\tensorflow\\cmake_build\\tf_core_kernels.vcxproj]\r\n1566\r\n         t:\\src\\github\\tensorflow\\cmake_build\\gemmlowp\\src\\gemmlowp\\meta\\multi_thread_common.h(26): error C2065: '_SC_NPROCESSORS_ONLN': undeclared identifier (compiling source file T:\\src\\github\\tensorflow\\tensorflow\\core\\kernels\\quantize_down_and_shrink_range.cc) [T:\\src\\github\\tensorflow\\cmake_build\\tf_core_kernels.vcxproj]\r\n1567\r\n         t:\\src\\github\\tensorflow\\cmake_build\\gemmlowp\\src\\gemmlowp\\meta\\multi_thread_common.h(26): error C3861: 'sysconf': identifier not found (compiling source file T:\\src\\github\\tensorflow\\tensorflow\\core\\kernels\\quantize_down_and_shrink_range.cc) [T:\\src\\github\\tensorflow\\cmake_build\\tf_core_kernels.vcxproj]\r\n1568\r\n         t:\\src\\github\\tensorflow\\cmake_build\\gemmlowp\\src\\gemmlowp\\meta\\multi_thread_common.h(26): error C2065: '_SC_NPROCESSORS_ONLN': undeclared identifier (compiling source file T:\\src\\github\\tensorflow\\tensorflow\\core\\kernels\\quantized_activation_ops.cc) [T:\\src\\github\\tensorflow\\cmake_build\\tf_core_kernels.vcxproj]\r\n1569\r\n         t:\\src\\github\\tensorflow\\cmake_build\\gemmlowp\\src\\gemmlowp\\meta\\multi_thread_common.h(26): error C3861: 'sysconf': identifier not found (compiling source file T:\\src\\github\\tensorflow\\tensorflow\\core\\kernels\\quantized_activation_ops.cc) [T:\\src\\github\\tensorflow\\cmake_build\\tf_core_kernels.vcxproj]\r\n1570\r\n         t:\\src\\github\\tensorflow\\cmake_build\\gemmlowp\\src\\gemmlowp\\meta\\multi_thread_common.h(26): error C2065: '_SC_NPROCESSORS_ONLN': undeclared identifier (compiling source file T:\\src\\github\\tensorflow\\tensorflow\\core\\kernels\\quantized_add_op.cc) [T:\\src\\github\\tensorflow\\cmake_build\\tf_core_kernels.vcxproj]\r\n1571\r\n         t:\\src\\github\\tensorflow\\cmake_build\\gemmlowp\\src\\gemmlowp\\meta\\multi_thread_common.h(26): error C3861: 'sysconf': identifier not found (compiling source file T:\\src\\github\\tensorflow\\tensorflow\\core\\kernels\\quantized_add_op.cc) [T:\\src\\github\\tensorflow\\cmake_build\\tf_core_kernels.vcxproj]\r\n1572\r\n         t:\\src\\github\\tensorflow\\cmake_build\\gemmlowp\\src\\gemmlowp\\meta\\multi_thread_common.h(26): error C2065: '_SC_NPROCESSORS_ONLN': undeclared identifier (compiling source file T:\\src\\github\\tensorflow\\tensorflow\\core\\kernels\\quantize_op.cc) [T:\\src\\github\\tensorflow\\cmake_build\\tf_core_kernels.vcxproj]\r\n1573\r\n         t:\\src\\github\\tensorflow\\cmake_build\\gemmlowp\\src\\gemmlowp\\meta\\multi_thread_common.h(26): error C3861: 'sysconf': identifier not found (compiling source file T:\\src\\github\\tensorflow\\tensorflow\\core\\kernels\\quantize_op.cc) [T:\\src\\github\\tensorflow\\cmake_build\\tf_core_kernels.vcxproj]\r\n1574\r\n         t:\\src\\github\\tensorflow\\cmake_build\\gemmlowp\\src\\gemmlowp\\meta\\multi_thread_common.h(26): error C2065: '_SC_NPROCESSORS_ONLN': undeclared identifier (compiling source file T:\\src\\github\\tensorflow\\tensorflow\\core\\kernels\\quantized_bias_add_op.cc) [T:\\src\\github\\tensorflow\\cmake_build\\tf_core_kernels.vcxproj]\r\n1575\r\n         t:\\src\\github\\tensorflow\\cmake_build\\gemmlowp\\src\\gemmlowp\\meta\\multi_thread_common.h(26): error C3861: 'sysconf': identifier not found (compiling source file T:\\src\\github\\tensorflow\\tensorflow\\core\\kernels\\quantized_bias_add_op.cc) [T:\\src\\github\\tensorflow\\cmake_build\\tf_core_kernels.vcxproj]\r\n1576\r\n         t:\\src\\github\\tensorflow\\cmake_build\\gemmlowp\\src\\gemmlowp\\meta\\multi_thread_common.h(26): error C2065: '_SC_NPROCESSORS_ONLN': undeclared identifier (compiling source file T:\\src\\github\\tensorflow\\tensorflow\\core\\kernels\\quantized_matmul_op.cc) [T:\\src\\github\\tensorflow\\cmake_build\\tf_core_kernels.vcxproj]\r\n1577\r\n         t:\\src\\github\\tensorflow\\cmake_build\\gemmlowp\\src\\gemmlowp\\meta\\multi_thread_common.h(26): error C3861: 'sysconf': identifier not found (compiling source file T:\\src\\github\\tensorflow\\tensorflow\\core\\kernels\\quantized_matmul_op.cc) [T:\\src\\github\\tensorflow\\cmake_build\\tf_core_kernels.vcxproj]\r\n1578\r\n         t:\\src\\github\\tensorflow\\cmake_build\\gemmlowp\\src\\gemmlowp\\meta\\multi_thread_common.h(26): error C2065: '_SC_NPROCESSORS_ONLN': undeclared identifier (compiling source file T:\\src\\github\\tensorflow\\tensorflow\\core\\kernels\\quantized_conv_ops.cc) [T:\\src\\github\\tensorflow\\cmake_build\\tf_core_kernels.vcxproj]\r\n1579\r\n         t:\\src\\github\\tensorflow\\cmake_build\\gemmlowp\\src\\gemmlowp\\meta\\multi_thread_common.h(26): error C3861: 'sysconf': identifier not found (compiling source file T:\\src\\github\\tensorflow\\tensorflow\\core\\kernels\\quantized_conv_ops.cc) [T:\\src\\github\\tensorflow\\cmake_build\\tf_core_kernels.vcxproj]\r\n1580\r\n         t:\\src\\github\\tensorflow\\cmake_build\\gemmlowp\\src\\gemmlowp\\meta\\multi_thread_common.h(26): error C2065: '_SC_NPROCESSORS_ONLN': undeclared identifier (compiling source file T:\\src\\github\\tensorflow\\tensorflow\\core\\kernels\\quantized_mul_op.cc) [T:\\src\\github\\tensorflow\\cmake_build\\tf_core_kernels.vcxproj]\r\n1581\r\n         t:\\src\\github\\tensorflow\\cmake_build\\gemmlowp\\src\\gemmlowp\\meta\\multi_thread_common.h(26): error C3861: 'sysconf': identifier not found (compiling source file T:\\src\\github\\tensorflow\\tensorflow\\core\\kernels\\quantized_mul_op.cc) [T:\\src\\github\\tensorflow\\cmake_build\\tf_core_kernels.vcxproj]\r\n1582\r\n         t:\\src\\github\\tensorflow\\cmake_build\\gemmlowp\\src\\gemmlowp\\meta\\multi_thread_common.h(26): error C2065: '_SC_NPROCESSORS_ONLN': undeclared identifier (compiling source file T:\\src\\github\\tensorflow\\tensorflow\\core\\kernels\\requantize.cc) [T:\\src\\github\\tensorflow\\cmake_build\\tf_core_kernels.vcxproj]\r\n1583\r\n         t:\\src\\github\\tensorflow\\cmake_build\\gemmlowp\\src\\gemmlowp\\meta\\multi_thread_common.h(26): error C3861: 'sysconf': identifier not found (compiling source file T:\\src\\github\\tensorflow\\tensorflow\\core\\kernels\\requantize.cc) [T:\\src\\github\\tensorflow\\cmake_build\\tf_core_kernels.vcxproj]\r\n1584\r\n1585\r\n    423 Warning(s)\r\n1586\r\n    24 Error(s)\r\n1587\r\n", "@yifeif looks like gemmlow hash was updated by other PR recently. Could you start a Windows CMake CI test?", "@yifeif Failed //tensorflow/python/keras:cudnn_recurrent_test  but I don't think it's related to my change."]}, {"number": 17004, "title": "MKL: cifar 10 divergance fix and batchnorm unit test fix", "body": "1. Fix Cifar 10 diverging issue\r\n2. Fix BatchNorm unit test failures", "comments": ["Based on suggestion from Tatiana (tatianashp), changes have been made to fix improper comments such as replacing \"tf\" with \"TensorFlow\".  The fix touches <comment> statements only - so no extra test is needed. "]}, {"number": 17003, "title": "Missing files and errors during Windows C++ Visual studio build", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Windows 10\r\n- **TensorFlow installed from (source or binary)**: Source\r\n- **TensorFlow version (use command below)**: 1.4\r\n- **Python version**:  3.5\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: Cmake 3.10.2, swigwin 3.0.12, Visual studio 2017, but toolset 2015 v140\r\n- **CUDA/cuDNN version**: N/A, trying to build cpu version\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**:\r\n\r\n**1. Cmake build**:\r\n```\r\nC:\\tensorflow\\tensorflow\\contrib\\cmake\\build>cmake .. -A x64 -DCMAKE_BUILD_TYPE=Release ^\r\nMore? -DSWIG_EXECUTABLE=C:\\swigwin-3.0.12\\swig.exe ^\r\nMore? -DPYTHON_EXECUTABLE=C:\\Users\\User\\Anaconda3\\python.exe  ^\r\nMore? -DPYTHON_LIBRARIES=C:\\Users\\User\\Anaconda3\\libs\\python35.lib\r\n```\r\n**2. Visual studio 2017**:\r\n\r\nFor each project I set in properties:\r\n- target platform version: 10.0.16299.0 -> 8.1\r\n- platform toolset: Visual studio 2017 (v141) -> Visual studio 2015 (v140)\r\n\r\nThen in Configuration Manager I select Release in Active Resolution Configuration.\r\n\r\n### Describe the problem\r\nI want to use Tensorflow in my Windows C++ application. Therefore I'm trying to build in Visual studio on a Windows system.\r\nHowever during the build I receive multiple errors, e.g. missing files and multiple projects cannot be built.\r\n\r\n### Source code / logs\r\n\r\nMultiple times I receive this missing file error:\r\n```\r\n...\r\nC:\\tensorflow\\tensorflow/core/common_runtime/device.h(37): fatal error C1083: Cannot open include file: 'tensorflow/core/framework/device_attributes.pb_text.h': No such file or directory (compiling source file C:\\tensorflow\\tensorflow\\core\\kernels\\captured_function.cc)\r\n...\r\n```\r\n\r\nFailed project builds:\r\n```\r\n79>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_cc_op_gen_main.dir\\Release\\cc_op_gen.obj'\r\n79>Done building project \"stateless_random_ops_gen_cc.vcxproj\" -- FAILED.\r\n80>------ Build started: Project: state_ops_gen_cc, Configuration: Release x64 ------\r\n80>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n80>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n80>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_cc_op_gen_main.dir\\Release\\cc_op_gen.obj'\r\n80>Done building project \"state_ops_gen_cc.vcxproj\" -- FAILED.\r\n81>------ Build started: Project: bitwise_ops_gen_cc, Configuration: Release x64 ------\r\n81>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n81>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n81>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_cc_op_gen_main.dir\\Release\\cc_op_gen.obj'\r\n81>Done building project \"bitwise_ops_gen_cc.vcxproj\" -- FAILED.\r\n82>------ Build started: Project: candidate_sampling_ops_gen_cc, Configuration: Release x64 ------\r\n82>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n82>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n82>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_cc_op_gen_main.dir\\Release\\cc_op_gen.obj'\r\n82>Done building project \"candidate_sampling_ops_gen_cc.vcxproj\" -- FAILED.\r\n83>------ Build started: Project: checkpoint_ops_gen_cc, Configuration: Release x64 ------\r\n83>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n83>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n83>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_cc_op_gen_main.dir\\Release\\cc_op_gen.obj'\r\n83>Done building project \"checkpoint_ops_gen_cc.vcxproj\" -- FAILED.\r\n84>------ Build started: Project: spectral_ops_gen_cc, Configuration: Release x64 ------\r\n84>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n77>tf_array_ops.vcxproj -> C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_array_ops.dir\\Release\\tf_array_ops.lib\r\n85>------ Build started: Project: array_ops_gen_cc, Configuration: Release x64 ------\r\n84>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n85>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n84>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_cc_op_gen_main.dir\\Release\\cc_op_gen.obj'\r\n84>Done building project \"spectral_ops_gen_cc.vcxproj\" -- FAILED.\r\n86>------ Build started: Project: io_ops_gen_cc, Configuration: Release x64 ------\r\n85>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n85>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_cc_op_gen_main.dir\\Release\\cc_op_gen.obj'\r\n86>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n85>Done building project \"array_ops_gen_cc.vcxproj\" -- FAILED.\r\n87>------ Build started: Project: set_ops_gen_cc, Configuration: Release x64 ------\r\n86>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n86>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_cc_op_gen_main.dir\\Release\\cc_op_gen.obj'\r\n86>Done building project \"io_ops_gen_cc.vcxproj\" -- FAILED.\r\n88>------ Build started: Project: linalg_ops_gen_cc, Configuration: Release x64 ------\r\n87>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n88>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n87>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n88>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n88>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_cc_op_gen_main.dir\\Release\\cc_op_gen.obj'\r\n88>Done building project \"linalg_ops_gen_cc.vcxproj\" -- FAILED.\r\n89>------ Build started: Project: resource_variable_ops_gen_cc, Configuration: Release x64 ------\r\n87>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_cc_op_gen_main.dir\\Release\\cc_op_gen.obj'\r\n87>Done building project \"set_ops_gen_cc.vcxproj\" -- FAILED.\r\n90>------ Build started: Project: math_ops_gen_cc, Configuration: Release x64 ------\r\n89>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n89>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n89>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_cc_op_gen_main.dir\\Release\\cc_op_gen.obj'\r\n89>Done building project \"resource_variable_ops_gen_cc.vcxproj\" -- FAILED.\r\n91>------ Build started: Project: logging_ops_gen_cc, Configuration: Release x64 ------\r\n90>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n90>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n90>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_cc_op_gen_main.dir\\Release\\cc_op_gen.obj'\r\n90>Done building project \"math_ops_gen_cc.vcxproj\" -- FAILED.\r\n92>------ Build started: Project: random_ops_gen_cc, Configuration: Release x64 ------\r\n91>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n91>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n91>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_cc_op_gen_main.dir\\Release\\cc_op_gen.obj'\r\n91>Done building project \"logging_ops_gen_cc.vcxproj\" -- FAILED.\r\n93>------ Build started: Project: lookup_ops_gen_cc, Configuration: Release x64 ------\r\n92>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n93>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n92>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n93>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n93>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_cc_op_gen_main.dir\\Release\\cc_op_gen.obj'\r\n93>Done building project \"lookup_ops_gen_cc.vcxproj\" -- FAILED.\r\n94>------ Build started: Project: sdca_ops_gen_cc, Configuration: Release x64 ------\r\n94>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n92>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_cc_op_gen_main.dir\\Release\\cc_op_gen.obj'\r\n92>Done building project \"random_ops_gen_cc.vcxproj\" -- FAILED.\r\n95>------ Build started: Project: image_ops_gen_cc, Configuration: Release x64 ------\r\n94>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n95>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n94>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_cc_op_gen_main.dir\\Release\\cc_op_gen.obj'\r\n94>Done building project \"sdca_ops_gen_cc.vcxproj\" -- FAILED.\r\n96>------ Build started: Project: nn_ops_gen_cc, Configuration: Release x64 ------\r\n95>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n95>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_cc_op_gen_main.dir\\Release\\cc_op_gen.obj'\r\n95>Done building project \"image_ops_gen_cc.vcxproj\" -- FAILED.\r\n97>------ Build started: Project: remote_fused_graph_ops_gen_cc, Configuration: Release x64 ------\r\n96>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n96>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n96>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_cc_op_gen_main.dir\\Release\\cc_op_gen.obj'\r\n96>Done building project \"nn_ops_gen_cc.vcxproj\" -- FAILED.\r\n98>------ Build started: Project: no_op_gen_cc, Configuration: Release x64 ------\r\n97>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n98>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n97>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n98>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n98>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_cc_op_gen_main.dir\\Release\\cc_op_gen.obj'\r\n98>Done building project \"no_op_gen_cc.vcxproj\" -- FAILED.\r\n99>------ Build started: Project: control_flow_ops_gen_cc, Configuration: Release x64 ------\r\n99>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n97>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_cc_op_gen_main.dir\\Release\\cc_op_gen.obj'\r\n97>Done building project \"remote_fused_graph_ops_gen_cc.vcxproj\" -- FAILED.\r\n100>------ Build started: Project: parsing_ops_gen_cc, Configuration: Release x64 ------\r\n99>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n99>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_cc_op_gen_main.dir\\Release\\cc_op_gen.obj'\r\n99>Done building project \"control_flow_ops_gen_cc.vcxproj\" -- FAILED.\r\n101>------ Build started: Project: ctc_ops_gen_cc, Configuration: Release x64 ------\r\n100>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n101>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n100>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n101>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n101>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_cc_op_gen_main.dir\\Release\\cc_op_gen.obj'\r\n101>Done building project \"ctc_ops_gen_cc.vcxproj\" -- FAILED.\r\n102>------ Build started: Project: script_ops_gen_cc, Configuration: Release x64 ------\r\n102>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n100>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_cc_op_gen_main.dir\\Release\\cc_op_gen.obj'\r\n100>Done building project \"parsing_ops_gen_cc.vcxproj\" -- FAILED.\r\n103>------ Build started: Project: data_flow_ops_gen_cc, Configuration: Release x64 ------\r\n102>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n102>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_cc_op_gen_main.dir\\Release\\cc_op_gen.obj'\r\n102>Done building project \"script_ops_gen_cc.vcxproj\" -- FAILED.\r\n104>------ Build started: Project: dataset_ops_gen_cc, Configuration: Release x64 ------\r\n103>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n103>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n103>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_cc_op_gen_main.dir\\Release\\cc_op_gen.obj'\r\n103>Done building project \"data_flow_ops_gen_cc.vcxproj\" -- FAILED.\r\n105>------ Build started: Project: sparse_ops_gen_cc, Configuration: Release x64 ------\r\n104>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n105>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n104>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n105>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n105>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_cc_op_gen_main.dir\\Release\\cc_op_gen.obj'\r\n105>Done building project \"sparse_ops_gen_cc.vcxproj\" -- FAILED.\r\n106>------ Build started: Project: functional_ops_gen_cc, Configuration: Release x64 ------\r\n104>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_cc_op_gen_main.dir\\Release\\cc_op_gen.obj'\r\n104>Done building project \"dataset_ops_gen_cc.vcxproj\" -- FAILED.\r\n107>------ Build started: Project: string_ops_gen_cc, Configuration: Release x64 ------\r\n106>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n106>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n106>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_cc_op_gen_main.dir\\Release\\cc_op_gen.obj'\r\n106>Done building project \"functional_ops_gen_cc.vcxproj\" -- FAILED.\r\n108>------ Build started: Project: sendrecv_ops_gen_cc, Configuration: Release x64 ------\r\n107>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n108>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n107>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n108>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n108>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_cc_op_gen_main.dir\\Release\\cc_op_gen.obj'\r\n108>Done building project \"sendrecv_ops_gen_cc.vcxproj\" -- FAILED.\r\n109>------ Build started: Project: training_ops_gen_cc, Configuration: Release x64 ------\r\n107>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_cc_op_gen_main.dir\\Release\\cc_op_gen.obj'\r\n107>Done building project \"string_ops_gen_cc.vcxproj\" -- FAILED.\r\n110>------ Build started: Project: user_ops_gen_cc, Configuration: Release x64 ------\r\n109>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n109>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n109>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_cc_op_gen_main.dir\\Release\\cc_op_gen.obj'\r\n109>Done building project \"training_ops_gen_cc.vcxproj\" -- FAILED.\r\n111>------ Build started: Project: tf_core_cpu, Configuration: Release x64 ------\r\n110>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n111>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n110>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n111>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n111>loader.cc\r\n110>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_cc_op_gen_main.dir\\Release\\cc_op_gen.obj'\r\n...\r\n```\r\n\r\n```\r\n152>------ Build started: Project: contrib_tensor_forest_stats_ops_gen_python, Configuration: Release x64 ------\r\n121>padded_batch_dataset_op.cc\r\n121>padding_fifo_queue.cc\r\n121>padding_fifo_queue_op.cc\r\n152>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n152>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n121>parallel_map_dataset_op.cc\r\n152>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n152>Done building project \"contrib_tensor_forest_stats_ops_gen_python.vcxproj\" -- FAILED.\r\n153>------ Build started: Project: contrib_text_skip_gram_ops_gen_python, Configuration: Release x64 ------\r\n121>parameterized_truncated_normal_op.cc\r\n121>parse_tensor_op.cc\r\n121>C:\\tensorflow\\tensorflow/core/common_runtime/device.h(37): fatal error C1083: Cannot open include file: 'tensorflow/core/framework/device_attributes.pb_text.h': No such file or directory (compiling source file C:\\tensorflow\\tensorflow\\core\\kernels\\parallel_map_dataset_op.cc)\r\n121>pooling_ops_3d.cc\r\n121>pooling_ops_common.cc\r\n121>population_count_op.cc\r\n121>C:\\tensorflow\\tensorflow/core/common_runtime/device.h(37): fatal error C1083: Cannot open include file: 'tensorflow/core/framework/device_attributes.pb_text.h': No such file or directory (compiling source file C:\\tensorflow\\tensorflow\\core\\kernels\\pooling_ops_common.cc)\r\n121>prefetch_dataset_op.cc\r\n153>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n153>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n153>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n121>priority_queue.cc\r\n153>Done building project \"contrib_text_skip_gram_ops_gen_python.vcxproj\" -- FAILED.\r\n154>------ Build started: Project: control_flow_ops_gen_python, Configuration: Release x64 ------\r\n121>priority_queue_op.cc\r\n154>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n121>qr_op_complex128.cc\r\n121>qr_op_complex64.cc\r\n121>qr_op_double.cc\r\n154>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n154>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n154>Done building project \"control_flow_ops_gen_python.vcxproj\" -- FAILED.\r\n155>------ Build started: Project: ctc_ops_gen_python, Configuration: Release x64 ------\r\n121>qr_op_float.cc\r\n155>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n155>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n155>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n155>Done building project \"ctc_ops_gen_python.vcxproj\" -- FAILED.\r\n```\r\n\r\n```\r\n150>C:\\tensorflow\\tensorflow/core/common_runtime/device.h(37): fatal error C1083: Cannot open include file: 'tensorflow/core/framework/device_attributes.pb_text.h': No such file or directory\r\n150>Done building project \"tf_core_direct_session.vcxproj\" -- FAILED.\r\n151>------ Build started: Project: tf_contrib_tensor_forest_stats_ops, Configuration: Release x64 ------\r\n121>mirror_pad_op_cpu_impl_3.cc\r\n121>mirror_pad_op_cpu_impl_4.cc\r\n121>mirror_pad_op_cpu_impl_5.cc\r\n121>mkl_aggregate_ops.cc\r\n121>mkl_avgpooling_op.cc\r\n121>mkl_concat_op.cc\r\n121>mkl_conv_grad_bias_ops.cc\r\n121>mkl_conv_grad_filter_ops.cc\r\n121>mkl_conv_grad_input_ops.cc\r\n121>mkl_conv_ops.cc\r\n121>mkl_cwise_ops_common.cc\r\n121>mkl_fused_batch_norm_op.cc\r\n121>mkl_identity_op.cc\r\n121>mkl_input_conversion_op.cc\r\n121>mkl_lrn_op.cc\r\n121>mkl_matmul_op.cc\r\n121>mkl_maxpooling_op.cc\r\n121>mkl_pooling_ops_common.cc\r\n121>mkl_relu_op.cc\r\n121>mkl_reshape_op.cc\r\n121>mkl_transpose_op.cc\r\n121>multinomial_op.cc\r\n121>no_op.cc\r\n121>non_max_suppression_op.cc\r\n121>one_hot_op.cc\r\n121>ops_util.cc\r\n121>pack_op.cc\r\n121>pad_op.cc\r\n152>------ Build started: Project: contrib_tensor_forest_stats_ops_gen_python, Configuration: Release x64 ------\r\n121>padded_batch_dataset_op.cc\r\n121>padding_fifo_queue.cc\r\n121>padding_fifo_queue_op.cc\r\n152>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n152>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n121>parallel_map_dataset_op.cc\r\n152>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n152>Done building project \"contrib_tensor_forest_stats_ops_gen_python.vcxproj\" -- FAILED.\r\n153>------ Build started: Project: contrib_text_skip_gram_ops_gen_python, Configuration: Release x64 ------\r\n121>parameterized_truncated_normal_op.cc\r\n121>parse_tensor_op.cc\r\n121>C:\\tensorflow\\tensorflow/core/common_runtime/device.h(37): fatal error C1083: Cannot open include file: 'tensorflow/core/framework/device_attributes.pb_text.h': No such file or directory (compiling source file C:\\tensorflow\\tensorflow\\core\\kernels\\parallel_map_dataset_op.cc)\r\n121>pooling_ops_3d.cc\r\n121>pooling_ops_common.cc\r\n121>population_count_op.cc\r\n121>C:\\tensorflow\\tensorflow/core/common_runtime/device.h(37): fatal error C1083: Cannot open include file: 'tensorflow/core/framework/device_attributes.pb_text.h': No such file or directory (compiling source file C:\\tensorflow\\tensorflow\\core\\kernels\\pooling_ops_common.cc)\r\n121>prefetch_dataset_op.cc\r\n153>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n153>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n153>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n121>priority_queue.cc\r\n153>Done building project \"contrib_text_skip_gram_ops_gen_python.vcxproj\" -- FAILED.\r\n154>------ Build started: Project: control_flow_ops_gen_python, Configuration: Release x64 ------\r\n121>priority_queue_op.cc\r\n154>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n121>qr_op_complex128.cc\r\n121>qr_op_complex64.cc\r\n121>qr_op_double.cc\r\n154>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n154>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n154>Done building project \"control_flow_ops_gen_python.vcxproj\" -- FAILED.\r\n155>------ Build started: Project: ctc_ops_gen_python, Configuration: Release x64 ------\r\n121>qr_op_float.cc\r\n155>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n155>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n155>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n155>Done building project \"ctc_ops_gen_python.vcxproj\" -- FAILED.\r\n156>------ Build started: Project: data_flow_ops_gen_python, Configuration: Release x64 ------\r\n121>queue_base.cc\r\n121>queue_ops.cc\r\n121>random_crop_op.cc\r\n121>random_op.cc\r\n121>random_poisson_op.cc\r\n121>random_shuffle_op.cc\r\n157>------ Build started: Project: dataset_ops_gen_python, Configuration: Release x64 ------\r\n121>random_shuffle_queue_op.cc\r\n157>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n121>range_dataset_op.cc\r\n157>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n121>range_sampler.cc\r\n121>reader_dataset_ops.cc\r\n121>reader_ops.cc\r\n157>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n157>Done building project \"dataset_ops_gen_python.vcxproj\" -- FAILED.\r\n158>------ Build started: Project: debug_ops_gen_python, Configuration: Release x64 ------\r\n121>record_input_op.cc\r\n121>record_yielder.cc\r\n121>reduce_join_op.cc\r\n121>reduction_ops_all.cc\r\n121>reduction_ops_any.cc\r\n121>reduction_ops_common.cc\r\n121>reduction_ops_max.cc\r\n158>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n158>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n121>reduction_ops_mean.cc\r\n158>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n158>Done building project \"debug_ops_gen_python.vcxproj\" -- FAILED.\r\n159>------ Build started: Project: functional_ops_gen_python, Configuration: Release x64 ------\r\n121>reduction_ops_min.cc\r\n121>reduction_ops_prod.cc\r\n121>reduction_ops_sum.cc\r\n159>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n159>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n159>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n159>Done building project \"functional_ops_gen_python.vcxproj\" -- FAILED.\r\n160>------ Build started: Project: image_ops_gen_python, Configuration: Release x64 ------\r\n160>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n160>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n160>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n160>Done building project \"image_ops_gen_python.vcxproj\" -- FAILED.\r\n161>------ Build started: Project: io_ops_gen_python, Configuration: Release x64 ------\r\n121>relu_op.cc\r\n121>remote_fused_graph_execute_op.cc\r\n161>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n161>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n121>remote_fused_graph_execute_utils.cc\r\n121>C:\\tensorflow\\tensorflow\\core\\kernels\\remote_fused_graph_execute_op.cc(74): warning C4373: 'tensorflow::RemoteFusedGraphExecuteOp::Compute': virtual function overrides 'tensorflow::OpKernel::Compute', previous versions of the compiler did not override when parameters only differed by const/volatile qualifiers\r\n121>C:\\tensorflow\\tensorflow/core/framework/op_kernel.h(102): note: see declaration of 'tensorflow::OpKernel::Compute'\r\n121>repeat_dataset_op.cc\r\n121>reshape_op.cc\r\n161>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n161>Done building project \"io_ops_gen_python.vcxproj\" -- FAILED.\r\n162>------ Build started: Project: linalg_ops_gen_python, Configuration: Release x64 ------\r\n121>resize_area_op.cc\r\n121>C:\\tensorflow\\tensorflow/core/common_runtime/device.h(37): fatal error C1083: Cannot open include file: 'tensorflow/core/framework/device_attributes.pb_text.h': No such file or directory (compiling source file C:\\tensorflow\\tensorflow\\core\\kernels\\remote_fused_graph_execute_utils.cc)\r\n121>resize_bicubic_op.cc\r\n121>resize_bilinear_op.cc\r\n121>resize_nearest_neighbor_op.cc\r\n121>resource_variable_ops.cc\r\n121>restore_op.cc\r\n121>reverse_op.cc\r\n121>reverse_sequence_op.cc\r\n121>C:\\tensorflow\\tensorflow/core/util/tensor_slice_writer.h(36): fatal error C1083: Cannot open include file: 'tensorflow/core/util/saved_tensor_slice.pb_text.h': No such file or directory (compiling source file C:\\tensorflow\\tensorflow\\core\\kernels\\restore_op.cc)\r\n121>sample_distorted_bounding_box_op.cc\r\n121>save_op.cc\r\n121>save_restore_tensor.cc\r\n163>------ Build started: Project: logging_ops_gen_python, Configuration: Release x64 ------\r\n163>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n121>C:\\tensorflow\\tensorflow/core/util/tensor_slice_writer.h(36): fatal error C1083: Cannot open include file: 'tensorflow/core/util/saved_tensor_slice.pb_text.h': No such file or directory (compiling source file C:\\tensorflow\\tensorflow\\core\\kernels\\save_op.cc)\r\n121>save_restore_v2_ops.cc\r\n163>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n121>C:\\tensorflow\\tensorflow/core/util/tensor_slice_writer.h(36): fatal error C1083: Cannot open include file: 'tensorflow/core/util/saved_tensor_slice.pb_text.h': No such file or directory (compiling source file C:\\tensorflow\\tensorflow\\core\\kernels\\save_restore_tensor.cc)\r\n121>scan_ops.cc\r\n163>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n163>Done building project \"logging_ops_gen_python.vcxproj\" -- FAILED.\r\n164>------ Build started: Project: lookup_ops_gen_python, Configuration: Release x64 ------\r\n121>C:\\tensorflow\\tensorflow/core/util/tensor_slice_writer.h(36): fatal error C1083: Cannot open include file: 'tensorflow/core/util/saved_tensor_slice.pb_text.h': No such file or directory (compiling source file C:\\tensorflow\\tensorflow\\core\\kernels\\save_restore_v2_ops.cc)\r\n121>scatter_functor.cc\r\n121>scatter_nd_op.cc\r\n164>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n164>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n121>scatter_nd_op_cpu_impl_0.cc\r\n121>scatter_nd_op_cpu_impl_1.cc\r\n164>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n164>Done building project \"lookup_ops_gen_python.vcxproj\" -- FAILED.\r\n165>------ Build started: Project: math_ops_gen_python, Configuration: Release x64 ------\r\n121>scatter_nd_op_cpu_impl_2.cc\r\n121>scatter_nd_op_cpu_impl_3.cc\r\n121>scatter_nd_op_cpu_impl_4.cc\r\n121>scatter_nd_op_cpu_impl_5.cc\r\n121>scatter_op.cc\r\n166>------ Build started: Project: nn_ops_gen_python, Configuration: Release x64 ------\r\n121>sdca_internal.cc\r\n121>sdca_ops.cc\r\n121>segment_reduction_ops.cc\r\n121>self_adjoint_eig_op.cc\r\n121>self_adjoint_eig_v2_op_complex128.cc\r\n166>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n166>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n121>self_adjoint_eig_v2_op_complex64.cc\r\n166>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n121>self_adjoint_eig_v2_op_double.cc\r\n166>Done building project \"nn_ops_gen_python.vcxproj\" -- FAILED.\r\n167>------ Build started: Project: parsing_ops_gen_python, Configuration: Release x64 ------\r\n167>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n167>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n121>self_adjoint_eig_v2_op_float.cc\r\n121>self_adjoint_eig_v2_op_gpu.cc\r\n121>sendrecv_ops.cc\r\n121>sequence_ops.cc\r\n121>serialize_sparse_op.cc\r\n167>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n167>Done building project \"parsing_ops_gen_python.vcxproj\" -- FAILED.\r\n168>------ Build started: Project: random_ops_gen_python, Configuration: Release x64 ------\r\n121>session_ops.cc\r\n121>set_kernels.cc\r\n121>C:\\tensorflow\\tensorflow/core/common_runtime/device.h(37): fatal error C1083: Cannot open include file: 'tensorflow/core/framework/device_attributes.pb_text.h': No such file or directory (compiling source file C:\\tensorflow\\tensorflow\\core\\kernels\\session_ops.cc)\r\n121>shape_ops.cc\r\n121>shuffle_dataset_op.cc\r\n121>skip_dataset_op.cc\r\n168>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n168>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n121>slice_op.cc\r\n121>slice_op_cpu_impl_1.cc\r\n121>slice_op_cpu_impl_2.cc\r\n121>slice_op_cpu_impl_3.cc\r\n121>slice_op_cpu_impl_4.cc\r\n121>slice_op_cpu_impl_5.cc\r\n168>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n168>Done building project \"random_ops_gen_python.vcxproj\" -- FAILED.\r\n169>------ Build started: Project: remote_fused_graph_ops_gen_python, Configuration: Release x64 ------\r\n169>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n169>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n121>slice_op_cpu_impl_6.cc\r\n121>slice_op_cpu_impl_7.cc\r\n121>sloppy_interleave_dataset_op.cc\r\n121>softmax_op.cc\r\n169>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n169>Done building project \"remote_fused_graph_ops_gen_python.vcxproj\" -- FAILED.\r\n170>------ Build started: Project: resource_variable_ops_gen_python, Configuration: Release x64 ------\r\n121>C:\\tensorflow\\tensorflow/core/common_runtime/device.h(37): fatal error C1083: Cannot open include file: 'tensorflow/core/framework/device_attributes.pb_text.h': No such file or directory (compiling source file C:\\tensorflow\\tensorflow\\core\\kernels\\sloppy_interleave_dataset_op.cc)\r\n121>softplus_op.cc\r\n121>softsign_op.cc\r\n121>spacetobatch_functor.cc\r\n170>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n121>spacetobatch_op.cc\r\n170>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n170>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n170>Done building project \"resource_variable_ops_gen_python.vcxproj\" -- FAILED.\r\n171>------ Build started: Project: script_ops_gen_python, Configuration: Release x64 ------\r\n121>C:\\tensorflow\\tensorflow\\core\\kernels\\spacetobatch_op.cc(196): warning C4002: too many actual parameters for macro 'TF_SPACETOBATCH_BLOCK_DIMS_CASE'\r\n121>spacetodepth_op.cc\r\n121>sparse_add_grad_op.cc\r\n121>sparse_add_op.cc\r\n121>sparse_concat_op.cc\r\n171>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n171>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n121>sparse_conditional_accumulator_op.cc\r\n121>sparse_cross_op.cc\r\n171>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n171>Done building project \"script_ops_gen_python.vcxproj\" -- FAILED.\r\n172>------ Build started: Project: sdca_ops_gen_python, Configuration: Release x64 ------\r\n121>sparse_dense_binary_op_shared.cc\r\n172>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n121>sparse_fill_empty_rows_op.cc\r\n172>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n121>sparse_matmul_op.cc\r\n121>C:\\tensorflow\\tensorflow/core/common_runtime/device.h(37): fatal error C1083: Cannot open include file: 'tensorflow/core/framework/device_attributes.pb_text.h': No such file or directory (compiling source file C:\\tensorflow\\tensorflow\\core\\kernels\\sparse_matmul_op.cc)\r\n121>sparse_reduce_op.cc\r\n121>sparse_reorder_op.cc\r\n172>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n121>sparse_reshape_op.cc\r\n172>Done building project \"sdca_ops_gen_python.vcxproj\" -- FAILED.\r\n173>------ Build started: Project: contrib_image_ops_gen_python, Configuration: Release x64 ------\r\n173>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n121>sparse_slice_op.cc\r\n173>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n121>sparse_softmax_op.cc\r\n121>sparse_sparse_binary_op_shared.cc\r\n173>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n173>Done building project \"contrib_image_ops_gen_python.vcxproj\" -- FAILED.\r\n174>------ Build started: Project: set_ops_gen_python, Configuration: Release x64 ------\r\n121>sparse_split_op.cc\r\n121>sparse_tensor_dense_add_op.cc\r\n174>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n174>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n121>sparse_tensor_dense_matmul_op.cc\r\n121>sparse_tensor_slice_dataset_op.cc\r\n174>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n174>Done building project \"set_ops_gen_python.vcxproj\" -- FAILED.\r\n175>------ Build started: Project: sparse_ops_gen_python, Configuration: Release x64 ------\r\n121>sparse_tensors_map_ops.cc\r\n121>sparse_to_dense_op.cc\r\n121>sparse_xent_op.cc\r\n175>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n121>spectrogram.cc\r\n121>spectrogram_op.cc\r\n121>split_lib_cpu.cc\r\n175>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n175>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n175>Done building project \"sparse_ops_gen_python.vcxproj\" -- FAILED.\r\n121>split_op.cc\r\n176>------ Build started: Project: spectral_ops_gen_python, Configuration: Release x64 ------\r\n121>split_v_op.cc\r\n121>driver_manager.cc\r\n176>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n176>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n121>sqlite_query_connection.cc\r\n176>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n176>Done building project \"spectral_ops_gen_python.vcxproj\" -- FAILED.\r\n177>------ Build started: Project: state_ops_gen_python, Configuration: Release x64 ------\r\n121>sql_dataset_ops.cc\r\n121>stack_ops.cc\r\n177>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n121>stage_op.cc\r\n121>stateless_random_ops.cc\r\n177>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n121>C:\\tensorflow\\tensorflow/core/common_runtime/device.h(37): fatal error C1083: Cannot open include file: 'tensorflow/core/framework/device_attributes.pb_text.h': No such file or directory (compiling source file C:\\tensorflow\\tensorflow\\core\\kernels\\stack_ops.cc)\r\n121>strided_slice_op.cc\r\n121>strided_slice_op_define_grad.cc\r\n121>strided_slice_op_inst_0.cc\r\n177>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n121>strided_slice_op_inst_1.cc\r\n177>Done building project \"state_ops_gen_python.vcxproj\" -- FAILED.\r\n178>------ Build started: Project: stateless_random_ops_gen_python, Configuration: Release x64 ------\r\n121>strided_slice_op_inst_2.cc\r\n178>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n178>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n121>strided_slice_op_inst_3.cc\r\n178>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n178>Done building project \"stateless_random_ops_gen_python.vcxproj\" -- FAILED.\r\n179>------ Build started: Project: array_ops_gen_python, Configuration: Release x64 ------\r\n179>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n179>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n179>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n179>Done building project \"array_ops_gen_python.vcxproj\" -- FAILED.\r\n180>------ Build started: Project: string_ops_gen_python, Configuration: Release x64 ------\r\n180>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n180>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n121>strided_slice_op_inst_4.cc\r\n180>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n180>Done building project \"string_ops_gen_python.vcxproj\" -- FAILED.\r\n181>------ Build started: Project: bitwise_ops_gen_python, Configuration: Release x64 ------\r\n181>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n181>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n181>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n181>Done building project \"bitwise_ops_gen_python.vcxproj\" -- FAILED.\r\n182>------ Build started: Project: candidate_sampling_ops_gen_python, Configuration: Release x64 ------\r\n121>strided_slice_op_inst_5.cc\r\n182>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n182>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n182>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n182>Done building project \"candidate_sampling_ops_gen_python.vcxproj\" -- FAILED.\r\n183>------ Build started: Project: checkpoint_ops_gen_python, Configuration: Release x64 ------\r\n121>strided_slice_op_inst_6.cc\r\n121>strided_slice_op_inst_7.cc\r\n121>string_join_op.cc\r\n183>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n183>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n183>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n183>Done building project \"checkpoint_ops_gen_python.vcxproj\" -- FAILED.\r\n121>string_split_op.cc\r\n121>string_to_hash_bucket_op.cc\r\n121>string_to_number_op.cc\r\n121>substr_op.cc\r\n121>summary_audio_op.cc\r\n121>summary_image_op.cc\r\n121>summary_interface.cc\r\n184>------ Build started: Project: contrib_bigquery_reader_ops_gen_python, Configuration: Release x64 ------\r\n121>summary_kernels.cc\r\n121>summary_op.cc\r\n121>summary_tensor_op.cc\r\n121>svd_op_complex128.cc\r\n121>svd_op_complex64.cc\r\n121>svd_op_double.cc\r\n184>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n184>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n121>svd_op_float.cc\r\n184>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n121>take_dataset_op.cc\r\n184>Done building project \"contrib_bigquery_reader_ops_gen_python.vcxproj\" -- FAILED.\r\n185>------ Build started: Project: contrib_boosted_trees_model_ops_gen_python, Configuration: Release x64 ------\r\n121>tensor_array.cc\r\n185>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n121>tensor_array_ops.cc\r\n185>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n121>tensor_dataset_op.cc\r\n185>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n185>Done building project \"contrib_boosted_trees_model_ops_gen_python.vcxproj\" -- FAILED.\r\n186>------ Build started: Project: contrib_boosted_trees_prediction_ops_gen_python, Configuration: Release x64 ------\r\n186>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n186>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n121>tensor_slice_dataset_op.cc\r\n186>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n186>Done building project \"contrib_boosted_trees_prediction_ops_gen_python.vcxproj\" -- FAILED.\r\n187>------ Build started: Project: contrib_boosted_trees_quantiles_ops_gen_python, Configuration: Release x64 ------\r\n187>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n121>text_line_reader_op.cc\r\n187>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n121>tf_record_reader_op.cc\r\n187>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n187>Done building project \"contrib_boosted_trees_quantiles_ops_gen_python.vcxproj\" -- FAILED.\r\n188>------ Build started: Project: contrib_boosted_trees_split_handler_ops_gen_python, Configuration: Release x64 ------\r\n188>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n188>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n121>tile_functor_cpu.cc\r\n121>tile_ops.cc\r\n188>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n188>Done building project \"contrib_boosted_trees_split_handler_ops_gen_python.vcxproj\" -- FAILED.\r\n189>------ Build started: Project: contrib_boosted_trees_stats_accumulator_ops_gen_python, Configuration: Release x64 ------\r\n121>tile_ops_cpu_impl_1.cc\r\n189>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n189>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n189>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n189>Done building project \"contrib_boosted_trees_stats_accumulator_ops_gen_python.vcxproj\" -- FAILED.\r\n190>------ Build started: Project: contrib_boosted_trees_training_ops_gen_python, Configuration: Release x64 ------\r\n190>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n190>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n190>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n121>tile_ops_cpu_impl_2.cc\r\n190>Done building project \"contrib_boosted_trees_training_ops_gen_python.vcxproj\" -- FAILED.\r\n191>------ Build started: Project: contrib_cudnn_rnn_ops_gen_python, Configuration: Release x64 ------\r\n121>c:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\external\\eigen_archive\\eigen\\src/Core/products/GeneralMatrixVector.h(131): fatal error C1060: compiler is out of heap space (compiling source file C:\\tensorflow\\tensorflow\\core\\kernels\\svd_op_complex128.cc)\r\n121>tile_ops_cpu_impl_3.cc\r\n121>tile_ops_cpu_impl_4.cc\r\n121>tile_ops_cpu_impl_5.cc\r\n191>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n191>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n191>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n191>Done building project \"contrib_cudnn_rnn_ops_gen_python.vcxproj\" -- FAILED.\r\n192>------ Build started: Project: contrib_factorization_clustering_ops_gen_python, Configuration: Release x64 ------\r\n121>tile_ops_cpu_impl_6.cc\r\n121>tile_ops_cpu_impl_7.cc\r\n121>topk_op.cc\r\n121>training_op_helpers.cc\r\n192>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n192>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n121>transpose_functor_cpu.cc\r\n121>transpose_op.cc\r\n121>unique_op.cc\r\n192>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n192>Done building project \"contrib_factorization_clustering_ops_gen_python.vcxproj\" -- FAILED.\r\n193>------ Build started: Project: contrib_factorization_factorization_ops_gen_python, Configuration: Release x64 ------\r\n121>unpack_op.cc\r\n121>warn_about_ints.cc\r\n121>where_op.cc\r\n121>whole_file_read_ops.cc\r\n193>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n193>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n121>window_dataset.cc\r\n121>word2vec_kernels.cc\r\n121>xent_op.cc\r\n121>xsmm_conv2d.cc\r\n121>zip_dataset_op.cc\r\n121>batch_features.cc\r\n121>dropout_utils.cc\r\n121>examples_iterable.cc\r\n193>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n193>Done building project \"contrib_factorization_factorization_ops_gen_python.vcxproj\" -- FAILED.\r\n194>------ Build started: Project: contrib_framework_variable_ops_gen_python, Configuration: Release x64 ------\r\n121>parallel_for.cc\r\n121>sparse_column_iterable.cc\r\n121>tensor_utils.cc\r\n121>example_partitioner.cc\r\n121>bias-feature-column-handler.cc\r\n121>categorical-feature-column-handler.cc\r\n121>dense-quantized-feature-column-handler.cc\r\n194>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n194>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n121>sparse-quantized-feature-column-handler.cc\r\n121>multiple_additive_trees.cc\r\n121>decision_tree.cc\r\n121>masked_matmul_ops.cc\r\n194>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n194>Done building project \"contrib_framework_variable_ops_gen_python.vcxproj\" -- FAILED.\r\n195>------ Build started: Project: contrib_image_distort_image_ops_gen_python, Configuration: Release x64 ------\r\n121>wals_solver_ops.cc\r\n121>factorization_ops.cc\r\n196>------ Build started: Project: contrib_image_sirds_ops_gen_python, Configuration: Release x64 ------\r\n121>zero_initializer_op.cc\r\n196>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n196>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n121>adjust_hsv_in_yiq_op.cc\r\n121>bipartite_match_op.cc\r\n196>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n196>Done building project \"contrib_image_sirds_ops_gen_python.vcxproj\" -- FAILED.\r\n121>distort_image_ops.cc\r\n121>sparse_feature_cross_kernel.cc\r\n121>sparse_feature_cross_op.cc\r\n121>resampler_ops.cc\r\n197>------ Build started: Project: contrib_input_pipeline_ops_gen_python, Configuration: Release x64 ------\r\n121>tensor_forest_ops.cc\r\n121>reinterpret_string_to_float_op.cc\r\n197>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n197>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n121>scatter_add_ndim_op.cc\r\n121>tree_utils.cc\r\n121>hard_routing_function_op.cc\r\n121>k_feature_gradient_op.cc\r\n121>k_feature_routing_function_op.cc\r\n197>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n197>Done building project \"contrib_input_pipeline_ops_gen_python.vcxproj\" -- FAILED.\r\n198>------ Build started: Project: contrib_layers_sparse_feature_cross_ops_gen_python, Configuration: Release x64 ------\r\n121>routing_function_op.cc\r\n121>routing_gradient_op.cc\r\n121>stochastic_hard_routing_function_op.cc\r\n121>stochastic_hard_routing_gradient_op.cc\r\n198>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n198>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n121>unpack_path_op.cc\r\n121>utils.cc\r\n198>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n198>Done building project \"contrib_layers_sparse_feature_cross_ops_gen_python.vcxproj\" -- FAILED.\r\n199>------ Build started: Project: contrib_memory_stats_ops_gen_python, Configuration: Release x64 ------\r\n121>skip_gram_kernels.cc\r\n199>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n121>skip_gram_ops.cc\r\n199>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n121>cross_replica_ops.cc\r\n121>infeed_ops.cc\r\n121>outfeed_ops.cc\r\n199>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n121>replication_ops.cc\r\n199>Done building project \"contrib_memory_stats_ops_gen_python.vcxproj\" -- FAILED.\r\n200>------ Build started: Project: contrib_nccl_ops_gen_python, Configuration: Release x64 ------\r\n200>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n200>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n121>tpu_configuration_ops.cc\r\n200>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n200>Done building project \"contrib_nccl_ops_gen_python.vcxproj\" -- FAILED.\r\n201>------ Build started: Project: contrib_nearest_neighbor_ops_gen_python, Configuration: Release x64 ------\r\n201>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n201>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n201>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n201>Done building project \"contrib_nearest_neighbor_ops_gen_python.vcxproj\" -- FAILED.\r\n202>------ Build started: Project: contrib_resampler_ops_gen_python, Configuration: Release x64 ------\r\n202>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n202>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n202>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n202>Done building project \"contrib_resampler_ops_gen_python.vcxproj\" -- FAILED.\r\n203>------ Build started: Project: contrib_rnn_gru_ops_gen_python, Configuration: Release x64 ------\r\n203>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n203>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n203>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n203>Done building project \"contrib_rnn_gru_ops_gen_python.vcxproj\" -- FAILED.\r\n204>------ Build started: Project: contrib_rnn_lstm_ops_gen_python, Configuration: Release x64 ------\r\n204>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n204>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n204>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n204>Done building project \"contrib_rnn_lstm_ops_gen_python.vcxproj\" -- FAILED.\r\n205>------ Build started: Project: contrib_seq2seq_beam_search_ops_gen_python, Configuration: Release x64 ------\r\n205>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n205>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n205>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n205>Done building project \"contrib_seq2seq_beam_search_ops_gen_python.vcxproj\" -- FAILED.\r\n206>------ Build started: Project: training_ops_gen_python, Configuration: Release x64 ------\r\n206>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n206>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n206>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n206>Done building project \"training_ops_gen_python.vcxproj\" -- FAILED.\r\n207>------ Build started: Project: contrib_tensor_forest_hybrid_ops_gen_python, Configuration: Release x64 ------\r\n207>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n207>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n207>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n207>Done building project \"contrib_tensor_forest_hybrid_ops_gen_python.vcxproj\" -- FAILED.\r\n208>------ Build started: Project: user_ops_gen_python, Configuration: Release x64 ------\r\n208>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n208>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n208>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n208>Done building project \"user_ops_gen_python.vcxproj\" -- FAILED.\r\n209>------ Build started: Project: contrib_tensor_forest_model_ops_gen_python, Configuration: Release x64 ------\r\n209>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n209>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n209>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n209>Done building project \"contrib_tensor_forest_model_ops_gen_python.vcxproj\" -- FAILED.\r\n210>------ Build started: Project: contrib_tensor_forest_ops_gen_python, Configuration: Release x64 ------\r\n210>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n210>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n210>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_python_op_gen_main.dir\\Release\\python_eager_op_gen.obj'\r\n210>Done building project \"contrib_tensor_forest_ops_gen_python.vcxproj\" -- FAILED.\r\n211>------ Build started: Project: tf_python_ops, Configuration: Release x64 ------\r\n211>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n211>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n211>Generating tf_python/tensorflow/python/ops/gen_array_ops.py\r\n211>'Release\\array_ops_gen_python.exe' is not recognized as an internal or external command,\r\n211>operable program or batch file.\r\n211>C:\\Program Files (x86)\\MSBuild\\Microsoft.Cpp\\v4.0\\V140\\Microsoft.CppCommon.targets(171,5): error MSB6006: \"cmd.exe\" exited with code 9009.\r\n211>Done building project \"tf_python_ops.vcxproj\" -- FAILED.\r\n212>------ Build started: Project: tf_contrib_reduce_slice_ops_ops, Configuration: Release x64 ------\r\n212>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n212>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n212>reduce_slice_ops.cc\r\n212>tf_contrib_reduce_slice_ops_ops.vcxproj -> C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_contrib_reduce_slice_ops_ops.dir\\Release\\tf_contrib_reduce_slice_ops_ops.lib\r\n213>------ Build started: Project: tf_contrib_tpu_ops, Configuration: Release x64 ------\r\n213>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n213>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n213>cross_replica_ops.cc\r\n213>infeed_ops.cc\r\n213>outfeed_ops.cc\r\n213>replication_ops.cc\r\n213>tpu_configuration_ops.cc\r\n213>tf_contrib_tpu_ops.vcxproj -> C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_contrib_tpu_ops.dir\\Release\\tf_contrib_tpu_ops.lib\r\n121>Done building project \"tf_core_kernels.vcxproj\" -- FAILED.\r\n214>------ Build started: Project: tf_tools_transform_graph_lib, Configuration: Release x64 ------\r\n215>------ Build started: Project: benchmark_model, Configuration: Release x64 ------\r\n214>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n215>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n214>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n215>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n215>benchmark_model.cc\r\n215>benchmark_model_main.cc\r\n214>add_default_attributes.cc\r\n214>backports.cc\r\n214>fake_quantize_training.cc\r\n214>file_utils.cc\r\n214>flatten_atrous.cc\r\n214>fold_batch_norms.cc\r\n214>fold_constants_lib.cc\r\n214>fold_old_batch_norms.cc\r\n214>C:\\tensorflow\\tensorflow/core/common_runtime/device.h(37): fatal error C1083: Cannot open include file: 'tensorflow/core/framework/device_attributes.pb_text.h': No such file or directory (compiling source file C:\\tensorflow\\tensorflow\\tools\\graph_transforms\\backports.cc)\r\n214>freeze_requantization_ranges.cc\r\n214>C:\\tensorflow\\tensorflow/core/common_runtime/device.h(37): fatal error C1083: Cannot open include file: 'tensorflow/core/framework/device_attributes.pb_text.h': No such file or directory (compiling source file C:\\tensorflow\\tensorflow\\tools\\graph_transforms\\fold_constants_lib.cc)\r\n214>fuse_convolutions.cc\r\n214>C:\\tensorflow\\tensorflow/core/common_runtime/device.h(37): fatal error C1083: Cannot open include file: 'tensorflow/core/framework/device_attributes.pb_text.h': No such file or directory (compiling source file C:\\tensorflow\\tensorflow\\tools\\graph_transforms\\fold_old_batch_norms.cc)\r\n214>insert_logging.cc\r\n214>C:\\tensorflow\\tensorflow/core/common_runtime/device.h(37): fatal error C1083: Cannot open include file: 'tensorflow/core/framework/device_attributes.pb_text.h': No such file or directory (compiling source file C:\\tensorflow\\tensorflow\\tools\\graph_transforms\\fold_batch_norms.cc)\r\n214>obfuscate_names.cc\r\n214>remove_attribute.cc\r\n214>remove_device.cc\r\n214>remove_ema.cc\r\n214>C:\\tensorflow\\tensorflow/core/common_runtime/device.h(37): fatal error C1083: Cannot open include file: 'tensorflow/core/framework/device_attributes.pb_text.h': No such file or directory (compiling source file C:\\tensorflow\\tensorflow\\tools\\graph_transforms\\remove_attribute.cc)\r\n214>remove_nodes.cc\r\n214>C:\\tensorflow\\tensorflow/core/common_runtime/device.h(37): fatal error C1083: Cannot open include file: 'tensorflow/core/framework/device_attributes.pb_text.h': No such file or directory (compiling source file C:\\tensorflow\\tensorflow\\tools\\graph_transforms\\fuse_convolutions.cc)\r\n214>rename_attribute.cc\r\n214>C:\\tensorflow\\tensorflow/core/common_runtime/device.h(37): fatal error C1083: Cannot open include file: 'tensorflow/core/framework/device_attributes.pb_text.h': No such file or directory (compiling source file C:\\tensorflow\\tensorflow\\tools\\graph_transforms\\remove_device.cc)\r\n214>rename_op.cc\r\n214>C:\\tensorflow\\tensorflow/core/common_runtime/device.h(37): fatal error C1083: Cannot open include file: 'tensorflow/core/framework/device_attributes.pb_text.h': No such file or directory (compiling source file C:\\tensorflow\\tensorflow\\tools\\graph_transforms\\obfuscate_names.cc)\r\n214>set_device.cc\r\n214>C:\\tensorflow\\tensorflow/core/common_runtime/device.h(37): fatal error C1083: Cannot open include file: 'tensorflow/core/framework/device_attributes.pb_text.h': No such file or directory (compiling source file C:\\tensorflow\\tensorflow\\tools\\graph_transforms\\insert_logging.cc)\r\n214>sort_by_execution_order.cc\r\n214>sparsify_gather.cc\r\n214>C:\\tensorflow\\tensorflow/core/common_runtime/device.h(37): fatal error C1083: Cannot open include file: 'tensorflow/core/framework/device_attributes.pb_text.h': No such file or directory (compiling source file C:\\tensorflow\\tensorflow\\tools\\graph_transforms\\remove_nodes.cc)\r\n214>strip_unused_nodes.cc\r\n214>transform_graph.cc\r\n214>C:\\tensorflow\\tensorflow/c/c_api.h(999): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file C:\\tensorflow\\tensorflow\\tools\\graph_transforms\\sparsify_gather.cc)\r\n214>C:\\tensorflow\\tensorflow/c/c_api.h(955): note: see declaration of 'TF_WhileParams' (compiling source file C:\\tensorflow\\tensorflow\\tools\\graph_transforms\\sparsify_gather.cc)\r\n214>transform_utils.cc\r\n214>C:\\tensorflow\\tensorflow/core/common_runtime/device.h(37): fatal error C1083: Cannot open include file: 'tensorflow/core/framework/device_attributes.pb_text.h': No such file or directory (compiling source file C:\\tensorflow\\tensorflow\\tools\\graph_transforms\\rename_op.cc)\r\n214>C:\\tensorflow\\tensorflow/core/common_runtime/device.h(37): fatal error C1083: Cannot open include file: 'tensorflow/core/framework/device_attributes.pb_text.h': No such file or directory (compiling source file C:\\tensorflow\\tensorflow\\tools\\graph_transforms\\rename_attribute.cc)\r\n214>C:\\tensorflow\\tensorflow/core/common_runtime/device.h(37): fatal error C1083: Cannot open include file: 'tensorflow/core/framework/device_attributes.pb_text.h': No such file or directory (compiling source file C:\\tensorflow\\tensorflow\\tools\\graph_transforms\\sort_by_execution_order.cc)\r\n214>C:\\tensorflow\\tensorflow/core/common_runtime/device.h(37): fatal error C1083: Cannot open include file: 'tensorflow/core/framework/device_attributes.pb_text.h': No such file or directory (compiling source file C:\\tensorflow\\tensorflow\\tools\\graph_transforms\\strip_unused_nodes.cc)\r\n215>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_core_cpu.dir\\Release\\accumulate_n_optimizer.obj'\r\n215>Done building project \"benchmark_model.vcxproj\" -- FAILED.\r\n216>------ Build started: Project: tf_tutorials_example_trainer, Configuration: Release x64 ------\r\n216>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n216>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n216>example_trainer.cc\r\n216>C:\\tensorflow\\tensorflow/cc/ops/standard_ops.h(19): fatal error C1083: Cannot open include file: 'tensorflow/cc/ops/array_ops.h': No such file or directory\r\n216>Done building project \"tf_tutorials_example_trainer.vcxproj\" -- FAILED.\r\n217>------ Build started: Project: tf_label_image_example, Configuration: Release x64 ------\r\n217>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n217>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n217>main.cc\r\n217>C:\\tensorflow\\tensorflow\\examples\\label_image\\main.cc(42): fatal error C1083: Cannot open include file: 'tensorflow/cc/ops/image_ops.h': No such file or directory\r\n214>Done building project \"tf_tools_transform_graph_lib.vcxproj\" -- FAILED.\r\n218>------ Build started: Project: pywrap_tensorflow_internal_static, Configuration: Release x64 ------\r\n217>Done building project \"tf_label_image_example.vcxproj\" -- FAILED.\r\n219>------ Build started: Project: compare_graphs, Configuration: Release x64 ------\r\n219>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n219>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n218>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n219>compare_graphs.cc\r\n218>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n218>Generating __force_rebuild\r\n218>\r\n218>Running SWIG to generate Python wrappers\r\n218>print_model_analysis.cc\r\n218>pywrap_tensor.cc\r\n218>pywrap_tfe_src.cc\r\n218>tf_session_helper.cc\r\n218>python_eager_op_gen.cc\r\n218>cpp_shape_inference.cc\r\n218>python_op_gen.cc\r\n218>numpy.cc\r\n218>C:\\tensorflow\\tensorflow/c/c_api.h(999): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file C:\\tensorflow\\tensorflow\\python\\eager\\pywrap_tfe_src.cc)\r\n218>C:\\tensorflow\\tensorflow/c/c_api.h(955): note: see declaration of 'TF_WhileParams' (compiling source file C:\\tensorflow\\tensorflow\\python\\eager\\pywrap_tfe_src.cc)\r\n218>C:\\tensorflow\\tensorflow/c/c_api.h(999): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file C:\\tensorflow\\tensorflow\\python\\client\\tf_session_helper.cc)\r\n218>C:\\tensorflow\\tensorflow/c/c_api.h(955): note: see declaration of 'TF_WhileParams' (compiling source file C:\\tensorflow\\tensorflow\\python\\client\\tf_session_helper.cc)\r\n218>ndarray_tensor.cc\r\n218>C:\\tensorflow\\tensorflow/c/c_api.h(999): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file C:\\tensorflow\\tensorflow\\python\\eager\\pywrap_tensor.cc)\r\n218>C:\\tensorflow\\tensorflow/c/c_api.h(955): note: see declaration of 'TF_WhileParams' (compiling source file C:\\tensorflow\\tensorflow\\python\\eager\\pywrap_tensor.cc)\r\n218>C:\\tensorflow\\tensorflow/c/c_api.h(999): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file C:\\tensorflow\\tensorflow\\python\\framework\\cpp_shape_inference.cc)\r\n218>C:\\tensorflow\\tensorflow/c/c_api.h(955): note: see declaration of 'TF_WhileParams' (compiling source file C:\\tensorflow\\tensorflow\\python\\framework\\cpp_shape_inference.cc)\r\n218>C:\\tensorflow\\tensorflow/c/c_api.h(999): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file C:\\tensorflow\\tensorflow\\python\\lib\\core\\ndarray_tensor.cc)\r\n218>C:\\tensorflow\\tensorflow/c/c_api.h(955): note: see declaration of 'TF_WhileParams' (compiling source file C:\\tensorflow\\tensorflow\\python\\lib\\core\\ndarray_tensor.cc)\r\n218>C:\\tensorflow\\tensorflow\\python\\framework\\python_op_gen.cc(23): fatal error C1083: Cannot open include file: 'tensorflow/core/framework/op_def.pb_text.h': No such file or directory\r\n218>ndarray_tensor_bridge.cc\r\n218>py_func.cc\r\n218>C:\\tensorflow\\tensorflow\\python\\eager\\python_eager_op_gen.cc(22): fatal error C1083: Cannot open include file: 'tensorflow/core/framework/op_def.pb_text.h': No such file or directory\r\n218>py_seq_tensor.cc\r\n218>C:\\tensorflow\\tensorflow/c/c_api.h(999): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file C:\\tensorflow\\tensorflow\\core\\profiler\\internal\\print_model_analysis.cc)\r\n218>C:\\tensorflow\\tensorflow/c/c_api.h(955): note: see declaration of 'TF_WhileParams' (compiling source file C:\\tensorflow\\tensorflow\\core\\profiler\\internal\\print_model_analysis.cc)\r\n218>C:\\tensorflow\\tensorflow/c/c_api.h(999): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file C:\\tensorflow\\tensorflow\\python\\lib\\core\\ndarray_tensor_bridge.cc)\r\n218>C:\\tensorflow\\tensorflow/c/c_api.h(955): note: see declaration of 'TF_WhileParams' (compiling source file C:\\tensorflow\\tensorflow\\python\\lib\\core\\ndarray_tensor_bridge.cc)\r\n219>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_tools_transform_graph_lib.dir\\Release\\backports.obj'\r\n218>safe_ptr.cc\r\n219>Done building project \"compare_graphs.vcxproj\" -- FAILED.\r\n218>py_record_reader.cc\r\n218>C:\\tensorflow\\tensorflow/c/c_api.h(999): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file C:\\tensorflow\\tensorflow\\python\\lib\\io\\py_record_reader.cc)\r\n218>C:\\tensorflow\\tensorflow/c/c_api.h(955): note: see declaration of 'TF_WhileParams' (compiling source file C:\\tensorflow\\tensorflow\\python\\lib\\io\\py_record_reader.cc)\r\n218>C:\\tensorflow\\tensorflow/c/c_api.h(999): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file C:\\tensorflow\\tensorflow\\python\\lib\\core\\safe_ptr.cc)\r\n218>C:\\tensorflow\\tensorflow/c/c_api.h(955): note: see declaration of 'TF_WhileParams' (compiling source file C:\\tensorflow\\tensorflow\\python\\lib\\core\\safe_ptr.cc)\r\n218>py_record_writer.cc\r\n220>------ Build started: Project: summarize_graph, Configuration: Release x64 ------\r\n218>C:\\tensorflow\\tensorflow/c/c_api.h(999): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file C:\\tensorflow\\tensorflow\\python\\lib\\io\\py_record_writer.cc)\r\n218>C:\\tensorflow\\tensorflow/c/c_api.h(955): note: see declaration of 'TF_WhileParams' (compiling source file C:\\tensorflow\\tensorflow\\python\\lib\\io\\py_record_writer.cc)\r\n218>kernel_registry.cc\r\n218>C:\\tensorflow\\tensorflow/c/c_api.h(999): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file C:\\tensorflow\\tensorflow\\python\\lib\\core\\py_seq_tensor.cc)\r\n218>C:\\tensorflow\\tensorflow/c/c_api.h(955): note: see declaration of 'TF_WhileParams' (compiling source file C:\\tensorflow\\tensorflow\\python\\lib\\core\\py_seq_tensor.cc)\r\n218>ops.cc\r\n218>C:\\tensorflow\\tensorflow/c/c_api.h(999): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file C:\\tensorflow\\tensorflow\\python\\lib\\core\\py_func.cc)\r\n218>C:\\tensorflow\\tensorflow/c/c_api.h(955): note: see declaration of 'TF_WhileParams' (compiling source file C:\\tensorflow\\tensorflow\\python\\lib\\core\\py_func.cc)\r\n218>scope.cc\r\n218>pywrap_tensorflow_internal.cc\r\n218>C:\\tensorflow\\tensorflow/c/c_api.h(999): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\pywrap_tensorflow_internal.cc)\r\n218>C:\\tensorflow\\tensorflow/c/c_api.h(955): note: see declaration of 'TF_WhileParams' (compiling source file C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\pywrap_tensorflow_internal.cc)\r\n218>C:\\tensorflow\\tensorflow/core/common_runtime/device.h(37): fatal error C1083: Cannot open include file: 'tensorflow/core/framework/device_attributes.pb_text.h': No such file or directory (compiling source file C:\\tensorflow\\tensorflow\\cc\\framework\\scope.cc)\r\n218>C:\\tensorflow\\tensorflow/core/common_runtime/device.h(37): fatal error C1083: Cannot open include file: 'tensorflow/core/framework/device_attributes.pb_text.h': No such file or directory (compiling source file C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\pywrap_tensorflow_internal.cc)\r\n221>------ Build started: Project: transform_graph, Configuration: Release x64 ------\r\n221>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n221>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n221>transform_graph_main.cc\r\n218>Done building project \"pywrap_tensorflow_internal_static.vcxproj\" -- FAILED.\r\n222>------ Build started: Project: pywrap_tensorflow_internal, Configuration: Release x64 ------\r\n222>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n222>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n222>Generating __force_rebuild\r\n222>\r\n222>Running SWIG to generate Python wrappers\r\n222>print_model_analysis.cc\r\n222>pywrap_tensor.cc\r\n222>pywrap_tfe_src.cc\r\n222>tf_session_helper.cc\r\n222>python_eager_op_gen.cc\r\n222>cpp_shape_inference.cc\r\n222>python_op_gen.cc\r\n222>numpy.cc\r\n222>C:\\tensorflow\\tensorflow/c/c_api.h(999): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file C:\\tensorflow\\tensorflow\\python\\eager\\pywrap_tfe_src.cc)\r\n222>C:\\tensorflow\\tensorflow/c/c_api.h(955): note: see declaration of 'TF_WhileParams' (compiling source file C:\\tensorflow\\tensorflow\\python\\eager\\pywrap_tfe_src.cc)\r\n222>C:\\tensorflow\\tensorflow/c/c_api.h(999): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file C:\\tensorflow\\tensorflow\\python\\client\\tf_session_helper.cc)\r\n222>C:\\tensorflow\\tensorflow/c/c_api.h(955): note: see declaration of 'TF_WhileParams' (compiling source file C:\\tensorflow\\tensorflow\\python\\client\\tf_session_helper.cc)\r\n222>ndarray_tensor.cc\r\n222>C:\\tensorflow\\tensorflow/c/c_api.h(999): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file C:\\tensorflow\\tensorflow\\python\\eager\\pywrap_tensor.cc)\r\n222>C:\\tensorflow\\tensorflow/c/c_api.h(955): note: see declaration of 'TF_WhileParams' (compiling source file C:\\tensorflow\\tensorflow\\python\\eager\\pywrap_tensor.cc)\r\n222>C:\\tensorflow\\tensorflow/c/c_api.h(999): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file C:\\tensorflow\\tensorflow\\python\\framework\\cpp_shape_inference.cc)\r\n222>C:\\tensorflow\\tensorflow/c/c_api.h(955): note: see declaration of 'TF_WhileParams' (compiling source file C:\\tensorflow\\tensorflow\\python\\framework\\cpp_shape_inference.cc)\r\n222>C:\\tensorflow\\tensorflow/c/c_api.h(999): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file C:\\tensorflow\\tensorflow\\python\\lib\\core\\ndarray_tensor.cc)\r\n222>C:\\tensorflow\\tensorflow/c/c_api.h(955): note: see declaration of 'TF_WhileParams' (compiling source file C:\\tensorflow\\tensorflow\\python\\lib\\core\\ndarray_tensor.cc)\r\n221>LINK : fatal error LNK1181: cannot open input file 'C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\tf_tools_transform_graph_lib.dir\\Release\\backports.obj'\r\n221>Done building project \"transform_graph.vcxproj\" -- FAILED.\r\n222>C:\\tensorflow\\tensorflow\\python\\eager\\python_eager_op_gen.cc(22): fatal error C1083: Cannot open include file: 'tensorflow/core/framework/op_def.pb_text.h': No such file or directory\r\n222>ndarray_tensor_bridge.cc\r\n222>C:\\tensorflow\\tensorflow\\python\\framework\\python_op_gen.cc(23): fatal error C1083: Cannot open include file: 'tensorflow/core/framework/op_def.pb_text.h': No such file or directory\r\n222>py_func.cc\r\n222>py_seq_tensor.cc\r\n222>C:\\tensorflow\\tensorflow/c/c_api.h(999): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file C:\\tensorflow\\tensorflow\\python\\lib\\core\\ndarray_tensor_bridge.cc)\r\n222>C:\\tensorflow\\tensorflow/c/c_api.h(955): note: see declaration of 'TF_WhileParams' (compiling source file C:\\tensorflow\\tensorflow\\python\\lib\\core\\ndarray_tensor_bridge.cc)\r\n222>C:\\tensorflow\\tensorflow/c/c_api.h(999): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file C:\\tensorflow\\tensorflow\\core\\profiler\\internal\\print_model_analysis.cc)\r\n222>C:\\tensorflow\\tensorflow/c/c_api.h(955): note: see declaration of 'TF_WhileParams' (compiling source file C:\\tensorflow\\tensorflow\\core\\profiler\\internal\\print_model_analysis.cc)\r\n222>safe_ptr.cc\r\n222>py_record_reader.cc\r\n222>C:\\tensorflow\\tensorflow/c/c_api.h(999): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file C:\\tensorflow\\tensorflow\\python\\lib\\io\\py_record_reader.cc)\r\n222>C:\\tensorflow\\tensorflow/c/c_api.h(955): note: see declaration of 'TF_WhileParams' (compiling source file C:\\tensorflow\\tensorflow\\python\\lib\\io\\py_record_reader.cc)\r\n222>C:\\tensorflow\\tensorflow/c/c_api.h(999): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file C:\\tensorflow\\tensorflow\\python\\lib\\core\\safe_ptr.cc)\r\n222>C:\\tensorflow\\tensorflow/c/c_api.h(955): note: see declaration of 'TF_WhileParams' (compiling source file C:\\tensorflow\\tensorflow\\python\\lib\\core\\safe_ptr.cc)\r\n222>py_record_writer.cc\r\n222>kernel_registry.cc\r\n222>C:\\tensorflow\\tensorflow/c/c_api.h(999): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file C:\\tensorflow\\tensorflow\\python\\lib\\io\\py_record_writer.cc)\r\n222>C:\\tensorflow\\tensorflow/c/c_api.h(955): note: see declaration of 'TF_WhileParams' (compiling source file C:\\tensorflow\\tensorflow\\python\\lib\\io\\py_record_writer.cc)\r\n222>C:\\tensorflow\\tensorflow/c/c_api.h(999): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file C:\\tensorflow\\tensorflow\\python\\lib\\core\\py_seq_tensor.cc)\r\n222>C:\\tensorflow\\tensorflow/c/c_api.h(955): note: see declaration of 'TF_WhileParams' (compiling source file C:\\tensorflow\\tensorflow\\python\\lib\\core\\py_seq_tensor.cc)\r\n222>ops.cc\r\n222>C:\\tensorflow\\tensorflow/c/c_api.h(999): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file C:\\tensorflow\\tensorflow\\python\\lib\\core\\py_func.cc)\r\n222>C:\\tensorflow\\tensorflow/c/c_api.h(955): note: see declaration of 'TF_WhileParams' (compiling source file C:\\tensorflow\\tensorflow\\python\\lib\\core\\py_func.cc)\r\n222>scope.cc\r\n222>pywrap_tensorflow_internal.cc\r\n222>C:\\tensorflow\\tensorflow/c/c_api.h(999): warning C4190: 'TF_NewWhile' has C-linkage specified, but returns UDT 'TF_WhileParams' which is incompatible with C (compiling source file C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\pywrap_tensorflow_internal.cc)\r\n222>C:\\tensorflow\\tensorflow/c/c_api.h(955): note: see declaration of 'TF_WhileParams' (compiling source file C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\pywrap_tensorflow_internal.cc)\r\n222>C:\\tensorflow\\tensorflow/core/common_runtime/device.h(37): fatal error C1083: Cannot open include file: 'tensorflow/core/framework/device_attributes.pb_text.h': No such file or directory (compiling source file C:\\tensorflow\\tensorflow\\cc\\framework\\scope.cc)\r\n222>C:\\tensorflow\\tensorflow/core/common_runtime/device.h(37): fatal error C1083: Cannot open include file: 'tensorflow/core/framework/device_attributes.pb_text.h': No such file or directory (compiling source file C:\\tensorflow\\tensorflow\\contrib\\cmake\\build\\pywrap_tensorflow_internal.cc)\r\n222>Done building project \"pywrap_tensorflow_internal.vcxproj\" -- FAILED.\r\n223>------ Build started: Project: _nearest_neighbor_ops, Configuration: Release x64 ------\r\n224>------ Build started: Project: _lstm_ops, Configuration: Release x64 ------\r\n224>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n223>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n223>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n224>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n224>cl : Command line warning D9025: overriding '/DTF_COMPILE_LIBRARY' with '/UTF_COMPILE_LIBRARY'\r\n224>blas_gemm.cc\r\n223>cl : Command line warning D9025: overriding '/DTF_COMPILE_LIBRARY' with '/UTF_COMPILE_LIBRARY'\r\n223>cl : Command line warning D9025: overriding '/DTF_COMPILE_LIBRARY' with '/UTF_COMPILE_LIBRARY'\r\n223>cl : Command line warning D9025: overriding '/DTF_COMPILE_LIBRARY' with '/UTF_COMPILE_LIBRARY'\r\n223>hyperplane_lsh_probes.cc\r\n223>nearest_neighbor_ops.cc\r\n224>cl : Command line warning D9025: overriding '/DTF_COMPILE_LIBRARY' with '/UTF_COMPILE_LIBRARY'\r\n224>lstm_ops.cc\r\n223>LINK : fatal error LNK1181: cannot open input file 'Release\\pywrap_tensorflow_internal.lib'\r\n223>Done building project \"_nearest_neighbor_ops.vcxproj\" -- FAILED.\r\n225>------ Build started: Project: _gru_ops, Configuration: Release x64 ------\r\n225>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n225>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n225>cl : Command line warning D9025: overriding '/DTF_COMPILE_LIBRARY' with '/UTF_COMPILE_LIBRARY'\r\n225>blas_gemm.cc\r\n225>cl : Command line warning D9025: overriding '/DTF_COMPILE_LIBRARY' with '/UTF_COMPILE_LIBRARY'\r\n225>gru_ops.cc\r\n224>cl : Command line warning D9025: overriding '/DTF_COMPILE_LIBRARY' with '/UTF_COMPILE_LIBRARY'\r\n224>lstm_ops.cc\r\n225>cl : Command line warning D9025: overriding '/DTF_COMPILE_LIBRARY' with '/UTF_COMPILE_LIBRARY'\r\n225>gru_ops.cc\r\n224>LINK : fatal error LNK1181: cannot open input file 'Release\\pywrap_tensorflow_internal.lib'\r\n224>Done building project \"_lstm_ops.vcxproj\" -- FAILED.\r\n226>------ Build started: Project: _beam_search_ops, Configuration: Release x64 ------\r\n226>Building Custom Rule C:/tensorflow/tensorflow/contrib/cmake/CMakeLists.txt\r\n226>CMake does not need to re-run because C:/tensorflow/tensorflow/contrib/cmake/build/CMakeFiles/generate.stamp is up-to-date.\r\n226>cl : Command line warning D9025: overriding '/DTF_COMPILE_LIBRARY' with '/UTF_COMPILE_LIBRARY'\r\n226>beam_search_ops.cc\r\n225>LINK : fatal error LNK1181: cannot open input file 'Release\\pywrap_tensorflow_internal.lib'\r\n225>Done building project \"_gru_ops.vcxproj\" -- FAILED.\r\n226>cl : Command line warning D9025: overriding '/DTF_COMPILE_LIBRARY' with '/UTF_COMPILE_LIBRARY'\r\n226>beam_search_ops.cc\r\n226>LINK : fatal error LNK1181: cannot open input file 'Release\\pywrap_tensorflow_internal.lib'\r\n226>Done building project \"_beam_search_ops.vcxproj\" -- FAILED.\r\n```\r\n\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nGPU model and memory", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "I have the same issue.\r\nThe projects _periodic_resample_op, _nearest_neighbor.ops, _beam_search_ops, _gru_ops, and _lstm_ops give the error message: \r\nLINK : fatal error LNK1181: cannot open input file '\\pywrap_tensorflow_internal.lib'\r\n\r\nNote that pywrap_tensorflow_internal.lib exists (under tensorflow\\contrib\\cmake\\build\\Release), and a rebuild of that project did not solve the problem.\r\nI've also had some other errors on the first attempts, but those went away with a few recompiles.\r\n\r\nHave I written custom code (as opposed to using a stock example script provided in TensorFlow): No\r\nOS Platform and Distribution (e.g., Linux Ubuntu 16.04): Windows 7 Pro 64 bit\r\nTensorFlow installed from (source or binary): Source\r\nTensorFlow version (use command below): ?? version from GutHub 13th of March, 2018\r\nPython version: 3.5\r\nBazel version (if compiling from source): N/A, using CMake\r\nGCC/Compiler version (if compiling from source): Cmake 3.10.2, swigwin 3.0.12, Visual studio 2015\r\nCUDA/cuDNN version: CUDA 9.0/cudnn-9.0-windows7-x64-v7.1\r\nGPU model and memory: GTX 1080, 8 GB\r\nExact command to reproduce: switch to Release config, and press F7 (compile)", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "I am facing the exact same issue. Here's the cmake log:\r\n\r\ncmake .. -A x64 -DCMAKE_BUILD_TYPE=Release -DSWIG_EXECUTABLE=C:\\Users\\USERNAME\\bin\\swig\\swigwin-3.0.12\\swig.exe -DPYTHON_EXECUTABLE=C:\\Users\\USERNAME\\AppData\\Local\\Programs\\Python\\Python35\\python.exe -DPYTHON_LIBRARIES=C:\\Users\\USERNAME\\AppData\\Local\\Programs\\Python\\Python35\\libs\\python35.lib -Dtensorflow_BUILD_PYTHON_BINDINGS=OFF -Dtensorflow_ENABLE_GRPC_SUPPORT=OFF -Dtensorflow_BUILD_SHARED_LIB=ON\r\n-- Building for: Visual Studio 15 2017\r\n-- The C compiler identification is MSVC 19.13.26131.1\r\n-- The CXX compiler identification is MSVC 19.13.26131.1\r\n-- Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio/2017/Professional/VC/Tools/MSVC/14.13.26128/bin/Hostx86/x64/cl.exe\r\n-- Check for working C compiler: C:/Program Files (x86)/Microsoft Visual Studio/2017/Professional/VC/Tools/MSVC/14.13.26128/bin/Hostx86/x64/cl.exe -- works\r\n-- Detecting C compiler ABI info\r\n-- Detecting C compiler ABI info - done\r\n-- Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual Studio/2017/Professional/VC/Tools/MSVC/14.13.26128/bin/Hostx86/x64/cl.exe\r\n-- Check for working CXX compiler: C:/Program Files (x86)/Microsoft Visual Studio/2017/Professional/VC/Tools/MSVC/14.13.26128/bin/Hostx86/x64/cl.exe -- works\r\n-- Detecting CXX compiler ABI info\r\n-- Detecting CXX compiler ABI info - done\r\n-- Detecting CXX compile features\r\n-- Detecting CXX compile features - done\r\n-- Performing Test COMPILER_OPT_ARCH_NATIVE_SUPPORTED\r\n-- Performing Test COMPILER_OPT_ARCH_NATIVE_SUPPORTED - Failed\r\n-- Performing Test GCC_OPENMP_SUPPORT\r\n-- Performing Test GCC_OPENMP_SUPPORT - Failed\r\n-- Performing Test MSVC_OPENMP_SUPPORT\r\n-- Performing Test MSVC_OPENMP_SUPPORT - Success\r\n-- Found PythonInterp: C:/Users/USERNAME/AppData/Local/Programs/Python/Python35/python.exe (found version \"3.5\")\r\n-- Configuring done\r\n-- Generating done\r\n\r\nI too am getting this error multiple times: Cannot open include file: 'tensorflow/core/framework/device_attributes.pb_text.h'\r\n\r\nI have followed the instructions on building Tensorflow in Windows from several tutorials word to word and I still have had no luck. Just for the record, I have compiled/used caffe/caffe2/Intel's Inference Engine/CoreML before so I am not exactly a beginner but nevetheless I still can't get past this issue.", "It has been 18 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 33 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 17002, "title": "Please add a working example for tf.contrib.factorization.KMeansClustering in tutorial example", "body": "### Describe the problem\r\nHi, \r\n\r\nI have been trying to use tf.contrib.factorization.KMeansClustering for clustering. I got the documentation in [link](https://www.tensorflow.org/api_docs/python/tf/contrib/factorization/KMeansClustering). But it did not specify how to give input. There is no input argument here : \r\n\r\n__init__(\r\n    num_clusters,\r\n    model_dir=None,\r\n    initial_clusters=RANDOM_INIT,\r\n    distance_metric=SQUARED_EUCLIDEAN_DISTANCE,\r\n    random_seed=0,\r\n    use_mini_batch=True,\r\n    mini_batch_steps_per_iteration=1,\r\n    kmeans_plus_plus_num_retries=2,\r\n    relative_tolerance=None,\r\n    config=None\r\n)\r\n\r\nSo I request you to please add a working example to train and predict using kmeansClustring in tutorial example.\r\n\r\nThank You\r\n", "comments": ["I\u2019d like to see a working example as well.", "@sandeepkumar8713 do the score() or evaluate() methods not do what you want in some way?", "@cy89 no they don't do that. First I have to train. For that i to have describe the feature. In init() there is no parameter to do so.\r\n\r\nHere is the code that I intend to run:\r\n\r\n### Source code \r\nk = 5\r\nN = 100\r\nvariables = 2\r\npoints = np.random.uniform(0,1,[N,variables])\r\nX = tf.convert_to_tensor(points,dtype=tf.float32)\r\nprint X\r\nkmeans=tf.contrib.factorization.KMeansClustering(num_clusters=k,model_dir=None)\r\nkmeans.train(input_fn=(lambda: [X,None]))\r\n\r\n### Log\r\nI am getting this error on train statement:\r\nValueError: Tensor(\"strided_slice:0\", shape=(), dtype=int32) must be from the same graph as Tensor(\"sub:0\", shape=(), dtype=int32).\r\n", "@sandeepkumar8713 The error is because your input Tensor (X) was created outside the graph that the Estimator code creates during the kmeans.train() invocation. The solution is to delay the creation of that Tensor by putting it inside the input_fn lambda, which will be invoked within train().\r\n\r\nBelow is a complete example. Let me know if you encounter difficulties.\r\n\r\n```\r\nk = 5\r\nn = 100\r\nvariables = 2\r\npoints = np.random.uniform(0, 1000, [n, variables])\r\ninput_fn=lambda: tf.train.limit_epochs(tf.convert_to_tensor(points, dtype=tf.float32), num_epochs=1)\r\nkmeans=tf.contrib.factorization.KMeansClustering(num_clusters=k, use_mini_batch=False)\r\nprevious_centers = None\r\nfor _ in xrange(10):\r\n  kmeans.train(input_fn)\r\n  centers = kmeans.cluster_centers()\r\n  if previous_centers is not None:\r\n    print 'delta:', centers - previous_centers\r\n  previous_centers = centers\r\n  print 'score:', kmeans.score(input_fn)\r\nprint 'centers:', centers\r\ncluster_indices = list(kmeans.predict_cluster_index(input_fn))\r\nfor i, point in enumerate(points):\r\n  cluster_index = cluster_indices[i]\r\n  print 'point:', point, 'is in cluster', cluster_index, 'centered at', centers[cluster_index]\r\n```", "Also, you can see other examples in [kmeans_test.py](https://github.com/tensorflow/tensorflow/blob/r1.5/tensorflow/contrib/factorization/python/ops/kmeans_test.py).", "@ccolby thanks for jumping in!", "### System information\r\n- **OS Platform and Distribution**: Open SUSE Leap 42.3\r\n- **TensorFlow installed from**: python pip\r\n- **TensorFlow version**: 1.5.0\r\n- **Python version**: 2.7\r\n\r\n### Problem Description\r\n@ccolby @cy89 Thank you very for explaining with code. Now I am facing a different problem while trying to save the above trained model. Can you please help me with that.\r\n\r\n### Source code \r\n```\r\ndef serving_input_receiver_fn():\r\n    feature_spec = {\"x\": tf.FixedLenFeature(dtype=tf.float32, shape=[2])}\r\n    model_placeholder = tf.placeholder(dtype=tf.string,shape=[None],name='input')\r\n    receiver_tensors = {\"model_inputs\": model_placeholder}\r\n    features = tf.parse_example(model_placeholder, feature_spec)\r\n    return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)\r\n\r\ndef trainAndSaveModel():\r\n    k = 5\r\n    n = 1000\r\n    variables = 2\r\n\r\n    points = np.random.uniform(0, 1, [n, variables])\r\n    input_fn = lambda: tf.train.limit_epochs(tf.convert_to_tensor(points, dtype=tf.float32), num_epochs=1)\r\n    kmeans = tf.contrib.factorization.KMeansClustering(num_clusters=k, use_mini_batch=False)\r\n    previous_centers = None\r\n    for _ in xrange(10):\r\n        kmeans.train(input_fn)\r\n        centers = kmeans.cluster_centers()\r\n        if previous_centers is not None:\r\n          print 'delta:', centers - previous_centers\r\n        previous_centers = centers\r\n        print 'score:', kmeans.score(input_fn)\r\n\r\n    modelPath = kmeans.export_savedmodel(export_dir_base=\"/path/\",serving_input_receiver_fn=serving_input_receiver_fn)\r\n    return modelPath\r\n```\r\n### Logs\r\n`ValueError: export_outputs must be a dict and not<type 'NoneType'>`\r\n\r\nI am getting this error while calling **serving_input_receiver_fn()** function. Same function is working for **tf.estimator.DNNClassifier** but not for **tf.contrib.factorization.KMeansClustering**.\r\n", "@sandeepkumar8713 the stack trace ought to tell us a lot about what wasn't supplied and where. Can you add it, please? ", "@sandeepkumar8713 Can you try r1.6 of kmeans.py? The current release (r1.5) did not set export_outputs in the EstimatorSpec. That was a bug.", "@ccolby @cy89 Thank you for the suggestion. I upgraded my tensorflow to r1.6 version and the above code is working now.\r\n\r\nCan you please suggest a way to import `cluster_centers()` of `tf.contrib.factorization.KMeansClustering` from the above saved model.\r\n \r\n### Source Code\r\n\r\n```\r\ndef restore(export_dir):\r\n    sess = tf.Session()\r\n    tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], export_dir)\r\n    from tensorflow.contrib import predictor\r\n\r\n    predict_fn = predictor.from_saved_model(export_dir)\r\n    dataList = np.random.uniform(0, 1, [10, 2])\r\n\r\n    inputList=[]\r\n    for test_data in dataList:\r\n        predictor_input_feature = {\r\n            'x': tf.train.Feature(\r\n                float_list=tf.train.FloatList(\r\n                    value=test_data\r\n                )\r\n            )\r\n        }\r\n\r\n        input_for_predictor = tf.train.Example(\r\n            features=tf.train.Features(\r\n                feature=predictor_input_feature\r\n            )\r\n        )\r\n\r\n        serialized_input = input_for_predictor.SerializeToString()\r\n        inputList.append(serialized_input)\r\n\r\n    results = predict_fn({\"model_inputs\": inputList})\r\n    clusterIndices = results['output']\r\n\r\n    for i, point in enumerate(dataList):\r\n       clusterIndex = clusterIndices[i]\r\n       print 'point:', point, 'is in cluster', clusterIndex\r\n       #print 'point:', point, 'is in cluster', clusterIndex, 'centered at', centers[clusterIndex]\r\n\r\n```\r\nI would like to execute the last commented line.", "@sandeepkumar8713 I haven't worked with SavedModels, so I'd need to dig into the details. However, note that:\r\n```\r\nkmeans.cluster_centers()\r\n```\r\nis equivalent to\r\n```\r\ntf.train.load_variable(kmeans.model_dir, 'clusters')\r\n```\r\nWill that work for you? I am not sure if there is a way to get this variable out of the SavedModel.", "@ccolby Even I think that currently there is no specify function to extract `cluster_centers` from the SavedModel. To use `tf.train.load_variable(kmeans.model_dir, 'clusters')` I will have to save checkpoints.", "@sandeepkumar8713 That is correct, but you don't need to do anything special to save the checkpoints. The `KMeansClustering.train` method will save the checkpoint for you. For example, the first code snippet that I posted above will work identically if you replace:\r\n```\r\ncenters = kmeans.cluster_centers()\r\n```\r\nwith\r\n```\r\ncenters = tf.train.load_variable(kmeans.model_dir, 'clusters')\r\n```\r\nPlease note that the variable name `'clusters'` should be considered an internal implementation detail that could change in future releases. Ideally, `tf.contrib.factorization` would include a public interface that hides that detail. But for now, this should work.\r\n\r\nI'll clean up the working example in this thread and add it to the `KMeansClustering` documentation.\r\n\r\nI believe exposing the cluster centers in the SavedModel would require a minor redesign of the `KMeansClustering` Estimator.", "@ccolby Ok, looking forward to see a interface that extract cluster centers from SavedModel.  By the way, thank you for explaining all this. It is a great help. ", "@ccolby when you're happy with the KMeansClustering documentation, please close. \r\n\r\n@sandeepkumar8713 could you please open a separate issue for exposing clustering centers, tag @ccolby and this bug, and note that it's a feature request? ", "@avigyan1009 That warning shouldn't prevent anything from working.", "@ccolby has an update on the internal side that should become visible through the normal merge process. \r\nI'll close this; please reopen if there is more to do. ", "@cy89 Could you point to the revision of the merge process where the update you referred has happened on the r1.6 branch? I don't manage to find it (or maybe it hasn't happened yet?).", "It's not in r1.6, but it has been merged into the master. The content is essentially what is in this thread (a documented example). Essentially no change to the code.", "@ccolby @cy89 While training tf.contrib.factorization.kmeanclustering in r1.5 on 3 node cluster using cpu throwing error 'UTF-8' not encode, i had provided data in input function as df.asmatrix.", "Aha! Okay, awesome! I saw the documented example in the master as you said and was confused looking for something else.\r\nThanks! :)"]}, {"number": 17001, "title": "Minor issue with TF Lite building natively on aarch64", "body": "Linux qds101 4.4.65 #1 SMP PREEMPT Mon Sep 18 13:34:00 CDT 2017 aarch64 aarch64 aarch64 GNU/Linux\r\nVERSION=\"16.04.2 LTS (Xenial Xerus)\"\r\nVERSION_ID=\"16.04\"\r\nVERSION_CODENAME=xenial\r\n\r\n== are we in docker =============================================\r\nNo\r\n\r\n== compiler =====================================================\r\nc++ (Ubuntu/Linaro 5.4.0-6ubuntu1~16.04.4) 5.4.0 20160609\r\n\r\n\r\n== uname -a =====================================================\r\nLinux qds101 4.4.65 #1 SMP PREEMPT Mon Sep 18 13:34:00 CDT 2017 aarch64 aarch64 aarch64 GNU/Linux\r\n\r\n== check pips ===================================================\r\nnumpy (1.13.3)\r\nprotobuf (3.4.0)\r\ntensorflow (1.3.0)\r\ntensorflow-tensorboard (0.1.5)\r\n\r\n== check for virtualenv =========================================\r\nFalse\r\n\r\n== tensorflow import ============================================\r\ntf.VERSION = 1.3.0\r\ntf.GIT_VERSION = v1.3.0-rc1-1607-gbe4e5ef\r\ntf.COMPILER_VERSION = v1.3.0-rc1-1607-gbe4e5ef\r\n\r\n### Describe the problem\r\nWhen I try to compile TF Lite example on my aarch64 machine, i get an error from gcc. \r\nThe problem, i think, is that kernels/internal/BUILD file does not support aarch64 properly:\r\nNEON_FLAGS_IF_APPLICABLE = select({\r\n    \":arm\": [\r\n        \"-O3\",\r\n        \"-mfpu=neon\",\r\n        \"-mfloat-abi=softfp\",\r\n\r\nBut for aarch64 gcc those options do not exist (https://gcc.gnu.org/onlinedocs/gcc/AArch64-Options.html#AArch64-Options). If I remove those two options, compilation is successful.\r\n\r\n### Source code / logs\r\nuser@qds101:~/ml/tf_lite/tensorflow$ bazel build --verbose_failures --config opt  --cxxopt=-std=c++11 --config monolithic  //tensorflow/contrib/lite/examples/label_image:label_image \r\nWARNING: /home/user/.cache/bazel/_bazel_user/5b7d3a270696b210c6b4e035929a0ce1/external/protobuf_archive/WORKSPACE:1: Workspace name in /home/user/.cache/bazel/_bazel_user/5b7d3a270696b210c6b4e035929a0ce1/external/protobuf_archive/WORKSPACE (@com_google_protobuf) does not match the name given in the repository's definition (@protobuf_archive); this will cause a build error in future versions\r\nINFO: Analysed target //tensorflow/contrib/lite/examples/label_image:label_image (1 packages loaded).\r\nINFO: Found 1 target...\r\nERROR: /home/user/ml/tf_lite/tensorflow/tensorflow/contrib/lite/kernels/internal/BUILD:308:1: C++ compilation of rule '//tensorflow/contrib/lite/kernels/internal:tensor_utils' failed (Exit 1): gcc failed: error executing command \r\n  (cd /home/user/.cache/bazel/_bazel_user/5b7d3a270696b210c6b4e035929a0ce1/execroot/org_tensorflow && \\\r\n  exec env - \\\r\n    PATH=/home/user/bin:/home/user/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games \\\r\n    PWD=/proc/self/cwd \\\r\n    PYTHON_BIN_PATH=/usr/bin/python \\\r\n    PYTHON_LIB_PATH=/usr/local/lib/python2.7/dist-packages \\\r\n    TF_NEED_CUDA=0 \\\r\n    TF_NEED_OPENCL_SYCL=0 \\\r\n  /usr/bin/gcc -U_FORTIFY_SOURCE -fstack-protector -Wall -B/usr/bin -B/usr/bin -Wunused-but-set-parameter -Wno-free-nonheap-object -fno-omit-frame-pointer -g0 -O2 '-D_FORTIFY_SOURCE=1' -DNDEBUG -ffunction-sections -fdata-sections -DGEMMLOWP_ALLOW_SLOW_SCALAR_FALLBACK '-march=native' '-std=c++0x' '-std=c++11' -MD -MF bazel-out/arm-opt/bin/tensorflow/contrib/lite/kernels/internal/_objs/tensor_utils/tensorflow/contrib/lite/kernels/internal/tensor_utils.d '-frandom-seed=bazel-out/arm-opt/bin/tensorflow/contrib/lite/kernels/internal/_objs/tensor_utils/tensorflow/contrib/lite/kernels/internal/tensor_utils.o' -iquote . -iquote bazel-out/arm-opt/genfiles -iquote external/bazel_tools -iquote bazel-out/arm-opt/genfiles/external/bazel_tools -iquote external/arm_neon_2_x86_sse -iquote bazel-out/arm-opt/genfiles/external/arm_neon_2_x86_sse -iquote external/gemmlowp -iquote bazel-out/arm-opt/genfiles/external/gemmlowp -isystem external/bazel_tools/tools/cpp/gcc3 -O3 '-mfpu=neon' '-mfloat-abi=softfp' -fno-canonical-system-headers -Wno-builtin-macro-redefined '-D__DATE__=\"redacted\"' '-D__TIMESTAMP__=\"redacted\"' '-D__TIME__=\"redacted\"' -c tensorflow/contrib/lite/kernels/internal/tensor_utils.cc -o bazel-out/arm-opt/bin/tensorflow/contrib/lite/kernels/internal/_objs/tensor_utils/tensorflow/contrib/lite/kernels/internal/tensor_utils.o)\r\ngcc: error: unrecognized command line option '-mfpu=neon'\r\ngcc: error: unrecognized command line option '-mfloat-abi=softfp'\r\nTarget //tensorflow/contrib/lite/examples/label_image:label_image failed to build\r\nINFO: Elapsed time: 1.052s, Critical Path: 0.03s\r\nFAILED: Build did NOT complete successfully\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Hi!\r\nHave I written custom code: No\r\nOS Platform and Distribution - Ubuntu 16.04.2 LTS\r\nTensorFlow installed from: https://github.com/tensorflow/tensorflow.git\r\nTensorFlow version: last commit 1e4b5b8c0cc1675b9ecac3569c91563a2a4f9984\r\nBazel version: Build label: 0.8.1- (@non-git)\r\nCUDA/cuDNN version N/A\r\nGPU model and memory N/A\r\nExact command to reproduce: bazel build --verbose_failures --config opt --cxxopt=-std=c++11 --config monolithic //tensorflow/contrib/lite/examples/label_image:label_image\r\n", "I sent a PR on this, see https://github.com/tensorflow/tensorflow/pull/16175", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?"]}, {"number": 17000, "title": "MKL: Fixing MklCPUAllocator error introduced by commit #1baac78", "body": "PR #16987 also fixes this problem. Commit 1baac78 also broke http://ci.tensorflow.org/view/Nightly/job/nightly-mkl/127", "comments": ["@tensorflow-jenkins test this please."]}, {"number": 16999, "title": "Feature Request: Add Edit Distance metric_fn to tf.metrics or Make a way to Pass Custom metric_fn outside tf.metrics", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nYes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows 8.1\r\n- **TensorFlow installed from (source or binary)**:\r\nBinary\r\n- **TensorFlow version (use command below)**:\r\n1.4 CPU\r\n- **Python version**: \r\n3.6\r\n- **CUDA/cuDNN version**:\r\nN/A\r\n- **GPU model and memory**:\r\nN/A\r\n\r\n\r\n### Describe the problem\r\nI would like another metric (edit_distance) to be added into tf.metrics for `label_error_rate` calculation. I'm having trouble passing metric dicts for `eval_metric_ops` to be used by `ModelFnOps` that are not part of  tf.metrics. \r\n\r\nIf that isn't possible, would it be possible for us we can pass our own `metric_fn`s that are outside tf.metrics? \r\n\r\n### Source code / logs\r\nThis is the metric dict I would like to pass as the `eval_metric_ops` for `ModelFnOps`:\r\n\r\n`metric = {\"label_error_rate\": tf.reduce_mean(tf.edit_distance(tf.cast(y_pred, tf.int32), y_true), name=\"label_error_rate\")}`\r\n\r\nWhere `y_pred` and `y_true` are sparse.\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nBazel version\nExact command to reproduce", "Both are irrelevant to the case since it is a feature request.", "We will consider it if we heard more demands for this request.\r\n", "Alright", "I needed this today too.", "One workaround I made is wrapped the `edit_distance` metric with `tf.metrics.mean` like so \r\n`edit_distance = tf.metrics.mean(tf.reduce_mean(tf.edit_distance(tf.cast(y_pred, tf.int32), y_true), name=name))` \r\n\r\nand passed that as the dict value for `eval_metric_ops` `{\"edit_distance\": edit_distance}`. It works but I'm not sure if this is the proper way of doing it.", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!"]}, {"number": 16998, "title": "fix a crash on Android Lollipop and lower versions", "body": "The allocated memory address is not aligned by 16, which causes\r\nBUS_ADRALN crash on Android platform of low versions.", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address on your commit.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot. The email used to register you as an authorized contributor must be the email used for the Git commit.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_sender_cla -->", "I signed it!", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "@petewarden Could you please review this commit?", "Nagging Reviewer @petewarden: It has been 14 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "Nagging Reviewer @petewarden: It has been 29 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "Nagging Reviewer @petewarden: It has been 44 days with no activity and the `awaiting review` label was assigned. Can you please take a look?", "@zhenyuni sorry for the delay.\r\nCould you rebase and resolve all conflicts? Looks like we can merge as soon as all the conflicts are resolved.", "@gunan I think the recent patch (commit 88103d000add4ea7f8d1a34ee3c898fc79d9e3c7) on master branch has also solved this problem so that my pull request can be closed. Thanks!"]}, {"number": 16997, "title": "permission request", "body": "Greetings team\r\nCan I volunteer to be a member of the tensorflow / tensorflow team\r\nif yes I am very happy to join and help, I speak Indonesian, maybe I can help a team that does not understand Indonesian or so forth.\r\n\r\nGreetings : raja-rizki\r\n\r\nthank you :)", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "@raja-rizki TensorFlow is an open source project to which anyone may contribute.  Is there something more that you're looking for?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "Automatically closing due to lack of recent activity. Please update the issue when new information becomes available, and we will reopen the issue. Thanks!\r\n", "Actually closing the issue."]}, {"number": 16996, "title": "Relu bn fix", "body": "1. Fix cifar 10 divergence issue due to MKL layout mismatch.\r\n2. Fix BatchNorm unit test failures", "comments": ["We found a Contributor License Agreement for you (the sender of this pull request), but were unable to find agreements for the commit author(s).  If you authored these, maybe you used a different email address in the git commits than was used to sign the CLA ([login here](https://cla.developers.google.com/) to double check)?  If these were authored by someone else, then they will need to sign a CLA as well, and confirm that they're okay with these being contributed to Google.\nIn order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again. If the bot doesn't comment, it means it doesn't think anything has changed.\n\n<!-- need_author_cla -->", "To address CLA, will create a new PR"]}, {"number": 16995, "title": "tf.fake_quant_with_min_max_vars returns wrong answer", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: No\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: Linux Ubuntu 16.04\r\n- **TensorFlow installed from (source or binary)**: pip install tensorflow-gpu\r\n- **TensorFlow version (use command below)**: 1.5.0\r\n- **Python version**: 2.7.12\r\n- **Bazel version (if compiling from source)**: \r\n- **GCC/Compiler version (if compiling from source)**: \r\n- **CUDA/cuDNN version**: CUDA-8.0 CuDNN 6.0\r\n- **GPU model and memory**: GTX 1080 8GB\r\n- **Exact command to reproduce**: \r\n\r\n\r\n### Describe the problem\r\ntf.fake_quant_with_min_max_vars returns wrong answer.\r\n\r\n\r\n### Source code / logs\r\n```python\r\nimport tensorflow as tf\r\n\r\na =tf.Variable([ 0.09504107, 0.0748544, 0.09333218, 0.106306, 0.09921047, 0.0930253, 0.09277194, 0.08704954, 0.12734564, 0.11479893], dtype=tf.float32)\r\n\r\n\r\nsess = tf.InteractiveSession()\r\nsess.run(tf.initialize_variables([a]))\r\n\r\nprint a.eval()\r\nprint tf.fake_quant_with_min_max_vars(inputs=a, min=tf.reduce_min(a), max=tf.reduce_max(a), num_bits=8).eval()\r\nprint tf.reduce_min(a).eval()\r\nprint tf.reduce_max(a).eval()\r\n```\r\n\r\nit prints like below\r\n```\r\n[ 0.09504107  0.0748544   0.09333218  0.106306    0.09921047  0.0930253\r\n  0.09277194  0.08704954  0.12734564  0.11479893]\r\n[ 0.05249124  0.05249124  0.05249124  0.05249124  0.05249124  0.05249124\r\n  0.05249124  0.05249124  0.05249124  0.05249124]\r\n0.0748544\r\n0.127346\r\n```", "comments": ["PTAL @suharshs. Thanks!", "Came across a similar error. The main reason is that fake_quant_with_min_max_vars Op is trying to \"nudge\" the quantized min, max values such that zero maps to an integer: [here](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/fake_quant_ops_functor.h#L139). Since both min,max values are positive and are _relatively_ far from zero, it happened that the (nudged min,max) values are (~0, 0.05249124), which are out of range of the values in variable \"a\". Hence all values are saturated to the upper bound of 0.05249124. \r\nSimple solution to your case is to not nudge, but the higher-level question is: will we encounter models  where min>0 and (max-min)<min?", "@navsuda  Yes this is indeed due to the nudging that happens. Nudging is very important because the float zero has to be represented exactly as a fixed point value when converted for hardware.\r\n\r\nThat being said, the particular implementation of nudging in FakeQuant may not be ideal because of saturation cases similar to what you describe. In practice it seems that as long as the nudging technique that the model is trained with is the same as what happens during inference on hardware, things seem to work out, but we are exploring different ways of nudging to avoid these cases.\r\n\r\nI will close this since this isn't really a true 'error' and is how to op is expected to work. We may be introduce new techniques in the future though.\r\n\r\nThanks!"]}, {"number": 16994, "title": "Cherrypicks for Android CUDA support in 1.6", "body": "", "comments": []}]