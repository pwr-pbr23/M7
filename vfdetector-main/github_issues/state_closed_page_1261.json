[{"number": 15312, "title": "iOS build_all_ios_ssd.sh 'double-conversion/double-conversion.h' file not found", "body": "iOS `build_all_ios_ssd.sh` `'double-conversion/double-conversion.h' file not found`\r\n\r\n```\r\n\r\nexport TF_ROOT=$(~/tensorflow-master)\r\n\r\n\r\ncd ~/tensorflow_ios_detector/config\r\nbash config.sh\r\n\r\nexport TF_ROOT=~/tensorflow-master\r\ncd $TF_ROOT\r\ntensorflow/contrib/makefile/build_all_ios_ssd.sh\r\n\r\ngcc --std=c++11 -I. -I/Users/admin/tensorflow-master/tensorflow/contrib/makefile/downloads/ -I/Users/admin/tensorflow-master/tensorflow/contrib/makefile/downloads/eigen -I/Users/admin/tensorflow-master/tensorflow/contrib/makefile/downloads/gemmlowp -I/Users/admin/tensorflow-master/tensorflow/contrib/makefile/downloads/nsync/public -I/Users/admin/tensorflow-master/tensorflow/contrib/makefile/downloads/fft2d -I/Users/admin/tensorflow-master/tensorflow/contrib/makefile/gen/host_obj/ -I/Users/admin/tensorflow-master/tensorflow/contrib/makefile/gen/protobuf-host/include -I/usr/local/include -c tensorflow/core/lib/random/simple_philox.cc -o /Users/admin/tensorflow-master/tensorflow/contrib/makefile/gen/host_obj/tensorflow/core/lib/random/simple_philox.o\r\ntensorflow/core/lib/strings/numbers.cc:26:10: fatal error: \r\n      'double-conversion/double-conversion.h' file not found\r\n#include \"double-conversion/double-conversion.h\"\r\n         ^\r\n1 error generated.\r\nmake: *** [/Users/admin/tensorflow-master/tensorflow/contrib/makefile/gen/host_obj/tensorflow/core/lib/strings/numbers.o] Error 1\r\nmake: *** Waiting for unfinished jobs....\r\n+ '[' 2 -ne 0 ']'\r\n+ echo 'arm64 compilation failed.'\r\narm64 compilation failed.\r\n+ exit 1\r\nMac-Admin:tensorflow-master admin$ \r\n\r\n```\r\nbut script downloaded `double-conversion` in `downloads` folder located at `tensorflow/contrib/makefile`\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "_OS Platform and Distribution_ - Mac OSX 10.11.6\r\n_TensorFlow installed from _- native pip https://www.tensorflow.org/install/install_mac\r\n_TensorFlow version_ - 1.4.0\r\n_Bazel version_ - not used, not installed\r\n_CUDA/cuDNN version_ - not used, not installed\r\n_GPU model and memory_ - not used, 4gb\r\n_Exact command to reproduce_ - `tensorflow/contrib/makefile/build_all_ios_ssd.sh`", "forgot `tensorflow/contrib/makefile/download_dependencies.sh`\r\nsolved"]}, {"number": 15311, "title": "Support python3.6 Linux", "body": "Python3.6 support Linux", "comments": ["https://www.tensorflow.org/install/install_linux#python_36 ?", "Dupe of #6533 (which was closed after Python 3.6 support was added) "]}, {"number": 15310, "title": "[XLA/tfcompile] Various fixes for MSVC Part 1", "body": "This is the initial work to solve #15213. More changes will come in other PRs.\r\n\r\n- `tensorflow/compiler/aot/tests/make_test_graphs.py`: Use `os.path` for path manipulation.\r\n\r\n- `tensorflow/compiler/xla/array.h`: Explicitly include `<numeric>` for `std::accumulate`.\r\n\r\n- `tensorflow/compiler/xla/service/cpu/external_constant_pool.{cc,h}`: Use `tensorflow::port::Aligned{Malloc,Free}`.\r\n\r\n- `tensorflow/compiler/xla/service/cpu/llvm_ir_runtime.cc`: Fix `std::array` initialization.\r\n\r\n- `tensorflow/compiler/xla/service/cpu/simple_orc_jit.cc`: Remove unused `<dlfcn.h>` and polyfill `sincos[f]` for MSVC.\r\n\r\n- `tensorflow/compiler/xla/service/heap_simulator.h`: Add `const` to custom comparator.\r\n\r\n- `tensorflow/compiler/xla/status_macros.h`: Use simplified version of `TF_ASSIGN_OR_RETURN` for MSVC. The simplified version also works for GCC as well actually.\r\n\r\n- `tensorflow/compiler/xla/util.h`: Hide the workaround for GCC 7 from MSVC's eyes.\r\n\r\n- `tensorflow/core/lib/gtl/compactptrset.h`: Define `ssize_t` for MSVC.\r\n\r\n- `tensorflow/core/platform/macros.h`: Define `LANG_CXX11` for >= VS 2015. In MSVC, `__cplusplus == 199711` even when `/std:c++latest` is set because MSVC is still not \"fully\" C++11 compliant.", "comments": ["Can one of the admins verify this patch?", "Sorry for a PR with so many commits. Each commit is too small to have its own PR and getting review for multiple small PRs is quite slow. No more changes until I get some reviews.", "Close this as this PR is split into 10 for easier reviewing."]}, {"number": 15309, "title": "Correct channels_first format in 1d_pooling for tf.layers", "body": "The code was equivalent in the case of self.data_format == 'channels_last' or self.data_format == 'channels_first'.\r\nMy modifications fix it when data_format == 'channels_first'.", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "This change is good, I think. But the fact that this survived indicates there's not enough test coverage of this code. Could you add a test which exercises the `channels_first` code path to make sure it works?", "I am not familiar with testing procedures in tensorflow and do not have much time to do it.\r\nWhereas this bug is problematic and should be fixed because it will not generate an exception and will  use the wrong data_format.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "@vroger11 @martinwicke how to proceed. I don't think we should merge this without test coverage.", "Fine. I don't like no tests, but I like it better than having no tests and\u00a0being broken.", "So there's good news and bad news.\n\n:thumbsup: The good news is that everyone that needs to sign a CLA (the pull request submitter and all commit authors) have done so.  Everything is all good there.\n\n:confused: The bad news is that it appears that one or more commits were authored by someone other than the pull request submitter.  We need to confirm that all authors are ok with their commits being contributed to this project.  Please have them confirm that here in the pull request.\n\n*Note to project maintainer: This is a terminal state, meaning the `cla/google` commit status will not change from this State. It's up to you to confirm consent of the commit author(s) and merge this pull request when appropriate.*\n\n<!-- need_author_consent -->", "Argh, this PR is against 1.4. That's bad. Can you make a new PR against master? We don't take PRs against release branches. "]}, {"number": 15308, "title": "improve compute high rank hessians", "body": "fix possible compute high rank hessians", "comments": ["Can one of the admins verify this patch?", "Yes. be sure to confirm.\r\nI solved this issue. https://github.com/tensorflow/tensorflow/issues/12330\r\n", "@wbaek Thanks -- can you add a test that uses higher rank gradients to test that what you are doing is correct?\r\n\r\n@tillahoffmann, let me know if you want to review this in more detail since you are the main author of this code now :)", "@vrv Yes, but i don't know how can i add test code. so can i get some guide or something example code? (i think current hessian test code are best)\r\n\r\nor it's possible gist(in github)?", "https://github.com/tensorflow/tensorflow/blob/f5a27328adafacb8d88bb62df835fc34cd7ed46c/tensorflow/python/ops/gradients_test.py#L596\r\n\r\nYou can take a look at the tests there for inspiration.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md is a guide for contributing in general, which contains information that you might find useful.", "@vrv I added testHessian2D (it's high rank hessians) and passed! thanks.\r\n\r\n```\r\n      Running (local):\r\n        Testing //tensorflow/python:gradients_test, 10 s\r\nPASS: //tensorflow/python:gradients_test\r\nTarget //tensorflow/python:gradients_test up-to-date:\r\n  bazel-bin/tensorflow/python/gradients_test\r\nINFO: Elapsed time: 197.817s, Critical Path: 34.44s\r\n//tensorflow/python:gradients_test                                       PASSED in 29.8s\r\n```", "@tillahoffmann Thanks for the review. The PR has been updated.", "@tillahoffmann Thanks. The PR has been updated.", "Jenkins, test this please.", "Minor style nits, otherwise still looks good", "@vrv @drpngx Thanks. fix to style guide \\w lint", "Jenkins, test this please.", "Jenkins, test this please."]}, {"number": 15307, "title": "Setting proper sonames on Linux", "body": "Setting proper soname prevents from linking with absolute path when using `cmake`.\r\n\r\nThe reference below contains long conversation about the issue with linking, but the general idea is when a library has no `DT_SONAME` field, executable is linked with absolute path and can't be used in a different environment, setting `LD_LIBRARY_PATH` doesn't help.\r\n\r\nhttp://cmake.3232098.n2.nabble.com/How-to-avoid-the-explicit-library-location-when-linking-with-imported-library-targets-td5542269.html", "comments": ["Can one of the admins verify this patch?", "/CC @gunan @av8ramit \r\n\r\nif we're going to start using sonames, maybe we should start having versions.", "CC @martinwicke @allenlavoie ", "This seems like the right thing to do in principle. @allenlavoie @gunan versions would make sense also -- we have a version, so we can use it.", "We can have `.so.1` and it will continue to resolve for all minor versions. If we want to make a requirement we can have a symbol required, like GLIBC does.", "> We can have .so.1 and it will continue to resolve for all minor versions. If we want to make a \r\n> requirement we can have a symbol required, like GLIBC does.\r\n\r\nI can add a test with `objdump -p <some_sofile> | grep SONAME`, is that what you mean?"]}, {"number": 15306, "title": "GO Tests Fail for Tensorflow 1.4.0 but example code works on amd64 and arm64", "body": "### System information\r\n- ~**Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**~:\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:  Linux Ubuntu 16.04 on amd64 and arm64\r\n- **TensorFlow installed from (source or binary)**: amd64: binary (https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-gpu-linux-x86_64-1.4.0.tar.gz); arch64: source (d752244f) `//tensorflow:libtensorflow.so`\r\n- **TensorFlow version (use command below)**: 1.4.0\r\n- **Python version**: python3.5\r\n- **Bazel version (if compiling from source)**:  arm64: 0.7.0\r\n- **GCC/Compiler version (if compiling from source)**: arm64: 5.4.0-6ubuntu1~16.04.5\r\n- **CUDA/cuDNN version**: amd64: cuda-8.0 | libcudnn.so.6\r\n- **GPU model and memory**: amd64: GeForce GTX 1060 6071MiB\r\n- **Exact command to reproduce**: `go test github.com/tensorflow/tensorflow/tensorflow/go`\r\n\r\n### Describe the problem\r\nTest fail but [example code](https://godoc.org/github.com/tensorflow/tensorflow/tensorflow/go#example-package) work on both platforms. \r\n\r\n### Source code / logs\r\namd64:\r\n```\r\n2017-12-12 11:37:29.916413: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2\r\n2017-12-12 11:37:29.918709: F tensorflow/core/framework/tensor.cc:822] Unexpected type: 23\r\nSIGABRT: abort\r\nPC=0x7f9b403b4428 m=4 sigcode=18446744073709551610\r\nsignal arrived during cgo execution\r\n\r\ngoroutine 29 [syscall, locked to thread]:\r\nruntime.cgocall(0x657730, 0xc4200479d0, 0xc4200479f8)\r\n\t/usr/local/go/src/runtime/cgocall.go:132 +0xe4 fp=0xc4200479a0 sp=0xc420047960 pc=0x405574\r\ngithub.com/tensorflow/tensorflow/tensorflow/go._Cfunc_TF_SetAttrTensor(0x7f9b0800c380, 0x7f9b0800e190, 0x7f9b0800c840, 0x7f9b0800dc80)\r\n\tgithub.com/tensorflow/tensorflow/tensorflow/go/_test/_obj_test/_cgo_gotypes.go:919 +0x45 fp=0xc4200479d0 sp=0xc4200479a0 pc=0x52d725\r\ngithub.com/tensorflow/tensorflow/tensorflow/go.setAttr.func18(0x7f9b0800c380, 0x7f9b0800e190, 0x7f9b0800c840, 0x7f9b0800dc80)\r\n\t/home/meldron/go/src/github.com/tensorflow/tensorflow/tensorflow/go/graph.go:306 +0xec fp=0xc420047a08 sp=0xc4200479d0 pc=0x539cdc\r\ngithub.com/tensorflow/tensorflow/tensorflow/go.setAttr(0x7f9b0800c380, 0xc42000e0c0, 0x6f01be, 0x5, 0x6b70c0, 0xc4200ec4c0, 0x0, 0x0)\r\n\t/home/meldron/go/src/github.com/tensorflow/tensorflow/tensorflow/go/graph.go:306 +0x10f1 fp=0xc420047c00 sp=0xc420047a08 pc=0x530481\r\ngithub.com/tensorflow/tensorflow/tensorflow/go.(*Graph).AddOperation(0xc42000e080, 0x6f0024, 0x5, 0xc42050a3b8, 0x6, 0x0, 0x0, 0x0, 0xc420080f00, 0x4b393b, ...)\r\n\t/home/meldron/go/src/github.com/tensorflow/tensorflow/tensorflow/go/graph.go:209 +0x4a0 fp=0xc420047d60 sp=0xc420047c00 pc=0x52f190\r\ngithub.com/tensorflow/tensorflow/tensorflow/go.Const(0xc42000e080, 0xc42050a3b8, 0x6, 0x683760, 0xc4200ec300, 0xc42050a3b8, 0x6, 0x4d499d, 0x7abe18)\r\n\t/home/meldron/go/src/github.com/tensorflow/tensorflow/tensorflow/go/util_test.go:38 +0x221 fp=0xc420047e38 sp=0xc420047d60 pc=0x52a781\r\ngithub.com/tensorflow/tensorflow/tensorflow/go.TestOutputDataTypeAndShape.func1(0xc420102780)\r\n\t/home/meldron/go/src/github.com/tensorflow/tensorflow/tensorflow/go/operation_test.go:137 +0x11e fp=0xc420047fa8 sp=0xc420047e38 pc=0x53708e\r\ntesting.tRunner(0xc420102780, 0xc4200ec480)\r\n\t/usr/local/go/src/testing/testing.go:746 +0xd0 fp=0xc420047fd0 sp=0xc420047fa8 pc=0x4d4a40\r\nruntime.goexit()\r\n\t/usr/local/go/src/runtime/asm_amd64.s:2337 +0x1 fp=0xc420047fd8 sp=0xc420047fd0 pc=0x45fa31\r\ncreated by testing.(*T).Run\r\n\t/usr/local/go/src/testing/testing.go:789 +0x2de\r\n\r\ngoroutine 1 [chan receive]:\r\ntesting.(*T).Run(0xc420102000, 0x6f62b2, 0x1a, 0x703770, 0x47b401)\r\n\t/usr/local/go/src/testing/testing.go:790 +0x2fc\r\ntesting.runTests.func1(0xc420102000)\r\n\t/usr/local/go/src/testing/testing.go:1004 +0x64\r\ntesting.tRunner(0xc420102000, 0xc420057de0)\r\n\t/usr/local/go/src/testing/testing.go:746 +0xd0\r\ntesting.runTests(0xc4200ec220, 0xa423e0, 0x11, 0x11, 0xc420057e78)\r\n\t/usr/local/go/src/testing/testing.go:1002 +0x2d8\r\ntesting.(*M).Run(0xc420057f18, 0xc420057f70)\r\n\t/usr/local/go/src/testing/testing.go:921 +0x111\r\nmain.main()\r\n\tgithub.com/tensorflow/tensorflow/tensorflow/go/_test/_testmain.go:84 +0xdb\r\n\r\ngoroutine 25 [chan receive]:\r\ntesting.(*T).Run(0xc4201023c0, 0xc4200145a0, 0x13, 0xc4200ec480, 0x2)\r\n\t/usr/local/go/src/testing/testing.go:790 +0x2fc\r\ngithub.com/tensorflow/tensorflow/tensorflow/go.TestOutputDataTypeAndShape(0xc4201023c0)\r\n\t/home/meldron/go/src/github.com/tensorflow/tensorflow/tensorflow/go/operation_test.go:136 +0x56e\r\ntesting.tRunner(0xc4201023c0, 0x703770)\r\n\t/usr/local/go/src/testing/testing.go:746 +0xd0\r\ncreated by testing.(*T).Run\r\n\t/usr/local/go/src/testing/testing.go:789 +0x2de\r\n\r\nrax    0x0\r\nrbx    0x7f9b1fbfca30\r\nrcx    0x7f9b403b4428\r\nrdx    0x6\r\nrdi    0x20a0\r\nrsi    0x20a3\r\nrbp    0x7f9b1fbfca20\r\nrsp    0x7f9b1fbfc8e8\r\nr8     0x7f9b0800eb80\r\nr9     0x0\r\nr10    0x8\r\nr11    0x206\r\nr12    0x7f9b1fbfcc50\r\nr13    0x17\r\nr14    0x5\r\nr15    0x7f9b1fbfcc50\r\nrip    0x7f9b403b4428\r\nrflags 0x206\r\ncs     0x33\r\nfs     0x0\r\ngs     0x0\r\nFAIL\tgithub.com/tensorflow/tensorflow/tensorflow/go\t0.059s\r\n```\r\n\r\narm64:\r\n```\r\n2017-12-12 11:40:20.357262: F tensorflow/core/framework/tensor.cc:822] Unexpected type: 23\r\nSIGABRT: abort\r\nPC=0x7f7a686528 m=0 sigcode=18446744073709551610\r\nsignal arrived during cgo execution\r\n\r\ngoroutine 56 [syscall, locked to thread]:\r\nruntime.cgocall(0x5e9a48, 0x442003d9d8, 0x29)\r\n\t/usr/local/go/src/runtime/cgocall.go:132 +0xa0 fp=0x442003d9a0 sp=0x442003d960 pc=0x405280\r\ngithub.com/tensorflow/tensorflow/tensorflow/go._Cfunc_TF_SetAttrTensor(0xa2bac10, 0xa24bfa0, 0x9fcbb50, 0xa289620)\r\n\tgithub.com/tensorflow/tensorflow/tensorflow/go/_test/_obj_test/_cgo_gotypes.go:919 +0x38 fp=0x442003d9d0 sp=0x442003d9a0 pc=0x508468\r\ngithub.com/tensorflow/tensorflow/tensorflow/go.setAttr.func18(0xa2bac10, 0xa24bfa0, 0x9fcbb50, 0xa289620)\r\n\t/home/rock64/go/src/github.com/tensorflow/tensorflow/tensorflow/go/graph.go:306 +0xa4 fp=0x442003da00 sp=0x442003d9d0 pc=0x511e04\r\ngithub.com/tensorflow/tensorflow/tensorflow/go.setAttr(0xa2bac10, 0x442008a0c0, 0x6809f9, 0x5, 0x648200, 0x4420106480, 0x0, 0x0)\r\n\t/home/rock64/go/src/github.com/tensorflow/tensorflow/tensorflow/go/graph.go:306 +0xd7c fp=0x442003dc00 sp=0x442003da00 pc=0x50aa3c\r\ngithub.com/tensorflow/tensorflow/tensorflow/go.(*Graph).AddOperation(0x442008a088, 0x680864, 0x5, 0x4420086728, 0x6, 0x0, 0x0, 0x0, 0x442007ef00, 0x4a1f7c, ...)\r\n\t/home/rock64/go/src/github.com/tensorflow/tensorflow/tensorflow/go/graph.go:209 +0x3b8 fp=0x442003dd60 sp=0x442003dc00 pc=0x509b38\r\ngithub.com/tensorflow/tensorflow/tensorflow/go.Const(0x442008a088, 0x4420086728, 0x6, 0x615100, 0x44201062c0, 0x4420086728, 0x6, 0x445a01, 0x80)\r\n\t/home/rock64/go/src/github.com/tensorflow/tensorflow/tensorflow/go/util_test.go:38 +0x190 fp=0x442003de30 sp=0x442003dd60 pc=0x505a90\r\ngithub.com/tensorflow/tensorflow/tensorflow/go.TestOutputDataTypeAndShape.func1(0x442011e780)\r\n\t/home/rock64/go/src/github.com/tensorflow/tensorflow/tensorflow/go/operation_test.go:137 +0xc4 fp=0x442003dfa0 sp=0x442003de30 pc=0x50fd44\r\ntesting.tRunner(0x442011e780, 0x4420106440)\r\n\t/usr/local/go/src/testing/testing.go:746 +0xb0 fp=0x442003dfc0 sp=0x442003dfa0 pc=0x4bd240\r\nruntime.goexit()\r\n\t/usr/local/go/src/runtime/asm_arm64.s:931 +0x4 fp=0x442003dfc0 sp=0x442003dfc0 pc=0x456a44\r\ncreated by testing.(*T).Run\r\n\t/usr/local/go/src/testing/testing.go:789 +0x244\r\n\r\ngoroutine 1 [chan receive]:\r\ntesting.(*T).Run(0x442011e000, 0x686c26, 0x1a, 0x694188, 0x5a2fb201)\r\n\t/usr/local/go/src/testing/testing.go:790 +0x258\r\ntesting.runTests.func1(0x442011e000)\r\n\t/usr/local/go/src/testing/testing.go:1004 +0x54\r\ntesting.tRunner(0x442011e000, 0x4420051dd0)\r\n\t/usr/local/go/src/testing/testing.go:746 +0xb0\r\ntesting.runTests(0x44201061c0, 0x7d8300, 0x11, 0x11, 0x3e7)\r\n\t/usr/local/go/src/testing/testing.go:1002 +0x280\r\ntesting.(*M).Run(0x4420051f18, 0x42d01c)\r\n\t/usr/local/go/src/testing/testing.go:921 +0xf0\r\nmain.main()\r\n\tgithub.com/tensorflow/tensorflow/tensorflow/go/_test/_testmain.go:84 +0xd0\r\n\r\ngoroutine 52 [chan receive]:\r\ntesting.(*T).Run(0x442011e3c0, 0x44200c02c0, 0x13, 0x4420106440, 0x2)\r\n\t/usr/local/go/src/testing/testing.go:790 +0x258\r\ngithub.com/tensorflow/tensorflow/tensorflow/go.TestOutputDataTypeAndShape(0x442011e3c0)\r\n\t/home/rock64/go/src/github.com/tensorflow/tensorflow/tensorflow/go/operation_test.go:136 +0x540\r\ntesting.tRunner(0x442011e3c0, 0x694188)\r\n\t/usr/local/go/src/testing/testing.go:746 +0xb0\r\ncreated by testing.(*T).Run\r\n\t/usr/local/go/src/testing/testing.go:789 +0x244\r\n\r\nr0      0x0\r\nr1      0x363f\r\nr2      0x6\r\nr3      0x7f7c729000\r\nr4      0x363f\r\nr5      0x7f7c7296f0\r\nr6      0x0\r\nr7      0x0\r\nr8      0x83\r\nr9      0x9fa59e0\r\nr10     0x7fdb6f6760\r\nr11     0x7fdb6f6760\r\nr12     0xa3d70a3d70a3d70b\r\nr13     0x7fdb6f6706\r\nr14     0x0\r\nr15     0x1db\r\nr16     0x7f7a639120\r\nr17     0x7f7a687830\r\nr18     0x14\r\nr19     0x7f7a797000\r\nr20     0x7f7c729000\r\nr21     0x7f7a7979d8\r\nr22     0xa322700\r\nr23     0x5\r\nr24     0xa2bac10\r\nr25     0x0\r\nr26     0x6941e0\r\nr27     0x10\r\nr28     0x80b700\r\nr29     0x7fdb6f66e0\r\nlr      0x7f7a6879e0\r\nsp      0x7fdb6f66e0\r\npc      0x7f7a686528\r\nfault   0x0\r\nFAIL\tgithub.com/tensorflow/tensorflow/tensorflow/go\t0.261s\r\n```", "comments": ["@meldron : Apologies for the error. The root cause of the error is that the Go code at head is not compatible with the release version of the C library (version 1.4.0) that you're using.\r\n\r\nPossible fixes:\r\n\r\n- Use the 1.4 version of the Go code, as suggested in https://github.com/tensorflow/tensorflow/issues/14546#issuecomment-347433966\r\n- Build the C library from source\r\n- Use the \"nightly\" build of the C library from: http://ci.tensorflow.org/view/Nightly/job/nightly-libtensorflow/TYPE=gpu-linux/lastSuccessfulBuild/artifact/lib_package/libtensorflow-gpu-linux-x86_64.tar.gz\r\n\r\nLet us know if any of these work for you.\r\n\r\n(Apologies for the trouble, we updated the Go tests in a way that they depend on new C API behavior before the official release containing those changes was made)", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "(Closing as there are suggested workarounds and the 1.5.0 release should be coming up soon too. Please feel free to reopen if the closing is unsatisfactory)"]}, {"number": 15305, "title": "Feature: Tensorflow-native doc2vec implementation planned?", "body": "### System information\r\nHave I written custom code N/A\r\nOS Platform and Distribution N/A\r\nTensorFlow installed from N/A\r\nTensorFlow version N/A\r\nBazel version N/A\r\nCUDA/cuDNN version N/A\r\nGPU model and memory N/A\r\nExact command to reproduce N/A\r\n\r\n### Describe the problem\r\n\r\n**Situation:**\r\n\r\n- We are seeking for a doc2vec implementation based on Tensorflow.\r\n- The reason for this is to be \"as PaaS as possible\" in model training and serving (using Google Cloud ML or AWS Sagemaker).\r\n\r\n**Complication:**\r\n\r\n- There is no native doc2vec implementation in Tensorflow (word2vec is available)\r\n- [Stackoverflow](https://stackoverflow.com/search?q=tensorflow+doc2vec) does not list too much on this.\r\n\r\n**Questions/Feature request:**\r\n\r\n- Is a \"native\" doc2vec implementation planned in Tensorflow?\r\n- if not, is there a common implementation to it, e.g. sum up all the individual word vectors and potentially add normalizing to each \"doc\"?\r\n\r\n### Source code / logs\r\nnot applicable", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "using seq2seq model to training a doc2vec.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "This is still an issue, seems to just be assigned incorrectly.  ", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 30 days with no activity and the `awaiting response` label was assigned. Is this still an issue?"]}, {"number": 15304, "title": "Removing unused variable \"b\" in EventsWriter from events_writer_test.py", "body": "There was no use of \"b\" I have found so far in codebase. However, \"foo\" was a proper tag.", "comments": ["Can one of the admins verify this patch?", "`b` in this case is not a variable, it is an indicator that the variable should be a bytes (not string) object.\r\n\r\nhttps://docs.python.org/2/reference/lexical_analysis.html#string-literals"]}, {"number": 15303, "title": "Fix initialization of tf.contrib.layers.spatial_softmax temperature", "body": "It's now possible to initialize a trainable `temperature` with values other than 1", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.", "Jenkins, test this please."]}, {"number": 15302, "title": "Fix #15297: bfloat16 is unsigned on Windows", "body": "#15297 \r\n\r\n__BYTE_ORDER__ is not a builtin macro in VC++.  Need to include \"tensorflow/core/platform/cpu_info.h\" before using it. ", "comments": ["Can one of the admins verify this patch?", "This PR depends on #14531.  ", "@guschmue ,  do you still working on gemmlowp port? ", "the pr for gemmlowp windows support was recently merged and a pr to enable quantization ops for windows was merged as well.\r\nhttps://github.com/tensorflow/tensorflow/pull/14955\r\n", "@tensorflow-jenkins Test this please", "dnn_linear_combined_test is also failing in the trunk.  It's not due to this change.  We may think all the tests were passed. ", "Looks like this PR is causing a breakage: http://ci.tensorflow.org/job/tf-master-win-bzl/2088/console\r\n\r\nIs it because we also need #14531 to be merged? @snnn ", "Yes. I updating #14531 "]}, {"number": 15301, "title": "Removing extra \"d\" after close() method in SessionTest.java", "body": "", "comments": ["Can one of the admins verify this patch?", "Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "I signed it!", "@googlebot please check CLA", "CLAs look good, thanks!\n\n<!-- ok -->", "@asimshankar I am struggling with tests for this change.", "@tensorflow-jenkins test this please"]}, {"number": 15300, "title": "Documentation - Fixing 'if' spelling", "body": "Fixing 'if' spelling", "comments": ["Thanks for your pull request.  It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\n:memo: **Please visit <https://cla.developers.google.com/> to sign.**\n\nOnce you've signed, please reply here (e.g. `I signed it!`) and we'll verify.  Thanks.\n\n---\n\n- If you've already signed a CLA, it's possible we don't have your GitHub username or you're using a different email address.  Check [your existing CLA data](https://cla.developers.google.com/clas) and verify that your [email is set on your git commits](https://help.github.com/articles/setting-your-email-in-git/).\n- If your company signed a CLA, they designated a Point of Contact who decides which employees are authorized to participate. You may need to contact the Point of Contact for your company and ask to be added to the group of authorized contributors. If you don't know who your Point of Contact is, direct the project maintainer to go/cla#troubleshoot.\n- In order to pass this check, please resolve this problem and have the pull request author add another comment and the bot will run again.\n\n<!-- need_sender_cla -->", "Can one of the admins verify this patch?", "I signed it!", "CLAs look good, thanks!\n\n<!-- ok -->", "\"Iff\" is a shortcut for \"if and only if\", meaning the original spelling is likely intended.\r\n\r\nhttps://en.wikipedia.org/wiki/If_and_only_if"]}, {"number": 15299, "title": "Model Average Optimizer", "body": "I have implemented model average optimizer and open a new pr since the [original one](https://github.com/tensorflow/tensorflow/pull/11581) is closed. ", "comments": ["Can one of the admins verify this patch?", "@alextp, Could you please review this pr? It is quite similar to EASGD. Thanks a lot for your help in EASGD!", "Thanks @jinxin0924. Could you resolve the conflicts?", "@yifeif Conflicts have been resolved. Thanks!", "Hi @alextp , any more advice?", "Jenkins, test this please.", "Hi @alextp , could you help me figure out why the Linux CPU Test failed? I have looked at the console output, and found:\r\n\"Build step 'Execute shell' marked build as failure\r\nUnable to get pull request builder trigger!!\"\r\nWhat does it mean?\r\nThank you!", "@caisq, could you please help me figure out why the Linux CPU Test failed? It seems the failure is not caused by this pr.", "The test failure in \"Linux CPU test (Python 3)\" you saw is a tool failure.  Triggering tests again.\r\n\r\n@tensorflow-jenkins test this please", "@caisq,  could you please help me figure out why the Linux CPU Test failed?", "Running kokoro one last time to be sure. If this succeeds then we can ignore the py3 failure, since it is an outdated Jenkins test.", "Hi @jinxin0924 ,\r\n\r\nI've been working with distributed tensorflow for a while and I found this contribution interesting. I've tried to make it work with a simple example on cifar-10, following this tutorial: https://www.tensorflow.org/tutorials/images/deep_cnn\r\n\r\nThe code I wrote works perfectly with tf.train.SyncReplicasOptimizer, however I can't make it work with your custom optimizer. I always get a TypeError: _true_getter() got multiple values for argument 'shape'. [Model Average Test](https://github.com/Acuratio/distributed-tensorflow-tests/blob/master/model_average_classifier.py)\r\n\r\nThis error was being triggered by tf.train.get_or_create_global_step() and tf.train.ExponentialMovingAverage(), so I removed them. However I still get the same error at the definition of the ModelAverageOptimizer which I can't remove, so I can't make it work.\r\n\r\nDo you have any ideas as of why is this happening or how could I solve this? Any help would be much appreciated. Thanks!", "Hi @ceballosiker \r\nI am sorry it should be a bug. You can take a look at https://github.com/tensorflow/tensorflow/pull/19661#event-1826361323. I hope it can fix the problem.\r\n", "@jinxin0924 \r\n\r\nThanks for the quick reply. I followed the instructions on that thread and solved the issue by modifying the model_average_optimizer.py with your suggestions, maybe you should update the optimizer to include those changes?\r\n\r\nHowever, now the chief worker is blocking just after starting the session. I'll try to figure out why this is happening and keep you updated.\r\n\r\nThanks again for your help!", "@ceballosiker Yes, I have pulled those changes and it has been merged! "]}, {"number": 15298, "title": "Parameterize tensorflow CUDA and cudnn versions in cmake build.", "body": "Also upgrade the defaults to cuda9 and cudnn 7.", "comments": ["dnn_linear_combined_test issue is known. it is disabled internally."]}, {"number": 15297, "title": "tf.bfloat16 is unsigned on Windows", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**:\r\nNo\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**:\r\nWindows 10\r\n- **TensorFlow installed from (source or binary)**:\r\nbinary\r\n- **TensorFlow version (use command below)**:\r\n1.4.0\r\n- **Python version**: \r\n3.5.4\r\n- **Bazel version (if compiling from source)**:\r\nNone\r\n- **GCC/Compiler version (if compiling from source)**:\r\nNone\r\n- **CUDA/cuDNN version**:\r\nNone\r\n- **GPU model and memory**:\r\nNone\r\n- **Exact command to reproduce**:\r\n```python\r\nimport tensorflow as tf\r\nprint(tf.bfloat16.is_unsigned)\r\n```\r\nExpected Output: False\r\nActual: True\r\n\r\n### Describe the problem\r\n\r\n\r\n### Source code / logs\r\nhttps://ci.tensorflow.org/job/tf-master-win-bzl/2057/console\r\nbfloat16_test/test.log\r\n", "comments": ["Did we recently introduce this breakage, or has this always been in our code?", "Hi @meteorcloudy  \r\nCan you review that PR?\r\n\r\nThanks.\r\n", "#15302 is merged, but the code is not compilable right now. Should we left this issue open or close it?", "It has been 14 days with no activity and this issue has an assignee.Please update the label and/or status accordingly.", "Sorry for the late reply, is #15466 a requirement for #15302?\r\nI don't quite understand the solution, is there any other way to fix it?", "http://ci.tensorflow.org/job/tf-master-win-bzl/2211/console\r\nBoth of the tests are failing, so I'll have to reopen this issue.\r\n", "Hi @meteorcloudy \r\n\r\nYou are right.\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/framework/numeric_types.h#L54\r\n```cpp\r\n#if __BYTE_ORDER__ == __ORDER_BIG_ENDIAN__\r\n    value = p[0];\r\n#else\r\n    value = p[1];\r\n#endif\r\n```\r\n\r\n\\_\\_BYTE_ORDER\\_\\_  and \\_\\_ORDER_BIG_ENDIAN\\_\\_ are not predefined macros in VC++, they are defined in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/platform/windows/cpu_info.h\r\n\r\nWe should include \"cpu_info.h\" before using them. \r\n  ", "A member of the TensorFlow organization has replied after the stat:awaiting tensorflower label was applied.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Nagging Assignee: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Hi @meteorcloudy\r\n\r\nWhat's the status of this issue?  Is it fixed or not?", "Sorry, I was on vacation for the last two weeks. And I don't know what's the proper way to fix it.\r\n@martinwicke Can you point this issue to the correct owner?", "@snnn could you send a fix including cpu_info.h and re-enable the bfloat16 test?", "Nagging Assignees @meteorcloudy, @gunan: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "ping @snnn ", "Hi @martinwicke ,\r\n\r\nI'm glad to take it.  Recently I'm quite busy, I have a lot of family stuffs to deal with. I just had a 3 months leave, for my new born baby. :-) I'll update this thread in the next week. ", "No worries! Congratulations!", "Nagging Assignees @meteorcloudy, @gunan: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "@snnn I fixed this with #18047.\r\n\r\n```python\r\n>>> import tensorflow as tf\r\n>>> print(tf.bfloat16.is_unsigned)\r\nFalse\r\n```", "Great! Thank you!"]}, {"number": 15296, "title": "variable_scopes_count miscalculates when reentering variable_scope again", "body": "### System information\r\n- **Have I written custom code (as opposed to using a stock example script provided in TensorFlow)**: Yes\r\n- **OS Platform and Distribution (e.g., Linux Ubuntu 16.04)**: mac 10.11\r\n- **TensorFlow installed from (source or binary)**: binary\r\n- **TensorFlow version (use command below)**: 1.4\r\n- **Python version**:  3.5\r\n- **Bazel version (if compiling from source)**: N/A\r\n- **GCC/Compiler version (if compiling from source)**: N/A\r\n- **CUDA/cuDNN version**: N/A\r\n- **GPU model and memory**: N/A\r\n- **Exact command to reproduce**: N/A\r\n\r\n### Describe the problem\r\n\r\nThe unexpected results are fund when I  investigates #14703, see code here:\r\n\r\nhttps://github.com/tensorflow/tensorflow/blob/4806cb0646bd21f713722bd97c0d0262c575f7e0/tensorflow/python/ops/variable_scope.py#L1621-L1623\r\n\r\nvariable_scope always restores its old `variable_scopes_count` after exit, unfortunately, it seems that we forget reentering case. I am not sure whether the behavior is a bug.\r\n\r\n### Source code / logs\r\n```python\r\nimport tensorflow as tf\r\nfrom tensorflow.python.ops import variable_scope\r\n\r\ndef print_scope(scope):\r\n    print(\"scope: {}, variable_scopes_count: {}\".format(\r\n        scope.name,\r\n        variable_scope._get_default_variable_store().variable_scopes_count))\r\n\r\nwith tf.variable_scope(\"a\") as scope:\r\n    print_scope(scope)\r\n\r\nwith tf.variable_scope(scope) as scope2:\r\n    print_scope(scope2)\r\n    with tf.variable_scope(scope2) as scope3:\r\n        print_scope(scope3)\r\n\r\nprint(\"===============\")\r\nprint_scope(tf.get_variable_scope())\r\n```\r\n\r\noutput:\r\n```bash\r\n~/Downloads \u276f\u276f\u276f python var_store_test.py\r\nscope: a, variable_scopes_count: {'a': 1}\r\nscope: a, variable_scopes_count: {'a': 2}\r\nscope: a, variable_scopes_count: {'a': 3}\r\n===============\r\nscope: , variable_scopes_count: {'a': 2}\r\n```\r\n", "comments": ["@lukaszkaiser Can you comment on this one? Thanks...", "Indeed, this looks very much like a bug! Probably hit relatively rarely, but a bug at all counts. I guess we should have multiple old count stores at least, right? Would you send a PR with a correction and a unit test?", "Yes, I agree that the case might be rare, in fact the bug is fund by accident. Moreover, I don't think I know the role of `variable_scopes_count` clearly. So l'm glad to leave the issue open :-)", "It has been 14 days with no activity and the `awaiting tensorflower` label was assigned. Please update the label and/or status accordingly.", "@facaiy, is there a reason this was closed, even though I don't see a PR referenced to this issue?", "Hi, @arunasank . I think variable_scope is going to be removed in the future: https://github.com/tensorflow/community/blob/master/rfcs/20180817-variables-20.md"]}, {"number": 15295, "title": "Add name scope to tf.image", "body": "This PR fixes #1560 \r\nI searched through the tf.image API list and found the following APIs need to add name scope\r\n\r\n> crop_to_bounding_box\r\n> pad_to_bounding_box\r\n> flip_left_right\r\n> random_flip_left_right\r\n> flip_up_down\r\n> random_flip_up_down\r\n> per_image_standardization\r\n> central_crop\r\n> resize_images\r\n> resize_image_with_crop_or_pad\r\n> transpose_image\r\n\r\n@martinwicke Thanks for quick reply before and could you please take a look?\r\n\r\n- [x] Add name scope to above functions\r\n- [x] Add test case(s)\r\n\r\nRELNOTES: Add name scopes to tf.image functions.", "comments": ["Can one of the admins verify this patch?", "For the following ops:\r\n> crop_to_bounding_box\r\n> pad_to_bounding_box\r\n> central_crop\r\n> resize_images\r\n> resize_image_with_crop_or_pad\r\n\r\nBecause of their structure, if we want to make them like [tf.name_scope](https://www.tensorflow.org/versions/master/api_docs/python/tf/name_scope) suggests, we need to add  `tf.identity` to rename the last ops (Is there another better way?). I am not sure if it is what we want. ", "Sorry, I don't quite understand why you need to add an identity there -- these ops have some early exit paths, so sometimes, you will not create a new name scope at all and return the original. Is that what you meant? You are suggesting to add an identity in that case? Since in those cases, the function doesn't create graphs, I think it is sensible to not add a name scope either. I like this as is.", "Jenkins, test this please.", "Flaky test starting local grpc server.\r\n\r\nJenkins, test this please.", "Yes, that is what I mean, sorry for my unclear expression. You are right, additional processing is not necessary."]}, {"number": 15294, "title": "Error tensorflow load library with Cuda 8 and 9", "body": "Hello,\r\nI use TF 1.0.1, and in my PC (Ubuntu 17.03), I already installed both Cuda 8.0 and Cuda 9.0.\r\n\r\nWhen I run a demo code (Fast R_CNN), I got this error:\r\n\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:126] Couldn't open CUDA library libcudnn.so.5. LD_LIBRARY_PATH: /usr/local/cuda-8.0/lib64\r\nI tensorflow/stream_executor/cuda/cuda_dnn.cc:3517] Unable to load cuDNN DSO\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\r\nI tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\r\nTraceback (most recent call last):\r\n  File \"./tools/demo.py\", line 11, in <module>\r\n    from networks.factory import get_network\r\n  File \"/home/tung/Documents/Plate/Thinh/Faster-RCNN_TF/tools/../lib/networks/__init__.py\", line 8, in <module>\r\n    from .VGGnet_train import VGGnet_train\r\n  File \"/home/tung/Documents/Plate/Thinh/Faster-RCNN_TF/tools/../lib/networks/VGGnet_train.py\", line 2, in <module>\r\n    from networks.network import Network\r\n  File \"/home/tung/Documents/Plate/Thinh/Faster-RCNN_TF/tools/../lib/networks/network.py\", line 3, in <module>\r\n    import roi_pooling_layer.roi_pooling_op as roi_pool_op\r\n  File \"/home/tung/Documents/Plate/Thinh/Faster-RCNN_TF/tools/../lib/roi_pooling_layer/roi_pooling_op.py\", line 5, in <module>\r\n    _roi_pooling_module = tf.load_op_library(filename)\r\n  File \"/home/tung/Envs/Tensor1/lib/python3.4/site-packages/tensorflow/python/framework/load_library.py\", line 64, in load_op_library\r\n    None, None, error_msg, error_code)\r\ntensorflow.python.framework.errors_impl.NotFoundError: libcudart.so.9.0: cannot open shared object file: No such file or directory\r\n\r\nIt seem there is a conflict between cuda 8.0 and 9.0\r\nIs there any suggest?\r\nThanks", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Why did you install two CUDA versions? You only need one CUDA installation but the problem is you haven't installed or properly installed cuDNN.\r\n\r\nPlease take a look in the installation docs for all details. It guides you step-by-step on how to set TensorFlow on your machine https://www.tensorflow.org/install/install_linux\r\n\r\nAlso please format stack traces inside `code blocks` for better readability. ", "Also a good way to get up and running is to use conda virtual environments\r\nhttps://conda.io/miniconda.html\r\n\r\nThey also offer cudnn as a dependency and all tensorflow versions can be installed with pip within that environment ", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "I have find the reason is ldconf, ldconfig is a dynamic link library management command whose purpose is to allow the dynamic link library to be usedby the system.\r\n\r\nThe default ldconf only search /lib and /usr/lib, as well as the library file under the directory listed in the configuration file /etc/ld. so. conf.\r\n\r\nso all of this is caused by the dynamic library of CUDA in the installed CUDA path such as : /path/cuda-9.0/lib64 or /path/cuda-9.0/lib. (for eample my CUDA is installed in /usr/local/cuda-9.0)\r\n\r\n**1.if you install the CUDA manual, then after install, you should add the path of cuda/lib64 to** \r\n  ```\r\n /etc/ld.so.conf file\r\n sudo echo \"/usr/local/cuda-9.0/lib64/\" >> /etc/ld.so.conf\r\n```\r\nthen\r\n    `sudo ldconfig`\r\n\r\nof course , you can add the path manual, like:\r\n     `vim /etc/ld.so.conf`\r\n\r\nthen add the path '/usr/local/cuda-9.0' at the end of ld.so.conf,  after that use command\r\n    `sudo ldconfig`\r\n\r\n\r\nafter the operation, reopen the ipython or pycharm ,\r\n    `import tensorflow as tf`\r\nwow, you will enjoy it!\r\n\r\n**2.if you install the CUDA by command such as 'dpkg -i cuda-repo-ubuntu1604_9.0.176-1_amd64.deb' or others, it may add the cuda lib path to the /etc/ld.so.conf automatically . but to be on the safe side, check the /etc/ld.so.conf and see if the path add to it .**", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 29 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 44 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 15292, "title": "Converting a .pb file to .meta in TF 1.3", "body": "Using `tf.slim`'s pre-trained models we can [export_inference_graph](https://github.com/tensorflow/models/tree/master/research/slim#exporting-the-inference-graph) to generate a `.pb` file for a given `.ckpt`, say `inception_v3`. Is there a way to generate `.meta` file of inception_v3 using these two files as well? \r\n\r\nMy specific use case is that I need to see the pre-trained weights if inception in each tensor (`tf.variable`) and don't know any other way to retrieve other using .meta and .ckpt to do so and I lack `.meta` here:\r\n\r\n```\r\n#retrieve a pre-trained model\r\nsess = tf.Session()\r\nsaver = tf.train.import_meta_graph('./model.meta')\r\nsaver.restore(sess,'./model.ckpt')\r\n```\r\n\r\n\r\n**Steps to reproduce:**\r\n\r\nI used the instution in export_inference_graph and generated a .pb file, then I exported the .meta file as bellow:\r\n\r\n```\r\nsess=tf.Session()\r\nINCEPTION_PB='./inception_v3_inf_graph.pb'\r\n    \r\nf=gfile.FastGFile(INCEPTION_PB,'rb')\r\ngraph_def = tf.GraphDef()\r\ngraph_def.ParseFromString(f.read())\r\n_= tf.import_graph_def(graph_def,name='')\r\nmeta_graph_def = tf.train.export_meta_graph(filename='./inception.meta')\r\n```\r\nHowever, this results in a `.meta` file without collections, thus can not initialized:\r\n\r\n```\r\n>>> saver = tf.train.import_meta_graph('./inception.meta')\r\nINFO:tensorflow:Saver not created because there are no variables in the graph to restore\r\n```\r\n\r\n```\r\n >>> saver.restore(sess,'../../inception_v3.ckpt')\r\nTraceback (most recent call last):\r\nFile \"<stdin>\", line 1, in <module>\r\nAttributeError: 'NoneType' object has no attribute 'restore'\r\n```\r\n\r\nWhat is the problem here? I guess it would be nice this conversion feature is added to TF.\r\n\r\nInfo: \r\nHave I written custom code: Not much except these above.\r\nOS Platform and Distribution: Ubuntu 14.04.3 - 3.19.0-25-generic\r\nTensorFlow installed from: pip installation \r\nTensorFlow version - v1.3\r\nBazel version: v5.4\r\nCUDA/cuDNN version:  v6.0\r\nGPU model and memory: NVIDIA GeForce GTX 1060 6GB - memoryClockRate (GHz) 1.7845\r\n\r\n\r\n\r\n", "comments": ["Thank you for your post. We noticed you have not filled out the following field in the issue template. Could you update them if they are relevant in your case, or leave them as N/A? Thanks.\nHave I written custom code\nOS Platform and Distribution\nTensorFlow installed from\nTensorFlow version\nBazel version\nCUDA/cuDNN version\nGPU model and memory\nExact command to reproduce", "Updated my question.", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Yes. It is still the same issue. No one has responded as of yet", "The original poster has replied to this issue after the stat:awaiting response label was applied.", "Did you try with the latest version of tensorflow?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "@amirjamez excuse me. Did you solve this problem? Since I tried your code and found the same issue as yours", "@zhengduoru No, I did not.", "Nagging Assignee @bignamehyp: It has been 14 days with no activity and this issue has an assignee. Please update the label and/or status accordingly.", "Can you reproduce this issue with the latest tensorflow?", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "It has been 30 days with no activity and the `awaiting response` label was assigned. Is this still an issue?", "We are closing this issue for now due to lack of activity. Please comment if this is still an issue for you. Thanks!"]}, {"number": 15291, "title": "Dockerfile.devel-gpu: infinite prompt loop", "body": "```sh\r\n$ docker build -f Dockerfile.devel-gpu github.com/tensorflow/tensorflow.git#master:tensorflow/tools/docker\r\n[...]\r\nStep 19/22 : RUN ln -s /usr/local/cuda/lib64/stubs/libcuda.so /usr/local/cuda/lib64/stubs/libcuda.so.1 &&     LD_LIBRARY_PATH=/usr/local/cuda/lib64/stubs:${LD_LIBRARY_PATH}     tensorflow/tools/ci_build/builds/configured GPU     bazel build -c opt --config=cuda --cxxopt=\"-D_GLIBCXX_USE_CXX11_ABI=0\"         tensorflow/tools/pip_package:build_pip_package &&     rm /usr/local/cuda/lib64/stubs/libcuda.so.1 &&     bazel-bin/tensorflow/tools/pip_package/build_pip_package /tmp/pip &&     pip --no-cache-dir install --upgrade /tmp/pip/tensorflow-*.whl &&     rm -rf /tmp/pip &&     rm -rf /root/.cache\r\n ---> Running in 3e8560e2d441\r\n/tensorflow /tensorflow\r\nINFO: Reading 'startup' options from /etc/bazel.bazelrc: --batch\r\nExtracting Bazel installation...\r\nYou have bazel 0.5.4 installed.\r\nFound possible Python library paths:\r\n  /usr/local/lib/python2.7/dist-packages\r\n  /usr/lib/python2.7/dist-packages\r\nPlease input the desired Python library path to use.  Default is [/usr/local/lib/python2.7/dist-packages]\r\nDo you wish to build TensorFlow with jemalloc as malloc support? [Y/n]: jemalloc as malloc support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Google Cloud Platform support? [Y/n]: Google Cloud Platform support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Hadoop File System support? [Y/n]: Hadoop File System support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with Amazon S3 File System support? [Y/n]: Amazon S3 File System support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with XLA JIT support? [y/N]: No XLA JIT support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with GDR support? [y/N]: No GDR support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with VERBS support? [y/N]: No VERBS support will be enabled for TensorFlow.\r\n\r\nDo you wish to build TensorFlow with OpenCL support? [y/N]: No OpenCL support will be enabled for TensorFlow.\r\n\r\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]: \r\n\r\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\n\r\nInvalid path to CUDA 8.0 toolkit. /usr/local/cuda/lib64/libcudart.so.8.0 cannot be found\r\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]: \r\n\r\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\n\r\nInvalid path to CUDA 8.0 toolkit. /usr/local/cuda/lib64/libcudart.so.8.0 cannot be found\r\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]: \r\n\r\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\n\r\nInvalid path to CUDA 8.0 toolkit. /usr/local/cuda/lib64/libcudart.so.8.0 cannot be found\r\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]: \r\n\r\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\n\r\nInvalid path to CUDA 8.0 toolkit. /usr/local/cuda/lib64/libcudart.so.8.0 cannot be found\r\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]: \r\n\r\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\n\r\nInvalid path to CUDA 8.0 toolkit. /usr/local/cuda/lib64/libcudart.so.8.0 cannot be found\r\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]: \r\n\r\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\n\r\nInvalid path to CUDA 8.0 toolkit. /usr/local/cuda/lib64/libcudart.so.8.0 cannot be found\r\nPlease specify the CUDA SDK version you want to use, e.g. 7.0. [Leave empty to default to CUDA 8.0]: \r\n\r\nPlease specify the location where CUDA 8.0 toolkit is installed. Refer to README.md for more details. [Default is /usr/local/cuda]: \r\n\r\n[... ad infinitum ... ]\r\n```\r\n\r\nIs it because the `1.4` branch doesn't support CUDA 9.0?\r\nhttps://github.com/tensorflow/tensorflow/blob/abd5375ba8d373045321d1eebdb4501c36ab0ccd/tensorflow/tools/docker/Dockerfile.devel-gpu#L74-L76\r\n\r\n@gunan", "comments": ["The reason is 1.4 branch defaults to CUDA 8, and if you do not have cuda8 available on the image.\r\n@angersson actually fixed this internally to avoid the infinite loop there.\r\n\r\nYou should be able to get around this by setting TF_CUDA_VERSION to 9.0, and TF_CUDNN_VERSION to 7 in the image.\r\nIn the future, we should have this controlled by ARGS in the image.", "> You should be able to get around this by setting TF_CUDA_VERSION to 9.0, and TF_CUDNN_VERSION to 7 in the image.\r\n\r\nSure, but I'm reporting that your official Dockerfile is broken ;)", "Actually, I think the CUDA prompt is one of the ones I didn't update because of its complexity (and potential breakages due to change).\r\n\r\nI replicated the loop with the same command:\r\n\r\n```shell\r\ndocker build -f Dockerfile.devel-gpu github.com/tensorflow/tensorflow.git#master:tensorflow/tools/docker\r\n```", "Worth noting: the [README in the Docker directory](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/tools/docker) says not to build the containers directly, though that may be out of date.", "@angersson As far as I know, the templating only happens for the `runtime` Dockerfiles (`Dockerfile` and `Dockerfile.gpu`). I don't think `Dockerfile.devel-gpu` is modified in any way.", "Also, I'm probably not smart enough to fathom how `parameterized_docker_build.sh` works :)", "This has been fixed by #15328."]}, {"number": 15289, "title": "Replace loop iteration with `chip`", "body": "In unique_op.cc, the ouput tensor was generated through loop iteration. It seems that this could be improved through Eigen's `chip`.\r\n\r\nThe fix addresses this improvement.\r\n\r\nSigned-off-by: Yong Tang <yong.tang.github@outlook.com>", "comments": []}, {"number": 15288, "title": "Eager: eager mode considerably slower than standard TensorFlow for large matrix multiplications ", "body": "We have been benchmarking eager mode versus standard TensorFlow for large square matrix multiplications, specifically the time to run\r\n\r\nm = tf.matmul(A, B) (in eager mode) \r\n\r\nversus \r\n\r\nm = sess.run(self.c, feed_dict={self.A:A, self.B:B})\r\n\r\nin non-eager mode. \r\n\r\nWe find that while runtimes are comparable for small matrices, eager mode is considerably slower for repeated multiplications of large matrices (eg, of dimension 15,000). The first multiplication is fast, but subsequent multiplications take much longer, even after resetting the computation graph. Is this expected behavior? We are running everything on a GPU. \r\n", "comments": ["Please fill out the template so that we understand more about your environment and TF version.", "@tensorflownoob99 : Eager should certainly not be slower than graph when multiplying large matrices., In fact, with larger matrices any overheads of eager execution should be further diminished. If you could provide all the details in the template (in particular the version number being used and self-contained code that reproduces the problem), that would help in tracking your issue down. Thanks.", "Thanks! Version info: \r\n\r\nPython 3.4.5 (default, Nov  9 2016, 16:24:59)\r\n[GCC 4.8.5 20150623 (Red Hat 4.8.5-11)] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> import tensorflow as tf\r\n>>> tf.__version__\r\n'1.5.0-dev20171127'\r\n\r\na stripped-down version of our code is below, along with our output when we run it. Essentially what we do is compute how long it takes to multiply matrices of various sizes. for each matrix size we run five trials. The odd thing is that for large matrices (10000 x 10000) the first trial is fast, but subsequent multiplications are very slow (see output below code).\r\n\r\n```\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.eager as tfe\r\nimport numpy as np\r\nimport time\r\nimport functools\r\n\r\nimport random\r\nimport json\r\nimport sys\r\n\r\nclass BenchmarkBaseClass():\r\n    # checked\r\n    def __init__(self):\r\n        self.n_trials = 5\r\n        self.eager = eager\r\n    def generate_data(self):\r\n        pass\r\n    def run_computation(self, data):\r\n        pass\r\n    def time_computation(self):\r\n        times = []\r\n        print(\"Benchmarking with eager = %s\" % eager)\r\n        for i in range(self.n_trials):\r\n            np.random.seed(i)\r\n            random.seed(i)\r\n            data = self.generate_data()\r\n            t0 = time.time()\r\n            with tf.device(\"/gpu:0\"):\r\n                self.run_computation(data)\r\n            times.append(time.time() - t0)\r\n            print('Runtime is: %2.3f' % times[-1])\r\n        return times\r\n\r\nclass MatrixMultiplicationBenchmark(BenchmarkBaseClass):\r\n    # checked\r\n    def __init__(self, p):\r\n        self.p = p\r\n        BenchmarkBaseClass.__init__(self)\r\n    def generate_data(self):\r\n        A = np.random.random([self.p, self.p])\r\n        B = np.random.random([self.p, self.p])\r\n        if not eager:\r\n            self.A = tf.placeholder(tf.float32, shape=(self.p, self.p))#tf.constant(A)\r\n            self.B = tf.placeholder(tf.float32, shape=(self.p, self.p))\r\n            self.c = tf.matmul(self.A, self.B)#self.a, self.b)\r\n            init = tf.initialize_all_variables()\r\n            sess.run(init)\r\n        return A, B\r\n    def run_computation(self, matrices):\r\n        A, B = matrices\r\n        if eager:\r\n            m = tf.matmul(A, B)\r\n        else:\r\n            m = sess.run(self.c, feed_dict={self.A:A, self.B:B})\r\n\r\ndef run_all_trials(benchmark_name):\r\n    if benchmark_name == 'matrix_multiplication':\r\n        all_param_sets = [{'p':500}, {'p':1000}, {'p':2000}, {'p':5000}, {'p':10000}]\r\n        class_to_use = MatrixMultiplicationBenchmark\r\n    else:\r\n        raise Exception(\"Invalid benchmark name\")\r\n\r\n    all_times = []\r\n    for param_set in all_param_sets:\r\n        print('Parameters: %s' % param_set)\r\n        benchmark = class_to_use(**param_set)\r\n        times = benchmark.time_computation()\r\n        all_times.append(times)\r\n\r\nbenchmark_name = sys.argv[1]\r\neager = sys.argv[2]\r\ntrial_number = sys.argv[3]\r\n\r\nassert eager in ['True', 'False']\r\nassert benchmark_name in ['matrix_multiplication', 'autoencoder', 'matrix_inversion']\r\nprint(\"Running benchmark: %s\" % benchmark_name)\r\neager = (eager == 'True')\r\n\r\nif eager:\r\n    tfe.enable_eager_execution()\r\nelse:\r\n    sess = tf.Session()\r\n\r\nrun_all_trials(benchmark_name)\r\n```\r\n\r\nOutput: (run with command python3 mwe.py matrix_multiplication True blar)\r\n\r\nRunning benchmark: matrix_multiplication\r\nParameters: {'p': 500}\r\nBenchmarking with eager = True\r\n2017-12-12 20:02:33.330365: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\n2017-12-12 20:02:33.637878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1062] Found device 0 with properties:\r\nname: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531\r\npciBusID: 0000:81:00.0\r\ntotalMemory: 11.90GiB freeMemory: 11.76GiB\r\n2017-12-12 20:02:33.637949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1152] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:81:00.0, compute capability: 6.1)\r\nRuntime is: 8.477\r\nRuntime is: 0.001\r\nRuntime is: 0.001\r\nRuntime is: 0.001\r\nRuntime is: 0.001\r\nParameters: {'p': 1000}\r\nBenchmarking with eager = True\r\nRuntime is: 0.003\r\nRuntime is: 0.003\r\nRuntime is: 0.003\r\nRuntime is: 0.003\r\nRuntime is: 0.003\r\nParameters: {'p': 2000}\r\nBenchmarking with eager = True\r\nRuntime is: 0.009\r\nRuntime is: 0.009\r\nRuntime is: 0.008\r\nRuntime is: 0.008\r\nRuntime is: 0.008\r\nParameters: {'p': 5000}\r\nBenchmarking with eager = True\r\nRuntime is: 0.046\r\nRuntime is: 0.078\r\nRuntime is: 0.079\r\nRuntime is: 0.079\r\nRuntime is: 0.079\r\nParameters: {'p': 10000}\r\nBenchmarking with eager = True\r\nRuntime is: 0.181\r\nRuntime is: 2.829\r\nRuntime is: 2.830\r\nRuntime is: 2.836\r\nRuntime is: 2.863", "Thanks for sharing the code, this helps.\r\n\r\nI noticed one big issue with the code you provided - the inputs are numpy arrays (which are necessarily in host memory) and so in each call to `tf.matmul` (with eager execution enabled) you're including the cost of (synchronously and serially) copying the input tensors from CPU to GPU memory. That cost is likely dominating (and increases with size). I'm not entirely sure about the variance, but the absolute numbers seem really high for all cases.\r\n\r\nHere is a simpler benchmark which I think is doing what you're trying to, along with results on my machine (which appears to have the same Titan X Pascal GPU):\r\n\r\n```python\r\nimport tensorflow as tf\r\nimport tensorflow.contrib.eager as tfe\r\nimport time\r\n\r\ntfe.enable_eager_execution()\r\n\r\ndef run(size):\r\n  with tf.device('/gpu:0'):\r\n    a = tf.random_uniform([size, size])\r\n    b = tf.random_uniform([size, size])\r\n    print('Size: ', a.shape)\r\n    for i in range(5):\r\n      start = time.time() \r\n      tf.matmul(a, b)\r\n      print('Runtime is %2.5f' % (time.time() - start))\r\n\r\nprint('One warmup run to account for GPU initialization')\r\nrun(10)\r\nfor p in [500, 1000, 2000, 5000, 10000]:\r\n  run(p)\r\n```\r\n\r\nWhich results in:\r\n\r\n```\r\nOne warmup run to account for GPU initialization\r\n2017-12-14 03:11:39.311967: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\n2017-12-14 03:11:39.619956: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:895] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2017-12-14 03:11:39.620511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Found device 0 with properties: \r\nname: TITAN X (Pascal) major: 6 minor: 1 memoryClockRate(GHz): 1.531\r\npciBusID: 0000:02:00.0\r\ntotalMemory: 11.90GiB freeMemory: 11.75GiB\r\n2017-12-14 03:11:39.799633: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:895] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\r\n2017-12-14 03:11:39.800043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1103] Found device 1 with properties: \r\nname: Quadro K620 major: 5 minor: 0 memoryClockRate(GHz): 1.124\r\npciBusID: 0000:03:00.0\r\ntotalMemory: 1.94GiB freeMemory: 1.12GiB\r\n2017-12-14 03:11:39.800099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1118] Device peer to peer matrix\r\n2017-12-14 03:11:39.800140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1124] DMA: 0 1 \r\n2017-12-14 03:11:39.800172: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1134] 0:   Y N \r\n2017-12-14 03:11:39.800211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1134] 1:   N Y \r\n2017-12-14 03:11:39.800275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1193] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN X (Pascal), pci bus id: 0000:02:00.0, compute capability: 6.1)\r\n2017-12-14 03:11:39.800330: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Ignoring gpu device (device: 1, name: Quadro K620, pci bus id: 0000:03:00.0, compute capability: 5.0) with Cuda multiprocessor count: 3. The minimum required count is 8. You can adjust this requirement with the env var TF_MIN_GPU_MULTIPROCESSOR_COUNT.\r\n('Size: ', TensorShape([Dimension(10), Dimension(10)]))\r\nRuntime is 0.10812\r\nRuntime is 0.00008\r\nRuntime is 0.00004\r\nRuntime is 0.00004\r\nRuntime is 0.00004\r\n('Size: ', TensorShape([Dimension(500), Dimension(500)]))\r\nRuntime is 0.00005\r\nRuntime is 0.00004\r\nRuntime is 0.00004\r\nRuntime is 0.00004\r\nRuntime is 0.00004\r\n('Size: ', TensorShape([Dimension(1000), Dimension(1000)]))\r\nRuntime is 0.00005\r\nRuntime is 0.00005\r\nRuntime is 0.00005\r\nRuntime is 0.00007\r\nRuntime is 0.00005\r\n('Size: ', TensorShape([Dimension(2000), Dimension(2000)]))\r\nRuntime is 0.00004\r\nRuntime is 0.00004\r\nRuntime is 0.00004\r\nRuntime is 0.00005\r\nRuntime is 0.00004\r\n('Size: ', TensorShape([Dimension(5000), Dimension(5000)]))\r\nRuntime is 0.00004\r\nRuntime is 0.00004\r\nRuntime is 0.00004\r\nRuntime is 0.00006\r\nRuntime is 0.00004\r\n('Size: ', TensorShape([Dimension(10000), Dimension(10000)]))\r\nRuntime is 0.00004\r\nRuntime is 0.00004\r\nRuntime is 0.00004\r\nRuntime is 0.00005\r\nRuntime is 0.00004\r\n```\r\n\r\nDo let us know if these results above are reproducible on your setup and if the explanation makes sense.", "Thank you!! Good to know. When we run that code on our GPU, we get quite similar results (pasted below). \r\n\r\nOur initial results still seem a bit odd to me, I guess, since in some cases you may need to get data from the CPU to the GPU, and it's odd that it takes so much longer for eager mode, and it's also odd that it is initially very fast for eager mode but then slows down? \r\n\r\nResults with your code: \r\nOne warmup run to account for GPU initialization\r\n2017-12-17 08:27:21.289886: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\r\n2017-12-17 08:27:21.720501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1062] Found device 0 with properties:\r\nname: TITAN Xp major: 6 minor: 1 memoryClockRate(GHz): 1.582\r\npciBusID: 0000:82:00.0\r\ntotalMemory: 11.90GiB freeMemory: 11.74GiB\r\n2017-12-17 08:27:21.720605: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1152] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: TITAN Xp, pci bus id: 0000:82:00.0, compute capability: 6.1)\r\nSize:  (10, 10)\r\nRuntime is 0.59110\r\nRuntime is 0.00020\r\nRuntime is 0.00009\r\nRuntime is 0.00009\r\nRuntime is 0.00008\r\nSize:  (500, 500)\r\nRuntime is 0.00014\r\nRuntime is 0.00009\r\nRuntime is 0.00009\r\nRuntime is 0.00009\r\nRuntime is 0.00008\r\nSize:  (1000, 1000)\r\nRuntime is 0.00014\r\nRuntime is 0.00011\r\nRuntime is 0.00010\r\nRuntime is 0.00010\r\nRuntime is 0.00010\r\nSize:  (2000, 2000)\r\nRuntime is 0.00010\r\nRuntime is 0.00009\r\nRuntime is 0.00009\r\nRuntime is 0.00009\r\nRuntime is 0.00009\r\nSize:  (5000, 5000)\r\nRuntime is 0.00010\r\nRuntime is 0.00009\r\nRuntime is 0.00009\r\nRuntime is 0.00009\r\nRuntime is 0.00009\r\nSize:  (10000, 10000)\r\nRuntime is 0.00010\r\nRuntime is 0.00009\r\nRuntime is 0.00009\r\nRuntime is 0.00008\r\nRuntime is 0.00008", "It has been 14 days with no activity and the `awaiting response` label was assigned. Is this still an issue? Please update the label and/or status accordingly.", "Nagging Awaiting Response: It has been 14 days with no activityand the `awaiting response` label was assigned. Is this still an issue?", "Nope! I will close it. "]}, {"number": 15287, "title": "Use base_dtype for self._dtype in tf.layers", "body": "This avoids mismatch dtype (ref vs no_ref) when using variables as inputs to a layer.\r\nSee #15262", "comments": ["Can one of the admins verify this patch?", "@alextp Since you're assigned #15262, do you think this PR is the correct way to fix the issue?", "Yes. I submitted this from the google side (with a test) and it should trickle down to github later today (I hope). So I'll close this PR.\r\n\r\nThanks!"]}, {"number": 15286, "title": "Branch 178689056", "body": "", "comments": ["@googlebot please review"]}, {"number": 15285, "title": "Add kappa coefficient as a new metric?", "body": "Currently tensorflow supports using accuracy as a metric for model's performance.\r\n\r\nHowever, for unbalanced datasets, kappa coefficient (https://www.wikiwand.com/en/Cohen%27s_kappa#) is a commonly used metric. Would it be possible to add this one in the model.metrics?", "comments": ["@roumposg, what do you think about this?", "SG, but I don't think we have the cycles to do it soon. We welcome contributions, though! I would add it to tf.contrib.metrics.", "@hanfeisun Hi, I added a very rudimentary implementation of `cohen_kappa` in PR #15443. It is pretty rough as am not sure about the api. Please take a look and comment. Thanks."]}, {"number": 15284, "title": "[RFE] Runtime GPU Docker image without Jupyter", "body": "Current image size for `nightly-gpu`:\r\n```sh\r\n$ docker images tensorflow/tensorflow:nightly-gpu\r\nREPOSITORY              TAG                 IMAGE ID            CREATED             SIZE\r\ntensorflow/tensorflow   nightly-gpu         8f64c1fbb504        12 hours ago        2.62GB\r\n```\r\nCurrent Dockerfile:\r\nhttps://github.com/tensorflow/tensorflow/blob/abd5375ba8d373045321d1eebdb4501c36ab0ccd/tensorflow/tools/docker/Dockerfile.gpu\r\n\r\nI see two potential improvements:\r\n1) We already switched the `FROM` to use the `runtime` base image of CUDA. We could go one step further and use `nvidia/cuda:9.0-base`. This flavor of CUDA is new with CUDA 9.0, it just installs the repos and libcudart. You have to manually install the CUDA libraries you want afterwards. The gain wouldn't be that big with TensorFlow since you use most of the libraries from the CUDA toolkit. But we will at least remove NPP from the shipped image.\r\n\r\n2) Looks like many dependencies in the current Dockerfile are required for Jupyter. Can we provide a new tag without Jupyter? Or stop shipping Jupyter in the runtime image? Users will still be able to use the `devel` image.\r\n\r\nI have a quick Dockerfile proof-of-concept with both improvements:\r\n```\r\nFROM nvidia/cuda:9.0-base-ubuntu16.04\r\n\r\nLABEL maintainer=\"Gunhan Gulsoy <gunan@google.com>\"\r\n\r\nRUN echo \"/usr/local/cuda-9.0/extras/CUPTI/lib64\" > /etc/ld.so.conf.d/cupti.conf && \\\r\n    apt-get update && apt-get install -y --no-install-recommends \\\r\n        libgomp1 \\\r\n        libcudnn7 \\\r\n        cuda-command-line-tools-9-0 \\\r\n        cuda-cudart-9-0 \\\r\n        cuda-cufft-9-0 \\\r\n        cuda-cublas-9-0 \\\r\n        cuda-cusparse-9-0 \\\r\n        cuda-curand-9-0 \\\r\n        cuda-cusolver-9-0 \\\r\n        python-pip \\\r\n        && \\\r\n    rm -rf /var/lib/apt/lists/\r\n\r\nRUN pip --no-cache-dir install --upgrade \\\r\n        pip setuptools\r\n\r\nRUN pip --no-cache-dir install http://ci.tensorflow.org/view/tf-nightly/job/tf-nightly-linux/TF_BUILD_IS_OPT=OPT,TF_BUILD_IS_PIP=PIP,TF_BUILD_PYTHON_VERSION=PYTHON2,label=gpu-linux/lastSuccessfulBuild/artifact/pip_test/whl/tf_nightly_gpu-1.head-cp27-cp27mu-manylinux1_x86_64.whl\r\n```\r\nSize is now 1.73 GB, down from 2.62 GB. And there is still room for improvement in CUDA 9.1 when CUPTI has its own package (today we have to pull `cuda-command-line-tools-9-0`), or if we disable CUPTI tracing (not sure if possible).\r\n", "comments": ["@gunan thoughts?", "I like the idea, and I expecially like the image size improvement. But I almost never use jupyter myself.\r\n@wolffg @caisq @martinwicke what do you all think?", "Many people do though -- a thinner docker container would make a lot of sense for a lot of people (could we use it in our CI?), but I'm not sure we have an appetite for maintaining more of those. ", "Could these people use the `devel-gpu` image instead? i.e., are they likely to require other packages provided by `devel`? The `nightly-devel-gpu` image is 4.87 GB, but maybe we can shrink it down more to make it acceptable.", "That's a very good idea. We probably want to clean the devel image a bit, but saving weight is always good.", "Ok, I'll see what I can do.\r\nAre you open to docker [multi-stage builds](https://docs.docker.com/engine/userguide/eng-image/multistage-build/)? It requires a recent version of Docker to build, but the generated container image is still compatible with older versions of Docker.", "\ud83d\udc4d for multi-stage build (docker 17.05), if the infrastructure of Jenkins supports it.", "By the way, currently `parameterized_docker_build.sh` uses `sed` to replace the following in Dockerfile in order to provide different builds:\r\n\r\n```\r\n# --- DO NOT EDIT OR DELETE BETWEEN THE LINES --- #\r\n....\r\n# --- ~ DO NOT EDIT OR DELETE BETWEEN THE LINES --- #\r\n```\r\n\r\nI don't know enough about the history of the code base. However, I do think the above could be achieved through other means like `--build-arg`, which might be easier to maintain. Wondering if it make sense to make some changes in this part?\r\n\r\n", "@yongtang yes, @gunan mentioned that he wants to get rid of this script:\r\nhttps://github.com/tensorflow/tensorflow/pull/15205#issuecomment-350197348", "Thanks @flx42 @gunan that would be great. Let me know if I can be of any help.", "Here's a proof of concept for `Dockerfile.devel-gpu`, 2 GB less: https://github.com/flx42/tensorflow/commit/101c8328a166e093925791d6e267a7d2d4ec5ab7\r\nIt uses `master` instead of `r1.4` because of https://github.com/tensorflow/tensorflow/issues/15291\r\n\r\nIf we push something like this, we will be in the same ballpark as the current runtime image. :)", "@yongtang yes, I definitely want to make parameterized_docker_build script unnecessary. We probably will need to keep the script working for a while, but that should not stop us from getting rid of the replaced lines using build_args.\r\nI have not been able to find time for that, but if anyone would like to contribute, I will be happy to review any PRs.", "@gunan @martinwicke any feedback on my improved `devel` Dockerfile?\r\nhttps://github.com/flx42/tensorflow/commit/101c8328a166e093925791d6e267a7d2d4ec5ab7", "I have no opposition to its contents.\n(A better question to you, and nvidia)\nHow much more space can we save by removing some of the CUDA Compute\nCapabilities?\nWe seem to be including quite a bunch.\n\nOn Wed, Dec 13, 2017 at 10:23 AM, Felix Abecassis <notifications@github.com>\nwrote:\n\n> @gunan <https://github.com/gunan> @martinwicke\n> <https://github.com/martinwicke> any feedback on my improved devel\n> Dockerfile?\n> flx42/tensorflow@101c832\n> <https://github.com/flx42/tensorflow/commit/101c8328a166e093925791d6e267a7d2d4ec5ab7>\n>\n> \u2014\n> You are receiving this because you were mentioned.\n> Reply to this email directly, view it on GitHub\n> <https://github.com/tensorflow/tensorflow/issues/15284#issuecomment-351477682>,\n> or mute the thread\n> <https://github.com/notifications/unsubscribe-auth/AHlCOS15fIcEj1eBc-e_ZJZ4KEHSdIDhks5tABY6gaJpZM4Q-OVB>\n> .\n>\n", "I tested that yesterday, I only built for `code=sm_61,compute_61` (the PTX is useless here actually). I gained ~300MB compared to all the archs we have today.\r\nIt also speeds-up build times.\r\n\r\nOur libraries (like `cublas`, `cudnn`, `cufft`) are large because they are also compiled for many compute archs. Even if you create a build of TensorFlow only for `6.1`, `libcublas.so` will still carry the compute archs you don't care about.\r\n\r\nWe do have a tool called `nvprune`, it can allow you to strip some binary/PTX code, but it doesn't work for shared libraries today, unfortunately. If you really wanted to have a minimal TensorFlow GPU build targeted at only one GPU type, I think the only option would be to use nvprune on `lib{cufft,cudnn,cublas,cusparse}_static.a` and then statically link your TensorFlow binary (somehow).\r\n", "@flx42 OCI's image-spec and manifest allows the specification of the running platform's CPU so that for `multi-arch` containers, only the image that is pertinent to user's machine, is downloaded and run. \r\n\r\nThere is no GPU specifications in OCI's image-spec yet though I could see it potentially could be of interest for many people. As user certainly will only want to download and run a minimal GPU capable container image that is relevant to running machine's GPU. I can raise that issue to OCI folks to see if there is anything that could be done in the future in OCI's image-spec.\r\n\r\n", "Nice idea, but I don't see that happening anytime soon ;). It will require the image pull to know which GPUs compute archs you have on the machine (either queried dynamically, or added to the docker configuration by the user). Also, you can have N compute archs on a single machine, so it's more complex that multi-arch.", "@yongtang you can sort of enforce that already with our runtime `arch` [requirement]( https://github.com/NVIDIA/nvidia-container-runtime#nvidia_require_) and the multiarch manifest supports arbitrary OS features, so it shouldn't be too hard in theory", "@3XX0 Thanks. That is good. I will see what could be done in docker for any enhancement. May need to discuss with other docker maintainers first though.", "@gunan now that #15355 was merged, the size of the `devel` image is now in the same ballpark as the `runtime` image today. We could then remove Jupyter from `runtime` and ask Jupyter users to use the `devel` image. Or do we want a new image tag?\r\n\r\nWhat do you think? ", "(I am on Gunan's team, hoping to help out with Docker things.)\r\n\r\nNaive question: what's the use case for Jupyter? If the -devel images are for developing on TF and the non-devel images are for developing *with* TF, does it make more sense for Jupyter to only be in the non-devel images (or in an image to itself?)", "I would say it should be a separate image, to avoid bloat in the `non-devel` image. But it seems you weren't willing to add a new tag.", "This is the jupyter we are talking about: http://jupyter.org/\r\nWe use this to run most of the tutorials. It is a neat learning tool.\r\nBut this is something I never really used myself.\r\n\r\nI like the new image idea better. If it were up to me, I would have a CPU only image that has jupyter for tutorials. @random-forests @wolffg @MarkDaoust what do you think?\r\nAre you OK with us creating a completely separate docker image with Jupyter?\r\nDo we even need GPU support for the image with jupyter?", "I've heard one report of a developer/data scientist using Jupyter for his day-to-day work, as a replacement for a code editor.\r\nI don't know if it's very common, but if it is, it would probably warrant keeping a GPU + Jupyter image.", "We are _planning_ to convert docs to use Jupyter format, where it makes sense. \r\n\r\nSo it will might be nice to have a GPU+Jupyter option when that happens, as some of the tutorials are pretty heavy, but it's hard to gauge how many users this would help.\r\n ", "Ideally, I think you should have 6 tags:\r\n- `cpu`\r\n- `jupyter-cpu` (extends the `cpu` image)\r\n- `devel-cpu`\r\n- `gpu`\r\n- `jupyter-gpu` (extends the `gpu` image).\r\n- `devel-gpu`\r\n\r\nThe non-Jupyter images (`devel` or not) will become smaller. \r\n\r\nBut, I helped shrink the `devel-gpu` image in case you don't want to introduce new tags. If the user just wants to use Jupyter, he probably doesn't care if it's `devel` or not behind the scenes, as long as the image size is reasonable.\r\n", "considering some of our tutorials also involve modifying code, let's add jupyter in our devel images, and minimize the size of our non-devel images as much as we can.", "> considering some of our tutorials also involve modifying code\r\n\r\nWait, modifying the TensorFlow code and recompiling it?\r\n\r\n> let's add jupyter in our devel images\r\n\r\nJupyter is already in the devel image I believe, the difference being that it doesn't start automatically, like the non-`devel` image does today.", "@gunan @angersson given the recent changes to the docker files, should this still be open?", "I think this discussion is still relevant, since Jupyter is still in the images we offer.", "So should we do this then? Any volunteer to send a PR for the `Dockerfile` without jupyter? As @yongtang suggested, if we remove the Jupyter section then this can be built at no extra cost because docker hashes each command and keeps the layers. What else do we need, some docs? Are people supposed to `docker run .. bash` then run python by hand?\r\n\r\nAnother possibility is to have a docker jupyter mount a tensorflow volume, though I'm not 100% how that would work with pip.", "We can probably just use a dockerfile like this:\r\nhttps://github.com/gunan/tensorflow-docker/blob/master/gpu-devel/Dockerfile.ubuntu\r\nWe will need to update scripts we have, too.", "I've recently proposed a change to TensorFlow that obsoletes parameterized_docker_build.sh, which should help alleviate this issue (in fact, this issue was one of the direct inspirations). If anyone following this thread is interested in making TensorFlow's Dockerfile story better for everyone, [please take a look at the RFC](https://github.com/tensorflow/community/pull/8).", "Not sure if still relevant, but ...\r\nOn the docs side, Jupyter notebooks are popular with users and something we're pushing more on tensorflow.org. And, in fact, we use a TensorFlow Docker container with Jupyter to render a number of tutorials and guides on the site.\r\n\r\nMy understanding is the *-devel* images are intended for hacking on TensorFlow and building from source. Jupyter notebooks are more for users and don't need to be included there.\r\n\r\nI have [an update to the /install section](https://github.com/tensorflow/docs/pull/42) that will elevate the Docker instructions more. I would prefer that the general images are more \"batteries included\" since it's a much easier story to tell instead of pointing beginners to a matrix of docker tags.\r\n\r\nWhat about a *-base* tag for something a little more \"lean and mean\"?", "Thanks for the information.\r\nThat aligns with what I vaguely remember.\r\n\r\nI would like to avoid proliferation of tags, to avoid confusion, so I would vote against the `-base` tag. But I think we will remove the jupyter notebooks from the devel images.", "I think this is done. The newer [Docker images](https://hub.docker.com/r/tensorflow/tensorflow) have subtags for `jupyter` now, and the base images exclude it.", "> I think this is done. The newer [Docker images](https://hub.docker.com/r/tensorflow/tensorflow) have subtags for `jupyter` now, and the base images exclude it.\r\n\r\n```tensorflow/tensorflow:1.12.0-gpu-py3``` still has jupyter in it, as far as I can tell.\r\n", "Right. The new docker images are only effective for tags newer than 1.12. "]}, {"number": 15283, "title": "Fix minor typo in CUDNN_VERSION check", "body": "Effectively enables CUDNN_CONVOLUTION_BWD_FILTER_ALGO_WINOGRAD_NONFUSED in\r\nCudnnSupport::GetConvolveBackwardFilterAlgorithms() for cuDNN v5.1.", "comments": ["Can one of the admins verify this patch?", "Jenkins, test this please.", "@tensorflow-jenkins test this please"]}, {"number": 15282, "title": "Fixed memory_stats_ops_test", "body": "Added explicit dependency to avoid matrix free prior to stats op execution.", "comments": ["Can one of the admins verify this patch?", "@tensorflow-jenkins test this please"]}, {"number": 15281, "title": "Remove redundant dependencies.", "body": "Looks like they got added back during merge. #15136", "comments": ["FYI sync team I'm bringing this PR in as CL. Please do NOT merge or close yet. Thanks!"]}]